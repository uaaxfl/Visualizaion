2021.splurobonlp-1.4,Modeling Semantics and Pragmatics of Spatial Prepositions via Hierarchical Common-Sense Primitives,2021,-1,-1,6,1,1054,georgiy platonov,Proceedings of Second International Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics,0,"Understanding spatial expressions and using them appropriately is necessary for seamless and natural human-machine interaction. However, capturing the semantics and appropriate usage of spatial prepositions is notoriously difficult, because of their vagueness and polysemy. Although modern data-driven approaches are good at capturing statistical regularities in the usage, they usually require substantial sample sizes, often do not generalize well to unseen instances and, most importantly, their structure is essentially opaque to analysis, which makes diagnosing problems and understanding their reasoning process difficult. In this work, we discuss our attempt at modeling spatial senses of prepositions in English using a combination of rule-based and statistical learning approaches. Each preposition model is implemented as a tree where each node computes certain intuitive relations associated with the preposition, with the root computing the final value of the prepositional relation itself. The models operate on a set of artificial 3D {``}room world{''} environments, designed in Blender, taking the scene itself as an input. We also discuss our annotation framework used to collect human judgments employed in the model training. Both our factored models and black-box baseline models perform quite well, but the factored models will enable reasoned explanations of spatial relation judgements."
2021.reinact-1.8,Generating Justifications in a Spatial Question-Answering Dialogue System for a Blocks World,2021,-1,-1,3,1,1054,georgiy platonov,Proceedings of the Reasoning and Interaction Conference (ReInAct 2021),0,"As AI reaches wider adoption, designing systems that are explainable and interpretable becomes a critical necessity. In particular, when it comes to dialogue systems, their reasoning must be transparent and must comply with human intuitions in order for them to be integrated seamlessly into day-to-day collaborative human-machine activities. Here, we describe our ongoing work on a (general purpose) dialogue system equipped with a spatial specialist with explanatory capabilities. We applied this system to a particular task of characterizing spatial configurations of blocks in a simple physical Blocks World (BW) domain using natural locative expressions, as well as generating justifications for the proposed spatial descriptions by indicating the factors that the system used to arrive at a particular conclusion."
2020.sigdial-1.16,A Spoken Dialogue System for Spatial Question Answering in a Physical Blocks World,2020,-1,-1,2,1,1054,georgiy platonov,Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"A physical blocks world, despite its relative simplicity, requires (in fully interactive form) a rich set of functional capabilities, ranging from vision to natural language understanding. In this work we tackle spatial question answering in a holistic way, using a vision system, speech input and output mediated by an animated avatar, a dialogue system that robustly interprets spatial queries, and a constraint solver that derives answers based on 3-D spatial modeling. The contributions of this work include a semantic parser that maps spatial questions into logical forms consistent with a general approach to meaning representation, a dialogue manager based on a schema representation, and a constraint solver for spatial questions that provides answers in agreement with human perception. These and other components are integrated into a multi-modal human-computer interaction pipeline."
W19-3306,Generating Discourse Inferences from Unscoped Episodic Logical Formulas,2019,0,0,8,1,24468,gene kim,Proceedings of the First International Workshop on Designing Meaning Representations,0,"Abstract Unscoped episodic logical form (ULF) is a semantic representation capturing the predicate-argument structure of English within the episodic logic formalism in relation to the syntactic structure, while leaving scope, word sense, and anaphora unresolved. We describe how ULF can be used to generate natural language inferences that are grounded in the semantic and syntactic structure through a small set of rules defined over interpretable predicates and transformations on ULFs. The semantic restrictions placed by ULF semantic types enables us to ensure that the inferred structures are semantically coherent while the nearness to syntax enables accurate mapping to English. We demonstrate these inferences on four classes of conversationally-oriented inferences in a mixed genre dataset with 68.5{\%} precision from human judgments."
W19-1102,Towards Natural Language Story Understanding with Rich Logical Schemas,2019,0,0,3,1,24468,gene kim,Proceedings of the Sixth Workshop on Natural Language and Computer Science,0,"Generating {``}commonsense{'}{'} knowledge for intelligent understanding and reasoning is a difficult, long-standing problem, whose scale challenges the capacity of any approach driven primarily by human input. Furthermore, approaches based on mining statistically repetitive patterns fail to produce the rich representations humans acquire, and fall far short of human efficiency in inducing knowledge from text. The idea of our approach to this problem is to provide a learning system with a {``}head start{''} consisting of a semantic parser, some basic ontological knowledge, and most importantly, a small set of very general schemas about the kinds of patterns of events (often purposive, causal, or socially conventional) that even a one- or two-year-old could reasonably be presumed to possess. We match these initial schemas to simple children{'}s stories, obtaining concrete instances, and combining and abstracting these into new candidate schemas. Both the initial and generated schemas are specified using a rich, expressive logical form. While modern approaches to schema reasoning often only use slot-and-filler structures, this logical form allows us to specify complex relations and constraints over the slots. Though formal, the representations are language-like, and as such readily relatable to NL text. The agents, objects, and other roles in the schemas are represented by typed variables, and the event variables can be related through partial temporal ordering and causal relations. To match natural language stories with existing schemas, we first parse the stories into an underspecified variant of the logical form used by the schemas, which is suitable for most concrete stories. We include a walkthrough of matching a children{'}s story to these schemas and generating inferences from these matches."
W19-0402,"A Type-coherent, Expressive Representation as an Initial Step to Language Understanding",2019,33,1,2,1,24468,gene kim,Proceedings of the 13th International Conference on Computational Semantics - Long Papers,0,"A growing interest in tasks involving language understanding by the NLP community has led to the need for effective semantic parsing and inference. Modern NLP systems use semantic representations that do not quite fulfill the nuanced needs for language understanding: adequately modeling language semantics, enabling general inferences, and being accurately recoverable. This document describes underspecified logical forms (ULF) for Episodic Logic (EL), which is an initial form for a semantic representation that balances these needs. ULFs fully resolve the semantic type structure while leaving issues such as quantifier scope, word sense, and anaphora unresolved; they provide a starting point for further resolution into EL, and enable certain structural inferences without further resolution. This document also presents preliminary results of creating a hand-annotated corpus of ULFs for the purpose of training a precise ULF parser, showing a three-person pairwise interannotator agreement of 0.88 on confident annotations. We hypothesize that a divide-and-conquer approach to semantic parsing starting with derivation of ULFs will lead to semantic analyses that do justice to subtle aspects of linguistic meaning, and will enable construction of more accurate semantic parsers."
W18-1403,Computational Models for Spatial Prepositions,2018,0,1,2,1,1054,georgiy platonov,Proceedings of the First International Workshop on Spatial Language Understanding,0,"Developing computational models of spatial prepositions (such as on, in, above, etc.) is crucial for such tasks as human-machine collaboration, story understanding, and 3D model generation from descriptions. However, these prepositions are notoriously vague and ambiguous, with meanings depending on the types, shapes and sizes of entities in the argument positions, the physical and task context, and other factors. As a result truth value judgments for prepositional relations are often uncertain and variable. In this paper we treat the modeling task as calling for assignment of probabilities to such relations as a function of multiple factors, where such probabilities can be viewed as estimates of whether humans would judge the relations to hold in given circumstances. We implemented our models in a 3D blocks world and a room world in a computer graphics setting, and found that true/false judgments based on these models do not differ much more from human judgments that the latter differ from one another. However, what really matters pragmatically is not the accuracy of truth value judgments but whether, for instance, the computer models suffice for identifying objects described in terms of prepositional relations, (e.g., {``}the box to the left of the table{''}, where there are multiple boxes). For such tasks, our models achieved accuracies above 90{\%} for most relations."
W17-1802,"Intension, Attitude, and Tense Annotation in a High-Fidelity Semantic Representation",2017,10,0,2,1,24468,gene kim,Proceedings of the Workshop Computational Semantics Beyond Events and Roles,0,"This paper describes current efforts in developing an annotation schema and guidelines for sentences in Episodic Logic (EL). We focus on important distinctions for representing modality, attitudes, and tense and present an annotation schema that makes these distinctions. EL has proved competitive with other logical formulations in speed and inference-enablement, while expressing a wider array of natural language phenomena including intensional modification of predicates and sentences, propositional attitudes, and tense and aspect."
S16-2004,High-Fidelity Lexical Axiom Construction from Verb Glosses,2016,30,2,2,1,24468,gene kim,Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics,0,"This paper presents a rule-based approach to constructing lexical axioms from WordNet verb entries in an expressive semantic representation, Episodic Logic (EL). EL differs from other representations in being syntactically close to natural language and covering phenomena such as generalized quantification, modification, and intensionality while still allowing highly effective inference. The presented approach uses a novel preprocessing technique to improve parsing precision of coordinators and incorporates frames, hand-tagged word senses, and examples from WordNet to achieve highly consistent semantic interpretations. EL allows the full content of glosses to be incorporated into the formal lexical axioms, without sacrificing interpretive accuracy, or verb-to-verb inference accuracy on a standard test set. Evaluation of semantic parser performance is based on EL-match, introduced here as a generalization of the smatch metric for semantic structure accuracy. On gloss parses, the approach achieves an ELmatch F1 score of 0.83, and a wholeaxiom F1 score of 0.45; verb entailment identification based on extracted axioms is competitive with the state-of-the-art."
W14-2411,From Treebank Parses to Episodic Logic and Commonsense Inference,2014,25,6,1,1,1059,lenhart schubert,Proceedings of the {ACL} 2014 Workshop on Semantic Parsing,0,"We have developed an approach to broad-coverage semantic parsing that starts with Treebank parses and yields scoped, deindexed formulas in Episodic Logic (EL) that are directly usable for knowledgebased inference. Distinctive properties of our approach are xe2x80xa2 the use of a tree transduction language, TTT, to partially disambiguate, refine (and sometimes repair) raw Treebank parses, and also to perform many deindexing and logical canonicalization tasks; xe2x80xa2 the use of EL, a Montague-inspired logical framework for semantic representation and knowledge representation; xe2x80xa2 allowance for nonclassical restricted quantifiers, several forms of modification and reification, quasi-quotes and syntactic closures; xe2x80xa2 an event semantics that directly represents events with complex characterizations; xe2x80xa2 a scoping algorithm that heuristically scopes quantifiers, logical connectives, and tense; xe2x80xa2 a compositional approach to tense deindexing making use of tense trees; and xe2x80xa2 the use of an inference engine, EPILOG, that supports input-driven and goal-driven inference in EL, in a style similar to (but more general than) Natural Logic."
2014.lilt-9.9,{NL}og-like Inference and Commonsense Reasoning,2014,36,6,1,1,1059,lenhart schubert,"Linguistic Issues in Language Technology, Volume 9, 2014 - Perspectives on Semantic Representations for Textual Inference",0,"Recent implementations of Natural Logic (NLog) have shown that NLog provides a quite direct means of going from sentences in ordinary language to many of the obvious entailments of those sentences. We show here that Episodic Logic (EL) and its Epilog implementation are well-adapted to capturing NLog-like inferences, but beyond that, also support inferences that require a combination of lexical knowledge and world knowledge. However, broad language understanding and commonsense reasoning are still thwarted by the {``}knowledge acquisition bottleneck{''}, and we summarize some of our ongoing and contemplated attacks on that persistent difficulty."
W12-3023,Using Textual Patterns to Learn Expected Event Frequencies,2012,14,7,2,1,27156,jonathan gordon,Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction ({AKBC}-{WEKEX}),0,"Commonsense reasoning requires knowledge about the frequency with which ordinary events and activities occur: How often do people eat a sandwich, go to sleep, write a book, or get married? This paper introduces work to acquire a knowledge base pairing factoids about such events with frequency categories learned from simple textual patterns. We are releasing a collection of the resulting event frequencies, which are evaluated for accuracy, and we demonstrate an initial application of the results to the problem of knowledge refinement."
W12-0803,{TTT}: A Tree Transduction Language for Syntactic and Semantic Processing,2012,12,8,2,0,42512,adam purtee,Proceedings of the Workshop on Applications of Tree Automata Techniques in Natural Language Processing,0,"In this paper we present the tree to tree transduction language, TTT. We motivate the overall template-to-template approach to the design of the language, and outline its constructs, also providing some examples. We then show that TTT allows transparent formalization of rules for parse tree refinement and correction, logical form refinement and predicate disambiguation, inference, and verbalization of logical forms."
W11-2408,Discovering Commonsense Entailment Rules Implicit in Sentences,2011,17,12,2,1,27156,jonathan gordon,Proceedings of the {T}ext{I}nfer 2011 Workshop on Textual Entailment,0,"Reasoning about ordinary human situations and activities requires the availability of diverse types of knowledge, including expectations about the probable results of actions and the lexical entailments for many predicates. We describe initial work to acquire such a collection of conditional (if--then) knowledge by exploiting presuppositional discourse patterns (such as ones involving 'but', 'yet', and 'hoping to') and abstracting the matched material into general rules."
W10-0724,Evaluation of Commonsense Knowledge with {M}echanical {T}urk,2010,13,18,3,1,27156,jonathan gordon,Proceedings of the {NAACL} {HLT} 2010 Workshop on Creating Speech and Language Data with {A}mazon{'}s Mechanical Turk,0,"Efforts to automatically acquire world knowledge from text suffer from the lack of an easy means of evaluating the resulting knowledge. We describe initial experiments using Mechanical Turk to crowdsource evaluation to non-experts for little cost, resulting in a collection of factoids with associated quality judgements. We describe the method of acquiring usable judgements from the public and the impact of such large-scale evaluation on the task of knowledge acquisition."
N09-3007,Building a Semantic Lexicon of {E}nglish Nouns via Bootstrapping,2009,11,4,3,0.625,36922,ting qian,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Student Research Workshop and Doctoral Consortium",0,We describe the use of a weakly supervised bootstrapping algorithm in discovering contrasting semantic categories from a source lexicon with little training data. Our method primarily exploits the patterns in sentential contexts where different categories of words may appear. Experimental results are presented showing that such automatically categorized terms tend to agree with human judgements.
E09-1092,Deriving Generalized Knowledge from Corpora Using {W}ord{N}et Abstraction,2009,27,29,3,1,668,benjamin durme,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"Existing work in the extraction of commonsense knowledge from text has been primarily restricted to factoids that serve as statements about what may possibly obtain in the world. We present an approach to deriving stronger, more general claims by abstracting over large sets of factoids. Our goal is to coalesce the observed nominals for a given predicate argument into a few predominant types, obtained as WordNet synsets. The results can be construed as generically quantified sentences restricting the semantic type of an argument position of a predicate."
W08-2219,Open Knowledge Extraction through Compositional Language Processing,2008,20,37,2,1,668,benjamin durme,Semantics in Text Processing. {STEP} 2008 Conference Proceedings,0,"We present results for a system designed to perform Open Knowledge Extraction, based on a tradition of compositional language processing, as applied to a large collection of text derived from the Web. Evaluation through manual assessment shows that well-formed propositions of reasonable quality, representing general world knowledge, given in a logical form potentially usable for inference, may be extracted in high volume from arbitrary input sentences. We compare these results with those obtained in recent work on Open Information Extraction, indicating with some examples the quite different kinds of output obtained by the two approaches. Finally, we observe that portions of the extracted knowledge are comparable to results of recent work on class attribute extraction."
C08-1116,Class-Driven Attribute Extraction,2008,17,22,3,1,668,benjamin durme,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"We report on the large-scale acquisition of class attributes with and without the use of lists of representative instances, as well as the discovery of unary attributes, such as typically expressed in English through prenominal adjectival modification. Our method employs a system based on compositional language processing, as applied to the British National Corpus. Experimental results suggest that document-based, open class attribute extraction can produce results of comparable quality as those obtained using web query logs, indicating the utility of exploiting explicit occurrences of class labels in text."
W03-0902,Extracting and evaluating general world knowledge from the Brown Corpus,2003,15,59,1,1,1059,lenhart schubert,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Text Meaning,0,"We have been developing techniques for extracting general world knowledge from miscellaneous texts by a process of approximate interpretation and abstraction, focusing initially on the Brown corpus. We apply interpretive rules to clausal patterns and patterns of modification, and concurrently abstract general possibilistic propositions from the resulting formulas. Two examples are A person may believe a proposition, and Children may live with relatives. Our methods currently yield over 117,000 such propositions (of variable quality) for the Brown corpus (more than 2 per sentence). We report here on our efforts to evaluate these results with a judging scheme aimed at determining how many of these propositions pass muster as reasonable general claims about the world in the opinion of human judges. We find that nearly 60% of the extracted propositions are favorably judged according to our scheme by any given judge. The percentage unanimously judged to be reasonable claims by multiple judges is lower, but still sufficiently high to suggest that our techniques may be of some use in tackling the long-standing knowledge acquisition bottleneck in AI."
W99-0622,Guiding a Well-Founded Parser with Corpus Statistics,1999,16,1,2,0,54854,amon seagull,1999 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,None
P99-1053,A Syntactic Framework for Speech Repairs and Other Disruptions,1999,11,30,2,0,51373,mark core,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents a grammatical and processing framework for handling the repairs, hesitations, and other interruptions in natural human dialog. The proposed framework has proved adequate for a collection of human-human task-oriented dialogs, both in a full manual examination of the corpus, and in tests with a parser capable of parsing some of that corpus. This parser can also correct a pre-parser speech repair identifier resulting in a 4.8% increase in recall."
H93-1027,Interpreting Temporal Adverbials,1993,22,8,2,1,56791,chung hwang,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,"We take for granted that sentences describe situations [2, 12]. One of the most important properties of situations are then their temporal locations, which are indicated by tense and aspect and temporal adverbials in the surface form. In [10, 22], we offered a formal theory for English tense and aspect and an algorithm that computes the temporal relationships between the situations implicitly introduced by a text. In the present paper, we propose a systematic approach to temporal adverbials, fully integrated with our tense-aspect theory and the interpretive algorithms, using the Episodic Logic (EL) formalism [9, 11, 12, 21]."
P92-1030,Tense Trees as the {``}Fine Structure{''} of Discourse,1992,21,48,2,1,56791,chung hwang,30th Annual Meeting of the Association for Computational Linguistics,1,"We present a new compositional tense-aspect deindexing mechanism that makes use of tense trees as components of discourse contexts. The mechanism allows reference episodes to be correctly identified even for embedded clauses and for discourse that involves shifts in temporal perspective, and permits deindexed logical forms to be automatically computed with a small number of deindexing rules."
H91-1105,"Natural Language, Knowledge Representation and Discourse",1991,-1,-1,2,0.621452,17476,james allen,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,None
H90-1008,"Picking Reference Events from Tense A Formal, Implement able Theory of {E}nglish Tense-Aspect Semantics Trees:",1990,12,10,1,1,1059,lenhart schubert,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"Despite numerous investigations into English tense-aspect semantics, the problem of formally interpreting tense and aspect remains in large part unsolved. A formal solution requires (a) a well-defined mapping from a subset of English covering the most common tense-aspect constructions (including embedded tensed clauses) to a formal meaning representation, and (b) a well-defined denotational semantics for the meaning representation, which accords with speakers' intuitions about the original text. We propose a simple structure called a tense tree (or a set of connected tense trees) as a basis for interpreting tense-aspect constructions and some time adverbials in a context-dependent way. The de-indexicalization process simultaneously transforms tense trees and logical forms, the former in accord with simple recursion equations and the latter in accord with formal equivalences between context-indexed and context-independent logical forms. The rules have been implemented, and yield meaning representations in a formal episodic logic for narrative understanding."
H90-1101,"Natural Language, Knowledge Representation, and Discourse",1990,0,0,2,0.854143,17476,james allen,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"The principal objective of this project is to develop a system for representing and reasoning about the discourse context in extended man-machine dialogs. Current focus areas include the development of a general theory of multi-agent planning to account for the structure of natural-language dialog, the development of a general knowledge representation for capturing a wide range of natural language semantics, and the development of a general, error- tolerant parser and semantic interpreter for English that can be guided by discourse information. Specifically, we are developing a model of discourse plans that includes actions such as introducing a new topic, as well as the actions of clarifying, correcting or acknowledging parts of the previous dialog. We are exploring how far the planning approach can be extended, and how the traditional language components, i.e. parsing, semantic interpretation and discourse processing, relate to the planning component."
H89-2071,"Natural Language, Knowledge Representation and Discourse",1989,-1,-1,2,0.854143,17476,james allen,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,None
P84-1025,Two Theories for Computing the Logical Form of Mass Expressions,1984,7,3,2,0,32409,francis pelletier,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,"There are various difficulties in accomodating the traditional mass/count distinction into a grammar for English which has a goal the production of logical form semantic translations of the initial English sentences. The present paper surveys some of these difficulties. One puzzle is whether the distinction is a syntactic one or a semantic one, i.e., whether it is a well-formedness constraint or whether it is a description of the semantic translations produced. Another puzzle is whether it should be applied to simple words (as they occur in the lexicon) or whether it should apply only to longer units (such as entire NPs). Of the wide variety of possible theories, only two seem to produce the required results (having to do with plausible inferences and intuitively satisfying semantic representations). These two theories are developed and compared."
P84-1054,On Parsing Preferences,1984,7,36,1,1,1059,lenhart schubert,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,"It is argued that syntactic preference principles such as Right Association and Minimal Attachment are unsatisfactory as usually formulated. Among the difficulties are: (1) dependence on ill-specified or implausible principles of parser operation; (2) dependence on questionable assumptions about syntax; (3) lack of provision, even in principle, for integration with semantic and pragmatic preference principles; and (4) apparent counterexamples, even when discounting (1)--(3). A possible approach to a solution is sketched."
J82-1003,From {E}nglish to Logic: Context-Free Computation of {`}Conventional{'} Logical Translation,1982,53,76,1,1,1059,lenhart schubert,American Journal of Computational Linguistics,0,"We describe an approach to parsing and logical translation that was inspired by Gazdar's work on context-free grammar for English. Each grammar rule consists of a syntactic part that specifies an acceptable fragment of a parse tree, and a semantic part that specifies how the logical formulas corresponding to the constituents of the fragment are to be combined to yield the formula for the fragment. However, we have sought to reformulate Gazdar's semantic rules so as to obtain more or less 'conventional' logical translations of English sentences, avoiding the interpretation of NPs as property sets and the use of intensional functors other than certain propositional operators. The reformulated semantic rules often turn out to be slightly simpler than Gazdar's. Moreover, by using a semantically ambiguous logical syntax for the preliminary translations, we can account for quantifier and coordinator scope ambiguities in syntactically unambiguous sentences without recourse to multiple semantic rules, and are able to separate the disambiguation process from the operation of the parser-translator. We have implemented simple recursive descent and left-corner parsers to demonstrate the practicality of our approach."
