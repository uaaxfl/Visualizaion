2004.iwslt-evaluation.8,P00-1056,0,0.237361,"ineseEnglish track. 2.1. Log-linear Model As originally proposed by [8], the most likely translation of a foreign source sentence f into English is obtained by searching for the sentence with the highest posterior probability: The ITC-irst SMT system implements an extension of the IBM Model 4 as a log-linear interpolation of statistical models, which estimate probabilities in terms of phrases. The use of phrases rather than words has recently emerged as a mean to cope with the limited context that Model 4 exploits to guess word translation (lexicon model) and word positions (distortion model) [1, 2, 3, 4, 5, 6, 7]. e∗ = arg max Pr(e |f ) e (1) Usually, the hidden variable a is introduced: While parameters of the models are estimated exploiting statistics of phrase pairs extracted from word alignments, the weights of the interpolation are optimized through a training procedure which directly aims at minimizing translation errors on a development set. e∗ = arg max e X Pr(e, a |f ) (2) a which represents an alignment from source to target positions. The framework of maximum entropy [9] provides a mean to directly estimate the posterior probability Pr(e, a |f ). It is determined through suitable real value"
2004.iwslt-evaluation.8,J03-1002,0,0.0116263,"own that if the process succeeds in generating a triple (φl0 , τ0l , π0l ), then there is exactly one corresponding pair (f , a), and viceversa. This property justifies the following decomposition of Model 4: pθ (f , a |e) = p(φl0 , τ0l , π0l |el0 ) = p(φ, τ , π |e) p(τi |φi , ei ) k=1 a a φi ) (10) i=1 with where λi ’s represent scaling factors of factors. In eq. (5), English strings e are ranked on the basis of the weighted product of the language model probability Pr(e), usually computed through an n-gram language model [13], and the marginal of the translation probability Pr(f , a |e). In [8, 14] six translation models (Model 1 to 6) of increasing complexity are introduced. These alignment models are usually estimated through the Expectation Maximization algorithm [15], or approximations of it, by exploiting a suitable parallel corpus of translation pairs. For computational reasons, the optimal translation of f is computed with the approximated search criterion: e l Y l X i=0 exploiting eq. (3), eq. (2) can be rewritten as: e∗ p(φi |ei ) p(φ0 | i=1 Unfortunately, a closed-form solution of (4) does not exist. An iterative procedure converging to the solution was proposed by [10]; an im"
2004.iwslt-evaluation.8,P01-1067,0,0.114159,"ineseEnglish track. 2.1. Log-linear Model As originally proposed by [8], the most likely translation of a foreign source sentence f into English is obtained by searching for the sentence with the highest posterior probability: The ITC-irst SMT system implements an extension of the IBM Model 4 as a log-linear interpolation of statistical models, which estimate probabilities in terms of phrases. The use of phrases rather than words has recently emerged as a mean to cope with the limited context that Model 4 exploits to guess word translation (lexicon model) and word positions (distortion model) [1, 2, 3, 4, 5, 6, 7]. e∗ = arg max Pr(e |f ) e (1) Usually, the hidden variable a is introduced: While parameters of the models are estimated exploiting statistics of phrase pairs extracted from word alignments, the weights of the interpolation are optimized through a training procedure which directly aims at minimizing translation errors on a development set. e∗ = arg max e X Pr(e, a |f ) (2) a which represents an alignment from source to target positions. The framework of maximum entropy [9] provides a mean to directly estimate the posterior probability Pr(e, a |f ). It is determined through suitable real value"
2004.iwslt-evaluation.8,W02-1018,0,0.0226266,"ineseEnglish track. 2.1. Log-linear Model As originally proposed by [8], the most likely translation of a foreign source sentence f into English is obtained by searching for the sentence with the highest posterior probability: The ITC-irst SMT system implements an extension of the IBM Model 4 as a log-linear interpolation of statistical models, which estimate probabilities in terms of phrases. The use of phrases rather than words has recently emerged as a mean to cope with the limited context that Model 4 exploits to guess word translation (lexicon model) and word positions (distortion model) [1, 2, 3, 4, 5, 6, 7]. e∗ = arg max Pr(e |f ) e (1) Usually, the hidden variable a is introduced: While parameters of the models are estimated exploiting statistics of phrase pairs extracted from word alignments, the weights of the interpolation are optimized through a training procedure which directly aims at minimizing translation errors on a development set. e∗ = arg max e X Pr(e, a |f ) (2) a which represents an alignment from source to target positions. The framework of maximum entropy [9] provides a mean to directly estimate the posterior probability Pr(e, a |f ). It is determined through suitable real value"
2004.iwslt-evaluation.8,2003.mtsummit-papers.53,0,0.0486164,"ineseEnglish track. 2.1. Log-linear Model As originally proposed by [8], the most likely translation of a foreign source sentence f into English is obtained by searching for the sentence with the highest posterior probability: The ITC-irst SMT system implements an extension of the IBM Model 4 as a log-linear interpolation of statistical models, which estimate probabilities in terms of phrases. The use of phrases rather than words has recently emerged as a mean to cope with the limited context that Model 4 exploits to guess word translation (lexicon model) and word positions (distortion model) [1, 2, 3, 4, 5, 6, 7]. e∗ = arg max Pr(e |f ) e (1) Usually, the hidden variable a is introduced: While parameters of the models are estimated exploiting statistics of phrase pairs extracted from word alignments, the weights of the interpolation are optimized through a training procedure which directly aims at minimizing translation errors on a development set. e∗ = arg max e X Pr(e, a |f ) (2) a which represents an alignment from source to target positions. The framework of maximum entropy [9] provides a mean to directly estimate the posterior probability Pr(e, a |f ). It is determined through suitable real value"
2004.iwslt-evaluation.8,N03-1017,0,0.0501189,"d by the many papers on the subject, which followed its first introduction. Of course, there have been also attempts to overcome some of its shortcomings, e.g. the use of limited context within the foreign string to guess word translations and word positions. Recently, several research labs have reported improvements in translation accuracy by shifting from word- to phrase-based SMT. In particular, statistical phrasebased translation models have recently emerged, which rely on statistics of phrase pairs. Phrase pairs statistics can be automatically extracted from word-aligned parallel corpora [5]. In the following subsections, we introduce the SMT framework and the Model 4. Then, we briefly describe a method for extracting phrase pairs. Finally, a novel phrase-based translation framework is presented which is tightly related to Model 4. Focus of this paper is the system for statistical machine translation developed at ITC-irst. It has been employed in the evaluation campaign of the International Workshop on Spoken Language Translation 2004 in all the three data set conditions of the Chinese-English track. Both the statistical model underlying the system and the system architecture are"
2004.iwslt-evaluation.8,2004.iwslt-papers.2,1,0.890764,"by means of the GIZA++ toolkit [1]. Phrase pairs are then extracted taking into account both direct and inverse alignments (see section 2.3), and the phrase-based distributions are estimated (section 2.4). In the second phase the scaling factors of the log-linear model are estimated by the so-called minimum error training procedure. This iterative method searches for a set of factors that minimizes a given error measure on a development corpus. The simplex method [17] is used to explore the space of scaling factors. A detailed description of the minimum error training approach is reported in [18]. BLEU NIST MWER MPER 0.3001 0.3509 0.3466 0.3460 0.4311 0.4574 7.0157 7.5099 7.4475 7.4427 8.5336 8.7890 50.8 47.2 47.6 47.1 42.0 39.7 41.5 38.1 38.3 38.3 33.3 30.5 baseline system, provided these data are close enough to the domain of the test set. However, an exhaustive exploration of corpora available for the IWSLT evaluation for finding the best combination for training the system is unfeasible. Hence, first we searched for the best monolingual resources consisting of the English part of parallel corpora. Successively, we tried the effectiveness of additional bilingual resources. Note tha"
2004.iwslt-evaluation.8,W03-1001,0,0.125553,"ineseEnglish track. 2.1. Log-linear Model As originally proposed by [8], the most likely translation of a foreign source sentence f into English is obtained by searching for the sentence with the highest posterior probability: The ITC-irst SMT system implements an extension of the IBM Model 4 as a log-linear interpolation of statistical models, which estimate probabilities in terms of phrases. The use of phrases rather than words has recently emerged as a mean to cope with the limited context that Model 4 exploits to guess word translation (lexicon model) and word positions (distortion model) [1, 2, 3, 4, 5, 6, 7]. e∗ = arg max Pr(e |f ) e (1) Usually, the hidden variable a is introduced: While parameters of the models are estimated exploiting statistics of phrase pairs extracted from word alignments, the weights of the interpolation are optimized through a training procedure which directly aims at minimizing translation errors on a development set. e∗ = arg max e X Pr(e, a |f ) (2) a which represents an alignment from source to target positions. The framework of maximum entropy [9] provides a mean to directly estimate the posterior probability Pr(e, a |f ). It is determined through suitable real value"
2004.iwslt-evaluation.8,takezawa-etal-2002-toward,0,0.115361,"Missing"
2004.iwslt-evaluation.8,P01-1050,0,0.0488447,"ineseEnglish track. 2.1. Log-linear Model As originally proposed by [8], the most likely translation of a foreign source sentence f into English is obtained by searching for the sentence with the highest posterior probability: The ITC-irst SMT system implements an extension of the IBM Model 4 as a log-linear interpolation of statistical models, which estimate probabilities in terms of phrases. The use of phrases rather than words has recently emerged as a mean to cope with the limited context that Model 4 exploits to guess word translation (lexicon model) and word positions (distortion model) [1, 2, 3, 4, 5, 6, 7]. e∗ = arg max Pr(e |f ) e (1) Usually, the hidden variable a is introduced: While parameters of the models are estimated exploiting statistics of phrase pairs extracted from word alignments, the weights of the interpolation are optimized through a training procedure which directly aims at minimizing translation errors on a development set. e∗ = arg max e X Pr(e, a |f ) (2) a which represents an alignment from source to target positions. The framework of maximum entropy [9] provides a mean to directly estimate the posterior probability Pr(e, a |f ). It is determined through suitable real value"
2004.iwslt-evaluation.8,P02-1038,0,0.215643,"These alignment models are usually estimated through the Expectation Maximization algorithm [15], or approximations of it, by exploiting a suitable parallel corpus of translation pairs. For computational reasons, the optimal translation of f is computed with the approximated search criterion: e l Y l X i=0 exploiting eq. (3), eq. (2) can be rewritten as: e∗ p(φi |ei ) p(φ0 | i=1 Unfortunately, a closed-form solution of (4) does not exist. An iterative procedure converging to the solution was proposed by [10]; an improved version is given in [11]. If the following feature functions are chosen [12]: h1 (e, f , a) h2 (e, f , a) l Y 2.3. Phrase-pair Extraction The here used method exploits the so called union alignments between sentence pairs of the training corpus [5]. Given strings f = f1 , . . . , fm and e = e1 , . . . , el , a direct alignment a (from f to e) and an inverted alignment b (from e to f ), the union alignment is defined as: c = {(j, i) : aj = i ∨ bi = j} (15) It is easy to verify that while a and b are many-to-one alignments, c is a many-to-many alignment. Moreover, the union 1 A cept is a target word (including e ) with positive fertility. A not-cept 0 word may only gene"
2004.iwslt-evaluation.8,J93-2003,0,\N,Missing
2004.iwslt-evaluation.8,J96-1002,0,\N,Missing
2005.iwslt-1.11,2004.iwslt-evaluation.8,1,\N,Missing
2005.iwslt-1.11,J93-2003,0,\N,Missing
2005.iwslt-1.11,J96-1002,0,\N,Missing
2005.iwslt-1.11,J00-2004,0,\N,Missing
2005.iwslt-1.11,J03-1005,0,\N,Missing
2005.iwslt-1.11,takezawa-etal-2002-toward,0,\N,Missing
2005.iwslt-1.11,P00-1056,0,\N,Missing
2005.iwslt-1.11,2004.iwslt-papers.2,1,\N,Missing
2006.iwslt-evaluation.7,W06-3110,0,0.0903759,"ments. Briefly, the CLA computes an association score between all possible word pairs within the parallel corpus, and then applies a greedy algorithm to compute the best word-alignment for each sentence pair • question feature, i.e. a binary feature which triggers when text ends with a question mark and starts with one of the typical starting words of question sentences found in training data • frequency of its n-grams (n=1,2,3,4) within the N-best translations • ratio between the target and source length • 2,3,5-grams target LMs • n-gram posterior probabilities within the N-best translations [4] • sentence length posterior probabilities [4] • word/block reordering probabilities (Section 2.2) 2. System Description • ratio of the source length and the number of source phrases (Section 2.3) ITC-irst SMT system [1] implements a log-linear model and features a two-step decoding strategy. In the first pass, a dynamic programming beam search algorithm generates N-best translation hypotheses for each source sentence. In the secThe first six feature functions were used in our system in IWSLT-2005. The two posterior probabilities represent a 53 Table 1: Statistics of training, development and"
2006.iwslt-evaluation.7,2006.iwslt-papers.4,1,0.889045,". Preprocessing tokenization txt-to-digit lower-casing Chi-to-Eng Chinese English x x x x – x Jpn-to-Eng Japanese English x x – – – x refinement of the counts of n-grams in N-best lists we employed for the 2005 campaign. The last two features are new and are presented in the following. Ara-to-Eng Arabic English x x – – – x Ita-to-Eng Italian English x x x x x x hrules (˜ e, f , a) = K 1 X log Pr(ri ) K i=1 (1) where ri is a matching rule, Pr(ri ) its probability and K the number of the reordering patterns matching the given source/target pair. 2.2. Word/Block Reordering In the companion paper [5], the use of rules for modeling word reordering phenomena in phrase-based SMT is proposed. Reordering rules consist of two sides: the left-handside (lhs), which is a word-based pattern, and the right-handside (rhs), which corresponds to a possible reordering of that pattern. Different rules can share the lhs, because the same pattern can be reordered in more than one way. Rules are automatically extracted from word aligned training data and weighted according to observed statistics. Rules can reorder sequences of single words or a pair of blocks of words. A block is a sequence of source words"
2006.iwslt-evaluation.7,takezawa-etal-2002-toward,0,0.137694,"Missing"
2006.iwslt-evaluation.7,P00-1056,0,0.124776,"2 20.04 5.445 21.07 5.465 Ita-to-Eng BLEU NIST 35.24 7.779 35.59 7.859 – – – – 37.47 8.075 tuation, etc. For both the modules we use the disambig tool,1 as suggested in the instructions supplied by the evaluation organizers. The English training data have been employed to train the language models of the two modules. 3.3. Development: Baseline and Improvements The setup of baselines includes the use of phrases up to 8 words and monotonic search. We extracted phrases and estimated the phrase translation models from the intersection of direct and inverse IBM alignments, expanded as suggested in [7]. Improvements were carried out by introducing novelties in an incremental way, monitoring performance on development sets. Upgrades involve: (i) the addition of CLA wordalignments and (ii) of IBM union word-alignments [3], (iii) the execution of non-monotonic search, and (iv) the application of the rescoring module. Non-monotonic search uses constraints on word reordering defined by means of the maximum vacancy number (MVN) and maximum vacancy distance (MVD) parameters. The following setting was used for experiments: 3.1. Preprocessing The most important stage of preprocessing is tokenization"
2006.iwslt-evaluation.7,W05-0835,0,0.122059,"lations is generated for each source sentence by means of a beam-search decoder; in the second pass, N-best lists are rescored and reranked exploiting additional feature functions. Main updates brought to the 2005 system involve novel additional features which are here described. Results on development sets are analyzed and commented. 2.1. Rescoring Models The feature functions and search constraints adopted for decoding are quite standard: phrase and word translation models, 4-gram language model, fertility model, IBM reordering constraints, beam search. A detailed description is provided in [1, 2]. On the other hand, SMT systems often differ a lot in the models employed for rescoring N-best candidates. Here the list of those we apply: 1. Introduction • direct and inverse IBM model 1 and 3 lexicons, over all possible alignments In this paper, we report on the participation of ITC-irst to the evaluation campaign of the International Workshop on Spoken Language Translation 2006. We submitted runs under the Open Data conditions for all the language pairs: Arabic-to-English, Chinese-to-English, Japanese-to-English and Italian-to-English. For each language pair, we performed translations of"
2006.iwslt-evaluation.7,2005.iwslt-1.11,1,\N,Missing
2006.iwslt-evaluation.8,takezawa-etal-2002-toward,0,0.0497024,"Missing"
2006.iwslt-evaluation.8,P03-1020,0,0.10591,"Missing"
2006.iwslt-evaluation.8,koen-2004-pharaoh,0,\N,Missing
2006.iwslt-evaluation.8,J00-2004,0,\N,Missing
2006.iwslt-evaluation.8,2005.iwslt-1.11,1,\N,Missing
2006.iwslt-evaluation.8,2006.iwslt-evaluation.15,1,\N,Missing
2007.iwslt-1.11,P07-2045,1,0.0120612,"dels, and finally the use of multiple phrase-tables. By working on top of a state-of-the art baseline, experiments showed that the above methods accounted for significant BLEU score improvements. 1. Introduction This paper presents work carried out at FBK (formerly ITCirst) to develop speech translation systems for three translation tasks of the IWSLT 2007 Evaluation, namely Chineseto-English (CE), Japanese-to-English (JE), and Italian-toEnglish (IE). All three systems are based on different set-ups of the same translation engine, namely the Moses statistical machine translation (SMT) Toolkit [1].1 The FBK team joined the Moses open source project in 2006 and indeed discontinued the development of its own decoding software [2]. This paper is organized as follows. Section 2 gives a short introduction of the general architecture of the systems, which basically takes advantage of experience gained in the past IWSLT evaluations. Section 3 focuses on the novel aspects that were investigated specifically for IWSLT 2007, namely the management of punctuation and the use of additional language resources. Sections 4 to 6 discuss details related to the development and experimentation of each sin"
2007.iwslt-1.11,W07-0712,1,0.913023,"rrently available release of Moses features a multistack, phrase-based, beam-search decoder able to process a CN as well as plain text. It implements a log-linear translation model including as feature functions: direct and inverse phrase-based and word-based lexicons, multiple wordbased n-gram target language models (LMs), phrase and word penalties, and distance-based (possibly lexicalized) reordering model. Computational efficiency is obtained through prefetching and early recombining the translation alternatives of the source phrases. On-demand loading of lexicon, distortion models and LMs [6] and quantization of LMs [7] allow a big reduction of run-time memory usage. 2 Available from http://www.speech.sri.com/projects/srilm A detailed description of the CN decoder can be found in [8]. 2.3. Rescoring After running Moses, a second decoding step can possibly be applied, which rescores the 5000-best list of translation hypotheses with the following 7 additional features: • direct and inverse IBM Model 1 lexicon scores which should capture lexical co-occurrences in the source and target strings; • weighted sum of n-grams relative frequencies (n from 1 to 4) in N -best list, which favor"
2007.iwslt-1.11,W06-3113,1,0.833384,"Moses features a multistack, phrase-based, beam-search decoder able to process a CN as well as plain text. It implements a log-linear translation model including as feature functions: direct and inverse phrase-based and word-based lexicons, multiple wordbased n-gram target language models (LMs), phrase and word penalties, and distance-based (possibly lexicalized) reordering model. Computational efficiency is obtained through prefetching and early recombining the translation alternatives of the source phrases. On-demand loading of lexicon, distortion models and LMs [6] and quantization of LMs [7] allow a big reduction of run-time memory usage. 2 Available from http://www.speech.sri.com/projects/srilm A detailed description of the CN decoder can be found in [8]. 2.3. Rescoring After running Moses, a second decoding step can possibly be applied, which rescores the 5000-best list of translation hypotheses with the following 7 additional features: • direct and inverse IBM Model 1 lexicon scores which should capture lexical co-occurrences in the source and target strings; • weighted sum of n-grams relative frequencies (n from 1 to 4) in N -best list, which favors hypotheses containing popu"
2007.iwslt-1.11,W06-3110,0,0.0169392,"rescores the 5000-best list of translation hypotheses with the following 7 additional features: • direct and inverse IBM Model 1 lexicon scores which should capture lexical co-occurrences in the source and target strings; • weighted sum of n-grams relative frequencies (n from 1 to 4) in N -best list, which favors hypotheses containing popular n-grams of higher order; • the reciprocal of the rank (log), which prefers high-ranked hypotheses; • counts of hypothesis duplicates (log), which awards translations occurring several times; • n-gram posterior probabilities within the N-best translations [9]; • sentence length posterior probabilities [9]. 2.4. Capitalization In the IE task both human and automatic transcripts do not contain case information. We decided to perform translation with models trained on lower-cased texts, and restore capitalization as postprocessing step, by means of the disambig tool of SRILM toolkit, fed with a n-gram case sensitive target LM. Instead, in the CE and JE tasks this issue is not present because the source languages do not represent capitalization explicitly. Hence, case information is automatically introduced during translation by using case-sensitive m"
2007.iwslt-1.11,2005.iwslt-1.8,0,0.0285146,"Missing"
2007.iwslt-1.11,P03-1010,0,0.02494,"s, also in this case performance well compare with the best official results of the 2006 IWSLT evaluation campaign. 5. Japanese-to-English System FBK also developed a system for the JE classic translation task, that is the translation of read speech in the travel domain. We exploited most of the outcomes of the CE system development, with few adjustments as specified in the following. Statistics of corpora utilized here are given in Table 5. It can be noted the symmetry with respect to the resources used for the CE task, with the LDC parallel corpus replaced by the much smaller Reuters corpus [15], one of the shared resources.4 Performance of the various system configurations tested for the JE task are collected in Table 6. The first row refers to the baseline system (Section 2 and Table 2), that is the 1TM/1-LM system corresponding to the entry +inter. of Table 4. In this task, the attempt of adding the 5-gram web75nc LM did not give any improvement (second row). On the contrary, the use of a second TM trained on the Reuters corpus yielded to the best performing system (third row), which was also tested on the best automatic transcription of the Japanese speech (last row). Even for th"
2007.iwslt-1.11,J03-1002,0,\N,Missing
2008.iwslt-evaluation.4,2008.iwslt-papers.1,1,0.809097,"tistical machine translation (SMT) system relies on the availability of parallel corpus for the estimation of its models. The translation quality is affected by the size of such corpus and its closeness to the task domain. Unfortunately, for many relevant language pairs such parallel data are available only to a small extent, or they are out-of-domain. To circumvent the data bottleneck for this low-resourced language pairs, research on SMT has been recently investigated the use of so-called pivot or bridge languages. An overview of research on pivot translation is given in our companion paper [1]. The assumptions underlying the adoption of a pivot language are simple to state: (i) there is lack of parallel texts between F and E, while (ii) there exists a language G for which (abundant) parallel texts between F and G and between G and E are available. These assumptions are fully matched by the specifications of the Pivot task, because the English parts of the Chinese-English and English- 34 - Spanish corpora do not overlap. We analyzed the pivot translation task from a theoretical point of view providing a mathematically sound formulation of the various approaches presented in the lite"
2008.iwslt-evaluation.4,P07-2045,1,0.0311749,"the problem and experimentally compared them on the Pivot task. Two of them couple Chinese-English and English-Spanish MT systems, the third approach creates a new translation model starting from them, and the fourth approach synthesizes Chinese-Spanish training data translating the target part of the available ChineseEnglish corpus and creates a MT system on these data. These approaches are briefly introduced in the following Section, while a detailed description can be found in [1]. To perform a fair comparison between these approaches we relied on the well-known open source MT system Moses [2] in its standard configuration, and we did not apply any specific enhancement like lexicalized reordering models or rescoring. For each approach specific training of the models were performed on the provided BTEC data only, without using any additional training data. We also submitted runs for the Chinese-English and Chinese-Spanish BTEC tasks and for the Chinese-English Challenge task. This paper is organized as follows. In next Section we introduce the four approaches we have taken into account to address the pivot translation. Section 3 describes the data and the systems we employed to part"
2008.iwslt-evaluation.4,takezawa-etal-2002-toward,0,0.0393909,"training and development, and the employed preprocessing. Then, the baseline system is described, which is used both for the BTEC and Challenge tasks and as building blocks for the Pivot task. Later, the systems specific for the Pivot task are presented with some details. Finally, the performance of the developed systems on a blind test are reported. 3.1. Data Five monolingual corpora are employed for training our systems: namely two for Chinese (C1 and C2), two for English (E1 and E2) and one for Spanish (S1). All corpora are officially provided by the organizers, and are extracted from BTEC [4]; each of them contains 20K sentences. According to the evaluation specification, the parallel corpora CE1 and CS1 are exploited for the CE- and CS-btec tasks, respectively; CE1 for the CE-challenge task; CE2 and ES1 are used to train the systems for the CES-pivot task. We stress that the parallel corpus CE1 are not considered at all for this task. Six development sets are provided consisting of about 500 sentences each and a number of references ranging from 6 to 16 for the CE-btec task. Only one of them is available Proceedings of IWSLT 2008, Hawaii - U.S.A. desde que la nueva administracion"
2008.iwslt-evaluation.4,P03-1021,0,0.0160048,"sent CE-btec CS-btec CE-chal CE-pivot ES-pivot 54,021 28,068 55,743 28,095 19,972 source words dict 439K 8,847 229K 8,284 447K 8,864 217K 8,987 182K 8,385 target words dict 499K 10,765 250K 11,734 507K 11,051 248K 8,951 177K 11,019 3.2. Baseline System The baseline system Direct is built upon the open-source MT toolkit Moses [2]. The decoder features a statistical loglinear model including a phrase-based translation model, a language model, a distortion model and word and phrase penalties. The 8 weights of the log-linear combination are optimized by means of a minimum error training procedure [5]. The phrase-based translation model provides direct and inverted frequency-based and lexical-based probabilities for each phrase pair included in a given phrase table. Phrase pairs are extracted from symmetrized word alignments generated by GIZA++ [6]. This extraction method does not apply in the case of pivoting with constrained alignments (see Section 2.1.2): phrase pairs and their scores are obtained by the product of two existing phrase tables (from source to pivot and from pivot to target). A 5-gram word-based LM is estimated on the target side of the parallel corpora using the improved"
2008.iwslt-evaluation.4,J03-1002,0,0.00295554,"The baseline system Direct is built upon the open-source MT toolkit Moses [2]. The decoder features a statistical loglinear model including a phrase-based translation model, a language model, a distortion model and word and phrase penalties. The 8 weights of the log-linear combination are optimized by means of a minimum error training procedure [5]. The phrase-based translation model provides direct and inverted frequency-based and lexical-based probabilities for each phrase pair included in a given phrase table. Phrase pairs are extracted from symmetrized word alignments generated by GIZA++ [6]. This extraction method does not apply in the case of pivoting with constrained alignments (see Section 2.1.2): phrase pairs and their scores are obtained by the product of two existing phrase tables (from source to pivot and from pivot to target). A 5-gram word-based LM is estimated on the target side of the parallel corpora using the improved Kneser-Ney smoothing [7]. The distortion model is a standard negative-exponential model. The Direct systems have been used in the BTEC and Challenge tasks, and they have been exploited as constituents of the systems employed in the Pivot task. 3.3. Piv"
2008.iwslt-papers.1,C88-2125,0,0.601156,"e interpreted carefully. This paper presents a theoretical formulation of SMT with pivot languages, that embraces several approaches in the literature and a few original methods. Extensive experiments are reported that compare performance of each bridging when using dependent and independent parallel data. Experiments were conducted on the IWSLT 2008 benchmark, namely the translation of traveling domain expressions from Chinese to Spanish via English. 2. Previous Work The use of pivot or bridge languages has been advocated for different purposes, such as rule-based machine translation systems [1], translation lexicon induction [2, 3], word alignment [4, 5, 6], cross language information retrieval [7]. Concerning statistical machine translation, pivot language translation has been investigated for instance by [8] in order to extend an interlingua based speech translation system to a new language. In [9], Catalan-English translation is bridged through Spanish. The authors compared two coupling strategies: cascading of two translation systems versus training of system from parallel texts whose target part has been automatically translated from pivot to target. System cascading was recent"
2008.iwslt-papers.1,N01-1020,0,0.0857246,"presents a theoretical formulation of SMT with pivot languages, that embraces several approaches in the literature and a few original methods. Extensive experiments are reported that compare performance of each bridging when using dependent and independent parallel data. Experiments were conducted on the IWSLT 2008 benchmark, namely the translation of traveling domain expressions from Chinese to Spanish via English. 2. Previous Work The use of pivot or bridge languages has been advocated for different purposes, such as rule-based machine translation systems [1], translation lexicon induction [2, 3], word alignment [4, 5, 6], cross language information retrieval [7]. Concerning statistical machine translation, pivot language translation has been investigated for instance by [8] in order to extend an interlingua based speech translation system to a new language. In [9], Catalan-English translation is bridged through Spanish. The authors compared two coupling strategies: cascading of two translation systems versus training of system from parallel texts whose target part has been automatically translated from pivot to target. System cascading was recently investigated in [10], too. In [11]"
2008.iwslt-papers.1,W02-2026,0,0.0369528,"presents a theoretical formulation of SMT with pivot languages, that embraces several approaches in the literature and a few original methods. Extensive experiments are reported that compare performance of each bridging when using dependent and independent parallel data. Experiments were conducted on the IWSLT 2008 benchmark, namely the translation of traveling domain expressions from Chinese to Spanish via English. 2. Previous Work The use of pivot or bridge languages has been advocated for different purposes, such as rule-based machine translation systems [1], translation lexicon induction [2, 3], word alignment [4, 5, 6], cross language information retrieval [7]. Concerning statistical machine translation, pivot language translation has been investigated for instance by [8] in order to extend an interlingua based speech translation system to a new language. In [9], Catalan-English translation is bridged through Spanish. The authors compared two coupling strategies: cascading of two translation systems versus training of system from parallel texts whose target part has been automatically translated from pivot to target. System cascading was recently investigated in [10], too. In [11]"
2008.iwslt-papers.1,C00-1015,0,0.0328714,"formulation of SMT with pivot languages, that embraces several approaches in the literature and a few original methods. Extensive experiments are reported that compare performance of each bridging when using dependent and independent parallel data. Experiments were conducted on the IWSLT 2008 benchmark, namely the translation of traveling domain expressions from Chinese to Spanish via English. 2. Previous Work The use of pivot or bridge languages has been advocated for different purposes, such as rule-based machine translation systems [1], translation lexicon induction [2, 3], word alignment [4, 5, 6], cross language information retrieval [7]. Concerning statistical machine translation, pivot language translation has been investigated for instance by [8] in order to extend an interlingua based speech translation system to a new language. In [9], Catalan-English translation is bridged through Spanish. The authors compared two coupling strategies: cascading of two translation systems versus training of system from parallel texts whose target part has been automatically translated from pivot to target. System cascading was recently investigated in [10], too. In [11] word alignment systems are"
2008.iwslt-papers.1,P06-2112,0,0.0435046,"formulation of SMT with pivot languages, that embraces several approaches in the literature and a few original methods. Extensive experiments are reported that compare performance of each bridging when using dependent and independent parallel data. Experiments were conducted on the IWSLT 2008 benchmark, namely the translation of traveling domain expressions from Chinese to Spanish via English. 2. Previous Work The use of pivot or bridge languages has been advocated for different purposes, such as rule-based machine translation systems [1], translation lexicon induction [2, 3], word alignment [4, 5, 6], cross language information retrieval [7]. Concerning statistical machine translation, pivot language translation has been investigated for instance by [8] in order to extend an interlingua based speech translation system to a new language. In [9], Catalan-English translation is bridged through Spanish. The authors compared two coupling strategies: cascading of two translation systems versus training of system from parallel texts whose target part has been automatically translated from pivot to target. System cascading was recently investigated in [10], too. In [11] word alignment systems are"
2008.iwslt-papers.1,N07-1061,0,0.413231,"on induction [2, 3], word alignment [4, 5, 6], cross language information retrieval [7]. Concerning statistical machine translation, pivot language translation has been investigated for instance by [8] in order to extend an interlingua based speech translation system to a new language. In [9], Catalan-English translation is bridged through Spanish. The authors compared two coupling strategies: cascading of two translation systems versus training of system from parallel texts whose target part has been automatically translated from pivot to target. System cascading was recently investigated in [10], too. In [11] word alignment systems are combined from multiple bridge languages by multiplying posterior probability matrices. This technique requires the existence of parallel Proceedings of IWSLT 2008, Hawaii - U.S.A. data for several languages, like the proceedings of United Nations or European Parliament. An approach based on phrase table multiplication is discussed in [10, 12]. Scores of the new phrase table are computed by combining corresponding translation probabilities in the source-pivot and pivot-target phrase-tables. Finally, in [13] a similar approach is described, but for the s"
2008.iwslt-papers.1,D07-1005,0,0.0350209,"2, 3], word alignment [4, 5, 6], cross language information retrieval [7]. Concerning statistical machine translation, pivot language translation has been investigated for instance by [8] in order to extend an interlingua based speech translation system to a new language. In [9], Catalan-English translation is bridged through Spanish. The authors compared two coupling strategies: cascading of two translation systems versus training of system from parallel texts whose target part has been automatically translated from pivot to target. System cascading was recently investigated in [10], too. In [11] word alignment systems are combined from multiple bridge languages by multiplying posterior probability matrices. This technique requires the existence of parallel Proceedings of IWSLT 2008, Hawaii - U.S.A. data for several languages, like the proceedings of United Nations or European Parliament. An approach based on phrase table multiplication is discussed in [10, 12]. Scores of the new phrase table are computed by combining corresponding translation probabilities in the source-pivot and pivot-target phrase-tables. Finally, in [13] a similar approach is described, but for the sake of improvi"
2008.iwslt-papers.1,P07-1108,0,0.41977,"ng strategies: cascading of two translation systems versus training of system from parallel texts whose target part has been automatically translated from pivot to target. System cascading was recently investigated in [10], too. In [11] word alignment systems are combined from multiple bridge languages by multiplying posterior probability matrices. This technique requires the existence of parallel Proceedings of IWSLT 2008, Hawaii - U.S.A. data for several languages, like the proceedings of United Nations or European Parliament. An approach based on phrase table multiplication is discussed in [10, 12]. Scores of the new phrase table are computed by combining corresponding translation probabilities in the source-pivot and pivot-target phrase-tables. Finally, in [13] a similar approach is described, but for the sake of improving translation probabilities through triangulation with other languages. 3. SMT through pivot languages SMT with bridge languages is concerned about how to optimally perform translation from F to E, by taking advantage of the available language resources. We can device two general approaches to apply bridge languages in SMT, namely bridging at translation time or bridgi"
2008.iwslt-papers.1,P07-1092,0,0.510381,"System cascading was recently investigated in [10], too. In [11] word alignment systems are combined from multiple bridge languages by multiplying posterior probability matrices. This technique requires the existence of parallel Proceedings of IWSLT 2008, Hawaii - U.S.A. data for several languages, like the proceedings of United Nations or European Parliament. An approach based on phrase table multiplication is discussed in [10, 12]. Scores of the new phrase table are computed by combining corresponding translation probabilities in the source-pivot and pivot-target phrase-tables. Finally, in [13] a similar approach is described, but for the sake of improving translation probabilities through triangulation with other languages. 3. SMT through pivot languages SMT with bridge languages is concerned about how to optimally perform translation from F to E, by taking advantage of the available language resources. We can device two general approaches to apply bridge languages in SMT, namely bridging at translation time or bridging at training time, which we briefly overview now. 3.1. Bridging at Translation Time Under this framework, we try to integrate or couple two levels of translation wit"
2008.iwslt-papers.1,J93-2003,0,0.0338674,"-ordering for each considered translation direction. Figure 1 shows the two level alignments for a simple example involving translations from Chinese to Italian, through English. Horizontal segments show that the English string is segmented differently when it is generated from Chinese than when it is translated into Italian. - 144 - Another way to exploit parallel training corpora F-G and G-E is to use them to develop and train a translation system from F to E. 3.2.1. Bridging Alignment Models We will focus here on possible extension of the standard training criterion of IBM alignment models [15], which assumes a parallel corpus (F, E) = {(fi , ei )} and looks for Proceedings of IWSLT 2008, Hawaii - U.S.A. desde que la nueva administracion tomo posesion de su cargo este año desde que la nueva administracion tomo posesion de su cargo este año since the new administration took office this year this year new administration took office since the Pivot Translation direction Target Source Figure 1: Phrase-based translation from Chinese to Spanish, through English, with independent alignments (left) and constrained alignments (right). parameters maximizing θF∗ E = argmax Y θF E PθF E (fi |ei"
2008.iwslt-papers.1,takezawa-etal-2002-toward,0,0.0108447,"are reinforced during training as well as phrase-pairs using words of the most probable translations. This approach is indeed more sound than just taking the list of n-best, as experimental results will confirm in the following sections. 4. Task description The approaches introduced in the previous section were evaluated on a benchmark provided by the 2008 International Workshop on Spoken Language Translation1 . One of the proposed tasks consists in translating from Chinese to Spanish by pivoting through English. Training and evaluation data are from the Basic Travel Expression Corpus (BTEC) [16], a collection of parallel translations in the traveling domain. Five monolingual corpora were available: two for Chinese (C1 and C2), two for English (E1 and E2) and one for Spanish (S1). C1, E1, and S1 are also aligned at the sentence level, hence they provide a trilingual parallel corpus; C2 and E2 are aligned as well and form a bilingual parallel corpus. The official benchmark for the pivot task of IWSLT consists only in the two non overlapping bilingual parallel corpora CE2 and ES1, while the bilingual parallel corpus CS1 is for contrastive experiments. The benchmark also includes a devel"
2008.iwslt-papers.1,P07-2045,1,0.0137344,"Missing"
2008.iwslt-papers.1,P03-1021,0,0.0374955,"Missing"
2008.iwslt-papers.1,J03-1002,0,0.00862119,"ms developed with the Moses open-source toolkit [17]. The employed decoder features a statistical log-linear model including a phrase-based translation model, a language model, a distortion model, and word and phrase penalties. The resulting eight weights of the log-linear combination are optimized by means of a minimum error training procedure [18]. The phrase-based translation model provides direct and inverted frequency-based and lexical-based probabilities for each phrase pair included in a given phrase table. Phrase pairs are extracted from symmetrized word alignments generated by GIZA++ [19]. This extraction method does not apply in the case of pivoting with constrained alignments (see Section 3.1.2) as the phrase table is obtained by taking the product of two existing phrase tables. A 5-gram word-based LM is estimated on the target side of the parallel corpora using the improved Kneser-Ney smoothing [20]. The distortion model is a standard negativeexponential model. Table 2 shows the BLEU scores achieved by the baseline systems (Direct) on the dev and test sets. It is worth noticing that the system trained on CE1 outperforms the one trained on CE2. The reason is that both dev an"
2009.iwslt-evaluation.5,N06-2013,0,0.0238153,"e-Processing for Morphologically Rich Languages Indeed linguistic preprocessing plays a fundamental role in any NLP application involving morphologically rich languages, such as Arabic and Turkish. This is particularly true for SMT into English where differences in word granularity between languages reflects on much higher data sparseness on the source side and on the difficulty to properly model word-level alignments. We approached these problems through morphological segmentation of the source languages, referring partly to the work of [1] on an EnglishTurkish task, and partly to the one of [2] on an ArabicEnglish task. Secondly, as this was shown to have a positive effect on some Arabic-English SMT systems of previous IWSLT editions [3, 4], we developed two simple languagespecific techniques of lexical approximation, which consists in replacing the OOVs of the test set by words of the training that are morphologically close to them. 1. Introduction FBK submitted runs at the IWSLT 2009 Evaluation for the Arabic-English and Turkish-English BTEC tasks, and for the Challenge Task involving Chinese and English languages in both directions. This paper reports on efforts we made in the de"
2009.iwslt-evaluation.5,2009.iwslt-papers.1,1,0.811638,"eaning absence of possessive suffixes is also removed; • copula is split off; • person suffixes are split off from finite verb forms and from copula. The following example shows an analyzed Turkish word before and after segmentation. The number of tokens increases from 1 to 5 as the word is split into noun, possessive, instrumental case, copula and verbal person: 2 More precisely: score = match × 20 − diff × 2 − diff × 5, 1 2 where match, diff1 and diff2 are respectively the numbers of shared contiguous tags, different tags in the OOV word, different tags in the replacer candidate. 1 Refer to [8] for a more detailed and linguistically motivated description. - 38 - Proceedings of IWSLT 2009, Tokyo - Japan where pi ’s are target LMs built on clusters which the training data are split in. With the help of Figure 1, the basic adaptation procedure is described in the following. Let us assume that the parallel training data have been partitioned into a set of M bilingual clusters, according to some criterion. On each cluster, language specific LMs are estimated, which are then organized into two language specific mixture models. All operations described so far are performed off-line. Now le"
2009.iwslt-evaluation.5,P05-1071,0,0.015153,"o language specific mixture models. All operations described so far are performed off-line. Now let us consider a source text or sentence to be translated. Before translation, the input is used to estimate optimal weights of the source language mixture through Expectation-Maximization. The resulting weights are then transferred to the target language mixture, which is finally used as LM feature function by the SMT system. 2.2.1. Morphological Segmentation Several state-of-the-art tools are available to perform morphological segmentation of Arabic text. For the evaluation we have compared MADA [9] and AMIRA [10], two softwares that differ both on their decision strategy and on the segmentation scheme they apply to the words. While the first is a morphological disambiguator based on linguistic features produced by the Buckwalter analyzer [11], the second is a much lighter-weight SVM classifier based on a -5/+5 character context. As for the segmentation schemes (see Table 2) MADA (scheme “D2”) only splits proclitics – namely conjunctions (w+ ‘and’, f+ ‘then’), prepositions (b+ ‘by’, k+ ‘as’, l+ ‘to’) and the future tense (s+) – whereas AMIRA also separates enclitics, i.e. object and poss"
2009.iwslt-evaluation.5,N04-4038,0,0.0110197,"cific mixture models. All operations described so far are performed off-line. Now let us consider a source text or sentence to be translated. Before translation, the input is used to estimate optimal weights of the source language mixture through Expectation-Maximization. The resulting weights are then transferred to the target language mixture, which is finally used as LM feature function by the SMT system. 2.2.1. Morphological Segmentation Several state-of-the-art tools are available to perform morphological segmentation of Arabic text. For the evaluation we have compared MADA [9] and AMIRA [10], two softwares that differ both on their decision strategy and on the segmentation scheme they apply to the words. While the first is a morphological disambiguator based on linguistic features produced by the Buckwalter analyzer [11], the second is a much lighter-weight SVM classifier based on a -5/+5 character context. As for the segmentation schemes (see Table 2) MADA (scheme “D2”) only splits proclitics – namely conjunctions (w+ ‘and’, f+ ‘then’), prepositions (b+ ‘by’, k+ ‘as’, l+ ‘to’) and the future tense (s+) – whereas AMIRA also separates enclitics, i.e. object and possessive pronouns"
2009.iwslt-evaluation.5,P02-1038,0,0.0119197,"ng the possible data sparseness issue that can affect the sentence specific weight estimation. 4.2. Turkish-English System 4.2.1. Data For training our Turkish-English system we exclusively used the provided BTEC training corpus. Parameters were tuned on IWSLT09’s devset1 using the gold reference translation only. Evaluation during development was performed on devset2. 4. Evaluation results 4.1. Baseline System Given a string f in the source language, the goal of statistical machine translation [12] is to select the most probable string e in the target language. By assuming a log-linear model [13, 14], the optimal translation can be searched for with the criterion: e∗ = arg max max e a R X 4.2.2. Baseline Setup The baseline preprocessing consists in simple tokenization (IWSLT09’s released script) and lowercasing of the source side data. Due to the severe mismatch in word order between the languages, we set the distortion limit (DL) to 10. Moses option -drop-unknown was active in all submitted runs. λr hr (e, f , a), 4.2.3. Results r=1 where a represents a word- or phrase-based alignment between f and e, and hr (e, f , a) r = 1, . . . , R are feature functions, designed to model different a"
2009.iwslt-evaluation.5,P07-2045,1,0.0126036,"t of separating the training corpus into several subsets yields wi pi (e) i=1 3 AMIRA splits the same proclitics as MADA except for the future tense. 4 Available - 39 - from http://glaros.dtc.umn.edu/gkhome/views/cluto Proceedings of IWSLT 2009, Tokyo - Japan SRC TRAINING PARALLEL TEXTS SRC SRC TGT CLSTR 1 LM ESTIMATION CLSTR 2 TGT CLSTR M TGT LM 1 LM 1 LM 2 LM 2 LM M LM M CLUSTERING OPTIMIZATION of SRC LMs INTERPOLATION SRC wi OFF−LINE ON−LINE INTERPOLATION of TGT LMs TEXT SMT TRANSLATION Figure 1: Basic procedure for LM adaptation. Our systems are built upon the open-source MT toolkit Moses [15]. The decoder features a statistical log-linear model including a phrase-based translation model, a language model, a distortion model and word and phrase penalties. The weights λr of the log-linear combination are optimized by means of a minimum error training (MERT) procedure [16]. The phrase-based translation model provides direct and inverted frequency-based and lexical-based probabilities for each phrase pair included in a given phrase table. Phrase pairs are extracted from symmetrized word alignments generated by GIZA++ [17]. better results, since the EM procedure is allowed complete fre"
2009.iwslt-evaluation.5,P03-1021,0,0.0149284,"EXTS SRC SRC TGT CLSTR 1 LM ESTIMATION CLSTR 2 TGT CLSTR M TGT LM 1 LM 1 LM 2 LM 2 LM M LM M CLUSTERING OPTIMIZATION of SRC LMs INTERPOLATION SRC wi OFF−LINE ON−LINE INTERPOLATION of TGT LMs TEXT SMT TRANSLATION Figure 1: Basic procedure for LM adaptation. Our systems are built upon the open-source MT toolkit Moses [15]. The decoder features a statistical log-linear model including a phrase-based translation model, a language model, a distortion model and word and phrase penalties. The weights λr of the log-linear combination are optimized by means of a minimum error training (MERT) procedure [16]. The phrase-based translation model provides direct and inverted frequency-based and lexical-based probabilities for each phrase pair included in a given phrase table. Phrase pairs are extracted from symmetrized word alignments generated by GIZA++ [17]. better results, since the EM procedure is allowed complete freedom in assigning the LM weights. However, weights computed in such a manner may be less reliable, since the estimation is performed on few data (one single sentence). 3.3.3. Two-step weight estimation This approach merges the previous two in the attempt of keeping their advantages"
2009.iwslt-evaluation.5,J93-2003,0,\N,Missing
2009.iwslt-evaluation.5,J96-1002,0,\N,Missing
2009.iwslt-evaluation.5,J03-1002,0,\N,Missing
2009.iwslt-evaluation.5,W07-0704,0,\N,Missing
2009.iwslt-evaluation.5,2007.iwslt-1.27,0,\N,Missing
2009.iwslt-evaluation.5,2008.iwslt-evaluation.10,0,\N,Missing
2009.iwslt-papers.5,C04-1059,0,\N,Missing
2009.iwslt-papers.5,J93-2003,0,\N,Missing
2009.iwslt-papers.5,J96-1002,0,\N,Missing
2009.iwslt-papers.5,P07-2045,1,\N,Missing
2009.iwslt-papers.5,W04-3225,0,\N,Missing
2009.iwslt-papers.5,D07-1036,0,\N,Missing
2009.iwslt-papers.5,W07-0733,0,\N,Missing
2009.iwslt-papers.5,N07-1064,0,\N,Missing
2009.iwslt-papers.5,P02-1038,0,\N,Missing
2009.iwslt-papers.5,J03-1002,0,\N,Missing
2009.iwslt-papers.5,W07-0722,0,\N,Missing
2009.iwslt-papers.5,2005.iwslt-1.8,0,\N,Missing
2009.iwslt-papers.5,P03-1021,0,\N,Missing
2010.iwslt-papers.3,W04-3208,0,0.167575,"Missing"
2010.iwslt-papers.3,J05-4003,0,0.17025,"al approaches have recently been proposed in the literature to extract parallel excerpts. Most of the techniques, if not all, share the stages of splitting documents into sentences and of pairing sentences across documents. Methods significantly differ in the successive filtering steps, that can be clustered into two main groups: procedures aiming at deciding if paired sentences are mutual translations or at extracting parallel sub-sentential fragments. In the following, we briefly describe a few works tightly related to our approach, which also report significant performance improvements. In [2] words in the source documents are translated through a bilingual lexicon; all possible sentence pairs of the two documents are passed first through a word-overlap filter and then classified as parallel or not by a maximum entropy classifier trained on (a small amount of) parallel sentences. In [3] a SMT system, trained on a small amount of parallel data, is used to directly translate the source side of the documents. Then, instead of the maximum entropy classifier, WER and TER scores are computed at the sentence level by comparing the translations with the target side; the amount of filtered"
2010.iwslt-papers.3,E09-1003,0,0.197294,"clustered into two main groups: procedures aiming at deciding if paired sentences are mutual translations or at extracting parallel sub-sentential fragments. In the following, we briefly describe a few works tightly related to our approach, which also report significant performance improvements. In [2] words in the source documents are translated through a bilingual lexicon; all possible sentence pairs of the two documents are passed first through a word-overlap filter and then classified as parallel or not by a maximum entropy classifier trained on (a small amount of) parallel sentences. In [3] a SMT system, trained on a small amount of parallel data, is used to directly translate the source side of the documents. Then, instead of the maximum entropy classifier, WER and TER scores are computed at the sentence level by comparing the translations with the target side; the amount of filtered pairs can be tuned by varying the acceptance threshold. The approach in [4] resembles [2] up to the definition of the set of candidate sentence pairs. Instead of deciding whether the two sentences are mutual translations, now they search for parallel fragments using an approach inspired by signal p"
2010.iwslt-papers.3,P06-1011,0,0.49035,"n; all possible sentence pairs of the two documents are passed first through a word-overlap filter and then classified as parallel or not by a maximum entropy classifier trained on (a small amount of) parallel sentences. In [3] a SMT system, trained on a small amount of parallel data, is used to directly translate the source side of the documents. Then, instead of the maximum entropy classifier, WER and TER scores are computed at the sentence level by comparing the translations with the target side; the amount of filtered pairs can be tuned by varying the acceptance threshold. The approach in [4] resembles [2] up to the definition of the set of candidate sentence pairs. Instead of deciding whether the two sentences are mutual translations, now they search for parallel fragments using an approach inspired by signal processing. Using a set of parameters derived from Log-Likelihood-Ratio statistics, each word is annotated with values in [−1, +1] indicating the likelihood that the word has some translations in the other sentence by performing a greedy alignment. This stream of values is then treated as a signal and passed through an averaging filter. Spans that have only positive signal v"
2010.iwslt-papers.3,2007.mtsummit-papers.50,0,0.391793,"ameters derived from Log-Likelihood-Ratio statistics, each word is annotated with values in [−1, +1] indicating the likelihood that the word has some translations in the other sentence by performing a greedy alignment. This stream of values is then treated as a signal and passed through an averaging filter. Spans that have only positive signal values and are longer than a threshold (3 words) are considered more likely to have a translation on the other side. The same process is repeated on the other translation direction, and the resulting fragment pair is assumed to be parallel. Quirk et al. [5] try to overcome some of the limitation of the approach described in [4] in the way parallel fragments are identified. In particular, they propose two generative models for generating noisy target sentences from the source sentences. One model is employed to align words in candidate sentence pairs; fragments are then extracted from alignments by applying simple heuristics. Another model tries to directly generate fragments; in the process, three generation options are competing: source-only fragment, targetonly fragment, or joint source-target fragment. The rational behind this model is that “"
2010.iwslt-papers.3,W04-3225,0,0.225101,"Missing"
2010.iwslt-papers.3,W07-0733,0,0.108535,"Missing"
2010.iwslt-papers.3,2009.mtsummit-posters.17,0,0.0274716,"Missing"
2010.iwslt-papers.3,D07-1103,0,0.0280528,"eam search, histogram pruning...) are omitted, but implemented. Some aspects of the algorithm deserve to be highlighted and commented. First of all, translation probabilities are not used at all. This allows the exploitation of any phrase pair repository, even lacking of probabilities (like multiwordnets), and prevents hypotheses built on low probability phrase pairs from cutting by the beam search. In our specific case, the SMT phrase table used as repository is likely to be noisy. In order to have the repository as clean as possible, the phrase table is pruned via the algorithm described in [10]. Secondly, the use of a phrase-based translation model allows us to cover phrases instead of single words, differently from what is done in similar approaches (e.g. [5] but also [4]). This way the job done in SMT training for discovering reliable phrase pairs is exploited: if such pairs occur in the bilingual input text, they represent a solid anchor for the fragment extraction. Finally, it is worth to noticing that the algorithm permits partial alignment: portions of either source or target texts can remain unaligned. This is achieved by (i) adding dummy translation options (i.e. a target ph"
2010.iwslt-papers.3,2005.mtsummit-papers.11,0,0.0449093,"ble 1: Statistics of the De-En/Ar-En translation/reordering models: size of training texts (running words), dictionary size, and number of phrase pairs in the baselines. from a corpus already cleaned at the sentence level. 5.1. Data Experiments were conducted on two different tasks and language pairs. In the first task, German news are translated into English (De-En) according to the setup established in the Workshop on Statistical Machine Translation of the ACL 2010.2 Parallel training data consist of a small in-domain corpus (News Commentary - NC) and a larger out-of-domain corpus (Europarl [11], version 5 - EP). News-test2008 has been used for development, while news-test2009 (TST09) and news-test2010 (TST10) for testing purposes. As comparable data, we used a set of 25,517 bilingual documents downloaded from the multilingual and pan-European television news channel EuroNews (EN),3 for a total of 4.3 million and 4.7 million German and English words, respectively. The second task involves the translation of news from Arabic into English (Ar-En) in the framework defined by the 2009 NIST evaluation campaign.4 In this case, for development and testing purposes the portions containing ne"
2010.iwslt-papers.3,P07-2045,1,0.010614,"and of both 2008 and 2009 evaluation sets have been employed. We used only one of the parallel resources allowed for the constrained training condition, namely the ISI Arabic-English Automatically Extracted Parallel Text (LDC2007T08). It consists of sentence pairs extracted automatically from the Arabic and English monolingual Gigaword corpora by means of the method described in [2]. For each sentence pair, a confidence score (between 0.5 and 1.0) is provided, which is indicative of its degree of parallelism. 5.2. Baselines The baseline systems are built upon the open-source MT toolkit Moses [12].5 The translation and the lexicalized reordering models have been trained on NC for De-En, and on the subset of ISI corpus containing sentences with confidence score larger than 0.993 (ISI-0.993), for Ar-En. Phrase tables are pruned according to [10]. In all experiments, 6gram LMs have been employed, smoothed with the improved Kneser-Ney technique [13] and computed with the IRSTLM 2 www.statmt.org/wmt10/ 3 www.euronews.net 4 www.itl.nist.gov/iad/mig/tests/mt/2009/ 5 www.statmt.org/moses/ 231 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3"
2010.iwslt-papers.3,P96-1041,0,0.144766,"Missing"
2011.eamt-1.34,E09-1003,0,0.0205869,"entences across documents. Methods significantly differ in the successive filtering steps, and can be clustered into two main groups: procedures aiming at deciding if paired sentences are mutual translations or at detecting and extracting parallel sub-sentential fragments. In (Munteanu and Marcu, 2005) words in the source documents are translated through a bilingual lexicon; all possible sentence pairs of the two documents are passed first through a word-overlap filter and then classified as parallel or not by a maximum entropy classifier trained on (a small amount of) parallel sentences. In (Abdul-Rauf and Schwenk, 2009) a SMT system, trained on a small amount of parallel data, is used to directly translate the source side of the documents. Then, instead of the maximum entropy classifier, WER and TER scores are computed at the sentence level by comparing the translations with the target side; the amount of filtered pairs can be tuned by varying the acceptance threshold. The approach in (Munteanu and Marcu, 2006) resembles (Munteanu and Marcu, 2005) up to the definition of the set of candidate sentence pairs. Instead of deciding whether the two sentences are mutual translations, now they search for parallel fr"
2011.eamt-1.34,C10-2010,0,0.0308503,"the estimation of SMT models. type web parallel sent. web parallel frag. total total clean web monol. sent. |W | ar it 1.4M 1.4M 1.8M 1.6M 3.0M 3.0M 2.8M 1.06G trained models LM TM RM LM Table 5: Training data for ArIt models. English-to-Italian (EnIt) Unlike in the case of the Arabic–Italian pair, many Web sites publish news in English and Italian which are (almost) parallel. We have been able to collect so far sentences for a total of about 24M words per side. Document pairs have been split into sentences on strong punctuation and sentence alignment has been performed by means of Gargantua (Braune and Fraser, 2010). On the contrary, from sites where documents are at most comparable, fragments (2.8M words) have been mined via the procedures described in Sections 4.1 and 4.2. In addition, Europarl8 and JRC-Acquis9 parallel corpora (70M words) have been employed. The LM of the ArIt system has been re-used. Table 6 provides some statistics on texts employed for the estimation of these specific SMT models. type web parallel sent. web parallel frag. total total clean ep5+acquis clean web monol. sent. |W | en it 24.2M 24.1M 2.7M 2.8M 27.0M 23.3M 23.5M 70.0M 70.0M 1.06G trained models LM TM RM TM RM LM Devsets"
2011.eamt-1.34,2010.iwslt-papers.3,1,0.845686,"te sentence pairs; fragments are then extracted from alignments by applying simple heuristics. Another model tries to directly generate fragments; in the process, three generation options are competing: source-only fragment, target-only fragment, or joint source-target fragment. The rational behind this model is that “the probability of generating source and target fragments jointly should be more likely than generating them independently if and only if they are parallel”. The latter model is definitely more complex than the former one, although their impact on SMT performance is similar. In (Cettolo et al., 2010), a method is defined for extracting fragments which was new in some aspects and that is summarized in Section 4.2. 3 Evaluation Sets Evaluation and comparison of MT systems are still open issues to which much attention and many efforts have been directed in the last years. One of the few certainties is the use of publicly available evaluation sets. Nowadays, several MT evaluation campaigns are held every year which release evaluation sets. Unfortunately, no evaluation set built on news texts has been made available so far for Arabic–Italian translation. To fill this gap, we decided to add two"
2011.eamt-1.34,P07-2045,1,0.0102695,"Missing"
2011.eamt-1.34,J05-4003,0,0.0790055,"t al., 2010). Once document pairs are available, the problem is the detection of actual parallel text inside them. Several approaches have recently been proposed in the literature to extract such parallel excerpts. Most of the techniques, if not all, share the stages of splitting documents into sentences and of pairing sentences across documents. Methods significantly differ in the successive filtering steps, and can be clustered into two main groups: procedures aiming at deciding if paired sentences are mutual translations or at detecting and extracting parallel sub-sentential fragments. In (Munteanu and Marcu, 2005) words in the source documents are translated through a bilingual lexicon; all possible sentence pairs of the two documents are passed first through a word-overlap filter and then classified as parallel or not by a maximum entropy classifier trained on (a small amount of) parallel sentences. In (Abdul-Rauf and Schwenk, 2009) a SMT system, trained on a small amount of parallel data, is used to directly translate the source side of the documents. Then, instead of the maximum entropy classifier, WER and TER scores are computed at the sentence level by comparing the translations with the target si"
2011.eamt-1.34,P06-1011,0,0.0293232,"rs of the two documents are passed first through a word-overlap filter and then classified as parallel or not by a maximum entropy classifier trained on (a small amount of) parallel sentences. In (Abdul-Rauf and Schwenk, 2009) a SMT system, trained on a small amount of parallel data, is used to directly translate the source side of the documents. Then, instead of the maximum entropy classifier, WER and TER scores are computed at the sentence level by comparing the translations with the target side; the amount of filtered pairs can be tuned by varying the acceptance threshold. The approach in (Munteanu and Marcu, 2006) resembles (Munteanu and Marcu, 2005) up to the definition of the set of candidate sentence pairs. Instead of deciding whether the two sentences are mutual translations, now they search for parallel fragments using an approach inspired by signal processing. Using a set of parameters derived from Log-Likelihood-Ratio statistics, each word is annotated with values in [−1, +1] indicating the likelihood that the word has some translations in the other sentence by performing a greedy alignment. This stream of values is then treated as a signal and passed through an averaging filter. Spans that have"
2011.eamt-1.34,2007.mtsummit-papers.50,0,0.0176098,"meters derived from Log-Likelihood-Ratio statistics, each word is annotated with values in [−1, +1] indicating the likelihood that the word has some translations in the other sentence by performing a greedy alignment. This stream of values is then treated as a signal and passed through an averaging filter. Spans that have only positive signal values and are longer than a threshold (3 words) are considered more likely to have a translation on the other side. The same process is repeated on the other translation direction, and the resulting fragment pair is assumed to be parallel. Quirk et al. (Quirk et al., 2007) try to overcome some of the limitations of the approach described in (Munteanu and Marcu, 2006) in the way paralset #sentences eval08-NW eval09-NW 813 586 Arabic |W | |V | 21.9k 7.8k 17.5k 6.4k English |W | |V | 29.1k 4.9k 23.1k 3.9k French |W | |V | 33.2k 4.9k 26.7k 4.4k Italian |W | |V | 32.0k 5.7k 25.1k 4.8k Table 1: Statistics of the dev/test sets for the pivoting task. Texts are tokenized. For the English side, 4 manual translations (references) are available: average values are reported. |W |stands for “running words”, |V |for “vocabulary size”. lel fragments are identified. In particul"
2011.eamt-1.34,C10-1124,0,0.0120521,"ng the same content in different languages. Although these documents are not parallel, it often happens that some portions of them are mutual translations to some extent. In the last years, much effort has been devoted by the research community to the effective exploitation of such data for SMT. The first problem to face is the alignment of multilingual documents reporting the same news. This problem has been rarely investigated systematically, as the usual pairing strategies aim to keep low the missing rate, that is to reward the recall. One of the most valuable methods is that presented in (Uszkoreit et al., 2010). There, all non-English documents are translated into English through a initial, even low-quality, translation system. Documents are then paired in two steps: the first generates a set of candidate pairs of documents sharing at least a certain number of rare features. This step is made linear in the number of input documents by setting a threshold defining such rare features. In the second step, a computationally more expensive and fine grained comparison is performed for deciding whether such document pairs are comparable or not. Pairing multilingual documents is also the goal of (Steinberge"
2011.eamt-1.34,P09-1018,0,0.145031,"el; on the target side, specific LMs were estimated as well; on the contrary, a single reordering model was built on such texts. Concerning the exploitation of monolingual data, again specific LMs were built on each of the 6 provided sets (English Gigaword 3rd Edition); also in this case, a single model has been defined by linearly interpolating the total of 11 LMs. Table 7 provides some statistics on texts actually employed for the estimation of SMT models. |W | ar/en 0.6M 0.9M 6.2M 24.3M 115.2M 142.2M 3.6G 5.2 The pivoting technique employed here is the composition, also called transfer in (Wu and Wang, 2009), consisting in the translation of the source language into the pivot language, and of this into the target language. Table 8 shows the performance obtained by composing the proper direct systems presented above, together with that by composing the two corresponding Google Translate systems. Table 6: Training data for EnIt models. corpus of-the-art SMT systems is possible (English-toItalian and Arabic-to-English directions); otherwise (Arabic-to-Italian) the need arises for alternative approaches to achieve acceptable quality. www.statmt.org/europarl wt.jrc.it/lt/Acquis/ 254 ArEn ⊗ EnIt ArEn-g"
2011.eamt-1.34,2010.iwslt-evaluation.1,1,\N,Missing
2011.mtsummit-papers.1,W08-0304,0,0.0462071,"rload, as multiple translations of the input are needed. On the other side, the average system well competes with the system combination, without any computational additional cost. 2 Related Work Since its ﬁrst appearance, the MERT procedure (Och, 2003) has been recognized as unstable. The author analyzed the problem and proposed a way for smoothing the objective function to be optimized. Thereafter, many works tried to handle and reduce instability of the MERT procedure, following different approaches including regularization/smoothing of the objective error surface (e.g. Zens et al. (2007), Cer et al. (2008)), improvement in the optimization algorithms – Simplex, Powell, Coordinate Descent, etc. – (e.g. Cettolo and Federico (2004), Cer et al. (2008)), usage of online learning techniques – Perceptron, MIRA – (e.g. Collins (2002), Chiang et al. (2008), Haddow et al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from origi"
2011.mtsummit-papers.1,2004.iwslt-papers.2,1,0.704303,"he system combination, without any computational additional cost. 2 Related Work Since its ﬁrst appearance, the MERT procedure (Och, 2003) has been recognized as unstable. The author analyzed the problem and proposed a way for smoothing the objective function to be optimized. Thereafter, many works tried to handle and reduce instability of the MERT procedure, following different approaches including regularization/smoothing of the objective error surface (e.g. Zens et al. (2007), Cer et al. (2008)), improvement in the optimization algorithms – Simplex, Powell, Coordinate Descent, etc. – (e.g. Cettolo and Federico (2004), Cer et al. (2008)), usage of online learning techniques – Perceptron, MIRA – (e.g. Collins (2002), Chiang et al. (2008), Haddow et al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e"
2011.mtsummit-papers.1,D08-1024,0,0.0531715,"Och, 2003) has been recognized as unstable. The author analyzed the problem and proposed a way for smoothing the objective function to be optimized. Thereafter, many works tried to handle and reduce instability of the MERT procedure, following different approaches including regularization/smoothing of the objective error surface (e.g. Zens et al. (2007), Cer et al. (2008)), improvement in the optimization algorithms – Simplex, Powell, Coordinate Descent, etc. – (e.g. Cettolo and Federico (2004), Cer et al. (2008)), usage of online learning techniques – Perceptron, MIRA – (e.g. Collins (2002), Chiang et al. (2008), Haddow et al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavi"
2011.mtsummit-papers.1,P11-2031,0,0.108123,"ion of models. Interpolation weights are typically computed by means of iterative procedures which aim at maximizing a given scoring function. Unfortunately, such a function is deﬁnitely non-convex; hence, only local optima can be reached. Moreover, it has been observed that the commonly used optimization procedure, the N-best minimum error rate training (simply MERT hereafter) (Och, 2003), is quite unstable. In the last years, many efforts have been devoted for making the procedure or its results more reliable. Recently, a deep investigation of the optimizer instability has been presented by Clark et al. (2011). In that work, experimental evidence of the instability problems affecting optimizers is shown; then, statistical tools 32 are selected for making possible both a quantitative evaluation of the optimization process of single systems and a fair comparison of two systems, somehow independent from the optimization process. The work ends with some recommendations: for instance, run optimization at least three times; use additional held-out test sets for manual analysis of translations in order to select the best optimization (better: “more reliable”) among those available. By taking that investig"
2011.mtsummit-papers.1,W02-1001,0,0.0979044,"MERT procedure (Och, 2003) has been recognized as unstable. The author analyzed the problem and proposed a way for smoothing the objective function to be optimized. Thereafter, many works tried to handle and reduce instability of the MERT procedure, following different approaches including regularization/smoothing of the objective error surface (e.g. Zens et al. (2007), Cer et al. (2008)), improvement in the optimization algorithms – Simplex, Powell, Coordinate Descent, etc. – (e.g. Cettolo and Federico (2004), Cer et al. (2008)), usage of online learning techniques – Perceptron, MIRA – (e.g. Collins (2002), Chiang et al. (2008), Haddow et al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (200"
2011.mtsummit-papers.1,P08-2010,0,0.0192258,"ct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008), He et al. (2008), Rosti et al. (2008)). These works focus on the combination of multiple machine translation systems based on different models and paradigms. Investigation similar to ours has been done by Macherey and Och (2007), and Duh and Kirchhoff (2008). Macherey and Och (2007) analyzed the combination of multiple outputs obtained by using one decoding engine with different models, trained on different conditions. Instead, we employ the same engine and the same models; the variable part of the combined systems is the set of interpolation weights. BoostedMERT (Duh and Kirchhoff, 2008) uses one single set of models, with different sets of interpolation weights. Each log-linear model is treated as a “weak learner”, and boosting is used to combine such weak learners for N-best re-ranking. On the contrary, we either produce a new log-linear model"
2011.mtsummit-papers.1,W09-0439,0,0.0317607,"ive function to be optimized. Thereafter, many works tried to handle and reduce instability of the MERT procedure, following different approaches including regularization/smoothing of the objective error surface (e.g. Zens et al. (2007), Cer et al. (2008)), improvement in the optimization algorithms – Simplex, Powell, Coordinate Descent, etc. – (e.g. Cettolo and Federico (2004), Cer et al. (2008)), usage of online learning techniques – Perceptron, MIRA – (e.g. Collins (2002), Chiang et al. (2008), Haddow et al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008), He et al. (2008), Rosti"
2011.mtsummit-papers.1,W11-2130,0,0.0127143,"cognized as unstable. The author analyzed the problem and proposed a way for smoothing the objective function to be optimized. Thereafter, many works tried to handle and reduce instability of the MERT procedure, following different approaches including regularization/smoothing of the objective error surface (e.g. Zens et al. (2007), Cer et al. (2008)), improvement in the optimization algorithms – Simplex, Powell, Coordinate Descent, etc. – (e.g. Cettolo and Federico (2004), Cer et al. (2008)), usage of online learning techniques – Perceptron, MIRA – (e.g. Collins (2002), Chiang et al. (2008), Haddow et al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et a"
2011.mtsummit-papers.1,D08-1011,0,0.015922,", Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008), He et al. (2008), Rosti et al. (2008)). These works focus on the combination of multiple machine translation systems based on different models and paradigms. Investigation similar to ours has been done by Macherey and Och (2007), and Duh and Kirchhoff (2008). Macherey and Och (2007) analyzed the combination of multiple outputs obtained by using one decoding engine with different models, trained on different conditions. Instead, we employ the same engine and the same models; the variable part of the combined systems is the set of interpolation weights. BoostedMERT (Duh and Kirchhoff, 2008) uses one single set"
2011.mtsummit-papers.1,W10-1744,0,0.0182485,"lso to high values of the test set score function. The centroid should then fall inside that region both for the development and for the test set, increasing the chance of stabilizing the performance on the test set. It is worth noticing that this approach requires additional computation effort only in tuning stage, as multiple optimization runs have to be performed. System combination (sysComb) System combination is the second solution we propose for smoothing the outputs of various optimizer samples. For combining the outputs of the available systems, we used the software1 developed at CMU (Heaﬁeld and Lavie, 2010). It works at the word level and smartly allows “the synthesis of new word orderings”. The scheme includes several stages. Hypotheses are aligned in pairs using the publicly available METEOR (Banerjee and Lavie, 2005) aligner. Then, on these alignments a search space is deﬁned, which is explored by a beam search decoding. Hypotheses are scored using a linear interpolation of features, including the LM score, the hypothesis length and the average n-gram length found in the LM. Interpolation weights are tuned using Z-MERT (Zaidan, 2009). 1 Available at http://kheaﬁeld.com/code/mt/ 34 This approa"
2011.mtsummit-papers.1,2008.amta-srw.3,0,0.0156974,"x, Powell, Coordinate Descent, etc. – (e.g. Cettolo and Federico (2004), Cer et al. (2008)), usage of online learning techniques – Perceptron, MIRA – (e.g. Collins (2002), Chiang et al. (2008), Haddow et al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008), He et al. (2008), Rosti et al. (2008)). These works focus on the combination of multiple machine translation systems based on different models and paradigms. Investigation similar to ours has been done by Macherey and Och (2007), and Duh and Kirchhoff (2008). Macherey and Och (2007) analyzed the combination of multiple outputs obtained"
2011.mtsummit-papers.1,P05-3026,0,0.0182981,"iang et al. (2008), Haddow et al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008), He et al. (2008), Rosti et al. (2008)). These works focus on the combination of multiple machine translation systems based on different models and paradigms. Investigation similar to ours has been done by Macherey and Och (2007), and Duh and Kirchhoff (2008). Macherey and Och (2007) analyzed the combination of multiple outputs obtained by using one decoding engine with different models, trained on different conditions. Instead, we employ the same engine and the same models; the variable part of the combine"
2011.mtsummit-papers.1,P07-2045,1,0.0123236,"se alignments a search space is deﬁned, which is explored by a beam search decoding. Hypotheses are scored using a linear interpolation of features, including the LM score, the hypothesis length and the average n-gram length found in the LM. Interpolation weights are tuned using Z-MERT (Zaidan, 2009). 1 Available at http://kheaﬁeld.com/code/mt/ 34 This approach requires the translation of the test set by each optimizer sample to be combined, besides the computational cost of the combination of translations itself. 4 Experiments The SMT systems are built upon the open-source MT toolkit Moses2 (Koehn et al., 2007). The translation and the lexicalized reordering models have been trained on parallel data. The LMs have been estimated via the IRSTLM toolkit (Federico et al., 2008) either on the monolingual data, when available, or on the target side of the parallel data; they are smoothed through the improved Kneser-Ney technique (Chen and Goodman, 1999). The weights of the log-linear interpolation model have been optimized on the development sets by means of the standard MERT procedure provided within the Moses toolkit: different realizations of tuned systems (optimizer samples) have been obtained by mult"
2011.mtsummit-papers.1,D07-1105,0,0.0173459,"evel combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008), He et al. (2008), Rosti et al. (2008)). These works focus on the combination of multiple machine translation systems based on different models and paradigms. Investigation similar to ours has been done by Macherey and Och (2007), and Duh and Kirchhoff (2008). Macherey and Och (2007) analyzed the combination of multiple outputs obtained by using one decoding engine with different models, trained on different conditions. Instead, we employ the same engine and the same models; the variable part of the combined systems is the set of interpolation weights. BoostedMERT (Duh and Kirchhoff, 2008) uses one single set of models, with different sets of interpolation weights. Each log-linear model is treated as a “weak learner”, and boosting is used to combine such weak learners for N-best re-ranking. On the contrary, we either"
2011.mtsummit-papers.1,E06-1005,0,0.0215326,"t al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008), He et al. (2008), Rosti et al. (2008)). These works focus on the combination of multiple machine translation systems based on different models and paradigms. Investigation similar to ours has been done by Macherey and Och (2007), and Duh and Kirchhoff (2008). Macherey and Och (2007) analyzed the combination of multiple outputs obtained by using one decoding engine with different models, trained on different conditions. Instead, we employ the same engine and the same models; the variable part of the combined systems is the set of"
2011.mtsummit-papers.1,C08-1074,0,0.0488716,"for smoothing the objective function to be optimized. Thereafter, many works tried to handle and reduce instability of the MERT procedure, following different approaches including regularization/smoothing of the objective error surface (e.g. Zens et al. (2007), Cer et al. (2008)), improvement in the optimization algorithms – Simplex, Powell, Coordinate Descent, etc. – (e.g. Cettolo and Federico (2004), Cer et al. (2008)), usage of online learning techniques – Perceptron, MIRA – (e.g. Collins (2002), Chiang et al. (2008), Haddow et al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008),"
2011.mtsummit-papers.1,P03-1021,0,0.396757,"ffective in smoothing instability, but also that the average system well competes with the more expensive system combination. 1 Introduction Statistical machine translation (SMT) systems feature a log-linear interpolation of models. Interpolation weights are typically computed by means of iterative procedures which aim at maximizing a given scoring function. Unfortunately, such a function is deﬁnitely non-convex; hence, only local optima can be reached. Moreover, it has been observed that the commonly used optimization procedure, the N-best minimum error rate training (simply MERT hereafter) (Och, 2003), is quite unstable. In the last years, many efforts have been devoted for making the procedure or its results more reliable. Recently, a deep investigation of the optimizer instability has been presented by Clark et al. (2011). In that work, experimental evidence of the instability problems affecting optimizers is shown; then, statistical tools 32 are selected for making possible both a quantitative evaluation of the optimization process of single systems and a fair comparison of two systems, somehow independent from the optimization process. The work ends with some recommendations: for insta"
2011.mtsummit-papers.1,N07-1029,0,0.020768,"hoice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008), He et al. (2008), Rosti et al. (2008)). These works focus on the combination of multiple machine translation systems based on different models and paradigms. Investigation similar to ours has been done by Macherey and Och (2007), and Duh and Kirchhoff (2008). Macherey and Och (2007) analyzed the combination of multiple outputs obtained by using one decoding engine with different models, trained on different conditions. Instead, we employ the same engine and the same models; the variable part of the combined systems is the set of interpolation weigh"
2011.mtsummit-papers.1,P07-1040,0,0.0185003,"hoice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008), He et al. (2008), Rosti et al. (2008)). These works focus on the combination of multiple machine translation systems based on different models and paradigms. Investigation similar to ours has been done by Macherey and Och (2007), and Duh and Kirchhoff (2008). Macherey and Och (2007) analyzed the combination of multiple outputs obtained by using one decoding engine with different models, trained on different conditions. Instead, we employ the same engine and the same models; the variable part of the combined systems is the set of interpolation weigh"
2011.mtsummit-papers.1,W08-0329,0,0.0192641,"(2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct selection from original outputs of single SMT systems (Sim et al. (2007), Hildebrand and Vogel (2008)), or phrase- or word-level combination, i.e. the synthesis of a (possibly) new output joining portions of the original outputs (Bangalore (2001), Jayaraman and Lavie (2005), Matusov et al. (2006), Rosti et al. (2007a), Rosti et al. (2007b), Ayan et al. (2008), He et al. (2008), Rosti et al. (2008)). These works focus on the combination of multiple machine translation systems based on different models and paradigms. Investigation similar to ours has been done by Macherey and Och (2007), and Duh and Kirchhoff (2008). Macherey and Och (2007) analyzed the combination of multiple outputs obtained by using one decoding engine with different models, trained on different conditions. Instead, we employ the same engine and the same models; the variable part of the combined systems is the set of interpolation weights. BoostedMERT (Duh and Kirchhoff, 2008) uses one single set of models, with diffe"
2011.mtsummit-papers.1,2009.iwslt-evaluation.12,0,0.0351409,"Missing"
2011.mtsummit-papers.1,D07-1055,0,0.0210922,"nt computational overload, as multiple translations of the input are needed. On the other side, the average system well competes with the system combination, without any computational additional cost. 2 Related Work Since its ﬁrst appearance, the MERT procedure (Och, 2003) has been recognized as unstable. The author analyzed the problem and proposed a way for smoothing the objective function to be optimized. Thereafter, many works tried to handle and reduce instability of the MERT procedure, following different approaches including regularization/smoothing of the objective error surface (e.g. Zens et al. (2007), Cer et al. (2008)), improvement in the optimization algorithms – Simplex, Powell, Coordinate Descent, etc. – (e.g. Cettolo and Federico (2004), Cer et al. (2008)), usage of online learning techniques – Perceptron, MIRA – (e.g. Collins (2002), Chiang et al. (2008), Haddow et al. (2011)), better choice of the random starting points (e.g. Moore and Quirk (2008), Foster and Kuhn (2009)). Also system combination has been already applied to SMT. One research line takes n-best translations of single systems, and produces the ﬁnal output by means of either sentence-level combination, i.e. a direct s"
2013.iwslt-evaluation.16,2012.eamt-1.60,1,0.8976,"neous speech and heterogeneous topics and styles. The 1 http://www.eu-bridge.eu task is open domain, with a wide range of heavily dissimilar subjects and jargons across talks. IWSLT subdivides the task and separately evaluates automatic transcription of talks from audio to text, speech translation of talks from audio, and text translation of talks as three different tracks [3, 4]. The training data is constrained to the corpora specified by the organizers. The supplied list of corpora comprises a large amount of publicly available monolingual and parallel training data, though, including WIT3 [5], Europarl [6], MultiUN [7], the English and French Gigaword corpora as provided by the Linguistic Data Consortium [8], and the News Crawl, 109 and News Commentary corpora from the WMT shared task training data [9]. For the two “official” language pairs [1] for translation at IWSLT 2013, English→French and German→English, these resources allow for building of systems with state-of-the-art performance by participants. The EU-BRIDGE project is funded by the European Union under the Seventh Framework Programme (FP7) [10] and brings together several project partners who have each previously been v"
2013.iwslt-evaluation.16,2005.mtsummit-papers.11,1,0.078384,"nd heterogeneous topics and styles. The 1 http://www.eu-bridge.eu task is open domain, with a wide range of heavily dissimilar subjects and jargons across talks. IWSLT subdivides the task and separately evaluates automatic transcription of talks from audio to text, speech translation of talks from audio, and text translation of talks as three different tracks [3, 4]. The training data is constrained to the corpora specified by the organizers. The supplied list of corpora comprises a large amount of publicly available monolingual and parallel training data, though, including WIT3 [5], Europarl [6], MultiUN [7], the English and French Gigaword corpora as provided by the Linguistic Data Consortium [8], and the News Crawl, 109 and News Commentary corpora from the WMT shared task training data [9]. For the two “official” language pairs [1] for translation at IWSLT 2013, English→French and German→English, these resources allow for building of systems with state-of-the-art performance by participants. The EU-BRIDGE project is funded by the European Union under the Seventh Framework Programme (FP7) [10] and brings together several project partners who have each previously been very successful"
2013.iwslt-evaluation.16,eisele-chen-2010-multiun,0,0.0452925,"ous topics and styles. The 1 http://www.eu-bridge.eu task is open domain, with a wide range of heavily dissimilar subjects and jargons across talks. IWSLT subdivides the task and separately evaluates automatic transcription of talks from audio to text, speech translation of talks from audio, and text translation of talks as three different tracks [3, 4]. The training data is constrained to the corpora specified by the organizers. The supplied list of corpora comprises a large amount of publicly available monolingual and parallel training data, though, including WIT3 [5], Europarl [6], MultiUN [7], the English and French Gigaword corpora as provided by the Linguistic Data Consortium [8], and the News Crawl, 109 and News Commentary corpora from the WMT shared task training data [9]. For the two “official” language pairs [1] for translation at IWSLT 2013, English→French and German→English, these resources allow for building of systems with state-of-the-art performance by participants. The EU-BRIDGE project is funded by the European Union under the Seventh Framework Programme (FP7) [10] and brings together several project partners who have each previously been very successful in contribut"
2013.iwslt-evaluation.16,E06-1005,1,0.921596,"e-scale evaluation campaigns like IWSLT and WMT in recent years, thereby demonstrating their ability to continuously enhance their systems and promoting progress in machine translation. Machine translation research within EU-BRIDGE has a strong focus on translation of spoken language. The IWSLT TED talks task constitutes an interesting framework for empirical testing of some of the systems for spoken language translation which are developed as part of the project. The work described here is an attempt to attain translation quality beyond strong single system performance via system combination [11]. Similar cooperative approaches based on system combination have proven to be valuable for machine translation in other projects, e.g. in the Quaero programme [12, 13]. Within EU-BRIDGE, we built combined system setups for text translation of talks from English to French as well as from German to English. We found that the combined translation engines of RWTH, UEDIN, KIT, and FBK systems are very effective. In the rest of the paper we will give some insight into the technology behind the combined engines which have been used to produce the joint EU-BRIDGE submission to the IWSLT 2013 MT track"
2013.iwslt-evaluation.16,P02-1040,0,0.0892795,"-BRIDGE submission to the IWSLT 2013 MT track. The remainder of the paper is structured as follows: We first describe the individual English→French and German→English systems by RWTH Aachen University (Section 2), the University of Edinburgh (Section 3), Karlsruhe Institute of Technology (Section 4), and Fondazione Bruno Kessler (Section 5), respectively. We then present the techniques for machine translation system combination which have been employed to obtain consensus translations from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SR"
2013.iwslt-evaluation.16,2006.amta-papers.25,0,0.15922,"sion to the IWSLT 2013 MT track. The remainder of the paper is structured as follows: We first describe the individual English→French and German→English systems by RWTH Aachen University (Section 2), the University of Edinburgh (Section 3), Karlsruhe Institute of Technology (Section 4), and Fondazione Bruno Kessler (Section 5), respectively. We then present the techniques for machine translation system combination which have been employed to obtain consensus translations from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SRILM toolkit [2"
2013.iwslt-evaluation.16,W10-1738,1,0.880309,"iques for machine translation system combination which have been employed to obtain consensus translations from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SRILM toolkit [21]. All RWTH systems include the standard set of models provided by Jane. For English→French, the final setups for RWTH scss and RWTH hiero differ in the amount of training data and in the choice of models. For the English→French hierarchical setup the bilingual data was limited to the in-domain WIT3 data, News Commentary, Europarl, and Common Crawl corpora. The word alignment w"
2013.iwslt-evaluation.16,popovic-ney-2006-pos,1,0.929216,"ll available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RWTH applied a more sophisticated discriminative phrase training method. Similar to [31], a gradient-based method is used to optimize a maximum expected B LEU objective, for which we define B LEU on the sentence level with smoothed 3-gram"
2013.iwslt-evaluation.16,P03-1021,0,0.129032,"ns from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SRILM toolkit [21]. All RWTH systems include the standard set of models provided by Jane. For English→French, the final setups for RWTH scss and RWTH hiero differ in the amount of training data and in the choice of models. For the English→French hierarchical setup the bilingual data was limited to the in-domain WIT3 data, News Commentary, Europarl, and Common Crawl corpora. The word alignment was created with fast align [22]. A language model was trained on the target side of all avai"
2013.iwslt-evaluation.16,P12-1031,0,0.10415,"For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RWTH applied a more sophisticated discriminative phrase training method. Similar to [31], a gradient-based method is used to optimize a maximum expected B LEU objective, for which we define B LEU on the sentence level with smoothed 3-gram and 4gram precisions. RWTH performed discriminative training on the WIT3 portion of the training data. The German→English phrase-based system was furthermore improved by a lexicalized reordering model and 7-gram word class language model. RWTH finally applied domain adaptation by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discri"
2013.iwslt-evaluation.16,P10-2041,0,0.0805135,"setups for RWTH scss and RWTH hiero differ in the amount of training data and in the choice of models. For the English→French hierarchical setup the bilingual data was limited to the in-domain WIT3 data, News Commentary, Europarl, and Common Crawl corpora. The word alignment was created with fast align [22]. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 41 of the French Gigaword Second Edition corpus. The monolingual data selection for using only parts of the corpora is based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a se"
2013.iwslt-evaluation.16,D08-1089,0,0.117877,"orpus. The monolingual data selection for using only parts of the corpora is based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of"
2013.iwslt-evaluation.16,P07-2045,1,0.0125349,"EU on the sentence level with smoothed 3-gram and 4gram precisions. RWTH performed discriminative training on the WIT3 portion of the training data. The German→English phrase-based system was furthermore improved by a lexicalized reordering model and 7-gram word class language model. RWTH finally applied domain adaptation by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a"
2013.iwslt-evaluation.16,W13-2212,1,0.868834,"m and 4gram precisions. RWTH performed discriminative training on the WIT3 portion of the training data. The German→English phrase-based system was furthermore improved by a lexicalized reordering model and 7-gram word class language model. RWTH finally applied domain adaptation by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation"
2013.iwslt-evaluation.16,W11-2123,0,0.0545914,"tion by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequen"
2013.iwslt-evaluation.16,P11-1105,1,0.916011,"d on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev"
2013.iwslt-evaluation.16,D09-1022,1,0.892821,"n for using only parts of the corpora is based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resu"
2013.iwslt-evaluation.16,2012.iwslt-papers.17,1,0.860668,"em [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate resu"
2013.iwslt-evaluation.16,D13-1138,1,0.815085,"based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running w"
2013.iwslt-evaluation.16,N04-1022,0,0.487773,"atistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate results. While UEDIN’s main submission also includes sequence models and operation sequence m"
2013.iwslt-evaluation.16,W12-2702,0,0.051709,"cribed in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RW"
2013.iwslt-evaluation.16,P07-1019,0,0.222647,"ranslation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate results. While UEDIN’s main submission also includes sequence models and operation sequence models over Brown wo"
2013.iwslt-evaluation.16,E03-1076,1,0.900834,"data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RWTH applied a more sophisticated discriminative phrase training method. Similar to [31], a gradient-based method is used to optimize a maximum expected B LEU objective"
2013.iwslt-evaluation.16,N12-1047,0,0.148125,"penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate results. While UEDIN’s main submission also includes sequence models and operation sequence models over Brown word clusters, these setups were not finished in time for the contribution to the EU-BRIDGE system combination. language models trained on WIT3 , Europarl, News Commentary, 109 , and Common Crawl by minimizing the perplexity on the development data. For the class-based language model, KIT utilized in-domain WIT3 data with 4grams and 50 clusters. In addition, a 9-gram POS-based language model derived fr"
2013.iwslt-evaluation.16,2011.iwslt-evaluation.9,1,0.925869,"ge model derived from LIA POS tags [55] on all monolingual data was applied. KIT optimized the log-linear combination of all these models on the provided development data using Minimum Error Rate Training [20]. 4. Karlsruhe Institute of Technology The KIT translations have been generated by an in-house phrase-based translations system [41]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, K"
2013.iwslt-evaluation.16,2007.tmi-papers.21,0,0.422618,"e-based translations system [41]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED"
2013.iwslt-evaluation.16,W09-0435,1,0.918776,"Commentary, WIT3 , Common Crawl corpora for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection"
2013.iwslt-evaluation.16,W13-0805,1,0.889592,"ra for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase tabl"
2013.iwslt-evaluation.16,W08-1006,0,0.169177,"SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a"
2013.iwslt-evaluation.16,2005.iwslt-1.8,1,0.888473,"t. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context feat"
2013.iwslt-evaluation.16,W08-0303,1,0.796238,"word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to bet"
2013.iwslt-evaluation.16,2012.amta-papers.19,1,0.890564,"and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-doma"
2013.iwslt-evaluation.16,W11-2124,1,0.885306,"ated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-"
2013.iwslt-evaluation.16,W13-2264,1,0.887808,"se trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-entropy difference [23]. Furthermore, K"
2013.iwslt-evaluation.16,2012.iwslt-papers.3,1,0.886049,"criminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-entropy difference [23]. Furthermore, KIT used an RBM-based language model [53] trained on the WIT3 corpus. Finally, KIT also used a classbased language model, trained on the WIT3 corpus using the MKCLS [54] algorithm to cluster the words. For the English→French translation task, KIT linearly combined the 5. Fondazione Bruno Kessler The FBK component of the system combination corresponds to the “contrastive 1” system of the official FBK submission. The FBK system was built upon a standard phrasebased system using the Moses toolkit [32], and exploited the huge amount of parallel English→French and monolingual French training data, provided by the organizers. It featured a"
2013.iwslt-evaluation.16,E99-1010,0,0.0594124,"ed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-entropy difference [23]. Furthermore, KIT used an RBM-based language model [53] trained on the WIT3 corpus. Finally, KIT also used a classbased language model, trained on the WIT3 corpus using the MKCLS [54] algorithm to cluster the words. For the English→French translation task, KIT linearly combined the 5. Fondazione Bruno Kessler The FBK component of the system combination corresponds to the “contrastive 1” system of the official FBK submission. The FBK system was built upon a standard phrasebased system using the Moses toolkit [32], and exploited the huge amount of parallel English→French and monolingual French training data, provided by the organizers. It featured a statistical log-linear model including a filled-up phrase translation model [56] and lexicalized reordering models (RMs), two F"
2013.iwslt-evaluation.16,2011.iwslt-evaluation.18,1,0.928081,"el, trained on the WIT3 corpus using the MKCLS [54] algorithm to cluster the words. For the English→French translation task, KIT linearly combined the 5. Fondazione Bruno Kessler The FBK component of the system combination corresponds to the “contrastive 1” system of the official FBK submission. The FBK system was built upon a standard phrasebased system using the Moses toolkit [32], and exploited the huge amount of parallel English→French and monolingual French training data, provided by the organizers. It featured a statistical log-linear model including a filled-up phrase translation model [56] and lexicalized reordering models (RMs), two French language models (LMs), as well as distortion, word, and phrase penalties. In order to focus it on TED specific domain and genre, and to reduce the size of the system, data selection by means of IRSTLM toolkit [57] was performed on the whole parallel English→French corpus, using the WIT3 training data as in-domain data. Different amount of data are selected from each available corpora but the WIT3 data, for a total of 66 M English running words. Two TMs and two RMs were trained on WIT3 and selected data, separately, and combined using the fil"
2013.iwslt-evaluation.16,W05-0909,0,0.0593782,"es which are outputs of different translation engines. The consensus translations can be better in terms of translation quality than any of the individual hypotheses. To combine the engines of the project partners for the EU-BRIDGE joint setups, we applied a system combination implementation that has been developed at RWTH Aachen University. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. [60]. This approach includes an enhanced alignment and reordering framework. Alignments between the system outputs are learned using METEOR [61]. A confusion network is then built using one of the hypotheses as “primary” hypothesis. We do not make a hard decision on which of the hypotheses to use for that, but instead combine all possible confusion networks into a single lattice. Majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models, e.g. a special n-gram language model which is learned on the input hypotheses. Scaling factors of the models are optimized using the Minimum Error Rate Training algorithm. The translation with the best total score within the"
2013.iwslt-evaluation.16,W12-3140,1,\N,Missing
2013.iwslt-evaluation.16,J03-1002,1,\N,Missing
2013.iwslt-evaluation.16,C12-3061,1,\N,Missing
2013.iwslt-evaluation.16,federico-etal-2012-iwslt,1,\N,Missing
2013.iwslt-evaluation.16,2011.iwslt-evaluation.1,1,\N,Missing
2013.iwslt-evaluation.16,W13-2223,1,\N,Missing
2013.iwslt-evaluation.16,N13-1073,0,\N,Missing
2013.iwslt-evaluation.20,P07-2045,1,0.0131661,"models, and language models from multiple corpora, respectively. In Section 3, we describe several experiments in the English-French translation task. In Section 4, we describe our first efforts at translated to and from English and Persian, a language pair with few parallel resources available. We introduce our efforts to collect and preprocess Perian corpora to improve the quality of Persian translation and show significant improvements over the state of the art. In Section 5 we summarize our findings. For all language pairs, we set up a standard phrase-based system using the Moses toolkit [2]. We construct a statistical 1 http://www.ted.com/talks 2 University of Trento ICT Doctoral School Via Sommarive, 5 38123 Trento, TN, Italy log-linear models including domain-adapted phrase translation and hierarchical reordering models [3, 4, 5], one or more target language models (LM), as well as distortion, word, and phrase penalties. 2. Domain adaptation techniques In this section, we summarize several well-known techniques for domain adaptation we applied to build high-performance models for our SMT submissions. 2.1. Data selection The idea of data selection is to find the subset of sente"
2013.iwslt-evaluation.20,N04-4026,0,0.0482934,"n, a language pair with few parallel resources available. We introduce our efforts to collect and preprocess Perian corpora to improve the quality of Persian translation and show significant improvements over the state of the art. In Section 5 we summarize our findings. For all language pairs, we set up a standard phrase-based system using the Moses toolkit [2]. We construct a statistical 1 http://www.ted.com/talks 2 University of Trento ICT Doctoral School Via Sommarive, 5 38123 Trento, TN, Italy log-linear models including domain-adapted phrase translation and hierarchical reordering models [3, 4, 5], one or more target language models (LM), as well as distortion, word, and phrase penalties. 2. Domain adaptation techniques In this section, we summarize several well-known techniques for domain adaptation we applied to build high-performance models for our SMT submissions. 2.1. Data selection The idea of data selection is to find the subset of sentences within an out-of-domain corpus that better fits with a given in-domain corpus. To this purpose, we follow the procedure described in [6], which adapts the cross-entropy difference scoring technique introduced by [7] toward bitext data select"
2013.iwslt-evaluation.20,2005.iwslt-1.8,0,0.0549463,"n, a language pair with few parallel resources available. We introduce our efforts to collect and preprocess Perian corpora to improve the quality of Persian translation and show significant improvements over the state of the art. In Section 5 we summarize our findings. For all language pairs, we set up a standard phrase-based system using the Moses toolkit [2]. We construct a statistical 1 http://www.ted.com/talks 2 University of Trento ICT Doctoral School Via Sommarive, 5 38123 Trento, TN, Italy log-linear models including domain-adapted phrase translation and hierarchical reordering models [3, 4, 5], one or more target language models (LM), as well as distortion, word, and phrase penalties. 2. Domain adaptation techniques In this section, we summarize several well-known techniques for domain adaptation we applied to build high-performance models for our SMT submissions. 2.1. Data selection The idea of data selection is to find the subset of sentences within an out-of-domain corpus that better fits with a given in-domain corpus. To this purpose, we follow the procedure described in [6], which adapts the cross-entropy difference scoring technique introduced by [7] toward bitext data select"
2013.iwslt-evaluation.20,D08-1089,0,0.0582814,"n, a language pair with few parallel resources available. We introduce our efforts to collect and preprocess Perian corpora to improve the quality of Persian translation and show significant improvements over the state of the art. In Section 5 we summarize our findings. For all language pairs, we set up a standard phrase-based system using the Moses toolkit [2]. We construct a statistical 1 http://www.ted.com/talks 2 University of Trento ICT Doctoral School Via Sommarive, 5 38123 Trento, TN, Italy log-linear models including domain-adapted phrase translation and hierarchical reordering models [3, 4, 5], one or more target language models (LM), as well as distortion, word, and phrase penalties. 2. Domain adaptation techniques In this section, we summarize several well-known techniques for domain adaptation we applied to build high-performance models for our SMT submissions. 2.1. Data selection The idea of data selection is to find the subset of sentences within an out-of-domain corpus that better fits with a given in-domain corpus. To this purpose, we follow the procedure described in [6], which adapts the cross-entropy difference scoring technique introduced by [7] toward bitext data select"
2013.iwslt-evaluation.20,P10-2041,0,0.060814,"l reordering models [3, 4, 5], one or more target language models (LM), as well as distortion, word, and phrase penalties. 2. Domain adaptation techniques In this section, we summarize several well-known techniques for domain adaptation we applied to build high-performance models for our SMT submissions. 2.1. Data selection The idea of data selection is to find the subset of sentences within an out-of-domain corpus that better fits with a given in-domain corpus. To this purpose, we follow the procedure described in [6], which adapts the cross-entropy difference scoring technique introduced by [7] toward bitext data selection. First, all sentence pairs of the out-of-domain corpus are associated with a source- and target-side scores, each computed as the basic technique proposes for the corresponding monolingual scenarios, using the in-domain (TED) data as a seed and LMs of order 3. Then, the sentences are sorted according to the sum of these two scores. Finally, the optimal split between useful and useless sentences is found by minimizing the source-side perplexity of a development set on growing percentages of the sorted corpus. In our experiments, dev2010 and tst2010 are concatenated"
2013.iwslt-evaluation.20,2011.iwslt-evaluation.18,1,0.880119,"onolingual scenarios, using the in-domain (TED) data as a seed and LMs of order 3. Then, the sentences are sorted according to the sum of these two scores. Finally, the optimal split between useful and useless sentences is found by minimizing the source-side perplexity of a development set on growing percentages of the sorted corpus. In our experiments, dev2010 and tst2010 are concatenated and used as the filtering development set. 2.2. Translation model combination Three methods are applied in our submissions to combine the TM built on the available parallel training corpora: namely, fill-up [8, 9], back-off, and interpolation. 2.2.1. Fill-up and Back-off In the fill-up approach, out-of-domain phrase pairs that do not appear in an in-domain (TED) phrase table are added, along with their scores – effectively filling the in-domain table with additional phrase translation options. The fill-up process is performed in a cascaded order, first filling in missing phrases from the corpora that are closest in domain to TED. Moreover, out-of-domain phrase pairs with more than four source tokens are pruned. Following [8, 9] the fill-up approach adds k-1 provenance binary features to weight the impo"
2013.iwslt-evaluation.20,E12-1055,0,0.0256716,"an four source tokens are pruned. Following [8, 9] the fill-up approach adds k-1 provenance binary features to weight the importance of out-of-domain data, where k is the number of phrase tables to combine. A similar back-off approach performs the fill-up technique, but does not add any provenance binary features. 2.2.2. Linear interpolation A common approach for building multi-model is through the linear interpolation of component models. Various approaches have been suggested for computing the coefficients of the interpolated model, the most recent being perplexity minimization described in [10] where the perplexity of each component translation model is minimized on the parallel development set. However, the mixing coefficients can be separately computed by several other techniques. In this paper, instead of calculating translation model perplexity we calculate language model perplexity on target side development set. After minimizing perplexity we get the interpolation weights which we then use as mixing coefficients for component translation models. 2.3. Reordering model combination All techniques available for combining the TMs can be applied straightfowardly to combine the RMs."
2013.iwslt-evaluation.20,2012.eamt-1.60,1,0.817797,"based system using the Moses toolkit [2], exploiting a huge amount of English-French bitexts and monolingual French training data. Each system features a statistical loglinear model including one phrase translation model [9] and one lexicalized reordering model, multiple French language models (LMs), as well as distortion, word, and phrase penalties. The training data are composed from some of the corpora allowed by the IWSLT Evaluation Campaign organizers. As parallel data the following corpora were taken into account: Web Inventory of Transcribed and Translated Talks (version 2013-01) (TED) [13], 109 -French-English (version 2) (Giga), English-French Europarl (version 7) (EP), Common Crawl (CC), MultiUN (UN), and the News Commentary (News) corpus as distributed by the organizers of the Workshop of Machine Translation (WMT). As monolingual data we use the entire monolingual news corpora (Full) distributed by WMT organizers for language model training. All texts were processed according to the language specific tokenization provided by Moses toolkit and kept casesensitive. Statistics of the training corpora are reported in Table 1. Corpus TED Giga UN CC EP News Full unselected En Fr Se"
2013.iwslt-evaluation.20,W11-2123,0,0.0253156,"omponent models. Details for these systems are provided in Section 3.1. Most system parameters are kept fixed to allow a better comparison among the systems. Word alignments are computed by means of MGIZA++ on case-insensitive parallel texts to reduce data sparseness; casing information is re-introduced in order to estimate case-sensitive models, unless otherwise specified in the particular experiment. In all systems the maximum phrase length is set to 7 and the distortion limit is set to the default value of 6. We train 5-gram LMs with IRSTLM toolkit [12] in most cases; in other cases, KenLM [14] is used. Each language model is smoothed via the improved Kneser-Ney technique. Singleton n-grams of order three or higher are pruned. The weights of the log-linear combination are optimized either via minimum error rate training (MERT) [15] or the Margin Infused Relaxed Algorithm (MIRA) [16, 17] on dev2010. 3.1. English-French submissions As described in Section 3, we submit five systems which differ in the exploitation of the training data for the creation of TM, RM and LMs. We evaluate the performance of each system in Table 2 and use the results on tst2010 to select our primary submission"
2013.iwslt-evaluation.20,P03-1021,0,0.0543223,"to reduce data sparseness; casing information is re-introduced in order to estimate case-sensitive models, unless otherwise specified in the particular experiment. In all systems the maximum phrase length is set to 7 and the distortion limit is set to the default value of 6. We train 5-gram LMs with IRSTLM toolkit [12] in most cases; in other cases, KenLM [14] is used. Each language model is smoothed via the improved Kneser-Ney technique. Singleton n-grams of order three or higher are pruned. The weights of the log-linear combination are optimized either via minimum error rate training (MERT) [15] or the Margin Infused Relaxed Algorithm (MIRA) [16, 17] on dev2010. 3.1. English-French submissions As described in Section 3, we submit five systems which differ in the exploitation of the training data for the creation of TM, RM and LMs. We evaluate the performance of each system in Table 2 and use the results on tst2010 to select our primary submission. In our Primary, Contrastive 1, and Contrastive 2 systems, the dev2010 and tst2010 data are added to the TED training data after optimizing each system’s feature weights, before evaluating their performances on the 2011, 2012, and 2013 test"
2013.iwslt-evaluation.20,D07-1080,0,0.0550361,"introduced in order to estimate case-sensitive models, unless otherwise specified in the particular experiment. In all systems the maximum phrase length is set to 7 and the distortion limit is set to the default value of 6. We train 5-gram LMs with IRSTLM toolkit [12] in most cases; in other cases, KenLM [14] is used. Each language model is smoothed via the improved Kneser-Ney technique. Singleton n-grams of order three or higher are pruned. The weights of the log-linear combination are optimized either via minimum error rate training (MERT) [15] or the Margin Infused Relaxed Algorithm (MIRA) [16, 17] on dev2010. 3.1. English-French submissions As described in Section 3, we submit five systems which differ in the exploitation of the training data for the creation of TM, RM and LMs. We evaluate the performance of each system in Table 2 and use the results on tst2010 to select our primary submission. In our Primary, Contrastive 1, and Contrastive 2 systems, the dev2010 and tst2010 data are added to the TED training data after optimizing each system’s feature weights, before evaluating their performances on the 2011, 2012, and 2013 test sets. 3.1.1. Primary A backed-off TM is created combinin"
2013.iwslt-evaluation.20,N04-1022,0,0.0529711,"weights, before evaluating their performances on the 2011, 2012, and 2013 test sets. 3.1.1. Primary A backed-off TM is created combining a primary TM trained on TED training data (TED-TM) and a background TM trained on the selected training data (Slct-TM). The RM is constructed in a similar manner. A log-linear combination of two LMs is employed. The first LM is a mixture estimated from the in-domain TED training data (TED-LM) and the out-of-domain data-selected training data (Slct-LM). Additionally, a second Full-LM is estimated from the entire French monolingual corpora. Minimum Bayes Risk [18] (MBR) decoding technique, provided by Moses, is also exploited. Feature weights are averaged over three MERT optimizations. 3.1.3. Contrastive 2 This system aims at enhancing the primary system by further focusing its models to each specific talk that comprises the test set. Using the same optimized feature weights, we construct talk-specific translation, reordering, and language models and insert them with highest priority in their respective back-off and mixture models. Given a talk to translate, we perform the data selection procedure described in Section 2.1, using the source text of the"
2013.mtsummit-papers.2,W12-3155,1,0.930194,"cal consistency through online learning. Cesa-Bianchi et al. (2008) are the first to apply online discriminative re-ranking to a CAT scenario. Incremental adaptations of the generative components of SMT have been presented for a related scenario, interactive machine translation, where an MT component produces hypotheses based on partial translations of a sentence (Nepveu et al., 2004; Ortiz-Mart´ınez et al., 2010). Our online learning protocol is similar, but operating on the sentence instead of word or phrase level. Incremental adaptations have also been presented for larger batches of data (Bertoldi et al., 2012). In terms of granularity, our scenario is most similar to the work by Hardt and Elming (2010), where the Moses training procedure is employed to update the phrase table immediately after a reference becomes available. Our work, however, focuses on adapting both language and translation model with techniques where the global model remains unchanged. This is important in a CAT scenario, where several users might use the same global model but individual local models. 3 Online Adaptation in SMT Cesa-Bianchi and Lugosi (2006) presented a protocol for online learning with expert advice. This protoc"
2013.mtsummit-papers.2,2011.iwslt-evaluation.18,1,0.82902,"D. or streaming scenarios for incremental adaptation of the core components of SMT (Levenberg et al., 2010). However, the online learning protocol is applied in these approaches to training data only, i.e., parameters are updated on a per-example basis on the training set, while testing is done by retranslating the full test set using the final model. Further related work can be found in the application of incremental learning to domain adaptation in SMT. Here a local and a global model have to be combined, either in a log-linear combination (Koehn and Schroeder, 2007), with a fill-up method (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Carpuat and Simard (2012) show that increased translation consistency does not correlate with better translation quality, however, translation errors are indicated by inconsistencies. Our approach can be seen as a successful approach to improve translation quality by enforcing local consistency through online learning. Cesa-Bianchi et al. (2008) are the first to apply online discriminative re-ranking to a CAT scenario. Incremental adaptations of the generative components of SMT have been presented for a related scenario, interactive machi"
2013.mtsummit-papers.2,W12-3156,0,0.0256807,"f SMT (Levenberg et al., 2010). However, the online learning protocol is applied in these approaches to training data only, i.e., parameters are updated on a per-example basis on the training set, while testing is done by retranslating the full test set using the final model. Further related work can be found in the application of incremental learning to domain adaptation in SMT. Here a local and a global model have to be combined, either in a log-linear combination (Koehn and Schroeder, 2007), with a fill-up method (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Carpuat and Simard (2012) show that increased translation consistency does not correlate with better translation quality, however, translation errors are indicated by inconsistencies. Our approach can be seen as a successful approach to improve translation quality by enforcing local consistency through online learning. Cesa-Bianchi et al. (2008) are the first to apply online discriminative re-ranking to a CAT scenario. Incremental adaptations of the generative components of SMT have been presented for a related scenario, interactive machine translation, where an MT component produces hypotheses based on partial transl"
2013.mtsummit-papers.2,2010.iwslt-papers.3,1,0.879186,"itive. The log-linear interpolation weights are optimized using the standard MERT procedure provided with the Moses toolkit. The baseline system also provides a list of k-best translations. In the online discriminative re-ranking approach, this k-best list is rescored according to lexicalized sparse features including phrase pairs and target-side n-grams. 3.2 Constrained Search for Feedback Exploitation In order to extract information for system refinement from user feedback, source and user translation need to be aligned at the phrase-level. We use a constrained search technique described in Cettolo et al. (2010) to achieve this, which optimizes the coverage of both source and target sentences given a set of translation options. The search produces exactly one phrase segmentation and alignment, and allows gaps such that some source and target words may be uncovered. Unambiguous gaps (i.e. one on the source and one on the target side) can then be aligned. It differs in this respect from forced decoding which produces an alignment only when the target is fully reachable with the given models. From the phrase alignment, three types of phrase pairs can be collected: (i) new phrase pairs by aligning unambi"
2013.mtsummit-papers.2,D08-1024,0,0.0689582,"this is the first comparison of generative and discriminative online adaptation methods in a CAT scenario. The discriminative approach allows to perform feature development and training independently of the underlying SMT system. In the generative approach, the model is simple, however, updates have to be communicated to the decoder. In sum, the gains of both approaches add up to average BLEU improvements of 4 points over a baseline non-adapted model. 2 Previous Work Online learning methods in SMT are found in the context of stochastic methods for discriminative training (Liang et al., 2006; Chiang et al., 2008), Sima’an, K., Forcada, M.L., Grasmick, D., Depraetere, H., Way, A. (eds.) Proceedings of the XIV Machine Translation Summit (Nice, September 2–6, 2013), p. 11–18. c 2013 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. or streaming scenarios for incremental adaptation of the core components of SMT (Levenberg et al., 2010). However, the online learning protocol is applied in these approaches to training data only, i.e., parameters are updated on a per-example basis on the training set, while testing is done by retranslating"
2013.mtsummit-papers.2,W02-1001,0,0.263479,"und in the cache receives a score of 0, i.e. no reward. n-grams crossing over contiguous translation options are not taken into account. Note that the proposed feature is simply a stateless function which rewards approved translation options, which are expected to be of high quality. To control the influence of the local language model, the additional weight is optimized with the Simplex algorithm; weights of the baseline system tuned with MERT are taken as fixed. 3.5 Online Discriminative Re-Ranking The learner used in our online discriminative re-ranking approach is a structured perceptron (Collins, 2002). We use lexicalized sparse features defined by two feature templates: First, all phrase pairs found by the decoder (for system translations) or by the constrained search (for the user translation) are used as features. Second, we use features defined by target-side n-grams from n = 1, . . . , 4 in the user translation. Our features are not indicator functions, but use the number of source words (for the first type of features) and the number of words in target-side n-grams (for the second type of features) as values. Given a feature representation f (x, y) for a source-target pair (x, y), and"
2013.mtsummit-papers.2,2010.amta-papers.21,0,0.646236,"line discriminative re-ranking to a CAT scenario. Incremental adaptations of the generative components of SMT have been presented for a related scenario, interactive machine translation, where an MT component produces hypotheses based on partial translations of a sentence (Nepveu et al., 2004; Ortiz-Mart´ınez et al., 2010). Our online learning protocol is similar, but operating on the sentence instead of word or phrase level. Incremental adaptations have also been presented for larger batches of data (Bertoldi et al., 2012). In terms of granularity, our scenario is most similar to the work by Hardt and Elming (2010), where the Moses training procedure is employed to update the phrase table immediately after a reference becomes available. Our work, however, focuses on adapting both language and translation model with techniques where the global model remains unchanged. This is important in a CAT scenario, where several users might use the same global model but individual local models. 3 Online Adaptation in SMT Cesa-Bianchi and Lugosi (2006) presented a protocol for online learning with expert advice. This protocol can be adapted to our scenario of online adaptation in SMT as follows: Train global model M"
2013.mtsummit-papers.2,W07-0733,0,0.0548648,"licence, no derivative works, attribution, CC-BY-ND. or streaming scenarios for incremental adaptation of the core components of SMT (Levenberg et al., 2010). However, the online learning protocol is applied in these approaches to training data only, i.e., parameters are updated on a per-example basis on the training set, while testing is done by retranslating the full test set using the final model. Further related work can be found in the application of incremental learning to domain adaptation in SMT. Here a local and a global model have to be combined, either in a log-linear combination (Koehn and Schroeder, 2007), with a fill-up method (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Carpuat and Simard (2012) show that increased translation consistency does not correlate with better translation quality, however, translation errors are indicated by inconsistencies. Our approach can be seen as a successful approach to improve translation quality by enforcing local consistency through online learning. Cesa-Bianchi et al. (2008) are the first to apply online discriminative re-ranking to a CAT scenario. Incremental adaptations of the generative components of SMT have been prese"
2013.mtsummit-papers.2,P07-2045,1,0.0112703,"erative components of translation model (TM) (Section 3.3) and language model (LM) (Section 3.4) and adaptation via discriminative reranking (Section 3.5). Different refinements result in different modes of combination of global and local models (step 0). Both generative and discriminative adaptation modes deploy a constrained search technique (Section 3.2) to extract information relevant for system refinement from the received user feedback (step 3). Translation (step 2) employs a standard phrase-based SMT engine. 3.1 Baseline System The MT engine is built upon the open source toolkit Moses (Koehn et al., 2007). The global translation and the lexicalized reordering models are estimated on parallel training data with default 12 Annex Allegato to the all’ 3.3 Technical Offer Offerta Tecnica Figure 1: Phrase segmentation and alignment. setting. The global 5-gram LM smoothed through the improved Kneser-Ney technique is estimated on the target monolingual side of the parallel training data using the IRSTLM toolkit (Federico et al., 2008). Models are case-sensitive. The log-linear interpolation weights are optimized using the standard MERT procedure provided with the Moses toolkit. The baseline system als"
2013.mtsummit-papers.2,N10-1062,0,0.179294,"BLEU improvements of 4 points over a baseline non-adapted model. 2 Previous Work Online learning methods in SMT are found in the context of stochastic methods for discriminative training (Liang et al., 2006; Chiang et al., 2008), Sima’an, K., Forcada, M.L., Grasmick, D., Depraetere, H., Way, A. (eds.) Proceedings of the XIV Machine Translation Summit (Nice, September 2–6, 2013), p. 11–18. c 2013 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. or streaming scenarios for incremental adaptation of the core components of SMT (Levenberg et al., 2010). However, the online learning protocol is applied in these approaches to training data only, i.e., parameters are updated on a per-example basis on the training set, while testing is done by retranslating the full test set using the final model. Further related work can be found in the application of incremental learning to domain adaptation in SMT. Here a local and a global model have to be combined, either in a log-linear combination (Koehn and Schroeder, 2007), with a fill-up method (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Carpuat and Simard (2012) show"
2013.mtsummit-papers.2,P06-1096,0,0.193911,"Missing"
2013.mtsummit-papers.2,D12-1037,0,0.045275,"e core components of SMT (Levenberg et al., 2010). However, the online learning protocol is applied in these approaches to training data only, i.e., parameters are updated on a per-example basis on the training set, while testing is done by retranslating the full test set using the final model. Further related work can be found in the application of incremental learning to domain adaptation in SMT. Here a local and a global model have to be combined, either in a log-linear combination (Koehn and Schroeder, 2007), with a fill-up method (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Carpuat and Simard (2012) show that increased translation consistency does not correlate with better translation quality, however, translation errors are indicated by inconsistencies. Our approach can be seen as a successful approach to improve translation quality by enforcing local consistency through online learning. Cesa-Bianchi et al. (2008) are the first to apply online discriminative re-ranking to a CAT scenario. Incremental adaptations of the generative components of SMT have been presented for a related scenario, interactive machine translation, where an MT component produces hypothe"
2013.mtsummit-papers.2,W04-3225,0,0.303316,"ranslation consistency does not correlate with better translation quality, however, translation errors are indicated by inconsistencies. Our approach can be seen as a successful approach to improve translation quality by enforcing local consistency through online learning. Cesa-Bianchi et al. (2008) are the first to apply online discriminative re-ranking to a CAT scenario. Incremental adaptations of the generative components of SMT have been presented for a related scenario, interactive machine translation, where an MT component produces hypotheses based on partial translations of a sentence (Nepveu et al., 2004; Ortiz-Mart´ınez et al., 2010). Our online learning protocol is similar, but operating on the sentence instead of word or phrase level. Incremental adaptations have also been presented for larger batches of data (Bertoldi et al., 2012). In terms of granularity, our scenario is most similar to the work by Hardt and Elming (2010), where the Moses training procedure is employed to update the phrase table immediately after a reference becomes available. Our work, however, focuses on adapting both language and translation model with techniques where the global model remains unchanged. This is impo"
2013.mtsummit-papers.2,N10-1079,0,0.347766,"Missing"
2013.mtsummit-papers.2,P02-1040,0,0.0869298,"ange of millions of sentence pairs. Then for each document d, consisting of a few hundred up to a thousand sentences, a local model Md is created. For each example, first the static global model Mg and the current local model Md are combined into a model Mg+d . Then the input xt is translated into yˆt using the model Mg+d . Finally the local model Md is refined on feedback yt that is received immediately after producing yˆt . Evaluations reported in this paper take the local predictions yˆt and compare them to the user translations yt for each document, e.g., using |d| BLEU {(ˆ yt , yt )}t=1 (Papineni et al., 2002). Note that this setup differs from the more standard scenario where the whole test set is re-translated using the learned model. However, the evaluation in our online learning scenario is still fair since only feedback from previous test set examples is used to update the current model. We present three techniques for refinements of local SMT models (step 4), namely adaptations of the generative components of translation model (TM) (Section 3.3) and language model (LM) (Section 3.4) and adaptation via discriminative reranking (Section 3.5). Different refinements result in different modes of c"
2013.mtsummit-papers.4,P11-2031,0,0.0525206,"Missing"
2013.mtsummit-papers.4,D10-1044,0,0.0660693,"Missing"
2013.mtsummit-papers.4,P07-2045,1,0.00719976,"er; in fact: – there is a significant mismatch between IT-docs and the TM – the customer specific project TM-prjct matches the TM, not generic IT-docs • the IT-docs/TM mismatch can be reduced by properly selecting a portion of the TM. 4 Lab Test Results Lab tests have been performed on data sets described in Section 3. Performance are given in terms of BLEU and TER, computed by means of the MultEval script (Clark et al., 2011) that also provides the standard deviation σ, and of GTM.5 4.1 Baseline SMT for the IT domain An IT baseline system has been built upon the open-source MT toolkit Moses (Koehn et al., 2007). The translation and the lexicalized reordering models are trained on the parallel training data available (Table 1); a 6-gram LM smoothed through the improved Kneser-Ney technique (Chen and Goodman, 1999) is estimated on the target side via the IRSTLM toolkit (Federico et al., 2008). The weights of the log-linear interpolation model are optimized by means of the standard MERT procedure provided within the Moses toolkit. For the experiments, the set of IT-docs has been split into three equally sized blocks: the first is used for data selection (employed for adaptation, not for baselines), the"
2013.mtsummit-papers.4,D09-1074,0,0.0594647,"Missing"
2013.mtsummit-papers.4,P10-2041,0,0.0437632,"Missing"
2013.mtsummit-papers.4,W08-0320,0,0.0588141,"Missing"
2013.mtsummit-papers.4,2012.amta-papers.19,0,0.0312502,"nt sizes and content is rather typical. One way to face this combination issue is the fill-up technique, initially proposed by Nakov (2008) and then refined by Bisazza et al. (2011). Fill-up effectively exploits background knowledge to improve translation and distortion models coverage, while preserving the more reliable information coming from the foreground corpus. In practice, the background phrase table is merged with the foreground phrase table by adding only phrase pairs that do not appear in the foreground table. While performing at least as good as other popular adaptation techniques (Niehues and Waibel, 2012), fill-up approach builds models that are more compact and easier to tune by means of the minimum error rate training procedure. 2.3 Mixture LMs As concerns the LM adaptation, we employed the mixture of LMs since it is a well-established and good-performing method. The mixture model can be used to combine one or more background LMs with a foreground LM representing new features of the language we want to include (Federico and Bertoldi, 2004). The technique consists of the convex combination of the LMs; the mixture weights are estimated on the training data of the foreground LM by applying a cr"
2013.mtsummit-papers.4,steinberger-etal-2006-jrc,0,0.0700722,"n of the LMs; the mixture weights are estimated on the training data of the foreground LM by applying a cross-validation scheme that simulates the occurrence of new n-grams. The method is available in the IRSTLM toolkit (Federico et al., 2008). 28 3 #seg Data for Development For our experiments we relied on existing language resources, including parallel corpora and translation memories. For the IT domain, in addition to small publicly available corpora, proprietary data sets were employed (software documentation in general). For the Legal domain, the publicly available JRC-Acquis collection (Steinberger et al., 2006) was used, which mostly includes EU legislative texts translated into 22 languages. More details are provided in the next sections. 3.1 #tgt wrds TM+OPUS all entries (wd) 5.5M 63.8M 66.6M no duplicates (wod) 1.9M 27.8M 29.0M IT-docs 4.1k 56.0k 60.5k data-sel 1.4k 18.0k 19.3k dev 1.4k 21.1k 22.9k test 1.4k 16.9k 18.3k TM-prjct 1.8k 18.0k 18.7k dev 800 5.1k 5.4k test 989 12.9k 13.3k IT domain Most of text corpora for this domain were provided by the industrial partner of the MateCat project. In particular, we employed the following resources: • Translation Memory (TM): a large collection of para"
2013.mtsummit-papers.4,D11-1033,0,0.0376481,"Missing"
2013.mtsummit-papers.4,2011.iwslt-evaluation.18,1,0.885137,"of the background corpus. This score is the difference between the cross-entropy calculated with the foreground LM and the crossentropy calculated with the background LM. The background sentences are then ordered according to this score. The selection of useful sentences Fill-up for phrase-based SMT adaptation Given the scarcity of parallel linguistic resources, in SMT training, the need of combining data of parallel corpora of different sizes and content is rather typical. One way to face this combination issue is the fill-up technique, initially proposed by Nakov (2008) and then refined by Bisazza et al. (2011). Fill-up effectively exploits background knowledge to improve translation and distortion models coverage, while preserving the more reliable information coming from the foreground corpus. In practice, the background phrase table is merged with the foreground phrase table by adding only phrase pairs that do not appear in the foreground table. While performing at least as good as other popular adaptation techniques (Niehues and Waibel, 2012), fill-up approach builds models that are more compact and easier to tune by means of the minimum error rate training procedure. 2.3 Mixture LMs As concerns"
2013.mtsummit-papers.4,I08-2088,0,0.0718824,"Missing"
2013.mtsummit-papers.5,W12-3155,1,0.837488,"eover, we propose a further enhancement of the basic caching mechanism for rewarding cached items related to the current sentence to translate. Our work also deals with MT adaptation in general, and online learning more specifically. A thorough overview of the literature on these topics can be found in the companion paper (W¨aschle et al., 2013). Here, we just list some of the most representative papers: (Levenberg et al., 2010; Levenberg et al., 2011) for online learning methods in streaming scenarios; (Koehn and Schroeder, 2007; Foster and Kuhn, 2007; Bisazza et al., 2011; Liu et al., 2012; Bertoldi et al., 2012) for incremental adaptation. 3 Online Adaptation in SMT In the well established CAT work flow, source documents are split into chunks, typically corresponding to sentences and called segments, that are in general translated sequentially. When the translator opens a segment, the CAT tool tries to propose possible translation suggestions, originating from the translation memory and/or from a machine translation engine. Depending on the quality of the suggestions, the translator decides whether to post-edit one of them or to translate the source segment from scratch. Completed segments represent"
2013.mtsummit-papers.5,2011.iwslt-evaluation.18,1,0.249691,"e matches the sentence to translate. Moreover, we propose a further enhancement of the basic caching mechanism for rewarding cached items related to the current sentence to translate. Our work also deals with MT adaptation in general, and online learning more specifically. A thorough overview of the literature on these topics can be found in the companion paper (W¨aschle et al., 2013). Here, we just list some of the most representative papers: (Levenberg et al., 2010; Levenberg et al., 2011) for online learning methods in streaming scenarios; (Koehn and Schroeder, 2007; Foster and Kuhn, 2007; Bisazza et al., 2011; Liu et al., 2012; Bertoldi et al., 2012) for incremental adaptation. 3 Online Adaptation in SMT In the well established CAT work flow, source documents are split into chunks, typically corresponding to sentences and called segments, that are in general translated sequentially. When the translator opens a segment, the CAT tool tries to propose possible translation suggestions, originating from the translation memory and/or from a machine translation engine. Depending on the quality of the suggestions, the translator decides whether to post-edit one of them or to translate the source segment f"
2013.mtsummit-papers.5,2010.iwslt-papers.3,1,0.832754,"-pairs can be inserted, and (ii) scores of all entries are modified when new pairs are added. All entries are associated with an age, corresponding to the time they were actually 37 inserted, and scored accordingly. Each new insertion causes the ageing of the existing phrase pairs and hence their rescoring; in case of re-insertion of a phrase pair, the old value is overwritten. Phrase pairs are scored based on a negative exponential decaying function. For each segment pair, a set of phrase pairs are extracted from the partial alignment provided by the constrained search algorithm described by Cettolo et al. (2010). The procedure, detailed in (W¨aschle et al., 2013), extracts both already “known” and “new” pairs; the latter can provide translation options for OOVs and phrases including OOVs. All the extracted phrase pairs are simultaneously added to the local translation model by feeding the decoder with an XML-tag like: &lt;dlt cbtm=“The crude face of domination . Le visage rustre de la domination . |crude rustre |· · · |domination la domination |face visage”/&gt; The pair (x, y) consisting of the whole segments is also added to mimic the behaviour of a translation memory. During decoding, translation altern"
2013.mtsummit-papers.5,2012.eamt-1.60,1,0.823386,"(Federico et al., 2012) were considered, i.e. the translation of talks from Arabic to English and from English to French. 4.1.1 Training Data The training data for the IT domain mostly consist of data extracted from a translation memory built during the execution of translation projects commissioned by several commercial companies. In addition, parallel texts from the OPUS corpus (Tiedemann, 2012) were are also included. Training data of the Legal domain come from Version 3.0 of the JRC-Acquis collection (Steinberger et al., 2006), while TED training data are those released through the WIT3 (Cettolo et al., 2012) website for the IWSLT 2012 evaluation campaign (Federico et al., 2012). The reader may again refer to Table 1 for statistics on the actual corpora employed for training. Evaluations were performed on both proprietary and publicly available data, involving the translation of documents from three domains, namely Information Technology (IT), Legal (LGL) and TED talks,3 and for different language pairs. Table 1 summarizes the experimental framework in terms of data type. Commercial data were provided by the industrial partner of the MateCat project and were collected during the real use of CAT to"
2013.mtsummit-papers.5,2013.mtsummit-papers.4,1,0.805,"nguage pairs. Table 1 summarizes the experimental framework in terms of data type. Commercial data were provided by the industrial partner of the MateCat project and were collected during the real use of CAT tools by professional translators. Public data, which allow to 4.1.2 Evaluation Data Evaluation on IT and Legal domains has been performed on data collected in a two-day field test. During the first day (D0), MT suggestions came from baseline SMT systems (Section 4.4); during the second day (D1), they came from static SMT systems adapted to the post-edits of the first day as described in (Cettolo et al., 2013). For the IT domain, the text to be translated was taken from a software user manual. Concerning the Legal domain, the text was taken from a recent motion for a European Parliament resolution published on the EUR-Lex platform. Statistics on the test documents translated during the field test are reported in Table 2 (rows D0 and D1); they refer to tokenized texts. Figures on the source side (English) refer to the texts the users are requested to translate; figures on the target side (Italian) refer to the references, whatever they are actual post-edited texts or new translations. The additional"
2013.mtsummit-papers.5,P11-2031,0,0.0254423,"systems were developed with the Moses toolkit (Koehn et al., 2007). Translation and lexicalized reordering models were trained on the parallel training data; 6-gram (for IT and Legal systems) and 5-gram (for TED systems) LMs with improved Kneser-Ney smoothing (Chen and Goodman, 1999) were estimated on the target side of the training parallel data with the IRSTLM toolkit (Federico et al., 2008). The weights of the log-linear interpolation model were optimized via the MERT procedure provided with Moses. Performance are provided in terms of BLEU and TER, computed by means of the MultEval script (Clark et al., 2011) that also provides the standard deviation σ, and of GTM8 Here some specific features of systems developed for each task: IT/Legal baselines: different weights were used in the two days of the field test, 8 nlp.cs.nyu.edu/GTM 40 task IT LGL system baseline +cache +context baseline +cache +context BLEU (σ) 44.69 (1.67) 47.25 (1.81) 47.89 (1.82) 47.66 (2.13) 47.69 (2.05) 46.58 (2.05) D0 TER (σ) 36.34 (1.30) 34.83 (1.34) 34.61 (1.44) 34.69 (1.71) 33.94 (1.63) 34.74 (1.65) GTM 74.59 76.36 76.99 73.88 75.04 74.49 BLEU (σ) 41.06 (1.57) 44.61 (1.72) 48.04 (1.93) 47.42 (2.11) 47.57 (2.09) 48.07 (2.16)"
2013.mtsummit-papers.5,W07-0717,0,0.0370258,"ptions whose source side matches the sentence to translate. Moreover, we propose a further enhancement of the basic caching mechanism for rewarding cached items related to the current sentence to translate. Our work also deals with MT adaptation in general, and online learning more specifically. A thorough overview of the literature on these topics can be found in the companion paper (W¨aschle et al., 2013). Here, we just list some of the most representative papers: (Levenberg et al., 2010; Levenberg et al., 2011) for online learning methods in streaming scenarios; (Koehn and Schroeder, 2007; Foster and Kuhn, 2007; Bisazza et al., 2011; Liu et al., 2012; Bertoldi et al., 2012) for incremental adaptation. 3 Online Adaptation in SMT In the well established CAT work flow, source documents are split into chunks, typically corresponding to sentences and called segments, that are in general translated sequentially. When the translator opens a segment, the CAT tool tries to propose possible translation suggestions, originating from the translation memory and/or from a machine translation engine. Depending on the quality of the suggestions, the translator decides whether to post-edit one of them or to translat"
2013.mtsummit-papers.5,W07-0733,0,0.0223156,"h, fed by all translation options whose source side matches the sentence to translate. Moreover, we propose a further enhancement of the basic caching mechanism for rewarding cached items related to the current sentence to translate. Our work also deals with MT adaptation in general, and online learning more specifically. A thorough overview of the literature on these topics can be found in the companion paper (W¨aschle et al., 2013). Here, we just list some of the most representative papers: (Levenberg et al., 2010; Levenberg et al., 2011) for online learning methods in streaming scenarios; (Koehn and Schroeder, 2007; Foster and Kuhn, 2007; Bisazza et al., 2011; Liu et al., 2012; Bertoldi et al., 2012) for incremental adaptation. 3 Online Adaptation in SMT In the well established CAT work flow, source documents are split into chunks, typically corresponding to sentences and called segments, that are in general translated sequentially. When the translator opens a segment, the CAT tool tries to propose possible translation suggestions, originating from the translation memory and/or from a machine translation engine. Depending on the quality of the suggestions, the translator decides whether to post-edit one"
2013.mtsummit-papers.5,P07-2045,1,0.0105799,"ce segment xt is received . . . [optional step] . . . a translation yˆt is computed with Mt a post-edited translation yt is received a new system Mt+1 is created by adapting Mt with features extracted from (xt , yt ) Step 5 is implemented via a caching mechanism that allows us to define and dynamically adapt local (with respect to the document) models that are combined during decoding with the global SMT models estimated on the training data. In the following, we present how the local cache-based models are defined and adapted under the wellknown phrase-based SMT setting of the Moses toolkit (Koehn et al., 2007). They will be included in a future release of the toolkit. The optional step 2 is additional with respect to the basic online learning procedure and comprises the updating of Mt with context features, as described in more detail in Section 3.3. 3.1 TM Adaptation The pair (x, y) composed of a source segment and its post-edited translation, is exploited to update a local translation model. This model is intended for integrating new translation alternatives suggested by the user and for rewarding those approved, with the ultimate goal of translating the successive segments more consistently with"
2013.mtsummit-papers.5,N10-1062,0,0.161242,"-edition; explicit, possibly partial, phrase-alignment is obtained via an efficient constrained search, fed by all translation options whose source side matches the sentence to translate. Moreover, we propose a further enhancement of the basic caching mechanism for rewarding cached items related to the current sentence to translate. Our work also deals with MT adaptation in general, and online learning more specifically. A thorough overview of the literature on these topics can be found in the companion paper (W¨aschle et al., 2013). Here, we just list some of the most representative papers: (Levenberg et al., 2010; Levenberg et al., 2011) for online learning methods in streaming scenarios; (Koehn and Schroeder, 2007; Foster and Kuhn, 2007; Bisazza et al., 2011; Liu et al., 2012; Bertoldi et al., 2012) for incremental adaptation. 3 Online Adaptation in SMT In the well established CAT work flow, source documents are split into chunks, typically corresponding to sentences and called segments, that are in general translated sequentially. When the translator opens a segment, the CAT tool tries to propose possible translation suggestions, originating from the translation memory and/or from a machine translat"
2013.mtsummit-papers.5,W11-2122,0,0.0186151,"ibly partial, phrase-alignment is obtained via an efficient constrained search, fed by all translation options whose source side matches the sentence to translate. Moreover, we propose a further enhancement of the basic caching mechanism for rewarding cached items related to the current sentence to translate. Our work also deals with MT adaptation in general, and online learning more specifically. A thorough overview of the literature on these topics can be found in the companion paper (W¨aschle et al., 2013). Here, we just list some of the most representative papers: (Levenberg et al., 2010; Levenberg et al., 2011) for online learning methods in streaming scenarios; (Koehn and Schroeder, 2007; Foster and Kuhn, 2007; Bisazza et al., 2011; Liu et al., 2012; Bertoldi et al., 2012) for incremental adaptation. 3 Online Adaptation in SMT In the well established CAT work flow, source documents are split into chunks, typically corresponding to sentences and called segments, that are in general translated sequentially. When the translator opens a segment, the CAT tool tries to propose possible translation suggestions, originating from the translation memory and/or from a machine translation engine. Depending on"
2013.mtsummit-papers.5,D12-1037,0,0.0337503,"to translate. Moreover, we propose a further enhancement of the basic caching mechanism for rewarding cached items related to the current sentence to translate. Our work also deals with MT adaptation in general, and online learning more specifically. A thorough overview of the literature on these topics can be found in the companion paper (W¨aschle et al., 2013). Here, we just list some of the most representative papers: (Levenberg et al., 2010; Levenberg et al., 2011) for online learning methods in streaming scenarios; (Koehn and Schroeder, 2007; Foster and Kuhn, 2007; Bisazza et al., 2011; Liu et al., 2012; Bertoldi et al., 2012) for incremental adaptation. 3 Online Adaptation in SMT In the well established CAT work flow, source documents are split into chunks, typically corresponding to sentences and called segments, that are in general translated sequentially. When the translator opens a segment, the CAT tool tries to propose possible translation suggestions, originating from the translation memory and/or from a machine translation engine. Depending on the quality of the suggestions, the translator decides whether to post-edit one of them or to translate the source segment from scratch. Compl"
2013.mtsummit-papers.5,W04-3225,0,0.675866,"and CasmaCat2 European projects, which are jointly developing a new generation CAT tool integrating novel interaction modalities and MT functions. In this paper we deal with SMT models which dynamically learn from the user feedback by means of a caching mechanism. The main idea behind cache-based models is to mix a large global (static) model with a small local (dynamic) model estimated from recent items observed in the history of the input stream. In (Kuhn and De Mori, 1990), the caching mechanism was applied to language models, and only very later its use was extended to translation models (Nepveu et al., 2004). In lab tests, cache-based language and translation models have already proven to be effective in interactive SMT (Nepveu et al., 2004); in adapting generic SMT models, (Tiedemann, 2010) obtained interesting but not definitive gains, the “main obstacle” being “the invalid assumption that initial translations are correct”. In a real CAT framework like ours, the cached items are correct by definition. The road map of our work is defined through a list of research questions addressed in this paper. Clearly, the first questions we are interested in is: Q1 - Is the effectiveness of cache-based ada"
2013.mtsummit-papers.5,steinberger-etal-2006-jrc,0,0.032325,"ency of observed feature. To mimic the way translation memory works, we also decide to reward target ngram and phrase-pair features observed in similar and already translated segments of the document. This implies adding the following lazy learning step to the previous on-line learning algorithm: 2. Mt is updated with features extracted from the pair (x, y) in {(x1 , y1 ), . . . , (xt−1 , yt−1 )} such that x is most similar to xt . replicate and cross-assess our outcomes, were chosen to cover a wide range of linguistic conditions. For the Legal domain, we worked with the JRCAcquis collection (Steinberger et al., 2006), on the English to Italian direction. The same direction is also investigated for the IT domain. As concerns TED, the two official MT tasks of the IWSLT 2012 evaluation campaign (Federico et al., 2012) were considered, i.e. the translation of talks from Arabic to English and from English to French. 4.1.1 Training Data The training data for the IT domain mostly consist of data extracted from a translation memory built during the execution of translation projects commissioned by several commercial companies. In addition, parallel texts from the OPUS corpus (Tiedemann, 2012) were are also includ"
2013.mtsummit-papers.5,W10-2602,0,0.0475392,"dynamically learn from the user feedback by means of a caching mechanism. The main idea behind cache-based models is to mix a large global (static) model with a small local (dynamic) model estimated from recent items observed in the history of the input stream. In (Kuhn and De Mori, 1990), the caching mechanism was applied to language models, and only very later its use was extended to translation models (Nepveu et al., 2004). In lab tests, cache-based language and translation models have already proven to be effective in interactive SMT (Nepveu et al., 2004); in adapting generic SMT models, (Tiedemann, 2010) obtained interesting but not definitive gains, the “main obstacle” being “the invalid assumption that initial translations are correct”. In a real CAT framework like ours, the cached items are correct by definition. The road map of our work is defined through a list of research questions addressed in this paper. Clearly, the first questions we are interested in is: Q1 - Is the effectiveness of cache-based adaptation confirmed in a real CAT environment? As mentioned in (Tiedemann, 2010), there are two types of important properties in natural language and translation that are often ignored in s"
2013.mtsummit-papers.5,tiedemann-2012-parallel,0,0.0187782,"collection (Steinberger et al., 2006), on the English to Italian direction. The same direction is also investigated for the IT domain. As concerns TED, the two official MT tasks of the IWSLT 2012 evaluation campaign (Federico et al., 2012) were considered, i.e. the translation of talks from Arabic to English and from English to French. 4.1.1 Training Data The training data for the IT domain mostly consist of data extracted from a translation memory built during the execution of translation projects commissioned by several commercial companies. In addition, parallel texts from the OPUS corpus (Tiedemann, 2012) were are also included. Training data of the Legal domain come from Version 3.0 of the JRC-Acquis collection (Steinberger et al., 2006), while TED training data are those released through the WIT3 (Cettolo et al., 2012) website for the IWSLT 2012 evaluation campaign (Federico et al., 2012). The reader may again refer to Table 1 for statistics on the actual corpora employed for training. Evaluations were performed on both proprietary and publicly available data, involving the translation of documents from three domains, namely Information Technology (IT), Legal (LGL) and TED talks,3 and for di"
2013.mtsummit-papers.5,2013.mtsummit-papers.2,1,0.847457,"Missing"
2013.mtsummit-papers.5,federico-etal-2012-iwslt,1,\N,Missing
2013.mtsummit-wptp.13,D11-1033,0,0.0228773,"o adapt a SMT system towards a target domain using small amounts of parallel in-domain data, namely the backoff, the factored, and the already mentioned log-linear and fill-up techniques; the general outcome is that each of them is effective in improving non-adapted models and none is definitely better than each other, which is the best depending on how well the test data matches the indomain training data. This work deals with data selection as well, which is a problem widely investigated by the SMT community, see for example (Yasuda et al., 2008; Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011). We apply a standard selection technique (Moore and Lewis, 2010), but in a quite different scenario where the task-specific data is extremely small and the generic corpus is actually close to the domain of the task. 3 Adaptation Methods In this section we describe the techniques employed to adapt our SMT systems, namely data selection and translation, distortion and language model combination. 3.1 Data selection It has been believed for a long time that just adding more training data always improves performance of a statistical model, e.g. a n-gram LM. However, this is in general true only if"
2013.mtsummit-wptp.13,N09-2038,0,0.0242009,"the use of local and global models for incremental learning was previously proposed through a log-linear combination (Koehn and Schroeder, 2007), a mixture model (linear or log-linear) (Foster and Kuhn, 2007), the filling-up (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Sharon O’Brien, Michel Simard and Lucia Specia (eds.) Proceedings of MT Summit XIV Workshop on Post-editing Technology and Practice, Nice, September 2, 2013, p. 111–118. c 2013 The Authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. Bach et al. (2009) investigate how a speechto-speech translation system can adapt day-to-day from collected data on day one to improve performance on day two, similarly to us. However, the adaptation of the MT module involves only the LM and is performed on the MT outputs. On standard machine translation tasks, Niehues and Waibel (2012) compare different approaches to adapt a SMT system towards a target domain using small amounts of parallel in-domain data, namely the backoff, the factored, and the already mentioned log-linear and fill-up techniques; the general outcome is that each of them is effective in impr"
2013.mtsummit-wptp.13,W12-3155,1,0.851259,"ently homogeneous, the language is sufficiently complex, and there is sufficient multilingual data available to train and tune MT models. The paper is organized as follows. Section 2 lists some of the related works. Section 3 introduces methods used for project adaptation. Section 4 briefly describes the conduct of the field test. Section 5 and Section 6, respectively, introduce the set-up and results of experiments. Section 7 concludes the paper with a discussion on the overall results. 2 Related Work Our work deals with MT adaptation in general, and incremental adaptation more specifically. Bertoldi et al. (2012) present an adaptation scenario where foreground translation and reordering models (TM) and language model (LM) of a phrase-based SMT system are incrementally trained on batches of fresh data and then paired to static background models. Similarly, the use of local and global models for incremental learning was previously proposed through a log-linear combination (Koehn and Schroeder, 2007), a mixture model (linear or log-linear) (Foster and Kuhn, 2007), the filling-up (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Sharon O’Brien, Michel Simard and Lucia Specia (e"
2013.mtsummit-wptp.13,2011.iwslt-evaluation.18,1,0.827144,"elated Work Our work deals with MT adaptation in general, and incremental adaptation more specifically. Bertoldi et al. (2012) present an adaptation scenario where foreground translation and reordering models (TM) and language model (LM) of a phrase-based SMT system are incrementally trained on batches of fresh data and then paired to static background models. Similarly, the use of local and global models for incremental learning was previously proposed through a log-linear combination (Koehn and Schroeder, 2007), a mixture model (linear or log-linear) (Foster and Kuhn, 2007), the filling-up (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Sharon O’Brien, Michel Simard and Lucia Specia (eds.) Proceedings of MT Summit XIV Workshop on Post-editing Technology and Practice, Nice, September 2, 2013, p. 111–118. c 2013 The Authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. Bach et al. (2009) investigate how a speechto-speech translation system can adapt day-to-day from collected data on day one to improve performance on day two, similarly to us. However, the adaptation of the MT module involves only the LM and is pe"
2013.mtsummit-wptp.13,P11-2031,0,0.0146555,"Dntgt , n=0,1) or the concatenation of the source side of both the development and test set (D01src ); we name FGtgt and FGsrc the selected corpus and the models trained on it in the two cases. The table also provides the percentage of data selected, computed with respect to the target side. The optimal splitting was performed by minimizing the perplexity of the target side of the development set. 6 Experiments Lab test experiments have been performed on data sets described in Section 5. Performance are provided in terms of BLEU and TER, computed by means of the MultEval script implemented by Clark et al. (2011), and of GTM.4 For statistical significance, p-values were calculated via approximate randomization for adapted systems with respect to the baselines and are reported in Tables 5 and 6 whenever not larger than 0.10. The SMT systems have been built upon the open-source MT toolkit Moses (Koehn et al., 2007). The translation and the lexicalized reordering models are trained on the available parallel training data (Table 1); 5-gram LMs smoothed through the improved Kneser-Ney tech4 http://nlp.cs.nyu.edu/GTM nique (Chen and Goodman, 1999) are estimated on the target side via the IRSTLM toolkit (Fed"
2013.mtsummit-wptp.13,2012.amta-papers.22,1,0.534373,"MT suggestions for the second half of the document came from a system adapted to the text of the first day by means of one of the adaptation methods tested in our experiments (Section 6). Translators post-edited machine-generated translations for correcting mistakes and making them stylistically appropriate. The document was selected such that the size of its halves corresponds approximately to the daily productivity of professional translators, that is three to five thousand words. A report on the field test including an analysis of the productivity of translators has already been published (Federico et al., 2012). Moreover, we performed a preliminary measure of the performance of MT outputs versus the post-edition of each translator. In both cases, pretty large inter-translator differences were observed. Since the limited number of subjects would have led to scores with large variances, we decided to choose segments en→de up, called backoff, in which the indicator feature is discarded. Again, the backoff method proposed by Niehues and Waibel (2012) differs slightly in the way the scores of the phrase pairs stemming from the background phrase table are computed. Language model: As concerns the LM adapt"
2013.mtsummit-wptp.13,P02-1023,0,0.0361356,"Missing"
2013.mtsummit-wptp.13,W07-0733,0,0.0352986,"t-up and results of experiments. Section 7 concludes the paper with a discussion on the overall results. 2 Related Work Our work deals with MT adaptation in general, and incremental adaptation more specifically. Bertoldi et al. (2012) present an adaptation scenario where foreground translation and reordering models (TM) and language model (LM) of a phrase-based SMT system are incrementally trained on batches of fresh data and then paired to static background models. Similarly, the use of local and global models for incremental learning was previously proposed through a log-linear combination (Koehn and Schroeder, 2007), a mixture model (linear or log-linear) (Foster and Kuhn, 2007), the filling-up (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Sharon O’Brien, Michel Simard and Lucia Specia (eds.) Proceedings of MT Summit XIV Workshop on Post-editing Technology and Practice, Nice, September 2, 2013, p. 111–118. c 2013 The Authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. Bach et al. (2009) investigate how a speechto-speech translation system can adapt day-to-day from collected data on day one to improve performan"
2013.mtsummit-wptp.13,P07-2045,1,0.00690725,"plitting was performed by minimizing the perplexity of the target side of the development set. 6 Experiments Lab test experiments have been performed on data sets described in Section 5. Performance are provided in terms of BLEU and TER, computed by means of the MultEval script implemented by Clark et al. (2011), and of GTM.4 For statistical significance, p-values were calculated via approximate randomization for adapted systems with respect to the baselines and are reported in Tables 5 and 6 whenever not larger than 0.10. The SMT systems have been built upon the open-source MT toolkit Moses (Koehn et al., 2007). The translation and the lexicalized reordering models are trained on the available parallel training data (Table 1); 5-gram LMs smoothed through the improved Kneser-Ney tech4 http://nlp.cs.nyu.edu/GTM nique (Chen and Goodman, 1999) are estimated on the target side via the IRSTLM toolkit (Federico et al., 2008). The weights of the log-linear interpolation model have been optimized by means of the Margin Infused Relaxed Algorithm (MIRA) process (Hasler et al., 2011) provided within the Moses toolkit. Various models have been built by means of the methods described in Section 3. Here the list o"
2013.mtsummit-wptp.13,D12-1037,0,0.0226802,"and incremental adaptation more specifically. Bertoldi et al. (2012) present an adaptation scenario where foreground translation and reordering models (TM) and language model (LM) of a phrase-based SMT system are incrementally trained on batches of fresh data and then paired to static background models. Similarly, the use of local and global models for incremental learning was previously proposed through a log-linear combination (Koehn and Schroeder, 2007), a mixture model (linear or log-linear) (Foster and Kuhn, 2007), the filling-up (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Sharon O’Brien, Michel Simard and Lucia Specia (eds.) Proceedings of MT Summit XIV Workshop on Post-editing Technology and Practice, Nice, September 2, 2013, p. 111–118. c 2013 The Authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. Bach et al. (2009) investigate how a speechto-speech translation system can adapt day-to-day from collected data on day one to improve performance on day two, similarly to us. However, the adaptation of the MT module involves only the LM and is performed on the MT outputs. On standard machine transla"
2013.mtsummit-wptp.13,D09-1074,0,0.0233102,"Waibel (2012) compare different approaches to adapt a SMT system towards a target domain using small amounts of parallel in-domain data, namely the backoff, the factored, and the already mentioned log-linear and fill-up techniques; the general outcome is that each of them is effective in improving non-adapted models and none is definitely better than each other, which is the best depending on how well the test data matches the indomain training data. This work deals with data selection as well, which is a problem widely investigated by the SMT community, see for example (Yasuda et al., 2008; Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011). We apply a standard selection technique (Moore and Lewis, 2010), but in a quite different scenario where the task-specific data is extremely small and the generic corpus is actually close to the domain of the task. 3 Adaptation Methods In this section we describe the techniques employed to adapt our SMT systems, namely data selection and translation, distortion and language model combination. 3.1 Data selection It has been believed for a long time that just adding more training data always improves performance of a statistical model, e.g. a n-gram"
2013.mtsummit-wptp.13,P10-2041,0,0.0161319,"of parallel in-domain data, namely the backoff, the factored, and the already mentioned log-linear and fill-up techniques; the general outcome is that each of them is effective in improving non-adapted models and none is definitely better than each other, which is the best depending on how well the test data matches the indomain training data. This work deals with data selection as well, which is a problem widely investigated by the SMT community, see for example (Yasuda et al., 2008; Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011). We apply a standard selection technique (Moore and Lewis, 2010), but in a quite different scenario where the task-specific data is extremely small and the generic corpus is actually close to the domain of the task. 3 Adaptation Methods In this section we describe the techniques employed to adapt our SMT systems, namely data selection and translation, distortion and language model combination. 3.1 Data selection It has been believed for a long time that just adding more training data always improves performance of a statistical model, e.g. a n-gram LM. However, this is in general true only if the new data is enough relevant to the task at hand, a condition"
2013.mtsummit-wptp.13,W08-0320,0,0.0387515,"Missing"
2013.mtsummit-wptp.13,2012.amta-papers.19,0,0.127366,"rien, Michel Simard and Lucia Specia (eds.) Proceedings of MT Summit XIV Workshop on Post-editing Technology and Practice, Nice, September 2, 2013, p. 111–118. c 2013 The Authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. Bach et al. (2009) investigate how a speechto-speech translation system can adapt day-to-day from collected data on day one to improve performance on day two, similarly to us. However, the adaptation of the MT module involves only the LM and is performed on the MT outputs. On standard machine translation tasks, Niehues and Waibel (2012) compare different approaches to adapt a SMT system towards a target domain using small amounts of parallel in-domain data, namely the backoff, the factored, and the already mentioned log-linear and fill-up techniques; the general outcome is that each of them is effective in improving non-adapted models and none is definitely better than each other, which is the best depending on how well the test data matches the indomain training data. This work deals with data selection as well, which is a problem widely investigated by the SMT community, see for example (Yasuda et al., 2008; Matsoukas et a"
2013.mtsummit-wptp.13,W12-3147,1,0.900227,"Missing"
2013.mtsummit-wptp.13,steinberger-etal-2006-jrc,0,0.0170217,"Missing"
2013.mtsummit-wptp.13,I08-2088,0,0.0276276,"on tasks, Niehues and Waibel (2012) compare different approaches to adapt a SMT system towards a target domain using small amounts of parallel in-domain data, namely the backoff, the factored, and the already mentioned log-linear and fill-up techniques; the general outcome is that each of them is effective in improving non-adapted models and none is definitely better than each other, which is the best depending on how well the test data matches the indomain training data. This work deals with data selection as well, which is a problem widely investigated by the SMT community, see for example (Yasuda et al., 2008; Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011). We apply a standard selection technique (Moore and Lewis, 2010), but in a quite different scenario where the task-specific data is extremely small and the generic corpus is actually close to the domain of the task. 3 Adaptation Methods In this section we describe the techniques employed to adapt our SMT systems, namely data selection and translation, distortion and language model combination. 3.1 Data selection It has been believed for a long time that just adding more training data always improves performance of a statistic"
2013.mtsummit-wptp.13,W07-0717,0,0.0387197,"a discussion on the overall results. 2 Related Work Our work deals with MT adaptation in general, and incremental adaptation more specifically. Bertoldi et al. (2012) present an adaptation scenario where foreground translation and reordering models (TM) and language model (LM) of a phrase-based SMT system are incrementally trained on batches of fresh data and then paired to static background models. Similarly, the use of local and global models for incremental learning was previously proposed through a log-linear combination (Koehn and Schroeder, 2007), a mixture model (linear or log-linear) (Foster and Kuhn, 2007), the filling-up (Bisazza et al., 2011), or via ultraconservative updating (Liu et al., 2012). Sharon O’Brien, Michel Simard and Lucia Specia (eds.) Proceedings of MT Summit XIV Workshop on Post-editing Technology and Practice, Nice, September 2, 2013, p. 111–118. c 2013 The Authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. Bach et al. (2009) investigate how a speechto-speech translation system can adapt day-to-day from collected data on day one to improve performance on day two, similarly to us. However, the adaptation of the M"
2013.mtsummit-wptp.13,D10-1044,0,0.0217311,"ifferent approaches to adapt a SMT system towards a target domain using small amounts of parallel in-domain data, namely the backoff, the factored, and the already mentioned log-linear and fill-up techniques; the general outcome is that each of them is effective in improving non-adapted models and none is definitely better than each other, which is the best depending on how well the test data matches the indomain training data. This work deals with data selection as well, which is a problem widely investigated by the SMT community, see for example (Yasuda et al., 2008; Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011). We apply a standard selection technique (Moore and Lewis, 2010), but in a quite different scenario where the task-specific data is extremely small and the generic corpus is actually close to the domain of the task. 3 Adaptation Methods In this section we describe the techniques employed to adapt our SMT systems, namely data selection and translation, distortion and language model combination. 3.1 Data selection It has been believed for a long time that just adding more training data always improves performance of a statistical model, e.g. a n-gram LM. However, this is"
2014.amta-researchers.13,D11-1033,0,0.0121256,"d, which mostly includes EU legislative texts translated into 22 languages. Table 2 provides detailed statistics on the actual bitexts used for training purposes. In particular, the train entries refer to the whole generic training texts, while development set entries to additional data on which the parameters of the phrase-based MT model were optimized. The domain selection entry of the IT en→fr task refers to data selected from out-ofdomain texts (Giga English-French, United Nation, and Common Crawl corpora6 (Bojar et al., 2013)) by using the in-domain text as seed in the method proposed by Axelrod et al. (2011) and available within the XenC toolkit (Rousseau, 2013); this was done to augment the amount of training data, since the size of in-domain text available for that language pair (15.4/17.9 million words) is about four times smaller than for the other tasks. domain pair en→it IT en→fr en→it Legal en→fr en→es corpus segments train development set train domain selection development set train development set train development set train development set 5.4 M 2,156 1.1 M 1.2 M 4,755 2.7 M 181 2.8 M 600 2.3 M 700 tokens source target 57.2M 59.9M 26,080 28,137 15.4M 17.9M 20.0M 22.2M 26,747 30,100 61.4"
2014.amta-researchers.13,2013.mtsummit-papers.5,1,0.943654,"ed for capturing the repetitiveness of text. Indeed, in the case of MT related tasks, like the quality estimation of MT output, in addition to features computed on the source text, features have been proposed which involve the translated/target text or even the MT models: although they can be really effective, we focus our investigation to the source side only, since we are interested in deciding what kind of MT system is most suitable for translating a given text before having any MT engine at disposal. In this paper we experimentally assess the repetition rate, that we recently proposed in (Bertoldi et al., 2013) where no support to its effectiveness was provided, as a single light measure to characterize a full document to be translated. Roughly, the repetition rate computes the rate of event types (single words and n-grams) that occur more than once in a text; for making this statistics independent from the size of the document, it is computed on a fixed-size sliding window. We measured the prediction power of the repetition rate on several MT adaptation tasks and compared it against other text features that were proposed for very related NLP tasks. The comparison was carried out through a regressio"
2014.amta-researchers.13,I13-1185,0,0.045335,"Missing"
2014.amta-researchers.13,J10-4005,0,0.0180421,"analysis between feature values and MT performance gains by dynamically adapted versus non-adapted MT engines, on five different translation tasks. The main outcome of experiments is that the repetition rate correlates better than any other considered feature with the MT gains yielded by the online adaptation, although using all features jointly results in better predictions than with any single feature. 1 Introduction Language and content repetitiveness1 is a key factor for the successful deployment of translation memories (TMs) (Somers, 2003) as well as statistical machine translation (MT) (Koehn, 2010). The capability of a TM to provide useful translation suggestions for a text segment relies on the chance of finding segments with very similar content – i.e. with a significant percentage of overlapping words – inside a large repository of already translated texts. On the other hand, statistical MT also relies on the assumption that the segment to be translated shares with the training data a significant amount of patterns, from single words to groups of words. Advances on the integration of human post-editing into MT have recently revealed the potential of incremental and online MT adaptati"
2014.amta-researchers.13,P07-2045,1,0.0161214,"Missing"
2014.amta-researchers.13,P11-1132,0,0.0267725,"oportion of simple/complex sentences, ambiguity as the average of senses per word, word length as the proportion of syllables per word, lexical richness, and information load as the proportion of lexical words to tokens in (Ilisei et al., 2010); most frequent words and 3 Obfuscation is the strategy adopted by real plagiarists to rewrite their source passages in order to make detection more difficult. Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 168 a list of some hundred function words are instead used in (Islam and Hoenen, 2013) and (Koppel and Ordan, 2011), respectively. 3 Repetition Rate We recently introduced the repetition rate (Bertoldi et al., 2013) as a way to measure the repetitiveness inside a text, by looking at the rate of non-singleton n-gram types (n=1. . .4) it contains. As shown there, this rate decays exponentially with n. For combining values with exponential decay, a reasonable scheme is to average their logarithms, or equivalently to compute their geometric mean. Furthermore, in order to make the measure comparable across different sized documents, statistics are collected on a sliding window of one thousand words, and properl"
2014.amta-researchers.13,P02-1040,0,0.0900417,"s iterates over all sentences of the document to be translated. In our systems, the local model is implemented by a caching mechanism. The caching regards both translation and language models: phrase pairs extracted from the alignment of the source and post-edit are extracted and inserted into the cache-based translation model, while n-grams of the post-edit fill the cache-based language model. More details are provided in (Bertoldi et al., 2013). Note that in our experiments the post-editing is simulated by using human references. 5.5 Results and comments First of all, Table 3 provides BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and GTM (Turian et al., 2003) scores computed on the evaluation documents with respect to human references for each of the five considered translation tasks. In both domains, but especially for IT, the improvements over the static systems yielded by the dynamic adaptation technique are remarkable. Focusing on the BLEU score, in the IT domain it improves by more than 7 absolute points for English-to-Italian (57.5 to 64.6), and almost 15 absolute points for English-to-French (41.4 to 56.3); in the LGL domain, the gain is quite limited in English-to-Italian (1.5 absolu"
2014.amta-researchers.13,2006.amta-papers.25,0,0.0546353,"of the document to be translated. In our systems, the local model is implemented by a caching mechanism. The caching regards both translation and language models: phrase pairs extracted from the alignment of the source and post-edit are extracted and inserted into the cache-based translation model, while n-grams of the post-edit fill the cache-based language model. More details are provided in (Bertoldi et al., 2013). Note that in our experiments the post-editing is simulated by using human references. 5.5 Results and comments First of all, Table 3 provides BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and GTM (Turian et al., 2003) scores computed on the evaluation documents with respect to human references for each of the five considered translation tasks. In both domains, but especially for IT, the improvements over the static systems yielded by the dynamic adaptation technique are remarkable. Focusing on the BLEU score, in the IT domain it improves by more than 7 absolute points for English-to-Italian (57.5 to 64.6), and almost 15 absolute points for English-to-French (41.4 to 56.3); in the LGL domain, the gain is quite limited in English-to-Italian (1.5 absolute points), but definitely"
2014.amta-researchers.13,steinberger-etal-2006-jrc,0,0.0939907,"Missing"
2014.amta-researchers.13,tiedemann-2012-parallel,0,0.0298076,"Missing"
2014.amta-researchers.13,2003.mtsummit-papers.51,0,0.043002,"ted. In our systems, the local model is implemented by a caching mechanism. The caching regards both translation and language models: phrase pairs extracted from the alignment of the source and post-edit are extracted and inserted into the cache-based translation model, while n-grams of the post-edit fill the cache-based language model. More details are provided in (Bertoldi et al., 2013). Note that in our experiments the post-editing is simulated by using human references. 5.5 Results and comments First of all, Table 3 provides BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and GTM (Turian et al., 2003) scores computed on the evaluation documents with respect to human references for each of the five considered translation tasks. In both domains, but especially for IT, the improvements over the static systems yielded by the dynamic adaptation technique are remarkable. Focusing on the BLEU score, in the IT domain it improves by more than 7 absolute points for English-to-Italian (57.5 to 64.6), and almost 15 absolute points for English-to-French (41.4 to 56.3); in the LGL domain, the gain is quite limited in English-to-Italian (1.5 absolute points), but definitely notable – almost 5 points – fo"
2014.amta-researchers.13,W12-2019,0,0.129424,"ts over the use of single tokens, especially by introducing not too long n-grams (F¨urnkranz, 1998), outcome that we exploit by defining the repetition rate over 1- to 4-grams. Readability assessment is a form of text classification aiming at retrieving texts that suit a particular target reading level. In a school setting, it can help teachers to find texts appropriate to their students; other real-life contexts where it can play an important role are those involving people with intellectual disabilities, dyslexics, immigrant populations, and second or foreign language learners. Commendably, Vajjala and Meurers (2012) present dozens of features used in previous research on text readability and complexity and group them into three broad categories: lexical, syntactic and traditional features. Examples of features from the first group are the type-token ratio (see Section 4) and the lexical density, defined as the ratio of the number of lexical word tokens (nouns, adjectives, verbs, adverbs) and the number of all tokens (total number of words) in the analysed text. Syntactic features include mean length of clauses and sentences, and co-ordinate phrases and complex nominals per clause. The average sentence le"
2014.amta-researchers.13,W13-2201,0,\N,Missing
2014.iwslt-evaluation.5,P07-2045,1,0.0126412,"f introduction to the baseline MT system in Section 2 employed for all tasks, in Section 3 we overview the data selection techniques used to extract TED-related data from the available huge and generic monolingual and bilingual corpora. Then, in Section 4 we describe the methods applied to combine translation models, reordering models, and language models trained on multiple corpora. Sections 5-7 give details about the actual MT and SLT systems built for evaluation task. 2. Baseline SMT system All our task-specific systems rely on the well-known and state-of-the-art phrase-based Moses toolkit [1]; and exploit the huge amount of parallel and monolingual training data 1 http://www.ted.com/talks University of Trento ICT Doctoral School Trento, Italy 2 provided by the organizers. Our common baseline system features a statistical log-linear model including a phrasebased translation model (TM), a lexicalized phrase-based reordering models (RM), one or more language models (LMs), as well as distortion, word and phrase penalties. Tuning of the baseline system is performed on tst2010 by optimizing BLEU using Minimum Error Rate Training [2]. However, all available development data sets, namely"
2014.iwslt-evaluation.5,P03-1021,0,0.0306464,"-known and state-of-the-art phrase-based Moses toolkit [1]; and exploit the huge amount of parallel and monolingual training data 1 http://www.ted.com/talks University of Trento ICT Doctoral School Trento, Italy 2 provided by the organizers. Our common baseline system features a statistical log-linear model including a phrasebased translation model (TM), a lexicalized phrase-based reordering models (RM), one or more language models (LMs), as well as distortion, word and phrase penalties. Tuning of the baseline system is performed on tst2010 by optimizing BLEU using Minimum Error Rate Training [2]. However, all available development data sets, namely dev2010 and tst2010-2012, are included in the in-domain training data to build the systems actually employed for the 2014 evaluation campaign. The task-specific systems differ in the way training data are processed and filtered, and how the models are trained and combined. 3. Data Filtering The idea of data selection is to find the subset of sentences within an out-of-domain corpus that better fits with a given in-domain corpus. To this purpose, we follow the procedure described in [3], implementing the bilingual cross-entropy difference ["
2014.iwslt-evaluation.5,D11-1033,0,0.055327,"]. However, all available development data sets, namely dev2010 and tst2010-2012, are included in the in-domain training data to build the systems actually employed for the 2014 evaluation campaign. The task-specific systems differ in the way training data are processed and filtered, and how the models are trained and combined. 3. Data Filtering The idea of data selection is to find the subset of sentences within an out-of-domain corpus that better fits with a given in-domain corpus. To this purpose, we follow the procedure described in [3], implementing the bilingual cross-entropy difference [4], i.e. an adaptation of the cross-entropy difference scoring technique introduced by [5] toward bitext data selection, by means of XenC toolkit [6]. First, all sentence pairs of the out-of-domain corpus are associated with source- and target-side scores, each of which are computed as the basic technique proposes for the corresponding monolingual scenarios. We use the in-domain (TED) data as a seed and LMs of order 2.2 Then, the sentences are sorted according to the sum of these two scores. Finally, the optimal split between useful and useless sentences is found by minimizing the source-side pe"
2014.iwslt-evaluation.5,P10-2041,0,0.0976877,"cluded in the in-domain training data to build the systems actually employed for the 2014 evaluation campaign. The task-specific systems differ in the way training data are processed and filtered, and how the models are trained and combined. 3. Data Filtering The idea of data selection is to find the subset of sentences within an out-of-domain corpus that better fits with a given in-domain corpus. To this purpose, we follow the procedure described in [3], implementing the bilingual cross-entropy difference [4], i.e. an adaptation of the cross-entropy difference scoring technique introduced by [5] toward bitext data selection, by means of XenC toolkit [6]. First, all sentence pairs of the out-of-domain corpus are associated with source- and target-side scores, each of which are computed as the basic technique proposes for the corresponding monolingual scenarios. We use the in-domain (TED) data as a seed and LMs of order 2.2 Then, the sentences are sorted according to the sum of these two scores. Finally, the optimal split between useful and useless sentences is found by minimizing the source-side perplexity of a development set on growing percentages of the sorted corpus. In our experi"
2014.iwslt-evaluation.5,2011.iwslt-evaluation.18,1,0.892258,"velopment set. 4. Domain Adaptation In this section, we summarize several well-known techniques for domain adaptation we applied to build high-performance models for our SMT submissions. 2 This small LM order permits a very fast computation of the scores, without losing performance. 42 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 4.1. Translation model combination 4.3. Language model combination Three methods are applied in our submissions to combine the TM built on the available parallel training corpora: namely, fill-up [7, 8], back-off, and interpolation. Language models are built from the monolingual training data, as well as the target language of the parallel data. As the corpora available in the IWSLT evaluation come from a number of sources, we apply several methods to combine the LMs built on the available target language training corpora, rather than concatenating the data. 4.1.1. Fill-up In the fill-up approach, out-of-domain phrase pairs that do not appear in an in-domain (TED) phrase table are added, along with their scores – effectively filling the in-domain table with additional phrase translation opti"
2014.iwslt-evaluation.5,W07-0717,0,0.0911291,"The mixture LM type can be loaded by Moses as any other LM type. 4.3.2. Log-linear interpolation This technique, provided directly within the Moses toolkit, consists in the log-linear interpolation of the n-gram probabilities from all component LMs. The weight optimization is performed during the tuning of all Moses features. 4.4. Factored Trigger Models 4.1.3. Linear interpolation Linear interpolation of component models is a widely used approach for building a domain adapted multi-model. Approaches such as using monolingual data or pairwise ranking optimization to set interpolation weights [9, 10], perplexity minimization [11], and combining lemmatized and non-lemmatized models [12] have been used in the past for improved domain adaptation. In this paper, we leverage a recent work of [13] which exploits the use of source-side of the parallel in-domain corpus for domain adaptation. This approach calculates a similarity score (known as BLEU-PT) for each of the out-domain translation models on the source in-domain data. We use these similarity scores and further normalize them by the number of phrases seen in each of the corresponding out-domain phrase tables. These normalized scores are"
2014.iwslt-evaluation.5,N13-1035,0,0.0274451,"The mixture LM type can be loaded by Moses as any other LM type. 4.3.2. Log-linear interpolation This technique, provided directly within the Moses toolkit, consists in the log-linear interpolation of the n-gram probabilities from all component LMs. The weight optimization is performed during the tuning of all Moses features. 4.4. Factored Trigger Models 4.1.3. Linear interpolation Linear interpolation of component models is a widely used approach for building a domain adapted multi-model. Approaches such as using monolingual data or pairwise ranking optimization to set interpolation weights [9, 10], perplexity minimization [11], and combining lemmatized and non-lemmatized models [12] have been used in the past for improved domain adaptation. In this paper, we leverage a recent work of [13] which exploits the use of source-side of the parallel in-domain corpus for domain adaptation. This approach calculates a similarity score (known as BLEU-PT) for each of the out-domain translation models on the source in-domain data. We use these similarity scores and further normalize them by the number of phrases seen in each of the corresponding out-domain phrase tables. These normalized scores are"
2014.iwslt-evaluation.5,E12-1055,0,0.0263646,"d by Moses as any other LM type. 4.3.2. Log-linear interpolation This technique, provided directly within the Moses toolkit, consists in the log-linear interpolation of the n-gram probabilities from all component LMs. The weight optimization is performed during the tuning of all Moses features. 4.4. Factored Trigger Models 4.1.3. Linear interpolation Linear interpolation of component models is a widely used approach for building a domain adapted multi-model. Approaches such as using monolingual data or pairwise ranking optimization to set interpolation weights [9, 10], perplexity minimization [11], and combining lemmatized and non-lemmatized models [12] have been used in the past for improved domain adaptation. In this paper, we leverage a recent work of [13] which exploits the use of source-side of the parallel in-domain corpus for domain adaptation. This approach calculates a similarity score (known as BLEU-PT) for each of the out-domain translation models on the source in-domain data. We use these similarity scores and further normalize them by the number of phrases seen in each of the corresponding out-domain phrase tables. These normalized scores are then used as linear interpolat"
2014.iwslt-evaluation.5,P07-2046,0,0.0647212,"olation This technique, provided directly within the Moses toolkit, consists in the log-linear interpolation of the n-gram probabilities from all component LMs. The weight optimization is performed during the tuning of all Moses features. 4.4. Factored Trigger Models 4.1.3. Linear interpolation Linear interpolation of component models is a widely used approach for building a domain adapted multi-model. Approaches such as using monolingual data or pairwise ranking optimization to set interpolation weights [9, 10], perplexity minimization [11], and combining lemmatized and non-lemmatized models [12] have been used in the past for improved domain adaptation. In this paper, we leverage a recent work of [13] which exploits the use of source-side of the parallel in-domain corpus for domain adaptation. This approach calculates a similarity score (known as BLEU-PT) for each of the out-domain translation models on the source in-domain data. We use these similarity scores and further normalize them by the number of phrases seen in each of the corresponding out-domain phrase tables. These normalized scores are then used as linear interpolation coefficients. In this paper, we perform linear interp"
2014.iwslt-evaluation.5,C14-1105,0,0.0191618,"of the n-gram probabilities from all component LMs. The weight optimization is performed during the tuning of all Moses features. 4.4. Factored Trigger Models 4.1.3. Linear interpolation Linear interpolation of component models is a widely used approach for building a domain adapted multi-model. Approaches such as using monolingual data or pairwise ranking optimization to set interpolation weights [9, 10], perplexity minimization [11], and combining lemmatized and non-lemmatized models [12] have been used in the past for improved domain adaptation. In this paper, we leverage a recent work of [13] which exploits the use of source-side of the parallel in-domain corpus for domain adaptation. This approach calculates a similarity score (known as BLEU-PT) for each of the out-domain translation models on the source in-domain data. We use these similarity scores and further normalize them by the number of phrases seen in each of the corresponding out-domain phrase tables. These normalized scores are then used as linear interpolation coefficients. In this paper, we perform linear interpolation of out-ofdomain models which results in one translation model. The in-domain translation model is th"
2014.iwslt-evaluation.5,2012.eamt-1.60,1,0.798668,"about the EU-Bridge system are available in a companion paper [23]. 6. German-English MT task Our German-English systems are built on top of the baseline system (see Section 2. Each system contains one translation model, reordering model, language model, the factored trigger model and operation sequence model; these models are then combined in a standard log-linear fashion. The training data is composed of several publicly available corpora provided in the IWSLT MT and the WMT 2014 translation tasks. As parallel data the following corpora were taken into account: WIT3 (version 2014-01) (TED) [18], German-English Europarl (version 7) (EP), Common Crawl (CC), MultiUN (UN), and the News Commentary (NC) corpus as distributed by the organizers of the WMT 2014. We used all the available monolingual corpora provided by the WMT 2014 translation task. The target side of the parallel corpora is also used to train our LMs. Corpus TED CC EP UN NC unselected De En Segm Words Words 171K 3.3M 3.46M 2.4M 56M 58M 1.9M 52M 53M 162K 5.8M 5.66M 200K 5.25M 5.0M Segm 171K 462K 188K 45K 59K selected De En Words Words 3.3M 3.46M 10.5M 10.7M 3.58M 3.64M 1.59M 1.52M 1.4M 1.3M Table 2: Statistics of the paralle"
2014.iwslt-evaluation.5,W08-0509,0,0.0224987,"Missing"
2014.iwslt-evaluation.5,N04-1022,0,0.129273,"Missing"
2014.iwslt-evaluation.5,2014.iwslt-evaluation.7,1,0.801513,"cn MT De-En tst2013 BLEU TER 38.20 44.83 38.13 44.83 37.88 45.05 36.27 47.48 38.16 44.90 38.04 44.93 37.95 45.08 36.73 46.44 37.89 44.98 25.45 55.59 25.76 55.80 tst2014 BLEU TER 34.24 46.75 34.18 46.61 33.79 47.02 32.07 50.02 33.98 47.03 34.02 46.87 33.67 47.24 32.49 48.81 34.03 46.86 20.52 63.54 20.37 63.37 Table 1: Case-sensitive BLEU and TER results for FBK’s submissions to the English-French and German-English MT tasks. The contrastive run 5, was also applied into the joint submission by the EU-Bridge project5 partners; details about the EU-Bridge system are available in a companion paper [23]. 6. German-English MT task Our German-English systems are built on top of the baseline system (see Section 2. Each system contains one translation model, reordering model, language model, the factored trigger model and operation sequence model; these models are then combined in a standard log-linear fashion. The training data is composed of several publicly available corpora provided in the IWSLT MT and the WMT 2014 translation tasks. As parallel data the following corpora were taken into account: WIT3 (version 2014-01) (TED) [18], German-English Europarl (version 7) (EP), Common Crawl (CC),"
2014.iwslt-evaluation.5,P13-2071,0,0.0418665,"Missing"
2014.iwslt-evaluation.5,2011.iwslt-papers.7,0,0.0471624,"nally, we describe our experimental results. 7.1. Preprocessing Prior to translating ASR outputs, we perform the following normalization steps to make them compatible with our phrase-based SMT system. Similar to the MT track, we tokenize ASR outputs using the scripts provided by Moses. After tokenization, we recase the outputs. The recaser system is trained using the Moses scripts and a 3-gram LM. The recaser model and language models are trained on a concatenation of TED and WMT News Commentary data. Finally, we insert punctuation via monotonic machine translation, similar to the approach of [29]. 7.2. Phoneme-motivated Text Normalization A SMT system trained only on transcripts and other text data results yields a search space that is inaccessible by ASR outputs that may contain errors and text normalization issues. In an ideal scenario, we would train our spoken language translation system on a combination of text corpora and speech recognition outputs with reference translations; however, a sufficiently large amount of such speech corpora is not readily available. In order to make our machine translation system more tolerant of potential ASR errors, we use a similar phoneme-motivat"
2014.iwslt-evaluation.5,2013.iwslt-evaluation.4,0,0.0340555,"scripts and other text data results yields a search space that is inaccessible by ASR outputs that may contain errors and text normalization issues. In an ideal scenario, we would train our spoken language translation system on a combination of text corpora and speech recognition outputs with reference translations; however, a sufficiently large amount of such speech corpora is not readily available. In order to make our machine translation system more tolerant of potential ASR errors, we use a similar phoneme-motivated text normalization approach as outlined in our previous year’s submission [30] to generate additional bilingual training data from the text corpora provided in the evaluation. We adapt the MT training data into ASR-like output to anticipate ASR errors and text normalization issues during SMT model training. We do this by leveraging several components from a target ASR system. In our experiments, we use the FBK’s Kaldi English ASR system, which was used in our ASR submission [31]. Similar to [32], we transform the text corpora into synthetic ASR outputs by first converting the text corpora into phonemes and then “translating” each phoneme sequence back into words that mo"
2014.iwslt-evaluation.5,E03-1076,0,0.134504,"Missing"
2014.iwslt-evaluation.5,D08-1089,0,0.0878675,"Missing"
2014.iwslt-evaluation.7,D14-1003,1,0.921764,"slation of spoken language. The IWSLT TED talks task constitutes an interesting framework for empirical testing of some of the systems for spoken language translation which are developed as part of the project. In this work, we describe the EU-BRIDGE submissions to the 2014 IWSLT translation task. This year, we combined several single systems of RWTH, UEDIN, KIT, and FBK for the German→English SLT, German→English MT, English→German MT, and English→French MT tasks. Additionally to the standard system combination pipeline presented in [1, 2], we applied a recurrent neural network rescoring step [3] for the English→French MT task. Similar cooperative approaches based on system combination have proven to be valuable for machine translation in previous joint submissions, e.g. [4, 5]. 2. RWTH Aachen University RWTH applied the identical training pipeline and models on both language pairs: The state-of-the-art phrase-based baseline systems were augmented with a hierarchical reordering model, several additional language models (LMs) and maximum expected B LEU training for phrasal, lexical and reordering models. Further, RWTH employed rescoring with novel recurrent neural language and translat"
2014.iwslt-evaluation.7,W10-1738,1,0.885248,"and maximum expected B LEU training for phrasal, lexical and reordering models. Further, RWTH employed rescoring with novel recurrent neural language and translation models. The same systems were used for the SLT track, where RWTH ad57 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 ditionally performed punctuation prediction on the automatic transcriptions employing hierarchical phrase-based translation. Both the phrase-based and the hierarchical decoder are implemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-"
2014.iwslt-evaluation.7,P03-1021,0,0.488353,"employed rescoring with novel recurrent neural language and translation models. The same systems were used for the SLT track, where RWTH ad57 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 ditionally performed punctuation prediction on the automatic transcriptions employing hierarchical phrase-based translation. Both the phrase-based and the hierarchical decoder are implemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing."
2014.iwslt-evaluation.7,popovic-ney-2006-pos,1,0.798687,"th and 5th, 2014 ditionally performed punctuation prediction on the automatic transcriptions employing hierarchical phrase-based translation. Both the phrase-based and the hierarchical decoder are implemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selectio"
2014.iwslt-evaluation.7,P13-2121,1,0.819366,"mplemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWT"
2014.iwslt-evaluation.7,P10-2041,0,0.0916594,"rdering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU ob"
2014.iwslt-evaluation.7,E99-1010,0,0.0737032,"them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for"
2014.iwslt-evaluation.7,D13-1138,1,0.85854,"RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumv"
2014.iwslt-evaluation.7,P12-1031,0,0.0125863,"lection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumvent over-fitting. Here, RWTH followed an approach similar to [18], where each feature type was condensed into a single feature for the log-linear model combination. In the first pass, RWTH trained phrase pair and"
2014.iwslt-evaluation.7,P10-1049,1,0.833909,"the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumvent over-fitting. Here, RWTH followed an approach similar to [18], where each feature type was condensed into a single feature for the log-linear model combination. In the first pass, RWTH trained phrase pair and phrase-internal word pair features, and in the second pass a hierarchical reordering model, resulting altogether in an additional eight models for log-linear combination. Recurrent Neural Network Models All systems applied rescoring on 1000-best lists using recurrent language and translation models. The recurrency was handled with the long short-term memory (LST"
2014.iwslt-evaluation.7,D14-1132,0,0.157332,"M. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumvent over-fitting. Here, RWTH followed an approach similar to [18], where each feature type was condensed into a single feature for the log-linear model combination. In the first pass, RWTH trained phrase pair and phrase-internal word pair features, and in the second pass a hierarchical reordering model, resulting altogether in an additional eight models for log-linear combination. Recurrent Neural Network Models All systems applied rescoring on 1000-best lists using recurrent language and translation models. The recurrency was handled with the long short-term memory (LSTM) architecture [19] and RWTH used a class-factored output layer for increased efficienc"
2014.iwslt-evaluation.7,2011.iwslt-papers.7,1,0.944851,"ort-term memory (LSTM) architecture [19] and RWTH used a class-factored output layer for increased efficiency as described in [20]. All neural networks were trained on the TED portion of the data with 2000 word classes. In addition to the recurrent language model (RNN-LM), RWTH applied the deep bidirectional word-based translation model (RNN-BTM) described in [3], which is capable of taking the full source context into account for each translation decision. Spoken Language Translation For the SLT task, RWTH reintroduced punctuation and case information before the actual translation similar to [21]. However, RWTH employed a hierarchical phrase-based system with a maximum of one nonterminal symbol per rule in place of a phrase-based system. A punctuation prediction system based on hierarchical translation is able to capture long-range dependencies between words and punctuation marks and is more robust for unseen word sequences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the f"
2014.iwslt-evaluation.7,2014.iwslt-papers.17,1,0.734908,"RWTH reintroduced punctuation and case information before the actual translation similar to [21]. However, RWTH employed a hierarchical phrase-based system with a maximum of one nonterminal symbol per rule in place of a phrase-based system. A punctuation prediction system based on hierarchical translation is able to capture long-range dependencies between words and punctuation marks and is more robust for unseen word sequences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the final translation systems from the MT track could be kept completely unchanged. 3. University of Edinburgh The UEDIN translation engines [23] are based on the open source Moses toolkit [24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided"
2014.iwslt-evaluation.7,P07-2045,1,0.0190208,"n hierarchical translation is able to capture long-range dependencies between words and punctuation marks and is more robust for unseen word sequences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the final translation systems from the MT track could be kept completely unchanged. 3. University of Edinburgh The UEDIN translation engines [23] are based on the open source Moses toolkit [24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26]"
2014.iwslt-evaluation.7,N04-1035,0,0.0565459,"equences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the final translation systems from the MT track could be kept completely unchanged. 3. University of Edinburgh The UEDIN translation engines [23] are based on the open source Moses toolkit [24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26] and symmetrizing the two trained alignments. Word alignments for the SLT track system were created using fast align [27]. The SRILM toolkit [2"
2014.iwslt-evaluation.7,W08-0509,0,0.192359,"[24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26] and symmetrizing the two trained alignments. Word alignments for the SLT track system were created using fast align [27]. The SRILM toolkit [28] was employed to train 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six"
2014.iwslt-evaluation.7,N13-1073,0,0.0453396,"e syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26] and symmetrizing the two trained alignments. Word alignments for the SLT track system were created using fast align [27]. The SRILM toolkit [28] was employed to train 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sp"
2014.iwslt-evaluation.7,C14-1041,1,0.839592,"ndividual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable"
2014.iwslt-evaluation.7,N12-1047,0,0.0681194,"them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is"
2014.iwslt-evaluation.7,P02-1040,0,0.0918061,"d to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is what UEDIN did by trai"
2014.iwslt-evaluation.7,2006.iwslt-papers.1,1,0.862433,"els over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT tas"
2014.iwslt-evaluation.7,2012.iwslt-papers.15,1,0.927241,"els over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT tas"
2014.iwslt-evaluation.7,P05-1066,1,0.733044,"ferrable to punctuate the text before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT task system, prereordering [37] and compound splitting [38] were applied to the German source language side in a preprocessing step. A factored translation model [39] was employed. Source side factors are word, lemma, part-of-speech (POS) tag, and morphological tag. Target side factors are word, lemma, and POS tag. UEDIN incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags (trained on WIT3 only) and a 7-gram LM over lemmas (trained on WIT3 only). Model weights were optimized on a concatenation of dev2010 and dev2012. English→French MT UEDIN contributed two phrase-based systems for the"
2014.iwslt-evaluation.7,E03-1076,1,0.858704,"xt before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT task system, prereordering [37] and compound splitting [38] were applied to the German source language side in a preprocessing step. A factored translation model [39] was employed. Source side factors are word, lemma, part-of-speech (POS) tag, and morphological tag. Target side factors are word, lemma, and POS tag. UEDIN incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags (trained on WIT3 only) and a 7-gram LM over lemmas (trained on WIT3 only). Model weights were optimized on a concatenation of dev2010 and dev2012. English→French MT UEDIN contributed two phrase-based systems for the English→French EU-BRIDGE sy"
2014.iwslt-evaluation.7,2012.amta-papers.9,1,0.84942,"arallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT task system, prereordering [37] and compound splitting [38] were applied to the German source language side in a preprocessing step. A factored translation model [39] was employed. Source side factors are word, lemma, part-of-speech (POS) tag, and morphological tag. Target side factors are word, lemma, and POS tag. UEDIN incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags (trained on WIT3 only) and a 7-gram LM over lemmas (trained on WIT3 only). Model weights were optimized on a concatenation of dev2010 and dev2012. English→French MT UEDIN contributed two phrase-based systems for the English→French EU-BRIDGE system combination. Both comprise Brown clusters with 200 classes as additional factors on source and target"
2014.iwslt-evaluation.7,D08-1089,0,0.176922,"ign [27]. The SRILM toolkit [28] was employed to train 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation a"
2014.iwslt-evaluation.7,W14-3324,1,0.784121,"ical tag. UEDIN-A was trained with all corpora, whereas for UEDIN-B the parallel training data was restricted to the indomain WIT3 corpus. Additional features of the systems are: a 5-gram LM over Brown clusters, a 7-gram LM over morphological tags (UEDIN-A: trained on all data, UEDIN-B: trained on WIT3 only), and a 7-gram LM over POS tags (UEDIN-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house ph"
2014.iwslt-evaluation.7,2012.iwslt-papers.17,1,0.881764,"ain 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic diff"
2014.iwslt-evaluation.7,C04-1024,0,0.0400394,"ereas for UEDIN-B the parallel training data was restricted to the indomain WIT3 corpus. Additional features of the systems are: a 5-gram LM over Brown clusters, a 7-gram LM over morphological tags (UEDIN-A: trained on all data, UEDIN-B: trained on WIT3 only), and a 7-gram LM over POS tags (UEDIN-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models wer"
2014.iwslt-evaluation.7,2011.iwslt-evaluation.18,1,0.873679,"ined on WIT3 only), and a 7-gram LM over POS tags (UEDIN-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standa"
2014.iwslt-evaluation.7,W14-3362,1,0.610881,"N-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for"
2014.iwslt-evaluation.7,W14-4018,1,0.774295,"ptimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In t"
2014.iwslt-evaluation.7,2011.iwslt-evaluation.9,1,0.861968,"m with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were"
2014.iwslt-evaluation.7,2007.tmi-papers.21,0,0.0614729,"ta. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabiliti"
2014.iwslt-evaluation.7,W09-0413,1,0.842557,"pora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the tra"
2014.iwslt-evaluation.7,W13-0805,1,0.85195,"ifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual langu"
2014.iwslt-evaluation.7,W08-1006,0,0.0150981,"k, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the ta"
2014.iwslt-evaluation.7,2012.amta-papers.19,1,0.839901,"e rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the task and to better model the sentence structure using a class-based LM. For the German→English task, KIT used one LM trained on all data, an in-domain LM trained only on the WIT3 corpus, and one LM trained on 5M sentences selected using cross-entropy difference [13]. As classes KIT used the clusters obtained using the mkcls algorithm on the WI"
2014.iwslt-evaluation.7,W11-2124,1,0.902739,"for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the task and to better model the sentence structure using a class-based LM. For the German→English task, KIT used one LM trained on all data, an in-domain LM trained only on the WIT3 corpus, and one LM trained on 5M sentences selected using cross-entropy difference [13]. As classes KIT used the clusters obtained using the mkcls algorithm on the WIT3 corpus. For German↔ English, KIT used a 9-gram LM with 100 or 1000 clusters and for the English→French MT task, a cl"
2014.iwslt-evaluation.7,W13-2264,1,0.835602,"ed by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the task and to better model the sentence structure using a class-based LM. For the German→English task, KIT used one LM trained on all data, an in-domain LM trained only on the WIT3 corpus, and one LM trained on 5M sentences selected using cross-entropy difference [13]. As classes KIT used the clusters obtained using the mkcls algorithm on the WIT3 corpus. For German↔ English, KIT used a 9-gram LM with 100 or 1000 clusters and for the English→French MT task, a cluster-based 4-gram LM was trained on 500 clusters. For English→German"
2014.iwslt-evaluation.7,2012.eamt-1.60,1,0.892622,"Missing"
2014.iwslt-evaluation.7,D11-1033,0,0.167316,"Missing"
2014.iwslt-evaluation.7,W05-0909,0,0.085167,"m multiple hypotheses which are outputs of different translation engines. The consensus translations can be better in terms of translation quality than any of the individual hypotheses. To combine the engines of the project partners for the EU-BRIDGE joint setups, we applied a system combination implementation that has been developed at RWTH Aachen University [1]. In Fig. 1 an overview is illustrated. We first address the generation of a confusion network (CN) from I input translations. For that we need a pairwise alignment between all input hypotheses. This alignment is calculated via METEOR [60]. The hypotheses are then reordered to match the word order of a selected skeleton hypothesis. Instead of using only one of the input hypothesis as skeleton, we generate I different CNs, each having one of the input systems as skeleton. The final lattice is the union of all I previous generated CNs. In Fig. 2 an example confusion network of I = 4 input translations with one skeleton translation is illustrated. Between two adjacent nodes, we always have a choice between the I different system output words. The confusion network decoding step involves determining the shortest path through the ne"
2014.iwslt-evaluation.7,2006.amta-papers.25,0,0.0356913,"andard set of models is a word penalty, a 3-gram language model trained on the input hypotheses, and for each system one binary voting feature. During decoding the binary voting feature for system i (1 ≤ i ≤ I) is 1 iff the word is from system i, otherwise 0. The M different model weights λm are trained with MERT [8]. the red cab the a a red blue green train car car Figure 2: System A: the red cab ; System B: the red train ; System C: a blue car ; System D: a green car ; Reference: the blue car . 7. Results In this section, we present our experimental results. All reported B LEU [34] and T ER [61] scores are case-sensitive with one reference. All system combination results have been generated with RWTH’s open source system combination implementation Jane [1]. German→English SLT For the German→English SLT task, we combined three different individual systems generated by UEDIN, KIT, and RWTH. Experimental results are given in Table 1. The final system combination yields improvements of 1.5 points in B LEU and 1.2 points in T ER compared to the best single system (KIT). All single systems as well as the system combination parameters were tuned on dev2012. For this year’s IWSLT SLT track,"
2014.iwslt-evaluation.7,E06-1005,1,\N,Missing
2014.iwslt-evaluation.7,P11-1105,1,\N,Missing
2014.iwslt-evaluation.7,W10-1711,1,\N,Missing
2014.iwslt-evaluation.7,2010.iwslt-evaluation.22,1,\N,Missing
2014.iwslt-evaluation.7,E14-2008,1,\N,Missing
2014.iwslt-evaluation.7,2014.iwslt-evaluation.6,1,\N,Missing
2014.iwslt-evaluation.7,J03-1002,1,\N,Missing
2014.iwslt-evaluation.7,C12-3061,1,\N,Missing
2014.iwslt-evaluation.7,2013.iwslt-evaluation.16,1,\N,Missing
2014.iwslt-evaluation.7,W14-3310,1,\N,Missing
C14-2028,2013.mtsummit-papers.5,1,0.880457,"Missing"
C14-2028,2013.mtsummit-wptp.13,1,0.900099,"Missing"
C14-2028,2012.amta-papers.22,1,0.865102,"Missing"
C14-2028,2013.mtsummit-wptp.10,0,0.135035,"Missing"
C14-2028,W13-2231,1,0.678754,"Missing"
C14-2028,P14-1067,1,0.806908,"Missing"
C14-2028,2013.mtsummit-wptp.7,1,\N,Missing
E06-2002,2005.mtsummit-posters.19,0,0.0175623,"del-4. Starting from the parallel training corpus, provided with direct and inverted alignments, the socalled union alignment (Och and Ney, 2003) is computed. Phrase-pairs are extracted from each sentence pair which correspond to sub-intervals of the source and target positions, J and I, such that the union alignment links all positions of J into I and all positions of I into J. In general, phrases are extracted with maximum length in the source and target defined by the parameters Jmax and Imax . All such phrase-pairs are efficiently computed by an 2 algorithm with complexity O(lImax Jmax ) (Cettolo et al., 2005). Given all phrase-pairs extracted from the training corpus, lexicon probabilities and fertility probabilities are estimated. Target language models (LMs) used by the decoder and rescoring modules are, respectively, estimated from 3-gram and 4-gram statistics by applying the modified Kneser-Ney smoothing method (Goodman and Chen, 1998). LMs are estimated with an in-house software toolkit which also provides a compact binary representation of the LM which is used by the decoder. 3 Demo Architecture Figure 1 shows the two-layer architecture of the demo. At the bottom lie the programs that provid"
E06-2002,W05-0835,0,0.0137666,"interface of the demo is described. 1 http://www.nist.gov/speech/tests/mt/ http://www.slt.atr.jp/IWSLT2004/ 3 http://www.is.cs.cmu.edu/iwslt2005/ 2 Exploiting the maximum entropy (Berger et al., 1996) framework, the conditional distribution Pr(e, a |f ) can be determined through suitable real valued functions (called features) hr (e, f , a), r = 1 . . . R, and takes the parametric form: pλ (e, a |f ) ∝ exp{ R X λr hr (e, f , a)} r=1 The ITC-irst system (Chen et al., 2005) is based on a log-linear model which extends the original IBM Model 4 (Brown et al., 1993) to phrases (Koehn et al., 2003; Federico and Bertoldi, 2005). In particular, target strings e are built from sequences of phrases e˜1 . . . e˜l . For each target phrase e˜ the corresponding source phrase within the source string is identified through three random quantities: the fertility φ, which establishes its length; the permutation πi , which sets its first position; the tablet f˜, which tells its word string. Notice that target phrases might have fertility equal to zero, hence they do not translate any 91 source word. Moreover, uncovered source positions are associated to a special target word (null) according to specific fertility and permutatio"
E06-2002,N03-1017,0,0.00726484,"ion 5 the Web-based interface of the demo is described. 1 http://www.nist.gov/speech/tests/mt/ http://www.slt.atr.jp/IWSLT2004/ 3 http://www.is.cs.cmu.edu/iwslt2005/ 2 Exploiting the maximum entropy (Berger et al., 1996) framework, the conditional distribution Pr(e, a |f ) can be determined through suitable real valued functions (called features) hr (e, f , a), r = 1 . . . R, and takes the parametric form: pλ (e, a |f ) ∝ exp{ R X λr hr (e, f , a)} r=1 The ITC-irst system (Chen et al., 2005) is based on a log-linear model which extends the original IBM Model 4 (Brown et al., 1993) to phrases (Koehn et al., 2003; Federico and Bertoldi, 2005). In particular, target strings e are built from sequences of phrases e˜1 . . . e˜l . For each target phrase e˜ the corresponding source phrase within the source string is identified through three random quantities: the fertility φ, which establishes its length; the permutation πi , which sets its first position; the tablet f˜, which tells its word string. Notice that target phrases might have fertility equal to zero, hence they do not translate any 91 source word. Moreover, uncovered source positions are associated to a special target word (null) according to spe"
E06-2002,J03-1002,0,0.00280669,"of generated theories some approximations are introduced during the search: less promising theories are pruned off (beam search) and a new source position is selected by limiting the number of vacant positions on the left-hand and the distance from the left most vacant position (re-ordering constraints). 2.3 Phrase extraction and model training Training of the phrase-based translation model requires a parallel corpus provided with wordalignments in both directions, i.e. from source to target positions, and viceversa. This preprocessing step can be accomplished by applying the GIZA++ toolkit (Och and Ney, 2003) that provides Viterbi alignments based on IBM Model-4. Starting from the parallel training corpus, provided with direct and inverted alignments, the socalled union alignment (Och and Ney, 2003) is computed. Phrase-pairs are extracted from each sentence pair which correspond to sub-intervals of the source and target positions, J and I, such that the union alignment links all positions of J into I and all positions of I into J. In general, phrases are extracted with maximum length in the source and target defined by the parameters Jmax and Imax . All such phrase-pairs are efficiently computed b"
E06-2002,takezawa-etal-2002-toward,0,0.0141419,"concerned, all the languages are encoded in UTF8: this allows to manage the processing phase in an uniform way and to render graphically different character sets. 4 The supported language-pairs Although there is no theoretical limit to the number of supported language-pairs, the current version of the demo provides translations to English from three source languages: Arabic, Chinese and The Arabic-to-English system has been trained with the data provided by the International Workshop on Spoken Language Translation 2005 The context is that of the Basic Traveling Expression Corpus (BTEC) task (Takezawa et al., 2002). BTEC is a multilingual speech corpus which contains sentences coming from phrase books for tourists. Training set includes 20k sentences containing 159K Arabic and 182K English running words; vocabulary size is 18K for Arabic, 7K for English. Chinese-to-English (Newswire) The Chinese-to-English system has been trained with the data provided by the NIST MT Evaluation Campaign 2005 , large-data condition. In this case parallel data are mainly news-wires provided by news agencies. Training set includes 71M Chinese and 77M English running words; vocabulary size is 157K for Chinese, 214K for Engl"
E06-2002,J96-1002,0,0.0194882,"se-based Statistical Machine Translation system which can be accessed by means of a Web page. Section 2 presents the general log-linear framework to SMT and gives an overview of our phrase-based SMT system. In section 3 the software architecture of the demo is outlined. Section 4 focuses on the currently supported language-pairs: Arabic-to-English, Chinese-toEnglish and Spanish-to-English. In section 5 the Web-based interface of the demo is described. 1 http://www.nist.gov/speech/tests/mt/ http://www.slt.atr.jp/IWSLT2004/ 3 http://www.is.cs.cmu.edu/iwslt2005/ 2 Exploiting the maximum entropy (Berger et al., 1996) framework, the conditional distribution Pr(e, a |f ) can be determined through suitable real valued functions (called features) hr (e, f , a), r = 1 . . . R, and takes the parametric form: pλ (e, a |f ) ∝ exp{ R X λr hr (e, f , a)} r=1 The ITC-irst system (Chen et al., 2005) is based on a log-linear model which extends the original IBM Model 4 (Brown et al., 1993) to phrases (Koehn et al., 2003; Federico and Bertoldi, 2005). In particular, target strings e are built from sequences of phrases e˜1 . . . e˜l . For each target phrase e˜ the corresponding source phrase within the source string is"
E06-2002,J93-2003,0,0.00522389,"and Spanish-to-English. In section 5 the Web-based interface of the demo is described. 1 http://www.nist.gov/speech/tests/mt/ http://www.slt.atr.jp/IWSLT2004/ 3 http://www.is.cs.cmu.edu/iwslt2005/ 2 Exploiting the maximum entropy (Berger et al., 1996) framework, the conditional distribution Pr(e, a |f ) can be determined through suitable real valued functions (called features) hr (e, f , a), r = 1 . . . R, and takes the parametric form: pλ (e, a |f ) ∝ exp{ R X λr hr (e, f , a)} r=1 The ITC-irst system (Chen et al., 2005) is based on a log-linear model which extends the original IBM Model 4 (Brown et al., 1993) to phrases (Koehn et al., 2003; Federico and Bertoldi, 2005). In particular, target strings e are built from sequences of phrases e˜1 . . . e˜l . For each target phrase e˜ the corresponding source phrase within the source string is identified through three random quantities: the fertility φ, which establishes its length; the permutation πi , which sets its first position; the tablet f˜, which tells its word string. Notice that target phrases might have fertility equal to zero, hence they do not translate any 91 source word. Moreover, uncovered source positions are associated to a special targ"
E06-2002,2005.iwslt-1.11,1,\N,Missing
E06-2002,P03-1021,0,\N,Missing
E17-2045,Q17-1024,0,0.0617671,"Missing"
E17-2045,W14-3363,0,0.0202907,"-Domain Machine Translation Multi-domain machine translation is very wellstudied in the field of statistical phrase-based MT. The approaches proposed for this issue vary from learning a single model from pooled training data, 280 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 280–284, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics to more complicated (log-)linear interpolations of multiple models using mixture models (Foster and Kuhn, 2007) and linear mixture models (Carpuat et al., 2014). However, being a very new field of research, to the best of our knowledge, there is no work on developing multi-domain NMT systems. However, to the best of our knowledge, there is still no work on developing multi-domain systems (i.e. generic/multi-purpose systems trained with all the data available at a given time) within the stateof-the-art NMT framework. Indeed, though interesting and well motivated from an applicationoriented perspective (e.g. think about a translation company looking for a generic MT backbone usable for jobs coming from any domain), this issue is still unexplored. The c"
E17-2045,N12-1047,0,0.0332362,"ra, after pre-processing. Experimental Setup 3.1 Segments 147.7K 238.4K 689.2K 163.2K 34.5K 38.4K 9.0K 40.3K 2.6M 1.7M 3.2 Phrase-based SMT The experiments of the phrase-based SMT systems are carried out using the open source Moses All these corpora are available in http://opus.lingfil.uu.se 281 4 toolkit (Koehn et al., 2007). The word alignment models are trained using fast-align (Dyer et al., 2013). In our experiments we used 5-gram language models trained with modified Kneser-Ney smoothing using KenLM toolkit (Heafield et al., 2013). The weights of the parameters are tuned with batch MIRA (Cherry and Foster, 2012) to maximize BLEU on the development set. Development set is a combination of all the development corpora of all the domains. 3.3 Table 3 presents the results of the generic systems (PBMT gen. and NMT gen.) and the NMT system adapted to the concatenation of all the eight specific domains (NMT-adp.jnt), as well as the NMT systems which are specifically adapted to each domain separately (NMT-adp.sep). In the case of NMT-adp.jnt and NMT-adp.sep we used the best model of the NMT gen. and adapted it to their corresponding training corpora by continuing the training for several epochs, using the tra"
E17-2045,P07-2045,1,0.014309,"ice (OOffice), PHP, Ubuntu, and translated UN documents (UNTM).1 Since the size of these corpora are relatively small for training robust data-driven MT systems, 1 Tokens 3.1M 1.7M 10.8M 1.0M 389.0K 259.0K 47.7K 913.8K 57.8M 39.6M Table 1: Statistics of the English side of the original corpora, after pre-processing. Experimental Setup 3.1 Segments 147.7K 238.4K 689.2K 163.2K 34.5K 38.4K 9.0K 40.3K 2.6M 1.7M 3.2 Phrase-based SMT The experiments of the phrase-based SMT systems are carried out using the open source Moses All these corpora are available in http://opus.lingfil.uu.se 281 4 toolkit (Koehn et al., 2007). The word alignment models are trained using fast-align (Dyer et al., 2013). In our experiments we used 5-gram language models trained with modified Kneser-Ney smoothing using KenLM toolkit (Heafield et al., 2013). The weights of the parameters are tuned with batch MIRA (Cherry and Foster, 2012) to maximize BLEU on the development set. Development set is a combination of all the development corpora of all the domains. 3.3 Table 3 presents the results of the generic systems (PBMT gen. and NMT gen.) and the NMT system adapted to the concatenation of all the eight specific domains (NMT-adp.jnt),"
E17-2045,N13-1073,0,0.0200347,"ze of these corpora are relatively small for training robust data-driven MT systems, 1 Tokens 3.1M 1.7M 10.8M 1.0M 389.0K 259.0K 47.7K 913.8K 57.8M 39.6M Table 1: Statistics of the English side of the original corpora, after pre-processing. Experimental Setup 3.1 Segments 147.7K 238.4K 689.2K 163.2K 34.5K 38.4K 9.0K 40.3K 2.6M 1.7M 3.2 Phrase-based SMT The experiments of the phrase-based SMT systems are carried out using the open source Moses All these corpora are available in http://opus.lingfil.uu.se 281 4 toolkit (Koehn et al., 2007). The word alignment models are trained using fast-align (Dyer et al., 2013). In our experiments we used 5-gram language models trained with modified Kneser-Ney smoothing using KenLM toolkit (Heafield et al., 2013). The weights of the parameters are tuned with batch MIRA (Cherry and Foster, 2012) to maximize BLEU on the development set. Development set is a combination of all the development corpora of all the domains. 3.3 Table 3 presents the results of the generic systems (PBMT gen. and NMT gen.) and the NMT system adapted to the concatenation of all the eight specific domains (NMT-adp.jnt), as well as the NMT systems which are specifically adapted to each domain se"
E17-2045,2015.iwslt-evaluation.11,0,0.698635,"g them on a generic parallel corpus composed of data from different domains. Our results on multi-domain English-French data show that, in these realistic conditions, PBMT outperforms its neural counterpart. This raises the question: is NMT ready for deployment as a generic/multi-purpose MT backbone in real-world settings? 1 Introduction Neural machine translation systems have recently outperformed their conventional statistical counterparts in the translation tasks in several domains such as news (Sennrich et al., 2016a), UN documents (Junczys-Dowmunt et al., 2016), and spoken language data (Luong and Manning, 2015). One common pattern in all these cases is that the target domain is always predefined, hence it is feasible to perform domain adaptation techniques in order to boost system performance for that particular application. However, in real-world applications it is very hard, if not impossible, to develop and maintain several specific MT systems for multiple domains. This is mostly due to the fact that usually: i) the target domain is not known in advance, and users might query different sen2 Multi-Domain Machine Translation Multi-domain machine translation is very wellstudied in the field of stati"
E17-2045,P16-5005,0,0.0509751,"Missing"
E17-2045,P02-1040,0,0.0980109,"to increase the consistency in segmenting the source and target text, the source and target side of the training set are combined and number of merge rules is set to 89,500, resulting in vocabularies of size 78K and 86K tokens for English and French languages, respectively. We use mini-batches of size 100, word embeddings of size 500, and hidden layers of size 1024. The maximum sentence length is set to 50 in our experiments. The models are trained using Adagrad (Duchi et al., 2011), reshuffling the training corpora for each epoch. The models are evaluated every 10,000 mini-batches via BLEU (Papineni et al., 2002). It is worth mentioning that with the same set-up we recently achieved state-of-theart performance in the International Workshop on Spoken Language Translation evaluation (Farajian et al., 2016). 2 Analysis and Discussion NMT vs. PBMT in Multi-domain scenario As the results show, the generic PBMT system outperforms its NMT counterpart in all the domains by a very large margin; and as the NMT system becomes more specific by observing more domain-specific data, the gap between the performances reduces until the NMT outperforms; which confirms the results of the previous works in this field (Luo"
E17-2045,N16-1101,0,0.0237093,"for jobs coming from any domain), this issue is still unexplored. The current state-of-theart research in NMT explored the effectiveness of domain adaptation, and the approaches for how to adapt existing NMT systems to a new domain (Luong and Manning, 2015). The assumption of these works, however, is that the new target domains are either known in advance or presented together after some sample data have been made available to fine-tune the system. There exist an active field of research that is trying to solve a quite different issue that has a similar motivation, which is multi-lingual NMT (Firat et al., 2016a; Firat et al., 2016b; Johnson et al., 2016). The motivations behind these works are very similar to the ones described in Section 1, which is mostly simplifying the deployment of MT engines in the production lines. So, the final goal is to reduce the number of final systems, trained with pooled multi-domain data sets, without degrading the final performance. As we will see in the remainder of this paper, this issue is still open, especially when we embrace the state-of-the-art NMT paradigm. 3 ECB Gnome JRC KDE4 OOffice PHP Ubuntu UN-TM CommonCrawl Europarl ECB Gnome JRC KDE4 OOffice PHP Ubun"
E17-2045,D16-1026,0,0.0380055,"Missing"
E17-2045,P16-1162,0,0.877463,"f a generic NMT system and phrase-based statistical machine translation (PBMT) system by training them on a generic parallel corpus composed of data from different domains. Our results on multi-domain English-French data show that, in these realistic conditions, PBMT outperforms its neural counterpart. This raises the question: is NMT ready for deployment as a generic/multi-purpose MT backbone in real-world settings? 1 Introduction Neural machine translation systems have recently outperformed their conventional statistical counterparts in the translation tasks in several domains such as news (Sennrich et al., 2016a), UN documents (Junczys-Dowmunt et al., 2016), and spoken language data (Luong and Manning, 2015). One common pattern in all these cases is that the target domain is always predefined, hence it is feasible to perform domain adaptation techniques in order to boost system performance for that particular application. However, in real-world applications it is very hard, if not impossible, to develop and maintain several specific MT systems for multiple domains. This is mostly due to the fact that usually: i) the target domain is not known in advance, and users might query different sen2 Multi-Do"
E17-2045,W07-0717,0,0.0623347,"dvance, and users might query different sen2 Multi-Domain Machine Translation Multi-domain machine translation is very wellstudied in the field of statistical phrase-based MT. The approaches proposed for this issue vary from learning a single model from pooled training data, 280 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 280–284, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics to more complicated (log-)linear interpolations of multiple models using mixture models (Foster and Kuhn, 2007) and linear mixture models (Carpuat et al., 2014). However, being a very new field of research, to the best of our knowledge, there is no work on developing multi-domain NMT systems. However, to the best of our knowledge, there is still no work on developing multi-domain systems (i.e. generic/multi-purpose systems trained with all the data available at a given time) within the stateof-the-art NMT framework. Indeed, though interesting and well motivated from an applicationoriented perspective (e.g. think about a translation company looking for a generic MT backbone usable for jobs coming from a"
L18-1004,2011.mtsummit-papers.35,0,0.440459,"Missing"
L18-1004,P15-2026,1,0.953279,"ting, Machine Translation 1. Introduction inal MT output that has been left untouched (i.e. raw, non post-edited translations). Automatic post-editing (APE) for machine translation (MT) aims to fix recurrent errors made by the MT decoder by learning from correction examples. As a post-processing step, APE has several possible applications, especially in black-box scenarios (e.g. when working with a third-party translation engine) in which the MT system is used “as is” and is not directly accessible for retraining or for more radical internal modifications. In such scenarios, as pointed out by Chatterjee et al. (2015), APE systems can help to: i) improve MT output by exploiting information unavailable to the decoder, or by performing a deeper text analysis that is too expensive at the decoding stage; ii) provide professional translators with improved MT output quality to reduce (human) post-editing effort, and iii) adapt the output of a general-purpose MT system to the lexicon/style requested in a specific application domain. The training of APE systems usually relies on data sets comprising (source, MT, human post-edit) triplets, in which the source sentence in a given language has been automatically tran"
L18-1004,W17-4773,1,0.903438,"lthough the general monolingual translation approach to the problem is still the same, over the years the proposed solutions evolved in several ways, first by refining the decoding approach and then, in the last couple of years, by radically changing the core APE technology. Decoding refinements successfully explored, for instance, the integration of source information for enhanced (joint, context-aware) input representation, either in the standard phrase-based MT (PBMT) framework (B´echara et al., 2011) or in more elegant batch factored models(Chatterjee et al., 2016) and online PBMT models (Chatterjee et al., 2017b). More recently, radical paradigm changes followed the “neural revolution” witnessed in the MT field. The current state of the art is indeed represented by single/multisource neural APE systems, the former relying on the loglinear combination of monolingual and bilingual models (Junczys-Dowmunt and Grundkiewicz, 2016), and the latter learning from source and target information in a joint fashion (Chatterjee et al., 2017a). Recent works addressed the problem by also integrating external information such as word-level quality estimation scores (Chatterjee et al., 2017c) as a way to guide neura"
L18-1004,E17-1050,1,0.938153,"lthough the general monolingual translation approach to the problem is still the same, over the years the proposed solutions evolved in several ways, first by refining the decoding approach and then, in the last couple of years, by radically changing the core APE technology. Decoding refinements successfully explored, for instance, the integration of source information for enhanced (joint, context-aware) input representation, either in the standard phrase-based MT (PBMT) framework (B´echara et al., 2011) or in more elegant batch factored models(Chatterjee et al., 2016) and online PBMT models (Chatterjee et al., 2017b). More recently, radical paradigm changes followed the “neural revolution” witnessed in the MT field. The current state of the art is indeed represented by single/multisource neural APE systems, the former relying on the loglinear combination of monolingual and bilingual models (Junczys-Dowmunt and Grundkiewicz, 2016), and the latter learning from source and target information in a joint fashion (Chatterjee et al., 2017a). Recent works addressed the problem by also integrating external information such as word-level quality estimation scores (Chatterjee et al., 2017c) as a way to guide neura"
L18-1004,W17-4716,1,0.890869,"lthough the general monolingual translation approach to the problem is still the same, over the years the proposed solutions evolved in several ways, first by refining the decoding approach and then, in the last couple of years, by radically changing the core APE technology. Decoding refinements successfully explored, for instance, the integration of source information for enhanced (joint, context-aware) input representation, either in the standard phrase-based MT (PBMT) framework (B´echara et al., 2011) or in more elegant batch factored models(Chatterjee et al., 2016) and online PBMT models (Chatterjee et al., 2017b). More recently, radical paradigm changes followed the “neural revolution” witnessed in the MT field. The current state of the art is indeed represented by single/multisource neural APE systems, the former relying on the loglinear combination of monolingual and bilingual models (Junczys-Dowmunt and Grundkiewicz, 2016), and the latter learning from source and target information in a joint fashion (Chatterjee et al., 2017a). Recent works addressed the problem by also integrating external information such as word-level quality estimation scores (Chatterjee et al., 2017c) as a way to guide neura"
L18-1004,P16-5005,0,0.021919,"essional translators. The combination of domain specificity and higher post-editing quality resulted in significant gains over the baseline. Related Work: Existing APE Corpora The growing interest towards APE has to confront with the hard truth of data scarcity. Although nowadays post-edited data are a clear by-product of industrial translation workflows, the largest part of the daily work done by professional translators focuses on proprietary or copyright data that cannot be released. Though present in the industrial sector (as confirmed by recent works coming from big players like SYSTRAN (Crego et al., 2016) or eBay (Mathur et al., 2017)), APE technology is still more a matter of inhouse development rather than a framework motivating free data sharing. The few existing corpora that are usable for APE research can be classified into two types: i) the aforementioned “gold” data sets made of (source, MT, human post-edit) triplets, and ii) the synthetic ones, to which our eSCAPE corpus belongs, in which some elements of the triplets derive from automatic translation. The remainder of this section provides an inventory of the existing APE corpora. As also shown in Table 1, the global picture is quite"
L18-1004,E17-2045,1,0.847727,"les Gnome Ubuntu KDE4 OpenOffice PHP TOTAL Domain LEGAL LEGAL MIXED LEGAL NEWS MIXED MEDIC. MEDIC. MEDIC. IT IT IT IT IT En-De 1,920,209 11,317 2,399,123 719,372 242,770 143,836 1,108,752 1,848,303 10,406 28,439 13,245 224,035 42,391 39,707 En-It 1,909,115 193,047 810,979 40,009 181,874 1,081,134 319,141 21,014 175,058 35,538 8,853,762 4,128,128 memory, storing external user translation memories (TMs). When ModernMT receives a translation query, it quickly analyses its context, recalls from its memory the most related translation examples, and instantly adapts its neural network to the query (Farajian et al., 2017). Training and test of the neural models were run on one GPU (NVIDIA Tesla K80) for around three weeks. Final performance is 38.17 BLEU points for English–German and 41.01 for English–Italian. To give the possibility for experiments on domainadaptation for APE, each eSCAPE triplet is associated to a label indicating the name of the corpus from which the original (source, reference) pair was extracted. 4. To test the usefulness of the eSCAPE corpus, we run APE experiments for both the language pairs covered by the data set. En-De and En-It data were first tokenised and then split into dev (2,00"
L18-1004,W17-4775,0,0.0615828,"ssed the problem by also integrating external information such as word-level quality estimation scores (Chatterjee et al., 2017c) as a way to guide neural APE decoding towards better corrections. Unsurprisingly, the impressive gains achieved by the neu24 2.1. ral solutions come at the cost of a much higher data demand compared to the PBMT methods. To overcome this problem, the latest published results on neural APE have been obtained by exploiting synthetically-created data during training (Junczys-Dowmunt and Grundkiewicz, 2016; Junczys-Dowmunt and Grundkiewicz, 2017; Variˇs and Bojar, 2017; Hokamp, 2017; Chatterjee et al., 2017a). These trends, which emerged after three rounds of the APE task organised within the Conference on Machine Translation (WMT) (Bojar et al., 2015; Bojar et al., 2016; Bojar et al., 2017), clearly indicate that: i) information from the source text is definitely useful to train reliable APE models, and ii) the limited availability of “gold” training corpora made of (source, MT, human post-edit) triplets calls for workarounds to unleash the full potential of state-of-the art but data-demanding neural systems. The eSCAPE corpus presented in this paper meets such demand b"
L18-1004,W16-2378,0,0.357143,"ully explored, for instance, the integration of source information for enhanced (joint, context-aware) input representation, either in the standard phrase-based MT (PBMT) framework (B´echara et al., 2011) or in more elegant batch factored models(Chatterjee et al., 2016) and online PBMT models (Chatterjee et al., 2017b). More recently, radical paradigm changes followed the “neural revolution” witnessed in the MT field. The current state of the art is indeed represented by single/multisource neural APE systems, the former relying on the loglinear combination of monolingual and bilingual models (Junczys-Dowmunt and Grundkiewicz, 2016), and the latter learning from source and target information in a joint fashion (Chatterjee et al., 2017a). Recent works addressed the problem by also integrating external information such as word-level quality estimation scores (Chatterjee et al., 2017c) as a way to guide neural APE decoding towards better corrections. Unsurprisingly, the impressive gains achieved by the neu24 2.1. ral solutions come at the cost of a much higher data demand compared to the PBMT methods. To overcome this problem, the latest published results on neural APE have been obtained by exploiting synthetically-created"
L18-1004,I17-1013,0,0.0310568,"n a joint fashion (Chatterjee et al., 2017a). Recent works addressed the problem by also integrating external information such as word-level quality estimation scores (Chatterjee et al., 2017c) as a way to guide neural APE decoding towards better corrections. Unsurprisingly, the impressive gains achieved by the neu24 2.1. ral solutions come at the cost of a much higher data demand compared to the PBMT methods. To overcome this problem, the latest published results on neural APE have been obtained by exploiting synthetically-created data during training (Junczys-Dowmunt and Grundkiewicz, 2016; Junczys-Dowmunt and Grundkiewicz, 2017; Variˇs and Bojar, 2017; Hokamp, 2017; Chatterjee et al., 2017a). These trends, which emerged after three rounds of the APE task organised within the Conference on Machine Translation (WMT) (Bojar et al., 2015; Bojar et al., 2016; Bojar et al., 2017), clearly indicate that: i) information from the source text is definitely useful to train reliable APE models, and ii) the limited availability of “gold” training corpora made of (source, MT, human post-edit) triplets calls for workarounds to unleash the full potential of state-of-the art but data-demanding neural systems. The eSCAPE corpus prese"
L18-1004,W04-3250,0,0.226557,"ificantly outperform baseline results in both language directions, independently from the MT technology underlying the data generation process. The work reported in this paper is the initial step of a more ambitious roadmap aimed to extend the resource with more data covering a larger spectrum of domains and language combinations. The current version of eSCAPE can be freely downloaded from: http://hltshare.fbk. eu/QT21/eSCAPE.html. 38.08 39.80 41.01 42.15 Table 3: Neural APE results (BLEU score improvements are statistically significant with p &lt; 0.05 computed with paired bootstrap resampling (Koehn, 2004)). and tested on artificial data built from phrase-based models (+1.39 on En–De, +1.72 on En–It), and when training and test are performed on artificial data derived from neural models (+1.04 on En–De, +1.14 on En–It).12 The observed gains vary for the two language pairs (with highest results on En–It) and depending on the type of data used. Concerning this latter aspect, the higher quality of neural MT output results in lower gains on both language settings. This confirms previous outcomes from the WMT APE task: the higher the baseline (i.e. the BLEU score of the raw MT output), the lower the"
L18-1004,2005.mtsummit-papers.11,0,0.0938754,"iments and the reuse of the selected triplets, the authors released the scripts used for data extraction.2 Another useful resource is described in (Potet et al., 2012).3 It consists of 10,881 triplets in which a French source sentence taken from several news corpora is translated into English by a PBMT system. Post-edits were collected using Amazon Mechanical Turk following strict control reviewing procedures to guarantee correction quality. Two smaller corpora are respectively described in (Specia et al., 2010) and (Specia, 2011). The former consists of 4,000 English sentences from Europarl (Koehn, 2005), which were translated into Spanish by a PBMT system and manually post-edited by professional translators. The latter, which covers the news domain, includes 2,525 French–English PBMT translations and 1,000 English– Spanish translations with professional post-edits. Other useful data have been released by the organisers of the WMT APE task. The first round of the task (Bojar et al., 2015) presented participants with around 12,000 English– Spanish training data drawn from the news domain, with translations derived from a PBMT system. A peculiarity of this corpus is that post-edits were collect"
L18-1004,W17-3525,0,0.0134074,"bination of domain specificity and higher post-editing quality resulted in significant gains over the baseline. Related Work: Existing APE Corpora The growing interest towards APE has to confront with the hard truth of data scarcity. Although nowadays post-edited data are a clear by-product of industrial translation workflows, the largest part of the daily work done by professional translators focuses on proprietary or copyright data that cannot be released. Though present in the industrial sector (as confirmed by recent works coming from big players like SYSTRAN (Crego et al., 2016) or eBay (Mathur et al., 2017)), APE technology is still more a matter of inhouse development rather than a framework motivating free data sharing. The few existing corpora that are usable for APE research can be classified into two types: i) the aforementioned “gold” data sets made of (source, MT, human post-edit) triplets, and ii) the synthetic ones, to which our eSCAPE corpus belongs, in which some elements of the triplets derive from automatic translation. The remainder of this section provides an inventory of the existing APE corpora. As also shown in Table 1, the global picture is quite fragmented, with domain-specif"
L18-1004,W07-0704,0,0.0928191,". In both cases, translations were produced by a customised PBMT system and post-edited by professional translators. 2.2. Synthetic corpora The use of synthetic resources aims to overcome the aforementioned problem of “gold” data scarcity with approximate solutions. This can be done in different ways. Several previous works have shown the viability of mimicking the ideal scenario in which the training triplets include actual human post-edits of machine-translated text by learning, instead, from the weaker connection between the MT output and external references. Though with variable margins, (Oflazer and El-Kahlout, 2007; B´echara et al., 2011; Rubino et al., 2012) report translation quality improvements in the PBMT scenario with post-editing components trained on (source, MT, reference) triplets. To the best of our knowledge, though potentially useful to APE research, none of such previous works released reusable datasets. When moving to the data-demanding neural framework, data scarcity becomes a major problem that definitely calls for the external support of artificial corpora that are orders of magnitude larger than the current training sets. 3. The eSCAPE corpus7 consists in two datasets (En-De and En-It"
L18-1004,P02-1040,0,0.105377,"to the lexicon/style requested in a specific application domain. The training of APE systems usually relies on data sets comprising (source, MT, human post-edit) triplets, in which the source sentence in a given language has been automatically translated to produce the MT element that, in turn, has been manually corrected to produce the human post-edit. In this supervised learning setting, the goal is to learn from the training data (and possibly generalise) the appropriate corrections of systematic errors made by the MT system, and apply them at test stage on unseen (source, MT) pairs. BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) computed against reference human post-edits are the standard evaluation metrics for the task. Their respective improvements and reductions are usually compared against the baseline scores obtained by the origEarly works on this problem date back to (Allen and Hogan, 2000; Simard et al., 2007), which addressed the problem as a “monolingual translation” task in which raw MT output in the target language has to be translated, in the same language, into a fluent and adequate translation of the original source text. Although the general monolingual translation approac"
L18-1004,potet-etal-2012-collection,0,0.02422,"Missing"
L18-1004,2012.eamt-1.55,0,0.0431765,"Missing"
L18-1004,W16-2323,0,0.0653322,"Missing"
L18-1004,E17-3017,0,0.0730758,"Missing"
L18-1004,N07-1064,0,0.194401,"produce the human post-edit. In this supervised learning setting, the goal is to learn from the training data (and possibly generalise) the appropriate corrections of systematic errors made by the MT system, and apply them at test stage on unseen (source, MT) pairs. BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) computed against reference human post-edits are the standard evaluation metrics for the task. Their respective improvements and reductions are usually compared against the baseline scores obtained by the origEarly works on this problem date back to (Allen and Hogan, 2000; Simard et al., 2007), which addressed the problem as a “monolingual translation” task in which raw MT output in the target language has to be translated, in the same language, into a fluent and adequate translation of the original source text. Although the general monolingual translation approach to the problem is still the same, over the years the proposed solutions evolved in several ways, first by refining the decoding approach and then, in the last couple of years, by radically changing the core APE technology. Decoding refinements successfully explored, for instance, the integration of source information for"
L18-1004,2006.amta-papers.25,0,0.514833,"n a specific application domain. The training of APE systems usually relies on data sets comprising (source, MT, human post-edit) triplets, in which the source sentence in a given language has been automatically translated to produce the MT element that, in turn, has been manually corrected to produce the human post-edit. In this supervised learning setting, the goal is to learn from the training data (and possibly generalise) the appropriate corrections of systematic errors made by the MT system, and apply them at test stage on unseen (source, MT) pairs. BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) computed against reference human post-edits are the standard evaluation metrics for the task. Their respective improvements and reductions are usually compared against the baseline scores obtained by the origEarly works on this problem date back to (Allen and Hogan, 2000; Simard et al., 2007), which addressed the problem as a “monolingual translation” task in which raw MT output in the target language has to be translated, in the same language, into a fluent and adequate translation of the original source text. Although the general monolingual translation approach to the problem is still the"
L18-1004,specia-etal-2010-dataset,0,0.163984,"human post-edit) triplets that share the same English source. To ease the replicability of their experiments and the reuse of the selected triplets, the authors released the scripts used for data extraction.2 Another useful resource is described in (Potet et al., 2012).3 It consists of 10,881 triplets in which a French source sentence taken from several news corpora is translated into English by a PBMT system. Post-edits were collected using Amazon Mechanical Turk following strict control reviewing procedures to guarantee correction quality. Two smaller corpora are respectively described in (Specia et al., 2010) and (Specia, 2011). The former consists of 4,000 English sentences from Europarl (Koehn, 2005), which were translated into Spanish by a PBMT system and manually post-edited by professional translators. The latter, which covers the news domain, includes 2,525 French–English PBMT translations and 1,000 English– Spanish translations with professional post-edits. Other useful data have been released by the organisers of the WMT APE task. The first round of the task (Bojar et al., 2015) presented participants with around 12,000 English– Spanish training data drawn from the news domain, with transl"
L18-1004,2011.eamt-1.12,0,0.125555,"that share the same English source. To ease the replicability of their experiments and the reuse of the selected triplets, the authors released the scripts used for data extraction.2 Another useful resource is described in (Potet et al., 2012).3 It consists of 10,881 triplets in which a French source sentence taken from several news corpora is translated into English by a PBMT system. Post-edits were collected using Amazon Mechanical Turk following strict control reviewing procedures to guarantee correction quality. Two smaller corpora are respectively described in (Specia et al., 2010) and (Specia, 2011). The former consists of 4,000 English sentences from Europarl (Koehn, 2005), which were translated into Spanish by a PBMT system and manually post-edited by professional translators. The latter, which covers the news domain, includes 2,525 French–English PBMT translations and 1,000 English– Spanish translations with professional post-edits. Other useful data have been released by the organisers of the WMT APE task. The first round of the task (Bojar et al., 2015) presented participants with around 12,000 English– Spanish training data drawn from the news domain, with translations derived from"
L18-1004,W17-4777,0,0.183411,"Missing"
L18-1004,2012.amta-wptp.10,0,0.0454916,"Missing"
L18-1004,W16-2377,1,\N,Missing
L18-1004,W16-2301,1,\N,Missing
N10-1064,P00-1037,0,0.264804,"ht affect text mining is in (Subramaniam et al., 2009), while an analysis of how noise phenomena, commonly occurring in blogs, affect an opinion mining application is in (Dey and Haque, 2009). Concerning spelling correction literature, many works apply the noisy channel model which consists of two components: a source model (prior of word probabilities) and a channel (error) model, that accounts for spelling transformations on letter sequences. Several approaches have been proposed under this framework, that mainly differ in the employed error model; see for example: (Church and Gale, 1991), (Brill and Moore, 2000) and (Toutanova and Moore, 2002). Comprehensive surveys on methods to model and recover spelling errors can be found in (Kukich, 1992) and (Pedler, 2007); in particular, the latter work is specifically centered on methods for correcting so-called real-word errors (cf. Section 3). The detection of errors and the suggestion of corrections typically rely on the availability of text corpora or human-made lexical resources. Search for correct alternatives can be based on word similarity measures, such as the edit distance (Mitton, 1995), anagram hashing (Reynaert, 2006), and semantic distance based"
N10-1064,E95-1010,0,0.187162,"Missing"
N10-1064,fossati-di-eugenio-2008-saw,0,0.0471505,"Missing"
N10-1064,P07-2045,1,0.011029,"Missing"
N10-1064,reynaert-2006-corpus,0,0.0152725,"rch and Gale, 1991), (Brill and Moore, 2000) and (Toutanova and Moore, 2002). Comprehensive surveys on methods to model and recover spelling errors can be found in (Kukich, 1992) and (Pedler, 2007); in particular, the latter work is specifically centered on methods for correcting so-called real-word errors (cf. Section 3). The detection of errors and the suggestion of corrections typically rely on the availability of text corpora or human-made lexical resources. Search for correct alternatives can be based on word similarity measures, such as the edit distance (Mitton, 1995), anagram hashing (Reynaert, 2006), and semantic distance based on WordNet (Hirst and Budanitsky, 2005). More sophisticated approaches have been proposed by (Fossati and Di Eugenio, 2008), that mixes surface and Part-Of-Speech Information, and (Schaback and Li, 2007), which combines similarity measures at the character, phonetic, word, syntax, and semantic levels into one global feature-based framework. 413 a) *W *w had just come in from Australia [Australia] b) good service we *staid one week. [Tahiti] c) The room was *exellent but the hallway was *filty . [NJ] d) is a good place to stay, if you are looking for a hotel *arrou"
N10-1064,P02-1019,0,0.149611,"(Subramaniam et al., 2009), while an analysis of how noise phenomena, commonly occurring in blogs, affect an opinion mining application is in (Dey and Haque, 2009). Concerning spelling correction literature, many works apply the noisy channel model which consists of two components: a source model (prior of word probabilities) and a channel (error) model, that accounts for spelling transformations on letter sequences. Several approaches have been proposed under this framework, that mainly differ in the employed error model; see for example: (Church and Gale, 1991), (Brill and Moore, 2000) and (Toutanova and Moore, 2002). Comprehensive surveys on methods to model and recover spelling errors can be found in (Kukich, 1992) and (Pedler, 2007); in particular, the latter work is specifically centered on methods for correcting so-called real-word errors (cf. Section 3). The detection of errors and the suggestion of corrections typically rely on the availability of text corpora or human-made lexical resources. Search for correct alternatives can be based on word similarity measures, such as the edit distance (Mitton, 1995), anagram hashing (Reynaert, 2006), and semantic distance based on WordNet (Hirst and Budanitsk"
N10-1064,E03-1050,0,\N,Missing
P07-2045,N03-2002,0,0.152204,"nfusion networks. This input type has been used successfully for speech to text translation (Shen et al. 2006). Every factor on the target language can have its own language model. Since many factors, like lemmas and POS tags, are less sparse than surface forms, it is possible to create a higher order language models for these factors. This may encourage more syntactically correct output. In Figure 3 we apply two language models, indicated by the shaded arrows, one over the words and another over the lemmas. Moses is also able to integrate factored language models, such as those described in (Bilmes and Kirchhoff 2003) and (Axelrod 2006). 4 Confusion Network Decoding Machine translation input currently takes the form of simple sequences of words. However, there are increasing demands to integrate machine translation technology into larger information processing systems with upstream NLP/speech processing tools (such as named entity recognizers, speech recognizers, morphological analyzers, etc.). These upstream processes tend to generate multiple, erroneous hypotheses with varying confidence. Current MT systems are designed to process only one input hypothesis, making them vulnerable to errors in the input."
P07-2045,koen-2004-pharaoh,0,0.148177,"to be duplicated. This has also hindered effective comparisons of the different elements of the systems. By providing a free and complete toolkit, we hope that this will stimulate the development of the field. For this system to be adopted by the community, it must demonstrate performance that is comparable to the best available systems. Moses has shown that it achieves results comparable to the most competitive and widely used statistical machine translation systems in translation quality and run-time (Shen et al. 2006). It features all the capabilities of the closed sourced Pharaoh decoder (Koehn 2004). Apart from providing an open-source toolkit for SMT, a further motivation for Moses is to extend phrase-based translation with factors and confusion network decoding. The current phrase-based approach to statistical machine translation is limited to the mapping of small text chunks without any explicit use of linguistic information, be it morphological, syntactic, or semantic. These additional sources of information have been shown to be valuable when integrated into pre-processing or post-processing steps. Moses also integrates confusion network decoding, which allows the translation of amb"
P07-2045,D07-1091,1,0.158367,"Missing"
P07-2045,N03-1017,1,0.161374,"informatik.rwth-aachen.de. 5 redpony@umd.edu. 6 bojar@ufal.ms.mff.cuni.cz. 7 07aec_2@williams.edu. 8 evh4@cornell.edu 2 Abstract We describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks. 1 Motivation Phrase-based statistical machine translation (Koehn et al. 2003) has emerged as the dominant paradigm in machine translation research. However, until now, most work in this field has been carried out on proprietary and in-house research systems. This lack of openness has created a high barrier to entry for researchers as many of the components required have had to be duplicated. This has also hindered effective comparisons of the different elements of the systems. By providing a free and complete toolkit, we hope that this will stimulate the development of the field. For this system to be adopted by the community, it must demonstrate performance that is co"
P07-2045,P03-1021,0,0.176468,"ent data structures in Moses for the memory-intensive translation model and language model allow the exploitation of much larger data resources with limited hardware. 177 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 177–180, c Prague, June 2007. 2007 Association for Computational Linguistics 2 Toolkit 3 The toolkit is a complete out-of-the-box translation system for academic research. It consists of all the components needed to preprocess data, train the language models and the translation models. It also contains tools for tuning these models using minimum error rate training (Och 2003) and evaluating the resulting translations using the BLEU score (Papineni et al. 2002). Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++ (Och and Ney 2003) for word alignments and SRILM for language modeling. Also, since these tasks are often CPU intensive, the toolkit has been designed to work with Sun Grid Engine parallel environment to increase throughput. In order to unify the experimental stages, a utility has been developed to run repeatable experiments. This uses the tools contained in Moses and requires minimal changes to set up and customiz"
P07-2045,J03-1002,0,0.164868,"L 2007 Demo and Poster Sessions, pages 177–180, c Prague, June 2007. 2007 Association for Computational Linguistics 2 Toolkit 3 The toolkit is a complete out-of-the-box translation system for academic research. It consists of all the components needed to preprocess data, train the language models and the translation models. It also contains tools for tuning these models using minimum error rate training (Och 2003) and evaluating the resulting translations using the BLEU score (Papineni et al. 2002). Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++ (Och and Ney 2003) for word alignments and SRILM for language modeling. Also, since these tasks are often CPU intensive, the toolkit has been designed to work with Sun Grid Engine parallel environment to increase throughput. In order to unify the experimental stages, a utility has been developed to run repeatable experiments. This uses the tools contained in Moses and requires minimal changes to set up and customize. The toolkit has been hosted and developed under sourceforge.net since inception. Moses has an active research community and has reached over 1000 downloads as of 1st March 2007. The main online pre"
P07-2045,P02-1040,0,0.148118,"d language model allow the exploitation of much larger data resources with limited hardware. 177 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 177–180, c Prague, June 2007. 2007 Association for Computational Linguistics 2 Toolkit 3 The toolkit is a complete out-of-the-box translation system for academic research. It consists of all the components needed to preprocess data, train the language models and the translation models. It also contains tools for tuning these models using minimum error rate training (Och 2003) and evaluating the resulting translations using the BLEU score (Papineni et al. 2002). Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++ (Och and Ney 2003) for word alignments and SRILM for language modeling. Also, since these tasks are often CPU intensive, the toolkit has been designed to work with Sun Grid Engine parallel environment to increase throughput. In order to unify the experimental stages, a utility has been developed to run repeatable experiments. This uses the tools contained in Moses and requires minimal changes to set up and customize. The toolkit has been hosted and developed under sourceforge.net since inception. Mo"
P07-2045,N07-1062,1,0.152186,"up gigabytes of disk space, but for the translation of a single sentence only a tiny fraction of this table is needed. Moses implements an efficient representation of the phrase translation table. Its key properties are a prefix tree structure for source words and on demand loading, i.e. only the fraction of the phrase table that is needed to translate a sentence is loaded into the working memory of the decoder. For the Chinese-English NIST task, the memory requirement of the phrase table is reduced from 1.7 gigabytes to less than 20 mega bytes, with no loss in translation quality and speed (Zens and Ney 2007). The other large data resource for statistical machine translation is the language model. Almost unlimited text resources can be collected from the Internet and used as training data for language modeling. This results in language models that are too large to easily fit into memory. The Moses system implements a data structure for language models that is more efficient than the canonical SRILM (Stolcke 2002) implementation used in most systems. The language model on disk is also converted into this binary format, resulting in a minimal loading time during start-up of the decoder. An even more"
P07-2045,D08-1076,0,\N,Missing
P07-2045,2006.iwslt-evaluation.8,1,\N,Missing
W02-1038,H94-1050,0,\N,Missing
W06-3113,2005.mtsummit-posters.19,0,0.0955322,"corresponds to the mean value of all points falling into it. If Ni is the number of points of the i-th bin, and xi the smallest point in the i-th bin, a partition [xi , xi+1 ] results such that Ni is constant for each i = 0, . . . , k − 1, where xk = 1 by default. The following map is thus defined: q(x) = ci if xi <= x < xi+1 . Our implementation uses the following greedy strategy: bins are build by uniformly partition all different points of the data set. Translation Model 4 Phrase-based Translation System Given a string f in the source language, our SMT system (Federico and Bertoldi, 2005; Cettolo et al., 2005), looks for the target string e maximizing the posterior probability Pr(e, a |f ) over all possible word alignments a. The conditional distribution is computed with the log-linear model: pλ (e, a |f ) ∝ exp ( R X ) λr hr (e, f , a) , r=1 where hr (e, f , a), r = 1 . . . R are real valued feature functions. The log-linear model is used to score translation hypotheses (e, a) built in terms of strings of phrases, which are simple sequences of words. The translation process works as follows. At each step, a target phrase is added to the translation whose corresponding source phrase within f is ide"
W06-3113,W05-0835,0,0.0928604,"tical machine translation (SMT) is based on parametric models incorporating a large number of observations and probabilities estimated from monolingual and parallel texts. The current state of the art is represented by the so-called phrase-based translation approach (Och and Ney, 2004; Koehn et • Which is the optimal trade-off between data compression and translation performance? • How do quantized models perform under different data-sparseness conditions? • Is the impact of quantization consistent across different translation tasks? Experiments were performed with our phrasebased SMT system (Federico and Bertoldi, 2005) on two large-vocabulary tasks: the translation of European Parliament Plenary Sessions from Spanish to 94 Proceedings of the Workshop on Statistical Machine Translation, pages 94–101, c New York City, June 2006. 2006 Association for Computational Linguistics English, and the translation of news agencies from Chinese to English, according to the set up defined by the 2005 NIST MT Evaluation Workshop. The paper is organized as follows. Section 2 reviews previous work addressing efficiency in speech recognition and information retrieval. Section 3 introduces the two quantization methods consider"
W06-3113,P02-1023,0,0.0656746,"Missing"
W06-3113,N03-1017,0,0.0130885,"Missing"
W06-3113,J04-4002,0,0.0338356,"y. • How does probability quantization impact on the components of the translation system, namely the language model and the translation model? 1 Introduction In several natural language processing tasks, such as automatic speech recognition and machine translation, state-of-the-art systems rely on the statistical approach. Statistical machine translation (SMT) is based on parametric models incorporating a large number of observations and probabilities estimated from monolingual and parallel texts. The current state of the art is represented by the so-called phrase-based translation approach (Och and Ney, 2004; Koehn et • Which is the optimal trade-off between data compression and translation performance? • How do quantized models perform under different data-sparseness conditions? • Is the impact of quantization consistent across different translation tasks? Experiments were performed with our phrasebased SMT system (Federico and Bertoldi, 2005) on two large-vocabulary tasks: the translation of European Parliament Plenary Sessions from Spanish to 94 Proceedings of the Workshop on Statistical Machine Translation, pages 94–101, c New York City, June 2006. 2006 Association for Computational Linguisti"
W06-3113,2005.mtsummit-papers.34,0,0.0189467,"of quantization, two separate codebooks are generated for each of the first three levels, and one codebook is generated for the last level. Hence, a total of 7 codebooks are generated. In all discussed quantized LMs, unigram probabilities are always encoded with 8 bits. The reason is that unigram probabilities have indeed the largest variability and do not contribute significantly to the total number of parameters. 5 Experiments Data and Experimental Framework We performed experiments on two large vocabulary translation tasks: the translation of European Parliamentary Plenary Sessions (EPPS) (Vilar et al., 2005) from Spanish to English, and the translation of documents from Chinese to English as proposed by the NIST MT Evaluation Workshops3 . Translation of EPPS is performed on the so-called final text editions, which are prepared by the translation office of the European Parliament. Both the training and testing data were collected by the TCSTAR4 project and were made freely available to participants in the 2006 TC-STAR Evaluation Campaign. In order to perform experiments under different data sparseness conditions, four subsamples of the training data with different sizes were generated, too. Traini"
W09-0432,W07-0717,0,0.524961,"ed only recently. In (Eck et al., 2004) adaptation is limited to the target language model (LM). The background LM is combined with one estimated on documents retrieved from the WEB by using the input sentence as query and applying crosslanguage information retrieval techniques. Refinements of this approach are described in (Zhao et al., 2004). In (Hildebrand et al., 2005) information retrieval techniques are applied to retrieve sentence pairs from the training corpus that are relevant to the test sentences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settings are investigated: cross-domain adaptation, in which a small sample of parallel in-domain text is assumed, and dynamic adaptation, in which only the current input source text is considered. Adaptation relies on mixture models estimated on the training data through some unsupervised clustering method. Given available adaptation data, mixture weights are re-estimated ad-hoc. A variation of this approach was also recently proposed in (Finch and Sumita, 2008). In (Civera and Juan, 2007) mixture models are instead employed to adapt a word alignment model to in-domain parallel dat"
W09-0432,2005.eamt-1.19,0,0.474349,"with respect to previous work we also investigate the behavior of the minimum error training procedure to optimize the combination of feature functions on a small in-domain bilingual sample. Previous Work Domain adaptation in SMT has been investigated only recently. In (Eck et al., 2004) adaptation is limited to the target language model (LM). The background LM is combined with one estimated on documents retrieved from the WEB by using the input sentence as query and applying crosslanguage information retrieval techniques. Refinements of this approach are described in (Zhao et al., 2004). In (Hildebrand et al., 2005) information retrieval techniques are applied to retrieve sentence pairs from the training corpus that are relevant to the test sentences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settings are investigated: cross-domain adaptation, in which a small sample of parallel in-domain text is assumed, and dynamic adaptation, in which only the current input source text is considered. Adaptation relies on mixture models estimated on the training data through some unsupervised clustering method. Given available adaptation data,"
W09-0432,W07-0733,0,0.694628,"umption that only monolingual texts are available, either in the source language or in the target language. The paper is organized as follows. Section 2 presents previous work on the problem of adaptation in SMT; Section 3 introduces the exemplar task and research questions we addressed; Section 4 describes the SMT system and the adaptation techniques that were investigated; Section 5 presents and discusses experimental results; and Section 6 provides conclusions. 2 tation methods relying on additional bilingual data synthesized from the development or test set. Our work is mostly related to (Koehn and Schroeder, 2007) but explores different assumptions about available adaptation data: i.e. only monolingual in-domain texts are available. The adaptation of the translation and re-ordering models is performed by generating synthetic bilingual data from monolingual texts, similarly to what proposed in (Schwenk, 2008). Interpolation of multiple phrase tables is applied in a more principled way than in (Koehn and Schroeder, 2007): all entries are merged into one single table, corresponding feature functions are concatenated and smoothing is applied when observations are missing. The approach proposed in this pape"
W09-0432,P07-2045,1,0.0220186,"Missing"
W09-0432,J93-2003,0,0.0141496,"Missing"
W09-0432,D08-1076,0,0.0247701,"nce. Figure 1 reports incremental tuning time and translation performance on the test set at each iteration. Notice that the four tuning configurations are ranked in order of complexity. Table 3 summaries the final performance of each tuning process, after convergence was reached. Notice that decoding time is not included in this plot, as Moses allows to perform this step in parallel on a computer cluster. Hence, to our view the real bottleneck of the tuning process is actually related to the strictly serial part of the mert implementation of Moses. As already observed in previous literature (Macherey et al., 2008), first iterations of the tuning process produces very bad weights (even close to 0); this exceptional performance drop is attributed to an over-fitting on the candidate repository. Configurations exploiting the small development set (c,d) show a slower and more unstable convergence; however, their final performance in Table 3 result only slightly lower than that obtained with the standard dev sets (a, b). Due to the larger number of iterations they needed, both configurations are indeed more time consuming than the intermediate configuration (b), which seems the best one. In conclusion, we fo"
W09-0432,W07-0722,0,0.548308,"tences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settings are investigated: cross-domain adaptation, in which a small sample of parallel in-domain text is assumed, and dynamic adaptation, in which only the current input source text is considered. Adaptation relies on mixture models estimated on the training data through some unsupervised clustering method. Given available adaptation data, mixture weights are re-estimated ad-hoc. A variation of this approach was also recently proposed in (Finch and Sumita, 2008). In (Civera and Juan, 2007) mixture models are instead employed to adapt a word alignment model to in-domain parallel data. In (Koehn and Schroeder, 2007) cross-domain adaptation techniques were applied on a phrasebased SMT trained on the Europarl task, in order to translate news commentaries, from French to English. In particular, a small portion of indomain bilingual data was exploited to adapt the Europarl language model and translation models by means of linear interpolation techniques. Ueffing et al. (2007) proposed several elaborate adap3 Task description This paper addresses the issue of adapting an already devel"
W09-0432,J03-1002,0,0.0465772,"earned from training data? • How can interpolation of models be effectively learned from small amounts of indomain parallel data? 4 System description The investigation presented in this paper was carried out with the Moses toolkit (Koehn et al., 2007), a state-of-the-art open-source phrase-based SMT system. We trained Moses in a standard configuration, including a 4-feature translation model, a 7-feature lexicalized re-ordering model, one LM, word and phrase penalties. The translation and the re-ordering model relied on “grow-diag-final” symmetrized word-toword alignments built using GIZA++ (Och and Ney, 2003) and the training script of Moses. A 5-gram language model was trained on the target side of the training parallel corpus using the IRSTLM toolkit (Federico et al., 2008), exploiting Modified Kneser-Ney smoothing, and quantizing both probabilities and backoff weights. Decoding was performed applying cube-pruning with a poplimit of 6000 hypotheses. Log-linear interpolations of feature functions were estimated with the parallel version of minimum error rate training procedure distributed with Moses. 4.1 4.2 Model combination Once monolingual adaptation data is automatically translated, we can us"
W09-0432,eck-etal-2004-language,0,0.0892838,"all entries are merged into one single table, corresponding feature functions are concatenated and smoothing is applied when observations are missing. The approach proposed in this paper has many similarities with the simplest technique in (Ueffing et al., 2007), but it is applied to a much larger monolingual corpus. Finally, with respect to previous work we also investigate the behavior of the minimum error training procedure to optimize the combination of feature functions on a small in-domain bilingual sample. Previous Work Domain adaptation in SMT has been investigated only recently. In (Eck et al., 2004) adaptation is limited to the target language model (LM). The background LM is combined with one estimated on documents retrieved from the WEB by using the input sentence as query and applying crosslanguage information retrieval techniques. Refinements of this approach are described in (Zhao et al., 2004). In (Hildebrand et al., 2005) information retrieval techniques are applied to retrieve sentence pairs from the training corpus that are relevant to the test sentences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settin"
W09-0432,P02-1040,0,0.0911631,"garithms. Henceforth, a phrase pair belonging to all original sets is penalized with respect to phrase pairs belonging to few of them only. To address this drawback, we proposed a new method3 to compute a more reliable and smoothed score in the undefined case, based on the IBM model 1 (Brown et al., 1993). If (f˜ = f1 , . . . , fl , e˜ = e1 , . . . , el ) ∈ SU  Sj for any j the 3 m X l Y  φ(ek |fh ) (l + 1)m k=1 h=0 4 Distributed by the Linguistic Data Consortium, catalogue # LDC94T4A. 5 http://www.statmt.org/wmt08 Authors are not aware of any work addressing this issue. 185 the BLEU score (Papineni et al., 2002), and tested on test2008. (Notice that one reference translation is available for both sets.) Table 1 reports statistics of original and synthetic parallel corpora, as well of the employed development and evaluation data sets. All the texts were just tokenized and mixed case was kept. Hence, all systems were developed to produce case-sensitive translations. corpus sent 2.5M 1.3M 1.3M 1.3M Spanish word dict 50.5M 253K 36.4M 164K 36.4M 164K 36.2M 120K English word dict 45.2M 224K 35.0M 109K 35.4M 133K 35.0M 109K UN EP ¯ SE-EP ¯SE-EP dev test 2,000 2,000 60,438 8,173 61,756 8,331 58,653 6,548 60,"
W09-0432,2008.iwslt-papers.6,0,0.127278,"SMT system and the adaptation techniques that were investigated; Section 5 presents and discusses experimental results; and Section 6 provides conclusions. 2 tation methods relying on additional bilingual data synthesized from the development or test set. Our work is mostly related to (Koehn and Schroeder, 2007) but explores different assumptions about available adaptation data: i.e. only monolingual in-domain texts are available. The adaptation of the translation and re-ordering models is performed by generating synthetic bilingual data from monolingual texts, similarly to what proposed in (Schwenk, 2008). Interpolation of multiple phrase tables is applied in a more principled way than in (Koehn and Schroeder, 2007): all entries are merged into one single table, corresponding feature functions are concatenated and smoothing is applied when observations are missing. The approach proposed in this paper has many similarities with the simplest technique in (Ueffing et al., 2007), but it is applied to a much larger monolingual corpus. Finally, with respect to previous work we also investigate the behavior of the minimum error training procedure to optimize the combination of feature functions on a"
W09-0432,C04-1059,0,0.813972,"Missing"
W09-0432,W08-0334,0,0.032125,"are relevant to the test sentences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settings are investigated: cross-domain adaptation, in which a small sample of parallel in-domain text is assumed, and dynamic adaptation, in which only the current input source text is considered. Adaptation relies on mixture models estimated on the training data through some unsupervised clustering method. Given available adaptation data, mixture weights are re-estimated ad-hoc. A variation of this approach was also recently proposed in (Finch and Sumita, 2008). In (Civera and Juan, 2007) mixture models are instead employed to adapt a word alignment model to in-domain parallel data. In (Koehn and Schroeder, 2007) cross-domain adaptation techniques were applied on a phrasebased SMT trained on the Europarl task, in order to translate news commentaries, from French to English. In particular, a small portion of indomain bilingual data was exploited to adapt the Europarl language model and translation models by means of linear interpolation techniques. Ueffing et al. (2007) proposed several elaborate adap3 Task description This paper addresses the issue"
W12-3155,P02-1040,0,\N,Missing
W12-3155,P07-2045,1,\N,Missing
W12-3155,W07-0717,0,\N,Missing
W12-3155,macklovitch-2006-transtype2,0,\N,Missing
W14-0313,2012.iwslt-papers.12,0,0.136526,"viding the learning task into word alignment and phrase extraction tasks, and replacing the standard wordalignment module, which is a variation of EM algorithm (Och and Ney, 2003), with a greedy search algorithm, they attempt to find a quick approximation of the word alignments of the newly translated sentence. They also use some heuristics to improve the obtained alignments, without supporting it with some proofs or even providing some experimental results. Furthermore, the running time of this approach is not discussed, and it is not clear how effective this approach is in online scenarios. Blain et al. (2012) have recently studied the problem of incremental learning from post-editing data, with minimum computational complexity and acceptable quality. They use the MT outTomeh et al. (2010) introduced a supervised discriminative word alignment model for producing higher quality word alignments, which is trained on a manually aligned training corpus. To reduce the search space of the word aligner, they propose to provide the system with a set of automatic word alignments and consider the union of these alignments as the possible search space. This transforms the word alignment process into 85 3.1 the"
W14-0313,N13-1073,0,0.0215216,"eir capability in handling the unknown words. For a fair comparison, all aligners are trained on the same training corpora described in Section 3.2. berkeley aligner (Liang et al., 2006) applies the co-training approach for training the IBM model 1 and HMM. We trained berkeley aligner using 5 iterations of model 1 followed by 5 iterations of HMM. When applied to new sentence pairs, the system produces bi-directional symmetrized alignment. fast-align is a recently developed unsupervised word aligner that uses a log-linear reparametrization of IBM model 2 for training the word alignment models (Dyer et al., 2013). We exploited the default configuration with 5 iterations for training. As the system is directional, we trained two systems (source-to-target and targetto-source). When applied to new sentence pairs, we first produced the two directional alignments, and then combined them into a symmetrized alignment by using the grow-diag-final-and heuristic (Och and Ney, 2003). mgiza++ (Gao and Vogel, 2008) and its ancestors, i.e. giza, and giza++, implement all the IBM models and HMM based alignment models. mgiza++ is a multithreaded version of giza++, which enables an efficient use of multi-core platform"
W14-0313,2010.amta-papers.18,0,0.0282127,"th a greedy search algorithm, they attempt to find a quick approximation of the word alignments of the newly translated sentence. They also use some heuristics to improve the obtained alignments, without supporting it with some proofs or even providing some experimental results. Furthermore, the running time of this approach is not discussed, and it is not clear how effective this approach is in online scenarios. Blain et al. (2012) have recently studied the problem of incremental learning from post-editing data, with minimum computational complexity and acceptable quality. They use the MT outTomeh et al. (2010) introduced a supervised discriminative word alignment model for producing higher quality word alignments, which is trained on a manually aligned training corpus. To reduce the search space of the word aligner, they propose to provide the system with a set of automatic word alignments and consider the union of these alignments as the possible search space. This transforms the word alignment process into 85 3.1 the alignment refinement task in which given a set of automatic word alignments, the system tries to find the best word alignment points. Similar to (McCarley et al., 2011), this approac"
W14-0313,C96-2141,0,0.173012,": T T |A P | |A S| P recision = , Recall = |A| |S| 1 F − measure = α 1−α P recision + Recall Word Alignment Word alignment is the task of finding the correspondence among the words of a sentence pair (Figure 1). From a mathematical point of view, it is a relation among the words, because any word in a sentence can be mapped into zero, one or more words of the other, and vice-versa; in other words, any kind of link is allowed, namely one-toone, many-to-one, many-to-many, as well as leaving words unaligned. So called IBM models 1-5 (Brown et al., 1993) as well as the HMM-based alignment models (Vogel et al., 1996), and their variations are extensively studied and widely used for this task. They are directional alignment models, because permit only many-to-one links; but often the alignments in the two opposite directions are combined in a so-called symmetrized alignment, which is obtained by intersection, union or other smart combination. Nowadays, word-aligners are mostly employed in an intermediate step of the training procedure of a SMT system; In this step, the training corpus is word aligned as a side effect of the estimation of the alignment models by means of the Expectation-Maximization algorit"
W14-0313,J07-3002,0,0.0598475,"of automatic word alignments and consider the union of these alignments as the possible search space. This transforms the word alignment process into 85 3.1 the alignment refinement task in which given a set of automatic word alignments, the system tries to find the best word alignment points. Similar to (McCarley et al., 2011), this approach relies on the manually annotated training corpora which is not available for most of the language pairs. 3 Evaluation Measures A word aligner is usually evaluated in terms of Precision, Recall, and F-measure (or shortly F ), which are defined as follows (Fraser and Marcu, 2007): T T |A P | |A S| P recision = , Recall = |A| |S| 1 F − measure = α 1−α P recision + Recall Word Alignment Word alignment is the task of finding the correspondence among the words of a sentence pair (Figure 1). From a mathematical point of view, it is a relation among the words, because any word in a sentence can be mapped into zero, one or more words of the other, and vice-versa; in other words, any kind of link is allowed, namely one-toone, many-to-one, many-to-many, as well as leaving words unaligned. So called IBM models 1-5 (Brown et al., 1993) as well as the HMM-based alignment models ("
W14-0313,2009.eamt-1.31,0,0.0197206,"ng oov-rate, for all language pairs. The oov-based F-measure for berkeley is not reported because it is undefined. depends on the quality of the employed word aligner. Once the alignments are computed and symmetrized (if required), phrase extraction procedure is applied to extract all valid phrase-pairs. Note that un-aligned words are included in the extracted phrase pairs, if their surrounding words are aligned. It has been shown that inclusion of un-aligned words in the phrase-pairs, generally, has negative effects on the translation quality and can produce errors in the translation output (Zhang et al., 2009). Nevertheless, the overlap among phrase-pairs, which contain un-aligned unknown words, can be considered as a valuable source of knowledge for inducing the correct alignment of these words. To get their alignments from the extracted phrase-pairs we follow an approach similar to (Espl´a-Gomis et al., 2012) in which the word alignment probabilities are determined by the alignment strength measure. Given the source and target segments (S = {s1 , . . . , sl } and T = {t1 , . . . , sm }), and the set of extracted parallel phrase-pairs (Φ), the alignment strength Ai,j (S, T, Φ) of the si and tj can"
W14-0313,W08-0509,0,0.0395269,"produces bi-directional symmetrized alignment. fast-align is a recently developed unsupervised word aligner that uses a log-linear reparametrization of IBM model 2 for training the word alignment models (Dyer et al., 2013). We exploited the default configuration with 5 iterations for training. As the system is directional, we trained two systems (source-to-target and targetto-source). When applied to new sentence pairs, we first produced the two directional alignments, and then combined them into a symmetrized alignment by using the grow-diag-final-and heuristic (Och and Ney, 2003). mgiza++ (Gao and Vogel, 2008) and its ancestors, i.e. giza, and giza++, implement all the IBM models and HMM based alignment models. mgiza++ is a multithreaded version of giza++, which enables an efficient use of multi-core platforms. We trained the system using the following configuration for model iterations: 15 h5 33 43 . mgiza++ also produces directional alignment; hence, we followed the same protocol to create a symmetrize alignment of sentence pairs as we did for fast-align. Differently from berkeley and fast-align, mgiza++ somehow adapts its models when applied to new sentence pairs. According to the so-called “for"
W14-0313,2010.amta-papers.21,0,0.0244442,"ons and to hence avoid repeating the same mistakes in future sentences. A typical application scenario is the usage by a professional translator of a Computer Assisted Translation (CAT) tool enhanced with a SMT system. For each input sentence, first the translator receives one or more translation suggestions from 84 Workshop on Humans and Computer-assisted Translation, pages 84–92, c Gothenburg, Sweden, 26 April 2014. 2014 Association for Computational Linguistics put (hypothesis) as a pivot to find the word alignments between the source sentence and its corresponding reference. Similarly to (Hardt and Elming, 2010), once the word alignment between the source and post-edit sentence pair is generated, they use the standard phrase extraction method to extract the parallel phrase pairs. This work is based on an implicit assumption that MT output is reliable enough to make a bridge between source and reference. However, in the real world this is not always true. The post-editor sometimes makes a lot of changes in the MT output, or even translates the entire sentence from scratch, which makes the post-edit very different from the automatic translation. Moreover, in the presence of new words in the source sent"
W14-0313,2005.mtsummit-papers.11,0,0.0275549,"is example, Precision and Recall will be about 0.85 (=11/13) and 0.91 (=10/11), respectively, and the corresponding F is hence about 0.88. Focusing on the oov-alignment only, Precisionoov is 1.00 (=1/1), Recalloov is 0.50 (=1/2), and Foov is 0.67. 3.2 Evaluation Benchmark In this paper, we compare word-alignment performance of three word-aligners introduced in Section 3.3 on three distinct tasks, namely EnglishItalian, English-French, and English-Spanish; the training corpora, common to all word-aligners, are subset of the JRC-legal corpus1 (Steinberger et al., ), of the Europarl corpus V7.0 (Koehn, 2005), and of the Hansard parallel corpus2 , respectively. 1 langtech.jrc.it/JRC-Acquis.html www.isi.edu/natural-language/ download/hansard/index.html 2 86 financial i meccanismi financial i meccanismi assistance di assistenza assistance di assistenza mechanisms finanziaria are sono attivabili mechanisms finanziaria less are less sono attivabili rapidly meno rapidly meno deployable than rapidamente deployable rispetto than rapidamente rispetto conventional ai meccanismi conventional ai budgetary di bilancio budgetary meccanismi di mechanisms convenzionali mechanisms bilancio convenzionali Figure 1:"
W14-0313,D11-1082,0,0.0592225,"Section 3, we describe three widely used toolkits, highlight their pros and cons in the online MT adaptation scenario, and compare their performance in aligning unknown terms. In Section 4 we propose a standalone module which refines the word alignment of unknown words; moreover, we present an enhanced faster implementation of the best performing word aligner, to make it usable in the online scenario. In Section 5 we show experimental results of this module on three different languages. Finally, we draw some final comments in Section 6. 2 In order to improve the quality of the word alignments McCarley et al. (2011) proposed a trainable correction model which given a sentence pair and their corresponding automatically produced word alignment, it tries to fix the wrong alignment links. Similar to the hill-climbing approach used in IBM models 3-5 (Brown et al., 1993), this approach iteratively performs small modifications in each step, based on the changes of the previous step. However, the use of additional sources of knowledge, such as POS tags of the words and their neighbours, helps the system to take more accurate decisions. But, requiring manual word alignments for learning the alignment moves makes"
W14-0313,P00-1056,0,0.375768,"Missing"
W14-0313,J03-1002,0,0.0507465,"ps the system to take more accurate decisions. But, requiring manual word alignments for learning the alignment moves makes this approach only applicable for a limited number of language pairs for which manual aligned gold references are available. Related works Hardt et al. (2010) presented an incremental retraining method which simulates the procedure of learning from post-edited MT outputs (references), in a real time fashion. By dividing the learning task into word alignment and phrase extraction tasks, and replacing the standard wordalignment module, which is a variation of EM algorithm (Och and Ney, 2003), with a greedy search algorithm, they attempt to find a quick approximation of the word alignments of the newly translated sentence. They also use some heuristics to improve the obtained alignments, without supporting it with some proofs or even providing some experimental results. Furthermore, the running time of this approach is not discussed, and it is not clear how effective this approach is in online scenarios. Blain et al. (2012) have recently studied the problem of incremental learning from post-editing data, with minimum computational complexity and acceptable quality. They use the MT"
W14-0313,steinberger-etal-2006-jrc,0,\N,Missing
W14-0313,J93-2003,0,\N,Missing
W17-4723,W16-2308,0,0.0433237,"valuation, our baseline outperforms the 2016 best system’s baseline on the test sets 2015 and 2016. However, in our set-up backtranslations produced a smaller improvement than expected. The final submission is given by the combination of 7 systems, including a system trained only on true parallel data and two right-to-left systems, which improves over our single best system by 1.5 BLEU points. 1 2 Neural Machine Translation Neural machine translation [25] represents the state of the art for machine translation since the outstanding results obtained on IWSLT2015 [17] IWSLT2016 [1, 7] and WMT16 [24, 5] where the neural models greatly outperformed phrase-based systems. NMT is based on the encoder-decoderattention architecture [3] which jointly learns the translation and the alignment model with a sequence-to-sequence learning model. Given a sequence of words f1 , f2 , . . . , fm in the source language, they are used to index an embedding lookup table and retrieve the vectors x1 , x2 , . . . , xm representing the words. The embeddings are processed by a bi-directional RNN Introduction FBK’s participation to the news translations shared task in WMT 17 focused this year on the English-German la"
W17-4723,D17-1151,0,0.0307186,"ater than 50 or length ratio in one direction more than 1:9. In Table 1 we report the number of sentences before and after the cleaning step. The last step of the preprocessing is the BPE segmentation [23]. We trained 45, 000 BPE merge rules over the joint parallel data, which resulted in a vocabulary sizes of 43, 853 words for English and 47, 465 for German. The NMT architecture consists of 2 LSTM layers both in the encoder and in the decoder. We used LSTM RNNs instead of the GRU RNNs, as they performed better in our preliminary experiments. Our result is hence coherent with what reported in [6]. The word embeddings size and the number of hidden units for each LSTM layer are fixed to 500. The encoder is a bidirectional LSTM [21] with 500 hidden units equally divided among the two directions. The optimizer of choice is SGD [20] with exponential decay. In preliminary experiments, using different and smaller datasets, this optimizer outperformed Adagrad [10] and Adam [15]. Figure 1 shows the validation scores after each epoch on the validation sets with the different optimizers. In [7] Adagrad led to better results on the IWSLT En-Fr validation set, thus we argue that the choice of the"
W17-4723,W14-4012,0,0.103825,"tools. With respect to our participation in the IWSLT 2016 evaluation campaign, we switched from the Nematus-Theano framework to the OpenNMT-Torch framework [16]. The reasons were twofold: higher baseline performance and significantly faster training. In our primary submission we used backtranslations [22], BPE-encoding [23] and sys→ − → − h j = g(xj , h j−1 ), j = 1, ..m ← − ← − h j = g(xj , h j+1 ), j = m, .., 1 → − ← − hj = merge( h j , h j ) where merge is a function for merging the output of the RNNs, like the vector concatenation or the point-wise sum, and g is the LSTM [13] or the GRU [8] function. The sequence of vectors produced by the bidirectional RNN is the encoded 271 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 271–275 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics representation of the source sentence. The decoder takes as input the encoder outputs (or states) and produces a sequence of target words e1 , e2 , . . . , el . The decoder works by progressively predicting the probability of the next target word ei given the previously generated target words and the source context"
W17-4723,W11-2107,0,0.0896025,"e dataset. In the bottom Figure the trend is confirmed on IWSLT EN-FR data. System Combination Our primary submission has been produced by merging the outputs of different systems with Jane’s system combination tool [11]. For a system combination of m systems we build m confusion networks that are then merged to form a single confusion network. For each of the small networks, only one of the systems is chosen as the primary system, which is the system that decides the word order. The sentences from every secondary systems are then aligned to the primary. We perform word alignment using METEOR [9], a tool that uses four criteria for aligning words: 1) exact match; 2) stem, which matches two words if their stems computed with the Snowball Stemmer [19] are the same; 3) synonym, which uses the WordNet [18] synsets database; 4) paraphrase, which matches phrases if they are in an internal paraphrase table. When no criterion is matched, there is a match with the empty string. The confusion networks are initialized with the primary system sentences, then the words from the secondary hypothesis are added to the network according to the alignment. The final confusion network is obtained by the"
W17-4723,E14-2008,0,0.0539509,"ng of both the parallel sentences and 5M back-translated parallel sentences randomly sampled from the 30M set. As we describe in the following section, we used monolingual data also for the system combination. 5 Figure 1: Comparison between different optimizers in terms of BLEU. In the top Figure SGD with exponential decay is the best performing against Adam and Adagrad in a private dataset. In the bottom Figure the trend is confirmed on IWSLT EN-FR data. System Combination Our primary submission has been produced by merging the outputs of different systems with Jane’s system combination tool [11]. For a system combination of m systems we build m confusion networks that are then merged to form a single confusion network. For each of the small networks, only one of the systems is chosen as the primary system, which is the system that decides the word order. The sentences from every secondary systems are then aligned to the primary. We perform word alignment using METEOR [9], a tool that uses four criteria for aligning words: 1) exact match; 2) stem, which matches two words if their stems computed with the Snowball Stemmer [19] are the same; 3) synonym, which uses the WordNet [18] synset"
W17-4723,P13-2121,0,0.0831469,"tems that used different training data: 1. A NMT system trained on parallel + synthetic1 for 12 epochs 2. An NMT trained on parallel + synthetic right to left for 11 epochs2 3. The tuning of the baseline for 7 epochs more on parallel + synthetic data 4. The baseline system For each system, with the exception of the baseline, we used the weights of last two epochs. This gave us an improvement on the validation set of 0.5 Bleu points. We improved the system combination by adding a 5-grams language model with modified Kneser-Ney smoothing [14] without pruning, trained on ∼ 500M tokens with KenLM [12]. This improved the result by another +0.6 BLEU on the validation. In Table 2 we present the results of the single systems on newstest 2015 and 16. As expected, the systems are quite different also in terms of performance, especially for newstest2016, thus we expected significant improvements. Surprisingly, we found that our system trained from scratch on back-translated data performed worse than the baseline, while the right-to-left system trained on the same data is slightly better on newstest2015 and 1 Bleu point better on newstest2016. The best system is the one that was trained in two pha"
W17-4723,P17-4012,0,0.0414764,"lookup table and retrieve the vectors x1 , x2 , . . . , xm representing the words. The embeddings are processed by a bi-directional RNN Introduction FBK’s participation to the news translations shared task in WMT 17 focused this year on the English-German language direction. Our purpose was to explore the state of the art and build a competitive neural machine translation [3] system in order to gain a practical knowledge of the available tools. With respect to our participation in the IWSLT 2016 evaluation campaign, we switched from the Nematus-Theano framework to the OpenNMT-Torch framework [16]. The reasons were twofold: higher baseline performance and significantly faster training. In our primary submission we used backtranslations [22], BPE-encoding [23] and sys→ − → − h j = g(xj , h j−1 ), j = 1, ..m ← − ← − h j = g(xj , h j+1 ), j = m, .., 1 → − ← − hj = merge( h j , h j ) where merge is a function for merging the output of the RNNs, like the vector concatenation or the point-wise sum, and g is the LSTM [13] or the GRU [8] function. The sequence of vectors produced by the bidirectional RNN is the encoded 271 Proceedings of the Conference on Machine Translation (WMT), Volume 2: S"
W17-4723,2015.iwslt-evaluation.11,0,0.0764343,"a. With respect to last year’s evaluation, our baseline outperforms the 2016 best system’s baseline on the test sets 2015 and 2016. However, in our set-up backtranslations produced a smaller improvement than expected. The final submission is given by the combination of 7 systems, including a system trained only on true parallel data and two right-to-left systems, which improves over our single best system by 1.5 BLEU points. 1 2 Neural Machine Translation Neural machine translation [25] represents the state of the art for machine translation since the outstanding results obtained on IWSLT2015 [17] IWSLT2016 [1, 7] and WMT16 [24, 5] where the neural models greatly outperformed phrase-based systems. NMT is based on the encoder-decoderattention architecture [3] which jointly learns the translation and the alignment model with a sequence-to-sequence learning model. Given a sequence of words f1 , f2 , . . . , fm in the source language, they are used to index an embedding lookup table and retrieve the vectors x1 , x2 , . . . , xm representing the words. The embeddings are processed by a bi-directional RNN Introduction FBK’s participation to the news translations shared task in WMT 17 focused"
W17-4723,W16-2323,0,0.104557,"valuation, our baseline outperforms the 2016 best system’s baseline on the test sets 2015 and 2016. However, in our set-up backtranslations produced a smaller improvement than expected. The final submission is given by the combination of 7 systems, including a system trained only on true parallel data and two right-to-left systems, which improves over our single best system by 1.5 BLEU points. 1 2 Neural Machine Translation Neural machine translation [25] represents the state of the art for machine translation since the outstanding results obtained on IWSLT2015 [17] IWSLT2016 [1, 7] and WMT16 [24, 5] where the neural models greatly outperformed phrase-based systems. NMT is based on the encoder-decoderattention architecture [3] which jointly learns the translation and the alignment model with a sequence-to-sequence learning model. Given a sequence of words f1 , f2 , . . . , fm in the source language, they are used to index an embedding lookup table and retrieve the vectors x1 , x2 , . . . , xm representing the words. The embeddings are processed by a bi-directional RNN Introduction FBK’s participation to the news translations shared task in WMT 17 focused this year on the English-German la"
