2018.jeptalnrecital-demo.7,Un corpus en arabe annot{\\'e} manuellement avec des sens {W}ord{N}et ({A}rabic Manually Sense Annotated Corpus with {W}ord{N}et Senses),2018,-1,-1,2,1,30964,marwa salah,"Actes de la Conf{\\'e}rence TALN. Volume 2 - D{\\'e}monstrations, articles des Rencontres Jeunes Chercheurs, ateliers DeFT",0,"OntoNotes comprend le seul corpus manuellement annot{\'e} en sens librement disponible pour l{'}arabe. Elle reste peu connue et utilis{\'e}e certainement parce que le projet s{'}est achev{\'e} sans lier cet inventaire au Princeton WordNet qui lui aurait ouvert l{'}acc{\`e}s {\`a} son riche {\'e}cosyst{\`e}me. Dans cet article, nous pr{\'e}sentons une version {\'e}tendue de OntoNotes Release 5.0 que nous avons cr{\'e}{\'e}e en suivant une m{\'e}thodologie de construction semi-automatique. Il s{'}agit d{'}une mise {\`a} jour de la partie arabe annot{\'e}e en sens du corpus en ajoutant l{'}alignement vers le Princeton WordNet 3.0. Cette ressource qui comprend plus de 12 500 mots annot{\'e}s est librement disponible pour la communaut{\'e}. Nous esp{\'e}rons qu{'}elle deviendra un standard pour l{'}{\'e}valuation de la d{\'e}sambigu{\""\i}sation lexicale de l{'}arabe."
2018.jeptalnrecital-court.15,Traduction automatique de corpus en anglais annot{\\'e}s en sens pour la d{\\'e}sambigu{\\\\\i}sation lexicale d{'}une langue moins bien dot{\\'e}e, l{'}exemple de l{'}arabe (Automatic Translation of {E}nglish Sense Annotated Corpora for Word Sense Disambiguation of a Less Well-endowed Language," the Example of {A}rabic)""",2018,-1,-1,3,1,30964,marwa salah,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"Les corpus annot{\'e}s en sens sont des ressources cruciales pour la t{\^a}che de d{\'e}sambigu{\""\i}sation lexicale (Word Sense Disambiguation). La plupart des langues n{'}en poss{\`e}dent pas ou trop peu pour pouvoir construire des syst{\`e}mes robustes. Nous nous int{\'e}ressons ici {\`a} la langue arabe et pr{\'e}sentons 12 corpus annot{\'e}s en sens, fabriqu{\'e}s automatiquement {\`a} partir de 12 corpus en langue anglaise. Nous {\'e}valuons la qualit{\'e} de nos syst{\`e}mes de d{\'e}sambigu{\""\i}sation gr{\^a}ce {\`a} un corpus d{'}{\'e}valuation en arabe nouvellement disponible."
C16-1110,{W}ord2{V}ec vs {DB}nary: Augmenting {METEOR} using Vector Representations or Lexical Resources?,2016,25,3,4,0,5281,christophe servan,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"This paper presents an approach combining lexico-semantic resources and distributed representations of words applied to the evaluation in machine translation (MT). This study is made through the enrichment of a well-known MT evaluation metric: METEOR. METEOR enables an approximate match (synonymy or morphological similarity) between an automatic and a reference translation. Our experiments are made in the framework of the Metrics task of WMT 2014. We show that distributed representations are a good alternative to lexico-semanticresources for MT evaluation and they can even bring interesting additional information. The augmented versions of METEOR, using vector representations, are made available on our Github page."
2016.jeptalnrecital-poster.1,Am{\\'e}lioration de la traduction automatique d{'}un corpus annot{\\'e} (Improvement of the automatic translation of an annotated corpus),2016,-1,-1,2,1,30964,marwa salah,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Posters),0,"Dans cet article, nous pr{\'e}sentons une m{\'e}thode pour am{\'e}liorer la traduction automatique d{'}un corpus annot{\'e} et porter ses annotations de l{'}anglais vers une langue cible. Il s{'}agit d{'}am{\'e}liorer la m{\'e}thode de (Nasiruddin et al., 2015) qui donnait de nombreux segments non traduits, des duplications et des d{\'e}sordres. Nous proposons un processus de pr{\'e}-traitement du SemCor anglais, pour qu{'}il soit adapt{\'e} au syst{\`e}me de traduction automatique statistique utilis{\'e}, ainsi qu{'}un processus de post-traitement pour la sortie. Nous montrons une augmentation de 2,9 points en terme de score F1 sur une t{\^a}che de d{\'e}sambigu{\""\i}sation lexicale ce qui prouve l{'}efficacit{\'e} de notre m{\'e}thode."
2016.jeptalnrecital-long.23,{W}ord2{V}ec vs {DB}nary ou comment (r{\\'e})concilier repr{\\'e}sentations distribu{\\'e}es et r{\\'e}seaux lexico-s{\\'e}mantiques ? Le cas de l{'}{\\'e}valuation en traduction automatique ({W}ord2{V}ec vs {DB}nary or how to bring back together vector representations and lexical resources ? A case study for machine translation evaluation),2016,-1,-1,3,0,5281,christophe servan,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs),0,Cet article pr{\'e}sente une approche associant r{\'e}seaux lexico-s{\'e}mantiques et repr{\'e}sentations distribu{\'e}es de mots appliqu{\'e}e {\`a} l{'}{\'e}valuation de la traduction automatique. Cette {\'e}tude est faite {\`a} travers l{'}enrichissement d{'}une m{\'e}trique bien connue pour {\'e}valuer la traduction automatique (TA) : METEOR. METEOR permet un appariement approch{\'e} (similarit{\'e} morphologique ou synonymie) entre une sortie de syst{\`e}me automatique et une traduction de r{\'e}f{\'e}rence. Nos exp{\'e}rimentations s{'}appuient sur la t{\^a}che Metrics de la campagne d{'}{\'e}valuation WMT 2014 et montrent que les repr{\'e}sentations distribu{\'e}es restent moins performantes que les ressources lexico-s{\'e}mantiques pour l{'}{\'e}valuation en TA mais peuvent n{\'e}ammoins apporter un compl{\'e}ment d{'}information int{\'e}ressant {\`a} ces derni{\`e}res.
2015.mtsummit-papers.7,{METEOR} for multiple target languages using {DB}nary,2015,0,4,2,1,27951,zied elloumi,Proceedings of Machine Translation Summit XV: Papers,0,"This paper proposes an extension of METEOR, a well-known MT evaluation metric, for multiple target languages using an in-house lexical resource called DBnary (an extraction from Wiktionary provided to the community as a Multilingual Lexical Linked Open Data). Today, the use of the synonymy module of METEOR is only exploited when English is the target language (use of WordNet). A synonymy module using DBnary would allow its use for the 21 languages (covered up to now) as target languages. The code of this new instance of METEOR, adapted to several target languages, is provided to the community via a github repository. We also show that our DBnary augmented METEOR increases the correlation with human judgements on the WMT 2013 and 2014 metrics dataset for English-to-(French, Russian, German, Spanish) language pairs."
2015.jeptalnrecital-long.8,"Cr{\\'e}ation rapide et efficace d{'}un syst{\\`e}me de d{\\'e}sambigu{\\\\\i}sation lexicale pour une langue peu dot{\\'e}e""",2015,-1,-1,3,1,36410,mohammad nasiruddin,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Nous pr{\'e}sentons une m{\'e}thode pour cr{\'e}er rapidement un syst{\`e}me de d{\'e}sambigu{\""\i}sation lexicale (DL) pour une langue L peu dot{\'e}e pourvu que l{'}on dispose d{'}un syst{\`e}me de traduction automatique statistique (TAS) d{'}une langue riche en corpus annot{\'e}s en sens (ici l{'}anglais) vers L. Il est, en effet, plus facile de disposer des ressources n{\'e}cessaires {\`a} la cr{\'e}ation d{'}un syst{\`e}me de TAS que des ressources d{\'e}di{\'e}es n{\'e}cessaires {\`a} la cr{\'e}ation d{'}un syst{\`e}me de DL pour la langue L. Notre m{\'e}thode consiste {\`a} traduire automatiquement un corpus annot{\'e} en sens vers la langue L, puis de cr{\'e}er le syst{\`e}me de d{\'e}sambigu{\""\i}sation pour L par des m{\'e}thodes supervis{\'e}es classiques. Nous montrons la faisabilit{\'e} de la m{\'e}thode et sa g{\'e}n{\'e}ricit{\'e} en traduisant le SemCor, un corpus en anglais annot{\'e} gr{\^a}ce au Princeton WordNet, de l{'}anglais vers le bangla et de l{'}anglais vers le fran{\c{c}}ais. Nous montrons la validit{\'e} de l{'}approche en {\'e}valuant les r{\'e}sultats sur la t{\^a}che de d{\'e}sambigu{\""\i}sation lexicale multilingue de Semeval 2013."
F14-2035,Word Sense Induction for Lexical Resource Enrichment (Induction de sens pour enrichir des ressources lexicales) [in {F}rench],2014,0,0,5,1,36410,mohammad nasiruddin,Proceedings of TALN 2014 (Volume 2: Short Papers),0,None
S13-2041,{GETALP} System : Propagation of a {L}esk Measure through an Ant Colony Algorithm,2013,19,13,6,0.640607,5694,didier schwab,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This article presents the GETALP system for the participation to SemEval-2013 Task 12, based on an adaptation of the Lesk measure propagated through an Ant Colony Algorithm, that yielded good results on the corpus of Semeval 2007 Task 7 (WordNet 2.1) as well as the trial data for Task 12 SemEval 2013 (BabelNet 1.0). We approach the parameter estimation to our algorithm from two perspectives: edogenous estimation where we maximised the sum the local Lesk scores; exogenous estimation where we maximised the F1 score on trial data. We proposed three runs of out system, exogenous estimation with BabelNet 1.1.1 synset id annotations, endogenous estimation with BabelNet 1.1.1 synset id annotations and endogenous estimation with WordNet 3.1 sense keys. A bug in our implementation led to incorrect results and here, we present an amended version thereof. Our system arrived third on this task and a more fine grained analysis of our results reveals that the algorithms performs best on general domain texts with as little named entities as possible. The presence of many named entities leads the performance of the system to plummet greatly."
potet-etal-2012-collection,Collection of a Large Database of {F}rench-{E}nglish {SMT} Output Corrections,2012,2,34,4,1,43044,marion potet,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Corpus-based approaches to machine translation (MT) rely on the availability of parallel corpora. To produce user-acceptable translation outputs, such systems need high quality data to be efficiency trained, optimized and evaluated. However, building high quality dataset is a relatively expensive task. In this paper, we describe the data collection and analysis of a large database of 10.881 SMT translation output hypotheses manually corrected. These post-editions were collected using Amazon's Mechanical Turk, following some ethical guidelines. A complete analysis of the collected data pointed out a high quality of the corrections with more than 87 {\%} of the collected post-editions that improve hypotheses and more than 94 {\%} of the crowdsourced post-editions which are at least of professional quality. We also post-edited 1,500 gold-standard reference translations (of bilingual parallel corpora generated by professional) and noticed that 72 {\%} of these translations needed to be corrected during post-edition. We computed a proximity measure between the differents kind of translations and pointed out that reference translations are as far from the hypotheses than from the corrected hypotheses (i.e. the post-editions). In light of these last findings, we discuss the adequation of text-based generated reference translations to train setence-to-sentence based SMT systems."
C12-1146,Ant Colony Algorithm for the Unsupervised Word Sense Disambiguation of Texts: Comparison and Evaluation,2012,30,16,4,0.640607,5694,didier schwab,Proceedings of {COLING} 2012,0,"Brute-force word sense disambiguation (WSD) algorithms based on semantic relatedness are really time consuming. We study how to perform WSD faster and better on the span of a text. Several stochastic algorithms can be used to perform Global WSD. We focus here on an Ant Colony Algorithm and compare it to two other methods (Genetic and Simulated Annealing Algorithms) in order to evaluate them on the Semeval 2007 Task 7. A comparison of the algorithms shows that the Ant Colony Algorithm is faster than the two others, and yields better results. Furthermore, the Ant Colony Algorithm coupled with a majority vote strategy reaches the level of the first sense baseline and among other systems evaluated on the same task rivals the lower performing supervised algorithms."
2012.iwslt-papers.19,Towards a better understanding of statistical post-editing,2012,18,3,3,1,43044,marion potet,Proceedings of the 9th International Workshop on Spoken Language Translation: Papers,0,"We describe several experiments to better understand the usefulness of statistical post-edition (SPE) to improve phrase-based statistical MT (PBMT) systems raw outputs. Whatever the size of the training corpus, we show that SPE systems trained on general domain data offers no breakthrough to our baseline general domain PBMT system. However, using manually post-edited system outputs to train the SPE led to a slight improvement in the translations quality compared with the use of professional reference translations. We also show that SPE is far more effective for domain adaptation, mainly because it recovers a lot of specific terms unknown to our general PBMT system. Finally, we compare two domain adaptation techniques, post-editing a general domain PBMT system vs building a new domain-adapted PBMT system with two different techniques, and show that the latter outperforms the first one. Yet, when the PBMT is a {``}black box{''}, SPE trained with post-edited system outputs remains an interesting option for domain adaptation."
W11-2154,The {LIGA} ({LIG}/{LIA}) Machine Translation System for {WMT} 2011,2011,7,2,6,1,43044,marion potet,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper describes the system submitted by the Laboratory of Informatics of Grenoble (LIG) for the fifth Workshop on Statistical Machine Translation. We participated to the news shared translation task for the French-English language pair. We investigated differents techniques to simply deal with Out-Of-Vocabulary words in a statistical phrase-based machine translation system and analyze their impact on translation quality. The final submission is a combination between a standard phrase-based system using the Moses decoder, with appropriate setups and pre-processing, and a lemmatized system to deal with Out-Of-Vocabulary conjugated verbs."
2011.iwslt-evaluation.8,{LIG} {E}nglish-{F}rench spoken language translation system for {IWSLT} 2011,2011,8,1,3,0,5784,benjamin lecouteux,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the system developed by the LIG laboratory for the 2011 IWSLT evaluation. We participated to the English-French MT and SLT tasks. The development of a reference translation system (MT task), as well as an ASR output translation system (SLT task) are presented. We focus this year on the SLT task and on the use of multiple 1-best ASR outputs to improve overall translation quality. The main experiment presented here compares the performance of a SLT system where multiple ASR 1-best are combined before translation (source combination), with a SLT system where multiple ASR 1-best are translated, the system combination being conducted afterwards on the target side (target combination). The experimental results show that the second approach (target combination) overpasses the first one, when the performance is measured with BLEU."
2011.eamt-1.24,Oracle-based Training for Phrase-based Statistical Machine Translation,2011,19,4,3,1,43044,marion potet,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"A Statistical Machine Translation (SMT) system generates an n-best list of candidate translations for each sentence. A model error occurs if the most probable translation (1-best) generated by the SMT decoder is not the most accurate as measured by its similarity to the human reference translation(s) (an oracle). In this paper we investigate the parametric differences between the 1-best and the oracle translation and attempt to try and close this gap by proposing two rescoring strategies to push the oracle up the n-best list. We observe modest improvements in METEOR scores over the baseline SMT system trained on Frenchxe2x80x93 English Europarl corpora. We present a detailed analysis of the oracle rankings to determine the source of model errors, which in turn has the potential to improve overall system performance."
W10-4009,Ontology driven content extraction using interlingual annotation of texts in the {OMNIA} project,2010,18,2,4,0,37968,achille falaise,Proceedings of the 4th Workshop on Cross Lingual Information Access,0,"OMNIA is an on-going project that aims to retrieve images accompanied with multilingual texts. In this paper, we propose a generic method (language and domain independent) to extract conceptual information from such texts and spontaneous user requests. First, texts are labelled with interlingual annotation, then a generic extractor taking a domain ontology as a parameter extract relevant conceptual information. Implementation is also presented with a first experiment and preliminary results."
W10-1723,The {LIG} Machine Translation System for {WMT} 2010,2010,9,16,3,1,43044,marion potet,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the system submitted by the Laboratory of Informatics of Grenoble (LIG) for the fifth Workshop on Statistical Machine Translation. We participated to the news shared translation task for the French-English language pair. We investigated differents techniques to simply deal with Out-Of-Vocabulary words in a statistical phrase-based machine translation system and analyze their impact on translation quality. The final submission is a combination between a standard phrase-based system using the Moses decoder, with appropriate setups and pre-processing, and a lemmatized system to deal with Out-Of-Vocabulary conjugated verbs."
2010.iwslt-evaluation.12,{LIG} statistical machine translation systems for {IWSLT} 2010,2010,0,1,4,0.654086,5610,laurent besacier,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
2009.mtsummit-btm.3,A Web Service Enabling Gradable Post-edition of Pre-translations Produced by Existing Translation Tools: Practical Use to Provide High-quality Translation of an Online Encyclopedia,2009,-1,-1,1,1,30965,herve blanchon,Beyond Translation Memories: New Tools for Translators Workshop,0,None
2009.iwslt-evaluation.9,{LIG} approach for {IWSLT}09,2009,-1,-1,3,0,13777,fethi bougares,Proceedings of the 6th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the LIG experiments in the context of IWSLT09 evaluation (Arabic to English Statistical Machine Translation task). Arabic is a morphologically rich language, and recent experimentations in our laboratory have shown that the performance of Arabic to English SMT systems varies greatly according to the Arabic morphological segmenters applied. Based on this observation, we propose to use simultaneously multiple segmentations for machine translation of Arabic. The core idea is to keep the ambiguity of the Arabic segmentation in the system input (using confusion networks or lattices). Then, we hope that the best segmentation will be chosen during MT decoding. The mathematics of this multiple segmentation approach are given. Practical implementations in the case of verbatim text translation as well as speech translation (outside of the scope of IWSLT09 this year) are proposed. Experiments conducted in the framework of IWSLT evaluation campaign show the potential of the multiple segmentation approach. The last part of this paper explains in detail the different systems submitted by LIG at IWSLT09 and the results obtained."
huynh-etal-2008-sectra,"{SECT}ra{\\_}w.1: an Online Collaborative System for Evaluating, Post-editing and Presenting {MT} Translation Corpora",2008,8,10,3,0,47527,congphap huynh,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"SECTra{\_}w is a web-oriented system mainly dedicated to the evaluation of MT systems. After importing a source corpus, and possibly reference translations, one can call various MT systems, store their results, and have a collection of human judges perform subjective evaluation online (fluidity, adequacy). It is also possible to perform objective, task-oriented evaluation by letting humans post-edit the MT results, using a web translation editor, and measuring an edit distance and/or the post-editing time. The post-edited results can be added to the set of reference translations, or constitute it if there were no references. SECTra{\_}w makes it possible to show not only tables of figures as results of an evaluation campaign, but also the real data (source, MT outputs, references, post-edited outputs), and to make the post-edition effort sensible by transforming the trace of the edit distance computation in an intuitive presentation, much like a ÂrevisionÂ presentation in Word. The system is written in java under Xwiki and uses the Ajax technique. It can handle large, multilingual and multimedia corpora: EuroParl, BTEC, ERIM (bilingual interpreted dialogues with audio and text), Unesco-B@bel, and a test corpus by France Telecom have been loaded together and used in tests."
2006.iwslt-evaluation.3,{IWSLT}-06: experiments with commercial {MT} systems and lessons from subjective evaluations,2006,11,12,5,0,18749,christian boitet,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This is a short report of our participation to IWSLT-06. First, we let 2 commercial systems participate as fairly as possible (Systran v5.0 for CE, JE, AE, & IE, Atlas-II for JE), taking care of preprocessing and postprocessing tasks, and tuning as many pairs as possible by creating user dictionaries and finding a good combination of parameters (such as dictionary priority). Second, we took part in the subjective evaluation of CE results (fluency and adequacy). Details on experiments and methodological remarks are provided, with a perspective to introduce less expensive and more objective humanand task-related evaluation methods."
2004.jeptalnrecital-poster.5,Traduction de dialogue: r{\\'e}sultats du projet {NESPOLE}! et pistes pour le domaine,2004,-1,-1,1,1,30965,herve blanchon,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Dans cet article, nous d{\'e}taillons les r{\'e}sultats de la seconde {\'e}valuation du projet europ{\'e}en NESPOLE! auquel nous avons pris part pour le fran{\c{c}}ais. Dans ce projet, ainsi que dans ceux qui l{'}ont pr{\'e}c{\'e}d{\'e}, des techniques d{'}{\'e}valuation subjectives {---} r{\'e}alis{\'e}es par des {\'e}valuateurs humains {---} ont {\'e}t{\'e} mises en oeuvre. Nous pr{\'e}sentons aussi les nouvelles techniques objectives {---} automatiques {---} propos{\'e}es en traduction de l{'}{\'e}crit et mises en oeuvre dans le projet C-STAR III. Nous conclurons en proposant quelques id{\'e}es et perspectives pour le domaine."
2004.jeptalnrecital-poster.24,Mod{\\`e}le de langage s{\\'e}mantique pour la reconnaissance automatique de parole dans un contexte de traduction,2004,-1,-1,3,0,52467,quang vuminh,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Le travail pr{\'e}sent{\'e} dans cet article a {\'e}t{\'e} r{\'e}alis{\'e} dans le cadre d{'}un projet global de traduction automatique de la parole. L{'}approche de traduction est fond{\'e}e sur un langage pivot ou Interchange Format (IF), qui repr{\'e}sente le sens de la phrase ind{\'e}pendamment de la langue. Nous proposons une m{\'e}thode qui int{\`e}gre des informations s{\'e}mantiques dans le mod{\`e}le statistique de langage du syst{\`e}me de Reconnaissance Automatique de Parole. Le principe consiste a utiliser certaines classes d{\'e}finies dans l{'}IF comme des classes s{\'e}mantiques dans le mod{\`e}le de langage. Ceci permet au syst{\`e}me de reconnaissance de la parole d{'}analyser partiellement en IF les tours de parole. Les exp{\'e}rimentations realis{\'e}es montrent qu{'}avec cette approche, le syst{\`e}me de reconnaissance peut analyser directement en IF une partie des donn{\'e}es de dialogues de notre application, sans faire appel au syst{\`e}me de traduction (35{\%} des mots ; 58{\%} des tours de parole), tout en maintenant le m{\^e}me niveau de performance du syst{\`e}me global."
2004.jeptalnrecital-long.11,Deux premi{\\`e}res {\\'e}tapes vers les documents auto-explicatifs,2004,-1,-1,1,1,30965,herve blanchon,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans le cadre du projet LIDIA, nous avons montr{\'e} que dans de nombreuses situations, la TA Fond{\'e}e sur le Dialogue (TAFD) pour auteur monolingue peut offrir une meilleure solution en traduction multicible que les aides aux traducteurs, ou la traduction avec r{\'e}vision, m{\^e}me si des langages contr{\^o}l{\'e}s sont utilis{\'e}s. Nos premi{\`e}res exp{\'e}riences ont mis en {\'e}vidence le besoin de conserver les Â« intentions de l{'}auteur Â» au moyen Â« d{'}annotations de d{\'e}sambigu{\""\i}sation Â». Ces annotations permettent de transformer le document source en un Document Auto-Explicatif (DAE). Nous pr{\'e}sentons ici une solution pour int{\'e}grer ces annotations dans un document XML et les rendre visibles et utilisables par un lecteur pour une meilleure compr{\'e}hension du Â« vrai contenu Â» du document. Le concept de Document Auto-Explicatif pourrait changer profond{\'e}ment notre fa{\c{c}}on de comprendre des documents importants ou {\'e}crits dans un style complexe. Nous montrerons aussi qu{'}un DAE, traduit dans une langue cible L, pourrait aussi {\^e}tre transform{\'e}, sans interaction humaine, en un DAE en langue L si un analyseur et un d{\'e}sambigu{\""\i}seur sont disponibles pour cette langue L. Ainsi, un DAE pourrait {\^e}tre utilis{\'e} dans un contexte monolingue, mais aussi dans un contexte multilingue sans travail humain additionnel."
2004.iwslt-papers.1,"Spoken dialogue translation systems evaluation: results, new trends, problems and proposals",2004,23,7,1,1,30965,herve blanchon,Proceedings of the First International Workshop on Spoken Language Translation: Papers,0,"It is important to evaluate Spoken Dialogue Translation Systems, but as we show by analyzing evaluation methods in the Verbmobil, C-STAR II, and the Nespole! projects, the current state of the art is not fully satisfactory. Subjective methods are too costly, and objective methods, although cheaper, donxe2x80x99t give good indications about usability. We propose some ideas to improve that situation."
2004.iwslt-evaluation.3,Towards fairer evaluations of commercial {MT} systems on basic travel expressions corpora,2004,-1,-1,1,1,30965,herve blanchon,Proceedings of the First International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
C02-1170,A Pattern-based Analyzer for {F}rench in the Context of Spoken Language Translation: First Prototype and Evaluation,2002,9,5,1,1,30965,herve blanchon,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"In this paper, we describe a first prototype of a pattern-based analyzer developed in the context of a speech-to-speech translation project using a pivot-based approach (the pivot is called IF). The chosen situation involves a French client talking to an Italian travel agent (both in their own language) to organize a stay in the Trentino area.An IF consists of a dialogue act, and a list, possibly empty, of argument values. The analyzer applies a phrase spotting mechanism on the output of the speech recognition module. It finds well-formed phrases corresponding to argument values. A dialogue act is then built according to the instantiated arguments and some other features of the input.The current version of the prototype has been involved in an evaluation campaign on an unseen corpus of four dialogues consisting of 235 speech turns. The results are given and commented in the last part of the paper. We think they pave the way for future enhancements to both the coverage and the development methodology."
C94-1017,"Perspectives of {DBMT} for monolingual authors on the basis of {LIDIA}-1, an implemented mock-up",1994,8,17,1,1,30965,herve blanchon,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"DBMT is researched here in the context of future systems for the general public, where a monolingual author wants to translate into several languages. We have produced a complete mock-up, LIDIA-1, which demonstrates how a French HyperCardxe2x84xa2 stack could be translated into German, Russian and English. We present the computational, linguistic and ergonomic aspects of the mock-up, and discuss them in the perspective of building an operational prototype in the future."
C92-4198,A Solution for the Problem of Interactive Disambiguation,1992,8,5,1,1,30965,herve blanchon,{COLING} 1992 Volume 4: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"After the experiences of dialogue based MT systems with ITS [9], N-Tran [6] and KBMT-89 [5], the LIDIA project aims at the construction of a mock-up of a personal MT system for a monolingual user. One major aspect of the LIDIA project is thus, the study of a dialogue of standardization and disambiguation between the system and the user so as to produce a high quality translation. This dialogue satisfies two properties: its questions are explicit, so no linguistic knowledge is required; its questions are monolingual, so no foreign language knowledge is needed. Here, we focus on one part of the disambiguation process: the disambiguation of the structure produced by the analyser.n n The structure produced by our analyser is called MMC (Multisolution, Multilevel and Concrete). Multisolution means that the analyser produces every analysis fitting with the syntagmatic, syntactic and logico-semantic model of the grammar (an example is shown fig. 1). Multilevel means that the same structure consists of three levels of linguistic interpretation, namely the level of syntactic and syntagmatic classes, the level of syntactic functions and the level of logic and semantic relations. Finally, the structure is said to be concrete because the original utterance can be found back by a simple left-to-right reading of the structure.n n We have taken into account three kinds of differences between the solutions produced for one sentence, and each kind of difference is associated with the name of an ambiguity. We have defined ambiguities of syntactic classes (cf fig. 2), ambiguities of geometry (cf fig. 3) and ambiguities of syntactic, logic and semantic decoration (cf fig. 4). We have also defined three principles (xc2xa7 III. 1) to order the questions if there is more than one to be asked. The first principle is: first of all, find out the right segmentation into simple sentences. The second principle is: for each common predicate in the MMC structure, find out the right subject, objects and adjuncts. The last principle is: for each simple sentence, find the right structure.n n With those principles we are able to define a strategy (cf fig. 5). We have also isolated some patterns in the three classes of ambiguity. The class of ambiguities of syntactic classes needs no refinement (xc2xa7 III. 3.1). On the other hand we create four patterns of ambiguity of geometry (xc2xa7 III. 3.2) called: verbal coordination, argument structure of the verb, non verbal coordination, subordination; and three patterns of ambiguity of syntactic, logic and semantic decoration (xc2xa7 III. 3.3) called: logico-semantic labelling, argument order of direct transitive verbs, syntactic labelling.n n Here is an example with the interpretations for each pattern we have chosen:n n Problem of class. Le pilote ferme la porte: The firm pilot carries her. The pilot shuts the door.n n Problem of verbal coordination. II regarde la photo et la classe: He looks at the photograph and the class. He looks at the photograph and files it.n n Problem of the argument structure of the verb. II parle de l'ecole de cuisine: He talks about the cooking school. He talks from the cooking school. He talks from the school about cooking.n n Problem of non-verbal coordination. II prend des crayons et des cahiers noirs: He takes pencils and black notebooks. He takes black pencils and black notebooks.n n Problem of subordination. L'ecole de cuisine lyonnaise est fermee: The lyonnaise cooking school is closed. The school of lyonnaise cooking is closed.n n Problem of logico-semantic labelling. Pierre fait porter des chocolats a Lucie: Pierre lets Lucie carry chocolates. Pierre gets chocolates to be delivered to Lucie.n n Problem of argument order of direct transitive verbs. Quel auteur cite ce conferencier: Which author this lecturer is quoting? Which lecturer this author is quoting?n n Problem of syntactic labelling. II parle de la tour Eiffel: He is talking about the Eiffel Tower. He is talking from the Eiffel Tower.n n For each pattern we have defined a method to produce the appropriate dialogue (xc2xa7 III. 3). These methods use two kinds of processing: projection and paraphrase. To build paraphrases we use basically three operators: an operator of semantic replacement of occurrence, an operator of permutation of groups of occurrences and an operator of distribution of occurrences. The examples (xc2xa7 IV) give an idea.n n In conclusion we can say that our method is quite simple but fixed once and for all. We are going to study two points in the near future. The first one is to reduce the number of analysis and thus, by getting information from the user, reduce the time to spend on the disambiguation. The second is to try to build tools which will allow the linguist, designer of the linguistic part of the LIDIA system, to define its own methods of disambiguation."
