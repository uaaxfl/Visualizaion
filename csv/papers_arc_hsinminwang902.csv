2021.rocling-1.5,A Flexible and Extensible Framework for Multiple Answer Modes Question Answering,2021,-1,-1,12,0,2300,chengchung fan,Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing (ROCLING 2021),0,"This paper presents a framework to answer the questions that require various kinds of inference mechanisms (such as Extraction, Entailment-Judgement, and Summarization). Most of the previous approaches adopt a rigid framework which handles only one inference mechanism. Only a few of them adopt several answer generation modules for providing different mechanisms; however, they either lack an aggregation mechanism to merge the answers from various modules, or are too complicated to be implemented with neural networks. To alleviate the problems mentioned above, we propose a divide-and-conquer framework, which consists of a set of various answer generation modules, a dispatch module, and an aggregation module. The answer generation modules are designed to provide different inference mechanisms, the dispatch module is used to select a few appropriate answer generation modules to generate answer candidates, and the aggregation module is employed to select the final answer. We test our framework on the 2020 Formosa Grand Challenge Contest dataset. Experiments show that the proposed framework outperforms the state-of-the-art Roberta-large model by about 11.4{\%}."
2021.rocling-1.15,Mining Commonsense and Domain Knowledge from Math Word Problems,2021,-1,-1,3,0,2344,shihhung tsai,Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing (ROCLING 2021),0,"Current neural math solvers learn to incorporate commonsense or domain knowledge by utilizing pre-specified constants or formulas. However, as these constants and formulas are mainly human-specified, the generalizability of the solvers is limited. In this paper, we propose to explicitly retrieve the required knowledge from math problemdatasets. In this way, we can determinedly characterize the required knowledge andimprove the explainability of solvers. Our two algorithms take the problem text andthe solution equations as input. Then, they try to deduce the required commonsense and domain knowledge by integrating information from both parts. We construct two math datasets and show the effectiveness of our algorithms that they can retrieve the required knowledge for problem-solving."
2021.acl-short.121,Sequence to General Tree: Knowledge-Guided Geometry Word Problem Solving,2021,-1,-1,3,0,2344,shihhung tsai,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"With the recent advancements in deep learning, neural solvers have gained promising results in solving math word problems. However, these SOTA solvers only generate binary expression trees that contain basic arithmetic operators and do not explicitly use the math formulas. As a result, the expression trees they produce are lengthy and uninterpretable because they need to use multiple operators and constants to represent one single formula. In this paper, we propose sequence-to-general tree (S2G) that learns to generate interpretable and executable operation trees where the nodes can be formulas with an arbitrary number of arguments. With nodes now allowed to be formulas, S2G can learn to incorporate mathematical domain knowledge into problem-solving, making the results more interpretable. Experiments show that S2G can achieve a better performance against strong baselines on problems that require domain knowledge."
2019.rocling-1.28,Influences of Prosodic Feature Replacement on the Perceived Singing Voice Identity,2019,-1,-1,3,0,27246,kuanyi kang,Proceedings of the 31st Conference on Computational Linguistics and Speech Processing (ROCLING 2019),0,None
O18-1009,"{W}ave{N}et è²ç¢¼å¨åå\
¶æ¼èªé³è½æä¹æç¨ ({W}ave{N}et Vocoder and its Applications in Voice Conversion) [In {C}hinese]",2018,-1,-1,5,0,29226,wenchin huang,Proceedings of the 30th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2018),0,None
O17-3002,èªé³æä»¶æª¢ç´¢ä½¿ç¨é¡ç¥ç¶ç¶²è·¯æè¡ (On the Use of Neural Network Modeling Techniques for Spoken Document Retrieval) [In {C}hinese],2017,0,0,4,0,2341,tienhong lo,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 22, Number 2, {D}ecember 2017-Special Issue on Selected Papers from {ROCLING} {XXIX}",0,None
O17-3006,åºæ¼éå¥å¼èªç·¨ç¢¼è§£ç¢¼å¨ä¹éé³åæ¾æ»æåµæ¸¬ç³»çµ± (A Replay Spoofing Detection System Based on Discriminative Autoencoders) [In {C}hinese],2017,0,0,6,0,32680,chialung wu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 22, Number 2, {D}ecember 2017-Special Issue on Selected Papers from {ROCLING} {XXIX}",0,None
O17-2001,ç¶ä»£éç£ç£å¼æ¹æ³ä¹æ¯è¼æ¼ç¯éå¼èªé³æè¦ (An Empirical Comparison of Contemporary Unsupervised Approaches for Extractive Speech Summarization) [In {C}hinese],2017,0,0,5,0.793072,19036,shihhung liu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 22, Number 1, June 2017",0,None
O17-1010,åºæ¼éå¥å¼èªç·¨ç¢¼è§£ç¢¼å¨ä¹éé³åæ¾æ»æåµæ¸¬ç³»çµ± (A Replay Spoofing Detection System Based on Discriminative Autoencoders) [In {C}hinese],2017,0,0,4,0,32682,yuding lu,Proceedings of the 29th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2017),0,None
O17-1012,"åºæ¼i-vectorè{PLDA}ä¸¦ä½¿ç¨{GMM}-{HMM}å¼·å¶å°ä½ä¹èªåèªè\
åæ®µæ¨è¨ç³»çµ± (Speaker Diarization based on {I}-vector {PLDA} Scoring and using {GMM}-{HMM} Forced Alignment) [In {C}hinese]",2017,0,0,3,0,32703,chengjo chang,Proceedings of the 29th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2017),0,None
O17-1015,ä½¿ç¨æ¥è©¢æåæ¢ç´¢èé¡ç¥ç¶ç¶²è·¯æ¼èªé³æä»¶æª¢ç´¢ä¹ç ç©¶ (Exploring Query Intent and Neural Network modeling Techniques for Spoken Document Retrieval) [In {C}hinese],2017,0,0,5,0,2341,tienhong lo,Proceedings of the 29th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2017),0,None
O16-1012,éç¨åºåå°åºåçææ¶æ§æ¼éå¯«å¼èªåæè¦(Exploiting Sequence-to-Sequence Generation Framework for Automatic Abstractive Summarization)[In {C}hinese],2016,0,0,4,0.701754,25636,yulun hsieh,Proceedings of the 28th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2016),0,None
C16-1035,Learning to Distill: The Essence Vector Modeling Framework,2016,25,5,4,1,2312,kuanyu chen,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"In the context of natural language processing, representation learning has emerged as a newly active research subject because of its excellent performance in many applications. Learning representations of words is a pioneering study in this school of research. However, paragraph (or sentence and document) embedding learning is more suitable/reasonable for some tasks, such as sentiment classification and document summarization. Nevertheless, as far as we are aware, there is only a dearth of research focusing on launching unsupervised paragraph embedding methods. Classic paragraph embedding methods infer the representation of a given paragraph by considering all of the words occurring in the paragraph. Consequently, those stop or function words that occur frequently may mislead the embedding learning process to produce a misty paragraph representation. Motivated by these observations, our major contributions are twofold. First, we propose a novel unsupervised paragraph embedding method, named the essence vector (EV) model, which aims at not only distilling the most representative information from a paragraph but also excluding the general background information to produce a more informative low-dimensional vector representation for the paragraph. We evaluate the proposed EV model on benchmark sentiment classification and multi-document summarization tasks. The experimental results demonstrate the effectiveness and applicability of the proposed embedding method. Second, in view of the increasing importance of spoken content processing, an extension of the EV model, named the denoising essence vector (D-EV) model, is proposed. The D-EV model not only inherits the advantages of the EV model but also can infer a more robust representation for a given spoken paragraph against imperfect speech recognition. The utility of the D-EV model is evaluated on a spoken document summarization task, confirming the effectiveness of the proposed embedding method in relation to several well-practiced and state-of-the-art summarization methods."
O15-3004,ç¯éå¼èªé³æä»¶æè¦ä½¿ç¨è¡¨ç¤ºæ³å­¸ç¿æè¡ (Extractive Spoken Document Summarization with Representation Learning Techniques) [In {C}hinese],2015,0,0,4,1,32687,kaiwun shih,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 20, Number 2, {D}ecember 2015 - Special Issue on Selected Papers from {ROCLING} {XXVII}",0,None
O15-3005,èª¿è®é »è­åè§£æè¡æ¼å¼·å¥èªé³è¾¨è­ä¹ç ç©¶ (Investigating Modulation Spectrum Factorization Techniques for Robust Speech Recognition) [In {C}hinese],2015,0,0,4,0,37547,tinghao chang,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 20, Number 2, {D}ecember 2015 - Special Issue on Selected Papers from {ROCLING} {XXVII}",0,None
O15-1001,è¡¨ç¤ºæ³å­¸ç¿æè¡æ¼ç¯éå¼èªé³æä»¶æè¦ä¹ç ç©¶(A Study on Representation Learning Techniques for Extractive Spoken Document Summarization) [In {C}hinese],2015,0,0,5,1,32687,kaiwun shih,Proceedings of the 27th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2015),0,None
O15-1010,èª¿è®é »è­åè§£ä¹æ¹è¯æ¼å¼·å¥æ§èªé³è¾¨è­(Several Refinements of Modulation Spectrum Factorization for Robust Speech Recognition) [In {C}hinese],2015,0,0,4,0,37547,tinghao chang,Proceedings of the 27th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2015),0,None
O14-1002,æ¢ç©¶æ°ç©èªå¥æ¨¡ååæè¡æ¼ç¯éå¼èªé³æè¦ (Investigating Novel Sentence Modeling Techniques for Extractive Speech Summarization) [In {C}hinese],2014,0,0,5,1,19036,shihhung liu,Proceedings of the 26th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2014),0,None
D14-1156,Leveraging Effective Query Modeling Techniques for Speech Recognition and Summarization,2014,47,7,5,1,2312,kuanyu chen,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Statistical language modeling (LM) that purports to quantify the acceptability of a given piece of text has long been an interesting yet challenging research area. In particular, language modeling for information retrieval (IR) has enjoyed remarkable empirical success; one emerging stream of the LM approach for IR is to employ the pseudo-relevance feedback process to enhance the representation of an input query so as to improve retrieval effectiveness. This paper presents a continuation of such a general line of research and the main contribution is threefold. First, we propose a principled framework which can unify the relationships among several widely-used query modeling formulations. Second, on top of the successfully developed framework, we propose an extended query modeling formulation by incorporating critical query-specific information cues to guide the model estimation. Third, we further adopt and formalize such a framework to the speech recognition and summarization tasks. A series of empirical experiments reveal the feasibility of such an LM framework and the performance merits of the deduced models on these two tasks."
W13-4414,A Study of Language Modeling for {C}hinese Spelling Check,2013,25,10,4,1,2312,kuanyu chen,Proceedings of the Seventh {SIGHAN} Workshop on {C}hinese Language Processing,0,"Chinese spelling check (CSC) is still an open problem today. To the best of our knowledge, language modeling is widely used in CSC because of its simplicity and fair predictive power, but most systems only use the conventional n-gram models. Our work in this paper continues this general line of research by further exploring different ways to glean extra semantic clues and Web resources to enhance the CSC performance in an unsupervised fashion. Empirical results demonstrate the utility of our CSC system."
O13-1001,æ¹è¯èªå¥æ¨¡åæè¡æ¼ç¯éå¼èªé³æè¦ä¹ç ç©¶ (Improved Sentence Modeling Techniques for Extractive Speech Summarization) [In {C}hinese],2013,0,0,3,1,19036,shihhung liu,Proceedings of the 25th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2013),0,None
I13-1158,"Semantic Na{\\\\\i}ve {B}ayes Classifier for Document Classification""",2013,21,7,4,0,41718,how jing,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"In this paper, we propose a semantic naive Bayes classifier (SNBC) to improve the conventional naive Bayes classifier (NBC) by incorporating xe2x80x9cdocument-levelxe2x80x9d semantic information for document classification (DC). To capture the semantic information from each document, we develop semantic feature extraction and modeling algorithms. For semantic feature extraction, we first apply a log-Bilinear document modeling (LBDM) algorithm to transform each word into a semantic vector, and then apply principal component analysis (PCA) to the semantic space formed by the word vectors to extract a set of semantic features for each document. For semantic modeling, a semantic model is constructed using the semantic features of the training documents. In the testing phase, SNBC systematically integrates the semantic model and the conventional NBC to perform DC. The results of experiments on the 20 News-groups and WebKB datasets confirm that, with the semantic score, SNBC consistently outperforms NBC with various language modeling approaches."
O07-5002,A Novel Characterization of the Alternative Hypothesis Using Kernel Discriminant Analysis for {LLR}-Based Speaker Verification,2007,-1,-1,2,0,49226,yihsiang chao,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 12, Number 3, September 2007: Special Issue on Invited Papers from {ISCSLP} 2006",0,None
O06-4002,An Empirical Study of Word Error Minimization Approaches for {M}andarin Large Vocabulary Continuous Speech Recognition,2006,27,0,3,0,50005,jenwei kuo,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 11, Number 3, September 2006: Special Issue on Selected Papers from {ROCLING} {XVII}",0,"This paper presents an empirical study of word error minimization approaches for Mandarin large vocabulary continuous speech recognition (LVCSR). First, the minimum phone error (MPE) criterion, which is one of the most popular discriminative training criteria, is extensively investigated for both acoustic model training and adaptation in a Mandarin LVCSR system. Second, the word error minimization (WEM) criterion, used to rescore N-best word strings, is appropriately modified for a Mandarin LVCSR system. Finally, a series of speech recognition experiments is conducted on the MATBN Mandarin Chinese broadcast news corpus. The experiment results demonstrate that the MPE training approach reduces the character error rate (CER) by 12% for a system initially trained with the maximum likelihood (ML) approach. Meanwhile, for unsupervised acoustic model adaptation, MPE-based linear regression (MPELR) adaptation outperforms conventional maximum likelihood linear regression (MLLR) in terms of CER reduction. When the WEM decoding approach is used for N-best rescoring, a slight performance gain over the conventional maximum a posteriori (MAP) decoding method is also observed."
O06-2003,A Maximum Entropy Approach for Semantic Language Modeling,2006,31,2,2,0,50014,chuanghua chueh,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 11, Number 1, March 2006: Special Issue on Human Computer Speech Processing",0,"The conventional n-gram language model exploits only the immediate context of historical words without exploring long-distance semantic information. In this paper, we present a new information source extracted from latent semantic analysis (LSA) and adopt the maximum entropy (ME) principle to integrate it into an n-gram language model. With the ME approach, each information source serves as a set of constraints, which should be satisfied to estimate a hybrid statistical language model with maximum randomness. For comparative study, we also carry out knowledge integration via linear interpolation (LI). In the experiments on the TDT2 Chinese corpus, we find that the ME language model that combines the features of trigram and semantic information achieves a 17.9% perplexity reduction compared to the conventional trigram language model, and it outperforms the LI language model. Furthermore, in evaluation on a Mandarin speech recognition task, the ME and LI language models reduce the character error rate by 16.9% and 8.5%, respectively, over the bigram language model."
O05-3004,{MATBN}: A {M}andarin {C}hinese Broadcast News Corpus,2005,-1,-1,1,1,2311,hsinmin wang,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 10, Number 2, June 2005: Special Issue on Annotated Speech Corpora",0,None
O04-1023,èè½ç¡ç·ç°å¢ä¸ä¸­æèªé³è¾¨è­æè½ä¹è©ä¼°èåæ (Performance Evaluation and Analysis of {M}andarin Speech Recognition over Bluetooth Communication Environments) [In {C}hinese],2004,0,0,3,0,51798,yincheng chen,Proceedings of the 16th Conference on Computational Linguistics and Speech Processing,0,None
H01-1050,{M}andarin-{E}nglish Information: Investigating Translingual Speech Retrieval,2001,20,17,9,1,36519,helen meng,Proceedings of the First International Conference on Human Language Technology Research,0,"This paper describes the Mandarin-English Information (MEI) project, where we investigated the problem of cross-language spoken document retrieval (CL-SDR), and developed one of the first English-Chinese CL-SDR systems. Our system accepts an entire English news story (text) as query, and retrieves relevant Chinese broadcast news stories (audio) from the document collection. Hence this is a cross-language and cross-media retrieval task. We applied a multi-scale approach to our problem, which unifies the use of phrases, words and subwords in retrieval. The English queries are translated into Chinese by means of a dictionary-based approach, where we have integrated phrase-based translation with word-by-word translation. Untranslatable named entities are transliterated by a novel subword translation technique. The multi-scale approach can be divided into three subtasks -- multi-scale query formulation, multi-scale audio indexing (by speech recognition) and multi-scale retrieval. Experimental results demonstrate that the use of phrase-based translation and subword translation gave performance gains, and multi-scale retrieval outperforms word-based retrieval."
W00-0504,{M}andarin-{E}nglish Information ({MEI}): Investigating Translingual Speech Retrieval,2000,44,14,5,1,36519,helen meng,{ANLP}-{NAACL} 2000 Workshop: Embedded Machine Translation Systems,0,We describe a system which supports English text queries searching for Mandarin Chinese spoken documents. This is one of the first attempts to tightly couple speech recognition with machine translation technologies for cross-media and cross-language retrieval. The Mandarin Chinese news audio are indexed with word and subword units by speech recognition. Translation of these multiscale units can effect cross-language information retrieval. The integrated technologies will be evaluated based on the performance of translingual speech retrieval.
O99-1008,A New Syllable-based Approach for Retrieving {M}andarin Spoken Documents Using Short Speech Queries,1999,0,0,1,1,2311,hsinmin wang,Proceedings of Research on Computational Linguistics Conference {XII},0,None
O98-4005,Statistical Analysis of {M}andarin Acoustic Units and Automatic Extraction of Phonetically Rich Sentences Based Upon a Very Large {C}hinese Text Corpus,1998,15,7,1,1,2311,hsinmin wang,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 3, Number 2, August 1998",0,"Automatic speech recognition by computers can provide humans with the most convenient method to communicate with computers. Because the Chinese language is not alphabetic and input of Chinese characters into computers is very difficult, Mandarin speech recognition is very highly desired. Recently, high performance speech recognition systems have begun to emerge from research institutes. However, it is believed that an adequate speech database for training acoustic models and evaluating performance is certainly critical for successful deployment of such systems in realistic operating environments. Thus, designing a set of phonetically rich sentences to be used in efficiently training and evaluating a speech recognition system has become very important. This paper first presents statistical analysis of various Mandarin acoustic units based upon a very large Chinese text corpus collected from daily newspapers and then presents an algorithm to automatically extract phonetically rich sentences from the text corpus to be used in training and evaluating a Mandarin speech recognition system."
O93-1008,å¾ä¸­æèªæåº«ä¸­èªåé¸åé£çºåèªèªé³ç¹æ§å¹³è¡¡å¥çæ¹æ³ (Automatic Selection of Phonetically Rich Sentences from A {C}hinese Text Corpus) [In {C}hinese],1993,0,0,1,1,2311,hsinmin wang,Proceedings of Rocling {VI} Computational Linguistics Conference {VI},0,None
