2009.iwslt-evaluation.5,N06-2013,0,0.0238153,"e-Processing for Morphologically Rich Languages Indeed linguistic preprocessing plays a fundamental role in any NLP application involving morphologically rich languages, such as Arabic and Turkish. This is particularly true for SMT into English where differences in word granularity between languages reflects on much higher data sparseness on the source side and on the difficulty to properly model word-level alignments. We approached these problems through morphological segmentation of the source languages, referring partly to the work of [1] on an EnglishTurkish task, and partly to the one of [2] on an ArabicEnglish task. Secondly, as this was shown to have a positive effect on some Arabic-English SMT systems of previous IWSLT editions [3, 4], we developed two simple languagespecific techniques of lexical approximation, which consists in replacing the OOVs of the test set by words of the training that are morphologically close to them. 1. Introduction FBK submitted runs at the IWSLT 2009 Evaluation for the Arabic-English and Turkish-English BTEC tasks, and for the Challenge Task involving Chinese and English languages in both directions. This paper reports on efforts we made in the de"
2009.iwslt-evaluation.5,2009.iwslt-papers.1,1,0.811638,"eaning absence of possessive suffixes is also removed; • copula is split off; • person suffixes are split off from finite verb forms and from copula. The following example shows an analyzed Turkish word before and after segmentation. The number of tokens increases from 1 to 5 as the word is split into noun, possessive, instrumental case, copula and verbal person: 2 More precisely: score = match × 20 − diff × 2 − diff × 5, 1 2 where match, diff1 and diff2 are respectively the numbers of shared contiguous tags, different tags in the OOV word, different tags in the replacer candidate. 1 Refer to [8] for a more detailed and linguistically motivated description. - 38 - Proceedings of IWSLT 2009, Tokyo - Japan where pi ’s are target LMs built on clusters which the training data are split in. With the help of Figure 1, the basic adaptation procedure is described in the following. Let us assume that the parallel training data have been partitioned into a set of M bilingual clusters, according to some criterion. On each cluster, language specific LMs are estimated, which are then organized into two language specific mixture models. All operations described so far are performed off-line. Now le"
2009.iwslt-evaluation.5,P05-1071,0,0.015153,"o language specific mixture models. All operations described so far are performed off-line. Now let us consider a source text or sentence to be translated. Before translation, the input is used to estimate optimal weights of the source language mixture through Expectation-Maximization. The resulting weights are then transferred to the target language mixture, which is finally used as LM feature function by the SMT system. 2.2.1. Morphological Segmentation Several state-of-the-art tools are available to perform morphological segmentation of Arabic text. For the evaluation we have compared MADA [9] and AMIRA [10], two softwares that differ both on their decision strategy and on the segmentation scheme they apply to the words. While the first is a morphological disambiguator based on linguistic features produced by the Buckwalter analyzer [11], the second is a much lighter-weight SVM classifier based on a -5/+5 character context. As for the segmentation schemes (see Table 2) MADA (scheme “D2”) only splits proclitics – namely conjunctions (w+ ‘and’, f+ ‘then’), prepositions (b+ ‘by’, k+ ‘as’, l+ ‘to’) and the future tense (s+) – whereas AMIRA also separates enclitics, i.e. object and poss"
2009.iwslt-evaluation.5,N04-4038,0,0.0110197,"cific mixture models. All operations described so far are performed off-line. Now let us consider a source text or sentence to be translated. Before translation, the input is used to estimate optimal weights of the source language mixture through Expectation-Maximization. The resulting weights are then transferred to the target language mixture, which is finally used as LM feature function by the SMT system. 2.2.1. Morphological Segmentation Several state-of-the-art tools are available to perform morphological segmentation of Arabic text. For the evaluation we have compared MADA [9] and AMIRA [10], two softwares that differ both on their decision strategy and on the segmentation scheme they apply to the words. While the first is a morphological disambiguator based on linguistic features produced by the Buckwalter analyzer [11], the second is a much lighter-weight SVM classifier based on a -5/+5 character context. As for the segmentation schemes (see Table 2) MADA (scheme “D2”) only splits proclitics – namely conjunctions (w+ ‘and’, f+ ‘then’), prepositions (b+ ‘by’, k+ ‘as’, l+ ‘to’) and the future tense (s+) – whereas AMIRA also separates enclitics, i.e. object and possessive pronouns"
2009.iwslt-evaluation.5,P02-1038,0,0.0119197,"ng the possible data sparseness issue that can affect the sentence specific weight estimation. 4.2. Turkish-English System 4.2.1. Data For training our Turkish-English system we exclusively used the provided BTEC training corpus. Parameters were tuned on IWSLT09’s devset1 using the gold reference translation only. Evaluation during development was performed on devset2. 4. Evaluation results 4.1. Baseline System Given a string f in the source language, the goal of statistical machine translation [12] is to select the most probable string e in the target language. By assuming a log-linear model [13, 14], the optimal translation can be searched for with the criterion: e∗ = arg max max e a R X 4.2.2. Baseline Setup The baseline preprocessing consists in simple tokenization (IWSLT09’s released script) and lowercasing of the source side data. Due to the severe mismatch in word order between the languages, we set the distortion limit (DL) to 10. Moses option -drop-unknown was active in all submitted runs. λr hr (e, f , a), 4.2.3. Results r=1 where a represents a word- or phrase-based alignment between f and e, and hr (e, f , a) r = 1, . . . , R are feature functions, designed to model different a"
2009.iwslt-evaluation.5,P07-2045,1,0.0126036,"t of separating the training corpus into several subsets yields wi pi (e) i=1 3 AMIRA splits the same proclitics as MADA except for the future tense. 4 Available - 39 - from http://glaros.dtc.umn.edu/gkhome/views/cluto Proceedings of IWSLT 2009, Tokyo - Japan SRC TRAINING PARALLEL TEXTS SRC SRC TGT CLSTR 1 LM ESTIMATION CLSTR 2 TGT CLSTR M TGT LM 1 LM 1 LM 2 LM 2 LM M LM M CLUSTERING OPTIMIZATION of SRC LMs INTERPOLATION SRC wi OFF−LINE ON−LINE INTERPOLATION of TGT LMs TEXT SMT TRANSLATION Figure 1: Basic procedure for LM adaptation. Our systems are built upon the open-source MT toolkit Moses [15]. The decoder features a statistical log-linear model including a phrase-based translation model, a language model, a distortion model and word and phrase penalties. The weights λr of the log-linear combination are optimized by means of a minimum error training (MERT) procedure [16]. The phrase-based translation model provides direct and inverted frequency-based and lexical-based probabilities for each phrase pair included in a given phrase table. Phrase pairs are extracted from symmetrized word alignments generated by GIZA++ [17]. better results, since the EM procedure is allowed complete fre"
2009.iwslt-evaluation.5,P03-1021,0,0.0149284,"EXTS SRC SRC TGT CLSTR 1 LM ESTIMATION CLSTR 2 TGT CLSTR M TGT LM 1 LM 1 LM 2 LM 2 LM M LM M CLUSTERING OPTIMIZATION of SRC LMs INTERPOLATION SRC wi OFF−LINE ON−LINE INTERPOLATION of TGT LMs TEXT SMT TRANSLATION Figure 1: Basic procedure for LM adaptation. Our systems are built upon the open-source MT toolkit Moses [15]. The decoder features a statistical log-linear model including a phrase-based translation model, a language model, a distortion model and word and phrase penalties. The weights λr of the log-linear combination are optimized by means of a minimum error training (MERT) procedure [16]. The phrase-based translation model provides direct and inverted frequency-based and lexical-based probabilities for each phrase pair included in a given phrase table. Phrase pairs are extracted from symmetrized word alignments generated by GIZA++ [17]. better results, since the EM procedure is allowed complete freedom in assigning the LM weights. However, weights computed in such a manner may be less reliable, since the estimation is performed on few data (one single sentence). 3.3.3. Two-step weight estimation This approach merges the previous two in the attempt of keeping their advantages"
2009.iwslt-evaluation.5,J93-2003,0,\N,Missing
2009.iwslt-evaluation.5,J96-1002,0,\N,Missing
2009.iwslt-evaluation.5,J03-1002,0,\N,Missing
2009.iwslt-evaluation.5,W07-0704,0,\N,Missing
2009.iwslt-evaluation.5,2007.iwslt-1.27,0,\N,Missing
2009.iwslt-evaluation.5,2008.iwslt-evaluation.10,0,\N,Missing
2009.iwslt-papers.1,N06-2013,0,0.588381,"orms of the same suffix into one single form. much simpler than those for Turkish, given that the number of involved clitics and suffixes is typically smaller1 . As pointed by [2], Turkish employs about 30,000 root words and about 150 distinct suffixes. Altough not all possible suffix combinations are grammatical, the number of potential inflected/derived forms of a given root word is still extremely high. This implies that linguistic knowledge becomes crucial to guide the investigation of meaningful segmentation schemes among all possible rule combinations. Another difference with respect to [3] is that in our work we consider not only splitting but also removing suffixes. In previous editions of IWSLT, [4] and [5] tried to further decrease the out-of-vocabulary rate of the Arabic test set by a so-called lexical approximation approach. This idea consists in finding words of the training that are morphologically close to OOVs and introducing them into the translation process by various techniques – i.e. best replacer computation at run-time in [4] or phrase table expansion in [5]. This method was shown to have a positive effect on Arabic-English SMT systems. In this work, we developed"
2009.iwslt-papers.1,P07-2045,1,0.0174347,"on one side to correctly map the translation phrase-pair kız arkadas¸‘girlfriend’ (left), and on the other to capture the complex word re-ordering of the phrase bu yere literally meaning ‘this to-place’ (right). - 131 - Proceedings of IWSLT 2009, Tokyo - Japan Figure 1: Two examples of sentence alignments before (up) and after (bottom) morphological segmentation MS11. 5. Experiments source side of the parallel data. This can be seen as a further sign of the fact that the translation task is being better modeled. 5.1. Baseline The baseline system is built upon the open-source MT toolkit Moses [9]. Phrase pairs are extracted from symmetrized word alignments generated by GIZA++ [10]. The phrase-based translation model provides direct and inverted frequency-based and lexical-based probabilities for each phrase pair included in a given phrase table. The decoder features a statistical log-linear model including a phrase-based translation model, a 5-gram language model, a lexicalized distortion model and word and phrase penalties. Distortion limit is 6 by default. The weights of the log-linear combination are optimized by means of a minimum error training procedure [11] run on IWSLT09’s dev"
2009.iwslt-papers.1,J03-1002,0,0.00382807,"eft), and on the other to capture the complex word re-ordering of the phrase bu yere literally meaning ‘this to-place’ (right). - 131 - Proceedings of IWSLT 2009, Tokyo - Japan Figure 1: Two examples of sentence alignments before (up) and after (bottom) morphological segmentation MS11. 5. Experiments source side of the parallel data. This can be seen as a further sign of the fact that the translation task is being better modeled. 5.1. Baseline The baseline system is built upon the open-source MT toolkit Moses [9]. Phrase pairs are extracted from symmetrized word alignments generated by GIZA++ [10]. The phrase-based translation model provides direct and inverted frequency-based and lexical-based probabilities for each phrase pair included in a given phrase table. The decoder features a statistical log-linear model including a phrase-based translation model, a 5-gram language model, a lexicalized distortion model and word and phrase penalties. Distortion limit is 6 by default. The weights of the log-linear combination are optimized by means of a minimum error training procedure [11] run on IWSLT09’s devset 1 using only the gold reference translation. Evaluation is performed on devset 2."
2009.iwslt-papers.1,W07-0704,0,0.431869,")m kol + (I)m g¨oz + (I)m kafa + (I)m → → → → → sac¸ım elim kolum g¨ozum ¨ kafam ‘my hair’ ‘my hand’ ‘my arm’ ‘my eye’ ‘my head’ Table 2: Different surface forms of possessive suffix -(I)m. If we envisage treating suffixes as single tokens, we foresee an additional increase of data sparseness due to suffix allomorphy. To cope with this problem, we need to introduce an abstract notation that factorizes different surface forms of the same suffix into one single form. much simpler than those for Turkish, given that the number of involved clitics and suffixes is typically smaller1 . As pointed by [2], Turkish employs about 30,000 root words and about 150 distinct suffixes. Altough not all possible suffix combinations are grammatical, the number of potential inflected/derived forms of a given root word is still extremely high. This implies that linguistic knowledge becomes crucial to guide the investigation of meaningful segmentation schemes among all possible rule combinations. Another difference with respect to [3] is that in our work we consider not only splitting but also removing suffixes. In previous editions of IWSLT, [4] and [5] tried to further decrease the out-of-vocabulary rate"
2009.iwslt-papers.1,2007.iwslt-1.27,0,\N,Missing
2009.iwslt-papers.1,P03-1021,0,\N,Missing
2009.iwslt-papers.1,2008.iwslt-evaluation.10,0,\N,Missing
2010.iwslt-evaluation.5,N03-1017,0,0.00258058,"ish-English. The combination of several Turkish segmentation schemes into a lattice input led to an improvement wrt to last year. The use of additional training data was explored for Arabic-English, while on the English to French task improvement was achieved over a strong baseline by automatically selecting relevant and high quality data from the available training corpora. 1. BTEC task Turkish and Arabic are morphologically rich languages. When dealing with a small scale task such as the BTEC, this characteristic can have a particularly negative impact on phrase-based statistical MT methods [1]. Following last year’s findings [2] we decided to continue working on the problem of out-of-vocabulary words (OOVs) using different strategies. In the Arabic-English pair we tested the usefulness of additional resources by decoding with multiple phrase-tables. As for Turkish-English, we enriched our morphological segmentation rule set and combined several segmentation schemes inside a word lattice. In order to further improve the coverage of the models on the test, we then tried to refine the lexical approximation technique developed last year. 1.1. Arabic-English The experience of last year"
2010.iwslt-evaluation.5,P08-1115,0,0.0847327,"fixes replaced by tags as explained in [4]. The rules for suffix splitting or removal are then applied according to the selected segmentation scheme. It can be seen that in some cases the new rules allow for a better correspondence at the level of words between the Turkish sentence and its English translation. However, this doesn’t always corresponds to an improvement in translation quality (see Table 3). It was shown in [7] that the choice of the optimal segmentation scheme for Arabic-English SMT is not a trivial problem and may depend on several factors such as the training data size. Later [8] obtained considerable gains in translation quality by combining unsegmented and segmented Arabic test sentences into a lattice. Given these findings and given that the segmentation space of Turkish is even richer 1o ¨ ks¨ur¨uk: ‘cough’, P1sg: 1st person singular possessive, Acc: accusative, dur-: ‘stop’, Caus: causative, Able: ability, Neg: negation, Prog1: present progressive, A1sg: 1st person singular subject suffix. segmentation MS11 MS13 MS14 MS15 MS11+13+15 BLEU – NIST 60.30 – 9.367 58.98 – 9.357 57.76 – 9.373 60.32 – 9.575 60.41 – 9.650 1.3. Evaluation results and discussion All our sys"
2010.iwslt-evaluation.5,P07-2045,1,0.0268624,"Missing"
2010.iwslt-evaluation.5,P03-1021,0,0.0310921,"Missing"
2010.iwslt-evaluation.5,N04-4038,0,0.322573,"Missing"
2010.iwslt-evaluation.5,2009.iwslt-papers.1,1,0.928397,"ide) of newswire parallel text. Multiple phrase-table decoding was handled by the Moses decoder [9] in the ‘either’ mode, that is for each phrase the union of translation options coming from all the tables is considered. 1.2. Turkish-English Turkish morphology is agglutinative, which implies that the vocabulary is built by a wide range of basic suffix combinations. Thus it often occurs that a Turkish word is aligned with an English phrase, and sometimes even to a whole sentence as in the following example: oda odam odamda odamdayım ‘room’ ‘my room’ ‘in my room’ ‘I am in my room’ Previous work [4] has shown that selectively splitting and removing suffixes from the Turkish text used to train a phrase-base SMT system considerably boosts performances 53 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 in a small scale task like the BTEC. The best segmentation scheme reported in that paper (MS11) mainly includes rules for nominal case and possessive suffixes, plus a few rules on verbal suffixation, namely the splitting of the copula and of the person subject suffixes. In order to better address the rich verbal morphology we adde"
2010.iwslt-evaluation.5,N06-2013,0,0.0267942,"make my cough stop) Table 21 illustrates the segmentation process: the Turkish text is first morphologically analysed and disambiguated ([5], [6]) and the surface form of suffixes replaced by tags as explained in [4]. The rules for suffix splitting or removal are then applied according to the selected segmentation scheme. It can be seen that in some cases the new rules allow for a better correspondence at the level of words between the Turkish sentence and its English translation. However, this doesn’t always corresponds to an improvement in translation quality (see Table 3). It was shown in [7] that the choice of the optimal segmentation scheme for Arabic-English SMT is not a trivial problem and may depend on several factors such as the training data size. Later [8] obtained considerable gains in translation quality by combining unsegmented and segmented Arabic test sentences into a lattice. Given these findings and given that the segmentation space of Turkish is even richer 1o ¨ ks¨ur¨uk: ‘cough’, P1sg: 1st person singular possessive, Acc: accusative, dur-: ‘stop’, Caus: causative, Able: ability, Neg: negation, Prog1: present progressive, A1sg: 1st person singular subject suffix. s"
2010.iwslt-evaluation.5,2010.iwslt-papers.3,1,0.882252,"Missing"
2010.iwslt-evaluation.5,J03-1002,0,0.00410318,"Missing"
2010.iwslt-evaluation.5,P07-1019,0,0.0308228,"Missing"
2011.iwslt-evaluation.18,W08-0320,0,0.577452,"eavily depends on the quantity of the available training material. The strain to balance these contrasting needs has motivated a large body of work in domain adaptation. In this work, we aim at increasing the coverage of a small but precise in-domain model. To this end, we assume that all the information coming from our primary source should be preserved as is, and use the secondary sources only to ‘fill the gaps’. The idea of fill-up goes back to Besling and Meier [1], which addressed the problem of language model adaptation for speech recognition, and was recently introduced in SMT by Nakov [2]. The original method was conceived by [1] to train speaker-dependent dictation systems and proved to outperform classical linear interpolation. In that context, the primary source of information was, naturally, the set of sentences uttered by a given speaker, as opposed to all the others. The SMT scenario that we are addressing is of course different, but here we can use our prior knowledge of the task to make assumptions on the relevance of the available corpora. For a practical example, consider the TED1 talks translation task [3]. The training material provided for the IWSLT11 1 http://www"
2011.iwslt-evaluation.18,eck-etal-2004-language,0,0.0652307,"can thus obtain models that are less redundant and easier to tune. The rest of this paper is organized as follows. After a review of relevant work, we describe in detail the fill-up technique and present possible refinements and extensions. In the experimental section, we apply the fill-up technique to two TED translation tasks and compare it with the two most popular methods for phrase table combination: linear and loglinear interpolation. 2. Previous Work Previous work on domain adaptation for SMT has focused on techniques for selecting parallel or monolingual in-domain training data (e.g. [4]), as well as methods for combining models trained independently on in-domain and on outof-domain data. Given the scope of our work, we review here only approaches for combining in-domain and out-ofdomain (background) translation models. Existing approaches combine different sources either at the data level or at phrase-table level. Adaptation at phrasetable level is either done off-line, typically by a linear mixture of weights, or at decoding-time through a log-linear combination. In the former case, a generative model and maximum likelihood estimation are employed; in the latter case weight"
2011.iwslt-evaluation.18,W07-0717,0,0.893608,"review here only approaches for combining in-domain and out-ofdomain (background) translation models. Existing approaches combine different sources either at the data level or at phrase-table level. Adaptation at phrasetable level is either done off-line, typically by a linear mixture of weights, or at decoding-time through a log-linear combination. In the former case, a generative model and maximum likelihood estimation are employed; in the latter case weights of the log-linear interpolation are typically learned discriminatively by directly optimizing the performance of the SMT decoder. In [5] a mixture-model approach is proposed, with weights depending on some text distances between in136 domain data and the mixture components. The authors explored different choices: cross-domain and dynamic adaptation; linear and log-linear mixtures; different text distance metrics and methods to map them to linear mixture weights. For log-linear mixtures, weights were estimated globally with the other features of the phrase-based model, through minimum error rate training [6]. Notice that the employed system used a relatively small number of features: two probabilities for each phrase table, one"
2011.iwslt-evaluation.18,P03-1021,0,0.270727,"linear interpolation are typically learned discriminatively by directly optimizing the performance of the SMT decoder. In [5] a mixture-model approach is proposed, with weights depending on some text distances between in136 domain data and the mixture components. The authors explored different choices: cross-domain and dynamic adaptation; linear and log-linear mixtures; different text distance metrics and methods to map them to linear mixture weights. For log-linear mixtures, weights were estimated globally with the other features of the phrase-based model, through minimum error rate training [6]. Notice that the employed system used a relatively small number of features: two probabilities for each phrase table, one for each language model, a length penalty, and a distortion model. Reported results show improvements by the linear and log-linear mixtures over a baseline trained on the union of all training data. Remarkably, best results with the linear mixture were obtained using uniform weights. In [7] a phrase-based SMT system trained on Europarl data is adapted to the news domain by integrating it with language and translation models, explicitly trained on indomain data. In particul"
2011.iwslt-evaluation.18,W07-0733,0,0.848423,"ds to map them to linear mixture weights. For log-linear mixtures, weights were estimated globally with the other features of the phrase-based model, through minimum error rate training [6]. Notice that the employed system used a relatively small number of features: two probabilities for each phrase table, one for each language model, a length penalty, and a distortion model. Reported results show improvements by the linear and log-linear mixtures over a baseline trained on the union of all training data. Remarkably, best results with the linear mixture were obtained using uniform weights. In [7] a phrase-based SMT system trained on Europarl data is adapted to the news domain by integrating it with language and translation models, explicitly trained on indomain data. In particular, the in-domain phrase-table was added to the global log-linear model. As a difference with [5], phrase-pairs are here scored with four translation probabilities and four reordering probabilities, thus resulting in a significantly larger set of feature weights to be trained. In [8] in-domain and out-of-domain phrase-tables are also combined using a two-component linear mixture. Extensive experiments are repor"
2011.iwslt-evaluation.18,I08-2088,0,0.0632227,"ained on the union of all training data. Remarkably, best results with the linear mixture were obtained using uniform weights. In [7] a phrase-based SMT system trained on Europarl data is adapted to the news domain by integrating it with language and translation models, explicitly trained on indomain data. In particular, the in-domain phrase-table was added to the global log-linear model. As a difference with [5], phrase-pairs are here scored with four translation probabilities and four reordering probabilities, thus resulting in a significantly larger set of feature weights to be trained. In [8] in-domain and out-of-domain phrase-tables are also combined using a two-component linear mixture. Extensive experiments are reported with different data-selection criteria and empirical weight settings. The contribution of the mixture approach is relevant and quite stable within a large interval of weight values, centered around 0.5. Very recently [9] proposed novel data selection criteria to extract “pseudo in-domain” data from a large background parallel corpus which is then used either to train a domainspecific SMT system, or to adapt a generic SMT system via linear and log-linear mixtures"
2011.iwslt-evaluation.18,D11-1033,0,0.294499,"added to the global log-linear model. As a difference with [5], phrase-pairs are here scored with four translation probabilities and four reordering probabilities, thus resulting in a significantly larger set of feature weights to be trained. In [8] in-domain and out-of-domain phrase-tables are also combined using a two-component linear mixture. Extensive experiments are reported with different data-selection criteria and empirical weight settings. The contribution of the mixture approach is relevant and quite stable within a large interval of weight values, centered around 0.5. Very recently [9] proposed novel data selection criteria to extract “pseudo in-domain” data from a large background parallel corpus which is then used either to train a domainspecific SMT system, or to adapt a generic SMT system via linear and log-linear mixtures, similarly to [5] but with a feature set similar to that used in [7]. In the reported experiments, the log-linear method outperformed the linear mixture adaptation method and both methods outperformed the in-domain and generic baselines. In [10] a corpus identifier is introduced to distinguish parallel in-domain data from out-of-domain data in a facto"
2011.iwslt-evaluation.18,2010.eamt-1.29,0,0.0596402,"ch is relevant and quite stable within a large interval of weight values, centered around 0.5. Very recently [9] proposed novel data selection criteria to extract “pseudo in-domain” data from a large background parallel corpus which is then used either to train a domainspecific SMT system, or to adapt a generic SMT system via linear and log-linear mixtures, similarly to [5] but with a feature set similar to that used in [7]. In the reported experiments, the log-linear method outperformed the linear mixture adaptation method and both methods outperformed the in-domain and generic baselines. In [10] a corpus identifier is introduced to distinguish parallel in-domain data from out-of-domain data in a factored translation model. Each target word is assigned an id tag corresponding to the part of the corpus from which it belongs. Three additional translation model features are introduced to compute the probability of corpus id tags being generated given the source phrase, as well as the source and target phrase probabilities, given the corpus id tags. The incorporation of corpus id tags promotes the preference of phrase pairs from a specific domain. Finally, the system description paper [2]"
2011.iwslt-evaluation.18,N03-1017,0,0.0142772,"and background data. This implies word alignment2 , phrase extraction and phrase scoring. In standard adaptation scenarios, background data is augmented with in-domain data; however, in the fill-up case, the background table is merged with the in-domain table by adding only new phrase pairs that do not appear in the in-domain table. Formally, let T1 and T2 be the in-domain and the background phrase tables, respectively. The translation model assigns a feature vector to each phrase pair φ(f˜, e˜), where f˜ and e˜ are respectively the source and target phrases. Namely, in the model we are using [11], five features are defined for each phrase pair: φ(f˜, e˜) = (Pph (˜ e|f˜), Pph (f˜|˜ e), Plex (˜ e|f˜), Plex (f˜|˜ e), pp(f˜|˜ e)) where Pph refers to the phrase translation probability, Plex is the lexical weighting probability, and pp is a constant phrase penalty that serves to adjust the degree of phrase segmentation (typically pp = exp(1)). Then, the filled-up model TF is defined as follows: ∀(f˜, e˜) ∈ T1 ∪ T2 : 8 &gt; &gt; &lt; (φ1 (f˜, e˜), exp(0)) φF (f˜, e˜) = &gt; &gt; : (φ2 (f˜, e˜), exp(1)) if (f˜, e˜) ∈ T1 otherwise The entries of the filled-up model correspond to the union of the two phrase t"
2011.iwslt-evaluation.18,N04-4026,0,0.0610555,"word alignment, this first step can be performed on the concatenation of all corpora, provided that phrase extraction and scoring are carried out separately on each corpus. 3 We apply the exponential function to binary features to neutralize the log function that is applied to all features participating in the log-linear model. 137 ing a way to promote one set of phrase pairs with respect to the other. 3.1. Reordering table fill-up When combining multiple phrase tables, one has generally to deal with phrase reordering models as well. Our system includes a popular lexicalized reordering model [12, 13, 14] whose entries are those of the phrase table trained on the same corpus, and whose features are reordering probabilities with three possible values: monotonic if immediately following the last translated phrase, swap if immediately preceding it or else discontinuous. The phrase table fill-up technique can be seamlessly applied to this type of reordering model, with the only difference that no additional feature is introduced. 3.2. Pruning options We explored several pruning options to limit the new translation model size: • NewSourceMaxLength: set a maximum length for the source side of new (b"
2011.iwslt-evaluation.18,2005.iwslt-1.8,0,0.17682,"word alignment, this first step can be performed on the concatenation of all corpora, provided that phrase extraction and scoring are carried out separately on each corpus. 3 We apply the exponential function to binary features to neutralize the log function that is applied to all features participating in the log-linear model. 137 ing a way to promote one set of phrase pairs with respect to the other. 3.1. Reordering table fill-up When combining multiple phrase tables, one has generally to deal with phrase reordering models as well. Our system includes a popular lexicalized reordering model [12, 13, 14] whose entries are those of the phrase table trained on the same corpus, and whose features are reordering probabilities with three possible values: monotonic if immediately following the last translated phrase, swap if immediately preceding it or else discontinuous. The phrase table fill-up technique can be seamlessly applied to this type of reordering model, with the only difference that no additional feature is introduced. 3.2. Pruning options We explored several pruning options to limit the new translation model size: • NewSourceMaxLength: set a maximum length for the source side of new (b"
2011.iwslt-evaluation.18,D08-1089,0,0.503345,"word alignment, this first step can be performed on the concatenation of all corpora, provided that phrase extraction and scoring are carried out separately on each corpus. 3 We apply the exponential function to binary features to neutralize the log function that is applied to all features participating in the log-linear model. 137 ing a way to promote one set of phrase pairs with respect to the other. 3.1. Reordering table fill-up When combining multiple phrase tables, one has generally to deal with phrase reordering models as well. Our system includes a popular lexicalized reordering model [12, 13, 14] whose entries are those of the phrase table trained on the same corpus, and whose features are reordering probabilities with three possible values: monotonic if immediately following the last translated phrase, swap if immediately preceding it or else discontinuous. The phrase table fill-up technique can be seamlessly applied to this type of reordering model, with the only difference that no additional feature is introduced. 3.2. Pruning options We explored several pruning options to limit the new translation model size: • NewSourceMaxLength: set a maximum length for the source side of new (b"
2011.iwslt-evaluation.18,P07-2045,1,0.0236945,"English and English-to-French. Training and test data were provided by the organizers of the IWSLT11 evaluation, and are summarized in Table 15 . The tuning (dev2010) and test (test2010) sets have one reference translation. Concerning preprocessing we apply standard tokenization to the English and French data, while for Arabic we use our in-house tokenizer that also removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA [16] according to the ATB scheme6 . For both language pairs, we set up a standard phrasebased system using the Moses toolkit [15]. The decoder features a statistical log-linear model including one or more 4 These observations refer to the Moses decoder [15], but we are not aware of other decoders having a different solution to this problem. 5 Europarl corpus was also available for English-to-French, but we did not use it in our experiments. 6 The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. 138 Table 1: IWSLT11 training and test data statistics: number of sentences |S|, number of tokens |W |and average senten"
2011.iwslt-evaluation.18,N04-4038,0,0.0135362,"d of 33. We evaluate fill-up, log-linear and linear interpolation on the TED task, in two different language pairs: Arabic-toEnglish and English-to-French. Training and test data were provided by the organizers of the IWSLT11 evaluation, and are summarized in Table 15 . The tuning (dev2010) and test (test2010) sets have one reference translation. Concerning preprocessing we apply standard tokenization to the English and French data, while for Arabic we use our in-house tokenizer that also removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA [16] according to the ATB scheme6 . For both language pairs, we set up a standard phrasebased system using the Moses toolkit [15]. The decoder features a statistical log-linear model including one or more 4 These observations refer to the Moses decoder [15], but we are not aware of other decoders having a different solution to this problem. 5 Europarl corpus was also available for English-to-French, but we did not use it in our experiments. 6 The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article"
2011.iwslt-evaluation.18,D07-1103,0,0.0241895,"1.6 128.3 32.1 0.7 – 2.7 – 0.1 – 1.3 – 2.5 – 0.02 5.1. Arabic to English phrase translation models, target language models, a phrase reordering model [12, 13], distortion, word and phrase penalties. In the Arabic-English task, we use a hierarchical reordering model [14], while in the English-French task we use a default word-based bidirectional extraction model. For each target language, two 5-gram language models are trained independently on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. The distortion limit is set to the default value of 6. As proposed by [17], statistically improbable phrase pairs are removed by all our phrase tables (before merging). The Arabic-English systems use cased translation models, while the English-French systems use lowercased models and a standard recasing postprocess. Word alignments are computed by GIZA++ [18] on the concatenation of all data. Consequently, phrase extraction and scoring are carried out separately on each corpus. Table 2 provides summary statistics on the phrase overlaps of the NEWS and UN phrase tables with respect to the TED phrase table. Note that, in this work, we do not evaluate the contribution"
2011.iwslt-evaluation.18,J03-1002,0,0.0118468,"glish-French task we use a default word-based bidirectional extraction model. For each target language, two 5-gram language models are trained independently on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. The distortion limit is set to the default value of 6. As proposed by [17], statistically improbable phrase pairs are removed by all our phrase tables (before merging). The Arabic-English systems use cased translation models, while the English-French systems use lowercased models and a standard recasing postprocess. Word alignments are computed by GIZA++ [18] on the concatenation of all data. Consequently, phrase extraction and scoring are carried out separately on each corpus. Table 2 provides summary statistics on the phrase overlaps of the NEWS and UN phrase tables with respect to the TED phrase table. Note that, in this work, we do not evaluate the contribution of the reodering model in isolation. Thus, in each experiment, the same data combination technique is used to build both translation and reordering models. As suggested by [19], we use approximate randomization to test whether differences among system performances are statistically sign"
2011.iwslt-evaluation.18,W05-0908,0,0.0299325,"ench systems use lowercased models and a standard recasing postprocess. Word alignments are computed by GIZA++ [18] on the concatenation of all data. Consequently, phrase extraction and scoring are carried out separately on each corpus. Table 2 provides summary statistics on the phrase overlaps of the NEWS and UN phrase tables with respect to the TED phrase table. Note that, in this work, we do not evaluate the contribution of the reodering model in isolation. Thus, in each experiment, the same data combination technique is used to build both translation and reordering models. As suggested by [19], we use approximate randomization to test whether differences among system performances are statistically significant7 . 7 Significance tests were computed with the Multeval toolkit: https://github.com/jhclark/multeval We apply fill-up and plug the resulting phrase and reordering tables (5+1 and 6 features respectively) to the decoder. The global feature vector for each experimental setting is then optimized by minimum error rate training (MERT) [6]. Table 3 presents translation quality results in terms of BLEU and NIST scores, using different data combination techniques: concat stands for a"
2011.iwslt-evaluation.18,W05-0900,0,\N,Missing
2011.iwslt-evaluation.18,2011.iwslt-evaluation.1,1,\N,Missing
2015.mtsummit-papers.12,N15-1027,0,0.0151387,"eterministically mapped to a soft tag ri . where Wc , Wh , and Wm are weight matrices, cj and hi are shorthands for [sj−k ; . . . ; sj+k ] and [ri−1 ; . . . ; ri−n+1 ] respectively, [v; v0 ] denotes vector concatenation, and φ is a non-linear transfer prelu. As φ, we use in all experiments the channel-shared parametric rectified linear unit (PReLU) introduced by He et al. (2015). PReLU φ(x) is defined as: φ(x) ( x if x > 0 φ(x) = ax otherwise x where a is a parameter learned during training. To speed up decoding, we train the Inf-NN model with a self-normalized objective (Devlin et al., 2014; Andreas and Klein, 2015). More specifically, we adopt the objective function proposed by Andreas and Klein (2015):   2 `(θ) = − E ln p(ri |hi , cj ) + η kθk2  γ  + E ln2 Z(hi , cj )|(hi , cj ) ∈ H p where H is a set of random samples on which self-normalization is performed, θ =  {sj }, {ri }, Wc , Wh , Wm , bz , a are the parameters of the networks, and Z(hi , cj ) is the partition function of the input (hi , cj ). In practice, we obtain H by sampling from a Bernoulli distribution Bern(p). This is equivalent to applying dropout (Srivastava et al., 2014) on the loss gradient 1 ∈ Rm of self-normalization term, wh"
2015.mtsummit-papers.12,P08-1087,0,0.202399,"ural language or translation modeling. 3 A Distributed Inflection Model In MRLs, the surface form of a word is heavily determined by its grammatical features, such as number, case, tense etc. Choosing the right target word form during translation is a complex problem since some of these features depend on the source context while others depend on the target context (agreement phenomena). We model target language inflection by a Markov process generating a sequence of abstract word representations based on source and target context. This complements previous work focusing on either the former (Avramidis and Koehn, 2008; Chahuneau et al., 2013; Tran et al., 2014) or the latter (Green and DeNero, 2012; Fraser et al., 2012; Botha and Blunsom, 2014; Bisazza and Monz, 2014). 3.1 Soft Morphological Representations As previously stated, it is common for words in MRLs to admit multiple morphological analyses out of context. Rather than trying to disambiguate the analyses in context using for instance conditional random fields (Green and DeNero, 2012; Fraser et al., 2012), we modify the tagging scheme so that each word corresponds to only one tag. To also avoid the loss of useful information incurred when arbitraril"
2015.mtsummit-papers.12,C14-1181,1,0.916601,"rather than generating new inflections, motivated by previous observations that, when translating into MRLs, a large number of reference inflections are already available in the SMT models but are not selected for Viterbi translation (Green and DeNero, 2012; Tran et al., 2014). More in general, our work is related to class-based language modeling (Brown et al., 1992) with the major difference that we also condition on source-side context and that we use explicit morphological representations instead of data-driven word clusters (Uszkoreit and Brants, 2008), word suffixes (Müller et al., 2012; Bisazza and Monz, 2014) or coarse-grained part-ofspeech tags (Koehn et al., 2008). Modeling morphology using neural networks has recently shown promising results: in the context of monolingual neural language modeling, Luong et al. (2013); Botha and Blunsom (2014) obtain the vectorial representation of a word by composing the representations of its morphemes. Tran et al. (2014) model translation stem and suffix selection in SMT with a bilingual neural network. Soricut and Och (2015) discover morphological transformation rules from word embeddings learned by a shallow network. We are not aware of work that leveraged"
2015.mtsummit-papers.12,2011.iwslt-evaluation.18,1,0.882169,"Missing"
2015.mtsummit-papers.12,J92-4003,0,0.0650167,"e been integrated to SMT as additional feature functions: e.g. as an additional lexical translation score (Jeong et al., 2010; Tran et al., 2014) or as an additional target language model score (Green and DeNero, 2012). We follow this last strategy, rather than generating new inflections, motivated by previous observations that, when translating into MRLs, a large number of reference inflections are already available in the SMT models but are not selected for Viterbi translation (Green and DeNero, 2012; Tran et al., 2014). More in general, our work is related to class-based language modeling (Brown et al., 1992) with the major difference that we also condition on source-side context and that we use explicit morphological representations instead of data-driven word clusters (Uszkoreit and Brants, 2008), word suffixes (Müller et al., 2012; Bisazza and Monz, 2014) or coarse-grained part-ofspeech tags (Koehn et al., 2008). Modeling morphology using neural networks has recently shown promising results: in the context of monolingual neural language modeling, Luong et al. (2013); Botha and Blunsom (2014) obtain the vectorial representation of a word by composing the representations of its morphemes. Tran et"
2015.mtsummit-papers.12,W12-3102,1,0.788711,"edings), we construct phrase table and reordering models for this experiment using the fillup technique (Bisazza et al., 2011). Note that our baseline does not include previously proposed inflection models because the main goal of our experiment is to demonstrate the effectiveness of the proposed approach for languages where no sizable disambiguated data exists, which is indeed the case for Italian. Feature weights are tuned with pairwise ranking optimization (Hopkins and May, 2011) on the union of IWSLT’s dev10 and test10 in Italian, and on the first 2000 lines of wmt12 benchmark in Russian (Callison-Burch et al., 2012). During tuning, 14 PRO parameter estimation runs are performed in parallel on different samples of the n-best list after each decoder iteration. The weights of the individual PRO runs are then averaged and passed on to the next decoding iteration. Performing weight estimation independently for a number of samples corrects for some of the instability that can be caused by individual samples. 6.2 Results Translation quality is measured by case-insensitive BLEU (Papineni et al., 2002) on IWSLT’s test12 and test14 in Italian, and on wmt13 and wmt14 for Russian, all provided with one reference tra"
2015.mtsummit-papers.12,2014.iwslt-evaluation.1,0,0.0121013,"guated data exists. Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 149 4.1 Data As target languages, we choose two MRLs belonging to different language families and displaying different inflectional patterns: Russian has very rich nominal, adjectival and verbal inflection, while Italian has moderate nominal and adjectival inflection, but extremely rich verbal inflection. Experiments are performed on the following tasks: • English-Russian WMT (Bojar et al., 2013): translation of news commentaries with largescale training data. • English-Italian IWSLT (Cettolo et al., 2014): translation of speeches with either smallscale training data (TED talks only) or large-scale training data (TED talks and European proceedings). SMT training data statistics are reported in Table 2. The Russian Inf-NN model is trained on a 1M-sentence subset of the bilingual data, while the Italian one is trained on all the data available in each setting. For each data set, we create automatic word alignments using GIZA++ (Och and Ney, 2003). Bilingual Monoling. En-Ru large small large #sentences src/trg #tokens src/trg dict.size 2.4M 49.2/47.2M 774K/1100K 180K 3.6/3.4M 55K/80K 2.0M 57.4/57."
2015.mtsummit-papers.12,D13-1174,0,0.220091,"ype (Minkov et al., 2007; Toutanova et al., 2008; Jeong et al., 2010). As for how inflection models are integrated into the STM system, different strategies have been proposed. Minkov et al. (2007); Toutanova et al. (2008); Fraser et al. (2012) treat inflection as a post-processing task: the SMT model is trained to produce lemmatized target sentences (possibly enhanced with some form of morphological annotation) and afterwards the best surface form for each lemma is chosen by separate inflection models. Some work has focused on the generation of new inflected phrases given the input sentence (Chahuneau et al., 2013) or given the bilingual context during decoding (Koehn and Hoang, 2007; Subotin, 2011). Other inflection models have been integrated to SMT as additional feature functions: e.g. as an additional lexical translation score (Jeong et al., 2010; Tran et al., 2014) or as an additional target language model score (Green and DeNero, 2012). We follow this last strategy, rather than generating new inflections, motivated by previous observations that, when translating into MRLs, a large number of reference inflections are already available in the SMT models but are not selected for Viterbi translation ("
2015.mtsummit-papers.12,P14-1129,0,0.175437,"-trained embeddings, which has been shown to encode certain morphological regularities (Soricut and Och, 2015), whereas target tag representations are initialized randomly. Inf-NN is a feed-forward neural network whose output is a conditional probability distribution over a set of morphological tags given target history and source context. Formally, let hi = (ri−1 , . . . , ri−n+1 ) be the n−1 tag history of the target word wi , and cj = (sj−k , . . . , sj+k ) the source context centering at the word sj aligned to wi by an automatic aligner. We use simple heuristics similar to the approach by Devlin et al. (2014) to handle null and multiple alignments so that each target word wi can be mapped to exactly one source word sj . Let sj ∈ RD and ri ∈ RD denote the distributed representations of source sj and target tag ri respectively. Then, the conditional probability pInf-NN (ri |hi , cj ) is computed at the output layer y of the network as follows: zi = φ(Wc cj + Wh hi + bz ) y = softmax(Wm zi + by ) 3 The implementation is available at https://bitbucket.org/ketran/soft-tags Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 148 wi 2 wi 1 wi ri 2 ri 1 sj 2 sj 1 sj s"
2015.mtsummit-papers.12,E12-1068,0,0.0816176,"also been shown to affect syntactic parsing of SMT output (Post and Gildea, 2008; Carter and Monz, 2011). Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 146 Considerably less work has focused on MRLs where disambiguated data does not exist, with few exceptions where ambiguity is solved by randomly selecting one analysis per word type (Minkov et al., 2007; Toutanova et al., 2008; Jeong et al., 2010). As for how inflection models are integrated into the STM system, different strategies have been proposed. Minkov et al. (2007); Toutanova et al. (2008); Fraser et al. (2012) treat inflection as a post-processing task: the SMT model is trained to produce lemmatized target sentences (possibly enhanced with some form of morphological annotation) and afterwards the best surface form for each lemma is chosen by separate inflection models. Some work has focused on the generation of new inflected phrases given the input sentence (Chahuneau et al., 2013) or given the bilingual context during decoding (Koehn and Hoang, 2007; Subotin, 2011). Other inflection models have been integrated to SMT as additional feature functions: e.g. as an additional lexical translation score"
2015.mtsummit-papers.12,D08-1089,0,0.0186718,"introducing spurious ambiguity into what is already a huge search space.6 As a result, the integration of our Inf-NN does not affect decoding speed. 6 Green and DeNero (2012) also tag each target phrase in context as it is produced. However, they avoid the spurious ambiguity problem by only preserving the most probable tag sequence for each phrase (incremental greedy decoding). Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 152 6.1 Baseline Our SMT baseline is a competitive phrase-based SMT system including hierarchical lexicalized reordering models (Galley and Manning, 2008) and a 5-gram target LM trained with modified Kneser-Ney smoothing (Chen and Goodman, 1999). Since the large English-Italian data comes from very different sources (TED talks and European proceedings), we construct phrase table and reordering models for this experiment using the fillup technique (Bisazza et al., 2011). Note that our baseline does not include previously proposed inflection models because the main goal of our experiment is to demonstrate the effectiveness of the proposed approach for languages where no sizable disambiguated data exists, which is indeed the case for Italian. Feat"
2015.mtsummit-papers.12,P12-1016,0,0.220312,"lly disambiguated data. Integrated into an SMT decoder and evaluated for English-Italian and English-Russian translation, our model yields improvements of up to 1.0 BLEU over a competitive baseline. 1 Introduction In morphologically rich languages (MRLs), words can have many different surface forms depending on the grammatical context. When translating into MRLs, standard statistical machine translation (SMT) models such as phrase translation models and n-gram language models (LMs) often fail to select the right surface form due to the sparsity of observed word sequences (Minkov et al., 2007; Green and DeNero, 2012). While neural LMs (Bengio et al., 2003; Schwenk, 2007) address lexical sparsity to a certain degree by projecting word sequences to distributed vector representations, they still suffer from the problem of rare words which is particularly exacerbated in MRLs (Botha and Blunsom, 2014; Jean et al., 2015; Luong et al., 2015). A potential solution to overcome data sparsity in MRLs, is to use word representations that separate the grammatical aspects of a word, i. e. inflection, from the lexical ones. Such word representations already exist for many languages in the form of morphological analyzers"
2015.mtsummit-papers.12,D11-1125,0,0.0217634,"moothing (Chen and Goodman, 1999). Since the large English-Italian data comes from very different sources (TED talks and European proceedings), we construct phrase table and reordering models for this experiment using the fillup technique (Bisazza et al., 2011). Note that our baseline does not include previously proposed inflection models because the main goal of our experiment is to demonstrate the effectiveness of the proposed approach for languages where no sizable disambiguated data exists, which is indeed the case for Italian. Feature weights are tuned with pairwise ranking optimization (Hopkins and May, 2011) on the union of IWSLT’s dev10 and test10 in Italian, and on the first 2000 lines of wmt12 benchmark in Russian (Callison-Burch et al., 2012). During tuning, 14 PRO parameter estimation runs are performed in parallel on different samples of the n-best list after each decoder iteration. The weights of the individual PRO runs are then averaged and passed on to the next decoding iteration. Performing weight estimation independently for a number of samples corrects for some of the instability that can be caused by individual samples. 6.2 Results Translation quality is measured by case-insensitive"
2015.mtsummit-papers.12,P15-1001,0,0.0287832,"on the grammatical context. When translating into MRLs, standard statistical machine translation (SMT) models such as phrase translation models and n-gram language models (LMs) often fail to select the right surface form due to the sparsity of observed word sequences (Minkov et al., 2007; Green and DeNero, 2012). While neural LMs (Bengio et al., 2003; Schwenk, 2007) address lexical sparsity to a certain degree by projecting word sequences to distributed vector representations, they still suffer from the problem of rare words which is particularly exacerbated in MRLs (Botha and Blunsom, 2014; Jean et al., 2015; Luong et al., 2015). A potential solution to overcome data sparsity in MRLs, is to use word representations that separate the grammatical aspects of a word, i. e. inflection, from the lexical ones. Such word representations already exist for many languages in the form of morphological analyzers or lexicons. However, using these resources for statistical language modeling is far from trivial due to the issue of ambiguous word analyses. Table 1 illustrates this problem in Italian, for which a fine-grained morphological lexicon but no sizable disambiguated corpus exists. These morphological ana"
2015.mtsummit-papers.12,2010.amta-papers.33,0,0.161766,"model with disambiguating the word sequence under construction, which is difficult given the ill-formedness of SMT output and a cause of spurious ambiguity. 2 This issue has also been shown to affect syntactic parsing of SMT output (Post and Gildea, 2008; Carter and Monz, 2011). Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 146 Considerably less work has focused on MRLs where disambiguated data does not exist, with few exceptions where ambiguity is solved by randomly selecting one analysis per word type (Minkov et al., 2007; Toutanova et al., 2008; Jeong et al., 2010). As for how inflection models are integrated into the STM system, different strategies have been proposed. Minkov et al. (2007); Toutanova et al. (2008); Fraser et al. (2012) treat inflection as a post-processing task: the SMT model is trained to produce lemmatized target sentences (possibly enhanced with some form of morphological annotation) and afterwards the best surface form for each lemma is chosen by separate inflection models. Some work has focused on the generation of new inflected phrases given the input sentence (Chahuneau et al., 2013) or given the bilingual context during decodin"
2015.mtsummit-papers.12,W04-3250,0,0.0241613,"data would reduce the impact of our inflection model, but currently we do not have access to other data sets that would be relevant to our translation tasks. To put these results into perspective, our improvements are comparable to those achieved by previous work that generated new phrase inflections using a morphological disambiguator (Chahuneau et al., 2013) on the same large-scale English-Russian task. 7 Riezler and Maxwell (2005) have shown that approximate randomization is less sensitive to Type-I errors, i. e. less likely to falsely reject the null hypothesis, than bootstrap resampling (Koehn, 2004) in the context of SMT. Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 153 SRC REF (1) BASE INFNN Effect: SRC REF (2) BASE INFNN Effect: SRC REF (3) BASE INFNN Effect: SRC REF (4) BASE INFNN Effect: SRC REF (5) BASE INFNN Effect: and if you’re wondering about those other spikes, those are also fridays e se vi state chiedendo cosa sono questi altri picchi, sono anche loro dei venerdì e se vi state chiedendo di queste altre picchi, sono anche il venerdì e se vi state chiedendo di questi altri picchi, sono anche il venerdì Correct number agreement betwee"
2015.mtsummit-papers.12,W08-0318,0,0.0182843,"observations that, when translating into MRLs, a large number of reference inflections are already available in the SMT models but are not selected for Viterbi translation (Green and DeNero, 2012; Tran et al., 2014). More in general, our work is related to class-based language modeling (Brown et al., 1992) with the major difference that we also condition on source-side context and that we use explicit morphological representations instead of data-driven word clusters (Uszkoreit and Brants, 2008), word suffixes (Müller et al., 2012; Bisazza and Monz, 2014) or coarse-grained part-ofspeech tags (Koehn et al., 2008). Modeling morphology using neural networks has recently shown promising results: in the context of monolingual neural language modeling, Luong et al. (2013); Botha and Blunsom (2014) obtain the vectorial representation of a word by composing the representations of its morphemes. Tran et al. (2014) model translation stem and suffix selection in SMT with a bilingual neural network. Soricut and Och (2015) discover morphological transformation rules from word embeddings learned by a shallow network. We are not aware of work that leveraged fine-grained morphological tags for neural language or tra"
2015.mtsummit-papers.12,D07-1091,0,0.350654,"resentations (Section 3). In Section 4 we introduce the general experimental setup, followed by a detailed description of the re-inflection experiments (Section 5) and the end-to-end SMT experiments (Section 6). We conclude with a discussion of SMT output examples and an outlook of future work 2 Previous Work Previous work on inflection modeling for translation into MRLs has mostly relied on the availability of morphologically disambiguated data to choose the most probable analysis of each word in either a context-independent (Minkov et al., 2007) or context-dependent (Green and DeNero, 2012; Koehn and Hoang, 2007; Subotin, 2011) way. While the former irrevocably discards potentially useful attributes of the words, the latter tasks the inflection model with disambiguating the word sequence under construction, which is difficult given the ill-formedness of SMT output and a cause of spurious ambiguity. 2 This issue has also been shown to affect syntactic parsing of SMT output (Post and Gildea, 2008; Carter and Monz, 2011). Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 146 Considerably less work has focused on MRLs where disambiguated data does not exist, with f"
2015.mtsummit-papers.12,P07-2045,0,0.00811056,"Missing"
2015.mtsummit-papers.12,P09-1067,0,0.0567845,"Missing"
2015.mtsummit-papers.12,W13-3512,0,0.0472851,"bi translation (Green and DeNero, 2012; Tran et al., 2014). More in general, our work is related to class-based language modeling (Brown et al., 1992) with the major difference that we also condition on source-side context and that we use explicit morphological representations instead of data-driven word clusters (Uszkoreit and Brants, 2008), word suffixes (Müller et al., 2012; Bisazza and Monz, 2014) or coarse-grained part-ofspeech tags (Koehn et al., 2008). Modeling morphology using neural networks has recently shown promising results: in the context of monolingual neural language modeling, Luong et al. (2013); Botha and Blunsom (2014) obtain the vectorial representation of a word by composing the representations of its morphemes. Tran et al. (2014) model translation stem and suffix selection in SMT with a bilingual neural network. Soricut and Och (2015) discover morphological transformation rules from word embeddings learned by a shallow network. We are not aware of work that leveraged fine-grained morphological tags for neural language or translation modeling. 3 A Distributed Inflection Model In MRLs, the surface form of a word is heavily determined by its grammatical features, such as number, ca"
2015.mtsummit-papers.12,P15-1002,0,0.0260468,"context. When translating into MRLs, standard statistical machine translation (SMT) models such as phrase translation models and n-gram language models (LMs) often fail to select the right surface form due to the sparsity of observed word sequences (Minkov et al., 2007; Green and DeNero, 2012). While neural LMs (Bengio et al., 2003; Schwenk, 2007) address lexical sparsity to a certain degree by projecting word sequences to distributed vector representations, they still suffer from the problem of rare words which is particularly exacerbated in MRLs (Botha and Blunsom, 2014; Jean et al., 2015; Luong et al., 2015). A potential solution to overcome data sparsity in MRLs, is to use word representations that separate the grammatical aspects of a word, i. e. inflection, from the lexical ones. Such word representations already exist for many languages in the form of morphological analyzers or lexicons. However, using these resources for statistical language modeling is far from trivial due to the issue of ambiguous word analyses. Table 1 illustrates this problem in Italian, for which a fine-grained morphological lexicon but no sizable disambiguated corpus exists. These morphological analyses1 clearly contai"
2015.mtsummit-papers.12,P07-1017,0,0.477834,"ained on morphologically disambiguated data. Integrated into an SMT decoder and evaluated for English-Italian and English-Russian translation, our model yields improvements of up to 1.0 BLEU over a competitive baseline. 1 Introduction In morphologically rich languages (MRLs), words can have many different surface forms depending on the grammatical context. When translating into MRLs, standard statistical machine translation (SMT) models such as phrase translation models and n-gram language models (LMs) often fail to select the right surface form due to the sparsity of observed word sequences (Minkov et al., 2007; Green and DeNero, 2012). While neural LMs (Bengio et al., 2003; Schwenk, 2007) address lexical sparsity to a certain degree by projecting word sequences to distributed vector representations, they still suffer from the problem of rare words which is particularly exacerbated in MRLs (Botha and Blunsom, 2014; Jean et al., 2015; Luong et al., 2015). A potential solution to overcome data sparsity in MRLs, is to use word representations that separate the grammatical aspects of a word, i. e. inflection, from the lexical ones. Such word representations already exist for many languages in the form o"
2015.mtsummit-papers.12,J03-1002,0,0.00706548,"following tasks: • English-Russian WMT (Bojar et al., 2013): translation of news commentaries with largescale training data. • English-Italian IWSLT (Cettolo et al., 2014): translation of speeches with either smallscale training data (TED talks only) or large-scale training data (TED talks and European proceedings). SMT training data statistics are reported in Table 2. The Russian Inf-NN model is trained on a 1M-sentence subset of the bilingual data, while the Italian one is trained on all the data available in each setting. For each data set, we create automatic word alignments using GIZA++ (Och and Ney, 2003). Bilingual Monoling. En-Ru large small large #sentences src/trg #tokens src/trg dict.size 2.4M 49.2/47.2M 774K/1100K 180K 3.6/3.4M 55K/80K 2.0M 57.4/57.0M 139K/195K #sentences trg #tokens src/trg dict.size 21.0M 390M 2.7M En-It 2.1M 58.4M 199K Table 2: Training corpora statistics. The ambiguous morphological analyses are obtained from the Russian OpenCorpora lexicon4 (Bocharov et al., 2013) and from the Italian Morph-it!5 lexicon (Zanchetta and Baroni, 2005). Table 3 shows the number of tags and soft tags occurring in our training data, as well as the expected counts of analyses per word Ew ["
2015.mtsummit-papers.12,P02-1040,0,0.0921194,"Missing"
2015.mtsummit-papers.12,D14-1162,0,0.0793013,".7 versus 7.2 words per lemma). At a closer inspection, we find that most of this richness is due to verbal inflection which goes up to 50 forms for frequently observed verbs. 4.2 Neural network training The Inf-NN models are trained on a history of 4 target tags and source context of 7 words with the following configuration: Embedding size is set to 200 and the number of hidden units to 768. Target word and soft-tag embeddings are initialized randomly from a Gaussian distribution with mean zero and standard deviation 0.01. Source word embeddings are initialized from pretrained Glove vectors (Pennington et al., 2014) and rescaled by a factor of 0.1. Weight matrices of p linear layers are initialized from a zero-mean Gaussian distribution with standard deviation 2/ni where ni is the number of input units (He et al., 2015). We set self-normalization strength γ = 0.02, Bernoulli parameter p = 0.1, and regularization parameter η = 10−4 . All models are trained with a mini-batch size of 128 for 30 epochs. Our stochastic objective functions are optimized using the first-order gradient-based optimizer Adam (Kingma and Ba, 2015). We use the default settings suggested by the authors: α = 0.001, β1 = 0.9, β2 = 0.99"
2015.mtsummit-papers.12,2008.amta-papers.16,0,0.0255149,"d on the availability of morphologically disambiguated data to choose the most probable analysis of each word in either a context-independent (Minkov et al., 2007) or context-dependent (Green and DeNero, 2012; Koehn and Hoang, 2007; Subotin, 2011) way. While the former irrevocably discards potentially useful attributes of the words, the latter tasks the inflection model with disambiguating the word sequence under construction, which is difficult given the ill-formedness of SMT output and a cause of spurious ambiguity. 2 This issue has also been shown to affect syntactic parsing of SMT output (Post and Gildea, 2008; Carter and Monz, 2011). Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 146 Considerably less work has focused on MRLs where disambiguated data does not exist, with few exceptions where ambiguity is solved by randomly selecting one analysis per word type (Minkov et al., 2007; Toutanova et al., 2008; Jeong et al., 2010). As for how inflection models are integrated into the STM system, different strategies have been proposed. Minkov et al. (2007); Toutanova et al. (2008); Fraser et al. (2012) treat inflection as a post-processing task: the SMT model is"
2015.mtsummit-papers.12,W05-0908,0,0.015192,"ts that morphological phenomena are not sufficiently captured by phrases and stresses the importance of specifically modeling word inflection. It is possible that adding even more training data would reduce the impact of our inflection model, but currently we do not have access to other data sets that would be relevant to our translation tasks. To put these results into perspective, our improvements are comparable to those achieved by previous work that generated new phrase inflections using a morphological disambiguator (Chahuneau et al., 2013) on the same large-scale English-Russian task. 7 Riezler and Maxwell (2005) have shown that approximate randomization is less sensitive to Type-I errors, i. e. less likely to falsely reject the null hypothesis, than bootstrap resampling (Koehn, 2004) in the context of SMT. Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 153 SRC REF (1) BASE INFNN Effect: SRC REF (2) BASE INFNN Effect: SRC REF (3) BASE INFNN Effect: SRC REF (4) BASE INFNN Effect: SRC REF (5) BASE INFNN Effect: and if you’re wondering about those other spikes, those are also fridays e se vi state chiedendo cosa sono questi altri picchi, sono anche loro dei vene"
2015.mtsummit-papers.12,sharoff-etal-2008-designing,0,0.02683,"mma of w or, more formally, as: Iw = {wi |lem(wi ) ∩ lem(w) 6= ∅} where lem(w) denotes the set of lemmas returned by the lexicon for word w. For example, the Italian form baci has two possible lemmas: bacio (noun: kiss) and baciare (verb: to kiss). Its candidate set Iw will then include all the forms of the noun bacio and all the forms of the verb baciare: that is, bacio, baci, baciamo, baciate, baciano, etc. We compare the proposed soft-tag Inf-NN against an Inf-NN trained on randomly assigned tag per type and to another one trained on tag sequences disambiguated by TreeTagger (Schmid, 1994; Sharoff et al., 2008). The latter model must search through a much larger space of morphological tag sequences. Therefore, to allow for a fair comparison, we set a higher beam size when re-inflecting with this model. As another difference from the other models, the TreeTagger-based inflection model relies on the lemmatization performed by TreeTagger to define the candidate set Iw . To validate the effectiveness of the neural network approach, we also compare Inf-NN to a simpler MaxEnt model trained on a similar configuration. Finally, we evaluate the importance of source-side context features by experimenting with"
2015.mtsummit-papers.12,C96-2215,0,0.0422269,"Missing"
2015.mtsummit-papers.12,N15-1186,0,0.119135,"t morphological representations instead of data-driven word clusters (Uszkoreit and Brants, 2008), word suffixes (Müller et al., 2012; Bisazza and Monz, 2014) or coarse-grained part-ofspeech tags (Koehn et al., 2008). Modeling morphology using neural networks has recently shown promising results: in the context of monolingual neural language modeling, Luong et al. (2013); Botha and Blunsom (2014) obtain the vectorial representation of a word by composing the representations of its morphemes. Tran et al. (2014) model translation stem and suffix selection in SMT with a bilingual neural network. Soricut and Och (2015) discover morphological transformation rules from word embeddings learned by a shallow network. We are not aware of work that leveraged fine-grained morphological tags for neural language or translation modeling. 3 A Distributed Inflection Model In MRLs, the surface form of a word is heavily determined by its grammatical features, such as number, case, tense etc. Choosing the right target word form during translation is a complex problem since some of these features depend on the source context while others depend on the target context (agreement phenomena). We model target language inflection"
2015.mtsummit-papers.12,P11-1024,0,0.0883783,"). In Section 4 we introduce the general experimental setup, followed by a detailed description of the re-inflection experiments (Section 5) and the end-to-end SMT experiments (Section 6). We conclude with a discussion of SMT output examples and an outlook of future work 2 Previous Work Previous work on inflection modeling for translation into MRLs has mostly relied on the availability of morphologically disambiguated data to choose the most probable analysis of each word in either a context-independent (Minkov et al., 2007) or context-dependent (Green and DeNero, 2012; Koehn and Hoang, 2007; Subotin, 2011) way. While the former irrevocably discards potentially useful attributes of the words, the latter tasks the inflection model with disambiguating the word sequence under construction, which is difficult given the ill-formedness of SMT output and a cause of spurious ambiguity. 2 This issue has also been shown to affect syntactic parsing of SMT output (Post and Gildea, 2008; Carter and Monz, 2011). Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 146 Considerably less work has focused on MRLs where disambiguated data does not exist, with few exceptions wh"
2015.mtsummit-papers.12,P08-1059,0,0.0689098,"Missing"
2015.mtsummit-papers.12,D14-1175,1,0.904902,"a post-processing task: the SMT model is trained to produce lemmatized target sentences (possibly enhanced with some form of morphological annotation) and afterwards the best surface form for each lemma is chosen by separate inflection models. Some work has focused on the generation of new inflected phrases given the input sentence (Chahuneau et al., 2013) or given the bilingual context during decoding (Koehn and Hoang, 2007; Subotin, 2011). Other inflection models have been integrated to SMT as additional feature functions: e.g. as an additional lexical translation score (Jeong et al., 2010; Tran et al., 2014) or as an additional target language model score (Green and DeNero, 2012). We follow this last strategy, rather than generating new inflections, motivated by previous observations that, when translating into MRLs, a large number of reference inflections are already available in the SMT models but are not selected for Viterbi translation (Green and DeNero, 2012; Tran et al., 2014). More in general, our work is related to class-based language modeling (Brown et al., 1992) with the major difference that we also condition on source-side context and that we use explicit morphological representation"
2015.mtsummit-papers.12,P08-1086,0,0.0266727,"el score (Green and DeNero, 2012). We follow this last strategy, rather than generating new inflections, motivated by previous observations that, when translating into MRLs, a large number of reference inflections are already available in the SMT models but are not selected for Viterbi translation (Green and DeNero, 2012; Tran et al., 2014). More in general, our work is related to class-based language modeling (Brown et al., 1992) with the major difference that we also condition on source-side context and that we use explicit morphological representations instead of data-driven word clusters (Uszkoreit and Brants, 2008), word suffixes (Müller et al., 2012; Bisazza and Monz, 2014) or coarse-grained part-ofspeech tags (Koehn et al., 2008). Modeling morphology using neural networks has recently shown promising results: in the context of monolingual neural language modeling, Luong et al. (2013); Botha and Blunsom (2014) obtain the vectorial representation of a word by composing the representations of its morphemes. Tran et al. (2014) model translation stem and suffix selection in SMT with a bilingual neural network. Soricut and Och (2015) discover morphological transformation rules from word embeddings learned b"
2020.emnlp-main.180,D15-1040,0,0.0224932,"oss-lingual transfer. Cross-Lingual Dependency Parsing The availability of consistent dependency treebanks in many languages (McDonald et al., 2013; Nivre et al., 2018) has provided an opportunity for the study of cross-lingual parsing. Early studies trained a delexicalized parser (Zeman and Resnik, 2008; McDonald et al., 2013) on one or more source languages by using either gold or predicted POS labels (Tiedemann, 2015) and applied it to target languages. Building on this, later work used additional features such as typological language properties (Naseem et al., 2012), syntactic embeddings (Duong et al., 2015), and cross-lingual word clusters (T¨ackstr¨om et al., 2012). Among lexicalized approaches, Vilares et al. (2016) learns a bilingual parser on a corpora obtained by merging harmonized treebanks. Ammar et al. (2016) trains a multilingual parser using multilingual word embeddings, token-level language information, language typology features and fine-grained POS tags. More recently, based on mBERT (Devlin et al., 2019), zero-shot transfer in dependency parsing was investigated (Wu and Dredze, 2019; Tran and Bisazza, 2019). Finally Kondratyuk and Straka (2019) trained a multilingual parser on the"
2020.emnlp-main.180,D18-1039,0,0.220448,"es (Johnson et al., 2017; Arivazhagan et al., 2019; Conneau et al., 2020), a problem also known as “the curse of multilinguality”. Generally speaking, a multilingual model without language-specific supervision is likely to suffer from over-generalization and perform poorly on high-resource languages due to limited capacity compared to the monolingual baselines, as verified by our experiments on parsing. In this paper, we strike a good balance between maximum sharing and language-specific capacity in multilingual dependency parsing. Inspired by recently introduced parameter sharing techniques (Platanios et al., 2018; Houlsby et al., 2019), we propose a new multilingual parser, UDapter, that learns to modify its language-specific parameters including the adapter modules, as a function of language embeddings. This allows the model to share parameters across languages, ensuring generalization and transfer ability, but also enables language-specific parameterization in a single multilingual model. Furthermore, we propose not to learn language embeddings from scratch, but to leverage a mix of linguistically curated and predicted typological features as obtained from the URIEL language typology database (Litte"
2020.emnlp-main.180,W15-2137,0,0.0139498,"d to combine language and task adapters, small bottleneck layers (Rebuffi et al., 2018; Houlsby et al., 2019), to address the capacity issue which limits multilingual pre-trained models for cross-lingual transfer. Cross-Lingual Dependency Parsing The availability of consistent dependency treebanks in many languages (McDonald et al., 2013; Nivre et al., 2018) has provided an opportunity for the study of cross-lingual parsing. Early studies trained a delexicalized parser (Zeman and Resnik, 2008; McDonald et al., 2013) on one or more source languages by using either gold or predicted POS labels (Tiedemann, 2015) and applied it to target languages. Building on this, later work used additional features such as typological language properties (Naseem et al., 2012), syntactic embeddings (Duong et al., 2015), and cross-lingual word clusters (T¨ackstr¨om et al., 2012). Among lexicalized approaches, Vilares et al. (2016) learns a bilingual parser on a corpora obtained by merging harmonized treebanks. Ammar et al. (2016) trains a multilingual parser using multilingual word embeddings, token-level language information, language typology features and fine-grained POS tags. More recently, based on mBERT (Devlin"
2020.emnlp-main.180,J19-3005,0,0.110741,"Missing"
2020.emnlp-main.180,W17-0412,0,0.0295288,"ed Attachement Scores (LAS) on the high-resource set are given in Table 1. UDapter consistently outperforms both our monolingual and multilingual baselines in all languages, and beats the previous work, setting a new state of the art, in 9 out of 13 languages. Statistical significance testing8 applied between UDapter and multi/mono-udify confirms that UDapter’s performance is significantly better than the baselines in 11 out of 13 languages (all except en and it). 8 We used paired bootstrap resampling to check whether the difference between two models is significant (p < 0.05) by using Udapi (Popel et al., 2017). 10 difference (udapter, multi-udify) treebank size (K) 20 8 16 6 12 4 8 2 4 0 ko eu tr zh he ar sv fi ru ja hi it en 0 Figure 2: Difference in LAS between UDapter and multi-udify in the high-resource setting. Diamonds indicate the amount of sentences in the corresponding treebank. Among directly comparable baselines, multiudify gives the worst performance in the typologically diverse high-resource setting. This multilingual model is clearly worse than its monolingually trained counterparts mono-udify: 83.0 vs 86.0. This result resounds with previous findings in multilingual NMT (Arivazhagan"
2020.emnlp-main.180,N19-1393,0,0.0935715,"lso enables language-specific parameterization in a single multilingual model. Furthermore, we propose not to learn language embeddings from scratch, but to leverage a mix of linguistically curated and predicted typological features as obtained from the URIEL language typology database (Littell et al., 2017) which supports 3718 languages including all languages represented in UD. While the importance of typological features for cross-lingual parsing is known for both non-neural (Naseem et al., 2012; T¨ackstr¨om et al., 2013; Zhang and Barzilay, 2015) and neural approaches (Ammar et al., 2016; Scholivet et al., 2019), we are the first to use them 2302 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 2302–2315, c November 16–20, 2020. 2020 Association for Computational Linguistics effectively as direct input to a neural parser, without manual selection, over a large number of languages in the context of zero-shot parsing where gold POS labels are not given at test time. In our model, typological features are crucial, leading to a substantial LAS increase on zero-shot languages and no loss on high-resource languages when compared to the language embeddings learne"
2020.emnlp-main.180,N12-1052,0,\N,Missing
2020.emnlp-main.180,P12-1066,0,\N,Missing
2020.emnlp-main.180,D15-1213,0,\N,Missing
2020.emnlp-main.180,P15-1166,0,\N,Missing
2020.emnlp-main.180,Q16-1023,0,\N,Missing
2020.emnlp-main.180,Q17-1024,0,\N,Missing
2020.emnlp-main.180,E17-2002,0,\N,Missing
2020.emnlp-main.180,D18-1103,0,\N,Missing
2020.emnlp-main.180,D18-1543,0,\N,Missing
2020.emnlp-main.180,K18-2020,0,\N,Missing
2020.emnlp-main.180,N19-1388,0,\N,Missing
2020.emnlp-main.180,N19-1423,0,\N,Missing
2020.emnlp-main.180,P13-2017,0,\N,Missing
2020.wmt-1.9,W18-6315,0,0.0205455,"ing In order to artificially increase the training data, we employ back-translation (BT) (Sennrich et al., 2016b). We consider two variations of this approach: TaggedBT was presented by Caswell et al. (2019) and is similar to the original BT technique of Sennrich et al. (2016b), with the major difference being the addition of a special tag (here <BT>) in front of every back-translated English sentence. Caswell et al. (2019) had shown that this simple manoeuvre resulted in a higher BLEU score when compared to untagged BT based NMTs. StupidBT Rather than performing actual BT which is expensive, Burlot and Yvon (2018) carry out the following: 1. Copy the target side data to the source side. 2. Prepend each token on the source side with a special id. For example, the token tablet becomes bt_tablet. Fine-tuning or transfer learning (Pan and Yang, 2010) is an effective technique to address a domain mismatch between the training set and the testset. While the testset consists of excerpts from newspapers, the training set consists of corpora with genres ranging from religious, political to movie subtitles. In fact, only a third of UFAL is news-oriented. A strategy to circumvent the domain mismatch is to fine-tu"
2020.wmt-1.9,W19-5206,0,0.0243779,"8 87 514 586 15 149 8 503 95 40 166 92 6 61 7 158 10669 1885 625 Total Table 1: Approximate sizes (in thousands) of the Parallel Corpora used for training the NMT models Name Domain Wikipedia Dumps News crawl PMI Wikipedia News Political Total TA Tokens(k) Sentences(k) 4034 1496 207 1669 709 99 5737 2477 Table 2: Approximate sizes (in thousands) of the Tamil Monolingual Corpora 5.2 Back-translation 5.3 Fine-tuning In order to artificially increase the training data, we employ back-translation (BT) (Sennrich et al., 2016b). We consider two variations of this approach: TaggedBT was presented by Caswell et al. (2019) and is similar to the original BT technique of Sennrich et al. (2016b), with the major difference being the addition of a special tag (here <BT>) in front of every back-translated English sentence. Caswell et al. (2019) had shown that this simple manoeuvre resulted in a higher BLEU score when compared to untagged BT based NMTs. StupidBT Rather than performing actual BT which is expensive, Burlot and Yvon (2018) carry out the following: 1. Copy the target side data to the source side. 2. Prepend each token on the source side with a special id. For example, the token tablet becomes bt_tablet. F"
2020.wmt-1.9,Y18-3003,0,0.14736,"rained on a much larger dataset of 190k parallel sentences. They also performed pre-processing steps involving morphological rules based on Tamil suffixes that improved upon the BLEU score of the baseline model (from 9.42 to 9.77). Their dataset (henceforth called UFAL) became the default benchmark for EN-TA translation systems until 2019, and we also use it in our experiments as an additional (general-domain) development set. To the best of our knowledge, there have only been a handful of NMT systems trained on EN→TA. For the Indic languages multilingual tasks of WAT-2018, Sen et al. (2018), Dabre et al. (2018) and Ojha et al. (2018) reported BLEU scores for EN→TA. The Phrasal-based SMT system of Ojha et al. (2018) with a score of 30.53 BLEU outperformed the NMT systems of Sen et al. (2018) (11.88) and Dabre et al. (2018) (18.60), suggesting that the NMT systems were not suitable for translating a highly morphological language such as Tamil. However, the following year, Philip et al. (2019) outperformed Ramasamy et al. (2012) on the UFAL dataset with a BLEU score of 13.05. They report that techniques such as domain adaptation and back-translation can make training NMT systems on low-resource languag"
2020.wmt-1.9,W01-1409,0,0.916802,"ne translation (NMT) systems submitted to the WMT-2020 English-Tamil (EN→TA) news translation task. This task is challenging mainly for two reasons: 1. Differing syntax: English is an IndoEuropean language which is fusional and SVO (Subject-Verb-Object). On the other hard, Tamil is part of the Dravidian language family and is a SOV language that is agglutinative. A good NMT system is expected to discern the various morphological forms on the Tamil target side. 2. Scarcity of training data: Prior to WMT-2020, there existed only a few corpora for parallel EN-TA sentences (Ramasamy et al., 2012; Germann, 2001). This left us with the choice of either only utilizing the low amount of parallel sentences or finding out ways of artificially enlarging the training data. Through our submission we wish to provide solutions to the following questions: Tamil is a Dravidian language spoken by around 80 million people. Tamil morphology is agglutinative and suffixal, i.e words are formed by suffixing morphemes to a lemma (Annamalai et. al 2014, cited in Sarveswaran et al. (2019)). Tamil suffixes can be either derivational (marking a change in PoS and/or meaning) or inflectional. In particular, nouns in Tamil ar"
2020.wmt-1.9,C14-1111,0,0.105253,"egmentation algorithms (Sennrich et al., 2016c; Kudo and Richardson, 2018) that generate sub-words based on simpler frequency criteria to attain a predetermined vocabulary size. In our experiments we try out different vocabulary sizes as well as generating the subwords either individually for each language or jointly learning on both. The SentencePiece (SP) implementation (Kudo and Richardson, 2018) is used to perform this segmentation. Linguistically Motivated Vocabulary Reduction (LMVR) is an unsupervised morphological segmentation algorithm based on Morfessor FlatCat (Kohonen et al., 2010; Grönroos et al., 2014) and proposed by Ataman et al. (2017). LMVR works by imposing an extra condition on the cost function of Morfessor so as to favour vocabularies of the desired size. When comparing regular Subword tokenization to LMVR, Ataman et al. (2017) report a +2.3 BLEU improvement on the EnglishTurkish translation task. Similar to SP, we need to set the vocabulary size prior to running the segmentation. LMVR models are trained separately for Tamil and English, which are then used to segment the respective datasets. 127 Name Domain Wikititles PMI UFAL Koran MkB PIB NLPC Wikimatrix Wikipedia Political Mixed"
2020.wmt-1.9,W10-2210,0,0.296753,"uistically motivated segmentation algorithms (Sennrich et al., 2016c; Kudo and Richardson, 2018) that generate sub-words based on simpler frequency criteria to attain a predetermined vocabulary size. In our experiments we try out different vocabulary sizes as well as generating the subwords either individually for each language or jointly learning on both. The SentencePiece (SP) implementation (Kudo and Richardson, 2018) is used to perform this segmentation. Linguistically Motivated Vocabulary Reduction (LMVR) is an unsupervised morphological segmentation algorithm based on Morfessor FlatCat (Kohonen et al., 2010; Grönroos et al., 2014) and proposed by Ataman et al. (2017). LMVR works by imposing an extra condition on the cost function of Morfessor so as to favour vocabularies of the desired size. When comparing regular Subword tokenization to LMVR, Ataman et al. (2017) report a +2.3 BLEU improvement on the EnglishTurkish translation task. Similar to SP, we need to set the vocabulary size prior to running the segmentation. LMVR models are trained separately for Tamil and English, which are then used to segment the respective datasets. 127 Name Domain Wikititles PMI UFAL Koran MkB PIB NLPC Wikimatrix W"
2020.wmt-1.9,D18-2012,0,0.0336662,"@rug.nl Abstract • Is linguistically motivated subword segmentation beneficial for EN-TA translation? This paper describes our submission for the English-Tamil news translation task of WMT2020. The various techniques and Neural Machine Translation (NMT) models used by our team are presented and discussed, including back-translation, fine-tuning and word dropout. Additionally, our experiments show that using a linguistically motivated subword segmentation technique (Ataman et al., 2017) does not consistently outperform the more widely used, non-linguistically motivated SentencePiece algorithm (Kudo and Richardson, 2018), despite the agglutinative nature of Tamil morphology. 1 • Can the addition of TA monolingual data compensate for the small amount of parallel ENTA sentences despite the domain mismatch? • Can fine-tuning on a corpus of Indian news improve quality on the WMT news translation task? We start our paper with a short description of the Tamil language before delving into the various techniques adopted by our submitted NMT systems. 2 Tamil Language Introduction In this paper we present the neural machine translation (NMT) systems submitted to the WMT-2020 English-Tamil (EN→TA) news translation task."
2020.wmt-1.9,Y18-3011,0,0.110138,"dataset of 190k parallel sentences. They also performed pre-processing steps involving morphological rules based on Tamil suffixes that improved upon the BLEU score of the baseline model (from 9.42 to 9.77). Their dataset (henceforth called UFAL) became the default benchmark for EN-TA translation systems until 2019, and we also use it in our experiments as an additional (general-domain) development set. To the best of our knowledge, there have only been a handful of NMT systems trained on EN→TA. For the Indic languages multilingual tasks of WAT-2018, Sen et al. (2018), Dabre et al. (2018) and Ojha et al. (2018) reported BLEU scores for EN→TA. The Phrasal-based SMT system of Ojha et al. (2018) with a score of 30.53 BLEU outperformed the NMT systems of Sen et al. (2018) (11.88) and Dabre et al. (2018) (18.60), suggesting that the NMT systems were not suitable for translating a highly morphological language such as Tamil. However, the following year, Philip et al. (2019) outperformed Ramasamy et al. (2012) on the UFAL dataset with a BLEU score of 13.05. They report that techniques such as domain adaptation and back-translation can make training NMT systems on low-resource languages possible. 4 Datasets"
2020.wmt-1.9,N19-4009,0,0.021606,"on the English→French translation task. 128 First introduced in Gal and Ghahramani (2016), the word dropout technique was modified by Sennrich et al. (2016a) to randomly drop tokens instead of types during training. They reported an increase of 4-5 BLEU for the English↔Romanian language pair. Furthermore, Sennrich and Zhang (2019) report that introducing word dropout into NMT systems in low-resource settings leads to improvements in BLEU scores. We would hence like to investigate if the same improvements can be observed for EN-TA. 6 Experimental Setup All our NMTs are developed using Fairseq (Ott et al., 2019). Following the architecture setup of Philip et al. (2019) the Transformer-Base implementation (BASE) is used, with slight changes to a few parameters, which are explained below. The encoder and decoder are both set to 5 layers with embedding dimension of 512 and 8 attention heads. The hidden layer dimension is 2048 and layer normalization is applied before each encoder and decoder layer. Other parameters were set as follows: dropout (0.001), weight decay (0.2) and batch size of 4k tokens. Our loss function is cross-entropy with label smoothing of 0.2. The model is trained for 100 epochs with"
2020.wmt-1.9,D19-5215,0,0.403423,"additional (general-domain) development set. To the best of our knowledge, there have only been a handful of NMT systems trained on EN→TA. For the Indic languages multilingual tasks of WAT-2018, Sen et al. (2018), Dabre et al. (2018) and Ojha et al. (2018) reported BLEU scores for EN→TA. The Phrasal-based SMT system of Ojha et al. (2018) with a score of 30.53 BLEU outperformed the NMT systems of Sen et al. (2018) (11.88) and Dabre et al. (2018) (18.60), suggesting that the NMT systems were not suitable for translating a highly morphological language such as Tamil. However, the following year, Philip et al. (2019) outperformed Ramasamy et al. (2012) on the UFAL dataset with a BLEU score of 13.05. They report that techniques such as domain adaptation and back-translation can make training NMT systems on low-resource languages possible. 4 Datasets For our constrained systems, we restrict ourselves to the datasets provided by WMT. Parallel Table 1 presents the various parallel corpora along with their size and genre. The various corpora come from various sources and differ considerably in size. We also observe a very large difference in number of tokens between the two languages, with around 5 times more"
2020.wmt-1.9,W15-3049,0,0.0602357,"we selected the following fine-tuning setup: learning rate of 0.002, batch size of 128, dropout of 0.3, label smoothing with factor of 0.3, and early stopping after 5 epochs without improvements. Word Dropout Following Sennrich and Zhang (2019) we set the source word dropout to 0.3, i.e. the probability of a source word, in a batch, being dropped prior to training is 0.3. 7 Results We report BLEU scores on three testsets: the UFAL testset (Ramasamy et al., 2012), half of the WMT2020 devset (DEV)1 and the official WMT2020 testset. Given the rich morphology of Tamil, we also report CHRF scores (Popović, 2015) on the WMT2020 testset. We ran the program chrF++.py2 with the arguments -nw 0 -b 3 to obtain the CHRF score. From prior experimentation we found that a jointly trained SP model resulted in better BLEU when compared to separate training for each language, and hence perform the majority of SP experiments in Table 3 using a joint segmentation. On the other hand, LMVR being linguistically motivated is supposed to be trained independently for each language. The last two contrastive experiments (Exp8.2 and Exp11.2) were run after the evaluation phase to better assess the impact of LMVR on translat"
2020.wmt-1.9,W12-5611,0,0.637722,"resent the neural machine translation (NMT) systems submitted to the WMT-2020 English-Tamil (EN→TA) news translation task. This task is challenging mainly for two reasons: 1. Differing syntax: English is an IndoEuropean language which is fusional and SVO (Subject-Verb-Object). On the other hard, Tamil is part of the Dravidian language family and is a SOV language that is agglutinative. A good NMT system is expected to discern the various morphological forms on the Tamil target side. 2. Scarcity of training data: Prior to WMT-2020, there existed only a few corpora for parallel EN-TA sentences (Ramasamy et al., 2012; Germann, 2001). This left us with the choice of either only utilizing the low amount of parallel sentences or finding out ways of artificially enlarging the training data. Through our submission we wish to provide solutions to the following questions: Tamil is a Dravidian language spoken by around 80 million people. Tamil morphology is agglutinative and suffixal, i.e words are formed by suffixing morphemes to a lemma (Annamalai et. al 2014, cited in Sarveswaran et al. (2019)). Tamil suffixes can be either derivational (marking a change in PoS and/or meaning) or inflectional. In particular, n"
2020.wmt-1.9,W19-3111,0,0.0237234,"rget side. 2. Scarcity of training data: Prior to WMT-2020, there existed only a few corpora for parallel EN-TA sentences (Ramasamy et al., 2012; Germann, 2001). This left us with the choice of either only utilizing the low amount of parallel sentences or finding out ways of artificially enlarging the training data. Through our submission we wish to provide solutions to the following questions: Tamil is a Dravidian language spoken by around 80 million people. Tamil morphology is agglutinative and suffixal, i.e words are formed by suffixing morphemes to a lemma (Annamalai et. al 2014, cited in Sarveswaran et al. (2019)). Tamil suffixes can be either derivational (marking a change in PoS and/or meaning) or inflectional. In particular, nouns in Tamil are inflected for number, gender, case and animacy while verbs are inflected for tense, mood, aspect, negation, interrogation, information about emphasis, speaker perspective, sentience or rationality, and conditional and causal relations. Table 4 shows examples of the case forms in singular for the noun தகம ’book’. All the aforementioned statements substantiate the fact that Tamil morphology is highly complex. In fact, Ramasamy et al. (2012) identified 716 infle"
2020.wmt-1.9,Y18-3012,0,0.162719,"chical) that were trained on a much larger dataset of 190k parallel sentences. They also performed pre-processing steps involving morphological rules based on Tamil suffixes that improved upon the BLEU score of the baseline model (from 9.42 to 9.77). Their dataset (henceforth called UFAL) became the default benchmark for EN-TA translation systems until 2019, and we also use it in our experiments as an additional (general-domain) development set. To the best of our knowledge, there have only been a handful of NMT systems trained on EN→TA. For the Indic languages multilingual tasks of WAT-2018, Sen et al. (2018), Dabre et al. (2018) and Ojha et al. (2018) reported BLEU scores for EN→TA. The Phrasal-based SMT system of Ojha et al. (2018) with a score of 30.53 BLEU outperformed the NMT systems of Sen et al. (2018) (11.88) and Dabre et al. (2018) (18.60), suggesting that the NMT systems were not suitable for translating a highly morphological language such as Tamil. However, the following year, Philip et al. (2019) outperformed Ramasamy et al. (2012) on the UFAL dataset with a BLEU score of 13.05. They report that techniques such as domain adaptation and back-translation can make training NMT systems on"
2020.wmt-1.9,W16-2323,0,0.122723,"an Press Mixed Mixed EN Tokens(k) TA Tokens(k) Sentences(k) 215 707 3893 2366 104 1123 65 2178 18 87 514 586 15 149 8 503 95 40 166 92 6 61 7 158 10669 1885 625 Total Table 1: Approximate sizes (in thousands) of the Parallel Corpora used for training the NMT models Name Domain Wikipedia Dumps News crawl PMI Wikipedia News Political Total TA Tokens(k) Sentences(k) 4034 1496 207 1669 709 99 5737 2477 Table 2: Approximate sizes (in thousands) of the Tamil Monolingual Corpora 5.2 Back-translation 5.3 Fine-tuning In order to artificially increase the training data, we employ back-translation (BT) (Sennrich et al., 2016b). We consider two variations of this approach: TaggedBT was presented by Caswell et al. (2019) and is similar to the original BT technique of Sennrich et al. (2016b), with the major difference being the addition of a special tag (here <BT>) in front of every back-translated English sentence. Caswell et al. (2019) had shown that this simple manoeuvre resulted in a higher BLEU score when compared to untagged BT based NMTs. StupidBT Rather than performing actual BT which is expensive, Burlot and Yvon (2018) carry out the following: 1. Copy the target side data to the source side. 2. Prepend eac"
2020.wmt-1.9,P16-1009,0,0.23135,"an Press Mixed Mixed EN Tokens(k) TA Tokens(k) Sentences(k) 215 707 3893 2366 104 1123 65 2178 18 87 514 586 15 149 8 503 95 40 166 92 6 61 7 158 10669 1885 625 Total Table 1: Approximate sizes (in thousands) of the Parallel Corpora used for training the NMT models Name Domain Wikipedia Dumps News crawl PMI Wikipedia News Political Total TA Tokens(k) Sentences(k) 4034 1496 207 1669 709 99 5737 2477 Table 2: Approximate sizes (in thousands) of the Tamil Monolingual Corpora 5.2 Back-translation 5.3 Fine-tuning In order to artificially increase the training data, we employ back-translation (BT) (Sennrich et al., 2016b). We consider two variations of this approach: TaggedBT was presented by Caswell et al. (2019) and is similar to the original BT technique of Sennrich et al. (2016b), with the major difference being the addition of a special tag (here <BT>) in front of every back-translated English sentence. Caswell et al. (2019) had shown that this simple manoeuvre resulted in a higher BLEU score when compared to untagged BT based NMTs. StupidBT Rather than performing actual BT which is expensive, Burlot and Yvon (2018) carry out the following: 1. Copy the target side data to the source side. 2. Prepend eac"
2020.wmt-1.9,P16-1162,0,0.335748,"an Press Mixed Mixed EN Tokens(k) TA Tokens(k) Sentences(k) 215 707 3893 2366 104 1123 65 2178 18 87 514 586 15 149 8 503 95 40 166 92 6 61 7 158 10669 1885 625 Total Table 1: Approximate sizes (in thousands) of the Parallel Corpora used for training the NMT models Name Domain Wikipedia Dumps News crawl PMI Wikipedia News Political Total TA Tokens(k) Sentences(k) 4034 1496 207 1669 709 99 5737 2477 Table 2: Approximate sizes (in thousands) of the Tamil Monolingual Corpora 5.2 Back-translation 5.3 Fine-tuning In order to artificially increase the training data, we employ back-translation (BT) (Sennrich et al., 2016b). We consider two variations of this approach: TaggedBT was presented by Caswell et al. (2019) and is similar to the original BT technique of Sennrich et al. (2016b), with the major difference being the addition of a special tag (here <BT>) in front of every back-translated English sentence. Caswell et al. (2019) had shown that this simple manoeuvre resulted in a higher BLEU score when compared to untagged BT based NMTs. StupidBT Rather than performing actual BT which is expensive, Burlot and Yvon (2018) carry out the following: 1. Copy the target side data to the source side. 2. Prepend eac"
2020.wmt-1.9,P19-1021,0,0.139307,"ith matters that are mostly political in nature. Despite the different content, we expect this corpus to be the closest in genre to the testset among the remaining parallel corpora. 5.4 Word Dropout This simple and cost-effective technique was shown to perform almost on a par with regular BT on the English→French translation task. 128 First introduced in Gal and Ghahramani (2016), the word dropout technique was modified by Sennrich et al. (2016a) to randomly drop tokens instead of types during training. They reported an increase of 4-5 BLEU for the English↔Romanian language pair. Furthermore, Sennrich and Zhang (2019) report that introducing word dropout into NMT systems in low-resource settings leads to improvements in BLEU scores. We would hence like to investigate if the same improvements can be observed for EN-TA. 6 Experimental Setup All our NMTs are developed using Fairseq (Ott et al., 2019). Following the architecture setup of Philip et al. (2019) the Transformer-Base implementation (BASE) is used, with slight changes to a few parameters, which are explained below. The encoder and decoder are both set to 5 layers with embedding dimension of 512 and 8 attention heads. The hidden layer dimension is 20"
2021.acl-short.97,E17-2039,1,0.890997,"Missing"
2021.acl-short.97,W19-1201,1,0.901733,"Missing"
2021.acl-short.97,D15-1041,0,0.0275795,"y et al., 2001; Xue, 2003; Zheng et al., 2013; Cai and Zhao, 2016; Min et al., 2019), is a fundamental step for many Chinese NLP applications, which directly affects downstream performance (Foo and Li, 2004; Xu et al., 2004). Despite the large body of existing research, the quality of Chinese word segmentation remains far from perfect, because many characters are highly ambiguous. Input Formats for Neural Methods Characterlevel representations have proved useful for neural network models in many NLP tasks such as POS-tagging (Santos and Zadrozny, 2014; Plank et al., 2016), dependency parsing (Ballesteros et al., 2015) and neural machine translation (Chung et al., 2016). However, only a few studies have used character-level representations as input representations for Chinese NLP tasks (Yu et al., 2017; Li et al., 2018, 2019; Min et al., 2019). For Chinese semantic parsing, previous studies mostly used wordbased representations as well (Che et al., 2016; Wang et al., 2018). For English DRS parsing, how768 Type English input representation Chinese input representation Char (raw) Char (continuous) Char (tokenized) Word BPE (5k) ˆbrad|ˆpitt|is|an|actor. ˆbradˆpittisanactor. ˆbrad|ˆpitt|is|an|actor|. brad pitt"
2021.acl-short.97,P13-1133,0,0.0210816,"Q3), though it will be interesting to experiment with higher quality word segmentation systems (Higashiyama et al., 2019; Tian et al., 2020). There are many research directions one could take next. One is to include pre-trained models. For instance, we could use recently proposed pretrained models such as BART (Lewis et al., 2020) or mBART (Liu et al., 2020) to improve parsing performance. Another interesting idea is, rather than assuming the English WordNet as a background ontology for concepts in the DRS, using concepts based on Chinese WordNet or multilingual wordnets (Wang and Bond, 2013; Bond and Foster, 2013). Both possibilities will likely further improve performance of semantic parsing for Chinese and inspire research for developing semantic parsing models for languages other than English. Chinese English F-score 80 60 40 20 0 overall oper roles conc nouns verbs adj adv events Figure 3: F-scores per clause type (DRS operators, VerbNet roles and WordNet concepts) and concept type (nouns, verbs, adjectives, adverbs and events) as introduced by van Noord et al. (2018b). Reported scores are on the Chinese and English dev set for the raw character-level models, averaged over 5 runs. Figure 3 shows de"
2021.acl-short.97,P16-1039,0,0.025293,"(Kipper et al., 2008). DRSs can be represented in box format or clause format (see Figure 1), where x, e, s, and t are discourse referents denoting individuals, events, Chinese Word Segmentation Differently from English, Chinese words are not separated by white spaces, as shown in Table 1. The first step of a typical Chinese NLP task is usually to use separators to mark boundaries at appropriate positions to identify words in a sentence. These words define the basic semantic units of Chinese. This process, i.e., Chinese word segmentation (Lafferty et al., 2001; Xue, 2003; Zheng et al., 2013; Cai and Zhao, 2016; Min et al., 2019), is a fundamental step for many Chinese NLP applications, which directly affects downstream performance (Foo and Li, 2004; Xu et al., 2004). Despite the large body of existing research, the quality of Chinese word segmentation remains far from perfect, because many characters are highly ambiguous. Input Formats for Neural Methods Characterlevel representations have proved useful for neural network models in many NLP tasks such as POS-tagging (Santos and Zadrozny, 2014; Plank et al., 2016), dependency parsing (Ballesteros et al., 2015) and neural machine translation (Chung e"
2021.acl-short.97,S16-1167,0,0.0197545,"characters are highly ambiguous. Input Formats for Neural Methods Characterlevel representations have proved useful for neural network models in many NLP tasks such as POS-tagging (Santos and Zadrozny, 2014; Plank et al., 2016), dependency parsing (Ballesteros et al., 2015) and neural machine translation (Chung et al., 2016). However, only a few studies have used character-level representations as input representations for Chinese NLP tasks (Yu et al., 2017; Li et al., 2018, 2019; Min et al., 2019). For Chinese semantic parsing, previous studies mostly used wordbased representations as well (Che et al., 2016; Wang et al., 2018). For English DRS parsing, how768 Type English input representation Chinese input representation Char (raw) Char (continuous) Char (tokenized) Word BPE (5k) ˆbrad|ˆpitt|is|an|actor. ˆbradˆpittisanactor. ˆbrad|ˆpitt|is|an|actor|. brad pitt is an actor . ˆ b@ ra@ d ˆ p@ it@ t is an ac@ tor@ . 布 拉 德 · 皮 特 是 个 演 员 。 布 拉 德 |· |皮 特 |是 |个 |演 员 |。 布拉德 · 皮特 是 个 演员 。 布 拉 德 · 皮 特 是个 演 员。 Table 1: Input representations for the English sentence Brad Pitt is an actor and its Chinese translation (布拉德.皮 特是个演员). Note that raw and continuous character representations are identical in Chinese"
2021.acl-short.97,P16-1160,0,0.0286902,"o, 2016; Min et al., 2019), is a fundamental step for many Chinese NLP applications, which directly affects downstream performance (Foo and Li, 2004; Xu et al., 2004). Despite the large body of existing research, the quality of Chinese word segmentation remains far from perfect, because many characters are highly ambiguous. Input Formats for Neural Methods Characterlevel representations have proved useful for neural network models in many NLP tasks such as POS-tagging (Santos and Zadrozny, 2014; Plank et al., 2016), dependency parsing (Ballesteros et al., 2015) and neural machine translation (Chung et al., 2016). However, only a few studies have used character-level representations as input representations for Chinese NLP tasks (Yu et al., 2017; Li et al., 2018, 2019; Min et al., 2019). For Chinese semantic parsing, previous studies mostly used wordbased representations as well (Che et al., 2016; Wang et al., 2018). For English DRS parsing, how768 Type English input representation Chinese input representation Char (raw) Char (continuous) Char (tokenized) Word BPE (5k) ˆbrad|ˆpitt|is|an|actor. ˆbradˆpittisanactor. ˆbrad|ˆpitt|is|an|actor|. brad pitt is an actor . ˆ b@ ra@ d ˆ p@ it@ t is an ac@ tor@ ."
2021.acl-short.97,E17-1051,0,0.0251358,"ynsets present in the DRS are reminiscent of English, they really represent concepts, not words. Similarly, the VerbNet roles have English names, but are universal thematic roles. An exception is formed by named entities, that are grounded by the orthography used in the source language. In sum, we assume that the translations are, by and large, meaning preserving, and project English to Chinese DRSs by changing all English named entities to Chinese ones as they appeared in the Chinese input (see Figure 1). This semantic annotation projection method bears strong similarities and is inspired by Damonte et al. (2017) and Min et al. (2019). Input Representation Types We consider five types of input representations, outlined in Table 1: (i) raw characters, (ii) continuous characters (i.e., without spaces), (iii) tokenised characters, (iv) tokenised words, and (v) byte-pair encoded text (BPE, Sennrich et al., 2016). Note that for Chinese, the first two options amount to the same kind of input. For BPE, we experiment with the number of merges (1k, 5k and 10k) and found in preliminary experiments that it was preferable to not add the indicator “@” for Chinese. For English character input we use an explicit “sh"
2021.acl-short.97,2020.acl-main.609,0,0.0172315,"task of mapping natural language to formal meaning representations (Figure 1). In this short paper we focus on parsing Discourse Representation Structures (DRSs): the meaning representations proposed in Discourse Representation Theory (DRT, Kamp and Reyle, 1993), covering a large variety of linguistic phenomena including coreference, thematic roles, presuppositions, scope, quantification, tense, and discourse relations. Several data-driven methods based on neural networks have been proposed for DRS parsing (van Noord et al., 2018b, 2019; Liu et al., 2019a; Evang, 2019; Fancellu et al., 2019; Fu et al., 2020; van Noord et al., 2020). These approaches frame semantic parsing as a sequence transformation problem and map the target meaning representation to string format. These models learn the meaning of a series of semantic phenomena by taking sentences Figure 1: Example DRS for Chinese in both clause and box representation. as input and directly outputting the corresponding DRSs, without the aid of any extra linguistic information (such as part-of-speech or syntactic structure). These previous studies have achieved good results, but have mostly focused on English or other languages that use the La"
2021.acl-short.97,N19-1276,0,0.0189248,"adverbs remain challenging. English results outperform those of Chinese, but it is likely that this is due to the general bias of the meaning representations towards English. Similar as for English, we find that characters are the preferred input representation for Chinese (RQ2). Surprisingly, for English, good results are even obtained by using characters without spaces as input. Tokenisation (segmenting the text into words) of the input offers a small advantage for English, but not for Chinese (RQ3), though it will be interesting to experiment with higher quality word segmentation systems (Higashiyama et al., 2019; Tian et al., 2020). There are many research directions one could take next. One is to include pre-trained models. For instance, we could use recently proposed pretrained models such as BART (Lewis et al., 2020) or mBART (Liu et al., 2020) to improve parsing performance. Another interesting idea is, rather than assuming the English WordNet as a background ontology for concepts in the DRS, using concepts based on Chinese WordNet or multilingual wordnets (Wang and Bond, 2013; Bond and Foster, 2013). Both possibilities will likely further improve performance of semantic parsing for Chinese and i"
2021.acl-short.97,P16-1002,0,0.0123575,"ke Chinese, a language with a large vocabulary of characters? Does rule-based tokenisation of the input help, and which granularity is preferred: characters, or words? The results are promising. Even with DRSs based on English, good results for Chinese are obtained. Tokenisation offers a small advantage for English, but not for Chinese. Overall, characters are preferred as input, both for English and Chinese. 1 Introduction Recently, sequence-to-sequence models have achieved remarkable performance in various natural language processing tasks, including semantic parsing (Dong and Lapata, 2016; Jia and Liang, 2016; Konstas et al., 2017; Dong and Lapata, 2018), the task of mapping natural language to formal meaning representations (Figure 1). In this short paper we focus on parsing Discourse Representation Structures (DRSs): the meaning representations proposed in Discourse Representation Theory (DRT, Kamp and Reyle, 1993), covering a large variety of linguistic phenomena including coreference, thematic roles, presuppositions, scope, quantification, tense, and discourse relations. Several data-driven methods based on neural networks have been proposed for DRS parsing (van Noord et al., 2018b, 2019; Liu"
2021.acl-short.97,W18-2716,0,0.0177919,"8,403 English–Chinese documents with gold data, of which 885 are used as development set and 898 as test set. The silver data (97,597 documents) is only used to augment the training data, following van Noord et al. (2018b). We use a fine-tuning approach to effectively use high-quality data in our experiments: first training the system with silver and gold data, then restarting the training to finetune on only the gold data. Neural Architecture We use a recurrent sequence-to-sequence neural network with two bi-directional LSTM layers (Hochreiter and Schmidhuber, 1997) as implemented by Marian (Junczys-Dowmunt et al., 2018), similar to van Noord et al. (2019).3 Specific hyper-parameters are shown in Appendix A. We also experimented with the Transformer model (Vaswani et al., 2017), as implemented in the same framework. However, similar to van Noord et al. (2020), none of our experiments reached the performance of the bi-LSTM model. We will therefore only show results of the bi-LSTM model in this paper. Evaluation DRS output is evaluated by using Counter (van Noord et al., 2018a), a tool that calculates the micro precision and recall of matching DRS clauses. Counter has been widely used in the evaluation of DRS p"
2021.acl-short.97,P07-2045,0,0.00670119,"), (iii) tokenised characters, (iv) tokenised words, and (v) byte-pair encoded text (BPE, Sennrich et al., 2016). Note that for Chinese, the first two options amount to the same kind of input. For BPE, we experiment with the number of merges (1k, 5k and 10k) and found in preliminary experiments that it was preferable to not add the indicator “@” for Chinese. For English character input we use an explicit “shift” symbol (ˆ) to indicate uppercased characters, to keep the vocabulary size low. Moreover, the |symbol represents an explicit word boundary. For tokenisation we use the Moses tokenizer (Koehn et al., 2007) for English, while we use the default mode of the Jieba tokenizer2 to segment the Chinese sentences. To fairly compare these different input representations, we do not employ pretrained embeddings. 1 https://github.com/wangchunliu/ Chinese-DRS-data 2 769 https://github.com/fxsjy/jieba Output Representation Appendix B shows how DRSs are represented for the purpose of training neural models, following van Noord et al. (2018b). Variables are replaced by indices, and the DRSs are coded in either a linearised character-level or wordlevel clause format. For Chinese, we experimented with both repres"
2021.acl-short.97,P17-1014,0,0.0240438,"e with a large vocabulary of characters? Does rule-based tokenisation of the input help, and which granularity is preferred: characters, or words? The results are promising. Even with DRSs based on English, good results for Chinese are obtained. Tokenisation offers a small advantage for English, but not for Chinese. Overall, characters are preferred as input, both for English and Chinese. 1 Introduction Recently, sequence-to-sequence models have achieved remarkable performance in various natural language processing tasks, including semantic parsing (Dong and Lapata, 2016; Jia and Liang, 2016; Konstas et al., 2017; Dong and Lapata, 2018), the task of mapping natural language to formal meaning representations (Figure 1). In this short paper we focus on parsing Discourse Representation Structures (DRSs): the meaning representations proposed in Discourse Representation Theory (DRT, Kamp and Reyle, 1993), covering a large variety of linguistic phenomena including coreference, thematic roles, presuppositions, scope, quantification, tense, and discourse relations. Several data-driven methods based on neural networks have been proposed for DRS parsing (van Noord et al., 2018b, 2019; Liu et al., 2019a; Evang,"
2021.acl-short.97,P03-1056,0,0.135574,"ls learn the meaning of a series of semantic phenomena by taking sentences Figure 1: Example DRS for Chinese in both clause and box representation. as input and directly outputting the corresponding DRSs, without the aid of any extra linguistic information (such as part-of-speech or syntactic structure). These previous studies have achieved good results, but have mostly focused on English or other languages that use the Latin alphabet. Our objective is to investigate whether the same method is applicable to Mandarin Chinese, an extremely analytic language which makes deep parsing challenging (Levy and Manning, 2003; Yu et al., 2011; Tse and Curran, 2012; Min et al., 2019). But Chinese is not only different on the level of syntax; its writing system also shows large differences with English, as there are no explicit word separators in written Chinese, and there is no distinction between 767 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Short Papers), pages 767–775 August 1–6, 2021. ©2021 Association for Computational Linguistics lower- and upper case characters. Unlike English, Chinese wo"
2021.acl-short.97,2020.acl-main.703,0,0.011455,"acters are the preferred input representation for Chinese (RQ2). Surprisingly, for English, good results are even obtained by using characters without spaces as input. Tokenisation (segmenting the text into words) of the input offers a small advantage for English, but not for Chinese (RQ3), though it will be interesting to experiment with higher quality word segmentation systems (Higashiyama et al., 2019; Tian et al., 2020). There are many research directions one could take next. One is to include pre-trained models. For instance, we could use recently proposed pretrained models such as BART (Lewis et al., 2020) or mBART (Liu et al., 2020) to improve parsing performance. Another interesting idea is, rather than assuming the English WordNet as a background ontology for concepts in the DRS, using concepts based on Chinese WordNet or multilingual wordnets (Wang and Bond, 2013; Bond and Foster, 2013). Both possibilities will likely further improve performance of semantic parsing for Chinese and inspire research for developing semantic parsing models for languages other than English. Chinese English F-score 80 60 40 20 0 overall oper roles conc nouns verbs adj adv events Figure 3: F-scores per clause type"
2021.acl-short.97,P19-1314,0,0.01798,"given the differences between the languages in how they convey meaning (Levy and Manning, 2003). In general, F-scores start to decrease when sentences get longer (Figure 2), though there is no clear difference between the character and wordlevel models. This is in line with the findings of van Noord et al. (2018b). For English, the input types based on characters outperform those based on words. BPE approaches character-level performance for small amounts of merges (1k), but never surpasses it. This too is in line with van Noord et al. (2018b), but also with previous work on NMT for Chinese (Li et al., 2019). There is a small benefit (0.5) for tokenizing the input text before converting the input to character-level format, though the continuous character representation also works surprisingly well. For Chinese, characterbased input shows the best performance too, though for a very small amount of merges BPE obtains a similar score. As opposed to English, tokenizing the Chinese input is not beneficial when using a character-level representation, though it also does not hurt performance. In general, character-level models seem the most promising for Chinese DRS parsing. Similar results were obtaine"
2021.acl-short.97,P19-1629,0,0.0212653,"2016; Konstas et al., 2017; Dong and Lapata, 2018), the task of mapping natural language to formal meaning representations (Figure 1). In this short paper we focus on parsing Discourse Representation Structures (DRSs): the meaning representations proposed in Discourse Representation Theory (DRT, Kamp and Reyle, 1993), covering a large variety of linguistic phenomena including coreference, thematic roles, presuppositions, scope, quantification, tense, and discourse relations. Several data-driven methods based on neural networks have been proposed for DRS parsing (van Noord et al., 2018b, 2019; Liu et al., 2019a; Evang, 2019; Fancellu et al., 2019; Fu et al., 2020; van Noord et al., 2020). These approaches frame semantic parsing as a sequence transformation problem and map the target meaning representation to string format. These models learn the meaning of a series of semantic phenomena by taking sentences Figure 1: Example DRS for Chinese in both clause and box representation. as input and directly outputting the corresponding DRSs, without the aid of any extra linguistic information (such as part-of-speech or syntactic structure). These previous studies have achieved good results, but have mostly"
2021.acl-short.97,W19-1203,0,0.0172344,"2016; Konstas et al., 2017; Dong and Lapata, 2018), the task of mapping natural language to formal meaning representations (Figure 1). In this short paper we focus on parsing Discourse Representation Structures (DRSs): the meaning representations proposed in Discourse Representation Theory (DRT, Kamp and Reyle, 1993), covering a large variety of linguistic phenomena including coreference, thematic roles, presuppositions, scope, quantification, tense, and discourse relations. Several data-driven methods based on neural networks have been proposed for DRS parsing (van Noord et al., 2018b, 2019; Liu et al., 2019a; Evang, 2019; Fancellu et al., 2019; Fu et al., 2020; van Noord et al., 2020). These approaches frame semantic parsing as a sequence transformation problem and map the target meaning representation to string format. These models learn the meaning of a series of semantic phenomena by taking sentences Figure 1: Example DRS for Chinese in both clause and box representation. as input and directly outputting the corresponding DRSs, without the aid of any extra linguistic information (such as part-of-speech or syntactic structure). These previous studies have achieved good results, but have mostly"
2021.acl-short.97,2020.tacl-1.47,0,0.0141999,"representation for Chinese (RQ2). Surprisingly, for English, good results are even obtained by using characters without spaces as input. Tokenisation (segmenting the text into words) of the input offers a small advantage for English, but not for Chinese (RQ3), though it will be interesting to experiment with higher quality word segmentation systems (Higashiyama et al., 2019; Tian et al., 2020). There are many research directions one could take next. One is to include pre-trained models. For instance, we could use recently proposed pretrained models such as BART (Lewis et al., 2020) or mBART (Liu et al., 2020) to improve parsing performance. Another interesting idea is, rather than assuming the English WordNet as a background ontology for concepts in the DRS, using concepts based on Chinese WordNet or multilingual wordnets (Wang and Bond, 2013; Bond and Foster, 2013). Both possibilities will likely further improve performance of semantic parsing for Chinese and inspire research for developing semantic parsing models for languages other than English. Chinese English F-score 80 60 40 20 0 overall oper roles conc nouns verbs adj adv events Figure 3: F-scores per clause type (DRS operators, VerbNet rol"
2021.acl-short.97,D19-1377,0,0.354055,"g sentences Figure 1: Example DRS for Chinese in both clause and box representation. as input and directly outputting the corresponding DRSs, without the aid of any extra linguistic information (such as part-of-speech or syntactic structure). These previous studies have achieved good results, but have mostly focused on English or other languages that use the Latin alphabet. Our objective is to investigate whether the same method is applicable to Mandarin Chinese, an extremely analytic language which makes deep parsing challenging (Levy and Manning, 2003; Yu et al., 2011; Tse and Curran, 2012; Min et al., 2019). But Chinese is not only different on the level of syntax; its writing system also shows large differences with English, as there are no explicit word separators in written Chinese, and there is no distinction between 767 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Short Papers), pages 767–775 August 1–6, 2021. ©2021 Association for Computational Linguistics lower- and upper case characters. Unlike English, Chinese words comprise few characters, but the number of different c"
2021.acl-short.97,L18-1267,1,0.897284,"Missing"
2021.acl-short.97,Q18-1043,1,0.855655,"Missing"
2021.acl-short.97,W19-0504,1,0.899694,"Missing"
2021.acl-short.97,2020.emnlp-main.371,1,0.855066,"Missing"
2021.acl-short.97,P16-2067,0,0.0167105,"i.e., Chinese word segmentation (Lafferty et al., 2001; Xue, 2003; Zheng et al., 2013; Cai and Zhao, 2016; Min et al., 2019), is a fundamental step for many Chinese NLP applications, which directly affects downstream performance (Foo and Li, 2004; Xu et al., 2004). Despite the large body of existing research, the quality of Chinese word segmentation remains far from perfect, because many characters are highly ambiguous. Input Formats for Neural Methods Characterlevel representations have proved useful for neural network models in many NLP tasks such as POS-tagging (Santos and Zadrozny, 2014; Plank et al., 2016), dependency parsing (Ballesteros et al., 2015) and neural machine translation (Chung et al., 2016). However, only a few studies have used character-level representations as input representations for Chinese NLP tasks (Yu et al., 2017; Li et al., 2018, 2019; Min et al., 2019). For Chinese semantic parsing, previous studies mostly used wordbased representations as well (Che et al., 2016; Wang et al., 2018). For English DRS parsing, how768 Type English input representation Chinese input representation Char (raw) Char (continuous) Char (tokenized) Word BPE (5k) ˆbrad|ˆpitt|is|an|actor. ˆbradˆpitt"
2021.acl-short.97,P16-1162,0,0.0170398,"ssume that the translations are, by and large, meaning preserving, and project English to Chinese DRSs by changing all English named entities to Chinese ones as they appeared in the Chinese input (see Figure 1). This semantic annotation projection method bears strong similarities and is inspired by Damonte et al. (2017) and Min et al. (2019). Input Representation Types We consider five types of input representations, outlined in Table 1: (i) raw characters, (ii) continuous characters (i.e., without spaces), (iii) tokenised characters, (iv) tokenised words, and (v) byte-pair encoded text (BPE, Sennrich et al., 2016). Note that for Chinese, the first two options amount to the same kind of input. For BPE, we experiment with the number of merges (1k, 5k and 10k) and found in preliminary experiments that it was preferable to not add the indicator “@” for Chinese. For English character input we use an explicit “shift” symbol (ˆ) to indicate uppercased characters, to keep the vocabulary size low. Moreover, the |symbol represents an explicit word boundary. For tokenisation we use the Moses tokenizer (Koehn et al., 2007) for English, while we use the default mode of the Jieba tokenizer2 to segment the Chinese se"
2021.acl-short.97,2020.acl-main.734,0,0.0373935,"g. English results outperform those of Chinese, but it is likely that this is due to the general bias of the meaning representations towards English. Similar as for English, we find that characters are the preferred input representation for Chinese (RQ2). Surprisingly, for English, good results are even obtained by using characters without spaces as input. Tokenisation (segmenting the text into words) of the input offers a small advantage for English, but not for Chinese (RQ3), though it will be interesting to experiment with higher quality word segmentation systems (Higashiyama et al., 2019; Tian et al., 2020). There are many research directions one could take next. One is to include pre-trained models. For instance, we could use recently proposed pretrained models such as BART (Lewis et al., 2020) or mBART (Liu et al., 2020) to improve parsing performance. Another interesting idea is, rather than assuming the English WordNet as a background ontology for concepts in the DRS, using concepts based on Chinese WordNet or multilingual wordnets (Wang and Bond, 2013; Bond and Foster, 2013). Both possibilities will likely further improve performance of semantic parsing for Chinese and inspire research for"
2021.acl-short.97,N12-1030,0,0.028497,"tic phenomena by taking sentences Figure 1: Example DRS for Chinese in both clause and box representation. as input and directly outputting the corresponding DRSs, without the aid of any extra linguistic information (such as part-of-speech or syntactic structure). These previous studies have achieved good results, but have mostly focused on English or other languages that use the Latin alphabet. Our objective is to investigate whether the same method is applicable to Mandarin Chinese, an extremely analytic language which makes deep parsing challenging (Levy and Manning, 2003; Yu et al., 2011; Tse and Curran, 2012; Min et al., 2019). But Chinese is not only different on the level of syntax; its writing system also shows large differences with English, as there are no explicit word separators in written Chinese, and there is no distinction between 767 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Short Papers), pages 767–775 August 1–6, 2021. ©2021 Association for Computational Linguistics lower- and upper case characters. Unlike English, Chinese words comprise few characters, but the nu"
2021.acl-short.97,N18-2040,0,0.0256041,"Missing"
2021.acl-short.97,W13-4302,0,0.015457,"ut not for Chinese (RQ3), though it will be interesting to experiment with higher quality word segmentation systems (Higashiyama et al., 2019; Tian et al., 2020). There are many research directions one could take next. One is to include pre-trained models. For instance, we could use recently proposed pretrained models such as BART (Lewis et al., 2020) or mBART (Liu et al., 2020) to improve parsing performance. Another interesting idea is, rather than assuming the English WordNet as a background ontology for concepts in the DRS, using concepts based on Chinese WordNet or multilingual wordnets (Wang and Bond, 2013; Bond and Foster, 2013). Both possibilities will likely further improve performance of semantic parsing for Chinese and inspire research for developing semantic parsing models for languages other than English. Chinese English F-score 80 60 40 20 0 overall oper roles conc nouns verbs adj adv events Figure 3: F-scores per clause type (DRS operators, VerbNet roles and WordNet concepts) and concept type (nouns, verbs, adjectives, adverbs and events) as introduced by van Noord et al. (2018b). Reported scores are on the Chinese and English dev set for the raw character-level models, averaged over 5"
2021.acl-short.97,W04-1118,0,0.0301864,"events, Chinese Word Segmentation Differently from English, Chinese words are not separated by white spaces, as shown in Table 1. The first step of a typical Chinese NLP task is usually to use separators to mark boundaries at appropriate positions to identify words in a sentence. These words define the basic semantic units of Chinese. This process, i.e., Chinese word segmentation (Lafferty et al., 2001; Xue, 2003; Zheng et al., 2013; Cai and Zhao, 2016; Min et al., 2019), is a fundamental step for many Chinese NLP applications, which directly affects downstream performance (Foo and Li, 2004; Xu et al., 2004). Despite the large body of existing research, the quality of Chinese word segmentation remains far from perfect, because many characters are highly ambiguous. Input Formats for Neural Methods Characterlevel representations have proved useful for neural network models in many NLP tasks such as POS-tagging (Santos and Zadrozny, 2014; Plank et al., 2016), dependency parsing (Ballesteros et al., 2015) and neural machine translation (Chung et al., 2016). However, only a few studies have used character-level representations as input representations for Chinese NLP tasks (Yu et al., 2017; Li et al.,"
2021.acl-short.97,O03-4002,0,0.253152,"ntic relations by Verbnet roles (Kipper et al., 2008). DRSs can be represented in box format or clause format (see Figure 1), where x, e, s, and t are discourse referents denoting individuals, events, Chinese Word Segmentation Differently from English, Chinese words are not separated by white spaces, as shown in Table 1. The first step of a typical Chinese NLP task is usually to use separators to mark boundaries at appropriate positions to identify words in a sentence. These words define the basic semantic units of Chinese. This process, i.e., Chinese word segmentation (Lafferty et al., 2001; Xue, 2003; Zheng et al., 2013; Cai and Zhao, 2016; Min et al., 2019), is a fundamental step for many Chinese NLP applications, which directly affects downstream performance (Foo and Li, 2004; Xu et al., 2004). Despite the large body of existing research, the quality of Chinese word segmentation remains far from perfect, because many characters are highly ambiguous. Input Formats for Neural Methods Characterlevel representations have proved useful for neural network models in many NLP tasks such as POS-tagging (Santos and Zadrozny, 2014; Plank et al., 2016), dependency parsing (Ballesteros et al., 2015)"
2021.acl-short.97,D17-1027,0,0.0283507,"Li, 2004; Xu et al., 2004). Despite the large body of existing research, the quality of Chinese word segmentation remains far from perfect, because many characters are highly ambiguous. Input Formats for Neural Methods Characterlevel representations have proved useful for neural network models in many NLP tasks such as POS-tagging (Santos and Zadrozny, 2014; Plank et al., 2016), dependency parsing (Ballesteros et al., 2015) and neural machine translation (Chung et al., 2016). However, only a few studies have used character-level representations as input representations for Chinese NLP tasks (Yu et al., 2017; Li et al., 2018, 2019; Min et al., 2019). For Chinese semantic parsing, previous studies mostly used wordbased representations as well (Che et al., 2016; Wang et al., 2018). For English DRS parsing, how768 Type English input representation Chinese input representation Char (raw) Char (continuous) Char (tokenized) Word BPE (5k) ˆbrad|ˆpitt|is|an|actor. ˆbradˆpittisanactor. ˆbrad|ˆpitt|is|an|actor|. brad pitt is an actor . ˆ b@ ra@ d ˆ p@ it@ t is an ac@ tor@ . 布 拉 德 · 皮 特 是 个 演 员 。 布 拉 德 |· |皮 特 |是 |个 |演 员 |。 布拉德 · 皮特 是 个 演员 。 布 拉 德 · 皮 特 是个 演 员。 Table 1: Input representations for the English"
2021.acl-short.97,W11-2907,0,0.0330785,"a series of semantic phenomena by taking sentences Figure 1: Example DRS for Chinese in both clause and box representation. as input and directly outputting the corresponding DRSs, without the aid of any extra linguistic information (such as part-of-speech or syntactic structure). These previous studies have achieved good results, but have mostly focused on English or other languages that use the Latin alphabet. Our objective is to investigate whether the same method is applicable to Mandarin Chinese, an extremely analytic language which makes deep parsing challenging (Levy and Manning, 2003; Yu et al., 2011; Tse and Curran, 2012; Min et al., 2019). But Chinese is not only different on the level of syntax; its writing system also shows large differences with English, as there are no explicit word separators in written Chinese, and there is no distinction between 767 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Short Papers), pages 767–775 August 1–6, 2021. ©2021 Association for Computational Linguistics lower- and upper case characters. Unlike English, Chinese words comprise few"
2021.acl-short.97,D13-1061,0,0.0930746,"Missing"
2021.emnlp-main.794,P19-1509,0,0.0925115,"rated Language Learning 1 Yuchen Lian1,2 , Arianna Bisazza3 , Tessa Verhoef2 Faculty of Electronic and Information Engineering, Xi’an Jiaotong University 2 Leiden Institute of Advanced Computer Science, Leiden University 3 Center for Language and Cognition, University of Groningen {y.lian, t.verhoef}@liacs.leidenuniv.nl a.bisazza@rug.nl Abstract Natural languages display a trade-off among different strategies to convey syntactic structure, such as word order or inflection. This trade-off, however, has not appeared in recent simulations of iterated language learning with neural network agents (Chaabouni et al., 2019b). We re-evaluate this result in light of three factors that play an important role in comparable experiments from the Language Evolution field: (i) speaker bias towards efficient messaging, (ii) non systematic input languages, and (iii) learning bottleneck. Our simulations show that neural agents mainly strive to maintain the utterance type distribution observed during learning, instead of developing a more efficient or systematic language. 1 Introduction Recently, the advent of deep learning based NLP has triggered a renewed interest in agent-based simulations of language emergence. Most ex"
2021.gem-1.8,W17-5519,0,0.0415756,"Missing"
2021.gem-1.8,2020.tacl-1.3,0,0.0141098,"nse sentences, but past tense and present tense can be generated well. The original test set contained not so many DRSs in future tense, but in the challenge set we added relatively many of them, which likely caused the lower performance on the challenge set. With regards to the polarity challenge set, inspection of the output shows that a common error is to confuse “never” with “not”. This difference in meaning is reflected in a DRS by the relative order of the reference time and the DRS negation operator. Interestingly, recent work in machine translation (Tang, 2020) and language modelling (Ettinger, 2020) has also shown that state-of-the-art neural models still struggle with handling negation. Although the results of the automatic evaluation metrics in the last three challenge sets have no obvious changes compared with the original data sets, our manual evaluation results show that the performance of the model in all challenge sets is lower than the original data sets. This further shows that there is not always a positive correlation between automatic evaluation and manual evaluation, and it is still necessary to rely on manual evaluation. BLEU METEOR ROUGE Char-level (raw) Word-level (tok) 6"
2021.gem-1.8,W13-2322,0,0.0493702,"es. The aim of these challenge sets is to assess the neural generator’s systematicity and generalization to unseen inputs. 1 Arianna Bisazza CLCG Univ. of Groningen Introduction Faithfully generating text from structured representations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, such as Discourse Representation Structures (DRSs). DRSs are proposed in Discourse Representation Theory (Kamp and Reyle, 1993; Kadmon, 1 Concurrently to this work, Liu et al. (2021) published a DRS-to-t"
2021.gem-1.8,W19-1202,0,0.011861,"MR is that DRSs are in principle language neutral (at least the version of DRS that we use in this paper), with gold standard annotations publicly available in four languages (Abzianidze et al., 2017). For these reasons, developing portable and high-quality generation systems for DRSs is a promising research direction. While there has been some initial work on DRSto-text generation (Basile and Bos, 2011; Narayan and Gardent, 2014; Basile, 2015), most DRS-based work has focused on semantic parsing, that is mapping text to DRS (Liu et al., 2018; van Noord et al., 2018b, 2019; Liu et al., 2019b; Evang, 2019; van Noord et al., 2020; Fancellu et al., 2020). Our work has two main contributions. The first is on the modelling side, as we take the first step in DRS-to-text generation with neural networks.1 Specifically, we use a bi-LSTM sequence-to-sequence model that processes linearized DRSs representations and produces English texts using a character-level decoder (see pipeline in Figure 1). Our second contribution regards the evaluation of the produced text. Given the known limitations of reference-based automatic metrics for natural language generation (Reiter and Belz, 2009; Novikova et al., 201"
2021.gem-1.8,2020.findings-emnlp.320,0,0.0597967,"Missing"
2021.gem-1.8,W11-2819,1,0.45373,", but their inclusion presents a challenge for the generation methods as well, as they, for example, have to deal with a lot more variables in the representation (van Noord et al., 2018a). Another difference with AMR is that DRSs are in principle language neutral (at least the version of DRS that we use in this paper), with gold standard annotations publicly available in four languages (Abzianidze et al., 2017). For these reasons, developing portable and high-quality generation systems for DRSs is a promising research direction. While there has been some initial work on DRSto-text generation (Basile and Bos, 2011; Narayan and Gardent, 2014; Basile, 2015), most DRS-based work has focused on semantic parsing, that is mapping text to DRS (Liu et al., 2018; van Noord et al., 2018b, 2019; Liu et al., 2019b; Evang, 2019; van Noord et al., 2020; Fancellu et al., 2020). Our work has two main contributions. The first is on the modelling side, as we take the first step in DRS-to-text generation with neural networks.1 Specifically, we use a bi-LSTM sequence-to-sequence model that processes linearized DRSs representations and produces English texts using a character-level decoder (see pipeline in Figure 1). Our s"
2021.gem-1.8,N16-1087,0,0.0238144,"ROSE, that targets specific semantic phenomena. We do this with five DRS generation challenge sets focusing on tense, grammatical number, polarity, named entities and quantities. The aim of these challenge sets is to assess the neural generator’s systematicity and generalization to unseen inputs. 1 Arianna Bisazza CLCG Univ. of Groningen Introduction Faithfully generating text from structured representations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, such as Discourse Represe"
2021.gem-1.8,S12-1040,1,0.775175,"these test suites it shows that it can deal with specific semantic phenomena adequately in unforeseen circumstances. We carry out these modifications on subsets of the PMB test data, and we group them into those that assess systematic predictions (tense, polarity, and grammatical number) and those that assess generalisation to unseen input (names and quantities). The specific challenge sets are described in detail below. 3.2 As negation plays a crucial role to determine the truth conditions of a sentence, there has been ample interest in recognizing negation in text (Morante and Blanco, 2012; Basile et al., 2012) and translating accurately (Sennrich, 2017; Tang, 2020). Here we focus on generation, that is expressing negation appropriately in a sentence given a meaning representation. Negation is expressed in a DRS with a unary operator, introducing an embedded DRS. For the first 100 instances of the test set we removed negation if it was already present, or, more frequently, added it if it was not. Again, the corresponding reference text was changed to reflect this change in meaning. Example: I cooked dinner. → I didn’t cook dinner. 3.3 Tom had three thousand books. Tom does not have three thousand bo"
2021.gem-1.8,W17-3518,0,0.0244069,"evaluate the surface level of generated output, we develop a new metric, ROSE, that targets specific semantic phenomena. We do this with five DRS generation challenge sets focusing on tense, grammatical number, polarity, named entities and quantities. The aim of these challenge sets is to assess the neural generator’s systematicity and generalization to unseen inputs. 1 Arianna Bisazza CLCG Univ. of Groningen Introduction Faithfully generating text from structured representations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to gener"
2021.gem-1.8,P07-2045,0,0.00835635,"of text representation possibilities, we considered just two ways to represent text: character-based, where raw characters are separate entities and spaces are indicated by a special symbol (three vertical bars); or (tokenised) word-based, where tokenised words form the basic entities. The character-based approach has the advantage that post-processing is straightforward. The use of word-level representations is the classical approach in natural language processing, but requires a de-tokenisation step after generating. Tokenisation and de-tokenisation is carried out with the Moses tokenizer (Koehn et al., 2007). 2.3 Value Parameter decoder, a mini-batch size of 48 and the Adam optimizer (Kingma and Ba, 2015) with a learning rate of 0.002. All hyper-parameters are shown in Table1. We use the English gold standard training, dev and test data of PMB 3.0.03 , containing 6,620, 885 and 898 instances, respectively. During training, we merge the gold standard with the only partially manually annotated silver standard of 97,598 instances. Differently from van Noord et al. (2018b), we do not fine-tune on the gold standard data in a second step, as this did not lead to improved performance. Vocabulary For a w"
2021.gem-1.8,C16-1103,0,0.0546334,"Missing"
2021.gem-1.8,P17-1014,0,0.0206008,"zation to unseen inputs. 1 Arianna Bisazza CLCG Univ. of Groningen Introduction Faithfully generating text from structured representations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, such as Discourse Representation Structures (DRSs). DRSs are proposed in Discourse Representation Theory (Kamp and Reyle, 1993; Kadmon, 1 Concurrently to this work, Liu et al. (2021) published a DRS-to-text model that is based on tree-LSTMs. 73 Proceedings of the 1st Workshop on Natural Language Ge"
2021.gem-1.8,W15-0116,0,0.01771,"develop a new metric, ROSE, that targets specific semantic phenomena. We do this with five DRS generation challenge sets focusing on tense, grammatical number, polarity, named entities and quantities. The aim of these challenge sets is to assess the neural generator’s systematicity and generalization to unseen inputs. 1 Arianna Bisazza CLCG Univ. of Groningen Introduction Faithfully generating text from structured representations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, su"
2021.gem-1.8,W07-0734,0,0.131628,"st set with numbers and then changed the numbers in the DRS representation to unknown quantity expressions, represented as a sequence of characters. For example, we changed Quantity(x, 150) to Quantity(x, 152). This way, we test if the model can systematically generalize to generate the right numeral expression, even though it has not seen this particular sequence of characters before. We use three standard metrics measuring wordoverlap between system output and references. They are BLEU (Papineni et al., 2002) used as standard in machine translation evaluation and very common in NLG, METEOR (Lavie and Agarwal, 2007), and ROUGE-L (Lin, 2004), which were applied in the COCO caption generation challenge as well as other NLG experiments (Novikova et al., 2017b; Duˇsek et al., 2020). As is well known, these standard metrics give a first, rough impression about the quality of the generated output, but often reveal only part of the story. This is why we also consider a further form of assessment. 4 4.2 Assessment Methods We consider two types of assessment for the generated English sentences. Our point of departure are the well-known automatic metrics based on Expert Assessment Inspired by work of Jagfeld et al"
2021.gem-1.8,W18-6529,0,0.0856308,"garwal, 2007), and ROUGE-L (Lin, 2004), which were applied in the COCO caption generation challenge as well as other NLG experiments (Novikova et al., 2017b; Duˇsek et al., 2020). As is well known, these standard metrics give a first, rough impression about the quality of the generated output, but often reveal only part of the story. This is why we also consider a further form of assessment. 4 4.2 Assessment Methods We consider two types of assessment for the generated English sentences. Our point of departure are the well-known automatic metrics based on Expert Assessment Inspired by work of Jagfeld et al. (2018) and Belz et al. (2020), we believe that the manual evaluation method for our task should be simple in definition, 77 deed learn the shallow information contained in the input data and copy it to generate, even if these subsets (numbers, quantities and name entities) in the DRSs do not appear in the training set. However, for tense and polarity, all three automatic metrics are significantly lower in the challenge sentences than in the original sentences. Through the observation of the generated texts of the tense challenge set, we find that it is difficult for the model to generate future tens"
2021.gem-1.8,W04-1013,0,0.0440214,"e numbers in the DRS representation to unknown quantity expressions, represented as a sequence of characters. For example, we changed Quantity(x, 150) to Quantity(x, 152). This way, we test if the model can systematically generalize to generate the right numeral expression, even though it has not seen this particular sequence of characters before. We use three standard metrics measuring wordoverlap between system output and references. They are BLEU (Papineni et al., 2002) used as standard in machine translation evaluation and very common in NLG, METEOR (Lavie and Agarwal, 2007), and ROUGE-L (Lin, 2004), which were applied in the COCO caption generation challenge as well as other NLG experiments (Novikova et al., 2017b; Duˇsek et al., 2020). As is well known, these standard metrics give a first, rough impression about the quality of the generated output, but often reveal only part of the story. This is why we also consider a further form of assessment. 4 4.2 Assessment Methods We consider two types of assessment for the generated English sentences. Our point of departure are the well-known automatic metrics based on Expert Assessment Inspired by work of Jagfeld et al. (2018) and Belz et al."
2021.gem-1.8,2020.coling-main.181,0,0.0243648,"resentations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, such as Discourse Representation Structures (DRSs). DRSs are proposed in Discourse Representation Theory (Kamp and Reyle, 1993; Kadmon, 1 Concurrently to this work, Liu et al. (2021) published a DRS-to-text model that is based on tree-LSTMs. 73 Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 73–83 August 5–6, 2021. ©2021 Association for Computational Linguistics Fi"
2021.gem-1.8,P18-1040,0,0.0259786,"representation (van Noord et al., 2018a). Another difference with AMR is that DRSs are in principle language neutral (at least the version of DRS that we use in this paper), with gold standard annotations publicly available in four languages (Abzianidze et al., 2017). For these reasons, developing portable and high-quality generation systems for DRSs is a promising research direction. While there has been some initial work on DRSto-text generation (Basile and Bos, 2011; Narayan and Gardent, 2014; Basile, 2015), most DRS-based work has focused on semantic parsing, that is mapping text to DRS (Liu et al., 2018; van Noord et al., 2018b, 2019; Liu et al., 2019b; Evang, 2019; van Noord et al., 2020; Fancellu et al., 2020). Our work has two main contributions. The first is on the modelling side, as we take the first step in DRS-to-text generation with neural networks.1 Specifically, we use a bi-LSTM sequence-to-sequence model that processes linearized DRSs representations and produces English texts using a character-level decoder (see pipeline in Figure 1). Our second contribution regards the evaluation of the produced text. Given the known limitations of reference-based automatic metrics for natural l"
2021.gem-1.8,W18-2716,0,0.0233605,"icial to not include the full vocabulary. For example, it might learn to handle unknown words better if it was exposed to unknown word tokens during training. We experimented with the vocabulary size of the target representation on the development set, as is shown in Figure 2. We find that the we get best performance when including the full vocabulary, with decreasing performance as we decrease the vocabulary. We use this setting for our word-level experiments. Neural Generation Model We use a standard recurrent encoder-decoder architecture with attention as implemented in the Marian toolkit (Junczys-Dowmunt et al., 2018), using two bi-directional LSTM layers (Hochreiter and Schmidhuber, 1997). In particular, we use an embedding size of 300 for both the encoder and 3 75 https://pmb.let.rug.nl/data.php 3 Semantic Challenge Sets tense. Example: She bought a vacuum cleaner at the supermarket. → She will buy a vacuum cleaner at the supermarket. Challenge sets are often used in Machine Translation to assess a model’s ability to systematically deal with specific linguistic phenomena that may be infrequent in standard test sets (Popovi´c and Castilho, 2019). Following this practice, we created five challenge sets for"
2021.gem-1.8,P19-1629,0,0.095897,"r difference with AMR is that DRSs are in principle language neutral (at least the version of DRS that we use in this paper), with gold standard annotations publicly available in four languages (Abzianidze et al., 2017). For these reasons, developing portable and high-quality generation systems for DRSs is a promising research direction. While there has been some initial work on DRSto-text generation (Basile and Bos, 2011; Narayan and Gardent, 2014; Basile, 2015), most DRS-based work has focused on semantic parsing, that is mapping text to DRS (Liu et al., 2018; van Noord et al., 2018b, 2019; Liu et al., 2019b; Evang, 2019; van Noord et al., 2020; Fancellu et al., 2020). Our work has two main contributions. The first is on the modelling side, as we take the first step in DRS-to-text generation with neural networks.1 Specifically, we use a bi-LSTM sequence-to-sequence model that processes linearized DRSs representations and produces English texts using a character-level decoder (see pipeline in Figure 1). Our second contribution regards the evaluation of the produced text. Given the known limitations of reference-based automatic metrics for natural language generation (Reiter and Belz, 2009; Noviko"
2021.gem-1.8,W19-1203,0,0.103335,"r difference with AMR is that DRSs are in principle language neutral (at least the version of DRS that we use in this paper), with gold standard annotations publicly available in four languages (Abzianidze et al., 2017). For these reasons, developing portable and high-quality generation systems for DRSs is a promising research direction. While there has been some initial work on DRSto-text generation (Basile and Bos, 2011; Narayan and Gardent, 2014; Basile, 2015), most DRS-based work has focused on semantic parsing, that is mapping text to DRS (Liu et al., 2018; van Noord et al., 2018b, 2019; Liu et al., 2019b; Evang, 2019; van Noord et al., 2020; Fancellu et al., 2020). Our work has two main contributions. The first is on the modelling side, as we take the first step in DRS-to-text generation with neural networks.1 Specifically, we use a bi-LSTM sequence-to-sequence model that processes linearized DRSs representations and produces English texts using a character-level decoder (see pipeline in Figure 1). Our second contribution regards the evaluation of the produced text. Given the known limitations of reference-based automatic metrics for natural language generation (Reiter and Belz, 2009; Noviko"
2021.gem-1.8,2021.naacl-main.35,0,0.0500456,"entation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, such as Discourse Representation Structures (DRSs). DRSs are proposed in Discourse Representation Theory (Kamp and Reyle, 1993; Kadmon, 1 Concurrently to this work, Liu et al. (2021) published a DRS-to-text model that is based on tree-LSTMs. 73 Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 73–83 August 5–6, 2021. ©2021 Association for Computational Linguistics Figure 1: An example of the DRS data and a corresponding reference text with their processing procedures. form a fine-grained manual evaluation. The general goal of these challenge sets is to assess the robustness of a DRS generator with respect to a number of linguistic phenomena. More specifically, we assess (i) generation systematicity with respect to th"
2021.gem-1.8,2020.emnlp-main.371,1,0.817108,"Missing"
2021.gem-1.8,2020.acl-main.167,0,0.011238,"include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, such as Discourse Representation Structures (DRSs). DRSs are proposed in Discourse Representation Theory (Kamp and Reyle, 1993; Kadmon, 1 Concurrently to this work, Liu et al. (2021) published a DRS-to-text model that is based on tree-LSTMs. 73 Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 73–83 August 5–6, 2021. ©2021 Association for Computational Linguistics Figure 1: An example of the DRS data and a correspondi"
2021.gem-1.8,D17-1238,0,0.026236,"Missing"
2021.gem-1.8,2020.coling-main.420,0,0.0118019,"o main contributions. The first is on the modelling side, as we take the first step in DRS-to-text generation with neural networks.1 Specifically, we use a bi-LSTM sequence-to-sequence model that processes linearized DRSs representations and produces English texts using a character-level decoder (see pipeline in Figure 1). Our second contribution regards the evaluation of the produced text. Given the known limitations of reference-based automatic metrics for natural language generation (Reiter and Belz, 2009; Novikova et al., 2017a) and in particular for AMRto-text (May and Priyadarshi, 2017; Manning et al., 2020), we design five DRS-specific challenge sets (Popovi´c and Castilho, 2019) and use them to perWe present an end-to-end neural approach to generate English sentences from formal meaning representations, Discourse Representation Structures (DRSs). We use a rather standard bi-LSTM sequence-to-sequence model, work with a linearized DRS input representation, and evaluate character-level and word-level decoders. We obtain very encouraging results in terms of reference-based automatic metrics such as BLEU. But because such metrics only evaluate the surface level of generated output, we develop a new"
2021.gem-1.8,W17-5525,0,0.0587451,"Missing"
2021.gem-1.8,S17-2090,0,0.0177406,"al., 2020). Our work has two main contributions. The first is on the modelling side, as we take the first step in DRS-to-text generation with neural networks.1 Specifically, we use a bi-LSTM sequence-to-sequence model that processes linearized DRSs representations and produces English texts using a character-level decoder (see pipeline in Figure 1). Our second contribution regards the evaluation of the produced text. Given the known limitations of reference-based automatic metrics for natural language generation (Reiter and Belz, 2009; Novikova et al., 2017a) and in particular for AMRto-text (May and Priyadarshi, 2017; Manning et al., 2020), we design five DRS-specific challenge sets (Popovi´c and Castilho, 2019) and use them to perWe present an end-to-end neural approach to generate English sentences from formal meaning representations, Discourse Representation Structures (DRSs). We use a rather standard bi-LSTM sequence-to-sequence model, work with a linearized DRS input representation, and evaluate character-level and word-level decoders. We obtain very encouraging results in terms of reference-based automatic metrics such as BLEU. But because such metrics only evaluate the surface level of generated ou"
2021.gem-1.8,P02-1040,0,0.111245,"changed to expressions that were never seen in the training data. We took the first 50 instances of the test set with numbers and then changed the numbers in the DRS representation to unknown quantity expressions, represented as a sequence of characters. For example, we changed Quantity(x, 150) to Quantity(x, 152). This way, we test if the model can systematically generalize to generate the right numeral expression, even though it has not seen this particular sequence of characters before. We use three standard metrics measuring wordoverlap between system output and references. They are BLEU (Papineni et al., 2002) used as standard in machine translation evaluation and very common in NLG, METEOR (Lavie and Agarwal, 2007), and ROUGE-L (Lin, 2004), which were applied in the COCO caption generation challenge as well as other NLG experiments (Novikova et al., 2017b; Duˇsek et al., 2020). As is well known, these standard metrics give a first, rough impression about the quality of the generated output, but often reveal only part of the story. This is why we also consider a further form of assessment. 4 4.2 Assessment Methods We consider two types of assessment for the generated English sentences. Our point of"
2021.gem-1.8,S12-1035,0,0.0341847,"enerator performs well on these test suites it shows that it can deal with specific semantic phenomena adequately in unforeseen circumstances. We carry out these modifications on subsets of the PMB test data, and we group them into those that assess systematic predictions (tense, polarity, and grammatical number) and those that assess generalisation to unseen input (names and quantities). The specific challenge sets are described in detail below. 3.2 As negation plays a crucial role to determine the truth conditions of a sentence, there has been ample interest in recognizing negation in text (Morante and Blanco, 2012; Basile et al., 2012) and translating accurately (Sennrich, 2017; Tang, 2020). Here we focus on generation, that is expressing negation appropriately in a sentence given a meaning representation. Negation is expressed in a DRS with a unary operator, introducing an embedded DRS. For the first 100 instances of the test set we removed negation if it was already present, or, more frequently, added it if it was not. Again, the corresponding reference text was changed to reflect this change in meaning. Example: I cooked dinner. → I didn’t cook dinner. 3.3 Tom had three thousand books. Tom does not"
2021.gem-1.8,2020.emnlp-main.89,0,0.0212567,"as BLEU. But because such metrics only evaluate the surface level of generated output, we develop a new metric, ROSE, that targets specific semantic phenomena. We do this with five DRS generation challenge sets focusing on tense, grammatical number, polarity, named entities and quantities. The aim of these challenge sets is to assess the neural generator’s systematicity and generalization to unseen inputs. 1 Arianna Bisazza CLCG Univ. of Groningen Introduction Faithfully generating text from structured representations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, f"
2021.gem-1.8,P14-1041,0,0.0280533,"presents a challenge for the generation methods as well, as they, for example, have to deal with a lot more variables in the representation (van Noord et al., 2018a). Another difference with AMR is that DRSs are in principle language neutral (at least the version of DRS that we use in this paper), with gold standard annotations publicly available in four languages (Abzianidze et al., 2017). For these reasons, developing portable and high-quality generation systems for DRSs is a promising research direction. While there has been some initial work on DRSto-text generation (Basile and Bos, 2011; Narayan and Gardent, 2014; Basile, 2015), most DRS-based work has focused on semantic parsing, that is mapping text to DRS (Liu et al., 2018; van Noord et al., 2018b, 2019; Liu et al., 2019b; Evang, 2019; van Noord et al., 2020; Fancellu et al., 2020). Our work has two main contributions. The first is on the modelling side, as we take the first step in DRS-to-text generation with neural networks.1 Specifically, we use a bi-LSTM sequence-to-sequence model that processes linearized DRSs representations and produces English texts using a character-level decoder (see pipeline in Figure 1). Our second contribution regards"
2021.gem-1.8,W19-7602,0,0.0614782,"Missing"
2021.gem-1.8,L18-1267,1,0.882016,"Missing"
2021.gem-1.8,W16-6603,0,0.0208096,"systematicity and generalization to unseen inputs. 1 Arianna Bisazza CLCG Univ. of Groningen Introduction Faithfully generating text from structured representations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, such as Discourse Representation Structures (DRSs). DRSs are proposed in Discourse Representation Theory (Kamp and Reyle, 1993; Kadmon, 1 Concurrently to this work, Liu et al. (2021) published a DRS-to-text model that is based on tree-LSTMs. 73 Proceedings of the 1st Workshop"
2021.gem-1.8,Q18-1043,1,0.891388,"Missing"
2021.gem-1.8,J09-4008,0,0.0335459,"2018b, 2019; Liu et al., 2019b; Evang, 2019; van Noord et al., 2020; Fancellu et al., 2020). Our work has two main contributions. The first is on the modelling side, as we take the first step in DRS-to-text generation with neural networks.1 Specifically, we use a bi-LSTM sequence-to-sequence model that processes linearized DRSs representations and produces English texts using a character-level decoder (see pipeline in Figure 1). Our second contribution regards the evaluation of the produced text. Given the known limitations of reference-based automatic metrics for natural language generation (Reiter and Belz, 2009; Novikova et al., 2017a) and in particular for AMRto-text (May and Priyadarshi, 2017; Manning et al., 2020), we design five DRS-specific challenge sets (Popovi´c and Castilho, 2019) and use them to perWe present an end-to-end neural approach to generate English sentences from formal meaning representations, Discourse Representation Structures (DRSs). We use a rather standard bi-LSTM sequence-to-sequence model, work with a linearized DRS input representation, and evaluate character-level and word-level decoders. We obtain very encouraging results in terms of reference-based automatic metrics s"
2021.gem-1.8,P18-1150,0,0.0183422,"v. of Groningen Introduction Faithfully generating text from structured representations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, such as Discourse Representation Structures (DRSs). DRSs are proposed in Discourse Representation Theory (Kamp and Reyle, 1993; Kadmon, 1 Concurrently to this work, Liu et al. (2021) published a DRS-to-text model that is based on tree-LSTMs. 73 Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), p"
2021.gem-1.8,2020.tacl-1.2,0,0.0341543,"Missing"
2021.gem-1.8,2020.acl-main.224,0,0.024264,"from structured representations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, such as Discourse Representation Structures (DRSs). DRSs are proposed in Discourse Representation Theory (Kamp and Reyle, 1993; Kadmon, 1 Concurrently to this work, Liu et al. (2021) published a DRS-to-text model that is based on tree-LSTMs. 73 Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 73–83 August 5–6, 2021. ©2021 Association for Compu"
2021.gem-1.8,D19-1548,0,0.0151835,"roduction Faithfully generating text from structured representations is an important task in NLP. Common tasks include generations from tables (Parikh et al., 2020), knowledge graphs (Gardent et al., 2017) and meaning representations (Horvat et al., 2015; Flanigan et al., 2016; Duˇsek and Jurˇc´ıcˇ ek, 2019). Recently, many research efforts have focused on the graph-based semantic formalism Abstract Meaning Representation (AMR, Banarescu et al., 2013), with approaches based on machine translation (Pourdamghani et al., 2016; Konstas et al., 2017), specialized graph encoders (Song et al., 2018; Zhu et al., 2019; Cai and Lam, 2020; Zhao et al., 2020; Jin and Gildea, 2020) and pre-trained language models (Mager et al., 2020; Ribeiro et al., 2020). However, far less attention has been given to generating text from formal meaning representation, such as Discourse Representation Structures (DRSs). DRSs are proposed in Discourse Representation Theory (Kamp and Reyle, 1993; Kadmon, 1 Concurrently to this work, Liu et al. (2021) published a DRS-to-text model that is based on tree-LSTMs. 73 Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 73–83 August"
2021.nodalida-main.8,Q16-1031,0,0.0556293,"Missing"
2021.nodalida-main.8,Q19-1038,0,0.0872966,"of the past few years has been that a single neural network can be successfully trained to perform a given NLP task in multiple languages without architectural changes compared to monolin¨ gual models (Ostling and Tiedemann, 2017; Johnson et al., 2017). Besides important practical advantages (fewer parameters and models to maintain), such multilingual Neural Networks (mNNs) provide an easy but powerful way to transfer taskspecific knowledge from high- to low-resource languages (Devlin et al., 2019; Conneau and Lample, 2019; Aharoni et al., 2019; Neubig and Hu, 2018; Arivazhagan et al., 2019; Artetxe and Schwenk, 2019; Chi et al., 2020). These success stories have led to a need for understanding how exactly cross-lingual transfer works within these models. Figure 1 illustrates different possible characterizations of a trained mNN: While the no-transfer scenario is rather easy to rule out, understanding which linguistic categories are shared, and to what extent, is more challenging. In this work, we focus on the transfer of syntactic knowledge among languages and look for evidence that mNNs induce a shared syntactic representation space while not receiving any direct cross-lingual supervision. To be clear,"
2021.nodalida-main.8,P17-1080,0,0.0310469,"ependency parsers to low- (or zero-)resource languages (Wu and Dredze, 2019; Kondratyuk and Straka, 2019; Tran and Bisazza, 2019). On the task of crosslingual textual entailment (Conneau et al., 2018b), XLM-based classifiers come surprisingly close to systems that use fully-supervised MT as part of their pipeline (to translate the training or test data). Implicit Learning of Linguistic Structure NNs trained for downstream tasks such as language modeling, translation or textual entailment, have been shown to implicitly encode a great deal of linguistic structure such as morphological features (Belinkov et al., 2017; Bisazza and Tump, 2018; Bjerva and Augenstein, 2018), number agreement (Linzen et al., 2016; Gulordava et al., 2018) and other structure-sensitive phenomena (Marvin and Linzen, 2018). Studies such as (Tenney et al., 2019b,a; Jawahar et al., 2019) have extended these findings to BERT representations showing positive results on a variety of syntactic probing tasks. Extensive overviews of this body of work are presented in (Belinkov and Glass, 2019) and (Rogers et al., 2020). Cross-lingual Transfer in Multilingual NNs Recent studies (Wu and Dredze, 2019; Pires et al., 2019; Chi et al., 2020) ha"
2021.nodalida-main.8,Q19-1004,0,0.0156354,"modeling, translation or textual entailment, have been shown to implicitly encode a great deal of linguistic structure such as morphological features (Belinkov et al., 2017; Bisazza and Tump, 2018; Bjerva and Augenstein, 2018), number agreement (Linzen et al., 2016; Gulordava et al., 2018) and other structure-sensitive phenomena (Marvin and Linzen, 2018). Studies such as (Tenney et al., 2019b,a; Jawahar et al., 2019) have extended these findings to BERT representations showing positive results on a variety of syntactic probing tasks. Extensive overviews of this body of work are presented in (Belinkov and Glass, 2019) and (Rogers et al., 2020). Cross-lingual Transfer in Multilingual NNs Recent studies (Wu and Dredze, 2019; Pires et al., 2019; Chi et al., 2020) have found evidence of syntactic transfer in m-BERT using POS tagging and dependency parsing experiments. On the other hand, Libovick´y et al. (2019) find that m-BERT representations capture cross-lingual semantic equivalence sufficiently well to allow for word-alignment and sentence retrieval, but fail at the more difficult task of MT quality estimation. While this massive Transformer-based (Vaswani et al., 2017) architecture has received overwhelmi"
2021.nodalida-main.8,D18-1313,1,0.931175,"w- (or zero-)resource languages (Wu and Dredze, 2019; Kondratyuk and Straka, 2019; Tran and Bisazza, 2019). On the task of crosslingual textual entailment (Conneau et al., 2018b), XLM-based classifiers come surprisingly close to systems that use fully-supervised MT as part of their pipeline (to translate the training or test data). Implicit Learning of Linguistic Structure NNs trained for downstream tasks such as language modeling, translation or textual entailment, have been shown to implicitly encode a great deal of linguistic structure such as morphological features (Belinkov et al., 2017; Bisazza and Tump, 2018; Bjerva and Augenstein, 2018), number agreement (Linzen et al., 2016; Gulordava et al., 2018) and other structure-sensitive phenomena (Marvin and Linzen, 2018). Studies such as (Tenney et al., 2019b,a; Jawahar et al., 2019) have extended these findings to BERT representations showing positive results on a variety of syntactic probing tasks. Extensive overviews of this body of work are presented in (Belinkov and Glass, 2019) and (Rogers et al., 2020). Cross-lingual Transfer in Multilingual NNs Recent studies (Wu and Dredze, 2019; Pires et al., 2019; Chi et al., 2020) have found evidence of syn"
2021.nodalida-main.8,N18-1083,0,0.0249644,"nguages (Wu and Dredze, 2019; Kondratyuk and Straka, 2019; Tran and Bisazza, 2019). On the task of crosslingual textual entailment (Conneau et al., 2018b), XLM-based classifiers come surprisingly close to systems that use fully-supervised MT as part of their pipeline (to translate the training or test data). Implicit Learning of Linguistic Structure NNs trained for downstream tasks such as language modeling, translation or textual entailment, have been shown to implicitly encode a great deal of linguistic structure such as morphological features (Belinkov et al., 2017; Bisazza and Tump, 2018; Bjerva and Augenstein, 2018), number agreement (Linzen et al., 2016; Gulordava et al., 2018) and other structure-sensitive phenomena (Marvin and Linzen, 2018). Studies such as (Tenney et al., 2019b,a; Jawahar et al., 2019) have extended these findings to BERT representations showing positive results on a variety of syntactic probing tasks. Extensive overviews of this body of work are presented in (Belinkov and Glass, 2019) and (Rogers et al., 2020). Cross-lingual Transfer in Multilingual NNs Recent studies (Wu and Dredze, 2019; Pires et al., 2019; Chi et al., 2020) have found evidence of syntactic transfer in m-BERT usin"
2021.nodalida-main.8,P18-2003,0,0.0202565,"alled natural overlap) to a no-overlap setup where all words are prepended with a language tag, resulting in a bilingual vocabulary of 100k words. 3.2 Cross-lingual Syntactic Category Classification To verify whether basic syntactic categories are shared among different language representations in mNNs, we inspect the activations of our trained LMs when processing a held-out corpus. Specifically we build linear classifiers to predict either the PoS tag or the Dependency label (type of relation to the head) of a word from its hidden layer representation. This setup is similar to previous work (Blevins et al., 2018; Tenney et al., 2019b), however our diagnostic classifiers are trained on L1 and tested on L2.1 If syntactic categories are shared, we expect to see minor drops in classification accuracy compared to a classifier trained and 1 Another difference regards the dependency classification: Blevins et al. (2018) uses constituency parsing and Tenney et al. (2019b) predicts dependency arcs given word pairs. tested on L2. In other words, we ask whether, e.g., French and Italian adjectives or subjects are recognizable by the same NN activations. Several studies such as (Bisazza and Tump, 2018; Hewitt an"
2021.nodalida-main.8,2020.acl-main.493,0,0.0728066,"been that a single neural network can be successfully trained to perform a given NLP task in multiple languages without architectural changes compared to monolin¨ gual models (Ostling and Tiedemann, 2017; Johnson et al., 2017). Besides important practical advantages (fewer parameters and models to maintain), such multilingual Neural Networks (mNNs) provide an easy but powerful way to transfer taskspecific knowledge from high- to low-resource languages (Devlin et al., 2019; Conneau and Lample, 2019; Aharoni et al., 2019; Neubig and Hu, 2018; Arivazhagan et al., 2019; Artetxe and Schwenk, 2019; Chi et al., 2020). These success stories have led to a need for understanding how exactly cross-lingual transfer works within these models. Figure 1 illustrates different possible characterizations of a trained mNN: While the no-transfer scenario is rather easy to rule out, understanding which linguistic categories are shared, and to what extent, is more challenging. In this work, we focus on the transfer of syntactic knowledge among languages and look for evidence that mNNs induce a shared syntactic representation space while not receiving any direct cross-lingual supervision. To be clear, if we measure trans"
2021.nodalida-main.8,D18-1269,0,0.167968,"LI) and document classification. m-BERT (Devlin et al., 2019; Devlin, 2018) and XLM (Conneau and Lample, 2019) are large-scale mNNs trained on a masked LM (MLM) objective using mixed-language corpora. This results in general-purpose contextualized word representations that are multilingual in nature, without requiring any parallel data. m-BERT representations have been proved particularly successful for transferring dependency parsers to low- (or zero-)resource languages (Wu and Dredze, 2019; Kondratyuk and Straka, 2019; Tran and Bisazza, 2019). On the task of crosslingual textual entailment (Conneau et al., 2018b), XLM-based classifiers come surprisingly close to systems that use fully-supervised MT as part of their pipeline (to translate the training or test data). Implicit Learning of Linguistic Structure NNs trained for downstream tasks such as language modeling, translation or textual entailment, have been shown to implicitly encode a great deal of linguistic structure such as morphological features (Belinkov et al., 2017; Bisazza and Tump, 2018; Bjerva and Augenstein, 2018), number agreement (Linzen et al., 2016; Gulordava et al., 2018) and other structure-sensitive phenomena (Marvin and Linzen,"
2021.nodalida-main.8,N19-1423,0,0.187927,"emantic transfer may not be optimal for syntactic transfer. 1 Introduction One of the most important NLP discoveries of the past few years has been that a single neural network can be successfully trained to perform a given NLP task in multiple languages without architectural changes compared to monolin¨ gual models (Ostling and Tiedemann, 2017; Johnson et al., 2017). Besides important practical advantages (fewer parameters and models to maintain), such multilingual Neural Networks (mNNs) provide an easy but powerful way to transfer taskspecific knowledge from high- to low-resource languages (Devlin et al., 2019; Conneau and Lample, 2019; Aharoni et al., 2019; Neubig and Hu, 2018; Arivazhagan et al., 2019; Artetxe and Schwenk, 2019; Chi et al., 2020). These success stories have led to a need for understanding how exactly cross-lingual transfer works within these models. Figure 1 illustrates different possible characterizations of a trained mNN: While the no-transfer scenario is rather easy to rule out, understanding which linguistic categories are shared, and to what extent, is more challenging. In this work, we focus on the transfer of syntactic knowledge among languages and look for evidence that m"
2021.nodalida-main.8,P15-1166,0,0.0370356,"agreement prediction. In this setup, we find limited and rather inconsistent evidence for the transfer of implicit grammatical knowledge when semantic cues are removed (Gulordava et al., 2018). While moderate PoS category transfer occurs, truly language-agnostic syntactic categories (such as noun or subject) do not seem to emerge in our mNN representations. Finally, we find that optimal conditions for lexical-semantic transfer may not be optimal for syntactic transfer. 2 Previous Work Multilingual Machine Translation Early work on multilingual NMT focused on building dedicated architectures (Dong et al., 2015; Firat et al., 2016; Johnson et al., 2017). Starting from (Johnson et al., 2017), m-NMT models are mostly built with the same architecture as their monolingual counterparts, by simply adding language identifying tags to the training sentences. Using a small set of English sentences and their Japanese and Korean translations, Johnson et al. (2017) showed that semantically equivalent sentences form welldefined clusters in the high-dimensional space induced by a NMT encoder trained on large-scale proprietary datasets. Kudugunta et al. (2019) analyze the similarity of encoder representations of d"
2021.nodalida-main.8,N16-1101,0,0.0287401,"on. In this setup, we find limited and rather inconsistent evidence for the transfer of implicit grammatical knowledge when semantic cues are removed (Gulordava et al., 2018). While moderate PoS category transfer occurs, truly language-agnostic syntactic categories (such as noun or subject) do not seem to emerge in our mNN representations. Finally, we find that optimal conditions for lexical-semantic transfer may not be optimal for syntactic transfer. 2 Previous Work Multilingual Machine Translation Early work on multilingual NMT focused on building dedicated architectures (Dong et al., 2015; Firat et al., 2016; Johnson et al., 2017). Starting from (Johnson et al., 2017), m-NMT models are mostly built with the same architecture as their monolingual counterparts, by simply adding language identifying tags to the training sentences. Using a small set of English sentences and their Japanese and Korean translations, Johnson et al. (2017) showed that semantically equivalent sentences form welldefined clusters in the high-dimensional space induced by a NMT encoder trained on large-scale proprietary datasets. Kudugunta et al. (2019) analyze the similarity of encoder representations of different languages w"
2021.nodalida-main.8,N18-1108,0,0.266527,"ons is given by the sharing of the hidden layer parameters (as well as, possibly, some of the word embeddings). Compression of separate language understanding/ generation systems No Transfer Compression of (mostly) separate systems + some ""information leakage"" Shallow Transfer A data-driven interlingua/ universal grammar learner Deep Transfer Figure 1: Possible characterizations of a trained mNN in terms of cross-lingual transfer levels. Neural language models have been shown to implicitly capture non-trivial structure-sensitive phenomena like long-range number agreement (Linzen et al., 2016; Gulordava et al., 2018; Marvin and Linzen, 2018). However most of these studies have been confined to monolingual models. We then investigate the following questions: 1. Does mNNs’ implicit syntactic knowledge of L2 increase by exposure to a related L1? 2. Do mNNs induce a common representation space with shared syntactic categories? Our research questions are reminiscent of wellknown questions in the fields of psycholinguistic and second language acquisition, where work has shown that both lexical and syntactic representations are shared in the mind of bilinguals (Hartsuiker et al., 2004a; Vasilyeva et al., 2010)."
2021.nodalida-main.8,D19-1275,0,0.0138519,"al., 2018; Tenney et al., 2019b), however our diagnostic classifiers are trained on L1 and tested on L2.1 If syntactic categories are shared, we expect to see minor drops in classification accuracy compared to a classifier trained and 1 Another difference regards the dependency classification: Blevins et al. (2018) uses constituency parsing and Tenney et al. (2019b) predicts dependency arcs given word pairs. tested on L2. In other words, we ask whether, e.g., French and Italian adjectives or subjects are recognizable by the same NN activations. Several studies such as (Bisazza and Tump, 2018; Hewitt and Liang, 2019; Pimentel et al., 2020) have criticised diagnostic classifiers for overestimating the ability of neural networks to capture linguistic information. We partly address these pitfalls by comparing classification accuracy on top of our trained mNNs with that of their corresponding randomly initialized counterparts. Probing Dataset We probe our models on manually annotated coarse-grained PoS and Dependency labels taken from Universal Dependency Treebanks (Nivre et al., 2019). Specifically, we use French-GSD (389k tokens), Italian-ISDT (278k), Spanish-AnCora (548k), and GermanGSD (288k). UD sentenc"
2021.nodalida-main.8,P19-1356,0,0.0206985,"to systems that use fully-supervised MT as part of their pipeline (to translate the training or test data). Implicit Learning of Linguistic Structure NNs trained for downstream tasks such as language modeling, translation or textual entailment, have been shown to implicitly encode a great deal of linguistic structure such as morphological features (Belinkov et al., 2017; Bisazza and Tump, 2018; Bjerva and Augenstein, 2018), number agreement (Linzen et al., 2016; Gulordava et al., 2018) and other structure-sensitive phenomena (Marvin and Linzen, 2018). Studies such as (Tenney et al., 2019b,a; Jawahar et al., 2019) have extended these findings to BERT representations showing positive results on a variety of syntactic probing tasks. Extensive overviews of this body of work are presented in (Belinkov and Glass, 2019) and (Rogers et al., 2020). Cross-lingual Transfer in Multilingual NNs Recent studies (Wu and Dredze, 2019; Pires et al., 2019; Chi et al., 2020) have found evidence of syntactic transfer in m-BERT using POS tagging and dependency parsing experiments. On the other hand, Libovick´y et al. (2019) find that m-BERT representations capture cross-lingual semantic equivalence sufficiently well to all"
2021.nodalida-main.8,D19-1279,0,0.0182423,"tilingual NMT system similar to (Johnson et al., 2017) to perform cross-lingual textual entailment (XNLI) and document classification. m-BERT (Devlin et al., 2019; Devlin, 2018) and XLM (Conneau and Lample, 2019) are large-scale mNNs trained on a masked LM (MLM) objective using mixed-language corpora. This results in general-purpose contextualized word representations that are multilingual in nature, without requiring any parallel data. m-BERT representations have been proved particularly successful for transferring dependency parsers to low- (or zero-)resource languages (Wu and Dredze, 2019; Kondratyuk and Straka, 2019; Tran and Bisazza, 2019). On the task of crosslingual textual entailment (Conneau et al., 2018b), XLM-based classifiers come surprisingly close to systems that use fully-supervised MT as part of their pipeline (to translate the training or test data). Implicit Learning of Linguistic Structure NNs trained for downstream tasks such as language modeling, translation or textual entailment, have been shown to implicitly encode a great deal of linguistic structure such as morphological features (Belinkov et al., 2017; Bisazza and Tump, 2018; Bjerva and Augenstein, 2018), number agreement (Linzen et"
2021.nodalida-main.8,D19-1167,0,0.018133,"ultilingual NMT focused on building dedicated architectures (Dong et al., 2015; Firat et al., 2016; Johnson et al., 2017). Starting from (Johnson et al., 2017), m-NMT models are mostly built with the same architecture as their monolingual counterparts, by simply adding language identifying tags to the training sentences. Using a small set of English sentences and their Japanese and Korean translations, Johnson et al. (2017) showed that semantically equivalent sentences form welldefined clusters in the high-dimensional space induced by a NMT encoder trained on large-scale proprietary datasets. Kudugunta et al. (2019) analyze the similarity of encoder representations of different languages within a massively m-NMT model. They find that representation similarity correlates strongly with linguistic similarity and that encoder representations diverge based on the target language. However they do not disentangle the syntactic aspect from other types of transfer. Multilingual Sentence Encoders A related line of work focuses on mapping sentences from different languages into a common representation space to be used as features in downstream tasks where training data is only available in a different language than"
2021.nodalida-main.8,P19-1493,0,0.0188044,"Missing"
2021.nodalida-main.8,Q16-1037,0,0.501084,"nguistic representations is given by the sharing of the hidden layer parameters (as well as, possibly, some of the word embeddings). Compression of separate language understanding/ generation systems No Transfer Compression of (mostly) separate systems + some ""information leakage"" Shallow Transfer A data-driven interlingua/ universal grammar learner Deep Transfer Figure 1: Possible characterizations of a trained mNN in terms of cross-lingual transfer levels. Neural language models have been shown to implicitly capture non-trivial structure-sensitive phenomena like long-range number agreement (Linzen et al., 2016; Gulordava et al., 2018; Marvin and Linzen, 2018). However most of these studies have been confined to monolingual models. We then investigate the following questions: 1. Does mNNs’ implicit syntactic knowledge of L2 increase by exposure to a related L1? 2. Do mNNs induce a common representation space with shared syntactic categories? Our research questions are reminiscent of wellknown questions in the fields of psycholinguistic and second language acquisition, where work has shown that both lexical and syntactic representations are shared in the mind of bilinguals (Hartsuiker et al., 2004a;"
2021.nodalida-main.8,D18-1151,0,0.311001,"ing of the hidden layer parameters (as well as, possibly, some of the word embeddings). Compression of separate language understanding/ generation systems No Transfer Compression of (mostly) separate systems + some ""information leakage"" Shallow Transfer A data-driven interlingua/ universal grammar learner Deep Transfer Figure 1: Possible characterizations of a trained mNN in terms of cross-lingual transfer levels. Neural language models have been shown to implicitly capture non-trivial structure-sensitive phenomena like long-range number agreement (Linzen et al., 2016; Gulordava et al., 2018; Marvin and Linzen, 2018). However most of these studies have been confined to monolingual models. We then investigate the following questions: 1. Does mNNs’ implicit syntactic knowledge of L2 increase by exposure to a related L1? 2. Do mNNs induce a common representation space with shared syntactic categories? Our research questions are reminiscent of wellknown questions in the fields of psycholinguistic and second language acquisition, where work has shown that both lexical and syntactic representations are shared in the mind of bilinguals (Hartsuiker et al., 2004a; Vasilyeva et al., 2010). Taking inspiration from t"
2021.nodalida-main.8,2020.acl-main.490,0,0.0167104,"ence retrieval, but fail at the more difficult task of MT quality estimation. While this massive Transformer-based (Vaswani et al., 2017) architecture has received overwhelming attention in the past year, we believe that smaller, better understood, and easier to replicate model configurations can still play an important role in the pursuit of NLP model explainability. Moreover, the large number of m-BERT training languages (ca. 100) added to the uneven language data distribution and the highly shared subword vocabulary, make it difficult to isolate transfer effects in any given language pair. Mueller et al. (2020) recently tested a LSTM trained on five languages on a multilingual extension of the subjectverb agreement set of Marvin and Linzen (2018). They found signs of harmful interference rather than positive transfer across languages. In Section 4 we corroborate this rather surprising finding by using a more favourable setup for transfer, that is: (i) only two, related, training languages, (ii) a simulated low-resource setup for the target language, and (iii) eliminating vocabulary overlap during training with language IDs. Cross-lingual Transfer in the Bilingual Mind Measuring the extent to which d"
2021.nodalida-main.8,P12-1066,0,0.0360706,"a Spanish passive sentence. Using neuroimaging techniques in a reading comprehension experiment with in German-English bilinguals, Tooley and Traxler (2010) report that the processing of L1 and L2 sentences activates the same brain areas, pointing to the shared nature of syntactic processing in the bilingual mind. Taking inspiration from this body of work, we investigate what factors trigger cross-lingual transfer of syntactic knowledge within mNNs. Cross-Lingual Dependency Parsing Finally, our work is also related to the productive field of cross-lingual and multilingual dependency parsing (Naseem et al., 2012; Zhang and Barzilay, 2015; T¨ackstr¨om et al., 2012; Ammar et al., 2016, inter alia), with the important difference that we are interested in models that are not explicitly trained to recognize syntactic structure but acquire it indirectly while optimizing next word prediction or translation objectives. Among others, Ahmad et al. (2019) have shown that the difficulty of transferring a dependency parser cross-lingually depends on typological differences between the source and target languages, with word order differences playing an important role. In this paper, we mainly consider source-targe"
2021.nodalida-main.8,D18-1103,0,0.0218551,"ction One of the most important NLP discoveries of the past few years has been that a single neural network can be successfully trained to perform a given NLP task in multiple languages without architectural changes compared to monolin¨ gual models (Ostling and Tiedemann, 2017; Johnson et al., 2017). Besides important practical advantages (fewer parameters and models to maintain), such multilingual Neural Networks (mNNs) provide an easy but powerful way to transfer taskspecific knowledge from high- to low-resource languages (Devlin et al., 2019; Conneau and Lample, 2019; Aharoni et al., 2019; Neubig and Hu, 2018; Arivazhagan et al., 2019; Artetxe and Schwenk, 2019; Chi et al., 2020). These success stories have led to a need for understanding how exactly cross-lingual transfer works within these models. Figure 1 illustrates different possible characterizations of a trained mNN: While the no-transfer scenario is rather easy to rule out, understanding which linguistic categories are shared, and to what extent, is more challenging. In this work, we focus on the transfer of syntactic knowledge among languages and look for evidence that mNNs induce a shared syntactic representation space while not receivin"
2021.nodalida-main.8,P19-1492,0,0.0257012,"The classifiers are always tested on L2 (IT), and trained on either L2 or L1 (FR). If syntactic categories were perfectly shared across languages, we should observe no drop between the blue and orange bars. Dashed red lines show majority baselines for both (b) and (c). 5.1 Effect of Training Regime and Vocabulary Overlap on Syntactic Category Transfer In this section we examine the same FR-IT Wikipedia-based LMs described in section 4.2. Figure 4(a) shows that joint training yields better alignment of the word embedding spaces compared to the pre-training setup, which confirms the findings by Ormazabal et al. (2019). Secondly, eliminating vocabulary overlap does not necessarily imply less alignment. Interestingly, work on m-BERT/XLM models has also shown that vocabulary overlap has a much smaller effect on transfer than previously believed (Wu et al., 2019). An exception to this is the combination of pre-training and disjoint vocabulary (dubbed P/D), which gives near zero alignment of both lexical and syntactic spaces. This suggests that sharing hidden layers is not a sufficient ingredient to adapt a pre-trained model on a new (even if related) language, and that specific techniques should be used when j"
2021.nodalida-main.8,E17-2102,0,0.0210942,"rms of cross-lingual transfer and look for its most determining factors, using a variety of models and probing tasks. We find that exposing our LMs to a related language does not always increase grammatical knowledge in the target language, and that optimal conditions for lexicalsemantic transfer may not be optimal for syntactic transfer. 1 Introduction One of the most important NLP discoveries of the past few years has been that a single neural network can be successfully trained to perform a given NLP task in multiple languages without architectural changes compared to monolin¨ gual models (Ostling and Tiedemann, 2017; Johnson et al., 2017). Besides important practical advantages (fewer parameters and models to maintain), such multilingual Neural Networks (mNNs) provide an easy but powerful way to transfer taskspecific knowledge from high- to low-resource languages (Devlin et al., 2019; Conneau and Lample, 2019; Aharoni et al., 2019; Neubig and Hu, 2018; Arivazhagan et al., 2019; Artetxe and Schwenk, 2019; Chi et al., 2020). These success stories have led to a need for understanding how exactly cross-lingual transfer works within these models. Figure 1 illustrates different possible characterizations of a"
2021.nodalida-main.8,N18-1202,0,0.0558944,"h parallel sentences, where L1 is one of nine languages chosen from three different families: French, Italian, Portuguese, Spanish (Romance); German, Dutch, Swedish and Danish (Germanic) and Finnish (Uralic), with about 45.9M tokens for each language pair. The NMT models implement a standard attentional sequence-to-sequence architecture based on 4-layer bidirectional LSTMs (Bahdanau et al., 2015) with embedding and hidden layer size of 1024. To maximize comparability between translation and language modeling objectives, the LMs in these experiments are also 4-layer bidirectional (BiLMs, a` la Peters et al. (2018)) with the same hidden layer size, trained on the source-side portion of our Europarl dataset. 3.3 Word Translation Retrieval To put syntactic transfer in contrast with other types of transfer effects, we also experiment with word translation retrieval (henceforth abbreviated as WTR). This was used as a probing task for 2 http://www.statmt.org/europarl/v7/ cross-lingual word embeddings in (Lample et al., 2018; Conneau et al., 2018a) and involves calculating the distance (measured by cosine similarity) between the embedding of a source language word (e.g., bonjour) and that of its translation ("
2021.nodalida-main.8,2020.acl-main.420,0,0.0146236,", 2019b), however our diagnostic classifiers are trained on L1 and tested on L2.1 If syntactic categories are shared, we expect to see minor drops in classification accuracy compared to a classifier trained and 1 Another difference regards the dependency classification: Blevins et al. (2018) uses constituency parsing and Tenney et al. (2019b) predicts dependency arcs given word pairs. tested on L2. In other words, we ask whether, e.g., French and Italian adjectives or subjects are recognizable by the same NN activations. Several studies such as (Bisazza and Tump, 2018; Hewitt and Liang, 2019; Pimentel et al., 2020) have criticised diagnostic classifiers for overestimating the ability of neural networks to capture linguistic information. We partly address these pitfalls by comparing classification accuracy on top of our trained mNNs with that of their corresponding randomly initialized counterparts. Probing Dataset We probe our models on manually annotated coarse-grained PoS and Dependency labels taken from Universal Dependency Treebanks (Nivre et al., 2019). Specifically, we use French-GSD (389k tokens), Italian-ISDT (278k), Spanish-AnCora (548k), and GermanGSD (288k). UD sentences are fed to a trained"
2021.nodalida-main.8,W18-5412,0,0.0197929,"the FR-IT pair. ITsmall Original Nonce 79.8 79.4 Bilingual (FR+ITsmall ) Joint Training Pre-Training ITlarge Natural None Natural None 74.8 72.4 85.7 77.6 79.8 77.7 83.2 76.8 86.6 79.4 Table 1: Impact of training regime and vocabulary overlap on agreement accuracy (FR→IT). 5 Do mNNs Induce Shared Syntactic Categories? Predicting long-range agreement is a rather complex task: in principle, besides learning agreement rules, the model has to discern several syntactic categories such as number, PoS and dependencies (e.g. distinguishing subject from other noun phrases). In practice, previous work (Ravfogel et al., 2018) showed that LSTMs sometimes resort to shallow heuristics when predicting agreement. In this section we therefore investigate whether our mNNs induce at least basic syntactic categories that are shared across languages (RQ2). We assume this is a necessary condition to enable transfer of purely grammatical knowledge, like agreement in nonce sentences, and beyond. (a) Word Trans. Retrieval Joint Training (b) PoS Classif. Acc. Pre-Training 100 75 Joint Training 100 71.91 Mono L2→L2 Classifier Train→Test P@5 75.66 95.73 (c) Dependency Classif. Acc. Joint Training Pre-Training 95.74 95.69 75 64.93"
2021.nodalida-main.8,2020.tacl-1.54,0,0.103824,"tic and second language acquisition, where work has shown that both lexical and syntactic representations are shared in the mind of bilinguals (Hartsuiker et al., 2004a; Vasilyeva et al., 2010). Taking inspiration from this body of work, we investigate what factors are needed for mNNs to successfully transfer linguistic knowledge, including vocabulary overlap, language relatedness, number of training languages, training regime (joint vs sequential) and training objective (next word prediction vs translation to a third language). In contrast to the current mainstream focus on BERT-like models (Rogers et al., 2020), we evaluate more classical LSTM-based models trained for next word prediction or translation over a moderate number of languages (2 or 9). We choose this setup because (i) it allows for more controlled and easy-to-replicate experiments in terms of both training data and model configuration and (ii) LSTMs trained on a standard sequence prediction objective are more cognitively plausible and directly applicable to our main probing task, namely agreement prediction. In this setup, we find limited and rather inconsistent evidence for the transfer of implicit grammatical knowledge when semantic c"
2021.nodalida-main.8,N12-1052,0,0.0774709,"Missing"
2021.nodalida-main.8,P19-1452,0,0.0532636,"Missing"
2021.nodalida-main.8,D19-6132,1,0.850328,"to (Johnson et al., 2017) to perform cross-lingual textual entailment (XNLI) and document classification. m-BERT (Devlin et al., 2019; Devlin, 2018) and XLM (Conneau and Lample, 2019) are large-scale mNNs trained on a masked LM (MLM) objective using mixed-language corpora. This results in general-purpose contextualized word representations that are multilingual in nature, without requiring any parallel data. m-BERT representations have been proved particularly successful for transferring dependency parsers to low- (or zero-)resource languages (Wu and Dredze, 2019; Kondratyuk and Straka, 2019; Tran and Bisazza, 2019). On the task of crosslingual textual entailment (Conneau et al., 2018b), XLM-based classifiers come surprisingly close to systems that use fully-supervised MT as part of their pipeline (to translate the training or test data). Implicit Learning of Linguistic Structure NNs trained for downstream tasks such as language modeling, translation or textual entailment, have been shown to implicitly encode a great deal of linguistic structure such as morphological features (Belinkov et al., 2017; Bisazza and Tump, 2018; Bjerva and Augenstein, 2018), number agreement (Linzen et al., 2016; Gulordava et"
2021.nodalida-main.8,D19-1575,0,0.0205768,"rlap does not necessarily imply less alignment. Interestingly, work on m-BERT/XLM models has also shown that vocabulary overlap has a much smaller effect on transfer than previously believed (Wu et al., 2019). An exception to this is the combination of pre-training and disjoint vocabulary (dubbed P/D), which gives near zero alignment of both lexical and syntactic spaces. This suggests that sharing hidden layers is not a sufficient ingredient to adapt a pre-trained model on a new (even if related) language, and that specific techniques should be used when joint training is not a viable option (Wang et al., 2019; Artetxe et al., 2019). Moving to the transfer of syntactic categories (Fig. 4(b) we find that all cross-lingually trained PoS classifiers (except P/D) perform much better than the majority baseline but notably worse than the corresponding monolingually trained classifiers. As for dependency classification (Fig. 4c), accuracies are low overall and no cross-lingual classifier outperforms the majority baseline. In summary, some form of syntactic transfer indeed occurs, but truly language-agnostic syntactic categories (such as noun or subject) have not emerged in our mNN representations. 5.2 Tra"
2021.nodalida-main.8,D19-1077,0,0.017334,"ed by a massively multilingual NMT system similar to (Johnson et al., 2017) to perform cross-lingual textual entailment (XNLI) and document classification. m-BERT (Devlin et al., 2019; Devlin, 2018) and XLM (Conneau and Lample, 2019) are large-scale mNNs trained on a masked LM (MLM) objective using mixed-language corpora. This results in general-purpose contextualized word representations that are multilingual in nature, without requiring any parallel data. m-BERT representations have been proved particularly successful for transferring dependency parsers to low- (or zero-)resource languages (Wu and Dredze, 2019; Kondratyuk and Straka, 2019; Tran and Bisazza, 2019). On the task of crosslingual textual entailment (Conneau et al., 2018b), XLM-based classifiers come surprisingly close to systems that use fully-supervised MT as part of their pipeline (to translate the training or test data). Implicit Learning of Linguistic Structure NNs trained for downstream tasks such as language modeling, translation or textual entailment, have been shown to implicitly encode a great deal of linguistic structure such as morphological features (Belinkov et al., 2017; Bisazza and Tump, 2018; Bjerva and Augenstein, 2018)"
2021.nodalida-main.8,W18-5448,0,0.0167824,"(such as noun or subject) have not emerged in our mNN representations. 5.2 Training Objective, Number of Input Languages, and Language Relatedness We now study whether a different training objective, namely translation to a third language (English), leads to more syntactic transfer among input languages. We also check whether number of input languages and language relatedness play a significant role in the sharing of syntactic categories. All models in this section are jointly trained with natural vocabulary overlap on Europarl, and compared to their randomly initialized equivalents following Zhang and Bowman (2018). Dependency classification results are omitted as they were always below the majority baseline. Learning Objective As shown in Fig. 5(a,b), the translation objective has a slightly negative impact on the alignment of word embedding spaces when all other factors are fixed. The translation objective also leads to lower PoS accuracy (monolingually probed), confirming previous results by Zhang and Bowman (2018). However, translating to English does result in visibly better crosslingual transfer of PoS categories (mono/crosslingual drop of −27.7 for translation vs −37.2 for Classifier Train→Test P"
2021.nodalida-main.8,D15-1213,0,0.024358,"ntence. Using neuroimaging techniques in a reading comprehension experiment with in German-English bilinguals, Tooley and Traxler (2010) report that the processing of L1 and L2 sentences activates the same brain areas, pointing to the shared nature of syntactic processing in the bilingual mind. Taking inspiration from this body of work, we investigate what factors trigger cross-lingual transfer of syntactic knowledge within mNNs. Cross-Lingual Dependency Parsing Finally, our work is also related to the productive field of cross-lingual and multilingual dependency parsing (Naseem et al., 2012; Zhang and Barzilay, 2015; T¨ackstr¨om et al., 2012; Ammar et al., 2016, inter alia), with the important difference that we are interested in models that are not explicitly trained to recognize syntactic structure but acquire it indirectly while optimizing next word prediction or translation objectives. Among others, Ahmad et al. (2019) have shown that the difficulty of transferring a dependency parser cross-lingually depends on typological differences between the source and target languages, with word order differences playing an important role. In this paper, we mainly consider source-target languages that are relat"
2021.privatenlp-1.6,D07-1090,0,0.00852865,"emories to the translation company it is hiring (Cancedda, 2012). This can lead to considerably worse MT quality, higher post-editing efforts, and subsequently higher translation costs for the data owners themselves. When the complete data cannot be shared in its original form, releasing fragmented data can be considered as a compromise. The most wellknown example of releasing fragmented data is Google N-gram (Michel et al., 2011). N-gram tables consisting of sequences of n words and their counts in a given corpus were routinely used to train count-based language models (Kneser and Ney, 1995; Brants et al., 2007) before the advent of neural methods. However, N-grams are not optimal for training state-of-the-art NLP models such as sequence-to-sequence LSTM (Bahdanau et al., 2015) or Transformers (Vaswani et al., 2017). In fact, one of the main strengths of these models 2 Background To our knowledge, the use of confidential data in MT has not received much attention recently. Cancedda (2012) proposed an encryption-based (onetime pad) method for phrase-based statistical machine translation (PB-SMT). However, PB-SMT is nowadays clearly outperformed by NMT (Bentivogli et al., 2016), which function complete"
2021.privatenlp-1.6,P12-2005,0,0.0305891,"nsiderably benefit from this adaptation, and that further gains can be obtained with a simple tagging technique. 1 Introduction The availability of in-domain data remains essential to ensure the quality of Neural Machine Translation (NMT), especially in technical domains (Koehn and Knowles, 2017). However, obtaining such data is often challenging, and in many real-world scenarios this is further aggravated by data confidentiality or copyright concerns. In fact, when data content is sensitive, the owner may simply deny providing its Translation Memories to the translation company it is hiring (Cancedda, 2012). This can lead to considerably worse MT quality, higher post-editing efforts, and subsequently higher translation costs for the data owners themselves. When the complete data cannot be shared in its original form, releasing fragmented data can be considered as a compromise. The most wellknown example of releasing fragmented data is Google N-gram (Michel et al., 2011). N-gram tables consisting of sequences of n words and their counts in a given corpus were routinely used to train count-based language models (Kneser and Ney, 1995; Brants et al., 2007) before the advent of neural methods. Howeve"
2021.privatenlp-1.6,N13-1073,0,0.0642146,"Missing"
2021.privatenlp-1.6,2020.wmt-1.63,0,0.0177163,"ently and therefore require new solutions to preserve data confidentiality. In the broader context of NLP, secure multiparty computation (Feng et al., 2020) and homomorphic encryption (Al Badawi et al., 2020) have been used to provide strong privacy guarantees. Since these cryptographic methods incur high performance penalties (see (Riazi et al., 2019) for an overview of their performance in deep learning), more recent proposals have focused on the careful use of simpler cryptographic primitives while training a model over encrypted text due to confidentiality reasons. For instance, TextHide (Huang et al., 2020) allows to perform natural language understanding tasks while requiring the participants to complete an encryption step in a federated setting. The aforementioned studies mostly focus on 46 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 46–52 July 5–10, 2020. ©2020 Association for Computational Linguistics https://doi.org/10.26615/978-954-452-056-4_006 3 Approach Releasing fragmented data in the form of N-grams has a long tradition in NLP (Michel et al., 2011). However, fixed-size N-gram extraction is not directly applicable to parallel data beca"
2021.privatenlp-1.6,Q13-1035,0,0.0233152,"y more data protection. 3.2 Domain Adaptation NMT models are trained on full sentences, and their ability to capture large context is one of their main 47 Type strengths compared to classical SMT approaches. As a result, training NMT on fragmented data is likely to lead to a very poor performance. Nonetheless, we postulate that phrase pairs may still contain very valuable information for the adaptation of a general-domain system to a specific target domain. In fact, much of domain adaptation has to do with learning new words or short phrases, as well as new senses for known words and phrases (Irvine et al., 2013). As the domain adaptation technique, we choose fine-tuning (Luong et al., 2015; Sennrich et al., 2016b) which consists of continuing training a previously trained model on a, typically smaller, in-domain dataset. We start by directly fine-tuning a general-domain NMT system on a random sample of phrase pairs (occurrences, not types) extracted from the indomain dataset. Since this is expected to bias the model to produce shorter sentences, we also experiment with a simple phrase tagging technique (Sennrich et al., 2016a) so that the model may learn to represent the special nature of phrases and"
2021.privatenlp-1.6,W19-5333,0,0.0805146,"l Machine Translation Sohyung Kim Arianna Bisazza Fatih Turkmen University of Groningen s.kim22@student.rug.nl {a.bisazza, f.turkmen}@rug.nl Abstract is the ability of handling arbitrarily long contexts, which would be hindered by the use of fragmented data. In this paper, we take a pragmatic approach and ask: If the data owner can only release fragmented data due to confidentiality issues, can this still benefit downstream NMT quality in any way? Motivated by the brittleness of NMT in out-ofdomain settings (Koehn and Knowles, 2017) and the increasing availability of large pre-trained models (Ng et al., 2019), we focus on the task of adapting a strong-performing general-domain NMT system to various technical domains. We show that fine-tuning on phrase pairs can be a viable solution to exploit confidential data, but the scale of improvements varies strongly across target domains. We study the problem of domain adaptation in Neural Machine Translation (NMT) when domain-specific data cannot be shared due to confidentiality or copyright issues. As a first step, we propose to fragment data into phrase pairs and use a random sample to fine-tune a generic NMT model instead of the full sentences. Despite"
2021.privatenlp-1.6,N19-4009,0,0.0534144,"Missing"
2021.privatenlp-1.6,P09-5002,0,0.0386279,"Missing"
2021.privatenlp-1.6,P07-2045,0,0.0128469,"Missing"
2021.privatenlp-1.6,W18-6319,0,0.0196869,"l., 2019) based on Transformer (Vaswani et al., 2017) and ranked first in the WMT19 competition. 5 Results the fact that increasing the maximum length leads to a much larger number of extracted phrases that are redundant and overlapping. Previous work on lexicon-augmented NMT also reported negative results when fine-tuning on very large numbers of segments (Thompson et al., 2019b). In future work, we plan to experiment with minimum phrase length as a way to reduce the total number of phrase pairs. We evaluate the quality of NMT models by BLEU (Papineni et al., 2002) computed with S ACRE BLEU (Post, 2018). The phrase-adapted models are compared to the non-adapted baseline (Ng et al., 2019), and to fine-tuning on the original (non fragmented) dataset in order to determine the maximum possible gains. Results are reported in Table 2. Our main finding is that phrase pairs can indeed be used to fine-tune a NMT model without any changes to the architecture or the need of specific fine-tuning algorithms. The BLEU gains over the non-adapted baseline vary between +7.0 on EMEA and +1.0 on JRC. This is relevant for our scenario because even translation companies without significant in-house NMT expertise"
2021.privatenlp-1.6,W17-3204,0,0.0198469,"data cannot be shared due to confidentiality or copyright issues. As a first step, we propose to fragment data into phrase pairs and use a random sample to fine-tune a generic NMT model instead of the full sentences. Despite the loss of long segments for the sake of confidentiality protection, we find that NMT quality can considerably benefit from this adaptation, and that further gains can be obtained with a simple tagging technique. 1 Introduction The availability of in-domain data remains essential to ensure the quality of Neural Machine Translation (NMT), especially in technical domains (Koehn and Knowles, 2017). However, obtaining such data is often challenging, and in many real-world scenarios this is further aggravated by data confidentiality or copyright concerns. In fact, when data content is sensitive, the owner may simply deny providing its Translation Memories to the translation company it is hiring (Cancedda, 2012). This can lead to considerably worse MT quality, higher post-editing efforts, and subsequently higher translation costs for the data owners themselves. When the complete data cannot be shared in its original form, releasing fragmented data can be considered as a compromise. The mo"
2021.privatenlp-1.6,N16-1005,0,0.0205232,"lity to capture large context is one of their main 47 Type strengths compared to classical SMT approaches. As a result, training NMT on fragmented data is likely to lead to a very poor performance. Nonetheless, we postulate that phrase pairs may still contain very valuable information for the adaptation of a general-domain system to a specific target domain. In fact, much of domain adaptation has to do with learning new words or short phrases, as well as new senses for known words and phrases (Irvine et al., 2013). As the domain adaptation technique, we choose fine-tuning (Luong et al., 2015; Sennrich et al., 2016b) which consists of continuing training a previously trained model on a, typically smaller, in-domain dataset. We start by directly fine-tuning a general-domain NMT system on a random sample of phrase pairs (occurrences, not types) extracted from the indomain dataset. Since this is expected to bias the model to produce shorter sentences, we also experiment with a simple phrase tagging technique (Sennrich et al., 2016a) so that the model may learn to represent the special nature of phrases and be less inclined to produce short outputs when translating full sentences in the test phase. 4 Train"
2021.privatenlp-1.6,N03-1017,0,0.150885,"Missing"
2021.privatenlp-1.6,2015.iwslt-evaluation.11,0,0.12957,"Missing"
2021.privatenlp-1.6,P16-1009,0,0.0220351,"lity to capture large context is one of their main 47 Type strengths compared to classical SMT approaches. As a result, training NMT on fragmented data is likely to lead to a very poor performance. Nonetheless, we postulate that phrase pairs may still contain very valuable information for the adaptation of a general-domain system to a specific target domain. In fact, much of domain adaptation has to do with learning new words or short phrases, as well as new senses for known words and phrases (Irvine et al., 2013). As the domain adaptation technique, we choose fine-tuning (Luong et al., 2015; Sennrich et al., 2016b) which consists of continuing training a previously trained model on a, typically smaller, in-domain dataset. We start by directly fine-tuning a general-domain NMT system on a random sample of phrase pairs (occurrences, not types) extracted from the indomain dataset. Since this is expected to bias the model to produce shorter sentences, we also experiment with a simple phrase tagging technique (Sennrich et al., 2016a) so that the model may learn to represent the special nature of phrases and be less inclined to produce short outputs when translating full sentences in the test phase. 4 Train"
2021.privatenlp-1.6,D17-1156,0,0.0264262,"Missing"
2021.privatenlp-1.6,N19-1209,0,0.0756314,"ences) 41.5 37.2 45.2 35.8 36.8 38.9 29.2 29.7 54.7 Table 2: BLEU scores of German-English NMT in three different domains: medical (EMEA), software (GNOME), and legal (JRC). The baseline is the pre-trained Fairseq WMT19 news system (Ng et al., 2019) based on Transformer (Vaswani et al., 2017) and ranked first in the WMT19 competition. 5 Results the fact that increasing the maximum length leads to a much larger number of extracted phrases that are redundant and overlapping. Previous work on lexicon-augmented NMT also reported negative results when fine-tuning on very large numbers of segments (Thompson et al., 2019b). In future work, we plan to experiment with minimum phrase length as a way to reduce the total number of phrase pairs. We evaluate the quality of NMT models by BLEU (Papineni et al., 2002) computed with S ACRE BLEU (Post, 2018). The phrase-adapted models are compared to the non-adapted baseline (Ng et al., 2019), and to fine-tuning on the original (non fragmented) dataset in order to determine the maximum possible gains. Results are reported in Table 2. Our main finding is that phrase pairs can indeed be used to fine-tune a NMT model without any changes to the architecture or the need of sp"
2021.privatenlp-1.6,D19-1142,0,0.0904919,"ences) 41.5 37.2 45.2 35.8 36.8 38.9 29.2 29.7 54.7 Table 2: BLEU scores of German-English NMT in three different domains: medical (EMEA), software (GNOME), and legal (JRC). The baseline is the pre-trained Fairseq WMT19 news system (Ng et al., 2019) based on Transformer (Vaswani et al., 2017) and ranked first in the WMT19 competition. 5 Results the fact that increasing the maximum length leads to a much larger number of extracted phrases that are redundant and overlapping. Previous work on lexicon-augmented NMT also reported negative results when fine-tuning on very large numbers of segments (Thompson et al., 2019b). In future work, we plan to experiment with minimum phrase length as a way to reduce the total number of phrase pairs. We evaluate the quality of NMT models by BLEU (Papineni et al., 2002) computed with S ACRE BLEU (Post, 2018). The phrase-adapted models are compared to the non-adapted baseline (Ng et al., 2019), and to fine-tuning on the original (non fragmented) dataset in order to determine the maximum possible gains. Results are reported in Table 2. Our main finding is that phrase pairs can indeed be used to fine-tune a NMT model without any changes to the architecture or the need of sp"
2021.privatenlp-1.6,tiedemann-2012-parallel,0,0.061067,"Missing"
2021.wat-1.21,P19-1310,0,0.0241054,"7, 2018) for Malayalam and (Lingam et al., 2014; Yadav and Lingam, 2017) for Telugu. findings was also reported by Ramesh et al. (2020) for Tamil and Dandapat and Federmann (2018) for Telugu . To the best of our knowledge and as of 2021, there has not been any scientific publication involving translation to and from Kannada, except for Chakravarthi et al. (2019). One possible reason for this could be the fact that sizeable corpora involving Kannada (i.e. in the order of magnitude of at least thousand sentences) have been readily available only since 2019, with the release of the JW300 Corpus (Agić and Vulić, 2019). Neural Machine Translation On the neural machine translation (NMT) side, there have been a handful of NMT systems trained on English→Tamil. On the aforementioned Indic languages multilingual tasks of WAT-2018, Sen et al. (2018), Dabre et al. (2018) reported only 11.88 and 18.60 BLEU scores, respectively, for English→Tamil. The poor performance of these systems compared to the 30.53 BLEU score of the SMT system (Ojha et al., 2018) showed that those NMT systems were not yet suitable for translating into the morphologically rich Tamil. However, the following year, Philip et al. (2019) outperfor"
2021.wat-1.21,P18-2049,0,0.0187454,"s Religion COVID-19 Technical Religion Technical General Cinema Press Politics Religion General General COVID-19 Technical Mixed General General Kannada 18 <1 70 1 Available in: Malayalam Tamil Telugu 1 <1 <1 45 <1 14 <1 <1 45 <1 <1 <1 26 5 4 18 <1 <1 <1 <1 10 <1 <1 <1 52 <1 <1 3 10 3 9 <1 <1 <1 <1 11 10 1 3 10 8 <1 1 <1 18 Table 2: Composition of training corpora. The numbers indicate the relative size (in percentages) of the corresponding part for that language. out-of-vocabulary (OOV) tokens. This was particularly an issue for translations involving agglutinative languages such as Turkish (Ataman and Federico, 2018) or Malayalam (Manohar et al., 2020). Various segmentation algorithms were brought forward to circumvent this issue and in turn, improve translation quality. Perhaps the most widely used algorithm in NMT to date is the language-agnostic Byte Pair Encoding (BPE) by Sennrich et al. (2016). Initially proposed by Gage (1994), BPE was repurposed by Sennrich et al. (2016) for the task of subword segmentation, and is based on a simple principle whereby pairs of character sequences that are frequently observed in a corpus get merged iteratively until a predetermined dictionary size is attained. In thi"
2021.wat-1.21,2020.lrec-1.444,0,0.0178853,"se NMT systems were not yet suitable for translating into the morphologically rich Tamil. However, the following year, Philip et al. (2019) outperformed Ramasamy et al. (2012) on the UFAL dataset with a BLEU score of 13.05 (the previous best score on this test set was 9.77). They report that techniques such as domain adaptation and back-translation can make training NMT systems on low-resource languages possible. Similar 182 Multilingual NMT Since 2018 several studies have presented multilingual NMT systems that can handle English → Malayalam, Tamil and Telugu translation (Dabre et al., 2018; Choudhary et al., 2020; Ojha et al., 2018; Sen et al., 2018; Yu et al., 2020; Dabre and Chakrabarty, 2020). In particular, Sen et al. (2018) presented results where the BLEU score improved when comparing monolingual and multilingual models. Conversely, Yu et al. (2020) found that NMT systems that were multi-way (Indic ↔ Indic) performed worse than English ↔ Indic systems. To our knowledge, no work so far has explored the effect of the segmentation algorithm and dictionary size on the four languages: Kannada, Malayalam, Tamil and Telugu. 3 Subword Segmentation Techniques Prior to the emergence of subword segmenters,"
2021.wat-1.21,W02-0603,0,0.0939728,"bserved in a corpus get merged iteratively until a predetermined dictionary size is attained. In this paper we use a popular implementation of BPE, called SentencePiece (SP) (Kudo and Richardson, 2018). While purely statistical algorithms are able to segment any token into smaller segments, there is no guarantee that the generated tokens will be linguistically sensible. Unsupervised morphological induction is a rich area of research that also aims at learning a segmentation from data, but in a linguistically motivated way. The most well-known example is Morphessor with its different variants (Creutz and Lagus, 2002; Kohonen et al., 2010; Grönroos et al., 2014). An important obstacle to applying Morfessor to the task of NMT is the lack of a mechanism to determine the dictionary size. To address this, Ataman et al. (2017) proposed a modification of Morfessor FlatCat (Grönroos et al., 2014), called Linguistically Motivated Vocabulary Reduction (LMVR). Specifically, LMVR imposes an extra condition on the cost function of Morfessor Flatcat so as to favour vocabularies of the desired size. In a comparison of LMVR to BPE, Ataman et al. (2017) reported a +2.3 BLEU improvement on the English-Turkish translation"
2021.wat-1.21,2020.wat-1.9,0,0.0270135,"rich Tamil. However, the following year, Philip et al. (2019) outperformed Ramasamy et al. (2012) on the UFAL dataset with a BLEU score of 13.05 (the previous best score on this test set was 9.77). They report that techniques such as domain adaptation and back-translation can make training NMT systems on low-resource languages possible. Similar 182 Multilingual NMT Since 2018 several studies have presented multilingual NMT systems that can handle English → Malayalam, Tamil and Telugu translation (Dabre et al., 2018; Choudhary et al., 2020; Ojha et al., 2018; Sen et al., 2018; Yu et al., 2020; Dabre and Chakrabarty, 2020). In particular, Sen et al. (2018) presented results where the BLEU score improved when comparing monolingual and multilingual models. Conversely, Yu et al. (2020) found that NMT systems that were multi-way (Indic ↔ Indic) performed worse than English ↔ Indic systems. To our knowledge, no work so far has explored the effect of the segmentation algorithm and dictionary size on the four languages: Kannada, Malayalam, Tamil and Telugu. 3 Subword Segmentation Techniques Prior to the emergence of subword segmenters, translation systems were plagued with the issue of Name Domain Bible ELRC GNOME JW3"
2021.wat-1.21,Y18-3003,0,0.0123773,"been any scientific publication involving translation to and from Kannada, except for Chakravarthi et al. (2019). One possible reason for this could be the fact that sizeable corpora involving Kannada (i.e. in the order of magnitude of at least thousand sentences) have been readily available only since 2019, with the release of the JW300 Corpus (Agić and Vulić, 2019). Neural Machine Translation On the neural machine translation (NMT) side, there have been a handful of NMT systems trained on English→Tamil. On the aforementioned Indic languages multilingual tasks of WAT-2018, Sen et al. (2018), Dabre et al. (2018) reported only 11.88 and 18.60 BLEU scores, respectively, for English→Tamil. The poor performance of these systems compared to the 30.53 BLEU score of the SMT system (Ojha et al., 2018) showed that those NMT systems were not yet suitable for translating into the morphologically rich Tamil. However, the following year, Philip et al. (2019) outperformed Ramasamy et al. (2012) on the UFAL dataset with a BLEU score of 13.05 (the previous best score on this test set was 9.77). They report that techniques such as domain adaptation and back-translation can make training NMT systems on low-resource la"
2021.wat-1.21,2020.wmt-1.9,1,0.725145,"Missing"
2021.wat-1.21,W01-1409,0,0.150349,"entence pairs. The analysis of our parallel datasets (section 4.1, Table 3) shows for • What is the optimal subword dictionary size for translating from English into these Dravidian languages? In what follows, we review the relevant previous work (Sect. 2), introduce the two segmenters (Sect. 3), describe the experimental setup (Sect. 4), and present our answers to the above research questions (Sect. 5). 2 Previous Work 2.1 Translation Systems Statistical Machine Translation One of the earliest automatic translation systems for English into a Dravidian language was the English→Tamil system by Germann (2001). They trained a hybrid rule-based/statistical machine translation system that was trained on only 5k English-Tamil parallel sentences. Ramasamy et al. (2012) created SMT systems (phrase-based and hierarchical) which were trained on a dataset of 190k parallel 181 Proceedings of the 8th Workshop on Asian Translation, pages 181–190 Bangkok, Thailand (online), August 5-6, 2021. ©2021 Association for Computational Linguistics EN He was born in Thirukkuvalai village in Nagapattinam District on 3rd June, 1924. KN ಅವರು ಗಪಟಣಂ ಯ ರುಕುವಲ ಮದ 1924ರ ಜೂ 3ರಂದು ಜ ದರು. avaru nāgapattan  am jilleya tirukkuval"
2021.wat-1.21,Y18-3011,0,0.119504,"n mātam 3-ām tēti   tirukkuvalaik pirantār. TE ఆయన గపటణం 3న జ ం . ౖ మం 1924 āyana nāgapattan  am jillā tirukkuvālai grāmanlō 1924 jūn 3na janmincāru. ത� Table 1: Example sentence in English along with its translation and transliteration in the four Dravidian languages. sentences (henceforth referred to as UFAL). They also reported that applying pre-processing steps involving morphological rules based on Tamil suffixes improved the BLEU score of the baseline model to a small extent (from 9.42 to 9.77). For the Indic languages multilingual tasks of WAT2018, the Phrasal-based SMT system of Ojha et al. (2018) with a BLEU score of 30.53. Subsequent papers also focused on SMT systems for Malayalam and Telugu with some notable work including: (Anto and Nisha, 2016; Sreelekha and Bhattacharyya, 2017, 2018) for Malayalam and (Lingam et al., 2014; Yadav and Lingam, 2017) for Telugu. findings was also reported by Ramesh et al. (2020) for Tamil and Dandapat and Federmann (2018) for Telugu . To the best of our knowledge and as of 2021, there has not been any scientific publication involving translation to and from Kannada, except for Chakravarthi et al. (2019). One possible reason for this could be the fac"
2021.wat-1.21,N19-4009,0,0.0388989,"Missing"
2021.wat-1.21,P02-1040,0,0.109198,"Missing"
2021.wat-1.21,C14-1111,0,0.0196363,"il a predetermined dictionary size is attained. In this paper we use a popular implementation of BPE, called SentencePiece (SP) (Kudo and Richardson, 2018). While purely statistical algorithms are able to segment any token into smaller segments, there is no guarantee that the generated tokens will be linguistically sensible. Unsupervised morphological induction is a rich area of research that also aims at learning a segmentation from data, but in a linguistically motivated way. The most well-known example is Morphessor with its different variants (Creutz and Lagus, 2002; Kohonen et al., 2010; Grönroos et al., 2014). An important obstacle to applying Morfessor to the task of NMT is the lack of a mechanism to determine the dictionary size. To address this, Ataman et al. (2017) proposed a modification of Morfessor FlatCat (Grönroos et al., 2014), called Linguistically Motivated Vocabulary Reduction (LMVR). Specifically, LMVR imposes an extra condition on the cost function of Morfessor Flatcat so as to favour vocabularies of the desired size. In a comparison of LMVR to BPE, Ataman et al. (2017) reported a +2.3 BLEU improvement on the English-Turkish translation task of WMT18. Given the encouraging results r"
2021.wat-1.21,W10-2210,0,0.038293,"merged iteratively until a predetermined dictionary size is attained. In this paper we use a popular implementation of BPE, called SentencePiece (SP) (Kudo and Richardson, 2018). While purely statistical algorithms are able to segment any token into smaller segments, there is no guarantee that the generated tokens will be linguistically sensible. Unsupervised morphological induction is a rich area of research that also aims at learning a segmentation from data, but in a linguistically motivated way. The most well-known example is Morphessor with its different variants (Creutz and Lagus, 2002; Kohonen et al., 2010; Grönroos et al., 2014). An important obstacle to applying Morfessor to the task of NMT is the lack of a mechanism to determine the dictionary size. To address this, Ataman et al. (2017) proposed a modification of Morfessor FlatCat (Grönroos et al., 2014), called Linguistically Motivated Vocabulary Reduction (LMVR). Specifically, LMVR imposes an extra condition on the cost function of Morfessor Flatcat so as to favour vocabularies of the desired size. In a comparison of LMVR to BPE, Ataman et al. (2017) reported a +2.3 BLEU improvement on the English-Turkish translation task of WMT18. Given t"
2021.wat-1.21,D18-2012,0,0.019646,"brought forward to circumvent this issue and in turn, improve translation quality. Perhaps the most widely used algorithm in NMT to date is the language-agnostic Byte Pair Encoding (BPE) by Sennrich et al. (2016). Initially proposed by Gage (1994), BPE was repurposed by Sennrich et al. (2016) for the task of subword segmentation, and is based on a simple principle whereby pairs of character sequences that are frequently observed in a corpus get merged iteratively until a predetermined dictionary size is attained. In this paper we use a popular implementation of BPE, called SentencePiece (SP) (Kudo and Richardson, 2018). While purely statistical algorithms are able to segment any token into smaller segments, there is no guarantee that the generated tokens will be linguistically sensible. Unsupervised morphological induction is a rich area of research that also aims at learning a segmentation from data, but in a linguistically motivated way. The most well-known example is Morphessor with its different variants (Creutz and Lagus, 2002; Kohonen et al., 2010; Grönroos et al., 2014). An important obstacle to applying Morfessor to the task of NMT is the lack of a mechanism to determine the dictionary size. To addr"
2021.wat-1.21,D19-5215,0,0.078287,"Corpus (Agić and Vulić, 2019). Neural Machine Translation On the neural machine translation (NMT) side, there have been a handful of NMT systems trained on English→Tamil. On the aforementioned Indic languages multilingual tasks of WAT-2018, Sen et al. (2018), Dabre et al. (2018) reported only 11.88 and 18.60 BLEU scores, respectively, for English→Tamil. The poor performance of these systems compared to the 30.53 BLEU score of the SMT system (Ojha et al., 2018) showed that those NMT systems were not yet suitable for translating into the morphologically rich Tamil. However, the following year, Philip et al. (2019) outperformed Ramasamy et al. (2012) on the UFAL dataset with a BLEU score of 13.05 (the previous best score on this test set was 9.77). They report that techniques such as domain adaptation and back-translation can make training NMT systems on low-resource languages possible. Similar 182 Multilingual NMT Since 2018 several studies have presented multilingual NMT systems that can handle English → Malayalam, Tamil and Telugu translation (Dabre et al., 2018; Choudhary et al., 2020; Ojha et al., 2018; Sen et al., 2018; Yu et al., 2020; Dabre and Chakrabarty, 2020). In particular, Sen et al. (2018"
2021.wat-1.21,W15-3049,0,0.0673808,"Missing"
2021.wat-1.21,W18-6319,0,0.0206115,"Missing"
2021.wat-1.21,W12-5611,0,0.176281,"om English into these Dravidian languages? In what follows, we review the relevant previous work (Sect. 2), introduce the two segmenters (Sect. 3), describe the experimental setup (Sect. 4), and present our answers to the above research questions (Sect. 5). 2 Previous Work 2.1 Translation Systems Statistical Machine Translation One of the earliest automatic translation systems for English into a Dravidian language was the English→Tamil system by Germann (2001). They trained a hybrid rule-based/statistical machine translation system that was trained on only 5k English-Tamil parallel sentences. Ramasamy et al. (2012) created SMT systems (phrase-based and hierarchical) which were trained on a dataset of 190k parallel 181 Proceedings of the 8th Workshop on Asian Translation, pages 181–190 Bangkok, Thailand (online), August 5-6, 2021. ©2021 Association for Computational Linguistics EN He was born in Thirukkuvalai village in Nagapattinam District on 3rd June, 1924. KN ಅವರು ಗಪಟಣಂ ಯ ರುಕುವಲ ಮದ 1924ರ ಜೂ 3ರಂದು ಜ ದರು. avaru nāgapattan  am jilleya tirukkuvalay grāmadalli 1924ra jūn 3randu janisiddaru. ML 1924ല  നാഗപ ണം ജി യിെല തിരു ുവൈള ഗാമ ിലാണ അേ ഹം ജനി 1924l nāgapattan jillayile tirukkuval ai grāmattilān ad"
2021.wat-1.21,2020.wat-1.22,0,0.027793,"ey also reported that applying pre-processing steps involving morphological rules based on Tamil suffixes improved the BLEU score of the baseline model to a small extent (from 9.42 to 9.77). For the Indic languages multilingual tasks of WAT2018, the Phrasal-based SMT system of Ojha et al. (2018) with a BLEU score of 30.53. Subsequent papers also focused on SMT systems for Malayalam and Telugu with some notable work including: (Anto and Nisha, 2016; Sreelekha and Bhattacharyya, 2017, 2018) for Malayalam and (Lingam et al., 2014; Yadav and Lingam, 2017) for Telugu. findings was also reported by Ramesh et al. (2020) for Tamil and Dandapat and Federmann (2018) for Telugu . To the best of our knowledge and as of 2021, there has not been any scientific publication involving translation to and from Kannada, except for Chakravarthi et al. (2019). One possible reason for this could be the fact that sizeable corpora involving Kannada (i.e. in the order of magnitude of at least thousand sentences) have been readily available only since 2019, with the release of the JW300 Corpus (Agić and Vulić, 2019). Neural Machine Translation On the neural machine translation (NMT) side, there have been a handful of NMT system"
2021.wat-1.21,I11-1062,0,0.0339622,"Missing"
2021.wat-1.21,Y18-3012,0,0.0193296,"021, there has not been any scientific publication involving translation to and from Kannada, except for Chakravarthi et al. (2019). One possible reason for this could be the fact that sizeable corpora involving Kannada (i.e. in the order of magnitude of at least thousand sentences) have been readily available only since 2019, with the release of the JW300 Corpus (Agić and Vulić, 2019). Neural Machine Translation On the neural machine translation (NMT) side, there have been a handful of NMT systems trained on English→Tamil. On the aforementioned Indic languages multilingual tasks of WAT-2018, Sen et al. (2018), Dabre et al. (2018) reported only 11.88 and 18.60 BLEU scores, respectively, for English→Tamil. The poor performance of these systems compared to the 30.53 BLEU score of the SMT system (Ojha et al., 2018) showed that those NMT systems were not yet suitable for translating into the morphologically rich Tamil. However, the following year, Philip et al. (2019) outperformed Ramasamy et al. (2012) on the UFAL dataset with a BLEU score of 13.05 (the previous best score on this test set was 9.77). They report that techniques such as domain adaptation and back-translation can make training NMT syste"
2021.wat-1.21,P16-1162,0,0.0608581,"<1 <1 <1 11 10 1 3 10 8 <1 1 <1 18 Table 2: Composition of training corpora. The numbers indicate the relative size (in percentages) of the corresponding part for that language. out-of-vocabulary (OOV) tokens. This was particularly an issue for translations involving agglutinative languages such as Turkish (Ataman and Federico, 2018) or Malayalam (Manohar et al., 2020). Various segmentation algorithms were brought forward to circumvent this issue and in turn, improve translation quality. Perhaps the most widely used algorithm in NMT to date is the language-agnostic Byte Pair Encoding (BPE) by Sennrich et al. (2016). Initially proposed by Gage (1994), BPE was repurposed by Sennrich et al. (2016) for the task of subword segmentation, and is based on a simple principle whereby pairs of character sequences that are frequently observed in a corpus get merged iteratively until a predetermined dictionary size is attained. In this paper we use a popular implementation of BPE, called SentencePiece (SP) (Kudo and Richardson, 2018). While purely statistical algorithms are able to segment any token into smaller segments, there is no guarantee that the generated tokens will be linguistically sensible. Unsupervised m"
2021.wat-1.21,P19-1021,0,0.0200061,"are flipped when we look at the CHRF scores. SP systems here report higher scores, with +3.5 improvement in Malayalam and +1.1 for Telugu. Given the morphological richness of our target languages, we take CHRF as the more reliable score, and conclude that the purely statistical segmenter SP is a better choice for translation into Dravidian languages in our setup. Larger dictionary sizes better: When observing the effect of the dictionary size, we find that the size 50k gives the highest BLEU scores for Malayalam, Tamil and Telugu. This is in contrast with studies such as (Philip et al., 2019; Sennrich and Zhang, 2019) who suggest to use a smaller dictionary size for low-resource settings. For these language pairs, we see a steady increase in BLEU and CHRF as we increase the dictionary size. For Kannada, the best results are obtained for much smaller dictionary sizes, but in contrast with the other three languages, the differences between the scores for other dictionary sizes is much smaller. For instance, looking at the CHRF scores of SP, the numbers decrease from 48.3 to 46.0, whereas for instance for Malayalam, these numbers range from 47.4 to 63.6. Kannada hardest to translate: When comparing more in ge"
2021.wat-1.21,ahrenberg-2017-comparing,0,0.0241379,"sentence in English along with its translation and transliteration in the four Dravidian languages. sentences (henceforth referred to as UFAL). They also reported that applying pre-processing steps involving morphological rules based on Tamil suffixes improved the BLEU score of the baseline model to a small extent (from 9.42 to 9.77). For the Indic languages multilingual tasks of WAT2018, the Phrasal-based SMT system of Ojha et al. (2018) with a BLEU score of 30.53. Subsequent papers also focused on SMT systems for Malayalam and Telugu with some notable work including: (Anto and Nisha, 2016; Sreelekha and Bhattacharyya, 2017, 2018) for Malayalam and (Lingam et al., 2014; Yadav and Lingam, 2017) for Telugu. findings was also reported by Ramesh et al. (2020) for Tamil and Dandapat and Federmann (2018) for Telugu . To the best of our knowledge and as of 2021, there has not been any scientific publication involving translation to and from Kannada, except for Chakravarthi et al. (2019). One possible reason for this could be the fact that sizeable corpora involving Kannada (i.e. in the order of magnitude of at least thousand sentences) have been readily available only since 2019, with the release of the JW300 Corpus (A"
2021.wat-1.21,L18-1413,0,0.0492773,"Missing"
2021.wat-1.21,tiedemann-2012-parallel,0,0.0136984,"mprovement on the English-Turkish translation task of WMT18. Given the encouraging results reported on the agglutinative Turkish language, we hypothesise that translation into Dravidian languages may also benefit from a linguistically motivated segmenter, and evaluate LMVR against SP across varying vocabulary sizes. 4 Experimental Setup 4.1 Training Corpora The parallel training data is mostly taken from the datasets available for the MultiIndicMT task from WAT 2021. If a certain dataset is not available from the MultiIndicMT training repository, we resorted to extract that dataset from OPUS (Tiedemann, 2012) or WMT20. Table 2 reports on the datasets that we used along with their domain and their source. After extracting and cleaning the data (see below), approximately 8 million English tokens and their corresponding target language tokens are selected as our training corpora. We fixed the number of source tokens across language pairs in or183 Target Language Kannada Malayalam Tamil Telugu Tokens(k) EN Tokens(k) Sentences(k) Source/Target Token Ratio 817 1153 1171 1027 7791 7973 7854 7872 361 458 345 385 9.53 6.91 6.71 7.67 Table 3: Approximate sizes (in thousands) of the parallel training corpora"
C14-1181,W13-2205,0,0.219241,". These problems have been long studied in the field of speech recognition but much less in SMT, although the target LM is a core component of all state-of-the-art SMT frameworks. Partly inspired by successful research in the field of speech recognition, various forms of class-based LMs have been shown to improve the quality of SMT when used in combination with standard wordlevel LMs. These approaches, however, have mostly focused on English (Uszkoreit and Brants, 2008; Dyer et al., 2011; Monz, 2011; Hassan et al., 2007; Birch et al., 2007) with only recent exceptions (Green and DeNero, 2012; Ammar et al., 2013; Wuebker et al., 2013; Durrani et al., 2014). Moreover, there is no published work that systematically evaluates different kinds of classes, model forms and LM combination methods in a unified SMT setting. On the contrary, most of the existing literature on LM combination uses mixtures of multiple word-level LMs for domain adaptation purposes. This paper aims to fill these gaps by applying various class-based LM techniques to the challenging problem of translating into a morphologically rich language. In particular we focus on English-Russian, a language pair for which a fair amount of both p"
C14-1181,W07-0702,0,0.113831,"order n-gram estimates, even when large amounts of training data are used. These problems have been long studied in the field of speech recognition but much less in SMT, although the target LM is a core component of all state-of-the-art SMT frameworks. Partly inspired by successful research in the field of speech recognition, various forms of class-based LMs have been shown to improve the quality of SMT when used in combination with standard wordlevel LMs. These approaches, however, have mostly focused on English (Uszkoreit and Brants, 2008; Dyer et al., 2011; Monz, 2011; Hassan et al., 2007; Birch et al., 2007) with only recent exceptions (Green and DeNero, 2012; Ammar et al., 2013; Wuebker et al., 2013; Durrani et al., 2014). Moreover, there is no published work that systematically evaluates different kinds of classes, model forms and LM combination methods in a unified SMT setting. On the contrary, most of the existing literature on LM combination uses mixtures of multiple word-level LMs for domain adaptation purposes. This paper aims to fill these gaps by applying various class-based LM techniques to the challenging problem of translating into a morphologically rich language. In particular we foc"
C14-1181,E12-1045,1,0.845755,"ents or grammatical agreement. Hassan et al. (2007) and Birch et al. (2007) went as far as scoring n-grams of Combinatorial Categorial Grammar supertags. When using linguistic classes, one has to deal with the fact that the same word can belong to different classes when used in different contexts. Solutions to this problem include tagging the target word sequence as it is generated (Koehn et al., 2007; Birch et al., 2007; Green and DeNero, 2012), choosing the most probable class sequence for each phrase pair (Monz, 2011) or—even more lightweight—choosing the most probable class for each word (Bisazza and Federico, 2012). Alternatively, simpler deterministic class mappings can be derived by using shallow linguistic knowledge, such as suffixes or orthographic features. The former can be obtained with a rule-based stemmer (as in this work), or, even more simply, by selecting the φ most common word suffixes in a training corpus and then mapping each word to its longest matching suffix (M¨uller et al., 2012). Orthographic features may include capitalization information or the presence of digits, punctuation or other special characters (M¨uller et al., 2012). 2.3 Hybrid surface/class models M¨uller et al. (2012) o"
C14-1181,J92-4003,0,0.664911,"ranslation quality when used in combination with standard word-level LMs but no published work has systematically compared different kinds of classes, model forms and LM combination methods in a unified SMT setting. This paper aims to fill these gaps by focusing on the challenging problem of translating into Russian, a language with rich inflectional morphology and complex agreement phenomena. We conduct our evaluation in a large-data scenario and report statistically significant BLEU improvements of up to 0.6 points when using a refined variant of the class-based model originally proposed by Brown et al. (1992). 1 Introduction Class-based n-gram modeling is an effective approach to overcome data sparsity in language model (LM) training. By grouping words with similar distributional behavior into equivalence classes, class-based LMs have less parameters to train and can make predictions based on longer histories. This makes them particularly attractive in situations where n-gram coverage is low due to shortage of training data or to specific properties of the language at hand. While translation into English has drawn most of the research effort in statistical machine translation (SMT) so far, there i"
C14-1181,D13-1174,0,0.104091,")) · p1 (wi |C(wi )) (1) This results in models that are more compact and more robust to data sparsity. Often, in the context of SMT, the word emission probability is dropped and only the class sequence is modeled. In this work, we refer to this model form as stream-based n-gram LM:1 i−1 i−1 Pstream (wi |wi−n+1 ) = p0 (C(wi )|C(wi−n+1 )) (2) Stream-based LMs are used, for instance, in factored SMT (Koehn et al., 2007), and in general many of the ‘class-based LMs’ mentioned in the SMT literature are actually of the latter form (2) (Dyer et al., 2011; Green and DeNero, 2012; Ammar et al., 2013; Chahuneau et al., 2013; Wuebker et al., 2013; Durrani et al., 2014). One exception is the work of Uszkoreit and Brants (2008), who incorporate word emission probabilities in their class-based LM used as an additional feature function in the log-linear combination (cf. Section 3.1). Interestingly, we are not aware of work that compares actual class-based LMs and stream-based LMs with respect to SMT quality. While class-based LMs are known to be effective at counteracting data sparsity issues due to rich vocabularies, it is worth noting that they adhere to the fundamental constraints of n-gram modeling. Thus, grammat"
C14-1181,W12-3125,0,0.165523,"Missing"
C14-1181,C14-1041,0,0.11568,"the field of speech recognition but much less in SMT, although the target LM is a core component of all state-of-the-art SMT frameworks. Partly inspired by successful research in the field of speech recognition, various forms of class-based LMs have been shown to improve the quality of SMT when used in combination with standard wordlevel LMs. These approaches, however, have mostly focused on English (Uszkoreit and Brants, 2008; Dyer et al., 2011; Monz, 2011; Hassan et al., 2007; Birch et al., 2007) with only recent exceptions (Green and DeNero, 2012; Ammar et al., 2013; Wuebker et al., 2013; Durrani et al., 2014). Moreover, there is no published work that systematically evaluates different kinds of classes, model forms and LM combination methods in a unified SMT setting. On the contrary, most of the existing literature on LM combination uses mixtures of multiple word-level LMs for domain adaptation purposes. This paper aims to fill these gaps by applying various class-based LM techniques to the challenging problem of translating into a morphologically rich language. In particular we focus on English-Russian, a language pair for which a fair amount of both parallel data and monolingual data has been pr"
C14-1181,W11-2139,0,0.105356,"cabulary word rates and frequent backing-off to low order n-gram estimates, even when large amounts of training data are used. These problems have been long studied in the field of speech recognition but much less in SMT, although the target LM is a core component of all state-of-the-art SMT frameworks. Partly inspired by successful research in the field of speech recognition, various forms of class-based LMs have been shown to improve the quality of SMT when used in combination with standard wordlevel LMs. These approaches, however, have mostly focused on English (Uszkoreit and Brants, 2008; Dyer et al., 2011; Monz, 2011; Hassan et al., 2007; Birch et al., 2007) with only recent exceptions (Green and DeNero, 2012; Ammar et al., 2013; Wuebker et al., 2013; Durrani et al., 2014). Moreover, there is no published work that systematically evaluates different kinds of classes, model forms and LM combination methods in a unified SMT setting. On the contrary, most of the existing literature on LM combination uses mixtures of multiple word-level LMs for domain adaptation purposes. This paper aims to fill these gaps by applying various class-based LM techniques to the challenging problem of translating into"
C14-1181,W07-0717,0,0.0597554,"(global λ) 18.9 +0.1 24.8 +0.1 5g class, linear (class λ’s) 18.6 −0.1 24.6 −0.1 Table 4: SMT translation quality on newstest13 when using different LM combining frameworks: additional feature in the log-linear combination or linear interpolation with perplexity-tuned weights (one global lambda or class-specific lambdas). 1924 guage models may be linearly interpolated with weights determined by maximizing the likelihood of a held-out monolingual data set (see Section 3.2). While linear interpolation often outperforms log-linear interpolation for combining language models for domain adaptation (Foster and Kuhn, 2007), this does not seem to be the case for language models for morphologically rich target languages. The results presented in Table 4 consistently show that linear interpolation under-performs log-linear combination under all conditions. Even using class-specific interpolation weights as suggested by M¨uller et al. (2012) did not lead to any further improvements. 5 Conclusion We have presented the first systematic comparison of different forms of class-based LMs and different class LM combination methods in the context of SMT into a morphologically rich language. First of all, our results have s"
C14-1181,D08-1089,0,0.573326,"Missing"
C14-1181,P09-1087,0,0.0133636,"ctual class-based LMs and stream-based LMs with respect to SMT quality. While class-based LMs are known to be effective at counteracting data sparsity issues due to rich vocabularies, it is worth noting that they adhere to the fundamental constraints of n-gram modeling. Thus, grammatical agreement may be improved by a class-based LM approach only within a limited context window. Previous work that attempted to overcome this limitation includes (i) syntactic LMs for n-best reranking (Hasan et al., 2006; Carter and Monz, 2011) or integrated into decoding with significant engineering challenges (Galley and Manning, 2009; Schwartz et al., 2011) and (ii) unification-based constraints applied to a syntax-based SMT framework (Williams and Koehn, 2011). We will now describe different kinds of word-to-class mapping functions used by class-based LMs. These can be completely data-driven or based on different sorts of linguistic or orthographic features. 2.1 Data-driven classes The most popular form of class-based LMs was introduced by (Brown et al., 1992). In this approach, the corpus vocabulary is partitioned into a preset number of clusters by directly maximizing the likelihood of a training corpus. No linguistic"
C14-1181,P12-1016,0,0.724899,"f training data are used. These problems have been long studied in the field of speech recognition but much less in SMT, although the target LM is a core component of all state-of-the-art SMT frameworks. Partly inspired by successful research in the field of speech recognition, various forms of class-based LMs have been shown to improve the quality of SMT when used in combination with standard wordlevel LMs. These approaches, however, have mostly focused on English (Uszkoreit and Brants, 2008; Dyer et al., 2011; Monz, 2011; Hassan et al., 2007; Birch et al., 2007) with only recent exceptions (Green and DeNero, 2012; Ammar et al., 2013; Wuebker et al., 2013; Durrani et al., 2014). Moreover, there is no published work that systematically evaluates different kinds of classes, model forms and LM combination methods in a unified SMT setting. On the contrary, most of the existing literature on LM combination uses mixtures of multiple word-level LMs for domain adaptation purposes. This paper aims to fill these gaps by applying various class-based LM techniques to the challenging problem of translating into a morphologically rich language. In particular we focus on English-Russian, a language pair for which a f"
C14-1181,W06-2606,0,0.0298512,"unction in the log-linear combination (cf. Section 3.1). Interestingly, we are not aware of work that compares actual class-based LMs and stream-based LMs with respect to SMT quality. While class-based LMs are known to be effective at counteracting data sparsity issues due to rich vocabularies, it is worth noting that they adhere to the fundamental constraints of n-gram modeling. Thus, grammatical agreement may be improved by a class-based LM approach only within a limited context window. Previous work that attempted to overcome this limitation includes (i) syntactic LMs for n-best reranking (Hasan et al., 2006; Carter and Monz, 2011) or integrated into decoding with significant engineering challenges (Galley and Manning, 2009; Schwartz et al., 2011) and (ii) unification-based constraints applied to a syntax-based SMT framework (Williams and Koehn, 2011). We will now describe different kinds of word-to-class mapping functions used by class-based LMs. These can be completely data-driven or based on different sorts of linguistic or orthographic features. 2.1 Data-driven classes The most popular form of class-based LMs was introduced by (Brown et al., 1992). In this approach, the corpus vocabulary is p"
C14-1181,P07-1037,0,0.0550328,"Missing"
C14-1181,D11-1125,0,0.60521,"in the global combination. 3.1 Log-linear combination The standard log-linear approach to SMT allows for the combination of m arbitrary model components (or feature functions), each weighted by a corresponding weight αm : p(x|h) = Y pm (x|h)αm (4) m In typical SMT settings, pm (x|h) are phrase- or word-level translation probabilities, reordering probabilities, and so on. Treating the new LM as an additional feature function has the advantage that its weight can be directly optimized for SMT quality together with all other feature weights, using standard parameter tuning techniques (Och, 2003; Hopkins and May, 2011). 3.2 Linear interpolation The other widely used combining framework is linear interpolation or mixture model: p(x|h) = X λq pq (x|h) (5) q More specifically, word LMs are usually interpolated as a word-level weighted average of the n-gram probabilities: ! n Y X pmixLM (e) = λq pq (ei |hi ) (6) i=1 q The drawback of this approach is that the linear interpolation weights, or lambdas, cannot be set with standard SMT tuning techniques. Instead, interpolation weights are typically determined by maximizing the likelihood of a held-out monolingual data set, but this does not always outperform simple"
C14-1181,N03-1017,0,0.06745,"Missing"
C14-1181,P07-2045,0,0.0240289,"into equivalence classes. The word transition probability is then decomposed into a class transition probability and a word emission probability: i−1 i−1 Pclass (wi |wi−n+1 ) = p0 (C(wi )|C(wi−n+1 )) · p1 (wi |C(wi )) (1) This results in models that are more compact and more robust to data sparsity. Often, in the context of SMT, the word emission probability is dropped and only the class sequence is modeled. In this work, we refer to this model form as stream-based n-gram LM:1 i−1 i−1 Pstream (wi |wi−n+1 ) = p0 (C(wi )|C(wi−n+1 )) (2) Stream-based LMs are used, for instance, in factored SMT (Koehn et al., 2007), and in general many of the ‘class-based LMs’ mentioned in the SMT literature are actually of the latter form (2) (Dyer et al., 2011; Green and DeNero, 2012; Ammar et al., 2013; Chahuneau et al., 2013; Wuebker et al., 2013; Durrani et al., 2014). One exception is the work of Uszkoreit and Brants (2008), who incorporate word emission probabilities in their class-based LM used as an additional feature function in the log-linear combination (cf. Section 3.1). Interestingly, we are not aware of work that compares actual class-based LMs and stream-based LMs with respect to SMT quality. While class"
C14-1181,D09-1079,0,0.0274821,"number of clusters by directly maximizing the likelihood of a training corpus. No linguistic or orthographic features are taken into account while training the classes.2 Later work has focused on decreasing the large computational cost of the exchange algorithm proposed by Brown et al. (1992), either with a distributed algorithm (Uszkoreit and Brants, 2008) or by using a whole-context distributional vector space model (Sch¨utze and Walsh, 2011). In this paper we use the standard SRILM implementation of Brown clustering. 1 Not to be confused with the incrementally trainable stream-based LMs of Levenberg and Osborne (2009). Och (1999) extends a similar approach to bilingual clustering with the aim of generalizing the applicability of translation rules in an alignment template SMT framework. 2 1919 2.2 Linguistic classes Linguistic knowledge is another way to establish word equivalence classes. Common examples include lemma, part of speech and morphology-based classes, each of which can capture different aspects of the word sequence, such as the relative order of syntactic constituents or grammatical agreement. Hassan et al. (2007) and Birch et al. (2007) went as far as scoring n-grams of Combinatorial Categoria"
C14-1181,D11-1080,1,0.935922,"and frequent backing-off to low order n-gram estimates, even when large amounts of training data are used. These problems have been long studied in the field of speech recognition but much less in SMT, although the target LM is a core component of all state-of-the-art SMT frameworks. Partly inspired by successful research in the field of speech recognition, various forms of class-based LMs have been shown to improve the quality of SMT when used in combination with standard wordlevel LMs. These approaches, however, have mostly focused on English (Uszkoreit and Brants, 2008; Dyer et al., 2011; Monz, 2011; Hassan et al., 2007; Birch et al., 2007) with only recent exceptions (Green and DeNero, 2012; Ammar et al., 2013; Wuebker et al., 2013; Durrani et al., 2014). Moreover, there is no published work that systematically evaluates different kinds of classes, model forms and LM combination methods in a unified SMT setting. On the contrary, most of the existing literature on LM combination uses mixtures of multiple word-level LMs for domain adaptation purposes. This paper aims to fill these gaps by applying various class-based LM techniques to the challenging problem of translating into a morpholog"
C14-1181,N12-1043,0,0.206176,"Missing"
C14-1181,E99-1010,0,0.369416,"maximizing the likelihood of a training corpus. No linguistic or orthographic features are taken into account while training the classes.2 Later work has focused on decreasing the large computational cost of the exchange algorithm proposed by Brown et al. (1992), either with a distributed algorithm (Uszkoreit and Brants, 2008) or by using a whole-context distributional vector space model (Sch¨utze and Walsh, 2011). In this paper we use the standard SRILM implementation of Brown clustering. 1 Not to be confused with the incrementally trainable stream-based LMs of Levenberg and Osborne (2009). Och (1999) extends a similar approach to bilingual clustering with the aim of generalizing the applicability of translation rules in an alignment template SMT framework. 2 1919 2.2 Linguistic classes Linguistic knowledge is another way to establish word equivalence classes. Common examples include lemma, part of speech and morphology-based classes, each of which can capture different aspects of the word sequence, such as the relative order of syntactic constituents or grammatical agreement. Hassan et al. (2007) and Birch et al. (2007) went as far as scoring n-grams of Combinatorial Categorial Grammar su"
C14-1181,P03-1021,0,0.0161206,"e function in the global combination. 3.1 Log-linear combination The standard log-linear approach to SMT allows for the combination of m arbitrary model components (or feature functions), each weighted by a corresponding weight αm : p(x|h) = Y pm (x|h)αm (4) m In typical SMT settings, pm (x|h) are phrase- or word-level translation probabilities, reordering probabilities, and so on. Treating the new LM as an additional feature function has the advantage that its weight can be directly optimized for SMT quality together with all other feature weights, using standard parameter tuning techniques (Och, 2003; Hopkins and May, 2011). 3.2 Linear interpolation The other widely used combining framework is linear interpolation or mixture model: p(x|h) = X λq pq (x|h) (5) q More specifically, word LMs are usually interpolated as a word-level weighted average of the n-gram probabilities: ! n Y X pmixLM (e) = λq pq (ei |hi ) (6) i=1 q The drawback of this approach is that the linear interpolation weights, or lambdas, cannot be set with standard SMT tuning techniques. Instead, interpolation weights are typically determined by maximizing the likelihood of a held-out monolingual data set, but this does not"
C14-1181,P02-1040,0,0.0900176,"s that using class-specific interpolation weights is not significantly better, and sometimes is even worse than using only one generic λ, at least from the point of view of perplexity. Since weight estimation for linear interpolation is still an open problem for SMT, we decide nevertheless to compare these two interpolation methods in our translation experiments (see Table 4). 4.3 SMT results Table 3 shows the results for English to Russian translation using log-linear combination with Brown clusters and the hybrid suffix/word classes. Translation quality is measured by case-insensitive BLEU (Papineni et al., 2002) on newstest13 using one reference translation. The relative improvements of the different class-based LM runs are with respect to the baseline which uses a word-based LM only and achieves comparable results to the state-of-the-art. We use approximate randomization (Noreen, 1989) to test for statistically significant differences between runs (Riezler and Maxwell, 2005). We can see from Table 2(a) that using a stream-based LM as an additional feature, which is log-linearly interpolated with the other decoder features during parameter estimation, leads to small but statistically significant impr"
C14-1181,W05-0908,0,0.474134,"ee Table 4). 4.3 SMT results Table 3 shows the results for English to Russian translation using log-linear combination with Brown clusters and the hybrid suffix/word classes. Translation quality is measured by case-insensitive BLEU (Papineni et al., 2002) on newstest13 using one reference translation. The relative improvements of the different class-based LM runs are with respect to the baseline which uses a word-based LM only and achieves comparable results to the state-of-the-art. We use approximate randomization (Noreen, 1989) to test for statistically significant differences between runs (Riezler and Maxwell, 2005). We can see from Table 2(a) that using a stream-based LM as an additional feature, which is log-linearly interpolated with the other decoder features during parameter estimation, leads to small but statistically significant improvements. The results also indicate that using a higher n-gram class model (7-gram) does not yield additional improvements over a 5-gram class model, which is in contrast with the results reported by Wuebker et al. (2013) on a French-German task. Since the stream-based models ignore word emission probabilities, one would expect further improvements from the theoretical"
C14-1181,J11-4008,0,0.0432536,"Missing"
C14-1181,P11-1063,0,0.0158854,"stream-based LMs with respect to SMT quality. While class-based LMs are known to be effective at counteracting data sparsity issues due to rich vocabularies, it is worth noting that they adhere to the fundamental constraints of n-gram modeling. Thus, grammatical agreement may be improved by a class-based LM approach only within a limited context window. Previous work that attempted to overcome this limitation includes (i) syntactic LMs for n-best reranking (Hasan et al., 2006; Carter and Monz, 2011) or integrated into decoding with significant engineering challenges (Galley and Manning, 2009; Schwartz et al., 2011) and (ii) unification-based constraints applied to a syntax-based SMT framework (Williams and Koehn, 2011). We will now describe different kinds of word-to-class mapping functions used by class-based LMs. These can be completely data-driven or based on different sorts of linguistic or orthographic features. 2.1 Data-driven classes The most popular form of class-based LMs was introduced by (Brown et al., 1992). In this approach, the corpus vocabulary is partitioned into a preset number of clusters by directly maximizing the likelihood of a training corpus. No linguistic or orthographic features"
C14-1181,P08-1086,0,0.54089,"at reflect in high out-of-vocabulary word rates and frequent backing-off to low order n-gram estimates, even when large amounts of training data are used. These problems have been long studied in the field of speech recognition but much less in SMT, although the target LM is a core component of all state-of-the-art SMT frameworks. Partly inspired by successful research in the field of speech recognition, various forms of class-based LMs have been shown to improve the quality of SMT when used in combination with standard wordlevel LMs. These approaches, however, have mostly focused on English (Uszkoreit and Brants, 2008; Dyer et al., 2011; Monz, 2011; Hassan et al., 2007; Birch et al., 2007) with only recent exceptions (Green and DeNero, 2012; Ammar et al., 2013; Wuebker et al., 2013; Durrani et al., 2014). Moreover, there is no published work that systematically evaluates different kinds of classes, model forms and LM combination methods in a unified SMT setting. On the contrary, most of the existing literature on LM combination uses mixtures of multiple word-level LMs for domain adaptation purposes. This paper aims to fill these gaps by applying various class-based LM techniques to the challenging problem"
C14-1181,W11-2126,0,0.0178667,"racting data sparsity issues due to rich vocabularies, it is worth noting that they adhere to the fundamental constraints of n-gram modeling. Thus, grammatical agreement may be improved by a class-based LM approach only within a limited context window. Previous work that attempted to overcome this limitation includes (i) syntactic LMs for n-best reranking (Hasan et al., 2006; Carter and Monz, 2011) or integrated into decoding with significant engineering challenges (Galley and Manning, 2009; Schwartz et al., 2011) and (ii) unification-based constraints applied to a syntax-based SMT framework (Williams and Koehn, 2011). We will now describe different kinds of word-to-class mapping functions used by class-based LMs. These can be completely data-driven or based on different sorts of linguistic or orthographic features. 2.1 Data-driven classes The most popular form of class-based LMs was introduced by (Brown et al., 1992). In this approach, the corpus vocabulary is partitioned into a preset number of clusters by directly maximizing the likelihood of a training corpus. No linguistic or orthographic features are taken into account while training the classes.2 Later work has focused on decreasing the large comput"
C14-1181,D13-1138,0,0.498402,"e been long studied in the field of speech recognition but much less in SMT, although the target LM is a core component of all state-of-the-art SMT frameworks. Partly inspired by successful research in the field of speech recognition, various forms of class-based LMs have been shown to improve the quality of SMT when used in combination with standard wordlevel LMs. These approaches, however, have mostly focused on English (Uszkoreit and Brants, 2008; Dyer et al., 2011; Monz, 2011; Hassan et al., 2007; Birch et al., 2007) with only recent exceptions (Green and DeNero, 2012; Ammar et al., 2013; Wuebker et al., 2013; Durrani et al., 2014). Moreover, there is no published work that systematically evaluates different kinds of classes, model forms and LM combination methods in a unified SMT setting. On the contrary, most of the existing literature on LM combination uses mixtures of multiple word-level LMs for domain adaptation purposes. This paper aims to fill these gaps by applying various class-based LM techniques to the challenging problem of translating into a morphologically rich language. In particular we focus on English-Russian, a language pair for which a fair amount of both parallel data and monol"
C14-1181,W13-2201,1,\N,Missing
C16-1242,P12-2040,0,0.0619647,"Missing"
C16-1242,2011.mtsummit-papers.32,0,0.068911,"Missing"
C16-1242,2012.eamt-1.41,0,0.0367107,"Missing"
C16-1242,N10-1064,0,0.0183104,"ers are harder to translate and use more vulgar language than female speakers, and that vulgarity is often not preserved during translation. 1 Introduction Research in statistical machine translation (SMT) has mostly been driven by formal translation tasks. These are, however, not representative for the abundance of informal data emerging on the Internet, for which state-of-the-art SMT systems perform markedly worse (van der Wees et al., 2015a). Recent years have therefore shown an increasing effort in improving SMT for informal text, for example by normalizing noisy text to more formal text (Bertoldi et al., 2010; Banerjee et al., 2012; Ling et al., 2013a), or by enhancing formal training data with user-generated data (Banerjee et al., 2011; Jehl et al., 2012; Ling et al., 2013b). In this paper we focus on SMT for dialogues, an informal genre that involves, by definition, multiple speakers, and is thus noticeably different from formal text (Fern´andez, 2014). Formal text is typically written by a single writer with a clear intention (e.g., informing or persuading), and moreover has been editorially controlled according to standards of language use. In dialogues, on the other hand, different speakers h"
C16-1242,W11-0609,0,0.0328163,"main This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ License details: http:// 2571 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 2571–2581, Osaka, Japan, December 11-17 2016. messages (Forchini, 2009; Forchini, 2012; Dose, 2013). In fact, movie dialogues approximate real faceto-face conversation more than for example SMS and chat, in which media constraints influence the flow of a conversation (Whittaker, 2003; Brennan and Lockridge, 2006). Finally, Danescu-Niculescu-Mizil and Lee (2011) have shown that certain psycholinguistic and gender-specific aspects of language are also observed in fictional dialogues, indicating that conclusions drawn from experiments on fictional dialogues generalize at least partially to real spoken conversations. The structure and contributions of this paper are as follows: First, in Section 2 we annotate multilingual movie dialogues with four dialogue-specific variables; dialogue acts, speakers, gender, and register level, and we release these annotated corpora. In Section 3 we describe our approach to measure how SMT quality is affected by each of"
C16-1242,D11-1125,0,0.0594698,"Missing"
C16-1242,W12-3153,0,0.0203806,"on Research in statistical machine translation (SMT) has mostly been driven by formal translation tasks. These are, however, not representative for the abundance of informal data emerging on the Internet, for which state-of-the-art SMT systems perform markedly worse (van der Wees et al., 2015a). Recent years have therefore shown an increasing effort in improving SMT for informal text, for example by normalizing noisy text to more formal text (Bertoldi et al., 2010; Banerjee et al., 2012; Ling et al., 2013a), or by enhancing formal training data with user-generated data (Banerjee et al., 2011; Jehl et al., 2012; Ling et al., 2013b). In this paper we focus on SMT for dialogues, an informal genre that involves, by definition, multiple speakers, and is thus noticeably different from formal text (Fern´andez, 2014). Formal text is typically written by a single writer with a clear intention (e.g., informing or persuading), and moreover has been editorially controlled according to standards of language use. In dialogues, on the other hand, different speakers have different intentions and language use, affected, for example, by their gender. Such variations are reflected by register, a term referring to soc"
C16-1242,P07-2045,0,0.00740994,"Missing"
C16-1242,D13-1008,0,0.0215073,"r language than female speakers, and that vulgarity is often not preserved during translation. 1 Introduction Research in statistical machine translation (SMT) has mostly been driven by formal translation tasks. These are, however, not representative for the abundance of informal data emerging on the Internet, for which state-of-the-art SMT systems perform markedly worse (van der Wees et al., 2015a). Recent years have therefore shown an increasing effort in improving SMT for informal text, for example by normalizing noisy text to more formal text (Bertoldi et al., 2010; Banerjee et al., 2012; Ling et al., 2013a), or by enhancing formal training data with user-generated data (Banerjee et al., 2011; Jehl et al., 2012; Ling et al., 2013b). In this paper we focus on SMT for dialogues, an informal genre that involves, by definition, multiple speakers, and is thus noticeably different from formal text (Fern´andez, 2014). Formal text is typically written by a single writer with a clear intention (e.g., informing or persuading), and moreover has been editorially controlled according to standards of language use. In dialogues, on the other hand, different speakers have different intentions and language use,"
C16-1242,L16-1147,0,0.148557,"Missing"
C16-1242,ma-2006-champollion,0,0.0308838,"Missing"
C16-1242,D15-1238,0,0.0259923,"Missing"
C16-1242,D15-1130,0,0.0785304,"Missing"
C16-1242,P02-1040,0,0.098913,"Missing"
C16-1242,W05-0908,0,0.123442,"Missing"
C16-1242,tiedemann-2008-synchronizing,0,0.352631,"Missing"
C16-1242,2009.eamt-1.16,0,0.0663045,"Missing"
C16-1242,L16-1559,0,0.251654,"Missing"
C16-1242,W15-4304,1,0.866525,"Missing"
C16-1242,P15-2092,1,0.839705,"Missing"
C16-1242,walker-etal-2012-annotated,0,0.0530557,"Missing"
C16-1242,L16-1436,0,0.281665,"Missing"
C16-1242,P13-1018,0,\N,Missing
D14-1175,D13-1106,0,0.0245771,"the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk, 2012; Zou et al., 2013; Gao et al., 2014) and minimal translation modeling (Hu et al., 2014). The recurrent neural network LMs of Auli et al. (2013) are primarily trained to predict target word sequences. However, they also experiment with an additional input layer representing source side context. Our models differ from most previous work in neural language modeling in that we predict a target translation given a source context while previous models predict the next word given a target word history. Unlike previous work in phrase translation modeling with NNs, our models have the advantage of accessing source context that can fall outside the phrase boundaries. We now describe our models in a general setting, predicting target translatio"
D14-1175,C14-1181,1,0.896409,"Missing"
D14-1175,W12-3102,1,0.882805,"Missing"
D14-1175,D13-1174,0,0.43889,"14 Association for Computational Linguistics pairs where the source language is morphologically poor, such as English, and the target language is morphologically rich, such as Russian, i.e., language pairs with a high degree of surface realization ambiguity (Minkov et al., 2007). To address this problem we propose a general approach based on bilingual neural networks (BNN) exploiting source-side contextual information. This paper makes a number of contributions: Unlike previous approaches our models do not require any form of linguistic annotation (Minkov et al., 2007; Kholy and Habash, 2012; Chahuneau et al., 2013), nor do they require any feature engineering (Gimpel and Smith, 2008). Moreover, besides directly predicting fully inflected forms as Jeong et al. (2010), our approach can also model stem and suffix prediction explicitly. Prediction accuracy is evaluated with respect to three morphologically rich target languages (Bulgarian, Czech, and Russian) showing that our approach consistently yields substantial improvements over a competitive baseline. We also show that these improvements in prediction accuracy can be beneficial in an end-to-end machine translation scenario by integrating into a large-"
D14-1175,W12-3125,0,0.0176506,"otherwise where a is the word-level alignment of the phrase pair (˜ s, t˜) and {ai } is the set of target positions aligned to si . If a source-target link cannot be scored by the BNN model, we give it a PBNN probability of 1 and increment a separate count feature ε. Note that the same phrase pair can get different BNN scores if used in different source side contexts. Our baseline is an in-house phrase-based (Koehn et al., 2003) statistical machine translation system very similar to Moses (Koehn et al., 2007). All system runs use hierarchical lexicalized reordering (Galley and Manning, 2008; Cherry et al., 2012), distinguishing between monotone, swap, and discontinuous reordering, all with respect to left-to-right and right-to-left decoding. Other features include linear distortion, bidirectional lexical weighting (Koehn et al., 2003), word and phrase penalties, and finally a word-level 5gram target LM trained on all available monolingual data with modified Kneser-Ney smoothing (Chen and Goodman, 1999). The distortion 1683 Corpus paral.train Wiki dict. mono.train WMT2012 WMT2013 Lang. EN RU EN/RU RU EN #Sent. 1.9M 508K 21.0M 3K 3K SMT system Baseline + stem/suff. BNN Base+suffLM + word BNN + stem/suf"
D14-1175,P13-2119,0,0.0251887,"en applied to several natural language processing tasks (Bengio et al., 2003; Collobert and Weston, 2008; Socher et al., 2011; Socher et al., 2012). Within statistical machine translation, they 4 Note that our suffix generation function Mσ is restricted to the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk, 2012; Zou et al., 2013; Gao et al., 2014) and minimal translation modeling (Hu et al., 2014). The recurrent neural network LMs of Auli et al. (2013) are primarily trained to predict target word sequences. However, they also experiment with an additional input layer representing source side context. Our models differ from most previous work in neural language modeling in that we predict a target translation given a source context while previous models predict the next word given a targ"
D14-1175,N13-1001,0,0.0150919,"significant improvements in word translation prediction accuracy for three morphologically rich target languages. In addition, preliminary results for integrating our approach into a largescale English-Russian statistical machine translation system show small but statistically significant improvements in translation quality. 1 Introduction The ability to make context-sensitive translation decisions is one of the major strengths of phrasebased SMT (PSMT). However, the way PSMT exploits source-language context has several limitations as pointed out, for instance, by Quirk and Menezes (2006) and Durrani et al. (2013). First, the amount of context used to translate a given input word depends on the phrase segmentation, with hypotheses resulting from different segmentations competing with one another. Another issue is that, given a phrase segmentation, each source phrase is translated independently from the others, which can be problematic especially for short phrases. As a result, the predictive translation of a source phrase does not access useful linguistic clues in the source sentence that are outside of the scope of the phrase. Lexical weighting tackles the problem of unreliable phrase probabilities, t"
D14-1175,D08-1089,0,0.0321145,"(NULL|si ) if |{ai } |> 0 otherwise where a is the word-level alignment of the phrase pair (˜ s, t˜) and {ai } is the set of target positions aligned to si . If a source-target link cannot be scored by the BNN model, we give it a PBNN probability of 1 and increment a separate count feature ε. Note that the same phrase pair can get different BNN scores if used in different source side contexts. Our baseline is an in-house phrase-based (Koehn et al., 2003) statistical machine translation system very similar to Moses (Koehn et al., 2007). All system runs use hierarchical lexicalized reordering (Galley and Manning, 2008; Cherry et al., 2012), distinguishing between monotone, swap, and discontinuous reordering, all with respect to left-to-right and right-to-left decoding. Other features include linear distortion, bidirectional lexical weighting (Koehn et al., 2003), word and phrase penalties, and finally a word-level 5gram target LM trained on all available monolingual data with modified Kneser-Ney smoothing (Chen and Goodman, 1999). The distortion 1683 Corpus paral.train Wiki dict. mono.train WMT2012 WMT2013 Lang. EN RU EN/RU RU EN #Sent. 1.9M 508K 21.0M 3K 3K SMT system Baseline + stem/suff. BNN Base+suffLM"
D14-1175,P14-1066,0,0.0291014,"thin statistical machine translation, they 4 Note that our suffix generation function Mσ is restricted to the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk, 2012; Zou et al., 2013; Gao et al., 2014) and minimal translation modeling (Hu et al., 2014). The recurrent neural network LMs of Auli et al. (2013) are primarily trained to predict target word sequences. However, they also experiment with an additional input layer representing source side context. Our models differ from most previous work in neural language modeling in that we predict a target translation given a source context while previous models predict the next word given a target word history. Unlike previous work in phrase translation modeling with NNs, our models have the advantage of accessing source context that can fall o"
D14-1175,W08-0302,0,0.248829,"oblem of unreliable phrase probabilities, typically associated with long phrases, but does not alleviate the problem of context segmentation. An important share of the translation selection task is then left to the language model (LM), which is certainly very effective but can only leverage target language context. Moreover, decisions that are taken at early decoding stages—such as the common practice of retaining only top n translation options for each source span—depend only on the translation models and on the target context available in the phrase. Source context based translation models (Gimpel and Smith, 2008; Mauser et al., 2009; Jeong et al., 2010; Haque et al., 2011) naturally address these limitations. These models can exploit a boundless context of the input text, but they assume that target words can be predicted independently from each other, which makes them easy to integrate into state-of-the-art PSMT systems. Even though the independence assumption is made on the target side, these models have shown the benefits of utilizing source context, especially in translating into morphologically rich languages. One drawback of previous research on this topic, though, is that it relied on rich set"
D14-1175,P12-1016,0,0.0442407,"coverage of SMT models The first question we ask is whether translation can be improved by a more accurate selection of the translation options already existing in the SMT models, as opposed to generating new options. To answer this question we measure the lexical coverage of a baseline PSMT system trained on English-Russian.1 We choose this language pair because of the morphological richness on the target side: Russian is characterized by a highly inflectional morphology with a particularly complex nominal declension (six core cases, three genders and two number categories). As suggested by Green and DeNero (2012), we compute the recall of reference tokens in the set of target tokens that the decoder could produce in a translation of the source, that is the target tokens of all phrase pairs that matched the input sentence 1 Training data and SMT setup are described in Section 6. and that were actually used for decoding.2 We call this the decoder’s lexical search space. Then, we compare the reference/space recall against the reference/MT-output recall: that is, the percentage of reference tokens that also appeared in the 1-best translation output by the SMT system. Results for the WMT12 benchmark are pr"
D14-1175,D11-1125,0,0.0373637,"Missing"
D14-1175,E14-1003,0,0.0151954,"at our suffix generation function Mσ is restricted to the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk, 2012; Zou et al., 2013; Gao et al., 2014) and minimal translation modeling (Hu et al., 2014). The recurrent neural network LMs of Auli et al. (2013) are primarily trained to predict target word sequences. However, they also experiment with an additional input layer representing source side context. Our models differ from most previous work in neural language modeling in that we predict a target translation given a source context while previous models predict the next word given a target word history. Unlike previous work in phrase translation modeling with NNs, our models have the advantage of accessing source context that can fall outside the phrase boundaries. We now describe our m"
D14-1175,2010.amta-papers.33,0,0.269594,"ically associated with long phrases, but does not alleviate the problem of context segmentation. An important share of the translation selection task is then left to the language model (LM), which is certainly very effective but can only leverage target language context. Moreover, decisions that are taken at early decoding stages—such as the common practice of retaining only top n translation options for each source span—depend only on the translation models and on the target context available in the phrase. Source context based translation models (Gimpel and Smith, 2008; Mauser et al., 2009; Jeong et al., 2010; Haque et al., 2011) naturally address these limitations. These models can exploit a boundless context of the input text, but they assume that target words can be predicted independently from each other, which makes them easy to integrate into state-of-the-art PSMT systems. Even though the independence assumption is made on the target side, these models have shown the benefits of utilizing source context, especially in translating into morphologically rich languages. One drawback of previous research on this topic, though, is that it relied on rich sets of manually designed features, which in"
D14-1175,D13-1176,0,0.0565001,"g row in the previous layer resulting in a weight matrix whose number of columns decreases by one. Thus after 2k convolutional layers, the network transforms the source context matrix mcsi to a feature vector q ˆ ∈ Rd . A fully connected layer with weight matrix W followed by a softmax layer are placed after the last convolutional layer L2k to perform classification. The parameters of the convolutional neural network model are θ = {rsi , mj , W}. Here, we focus on a fixed length input, however convolutional neural networks may be used to model variable length input (Kalchbrenner et al., 2014; Kalchbrenner and Blunsom, 2013). 4.3 Training In training, for each example (t, cs ), we maximize the conditional probability Pθ (t|cs ) of a correct target label t. The contribution of the training example (t, cs ) to the gradient of the log conditional probability is given by: ∂ ∂ log Pθ (t|cs ) = sθ (t|cs ) ∂θ ∂θ X ∂ − Pθ (t0 |cs ) sθ (t0 , cs ) ∂θ 0 t ∈Ts Note that in the gradient, we do not sum over all target translations T but a set of possible candidates Ts of a source word s. In practice |Ts |≤ 200 with our pruning settings (see Section 5.1), thus training time for one example does not depend on the vocabulary size"
D14-1175,P14-1062,0,0.203091,"a natural mechanism to compute word surface conditional probability p(t|cs ) given individual stem probability p(σ|cs ) and suffix probability p(µ|cs , σ), and (ii) FFNNs do not provide the flexibility to capture long dependencies among words if they lie outside the source context window. Hence, we consider two BNN variants: a log-bilinear model (LBL) and a convolutional neural network model (ConvNet). LBL could potentially address (i) by factorizing target representations into target stem and suffix representations whereas ConvNets offer the advantage of modeling variable input length (ii) (Kalchbrenner et al., 2014). Log-bilinear model. The FFNN models stem and suffix probabilities separately. A log-bilinear model instead could directly model word prediction through a factored representation of target words, similarly to Botha and Blunsom (2014). Thus, no probability mass would be wasted over stem-suffix combinations that are not in the candidate generation function. The LBL model specifies the conditional distribution for the word translation tj ∈ Tsi given a source context csi : exp(sθ (tj , csi )) Pθ (tj |csi ) = P exp(sθ (t0j , csi )) (3) t0j ∈Tsi We use an additional set of word representations qtj"
D14-1175,2012.eamt-1.6,0,0.0373511,"Missing"
D14-1175,N03-1017,0,0.00693631,"air matching the input, the phrase BNN score PBNN-p is computed as follows: PBNN-p (˜ s, t˜, a) =  X 1 |˜ s | PBNN (tj |csi )  Y |{ai }| j∈{ai }  i=1  Pmle (NULL|si ) if |{ai } |> 0 otherwise where a is the word-level alignment of the phrase pair (˜ s, t˜) and {ai } is the set of target positions aligned to si . If a source-target link cannot be scored by the BNN model, we give it a PBNN probability of 1 and increment a separate count feature ε. Note that the same phrase pair can get different BNN scores if used in different source side contexts. Our baseline is an in-house phrase-based (Koehn et al., 2003) statistical machine translation system very similar to Moses (Koehn et al., 2007). All system runs use hierarchical lexicalized reordering (Galley and Manning, 2008; Cherry et al., 2012), distinguishing between monotone, swap, and discontinuous reordering, all with respect to left-to-right and right-to-left decoding. Other features include linear distortion, bidirectional lexical weighting (Koehn et al., 2003), word and phrase penalties, and finally a word-level 5gram target LM trained on all available monolingual data with modified Kneser-Ney smoothing (Chen and Goodman, 1999). The distortio"
D14-1175,P07-2045,0,0.00446829,"(˜ s, t˜, a) =  X 1 |˜ s | PBNN (tj |csi )  Y |{ai }| j∈{ai }  i=1  Pmle (NULL|si ) if |{ai } |> 0 otherwise where a is the word-level alignment of the phrase pair (˜ s, t˜) and {ai } is the set of target positions aligned to si . If a source-target link cannot be scored by the BNN model, we give it a PBNN probability of 1 and increment a separate count feature ε. Note that the same phrase pair can get different BNN scores if used in different source side contexts. Our baseline is an in-house phrase-based (Koehn et al., 2003) statistical machine translation system very similar to Moses (Koehn et al., 2007). All system runs use hierarchical lexicalized reordering (Galley and Manning, 2008; Cherry et al., 2012), distinguishing between monotone, swap, and discontinuous reordering, all with respect to left-to-right and right-to-left decoding. Other features include linear distortion, bidirectional lexical weighting (Koehn et al., 2003), word and phrase penalties, and finally a word-level 5gram target LM trained on all available monolingual data with modified Kneser-Ney smoothing (Chen and Goodman, 1999). The distortion 1683 Corpus paral.train Wiki dict. mono.train WMT2012 WMT2013 Lang. EN RU EN/RU"
D14-1175,koen-2004-pharaoh,0,0.0681058,"logy, generation seems to be of secondary importance compared to better selection in our experimental setup. 3 Predicting word translations in context It is standard practice in PSMT to use wordto-word translation probabilities as an additional phrase score. More specifically, state-of-the-art PSMT systems employ the maximum-likelihood estimate of the context-independent probability of a target word given its aligned source word P (tj |si ) for each word alignment link aij . 2 This corresponds to the top 30 phrases sorted by weighted phrase, lexical and LM probabilities, for each source span. Koehn (2004) and our own experience suggest that using more phrases has little or no impact on MT quality. 3 Word segmentation for this analysis is performed by the Russian Snowball stemmer, see also Section 5.3. 1677 1. predict target stem σ given source context cs ; [конституционность] [индиана закон] [.] 2. predict target suffix µ given source context cs and target stem σ. [the constitutionality of the] [indiana law] [.] Figure 1: Fragment of English sentence and its incorrect Russian translation produced by the baseline SMT system. Square brackets indicate phrase boundaries. The main goal of our work"
D14-1175,W11-0301,0,0.0699695,"Missing"
D14-1175,D09-1022,0,0.120957,"Missing"
D14-1175,P07-1017,0,0.0742988,"his paper, we specifically focus on improving the prediction accuracy for word translations. Achieving high levels of word translation accuracy is particularly challenging for language 1676 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1676–1688, c October 25-29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics pairs where the source language is morphologically poor, such as English, and the target language is morphologically rich, such as Russian, i.e., language pairs with a high degree of surface realization ambiguity (Minkov et al., 2007). To address this problem we propose a general approach based on bilingual neural networks (BNN) exploiting source-side contextual information. This paper makes a number of contributions: Unlike previous approaches our models do not require any form of linguistic annotation (Minkov et al., 2007; Kholy and Habash, 2012; Chahuneau et al., 2013), nor do they require any feature engineering (Gimpel and Smith, 2008). Moreover, besides directly predicting fully inflected forms as Jeong et al. (2010), our approach can also model stem and suffix prediction explicitly. Prediction accuracy is evaluated"
D14-1175,N12-1043,0,0.064525,"Missing"
D14-1175,N06-1002,0,0.0284164,"ature engineering. We report significant improvements in word translation prediction accuracy for three morphologically rich target languages. In addition, preliminary results for integrating our approach into a largescale English-Russian statistical machine translation system show small but statistically significant improvements in translation quality. 1 Introduction The ability to make context-sensitive translation decisions is one of the major strengths of phrasebased SMT (PSMT). However, the way PSMT exploits source-language context has several limitations as pointed out, for instance, by Quirk and Menezes (2006) and Durrani et al. (2013). First, the amount of context used to translate a given input word depends on the phrase segmentation, with hypotheses resulting from different segmentations competing with one another. Another issue is that, given a phrase segmentation, each source phrase is translated independently from the others, which can be problematic especially for short phrases. As a result, the predictive translation of a source phrase does not access useful linguistic clues in the source sentence that are outside of the scope of the phrase. Lexical weighting tackles the problem of unreliab"
D14-1175,W05-0908,0,0.0753458,"Missing"
D14-1175,P06-2093,0,0.031168,"ion over the last few years and have been applied to several natural language processing tasks (Bengio et al., 2003; Collobert and Weston, 2008; Socher et al., 2011; Socher et al., 2012). Within statistical machine translation, they 4 Note that our suffix generation function Mσ is restricted to the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk, 2012; Zou et al., 2013; Gao et al., 2014) and minimal translation modeling (Hu et al., 2014). The recurrent neural network LMs of Auli et al. (2013) are primarily trained to predict target word sequences. However, they also experiment with an additional input layer representing source side context. Our models differ from most previous work in neural language modeling in that we predict a target translation given a source context while previous models"
D14-1175,C12-2104,0,0.0229426,"., 2011; Socher et al., 2012). Within statistical machine translation, they 4 Note that our suffix generation function Mσ is restricted to the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk, 2012; Zou et al., 2013; Gao et al., 2014) and minimal translation modeling (Hu et al., 2014). The recurrent neural network LMs of Auli et al. (2013) are primarily trained to predict target word sequences. However, they also experiment with an additional input layer representing source side context. Our models differ from most previous work in neural language modeling in that we predict a target translation given a source context while previous models predict the next word given a target word history. Unlike previous work in phrase translation modeling with NNs, our models have the advantage of acc"
D14-1175,sharoff-etal-2008-designing,0,0.0917098,"Missing"
D14-1175,P05-1044,0,0.018985,"ditional probability Pθ (t|cs ) of a correct target label t. The contribution of the training example (t, cs ) to the gradient of the log conditional probability is given by: ∂ ∂ log Pθ (t|cs ) = sθ (t|cs ) ∂θ ∂θ X ∂ − Pθ (t0 |cs ) sθ (t0 , cs ) ∂θ 0 t ∈Ts Note that in the gradient, we do not sum over all target translations T but a set of possible candidates Ts of a source word s. In practice |Ts |≤ 200 with our pruning settings (see Section 5.1), thus training time for one example does not depend on the vocabulary size. Our training criterion can be seen as a form of contrastive estimation (Smith and Eisner, 2005), however we explicitly move the probability mass from competing candidates to the correct translation candidate, thus obtaining more reliable estimates of the conditional probabilities. The BNN parameters are initialized randomly according to a zero-mean Gaussian. We regularize the models with L2 . As an alternative to the L2 regularizer, we also experiment with dropout (Hinton et al., 2012), where the neurons are randomly zeroed out with dropout rate p. This technique is known to be useful in computer vision tasks but has been rarely used in NLP tasks. In FFNN, we use dropout after the hidde"
D14-1175,D11-1014,0,0.0704887,"nt for each of the modeled tasks, directly from word-aligned data. To make the approach completely language independent, the word segmentation function g can be trained with an unsupervised segmentation tool. The effects of using different word segmentation techniques are discussed in Section 5. 4 Bilingual neural networks for translation prediction Probabilistic neural network (NN), or continuous space, language models have received increasing attention over the last few years and have been applied to several natural language processing tasks (Bengio et al., 2003; Collobert and Weston, 2008; Socher et al., 2011; Socher et al., 2012). Within statistical machine translation, they 4 Note that our suffix generation function Mσ is restricted to the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk"
D14-1175,D12-1110,0,0.0428411,"deled tasks, directly from word-aligned data. To make the approach completely language independent, the word segmentation function g can be trained with an unsupervised segmentation tool. The effects of using different word segmentation techniques are discussed in Section 5. 4 Bilingual neural networks for translation prediction Probabilistic neural network (NN), or continuous space, language models have received increasing attention over the last few years and have been applied to several natural language processing tasks (Bengio et al., 2003; Collobert and Weston, 2008; Socher et al., 2011; Socher et al., 2012). Within statistical machine translation, they 4 Note that our suffix generation function Mσ is restricted to the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk, 2012; Zou et al., 20"
D14-1175,N12-1005,0,0.0302915,", 2003; Collobert and Weston, 2008; Socher et al., 2011; Socher et al., 2012). Within statistical machine translation, they 4 Note that our suffix generation function Mσ is restricted to the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk, 2012; Zou et al., 2013; Gao et al., 2014) and minimal translation modeling (Hu et al., 2014). The recurrent neural network LMs of Auli et al. (2013) are primarily trained to predict target word sequences. However, they also experiment with an additional input layer representing source side context. Our models differ from most previous work in neural language modeling in that we predict a target translation given a source context while previous models predict the next word given a target word history. Unlike previous work in phrase translation modeling wi"
D14-1175,W07-1709,0,0.0695006,"Missing"
D14-1175,P08-1059,0,0.187605,"rget words Ts = {t1 , . . . , tm } that were aligned to si in the parallel training corpus, which in turn corresponds to the set of target words that the SMT system can produce for a given source. In practice, we use a pruned version of Ts to speed up training and reduce noise (see details in Section 5). As for the morphological models, given Ts and g, we can obtain Ls = {σ1 , . . . , σk }, the set of possible target stem translations of s, and Mσ = {µ1 , . . . , µl }, the set of possible suffixes for a target stem σ. The use of Ls , and Mσ is similar to stemming and inflection operations in (Toutanova et al., 2008) while the set Ts is similar to the GEN function in (Jeong et al., 2010).4 Our approach differs crucially from previous work (Minkov et al., 2007; Chahuneau et al., 2013) in that it does not require linguistic features such as part-of-speech and syntactic tree on the source side. The proposed models automatically learn features that are relevant for each of the modeled tasks, directly from word-aligned data. To make the approach completely language independent, the word segmentation function g can be trained with an unsupervised segmentation tool. The effects of using different word segmentati"
D14-1175,D13-1140,0,0.0351327,"ral natural language processing tasks (Bengio et al., 2003; Collobert and Weston, 2008; Socher et al., 2011; Socher et al., 2012). Within statistical machine translation, they 4 Note that our suffix generation function Mσ is restricted to the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk, 2012; Zou et al., 2013; Gao et al., 2014) and minimal translation modeling (Hu et al., 2014). The recurrent neural network LMs of Auli et al. (2013) are primarily trained to predict target word sequences. However, they also experiment with an additional input layer representing source side context. Our models differ from most previous work in neural language modeling in that we predict a target translation given a source context while previous models predict the next word given a target word history. Unlike"
D14-1175,D13-1141,0,0.0350035,"et al., 2012). Within statistical machine translation, they 4 Note that our suffix generation function Mσ is restricted to the forms observed in the target monolingual data, but not to those aligned to a source word s, which opens the possibility of generating inflected forms that are missing from the translation models. We leave this possibility to future work. 1678 have been used for monolingual target language modeling (Schwenk et al., 2006; Le et al., 2011; Duh et al., 2013; Vaswani et al., 2013), n-gram translation modeling (Son et al., 2012), phrase translation modeling (Schwenk, 2012; Zou et al., 2013; Gao et al., 2014) and minimal translation modeling (Hu et al., 2014). The recurrent neural network LMs of Auli et al. (2013) are primarily trained to predict target word sequences. However, they also experiment with an additional input layer representing source side context. Our models differ from most previous work in neural language modeling in that we predict a target translation given a source context while previous models predict the next word given a target word history. Unlike previous work in phrase translation modeling with NNs, our models have the advantage of accessing source cont"
D14-1175,bojar-etal-2012-joy,0,\N,Missing
D14-1175,W13-2201,1,\N,Missing
D16-1025,W13-2257,1,0.870008,"Missing"
D16-1025,P11-1059,0,0.0237569,"Missing"
D16-1025,2012.eamt-1.60,1,0.116875,"not applicable to NMT, which does not rely on a fixed inventory of translation units extracted from the parallel data. Previous error analyses based on manually postedited translations were presented in (Bojar, 2011; Koponen, 2012; Popovi´c et al., 2013). We are the first to conduct this kind of study on the output of a neural MT system. 3 Experimental Setting We perform a number of analyses on data and results of the IWSLT 2015 MT En-De task, which consists in translating manual transcripts of English TED talks into German. Evaluation data are publicly available through the WIT3 repository (Cettolo et al., 2012).3 3.1 Task Data TED Talks4 are a collection of rather short speeches (max 18 minutes each, roughly equivalent to 2,500 words) covering a wide variety of topics. All talks have captions, which are translated into many languages by volunteers worldwide. Besides representing a popular benchmark for spoken language technology, TED Talks embed interesting research challenges. Translating TED Talks implies dealing with spoken rather than written language, which is hence expected to be structurally less complex, formal and fluent (Ruiz and Federico, 2014). Moreover, as human translations of the talk"
D16-1025,W14-4012,0,0.0937737,"Missing"
D16-1025,D14-1179,0,0.0584623,"Missing"
D16-1025,daems-etal-2014-origin,0,0.0125712,"aspects are better modeled by different MT frameworks. To this end, a detailed and systematic error analysis of NMT vs. PBMT output is required. Translation error analysis, as a way to identify systems’ weaknesses and define priorities for their improvement, has received a fair amount of attention in the MT community. In this work we opt for the automatic detection and classification of translation errors based on manual post-edits of the MT output. We believe this choice provides an optimal trade-off between fully manual error analysis (Farr´us Cabeceran et al., 2010; Popovi´c et al., 2013; Daems et al., 2014; Federico et al., 2014; Neubig et al., 2015), which is very costly and complex, and fully automatic error analysis (Popovi´c and Ney, 2011; Irvine et al., 2013), which is noisy and biased towards one or few arbitrary reference translations. Existing tools for translation error detection are either based on Word Error Rate (WER) and Position-independent word Error Rate (PER) (Popovi´c, 2011) or on output-reference alignment (Zeman et al., 2011). Regarding error classification, Hjerson (Popovi´c, 2011) detects five main types of word-level errors as defined in (Vilar et al., 2006): morphologica"
D16-1025,N13-1073,0,0.0838252,"Missing"
D16-1025,D14-1172,1,0.84939,"modeled by different MT frameworks. To this end, a detailed and systematic error analysis of NMT vs. PBMT output is required. Translation error analysis, as a way to identify systems’ weaknesses and define priorities for their improvement, has received a fair amount of attention in the MT community. In this work we opt for the automatic detection and classification of translation errors based on manual post-edits of the MT output. We believe this choice provides an optimal trade-off between fully manual error analysis (Farr´us Cabeceran et al., 2010; Popovi´c et al., 2013; Daems et al., 2014; Federico et al., 2014; Neubig et al., 2015), which is very costly and complex, and fully automatic error analysis (Popovi´c and Ney, 2011; Irvine et al., 2013), which is noisy and biased towards one or few arbitrary reference translations. Existing tools for translation error detection are either based on Word Error Rate (WER) and Position-independent word Error Rate (PER) (Popovi´c, 2011) or on output-reference alignment (Zeman et al., 2011). Regarding error classification, Hjerson (Popovi´c, 2011) detects five main types of word-level errors as defined in (Vilar et al., 2006): morphological, reordering, missing"
D16-1025,fishel-etal-2012-terra,0,0.038989,"Missing"
D16-1025,1994.amta-1.9,0,0.196451,"s vocabulary and the variety of subject matter in a text. For the first two features we did not find any correlation; on the contrary, we found a moderate Pearson correlation (R=0.7332) between TTR and the mTER gains of NMT over its closest competitor in each talk. This result suggests that NMT is able to cope with lexical diversity better than any other considered approach. 5 Analysis of Translation Errors We now turn to analyze which types of linguistic errors characterize NMT vs. PBMT. In the literature, various error taxonomies covering different levels of granularity have been developed (Flanagan, 1994; Vilar et al., 2006; Farr´us Cabeceran et al., 2010; Stymne and Ahrenberg, 2012; Lommel et al., 2014). We focus on three error categories, namely (i) morphology errors, (ii) lexical errors, and (iii) word order errors. As for lexical errors, a number of existing taxonomies further distinguish among translation errors due to missing words, extra words, or incorrect lexical choice. However, given the proven difficulty of disambiguating between these three subclasses (Popovi´c and Ney, 2011; Fishel et al., 2012), we prefer to rely on a more coarse-grained linguistic error classification where le"
D16-1025,D12-1043,0,0.0167871,"Missing"
D16-1025,2015.iwslt-evaluation.9,0,0.093503,"Missing"
D16-1025,2015.iwslt-evaluation.4,0,0.120054,"rephrasing and reordering is expected than in the translation of written documents. As regards the English-German language pair, the two languages are interesting since, while belonging to the same language family, they have marked differences in levels of inflection, morphological variation, and word order, especially long-range reordering of verbs. 3.2 Evaluation Data Five systems participated in the MT En-De task and were manually evaluated on a representative subset of the official 2015 test set. The Human Evaluation (HE) set includes the first half of each of the 12 test 3 4 System PBSY (Huck and Birch, 2015) HPB (Jehl et al., 2015) SPB (Ha et al., 2015) NMT (Luong & Manning, 2015) Data 175M/ 3.1B 166M/ 854M 117M/ 2.4B 120M/ – Table 1: MT systems’ overview. Data column: size of parallel/monolingual training data for each system in terms of English and German tokens. talks, for a total of 600 sentences and around 10K words. Five professional translators were asked to post-edit the MT output by applying the minimal edits required to transform it into a fluent sentence with the same meaning as the source sentence. Data were prepared so that all translators equally post-edited the five MT outputs, i.e"
D16-1025,Q13-1035,0,0.0418296,"Missing"
D16-1025,P15-1001,0,0.0782404,"tationally costly and resource demanding to compete with state-of-the-art Phrase-Based MT (PBMT)1 , the situation changed in 2015. For the first time, in the latest edition of IWSLT2 (Cettolo et 1 We use the generic term phrase-based MT to cover standard phrase-based, hierarchical and syntax-based SMT approaches. 2 International Workshop on Spoken Language Translation (http://workshop2015.iwslt.org/) This impressive improvement follows the distance reduction previously observed in the WMT 2015 shared translation task (Bojar et al., 2015). Just few months earlier, the NMT systems described in (Jean et al., 2015b) ranked on par with the best phrase-based models on a couple of language pairs. Such rapid progress stems from the improvement of the recurrent neural network encoderdecoder model, originally proposed in (Sutskever et al., 2014; Cho et al., 2014b), with the use of the attention mechanism (Bahdanau et al., 2015). This evolution has several implications. On one side, NMT represents a simplification with respect to previous paradigms. From a management point of view, similar to PBMT, it allows for a more efficient use of human and data resources with respect to rulebased MT. From the architectu"
D16-1025,W15-3014,0,0.0509369,"tationally costly and resource demanding to compete with state-of-the-art Phrase-Based MT (PBMT)1 , the situation changed in 2015. For the first time, in the latest edition of IWSLT2 (Cettolo et 1 We use the generic term phrase-based MT to cover standard phrase-based, hierarchical and syntax-based SMT approaches. 2 International Workshop on Spoken Language Translation (http://workshop2015.iwslt.org/) This impressive improvement follows the distance reduction previously observed in the WMT 2015 shared translation task (Bojar et al., 2015). Just few months earlier, the NMT systems described in (Jean et al., 2015b) ranked on par with the best phrase-based models on a couple of language pairs. Such rapid progress stems from the improvement of the recurrent neural network encoderdecoder model, originally proposed in (Sutskever et al., 2014; Cho et al., 2014b), with the use of the attention mechanism (Bahdanau et al., 2015). This evolution has several implications. On one side, NMT represents a simplification with respect to previous paradigms. From a management point of view, similar to PBMT, it allows for a more efficient use of human and data resources with respect to rulebased MT. From the architectu"
D16-1025,2015.iwslt-evaluation.6,0,0.129399,"s expected than in the translation of written documents. As regards the English-German language pair, the two languages are interesting since, while belonging to the same language family, they have marked differences in levels of inflection, morphological variation, and word order, especially long-range reordering of verbs. 3.2 Evaluation Data Five systems participated in the MT En-De task and were manually evaluated on a representative subset of the official 2015 test set. The Human Evaluation (HE) set includes the first half of each of the 12 test 3 4 System PBSY (Huck and Birch, 2015) HPB (Jehl et al., 2015) SPB (Ha et al., 2015) NMT (Luong & Manning, 2015) Data 175M/ 3.1B 166M/ 854M 117M/ 2.4B 120M/ – Table 1: MT systems’ overview. Data column: size of parallel/monolingual training data for each system in terms of English and German tokens. talks, for a total of 600 sentences and around 10K words. Five professional translators were asked to post-edit the MT output by applying the minimal edits required to transform it into a fluent sentence with the same meaning as the source sentence. Data were prepared so that all translators equally post-edited the five MT outputs, i.e. 120 sentences for each"
D16-1025,W12-3123,0,0.0131782,"(see also Section 3.4). Irvine et al. (2013) propose another word-level error analysis technique specifically focused on lexical choice and aimed at understanding the effects of domain differences on MT. Their error classification is strictly related to model coverage and insensitive to word order differences. The technique requires access to the system’s phrase table and is thus not applicable to NMT, which does not rely on a fixed inventory of translation units extracted from the parallel data. Previous error analyses based on manually postedited translations were presented in (Bojar, 2011; Koponen, 2012; Popovi´c et al., 2013). We are the first to conduct this kind of study on the output of a neural MT system. 3 Experimental Setting We perform a number of analyses on data and results of the IWSLT 2015 MT En-De task, which consists in translating manual transcripts of English TED talks into German. Evaluation data are publicly available through the WIT3 repository (Cettolo et al., 2012).3 3.1 Task Data TED Talks4 are a collection of rather short speeches (max 18 minutes each, roughly equivalent to 2,500 words) covering a wide variety of topics. All talks have captions, which are translated in"
D16-1025,2014.eamt-1.38,0,0.0817661,"Missing"
D16-1025,2015.iwslt-evaluation.11,0,0.0570707,"e. 120 sentences for each evaluated system. The resulting evaluation data consist of five new reference translations for each of the sentences in the HE set. Each one of these references represents the targeted translation of the system output from which it was derived, but the other four additional translations can also be used to evaluate each MT system. We will see in the next sections how we exploited the available post-edits in the more suitable way depending on the kind of analysis carried out. 3.3 MT Systems Our analysis focuses on the first four top-ranking systems, which include NMT (Luong and Manning, 2015) and three different phrase-based approaches: standard phrase-based (Ha et al., 2015), hierarchical (Jehl et al., 2015) and a combination of phrasebased and syntax-based (Huck and Birch, 2015). Table 1 presents an overview of each system, as well as figures about the training data used.5 The phrase+syntax-based (PBSY) system combines the outputs of a string-to-tree decoder, trained with the GHKM algorithm, with those of two stan5 wit3.fbk.eu http://www.ted.com/ Approach Combination: Phrase+Syntax-based GHKM string-to-tree; hierarchical + sparse lexicalized reordering models Hierarchical Phrase"
D16-1025,D15-1166,0,0.088644,"nvestigate how MT systems’ quality varies with specific characteristics of the input, i.e. sentence length and type of content of each talk (Section 4). Then, we focus on differences among MT systems with respect to morphology, lexical, and word order errors (Section 5). Finally, based on the finding that word reordering is the strongest aspect of NMT compared to the other systems, we carry out a finegrained analysis of word order errors (Section 6). 2 Previous Work To date, NMT systems have only been evaluated by BLEU in single-reference setups (Bahdanau et al., 2015; Sutskever et al., 2014; Luong et al., 2015; Jean et al., 2015a; G¨ulc¸ehre et al., 2015). Ad258 ditionally, the Montreal NMT system submitted to WMT 2015 (Jean et al., 2015b) was part of a manual evaluation experiment where a large number of non-professional annotators were asked to rank the outputs of multiple MT systems (Bojar et al., 2015). Results for the Montreal system were very positive – ranked first in English-German, third in GermanEnglish, English-Czech and Czech-English – which confirmed and strengthened the BLEU results published so far. Unfortunately neither BLEU nor manual ranking judgements tell us which translation as"
D16-1025,W15-5003,0,0.016732,"frameworks. To this end, a detailed and systematic error analysis of NMT vs. PBMT output is required. Translation error analysis, as a way to identify systems’ weaknesses and define priorities for their improvement, has received a fair amount of attention in the MT community. In this work we opt for the automatic detection and classification of translation errors based on manual post-edits of the MT output. We believe this choice provides an optimal trade-off between fully manual error analysis (Farr´us Cabeceran et al., 2010; Popovi´c et al., 2013; Daems et al., 2014; Federico et al., 2014; Neubig et al., 2015), which is very costly and complex, and fully automatic error analysis (Popovi´c and Ney, 2011; Irvine et al., 2013), which is noisy and biased towards one or few arbitrary reference translations. Existing tools for translation error detection are either based on Word Error Rate (WER) and Position-independent word Error Rate (PER) (Popovi´c, 2011) or on output-reference alignment (Zeman et al., 2011). Regarding error classification, Hjerson (Popovi´c, 2011) detects five main types of word-level errors as defined in (Vilar et al., 2006): morphological, reordering, missing words, extra words, an"
D16-1025,J11-4002,0,0.200619,"Missing"
D16-1025,2013.mtsummit-posters.5,0,0.0498368,"Missing"
D16-1025,W14-4009,0,0.0473704,"Missing"
D16-1025,2014.eamt-1.39,1,0.718619,"publicly available through the WIT3 repository (Cettolo et al., 2012).3 3.1 Task Data TED Talks4 are a collection of rather short speeches (max 18 minutes each, roughly equivalent to 2,500 words) covering a wide variety of topics. All talks have captions, which are translated into many languages by volunteers worldwide. Besides representing a popular benchmark for spoken language technology, TED Talks embed interesting research challenges. Translating TED Talks implies dealing with spoken rather than written language, which is hence expected to be structurally less complex, formal and fluent (Ruiz and Federico, 2014). Moreover, as human translations of the talks are required to follow the structure and rhythm of the English captions, a lower amount of rephrasing and reordering is expected than in the translation of written documents. As regards the English-German language pair, the two languages are interesting since, while belonging to the same language family, they have marked differences in levels of inflection, morphological variation, and word order, especially long-range reordering of verbs. 3.2 Evaluation Data Five systems participated in the MT En-De task and were manually evaluated on a represent"
D16-1025,stymne-ahrenberg-2012-practice,0,0.0488173,"rst two features we did not find any correlation; on the contrary, we found a moderate Pearson correlation (R=0.7332) between TTR and the mTER gains of NMT over its closest competitor in each talk. This result suggests that NMT is able to cope with lexical diversity better than any other considered approach. 5 Analysis of Translation Errors We now turn to analyze which types of linguistic errors characterize NMT vs. PBMT. In the literature, various error taxonomies covering different levels of granularity have been developed (Flanagan, 1994; Vilar et al., 2006; Farr´us Cabeceran et al., 2010; Stymne and Ahrenberg, 2012; Lommel et al., 2014). We focus on three error categories, namely (i) morphology errors, (ii) lexical errors, and (iii) word order errors. As for lexical errors, a number of existing taxonomies further distinguish among translation errors due to missing words, extra words, or incorrect lexical choice. However, given the proven difficulty of disambiguating between these three subclasses (Popovi´c and Ney, 2011; Fishel et al., 2012), we prefer to rely on a more coarse-grained linguistic error classification where lexical errors include all of them (Farr´us Cabeceran et al., 2010). 6 The type-to"
D16-1025,vilar-etal-2006-error,0,0.431417,"Missing"
D16-1025,2010.iwslt-evaluation.11,0,\N,Missing
D16-1025,W15-3001,0,\N,Missing
D16-1025,R13-1079,0,\N,Missing
D16-1025,2015.iwslt-evaluation.1,1,\N,Missing
D17-1147,D11-1033,0,0.772776,"time-consuming task, with training times of several weeks not being unusual. Despite its training inefficiency, most work in NMT greedily uses all available training data for a given language pair. However, it is unlikely ∗ Work done while at University of Amsterdam Christof Monz Informatics Institute University of Amsterdam that all data is equally helpful to create the bestperforming system. In PBMT, this issue has been addressed by applying intelligent data selection, and it has consistently been shown that using more data does not always improve translation quality (Moore and Lewis, 2010; Axelrod et al., 2011; Gasc´o et al., 2012). Instead, for a given translation task, the training bitext likely contains sentences that are irrelevant or even harmful, making it beneficial to keep only the most relevant subset of the data while discarding the rest, with the additional benefit of smaller models and faster training. Motivated by the success of data selection in PBMT, we investigate in this paper to what extent and how NMT can benefit from data selection as well. While data selection has been applied to NMT to reduce the size of the data (Cho et al., 2014; Luong et al., 2015b), the effects on translat"
D17-1147,W15-3003,0,0.0331958,"Missing"
D17-1147,D16-1025,1,0.852981,"parallelizing models or data (Wu et al., 2016), modifying the NMT network structure (Kalchbrenner et al., 2016), decreasing the number of parameters through knowledge distillation (Crego et al., 2016; Kim and Rush, 2016), or by boosting parts of the data that are ‘challenging’ to the NMT system (Zhang et al., 2016). The latter is most related to our work since training data is also adjusted during training, however we reduce the training data size much more aggressively and study different techniques of data selection. Finally, recent work comparing various aspects for PBMT and NMT includes (Bentivogli et al., 2016; Farajian et al., 2017; Toral and S´anchezCartagena, 2017; Koehn and Knowles, 2017). 8 Conclusions With the recent increase in popularity of neural machine translation (NMT), we explored in this paper to what extent and how NMT can benefit from data selection. We first showed that a stateof-the-art data selection method yields unreliable results for NMT while consistently performing well for PBMT. Next, we have introduced dynamic data selection for NMT, which entails varying the selected subset of training data between different training epochs. We explored two techniques of dynamic data sele"
D17-1147,2012.eamt-1.60,0,0.0605642,"okens Lines Tokens EMEA 206K 3.3M Movies 101K 1.2M TED 189K 3.3M WMT 3.8M 84M 3.9K 4.5K 2.5K 3.0K 59K 54K 50K 64K 5.8K 7.1K 5.4K 3.0K 93K 87K 99K 65K Mix 3.5K 61K – – 4.3M 92M Table 1: Data specifications with tokens counted on the German side. The WMT training corpus contains Commoncrawl, Europarl, and News Commentary but no in-domain news data. 4.2 Training and evaluation data We evaluate all experiments on four domains: (i) EMEA medical guidelines (Tiedemann, 2009), (ii) movie dialogues (van der Wees et al., 2016) constructed from OpenSubtitles (Lison and Tiedemann, 2016), (iii) TED talks (Cettolo et al., 2012), and (iv) WMT news. For TED, we use IWSLT2010 as development set and IWSLT20112014 as test set, and for WMT we use newstest2013 as development set and newstest2016 as test set. We train our systems on a mixture of domains, comprising Commoncrawl, Europarl, News Commentary, EMEA, Movies, and TED. Corpus specifications are listed in Table 1. The in-domain LMs used to rank training sentences for data selection are trained on small portions of in-domain parallel data whenever available (3.3M, 1.2M and 3.3M German tokens for EMEA, Movies and TED, respectively). Since no sizeable in-domain parallel"
D17-1147,K16-1031,0,0.107622,"domains. Data selection methods for domain adaptation mostly employ information theory metrics to rank training sentences by their relevance to the domain at hand. This has been applied monolingually (Gao et al., 2002) as well as bilingually (Yasuda et al., 2008). In more recent work, training sentences are typically ranked according to their cross-entropy difference between in-domain and general-domain data (Moore and Lewis, 2010; Axelrod et al., 2011, 2015), favoring sentences that are similar to the test domain and at the same time dissimilar from the general domain. Duh et al. (2013) and Chen and Huang (2016) present similar methods in which n-gram LMs are replaced by neural LMs or neural classifiers, respectively. Data selection with the aim of model size and training time reduction has the objective to use the minimum amount of data while still maintaining high vocabulary coverage (Eck et al., 2005; Gasc´o et al., 2012; Lewis and Eetemadi, 2013). In a comparative study, Mirkin and Besacier (2014) find that similarity-objected methods perform best if the test domain and general corpus are very different, while a coverage-objected method is superior if test and general corpus are relatively simila"
D17-1147,P17-2061,0,0.0838773,"15). While in this work we have used a similarity objective to rank our bitext, one could also apply dynamic data selection using a coverage objective. In NMT, data selection can serve similar goals as in PBMT; increasing training efficiency or domain adaptation. Domain adaptation in NMT typically involves training a model on the complete bitext, followed by fine-tuning the parameters on a smaller in-domain corpus (Luong and Manning, 2015; Zoph et al., 2016). Other work combines fine-tuning with model ensembles (Freitag and AlOnaizan, 2016) or with domain-specific tags in the training corpus (Chu et al., 2017). Finally, Sennrich et al. (2016a) adapt their systems by backtranslating in-domain data, which is then added to the training data and used for fine-tuning. Some other previous work has addressed training efficiency for NMT, for example by parallelizing models or data (Wu et al., 2016), modifying the NMT network structure (Kalchbrenner et al., 2016), decreasing the number of parameters through knowledge distillation (Crego et al., 2016; Kim and Rush, 2016), or by boosting parts of the data that are ‘challenging’ to the NMT system (Zhang et al., 2016). The latter is most related to our work sin"
D17-1147,1981.tc-1.3,0,0.59213,"Missing"
D17-1147,P13-2119,0,0.116555,"es, or to adapt to new domains. Data selection methods for domain adaptation mostly employ information theory metrics to rank training sentences by their relevance to the domain at hand. This has been applied monolingually (Gao et al., 2002) as well as bilingually (Yasuda et al., 2008). In more recent work, training sentences are typically ranked according to their cross-entropy difference between in-domain and general-domain data (Moore and Lewis, 2010; Axelrod et al., 2011, 2015), favoring sentences that are similar to the test domain and at the same time dissimilar from the general domain. Duh et al. (2013) and Chen and Huang (2016) present similar methods in which n-gram LMs are replaced by neural LMs or neural classifiers, respectively. Data selection with the aim of model size and training time reduction has the objective to use the minimum amount of data while still maintaining high vocabulary coverage (Eck et al., 2005; Gasc´o et al., 2012; Lewis and Eetemadi, 2013). In a comparative study, Mirkin and Besacier (2014) find that similarity-objected methods perform best if the test domain and general corpus are very different, while a coverage-objected method is superior if test and general co"
D17-1147,2005.iwslt-1.7,0,0.110622,"Missing"
D17-1147,P17-2090,1,0.867279,"est, with the additional benefit of smaller models and faster training. Motivated by the success of data selection in PBMT, we investigate in this paper to what extent and how NMT can benefit from data selection as well. While data selection has been applied to NMT to reduce the size of the data (Cho et al., 2014; Luong et al., 2015b), the effects on translation quality have not been investigated. Intuitively, and confirmed by our exploratory experiments in Section 5.1, this is a challenging task; NMT systems are known to under-perform when trained on limited parallel data (Zoph et al., 2016; Fadaee et al., 2017), and do not have a separate large-scale target-side language model to compensate for smaller parallel training data. To alleviate the negative effect of small training data on NMT, we introduce dynamic data selection. Following conventional data selection, we still dramatically reduce the training data size, favoring parts of the data which are most relevant to the translation task at hand. However, we exploit the fact that the NMT training process iterates over the training corpus in multiple epochs, and we alter the quantity or the composition of the training data between epochs. The propos"
D17-1147,E17-2045,0,0.083002,"data (Wu et al., 2016), modifying the NMT network structure (Kalchbrenner et al., 2016), decreasing the number of parameters through knowledge distillation (Crego et al., 2016; Kim and Rush, 2016), or by boosting parts of the data that are ‘challenging’ to the NMT system (Zhang et al., 2016). The latter is most related to our work since training data is also adjusted during training, however we reduce the training data size much more aggressively and study different techniques of data selection. Finally, recent work comparing various aspects for PBMT and NMT includes (Bentivogli et al., 2016; Farajian et al., 2017; Toral and S´anchezCartagena, 2017; Koehn and Knowles, 2017). 8 Conclusions With the recent increase in popularity of neural machine translation (NMT), we explored in this paper to what extent and how NMT can benefit from data selection. We first showed that a stateof-the-art data selection method yields unreliable results for NMT while consistently performing well for PBMT. Next, we have introduced dynamic data selection for NMT, which entails varying the selected subset of training data between different training epochs. We explored two techniques of dynamic data selection and found that ou"
D17-1147,E12-1016,0,0.0954133,"Missing"
D17-1147,D11-1125,0,0.0823035,"actual selection contains the top n sentences pairs of G. 4 Experimental settings We evaluate static and dynamic data selection on a German→English translation task comprising four test sets. Below we describe the MT systems and data specifications. 4.1 Machine translation systems While the main aim of this paper is to improve data selection for NMT, we also perform comparative experiments using PBMT. Our PBMT system is an in-house system similar to Moses (Koehn et al., 2007). To create optimal PBMT systems given the available resources, we apply test-set-specific parameter tuning using PRO (Hopkins and May, 2011). In addition, we use a linearly interpolated target-side language model trained with KneserNey smoothing on 480M tokens of data in various domains. LM interpolation weights are also optimized per test set. Consistent with Axelrod et al. (2011), we do not vary the target-side LM between different experiments on the same test set. All ngram models in our work are 5-gram. For our NMT experiments we use an in-house encoder-decoder3 model with global attention as described in Luong et al. (2015a). This choice comes at the cost of optimal translation quality but allows for a relatively fast realiza"
D17-1147,D16-1139,0,0.0569009,"016). Other work combines fine-tuning with model ensembles (Freitag and AlOnaizan, 2016) or with domain-specific tags in the training corpus (Chu et al., 2017). Finally, Sennrich et al. (2016a) adapt their systems by backtranslating in-domain data, which is then added to the training data and used for fine-tuning. Some other previous work has addressed training efficiency for NMT, for example by parallelizing models or data (Wu et al., 2016), modifying the NMT network structure (Kalchbrenner et al., 2016), decreasing the number of parameters through knowledge distillation (Crego et al., 2016; Kim and Rush, 2016), or by boosting parts of the data that are ‘challenging’ to the NMT system (Zhang et al., 2016). The latter is most related to our work since training data is also adjusted during training, however we reduce the training data size much more aggressively and study different techniques of data selection. Finally, recent work comparing various aspects for PBMT and NMT includes (Bentivogli et al., 2016; Farajian et al., 2017; Toral and S´anchezCartagena, 2017; Koehn and Knowles, 2017). 8 Conclusions With the recent increase in popularity of neural machine translation (NMT), we explored in this pa"
D17-1147,W17-3204,0,0.0675471,"e (Kalchbrenner et al., 2016), decreasing the number of parameters through knowledge distillation (Crego et al., 2016; Kim and Rush, 2016), or by boosting parts of the data that are ‘challenging’ to the NMT system (Zhang et al., 2016). The latter is most related to our work since training data is also adjusted during training, however we reduce the training data size much more aggressively and study different techniques of data selection. Finally, recent work comparing various aspects for PBMT and NMT includes (Bentivogli et al., 2016; Farajian et al., 2017; Toral and S´anchezCartagena, 2017; Koehn and Knowles, 2017). 8 Conclusions With the recent increase in popularity of neural machine translation (NMT), we explored in this paper to what extent and how NMT can benefit from data selection. We first showed that a stateof-the-art data selection method yields unreliable results for NMT while consistently performing well for PBMT. Next, we have introduced dynamic data selection for NMT, which entails varying the selected subset of training data between different training epochs. We explored two techniques of dynamic data selection and found that our gradual fine-tuning technique, in which we gradually reduce"
D17-1147,W13-2235,0,0.0477883,"uation (2). Given this ranking, we investigate two dynamic data selection techniques2 that vary per epoch the composition or the size of the selected training data. Both techniques aim to favor highly relevant sentences over less relevant sentences while not completely discarding the latter. In all experiments, we use a fixed vocabulary created from the complete bitext. While we use in this work a domain-relevance ranking of the bitext following Axelrod et al. (2011), dynamic data selection can also be applied using other ranking criteria, for example limiting redundancy in the training data (Lewis and Eetemadi, 2013) or complementing similarity with diversity (Ruder and Plank, 2017). Sampling sentence pairs In the first technique, illustrated in Figure 1a, we sample for every epoch n sentence pairs from G, using a distribution computed from the domain-specific CEDs scores. Concretely, this is done as follows: First, since higher ranked sentence pairs have lower CEDs scores, and they can be either negative or positive, we scale and invert CEDs scores such that 0 ≤ CED0s ≤ 1 for each sentence pair s ∈ G: CED0s = 1 − 2 CEDs − min(CEDG ) , max(CEDG ) − min(CEDG ) (3) Code for bitext ranking and both selection"
D17-1147,L16-1147,0,0.0454519,"in Dev/valid Test Corpus Lines Tokens Lines Tokens Lines Tokens EMEA 206K 3.3M Movies 101K 1.2M TED 189K 3.3M WMT 3.8M 84M 3.9K 4.5K 2.5K 3.0K 59K 54K 50K 64K 5.8K 7.1K 5.4K 3.0K 93K 87K 99K 65K Mix 3.5K 61K – – 4.3M 92M Table 1: Data specifications with tokens counted on the German side. The WMT training corpus contains Commoncrawl, Europarl, and News Commentary but no in-domain news data. 4.2 Training and evaluation data We evaluate all experiments on four domains: (i) EMEA medical guidelines (Tiedemann, 2009), (ii) movie dialogues (van der Wees et al., 2016) constructed from OpenSubtitles (Lison and Tiedemann, 2016), (iii) TED talks (Cettolo et al., 2012), and (iv) WMT news. For TED, we use IWSLT2010 as development set and IWSLT20112014 as test set, and for WMT we use newstest2013 as development set and newstest2016 as test set. We train our systems on a mixture of domains, comprising Commoncrawl, Europarl, News Commentary, EMEA, Movies, and TED. Corpus specifications are listed in Table 1. The in-domain LMs used to rank training sentences for data selection are trained on small portions of in-domain parallel data whenever available (3.3M, 1.2M and 3.3M German tokens for EMEA, Movies and TED, respectivel"
D17-1147,2015.iwslt-evaluation.11,0,0.264764,"drawing for each epoch n sentence pairs without replacement. While all selection weights are very close to zero, higher ranked sentences have a noticeably higher probability of being selected than lower-ranked sentences; in practice we find that top-ranked sentences get selected in nearly each epoch, while bottom-ranked sentence pairs get selected at most once. Note that the sampled selection for any epoch is independent of selections for all other epochs. Gradual fine-tuning The second dynamic data selection technique, see Figure 1b, is inspired by the success of domain-specific fine-tuning (Luong and Manning, 2015; Zoph et al., 2016; Sennrich et al., 2016a; Freitag and Al-Onaizan, 2016), in which a model trained on a large general-domain bitext is trained for a few additional epochs only on small in-domain data. However, rather than training a full model on the complete bitext G, we gradually decrease the training data size, starting from G and keeping only the top n sentence pairs for the duration of η epochs, where the top n pairs are defined by their CEDs scores. Given its resemblance to fine-tuning, we refer to this variant as gradual fine-tuning. 1402 During gradual fine-tuning, the selection size"
D17-1147,D15-1166,0,0.181845,"lassifiers, respectively. Data selection with the aim of model size and training time reduction has the objective to use the minimum amount of data while still maintaining high vocabulary coverage (Eck et al., 2005; Gasc´o et al., 2012; Lewis and Eetemadi, 2013). In a comparative study, Mirkin and Besacier (2014) find that similarity-objected methods perform best if the test domain and general corpus are very different, while a coverage-objected method is superior if test and general corpus are relatively similar. A comprehensive survey on data selection for SMT is provided by Eetemadi et al. (2015). While in this work we have used a similarity objective to rank our bitext, one could also apply dynamic data selection using a coverage objective. In NMT, data selection can serve similar goals as in PBMT; increasing training efficiency or domain adaptation. Domain adaptation in NMT typically involves training a model on the complete bitext, followed by fine-tuning the parameters on a smaller in-domain corpus (Luong and Manning, 2015; Zoph et al., 2016). Other work combines fine-tuning with model ensembles (Freitag and AlOnaizan, 2016) or with domain-specific tags in the training corpus (Chu"
D17-1147,P15-1002,0,0.0826066,"(Moore and Lewis, 2010; Axelrod et al., 2011; Gasc´o et al., 2012). Instead, for a given translation task, the training bitext likely contains sentences that are irrelevant or even harmful, making it beneficial to keep only the most relevant subset of the data while discarding the rest, with the additional benefit of smaller models and faster training. Motivated by the success of data selection in PBMT, we investigate in this paper to what extent and how NMT can benefit from data selection as well. While data selection has been applied to NMT to reduce the size of the data (Cho et al., 2014; Luong et al., 2015b), the effects on translation quality have not been investigated. Intuitively, and confirmed by our exploratory experiments in Section 5.1, this is a challenging task; NMT systems are known to under-perform when trained on limited parallel data (Zoph et al., 2016; Fadaee et al., 2017), and do not have a separate large-scale target-side language model to compensate for smaller parallel training data. To alleviate the negative effect of small training data on NMT, we introduce dynamic data selection. Following conventional data selection, we still dramatically reduce the training data size, fav"
D17-1147,2014.amta-researchers.23,0,0.0646374,"general-domain data (Moore and Lewis, 2010; Axelrod et al., 2011, 2015), favoring sentences that are similar to the test domain and at the same time dissimilar from the general domain. Duh et al. (2013) and Chen and Huang (2016) present similar methods in which n-gram LMs are replaced by neural LMs or neural classifiers, respectively. Data selection with the aim of model size and training time reduction has the objective to use the minimum amount of data while still maintaining high vocabulary coverage (Eck et al., 2005; Gasc´o et al., 2012; Lewis and Eetemadi, 2013). In a comparative study, Mirkin and Besacier (2014) find that similarity-objected methods perform best if the test domain and general corpus are very different, while a coverage-objected method is superior if test and general corpus are relatively similar. A comprehensive survey on data selection for SMT is provided by Eetemadi et al. (2015). While in this work we have used a similarity objective to rank our bitext, one could also apply dynamic data selection using a coverage objective. In NMT, data selection can serve similar goals as in PBMT; increasing training efficiency or domain adaptation. Domain adaptation in NMT typically involves tra"
D17-1147,P10-2041,0,0.53045,"n NMT model is often a time-consuming task, with training times of several weeks not being unusual. Despite its training inefficiency, most work in NMT greedily uses all available training data for a given language pair. However, it is unlikely ∗ Work done while at University of Amsterdam Christof Monz Informatics Institute University of Amsterdam that all data is equally helpful to create the bestperforming system. In PBMT, this issue has been addressed by applying intelligent data selection, and it has consistently been shown that using more data does not always improve translation quality (Moore and Lewis, 2010; Axelrod et al., 2011; Gasc´o et al., 2012). Instead, for a given translation task, the training bitext likely contains sentences that are irrelevant or even harmful, making it beneficial to keep only the most relevant subset of the data while discarding the rest, with the additional benefit of smaller models and faster training. Motivated by the success of data selection in PBMT, we investigate in this paper to what extent and how NMT can benefit from data selection as well. While data selection has been applied to NMT to reduce the size of the data (Cho et al., 2014; Luong et al., 2015b), t"
D17-1147,P02-1040,0,0.0985775,"Missing"
D17-1147,P16-1009,0,0.160861,"encountering out-of-vocabulary words. In this neural variant to rank sentences, the score for each sentence pair in G is still computed as the bilingual cross-entropy difference in Equation (2). In addition, we use the same in-domain and general corpora as with the ngram method, and we again restrict the vocabulary to the most frequent words. 3 Dynamic data selection While data selection aims to discard irrelevant data, it can also exacerbate the problem of low vocabulary coverage and unreliable statistics for rarer words in the ‘long tail’, which are major issues in NMT (Luong et al., 2015b; Sennrich et al., 2016b). In addition, it has been shown that NMT performance drops tremendously in low-resource scenarios (Zoph et al., 2016; Fadaee et al., 2017; Koehn and Knowles, 2017). To overcome this problem, we introduce dynamic data selection, in which we vary the selected data subsets during training. Unlike other MT paradigms, which require training data to be fixed during the entire training process, NMT iterates over the training corpus in several epochs, 1 We use four-layer LSTMs with embedding and hidden sizes of 1,024, which we train for 30 epochs. 1401 a) Dynamic data selection: sampling b) Dynamic"
D17-1147,P16-1162,0,0.342819,"encountering out-of-vocabulary words. In this neural variant to rank sentences, the score for each sentence pair in G is still computed as the bilingual cross-entropy difference in Equation (2). In addition, we use the same in-domain and general corpora as with the ngram method, and we again restrict the vocabulary to the most frequent words. 3 Dynamic data selection While data selection aims to discard irrelevant data, it can also exacerbate the problem of low vocabulary coverage and unreliable statistics for rarer words in the ‘long tail’, which are major issues in NMT (Luong et al., 2015b; Sennrich et al., 2016b). In addition, it has been shown that NMT performance drops tremendously in low-resource scenarios (Zoph et al., 2016; Fadaee et al., 2017; Koehn and Knowles, 2017). To overcome this problem, we introduce dynamic data selection, in which we vary the selected data subsets during training. Unlike other MT paradigms, which require training data to be fixed during the entire training process, NMT iterates over the training corpus in several epochs, 1 We use four-layer LSTMs with embedding and hidden sizes of 1,024, which we train for 30 epochs. 1401 a) Dynamic data selection: sampling b) Dynamic"
D17-1147,E17-1100,0,0.0420941,"Missing"
D17-1147,C16-1242,1,0.901265,"Missing"
D17-1147,1983.tc-1.13,0,0.683309,"Missing"
D17-1147,I08-2088,0,0.11659,"ing rate, BLEU scores hardly change or even improve, indicating that the implicit change in search behavior may contribute to the success of gradual fine-tuning. 7 Related work A few research topics are related to our work. Regarding data selection for SMT, previous work has targeted two goals; to reduce model sizes and training times, or to adapt to new domains. Data selection methods for domain adaptation mostly employ information theory metrics to rank training sentences by their relevance to the domain at hand. This has been applied monolingually (Gao et al., 2002) as well as bilingually (Yasuda et al., 2008). In more recent work, training sentences are typically ranked according to their cross-entropy difference between in-domain and general-domain data (Moore and Lewis, 2010; Axelrod et al., 2011, 2015), favoring sentences that are similar to the test domain and at the same time dissimilar from the general domain. Duh et al. (2013) and Chen and Huang (2016) present similar methods in which n-gram LMs are replaced by neural LMs or neural classifiers, respectively. Data selection with the aim of model size and training time reduction has the objective to use the minimum amount of data while still"
D17-1147,P16-5005,0,0.0422657,"domain-specific tags in the training corpus (Chu et al., 2017). Finally, Sennrich et al. (2016a) adapt their systems by backtranslating in-domain data, which is then added to the training data and used for fine-tuning. Some other previous work has addressed training efficiency for NMT, for example by parallelizing models or data (Wu et al., 2016), modifying the NMT network structure (Kalchbrenner et al., 2016), decreasing the number of parameters through knowledge distillation (Crego et al., 2016; Kim and Rush, 2016), or by boosting parts of the data that are ‘challenging’ to the NMT system (Zhang et al., 2016). The latter is most related to our work since training data is also adjusted during training, however we reduce the training data size much more aggressively and study different techniques of data selection. Finally, recent work comparing various aspects for PBMT and NMT includes (Bentivogli et al., 2016; Farajian et al., 2017; Toral and S´anchezCartagena, 2017; Koehn and Knowles, 2017). 8 Conclusions With the recent increase in popularity of neural machine translation (NMT), we explored in this paper to what extent and how NMT can benefit from data selection. We first showed that a stateof-t"
D17-1147,D16-1163,0,0.0455804,"le discarding the rest, with the additional benefit of smaller models and faster training. Motivated by the success of data selection in PBMT, we investigate in this paper to what extent and how NMT can benefit from data selection as well. While data selection has been applied to NMT to reduce the size of the data (Cho et al., 2014; Luong et al., 2015b), the effects on translation quality have not been investigated. Intuitively, and confirmed by our exploratory experiments in Section 5.1, this is a challenging task; NMT systems are known to under-perform when trained on limited parallel data (Zoph et al., 2016; Fadaee et al., 2017), and do not have a separate large-scale target-side language model to compensate for smaller parallel training data. To alleviate the negative effect of small training data on NMT, we introduce dynamic data selection. Following conventional data selection, we still dramatically reduce the training data size, favoring parts of the data which are most relevant to the translation task at hand. However, we exploit the fact that the NMT training process iterates over the training corpus in multiple epochs, and we alter the quantity or the composition of the training data betw"
D17-1147,D17-1038,0,0.145857,"Missing"
D17-1147,P07-2045,0,\N,Missing
D17-1147,W16-2301,1,\N,Missing
D18-1313,I17-1001,0,0.093554,"Missing"
D18-1313,D16-1025,1,0.720711,"alysis of how various source-side morphological features are captured at different levels of the NMT encoder while varying the target language. Differently from previous work, we find no correlation between the accuracy of source morphology encoding and translation quality. We do find that morphological features are only captured in context and only to the extent that they are directly transferable to the target words. 1 Introduction The advent of Neural Machine Translation (NMT) (Sutskever et al., 2014; Bahdanau et al., 2014) has led to remarkable improvements in machine translation quality (Bentivogli et al., 2016) but has also produced models that are much less interpretable. In particular, the role played by linguistic features in the process of understanding the source text and rendering it in the target language remains hard to gauge. Acquiring this knowledge is important to inform future research in NMT, especially regarding the usefulness of injecting linguistic information into the NMT model, e.g. by using supervised annotation (Sennrich and Haddow, 2016). Hill et al. (2014) gave a first answer to this question, reporting high accuracies by source-side NMT word embeddings on the well-known analog"
D18-1313,I17-1015,0,0.0978812,"onds to that of French because of their common language ancestor, whereas German gender is mostly unrelated from French gender (see example in Fig. 1). The continuous word representations produced by the three NMT systems while encoding a corpus of French sentences are used to build and evaluate several specialized classifiers: one per morphological feature. If a classifier significantly outperforms the majority baseline, we conclude that the corresponding feature is captured by the NMT encoder. While this methodology is similar to that of previous work (K¨ohn, 2015; Belinkov et al., 2017a,b; Dalvi et al., 2017) we make sure that our results are not affected by overfitting by eliminating any vocabulary overlap between the classifier’s training and test sets. We find this step crucial to ensure that the redundancy in this type of data does not lead to over-optimistic conclusions. We now provide more details on the experimental setup. Parallel corpora. For a fair comparison among target languages, we extract the intersection of the Europarl corpus (Koehn, 2005) in our three language pairs so that the source side data is identical for all NMT systems. Sentences longer than 50 tokens are ignored. This da"
D18-1313,K17-1003,0,0.0486641,"Missing"
D18-1313,P17-1080,0,0.499745,"regarding the usefulness of injecting linguistic information into the NMT model, e.g. by using supervised annotation (Sennrich and Haddow, 2016). Hill et al. (2014) gave a first answer to this question, reporting high accuracies by source-side NMT word embeddings on the well-known analogy task by Mikolov et al. (2013) which also includes a number of derivational and inflectional transformations in the morphologically poor English language. More recent work (Shi et al., 2016) has shown that source sentence representations produced by NMT encoders contain a great deal of syntactic information. Belinkov et al. (2017a) focused on the word level and examined to what extent part-of-speech and morphological information can be extracted from various NMT word representations. The latter study found that source-side morphology is captured slightly better by the first recurrent layer than by the word embedding and the final recurrent layer. Another, somewhat surprising finding was that source-side morphology is learned better when translating into an ‘easier’ target language than into a related one, even if the ’easier’ language is morphologically poor. In this paper, we also focus on source-side morphology but"
D18-1313,2005.mtsummit-papers.11,0,0.0165209,"ature is captured by the NMT encoder. While this methodology is similar to that of previous work (K¨ohn, 2015; Belinkov et al., 2017a,b; Dalvi et al., 2017) we make sure that our results are not affected by overfitting by eliminating any vocabulary overlap between the classifier’s training and test sets. We find this step crucial to ensure that the redundancy in this type of data does not lead to over-optimistic conclusions. We now provide more details on the experimental setup. Parallel corpora. For a fair comparison among target languages, we extract the intersection of the Europarl corpus (Koehn, 2005) in our three language pairs so that the source side data is identical for all NMT systems. Sentences longer than 50 tokens are ignored. This data is then split into an NMT training, validation, and test set of 1.3M, 2.5K, and 2.5K sentence pairs respectively. NMT model. The NMT architecture is an attentional encoder-decoder model similar to (Luong et al., 2015) and uses a long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) as the recurrent cell. The models have 3 stacked LSTM layers and are trained for 15 epochs. Embedding and hidden state sizes are set to 1000. Source and target"
D18-1313,D15-1246,0,0.254637,"Missing"
D18-1313,D15-1166,0,0.0551704,"ancy in this type of data does not lead to over-optimistic conclusions. We now provide more details on the experimental setup. Parallel corpora. For a fair comparison among target languages, we extract the intersection of the Europarl corpus (Koehn, 2005) in our three language pairs so that the source side data is identical for all NMT systems. Sentences longer than 50 tokens are ignored. This data is then split into an NMT training, validation, and test set of 1.3M, 2.5K, and 2.5K sentence pairs respectively. NMT model. The NMT architecture is an attentional encoder-decoder model similar to (Luong et al., 2015) and uses a long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) as the recurrent cell. The models have 3 stacked LSTM layers and are trained for 15 epochs. Embedding and hidden state sizes are set to 1000. Source and target vocabularies are limited to the 30,000 most frequent words on each side of the training data.1 The NMT models achieve a test BLEU score of 32.6, 25.4 and 39.4 for FrenchItalian, French-German and French-English respectively. Continuous word representations. Given a source sentence, the NMT system first encodes it into a sequence of word embeddings (contextindep"
D18-1313,sagot-2010-lefff,0,0.0338782,"Missing"
D18-1313,W16-2209,0,0.0216904,"ural Machine Translation (NMT) (Sutskever et al., 2014; Bahdanau et al., 2014) has led to remarkable improvements in machine translation quality (Bentivogli et al., 2016) but has also produced models that are much less interpretable. In particular, the role played by linguistic features in the process of understanding the source text and rendering it in the target language remains hard to gauge. Acquiring this knowledge is important to inform future research in NMT, especially regarding the usefulness of injecting linguistic information into the NMT model, e.g. by using supervised annotation (Sennrich and Haddow, 2016). Hill et al. (2014) gave a first answer to this question, reporting high accuracies by source-side NMT word embeddings on the well-known analogy task by Mikolov et al. (2013) which also includes a number of derivational and inflectional transformations in the morphologically poor English language. More recent work (Shi et al., 2016) has shown that source sentence representations produced by NMT encoders contain a great deal of syntactic information. Belinkov et al. (2017a) focused on the word level and examined to what extent part-of-speech and morphological information can be extracted from"
D18-1313,D16-1159,0,0.206176,"ering it in the target language remains hard to gauge. Acquiring this knowledge is important to inform future research in NMT, especially regarding the usefulness of injecting linguistic information into the NMT model, e.g. by using supervised annotation (Sennrich and Haddow, 2016). Hill et al. (2014) gave a first answer to this question, reporting high accuracies by source-side NMT word embeddings on the well-known analogy task by Mikolov et al. (2013) which also includes a number of derivational and inflectional transformations in the morphologically poor English language. More recent work (Shi et al., 2016) has shown that source sentence representations produced by NMT encoders contain a great deal of syntactic information. Belinkov et al. (2017a) focused on the word level and examined to what extent part-of-speech and morphological information can be extracted from various NMT word representations. The latter study found that source-side morphology is captured slightly better by the first recurrent layer than by the word embedding and the final recurrent layer. Another, somewhat surprising finding was that source-side morphology is learned better when translating into an ‘easier’ target languag"
D18-1503,P18-2003,0,0.0343089,", making them more suited for modeling long distance dependencies than CNNs. Additionally, FANs promise to be more interpretable than LSTMs by visualizing attention weights. The rest of the paper is organized as follows: We first highlight the differences between the two architectures (§2) and introduce the two tasks (§3). Then we provide setup and results for each task (§4 and §5) and discuss our findings (§6). Recent work has shown that recurrent neural networks (RNNs) can implicitly capture and exploit hierarchical information when trained to solve common natural language processing tasks (Blevins et al., 2018) such as language modeling (Linzen et al., 2016; Gulordava et al., 2018) and neural machine translation (Shi et al., 2016). In contrast, the ability to model structured data with non-recurrent neural networks has received little attention despite their success in many NLP tasks (Gehring et al., 2017; Vaswani et al., 2017). In this work, we compare the two architectures—recurrent versus non-recurrent—with respect to their ability to model hierarchical structure and find that recurrency is indeed important for this purpose. The code and data used in our experiments is available at https://github"
D18-1503,D15-1075,0,0.449039,"showing the main difference between a LSTM and a FAN. Purple boxes indicate the summarized vector at current time step t which is used to make prediction. Orange arrows indicate the information flow from a previous input to that vector. learn hierarchical structure with a set of controlled experiments. 3 Tasks We choose two tasks to study in this work: (1) subject-verb agreement, and (2) logical inference. The first task was proposed by Linzen et al. (2016) to test the ability of recurrent neural networks to capture syntactic dependencies in natural language. The second task was introduced by Bowman et al. (2015b) to compare tree-based recursive neural networks against sequence-based recurrent networks with respect to their ability to exploit hierarchical structures to make accurate inferences. The choice of tasks here is important to ensure that both models have to exploit hierarchical structural features (Jia and Liang, 2017). 4 Subject-Verb Agreement Linzen et al. (2016) propose the task of predicting number agreement between subject and verb in naturally occurring English sentences as a proxy for the ability of LSTMs to capture hierarchical structure in natural language. We use the dataset provid"
D18-1503,P18-2103,0,0.0457007,"Missing"
D18-1503,N18-1108,0,0.0600681,"CNNs. Additionally, FANs promise to be more interpretable than LSTMs by visualizing attention weights. The rest of the paper is organized as follows: We first highlight the differences between the two architectures (§2) and introduce the two tasks (§3). Then we provide setup and results for each task (§4 and §5) and discuss our findings (§6). Recent work has shown that recurrent neural networks (RNNs) can implicitly capture and exploit hierarchical information when trained to solve common natural language processing tasks (Blevins et al., 2018) such as language modeling (Linzen et al., 2016; Gulordava et al., 2018) and neural machine translation (Shi et al., 2016). In contrast, the ability to model structured data with non-recurrent neural networks has received little attention despite their success in many NLP tasks (Gehring et al., 2017; Vaswani et al., 2017). In this work, we compare the two architectures—recurrent versus non-recurrent—with respect to their ability to model hierarchical structure and find that recurrency is indeed important for this purpose. The code and data used in our experiments is available at https://github.com/ ketranm/fan_vs_rnn 1 Introduction Recurrent neural networks (RNNs)"
D18-1503,N18-2017,0,0.0285549,"Missing"
D18-1503,D17-1215,0,0.0182162,"two tasks to study in this work: (1) subject-verb agreement, and (2) logical inference. The first task was proposed by Linzen et al. (2016) to test the ability of recurrent neural networks to capture syntactic dependencies in natural language. The second task was introduced by Bowman et al. (2015b) to compare tree-based recursive neural networks against sequence-based recurrent networks with respect to their ability to exploit hierarchical structures to make accurate inferences. The choice of tasks here is important to ensure that both models have to exploit hierarchical structural features (Jia and Liang, 2017). 4 Subject-Verb Agreement Linzen et al. (2016) propose the task of predicting number agreement between subject and verb in naturally occurring English sentences as a proxy for the ability of LSTMs to capture hierarchical structure in natural language. We use the dataset provided by Linzen et al. (2016) and follow their experimental protocol of training each model using either (a) a general language model, i.e., next word prediction objective, and (b) an explicit supervision objective, i.e., predicting the number of the verb given its sentence history. Table 1 illustrates the training and test"
D18-1503,Q16-1037,0,0.619087,"nce dependencies than CNNs. Additionally, FANs promise to be more interpretable than LSTMs by visualizing attention weights. The rest of the paper is organized as follows: We first highlight the differences between the two architectures (§2) and introduce the two tasks (§3). Then we provide setup and results for each task (§4 and §5) and discuss our findings (§6). Recent work has shown that recurrent neural networks (RNNs) can implicitly capture and exploit hierarchical information when trained to solve common natural language processing tasks (Blevins et al., 2018) such as language modeling (Linzen et al., 2016; Gulordava et al., 2018) and neural machine translation (Shi et al., 2016). In contrast, the ability to model structured data with non-recurrent neural networks has received little attention despite their success in many NLP tasks (Gehring et al., 2017; Vaswani et al., 2017). In this work, we compare the two architectures—recurrent versus non-recurrent—with respect to their ability to model hierarchical structure and find that recurrency is indeed important for this purpose. The code and data used in our experiments is available at https://github.com/ ketranm/fan_vs_rnn 1 Introduction Recurre"
D18-1503,E17-2025,0,0.0249278,"replaced by their part-of-speech. (a) (b) Input Train Test the keys to the cabinet the keys to the cabinet are plural p(are) > p(is)? plural/singular? Hyperparameters: To allow for a fair comparison, we find the best configuration for each model by running a grid search over the following hyperparameters: number of layers in {2, 3, 4}, dropout rate in {0.2, 0.3, 0.5}, embedding size and number of hidden units in {128, 256, 512}, number of heads (for FAN) in {2, 4}, and learning rate in {0.00001, 0.0001, 0.001}. The weights of the word embeddings and output layer are shared (Inan et al., 2017; Press and Wolf, 2017). Models are optimized by Adam (Kingma and Ba, 2015). We first assess whether the LSTM and FAN models trained with respect to the language model objective assign higher probabilities to the correctly inflected verbs. As shown in Figures 2a and 2b, both models achieve high accuracies for this task, but LSTMs consistently outperform FANs. Moreover, LSTMs are clearly more robust than FANs with respect to task difficulty, measured both in terms of word distance and number of agreement attractors1 between subject and verb. Christiansen and Chater (2016); Cornish et al. (2017) have argued that human"
D18-1503,D16-1159,0,0.0750391,"le than LSTMs by visualizing attention weights. The rest of the paper is organized as follows: We first highlight the differences between the two architectures (§2) and introduce the two tasks (§3). Then we provide setup and results for each task (§4 and §5) and discuss our findings (§6). Recent work has shown that recurrent neural networks (RNNs) can implicitly capture and exploit hierarchical information when trained to solve common natural language processing tasks (Blevins et al., 2018) such as language modeling (Linzen et al., 2016; Gulordava et al., 2018) and neural machine translation (Shi et al., 2016). In contrast, the ability to model structured data with non-recurrent neural networks has received little attention despite their success in many NLP tasks (Gehring et al., 2017; Vaswani et al., 2017). In this work, we compare the two architectures—recurrent versus non-recurrent—with respect to their ability to model hierarchical structure and find that recurrency is indeed important for this purpose. The code and data used in our experiments is available at https://github.com/ ketranm/fan_vs_rnn 1 Introduction Recurrent neural networks (RNNs), in particular Long Short-Term Memory networks (L"
D18-1503,N16-1036,1,0.849596,"Missing"
D19-6132,K15-1012,0,0.246594,"Tran∗ Amazon Alexa AI trnke@amazon.com Arianna Bisazza† University of Groningen a.bisazza@rug.nl Abstract (m-BERT) allow for the development of a universal dependency parser that is able to parse sentences in a diverse range of languages without receiving any supervision in those language. Our parser is fully lexicalized, in contrast to a successful approach based on delexicalized parsers (Zeman and Resnik, 2008; McDonald et al., 2011). Building on the delexicalized approach, previous work employed additional features such as typological properties (Naseem et al., 2012), syntactic embeddings (Duong et al., 2015), and crosslingual word clusters (Täckström et al., 2012) to boost parsing performance. More recent work by Ammar et al. (2016); Guo et al. (2016) requires translation data for projecting word embeddings into a shared multilingual space. We investigate whether off-the-shelf deep bidirectional sentence representations (Devlin et al., 2018) trained on a massively multilingual corpus (multilingual BERT) enable the development of an unsupervised universal dependency parser. This approach only leverages a mix of monolingual corpora in many languages and does not require any translation data making"
D19-6132,D19-1279,0,0.0263699,"ltilingual corpus ∗ Work done prior to joining Amazon. Work done while at Leiden University. Both authors contributed equally. † 281 Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo), pages 281–288 c Hong Kong, China, November 3, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 languages while using a single system. The arc score is computed similar to Dozat and Manning (2016): The effectiveness of m-BERT for cross-lingual transfer of UD parsers has also been demonstrated in concurrent work by Wu and Dredze (2019) and Kondratyuk (2019). While the former utilizes only English as the training language, the latter trains on a concatentation of all available UD treebanks. We additionally experiment with three different sets of training languages beyond English-only and make interesting observations on the resulting large, and sometimes unexplicable, variation of performance among test languages. 2 s(arc) = DeepBiaffine(H(arc-head) , H(arc-dep) ) (1) The log probability of the dependency tree y of x is given by X log p(y |x) = s(arc) [h, c] − log Z(x) (2) (h,c)∈y where Z(x) is the partition function. Our objective function for p"
D19-6132,D07-1015,0,0.212478,"tion of all available UD treebanks. We additionally experiment with three different sets of training languages beyond English-only and make interesting observations on the resulting large, and sometimes unexplicable, variation of performance among test languages. 2 s(arc) = DeepBiaffine(H(arc-head) , H(arc-dep) ) (1) The log probability of the dependency tree y of x is given by X log p(y |x) = s(arc) [h, c] − log Z(x) (2) (h,c)∈y where Z(x) is the partition function. Our objective function for predicting dependency arcs therefore is globally normalized. We compute Z(x) via matrix determinant (Koo et al., 2007). In our experiments, we find that training with a global objective is more stable if theP score s(arc) [h, c] is locally nor2 malized such that h exp(s(arc) [h, c]) = 1. During training, we update both m-BERT and parsing layer parameters. Model We use the representations produced by BERT (Devlin et al., 2018) which is a self-attentive deep bidirectional network (Vaswani et al., 2017) trained with a masked language model objective. Specifically we use BERT’s multilingual cased version1 which was trained on the 100 languages with the largest available Wikipedias. Exponentially smoothed weightin"
D19-6132,K17-3009,0,0.03041,"Manning (2016), our arc prediction model is a globally normalized model which computes partition functions of non-projective dependency structures using Kirchhoff’s Matrix-Tree Theorem (Koo et al., 2007). 3 Experiments While most previous work on parser transfer, including the closely related (Duong et al., 2015) relies on gold tokenization and POS tags, we adopt the more realistic scenario of parsing from raw text (Zeman et al., 2018) and adopt the automatic sentence segmenter and tokenizer provided as baselines by the shared task organizers. 3.1 Data We use the UDpipe-tokenized test data3 (Straka and Straková, 2017) and the CoNLL18 official script for evaluation. Gold tokenization is only used for the training data, while POS information is never used. All of our experiments are carried out on the Universal Dependencies (UD) corpus version 2.2 (Nivre et al., 2018) for a fair comparison with previous work. Let x = w1 , w2 , . . . , wn be an input sentence of n tokens, which are given by the gold segmentation in training or by an automatic tokenizer in testing (§3.1). To obtain the m-BERT representation of x, we first obtain a sequence t = t1 , . . . , tm of m ≥ n subwords from x using the WordPiece algori"
D19-6132,K17-3001,0,0.0243015,"guages (expMix) beats the best CoNLL18 language-specific systems on all six languages, even though three of these languages are not represented in m-BERT’s training data5 . This result highlights the advantage of multilingual pre-trained model in the truly low resource scenario. Training details We notice the poor performance of our parser on spoken French in comparison to other European languages. While there is sufficient amount of Wikipedia text for French, it seems that zero-shot parsing on a different domain remains a challenge even with a large pre-trained model. Similar to Dozat et al. (2017), we use a neural network output size of 400 for arc prediction and 100 for label prediction. We use the Adam optimizer with learning rate 5e−6 to update the parameters of our models. The model is evaluated every 500 updates and we stop training if the score LAS does not increase in ten consecutive validations. 3.3 4 Results Analysis By varying the set of parser training languages we analyze our results with respect to two factors: parser training language diversity and word order similarity. To put our results into perspective, we report the accuracy of the best CoNLL18 system for each langua"
D19-6132,N12-1052,0,0.0775998,"a† University of Groningen a.bisazza@rug.nl Abstract (m-BERT) allow for the development of a universal dependency parser that is able to parse sentences in a diverse range of languages without receiving any supervision in those language. Our parser is fully lexicalized, in contrast to a successful approach based on delexicalized parsers (Zeman and Resnik, 2008; McDonald et al., 2011). Building on the delexicalized approach, previous work employed additional features such as typological properties (Naseem et al., 2012), syntactic embeddings (Duong et al., 2015), and crosslingual word clusters (Täckström et al., 2012) to boost parsing performance. More recent work by Ammar et al. (2016); Guo et al. (2016) requires translation data for projecting word embeddings into a shared multilingual space. We investigate whether off-the-shelf deep bidirectional sentence representations (Devlin et al., 2018) trained on a massively multilingual corpus (multilingual BERT) enable the development of an unsupervised universal dependency parser. This approach only leverages a mix of monolingual corpora in many languages and does not require any translation data making it applicable to low-resource languages. In our experimen"
D19-6132,E17-2002,0,0.0312676,"parsing experiments.8 In (Lin et al., 2019) Japanese is completely excluded from the parsing experiments because of unstable results. Japanese and Vietnamese are language isolates in an NLP sense, meaning that they do not enjoy the presence of a closely related language among the highresourced training languages.9 For this class of languages, transfer performance is overall very inconsistent and hard to explain. To account for typological features, we also plot the average syntactic similarity σ ¯ of each test language to the eight expSOV training languages as computed by the URIEL database7 (Littell et al., 2017). 80 60 40 20 4.4 τ η σ ko→ja ja→ko 0 bxr ja vi ta kk br fa hy hu fo fi te hsb fr ur de sv Figure 1: Relationship between parsing accuracy (expMix), parser training-test vocabulary overlap τ , m-BERT unsegmented word score η, and average typological syntactic similarity σ ¯ . Purple bar indicates there is no language that belongs to the same family presented in training data. Languages in the training set of expMix are not shown. UDpipe Gold 14.96 37.44 20.04 37.45 Table 2: LAS scores when transferring between Korean and Japanese in two tokenization conditions. The case of Japanese is particul"
D19-6132,W18-5446,0,0.0327055,"its sentence context, also in language `), we hypothesize that cross-lingual syntactic transfer occurs via the shared subword vocabulary and hidden layer parameters. Indeed, on the challenging task of universal dependency parsing from raw text, we outperform by a large margin the best CoNLL18 language-specific systems (Zeman et al., 2018) on the shared task’s truly low-resource Introduction Pretrained sentence representations (Howard and Ruder, 2018; Radford et al., 2018; Peters et al., 2018; Devlin et al., 2018) have recently set the new state of the art in many language understanding tasks (Wang et al., 2018). An appealing avenue for this line of work is to use a mix of training data in several languages and a shared subword vocabulary leading to general-purpose multilingual representations. In turn, this opens the way to a number of promising cross-lingual transfer techniques that can address the lack of annotated data in the large majority of world languages. In this paper, we investigate whether deep bidirectional sentence representations (Devlin et al., 2018) trained on a massively multilingual corpus ∗ Work done prior to joining Amazon. Work done while at Leiden University. Both authors contr"
D19-6132,D11-1006,0,0.0456039,"Missing"
D19-6132,P12-1066,0,0.411903,"ed Multilingual Sentence Representations Ke Tran∗ Amazon Alexa AI trnke@amazon.com Arianna Bisazza† University of Groningen a.bisazza@rug.nl Abstract (m-BERT) allow for the development of a universal dependency parser that is able to parse sentences in a diverse range of languages without receiving any supervision in those language. Our parser is fully lexicalized, in contrast to a successful approach based on delexicalized parsers (Zeman and Resnik, 2008; McDonald et al., 2011). Building on the delexicalized approach, previous work employed additional features such as typological properties (Naseem et al., 2012), syntactic embeddings (Duong et al., 2015), and crosslingual word clusters (Täckström et al., 2012) to boost parsing performance. More recent work by Ammar et al. (2016); Guo et al. (2016) requires translation data for projecting word embeddings into a shared multilingual space. We investigate whether off-the-shelf deep bidirectional sentence representations (Devlin et al., 2018) trained on a massively multilingual corpus (multilingual BERT) enable the development of an unsupervised universal dependency parser. This approach only leverages a mix of monolingual corpora in many languages and do"
D19-6132,D19-1077,0,0.132735,"trained on a massively multilingual corpus ∗ Work done prior to joining Amazon. Work done while at Leiden University. Both authors contributed equally. † 281 Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo), pages 281–288 c Hong Kong, China, November 3, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 languages while using a single system. The arc score is computed similar to Dozat and Manning (2016): The effectiveness of m-BERT for cross-lingual transfer of UD parsers has also been demonstrated in concurrent work by Wu and Dredze (2019) and Kondratyuk (2019). While the former utilizes only English as the training language, the latter trains on a concatentation of all available UD treebanks. We additionally experiment with three different sets of training languages beyond English-only and make interesting observations on the resulting large, and sometimes unexplicable, variation of performance among test languages. 2 s(arc) = DeepBiaffine(H(arc-head) , H(arc-dep) ) (1) The log probability of the dependency tree y of x is given by X log p(y |x) = s(arc) [h, c] − log Z(x) (2) (h,c)∈y where Z(x) is the partition function. Our ob"
D19-6132,N18-1202,0,0.0522088,"resource languages (§3.3). While m-BERT’s training objective is inherently monolingual (predict a word in language ` given its sentence context, also in language `), we hypothesize that cross-lingual syntactic transfer occurs via the shared subword vocabulary and hidden layer parameters. Indeed, on the challenging task of universal dependency parsing from raw text, we outperform by a large margin the best CoNLL18 language-specific systems (Zeman et al., 2018) on the shared task’s truly low-resource Introduction Pretrained sentence representations (Howard and Ruder, 2018; Radford et al., 2018; Peters et al., 2018; Devlin et al., 2018) have recently set the new state of the art in many language understanding tasks (Wang et al., 2018). An appealing avenue for this line of work is to use a mix of training data in several languages and a shared subword vocabulary leading to general-purpose multilingual representations. In turn, this opens the way to a number of promising cross-lingual transfer techniques that can address the lack of annotated data in the large majority of world languages. In this paper, we investigate whether deep bidirectional sentence representations (Devlin et al., 2018) trained on a m"
D19-6132,P19-1493,0,0.116203,"language typology Training on languages with similar typological features has been shown beneficial for parsing target languages in the delexicalized setup. In particular, word order similarities have been proved beneficial to select source languages for parsing model transfer (Naseem et al., 2012; Duong et al., 2015). 6 Unfortunately at the time of writing we have not yet managed to use their released implementation. 284 4.3 Towards explaining transfer performance that belong to a different family than all training languages, no correlation appears. A similar observation is also reported by Pires et al. (2019): namely, they find that the performance of crosslingual named entity recognition with m-BERT is largely independent of vocabulary overlap. Even when keeping the training languages fixed, for instance in expMix, we observe a large variation of zero-shot parsing transfer accuracy among test languages which does not often correlate with supervised parsing accuracy. As an attempt to explain this variation we look at the overlap of test vocabulary with (i) parser’s training data vocabulary τ and (ii) m-BERT’s training data vocabulary. Because m-BERT uses a subword vocabulary that also includes cha"
D19-6132,K18-2001,0,0.113061,") parsing accuracy still varies dramatically when changing the training languages and (ii) in some target languages zero-shot transfer fails under all tested conditions, raising concerns on the ‘universality’ of the whole approach. 1 Among lexicalized systems in CoNLL18, the top system (Che et al., 2018) utilizes contextualized vectors from ELMo. However, they train each ELMo for each language in the shared task. While their approach achieves the best LAS score on average, for low resource languages, the performance of their parser lags behind other systems that do not use pre-trained models (Zeman et al., 2018). By contrast, we build our dependency parser on top of general-purpose context-dependent word representations pretrained on a multilingual corpus. This approach does not require any translation data making it applicable to truly low-resource languages (§3.3). While m-BERT’s training objective is inherently monolingual (predict a word in language ` given its sentence context, also in language `), we hypothesize that cross-lingual syntactic transfer occurs via the shared subword vocabulary and hidden layer parameters. Indeed, on the challenging task of universal dependency parsing from raw text"
D19-6132,K18-2016,0,0.0148534,"00 for label prediction. We use the Adam optimizer with learning rate 5e−6 to update the parameters of our models. The model is evaluated every 500 updates and we stop training if the score LAS does not increase in ten consecutive validations. 3.3 4 Results Analysis By varying the set of parser training languages we analyze our results with respect to two factors: parser training language diversity and word order similarity. To put our results into perspective, we report the accuracy of the best CoNLL18 system for each language and that of the Stanford system submitted at the same evaluation (Qi et al., 2018). The latter is also based on the deep biaffine parser of Dozat and Manning (2016), it does not use ensembles and was ranked 2nd on official evaluation metric LAS4 . Both these parsers receive supervision in most of the languages, therefore comparison to our parser is only fair for the low-resource languages where training data is not available (or negligible, i.e. less than 1K tokens). 4.1 Training language diversity Increasing language diversity (expEn→expLatin and expLatin→expMix) leads to improvements in most test languages, even when the total amount of training data is fixed (expEn→expLa"
D19-6132,K17-3002,0,\N,Missing
E12-1045,W07-0702,0,0.0465663,"T system weights. For each target language, two standard 5-gram LMs are trained separately on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. In the Arabic-English task, we use a hierarchical reordering model (Galley and Manning, 2008; Hardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit is set to the default value of 6. Note that the use of large n-gram LMs and of lexicalized reordering models was shown to wipe out the improvement achievable by POS-level LM (Kirchhoff and Yang, 2005; Birch et al., 2007). Concerning data preprocessing we apply standard tokenization to the English and French text, while for Arabic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7 . The Arabic-English system uses cased 7 The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasi"
E12-1045,2011.iwslt-evaluation.18,1,0.853422,"2010 tst2010 |S| 90K 7.9M 124K 30.7M 934 1664 |W | 1.7M 220M 2.4M 782M 19K 30K ` 18.9 27.8 19.5 25.4 20.0 18.1 TED UN NEWS TED NEWS dev2010 tst2010 105K 11M 111K 107K 11.6M 934 1664 2.0M 291M 3.1M 2.2M 291M 20K 32K 19.5 26.5 27.6 20.6 25.2 21.5 19.1 Table 6: IWSLT11 training and test data statistics: number of sentences |S|, number of tokens |W |and average sentence length `. Token numbers are computed on the target language, except for the test sets. lel corpora: namely TED and NEWS for ArabicEnglish; TED, NEWS and UN for EnglishFrench. To this end we applied the fill-up method (Nakov, 2008; Bisazza et al., 2011) in which outof-domain phrase tables are merged with the indomain table by adding only new phrase pairs. Out-of-domain phrases are marked with a binary feature whose weight is tuned together with the SMT system weights. For each target language, two standard 5-gram LMs are trained separately on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. In the Arabic-English task, we use a hierarchical reordering model (Galley and Manning, 2008; Hardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit"
E12-1045,J92-4003,0,0.289015,"its to better tailor the LM to the task syntax, by complementing word-based n-grams with a part-of-speech (POS) LM , that can be estimated even on a limited amount of task-specific data. Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011). Our work makes another step in this direction by investigating hybrid LMs that try to explicitly represent the speaking style of the talk genre. As a difference from standard class-based LMs (Brown et al., 1992) or the more recent local LMs (Monz, 2011), which are used to predict sequences of classes or wordclass pairs, our hybrid LM is devised to predict sequences of classes interleaved by words. While we do not claim any technical novelty in the model itself, to our knowledge a deep investigation of hybrid LMs for the sake of style adaptation is definitely new. Finally, the term hybrid LM was inspired by Yazgan and Sarac¸lar (2004), which called with this name a LM predicting sequences of words and sub-words units, devised to let a speech recognizer detect out-of-vocabularywords. 4 Hybrid Language"
E12-1045,2011.mtsummit-papers.1,1,0.747648,"ormalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7 . The Arabic-English system uses cased 7 The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasing post-process. Feature weights are tuned on dev2010 by means of a minimum error training procedure (MERT) (Och, 2003). Following suggestions by Clark et al. (2011) and Cettolo et al. (2011) on controlling optimizer instability, we run MERT four times on the same configuration and use the average of the resulting weights to evaluate translation performance. 5.3 Hybrid LM integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8 . The order of the additional LM is set to 10 in the Arabic-English evaluation and 7 in the Englis"
E12-1045,P11-2031,0,0.100977,"removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7 . The Arabic-English system uses cased 7 The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasing post-process. Feature weights are tuned on dev2010 by means of a minimum error training procedure (MERT) (Och, 2003). Following suggestions by Clark et al. (2011) and Cettolo et al. (2011) on controlling optimizer instability, we run MERT four times on the same configuration and use the average of the resulting weights to evaluate translation performance. 5.3 Hybrid LM integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8 . The order of the additional LM is set to 10 in the Arabic-English eval"
E12-1045,N04-4038,0,0.01621,"ardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit is set to the default value of 6. Note that the use of large n-gram LMs and of lexicalized reordering models was shown to wipe out the improvement achievable by POS-level LM (Kirchhoff and Yang, 2005; Birch et al., 2007). Concerning data preprocessing we apply standard tokenization to the English and French text, while for Arabic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7 . The Arabic-English system uses cased 7 The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasing post-process. Feature weights are tuned on dev2010 by means of a minimum error training procedure (MERT) (Och, 2003). Following suggestions by Clark et al. (2011) and Cettolo et al. (2011) on controlling optimizer instability, we run MERT four times on the same config"
E12-1045,W07-0717,0,0.230189,"nce of one single LM. The progressive adoption of the log-linear modeling framework in many NLP tasks has recently introduced the use of multiple LM components (features), which permit to naturally factor out and integrate different aspects of language into one model. In SMT, the factored model (Koehn and Hoang, 2007), for instance, permits to better tailor the LM to the task syntax, by complementing word-based n-grams with a part-of-speech (POS) LM , that can be estimated even on a limited amount of task-specific data. Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011). Our work makes another step in this direction by investigating hybrid LMs that try to explicitly represent the speaking style of the talk genre. As a difference from standard class-based LMs (Brown et al., 1992) or the more recent local LMs (Monz, 2011), which are used to predict sequences of classes or wordclass pairs, our hybrid LM is devised to predict sequences of classes interleaved by words. While we do not claim any technical novelty in the model itself, to our kn"
E12-1045,D08-1089,0,0.0807084,"namely TED and NEWS for ArabicEnglish; TED, NEWS and UN for EnglishFrench. To this end we applied the fill-up method (Nakov, 2008; Bisazza et al., 2011) in which outof-domain phrase tables are merged with the indomain table by adding only new phrase pairs. Out-of-domain phrases are marked with a binary feature whose weight is tuned together with the SMT system weights. For each target language, two standard 5-gram LMs are trained separately on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. In the Arabic-English task, we use a hierarchical reordering model (Galley and Manning, 2008; Hardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit is set to the default value of 6. Note that the use of large n-gram LMs and of lexicalized reordering models was shown to wipe out the improvement achievable by POS-level LM (Kirchhoff and Yang, 2005; Birch et al., 2007). Concerning data preprocessing we apply standard tokenization to the English and French text, while for Arabic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIR"
E12-1045,W11-2144,1,0.852296,"itics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7 . The Arabic-English system uses cased 7 The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasing post-process. Feature weights are tuned on dev2010 by means of a minimum error training procedure (MERT) (Och, 2003). Following suggestions by Clark et al. (2011) and Cettolo et al. (2011) on controlling optimizer instability, we run MERT four times on the same configuration and use the average of the resulting weights to evaluate translation performance. 5.3 Hybrid LM integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8 . The order of the additional LM is set to 10 in the Arabic-English eval"
E12-1045,W05-0821,0,0.0197691,"tuned together with the SMT system weights. For each target language, two standard 5-gram LMs are trained separately on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. In the Arabic-English task, we use a hierarchical reordering model (Galley and Manning, 2008; Hardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit is set to the default value of 6. Note that the use of large n-gram LMs and of lexicalized reordering models was shown to wipe out the improvement achievable by POS-level LM (Kirchhoff and Yang, 2005; Birch et al., 2007). Concerning data preprocessing we apply standard tokenization to the English and French text, while for Arabic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7 . The Arabic-English system uses cased 7 The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models"
E12-1045,D07-1091,0,0.0222642,"ontent, and style. Most of the known LM adaption techniques (Bellegarda, 2004), however, address all these variations in a holistic way. A possible reason for this is that LM adaptation methods were originally developed under the automatic speech recognition framework, which typically assumes the presence of one single LM. The progressive adoption of the log-linear modeling framework in many NLP tasks has recently introduced the use of multiple LM components (features), which permit to naturally factor out and integrate different aspects of language into one model. In SMT, the factored model (Koehn and Hoang, 2007), for instance, permits to better tailor the LM to the task syntax, by complementing word-based n-grams with a part-of-speech (POS) LM , that can be estimated even on a limited amount of task-specific data. Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011). Our work makes another step in this direction by investigating hybrid LMs that try to explicitly represent the speaking style of the talk genre. As a difference from standa"
E12-1045,2005.iwslt-1.8,0,0.0609508,"line Our SMT experiments address the translation of TED talks from Arabic to English and from English to French. The training and test datasets were provided by the organizers of the IWSLT11 evaluation, and are summarized in Table 6. Marked in bold are the corpora used for hybrid LM training. Dev and test sets have a single reference translation. For both language pairs, we set up competitive phrase-based systems6 using the Moses toolkit (Koehn et al., 2007). The decoder features a statistical log-linear model including a phrase translation model and a phrase reordering model (Tillmann, 2004; Koehn et al., 2005), two word-based language models, distortion, word and phrase penalties. The translation and reordering models are obtained by combining models independently trained on the available paral6 The SMT systems used in this paper are thoroughly described in (Ruiz et al., 2011). 443 Corpus AR-EN EN AR test EN-FR FR EN test TED UN TED NEWS dev2010 tst2010 |S| 90K 7.9M 124K 30.7M 934 1664 |W | 1.7M 220M 2.4M 782M 19K 30K ` 18.9 27.8 19.5 25.4 20.0 18.1 TED UN NEWS TED NEWS dev2010 tst2010 105K 11M 111K 107K 11.6M 934 1664 2.0M 291M 3.1M 2.2M 291M 20K 32K 19.5 26.5 27.6 20.6 25.2 21.5 19.1 Table 6: IWS"
E12-1045,P07-2045,1,0.0182773,"Missing"
E12-1045,D11-1080,0,0.0936842,"complementing word-based n-grams with a part-of-speech (POS) LM , that can be estimated even on a limited amount of task-specific data. Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011). Our work makes another step in this direction by investigating hybrid LMs that try to explicitly represent the speaking style of the talk genre. As a difference from standard class-based LMs (Brown et al., 1992) or the more recent local LMs (Monz, 2011), which are used to predict sequences of classes or wordclass pairs, our hybrid LM is devised to predict sequences of classes interleaved by words. While we do not claim any technical novelty in the model itself, to our knowledge a deep investigation of hybrid LMs for the sake of style adaptation is definitely new. Finally, the term hybrid LM was inspired by Yazgan and Sarac¸lar (2004), which called with this name a LM predicting sequences of words and sub-words units, devised to let a speech recognizer detect out-of-vocabularywords. 4 Hybrid Language Model Hybrid LMs are n-gram models trained"
E12-1045,E99-1010,0,0.134571,"ect to the style, than its English counterpart. In fact, while the English corpus include transcripts of talks given by English speakers, the French one is mostly a collection of (human) translations. Typical features of the speech style may have been lost in this process. Comparison with baseline. In Table 8 the best performing hybrid LM is compared against the baseline that only includes the standard LMs described in Section 5.2. To complete our evaluation, we also report the effect of an in-domain LM trained on 50 word classes induced from the corpus by maximum-likelihood based clustering (Och, 1999). In the two language pairs, both types of LM result in consistent improvements over the baseline. However, the gains achieved by the hybrid approach are larger and all statistically significant. The hybrid approach is significantly better than the unsupervised one by TER in ArabicEnglish and by BLEU and METEOR in EnglishFrench (these siginificances are not reported in (a) Arabic to English, IWSLT–tst2010 Added InDomain 10g LM none (baseline) unsup. classes hybrid BLEU↑ MET ↑ TER ↓ 26.0 30.4 55.6 26.4◦ 30.8• 55.1◦ • • 26.5 (+.5) 30.8 (+.4) 54.6• (-1.0) (b) English to French, IWSLT–tst2010 Adde"
E12-1045,P03-1021,0,0.0120362,"ic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7 . The Arabic-English system uses cased 7 The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasing post-process. Feature weights are tuned on dev2010 by means of a minimum error training procedure (MERT) (Och, 2003). Following suggestions by Clark et al. (2011) and Cettolo et al. (2011) on controlling optimizer instability, we run MERT four times on the same configuration and use the average of the resulting weights to evaluate translation performance. 5.3 Hybrid LM integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8 . The order of the additio"
E12-1045,P02-1040,0,0.0851667,"resulting weights to evaluate translation performance. 5.3 Hybrid LM integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8 . The order of the additional LM is set to 10 in the Arabic-English evaluation and 7 in the English-French, as these appeared to be the best settings in preliminary tests. Translation quality is measured by BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006)9 . To test whether differences among systems are statistically significant we use approximate randomization as done in (Riezler and Maxwell, 2005)10 . Model variants. The effect on MT quality of various hybrid LM variants is shown in Table 7. Note that allPOS and allLemmas refer to deterministically assigned POS tags and lemmas, respectively. Concerning the ratio of POS-mapped tokens, the best performing values are WP =.25 in Arabic-English and WP =.50 in English-French. These hybrid mappings outperform all the uniform represent"
E12-1045,W05-0908,0,0.167854,"rget LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8 . The order of the additional LM is set to 10 in the Arabic-English evaluation and 7 in the English-French, as these appeared to be the best settings in preliminary tests. Translation quality is measured by BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006)9 . To test whether differences among systems are statistically significant we use approximate randomization as done in (Riezler and Maxwell, 2005)10 . Model variants. The effect on MT quality of various hybrid LM variants is shown in Table 7. Note that allPOS and allLemmas refer to deterministically assigned POS tags and lemmas, respectively. Concerning the ratio of POS-mapped tokens, the best performing values are WP =.25 in Arabic-English and WP =.50 in English-French. These hybrid mappings outperform all the uniform representations (words, lemmas and POS) with statistically significant BLEU and METEOR improvements. The fdf experiment involves the use of document frequency for the selection of common words. Its performance is very clo"
E12-1045,W11-2133,1,0.849634,"uced the use of multiple LM components (features), which permit to naturally factor out and integrate different aspects of language into one model. In SMT, the factored model (Koehn and Hoang, 2007), for instance, permits to better tailor the LM to the task syntax, by complementing word-based n-grams with a part-of-speech (POS) LM , that can be estimated even on a limited amount of task-specific data. Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011). Our work makes another step in this direction by investigating hybrid LMs that try to explicitly represent the speaking style of the talk genre. As a difference from standard class-based LMs (Brown et al., 1992) or the more recent local LMs (Monz, 2011), which are used to predict sequences of classes or wordclass pairs, our hybrid LM is devised to predict sequences of classes interleaved by words. While we do not claim any technical novelty in the model itself, to our knowledge a deep investigation of hybrid LMs for the sake of style adaptation is definitely new. Finally, the term hybrid LM"
E12-1045,2006.amta-papers.25,0,0.0236666,"M integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8 . The order of the additional LM is set to 10 in the Arabic-English evaluation and 7 in the English-French, as these appeared to be the best settings in preliminary tests. Translation quality is measured by BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006)9 . To test whether differences among systems are statistically significant we use approximate randomization as done in (Riezler and Maxwell, 2005)10 . Model variants. The effect on MT quality of various hybrid LM variants is shown in Table 7. Note that allPOS and allLemmas refer to deterministically assigned POS tags and lemmas, respectively. Concerning the ratio of POS-mapped tokens, the best performing values are WP =.25 in Arabic-English and WP =.50 in English-French. These hybrid mappings outperform all the uniform representations (words, lemmas and POS) with statistically significant BLE"
E12-1045,N04-4026,0,0.109614,"Missing"
E12-1045,W08-0320,0,\N,Missing
E12-1045,W05-0909,0,\N,Missing
E12-1045,2011.iwslt-evaluation.1,1,\N,Missing
E12-1045,2011.iwslt-evaluation.11,0,\N,Missing
J16-2001,P06-1067,0,0.21262,"ure 2, the phrase pair [Almlk mHmd AlsAds]-[King Mohamed VI] has monotone orientation whereas [jdd]-[renewed] has discontinuous left orientation with respect to the previously translated phrase. Because of their simple reordering step classification, POM can be conditioned on very finegrained information, such as the whole phrase pair, without suffering too much from data sparseness. However, because POM ignore the distance between consecutively translated phrases, they cannot properly handle long-range reordering phenomena and are typically used with a low distortion limit. Jump models (JM) (Al-Onaizan and Papineni 2006; Green, Galley, and Manning 2010) predict the direction and length of the jump that is performed between consecutively translated words or phrases, with the goal of better handling long-range reordering. Because of data sparseness, JM work best when trained in a discriminative fashion using a variety of binary features (such as the last translated word, its POS tag, and relative position in the sentence) and when length bins are used instead of the exact jump length (Green, Galley, and Manning 2010). A drawback of JM is that they typically over-penalize long jumps because they are more rarely"
J16-2001,W11-2127,0,0.0258221,"Missing"
J16-2001,D14-1132,0,0.031863,"Missing"
J16-2001,J04-4004,0,0.0455168,"Missing"
J16-2001,W09-0434,0,0.0605206,"Missing"
J16-2001,P11-1103,0,0.0647627,"Missing"
J16-2001,D08-1078,0,0.0765434,"Missing"
J16-2001,W10-1735,1,0.842988,"s similarly or better than HSMT for the Arabic-to-English language pair. However, HSMT was shown to better cope with the reordering of VSO sentences (Bisazza 2013). Pre-ordering of Arabic VSO sentences for translation into English has proved to 1 7 Pre-verbal negation can be omitted in colloquial French. 190 Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation be a particularly difficult task (Green, Sathi, and Manning 2009; Carpuat, Marton, and Habash 2010) and has inspired work on hybrid pre-ordering where multiple verb pre-orderings are fed to a PSMT decoder (Bisazza and Federico 2010; Andreas, Habash, and Rambow 2011); see also Section 2.4. English and Turkish [ Main order: different; CDiff: 5.5; PDiff: 1.5 ] Turkish is a good example of head-final language, except for the fact that it can use both clause-final and clause-initial subordinators.18 As a result, almost all clause-level features are discordant in this pair. At the phrase level, Turkish mainly differs from English for the use of postpositions instead of prepositions. Among our language pairs, this is one of the most difficult to reorder for an SMT system. The complex nature of its reordering phenomena suggests"
J16-2001,P12-1050,1,0.842953,"is adopted by Bisazza and Federico (2010) and to-HFE translation and 2) HFE-to-English postAndreas, Habash, and Rambow (2011): Rules are used to generate multiple likely preordering. butWe achieved significant orderings, only for specific language improvements phenomena that are responsible for difficult (long-range) reordering patterns. The sparse reordering lattices produced by these techfrom baseline (phrase-based, hierarchical phraseniques are then translated by a decoder performing additional based, and string-to-tree) translation methods by phrase-based reordering. In a follow-up work, Bisazza and Federico (2012) introduce another way to encode 1.56, 0.76, and 2.77 points in BLEU, respectively, multiple pre-orderings of the input: Instead of generating a word lattice, pre-computed in the experiment of patent by translation. permutations are represented a modified distortion matrix so that lower distortion costs or “shortcuts” are permitted selectedaspairs The remainder of this paperbetween is organized fol-of input positions. Pre-ordering methods can also be classified by the kind of pre-ordering rules that lows. Section 2 briefly reviews related studies on the they apply: that is, manually written ba"
J16-2001,2012.eamt-1.42,0,0.044209,"Missing"
J16-2001,J90-2002,0,0.21784,"Missing"
J16-2001,J93-2003,0,0.105778,"Missing"
J16-2001,2010.jeptalnrecital-long.30,0,0.0817498,"Missing"
J16-2001,J04-2004,0,0.0240884,"ing model by relative frequency or maximum entropy and using its score as one dense feature function, Cherry (2013) introduces sparse phrase orientation features that are directly added to the model score during decoding (cf. Equation (1)) and optimized jointly with all other SMT feature weights. Effective sparse reordering features can be obtained by simply coupling a phrase pair’s orientation with the first or last word (or word class) of its source and target side (Cherry 2013), or even with the whole phrase pair identity (Auli, Galley, and Gao 2014). 2.2 n-gram Based SMT n-gram based SMT (Casacuberta and Vidal 2004; Mariño et al. 2006) is a string-based alternative to PSMT. In this framework, smoothed n-gram models are learned over sequences of minimal translation units (called tuples), which, like phrase pairs, are pairs of word sequences extracted from word-aligned parallel sentences. Tuples, however, are typically shorter than phrase pairs and are extracted from a unique, monotonic segmentation of the sentence pair. Thus, the problem of spurious phrase segmentation is avoided but non-local reordering becomes an issue. For instance, in Figure 2, a monotonic phrase segmentation could be achieved only b"
J16-2001,2014.iwslt-evaluation.1,1,0.641125,"el, German predominantly places the genitive after the noun, while English displays both orders. Thus, despite belonging to the same family branch (Indo-European/Germanic), this pair displays complex reordering patterns. Indeed, German–English reordering has been widely studied in SMT and is still an open topic. At the Workshop on Statistical Machine Translation 2014 (Bojar et al. 2014), a syntaxbased string-to-tree SMT approach (Williams et al. 2014) won in both language directions (official results excluding online systems). At the International Workshop on Spoken Language Translation 2014 (Cettolo et al. 2014), the best submission was a combination of PSMT with POS- and syntax-based preordering (Slawik et al. 2014), string-to-tree syntax-based SMT, and factored PSMT (Birch et al. 2014). English and French [ Main order: same; CDiff: 0.5; PDiff: 1.5 ] Most clause-level features have the same values in French as in English, except for the negation, which is typically expressed by two words in French: one preceding and one following the verb.17 At the phrase level, differences are found in the location of genitives and adjectives. Thus, English and French have very similar clause-level orders, but reor"
J16-2001,P07-1002,0,0.0223343,"et al. 2009) are added to the treebank data and used to re-train the baseline parser. 2.4.5 Post-ordering. A somewhat smaller line of research has instead treated reordering as post-processing. In Bangalore and Riccardi (2000) and Sudoh et al. (2011), target words are reordered after a monotonic translation process. Other work has focused on rescoring a set of n-best translation candidates produced by a regular PSMT decoder— for instance, by means of POS-based reordering templates (Chen, Cettolo, and Federico 2006) or word-class specific distortion models (Gupta, Cettolo, and Federico 2007). Chang and Toutanova (2007) use a dependency tree reordering model to generate n alternative orders for each 1-best sentence produced by the SMT system. Each set of n sentence reorderings is then reranked using a discriminative model trained on word bigram features and standard word reordering features (i.e., distance or orientation between consecutively translated input words). Focusing on Japanese-to-English translation, Sudoh et al. (2011, 2013) proposed to “translate” foreign-order English into correct-order English using a monolingual phrase-based (Sudoh et al. 2011) or syntax-based (Sudoh et al. 2013) SMT system t"
J16-2001,2006.iwslt-papers.4,1,0.832764,"Missing"
J16-2001,P08-1009,0,0.0145689,"o generate inconsistent constraints leading to decoding dead-ends. Bisazza and Federico (2013a) further develop this idea so that only long reorderings predicted by a specific reordering model are explored by the decoder. This form of early reordering pruning enables the PSMT system to capture long-range reordering without hurting efficiency and is not affected by the constraint inconsistency problem. When available, a parse tree of the input may also be used to constrain PSMT reordering, following the principle of syntactic cohesion (Fox 2002). Concretely, the dependency cohesion constraint (Cherry 2008) states that when part of a source subtree is translated, all words under the same subtree must be covered before moving to words outside of it. Integrated in phrase-based decoding as soft constraints (i. e., by using the number of violations as a feature function), dependency cohesion and its variants (Cherry 2008; Bach, Vogel, and Cherry 2009) were shown to significantly improve translation quality. In related work, Feng, Sun, and Ney (2012) derive similar cohesion constraints from the semantic role labeling structure of the input sentence. The divide-and-translate approach of Sudoh et al. ("
J16-2001,N13-1003,0,0.0606426,"in a generative (gener.) or discriminative (discr.) way. All examples refer to the sentence pair shown in Figure 2. Reordering models References Model type Reordering step classification Features Phrase orientation models (POM): Example: P(orient=discontinuous-left |next-phrase-pair=[jdd]-[renewed]) lexicalized (hierarchical) phrase orientation model Tillmann 2004; Koehn et al. 2005; Nagata et al. 2006; Galley & Manning 2008 gener. monotonic, swap, source/target phrases discontinuous (left or right) phrase orientation maxent classifier Zens & Ney 2006 discr. sparse phrase orientation features Cherry 2013 discr. source/target words or word clusters Jump models (JM): Example: P(jump=−5 |from=AlsAds, to=jdd ) inbound/outbound/pairwise Al-Onaizan & Papineni lexicalized distortion 2006 gener. jump length inbound/outbound length-bin classifier discr. Green et al. 2010 source words jump length based source words, POS, (9 length bins) position; sent. length Source decoding sequence models (SDSM): Example: P(next-word=jdd |prev-translated-words=AlEahil Almlk mHmd AlsAds) reordered source n-gram Feng et al. 2010a gener. source word-after-word Bisazza & Federico 2013; discr. Goto et al. 2013 — source wo"
J16-2001,W12-3125,0,0.0266987,"Missing"
J16-2001,P05-1033,0,0.0495033,"ng treelet pairs and order templates are combined to construct lexicalized translation rules for that sentence and, finally, decoding is performed with a chart parsing algorithm. We will now discuss SMT frameworks that model translation as a process of parallel parsing of the source and target language via a synchronous grammar. 2.3.2 Tree-Based SMT Without Syntax. The idea of extracting bilingual translation (i.e., synchronous) grammars directly from word-aligned parallel data originates in early work on ITG by Wu (1996, 1997). In a more mature approach, hierarchical phrase-based SMT (HSMT) (Chiang 2005), the translation model is a probabilistic synchronous context-free grammar (SCFG) whose rules can correspond to arbitrary (i.e., nonsyntactically motivated) phrases labeled by only two generic non-terminal symbols (X or S). As shown in Figure 5, HSMT translation rules can either include a mix of terminals and non-terminals capturing reordering patterns and discontinuities (rules 1–4), or only terminals (rules 7–10) basically corresponding to phrase pairs in string-based PSMT. Finally, the so-called glue rules (5–6) Hiero& are always added to the grammar to combine translated blocks in a monot"
J16-2001,D08-1024,0,0.0171774,"Missing"
J16-2001,P05-1066,0,0.0630099,"Missing"
J16-2001,W06-1609,0,0.437444,"ntext. Figure 7 (Sudoh et al. 2011) illustrates the workflows of pre- and post-ordering approaches as opposed to standard SMT. 2.4.1 Main Pre-ordering Strategies. A large number of pre-ordering strategies have been proposed. As a first classification, we divide them into deterministic, non-deterministic, and hybrid. Deterministic pre-ordering aims at finding a single optimal permutation of the input sentence, which is then translated monotonically or with a low distortion limit (Nießen and Ney 2001; Xia and McCord 2004; Collins, Koehn, and Kucerova 2005; Popovi´c and Ney 2006; Costa-jussà and Fonollosa 2006; Wang, Collins, and Koehn 2007; 177 d order ng synlies anng techble, we n which s. for this e name ntences ces and et landifferirection nguage, e posthe preologies. st idene postng diford orrdering ed sena SMT and tarmodels ly genes. We ces and rain the “correct ach has op new od pret it can ave pre. ation in g transdirec10) prong rules Computational Linguistics [Source language] (c1) monotone translation in source word order [Source-ordered target] Words : source Word order : source (b1) pre-ordering Volume 42, Number 2 Words : target Word order : source (a) standard translation (c2) post-or"
J16-2001,N04-4038,0,0.00961171,"Missing"
J16-2001,P05-1067,0,0.00680197,"specific categories. For instance, the swap of Alr}ys Alfrnsy may only be dictated by a rule applying to noun phrases composed of a noun and an adjective. On the other hand, string-to-tree methods (Yamada and Knight 2002; Galley et al. 2004; Marcu et al. 2006; Shen, Xu, and Weischedel 2010) use syntax as a way to restrict translation hypotheses to well-formed target language sentences—ruling out, for instance, a translation that fails to reorder the translated verb renewed with respect to its subject. Using syntax on both source and target sides (treeto-tree) (Imamura, Okuma, and Sumita 2005; Ding and Palmer 2005; Smith and Eisner 2006; Watanabe, Tsukada, and Isozaki 2006; Zhang et al. 2008) has proven rather difficult in practice due to the complexity of aligning potentially very different tree topologies and to the large size of the resulting translation grammars. Moreover, the need for highquality parsers in both language sides seriously limits the applicability of this approach. Syntax-based SMT approaches also differ in the formalism they use to represent the trees. Those based on phrase structure (constituency) grammars typically comply with the principle that each translation/reordering rule sh"
J16-2001,2010.amta-papers.22,0,0.209269,"led IBM constraints. A different kind of reordering constraint can be derived from the Inversion Transduction Grammars (ITGs) (Wu 1995, 1997). ITG constraints only admit permutations 167 Computational Linguistics Volume 42, Number 2 that are generated by recursively swapping pairs of adjacent blocks of words.4 In particular, ITG constraints disallow reorderings that generalize the patterns (3 1 4 2) and (2 4 1 3), which are rarely attested in natural languages (Wu 1997).5 Enforcing ITG constraints in left-to-right PSMT decoding requires the use of a shift-reduce permutation parser (Zens 2008; Feng et al. 2010). Alternatively, a relaxed version of the ITG constraints (i.e., Baxter permutations) may be enforced by simply inspecting the set of covered source positions, as proposed by Zens et al. (2004) and Zens (2008). Interestingly, Cherry, Moore, and Quirk (2012) found no consistent benefit from applying either exact or approximate ITG-constraints to a PSMT system that already included a hierarchical phrase orientation model6 (Galley and Manning 2008). The reordering constraints presented so far are not sensitive to the words being translated nor to their context. This results in a very coarse defin"
J16-2001,P13-1032,0,0.0478629,"Missing"
J16-2001,C12-1053,0,0.0507379,"Missing"
J16-2001,C10-2033,0,0.131191,"led IBM constraints. A different kind of reordering constraint can be derived from the Inversion Transduction Grammars (ITGs) (Wu 1995, 1997). ITG constraints only admit permutations 167 Computational Linguistics Volume 42, Number 2 that are generated by recursively swapping pairs of adjacent blocks of words.4 In particular, ITG constraints disallow reorderings that generalize the patterns (3 1 4 2) and (2 4 1 3), which are rarely attested in natural languages (Wu 1997).5 Enforcing ITG constraints in left-to-right PSMT decoding requires the use of a shift-reduce permutation parser (Zens 2008; Feng et al. 2010). Alternatively, a relaxed version of the ITG constraints (i.e., Baxter permutations) may be enforced by simply inspecting the set of covered source positions, as proposed by Zens et al. (2004) and Zens (2008). Interestingly, Cherry, Moore, and Quirk (2012) found no consistent benefit from applying either exact or approximate ITG-constraints to a PSMT system that already included a hierarchical phrase orientation model6 (Galley and Manning 2008). The reordering constraints presented so far are not sensitive to the words being translated nor to their context. This results in a very coarse defin"
J16-2001,D09-1117,0,0.0316319,"Missing"
J16-2001,W02-1039,0,0.619559,"L after that position. Unfortunately, this method appears to generate inconsistent constraints leading to decoding dead-ends. Bisazza and Federico (2013a) further develop this idea so that only long reorderings predicted by a specific reordering model are explored by the decoder. This form of early reordering pruning enables the PSMT system to capture long-range reordering without hurting efficiency and is not affected by the constraint inconsistency problem. When available, a parse tree of the input may also be used to constrain PSMT reordering, following the principle of syntactic cohesion (Fox 2002). Concretely, the dependency cohesion constraint (Cherry 2008) states that when part of a source subtree is translated, all words under the same subtree must be covered before moving to words outside of it. Integrated in phrase-based decoding as soft constraints (i. e., by using the number of violations as a feature function), dependency cohesion and its variants (Cherry 2008; Bach, Vogel, and Cherry 2009) were shown to significantly improve translation quality. In related work, Feng, Sun, and Ney (2012) derive similar cohesion constraints from the semantic role labeling structure of the input"
J16-2001,N04-1035,0,0.0564172,"ing methods (Huang, Knight, and Joshi 2006; Liu, Liu, and Lin 2006) use a given input sentence parse tree to restrict the application of translation/reordering rules to word 8 More pre-ordering techniques will be discussed in Section 2.4. 172 Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation spans that coincide with syntactic constituents of specific categories. For instance, the swap of Alr}ys Alfrnsy may only be dictated by a rule applying to noun phrases composed of a noun and an adjective. On the other hand, string-to-tree methods (Yamada and Knight 2002; Galley et al. 2004; Marcu et al. 2006; Shen, Xu, and Weischedel 2010) use syntax as a way to restrict translation hypotheses to well-formed target language sentences—ruling out, for instance, a translation that fails to reorder the translated verb renewed with respect to its subject. Using syntax on both source and target sides (treeto-tree) (Imamura, Okuma, and Sumita 2005; Ding and Palmer 2005; Smith and Eisner 2006; Watanabe, Tsukada, and Isozaki 2006; Zhang et al. 2008) has proven rather difficult in practice due to the complexity of aligning potentially very different tree topologies and to the large size"
J16-2001,D08-1089,0,0.215595,"d in natural languages (Wu 1997).5 Enforcing ITG constraints in left-to-right PSMT decoding requires the use of a shift-reduce permutation parser (Zens 2008; Feng et al. 2010). Alternatively, a relaxed version of the ITG constraints (i.e., Baxter permutations) may be enforced by simply inspecting the set of covered source positions, as proposed by Zens et al. (2004) and Zens (2008). Interestingly, Cherry, Moore, and Quirk (2012) found no consistent benefit from applying either exact or approximate ITG-constraints to a PSMT system that already included a hierarchical phrase orientation model6 (Galley and Manning 2008). The reordering constraints presented so far are not sensitive to the words being translated nor to their context. This results in a very coarse definition of the reordering search space, which is problematic in language pairs with different syntactic structures. To address this problem, Yahyaei and Monz (2009) propose decoupling local and global reordering by segmenting the input sentence into chunks that can be permuted arbitrarily, but each of which is translated monotonically. In related work, Yahyaei and Monz (2010) present a technique to dynamically set the DL during decoding: They trai"
J16-2001,D11-1079,0,0.0375711,"Missing"
J16-2001,C10-1043,0,0.0440401,"rds : source Word order : source (b1) pre-ordering Volume 42, Number 2 Words : target Word order : source (a) standard translation (c2) post-ordering [Target language] [Target-ordered source] Words : source (b2) Word order : target monotone translation in target word order Words : target Word order : target Figure 7 Figure 1: A typical work flow in a standard translation, Typical workflows of standard, pre-ordering, and post-ordering approaches to SMT. Taken from pre-ordering and post-ordering approach. Sudoh et al. (2011). Habash 2007; Li et al. 2007; Tromble and Eisner 2009; Xu et al. 2009; Genzel 2010; the opposite direction by placing Japanese syntac-and Fonollosa 2011; Khalilov Isozaki et al. 2010b; Yeniterzi and Oflazer 2010; Khalilov and Sima’an 2011; Visweswariah et al. 2011; Gojun and Fraser 2012; Yang et al. 2012; tic heads in the middle is not a trivial problem. Lerner and Petrov 2013; Jehl et al. 2014).10 Non-deterministic pre-ordering encodes We utilize the Head-Finalization rules to genermultiple alternative reorderings into a word lattice and lets a monotonic (usually ate intermediate head-finalized English sentencesto its models (Zens, Och, and n-gram–based) decoder choose the"
J16-2001,E12-1074,0,0.0220821,"lly and practically challenging problem in SMT. In the early period 10 Li et al. (2007) experiment with a small number of n-best pre-orderings given as alternative inputs to the of SMT SMT studies, reordering is modeled by distancesystem. based constraints in translation model (Brown et al., 1993; Koehn et al., 2003). This reordering model 178 is easy to compute and also works well in relatively similar language pair like French-to-English. Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation are applied to constituency parse trees. Following a similar approach, Gojun and Fraser (2012) develop a set of rules for the opposite translation direction (English-to-German). Xu et al. (2009) instead propose a simple set of dependency-based rules to pre-order English for translation into subject-object-verb (SOV) languages, which is shown to be effective for Korean, Japanese, Hindi, Urdu, and Turkish. Isozaki et al. (2010b) obtain even better results in an English-to-Japanese task using only one pre-ordering rule (i.e., head finalization) with a parser annotating syntactic heads. 2.4.3 Data-Driven Pre-ordering. This kind of model is learned from sets of pairs (f, f0 ) where f is a s"
J16-2001,P12-2061,0,0.0303757,"Missing"
J16-2001,N10-1129,0,0.0158044,"ous-left |next-phrase-pair=[jdd]-[renewed]) lexicalized (hierarchical) phrase orientation model Tillmann 2004; Koehn et al. 2005; Nagata et al. 2006; Galley & Manning 2008 gener. monotonic, swap, source/target phrases discontinuous (left or right) phrase orientation maxent classifier Zens & Ney 2006 discr. sparse phrase orientation features Cherry 2013 discr. source/target words or word clusters Jump models (JM): Example: P(jump=−5 |from=AlsAds, to=jdd ) inbound/outbound/pairwise Al-Onaizan & Papineni lexicalized distortion 2006 gener. jump length inbound/outbound length-bin classifier discr. Green et al. 2010 source words jump length based source words, POS, (9 length bins) position; sent. length Source decoding sequence models (SDSM): Example: P(next-word=jdd |prev-translated-words=AlEahil Almlk mHmd AlsAds) reordered source n-gram Feng et al. 2010a gener. source word-after-word Bisazza & Federico 2013; discr. Goto et al. 2013 — source words (9-gram context) — source words, POS; source context’s words and POS Operation sequence models (OSM): Example: P(next − operation = generate[jdd,renewed] |prev-operations=generate[AlsAds,VI] jumpBack[1]) translation/reordering operation n-gram Durrani et al."
J16-2001,2009.mtsummit-caasl.4,0,0.0190353,"Missing"
J16-2001,2007.mtsummit-papers.28,1,0.833171,"Missing"
J16-2001,2007.mtsummit-papers.29,0,0.437369,") monotone translation in source word order [Source-ordered target] Words : source Word order : source (b1) pre-ordering Volume 42, Number 2 Words : target Word order : source (a) standard translation (c2) post-ordering [Target language] [Target-ordered source] Words : source (b2) Word order : target monotone translation in target word order Words : target Word order : target Figure 7 Figure 1: A typical work flow in a standard translation, Typical workflows of standard, pre-ordering, and post-ordering approaches to SMT. Taken from pre-ordering and post-ordering approach. Sudoh et al. (2011). Habash 2007; Li et al. 2007; Tromble and Eisner 2009; Xu et al. 2009; Genzel 2010; the opposite direction by placing Japanese syntac-and Fonollosa 2011; Khalilov Isozaki et al. 2010b; Yeniterzi and Oflazer 2010; Khalilov and Sima’an 2011; Visweswariah et al. 2011; Gojun and Fraser 2012; Yang et al. 2012; tic heads in the middle is not a trivial problem. Lerner and Petrov 2013; Jehl et al. 2014).10 Non-deterministic pre-ordering encodes We utilize the Head-Finalization rules to genermultiple alternative reorderings into a word lattice and lets a monotonic (usually ate intermediate head-finalized English s"
J16-2001,W10-1710,1,0.88774,"Missing"
J16-2001,hasan-ney-2008-multi,0,0.0143221,"rch, Blunsom, and Osborne 2009). It is worth noting that translation between Chinese and English has been the main motivation and test bed for the development of HSMT. French and Arabic [ Main order: different; CDiff: 1.5; PDiff: 1 ] At the clause level, this pair differs in main word order (SVO versus VSO or SVO) like the English–Arabic pair, but also in the order of negation and verb. On the other hand, phrase-level order is notably more similar, with only one discordant feature of minor importance (adjective and degree word). Less research was published on this language pair. Nevertheless, Hasan and Ney (2008) and Schwenk and Senellart (2009) chose a PSMT approach to experiment with an Arabic-to-French task. Figure 8 illustrates the reordering characteristics of three language pairs by means of sentence examples that were automatically word-aligned with GIZA++ (Och and Ney 2003) (intersection of direct and inverse alignments). In the first row, we see two English–German sentence pairs; in both cases, most of the points lie close to the diagonal representing an overall monotonic translation, whereas few isolated points denote the very long-range reordering of verbs. Similarly, in the two English–Ara"
J16-2001,D13-1139,0,0.0212233,"The underlying motivation is that, while English-to-Japanese is well handled by pre-ordering with the aforementioned head-finalization rule (Isozaki et al. 2010b), it is much harder to predict the English-like order of Japanese constituents for Japanese-to-English translation. Post-ordering addresses this issue by generating head-final English (HFE) sentences that are used to create a HFE-to-English parallel corpus. Goto, Utiyama, and Sumita (2012, 2013) solve post-ordering by parsing the HFE sentences into binary trees annotated with both syntactic labels and ITG-style monotone/swap labels. Hayashi et al. (2013) improve upon this work with a shiftreduce parser that efficiently integrates non-local features like n-grams of the postordered string. Also related to post-ordering is the work on right-to-left or reverse decoding by Watanabe and Sumita (2002), Finch and Sumita (2009), and Freitag et al. (2013). Here, the target sentence is built up from the last word to the first, thereby altering language model context and reordering search space. Finch and Sumita obtain best results on a wide range of language pairs by combining the outputs of standard and reverse decoding systems. 3. Evaluating Word Reor"
J16-2001,P11-2067,0,0.0289348,"Missing"
J16-2001,2006.amta-papers.8,0,0.0999394,"Missing"
J16-2001,D13-1053,0,0.0262152,"Missing"
J16-2001,W13-2258,0,0.0124887,"on on the whole phrase pair, the classifier uses features extracted from it, such as first and last word (or POS tag) of the source and target side. A similar model was first developed by Xiong, Liu, and Lin (2006) for simpler phrase translation models (i.e., without discontinuities) based on ITG. Li, Liu, and Sun (2013) use recursive autoencoders (Socher et al. 2011) to assign vector representations to the neighboring phrases given as input to the ITG classifier, thereby avoiding manual feature engineering but affecting hypothesis recombination and decoding speed. Nguyen and Vogel (2013) and Huck et al. (2013) successfully integrate the distortion cost feature function and phrase orientation models initially designed for string-based PSMT into a chart-based HSMT decoder. Finally, Setiawan, Kan, and Li (2007) observe that, in languages like Chinese and English, function words provide important clues on the grammatical relationships among phrases. Consequently, they introduce a SCFG where function words (approximated by high-frequency words) are the only lexicalized non-terminals guiding phrase reordering. Based on the same intuition, Setiawan et al. (2009) augment a HSMT system with a function-word"
J16-2001,2005.mtsummit-papers.35,0,0.0266991,"Missing"
J16-2001,D10-1092,0,0.00858649,"Missing"
J16-2001,W10-1736,0,0.498296,"rder : source (a) standard translation (c2) post-ordering [Target language] [Target-ordered source] Words : source (b2) Word order : target monotone translation in target word order Words : target Word order : target Figure 7 Figure 1: A typical work flow in a standard translation, Typical workflows of standard, pre-ordering, and post-ordering approaches to SMT. Taken from pre-ordering and post-ordering approach. Sudoh et al. (2011). Habash 2007; Li et al. 2007; Tromble and Eisner 2009; Xu et al. 2009; Genzel 2010; the opposite direction by placing Japanese syntac-and Fonollosa 2011; Khalilov Isozaki et al. 2010b; Yeniterzi and Oflazer 2010; Khalilov and Sima’an 2011; Visweswariah et al. 2011; Gojun and Fraser 2012; Yang et al. 2012; tic heads in the middle is not a trivial problem. Lerner and Petrov 2013; Jehl et al. 2014).10 Non-deterministic pre-ordering encodes We utilize the Head-Finalization rules to genermultiple alternative reorderings into a word lattice and lets a monotonic (usually ate intermediate head-finalized English sentencesto its models (Zens, Och, and n-gram–based) decoder choose the best path according called Head-Final andMariño decompose Ney 2002; Kanthak etEnglish al. 2005; (HF"
J16-2001,E14-1026,0,0.138313,"Missing"
J16-2001,W05-0831,0,0.0991336,"Missing"
J16-2001,D11-1017,0,0.0134501,"ng model is trained to maximize the likelihood of source trees that can generate such reorderings. Finally, a pre-ordering model is trained to permute each node in the tree. Evaluated on the English–Japanese language pair, this method almost equals the performance of a pre-ordering method based on a supervised parser. Neubig, Watanabe, and Mori (2012) follow a similar approach but build a single ITG-style pre-ordering model treating the parse tree as a 180 Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation latent variable. In the target self-training method of Katz-Brown et al. (2011), a baseline treebank-trained parser is used to produce n-best parses of a parallel corpus’s source side. Then, the parses resulting in the most accurate pre-ordering after application of a dependency-based pre-ordering rule set (Xu et al. 2009) are added to the treebank data and used to re-train the baseline parser. 2.4.5 Post-ordering. A somewhat smaller line of research has instead treated reordering as post-processing. In Bangalore and Riccardi (2000) and Sudoh et al. (2011), target words are reordered after a monotonic translation process. Other work has focused on rescoring a set of n-be"
J16-2001,I11-1005,0,0.047333,"Missing"
J16-2001,J99-4005,0,0.363405,"e division of reordering patterns into long range, or global, and short range, or local. However, other language pairs display more complex, hierarchical patterns. Word reordering phenomena are naturally handled by human translators1 but are a major source of complexity for SMT. In very general terms, the task of SMT consists of breaking the input sentence into smaller units, selecting an optimal translation for each unit, and placing them in the correct order. Searching for the overall best translation throughout the space of all possible reorderings is, however, computationally intractable (Knight 1999). This crucial fact has motivated an impressive amount of research around two inter-related questions: namely, how to effectively restrict the set of allowed word permutations and how to detect the best permutation among them. Existing solutions to these problems range from heuristic constraints, based on word-to-word distances and completely agnostic about the sentence content, to linguistically motivated SMT frameworks where the entire translation process is guided by syntactic structure. The research in word reordering has advanced together with core SMT research and has sometimes directed"
J16-2001,2005.iwslt-1.8,0,0.065623,"t yet to be incurred (Moore and Quirk 2007). State-of-the-art systems use the distortion cost in combination with more sophisticated reordering models that take into account the identity of the reordered phrases and, optionally, various kinds of contextual information. A representative selection of such models is summarized in Table 1. To ease the presentation, we have divided the models into four groups according to their problem formulation: phrase orientation models, jump models, source decoding sequence models, and operation sequence models. Phrase orientation models (POM) (Tillmann 2004; Koehn et al. 2005; Nagata et al. 2006; Zens and Ney 2006; Li et al. 2014), simply known as lexicalized reordering models, predict whether the next translated source span should be immediately to the right (monotone), immediately to the left (swap), or anywhere else (discontinuous) relatively to the last translated one.7 For example, in Figure 2, the phrase pair [Almlk mHmd AlsAds]-[King Mohamed VI] has monotone orientation whereas [jdd]-[renewed] has discontinuous left orientation with respect to the previously translated phrase. Because of their simple reordering step classification, POM can be conditioned on"
J16-2001,N03-1017,0,0.0194014,"early example of syntax-based pre-ordering, Collins, Koehn, and Kucerova (2005) 2 Related propose a set ofWork six rules aimed at arranging German sentences in English-like order. The rules address the position of verbs, verb particles, and negation particles, and they Reordering is a both theoretically and practically challenging problem in SMT. In the early period 10 Li et al. (2007) experiment with a small number of n-best pre-orderings given as alternative inputs to the of SMT SMT studies, reordering is modeled by distancesystem. based constraints in translation model (Brown et al., 1993; Koehn et al., 2003). This reordering model 178 is easy to compute and also works well in relatively similar language pair like French-to-English. Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation are applied to constituency parse trees. Following a similar approach, Gojun and Fraser (2012) develop a set of rules for the opposite translation direction (English-to-German). Xu et al. (2009) instead propose a simple set of dependency-based rules to pre-order English for translation into subject-object-verb (SOV) languages, which is shown to be effective for Korean, Japanese, Hindi,"
J16-2001,D13-1049,0,0.156843,"et Word order : target Figure 7 Figure 1: A typical work flow in a standard translation, Typical workflows of standard, pre-ordering, and post-ordering approaches to SMT. Taken from pre-ordering and post-ordering approach. Sudoh et al. (2011). Habash 2007; Li et al. 2007; Tromble and Eisner 2009; Xu et al. 2009; Genzel 2010; the opposite direction by placing Japanese syntac-and Fonollosa 2011; Khalilov Isozaki et al. 2010b; Yeniterzi and Oflazer 2010; Khalilov and Sima’an 2011; Visweswariah et al. 2011; Gojun and Fraser 2012; Yang et al. 2012; tic heads in the middle is not a trivial problem. Lerner and Petrov 2013; Jehl et al. 2014).10 Non-deterministic pre-ordering encodes We utilize the Head-Finalization rules to genermultiple alternative reorderings into a word lattice and lets a monotonic (usually ate intermediate head-finalized English sentencesto its models (Zens, Och, and n-gram–based) decoder choose the best path according called Head-Final andMariño decompose Ney 2002; Kanthak etEnglish al. 2005; (HFE) Crego and 2006; Zhang, Zens, and Ney 2007; Rottmann and Vogel 2007; Crego and Habash 2008; Elming and Habash 2009; Niehues Japanese-to-English translation into 1) Japaneseand Kolss 2009). A hybr"
J16-2001,P07-1091,0,0.426577,"anslation in source word order [Source-ordered target] Words : source Word order : source (b1) pre-ordering Volume 42, Number 2 Words : target Word order : source (a) standard translation (c2) post-ordering [Target language] [Target-ordered source] Words : source (b2) Word order : target monotone translation in target word order Words : target Word order : target Figure 7 Figure 1: A typical work flow in a standard translation, Typical workflows of standard, pre-ordering, and post-ordering approaches to SMT. Taken from pre-ordering and post-ordering approach. Sudoh et al. (2011). Habash 2007; Li et al. 2007; Tromble and Eisner 2009; Xu et al. 2009; Genzel 2010; the opposite direction by placing Japanese syntac-and Fonollosa 2011; Khalilov Isozaki et al. 2010b; Yeniterzi and Oflazer 2010; Khalilov and Sima’an 2011; Visweswariah et al. 2011; Gojun and Fraser 2012; Yang et al. 2012; tic heads in the middle is not a trivial problem. Lerner and Petrov 2013; Jehl et al. 2014).10 Non-deterministic pre-ordering encodes We utilize the Head-Finalization rules to genermultiple alternative reorderings into a word lattice and lets a monotonic (usually ate intermediate head-finalized English sentencesto its m"
J16-2001,W12-3128,0,0.0292487,"Missing"
J16-2001,D13-1054,0,0.00598118,"Missing"
J16-2001,C14-1179,0,0.0394367,"art systems use the distortion cost in combination with more sophisticated reordering models that take into account the identity of the reordered phrases and, optionally, various kinds of contextual information. A representative selection of such models is summarized in Table 1. To ease the presentation, we have divided the models into four groups according to their problem formulation: phrase orientation models, jump models, source decoding sequence models, and operation sequence models. Phrase orientation models (POM) (Tillmann 2004; Koehn et al. 2005; Nagata et al. 2006; Zens and Ney 2006; Li et al. 2014), simply known as lexicalized reordering models, predict whether the next translated source span should be immediately to the right (monotone), immediately to the left (swap), or anywhere else (discontinuous) relatively to the last translated one.7 For example, in Figure 2, the phrase pair [Almlk mHmd AlsAds]-[King Mohamed VI] has monotone orientation whereas [jdd]-[renewed] has discontinuous left orientation with respect to the previously translated phrase. Because of their simple reordering step classification, POM can be conditioned on very finegrained information, such as the whole phrase"
J16-2001,P06-1077,0,0.0297579,"Missing"
J16-2001,W14-4002,0,0.0217398,"Missing"
J16-2001,W06-1606,0,0.0317476,"Knight, and Joshi 2006; Liu, Liu, and Lin 2006) use a given input sentence parse tree to restrict the application of translation/reordering rules to word 8 More pre-ordering techniques will be discussed in Section 2.4. 172 Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation spans that coincide with syntactic constituents of specific categories. For instance, the swap of Alr}ys Alfrnsy may only be dictated by a rule applying to noun phrases composed of a noun and an adjective. On the other hand, string-to-tree methods (Yamada and Knight 2002; Galley et al. 2004; Marcu et al. 2006; Shen, Xu, and Weischedel 2010) use syntax as a way to restrict translation hypotheses to well-formed target language sentences—ruling out, for instance, a translation that fails to reorder the translated verb renewed with respect to its subject. Using syntax on both source and target sides (treeto-tree) (Imamura, Okuma, and Sumita 2005; Ding and Palmer 2005; Smith and Eisner 2006; Watanabe, Tsukada, and Isozaki 2006; Zhang et al. 2008) has proven rather difficult in practice due to the complexity of aligning potentially very different tree topologies and to the large size of the resulting tr"
J16-2001,J06-4004,0,0.0856055,"Missing"
J16-2001,P08-1114,0,0.0093755,"he translation model is fully based on the syntactic parse tree of the source or target sentence (Section 2.3.1) or where syntax is not used at all (Section 2.3.2). A third line of work bridges between these two by exploiting syntactic information in the form of soft constraints while operating with a synchronous translation grammar extracted from non-parsed parallel data. Chiang (2005) first experimented with a feature function rewarding translation rules applied to full syntactic constituents (constituent feature). Although this initial attempt did not appear to improve translation quality, Marton and Resnik (2008) further elaborated the idea and proposed a series of finer-grained features distinguishing among 9 Two other models utilizing function words as the anchors of global reordering decisions are proposed in Setiawan et al. (2013) and Setiawan, Zhou, and Xiang (2013). Although integrated in a syntax-based system (Shen, Xu, and Weischedel 2010), these models are in principle applicable to other SMT frameworks such as HSMT. 176 Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation constituent types (VP, NP, etc.), eventually leading to better performance. Gao, Koehn, an"
J16-2001,W07-0701,0,0.0161184,"t pair (3) determines the swapping of jdd and AlEAhl but does not specify the ordering of dEm, which is also a child of jdd. Hence, during decoding, all possible reorderings of the unmatched children are considered and scored by a separate discriminative model, predicting the position of a child node (or modifier m) relative to its head h, given lexical, POS, and positional features of m and h. Reordering modeling is thus largely decoupled from lexical selection, which makes the model very flexible but results in a very large search space and high risk of search errors. To address this issue, Menezes and Quirk (2007) introduce another mechanism to complement treelet reordering: namely, dependency order templates. An order template is an unlexicalized rule specifying the reordering of a node and all its children based on their POS tags. For instance, in Figure 4, treelet pair (3) may be combined with template (a) to specify the order of the child dEm. For each new test sentence, matching treelet pairs and order templates are combined to construct lexicalized translation rules for that sentence and, finally, decoding is performed with a chart parsing algorithm. We will now discuss SMT frameworks that model"
J16-2001,2007.mtsummit-papers.43,0,0.0137911,"word or phrase that was previously translated. The simplest example of reordering feature function is the distortion cost or distortion penalty jump(Ji−1 , Ji ), which by convention assigns zero cost to hypotheses that preserve the order of the source phrases (monotonic translations). During decoding, the basic implementation of distortion cost penalizes long jumps only when they are performed, leading to the proliferation of hypotheses with gaps (i.e., uncovered input positions). This issue can be addressed by incorporating into the distortion cost an estimate of the cost yet to be incurred (Moore and Quirk 2007). State-of-the-art systems use the distortion cost in combination with more sophisticated reordering models that take into account the identity of the reordered phrases and, optionally, various kinds of contextual information. A representative selection of such models is summarized in Table 1. To ease the presentation, we have divided the models into four groups according to their problem formulation: phrase orientation models, jump models, source decoding sequence models, and operation sequence models. Phrase orientation models (POM) (Tillmann 2004; Koehn et al. 2005; Nagata et al. 2006; Zens"
J16-2001,W10-2915,0,0.0569807,"Missing"
J16-2001,P11-1065,0,0.0412683,"Missing"
J16-2001,P06-1090,0,0.217647,"d (Moore and Quirk 2007). State-of-the-art systems use the distortion cost in combination with more sophisticated reordering models that take into account the identity of the reordered phrases and, optionally, various kinds of contextual information. A representative selection of such models is summarized in Table 1. To ease the presentation, we have divided the models into four groups according to their problem formulation: phrase orientation models, jump models, source decoding sequence models, and operation sequence models. Phrase orientation models (POM) (Tillmann 2004; Koehn et al. 2005; Nagata et al. 2006; Zens and Ney 2006; Li et al. 2014), simply known as lexicalized reordering models, predict whether the next translated source span should be immediately to the right (monotone), immediately to the left (swap), or anywhere else (discontinuous) relatively to the last translated one.7 For example, in Figure 2, the phrase pair [Almlk mHmd AlsAds]-[King Mohamed VI] has monotone orientation whereas [jdd]-[renewed] has discontinuous left orientation with respect to the previously translated phrase. Because of their simple reordering step classification, POM can be conditioned on very finegrained in"
J16-2001,D12-1077,0,0.030601,"Missing"
J16-2001,P13-1156,0,0.0126456,"than conditioning the decision on the whole phrase pair, the classifier uses features extracted from it, such as first and last word (or POS tag) of the source and target side. A similar model was first developed by Xiong, Liu, and Lin (2006) for simpler phrase translation models (i.e., without discontinuities) based on ITG. Li, Liu, and Sun (2013) use recursive autoencoders (Socher et al. 2011) to assign vector representations to the neighboring phrases given as input to the ITG classifier, thereby avoiding manual feature engineering but affecting hypothesis recombination and decoding speed. Nguyen and Vogel (2013) and Huck et al. (2013) successfully integrate the distortion cost feature function and phrase orientation models initially designed for string-based PSMT into a chart-based HSMT decoder. Finally, Setiawan, Kan, and Li (2007) observe that, in languages like Chinese and English, function words provide important clues on the grammatical relationships among phrases. Consequently, they introduce a SCFG where function words (approximated by high-frequency words) are the only lexicalized non-terminals guiding phrase reordering. Based on the same intuition, Setiawan et al. (2009) augment a HSMT syste"
J16-2001,W09-0435,0,0.0240666,"rce sentence and f0 is its reference permutation (pre-ordering) inferred from a reference translation e via a word-level alignment.11 These approaches typically require some form of linguistic annotation of the source language, such as syntactic parse trees (Xia and McCord 2004; Habash 2007; Li et al. 2007; Elming and Habash 2009; Genzel 2010; Khalilov and Fonollosa 2011; Khalilov and Sima’an 2011; Yang et al. 2012; Lerner and Petrov 2013; Jehl et al. 2014), shallow syntax chunks (Zhang, Zens, and Ney 2007; Crego and Habash 2008), or POS labels (Crego and Mariño 2006; Rottmann and Vogel 2007; Niehues and Kolss 2009; Tromble and Eisner 2009; Visweswariah et al. 2011). Among the first examples of data-driven tree-based pre-ordering, Xia and McCord (2004) propose a method to automatically learn reordering patterns from a dependencyparsed French–English bitext, using a number of heuristics. While source-side parses are required by their method, target-side parses are optionally used to provide additional constraints during rule extraction. Habash (2007) extracts pre-ordering rules from an Arabic–English parallel corpus dependency-parsed on the source side. In both these works, pre-ordering rules are applied"
J16-2001,2001.mtsummit-papers.45,0,0.100136,"i.e., pre-ordering or post-ordering) in a monolingual fashion and with unconstrained access to the whole sentence context. Figure 7 (Sudoh et al. 2011) illustrates the workflows of pre- and post-ordering approaches as opposed to standard SMT. 2.4.1 Main Pre-ordering Strategies. A large number of pre-ordering strategies have been proposed. As a first classification, we divide them into deterministic, non-deterministic, and hybrid. Deterministic pre-ordering aims at finding a single optimal permutation of the input sentence, which is then translated monotonically or with a low distortion limit (Nießen and Ney 2001; Xia and McCord 2004; Collins, Koehn, and Kucerova 2005; Popovi´c and Ney 2006; Costa-jussà and Fonollosa 2006; Wang, Collins, and Koehn 2007; 177 d order ng synlies anng techble, we n which s. for this e name ntences ces and et landifferirection nguage, e posthe preologies. st idene postng diford orrdering ed sena SMT and tarmodels ly genes. We ces and rain the “correct ach has op new od pret it can ave pre. ation in g transdirec10) prong rules Computational Linguistics [Source language] (c1) monotone translation in source word order [Source-ordered target] Words : source Word order : source"
J16-2001,nivre-etal-2006-maltparser,0,0.0158681,"Missing"
J16-2001,E99-1010,0,0.135134,"med to be locally decomposable to allow for efficient decoding via dynamic programming. Feature weights are tuned discriminatively by directly optimizing translation quality3 on a development set, using parameter tuning techniques such as MERT (Och 2003), MIRA (Chiang, Marton, and Resnik 2008), or PRO (Hopkins and May 2011). 2.1 Phrase-Based SMT Phrase-based SMT (PSMT) is the currently dominant approach in string-based SMT. PSMT ruled out the early word-based SMT framework (Brown et al. 1990, 1993; Berger et al. 1996) thanks to two important novelties: the use of multi-word translation units (Och 1999; Zens, Och, and Ney 2002; Koehn, Och, and Marcu 2003), and the move from a generative to a discriminative modeling framework (Och and Ney 2002). The search process (1) in PSMT is guided by the target string e, built from left to right, and the alignment variable b that embeds both segmentation and reordering of the source phrases. This is defined as b = bI1 = ((J1 , K1 ), (J2 , K2 ), . . . , (JI , KI )) (2) such that K1 , . . . , KI are consecutive intervals partitioning the target word positions, and J1 , . . . , JI are corresponding but not necessarily consecutive intervals partitioning the"
J16-2001,P03-1021,0,0.0651104,"cal mapping (alignment) between f and e, hr (e, f, b) are R arbitrary feature functions and λr the corresponding feature weights. Feature functions try to capture relevant translation adequacy and word reordering aspects from aligned parallel data, as well as translation fluency aspects from monolingual target texts. Moreover, feature functions are assumed to be locally decomposable to allow for efficient decoding via dynamic programming. Feature weights are tuned discriminatively by directly optimizing translation quality3 on a development set, using parameter tuning techniques such as MERT (Och 2003), MIRA (Chiang, Marton, and Resnik 2008), or PRO (Hopkins and May 2011). 2.1 Phrase-Based SMT Phrase-based SMT (PSMT) is the currently dominant approach in string-based SMT. PSMT ruled out the early word-based SMT framework (Brown et al. 1990, 1993; Berger et al. 1996) thanks to two important novelties: the use of multi-word translation units (Och 1999; Zens, Och, and Ney 2002; Koehn, Och, and Marcu 2003), and the move from a generative to a discriminative modeling framework (Och and Ney 2002). The search process (1) in PSMT is guided by the target string e, built from left to right, and the a"
J16-2001,P02-1038,0,0.0466997,"irectly optimizing translation quality3 on a development set, using parameter tuning techniques such as MERT (Och 2003), MIRA (Chiang, Marton, and Resnik 2008), or PRO (Hopkins and May 2011). 2.1 Phrase-Based SMT Phrase-based SMT (PSMT) is the currently dominant approach in string-based SMT. PSMT ruled out the early word-based SMT framework (Brown et al. 1990, 1993; Berger et al. 1996) thanks to two important novelties: the use of multi-word translation units (Och 1999; Zens, Och, and Ney 2002; Koehn, Och, and Marcu 2003), and the move from a generative to a discriminative modeling framework (Och and Ney 2002). The search process (1) in PSMT is guided by the target string e, built from left to right, and the alignment variable b that embeds both segmentation and reordering of the source phrases. This is defined as b = bI1 = ((J1 , K1 ), (J2 , K2 ), . . . , (JI , KI )) (2) such that K1 , . . . , KI are consecutive intervals partitioning the target word positions, and J1 , . . . , JI are corresponding but not necessarily consecutive intervals partitioning the source word positions. A phrase segmentation for our running example is shown in Figure 2. The use of phrases mainly results in a better handli"
J16-2001,J03-1002,0,0.0111105,"ain word order (SVO versus VSO or SVO) like the English–Arabic pair, but also in the order of negation and verb. On the other hand, phrase-level order is notably more similar, with only one discordant feature of minor importance (adjective and degree word). Less research was published on this language pair. Nevertheless, Hasan and Ney (2008) and Schwenk and Senellart (2009) chose a PSMT approach to experiment with an Arabic-to-French task. Figure 8 illustrates the reordering characteristics of three language pairs by means of sentence examples that were automatically word-aligned with GIZA++ (Och and Ney 2003) (intersection of direct and inverse alignments). In the first row, we see two English–German sentence pairs; in both cases, most of the points lie close to the diagonal representing an overall monotonic translation, whereas few isolated points denote the very long-range reordering of verbs. Similarly, in the two English–Arabic sentence pairs, we mostly observe local reorderings, with the exception of few isolated points corresponding to the Arabic clause-initial verbs. Finally, the two Turkish–English examples display global reordering, due to the high number of clause-level order differences"
J16-2001,2001.mtsummit-papers.68,0,0.024586,"ta-jussà and Fonollosa (2006), except that here the monolingual SMT process is applied to the target language after a monotonic translation phase. 181 Computational Linguistics Volume 42, Number 2 feature weights on a development corpus—for instance, by means of minimum error rate training procedures (Och 2003). The design of MT evaluation metrics correlating with human judgments is an active research area. Here we briefly survey two widely used general-purpose metrics, BLEU and METEOR, and then describe in more detail a number of reordering-specific metrics. 3.1 General-Purpose Metrics BLEU (Papineni et al. 2001) is a lexical match–based score that represents the de facto standard for SMT evaluation. Here, proximity between candidate and reference translations is measured in terms of overlapping word n-grams, with n typically ranging from 1 to 4. For each order n a modified precision score (see Papineni et al. [2001] for details) is computed on the whole test set and combined in a geometric mean. The resulting score is then multiplied by a brevity penalty that accounts for length mismatches between reference and candidate translations. Al-Onaizan and Papineni (2006) use BLEU to measure word order simi"
J16-2001,popovic-ney-2006-pos,0,0.0958148,"Missing"
J16-2001,P05-1034,0,0.070858,"Missing"
J16-2001,2007.tmi-papers.21,0,0.380885,"ma’an 2011; Visweswariah et al. 2011; Gojun and Fraser 2012; Yang et al. 2012; tic heads in the middle is not a trivial problem. Lerner and Petrov 2013; Jehl et al. 2014).10 Non-deterministic pre-ordering encodes We utilize the Head-Finalization rules to genermultiple alternative reorderings into a word lattice and lets a monotonic (usually ate intermediate head-finalized English sentencesto its models (Zens, Och, and n-gram–based) decoder choose the best path according called Head-Final andMariño decompose Ney 2002; Kanthak etEnglish al. 2005; (HFE) Crego and 2006; Zhang, Zens, and Ney 2007; Rottmann and Vogel 2007; Crego and Habash 2008; Elming and Habash 2009; Niehues Japanese-to-English translation into 1) Japaneseand Kolss 2009). A hybrid approach is adopted by Bisazza and Federico (2010) and to-HFE translation and 2) HFE-to-English postAndreas, Habash, and Rambow (2011): Rules are used to generate multiple likely preordering. butWe achieved significant orderings, only for specific language improvements phenomena that are responsible for difficult (long-range) reordering patterns. The sparse reordering lattices produced by these techfrom baseline (phrase-based, hierarchical phraseniques are then tra"
J16-2001,2012.iwslt-evaluation.6,0,0.0495299,"Missing"
J16-2001,2009.mtsummit-posters.17,0,0.0151225,"2009). It is worth noting that translation between Chinese and English has been the main motivation and test bed for the development of HSMT. French and Arabic [ Main order: different; CDiff: 1.5; PDiff: 1 ] At the clause level, this pair differs in main word order (SVO versus VSO or SVO) like the English–Arabic pair, but also in the order of negation and verb. On the other hand, phrase-level order is notably more similar, with only one discordant feature of minor importance (adjective and degree word). Less research was published on this language pair. Nevertheless, Hasan and Ney (2008) and Schwenk and Senellart (2009) chose a PSMT approach to experiment with an Arabic-to-French task. Figure 8 illustrates the reordering characteristics of three language pairs by means of sentence examples that were automatically word-aligned with GIZA++ (Och and Ney 2003) (intersection of direct and inverse alignments). In the first row, we see two English–German sentence pairs; in both cases, most of the points lie close to the diagonal representing an overall monotonic translation, whereas few isolated points denote the very long-range reordering of verbs. Similarly, in the two English–Arabic sentence pairs, we mostly obs"
J16-2001,P07-1090,0,0.0551832,"Missing"
J16-2001,P09-1037,0,0.0242489,"and decoding speed. Nguyen and Vogel (2013) and Huck et al. (2013) successfully integrate the distortion cost feature function and phrase orientation models initially designed for string-based PSMT into a chart-based HSMT decoder. Finally, Setiawan, Kan, and Li (2007) observe that, in languages like Chinese and English, function words provide important clues on the grammatical relationships among phrases. Consequently, they introduce a SCFG where function words (approximated by high-frequency words) are the only lexicalized non-terminals guiding phrase reordering. Based on the same intuition, Setiawan et al. (2009) augment a HSMT system with a function-word ordering model that predicts, for any pair of translation rules, which one should dominate the other in the hierarchical structure, based on the function words that they contain.9 2.3.3 Tree-Based SMT with Soft Syntactic Constraints. We have discussed SMT frameworks where the translation model is fully based on the syntactic parse tree of the source or target sentence (Section 2.3.1) or where syntax is not used at all (Section 2.3.2). A third line of work bridges between these two by exploiting syntactic information in the form of soft constraints wh"
J16-2001,D13-1048,0,0.0175651,"ntactic information in the form of soft constraints while operating with a synchronous translation grammar extracted from non-parsed parallel data. Chiang (2005) first experimented with a feature function rewarding translation rules applied to full syntactic constituents (constituent feature). Although this initial attempt did not appear to improve translation quality, Marton and Resnik (2008) further elaborated the idea and proposed a series of finer-grained features distinguishing among 9 Two other models utilizing function words as the anchors of global reordering decisions are proposed in Setiawan et al. (2013) and Setiawan, Zhou, and Xiang (2013). Although integrated in a syntax-based system (Shen, Xu, and Weischedel 2010), these models are in principle applicable to other SMT frameworks such as HSMT. 176 Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation constituent types (VP, NP, etc.), eventually leading to better performance. Gao, Koehn, and Birch (2011) extract two reordering-related feature functions from source dependency parse trees: (i) The dependency orientation model predicts whether the relative order of a source word and its head should be reversed duri"
J16-2001,P13-1124,0,0.01341,"ntactic information in the form of soft constraints while operating with a synchronous translation grammar extracted from non-parsed parallel data. Chiang (2005) first experimented with a feature function rewarding translation rules applied to full syntactic constituents (constituent feature). Although this initial attempt did not appear to improve translation quality, Marton and Resnik (2008) further elaborated the idea and proposed a series of finer-grained features distinguishing among 9 Two other models utilizing function words as the anchors of global reordering decisions are proposed in Setiawan et al. (2013) and Setiawan, Zhou, and Xiang (2013). Although integrated in a syntax-based system (Shen, Xu, and Weischedel 2010), these models are in principle applicable to other SMT frameworks such as HSMT. 176 Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation constituent types (VP, NP, etc.), eventually leading to better performance. Gao, Koehn, and Birch (2011) extract two reordering-related feature functions from source dependency parse trees: (i) The dependency orientation model predicts whether the relative order of a source word and its head should be reversed duri"
J16-2001,J10-4005,0,0.0360101,"Missing"
J16-2001,2014.iwslt-evaluation.17,0,0.0745524,"Missing"
J16-2001,W06-3104,0,0.00704584,"or instance, the swap of Alr}ys Alfrnsy may only be dictated by a rule applying to noun phrases composed of a noun and an adjective. On the other hand, string-to-tree methods (Yamada and Knight 2002; Galley et al. 2004; Marcu et al. 2006; Shen, Xu, and Weischedel 2010) use syntax as a way to restrict translation hypotheses to well-formed target language sentences—ruling out, for instance, a translation that fails to reorder the translated verb renewed with respect to its subject. Using syntax on both source and target sides (treeto-tree) (Imamura, Okuma, and Sumita 2005; Ding and Palmer 2005; Smith and Eisner 2006; Watanabe, Tsukada, and Isozaki 2006; Zhang et al. 2008) has proven rather difficult in practice due to the complexity of aligning potentially very different tree topologies and to the large size of the resulting translation grammars. Moreover, the need for highquality parsers in both language sides seriously limits the applicability of this approach. Syntax-based SMT approaches also differ in the formalism they use to represent the trees. Those based on phrase structure (constituency) grammars typically comply with the principle that each translation/reordering rule should match a complete c"
J16-2001,D11-1014,0,0.00498533,"Missing"
J16-2001,W14-4017,0,0.0509408,"Missing"
J16-2001,D14-1025,0,0.0165578,"Missing"
J16-2001,W10-1762,0,0.0158828,"(Cherry 2008) states that when part of a source subtree is translated, all words under the same subtree must be covered before moving to words outside of it. Integrated in phrase-based decoding as soft constraints (i. e., by using the number of violations as a feature function), dependency cohesion and its variants (Cherry 2008; Bach, Vogel, and Cherry 2009) were shown to significantly improve translation quality. In related work, Feng, Sun, and Ney (2012) derive similar cohesion constraints from the semantic role labeling structure of the input sentence. The divide-and-translate approach of Sudoh et al. (2010) uses source-side parse trees to segment complex sentences into simple clauses which are replaced by specific symbols and translated independently. Then, the target sentence is reconstructed using the placeholders, with the aim of simplifying long-range clause-level reordering. 2.1.2 PSMT Reordering Feature Functions. Target language modeling is the primary way to reward promising reorderings during translation. This happens indirectly, through the scoring of target word n-grams, which are generated by translating the source positions in different orders. However, the fixed-size context of lan"
J16-2001,P13-2060,0,0.121098,"07). Chang and Toutanova (2007) use a dependency tree reordering model to generate n alternative orders for each 1-best sentence produced by the SMT system. Each set of n sentence reorderings is then reranked using a discriminative model trained on word bigram features and standard word reordering features (i.e., distance or orientation between consecutively translated input words). Focusing on Japanese-to-English translation, Sudoh et al. (2011, 2013) proposed to “translate” foreign-order English into correct-order English using a monolingual phrase-based (Sudoh et al. 2011) or syntax-based (Sudoh et al. 2013) SMT system trained for this specific subtask.12 The underlying motivation is that, while English-to-Japanese is well handled by pre-ordering with the aforementioned head-finalization rule (Isozaki et al. 2010b), it is much harder to predict the English-like order of Japanese constituents for Japanese-to-English translation. Post-ordering addresses this issue by generating head-final English (HFE) sentences that are used to create a HFE-to-English parallel corpus. Goto, Utiyama, and Sumita (2012, 2013) solve post-ordering by parsing the HFE sentences into binary trees annotated with both synta"
J16-2001,W11-2102,0,0.0137081,"lled RIBES, Isozaki et al. (2010a) propose directly measuring the reordering occurring between the words of the hypothesis and those of the reference translation, thereby eliminating the need to word-align input and output sentence. A limitation of this approach is that only identical words contribute to the score. As a solution, the permutation distance is multiplied by a word precision score that penalizes hypotheses containing few reference words. Nevertheless, the resulting metric assigns different scores to hypotheses that differ in their lexical choice, but not in their word reordering. Talbot et al. (2011) introduce yet another reordering-specific metric, called fuzzy reordering score (FRS) which, like the KRS, is independent from lexical choice and measures the similarity between a sentence’s reference reordering and the reordering produced by an SMT system (or by a pre-ordering technique). However, whereas Birch, Osborne, and Blunsom (2010) used Kendall’s tau between the two sentence permutations, Talbot et al. count the smallest number of chunks that the hypothesis permutation must be divided into to align with the reference permutation. This corresponds precisely to the fragmentation penalt"
J16-2001,N04-4026,0,0.301097,"mate of the cost yet to be incurred (Moore and Quirk 2007). State-of-the-art systems use the distortion cost in combination with more sophisticated reordering models that take into account the identity of the reordered phrases and, optionally, various kinds of contextual information. A representative selection of such models is summarized in Table 1. To ease the presentation, we have divided the models into four groups according to their problem formulation: phrase orientation models, jump models, source decoding sequence models, and operation sequence models. Phrase orientation models (POM) (Tillmann 2004; Koehn et al. 2005; Nagata et al. 2006; Zens and Ney 2006; Li et al. 2014), simply known as lexicalized reordering models, predict whether the next translated source span should be immediately to the right (monotone), immediately to the left (swap), or anywhere else (discontinuous) relatively to the last translated one.7 For example, in Figure 2, the phrase pair [Almlk mHmd AlsAds]-[King Mohamed VI] has monotone orientation whereas [jdd]-[renewed] has discontinuous left orientation with respect to the previously translated phrase. Because of their simple reordering step classification, POM ca"
J16-2001,D09-1105,0,0.062238,"Missing"
J16-2001,D11-1045,0,0.21337,"Target-ordered source] Words : source (b2) Word order : target monotone translation in target word order Words : target Word order : target Figure 7 Figure 1: A typical work flow in a standard translation, Typical workflows of standard, pre-ordering, and post-ordering approaches to SMT. Taken from pre-ordering and post-ordering approach. Sudoh et al. (2011). Habash 2007; Li et al. 2007; Tromble and Eisner 2009; Xu et al. 2009; Genzel 2010; the opposite direction by placing Japanese syntac-and Fonollosa 2011; Khalilov Isozaki et al. 2010b; Yeniterzi and Oflazer 2010; Khalilov and Sima’an 2011; Visweswariah et al. 2011; Gojun and Fraser 2012; Yang et al. 2012; tic heads in the middle is not a trivial problem. Lerner and Petrov 2013; Jehl et al. 2014).10 Non-deterministic pre-ordering encodes We utilize the Head-Finalization rules to genermultiple alternative reorderings into a word lattice and lets a monotonic (usually ate intermediate head-finalized English sentencesto its models (Zens, Och, and n-gram–based) decoder choose the best path according called Head-Final andMariño decompose Ney 2002; Kanthak etEnglish al. 2005; (HFE) Crego and 2006; Zhang, Zens, and Ney 2007; Rottmann and Vogel 2007; Crego and H"
J16-2001,D07-1077,0,0.0432283,"Missing"
J16-2001,C02-1050,0,0.0175591,"Missing"
J16-2001,P06-1098,0,0.0199238,"Missing"
J16-2001,P06-1123,0,0.0955611,"Missing"
J16-2001,W14-3324,0,0.0127617,"n also differs from English with respect to the position of oblique phrases and that of the negation: Both are fixed in English but mixed in German. At the phrase level, German predominantly places the genitive after the noun, while English displays both orders. Thus, despite belonging to the same family branch (Indo-European/Germanic), this pair displays complex reordering patterns. Indeed, German–English reordering has been widely studied in SMT and is still an open topic. At the Workshop on Statistical Machine Translation 2014 (Bojar et al. 2014), a syntaxbased string-to-tree SMT approach (Williams et al. 2014) won in both language directions (official results excluding online systems). At the International Workshop on Spoken Language Translation 2014 (Cettolo et al. 2014), the best submission was a combination of PSMT with POS- and syntax-based preordering (Slawik et al. 2014), string-to-tree syntax-based SMT, and factored PSMT (Birch et al. 2014). English and French [ Main order: same; CDiff: 0.5; PDiff: 1.5 ] Most clause-level features have the same values in French as in English, except for the negation, which is typically expressed by two words in French: one preceding and one following the ver"
J16-2001,P96-1021,0,0.0730453,"late (a) to specify the order of the child dEm. For each new test sentence, matching treelet pairs and order templates are combined to construct lexicalized translation rules for that sentence and, finally, decoding is performed with a chart parsing algorithm. We will now discuss SMT frameworks that model translation as a process of parallel parsing of the source and target language via a synchronous grammar. 2.3.2 Tree-Based SMT Without Syntax. The idea of extracting bilingual translation (i.e., synchronous) grammars directly from word-aligned parallel data originates in early work on ITG by Wu (1996, 1997). In a more mature approach, hierarchical phrase-based SMT (HSMT) (Chiang 2005), the translation model is a probabilistic synchronous context-free grammar (SCFG) whose rules can correspond to arbitrary (i.e., nonsyntactically motivated) phrases labeled by only two generic non-terminal symbols (X or S). As shown in Figure 5, HSMT translation rules can either include a mix of terminals and non-terminals capturing reordering patterns and discontinuities (rules 1–4), or only terminals (rules 7–10) basically corresponding to phrase pairs in string-based PSMT. Finally, the so-called glue rule"
J16-2001,J97-3002,0,0.526747,"stems, the first constraining paradigms were formulated earlier for word-based SMT (Berger et al. 1996; Zens and Ney 2003) and are called IBM constraints. A different kind of reordering constraint can be derived from the Inversion Transduction Grammars (ITGs) (Wu 1995, 1997). ITG constraints only admit permutations 167 Computational Linguistics Volume 42, Number 2 that are generated by recursively swapping pairs of adjacent blocks of words.4 In particular, ITG constraints disallow reorderings that generalize the patterns (3 1 4 2) and (2 4 1 3), which are rarely attested in natural languages (Wu 1997).5 Enforcing ITG constraints in left-to-right PSMT decoding requires the use of a shift-reduce permutation parser (Zens 2008; Feng et al. 2010). Alternatively, a relaxed version of the ITG constraints (i.e., Baxter permutations) may be enforced by simply inspecting the set of covered source positions, as proposed by Zens et al. (2004) and Zens (2008). Interestingly, Cherry, Moore, and Quirk (2012) found no consistent benefit from applying either exact or approximate ITG-constraints to a PSMT system that already included a hierarchical phrase orientation model6 (Galley and Manning 2008). The re"
J16-2001,C04-1073,0,0.409974,"Missing"
J16-2001,P06-1066,0,0.225701,"Missing"
J16-2001,N09-1028,0,0.249285,"dered target] Words : source Word order : source (b1) pre-ordering Volume 42, Number 2 Words : target Word order : source (a) standard translation (c2) post-ordering [Target language] [Target-ordered source] Words : source (b2) Word order : target monotone translation in target word order Words : target Word order : target Figure 7 Figure 1: A typical work flow in a standard translation, Typical workflows of standard, pre-ordering, and post-ordering approaches to SMT. Taken from pre-ordering and post-ordering approach. Sudoh et al. (2011). Habash 2007; Li et al. 2007; Tromble and Eisner 2009; Xu et al. 2009; Genzel 2010; the opposite direction by placing Japanese syntac-and Fonollosa 2011; Khalilov Isozaki et al. 2010b; Yeniterzi and Oflazer 2010; Khalilov and Sima’an 2011; Visweswariah et al. 2011; Gojun and Fraser 2012; Yang et al. 2012; tic heads in the middle is not a trivial problem. Lerner and Petrov 2013; Jehl et al. 2014).10 Non-deterministic pre-ordering encodes We utilize the Head-Finalization rules to genermultiple alternative reorderings into a word lattice and lets a monotonic (usually ate intermediate head-finalized English sentencesto its models (Zens, Och, and n-gram–based) decod"
J16-2001,2009.mtsummit-papers.19,0,0.0170227,"ed source positions, as proposed by Zens et al. (2004) and Zens (2008). Interestingly, Cherry, Moore, and Quirk (2012) found no consistent benefit from applying either exact or approximate ITG-constraints to a PSMT system that already included a hierarchical phrase orientation model6 (Galley and Manning 2008). The reordering constraints presented so far are not sensitive to the words being translated nor to their context. This results in a very coarse definition of the reordering search space, which is problematic in language pairs with different syntactic structures. To address this problem, Yahyaei and Monz (2009) propose decoupling local and global reordering by segmenting the input sentence into chunks that can be permuted arbitrarily, but each of which is translated monotonically. In related work, Yahyaei and Monz (2010) present a technique to dynamically set the DL during decoding: They train a discriminative classifier to predict the most probable jump length after each input word, and use the predicted value as the DL after that position. Unfortunately, this method appears to generate inconsistent constraints leading to decoding dead-ends. Bisazza and Federico (2013a) further develop this idea so"
J16-2001,2010.iwslt-papers.19,0,0.0216811,"system that already included a hierarchical phrase orientation model6 (Galley and Manning 2008). The reordering constraints presented so far are not sensitive to the words being translated nor to their context. This results in a very coarse definition of the reordering search space, which is problematic in language pairs with different syntactic structures. To address this problem, Yahyaei and Monz (2009) propose decoupling local and global reordering by segmenting the input sentence into chunks that can be permuted arbitrarily, but each of which is translated monotonically. In related work, Yahyaei and Monz (2010) present a technique to dynamically set the DL during decoding: They train a discriminative classifier to predict the most probable jump length after each input word, and use the predicted value as the DL after that position. Unfortunately, this method appears to generate inconsistent constraints leading to decoding dead-ends. Bisazza and Federico (2013a) further develop this idea so that only long reorderings predicted by a specific reordering model are explored by the decoder. This form of early reordering pruning enables the PSMT system to capture long-range reordering without hurting effic"
J16-2001,P02-1039,0,0.0609456,"h. So-called tree-to-string methods (Huang, Knight, and Joshi 2006; Liu, Liu, and Lin 2006) use a given input sentence parse tree to restrict the application of translation/reordering rules to word 8 More pre-ordering techniques will be discussed in Section 2.4. 172 Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation spans that coincide with syntactic constituents of specific categories. For instance, the swap of Alr}ys Alfrnsy may only be dictated by a rule applying to noun phrases composed of a noun and an adjective. On the other hand, string-to-tree methods (Yamada and Knight 2002; Galley et al. 2004; Marcu et al. 2006; Shen, Xu, and Weischedel 2010) use syntax as a way to restrict translation hypotheses to well-formed target language sentences—ruling out, for instance, a translation that fails to reorder the translated verb renewed with respect to its subject. Using syntax on both source and target sides (treeto-tree) (Imamura, Okuma, and Sumita 2005; Ding and Palmer 2005; Smith and Eisner 2006; Watanabe, Tsukada, and Isozaki 2006; Zhang et al. 2008) has proven rather difficult in practice due to the complexity of aligning potentially very different tree topologies an"
J16-2001,P12-1096,0,0.261056,"rder : target monotone translation in target word order Words : target Word order : target Figure 7 Figure 1: A typical work flow in a standard translation, Typical workflows of standard, pre-ordering, and post-ordering approaches to SMT. Taken from pre-ordering and post-ordering approach. Sudoh et al. (2011). Habash 2007; Li et al. 2007; Tromble and Eisner 2009; Xu et al. 2009; Genzel 2010; the opposite direction by placing Japanese syntac-and Fonollosa 2011; Khalilov Isozaki et al. 2010b; Yeniterzi and Oflazer 2010; Khalilov and Sima’an 2011; Visweswariah et al. 2011; Gojun and Fraser 2012; Yang et al. 2012; tic heads in the middle is not a trivial problem. Lerner and Petrov 2013; Jehl et al. 2014).10 Non-deterministic pre-ordering encodes We utilize the Head-Finalization rules to genermultiple alternative reorderings into a word lattice and lets a monotonic (usually ate intermediate head-finalized English sentencesto its models (Zens, Och, and n-gram–based) decoder choose the best path according called Head-Final andMariño decompose Ney 2002; Kanthak etEnglish al. 2005; (HFE) Crego and 2006; Zhang, Zens, and Ney 2007; Rottmann and Vogel 2007; Crego and Habash 2008; Elming and Habash 2009; Niehu"
J16-2001,P10-1047,0,0.0159843,"difficult to reorder for an SMT system. The complex nature of its reordering phenomena suggests a good fit for tree-based SMT approaches, and indeed, HSMT was shown to significantly outperform PSMT between Turkish and English in both language directions (Ruiz et al. 2012; Yılmaz et al. 2013). However, state-of-the-art SMT quality in this language pair is still very low, mostly because of the agglutinative nature of Turkish, which makes it difficult to tear apart word reordering issues from rich morphology issues. Attempting to address both issues in an English-to-Turkish factored PSMT system, Yeniterzi and Oflazer (2010) pre-process the parsed English side with a number of syntax-to-morphology mapping rules and constituent pre-ordering rules dealing with local and global reordering phenomena, respectively. Only the former, though, resulted in better translation quality. English and Japanese [ Main order: different; CDiff: 6; PDiff: 1.5 ] Japanese is the prototypical example of head-final language. In this pair all clause-level features are discordant, whereas at the phrase level, Japanese differs from English for the use of postpositions and the strictly head-final genitive construction. This pair, like the p"
J16-2001,I08-1068,0,0.0412101,"and are called IBM constraints. A different kind of reordering constraint can be derived from the Inversion Transduction Grammars (ITGs) (Wu 1995, 1997). ITG constraints only admit permutations 167 Computational Linguistics Volume 42, Number 2 that are generated by recursively swapping pairs of adjacent blocks of words.4 In particular, ITG constraints disallow reorderings that generalize the patterns (3 1 4 2) and (2 4 1 3), which are rarely attested in natural languages (Wu 1997).5 Enforcing ITG constraints in left-to-right PSMT decoding requires the use of a shift-reduce permutation parser (Zens 2008; Feng et al. 2010). Alternatively, a relaxed version of the ITG constraints (i.e., Baxter permutations) may be enforced by simply inspecting the set of covered source positions, as proposed by Zens et al. (2004) and Zens (2008). Interestingly, Cherry, Moore, and Quirk (2012) found no consistent benefit from applying either exact or approximate ITG-constraints to a PSMT system that already included a hierarchical phrase orientation model6 (Galley and Manning 2008). The reordering constraints presented so far are not sensitive to the words being translated nor to their context. This results in"
J16-2001,P03-1019,0,0.26372,"rtant for translation quality because the existing SMT models are typically not discriminative enough to guide the search over very large sets of reordering hypotheses. However, reordering constraints have also several drawbacks. For instance, the verb reordering in Figure 2 may not be captured by a PSMT system that applies a DL of k = 5 or less, because jumping back from AlsAds to jdd corresponds to a skip of six positions. While the distortion limit is a de facto standard in modern PSMT systems, the first constraining paradigms were formulated earlier for word-based SMT (Berger et al. 1996; Zens and Ney 2003) and are called IBM constraints. A different kind of reordering constraint can be derived from the Inversion Transduction Grammars (ITGs) (Wu 1995, 1997). ITG constraints only admit permutations 167 Computational Linguistics Volume 42, Number 2 that are generated by recursively swapping pairs of adjacent blocks of words.4 In particular, ITG constraints disallow reorderings that generalize the patterns (3 1 4 2) and (2 4 1 3), which are rarely attested in natural languages (Wu 1997).5 Enforcing ITG constraints in left-to-right PSMT decoding requires the use of a shift-reduce permutation parser"
J16-2001,W06-3108,0,0.0415396,"007). State-of-the-art systems use the distortion cost in combination with more sophisticated reordering models that take into account the identity of the reordered phrases and, optionally, various kinds of contextual information. A representative selection of such models is summarized in Table 1. To ease the presentation, we have divided the models into four groups according to their problem formulation: phrase orientation models, jump models, source decoding sequence models, and operation sequence models. Phrase orientation models (POM) (Tillmann 2004; Koehn et al. 2005; Nagata et al. 2006; Zens and Ney 2006; Li et al. 2014), simply known as lexicalized reordering models, predict whether the next translated source span should be immediately to the right (monotone), immediately to the left (swap), or anywhere else (discontinuous) relatively to the last translated one.7 For example, in Figure 2, the phrase pair [Almlk mHmd AlsAds]-[King Mohamed VI] has monotone orientation whereas [jdd]-[renewed] has discontinuous left orientation with respect to the previously translated phrase. Because of their simple reordering step classification, POM can be conditioned on very finegrained information, such as"
J16-2001,C04-1030,0,0.0580088,"tational Linguistics Volume 42, Number 2 that are generated by recursively swapping pairs of adjacent blocks of words.4 In particular, ITG constraints disallow reorderings that generalize the patterns (3 1 4 2) and (2 4 1 3), which are rarely attested in natural languages (Wu 1997).5 Enforcing ITG constraints in left-to-right PSMT decoding requires the use of a shift-reduce permutation parser (Zens 2008; Feng et al. 2010). Alternatively, a relaxed version of the ITG constraints (i.e., Baxter permutations) may be enforced by simply inspecting the set of covered source positions, as proposed by Zens et al. (2004) and Zens (2008). Interestingly, Cherry, Moore, and Quirk (2012) found no consistent benefit from applying either exact or approximate ITG-constraints to a PSMT system that already included a hierarchical phrase orientation model6 (Galley and Manning 2008). The reordering constraints presented so far are not sensitive to the words being translated nor to their context. This results in a very coarse definition of the reordering search space, which is problematic in language pairs with different syntactic structures. To address this problem, Yahyaei and Monz (2009) propose decoupling local and g"
J16-2001,2002.tmi-tutorials.2,0,0.0206069,"Missing"
J16-2001,W07-0404,0,0.0564113,"Missing"
J16-2001,P08-1064,0,0.0279742,"by a rule applying to noun phrases composed of a noun and an adjective. On the other hand, string-to-tree methods (Yamada and Knight 2002; Galley et al. 2004; Marcu et al. 2006; Shen, Xu, and Weischedel 2010) use syntax as a way to restrict translation hypotheses to well-formed target language sentences—ruling out, for instance, a translation that fails to reorder the translated verb renewed with respect to its subject. Using syntax on both source and target sides (treeto-tree) (Imamura, Okuma, and Sumita 2005; Ding and Palmer 2005; Smith and Eisner 2006; Watanabe, Tsukada, and Isozaki 2006; Zhang et al. 2008) has proven rather difficult in practice due to the complexity of aligning potentially very different tree topologies and to the large size of the resulting translation grammars. Moreover, the need for highquality parsers in both language sides seriously limits the applicability of this approach. Syntax-based SMT approaches also differ in the formalism they use to represent the trees. Those based on phrase structure (constituency) grammars typically comply with the principle that each translation/reordering rule should match a complete constituent, whereas those based on dependency grammars op"
J16-2001,W07-0401,0,0.0624539,"Missing"
J16-2001,W06-3119,0,0.00859258,"Devlin, and Zbib (2013) worked instead with constituency parses and trained a classifier to predict whether the order of any two sibling constituents in the input tree should be reversed or maintained during translation. The classifier is trained by maximum entropy, using a number of syntactic features and used during decoding at the word level: that is, each pair of input words inherit the orientation probabilities of the constituents that cover them, respectively. Syntactic annotation has also been used to refine non-terminal SCFG labels, potentially leading to better reordering choices. In Zollmann and Venugopal (2006) and Mylonakis and Sima’an (2011), labels indicate whether a phrase corresponds to a syntactic constituent or to part of it, as well as the constituent type, relatively to a target or source parse tree, respectively. Moreover, Mylonakis and Sima’an treat the phrasepair category as a latent variable and let their system learn reordering distributions over multiple labels per span (generic X or source-syntax based like NP, VBZ + DT, etc.). Li et al. (2012) use source dependency annotation to refine non-terminal symbols with syntactic head information. More specifically, given a hierarchical phra"
J16-2001,C08-1144,0,0.202405,"as observed in the French-to-English track. English and Arabic [ Main order: different; CDiff: 0.5; PDiff: 2.5 ] The dominant Arabic order is VSO, followed by SVO (cf. Section 4.2). Apart from this important difference, all other clause-level features agree between Arabic and English. At the phrase level, differences are found in genitives, adjectives, and degree words. As a result, reordering is overwhelmingly local but few crucial long-range reorderings also regularly occur. Thus, this pair is challenging for PSMT but, at the same time, not well suited for a tree-based approach. As shown by Zollmann et al. (2008) and Birch, Blunsom, and Osborne (2009), PSMT performs similarly or better than HSMT for the Arabic-to-English language pair. However, HSMT was shown to better cope with the reordering of VSO sentences (Bisazza 2013). Pre-ordering of Arabic VSO sentences for translation into English has proved to 1 7 Pre-verbal negation can be omitted in colloquial French. 190 Bisazza and Federico A Survey of Word Reordering in Statistical Machine Translation be a particularly difficult task (Green, Sathi, and Manning 2009; Carpuat, Marton, and Habash 2010) and has inspired work on hybrid pre-ordering where mu"
J16-2001,N10-1140,0,\N,Missing
J16-2001,D11-1018,0,\N,Missing
J16-2001,N10-1128,0,\N,Missing
J16-2001,N09-2001,0,\N,Missing
J16-2001,W06-3601,0,\N,Missing
J16-2001,P02-1040,0,\N,Missing
J16-2001,H05-1098,0,\N,Missing
J16-2001,P13-2071,0,\N,Missing
J16-2001,P13-1016,0,\N,Missing
J16-2001,Q13-1027,1,\N,Missing
J16-2001,J10-3008,0,\N,Missing
J16-2001,2010.iwslt-keynotes.2,0,\N,Missing
J16-2001,P11-1105,0,\N,Missing
J16-2001,J04-4002,0,\N,Missing
J16-2001,W05-0909,0,\N,Missing
J16-2001,P07-2045,1,\N,Missing
J16-2001,W09-0809,0,\N,Missing
J16-2001,P10-2033,0,\N,Missing
J16-2001,W13-2257,1,\N,Missing
J16-2001,E09-1061,0,\N,Missing
J16-2001,2014.iwslt-evaluation.6,0,\N,Missing
J16-2001,J03-1005,0,\N,Missing
J16-2001,W08-0307,0,\N,Missing
J16-2001,P08-1066,0,\N,Missing
J16-2001,2010.iwslt-evaluation.11,0,\N,Missing
J16-2001,C14-1041,0,\N,Missing
J16-2001,W14-3302,0,\N,Missing
J16-2001,D11-1125,0,\N,Missing
L18-1148,D16-1025,1,0.858108,"nary NMT experiments as the first step towards better idiom translation. Keywords: multiword expression, idioms, bilingual corpora, machine translation 1. Introduction Neural Machine Translation (NMT) (Bahdanau et al., 2015; Sutskever et al., 2014; Cho et al., 2014) has achieved substantial improvements in translation quality over traditional Rule-based and Phrase-based Translation (PBMT) in recent years. For instance, subject-verb agreement, doubleobject verbs, and overlapping subcategorization are various areas where NMT successfully overcomes the limitations of PBMT (Isabelle et al., 2017; Bentivogli et al., 2016). However, one of the remaining challenges of NMT is translating infrequent words and phrases (Koehn and Knowles, 2017; Fadaee et al., 2017) and idioms are a particular instance of this problem (Isabelle et al., 2017). Idioms are semantic lexical units whose meaning is often not simply a function of the meaning of its constituent parts (Nunberg et al., 1994; K¨ovecses and Szabo, 1996). The non-compositionality characteristic of idiom expressions exists in different degrees in a language (Nunberg et al., 1994). In English for example, for the idiom “spill the beans”, the word ‘spill’ symbolizes"
L18-1148,W14-4012,0,0.0258764,"Missing"
L18-1148,N13-1073,0,0.0112828,"e and by itself does not focus on the translation quality of the idiomatic expressions. Modified Unigram Precision To specifically concentrate on the quality of the translation of idiom expressions, we also look at the localized precision. In this approach we translate the idiomatic expression in the context of a sentence, and only evaluate the translation quality of the idiom phrase. To isolate the idiom translation in the sentence, we look at the word-level alignments between the idiom expression in the source sentence and the generated translation in the target sentence. We use fast-align (Dyer et al., 2013) to extract word alignments. Since idiomatic phrases and the respective translations are not contiguous in many cases we only compare the unigrams of the two phrases. Note that for this metric we have two references: The idiom translation as an independent expression, and the human generated idiom translation in the target sentence. Word-level Idiom Accuracy We also use another metric to evaluate the word-level translation accuracy of the idiom phrase. We use word alignments between source and target sentences to determine the number of correctly translated words. We use the following equation"
L18-1148,P17-2090,1,0.792484,"slation 1. Introduction Neural Machine Translation (NMT) (Bahdanau et al., 2015; Sutskever et al., 2014; Cho et al., 2014) has achieved substantial improvements in translation quality over traditional Rule-based and Phrase-based Translation (PBMT) in recent years. For instance, subject-verb agreement, doubleobject verbs, and overlapping subcategorization are various areas where NMT successfully overcomes the limitations of PBMT (Isabelle et al., 2017; Bentivogli et al., 2016). However, one of the remaining challenges of NMT is translating infrequent words and phrases (Koehn and Knowles, 2017; Fadaee et al., 2017) and idioms are a particular instance of this problem (Isabelle et al., 2017). Idioms are semantic lexical units whose meaning is often not simply a function of the meaning of its constituent parts (Nunberg et al., 1994; K¨ovecses and Szabo, 1996). The non-compositionality characteristic of idiom expressions exists in different degrees in a language (Nunberg et al., 1994). In English for example, for the idiom “spill the beans”, the word ‘spill’ symbolizes ‘reveal’ and ‘beans’ symbolizes the ‘secrets’. With the idiomatic expression “kick the bucket”, on the other hand, no such analysis is poss"
L18-1148,D17-1263,0,0.0814123,"e it to perform preliminary NMT experiments as the first step towards better idiom translation. Keywords: multiword expression, idioms, bilingual corpora, machine translation 1. Introduction Neural Machine Translation (NMT) (Bahdanau et al., 2015; Sutskever et al., 2014; Cho et al., 2014) has achieved substantial improvements in translation quality over traditional Rule-based and Phrase-based Translation (PBMT) in recent years. For instance, subject-verb agreement, doubleobject verbs, and overlapping subcategorization are various areas where NMT successfully overcomes the limitations of PBMT (Isabelle et al., 2017; Bentivogli et al., 2016). However, one of the remaining challenges of NMT is translating infrequent words and phrases (Koehn and Knowles, 2017; Fadaee et al., 2017) and idioms are a particular instance of this problem (Isabelle et al., 2017). Idioms are semantic lexical units whose meaning is often not simply a function of the meaning of its constituent parts (Nunberg et al., 1994; K¨ovecses and Szabo, 1996). The non-compositionality characteristic of idiom expressions exists in different degrees in a language (Nunberg et al., 1994). In English for example, for the idiom “spill the beans”, t"
L18-1148,P17-4012,0,0.0214191,"o not have just a white vest. Coca-Cola and Nestl´e are among the signatories. Both don’t have a white essence. Table 1: Example of an idiom phrase in German and its translation. We compare the output of DeepL, GoogleNMT, and OpenNMT translating a sentence with this idiom phrase and notice that none capture the idiom translation correctly. not the correct translation, neither does it capture part of the meaning. To illustrate the problem of idiom translation we also provide the output of three NMT systems for this sentence: GoogleNMT (Wu et al., 2016), DeepL1 , and the OpenNMT implementation (Klein et al., 2017) based on Bahdanau et al. (2015) and Luong et al. (2015). All systems fail to generate the proper translation of the idiom expression. This problem is particularly pronounced when the source idiom is very different from its equivalent in the target language, as the case here. 1 925 www.deepl.com/translator Idiom Identification no idiom phrase Bilingual Training Data New Training Data idiom 1 idiom 2 New Test Data … idiom k Bilingual Idiom Resource Sampling Figure 1: The process of data collection and construction of the test set containing only sentence pairs with idiom phrases. Although there"
L18-1148,W17-3204,0,0.0215271,"ual corpora, machine translation 1. Introduction Neural Machine Translation (NMT) (Bahdanau et al., 2015; Sutskever et al., 2014; Cho et al., 2014) has achieved substantial improvements in translation quality over traditional Rule-based and Phrase-based Translation (PBMT) in recent years. For instance, subject-verb agreement, doubleobject verbs, and overlapping subcategorization are various areas where NMT successfully overcomes the limitations of PBMT (Isabelle et al., 2017; Bentivogli et al., 2016). However, one of the remaining challenges of NMT is translating infrequent words and phrases (Koehn and Knowles, 2017; Fadaee et al., 2017) and idioms are a particular instance of this problem (Isabelle et al., 2017). Idioms are semantic lexical units whose meaning is often not simply a function of the meaning of its constituent parts (Nunberg et al., 1994; K¨ovecses and Szabo, 1996). The non-compositionality characteristic of idiom expressions exists in different degrees in a language (Nunberg et al., 1994). In English for example, for the idiom “spill the beans”, the word ‘spill’ symbolizes ‘reveal’ and ‘beans’ symbolizes the ‘secrets’. With the idiomatic expression “kick the bucket”, on the other hand, no"
L18-1148,P07-2045,0,0.00531733,"U Unigram Precision Word-level Accuracy 20.2 26.9 25.2 19.7 24.8 22.5 57.7 53.2 64.1 71.6 67.8 73.2 Table 5: Translation performance on German idiom translation test set. Word-level Idiom Accuracy and Unigram Precision are computed only on the idiom phrase and its corresponding translation in the sentence. In all experiments the NMT vocabulary is limited to the most common 30K words in both languages and we preprocess source and target language data with Byte-pair encoding (BPE) (Sennrich et al., 2016) using 30K merge operations. We also use a Phrase-based translation system similar to Moses (Koehn et al., 2007) as baseline to explore PBMT performance for idiom translation. 4. Idiom Translation Evaluation Ideally idiom translation should be evaluated manually, but this is a very costly process. Automatic metrics, on the other hand, can be used on large data sets at no cost and have the advantage of replicability. We use the following metrics to evaluate the translation quality with a specific focus on idiom translation accuracy: BLEU The traditional BLEU score (Papineni et al., 2002) is a good measure to determine the overall quality of the translations. However this measure considers the precision o"
L18-1148,D15-1166,0,0.273681,"among the signatories. Both don’t have a white essence. Table 1: Example of an idiom phrase in German and its translation. We compare the output of DeepL, GoogleNMT, and OpenNMT translating a sentence with this idiom phrase and notice that none capture the idiom translation correctly. not the correct translation, neither does it capture part of the meaning. To illustrate the problem of idiom translation we also provide the output of three NMT systems for this sentence: GoogleNMT (Wu et al., 2016), DeepL1 , and the OpenNMT implementation (Klein et al., 2017) based on Bahdanau et al. (2015) and Luong et al. (2015). All systems fail to generate the proper translation of the idiom expression. This problem is particularly pronounced when the source idiom is very different from its equivalent in the target language, as the case here. 1 925 www.deepl.com/translator Idiom Identification no idiom phrase Bilingual Training Data New Training Data idiom 1 idiom 2 New Test Data … idiom k Bilingual Idiom Resource Sampling Figure 1: The process of data collection and construction of the test set containing only sentence pairs with idiom phrases. Although there are a number of monolingual data sets available for ide"
L18-1148,D13-1145,0,0.0260704,"te the proper translation of the idiom expression. This problem is particularly pronounced when the source idiom is very different from its equivalent in the target language, as the case here. 1 925 www.deepl.com/translator Idiom Identification no idiom phrase Bilingual Training Data New Training Data idiom 1 idiom 2 New Test Data … idiom k Bilingual Idiom Resource Sampling Figure 1: The process of data collection and construction of the test set containing only sentence pairs with idiom phrases. Although there are a number of monolingual data sets available for identifying idiom expressions (Muzny and Zettlemoyer, 2013; Markantonatou et al., 2017), there is limited work on building a parallel corpus annotated with idioms, which is necessary to investigate this problem more systematically. Salton et al. (2014) selected a small subset of 17 English idioms, collected 10 sentence examples for each idiom from the internet, and manually translated them into Brazilian-Portuguese to use for the translation task. Building a hand-crafted data set for idiom translation is costly and time-consuming. In this paper we automatically build a new bilingual data set for idiom translation extracted from an existing general-pu"
L18-1148,P02-1040,0,0.10232,"(BPE) (Sennrich et al., 2016) using 30K merge operations. We also use a Phrase-based translation system similar to Moses (Koehn et al., 2007) as baseline to explore PBMT performance for idiom translation. 4. Idiom Translation Evaluation Ideally idiom translation should be evaluated manually, but this is a very costly process. Automatic metrics, on the other hand, can be used on large data sets at no cost and have the advantage of replicability. We use the following metrics to evaluate the translation quality with a specific focus on idiom translation accuracy: BLEU The traditional BLEU score (Papineni et al., 2002) is a good measure to determine the overall quality of the translations. However this measure considers the precision of all n-grams in a sentence and by itself does not focus on the translation quality of the idiomatic expressions. Modified Unigram Precision To specifically concentrate on the quality of the translation of idiom expressions, we also look at the localized precision. In this approach we translate the idiomatic expression in the context of a sentence, and only evaluate the translation quality of the idiom phrase. To isolate the idiom translation in the sentence, we look at the wo"
L18-1148,W14-1007,0,0.0155232,"w.deepl.com/translator Idiom Identification no idiom phrase Bilingual Training Data New Training Data idiom 1 idiom 2 New Test Data … idiom k Bilingual Idiom Resource Sampling Figure 1: The process of data collection and construction of the test set containing only sentence pairs with idiom phrases. Although there are a number of monolingual data sets available for identifying idiom expressions (Muzny and Zettlemoyer, 2013; Markantonatou et al., 2017), there is limited work on building a parallel corpus annotated with idioms, which is necessary to investigate this problem more systematically. Salton et al. (2014) selected a small subset of 17 English idioms, collected 10 sentence examples for each idiom from the internet, and manually translated them into Brazilian-Portuguese to use for the translation task. Building a hand-crafted data set for idiom translation is costly and time-consuming. In this paper we automatically build a new bilingual data set for idiom translation extracted from an existing general-purpose German↔English parallel corpus. The first part of our data set consists of 1,500 parallel sentences whose German side contains an idiom, while the second consists of 1,500 parallel sentenc"
L18-1148,P16-1162,0,0.0259326,"chs. 927 WMT test sets 2008-2016 Model PBMT Baseline NMT Baseline NMT &lt;idm&gt; token on source Idiom test set BLEU BLEU Unigram Precision Word-level Accuracy 20.2 26.9 25.2 19.7 24.8 22.5 57.7 53.2 64.1 71.6 67.8 73.2 Table 5: Translation performance on German idiom translation test set. Word-level Idiom Accuracy and Unigram Precision are computed only on the idiom phrase and its corresponding translation in the sentence. In all experiments the NMT vocabulary is limited to the most common 30K words in both languages and we preprocess source and target language data with Byte-pair encoding (BPE) (Sennrich et al., 2016) using 30K merge operations. We also use a Phrase-based translation system similar to Moses (Koehn et al., 2007) as baseline to explore PBMT performance for idiom translation. 4. Idiom Translation Evaluation Ideally idiom translation should be evaluated manually, but this is a very costly process. Automatic metrics, on the other hand, can be used on large data sets at no cost and have the advantage of replicability. We use the following metrics to evaluate the translation quality with a specific focus on idiom translation accuracy: BLEU The traditional BLEU score (Papineni et al., 2002) is a g"
L18-1148,W17-4717,1,\N,Missing
L18-1148,W17-1700,0,\N,Missing
L18-1604,2010.amta-papers.16,0,0.0390509,"Missing"
L18-1604,E12-1045,1,0.832814,"rpora available. To alleviate this problem, we present in this paper novel parallel training and evaluation corpora covering four genres for four language pairs that we automatically harvested from the web. Next, we evaluate the usefulness of the newly collected bilingual resources by exploiting them for genre adaptation of SMT systems. Most existing adaptation approaches depend on the availability of provenance information and make the strong assumption that a translation task has known domain, genre or topic that is exploited to adapt the system (Matsoukas et al., 2009; Foster et al., 2010; Bisazza and Federico, 2012; Chen et al., 2013; Chen et al., 2014; Kobus et al., 2016; Sennrich et al., 2016; Freitag and AlOnaizan, 2016; Chu et al., 2017, among others). While this is a fair assumption in a controlled research setting, it is less realistic in real world applications, such as general-purpose online MT services. In this paper, we provide the SMT system with a test document of unknown origin, and we show that we can use automatic genre classification to guide each test document to the most appropriate pre-trained system. While similar setups have been used in previous work (Xu et al., 2007; Banerjee et a"
L18-1604,2011.iwslt-evaluation.18,1,0.72949,"lates various Gigaword subcorpora with the English sides of the bilingual training corpora. To evaluate the effect of our new bilingual resources, we do not vary the language model between experiments. In order to create genre-specific SMT systems, we have to adequately use the available data. Simply concatenating the different corpora yields a general SMT system that performs reasonably well across a variety of genres, i.e., those covered in the training data, but is not optimal for each individual genre. Since we aim to create genre-specific systems, we use the fill-up technique proposed by Bisazza et al. (2011), in which we combine models trained on a particular genre with models trained on the remaining training corpora. Using this model combination technique, an additional feature is learned that favors genre-specific models, and ‘backs off’ to additional (out-of-genre) models for phrases that are unseen in the genre of interest. For instance, to train our news translation system, we train two phrase tables: one using all news data and one using all non-news data. We use the latter to complement the first with phrase pairs that are not covered in the first. Following the above strategy, we can tra"
L18-1604,P13-1126,0,0.0175776,"e this problem, we present in this paper novel parallel training and evaluation corpora covering four genres for four language pairs that we automatically harvested from the web. Next, we evaluate the usefulness of the newly collected bilingual resources by exploiting them for genre adaptation of SMT systems. Most existing adaptation approaches depend on the availability of provenance information and make the strong assumption that a translation task has known domain, genre or topic that is exploited to adapt the system (Matsoukas et al., 2009; Foster et al., 2010; Bisazza and Federico, 2012; Chen et al., 2013; Chen et al., 2014; Kobus et al., 2016; Sennrich et al., 2016; Freitag and AlOnaizan, 2016; Chu et al., 2017, among others). While this is a fair assumption in a controlled research setting, it is less realistic in real world applications, such as general-purpose online MT services. In this paper, we provide the SMT system with a test document of unknown origin, and we show that we can use automatic genre classification to guide each test document to the most appropriate pre-trained system. While similar setups have been used in previous work (Xu et al., 2007; Banerjee et al., 2010; Pecina et"
L18-1604,2014.amta-researchers.10,0,0.0179565,"present in this paper novel parallel training and evaluation corpora covering four genres for four language pairs that we automatically harvested from the web. Next, we evaluate the usefulness of the newly collected bilingual resources by exploiting them for genre adaptation of SMT systems. Most existing adaptation approaches depend on the availability of provenance information and make the strong assumption that a translation task has known domain, genre or topic that is exploited to adapt the system (Matsoukas et al., 2009; Foster et al., 2010; Bisazza and Federico, 2012; Chen et al., 2013; Chen et al., 2014; Kobus et al., 2016; Sennrich et al., 2016; Freitag and AlOnaizan, 2016; Chu et al., 2017, among others). While this is a fair assumption in a controlled research setting, it is less realistic in real world applications, such as general-purpose online MT services. In this paper, we provide the SMT system with a test document of unknown origin, and we show that we can use automatic genre classification to guide each test document to the most appropriate pre-trained system. While similar setups have been used in previous work (Xu et al., 2007; Banerjee et al., 2010; Pecina et al., 2011; Wang et"
L18-1604,P17-2061,0,0.0167851,"or four language pairs that we automatically harvested from the web. Next, we evaluate the usefulness of the newly collected bilingual resources by exploiting them for genre adaptation of SMT systems. Most existing adaptation approaches depend on the availability of provenance information and make the strong assumption that a translation task has known domain, genre or topic that is exploited to adapt the system (Matsoukas et al., 2009; Foster et al., 2010; Bisazza and Federico, 2012; Chen et al., 2013; Chen et al., 2014; Kobus et al., 2016; Sennrich et al., 2016; Freitag and AlOnaizan, 2016; Chu et al., 2017, among others). While this is a fair assumption in a controlled research setting, it is less realistic in real world applications, such as general-purpose online MT services. In this paper, we provide the SMT system with a test document of unknown origin, and we show that we can use automatic genre classification to guide each test document to the most appropriate pre-trained system. While similar setups have been used in previous work (Xu et al., 2007; Banerjee et al., 2010; Pecina et al., 2011; Wang et al., 2012; Pecina et al., 2015), we are the first to extend this setup to four genres and"
L18-1604,W01-1007,0,0.1249,"Missing"
L18-1604,W07-0717,0,0.0414157,"rather than a single genre-agnostic system. Finally, we train and use genre classifiers to route test documents to the most appropriate genre systems. The results of these experiments show that our multi-genre benchmarks can serve to advance research on text genre adaptation for MT. Keywords: Machine translation, parallel benchmarks, text genres, genre adaptation 1. Introduction Text genre differences have shown to affect the output quality of statistical machine translation (SMT) systems: SMT systems trained on one genre often achieve poor performance when used for translating another genre (Foster and Kuhn, 2007; Matsoukas et al., 2009; Wang et al., 2012, among others). In addition, even if different genres in a test set are both present in equal amounts in the bilingual training data, performance differences between the test genres can be large, mostly due to poor model coverage for certain genres (van der Wees et al., 2015a; van der Wees et al., 2015b). In this paper, we evaluate the impact of genre differences on phrase-based SMT for a diverse set of language pairs, covering both commonly and rarely studied language pairs. For common language pairs, parallel training data is abundant but limited t"
L18-1604,D10-1044,0,0.027298,"ew to no bilingual corpora available. To alleviate this problem, we present in this paper novel parallel training and evaluation corpora covering four genres for four language pairs that we automatically harvested from the web. Next, we evaluate the usefulness of the newly collected bilingual resources by exploiting them for genre adaptation of SMT systems. Most existing adaptation approaches depend on the availability of provenance information and make the strong assumption that a translation task has known domain, genre or topic that is exploited to adapt the system (Matsoukas et al., 2009; Foster et al., 2010; Bisazza and Federico, 2012; Chen et al., 2013; Chen et al., 2014; Kobus et al., 2016; Sennrich et al., 2016; Freitag and AlOnaizan, 2016; Chu et al., 2017, among others). While this is a fair assumption in a controlled research setting, it is less realistic in real world applications, such as general-purpose online MT services. In this paper, we provide the SMT system with a test document of unknown origin, and we show that we can use automatic genre classification to guide each test document to the most appropriate pre-trained system. While similar setups have been used in previous work (Xu"
L18-1604,P05-1071,0,0.102597,"n the sky, but we have already tasted it in Africa, where Sierra Leone’s agenda for prosperity 2013–2017 and the Liberia Vision 2030 exemplify the potential of such programs. News She is not only the first Saudi woman to ever attempt the climb but also the youngest Arab to make it to the top of the world’s highest peak. Speech These are just a few of the milestones of recent progress. I have another reason to be optimistic. I know global health is guided by the right values. Table 2: English example sentences for four genres in the web-harvested evaluation corpora. all Arabic data using MADA (Habash and Rambow, 2005), segment the Chinese data following (Tseng et al., 2005), and use a simple in-house tokenizer for the other languages. The total numbers of foreign→English sentence pairs for the four genres and four language pairs are listed in Tables 1a–1d. In addition, Table 2 shows English example sentences for each of the four genres. 3. Evaluating genre differences in SMT In this section, we use our newly assembled resources to evaluate SMT performance across different genres and language pairs. 3823 Coll. Edit. News Speech 11.7 22.6 22.6 11.5 SMT system optimized for Combined Coll. Edit. News Speech be"
L18-1604,C94-2174,0,0.627046,"Missing"
L18-1604,P97-1005,0,0.047111,"Missing"
L18-1604,P07-2045,0,0.00720101,"7 22.6 All 21.9 20.8 Test genre Baseline (c) Bulgarian→English results. – 21.3 21.5 (d) Persian→English results. Table 3: Translation quality in BLEU of four test genres using genre-optimized systems and a genre-agnostic baseline. Best results for each test set genre are boldfaced. ‘Combined best BLEU’ indicates the overall BLEU score when combining the bold-faced results of all test genres in a single test set, followed by the difference with the genre-agnostic system. 3.1. Experimental setup All SMT systems in this paper are trained using an inhouse phrase-based SMT system similar to Moses (Koehn et al., 2007). To train our systems, we use our webcrawled corpora, supplemented with commonly used training data, if available: LDC corpora for Arabic→English and Chinese→English, and Europarl data (Koehn, 2005) for Bulgarian→English. In addition, we use a 5-gram language model that linearly interpolates various Gigaword subcorpora with the English sides of the bilingual training corpora. To evaluate the effect of our new bilingual resources, we do not vary the language model between experiments. In order to create genre-specific SMT systems, we have to adequately use the available data. Simply concatenat"
L18-1604,2005.mtsummit-papers.11,0,0.0603303,"genre-agnostic baseline. Best results for each test set genre are boldfaced. ‘Combined best BLEU’ indicates the overall BLEU score when combining the bold-faced results of all test genres in a single test set, followed by the difference with the genre-agnostic system. 3.1. Experimental setup All SMT systems in this paper are trained using an inhouse phrase-based SMT system similar to Moses (Koehn et al., 2007). To train our systems, we use our webcrawled corpora, supplemented with commonly used training data, if available: LDC corpora for Arabic→English and Chinese→English, and Europarl data (Koehn, 2005) for Bulgarian→English. In addition, we use a 5-gram language model that linearly interpolates various Gigaword subcorpora with the English sides of the bilingual training corpora. To evaluate the effect of our new bilingual resources, we do not vary the language model between experiments. In order to create genre-specific SMT systems, we have to adequately use the available data. Simply concatenating the different corpora yields a general SMT system that performs reasonably well across a variety of genres, i.e., those covered in the training data, but is not optimal for each individual genre."
L18-1604,ma-2006-champollion,0,0.0368668,"‘en-US’ with ‘ar’. To determine the genre of each text we use categories indicated on the respective website. For example, websites that support news articles and user comments (i.e., the genres news and colloquial), have clear website sections for these different genres. While not all language-genre combinations are equally common, we can construct at least a translation test set for each of the four genres in each of the four language pairs. To do so, we first create sentence-parallel corpora using a combination of Moore’s sentence alignment (Moore, 2002) and Champollion sentence alignment (Ma, 2006). We then organize the collected bilingual data into training, development, and test sets, such that each portion contains documents from non-overlapping time periods.2 We tokenize 2 The benchmarks are available for download http://ilps.science.uva.nl/resources/ genre-benchmarks. at Genre Example sentence(s) Colloquial Ministers should be sitting and attending the oath, like in Italy. Editorial This may sound like pie in the sky, but we have already tasted it in Africa, where Sierra Leone’s agenda for prosperity 2013–2017 and the Liberia Vision 2030 exemplify the potential of such programs. Ne"
L18-1604,D09-1074,0,0.158285,"nre-agnostic system. Finally, we train and use genre classifiers to route test documents to the most appropriate genre systems. The results of these experiments show that our multi-genre benchmarks can serve to advance research on text genre adaptation for MT. Keywords: Machine translation, parallel benchmarks, text genres, genre adaptation 1. Introduction Text genre differences have shown to affect the output quality of statistical machine translation (SMT) systems: SMT systems trained on one genre often achieve poor performance when used for translating another genre (Foster and Kuhn, 2007; Matsoukas et al., 2009; Wang et al., 2012, among others). In addition, even if different genres in a test set are both present in equal amounts in the bilingual training data, performance differences between the test genres can be large, mostly due to poor model coverage for certain genres (van der Wees et al., 2015a; van der Wees et al., 2015b). In this paper, we evaluate the impact of genre differences on phrase-based SMT for a diverse set of language pairs, covering both commonly and rarely studied language pairs. For common language pairs, parallel training data is abundant but limited to a few genres such as p"
L18-1604,moore-2002-fast,0,0.166016,"anguage abbreviation in the url, e.g., replacing ‘en-US’ with ‘ar’. To determine the genre of each text we use categories indicated on the respective website. For example, websites that support news articles and user comments (i.e., the genres news and colloquial), have clear website sections for these different genres. While not all language-genre combinations are equally common, we can construct at least a translation test set for each of the four genres in each of the four language pairs. To do so, we first create sentence-parallel corpora using a combination of Moore’s sentence alignment (Moore, 2002) and Champollion sentence alignment (Ma, 2006). We then organize the collected bilingual data into training, development, and test sets, such that each portion contains documents from non-overlapping time periods.2 We tokenize 2 The benchmarks are available for download http://ilps.science.uva.nl/resources/ genre-benchmarks. at Genre Example sentence(s) Colloquial Ministers should be sitting and attending the oath, like in Italy. Editorial This may sound like pie in the sky, but we have already tasted it in Africa, where Sierra Leone’s agenda for prosperity 2013–2017 and the Liberia Vision 203"
L18-1604,P02-1040,0,0.114321,"data. Genres not covered in the training data have to be translated using a system trained on a mixture of genres or on one of the other genre-specific systems. For example, editorial Persian→English data is scarce, so for Persian editorial documents we have to resort to our colloquial, news, speech or mixed system. In addition to using the fill-up approach, we tune each genre-specific system on a development set covering only the genre of interest. 3.2. Results Tables 3a–3d show the translation quality results for all language pairs. For each language pair, we measure case-insensitive BLEU (Papineni et al., 2002) for our four test genres with the available genre-specific systems as well as the genre-agnostic system. Note that some Arabic→English and Chinese→English BLEU scores might be lower than those reported in literature since our test data contains only a single reference translation. The results confirm our expectation that the various test set genres benefit from being translated using a genreoptimized system rather than using a general system: generally, the highest BLEU scores are located on the diagonal of each table. In cases where no genre-specific system is available, we see that the best"
L18-1604,2011.eamt-1.40,0,0.0221275,"al., 2013; Chen et al., 2014; Kobus et al., 2016; Sennrich et al., 2016; Freitag and AlOnaizan, 2016; Chu et al., 2017, among others). While this is a fair assumption in a controlled research setting, it is less realistic in real world applications, such as general-purpose online MT services. In this paper, we provide the SMT system with a test document of unknown origin, and we show that we can use automatic genre classification to guide each test document to the most appropriate pre-trained system. While similar setups have been used in previous work (Xu et al., 2007; Banerjee et al., 2010; Pecina et al., 2011; Wang et al., 2012; Pecina et al., 2015), we are the first to extend this setup to four genres and four language pairs. Finally, we show that an adaptation method based on automatic classifiers also improves translation quality for genres with no parallel training data available. 2. Multi-genre benchmarks In this section, we describe the construction of multi-genre corpora for four language pairs and four genres, which we obtained using an automated web-harvesting process. 2.1. Language pairs and genres While most research in MT is evaluated on a small number of well resourced language pairs"
L18-1604,W05-0908,0,0.150376,"Missing"
L18-1604,P16-1009,0,0.0205039,"aining and evaluation corpora covering four genres for four language pairs that we automatically harvested from the web. Next, we evaluate the usefulness of the newly collected bilingual resources by exploiting them for genre adaptation of SMT systems. Most existing adaptation approaches depend on the availability of provenance information and make the strong assumption that a translation task has known domain, genre or topic that is exploited to adapt the system (Matsoukas et al., 2009; Foster et al., 2010; Bisazza and Federico, 2012; Chen et al., 2013; Chen et al., 2014; Kobus et al., 2016; Sennrich et al., 2016; Freitag and AlOnaizan, 2016; Chu et al., 2017, among others). While this is a fair assumption in a controlled research setting, it is less realistic in real world applications, such as general-purpose online MT services. In this paper, we provide the SMT system with a test document of unknown origin, and we show that we can use automatic genre classification to guide each test document to the most appropriate pre-trained system. While similar setups have been used in previous work (Xu et al., 2007; Banerjee et al., 2010; Pecina et al., 2011; Wang et al., 2012; Pecina et al., 2015), we are th"
L18-1604,C00-2117,0,0.0297715,"Missing"
L18-1604,W15-4304,1,0.893602,"Missing"
L18-1604,P15-2092,1,0.87531,"Missing"
L18-1604,2012.amta-papers.18,0,0.298726,"ally, we train and use genre classifiers to route test documents to the most appropriate genre systems. The results of these experiments show that our multi-genre benchmarks can serve to advance research on text genre adaptation for MT. Keywords: Machine translation, parallel benchmarks, text genres, genre adaptation 1. Introduction Text genre differences have shown to affect the output quality of statistical machine translation (SMT) systems: SMT systems trained on one genre often achieve poor performance when used for translating another genre (Foster and Kuhn, 2007; Matsoukas et al., 2009; Wang et al., 2012, among others). In addition, even if different genres in a test set are both present in equal amounts in the bilingual training data, performance differences between the test genres can be large, mostly due to poor model coverage for certain genres (van der Wees et al., 2015a; van der Wees et al., 2015b). In this paper, we evaluate the impact of genre differences on phrase-based SMT for a diverse set of language pairs, covering both commonly and rarely studied language pairs. For common language pairs, parallel training data is abundant but limited to a few genres such as parliamentary and le"
L18-1604,2007.mtsummit-papers.68,0,0.215911,"10; Bisazza and Federico, 2012; Chen et al., 2013; Chen et al., 2014; Kobus et al., 2016; Sennrich et al., 2016; Freitag and AlOnaizan, 2016; Chu et al., 2017, among others). While this is a fair assumption in a controlled research setting, it is less realistic in real world applications, such as general-purpose online MT services. In this paper, we provide the SMT system with a test document of unknown origin, and we show that we can use automatic genre classification to guide each test document to the most appropriate pre-trained system. While similar setups have been used in previous work (Xu et al., 2007; Banerjee et al., 2010; Pecina et al., 2011; Wang et al., 2012; Pecina et al., 2015), we are the first to extend this setup to four genres and four language pairs. Finally, we show that an adaptation method based on automatic classifiers also improves translation quality for genres with no parallel training data available. 2. Multi-genre benchmarks In this section, we describe the construction of multi-genre corpora for four language pairs and four genres, which we obtained using an automated web-harvesting process. 2.1. Language pairs and genres While most research in MT is evaluated on a sm"
N16-1036,W14-4012,0,0.0588047,"Missing"
N16-1036,P15-1033,0,0.0192988,"features within LSTMs in their sentence compression model hurts the performance of overall system. They then hypothesize that a basic LSTM is powerful enough to capture syntactic aspects which are useful for compression. Introduction Recurrent Neural Networks (RNNs) (Elman, 1990; Mikolov et al., 2010) are remarkably powerful models for sequential data. Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997), a specific architecture of RNN, has a track record of success in many natural language processing tasks such as language modeling (J´ozefowicz et al., 2015), dependency parsing (Dyer et al., 2015), sentence com1 Our code and data are available at https://github. com/ketranm/RMN To understand and explain which linguistic dimensions are captured by an LSTM is non-trivial. This is due to the fact that the sequences of input histories are compressed into several dense vectors by the LSTM’s components whose purposes with respect to representing linguistic information is not evident. To our knowledge, the only attempt to better understand the reasons of an LSTM’s performance and limitations is the work of Karpathy et al. (2015) by means of visualization experiments and cell activation statis"
N16-1036,D15-1042,0,0.0726834,"Missing"
N16-1036,W14-0406,0,0.0784721,"Missing"
N16-1036,J93-2004,0,0.0539502,"122.9 92.4 94.0 127.2 130.4 +tM-g –tM-g 118.6 129.7 88.9 96.6 128.8 135.7 RMR RM Table 2: Perplexity comparison including RMN variants with and without temporal matrix (tM) and linear (l) versus gating (g) composition function. overall performance is not as good as RM. This suggests that we need a better mechanism to address the interaction between MBs, which we leave to future work. Finally, the proposed gating composition function outperforms the linear one in most cases. For historical reasons, we also run a stacked threelayer LSTM and a RM(+tM-g) on the much smaller Penn Treebank dataset (Marcus et al., 1993) with the same setting described above. The respective perplexities are 126.1 and 123.5. 5 Results De Attention Analysis The goal of our RMN design is twofold: (i) to obtain better predictive power and (ii) to facilitate understanding of the model and discover patterns in data. In Section 4, we have validated the predictive power of the RMN and below we investigate the source of this performance based on linguistic assumptions of word co-occurrences and dependency structures. 5.1 Positional and lexical analysis As a first step towards understanding RMN, we look at the average attention weights"
N16-1036,P15-2084,0,0.0789589,"Missing"
N16-1036,R13-1079,0,0.0561822,"Missing"
N16-1036,simi-etal-2014-less,0,0.0136173,"occurrences (bottom of Figure 6), the most attended are argument heads (→arg), complement heads (→comp), object heads (→obj) and subjects (subj←). This suggests that RMN is mainly capturing predicate argument structure in Italian. Notice that syntactic annotation is never used to train the model, but only to analyze its predictions. We can also use RMN to discover which complex dependency paths are important for word prediction. To mention just a few examples, high attention on 2 The full plots are available at https://github.com/ ketranm/RMN. The German and Italian tag sets are explained in (Simi et al., 2014) and (Foth, 2006) respectively. 327 3 Some dependency directions, like obj← in Italian, are almost never observed due to order constraints of the language. adv← →aux →avz →kon konj← obja← →objc →obji →rel subj← [ALL] 0.5 0.4 0.3 0.2 0.1 [-15, -12] [-11, -8] [-7, -4] -3 -2 -1 →arg →comp comp← →con →mod mod← →obj →pred →sub subj← [ALL] 0.0 0.5 0.4 0.3 0.2 0.1 [-15, -12] [-11, -8] [-7, -4] -3 -2 -1 Figure 6: Average attention weights per position, broken down by dependency relation type+direction between the attended word and the word to predict. Top: German. Bottom: Italian. More distant positio"
N16-1036,D11-1014,0,0.0158104,"ir 5,400 experimental runs suggest that forget gates and output gates are the most critical components of LSTMs. J´ozefowicz et al. (2015) conduct and evaluate over ten thousand RNN architectures and find that the initialization of the forget gate bias is crucial to the LSTM’s performance. While these findings are important to help choosing appropriate LSTM architectures, they do not shed light on what information is captured by the hidden states of an LSTM. Bowman et al. (2015) show that a vanilla LSTM, such as described above, performs reasonably well compared to a recursive neural network (Socher et al., 2011) that explicitly exploits tree structures on two artificial datasets. They find that LSTMs can effectively exploit recursive structure in the artificial datasets. In contrast to these simple datasets containing a few logical operations in their experiments, natural languages exhibit highly complex patterns. The extent to which linguistic assumptions about syntactic structures and compositional semantics are reflected in LSTMs is rather poorly understood. Thus it is desirable to have a more principled mechanism allowing us to inspect recurrent architectures from a linguistic perspective. In the"
N16-1036,W12-2704,0,0.0658696,"Missing"
N16-1036,W15-3001,1,\N,Missing
P12-1050,P06-1067,0,0.732893,"lated and described by a handful of linguistic rules. Notable examples are the family-unrelated Arabic-English and the related German-English language pairs. Interestingly, on these pairs, PSMT generally prevails over tree-based SMT1 , producing overall highquality outputs and isolated but critical reordering errors that undermine the global sentence meaning. Previous works on this type of language pairs have mostly focused on source reordering prior to translation (Xia and McCord, 2004; Collins et al., 2005), or on sophisticated reordering models integrated into decoding (Koehn et al., 2005; Al-Onaizan and Papineni, 2006), achieving mixed results. To merge the best of both approaches – namely, access to rich context in the former and natural coupling of reordering and translation decisions in the latter – we introduce modified distortion matrices: a novel method to seamlessly provide to the decoder a set of likely long reorderings pre-computed for a given input sentence. Added to the usual space of local permutations defined by a low distortion limit (DL), this results in a linguistically informed definition of the search space that simplifies the task of the in-decoder reordering model, besides decreasing its"
P12-1050,W11-2127,0,0.774583,"reordering for each input sentence, which is then translated monotonically (Xia and McCord, 2004) or with a low DL (Collins et al., 2005; Habash, 2007); non-deterministic reordering encodes multiple alternative reorderings into a word lattice and lets a monotonic decoder find the best path according to its models (Zhang et al., 2007; Crego and Habash, 2008; Elming and Habash, 2009; Niehues and Kolss, 2009). The latter approaches are ideally conceived as alternative to in-decoding reordering, and therefore require an exhaustive reordering rule set. Two recent works (Bisazza and Federico, 2010; Andreas et al., 2011) opt instead for a hybrid way: rules are used to generate multiple likely reorderings, but only for a specific phenomenon – namely verb-initial clauses in Arabic. This yields sparse reordering lattices that can be translated with a regular decoder performing additional reordering. Reordering rules for pre-processing are either manually written (Collins et al., 2005) or automatically learned from syntactic parses (Xia and McCord, 2004; Habash, 2007; Elming and Habash, 2009), shallow syntax chunks (Zhang et al., 2007; Crego and Habash, 2008) or part-of-speech labels (Niehues and Kolss, 2009). Si"
P12-1050,W05-0909,0,0.166472,"its authors to outperform the default word-based on an Arabic-English task. Finally, for German, we enable the Moses option monotone-atpunctuation which forbids reordering across punctuation marks. The DL is initially set to 5 words for Arabic-English and to 10 for German-English. According to our experience, these are the optimal settings for the evaluated tasks. Feature weights are optimized by minimum error training (Och, 2003) on the development sets (dev06-NW and test08). 7.2 Translation quality and efficiency results We evaluate translations with BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005). As these scores are only indirectly sensitive to word order, we also compute KRS or Kendall Reordering Score (Birch et al., 2010; Bisazza et al., 2011) which is a positive score based on the Kendall’s Tau distance between the source-output and sourcereference permutations. To isolate the impact of our techniques on problematic reordering, we extract from each test set the sentences that got permuted by “oracle reordering” (see Sect. 5). These constitute about a half of the Arabic sentences, and about a third of the German. We refer to the KRS computed on these test subsets as KRS(R). Statist"
P12-1050,W10-1735,1,0.93138,"at finding a single optimal reordering for each input sentence, which is then translated monotonically (Xia and McCord, 2004) or with a low DL (Collins et al., 2005; Habash, 2007); non-deterministic reordering encodes multiple alternative reorderings into a word lattice and lets a monotonic decoder find the best path according to its models (Zhang et al., 2007; Crego and Habash, 2008; Elming and Habash, 2009; Niehues and Kolss, 2009). The latter approaches are ideally conceived as alternative to in-decoding reordering, and therefore require an exhaustive reordering rule set. Two recent works (Bisazza and Federico, 2010; Andreas et al., 2011) opt instead for a hybrid way: rules are used to generate multiple likely reorderings, but only for a specific phenomenon – namely verb-initial clauses in Arabic. This yields sparse reordering lattices that can be translated with a regular decoder performing additional reordering. Reordering rules for pre-processing are either manually written (Collins et al., 2005) or automatically learned from syntactic parses (Xia and McCord, 2004; Habash, 2007; Elming and Habash, 2009), shallow syntax chunks (Zhang et al., 2007; Crego and Habash, 2008) or part-of-speech labels (Niehu"
P12-1050,2011.eamt-1.3,0,0.0467422,"g is triggered by any verb chunk. 5 Reordering selection The number of chunk-based reorderings per sentence varies according to the rule set, to the size of chunks and to the context. A high degree of fuzziness can complicate the decoding process, leaving too much work to the in-decoding reordering model. A solution to this problem is using an external model to score the rule-generated reorderings and discard the less probable ones. In such a way, a further part of reordering complexity is taken out of decoding. At this end, instead of using a Support Vector Machine classifier as was done in (Bisazza et al., 2011), we apply reordered n-gram models that are lighterweight and more suitable for a ranking task. Differently from Feng et al. (2010), we train our models on partially reordered data and at the level of chunks. Chunks can be represented simply by their type label (such as VC or NC), but also by a combination of the type and head word, to obtain finer lexicalized distributions. LMs trained on different chunk representations can also be applied jointly, by log-linear combination. We perform reordering selection as follows: 1. Chunk-based reordering rules are applied deterministically to the source"
P12-1050,P05-1033,0,0.0490524,"well-known SMT benchmarks. 1 Introduction Despite the large research effort devoted to the modeling of word reordering, this remains one of the main obstacles to the development of accurate SMT systems for many language pairs. On one hand, the phrase-based approach (PSMT) (Och, 2002; Zens et al., 2002; Koehn et al., 2003), with its shallow and loose modeling of linguistic equivalences, appears as the most competitive choice for closely related language pairs with similar clause structures, both in terms of quality and of efficiency. On the other, tree-based approaches (Wu, 1997; Yamada, 2002; Chiang, 2005) gain advantage, at the cost of higher complexity and isomorphism assumptions, on language pairs with radically different word orders. Lying between these two extremes are language pairs where most of the reordering happens locally, and where long reorderings can be isolated and described by a handful of linguistic rules. Notable examples are the family-unrelated Arabic-English and the related German-English language pairs. Interestingly, on these pairs, PSMT generally prevails over tree-based SMT1 , producing overall highquality outputs and isolated but critical reordering errors that undermi"
P12-1050,P11-2031,0,0.0232596,"ermuted by “oracle reordering” (see Sect. 5). These constitute about a half of the Arabic sentences, and about a third of the German. We refer to the KRS computed on these test subsets as KRS(R). Statistically significant differences are assessed by approximate randomization as in (Riezler and Maxwell, 2005)13 . Tab. 1 reports results obtained by varying the DL junctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. 12 http://www2.lingsoft.fi/cgi-bin/gertwol 13 Translation scores and significance tests are computed with the tools multeval (Clark et al., 2011) and sigf (Pad´o, 2006). 484 and modifying the distortion function. To evaluate the reordering selection technique, we also compare the encoding of all rule-generated reorderings against only the 3 best per rule-matching sequence, as ranked by our best performing reordered LM (see end of Sect. 5). We mark the DL with a ‘+’ to denote that some longer jumps are being allowed by modified distortion. Run times refer to the translation of the first 100 sentences of eval08-NW and test09 by a 4-core processor. Arabic-English. As anticipated, raising the DL does not improve, but rather worsen performa"
P12-1050,P05-1066,0,0.585597,"emes are language pairs where most of the reordering happens locally, and where long reorderings can be isolated and described by a handful of linguistic rules. Notable examples are the family-unrelated Arabic-English and the related German-English language pairs. Interestingly, on these pairs, PSMT generally prevails over tree-based SMT1 , producing overall highquality outputs and isolated but critical reordering errors that undermine the global sentence meaning. Previous works on this type of language pairs have mostly focused on source reordering prior to translation (Xia and McCord, 2004; Collins et al., 2005), or on sophisticated reordering models integrated into decoding (Koehn et al., 2005; Al-Onaizan and Papineni, 2006), achieving mixed results. To merge the best of both approaches – namely, access to rich context in the former and natural coupling of reordering and translation decisions in the latter – we introduce modified distortion matrices: a novel method to seamlessly provide to the decoder a set of likely long reorderings pre-computed for a given input sentence. Added to the usual space of local permutations defined by a low distortion limit (DL), this results in a linguistically informe"
P12-1050,W08-0307,0,0.120168,"ate the proposed techniques on two popular MT tasks. 2 Previous work Pre-processing approaches to word reordering aim at permuting input words in a way that minimizes the reordering needed for translation: deterministic reordering aims at finding a single optimal reordering for each input sentence, which is then translated monotonically (Xia and McCord, 2004) or with a low DL (Collins et al., 2005; Habash, 2007); non-deterministic reordering encodes multiple alternative reorderings into a word lattice and lets a monotonic decoder find the best path according to its models (Zhang et al., 2007; Crego and Habash, 2008; Elming and Habash, 2009; Niehues and Kolss, 2009). The latter approaches are ideally conceived as alternative to in-decoding reordering, and therefore require an exhaustive reordering rule set. Two recent works (Bisazza and Federico, 2010; Andreas et al., 2011) opt instead for a hybrid way: rules are used to generate multiple likely reorderings, but only for a specific phenomenon – namely verb-initial clauses in Arabic. This yields sparse reordering lattices that can be translated with a regular decoder performing additional reordering. Reordering rules for pre-processing are either manually"
P12-1050,N04-4038,0,0.355651,"Missing"
P12-1050,W09-0809,0,0.0887519,"ues on two popular MT tasks. 2 Previous work Pre-processing approaches to word reordering aim at permuting input words in a way that minimizes the reordering needed for translation: deterministic reordering aims at finding a single optimal reordering for each input sentence, which is then translated monotonically (Xia and McCord, 2004) or with a low DL (Collins et al., 2005; Habash, 2007); non-deterministic reordering encodes multiple alternative reorderings into a word lattice and lets a monotonic decoder find the best path according to its models (Zhang et al., 2007; Crego and Habash, 2008; Elming and Habash, 2009; Niehues and Kolss, 2009). The latter approaches are ideally conceived as alternative to in-decoding reordering, and therefore require an exhaustive reordering rule set. Two recent works (Bisazza and Federico, 2010; Andreas et al., 2011) opt instead for a hybrid way: rules are used to generate multiple likely reorderings, but only for a specific phenomenon – namely verb-initial clauses in Arabic. This yields sparse reordering lattices that can be translated with a regular decoder performing additional reordering. Reordering rules for pre-processing are either manually written (Collins et al.,"
P12-1050,2010.amta-papers.22,0,0.519305,"MT community. However, they are unsuitable to model long reordering as they classify as “discontinuous” every phrase that does not immediately follow or precede the last translated one. Lexicalized distortion models predict the jump from the last translated word to the next one, with a class for each possible jump length (Al-Onaizan and Papineni, 2006), or bin of lengths (Green et al., 2010). These models are conceived to deal with long reordering, but can easily suffer from data sparseness, especially for longer jumps occurring less frequently. Following a typical sequence modeling approach, Feng et al. (2010) train n-gram language models on source data previously reordered in accordance to the target language translation. This method does not directly model reordering decisions, but rather word sequences produced by them. Despite their high perplexities, reordered LMs yield some improvements when integrated to a PSMT baseline that already includes a discriminative phrase orientation model (Zens and Ney, 2006). In this work we use similar models to rank sets of chunk permutations. Attempting to improve the reordering space definition, Yahyaei and Monz (2010) train a classifier to guess the most lik"
P12-1050,D08-1089,0,0.620207,"r distortion to more complex models that are conditioned on the words being translated. 479 The linear distortion model (Koehn et al., 2003) encourages monotonic translations by penalizing source position jumps proportionally to their length. If used alone, this model is inadequate for language pairs with different word orders. Green et al. (2010) tried to improve it with a future distortion cost estimate. Thus they were able to preserve baseline performance at a very high DL, but not to improve it. Lexicalized phrase orientation models (Tillmann, 2004; Koehn et al., 2005; Zens and Ney, 2006; Galley and Manning, 2008) predict the orientation of a phrase with respect to the last translated one. These models are known to well handle local reordering and are widely adopted by the PSMT community. However, they are unsuitable to model long reordering as they classify as “discontinuous” every phrase that does not immediately follow or precede the last translated one. Lexicalized distortion models predict the jump from the last translated word to the next one, with a class for each possible jump length (Al-Onaizan and Papineni, 2006), or bin of lengths (Green et al., 2010). These models are conceived to deal with"
P12-1050,N10-1129,0,0.724158,"in all the systems used to evaluate our methods. Another large body of work is devoted to the modeling of reordering decisions inside decoding, based on a decomposition of the problem into a sequence of basic reordering steps. Existing approaches range from basic linear distortion to more complex models that are conditioned on the words being translated. 479 The linear distortion model (Koehn et al., 2003) encourages monotonic translations by penalizing source position jumps proportionally to their length. If used alone, this model is inadequate for language pairs with different word orders. Green et al. (2010) tried to improve it with a future distortion cost estimate. Thus they were able to preserve baseline performance at a very high DL, but not to improve it. Lexicalized phrase orientation models (Tillmann, 2004; Koehn et al., 2005; Zens and Ney, 2006; Galley and Manning, 2008) predict the orientation of a phrase with respect to the last translated one. These models are known to well handle local reordering and are widely adopted by the PSMT community. However, they are unsuitable to model long reordering as they classify as “discontinuous” every phrase that does not immediately follow or preced"
P12-1050,2007.mtsummit-papers.29,0,0.128389,"f Korea, 8-14 July 2012. 2012 Association for Computational Linguistics reordered n-gram LMs and, finally, explain the notion of modified distortion matrices. In the last part of the paper, we evaluate the proposed techniques on two popular MT tasks. 2 Previous work Pre-processing approaches to word reordering aim at permuting input words in a way that minimizes the reordering needed for translation: deterministic reordering aims at finding a single optimal reordering for each input sentence, which is then translated monotonically (Xia and McCord, 2004) or with a low DL (Collins et al., 2005; Habash, 2007); non-deterministic reordering encodes multiple alternative reorderings into a word lattice and lets a monotonic decoder find the best path according to its models (Zhang et al., 2007; Crego and Habash, 2008; Elming and Habash, 2009; Niehues and Kolss, 2009). The latter approaches are ideally conceived as alternative to in-decoding reordering, and therefore require an exhaustive reordering rule set. Two recent works (Bisazza and Federico, 2010; Andreas et al., 2011) opt instead for a hybrid way: rules are used to generate multiple likely reorderings, but only for a specific phenomenon – namely"
P12-1050,W10-1710,1,0.928179,"Missing"
P12-1050,N03-1017,0,0.206016,"ode these reorderings by modifying selected entries of the distortion cost matrix, on a per-sentence basis. In this way, we expand the search space by a much finer degree than if we simply raised the distortion limit. The proposed techniques are tested on Arabic-English and German-English using well-known SMT benchmarks. 1 Introduction Despite the large research effort devoted to the modeling of word reordering, this remains one of the main obstacles to the development of accurate SMT systems for many language pairs. On one hand, the phrase-based approach (PSMT) (Och, 2002; Zens et al., 2002; Koehn et al., 2003), with its shallow and loose modeling of linguistic equivalences, appears as the most competitive choice for closely related language pairs with similar clause structures, both in terms of quality and of efficiency. On the other, tree-based approaches (Wu, 1997; Yamada, 2002; Chiang, 2005) gain advantage, at the cost of higher complexity and isomorphism assumptions, on language pairs with radically different word orders. Lying between these two extremes are language pairs where most of the reordering happens locally, and where long reorderings can be isolated and described by a handful of ling"
P12-1050,2005.iwslt-1.8,0,0.686546,"orderings can be isolated and described by a handful of linguistic rules. Notable examples are the family-unrelated Arabic-English and the related German-English language pairs. Interestingly, on these pairs, PSMT generally prevails over tree-based SMT1 , producing overall highquality outputs and isolated but critical reordering errors that undermine the global sentence meaning. Previous works on this type of language pairs have mostly focused on source reordering prior to translation (Xia and McCord, 2004; Collins et al., 2005), or on sophisticated reordering models integrated into decoding (Koehn et al., 2005; Al-Onaizan and Papineni, 2006), achieving mixed results. To merge the best of both approaches – namely, access to rich context in the former and natural coupling of reordering and translation decisions in the latter – we introduce modified distortion matrices: a novel method to seamlessly provide to the decoder a set of likely long reorderings pre-computed for a given input sentence. Added to the usual space of local permutations defined by a low distortion limit (DL), this results in a linguistically informed definition of the search space that simplifies the task of the in-decoder reorderi"
P12-1050,P07-2045,1,0.012963,"e sentence. If compared to the word reordering lattices used by Bisazza and Federico (2010) and Andreas et al. (2011), modified distortion matrices provide a more compact, implicit way to encode likely reorderings in a sentence-specific fashion. Matrix representation does not require multiplication of nodes for the same 8 In L×F mode, instead, each chunk-to-chunk jump would yield exactly one word shortcut, for a total of three. 483 7 Evaluation In this section we evaluate the impact of modified distortion matrices on two news translation tasks. Matrices were integrated into the Moses toolkit (Koehn et al., 2007) using a sentencelevel XML markup. The list of word shortcuts for each sentence is provided as an XML tag that is parsed by the decoder to modify the distortion matrix just before starting the search. As usual, the distortion matrix is queried by the distortion penalty generator and by the hypothesis expander9 . 7.1 Experimental setup For Arabic-English, we use the union of all indomain parallel corpora provided for the NIST- MT 09 evaluation10 for a total of 986K sentences, 31M English words. The target LM is trained on the English side of all available NIST- MT 09 parallel data, UN included"
P12-1050,N06-1014,0,0.065959,"tion class of a new hypothesis, thus they are not affected by changes in the matrix. 10 That is everything except the small GALE corpus and the UN corpus. As reported by Green et al. (2010) the removal of UN data does not affect baseline performances on news test. 11 The Arabic Treebank tokenization scheme isolates conand compound splitting is performed with Tree Tagger (Schmid, 1994) and the Gertwol morphological analyser (Koskenniemi and Haapalainen, 1994)12 . Using Moses we build competitive baselines on the training data described above. Word alignment is produced by the Berkeley Aligner (Liang et al., 2006). The decoder is based on the log-linear combination of a phrase translation model, a lexicalized reordering model, a 6-gram target language model, distortion cost, word and phrase penalties. The reordering model is a hierarchical phrase orientation model (Tillmann, 2004; Koehn et al., 2005; Galley and Manning, 2008) trained on all the available parallel data. We choose the hierarchical variant, as it was shown by its authors to outperform the default word-based on an Arabic-English task. Finally, for German, we enable the Moses option monotone-atpunctuation which forbids reordering across pun"
P12-1050,W09-0435,0,0.041795,"ks. 2 Previous work Pre-processing approaches to word reordering aim at permuting input words in a way that minimizes the reordering needed for translation: deterministic reordering aims at finding a single optimal reordering for each input sentence, which is then translated monotonically (Xia and McCord, 2004) or with a low DL (Collins et al., 2005; Habash, 2007); non-deterministic reordering encodes multiple alternative reorderings into a word lattice and lets a monotonic decoder find the best path according to its models (Zhang et al., 2007; Crego and Habash, 2008; Elming and Habash, 2009; Niehues and Kolss, 2009). The latter approaches are ideally conceived as alternative to in-decoding reordering, and therefore require an exhaustive reordering rule set. Two recent works (Bisazza and Federico, 2010; Andreas et al., 2011) opt instead for a hybrid way: rules are used to generate multiple likely reorderings, but only for a specific phenomenon – namely verb-initial clauses in Arabic. This yields sparse reordering lattices that can be translated with a regular decoder performing additional reordering. Reordering rules for pre-processing are either manually written (Collins et al., 2005) or automatically le"
P12-1050,P03-1021,0,0.0194585,"ntation model (Tillmann, 2004; Koehn et al., 2005; Galley and Manning, 2008) trained on all the available parallel data. We choose the hierarchical variant, as it was shown by its authors to outperform the default word-based on an Arabic-English task. Finally, for German, we enable the Moses option monotone-atpunctuation which forbids reordering across punctuation marks. The DL is initially set to 5 words for Arabic-English and to 10 for German-English. According to our experience, these are the optimal settings for the evaluated tasks. Feature weights are optimized by minimum error training (Och, 2003) on the development sets (dev06-NW and test08). 7.2 Translation quality and efficiency results We evaluate translations with BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005). As these scores are only indirectly sensitive to word order, we also compute KRS or Kendall Reordering Score (Birch et al., 2010; Bisazza et al., 2011) which is a positive score based on the Kendall’s Tau distance between the source-output and sourcereference permutations. To isolate the impact of our techniques on problematic reordering, we extract from each test set the sentences that got permuted by “"
P12-1050,P02-1040,0,0.0880848,"chical variant, as it was shown by its authors to outperform the default word-based on an Arabic-English task. Finally, for German, we enable the Moses option monotone-atpunctuation which forbids reordering across punctuation marks. The DL is initially set to 5 words for Arabic-English and to 10 for German-English. According to our experience, these are the optimal settings for the evaluated tasks. Feature weights are optimized by minimum error training (Och, 2003) on the development sets (dev06-NW and test08). 7.2 Translation quality and efficiency results We evaluate translations with BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005). As these scores are only indirectly sensitive to word order, we also compute KRS or Kendall Reordering Score (Birch et al., 2010; Bisazza et al., 2011) which is a positive score based on the Kendall’s Tau distance between the source-output and sourcereference permutations. To isolate the impact of our techniques on problematic reordering, we extract from each test set the sentences that got permuted by “oracle reordering” (see Sect. 5). These constitute about a half of the Arabic sentences, and about a third of the German. We refer to the KRS computed on"
P12-1050,W05-0908,0,0.124297,"RS or Kendall Reordering Score (Birch et al., 2010; Bisazza et al., 2011) which is a positive score based on the Kendall’s Tau distance between the source-output and sourcereference permutations. To isolate the impact of our techniques on problematic reordering, we extract from each test set the sentences that got permuted by “oracle reordering” (see Sect. 5). These constitute about a half of the Arabic sentences, and about a third of the German. We refer to the KRS computed on these test subsets as KRS(R). Statistically significant differences are assessed by approximate randomization as in (Riezler and Maxwell, 2005)13 . Tab. 1 reports results obtained by varying the DL junctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. 12 http://www2.lingsoft.fi/cgi-bin/gertwol 13 Translation scores and significance tests are computed with the tools multeval (Clark et al., 2011) and sigf (Pad´o, 2006). 484 and modifying the distortion function. To evaluate the reordering selection technique, we also compare the encoding of all rule-generated reorderings against only the 3 best per rule-matching sequence, as ranked by our best performing reordered LM (see end of S"
P12-1050,N04-4026,0,0.812663,"dering steps. Existing approaches range from basic linear distortion to more complex models that are conditioned on the words being translated. 479 The linear distortion model (Koehn et al., 2003) encourages monotonic translations by penalizing source position jumps proportionally to their length. If used alone, this model is inadequate for language pairs with different word orders. Green et al. (2010) tried to improve it with a future distortion cost estimate. Thus they were able to preserve baseline performance at a very high DL, but not to improve it. Lexicalized phrase orientation models (Tillmann, 2004; Koehn et al., 2005; Zens and Ney, 2006; Galley and Manning, 2008) predict the orientation of a phrase with respect to the last translated one. These models are known to well handle local reordering and are widely adopted by the PSMT community. However, they are unsuitable to model long reordering as they classify as “discontinuous” every phrase that does not immediately follow or precede the last translated one. Lexicalized distortion models predict the jump from the last translated word to the next one, with a class for each possible jump length (Al-Onaizan and Papineni, 2006), or bin of le"
P12-1050,J97-3002,0,0.373619,"nd German-English using well-known SMT benchmarks. 1 Introduction Despite the large research effort devoted to the modeling of word reordering, this remains one of the main obstacles to the development of accurate SMT systems for many language pairs. On one hand, the phrase-based approach (PSMT) (Och, 2002; Zens et al., 2002; Koehn et al., 2003), with its shallow and loose modeling of linguistic equivalences, appears as the most competitive choice for closely related language pairs with similar clause structures, both in terms of quality and of efficiency. On the other, tree-based approaches (Wu, 1997; Yamada, 2002; Chiang, 2005) gain advantage, at the cost of higher complexity and isomorphism assumptions, on language pairs with radically different word orders. Lying between these two extremes are language pairs where most of the reordering happens locally, and where long reorderings can be isolated and described by a handful of linguistic rules. Notable examples are the family-unrelated Arabic-English and the related German-English language pairs. Interestingly, on these pairs, PSMT generally prevails over tree-based SMT1 , producing overall highquality outputs and isolated but critical r"
P12-1050,C04-1073,0,0.401205,"between these two extremes are language pairs where most of the reordering happens locally, and where long reorderings can be isolated and described by a handful of linguistic rules. Notable examples are the family-unrelated Arabic-English and the related German-English language pairs. Interestingly, on these pairs, PSMT generally prevails over tree-based SMT1 , producing overall highquality outputs and isolated but critical reordering errors that undermine the global sentence meaning. Previous works on this type of language pairs have mostly focused on source reordering prior to translation (Xia and McCord, 2004; Collins et al., 2005), or on sophisticated reordering models integrated into decoding (Koehn et al., 2005; Al-Onaizan and Papineni, 2006), achieving mixed results. To merge the best of both approaches – namely, access to rich context in the former and natural coupling of reordering and translation decisions in the latter – we introduce modified distortion matrices: a novel method to seamlessly provide to the decoder a set of likely long reorderings pre-computed for a given input sentence. Added to the usual space of local permutations defined by a low distortion limit (DL), this results in a"
P12-1050,2010.iwslt-papers.19,0,0.422847,"llowing a typical sequence modeling approach, Feng et al. (2010) train n-gram language models on source data previously reordered in accordance to the target language translation. This method does not directly model reordering decisions, but rather word sequences produced by them. Despite their high perplexities, reordered LMs yield some improvements when integrated to a PSMT baseline that already includes a discriminative phrase orientation model (Zens and Ney, 2006). In this work we use similar models to rank sets of chunk permutations. Attempting to improve the reordering space definition, Yahyaei and Monz (2010) train a classifier to guess the most likely jump length at each source position, then use its predictions to dynamically set the DL. Translation improvements are obtained on a simple task with mostly short sentences (BTEC). Modifying the distortion function, as proposed in this paper, makes it possible to expand the pemutation search space by a much finer degree than varying the DL does. 3 Long reordering patterns Our study focuses on Arabic-English and GermanEnglish: two language pairs characterized by uneven distributions of word-reordering phenomena, with long-range movements concentrating"
P12-1050,W06-3108,0,0.361092,"Missing"
P12-1050,2002.tmi-tutorials.2,0,0.0700091,"ion. Finally we encode these reorderings by modifying selected entries of the distortion cost matrix, on a per-sentence basis. In this way, we expand the search space by a much finer degree than if we simply raised the distortion limit. The proposed techniques are tested on Arabic-English and German-English using well-known SMT benchmarks. 1 Introduction Despite the large research effort devoted to the modeling of word reordering, this remains one of the main obstacles to the development of accurate SMT systems for many language pairs. On one hand, the phrase-based approach (PSMT) (Och, 2002; Zens et al., 2002; Koehn et al., 2003), with its shallow and loose modeling of linguistic equivalences, appears as the most competitive choice for closely related language pairs with similar clause structures, both in terms of quality and of efficiency. On the other, tree-based approaches (Wu, 1997; Yamada, 2002; Chiang, 2005) gain advantage, at the cost of higher complexity and isomorphism assumptions, on language pairs with radically different word orders. Lying between these two extremes are language pairs where most of the reordering happens locally, and where long reorderings can be isolated and described"
P12-1050,W07-0401,0,0.116683,"Missing"
P12-1050,C08-1144,0,0.0529759,"results in a linguistically informed definition of the search space that simplifies the task of the in-decoder reordering model, besides decreasing its complexity. The paper is organized as follows. After reviewing a selection of relevant works, we analyze salient reordering patterns in Arabic-English and GermanEnglish, and describe the corresponding chunkbased reordering rule sets. In the following sections we present a reordering selection technique based on 1 A good comparison of phrase-based and tree-based approaches across language pairs with different reordering levels can be found in (Zollmann et al., 2008). 478 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 478–487, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics reordered n-gram LMs and, finally, explain the notion of modified distortion matrices. In the last part of the paper, we evaluate the proposed techniques on two popular MT tasks. 2 Previous work Pre-processing approaches to word reordering aim at permuting input words in a way that minimizes the reordering needed for translation: deterministic reordering aims at finding a single optimal reordering"
P15-2092,D10-1044,0,0.190732,"Missing"
P15-2092,D11-1033,0,0.189801,"Missing"
P15-2092,W12-3154,0,0.061537,"ry to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Genre Topic Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 NW UG Total Culture segments tokens 654 15.5K 507 14.9K 1161 30.4K Economy segments tokens 500 16.0K 578 15.5K 1078 31.5K Health segments tokens 384 9.7K 319 9.3K 703 19.1K Pol"
P15-2092,N10-1064,0,0.345414,"ic and genre distributions, we have shown that earlier findings explaining the differences across topics only explain to a limited degree translation performance differences across genres. Our analysis shows that genre-specific errors are more attributable to model-coverage errors than to suboptimal scoring of existing translation candidates. This suggests that future work on improving SMT across genres needs to investigate approaches that increase model coverage. Our fine-grained manual error analysis at the word level also suggests that source coverage could benefit from text normalization (Bertoldi et al., 2010). Finally, we make both our benchmark and the manual OOV annotations publicly available. is a subclass of spelling errors). In total, we consider 17 subclasses which we group into five main classes, see Table 5 for examples. Table 6 shows the type level percentages3 for each main OOV class per genre or topic. When comparing the two genres, a number of observations emerge. Firstly, rare but correct words (e.g., proper nouns and technical terms, both regular issues for adaptation in SMT) make up the vast majority of the OOVs in NW, but are relatively infrequent in UG. By contrast, OOVs containin"
P15-2092,E14-1035,0,0.074205,"Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Genre Topic Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 NW UG Total Culture segments tokens 654 15.5K 507 14.9K 1161 30.4K Economy segments tokens 500 16.0K 578 15.5K 1078 31.5K Health segments tokens 384 9.7K 319 9.3K 703 19.1K Politics segments tokens 494 15.8K 646 15.8K 1140 31.6K Security segments tokens 532 16.1K 826 15.9K 1358 32.0K Total segments tokens 2564 73.2K 2876 71.3K 5440 144.5K"
P15-2092,E12-1045,1,0.885574,"sed as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Genre Topic Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 NW UG Total Culture segments tokens 654 15.5K 507 14.9K 1161 30.4K Economy segments tokens 500 16.0K 578 15.5K 1078 31.5K Health segments tokens 384 9.7"
P15-2092,2014.amta-researchers.11,0,0.0316693,"Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Genre Topic Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 NW UG Total Culture segments tokens 654 15.5K 507 14.9K 1161 30.4K Economy segments tokens 500 16.0K 578 15.5K 1078 31.5K Health segments tokens 384 9.7K 319 9.3K 703 19.1K Politics segments tokens 494 15.8K 646 15.8K 1140 31.6K Security segments tokens 532 16.1K 826 15.9K 1358 32.0K Total segments tokens 2564 73.2K 2876 71.3K 5440 144.5K"
P15-2092,2011.iwslt-evaluation.18,1,0.880842,"04) concludes that the term genre is used as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Genre Topic Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 NW UG Total Culture segments tokens 654 15.5K 507 14.9K 1161 30.4K Economy segments tokens 500 16.0K 578 15."
P15-2092,W14-3358,0,0.0351605,"Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Genre Topic Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 NW UG Total Culture segments tokens 654 15.5K 507 14.9K 1161 30.4K Economy segments tokens 500 16.0K 578 15.5K 1078 31.5K Health segments tokens 384 9.7K 319 9.3K 703 19.1K Politics segments tokens 494 15.8K 646 15.8K 1140 31.6K Security segments tokens 532 16.1K 826 15.9K 1358 32.0K Total segments tokens 2564 73.2K 2876 71.3K 5440 144.5K"
P15-2092,P13-2122,0,0.0363058,"of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Genre Topic Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 NW UG Total Culture segments tokens 654 15.5K 507 14.9K 1161 30.4K Economy segments tokens 500 16.0K 578 15.5K 1078 31.5K Health segments tokens 384 9.7K 319 9.3K 703 19.1K Politics segments tokens 494 15.8K 646 15.8K 1140 31.6K Security segments tokens 532 16.1K 826 15.9K 1358 32.0K Total segments tokens 2564 73.2K 28"
P15-2092,N06-1003,0,0.175312,"Missing"
P15-2092,D11-1125,0,0.0593822,"what extent this gap can be attributed to genre differences. We first run a translation experiment on the Gen&Topic test set using our in-house phrasebased SMT system similar to Moses (Koehn et al., 2007). Features include lexicalized reordering, linear distortion with limit 5, and lexical weighting. In addition, we use a 5-gram linearly interpolated language model, trained on 1.6B words with Kneser-Ney smoothing (Chen and Goodman, 1999), that covers all topics and genres contained in the benchmark. We tune our system on the Gen&Topic development set using pairwise ranking optimization (PRO) (Hopkins and May, 2011). Naturally, performance differences across topics and genres depend on the degree to which both are represented in the parallel training data. To allow for fair comparison, we down-sample our available training data to be as balanced as possible in terms of topics and genres. The resulting system is trained on approximately 200K sentence pairs with 6M source tokens per genre, as much as is available for UG. All data originates from the same web sources as the documents in the benchmark. Our more competitive system (van der Wees et al., 2015) that uses also LDC-distributed data yields slightly"
P15-2092,P13-1126,0,0.175386,"Missing"
P15-2092,W14-1617,0,0.0921081,"Missing"
P15-2092,Q13-1035,0,0.0966154,"Missing"
P15-2092,2010.iwslt-papers.5,0,0.0602458,"tions, Santini (2004) concludes that the term genre is used as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Genre Topic Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 NW UG Total Culture segments tokens 654 15.5K 507 14.9K 1161 30.4K Economy segments to"
P15-2092,P12-2023,0,0.0276135,"hibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Genre Topic Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 NW UG Total Culture segments tokens 654 15.5K 507 14.9K 1161 30.4K Economy segments tokens 500 16.0K 578 15.5K 1078 31.5K Health segments tokens 384 9.7K 319 9.3K 703 19.1K Politics segments tokens 494 15.8K 646 15.8K 1140 31.6K Security segments tokens 532 16.1K 826 15.9K 1358 32.0K Total s"
P15-2092,P07-2045,0,0.0057445,"truction of the Gen&Topic data set and the use of down-sampled training data. On the other hand, the gap between different topics is only 0.6 BLEU points on average, and at most 1.1 (between culture and politics). A translation quality gap between genres has also been observed in past OpenMT evaluation campaigns. However, as the NIST benchmarks have not been controlled for topics across genres, it is unclear to what extent this gap can be attributed to genre differences. We first run a translation experiment on the Gen&Topic test set using our in-house phrasebased SMT system similar to Moses (Koehn et al., 2007). Features include lexicalized reordering, linear distortion with limit 5, and lexical weighting. In addition, we use a 5-gram linearly interpolated language model, trained on 1.6B words with Kneser-Ney smoothing (Chen and Goodman, 1999), that covers all topics and genres contained in the benchmark. We tune our system on the Gen&Topic development set using pairwise ranking optimization (PRO) (Hopkins and May, 2011). Naturally, performance differences across topics and genres depend on the degree to which both are represented in the parallel training data. To allow for fair comparison, we down-"
P15-2092,D09-1074,0,0.264401,"Missing"
P15-2092,P02-1040,0,0.0921924,"approximately 200K sentence pairs with 6M source tokens per genre, as much as is available for UG. All data originates from the same web sources as the documents in the benchmark. Our more competitive system (van der Wees et al., 2015) that uses also LDC-distributed data yields slightly higher BLEU scores, but is more favorable for NW than for UG translation tasks. Due to the strict data requirements in terms of topic and genre distributions, as well as the availability of sizable parallel training data, our current experimental set-up covers Arabic-English only. Table 3 compares BLEU scores (Papineni et al., 2002, 1 reference) of the Gen&Topic data, split down by topics and genres. We observe that trans4.2 Model coverage analysis Next, to explain the large performance gap between genres, we analyze the phrase lengths within Viterbi translations, source phrase and phrase pair recall, and phrase pair OOV of the Gen&Topic test set (Table 4). Average source-side phrase length We first compute the average number of source words contained in the phrases that our SMT system uses to produce the 1-best translations for the Gen&Topic test set. One can see that UG is translated with shorter phrases than NW, and"
P15-2092,E12-1055,0,0.0286028,"term genre is used as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Genre Topic Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 NW UG Total Culture segments tokens 654 15.5K 507 14.9K 1161 30.4K Economy segments tokens 500 16.0K 578 15.5K 1078 31.5K He"
P15-2092,W15-4304,1,0.787798,"Missing"
P15-2092,W07-0717,0,\N,Missing
P17-2070,Q15-1016,0,0.0383683,"ze). 3.3 41.1 30.4 41.6 32.8 42.9 33.9 n/a 36.2 36.6 37.8 LS-CIC Dimension 100 300 600 HTLE 40.3N 42.8N 43.4N 36.6N 40.9N 41.3N HTLEadd Exp 39.9N 41.8N 42.2 35.5M 37.9M 38.6 STLE 38.7M 41.0 41.0 36.8N 36.8 37.1 ant with window size c “ 10 and different embedding sizes (100, 300, 600) initialized randomly. We compare our models to several baselines: Skipgram (SGE) and the best-performing multisense embeddings model per word type (MSSG) (Neelakantan et al., 2014). All model variants are trained on the same training data with the same settings, following suggestions by Mikolov et al. (2013a) and Levy et al. (2015). For MSSG we use the best performing similarity measure (avgSimC) as proposed by Neelakantan et al. (2014). 3.2 Dimension Infer. 100 300 600 Sampled (Smp): SimTSE pws , wt q “ ř 1 cosphpwsτ q, opwc qq cosphpwsτ q, hpwtτ qq ` c C ÿ Expected (Exp): SimTSE pws , wt q “ ppτ q ppτ 1 q 1 cosphpwsτ q, hpwtτ qq ` τ,τ 1 ř τ τ,c cosphpws q, opwc qq C 1 ppτ q where hpwsτ q and hpwtτ q are the representations for substitution word s with topic τ and target word t with topic τ 1 respectively (cf. Section 2), wc are context words of wt taken from a sliding window of the same size as the embeddings, opwc q"
P17-2070,D15-1200,0,0.0718063,"Missing"
P17-2070,W16-2506,0,0.0154425,"mer et al., 2014). Unlike previous work (Szarvas et al., 2013; Kremer et al., 2014; Melamud et al., 2015) we do not use any syntactic information, motivated by the fact that high-quality parsers are not available for most languages. The evaluation is performed by computing the Generalized Average Precision (GAP) score (Kishida, 2005). We run HDP on the evaluation set and compute the similarity between target word wt and each substitution ws using two different inference methods in line with how we incorporate topics during training: Context-Aware Word Similarity Task Despite its shortcomings (Faruqui et al., 2016), word similarity remains the most frequently used method of evaluation in the literature. There are multiple test sets available but in almost all of them word pairs are considered out of context. To the best of our knowledge, the only word similarity data set providing word context is SCWS (Huang et al., 2012). To evaluate our models on SCWS, we run HDP on the data treating each word’s context as a separate document. We compute the similarity of each word pair as follows: Simpw1 , w2 q “ cosphpw1 q, hpw2 qq where hpwi q refers to any of the topic-sensitive representations defined in Section"
P17-2070,S07-1009,0,0.0739372,"2.1 HTLEadd Smp 39.4M 41.3N 41.8 30.4 STLE 35.2 36.7 39.0 32.9 32.7 31.5 32.3 33.0 31.7 33.9 Table 3: GAP scores on LS-SE07 and LS-CIC sets. For SGE + C we use the context embeddings to disambiguate the substitutions. Improvements over the best baseline (MSSG) are marked N at p ă .01 and M at p ă .05. ence of many polysemous target words makes this task more suitable for evaluating sense embedding. Following Melamud et al. (2015) we pool substitutions from different instances and rank them by the number of annotators that selected them for a given context. We use two evaluation sets: LS-SE07 (McCarthy and Navigli, 2007), and LS-CIC (Kremer et al., 2014). Unlike previous work (Szarvas et al., 2013; Kremer et al., 2014; Melamud et al., 2015) we do not use any syntactic information, motivated by the fact that high-quality parsers are not available for most languages. The evaluation is performed by computing the Generalized Average Precision (GAP) score (Kishida, 2005). We run HDP on the evaluation set and compute the similarity between target word wt and each substitution ws using two different inference methods in line with how we incorporate topics during training: Context-Aware Word Similarity Task Despite i"
P17-2070,W16-1817,0,0.0223469,"in representations that are able to distinguish between different meanings of a given word. Our models yield statistically significant improvements for the lexical substitution task indicating that commonly used single word representations, even when combined with contextual information, are insufficient for this task. 1 Introduction Word representations in the form of dense vectors, or word embeddings, capture semantic and syntactic information (Mikolov et al., 2013a; Pennington et al., 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016). Most of the existing models generate one representation per word and do not distinguish between different meanings of a word. However, many tasks can benefit from using multiple representations per word to capture polysemy (Reisinger and Mooney, 2010). There have been several attempts to build repositories for word senses (Miller, 1995; Navigli and Ponzetto, 2010), but this is laborious and limited to few languages. Moreover, defining a universal set of word senses is challenging as polysemous words can exist at many levels of 2 Topic-Sensitive Representations In this section we describe the"
P17-2070,W15-1501,0,0.0683766,".58 0.55 Model SGE SGE + C MSSG Table 2: Spearman’s rank correlation performance for the Word Similarity task on SCWS. 40.5 40.9 41.1 32.1 36.1 37.8 32.3 36.8 39.1 HTLE 39.8N 42.5N 43.0N 32.1 HTLEadd Smp 39.4M 41.3N 41.8 30.4 STLE 35.2 36.7 39.0 32.9 32.7 31.5 32.3 33.0 31.7 33.9 Table 3: GAP scores on LS-SE07 and LS-CIC sets. For SGE + C we use the context embeddings to disambiguate the substitutions. Improvements over the best baseline (MSSG) are marked N at p ă .01 and M at p ă .05. ence of many polysemous target words makes this task more suitable for evaluating sense embedding. Following Melamud et al. (2015) we pool substitutions from different instances and rank them by the number of annotators that selected them for a given context. We use two evaluation sets: LS-SE07 (McCarthy and Navigli, 2007), and LS-CIC (Kremer et al., 2014). Unlike previous work (Szarvas et al., 2013; Kremer et al., 2014; Melamud et al., 2015) we do not use any syntactic information, motivated by the fact that high-quality parsers are not available for most languages. The evaluation is performed by computing the Generalized Average Precision (GAP) score (Kishida, 2005). We run HDP on the evaluation set and compute the sim"
P17-2070,P12-1092,0,0.185994,"core (Kishida, 2005). We run HDP on the evaluation set and compute the similarity between target word wt and each substitution ws using two different inference methods in line with how we incorporate topics during training: Context-Aware Word Similarity Task Despite its shortcomings (Faruqui et al., 2016), word similarity remains the most frequently used method of evaluation in the literature. There are multiple test sets available but in almost all of them word pairs are considered out of context. To the best of our knowledge, the only word similarity data set providing word context is SCWS (Huang et al., 2012). To evaluate our models on SCWS, we run HDP on the data treating each word’s context as a separate document. We compute the similarity of each word pair as follows: Simpw1 , w2 q “ cosphpw1 q, hpw2 qq where hpwi q refers to any of the topic-sensitive representations defined in Section 2. Note that w1 and w2 can refer to the same word. Table 2 provides the Spearman’s correlation scores for different models against the human ranking. We see that with dimensions 100 and 300, two of our models obtain improvements over the baseline. The MSSG model of Neelakantan et al. (2014) performs only slightl"
P17-2070,E14-1057,0,0.282865,"Missing"
P17-2070,P14-1025,0,0.0273283,"distinguish between different meanings of a word. However, many tasks can benefit from using multiple representations per word to capture polysemy (Reisinger and Mooney, 2010). There have been several attempts to build repositories for word senses (Miller, 1995; Navigli and Ponzetto, 2010), but this is laborious and limited to few languages. Moreover, defining a universal set of word senses is challenging as polysemous words can exist at many levels of 2 Topic-Sensitive Representations In this section we describe the proposed models. To learn topics from a corpus we use HDP (Teh et al., 2006; Lau et al., 2014). The main advantage of this model compared to non-hierarchical methods like the Chinese Restaurant Process (CRP) is that each document in the corpus is modeled using a mixture model with topics shared between all documents (Teh et al., 2005; Brody and Lapata, 2009). HDP yields two sets of distributions that we use in our methods: distributions over topics for words in the vocabulary, and distributions over topics for documents in the corpus. Similarly to Neelakantan et al. (2014), we use neighboring words to detect the meaning of the context, however, we also use the two HDP dis441 Proceeding"
P17-2070,P14-2050,0,0.0565111,"opic distributions for each document we obtain representations that are able to distinguish between different meanings of a given word. Our models yield statistically significant improvements for the lexical substitution task indicating that commonly used single word representations, even when combined with contextual information, are insufficient for this task. 1 Introduction Word representations in the form of dense vectors, or word embeddings, capture semantic and syntactic information (Mikolov et al., 2013a; Pennington et al., 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016). Most of the existing models generate one representation per word and do not distinguish between different meanings of a word. However, many tasks can benefit from using multiple representations per word to capture polysemy (Reisinger and Mooney, 2010). There have been several attempts to build repositories for word senses (Miller, 1995; Navigli and Ponzetto, 2010), but this is laborious and limited to few languages. Moreover, defining a universal set of word senses is challenging as polysemous words can exist at many levels of 2 Topic-Sensitive Repr"
P17-2070,P10-1023,0,0.0142999,"form of dense vectors, or word embeddings, capture semantic and syntactic information (Mikolov et al., 2013a; Pennington et al., 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016). Most of the existing models generate one representation per word and do not distinguish between different meanings of a word. However, many tasks can benefit from using multiple representations per word to capture polysemy (Reisinger and Mooney, 2010). There have been several attempts to build repositories for word senses (Miller, 1995; Navigli and Ponzetto, 2010), but this is laborious and limited to few languages. Moreover, defining a universal set of word senses is challenging as polysemous words can exist at many levels of 2 Topic-Sensitive Representations In this section we describe the proposed models. To learn topics from a corpus we use HDP (Teh et al., 2006; Lau et al., 2014). The main advantage of this model compared to non-hierarchical methods like the Chinese Restaurant Process (CRP) is that each document in the corpus is modeled using a mixture model with topics shared between all documents (Teh et al., 2005; Brody and Lapata, 2009). HDP y"
P17-2070,D14-1113,0,0.553306,"presentations In this section we describe the proposed models. To learn topics from a corpus we use HDP (Teh et al., 2006; Lau et al., 2014). The main advantage of this model compared to non-hierarchical methods like the Chinese Restaurant Process (CRP) is that each document in the corpus is modeled using a mixture model with topics shared between all documents (Teh et al., 2005; Brody and Lapata, 2009). HDP yields two sets of distributions that we use in our methods: distributions over topics for words in the vocabulary, and distributions over topics for documents in the corpus. Similarly to Neelakantan et al. (2014), we use neighboring words to detect the meaning of the context, however, we also use the two HDP dis441 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 441–447 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2070 hHTLE owi+j owi+j … … … hHTLEadd owi+j … … hSTLE … … … … r(wi⌧ ) r0 (wi⌧ ) r0 (wi ) r00 (wi⌧ ) (a) p(⌧ |di ) … … 1 (b) … … 2 r00 (wi⌧ ) k r00 (wi⌧ ) (c) Figure 1: Illustration of our topic-sensitive representation models: (a) hard-topic labeled r"
P17-2070,D14-1162,0,0.111106,"erarchical Dirichlet Process. We observe that by modeling topics and integrating topic distributions for each document we obtain representations that are able to distinguish between different meanings of a given word. Our models yield statistically significant improvements for the lexical substitution task indicating that commonly used single word representations, even when combined with contextual information, are insufficient for this task. 1 Introduction Word representations in the form of dense vectors, or word embeddings, capture semantic and syntactic information (Mikolov et al., 2013a; Pennington et al., 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016). Most of the existing models generate one representation per word and do not distinguish between different meanings of a word. However, many tasks can benefit from using multiple representations per word to capture polysemy (Reisinger and Mooney, 2010). There have been several attempts to build repositories for word senses (Miller, 1995; Navigli and Ponzetto, 2010), but this is laborious and limited to few languages. Moreover, defining a universal set of word senses is c"
P17-2070,D13-1141,0,0.033758,"and integrating topic distributions for each document we obtain representations that are able to distinguish between different meanings of a given word. Our models yield statistically significant improvements for the lexical substitution task indicating that commonly used single word representations, even when combined with contextual information, are insufficient for this task. 1 Introduction Word representations in the form of dense vectors, or word embeddings, capture semantic and syntactic information (Mikolov et al., 2013a; Pennington et al., 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016). Most of the existing models generate one representation per word and do not distinguish between different meanings of a word. However, many tasks can benefit from using multiple representations per word to capture polysemy (Reisinger and Mooney, 2010). There have been several attempts to build repositories for word senses (Miller, 1995; Navigli and Ponzetto, 2010), but this is laborious and limited to few languages. Moreover, defining a universal set of word senses is challenging as polysemous words can exist at many levels"
P17-2070,D16-1018,0,0.0147706,"are consistent with how we train HTLE and STLE. The sampled method, similar to HTLE, uses the HDP model to assign topics to word occurrences during testing. The expected method, similar to STLE, uses the HDP model to learn the probability distribution of topics of the context sentence and uses the entire distribution to compute the similarity. For the Skipgram baseline we compute the similarity SimSGE+C pws , wt q as follows: cosphpws q, hpwt qq ` ř c 2013a; Pennington et al., 2014), recent studies have focused on learning multiple embeddings per word due to the ambiguous nature of language (Qiu et al., 2016). Huang et al. (2012) cluster word contexts and use the average embedding of each cluster as word sense embeddings, which yields improvements on a word similarity task. Neelakantan et al. (2014) propose two approaches, both based on clustering word contexts: In the first, they fix the number of senses manually, and in the second, they use an ad-hoc greedy procedure that allocates a new representation to a word if existing representations explain the context below a certain threshold. Li and Jurafsky (2015) used a CRP model to distinguish between senses of words and train vectors for senses, wh"
P17-2070,N10-1013,0,0.0181907,"en combined with contextual information, are insufficient for this task. 1 Introduction Word representations in the form of dense vectors, or word embeddings, capture semantic and syntactic information (Mikolov et al., 2013a; Pennington et al., 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016). Most of the existing models generate one representation per word and do not distinguish between different meanings of a word. However, many tasks can benefit from using multiple representations per word to capture polysemy (Reisinger and Mooney, 2010). There have been several attempts to build repositories for word senses (Miller, 1995; Navigli and Ponzetto, 2010), but this is laborious and limited to few languages. Moreover, defining a universal set of word senses is challenging as polysemous words can exist at many levels of 2 Topic-Sensitive Representations In this section we describe the proposed models. To learn topics from a corpus we use HDP (Teh et al., 2006; Lau et al., 2014). The main advantage of this model compared to non-hierarchical methods like the Chinese Restaurant Process (CRP) is that each document in the corpus is model"
P17-2070,D13-1198,0,0.0502976,"Missing"
P17-2070,P14-1146,0,0.0370005,"ch document we obtain representations that are able to distinguish between different meanings of a given word. Our models yield statistically significant improvements for the lexical substitution task indicating that commonly used single word representations, even when combined with contextual information, are insufficient for this task. 1 Introduction Word representations in the form of dense vectors, or word embeddings, capture semantic and syntactic information (Mikolov et al., 2013a; Pennington et al., 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016). Most of the existing models generate one representation per word and do not distinguish between different meanings of a word. However, many tasks can benefit from using multiple representations per word to capture polysemy (Reisinger and Mooney, 2010). There have been several attempts to build repositories for word senses (Miller, 1995; Navigli and Ponzetto, 2010), but this is laborious and limited to few languages. Moreover, defining a universal set of word senses is challenging as polysemous words can exist at many levels of 2 Topic-Sensitive Representations In this"
P17-2070,W11-1102,0,\N,Missing
P17-2090,W16-2301,1,0.695868,"Missing"
P17-2090,D15-1166,0,0.045947,"Missing"
P17-2090,D09-1040,0,0.0212379,"e meaning of the sentence, requiring sentential paraphrasing systems which are not available for many language pairs. Instead, we propose a weaker notion of label preservation that allows to alter both source and target sentences at the same time as long as they remain translations of each other. While our approach allows us to augment data in numerous ways, we focus on augmenting instances involving low-frequency words, because the parameter estimation of rare words is challenging, and further exacerbated in a lowresource setting. We simulate a low-resource setting as done in the literature (Marton et al., 2009; Duong et al., 2015) and obtain substantial improvements for translating EnglishÑGerman and GermanÑEnglish. 2 Implausible substitutions need to be ruled out during data augmentation. To this end, rather than relying on linguistic resources which are not available for many languages, we rely on LSTM language models (LM) (Hochreiter and Schmidhuber, 1997; Jozefowicz et al., 2015) trained on large amounts of monolingual data in both forward and backward directions. Our data augmentation method involves the following steps: Targeted words selection: Following common practice, our NMT system limit"
P17-2090,P02-1040,0,0.115466,"Missing"
P17-2090,W14-4012,0,0.197783,"Missing"
P17-2090,D15-1040,0,0.012259,"ence, requiring sentential paraphrasing systems which are not available for many language pairs. Instead, we propose a weaker notion of label preservation that allows to alter both source and target sentences at the same time as long as they remain translations of each other. While our approach allows us to augment data in numerous ways, we focus on augmenting instances involving low-frequency words, because the parameter estimation of rare words is challenging, and further exacerbated in a lowresource setting. We simulate a low-resource setting as done in the literature (Marton et al., 2009; Duong et al., 2015) and obtain substantial improvements for translating EnglishÑGerman and GermanÑEnglish. 2 Implausible substitutions need to be ruled out during data augmentation. To this end, rather than relying on linguistic resources which are not available for many languages, we rely on LSTM language models (LM) (Hochreiter and Schmidhuber, 1997; Jozefowicz et al., 2015) trained on large amounts of monolingual data in both forward and backward directions. Our data augmentation method involves the following steps: Targeted words selection: Following common practice, our NMT system limits its vocabulary V to"
P17-2090,P16-1009,0,0.404694,"rget translation. To train a model with reliable parameter estimations, these networks require numerous instances of sentence translation pairs with words occurring in diverse contexts, which is typically not available in low-resource language pairs. As a result NMT falls short of reaching state-of-the-art performances for these language pairs (Zoph et al., 2016). The solution is to either manually annotate more data or perform unsupervised data augmentation. Since manual annotation of data is timeconsuming, data augmentation for low-resource language pairs is a more viable approach. Recently Sennrich et al. (2016a) proposed a method to back-translate sentences from monolingual data and augment the bitext with the resulting pseudo parallel corpora. In this paper, we propose a simple yet effective approach, translation data augmentation (TDA), that augments the training data by altering existing sentences in the parallel corpus, similar in spirit to the data augmentation approaches in computer vision (see Figure 1). In order for the augmentation process in this scenario to be label-preserving, any change to a sentence in one language must preIntroduction In computer vision, data augmentation techniques"
P17-2090,N13-1073,0,0.0802615,"Missing"
P17-2090,P82-1020,0,0.855271,"Missing"
P17-2090,P16-1162,0,0.124968,"rget translation. To train a model with reliable parameter estimations, these networks require numerous instances of sentence translation pairs with words occurring in diverse contexts, which is typically not available in low-resource language pairs. As a result NMT falls short of reaching state-of-the-art performances for these language pairs (Zoph et al., 2016). The solution is to either manually annotate more data or perform unsupervised data augmentation. Since manual annotation of data is timeconsuming, data augmentation for low-resource language pairs is a more viable approach. Recently Sennrich et al. (2016a) proposed a method to back-translate sentences from monolingual data and augment the bitext with the resulting pseudo parallel corpora. In this paper, we propose a simple yet effective approach, translation data augmentation (TDA), that augments the training data by altering existing sentences in the parallel corpus, similar in spirit to the data augmentation approaches in computer vision (see Figure 1). In order for the augmentation process in this scenario to be label-preserving, any change to a sentence in one language must preIntroduction In computer vision, data augmentation techniques"
P17-2090,D16-1163,0,0.0216969,"ck. Figure 1: Top: flip and crop, two label-preserving data augmentation techniques in computer vision. Bottom: Altering one sentence in a parallel corpus requires changing its translation. LSTM hidden states and an attention mechanism, generates the target translation. To train a model with reliable parameter estimations, these networks require numerous instances of sentence translation pairs with words occurring in diverse contexts, which is typically not available in low-resource language pairs. As a result NMT falls short of reaching state-of-the-art performances for these language pairs (Zoph et al., 2016). The solution is to either manually annotate more data or perform unsupervised data augmentation. Since manual annotation of data is timeconsuming, data augmentation for low-resource language pairs is a more viable approach. Recently Sennrich et al. (2016a) proposed a method to back-translate sentences from monolingual data and augment the bitext with the resulting pseudo parallel corpora. In this paper, we propose a simple yet effective approach, translation data augmentation (TDA), that augments the training data by altering existing sentences in the parallel corpus, similar in spirit to th"
Q13-1027,D07-1103,0,\N,Missing
Q13-1027,W11-2127,0,\N,Missing
Q13-1027,N04-4026,0,\N,Missing
Q13-1027,N04-4038,0,\N,Missing
Q13-1027,D08-1089,0,\N,Missing
Q13-1027,P06-1067,0,\N,Missing
Q13-1027,P12-1050,1,\N,Missing
Q13-1027,P02-1040,0,\N,Missing
Q13-1027,H05-1066,0,\N,Missing
Q13-1027,W05-0909,0,\N,Missing
Q13-1027,P07-2045,1,\N,Missing
Q13-1027,P10-2033,0,\N,Missing
Q13-1027,N03-1017,0,\N,Missing
Q13-1027,D11-1045,0,\N,Missing
Q13-1027,P02-1038,0,\N,Missing
Q13-1027,W09-0434,0,\N,Missing
Q13-1027,W06-3108,0,\N,Missing
Q13-1027,J97-3002,0,\N,Missing
Q13-1027,W05-0908,0,\N,Missing
Q13-1027,2005.iwslt-1.8,0,\N,Missing
Q13-1027,N10-1129,0,\N,Missing
Q13-1027,P03-1021,0,\N,Missing
Q13-1027,N06-1014,0,\N,Missing
Q13-1027,2010.iwslt-papers.19,0,\N,Missing
W10-1710,N04-1022,0,0.0353991,"phological Reduction and Chunk-based Reordering Christian Hardmeier, Arianna Bisazza and Marcello Federico Fondazione Bruno Kessler Human Language Technologies Trento, Italy {hardmeier,bisazza,federico}@fbk.eu Abstract a recasing step, we retained the data in document case throughout our system, except for the morphologically normalised word forms described in section 3. Our phrase tables were trained with the standard Moses training script, then filtered based on statistical significance according to the method described by Johnson et al. (2007). Finally, we used Minimum Bayes Risk decoding (Kumar and Byrne, 2004) based on the BLEU score (Papineni et al., 2002). FBK participated in the WMT 2010 Machine Translation shared task with phrase-based Statistical Machine Translation systems based on the Moses decoder for English-German and German-English translation. Our work concentrates on exploiting the available language modelling resources by using linear mixtures of large 6-gram language models and on addressing linguistic differences between English and German with methods based on word lattices. In particular, we use lattices to integrate a morphological analyser for German into our system, and we pres"
W10-1710,W09-0435,0,0.190543,"Missing"
W10-1710,P03-1021,0,0.0227324,"Missing"
W10-1710,P02-1040,0,0.0782298,"Christian Hardmeier, Arianna Bisazza and Marcello Federico Fondazione Bruno Kessler Human Language Technologies Trento, Italy {hardmeier,bisazza,federico}@fbk.eu Abstract a recasing step, we retained the data in document case throughout our system, except for the morphologically normalised word forms described in section 3. Our phrase tables were trained with the standard Moses training script, then filtered based on statistical significance according to the method described by Johnson et al. (2007). Finally, we used Minimum Bayes Risk decoding (Kumar and Byrne, 2004) based on the BLEU score (Papineni et al., 2002). FBK participated in the WMT 2010 Machine Translation shared task with phrase-based Statistical Machine Translation systems based on the Moses decoder for English-German and German-English translation. Our work concentrates on exploiting the available language modelling resources by using linear mixtures of large 6-gram language models and on addressing linguistic differences between English and German with methods based on word lattices. In particular, we use lattices to integrate a morphological analyser for German into our system, and we present some initial work on rule-based word reorder"
W10-1710,W10-1735,1,0.823142,"s a working solution that results in a significant improvement in translation quality. It is an alternative to the popular statistical compound splitting methods, such as the one by Koehn and Knight (2003), incorporating a greater amount of linguistic knowledge and offering morphological reduction even of simplex words to their base form in addition. It would be interesting to compare the relative performance of the two approaches systematically. Word reordering between German and English is a complex problem. Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish (Bisazza and Federico, 2010), we tried to adapt the same approach to the German-English language pair. It turned out that there is a larger variety of long reordering patterns in this case. Nevertheless, some experiments performed after 20.6 21.1 note: only News LM, case-sensitive evaluation Table 5: Results with morphological reduction and chunk reordering on newstest 2009/2010 ual inspection of a data sample, we then identified a few recurrent patterns of long reorderings involving the verbs. In particular, we focused on clause-final verbs in German SOV clauses, which we move to the left in order to approximate the Eng"
W10-1710,P08-1115,0,0.293714,"Missing"
W10-1710,D07-1103,0,0.0373687,"Missing"
W10-1710,E03-1076,0,0.286632,"n our parallel computing environment. We are working on methods to reduce and distribute disk accesses to large language models, which will be implemented in the IRSTLM language modelling toolkit (Federico et al., 2008). By doing so, we hope to overcome the current limitations and exploit the power of language model mixtures more fully. The Gertwol-based morphological reduction and decompounding component we used is a working solution that results in a significant improvement in translation quality. It is an alternative to the popular statistical compound splitting methods, such as the one by Koehn and Knight (2003), incorporating a greater amount of linguistic knowledge and offering morphological reduction even of simplex words to their base form in addition. It would be interesting to compare the relative performance of the two approaches systematically. Word reordering between German and English is a complex problem. Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish (Bisazza and Federico, 2010), we tried to adapt the same approach to the German-English language pair. It turned out that there is a larger variety of long reordering patterns in this case. Nevertheless, so"
W10-1710,P07-2045,1,0.0183052,"some more effort into the inverse translation direction to make better use of the abundance of language modelling data available for English and to address the richness of German morphology, which makes it hard for a Statistical Machine Translation (SMT) system to achieve good vocabulary coverage. In the remainder of this section, an overview of the common features of our systems will be given. The next two sections provide a more detailed description of our approaches to language modelling, morphological preprocessing and word reordering. Both of our systems were based on the Moses decoder (Koehn et al., 2007). They were similar to the WMT 2010 Moses baseline system. Instead of lowercasing the training data and adding 1. For a linear mixture of the complete set of 24 language models, we estimated a set of 88 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 88–92, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics Corpus Europarl v5 News News commentary 10 Gigaword v3: 6 models Gigaword 2007/08: 6 models 109 fr-en UNDOC fr-en CzEng: 7 models Total: 24 models n-grams 115,702,157 1,437,562,740 10,381,511 7,990,828,834 1,418"
W10-1735,W09-0809,0,0.185667,"Missing"
W10-1735,D08-1089,0,0.0691096,"hese, however, appear to be mostly local, therefore more likely to be modeled through phrase internal alignments, or to be captured by the reordering capabilities of the decoder. In general there is a quite uneven distribution of word-reordering phenomena in Arabic-English, and long-range movements concentrate on few patterns. Reordering in PSMT is typically performed by (i) constraining the maximum allowed word movement and exponentially penalizing long reorderings (distortion limit and penalty), and (ii) through so-called lexicalized orientation models (Och et al., 2004; Koehn et al., 2007; Galley and Manning, 2008). While the former is mainly aimed at reducing the computational complexity of the decoding algorithm, the latter assigns at each decoding step a score to the next source phrase to cover, according to its orientation with respect to the last translated phrase. In fact, neither method discriminates among different reordering distances for a specific word or syntactic class. To our view, this could be a reason for their inadequacy to properly deal with the reordering peculiarities of the Arabic-English language pair. In In Arabic-to-English phrase-based statistical machine translation, a large n"
W10-1735,E06-1032,0,0.0214445,"Missing"
W10-1735,P01-1030,0,0.0607618,"Missing"
W10-1735,W08-0307,0,0.319807,"Missing"
W10-1735,2009.mtsummit-caasl.4,0,0.370195,"Missing"
W10-1735,N04-4038,0,0.128355,"e a correct translation. In order to restrict the set of possible movements of a verb and to abstract from the usual token-based movement length measure, we decided to use shallow syntax chunking of the source language. Full syntactic parsing is another option which we have not tried so far mainly because popular parsers that are available for Arabic do not mark grammatical relations such as the ones we are interested in. We assume that Arabic verb reordering only occurs between shallow syntax chunks, and not within them. For this purpose we annotated our Arabic data with the AMIRA chunker by Diab et al. (2004)2 . The resulting chunks are generally short (1.6 words on average). We then consider a specific type of reordering by defining a production rule of the kind: “move a chunk of type T along with its L left neighbours and R right neighbours by a shift of S chunks”. A basic set of rules 3 Analysis of Verb Reordering We applied the above technique to two parallel corpora3 provided by the organizers of the NISTMT09 Evaluation. The first corpus (Gale-NW) contains human-made alignments. As these refer to non-segmented text, they were adjusted to 2 This tool implies morphological segmentation of the A"
W10-1735,2007.mtsummit-papers.29,0,0.696769,"77 sentence pairs. 236 Figure 2: Percentage of verb reorderings by maximum shift (0 stands for no movement). Figure 3: Distortion reduction in the GALE-NW corpus: jump occurrences grouped by length range (in nb. of words). agree with AMIRA-style segmentation. For the second corpus (Eval08-NW), we filtered out sentences longer than 80 tokens in order to make word alignment feasible with GIZA++ (Och and Ney, 2003). We then used the Intersection of the direct and inverse alignments, as computed by Moses. The choice of such a high-precision, lowrecall alignment set is supported by the findings of Habash (2007) on syntactic rule extraction from parallel corpora. 3.2 3.1 Impact on Corpus Global Distortion We tried to measure the impact of chunk-based verb reordering on the total word distortion found in parallel data. For the sake of reliability, this investigation was carried out on the manually aligned corpus (Gale-NW) only. Fig. 3 shows the positive effect of verb reordering on the total distortion, which is measured as the number of words that have to be jumped on the source side in order to cover the sentence in the target order (that is |ai − (ai−1 + 1)|). Jumps have been grouped by length and"
W10-1735,P08-1115,0,0.25069,"act of VSO sentences on Arabic-English translation performance, we now propose a method to improve the handling of this phenomenon at decoding time. As in real working conditions word alignments of the input text are not available, we explore a reordering lattice approach. 5.1 Lattice Construction Firstly conceived to optimally encode multiple transcription hypothesis produced by a speech recognizer, word lattices have later been used to represent various forms of input ambiguity, mainly at the level of token boundaries (e.g. word segmentation, morphological decomposition, word decompounding (Dyer et al., 2008)). A main problem when dealing with permutaTo be consistent with the reordering applied to the training data, we use a set of rules that move each verb phrase alone or with its following chunk by 1 to 6 chunks to the right. With this settings, 239 Figure 6: Structure of a chunk-based reordering lattice for verb reordering, before word expansion. Edges in boldface represent the verbal chunk. our lattice generation algorithm computes a compact lattice (Fig. 6) that introduces at most 5 × ∆S chunk edges for each verb chunk, where ∆S is the permitted movement range (6 in this case). Before transla"
W10-1735,P07-2045,1,0.023212,"tructions (Idafa). These, however, appear to be mostly local, therefore more likely to be modeled through phrase internal alignments, or to be captured by the reordering capabilities of the decoder. In general there is a quite uneven distribution of word-reordering phenomena in Arabic-English, and long-range movements concentrate on few patterns. Reordering in PSMT is typically performed by (i) constraining the maximum allowed word movement and exponentially penalizing long reorderings (distortion limit and penalty), and (ii) through so-called lexicalized orientation models (Och et al., 2004; Koehn et al., 2007; Galley and Manning, 2008). While the former is mainly aimed at reducing the computational complexity of the decoding algorithm, the latter assigns at each decoding step a score to the next source phrase to cover, according to its orientation with respect to the last translated phrase. In fact, neither method discriminates among different reordering distances for a specific word or syntactic class. To our view, this could be a reason for their inadequacy to properly deal with the reordering peculiarities of the Arabic-English language pair. In In Arabic-to-English phrase-based statistical mac"
W10-1735,2006.amta-papers.11,0,0.0874189,"Missing"
W10-1735,W09-0435,0,0.25433,"Missing"
W10-1735,J03-1002,0,0.00536733,"This tool implies morphological segmentation of the Arabic text. All word statistics in this paper refer to AMIRAsegmented text. 3 Newswire sections of LDC2006E93 and LDC2009E08, respectively 4337 and 777 sentence pairs. 236 Figure 2: Percentage of verb reorderings by maximum shift (0 stands for no movement). Figure 3: Distortion reduction in the GALE-NW corpus: jump occurrences grouped by length range (in nb. of words). agree with AMIRA-style segmentation. For the second corpus (Eval08-NW), we filtered out sentences longer than 80 tokens in order to make word alignment feasible with GIZA++ (Och and Ney, 2003). We then used the Intersection of the direct and inverse alignments, as computed by Moses. The choice of such a high-precision, lowrecall alignment set is supported by the findings of Habash (2007) on syntactic rule extraction from parallel corpora. 3.2 3.1 Impact on Corpus Global Distortion We tried to measure the impact of chunk-based verb reordering on the total word distortion found in parallel data. For the sake of reliability, this investigation was carried out on the manually aligned corpus (Gale-NW) only. Fig. 3 shows the positive effect of verb reordering on the total distortion, whi"
W10-1735,N04-1021,0,0.0309736,"tial genitive constructions (Idafa). These, however, appear to be mostly local, therefore more likely to be modeled through phrase internal alignments, or to be captured by the reordering capabilities of the decoder. In general there is a quite uneven distribution of word-reordering phenomena in Arabic-English, and long-range movements concentrate on few patterns. Reordering in PSMT is typically performed by (i) constraining the maximum allowed word movement and exponentially penalizing long reorderings (distortion limit and penalty), and (ii) through so-called lexicalized orientation models (Och et al., 2004; Koehn et al., 2007; Galley and Manning, 2008). While the former is mainly aimed at reducing the computational complexity of the decoding algorithm, the latter assigns at each decoding step a score to the next source phrase to cover, according to its orientation with respect to the last translated phrase. In fact, neither method discriminates among different reordering distances for a specific word or syntactic class. To our view, this could be a reason for their inadequacy to properly deal with the reordering peculiarities of the Arabic-English language pair. In In Arabic-to-English phrase-b"
W10-1735,P03-1021,0,0.0159675,"verb reordering procedure on training only. The latter will provide an estimate of the maximum improvement we can expect from the application to the test of an optimal verb reordering prediction technique. Given our experimental setting, one could argue that our BLEU score is biased because one of the references was also used to generate the verb reordering. However, in a series of experiments not reported here, we evaluated the same systems using only the remaining three references and observed similar trends as when all four references are used. Feature weights were optimized through MERT (Och, 2003) on the newswire section of the NISTMT06 evaluation set (Dev06-NW), in the original version for the baseline system, in the verbreordered version for the reordered system. 4.2 Discussion The first observation is that the reordered system always performs better (0.5∼0.6 points) than the baseline on the plain test, despite the mismatch between training and test ordering. This may be due to the fact that automatic word alignments are more accurate when less reordering is present in the data, although previous work (Lopez and Resnik, 2006) showed that even large gains in alignment accuracy seldom"
W10-1735,W10-1710,1,\N,Missing
W10-1735,W09-0434,0,\N,Missing
W13-2257,kim-etal-2000-machine,0,0.117241,"Missing"
W13-2257,2012.eamt-1.42,0,0.234824,"verb is separated from the inflected auxiliary or modal. The distance between the two parts of a verb phrase can be arbitrarily long as shown in the following example: selected by the decoder at translation time. In (Tromble and Eisner, 2009), pre-ordering is cast as a permutation problem and solved by a model that estimates the probability of reversing the relative order of any two input words. In the field of tree-based SMT, positive results in German-English were achieved by combining syntactic translation rules with unlabeled hierarchical SMT rules (Hoang and Koehn, 2010). More recently, Braune et al. (2012) proposed to improve the long-range reordering capability of an HSMT system by integrating constraints based on clausal boundaries and by manually selecting the rule patterns applicable to long word spans. The paper did not analyse the impact of the technique on efficiency. [DE] Jedoch konnten sie Kinder in Teilen von Helmand und Kandahar im Suden aus Sicherheitsgrund nicht er¨ reichen. [EN] But they could not reach children in parts of Helmand and Kandahar in the south for security reasons. Translating this sentence with a PSMT engine implies performing two very long jumps that are not even c"
W13-2257,W12-3102,0,0.0446434,"Missing"
W13-2257,2011.mtsummit-papers.1,1,0.769012,"d two lexical probability features), a 6-gram target language model, word and rule penalties. We set the span constraint (cf. Section 5) to the default value of 10 words for rule extraction, while for decoding we consider two different settings: the default 10 words and a large value of 20 to enable very longrange reorderings. Feature weights for all systems are optimized by minimum BLEU-error training (Och, 2003) on test08. To reduce the effects of the optimizer instability, we tune each configuration four times and use the average of the resulting weight vectors for testing, as suggested by Cettolo et al. (2011). The source-to-reference word alignments that are needed to compute the reordering scores are generated by the Berkeley Aligner previously trained on the training data. Source-to-output alignments are obtained from the decoder’s trace. 6.2 Figure 1: Standard vs early distortion cost performance measured in terms of BLEU and KRS on tests(09-11) under different distortion limits. Distortion function and limit We start by measuring the difference between standard and early distortion cost.7 Figure 1 shows the results in terms of BLEU and KRS, plotted against the distortion limit (DL). Indeed, ea"
W13-2257,P05-1033,0,0.537828,"the German-English language pair is known to be a challenging task for state-of-theart statistical machine translation (SMT) methods. A major factor of difficulty is given by word order differences that yield important long-range reordering phenomena. Thanks to specific reordering modeling components, phrase-based SMT (PSMT) systems (Zens et al., 2002; Koehn et al., 2003; Och and Ney, 2002) are generally good at handling local reordering phenomena that are not captured inside phrases. However, they typically fail to predict long reorderings. On the other hand, hierarchical SMT (HSMT) systems (Chiang, 2005) can learn reordering patterns by means of discontinuous translation rules, and are therefore considered a better choice for language pairs characterized by massive and hierarchical reordering. 2 Background Word order differences between German and English are mainly found at the clause (global) level, as opposed to the phrase (local) level. We refer to Collins et al. (2005) and Gojun and Fraser (2012) for a detailed description of the German clause structure. To briefly summarize, we can say that 440 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 440–451, c Sofia"
W13-2257,P06-1067,0,0.575662,"Missing"
W13-2257,J07-2003,0,0.0679615,"features), a 6-gram target language model, distortion cost, word and phrase penalties. As lexicalized reordering model, we use a hierarchical phrase orientation model (Galley and Manning, 2008) trained on all the parallel data using three orientation classes – monotone, swap or discontinuous – in bidirectional mode. Statistically Furthermore, the HSMT decoder is based on a chart parsing algorithm, whose complexity is cubic in the input length, and even higher when taking into account the target language model. This issue can be partially addressed by different strategies such as cube pruning (Chiang, 2007), which reduces the LM complexity to a constant, or rule application constraints. One of such constraints is the maximum number of source words that may be covered by non-terminal symbols (span constraint). Setting a span constraint – which is essential to obtain reasonable decoding times – means preventing long-range reordering similarly to setting a distortion limit in PSMT. In our experiments, we consider two settings for this parameter: 10 to capture short to medium-range reorderings, and 20 to also capture long-range reorderings. 6 Experimental setup Experiments In this section we evaluat"
W13-2257,P05-1066,0,0.814336,"2003; Och and Ney, 2002) are generally good at handling local reordering phenomena that are not captured inside phrases. However, they typically fail to predict long reorderings. On the other hand, hierarchical SMT (HSMT) systems (Chiang, 2005) can learn reordering patterns by means of discontinuous translation rules, and are therefore considered a better choice for language pairs characterized by massive and hierarchical reordering. 2 Background Word order differences between German and English are mainly found at the clause (global) level, as opposed to the phrase (local) level. We refer to Collins et al. (2005) and Gojun and Fraser (2012) for a detailed description of the German clause structure. To briefly summarize, we can say that 440 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 440–451, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics the verb-second order of German main clauses contrasts with the rigid SVO structure of English, as does the clause-final verb position of German subordinate clauses. A further difficulty is given by the German discontinuous verb phrases, where the main verb is separated from the inflected auxiliary o"
W13-2257,W05-0909,0,0.0128905,"its syntactic parse tree (Collins et al., 2005).1 Other approaches learn the pre-ordering rules automatically, from syntactic parses (Xia and McCord, 2004; Genzel, 2010) or from part-of-speech labels (Niehues and Kolss, 2009). In the former case, pre-ordering decisions are typically taken deterministically (i. e. one permuation per sentence), whereas in the latter, multiple alternatives are represented as word lattices, and the optimal path is A large number of previous works on word reordering measured their success with generalpurpose metrics such as BLEU (Papineni et al., 2001) or METEOR (Banerjee and Lavie, 2005). These metrics, however, are only indirectly sensitive to word order and do not sufficiently penalize long-range reordering errors, as demonstrated for instance by Birch et al. (2010). While BLEU remains a standard choice for many evaluation campaigns, we believe it is extremely important to complement it with metrics that are specifically designed to capture word order differences. In this work, we adopt two reordering-specific metrics in addition to BLEU and METEOR: Kendall Reordering Score (KRS). As proposed by Birch et al. (2010), the KRS measures the similarity between the input-output r"
W13-2257,D08-1078,0,0.465777,"ystems) the rule-based systems outperformed all SMT approaches, and among the best SMT systems we find a variety of approaches: pure phrase-based, phrase-based and hierarchical systems combination, n-gram based, a rich syntaxbased approach, and a phrase-based system coupled with POS-based pre-ordering. This gives an idea of how challenging this language pair is for SMT and raises the question of which SMT approach is best suited to model it. In this work, we aim at answering this question by focussing on the word reordering problem, which is known to be an important factor of SMT performance (Birch et al., 2008). We hypothesize that PSMT can be as successful for GermanEnglish as the more computationally costly HSMT approach, provided that the reordering-related parameters are carefully chosen and the best available reordering models are used. More specifically, our study covers the following topics: distortion functions and limits, and dynamic shaping of the reordering search space based on a discriminative reordering model. We first review these topics, and then evaluate them systematically on the WMT task using both generic and reordering-specific metrics, with the aim of providing a reference for"
W13-2257,2010.amta-papers.22,0,0.361518,"ring model that predicts what input word should be translated at a given decoding state (Bisazza, 2013; Bisazza and Federico, 2013). The model is similar to the one proposed by Visweswariah et al. (2011), however we use it differently: that is, not simply for data preprocessing but as an additional feature function fully integrated in the phrase-based decoder. More importantly, we propose to use the same model to dynamically shape the space of reorderings explored during decoding (cf. Section 4.2), which was never done before. Another related work is the source-side decoding sequence model by Feng et al. (2010), that is a generative n-gram model trained on a corpus of pre-ordered source sentences. Although reminiscent of a source-side bigram model, our model has two important differences: (i) the discriminative modeling framework enables us to design a much richer feature set including, for instance, the context of the next word to pick; (ii) all our features are independent from the decoding history, which allows for an efficient decoder-integration with no effect on hypothesis recombination. Finally, we have to mention the models by AlOnaizan and Papineni (2006) and Green et al. (2010), who predic"
W13-2257,Q13-1027,1,0.900171,"eful for short and medium-range reordering and are probably the most widely used in PSMT nowadays. However, their coarse classification of reordering steps makes them unsuitable to capture long-range reordering phenomena, such as those attested in German-English. Indeed, Galley and Manning (2008) reported a decrease of translation quality when the distortion limit was set beyond 6 in Chinese-English and beyond 4 in Arabic-English. To address this problem, we have developed a different reordering model that predicts what input word should be translated at a given decoding state (Bisazza, 2013; Bisazza and Federico, 2013). The model is similar to the one proposed by Visweswariah et al. (2011), however we use it differently: that is, not simply for data preprocessing but as an additional feature function fully integrated in the phrase-based decoder. More importantly, we propose to use the same model to dynamically shape the space of reorderings explored during decoding (cf. Section 4.2), which was never done before. Another related work is the source-side decoding sequence model by Feng et al. (2010), that is a generative n-gram model trained on a corpus of pre-ordered source sentences. Although reminiscent of"
W13-2257,D08-1089,0,0.0669847,"olkit (Koehn et al., 2007; Hoang et al., 2009), and word alignments are generated by the Berkeley Aligner (Liang et al., 2006). The target language model is estimated by the IRSTLM toolkit (Federico et al., 2008) with modified Kneser-Ney smoothing (Chen and Goodman, 1999). The phrase-based baseline decoder includes a phrase translation model (two phrasal and two lexical probability features), a lexicalized reordering model (six features), a 6-gram target language model, distortion cost, word and phrase penalties. As lexicalized reordering model, we use a hierarchical phrase orientation model (Galley and Manning, 2008) trained on all the parallel data using three orientation classes – monotone, swap or discontinuous – in bidirectional mode. Statistically Furthermore, the HSMT decoder is based on a chart parsing algorithm, whose complexity is cubic in the input length, and even higher when taking into account the target language model. This issue can be partially addressed by different strategies such as cube pruning (Chiang, 2007), which reduces the LM complexity to a constant, or rule application constraints. One of such constraints is the maximum number of source words that may be covered by non-terminal"
W13-2257,N06-1014,0,0.023422,"es one reference translation. Note that our goal is not to reach the performance of the best systems participating at the last WMT edition, but rather to assess the usefulness of our techniques on a larger and therefore more reliable test set, while starting from a reasonable baseline.5 For German tokenization and compound splitting we use Tree Tagger (Schmid, 1994) and the Gertwol morphological analyser (Koskenniemi and Haapalainen, 1994).6 All our SMT systems are built with the Moses toolkit (Koehn et al., 2007; Hoang et al., 2009), and word alignments are generated by the Berkeley Aligner (Liang et al., 2006). The target language model is estimated by the IRSTLM toolkit (Federico et al., 2008) with modified Kneser-Ney smoothing (Chen and Goodman, 1999). The phrase-based baseline decoder includes a phrase translation model (two phrasal and two lexical probability features), a lexicalized reordering model (six features), a 6-gram target language model, distortion cost, word and phrase penalties. As lexicalized reordering model, we use a hierarchical phrase orientation model (Galley and Manning, 2008) trained on all the parallel data using three orientation classes – monotone, swap or discontinuous –"
W13-2257,E12-1074,0,0.0515982,"re generally good at handling local reordering phenomena that are not captured inside phrases. However, they typically fail to predict long reorderings. On the other hand, hierarchical SMT (HSMT) systems (Chiang, 2005) can learn reordering patterns by means of discontinuous translation rules, and are therefore considered a better choice for language pairs characterized by massive and hierarchical reordering. 2 Background Word order differences between German and English are mainly found at the clause (global) level, as opposed to the phrase (local) level. We refer to Collins et al. (2005) and Gojun and Fraser (2012) for a detailed description of the German clause structure. To briefly summarize, we can say that 440 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 440–451, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics the verb-second order of German main clauses contrasts with the rigid SVO structure of English, as does the clause-final verb position of German subordinate clauses. A further difficulty is given by the German discontinuous verb phrases, where the main verb is separated from the inflected auxiliary or modal. The distance betwee"
W13-2257,2007.mtsummit-papers.43,0,0.802932,"approach includes a basic reordering model, called distortion cost, that exponentially penalizes longer jumps among consecutively translated phrases simply based on their distance. Thus, a completely monotonic translation has a total distortion cost of zero. A weakness of this model is that it penalizes long jumps only when they are performed, rather than accumulating their cost gradually. As an effect, hypotheses with gaps (i. e. uncovered input positions) can proliferate and cause the pruning of more monotonic hypotheses that could lead to overall better translations. To solve this problem, Moore and Quirk (2007) proposed an improved version of the distortion cost function that anticipates the gradual accumulation of the total distortion cost, making hypotheses with the same number of covered words more comparable with one another. Early distortion cost (as called in Moses, or “distortion penalty estimation” in the original paper) is computed by a simple algorithm that keeps track of the uncovered input positions. Note that this option affects the distortion feature function, but not the distortion limit, which always corresponds to the maximum distance allowed between consecutively translated phrases"
W13-2257,W09-0435,0,0.047549,"k, we only consider efficient solutions that are fully integrated into the decoding process, and that do not require syntactic parsers or manual reordering rules. Still, it has to be mentioned that several alternative solutions were proposed in the literature. A well-known strategy consists of preordering the German sentence in an English-like order by applying a set of manually written rules to its syntactic parse tree (Collins et al., 2005).1 Other approaches learn the pre-ordering rules automatically, from syntactic parses (Xia and McCord, 2004; Genzel, 2010) or from part-of-speech labels (Niehues and Kolss, 2009). In the former case, pre-ordering decisions are typically taken deterministically (i. e. one permuation per sentence), whereas in the latter, multiple alternatives are represented as word lattices, and the optimal path is A large number of previous works on word reordering measured their success with generalpurpose metrics such as BLEU (Papineni et al., 2001) or METEOR (Banerjee and Lavie, 2005). These metrics, however, are only indirectly sensitive to word order and do not sufficiently penalize long-range reordering errors, as demonstrated for instance by Birch et al. (2010). While BLEU rema"
W13-2257,N10-1129,0,0.289051,"nce model by Feng et al. (2010), that is a generative n-gram model trained on a corpus of pre-ordered source sentences. Although reminiscent of a source-side bigram model, our model has two important differences: (i) the discriminative modeling framework enables us to design a much richer feature set including, for instance, the context of the next word to pick; (ii) all our features are independent from the decoding history, which allows for an efficient decoder-integration with no effect on hypothesis recombination. Finally, we have to mention the models by AlOnaizan and Papineni (2006) and Green et al. (2010), who predict the direction and (binned) length of a jump to perform after a given input word. Those models too were only used as additional feature functions, and were not shown to maintain translation quality and efficiency at very high distortion limits. Early distortion cost In its original formulation, the PSMT approach includes a basic reordering model, called distortion cost, that exponentially penalizes longer jumps among consecutively translated phrases simply based on their distance. Thus, a completely monotonic translation has a total distortion cost of zero. A weakness of this mode"
W13-2257,P02-1038,0,0.17283,"ering phenomena. Through an extensive evaluation including diverse translation quality metrics, we show that these solutions can significantly narrow the gap between phrase-based and hierarchical SMT. 1 Introduction Modeling the German-English language pair is known to be a challenging task for state-of-theart statistical machine translation (SMT) methods. A major factor of difficulty is given by word order differences that yield important long-range reordering phenomena. Thanks to specific reordering modeling components, phrase-based SMT (PSMT) systems (Zens et al., 2002; Koehn et al., 2003; Och and Ney, 2002) are generally good at handling local reordering phenomena that are not captured inside phrases. However, they typically fail to predict long reorderings. On the other hand, hierarchical SMT (HSMT) systems (Chiang, 2005) can learn reordering patterns by means of discontinuous translation rules, and are therefore considered a better choice for language pairs characterized by massive and hierarchical reordering. 2 Background Word order differences between German and English are mainly found at the clause (global) level, as opposed to the phrase (local) level. We refer to Collins et al. (2005) an"
W13-2257,W10-1761,0,0.0130042,"continuous verb phrases, where the main verb is separated from the inflected auxiliary or modal. The distance between the two parts of a verb phrase can be arbitrarily long as shown in the following example: selected by the decoder at translation time. In (Tromble and Eisner, 2009), pre-ordering is cast as a permutation problem and solved by a model that estimates the probability of reversing the relative order of any two input words. In the field of tree-based SMT, positive results in German-English were achieved by combining syntactic translation rules with unlabeled hierarchical SMT rules (Hoang and Koehn, 2010). More recently, Braune et al. (2012) proposed to improve the long-range reordering capability of an HSMT system by integrating constraints based on clausal boundaries and by manually selecting the rule patterns applicable to long word spans. The paper did not analyse the impact of the technique on efficiency. [DE] Jedoch konnten sie Kinder in Teilen von Helmand und Kandahar im Suden aus Sicherheitsgrund nicht er¨ reichen. [EN] But they could not reach children in parts of Helmand and Kandahar in the south for security reasons. Translating this sentence with a PSMT engine implies performing tw"
W13-2257,P03-1021,0,0.0985419,"rom the translation model as proposed by Johnson et al. (2007). The hierarchical system is trained and tested using the standard Moses configuration which includes: a rule table (two phrasal and two lexical probability features), a 6-gram target language model, word and rule penalties. We set the span constraint (cf. Section 5) to the default value of 10 words for rule extraction, while for decoding we consider two different settings: the default 10 words and a large value of 20 to enable very longrange reorderings. Feature weights for all systems are optimized by minimum BLEU-error training (Och, 2003) on test08. To reduce the effects of the optimizer instability, we tune each configuration four times and use the average of the resulting weight vectors for testing, as suggested by Cettolo et al. (2011). The source-to-reference word alignments that are needed to compute the reordering scores are generated by the Berkeley Aligner previously trained on the training data. Source-to-output alignments are obtained from the decoder’s trace. 6.2 Figure 1: Standard vs early distortion cost performance measured in terms of BLEU and KRS on tests(09-11) under different distortion limits. Distortion fun"
W13-2257,2009.iwslt-papers.4,0,0.0202593,"nstead 1.2 billion entries – one order of magnitude larger. Each data set includes one reference translation. Note that our goal is not to reach the performance of the best systems participating at the last WMT edition, but rather to assess the usefulness of our techniques on a larger and therefore more reliable test set, while starting from a reasonable baseline.5 For German tokenization and compound splitting we use Tree Tagger (Schmid, 1994) and the Gertwol morphological analyser (Koskenniemi and Haapalainen, 1994).6 All our SMT systems are built with the Moses toolkit (Koehn et al., 2007; Hoang et al., 2009), and word alignments are generated by the Berkeley Aligner (Liang et al., 2006). The target language model is estimated by the IRSTLM toolkit (Federico et al., 2008) with modified Kneser-Ney smoothing (Chen and Goodman, 1999). The phrase-based baseline decoder includes a phrase translation model (two phrasal and two lexical probability features), a lexicalized reordering model (six features), a 6-gram target language model, distortion cost, word and phrase penalties. As lexicalized reordering model, we use a hierarchical phrase orientation model (Galley and Manning, 2008) trained on all the p"
W13-2257,2001.mtsummit-papers.68,0,0.0275534,"a set of manually written rules to its syntactic parse tree (Collins et al., 2005).1 Other approaches learn the pre-ordering rules automatically, from syntactic parses (Xia and McCord, 2004; Genzel, 2010) or from part-of-speech labels (Niehues and Kolss, 2009). In the former case, pre-ordering decisions are typically taken deterministically (i. e. one permuation per sentence), whereas in the latter, multiple alternatives are represented as word lattices, and the optimal path is A large number of previous works on word reordering measured their success with generalpurpose metrics such as BLEU (Papineni et al., 2001) or METEOR (Banerjee and Lavie, 2005). These metrics, however, are only indirectly sensitive to word order and do not sufficiently penalize long-range reordering errors, as demonstrated for instance by Birch et al. (2010). While BLEU remains a standard choice for many evaluation campaigns, we believe it is extremely important to complement it with metrics that are specifically designed to capture word order differences. In this work, we adopt two reordering-specific metrics in addition to BLEU and METEOR: Kendall Reordering Score (KRS). As proposed by Birch et al. (2010), the KRS measures the"
W13-2257,D07-1103,0,0.0212169,"pothesis that better reordering modeling and better reordering space definition can significantly improve the accuracy of PSMT in German-English without sacrificing its efficiency. 5 Our results on test12 are not directly comparable to the WMT12 submissions due to the different training data: that is, the WMT12 parallel data includes 50M German tokens of Europarl data and 4M of news-commentary, as opposed to the 41M and 2.5M released for WMT10 and used in our experiments. 6 http://www2.lingsoft.fi/cgi-bin/gertwol 444 improbable phrase pairs are pruned from the translation model as proposed by Johnson et al. (2007). The hierarchical system is trained and tested using the standard Moses configuration which includes: a rule table (two phrasal and two lexical probability features), a 6-gram target language model, word and rule penalties. We set the span constraint (cf. Section 5) to the default value of 10 words for rule extraction, while for decoding we consider two different settings: the default 10 words and a large value of 20 to enable very longrange reorderings. Feature weights for all systems are optimized by minimum BLEU-error training (Och, 2003) on test08. To reduce the effects of the optimizer i"
W13-2257,W05-0908,0,0.0712858,"Missing"
W13-2257,N03-1017,0,0.0311496,"ure long-range reordering phenomena. Through an extensive evaluation including diverse translation quality metrics, we show that these solutions can significantly narrow the gap between phrase-based and hierarchical SMT. 1 Introduction Modeling the German-English language pair is known to be a challenging task for state-of-theart statistical machine translation (SMT) methods. A major factor of difficulty is given by word order differences that yield important long-range reordering phenomena. Thanks to specific reordering modeling components, phrase-based SMT (PSMT) systems (Zens et al., 2002; Koehn et al., 2003; Och and Ney, 2002) are generally good at handling local reordering phenomena that are not captured inside phrases. However, they typically fail to predict long reorderings. On the other hand, hierarchical SMT (HSMT) systems (Chiang, 2005) can learn reordering patterns by means of discontinuous translation rules, and are therefore considered a better choice for language pairs characterized by massive and hierarchical reordering. 2 Background Word order differences between German and English are mainly found at the clause (global) level, as opposed to the phrase (local) level. We refer to Coll"
W13-2257,2005.iwslt-1.8,0,0.0954106,"Missing"
W13-2257,N04-4026,0,0.133324,"Missing"
W13-2257,P07-2045,1,0.0129816,"aint (10) contains instead 1.2 billion entries – one order of magnitude larger. Each data set includes one reference translation. Note that our goal is not to reach the performance of the best systems participating at the last WMT edition, but rather to assess the usefulness of our techniques on a larger and therefore more reliable test set, while starting from a reasonable baseline.5 For German tokenization and compound splitting we use Tree Tagger (Schmid, 1994) and the Gertwol morphological analyser (Koskenniemi and Haapalainen, 1994).6 All our SMT systems are built with the Moses toolkit (Koehn et al., 2007; Hoang et al., 2009), and word alignments are generated by the Berkeley Aligner (Liang et al., 2006). The target language model is estimated by the IRSTLM toolkit (Federico et al., 2008) with modified Kneser-Ney smoothing (Chen and Goodman, 1999). The phrase-based baseline decoder includes a phrase translation model (two phrasal and two lexical probability features), a lexicalized reordering model (six features), a 6-gram target language model, distortion cost, word and phrase penalties. As lexicalized reordering model, we use a hierarchical phrase orientation model (Galley and Manning, 2008)"
W13-2257,D09-1105,0,0.225795,"tatistical Machine Translation, pages 440–451, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics the verb-second order of German main clauses contrasts with the rigid SVO structure of English, as does the clause-final verb position of German subordinate clauses. A further difficulty is given by the German discontinuous verb phrases, where the main verb is separated from the inflected auxiliary or modal. The distance between the two parts of a verb phrase can be arbitrarily long as shown in the following example: selected by the decoder at translation time. In (Tromble and Eisner, 2009), pre-ordering is cast as a permutation problem and solved by a model that estimates the probability of reversing the relative order of any two input words. In the field of tree-based SMT, positive results in German-English were achieved by combining syntactic translation rules with unlabeled hierarchical SMT rules (Hoang and Koehn, 2010). More recently, Braune et al. (2012) proposed to improve the long-range reordering capability of an HSMT system by integrating constraints based on clausal boundaries and by manually selecting the rule patterns applicable to long word spans. The paper did not"
W13-2257,D11-1045,0,0.603126,"ly used in PSMT nowadays. However, their coarse classification of reordering steps makes them unsuitable to capture long-range reordering phenomena, such as those attested in German-English. Indeed, Galley and Manning (2008) reported a decrease of translation quality when the distortion limit was set beyond 6 in Chinese-English and beyond 4 in Arabic-English. To address this problem, we have developed a different reordering model that predicts what input word should be translated at a given decoding state (Bisazza, 2013; Bisazza and Federico, 2013). The model is similar to the one proposed by Visweswariah et al. (2011), however we use it differently: that is, not simply for data preprocessing but as an additional feature function fully integrated in the phrase-based decoder. More importantly, we propose to use the same model to dynamically shape the space of reorderings explored during decoding (cf. Section 4.2), which was never done before. Another related work is the source-side decoding sequence model by Feng et al. (2010), that is a generative n-gram model trained on a corpus of pre-ordered source sentences. Although reminiscent of a source-side bigram model, our model has two important differences: (i)"
W13-2257,C04-1073,0,0.0811749,"SMT has been widely studied and is still an open topic. In this work, we only consider efficient solutions that are fully integrated into the decoding process, and that do not require syntactic parsers or manual reordering rules. Still, it has to be mentioned that several alternative solutions were proposed in the literature. A well-known strategy consists of preordering the German sentence in an English-like order by applying a set of manually written rules to its syntactic parse tree (Collins et al., 2005).1 Other approaches learn the pre-ordering rules automatically, from syntactic parses (Xia and McCord, 2004; Genzel, 2010) or from part-of-speech labels (Niehues and Kolss, 2009). In the former case, pre-ordering decisions are typically taken deterministically (i. e. one permuation per sentence), whereas in the latter, multiple alternatives are represented as word lattices, and the optimal path is A large number of previous works on word reordering measured their success with generalpurpose metrics such as BLEU (Papineni et al., 2001) or METEOR (Banerjee and Lavie, 2005). These metrics, however, are only indirectly sensitive to word order and do not sufficiently penalize long-range reordering error"
W13-2257,2002.tmi-tutorials.2,0,0.0879086,"nd effectively capture long-range reordering phenomena. Through an extensive evaluation including diverse translation quality metrics, we show that these solutions can significantly narrow the gap between phrase-based and hierarchical SMT. 1 Introduction Modeling the German-English language pair is known to be a challenging task for state-of-theart statistical machine translation (SMT) methods. A major factor of difficulty is given by word order differences that yield important long-range reordering phenomena. Thanks to specific reordering modeling components, phrase-based SMT (PSMT) systems (Zens et al., 2002; Koehn et al., 2003; Och and Ney, 2002) are generally good at handling local reordering phenomena that are not captured inside phrases. However, they typically fail to predict long reorderings. On the other hand, hierarchical SMT (HSMT) systems (Chiang, 2005) can learn reordering patterns by means of discontinuous translation rules, and are therefore considered a better choice for language pairs characterized by massive and hierarchical reordering. 2 Background Word order differences between German and English are mainly found at the clause (global) level, as opposed to the phrase (local) lev"
W13-2257,P02-1040,0,\N,Missing
W13-2257,C10-1043,0,\N,Missing
W15-2518,D11-1033,0,0.0160741,"Kuhn, 2007) or log-linearly (Koehn and Schroeder, 2007). Sennrich (2012) enhances the approach by interpolating up to ten models, and Bertoldi and Federico (2009) use in-domain monolingual data to automatically generate in-domain bilingual data. Second, instance weighting methods prioritize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-labeled concepts that correspond to provenance or particular topic-genre combinations. In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014b) using latent Dirichlet allocation (Blei et al., 2003). Surprisingly, genre (or style) adaptation has only been addressed to a limited extent (Bisazza and Federico, 2012; Wang et al., 2012), with methods requiring the availability of clearly separable in-domain and out-of-domain training"
W15-2518,W09-0432,0,0.0244016,"e fine-grained subclasses, such as dialog-oriented content (e.g., SMS or chat messages), weblogs, or commentaries to news articles, all of which pose different challenges to SMT (van der Wees et al., 2015a). Most existing domain adaptation approaches can be grouped into two categories, depending on where in the SMT pipeline they adapt the system. First, mixture modeling approaches learn models from different subcorpora and interpolate these linearly (Foster and Kuhn, 2007) or log-linearly (Koehn and Schroeder, 2007). Sennrich (2012) enhances the approach by interpolating up to ten models, and Bertoldi and Federico (2009) use in-domain monolingual data to automatically generate in-domain bilingual data. Second, instance weighting methods prioritize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-labeled concepts that correspond to provenance or particular topic-genre combinations. In"
W15-2518,P05-1071,0,0.0316744,"ing data with a variety of web-crawled manually translated documents, containing user comments that are of a similar nature as the UG documents in the Gen&Topic, set as well as a number of other genres. Table 3 lists the corpus statistics of the training data, split by manual subcorpus labels as used for the subcorpus VSM variant (see Section 3.2). While our manually grouped subcorpora approximate those used by Chen et al. (2013), exact agreement was impossible to obtain, illustrating that it is not trivial to manually generate optimal subcorpus labels. We tokenize all Arabic data using MADA (Habash and Rambow, 2005), ATB scheme. Word alignment was performed by running GIZA++ in both directions and generating the symmetric alignments using the ‘grow-diag-final-and’ heuristics. We use an adapted language model which Experimental setup We evaluate the methods described in Section 3 on two Arabic-to-English translation tasks, both comprising the NW and UG. The first evaluation set is the Gen&Topic benchmark (van der Wees et al., 2015b), which consists of manually translated web-crawled news articles and their respective manually translated user comments, both covering five different topics. Since this evalua"
W15-2518,E14-1035,0,0.0131251,"ize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-labeled concepts that correspond to provenance or particular topic-genre combinations. In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014b) using latent Dirichlet allocation (Blei et al., 2003). Surprisingly, genre (or style) adaptation has only been addressed to a limited extent (Bisazza and Federico, 2012; Wang et al., 2012), with methods requiring the availability of clearly separable in-domain and out-of-domain training corpora. Recently, we studied the impact of topic and genre differences on SMT quality using the Gen&Topic benchmark set, an Arabic-English evaluation set with controlled topic distributions over two genres; newswire and UG comments (van der Wees et al., 2015b). Motivated by the observa"
W15-2518,E12-1045,1,0.862424,"In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-labeled concepts that correspond to provenance or particular topic-genre combinations. In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014b) using latent Dirichlet allocation (Blei et al., 2003). Surprisingly, genre (or style) adaptation has only been addressed to a limited extent (Bisazza and Federico, 2012; Wang et al., 2012), with methods requiring the availability of clearly separable in-domain and out-of-domain training corpora. Recently, we studied the impact of topic and genre differences on SMT quality using the Gen&Topic benchmark set, an Arabic-English evaluation set with controlled topic distributions over two genres; newswire and UG comments (van der Wees et al., 2015b). Motivated by the observation that translation quality varies more between the two genres than across topics, we explore in this paper the task of genre adaptation. Concretely, we incorporate genre-revealing features,"
W15-2518,W14-3358,0,0.0163973,"ize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-labeled concepts that correspond to provenance or particular topic-genre combinations. In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014b) using latent Dirichlet allocation (Blei et al., 2003). Surprisingly, genre (or style) adaptation has only been addressed to a limited extent (Bisazza and Federico, 2012; Wang et al., 2012), with methods requiring the availability of clearly separable in-domain and out-of-domain training corpora. Recently, we studied the impact of topic and genre differences on SMT quality using the Gen&Topic benchmark set, an Arabic-English evaluation set with controlled topic distributions over two genres; newswire and UG comments (van der Wees et al., 2015b). Motivated by the observa"
W15-2518,W12-3156,0,0.0318312,"nd Simard show that translation consistency does not imply higher quality, they also conclude that consistently translated phrases are more often translated correctly than inconsistently translated phrases. Table 7 shows some examples of phrases that Translation consistency analysis In the proposed translation model adaptation approach lexical choice is more tailored towards the different genres than in the baseline. We therefore hypothesize that the adapted system increases consistency of output translations within genres. To test this hypothesis, we measure translation consistency following Carpuat and Simard (2012). Their approach studies repeated phrases, defined 138 Genre Source phrase Baseline translation(s) VSM automatic genre translation(s) Inconsistent in baseline, consistent in adapted system: UG UG NW NW ð ÈYK @ Yë XAêk. B@ ð  ú jË@ ¨A¢®Ë@ éKAÖÏ@ áÓ and this indicates / and this shows that fatigue and stress / and the stress the health sector / workers in the health sector and this shows and the stress the health sector percent of egyptians / percent of them percent of Consistent in baseline, inconsistent in adapted system: UG UG NW NW PBðX PAJ ÊÓ AK ñJ Õæ ª¢JË@    AJ ®K Q¯@ Qå AJ ÖÏA«"
W15-2518,P13-2122,0,0.0121754,"ce weighting methods prioritize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-labeled concepts that correspond to provenance or particular topic-genre combinations. In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014b) using latent Dirichlet allocation (Blei et al., 2003). Surprisingly, genre (or style) adaptation has only been addressed to a limited extent (Bisazza and Federico, 2012; Wang et al., 2012), with methods requiring the availability of clearly separable in-domain and out-of-domain training corpora. Recently, we studied the impact of topic and genre differences on SMT quality using the Gen&Topic benchmark set, an Arabic-English evaluation set with controlled topic distributions over two genres; newswire and UG comments (van der Wees et al., 2015b). Mot"
W15-2518,D11-1125,0,0.0270128,"with varying numbers of latent dimensions (5, 10, 20, and 50). Of these, LDA with 10 dimensions yields the best translation performance, which is consistent with findings in a related topic adaptation approach by Eidelman et al. (2012). The LDA features in this VSM variant are inferred from the source side of the training data. 4 Genre Other features include linear distortion with limit 5, lexical weighting (Koehn et al., 2003), and a 5gram target language model trained with KneserNey smoothing (Chen and Goodman, 1999). The feature weights are tuned using pairwise ranking optimization (PRO) (Hopkins and May, 2011). For all experiments, tuning is done separately for the two genre-specific development sets. All runs use parallel corpora made available for NIST OpenMT 2012, excluding the UN data. While LDC-distributed data sets contain substantial portions of documents within the NW genre, they only contain small portions of UG documents. To alleviate this imbalance we augment our LDC-distributed training data with a variety of web-crawled manually translated documents, containing user comments that are of a similar nature as the UG documents in the Gen&Topic, set as well as a number of other genres. Tabl"
W15-2518,P13-1126,0,0.0291009,"Missing"
W15-2518,Q13-1035,0,0.0332699,"Missing"
W15-2518,W01-1007,0,0.315253,"tionally other textual characteristics such as dialect and register. This definition, however, has two major shortcomings. First, subcorpusbased domains depend on provenance information, which might not be available, or on manual grouping of documents into subcorpora, which is labor intensive and often carried out according to arbitrary criteria. Second, the commonly used notion of a domain neglects the fact that topic and genre are two distinct properties of text (Stein and Meyer Zu Eissen, 2006). While this distinction has long been acknowledged in text classification literature (Lee, 2001; Dewdney et al., 2001; Lee and Myaeng, 2002), most work on domain adaptation in SMT uses in-domain and out-of-domain data that differs on both the topic and the genre level (e.g., Europarl political proceedings (Koehn, 2005) versus EMEA medical text (Tiedemann, 2009)), making it unclear whether the proposed solutions address topic or genre differences. In this work, we follow text classification literature for definitions of the concepts topic and genre. While topic refers to the general subject (e.g., sports, politics or science) of a document, genre is harder to define since existing definitions vary. Swales (19"
W15-2518,C94-2174,0,0.467237,"s when using the automatic genre indicators on top of manual subcorpus labels. We also find that our genre-revealing feature values can be computed on either side of the training bitext, indicating that the proposed features are to a large extent language independent. Finally, we notice that our genre-adapted translation models encourage document-level translation consistency with respect to the unadapted baseline. 2 Domain adaptation for SMT 2.2 Text genre classification Work on text genre classification has resulted in various methods that use different sets of genre-specific text features. Karlgren and Cutting (1994) were among the first to use simple document statistics, such as common word frequencies, first-person pronoun count, and average sentence length. Kessler et al. (1997) categorize four types of genre-revealing cues: structural cues (e.g., part-of-speech (POS) tag counts), lexical cues (specific words), character-level cues (e.g., punctuation marks), and derivative cues (ratios and variation measures based on other types of cues). Dewdney et al. (2001) compare a large number of document features and show that these outperform bag-of-words approaches, which are traditionally used in topic-based"
W15-2518,P12-2023,0,0.0956579,"al data. Second, instance weighting methods prioritize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-labeled concepts that correspond to provenance or particular topic-genre combinations. In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014b) using latent Dirichlet allocation (Blei et al., 2003). Surprisingly, genre (or style) adaptation has only been addressed to a limited extent (Bisazza and Federico, 2012; Wang et al., 2012), with methods requiring the availability of clearly separable in-domain and out-of-domain training corpora. Recently, we studied the impact of topic and genre differences on SMT quality using the Gen&Topic benchmark set, an Arabic-English evaluation set with controlled topic distributions over two genres; newswire and UG comments (van"
W15-2518,P97-1005,0,0.345578,"Missing"
W15-2518,W07-0717,0,0.0205513,"-generated (UG) text, i.e., content written by lay-persons that has not undergone any editorial control. Within the latter we can distinguish more fine-grained subclasses, such as dialog-oriented content (e.g., SMS or chat messages), weblogs, or commentaries to news articles, all of which pose different challenges to SMT (van der Wees et al., 2015a). Most existing domain adaptation approaches can be grouped into two categories, depending on where in the SMT pipeline they adapt the system. First, mixture modeling approaches learn models from different subcorpora and interpolate these linearly (Foster and Kuhn, 2007) or log-linearly (Koehn and Schroeder, 2007). Sennrich (2012) enhances the approach by interpolating up to ten models, and Bertoldi and Federico (2009) use in-domain monolingual data to automatically generate in-domain bilingual data. Second, instance weighting methods prioritize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et a"
W15-2518,W07-0733,0,0.0242192,"ten by lay-persons that has not undergone any editorial control. Within the latter we can distinguish more fine-grained subclasses, such as dialog-oriented content (e.g., SMS or chat messages), weblogs, or commentaries to news articles, all of which pose different challenges to SMT (van der Wees et al., 2015a). Most existing domain adaptation approaches can be grouped into two categories, depending on where in the SMT pipeline they adapt the system. First, mixture modeling approaches learn models from different subcorpora and interpolate these linearly (Foster and Kuhn, 2007) or log-linearly (Koehn and Schroeder, 2007). Sennrich (2012) enhances the approach by interpolating up to ten models, and Bertoldi and Federico (2009) use in-domain monolingual data to automatically generate in-domain bilingual data. Second, instance weighting methods prioritize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains ar"
W15-2518,D10-1044,0,0.0558209,"Missing"
W15-2518,N03-1017,0,0.0151878,"ted on the Arabic side. Genre mapping: BC=broadcast conversation, BN=broadcast news, NG=newsgroup, NW=newswire, WL=UG weblogs, CM=UG comments, ED=editorials, SP=speech transcripts. 2010), with varying numbers of latent dimensions (5, 10, 20, and 50). Of these, LDA with 10 dimensions yields the best translation performance, which is consistent with findings in a related topic adaptation approach by Eidelman et al. (2012). The LDA features in this VSM variant are inferred from the source side of the training data. 4 Genre Other features include linear distortion with limit 5, lexical weighting (Koehn et al., 2003), and a 5gram target language model trained with KneserNey smoothing (Chen and Goodman, 1999). The feature weights are tuned using pairwise ranking optimization (PRO) (Hopkins and May, 2011). For all experiments, tuning is done separately for the two genre-specific development sets. All runs use parallel corpora made available for NIST OpenMT 2012, excluding the UN data. While LDC-distributed data sets contain substantial portions of documents within the NW genre, they only contain small portions of UG documents. To alleviate this imbalance we augment our LDC-distributed training data with a v"
W15-2518,P06-1070,0,0.0350482,"n any previous work. 133 In addition to the phrase pair vectors, a single vector is created for the development set which is assumed to be similar to the test data: tion. Finn and Kushmerick (2006) also compare the bag-of-words approach with simple text statistics and conclude that both methods achieve high classification accuracy on fixed topic-genre combinations but perform worse when predicting topic-independent genre labels. While mostly focused on the English language, some work has addressed language-independent (Sharoff, 2007; Sharoff et al., 2010) or crosslingual genre classification (Gliozzo and Strapparava, 2006; Petrenz, 2012; Petrenz and Webber, 2012), indicating that a single set of genrerevealing features can generalize across multiple languages. In this paper, we examine whether genre-revealing features are also language independent when applied to translation model genre adaptation for SMT. 3 V (dev ) = < w1 (dev ), . . . , wN (dev ) >, where weights wi (dev ) are computed for the entire development set, summing over the vectors of all phrase pairs that occur in the development set: X cdev (f¯, e¯) wi (f¯, e¯). (3) wi (dev ) = (f¯,¯ e)∈Pdev Here Pdev refers to the set of phrase pairs that can b"
W15-2518,2005.iwslt-1.8,0,0.0248349,"tuning, and NIST 2008 and NIST 2009 combined for testing. These data sets cover the genres NW and UG weblogs but are not controlled for topic distributions. Specifications for both evaluation sets are shown in Table 2. Note that Gen&Topic contains one reference translation per sentence, while NIST has four sets of reference translations. We perform our experiments using an inhouse phrase-based SMT system similar to Moses (Koehn et al., 2007). All runs use lexicalized reordering, distinguishing between monotone, swap, and discontinuous reordering, with respect to the previous and next phrase (Koehn et al., 2005). 136 Gen&Topic (1 reference) NIST (4 references) Method NW UG All NW UG All Baseline 21.5 17.2 19.3 55.3 40.4 48.5 VSM variants using automatic indicators of genre: LDA 10 topics 21.7 (+0.2) 17.3 (+0.1) 19.4M (+0.1) 55.9N (+0.6) 40.7M (+0.3) 49.0N (+0.5) Genre features Source Target 21.9N (+0.4) 21.7 (+0.2) 17.4M (+0.2) 17.5N (+0.3) 19.6N (+0.3) 19.6N (+0.3) 55.7N (+0.4) 55.9N (+0.6) 41.0N (+0.6) 41.2N (+0.8) 49.0N (+0.5) 49.1N (+0.6) Genre+LDA Source Target 21.9N (+0.4) 21.8N (+0.3) 17.5N (+0.3) 17.5N (+0.3) 19.7N (+0.4) 19.6N (+0.3) 56.1N (+0.8) 56.2N (+0.9) 41.2N (+0.8) 41.2N (+0.8) 49.2N"
W15-2518,E12-1055,0,0.0195346,"not undergone any editorial control. Within the latter we can distinguish more fine-grained subclasses, such as dialog-oriented content (e.g., SMS or chat messages), weblogs, or commentaries to news articles, all of which pose different challenges to SMT (van der Wees et al., 2015a). Most existing domain adaptation approaches can be grouped into two categories, depending on where in the SMT pipeline they adapt the system. First, mixture modeling approaches learn models from different subcorpora and interpolate these linearly (Foster and Kuhn, 2007) or log-linearly (Koehn and Schroeder, 2007). Sennrich (2012) enhances the approach by interpolating up to ten models, and Bertoldi and Federico (2009) use in-domain monolingual data to automatically generate in-domain bilingual data. Second, instance weighting methods prioritize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-"
W15-2518,2005.mtsummit-papers.11,0,0.00719864,"able, or on manual grouping of documents into subcorpora, which is labor intensive and often carried out according to arbitrary criteria. Second, the commonly used notion of a domain neglects the fact that topic and genre are two distinct properties of text (Stein and Meyer Zu Eissen, 2006). While this distinction has long been acknowledged in text classification literature (Lee, 2001; Dewdney et al., 2001; Lee and Myaeng, 2002), most work on domain adaptation in SMT uses in-domain and out-of-domain data that differs on both the topic and the genre level (e.g., Europarl political proceedings (Koehn, 2005) versus EMEA medical text (Tiedemann, 2009)), making it unclear whether the proposed solutions address topic or genre differences. In this work, we follow text classification literature for definitions of the concepts topic and genre. While topic refers to the general subject (e.g., sports, politics or science) of a document, genre is harder to define since existing definitions vary. Swales (1990), for example, refers to genre as a class of communicative events with a shared set of communicative purposes, and Karlgren (2004) calls it a grouping of documents that are stylistically consistent. B"
W15-2518,sharoff-etal-2010-web,0,0.0278368,"tures. To our knowledge, the fields have not been combined in any previous work. 133 In addition to the phrase pair vectors, a single vector is created for the development set which is assumed to be similar to the test data: tion. Finn and Kushmerick (2006) also compare the bag-of-words approach with simple text statistics and conclude that both methods achieve high classification accuracy on fixed topic-genre combinations but perform worse when predicting topic-independent genre labels. While mostly focused on the English language, some work has addressed language-independent (Sharoff, 2007; Sharoff et al., 2010) or crosslingual genre classification (Gliozzo and Strapparava, 2006; Petrenz, 2012; Petrenz and Webber, 2012), indicating that a single set of genrerevealing features can generalize across multiple languages. In this paper, we examine whether genre-revealing features are also language independent when applied to translation model genre adaptation for SMT. 3 V (dev ) = < w1 (dev ), . . . , wN (dev ) >, where weights wi (dev ) are computed for the entire development set, summing over the vectors of all phrase pairs that occur in the development set: X cdev (f¯, e¯) wi (f¯, e¯). (3) wi (dev ) ="
W15-2518,D09-1074,0,0.0291166,"grouped into two categories, depending on where in the SMT pipeline they adapt the system. First, mixture modeling approaches learn models from different subcorpora and interpolate these linearly (Foster and Kuhn, 2007) or log-linearly (Koehn and Schroeder, 2007). Sennrich (2012) enhances the approach by interpolating up to ten models, and Bertoldi and Federico (2009) use in-domain monolingual data to automatically generate in-domain bilingual data. Second, instance weighting methods prioritize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-labeled concepts that correspond to provenance or particular topic-genre combinations. In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014b) using latent Dirichlet allocation (Blei et al., 2003). Surprisingly, genre (or styl"
W15-2518,P10-2041,0,0.020232,"se linearly (Foster and Kuhn, 2007) or log-linearly (Koehn and Schroeder, 2007). Sennrich (2012) enhances the approach by interpolating up to ten models, and Bertoldi and Federico (2009) use in-domain monolingual data to automatically generate in-domain bilingual data. Second, instance weighting methods prioritize training instances that are most relevant to the test data, by assigning weights to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010; Chen et al., 2013). In the most extreme case, weights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-labeled concepts that correspond to provenance or particular topic-genre combinations. In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014b) using latent Dirichlet allocation (Blei et al., 2003). Surprisingly, genre (or style) adaptation has only been addressed to a limited extent (Bisazza and Federico, 2012; Wang et al., 2012), with methods requiring the availability of clearly separable in-domain and"
W15-2518,W15-4304,1,0.851321,"Missing"
W15-2518,P15-2092,1,0.745217,"Missing"
W15-2518,P02-1040,0,0.093436,"er overall results for NIST. is trained on 1.6B tokens and linearly interpolates different English Gigaword subcorpora with the English side of our bitext. The resulting model covers both genres in the benchmark sets, but is not varied between experiments since we want to investigate the effects of different features on translation model adaptation. 5 Results In this section we compare a number of variants of the general VSM framework, differing in the way vectors are defined and constructed (see Sections 3.2–3.4). Translation quality of all experiments is measured with case-insensitive BLEU (Papineni et al., 2002) using the closest-reference brevity penalty. We use approximate randomization (Noreen, 1989) for significance testing (Riezler and Maxwell, 2005). Statistically significant differences are marked by M and N for the p ≤ 0.05 and the p ≤ 0.01 level, respectively. VSM using intrinsic text features. We first test various VSM variants that use automatic indicators of genre and do not depend on the availability of provenance information or manual subcorpus labels (Table 4). Of these, genre adaptation with LDA-based features (Section 3.4) achieves strongly significant improvements over the unadapted"
W15-2518,2012.amta-papers.18,0,0.0169071,"ights are binary and training instances are either selected or discarded (Moore and Lewis, 2010; Axelrod et al., 2011). In most previous work, domains are typically hard-labeled concepts that correspond to provenance or particular topic-genre combinations. In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014b) using latent Dirichlet allocation (Blei et al., 2003). Surprisingly, genre (or style) adaptation has only been addressed to a limited extent (Bisazza and Federico, 2012; Wang et al., 2012), with methods requiring the availability of clearly separable in-domain and out-of-domain training corpora. Recently, we studied the impact of topic and genre differences on SMT quality using the Gen&Topic benchmark set, an Arabic-English evaluation set with controlled topic distributions over two genres; newswire and UG comments (van der Wees et al., 2015b). Motivated by the observation that translation quality varies more between the two genres than across topics, we explore in this paper the task of genre adaptation. Concretely, we incorporate genre-revealing features, inspired by previous"
W15-2518,E12-3002,0,0.0193562,"ition to the phrase pair vectors, a single vector is created for the development set which is assumed to be similar to the test data: tion. Finn and Kushmerick (2006) also compare the bag-of-words approach with simple text statistics and conclude that both methods achieve high classification accuracy on fixed topic-genre combinations but perform worse when predicting topic-independent genre labels. While mostly focused on the English language, some work has addressed language-independent (Sharoff, 2007; Sharoff et al., 2010) or crosslingual genre classification (Gliozzo and Strapparava, 2006; Petrenz, 2012; Petrenz and Webber, 2012), indicating that a single set of genrerevealing features can generalize across multiple languages. In this paper, we examine whether genre-revealing features are also language independent when applied to translation model genre adaptation for SMT. 3 V (dev ) = < w1 (dev ), . . . , wN (dev ) >, where weights wi (dev ) are computed for the entire development set, summing over the vectors of all phrase pairs that occur in the development set: X cdev (f¯, e¯) wi (f¯, e¯). (3) wi (dev ) = (f¯,¯ e)∈Pdev Here Pdev refers to the set of phrase pairs that can be extracted fro"
W15-2518,W05-0908,0,0.101247,"f our bitext. The resulting model covers both genres in the benchmark sets, but is not varied between experiments since we want to investigate the effects of different features on translation model adaptation. 5 Results In this section we compare a number of variants of the general VSM framework, differing in the way vectors are defined and constructed (see Sections 3.2–3.4). Translation quality of all experiments is measured with case-insensitive BLEU (Papineni et al., 2002) using the closest-reference brevity penalty. We use approximate randomization (Noreen, 1989) for significance testing (Riezler and Maxwell, 2005). Statistically significant differences are marked by M and N for the p ≤ 0.05 and the p ≤ 0.01 level, respectively. VSM using intrinsic text features. We first test various VSM variants that use automatic indicators of genre and do not depend on the availability of provenance information or manual subcorpus labels (Table 4). Of these, genre adaptation with LDA-based features (Section 3.4) achieves strongly significant improvements over the unadapted baseline for the NIST-NW and the complete NIST test sets, however improvements on the other test portions are very small. When manually inspectin"
W15-2518,P07-2045,0,\N,Missing
W15-4304,D10-1044,0,0.216563,"Missing"
W15-4304,D11-1033,0,0.0616033,"Missing"
W15-4304,P05-1071,0,0.0736573,"periments on a wellknown and established online SMT system. 4 Error analysis and results We perform four series of experiments, each with the goal of answering different questions about SMT for UG text: SMT systems All experiments presented in this paper are performed with our in-house state-of-the-art system based on phrase-based SMT and similar to Moses (Koehn et al., 2007). Our Arabic-English system is built from 1.75M lines (52.9M source tokens) of parallel text, and our Chinese-English system from 3.13M lines (55.4M source tokens) of parallel text. We tokenize all Arabic data using MADA (Habash and Rambow, 2005), ATB scheme, and we segment the Chinese data following Tseng et al. (2005). Both systems use an adapted 5-gram English language model that linearly interpolates different English Gigaword subcorpora with the 1. How large is the gap in translation quality between news and different types of UG data? (§4.1). To answer this question, we measure the BLEU score of two state-of-the-art SMT system outputs on all our data sets. 2. What kind of translation choices does the SMT system make for UG data? To answer this question, we measure phrase lengths used during the translation (or decoding) process"
W15-4304,W05-0909,0,0.0136668,"es on five different UG benchmark sets for two language pairs, Arabic-English and Chinese-English, with the goals of (i) explaining the typically poor SMT performance observed for UG texts, and (ii) identifying translation modeling Introduction User-generated (UG) text such as found on social media and web forums poses different challenges to statistical machine translation (SMT) than formal text. This is reflected by poor translation quality for informal genres (see for example Figure 1), which is typically measured with automatic quality metrics such as BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), or TER (Snover et al., 2006). These scores alone, however, only reflect the overall translation quality, and do not provide any insight in what exactly makes translating UG text hard. While such knowledge is crucial for improving SMT of UG text, surprisingly little work on error analysis for SMT of usergenerated text has been reported. Moreover, the notion of user-generated content 1 One of the very few exceptions is NIST OpenMT 2015, which focusses entirely on translating informal genres. 28 Proceedings of the ACL 2015 Workshop on Noisy User-generated Text, pages 28–37, c Beijing, China, Ju"
W15-4304,W12-3154,0,0.0451109,"slation of UG data. We not only contrast our observations with two news data sets, but we also show that SMT quality can vary significantly across different types of UG content, and that different UG types exhibit dissimilar error distributions. Specifically, we summarize our main findings as follows: on SMT error analysis studies the effect of domain adaptation on SMT, for example by examining in which stage of the SMT pipeline the available indomain data can best be used (Duh et al., 2010), or whether it is more promising to improve either phrase extraction or scoring (Bisazza et al., 2011; Haddow and Koehn, 2012). The vast majority of SMT research, including the above described work on error analysis, is evaluated on data containing formal language. Work on SMT of informal text mostly targets reduction of OOV words in the source text, for example by correcting spelling errors (Bertoldi et al., 2010), normalizing noisy text to more formal text (Banerjee et al., 2012; Ling et al., 2013a), or enhancing the training data with bilingual segments extracted from Twitter (Jehl et al., 2012; Ling et al., 2013b). Other work improves SMT of UG text by combining statistical and rule-based MT (Carrera et al., 2009"
W15-4304,2011.mtsummit-papers.32,0,0.206512,"Missing"
W15-4304,D11-1125,0,0.185121,"Missing"
W15-4304,2012.eamt-1.41,0,0.200338,"Missing"
W15-4304,W14-1617,0,0.0726374,". For example, SMS and chat data might benefit from text normalization (Bertoldi et al., 2010; Yvon, 2010; Ling et al., 2013a) or otherwise resolving source OOVs, which also has been the main focus of previous work on SMT for UG. On the other hand, while research in domain adaptation for SMT often aims at better scoring of existing translation candidates, we have shown that for many UG tasks the most promising direction involves increasing phrase pair recall of the SMT models (i.e., reducing phrase pair OOVs), for example by paraphrasing (Callison-Burch et al., 2006) or translation synthesis (Irvine and Callison-Burch, 2014). Conclusions and future directions Translating user-generated (UG) text is a difficult task for SMT. To explain the poor translation quality observed for UG data, we have performed a detailed error analysis on two language pairs (Arabic-English and Chinese-English) and five different types of UG data (SMS, chat, CTS, weblogs, and comments). Our quantitative results show among others that (i) UG data is translated with shorter source phrases than news, (ii) UG translation model coverage deteriorates substantially for longer phrases, and (iii) phrase-pair Acknowledgments This research was funde"
W15-4304,Q13-1035,0,0.14721,"Missing"
W15-4304,N10-1064,0,0.504951,"follows: on SMT error analysis studies the effect of domain adaptation on SMT, for example by examining in which stage of the SMT pipeline the available indomain data can best be used (Duh et al., 2010), or whether it is more promising to improve either phrase extraction or scoring (Bisazza et al., 2011; Haddow and Koehn, 2012). The vast majority of SMT research, including the above described work on error analysis, is evaluated on data containing formal language. Work on SMT of informal text mostly targets reduction of OOV words in the source text, for example by correcting spelling errors (Bertoldi et al., 2010), normalizing noisy text to more formal text (Banerjee et al., 2012; Ling et al., 2013a), or enhancing the training data with bilingual segments extracted from Twitter (Jehl et al., 2012; Ling et al., 2013b). Other work improves SMT of UG text by combining statistical and rule-based MT (Carrera et al., 2009), or models trained on formal and informal data (Banerjee et al., 2011). Finally, Roturier and Bensadoun (2011) conduct a comparative study to determine the ability of several SMT systems to translate UG text, but they do not examine what errors the systems make. To our knowledge, our work"
W15-4304,W12-3153,0,0.0782671,"t al., 2010), or whether it is more promising to improve either phrase extraction or scoring (Bisazza et al., 2011; Haddow and Koehn, 2012). The vast majority of SMT research, including the above described work on error analysis, is evaluated on data containing formal language. Work on SMT of informal text mostly targets reduction of OOV words in the source text, for example by correcting spelling errors (Bertoldi et al., 2010), normalizing noisy text to more formal text (Banerjee et al., 2012; Ling et al., 2013a), or enhancing the training data with bilingual segments extracted from Twitter (Jehl et al., 2012; Ling et al., 2013b). Other work improves SMT of UG text by combining statistical and rule-based MT (Carrera et al., 2009), or models trained on formal and informal data (Banerjee et al., 2011). Finally, Roturier and Bensadoun (2011) conduct a comparative study to determine the ability of several SMT systems to translate UG text, but they do not examine what errors the systems make. To our knowledge, our work is the first that looks inside an SMT system to systematically inspect its behavior across a diverse spectrum of UG text types. • The SMS and chat benchmarks are the most distant from fo"
W15-4304,2011.iwslt-evaluation.18,1,0.877498,"ressed to improve translation of UG data. We not only contrast our observations with two news data sets, but we also show that SMT quality can vary significantly across different types of UG content, and that different UG types exhibit dissimilar error distributions. Specifically, we summarize our main findings as follows: on SMT error analysis studies the effect of domain adaptation on SMT, for example by examining in which stage of the SMT pipeline the available indomain data can best be used (Duh et al., 2010), or whether it is more promising to improve either phrase extraction or scoring (Bisazza et al., 2011; Haddow and Koehn, 2012). The vast majority of SMT research, including the above described work on error analysis, is evaluated on data containing formal language. Work on SMT of informal text mostly targets reduction of OOV words in the source text, for example by correcting spelling errors (Bertoldi et al., 2010), normalizing noisy text to more formal text (Banerjee et al., 2012; Ling et al., 2013a), or enhancing the training data with bilingual segments extracted from Twitter (Jehl et al., 2012; Ling et al., 2013b). Other work improves SMT of UG text by combining statistical and rule-based"
W15-4304,N03-1017,0,0.0350837,"Chat SMS Figure 3: Average source-side and target-side phrase lengths used during decoding. 4.2 4. Why did the SMT system make the translation choices that it made? What errors are observed for each benchmark, and how often? To answer these questions, we reimplement the word-alignment driven error analysis approach by Irvine et al. (2013) and perform a qualitative analysis on the results (§4.4). 4.1 Translation phrase length analysis Most state-of-the-art SMT systems, including our in-house system, are phrase-based, with translations being generated phrase by phrase rather than word by word (Koehn et al., 2003). An abundant use of small phrases during decoding indicates that the system is not taking advantage of the model’s ability to memorize large contextual and possibly non-compositional translation blocks. It is therefore interesting to measure the average phrase length (i.e., number of tokens) used by the system, for the source as well as the target language (Figure 3). For Arabic-English we see that source-side phrases are noticeably longer for both news benchmarks than for the UG data sets. The average target-side phrase length, on the other hand, shows less correlation with the genres of the"
W15-4304,N06-1003,0,0.0673689,"ns, demanding diverse strategies to improve SMT quality. For example, SMS and chat data might benefit from text normalization (Bertoldi et al., 2010; Yvon, 2010; Ling et al., 2013a) or otherwise resolving source OOVs, which also has been the main focus of previous work on SMT for UG. On the other hand, while research in domain adaptation for SMT often aims at better scoring of existing translation candidates, we have shown that for many UG tasks the most promising direction involves increasing phrase pair recall of the SMT models (i.e., reducing phrase pair OOVs), for example by paraphrasing (Callison-Burch et al., 2006) or translation synthesis (Irvine and Callison-Burch, 2014). Conclusions and future directions Translating user-generated (UG) text is a difficult task for SMT. To explain the poor translation quality observed for UG data, we have performed a detailed error analysis on two language pairs (Arabic-English and Chinese-English) and five different types of UG data (SMS, chat, CTS, weblogs, and comments). Our quantitative results show among others that (i) UG data is translated with shorter source phrases than news, (ii) UG translation model coverage deteriorates substantially for longer phrases, an"
W15-4304,P13-1126,0,0.400947,"Missing"
W15-4304,P07-2045,0,0.0360285,"eriments use the same SMT models, but we tune parameters separately for each benchmark set using pairwise ranking optimization (PRO) (Hopkins and May, 2011). To put the results of our system into perspective, we also run a first series of experiments on a wellknown and established online SMT system. 4 Error analysis and results We perform four series of experiments, each with the goal of answering different questions about SMT for UG text: SMT systems All experiments presented in this paper are performed with our in-house state-of-the-art system based on phrase-based SMT and similar to Moses (Koehn et al., 2007). Our Arabic-English system is built from 1.75M lines (52.9M source tokens) of parallel text, and our Chinese-English system from 3.13M lines (55.4M source tokens) of parallel text. We tokenize all Arabic data using MADA (Habash and Rambow, 2005), ATB scheme, and we segment the Chinese data following Tseng et al. (2005). Both systems use an adapted 5-gram English language model that linearly interpolates different English Gigaword subcorpora with the 1. How large is the gap in translation quality between news and different types of UG data? (§4.1). To answer this question, we measure the BLEU"
W15-4304,2010.iwslt-papers.5,0,0.0753594,"ng, China, July 31, 2015. 2015 Association for Computational Linguistics aspects that should be addressed to improve translation of UG data. We not only contrast our observations with two news data sets, but we also show that SMT quality can vary significantly across different types of UG content, and that different UG types exhibit dissimilar error distributions. Specifically, we summarize our main findings as follows: on SMT error analysis studies the effect of domain adaptation on SMT, for example by examining in which stage of the SMT pipeline the available indomain data can best be used (Duh et al., 2010), or whether it is more promising to improve either phrase extraction or scoring (Bisazza et al., 2011; Haddow and Koehn, 2012). The vast majority of SMT research, including the above described work on error analysis, is evaluated on data containing formal language. Work on SMT of informal text mostly targets reduction of OOV words in the source text, for example by correcting spelling errors (Bertoldi et al., 2010), normalizing noisy text to more formal text (Banerjee et al., 2012; Ling et al., 2013a), or enhancing the training data with bilingual segments extracted from Twitter (Jehl et al.,"
W15-4304,D13-1008,0,0.235712,"by examining in which stage of the SMT pipeline the available indomain data can best be used (Duh et al., 2010), or whether it is more promising to improve either phrase extraction or scoring (Bisazza et al., 2011; Haddow and Koehn, 2012). The vast majority of SMT research, including the above described work on error analysis, is evaluated on data containing formal language. Work on SMT of informal text mostly targets reduction of OOV words in the source text, for example by correcting spelling errors (Bertoldi et al., 2010), normalizing noisy text to more formal text (Banerjee et al., 2012; Ling et al., 2013a), or enhancing the training data with bilingual segments extracted from Twitter (Jehl et al., 2012; Ling et al., 2013b). Other work improves SMT of UG text by combining statistical and rule-based MT (Carrera et al., 2009), or models trained on formal and informal data (Banerjee et al., 2011). Finally, Roturier and Bensadoun (2011) conduct a comparative study to determine the ability of several SMT systems to translate UG text, but they do not examine what errors the systems make. To our knowledge, our work is the first that looks inside an SMT system to systematically inspect its behavior ac"
W15-4304,P13-1018,0,0.221962,"by examining in which stage of the SMT pipeline the available indomain data can best be used (Duh et al., 2010), or whether it is more promising to improve either phrase extraction or scoring (Bisazza et al., 2011; Haddow and Koehn, 2012). The vast majority of SMT research, including the above described work on error analysis, is evaluated on data containing formal language. Work on SMT of informal text mostly targets reduction of OOV words in the source text, for example by correcting spelling errors (Bertoldi et al., 2010), normalizing noisy text to more formal text (Banerjee et al., 2012; Ling et al., 2013a), or enhancing the training data with bilingual segments extracted from Twitter (Jehl et al., 2012; Ling et al., 2013b). Other work improves SMT of UG text by combining statistical and rule-based MT (Carrera et al., 2009), or models trained on formal and informal data (Banerjee et al., 2011). Finally, Roturier and Bensadoun (2011) conduct a comparative study to determine the ability of several SMT systems to translate UG text, but they do not examine what errors the systems make. To our knowledge, our work is the first that looks inside an SMT system to systematically inspect its behavior ac"
W15-4304,D09-1074,0,0.461159,"Missing"
W15-4304,J03-1002,0,0.00461181,"the different data sets and between the two SMT systems. Still, translation quality is worse for the UG data sets than for news, indicating that also for this language pair translating UG text is more challenging than translating news. As all subsequent analyses require systeminternal information, we carry out the experiments with our in-house system only. 4.3 Model coverage analysis Next, we examine the translation model coverage for each data set, which tells us what phrases the system could have used for decoding. For each of our test sets, we create automatic word alignments using GIZA++ (Och and Ney, 2003), and extract from these the set of all reference phrase pairs using Moses’ phrase extraction algorithm (Koehn et al., 2007). By comparing this set of phrase pairs to the available phrases in the SMT models, which 31 Source phrase recall Genre BLEU LM PP Target phrase recall Phrase pair recall 1 2 3 4 1 2 3 4 1 2 3 4 News 1 News 2 33.8 21.5 65 86 99.7 99.6 88.9 88.1 56.3 53.7 26.1 21.8 99.7 99.5 91.1 88.1 61.5 53.4 29.6 23.6 84.9 77.4 54.4 46.9 23.6 18.8 8.1 5.9 Weblogs Comments CTS Chat SMS 22.3 17.2 16.0 10.0 8.8 152 117 103 179 196 99.2 97.7 97.4 94.1 93.7 80.5 80.2 66.3 56.0 57.8 40.6 43.0"
W15-4304,P02-1040,0,0.0927576,"k, we conduct a series of analyses on five different UG benchmark sets for two language pairs, Arabic-English and Chinese-English, with the goals of (i) explaining the typically poor SMT performance observed for UG texts, and (ii) identifying translation modeling Introduction User-generated (UG) text such as found on social media and web forums poses different challenges to statistical machine translation (SMT) than formal text. This is reflected by poor translation quality for informal genres (see for example Figure 1), which is typically measured with automatic quality metrics such as BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), or TER (Snover et al., 2006). These scores alone, however, only reflect the overall translation quality, and do not provide any insight in what exactly makes translating UG text hard. While such knowledge is crucial for improving SMT of UG text, surprisingly little work on error analysis for SMT of usergenerated text has been reported. Moreover, the notion of user-generated content 1 One of the very few exceptions is NIST OpenMT 2015, which focusses entirely on translating informal genres. 28 Proceedings of the ACL 2015 Workshop on Noisy User-generated Text"
W15-4304,J11-4002,0,0.0497536,"Missing"
W15-4304,2011.mtsummit-papers.27,0,0.027633,"alysis, is evaluated on data containing formal language. Work on SMT of informal text mostly targets reduction of OOV words in the source text, for example by correcting spelling errors (Bertoldi et al., 2010), normalizing noisy text to more formal text (Banerjee et al., 2012; Ling et al., 2013a), or enhancing the training data with bilingual segments extracted from Twitter (Jehl et al., 2012; Ling et al., 2013b). Other work improves SMT of UG text by combining statistical and rule-based MT (Carrera et al., 2009), or models trained on formal and informal data (Banerjee et al., 2011). Finally, Roturier and Bensadoun (2011) conduct a comparative study to determine the ability of several SMT systems to translate UG text, but they do not examine what errors the systems make. To our knowledge, our work is the first that looks inside an SMT system to systematically inspect its behavior across a diverse spectrum of UG text types. • The SMS and chat benchmarks are the most distant from formal text at all the analyzed levels. Errors in other types of UG are often more similar to news errors than to those in SMS and chat messages. • SMT model coverage dramatically deteriorates for phrases of length 3 or longer in most o"
W15-4304,2006.amta-papers.25,0,0.0591767,"ets for two language pairs, Arabic-English and Chinese-English, with the goals of (i) explaining the typically poor SMT performance observed for UG texts, and (ii) identifying translation modeling Introduction User-generated (UG) text such as found on social media and web forums poses different challenges to statistical machine translation (SMT) than formal text. This is reflected by poor translation quality for informal genres (see for example Figure 1), which is typically measured with automatic quality metrics such as BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), or TER (Snover et al., 2006). These scores alone, however, only reflect the overall translation quality, and do not provide any insight in what exactly makes translating UG text hard. While such knowledge is crucial for improving SMT of UG text, surprisingly little work on error analysis for SMT of usergenerated text has been reported. Moreover, the notion of user-generated content 1 One of the very few exceptions is NIST OpenMT 2015, which focusses entirely on translating informal genres. 28 Proceedings of the ACL 2015 Workshop on Noisy User-generated Text, pages 28–37, c Beijing, China, July 31, 2015. 2015 Association"
W15-4304,P15-2092,1,0.787076,"Missing"
W15-4304,I05-3027,0,\N,Missing
W16-3908,W14-1604,0,0.217424,"when Arabizi text is alternated with words from other languages, such as French or English, which it regularly is. While our approach leaves unconvertible words unchanged and often yields the right SMT output for English source words, addressing the problem of language detection before transliteration will likely benefit our approach. Bies et al. (2014) present their work on manually transliterating Arabizi SMS and chat messages to Arabic. Their work is focused on releasing a new resource rather than presenting a transliteration methodology, and naturally yields high-quality transliteration. Al-Badrashiny et al. (2014) use a weighted finite-state transducer (wFST) approach to converting Arabizi to Arabic in their system “3arrib”. They incorporate linguistic information by using CODA, a conventional orthography for Dialectal Arabic (Habash et al., 2012) and morphological analysis, and thus heavily rely on expert knowledge. All of the above focus on Arabizi-to-Arabic conversion outside the context of SMT from Arabizi. The work by May et al. (2014) is the only that presents an Arabizi-to-English SMT system, in which the authors not only focus on transliterating Arabizi to Arabic, but also evaluate performance"
W16-3908,W14-3612,0,0.0732706,"t a transliteration engine that, like our approach, follows the SMT paradigm. However, they complement their method with handcrafted rules. A similar approach by Darwish (2014) focuses on Arabizi detection as well as conversion to Arabic. The former is important when Arabizi text is alternated with words from other languages, such as French or English, which it regularly is. While our approach leaves unconvertible words unchanged and often yields the right SMT output for English source words, addressing the problem of language detection before transliteration will likely benefit our approach. Bies et al. (2014) present their work on manually transliterating Arabizi SMS and chat messages to Arabic. Their work is focused on releasing a new resource rather than presenting a transliteration methodology, and naturally yields high-quality transliteration. Al-Badrashiny et al. (2014) use a weighted finite-state transducer (wFST) approach to converting Arabizi to Arabic in their system “3arrib”. They incorporate linguistic information by using CODA, a conventional orthography for Dialectal Arabic (Habash et al., 2012) and morphological analysis, and thus heavily rely on expert knowledge. All of the above fo"
W16-3908,2011.iwslt-evaluation.18,1,0.842234,"word subcorpora with the English side of our bitext. When no valid Arabic transliteration is found for an Arabizi word, our software component leaves it unchanged. To increase the chances of handling such cases, we exploit our in-house Arabizi-English corpus of web-crawled user comments (see Section 2), on which we train a separate Arabizi-English system. Instead of using this system for the actual translation task, which would suffer from very low coverage, we merge the Arabizi-English phrase translation and phrase reordering models to the main Arabic-English models using a fillup technique (Bisazza et al., 2011). In this way, a non-transliterated word that is not matched by the main Arabic-English models has still a chance of being translated directly by the Arabizi-English models. We tokenize all Arabic data—training data as well as transliterated Arabizi—using the MADA toolkit (Habash and Rambow, 2005). 4.2 Results Table 4 shows SMT quality measured with case-insensitive BLEU (Papineni et al., 2002) for a number of transliteration scenarios. First, we see that Arabizi-to-English translation without any preprocessing (top row) results in very poor translation quality. There is, however, a large diff"
W16-3908,W12-4808,0,0.0236874,"able 5: SMT input-output example pairs for a sentence containing English words in the original Arabizi text. English reference translation: fine, okay, did you have fun?. 5 Related work In the past years, a few approaches to transliterate Arabizi to Arabic (or other tasks of deromanizing text in non-native Romanized script (Irvine et al., 2012)) have been presented, most of which rely to at least some extent on knowledge of experts or native speakers. In contrast, the approach we have presented does not rely on expert knowledge and is constructed using only publicly available data sources. 48 Chalabi and Gerges (2012) present a transliteration engine that, like our approach, follows the SMT paradigm. However, they complement their method with handcrafted rules. A similar approach by Darwish (2014) focuses on Arabizi detection as well as conversion to Arabic. The former is important when Arabizi text is alternated with words from other languages, such as French or English, which it regularly is. While our approach leaves unconvertible words unchanged and often yields the right SMT output for English source words, addressing the problem of language detection before transliteration will likely benefit our app"
W16-3908,W14-3629,0,0.0133144,"ast years, a few approaches to transliterate Arabizi to Arabic (or other tasks of deromanizing text in non-native Romanized script (Irvine et al., 2012)) have been presented, most of which rely to at least some extent on knowledge of experts or native speakers. In contrast, the approach we have presented does not rely on expert knowledge and is constructed using only publicly available data sources. 48 Chalabi and Gerges (2012) present a transliteration engine that, like our approach, follows the SMT paradigm. However, they complement their method with handcrafted rules. A similar approach by Darwish (2014) focuses on Arabizi detection as well as conversion to Arabic. The former is important when Arabizi text is alternated with words from other languages, such as French or English, which it regularly is. While our approach leaves unconvertible words unchanged and often yields the right SMT output for English source words, addressing the problem of language detection before transliteration will likely benefit our approach. Bies et al. (2014) present their work on manually transliterating Arabizi SMS and chat messages to Arabic. Their work is focused on releasing a new resource rather than present"
W16-3908,P05-1071,0,0.171505,"Missing"
W16-3908,habash-etal-2012-conventional,0,0.0317555,"g the problem of language detection before transliteration will likely benefit our approach. Bies et al. (2014) present their work on manually transliterating Arabizi SMS and chat messages to Arabic. Their work is focused on releasing a new resource rather than presenting a transliteration methodology, and naturally yields high-quality transliteration. Al-Badrashiny et al. (2014) use a weighted finite-state transducer (wFST) approach to converting Arabizi to Arabic in their system “3arrib”. They incorporate linguistic information by using CODA, a conventional orthography for Dialectal Arabic (Habash et al., 2012) and morphological analysis, and thus heavily rely on expert knowledge. All of the above focus on Arabizi-to-Arabic conversion outside the context of SMT from Arabizi. The work by May et al. (2014) is the only that presents an Arabizi-to-English SMT system, in which the authors not only focus on transliterating Arabizi to Arabic, but also evaluate performance in end-to-end Arabizi-to-English SMT experiments. Their transliteration approach uses wFSTs which are constructed by (i) experts, (ii) machine translation, or (iii) semi-automatically. In downstream SMT experiments, the semi-automatic con"
W16-3908,W12-2109,0,0.161558,"you have fun okay mashyyyy did you have fun Char.map.+disambig Char.map.+disambig+word pairs Human transliteration  did you have fun ú» úæAÓ  did you have fun ú»ð@ úæ AÓ AK Y ú»ð@ úæ AÓ à@ ¬ ¬Aë in order to did you have fun ok, ok, did you have fun ok, ok, against,, Table 5: SMT input-output example pairs for a sentence containing English words in the original Arabizi text. English reference translation: fine, okay, did you have fun?. 5 Related work In the past years, a few approaches to transliterate Arabizi to Arabic (or other tasks of deromanizing text in non-native Romanized script (Irvine et al., 2012)) have been presented, most of which rely to at least some extent on knowledge of experts or native speakers. In contrast, the approach we have presented does not rely on expert knowledge and is constructed using only publicly available data sources. 48 Chalabi and Gerges (2012) present a transliteration engine that, like our approach, follows the SMT paradigm. However, they complement their method with handcrafted rules. A similar approach by Darwish (2014) focuses on Arabizi detection as well as conversion to Arabic. The former is important when Arabizi text is alternated with words from oth"
W16-3908,P07-2045,0,0.00444937,"due to different possible spellings of English words in Arabic (e.g. baby / úG AK. or úæJ K.) or different spellings of Arabic dialectal forms (e.g. when / 4 . .  ), which reveals the difficulty éJÓ@ or úæÓ@ of evaluating Arabizi transliteration. Arabizi-to-English machine translation We examine the success of the proposed transliteration approaches by running Arabic-to-English SMT experiments, which we describe in Section 4.1 and discuss in Section 4.2. 4.1 Experimental setup We perform our translation experiments using an in-house state-of-the-art phrase-based SMT system similar to Moses (Koehn et al., 2007). The system is trained on the collection of Arabic-English parallel corpora discussed in Section 2, comprising 1.75M lines (52.9M Arabic tokens) of parallel text. In addition, we use a 5-gram English language model that linearly interpolates different English Gigaword subcorpora with the English side of our bitext. When no valid Arabic transliteration is found for an Arabizi word, our software component leaves it unchanged. To increase the chances of handling such cases, we exploit our in-house Arabizi-English corpus of web-crawled user comments (see Section 2), on which we train a separate A"
W16-3908,2014.amta-researchers.25,0,0.546466,"tical machine translation systems use a word-based language model over target language sequences to estimate the fluency of translation hypotheses. Here, we use an Arabiccharacter based language model instead. Decoding is carried out in the same manner as the normal translation setting, except that the distortion limit is set to 0, enforcing monotone decoding. Note that while we opt for using a publicly available character table, it would also be possible to learn a character mapping and its corresponding probabilities from an Arabizi-Arabic bitext. This is done for example in related work by May et al. (2014). An important problem at this point is that vowel mappings result in Arabic words having too many vowels orthographically present. This is particularly problematic for Arabizi words with repetitive vowels, a common phenomenon in user-generated text, such as observed in the word henaaa in Table 1. In order to address this problem, we allow for more flexible character mappings of vowels in which Arabizi vowels can be dropped. As a result, transliteration candidates for henaaa also include candidates for . hena, among which the correct Arabic word AJë 3.2 Filtering non-Arabic words Using the des"
W16-3908,P02-1040,0,0.0985415,"Missing"
W18-1801,N16-1036,1,0.893872,"Missing"
W18-1801,D18-1503,1,0.877386,"Missing"
W18-5453,Q16-1037,0,0.0514945,"et al., 2016; Johnson et al., 2017), morphological reinflection (Kann et al., 2017) and more (Bjerva, 2017). A practical benefit of training models multilingually is to transfer knowledge from high-resource languages to lowresource ones and improve task performance in the latter. Here we aim at understanding how linguistic knowledge is transferred among languages, specifically at the syntactic level, which to our knowledge has not been studied so far. Assessing the syntactic abilities of monolingual neural LMs trained without explicit supervision has been the focus of several recent studies: Linzen et al. (2016) analyzed the performance of LSTM LMs at an English subject-verb agreement task, while Gulordava et al. (2018) extended the analysis to various long-range agreement patterns in different languages. The latter study found that state-of-the-art LMs trained on a standard loglikelihood objective capture non-trivial patterns of syntactic agreement and can approach the performance levels of humans, even when tested on syntactically well-formed but meaningless (nonce) sentences. Cross-language interaction during language production and comprehension by human subjects has been widely studied in the fi"
W18-5453,P15-1166,0,0.064556,"Missing"
W18-5453,D17-1268,0,0.0910482,"Missing"
W18-5453,I17-2050,0,0.0205405,"periments. The unigram baseline simply picks, for each sentence, the most frequent word form between singular or plural. As an upper-bound we report the agreement accuracy obtained by a monolingual model trained on a large L2 corpus. 4 Experiment We consider the scenario where L1 is overresourced compared to L2 and train our bilingual models by joint training on a mixed L1/L2 corpus so that supervision is provided simultaneously in ¨ the two languages (Ostling and Tiedemann, 2017; Johnson et al., 2017). We leave the evaluation of pre-training (or transfer learning) methods (Zoph et al., 2016; Nguyen and Chiang, 2017) to future work. The monolingual LM is trained on a small L2 corpus (LML2 ). The bilingual LM is trained on a shuffled mix of the same small L2 corpus and a large L1 corpus, where L2 is oversampled to approximately match the amount of L1 sentences (LML1+L2 ). See Table 1 for the actual training sizes. For our preliminary experiments we have chosen French as the helper language (L1) and Italian as the target language (L2). Since French and Italian share many morphosyntactic patterns, accuracy on the Italian agreement tasks is expected to benefit from adding French sentences to the training data"
W18-5453,N16-1101,0,0.0397728,"Missing"
W18-5453,N18-1108,0,0.107699,"). A practical benefit of training models multilingually is to transfer knowledge from high-resource languages to lowresource ones and improve task performance in the latter. Here we aim at understanding how linguistic knowledge is transferred among languages, specifically at the syntactic level, which to our knowledge has not been studied so far. Assessing the syntactic abilities of monolingual neural LMs trained without explicit supervision has been the focus of several recent studies: Linzen et al. (2016) analyzed the performance of LSTM LMs at an English subject-verb agreement task, while Gulordava et al. (2018) extended the analysis to various long-range agreement patterns in different languages. The latter study found that state-of-the-art LMs trained on a standard loglikelihood objective capture non-trivial patterns of syntactic agreement and can approach the performance levels of humans, even when tested on syntactically well-formed but meaningless (nonce) sentences. Cross-language interaction during language production and comprehension by human subjects has been widely studied in the fields of bilingualism and second language acquisition (Kellerman and Sharwood Smith; Odlin, 1989; Jarvis and Pa"
W18-5453,E17-2102,0,0.0894617,"ntly but together in the mind of bilinguals and second-language learners, leading to observRecent work has shown that neural models can be successfully trained on multiple languages simultaneously. We investigate whether such models learn to share and exploit common syntactic knowledge among the languages on which they are trained. This extended abstract presents our preliminary results. 1 Introduction Recent work has shown that state-of-the-art neural models of language and translation can be successfully trained on multiple languages simultaneously without changing the model architecture ¨ (Ostling and Tiedemann, 2017; Johnson et al., 2017). In some cases this leads to improved performance compared to models only trained on a specific language, suggesting that multilingual models learn to share useful knowledge crosslingually through their learned representations. While a large body of research exists on the multilingual mind, the mechanisms explaining knowledge sharing in computational multilingual models remain largely unknown: What kind of knowledge is shared among languages? Do multilingual models mostly benefit from a better modeling of lexical entries or do they also learn to share more abstract ling"
W18-5453,N16-1161,0,0.0692066,"Missing"
W18-5453,D16-1163,0,0.0202744,"our preliminary experiments. The unigram baseline simply picks, for each sentence, the most frequent word form between singular or plural. As an upper-bound we report the agreement accuracy obtained by a monolingual model trained on a large L2 corpus. 4 Experiment We consider the scenario where L1 is overresourced compared to L2 and train our bilingual models by joint training on a mixed L1/L2 corpus so that supervision is provided simultaneously in ¨ the two languages (Ostling and Tiedemann, 2017; Johnson et al., 2017). We leave the evaluation of pre-training (or transfer learning) methods (Zoph et al., 2016; Nguyen and Chiang, 2017) to future work. The monolingual LM is trained on a small L2 corpus (LML2 ). The bilingual LM is trained on a shuffled mix of the same small L2 corpus and a large L1 corpus, where L2 is oversampled to approximately match the amount of L1 sentences (LML1+L2 ). See Table 1 for the actual training sizes. For our preliminary experiments we have chosen French as the helper language (L1) and Italian as the target language (L2). Since French and Italian share many morphosyntactic patterns, accuracy on the Italian agreement tasks is expected to benefit from adding French sent"
