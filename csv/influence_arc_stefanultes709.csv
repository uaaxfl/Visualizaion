2020.lrec-1.65,E17-1024,0,0.0163103,"t contain topic specific key words. The list of key words consists of sub strings of the topic (for example nuclear and energy) as well as a WordNet (Bird et al., 2009; Miller et al., 1990) synonym either of the complete search query or (if none was found) the sub strings. The final arguments are then sampled from this list with a fixed random seed, also 3 http://commoncrawl.org/ https://guncontrolfacts.org/category/gun-control-pros-andcons/ 4 516 to ensure reproducibility. In order to determine the stance of the retrieved argument, we train a classifier on the IBM stance classification data (Bar-Haim et al., 2017). The corpus consists of 2394 claims annotated with an overall sentiment label sc ∈ {1, −1}, the stance towards the related topic and a sentiment label for the topic st ∈ {1, −1}. Similar to the baseline approaches in the original work, we train a model to estimate the sentiment of each claim and assume that the target towards which the estimated sentiment is expressed is consistent with the target of the topic. The corresponding stance can then be derived as sc × st . Our approach utilizes a pre-trained BERT (Devlin et al., 2019) model5 to get sentence embeddings for all claims in the corpus"
2020.lrec-1.65,W15-4603,0,0.0157949,"guments, i.e. the dialogue management, and the non-verbal behaviour of the avatar. Implications for Dialogue Systems The results of our study also allow some general conclusions for the development of future argumentative dialogue systems that aim to exploit argument search in order to retrieve arguments. Firstly, the reported subjectivity of the argument perception stresses the need for a careful selection of arguments based on the target audience or user. Consequently, adaptation and user modelling approaches investigated for the use in dialogue systems (Ultes et al., 2019; Mo et al., 2018; Casanueva et al., 2015) are also required in the domain of argumentation, although it is not clear from the results which user traits are the most relevant. In addition to this, the reported high user comprehension of the system’s utterances (Figure 2) allows the conclusion that arguments retrieved by argument search engines can generally be understood. However, several participants reported that spelling or grammar errors in the arguments lead to an unnatural system output, which, although generally comprehensible, was not natural and intuitive. Consequently, more advanced approaches to NLG in combination with para"
2020.lrec-1.65,P19-3022,0,0.522077,"first requirement is necessary for the technical applicability of the search engine within argumentative applications whereas the second requirement is motivated by the need for stance information in the majority of the desired tasks of an argumentative system. The aim of an argument search engine is to retrieve a ranked list of arguments related to a given search query. Different systems introduced so far follow different paradigms in order to accomplish this goal (Ajjour et al., 2019) and include the IBM Project Debater (Levy et al., 2018), TARGER (Chernodub et al., 2019), PerspectroScope (Chen et al., 2019), args.me (Wachsmuth et al., 2017c) and ArgumenText (Stab et al., 2018a). Out of this list, only ArgumenText, args.me and TARGER provide an API to access retrieved arguments and only the first two also include information about their stance. Consequently, we focus our evaluation on these two and discuss the underlying approaches in detail in the following subsections. In addition, we propose a novel system utilizing a conventional web search approach in order to generate baseline results for the evaluation. 515 Information System Return Information System Return Premises If marriage’s main fun"
2020.lrec-1.65,P19-3031,0,0.244586,"the stance of the retrieved arguments. The first requirement is necessary for the technical applicability of the search engine within argumentative applications whereas the second requirement is motivated by the need for stance information in the majority of the desired tasks of an argumentative system. The aim of an argument search engine is to retrieve a ranked list of arguments related to a given search query. Different systems introduced so far follow different paradigms in order to accomplish this goal (Ajjour et al., 2019) and include the IBM Project Debater (Levy et al., 2018), TARGER (Chernodub et al., 2019), PerspectroScope (Chen et al., 2019), args.me (Wachsmuth et al., 2017c) and ArgumenText (Stab et al., 2018a). Out of this list, only ArgumenText, args.me and TARGER provide an API to access retrieved arguments and only the first two also include information about their stance. Consequently, we focus our evaluation on these two and discuss the underlying approaches in detail in the following subsections. In addition, we propose a novel system utilizing a conventional web search approach in order to generate baseline results for the evaluation. 515 Information System Return Information System R"
2020.lrec-1.65,N19-1423,0,0.0139232,"we train a classifier on the IBM stance classification data (Bar-Haim et al., 2017). The corpus consists of 2394 claims annotated with an overall sentiment label sc ∈ {1, −1}, the stance towards the related topic and a sentiment label for the topic st ∈ {1, −1}. Similar to the baseline approaches in the original work, we train a model to estimate the sentiment of each claim and assume that the target towards which the estimated sentiment is expressed is consistent with the target of the topic. The corresponding stance can then be derived as sc × st . Our approach utilizes a pre-trained BERT (Devlin et al., 2019) model5 to get sentence embeddings for all claims in the corpus which are then used as feature vectors for a support vector machine (SVM) classification. The parameters of the SVM are optimized in a systematic grid search in order to match the specific task. The performance of our model is evaluated by averaging the results for five different random train/test splittings of the data with the same characteristics provided in the original work (training: 25 topics and 1039 claims, test: 30 topics and 1355 claims). Since the overall system requires an estimate of the stance for all retrieved argu"
2020.lrec-1.65,P19-1093,0,0.0174145,"hey divide argument quality in the broad categories of logical, rhetorical and dialectical quality and introduce 15 fine-grained sub-dimensions as well as a corpus annotated with these dimensions. Habernal and Gurevych (2016a) introduced an approach to assess the convincingness of arguments in which arguments were rated in direct comparison to each other in a crowd-sourcing experiment. The correlations between the theoretical and the crowd-sourcing based approach were also investigated (Wachsmuth et al., 2017a) and a corpus for the comparison of the convincingness of evidences was introduced (Gleize et al., 2019). The overall quality of single arguments as well as argument pairs was discussed by Toledo et al. (2019) together with automatized approaches for argument ranking and argument-pair classification. Finally, Potthast et al. (2019) utilized expert ratings of the above mentioned categories logical, rhetorical and dialectical quality to assess different retrieval approaches for argument search in combination with the information retrieval notion of relevance. To the best of our knowledge, no studies have been carried out which explicitly focus on argument quality assessment in the context of dialo"
2020.lrec-1.65,D16-1129,0,0.115863,"eans of an argumentative dialogue system that evaluates arguments retrieved by different search approaches directly in the interaction with users. This is realized by allowing the user to give specific ratings in the categories Interesting, Convincing, Comprehensible and Related as direct feedback to each system utterance. In order to ensure a setting that is representative for dialogue system applications, the arguments are presented by means of a virtual avatar and synthetic speech. The approach is motivated by the difficulty of argument quality assessment from a purely logical perspective (Habernal and Gurevych, 2016b; Wachsmuth et al., 2017a) as well as the common approach to evaluate dialogue systems from the user perspective (Deriu et al., 2019). Especially the subjective nature of our addressed application scenarios (and argumentation itself) and the effects of system modalities (virtual avatar and synthetic speech) in the present scenario render approaches that do not explicitly consider the user perception impractical. We apply our system in a user study in order to compare two state of the art argument search engines, namely ArgumenText (Stab et al., 2018a) and args.me (Wachsmuth et al., 2017c), to"
2020.lrec-1.65,P16-1150,0,0.180899,"eans of an argumentative dialogue system that evaluates arguments retrieved by different search approaches directly in the interaction with users. This is realized by allowing the user to give specific ratings in the categories Interesting, Convincing, Comprehensible and Related as direct feedback to each system utterance. In order to ensure a setting that is representative for dialogue system applications, the arguments are presented by means of a virtual avatar and synthetic speech. The approach is motivated by the difficulty of argument quality assessment from a purely logical perspective (Habernal and Gurevych, 2016b; Wachsmuth et al., 2017a) as well as the common approach to evaluate dialogue systems from the user perspective (Deriu et al., 2019). Especially the subjective nature of our addressed application scenarios (and argumentation itself) and the effects of system modalities (virtual avatar and synthetic speech) in the present scenario render approaches that do not explicitly consider the user perception impractical. We apply our system in a user study in order to compare two state of the art argument search engines, namely ArgumenText (Stab et al., 2018a) and args.me (Wachsmuth et al., 2017c), to"
2020.lrec-1.65,W18-5215,0,0.109042,"006). The effect of different types of arguments presented by an argumentative chat bot were investigated in the behaviour change domain and also by means of a user study by Chalaguine et al. (2019), showing that arguments that address the concerns of the user were preferred over others. The assessment from a technical perspective was considered by Rakshit et al. (2019), where a comparison of response times for the different underlying techniques was utilized as evaluation criterion. Moreover, a retrieval-based approach and a generative approach to generate the system response were discussed (Le et al., 2018) and separately evaluated on established metrics for the underlying technological task. Finally, Sakai et al. (2018) and Rach et al. (2019) evaluated argument structures acquired specifically for the use in dialogue systems also by means of user studies. However, the evaluation in these cases is focused on specific systems and/or data and the effect of different acquisition techniques as desired in the present work was therefore not included. In order to provide a detailed evaluation that is not tailored to one specific task, we combine the generalized approach of task success rate as evaluati"
2020.lrec-1.65,C18-1176,0,0.200915,"d provide information about the stance of the retrieved arguments. The first requirement is necessary for the technical applicability of the search engine within argumentative applications whereas the second requirement is motivated by the need for stance information in the majority of the desired tasks of an argumentative system. The aim of an argument search engine is to retrieve a ranked list of arguments related to a given search query. Different systems introduced so far follow different paradigms in order to accomplish this goal (Ajjour et al., 2019) and include the IBM Project Debater (Levy et al., 2018), TARGER (Chernodub et al., 2019), PerspectroScope (Chen et al., 2019), args.me (Wachsmuth et al., 2017c) and ArgumenText (Stab et al., 2018a). Out of this list, only ArgumenText, args.me and TARGER provide an API to access retrieved arguments and only the first two also include information about their stance. Consequently, we focus our evaluation on these two and discuss the underlying approaches in detail in the following subsections. In addition, we propose a novel system utilizing a conventional web search approach in order to generate baseline results for the evaluation. 515 Information S"
2020.lrec-1.65,P19-1054,1,0.836778,"roaches to NLG in combination with paraphrasing and grammar correction are also of interest in order to improve the user experience (Kwon et al., 2015; Wen et al., 2015). Finally it should be noted that many dialogue systems require a more fine grained structure of arguments (Aicher et al., 2019; Sakai et al., 2018; Rosenfeld and Kraus, 2016; Rach et al., 2018) that include not just the general argument stance but also their explicit relations to each other. Hence, additional processing of the search results in order to structure the retrieved arguments as for example clustering of arguments (Reimers et al., 2019) may be required in order to allow systems of these kind to exploit argument search engines. 8. Conclusion We introduced an evaluation setup for argument search approaches in the context of argumentative dialogue systems. Our approach assesses the users’ opinions and perception regarding arguments presented by an avatar with synthetic speech. During the interaction with the system, users are able to rate the arguments presented by the avatar in the categories Interesting, Convincing, Comprehensible and Related as a direct response to the system utterance. The approach was applied in a user stu"
2020.lrec-1.65,L18-1627,0,0.185199,"behaviour change domain and also by means of a user study by Chalaguine et al. (2019), showing that arguments that address the concerns of the user were preferred over others. The assessment from a technical perspective was considered by Rakshit et al. (2019), where a comparison of response times for the different underlying techniques was utilized as evaluation criterion. Moreover, a retrieval-based approach and a generative approach to generate the system response were discussed (Le et al., 2018) and separately evaluated on established metrics for the underlying technological task. Finally, Sakai et al. (2018) and Rach et al. (2019) evaluated argument structures acquired specifically for the use in dialogue systems also by means of user studies. However, the evaluation in these cases is focused on specific systems and/or data and the effect of different acquisition techniques as desired in the present work was therefore not included. In order to provide a detailed evaluation that is not tailored to one specific task, we combine the generalized approach of task success rate as evaluation criterion with aspects related to the field of argument quality assessment. As for computational argumentation, W"
2020.lrec-1.65,N07-2038,0,0.20191,"ussion of the results is included in Section 7., followed by a conclusion and an outlook on future work in Section 8. 2. Related Work In this section, we discuss related work from the fields of dialogue system evaluation and argument quality assessment. For dialogue systems, different general evaluation approaches exist based on the different types of system (Deriu et al., 2019). For task oriented systems, which are the most relevant in view of argumentation, the task success rate, i.e. the rate at which a system successfully carries out the assigned function is a common evaluation criterion (Schatzmann et al., 2007; Laroche et al., 2011). It was combined with a measure of the dialogue cost and the subjective satisfaction of the user with the interaction in the PARADISE framework (Walker et al., 1997; Walker et al., 2000) in order to enable comparisons of different systems. In addition, Ultes et al. (2013) introduced the Interaction Quality as an expert rating based approach to model user satisfaction. Since argumentation is a comparatively new domain for dialogue systems, assessment of argumentative systems is currently done in a very system specific way: The Project Debater introduced by IBM was evalua"
2020.lrec-1.65,N18-5005,1,0.864142,"Missing"
2020.lrec-1.65,D18-1402,0,0.249833,"rom a purely logical perspective (Habernal and Gurevych, 2016b; Wachsmuth et al., 2017a) as well as the common approach to evaluate dialogue systems from the user perspective (Deriu et al., 2019). Especially the subjective nature of our addressed application scenarios (and argumentation itself) and the effects of system modalities (virtual avatar and synthetic speech) in the present scenario render approaches that do not explicitly consider the user perception impractical. We apply our system in a user study in order to compare two state of the art argument search engines, namely ArgumenText (Stab et al., 2018a) and args.me (Wachsmuth et al., 2017c), to each other. In addition, we introduce an argument retrieval system based on conventional web search to provide a suitable baseline. In order to exclude topic dependencies, the comparison is done over three different controversial topics. The results show significant differences between the investigated approaches for three of the four categories and both search engines outperform the baseline in one category. In addition, both search engines outperform each other in a different category, thereby reflecting the different strengths and drawbacks of th"
2020.lrec-1.65,D19-1564,0,0.0113043,"troduce 15 fine-grained sub-dimensions as well as a corpus annotated with these dimensions. Habernal and Gurevych (2016a) introduced an approach to assess the convincingness of arguments in which arguments were rated in direct comparison to each other in a crowd-sourcing experiment. The correlations between the theoretical and the crowd-sourcing based approach were also investigated (Wachsmuth et al., 2017a) and a corpus for the comparison of the convincingness of evidences was introduced (Gleize et al., 2019). The overall quality of single arguments as well as argument pairs was discussed by Toledo et al. (2019) together with automatized approaches for argument ranking and argument-pair classification. Finally, Potthast et al. (2019) utilized expert ratings of the above mentioned categories logical, rhetorical and dialectical quality to assess different retrieval approaches for argument search in combination with the information retrieval notion of relevance. To the best of our knowledge, no studies have been carried out which explicitly focus on argument quality assessment in the context of dialogue systems. 3. Evaluation Criteria As a first step in developing the actual evaluation setup, we introdu"
2020.lrec-1.65,N13-1064,1,0.699414,"tion approaches exist based on the different types of system (Deriu et al., 2019). For task oriented systems, which are the most relevant in view of argumentation, the task success rate, i.e. the rate at which a system successfully carries out the assigned function is a common evaluation criterion (Schatzmann et al., 2007; Laroche et al., 2011). It was combined with a measure of the dialogue cost and the subjective satisfaction of the user with the interaction in the PARADISE framework (Walker et al., 1997; Walker et al., 2000) in order to enable comparisons of different systems. In addition, Ultes et al. (2013) introduced the Interaction Quality as an expert rating based approach to model user satisfaction. Since argumentation is a comparatively new domain for dialogue systems, assessment of argumentative systems is currently done in a very system specific way: The Project Debater introduced by IBM was evaluated by engaging with a human in a live debate. The outcome was determined by a comparison of the audience’s stance before and after the debate, showing an advantage of the human debater over Project Debater. Rosenfeld and Kraus (2016) evaluated the persuasive effect of their introduced persuasiv"
2020.lrec-1.65,P17-2039,0,0.0963646,"gue system that evaluates arguments retrieved by different search approaches directly in the interaction with users. This is realized by allowing the user to give specific ratings in the categories Interesting, Convincing, Comprehensible and Related as direct feedback to each system utterance. In order to ensure a setting that is representative for dialogue system applications, the arguments are presented by means of a virtual avatar and synthetic speech. The approach is motivated by the difficulty of argument quality assessment from a purely logical perspective (Habernal and Gurevych, 2016b; Wachsmuth et al., 2017a) as well as the common approach to evaluate dialogue systems from the user perspective (Deriu et al., 2019). Especially the subjective nature of our addressed application scenarios (and argumentation itself) and the effects of system modalities (virtual avatar and synthetic speech) in the present scenario render approaches that do not explicitly consider the user perception impractical. We apply our system in a user study in order to compare two state of the art argument search engines, namely ArgumenText (Stab et al., 2018a) and args.me (Wachsmuth et al., 2017c), to each other. In addition,"
2020.lrec-1.65,E17-1017,0,0.134625,"gue system that evaluates arguments retrieved by different search approaches directly in the interaction with users. This is realized by allowing the user to give specific ratings in the categories Interesting, Convincing, Comprehensible and Related as direct feedback to each system utterance. In order to ensure a setting that is representative for dialogue system applications, the arguments are presented by means of a virtual avatar and synthetic speech. The approach is motivated by the difficulty of argument quality assessment from a purely logical perspective (Habernal and Gurevych, 2016b; Wachsmuth et al., 2017a) as well as the common approach to evaluate dialogue systems from the user perspective (Deriu et al., 2019). Especially the subjective nature of our addressed application scenarios (and argumentation itself) and the effects of system modalities (virtual avatar and synthetic speech) in the present scenario render approaches that do not explicitly consider the user perception impractical. We apply our system in a user study in order to compare two state of the art argument search engines, namely ArgumenText (Stab et al., 2018a) and args.me (Wachsmuth et al., 2017c), to each other. In addition,"
2020.lrec-1.65,W17-5106,0,0.22544,"gue system that evaluates arguments retrieved by different search approaches directly in the interaction with users. This is realized by allowing the user to give specific ratings in the categories Interesting, Convincing, Comprehensible and Related as direct feedback to each system utterance. In order to ensure a setting that is representative for dialogue system applications, the arguments are presented by means of a virtual avatar and synthetic speech. The approach is motivated by the difficulty of argument quality assessment from a purely logical perspective (Habernal and Gurevych, 2016b; Wachsmuth et al., 2017a) as well as the common approach to evaluate dialogue systems from the user perspective (Deriu et al., 2019). Especially the subjective nature of our addressed application scenarios (and argumentation itself) and the effects of system modalities (virtual avatar and synthetic speech) in the present scenario render approaches that do not explicitly consider the user perception impractical. We apply our system in a user study in order to compare two state of the art argument search engines, namely ArgumenText (Stab et al., 2018a) and args.me (Wachsmuth et al., 2017c), to each other. In addition,"
2020.lrec-1.65,P97-1035,0,0.683758,"f dialogue system evaluation and argument quality assessment. For dialogue systems, different general evaluation approaches exist based on the different types of system (Deriu et al., 2019). For task oriented systems, which are the most relevant in view of argumentation, the task success rate, i.e. the rate at which a system successfully carries out the assigned function is a common evaluation criterion (Schatzmann et al., 2007; Laroche et al., 2011). It was combined with a measure of the dialogue cost and the subjective satisfaction of the user with the interaction in the PARADISE framework (Walker et al., 1997; Walker et al., 2000) in order to enable comparisons of different systems. In addition, Ultes et al. (2013) introduced the Interaction Quality as an expert rating based approach to model user satisfaction. Since argumentation is a comparatively new domain for dialogue systems, assessment of argumentative systems is currently done in a very system specific way: The Project Debater introduced by IBM was evaluated by engaging with a human in a live debate. The outcome was determined by a comparison of the audience’s stance before and after the debate, showing an advantage of the human debater ov"
2020.lrec-1.65,W15-4639,0,0.0675677,"Missing"
2020.lrec-1.68,E17-1003,0,0.043442,"Missing"
2020.lrec-1.68,D16-1216,0,0.0188355,"n down to rather simple key word spotting (e.g. “sorry”, “just”, “and stuff”, “I think”). Neuliep (2011) describes the indirect style as “one where the speaker’s intentions are hidden or only hinted at during interaction”. For our corpus annotation, we used this definition and annotated the directness/indirectness in a global way and not based on fixed structures or key words. Other work in this field only focuses on a specific phenomena of indirect speech, like hedge detection (Prokofieva and Hirschberg, 2014; Ulinski et al., 2018), politeness detection (Danescu-Niculescu-Mizil et al., 2013; Aubakirova and Bansal, 2016) and uncertainty detection (Liscombe et al., 2005; Forbes-Riley and Litman, 2011; Adel and Sch¨utze, 2017). 3. Corpus Description Our data set is based on recordings on health care topics containing spontaneous interactions in dialogue format between two participants: one is taking the role of the system while the other one is taking the role of the user. Each dialogue turn contains one or more dialogue acts. These dialogue acts are chosen out of a set of 43 distinct dialogue acts which have been predefined. A list of all dialogue acts can be found in Table 9 in the appendix. Along with the di"
2020.lrec-1.68,W15-4603,0,0.0294542,"linguistic features on its estimation. Our classifiers use only features that can be automatically generated during an interaction with a spoken dialogue system (i.e. without any manual annotation). Even though intelligent assistants like Amazon Alexa, Apple Siri, Google Assistant or Microsoft Cortana are becoming increasingly popular, they do not consider different communication styles to adapt their behaviour. Instead, current research in the field of spoken dialogue systems focuses on general user adaptivity like satisfaction or general user groups (Honold et al., 2014; Ultes et al., 2015; Casanueva et al., 2015; Pragst et al., 2015; Miehle et al., 2019). However, various studies suggest that adapting the communication styles of spoken dialogue systems to the individual users in a similar way to what humans do will lead to more natural interactions (Cassell and Bickmore, 2003; Forbes-Riley et al., 2008; Stenchikova and Stent, 2007; Reitter et al., 2006; Mairesse and Walker, 2010). To adapt the behaviour of the system to individual users, we consider the communication styles elaborateness and directness in this work as Pragst et al. (2019) have shown that they influence the user’s perception of a dial"
2020.lrec-1.68,P13-1025,0,0.0330135,"and that indirectness cannot be broken down to rather simple key word spotting (e.g. “sorry”, “just”, “and stuff”, “I think”). Neuliep (2011) describes the indirect style as “one where the speaker’s intentions are hidden or only hinted at during interaction”. For our corpus annotation, we used this definition and annotated the directness/indirectness in a global way and not based on fixed structures or key words. Other work in this field only focuses on a specific phenomena of indirect speech, like hedge detection (Prokofieva and Hirschberg, 2014; Ulinski et al., 2018), politeness detection (Danescu-Niculescu-Mizil et al., 2013; Aubakirova and Bansal, 2016) and uncertainty detection (Liscombe et al., 2005; Forbes-Riley and Litman, 2011; Adel and Sch¨utze, 2017). 3. Corpus Description Our data set is based on recordings on health care topics containing spontaneous interactions in dialogue format between two participants: one is taking the role of the system while the other one is taking the role of the user. Each dialogue turn contains one or more dialogue acts. These dialogue acts are chosen out of a set of 43 distinct dialogue acts which have been predefined. A list of all dialogue acts can be found in Table 9 in t"
2020.lrec-1.68,L18-1550,0,0.0149334,"laries and the combination with word embeddings led to three different linguistic feature sets: • U: This feature set contains a BoW-U vector for each utterance, thus encoding the number of times each word (of the overall vocabulary) appears in the corresponding utterance. • UB: This feature set contains a BoW-UB vector for each utterance, thus encoding the number of times each word and each two-word-sequence (of the overall vocabulary) appear in the corresponding utterance. • WE: For this feature set, the BoW-U vocabulary has been combined with the German pre-trained fastText word vectors by Grave et al. (2018)2 . Matrix X of dimension u × w contains the BoW-U vectors (dimension 1 × w with w the amount of words in vocabulary BoW-U) for each utterance, where u is the total number of utterances. Matrix W of dimension w × p contains the fastText word vectors (dimension 1 × p with p the length of each word vector) for each word. By multiplying these matrices a new matrix Z = X ·W of dimension u×p is obtained, containing a vector representation for each utterance. These utterance vectors of dimension 1 × p can then be used as feature vectors for the classification task. The Contribution of Grammatical an"
2020.lrec-1.68,W16-3610,1,0.834984,"m behaviour to the user. spoken user interface are perceived by users and whether there exist global preferences in the communication styles elaborateness and directness. The authors could show that the system’s communication style influences the user’s satisfaction and the user’s perception of the dialogue and that there is no general preference in the system’s communication style. The authors conclude that spoken dialogue systems need to adapt their communication style to each user individually during every dialogue in order to achieve a high level of user satisfaction. A study presented by Miehle et al. (2016) investigated cultural differences between the Germans and the Japanese. The results revealed that communication idiosyncrasies in human-human interaction may also be observed during human-computer interaction in a spoken dialogue system context. Moreover, Miehle et al. (2018b) presented another study examining five European cultures whose communication styles are much more alike than the German and Japanese communication idiosyncrasies. The study explores not only the influence of the user’s culture but also of the gender, the frequency of use of speech based assistants as well as the system’"
2020.lrec-1.68,L18-1625,1,0.74689,"nswer provides some additional information: “Most of the time it is cloudy and in the afternoon it will rain.” The indirect and concise version of this utterance also contains few information, yet addresses the fact that it is raining in a less concrete way: “Today is a good day for cosy activities at home.” In this case, the interlocutor can infer that the weather won’t be nice as it is better to stay at home. The elaborate and indirect version provides some more details: “Today is a good day for cosy activities at home. In the afternoon you could get wet outside.” This example is taken from Miehle et al. (2018a) addressing the issues of how varying communication styles of a 540 Speech Recognition Linguistic Analysis Communication Style Classifier Speech Synthesis Dialogue Management Application Text Generation Figure 1: The estimated communication style, which is classified based on features from the speech recognition and the linguistic analysis, can be used in the dialogue management to adapt the system behaviour to the user. spoken user interface are perceived by users and whether there exist global preferences in the communication styles elaborateness and directness. The authors could show that"
2020.lrec-1.68,P08-2043,0,0.0559436,"e classification results. Afterwards, we run a comparison with a support vector machine and a recurrent neural network classifier. Keywords: Dialogue management, User adaptation, Supervised learning. 1. Introduction For humans, speech is the most natural form of interaction and it has been shown that people adapt their interaction styles to one another across many levels of utterance production when communicating, e.g. by matching each other’s behaviour or synchronising the timing of behaviour (Burgoon et al., 2007; Niederhoffer and Pennebaker, 2002; Brennan, 1996; Pickering and Garrod, 2004; Nenkova et al., 2008). However, this adaptive behaviour has rarely been addressed and implemented in a live spoken dialogue system. With the aim of designing such a spoken dialogue system which adapts to the user’s communication idiosyncrasies, we present a classification approach to automatically estimate the user’s communication style during an ongoing dialogue. The estimated communication style can then be used in the dialogue management to adapt the system behaviour to the user, as depicted in Figure 1. To the best of our knowledge, this is the first work on automatic estimation of the user’s communication sty"
2020.lrec-1.68,E14-2005,0,0.0195777,"containing a vector representation for each utterance. These utterance vectors of dimension 1 × p can then be used as feature vectors for the classification task. The Contribution of Grammatical and Linguistic Features To address the question of whether grammatical features improve the estimation of the communication style, a second feature set is used containing the dialogue act features (as have been used for the baseline) as well as grammatical features. The grammatical features (G) are represented by Part-of-speech (POS) tags which have been assigned to the utterances by the RDRPOSTagger (Nguyen et al., 2014). As the utterance is the output of the speech recognition and this tagger can be used online during an ongoing interaction, there is also no annotation necessary for this feature set. The results are shown in Table 5. It can be seen that there is no improvement in comparison to the baseline. In addition to grammatical features, linguistic features may majorly contribute to the overall classification performance. In order to encode the linguistic features, a Bag-of-Words (BoW) approach has been used in combination with unigrams (U), unigrams and bigrams (UB) and word embeddings (WE). Using BoW"
2020.lrec-1.68,N06-2031,0,0.0744697,"consider different communication styles to adapt their behaviour. Instead, current research in the field of spoken dialogue systems focuses on general user adaptivity like satisfaction or general user groups (Honold et al., 2014; Ultes et al., 2015; Casanueva et al., 2015; Pragst et al., 2015; Miehle et al., 2019). However, various studies suggest that adapting the communication styles of spoken dialogue systems to the individual users in a similar way to what humans do will lead to more natural interactions (Cassell and Bickmore, 2003; Forbes-Riley et al., 2008; Stenchikova and Stent, 2007; Reitter et al., 2006; Mairesse and Walker, 2010). To adapt the behaviour of the system to individual users, we consider the communication styles elaborateness and directness in this work as Pragst et al. (2019) have shown that they influence the user’s perception of a dialogue and are therefore valuable candidates for adaptive dialogue management. The elaborateness thereby refers to the amount of additional information provided to the user and the directness describes how concretely the information that is to be conveyed is addressed by the speaker. This means that a direct and concise answer to the question “Can"
2020.lrec-1.68,2007.sigdial-1.29,0,0.0558973,"easingly popular, they do not consider different communication styles to adapt their behaviour. Instead, current research in the field of spoken dialogue systems focuses on general user adaptivity like satisfaction or general user groups (Honold et al., 2014; Ultes et al., 2015; Casanueva et al., 2015; Pragst et al., 2015; Miehle et al., 2019). However, various studies suggest that adapting the communication styles of spoken dialogue systems to the individual users in a similar way to what humans do will lead to more natural interactions (Cassell and Bickmore, 2003; Forbes-Riley et al., 2008; Stenchikova and Stent, 2007; Reitter et al., 2006; Mairesse and Walker, 2010). To adapt the behaviour of the system to individual users, we consider the communication styles elaborateness and directness in this work as Pragst et al. (2019) have shown that they influence the user’s perception of a dialogue and are therefore valuable candidates for adaptive dialogue management. The elaborateness thereby refers to the amount of additional information provided to the user and the directness describes how concretely the information that is to be conveyed is addressed by the speaker. This means that a direct and concise answe"
2020.lrec-1.68,W18-1301,0,0.0249547,"6 0.643 Directness (3 classes) in this corpus and that indirectness cannot be broken down to rather simple key word spotting (e.g. “sorry”, “just”, “and stuff”, “I think”). Neuliep (2011) describes the indirect style as “one where the speaker’s intentions are hidden or only hinted at during interaction”. For our corpus annotation, we used this definition and annotated the directness/indirectness in a global way and not based on fixed structures or key words. Other work in this field only focuses on a specific phenomena of indirect speech, like hedge detection (Prokofieva and Hirschberg, 2014; Ulinski et al., 2018), politeness detection (Danescu-Niculescu-Mizil et al., 2013; Aubakirova and Bansal, 2016) and uncertainty detection (Liscombe et al., 2005; Forbes-Riley and Litman, 2011; Adel and Sch¨utze, 2017). 3. Corpus Description Our data set is based on recordings on health care topics containing spontaneous interactions in dialogue format between two participants: one is taking the role of the system while the other one is taking the role of the user. Each dialogue turn contains one or more dialogue acts. These dialogue acts are chosen out of a set of 43 distinct dialogue acts which have been predefin"
2020.lrec-1.68,W15-4649,1,0.821632,"of grammatical and linguistic features on its estimation. Our classifiers use only features that can be automatically generated during an interaction with a spoken dialogue system (i.e. without any manual annotation). Even though intelligent assistants like Amazon Alexa, Apple Siri, Google Assistant or Microsoft Cortana are becoming increasingly popular, they do not consider different communication styles to adapt their behaviour. Instead, current research in the field of spoken dialogue systems focuses on general user adaptivity like satisfaction or general user groups (Honold et al., 2014; Ultes et al., 2015; Casanueva et al., 2015; Pragst et al., 2015; Miehle et al., 2019). However, various studies suggest that adapting the communication styles of spoken dialogue systems to the individual users in a similar way to what humans do will lead to more natural interactions (Cassell and Bickmore, 2003; Forbes-Riley et al., 2008; Stenchikova and Stent, 2007; Reitter et al., 2006; Mairesse and Walker, 2010). To adapt the behaviour of the system to individual users, we consider the communication styles elaborateness and directness in this work as Pragst et al. (2019) have shown that they influence the use"
2020.lrec-1.845,W17-5310,0,0.0158255,"ingle work but must be gathered from numerous individual contributions. Furthermore, the same procedure is not necessarily used across evaluations, further impeding a thorough understanding of advantages and disadvantages of any given model. There have been some efforts to address this issue, e.g. (White et al., 2015). Here, the authors evaluate sentence embeddings with a semantic classification task in a generalised manner. Additionally, the RepEval 2017 Shared Task (Nangia et al., 2017) compares the performance of seven sentence embedding approaches (Chen et al., 2017; Nie and Bansal, 2017; Balazs et al., 2017; Vu et al., 2017; Yang et al., 2017) on a shared task. Those works operate on a strict definition of sentence paraphrases: each sentence must entail the other to be considered a paraphrase. The first task of SemEval-2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen, 2014; Bic¸ici and W"
2020.lrec-1.845,S14-2141,0,0.0173973,"., 2017; Nie and Bansal, 2017; Balazs et al., 2017; Vu et al., 2017; Yang et al., 2017) on a shared task. Those works operate on a strict definition of sentence paraphrases: each sentence must entail the other to be considered a paraphrase. The first task of SemEval-2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen, 2014; Bic¸ici and Way, 2014; Bjerva et al., 2014; Ferrone and Zanzotto, 2014; Gupta et al., 2014; Jimenez et al., 2014; Lai and Hockenmaier, 2014; Le´on et al., 2014; 6841 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often, evaluations of the semantic meaning of sentence embeddings are carried out as classification task on paraphrase corpora such as the MSR paraphrase corpus (Dolan et al., 2004). Another, similar option is the natural language entailment task where, instead of labelling sentence pairs as either paraphrases or unrelated, they ar"
2020.lrec-1.845,S14-2024,0,0.0209715,"l, 2017; Balazs et al., 2017; Vu et al., 2017; Yang et al., 2017) on a shared task. Those works operate on a strict definition of sentence paraphrases: each sentence must entail the other to be considered a paraphrase. The first task of SemEval-2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen, 2014; Bic¸ici and Way, 2014; Bjerva et al., 2014; Ferrone and Zanzotto, 2014; Gupta et al., 2014; Jimenez et al., 2014; Lai and Hockenmaier, 2014; Le´on et al., 2014; 6841 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often, evaluations of the semantic meaning of sentence embeddings are carried out as classification task on paraphrase corpora such as the MSR paraphrase corpus (Dolan et al., 2004). Another, similar option is the natural language entailment task where, instead of labelling sentence pairs as either paraphrases or unrelated, they are labelled as e"
2020.lrec-1.845,S14-2085,0,0.0537419,"Missing"
2020.lrec-1.845,S14-2114,0,0.0662646,"Missing"
2020.lrec-1.845,D15-1075,0,0.0432129,"4; Lai and Hockenmaier, 2014; Le´on et al., 2014; 6841 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often, evaluations of the semantic meaning of sentence embeddings are carried out as classification task on paraphrase corpora such as the MSR paraphrase corpus (Dolan et al., 2004). Another, similar option is the natural language entailment task where, instead of labelling sentence pairs as either paraphrases or unrelated, they are labelled as either entailment, neutral or contradiction. Such corpora include the Stanford Natural Language Inference corpus (Bowman et al., 2015) and the Multi-Genre NLI corpus (Williams et al., 2018), which has been used in the RepEval 2017 Shared Task. The SICK corpus (Marelli et al., 2014) developed for SemEval-2014 Task 1 expands entailment annotations by more fine-grained, human-annotated semantic relatedness scores. In our work, we include a greater number of sentence pairs in our understanding of paraphrases: two sentences are considered contextual paraphrases if they can fulfil the same function in the context of a conversation. 3. Sentence Similarity Models Several approaches to sentence encoding exist, however, not all of the"
2020.lrec-1.845,W17-5307,0,0.0138364,"f different models cannot be found in a single work but must be gathered from numerous individual contributions. Furthermore, the same procedure is not necessarily used across evaluations, further impeding a thorough understanding of advantages and disadvantages of any given model. There have been some efforts to address this issue, e.g. (White et al., 2015). Here, the authors evaluate sentence embeddings with a semantic classification task in a generalised manner. Additionally, the RepEval 2017 Shared Task (Nangia et al., 2017) compares the performance of seven sentence embedding approaches (Chen et al., 2017; Nie and Bansal, 2017; Balazs et al., 2017; Vu et al., 2017; Yang et al., 2017) on a shared task. Those works operate on a strict definition of sentence paraphrases: each sentence must entail the other to be considered a paraphrase. The first task of SemEval-2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy"
2020.lrec-1.845,D17-1070,0,0.377036,"of great importance to the overall performance of the approach. However, the model used in that work is highly specialised to the evaluation corpus and unlikely to perform as well in different scenarios. This work examines existing approaches to measuring sentence similarity and determines how well they capture information relevant to contextual paraphrasing tasks in a more general setting. To this end, we evaluate four models: sentence similarity based on semantic nets and corpus statistics (Li et al., 2006), BERT (Devlin et al., 2018), skipthought vectors (Kiros et al., 2015) and InferSent (Conneau et al., 2017). We test their performance regarding paraphrase classification, dialogue act clustering and sentence swapping, and provide an in depth discussion of the implications of our findings. In the following, we first discuss related work in Section 2. Section 3 gives an overview of the chosen sentence embedding models, followed by a description of our evaluation approaches and discussion of our findings in Section 4. Finally, we summarise our contribution and outline future work. 2. Related Work The evaluation of sentence embeddings is often performed at the time of their introduction with regard to"
2020.lrec-1.845,L18-1218,0,0.18761,"r unrelated. The ground truth is usually given by a corpus of sentences pairs with corresponding labels. We perform the evaluation of the paraphrase classification task in two steps: first, a traditional paraphrase classification task is performed on the MSR paraphrase corpus (Dolan et al., 2004). This corpus contains 5,800 sentences pairs from news sources on the web, human-annotated as either paraphrases or unrelated. The results of this first part serve as comparison for the results obtained in the second part, the contextual paraphrase classification task. Here, we utilise the Opusparcus (Creutz, 2018) corpus. Opusparcus is a paraphrase corpus for six languages, including English. The sentence pairs are extracted from the Opensubtitles2016 corpus (Lison and Tiedemann, 2016), a corpus of movie and TV subtitles. Opusparcus consists of manually annotated development and test sets, as well as a larger automatically ranked training set. The annotations consist of four categories that rate the degree to which two sentences are paraphrases, ‘good’, ‘mostly good’, ‘mostly bad’ and ‘bad’. As opposed to a binary classification, this annotation allows for sentences that are contextual paraphrases to b"
2020.lrec-1.845,C04-1051,0,0.508643,"the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen, 2014; Bic¸ici and Way, 2014; Bjerva et al., 2014; Ferrone and Zanzotto, 2014; Gupta et al., 2014; Jimenez et al., 2014; Lai and Hockenmaier, 2014; Le´on et al., 2014; 6841 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often, evaluations of the semantic meaning of sentence embeddings are carried out as classification task on paraphrase corpora such as the MSR paraphrase corpus (Dolan et al., 2004). Another, similar option is the natural language entailment task where, instead of labelling sentence pairs as either paraphrases or unrelated, they are labelled as either entailment, neutral or contradiction. Such corpora include the Stanford Natural Language Inference corpus (Bowman et al., 2015) and the Multi-Genre NLI corpus (Williams et al., 2018), which has been used in the RepEval 2017 Shared Task. The SICK corpus (Marelli et al., 2014) developed for SemEval-2014 Task 1 expands entailment annotations by more fine-grained, human-annotated semantic relatedness scores. In our work, we inc"
2020.lrec-1.845,S14-2049,0,0.0118311,"2017) on a shared task. Those works operate on a strict definition of sentence paraphrases: each sentence must entail the other to be considered a paraphrase. The first task of SemEval-2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen, 2014; Bic¸ici and Way, 2014; Bjerva et al., 2014; Ferrone and Zanzotto, 2014; Gupta et al., 2014; Jimenez et al., 2014; Lai and Hockenmaier, 2014; Le´on et al., 2014; 6841 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often, evaluations of the semantic meaning of sentence embeddings are carried out as classification task on paraphrase corpora such as the MSR paraphrase corpus (Dolan et al., 2004). Another, similar option is the natural language entailment task where, instead of labelling sentence pairs as either paraphrases or unrelated, they are labelled as either entailment, neutral or contradiction. Such corpora include the Sta"
2020.lrec-1.845,S14-2139,0,0.0410817,"Missing"
2020.lrec-1.845,D13-1090,0,0.0302725,"Presumably, BERT lacks fine-tuning, while STV puts too little focus on the word level to perform well on this task. We decided to use the UAR for our evaluation as it is robust with regard to unbalanced class sizes. However, many previous works have used Accuracy and F-score as performance metrics. To put our results in context, we provide those values for our chosen approaches in Table 1, as well as the worst and best approaches for Paraphrase Identification according to https://aclweb.org/aclwiki/State of the art (as of 28.02.2020): Vector Based Similarity (Mihalcea et al., 2006) and TF-KLD(Ji and Eisenstein, 2013). Our chosen approaches show moderate success for this task compared to others available. The evaluation of the contextual paraphrase task results in a different ranking. As Figure 3 shows, the best result is again achieved by InfS. With an average UAR of 0.42, it performs significantly better than the next best model, STV, achieving an UAR of 0.36 (t(108.24) = 6.36, p &lt; .001). While InfS can maintain its status, SNCS does not seem to be as well suited for this task, performing significantly worse than STV with an UAR of 0.29 (t(105.40) = 7.36, p &lt; .001). A majority class predictor would achie"
2020.lrec-1.845,S14-2131,0,0.0354951,"Missing"
2020.lrec-1.845,P14-1062,0,0.0184407,"ed semantic relatedness scores. In our work, we include a greater number of sentence pairs in our understanding of paraphrases: two sentences are considered contextual paraphrases if they can fulfil the same function in the context of a conversation. 3. Sentence Similarity Models Several approaches to sentence encoding exist, however, not all of them are equally promising to perform well on contextual paraphrasing tasks. Many focus mainly on word-level features such as lexical similarity or word order (e.g. (Sutskever et al., 2014; Palangi et al., 2016; Tsunoo et al., 2017; Shen et al., 2014; Kalchbrenner et al., 2014; Hu et al., 2014; Socher et al., 2011)). The identification of contextual paraphrases is likely to be dependent mainly on the ability of a model to capture functional similarity. Therefore, we choose the following four approaches for our comparative study: a similarity measure based on semantic nets and corpus statistics (Li et al., 2006), BERT (Devlin et al., 2018), skip-thought vectors (Kiros et al., 2015) and InferSent (Conneau et al., 2017). Those models do not rely solely on word similarities for their encoding, but take context into account. In the following, a short overview of the cho"
2020.lrec-1.845,W03-1601,0,0.17371,"Those variants can be considered word-level paraphrases. However, the sentence ‘I just got on the bus.’ can fulfil the same function of providing the expected time of arrival, while differing greatly with regard to syntactic structure and the words used. We refer to such sentences that can fulfil the same function in the context of a conversation despite being dissimilar in their surface realisation as contextual paraphrases. In the area of dialogue systems, a number of contributions are concerned with the generation of variety in the utterances of the dialogue system (e.g (Wen et al., 2015; Kozlowski et al., 2003; Langkilde and Knight, 1998)). However, those efforts are mainly focused on word-level paraphrases and little work has been dedicated to the generation of contextual paraphrases. Pragst and Ultes (2018) have made a first effort in this direction by proposing an approach for exchanging sentences, using a dialogue vector model to assess whether two sentences can be used interchangeably. They find that the ability to identify contextual paraphrases is of great importance to the overall performance of the approach. However, the model used in that work is highly specialised to the evaluation corpu"
2020.lrec-1.845,S14-2055,0,0.0127612,"sentence paraphrases: each sentence must entail the other to be considered a paraphrase. The first task of SemEval-2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen, 2014; Bic¸ici and Way, 2014; Bjerva et al., 2014; Ferrone and Zanzotto, 2014; Gupta et al., 2014; Jimenez et al., 2014; Lai and Hockenmaier, 2014; Le´on et al., 2014; 6841 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often, evaluations of the semantic meaning of sentence embeddings are carried out as classification task on paraphrase corpora such as the MSR paraphrase corpus (Dolan et al., 2004). Another, similar option is the natural language entailment task where, instead of labelling sentence pairs as either paraphrases or unrelated, they are labelled as either entailment, neutral or contradiction. Such corpora include the Stanford Natural Language Inference corpus (Bowman et al., 2015) and the"
2020.lrec-1.845,P98-1116,0,0.451854,"onsidered word-level paraphrases. However, the sentence ‘I just got on the bus.’ can fulfil the same function of providing the expected time of arrival, while differing greatly with regard to syntactic structure and the words used. We refer to such sentences that can fulfil the same function in the context of a conversation despite being dissimilar in their surface realisation as contextual paraphrases. In the area of dialogue systems, a number of contributions are concerned with the generation of variety in the utterances of the dialogue system (e.g (Wen et al., 2015; Kozlowski et al., 2003; Langkilde and Knight, 1998)). However, those efforts are mainly focused on word-level paraphrases and little work has been dedicated to the generation of contextual paraphrases. Pragst and Ultes (2018) have made a first effort in this direction by proposing an approach for exchanging sentences, using a dialogue vector model to assess whether two sentences can be used interchangeably. They find that the ability to identify contextual paraphrases is of great importance to the overall performance of the approach. However, the model used in that work is highly specialised to the evaluation corpus and unlikely to perform as"
2020.lrec-1.845,S14-2021,0,0.0606465,"Missing"
2020.lrec-1.845,S14-2125,0,0.064281,"other to be considered a paraphrase. The first task of SemEval-2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen, 2014; Bic¸ici and Way, 2014; Bjerva et al., 2014; Ferrone and Zanzotto, 2014; Gupta et al., 2014; Jimenez et al., 2014; Lai and Hockenmaier, 2014; Le´on et al., 2014; 6841 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often, evaluations of the semantic meaning of sentence embeddings are carried out as classification task on paraphrase corpora such as the MSR paraphrase corpus (Dolan et al., 2004). Another, similar option is the natural language entailment task where, instead of labelling sentence pairs as either paraphrases or unrelated, they are labelled as either entailment, neutral or contradiction. Such corpora include the Stanford Natural Language Inference corpus (Bowman et al., 2015) and the Multi-Genre NLI corpus (Williams et al., 2018), wh"
2020.lrec-1.845,L16-1147,0,0.0609891,"n task in two steps: first, a traditional paraphrase classification task is performed on the MSR paraphrase corpus (Dolan et al., 2004). This corpus contains 5,800 sentences pairs from news sources on the web, human-annotated as either paraphrases or unrelated. The results of this first part serve as comparison for the results obtained in the second part, the contextual paraphrase classification task. Here, we utilise the Opusparcus (Creutz, 2018) corpus. Opusparcus is a paraphrase corpus for six languages, including English. The sentence pairs are extracted from the Opensubtitles2016 corpus (Lison and Tiedemann, 2016), a corpus of movie and TV subtitles. Opusparcus consists of manually annotated development and test sets, as well as a larger automatically ranked training set. The annotations consist of four categories that rate the degree to which two sentences are paraphrases, ‘good’, ‘mostly good’, ‘mostly bad’ and ‘bad’. As opposed to a binary classification, this annotation allows for sentences that are contextual paraphrases to be rated accordingly. Most contextual paraphrases can be found in the category ‘mostly good’, for example the pairs ‘No different.’/‘That ’s the same thing.’ or ‘I think I got"
2020.lrec-1.845,S14-2001,0,0.103578,"There have been some efforts to address this issue, e.g. (White et al., 2015). Here, the authors evaluate sentence embeddings with a semantic classification task in a generalised manner. Additionally, the RepEval 2017 Shared Task (Nangia et al., 2017) compares the performance of seven sentence embedding approaches (Chen et al., 2017; Nie and Bansal, 2017; Balazs et al., 2017; Vu et al., 2017; Yang et al., 2017) on a shared task. Those works operate on a strict definition of sentence paraphrases: each sentence must entail the other to be considered a paraphrase. The first task of SemEval-2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen, 2014; Bic¸ici and Way, 2014; Bjerva et al., 2014; Ferrone and Zanzotto, 2014; Gupta et al., 2014; Jimenez et al., 2014; Lai and Hockenmaier, 2014; Le´on et al., 2014; 6841 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often,"
2020.lrec-1.845,W17-5308,0,0.0173111,"cannot be found in a single work but must be gathered from numerous individual contributions. Furthermore, the same procedure is not necessarily used across evaluations, further impeding a thorough understanding of advantages and disadvantages of any given model. There have been some efforts to address this issue, e.g. (White et al., 2015). Here, the authors evaluate sentence embeddings with a semantic classification task in a generalised manner. Additionally, the RepEval 2017 Shared Task (Nangia et al., 2017) compares the performance of seven sentence embedding approaches (Chen et al., 2017; Nie and Bansal, 2017; Balazs et al., 2017; Vu et al., 2017; Yang et al., 2017) on a shared task. Those works operate on a strict definition of sentence paraphrases: each sentence must entail the other to be considered a paraphrase. The first task of SemEval-2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen"
2020.lrec-1.845,W18-5002,1,0.942245,"ith regard to syntactic structure and the words used. We refer to such sentences that can fulfil the same function in the context of a conversation despite being dissimilar in their surface realisation as contextual paraphrases. In the area of dialogue systems, a number of contributions are concerned with the generation of variety in the utterances of the dialogue system (e.g (Wen et al., 2015; Kozlowski et al., 2003; Langkilde and Knight, 1998)). However, those efforts are mainly focused on word-level paraphrases and little work has been dedicated to the generation of contextual paraphrases. Pragst and Ultes (2018) have made a first effort in this direction by proposing an approach for exchanging sentences, using a dialogue vector model to assess whether two sentences can be used interchangeably. They find that the ability to identify contextual paraphrases is of great importance to the overall performance of the approach. However, the model used in that work is highly specialised to the evaluation corpus and unlikely to perform as well in different scenarios. This work examines existing approaches to measuring sentence similarity and determines how well they capture information relevant to contextual p"
2020.lrec-1.845,S14-2093,0,0.0332972,"Missing"
2020.lrec-1.845,D11-1014,0,0.0210413,"we include a greater number of sentence pairs in our understanding of paraphrases: two sentences are considered contextual paraphrases if they can fulfil the same function in the context of a conversation. 3. Sentence Similarity Models Several approaches to sentence encoding exist, however, not all of them are equally promising to perform well on contextual paraphrasing tasks. Many focus mainly on word-level features such as lexical similarity or word order (e.g. (Sutskever et al., 2014; Palangi et al., 2016; Tsunoo et al., 2017; Shen et al., 2014; Kalchbrenner et al., 2014; Hu et al., 2014; Socher et al., 2011)). The identification of contextual paraphrases is likely to be dependent mainly on the ability of a model to capture functional similarity. Therefore, we choose the following four approaches for our comparative study: a similarity measure based on semantic nets and corpus statistics (Li et al., 2006), BERT (Devlin et al., 2018), skip-thought vectors (Kiros et al., 2015) and InferSent (Conneau et al., 2017). Those models do not rely solely on word similarities for their encoding, but take context into account. In the following, a short overview of the chosen approaches as well as a discussion"
2020.lrec-1.845,J00-3003,0,0.0886784,"Missing"
2020.lrec-1.845,S14-2047,0,0.012785,"task of SemEval-2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen, 2014; Bic¸ici and Way, 2014; Bjerva et al., 2014; Ferrone and Zanzotto, 2014; Gupta et al., 2014; Jimenez et al., 2014; Lai and Hockenmaier, 2014; Le´on et al., 2014; 6841 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often, evaluations of the semantic meaning of sentence embeddings are carried out as classification task on paraphrase corpora such as the MSR paraphrase corpus (Dolan et al., 2004). Another, similar option is the natural language entailment task where, instead of labelling sentence pairs as either paraphrases or unrelated, they are labelled as either entailment, neutral or contradiction. Such corpora include the Stanford Natural Language Inference corpus (Bowman et al., 2015) and the Multi-Genre NLI corpus (Williams et al., 2018), which has been used in the RepEval 2017"
2020.lrec-1.845,D15-1199,0,0.040663,"Missing"
2020.lrec-1.845,N18-1101,0,0.0164121,"1 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often, evaluations of the semantic meaning of sentence embeddings are carried out as classification task on paraphrase corpora such as the MSR paraphrase corpus (Dolan et al., 2004). Another, similar option is the natural language entailment task where, instead of labelling sentence pairs as either paraphrases or unrelated, they are labelled as either entailment, neutral or contradiction. Such corpora include the Stanford Natural Language Inference corpus (Bowman et al., 2015) and the Multi-Genre NLI corpus (Williams et al., 2018), which has been used in the RepEval 2017 Shared Task. The SICK corpus (Marelli et al., 2014) developed for SemEval-2014 Task 1 expands entailment annotations by more fine-grained, human-annotated semantic relatedness scores. In our work, we include a greater number of sentence pairs in our understanding of paraphrases: two sentences are considered contextual paraphrases if they can fulfil the same function in the context of a conversation. 3. Sentence Similarity Models Several approaches to sentence encoding exist, however, not all of them are equally promising to perform well on contextual p"
2020.lrec-1.845,W17-5309,0,0.0488764,"Missing"
2020.lrec-1.845,S14-2044,0,0.0178977,"2014 (Marelli et al., 2014) expands on this definition by adding a semantic relatedness score to sentence pairs. The task was solved by 21 participating teams, with 17 submission for the semantic relatedness subtask and 18 for the entailment subtask. However, only 14 of those entries were accompanied by papers (Alves et al., 2014; Beltagy et al., 2014; Bestgen, 2014; Bic¸ici and Way, 2014; Bjerva et al., 2014; Ferrone and Zanzotto, 2014; Gupta et al., 2014; Jimenez et al., 2014; Lai and Hockenmaier, 2014; Le´on et al., 2014; 6841 Lien and Kouylekov, 2014; Proisl et al., 2014; Vo et al., 2014; Zhao et al., 2014). Often, evaluations of the semantic meaning of sentence embeddings are carried out as classification task on paraphrase corpora such as the MSR paraphrase corpus (Dolan et al., 2004). Another, similar option is the natural language entailment task where, instead of labelling sentence pairs as either paraphrases or unrelated, they are labelled as either entailment, neutral or contradiction. Such corpora include the Stanford Natural Language Inference corpus (Bowman et al., 2015) and the Multi-Genre NLI corpus (Williams et al., 2018), which has been used in the RepEval 2017 Shared Task. The SIC"
2020.sigdial-1.38,D18-2029,0,0.021668,"ue actions treating slots s and values v in S˜ as individual γ: X ˜ (a, a0 ) = δact,act 0 + CM m(a, ˜ a0 , γ) (8) 15,000 1.00 0.99 3.79 3.81 4.36 4.43 20,000 1.00 0.97 3.86 3.73 4.15 4.62 25,000 1.00 0.98 3.77 3.85 4.37 4.30 30,000 1.00 0.96 3.71 3.87 4.49 4.41 ∈S˜ a0 35,000 0.99 0.96 3.73 3.84 4.42 4.46 40,000 1.00 0.94 3.77 3.77 4.35 4.75 A concept match of two dialogue actions a and is thus defined by ˜ (a, a0 ) CM CM (a, a0 ) = (9) ˜ 1 + |S| and the concept match rate by |C| 1 X CMR = CM (a, a0 ) . |C| (10) i=1 Cosine Similarity and angular similarity The Universal Sentence Encoder (USE) (Cer et al., 2018) is a generic sentence encoder which employs two measures for the computation of the distances between encoded sentences, namely cosine similarity and angular similarity: BERTscore The BERTscore (Zhang* et al., 2020) is an automatic evaluation metric used for text generation that has shown a high correlation with human ratings. Given a function β which returns the BERT embedding (Devlin et al., 2018) for a given token, recall and precision along with the F1-score are computed for a reference p and a candidate p0 as 1 X RBERT = max β(pi )&gt; β(p0j ) , (14) |p |p ∈p p0j ∈p0 i 1 X max β(pi )&gt; β(p0j"
2020.sigdial-1.38,A00-2027,0,0.458263,"Missing"
2020.sigdial-1.38,W11-2019,0,0.0353477,"ponse directly based on text input thus combining user input interpretation, dialogue context integration, and dialogue response selection in one model. Absolute measures to evaluate the performance of these behaviour models through the interaction with real or simulated users are, for example, task success or dialogue length (Gaˇsi´c and Young, 2014; Lemon and Pietquin, 2007; Daubigney et al., 2012; Levin and Pieraccini, 1997; Young et al., 2013; Su et al., 2016; Ultes et al., 2015; Wen et al., 2017). Other measures are user satisfaction (Walker et al., 1997; Chu-Carroll and Nickerson, 2000; Dzikovska et al., 2011; Ultes et al., 2015; Wen et al., 2016; Ultes et al., 2017a) or quality of interaction (M¨oller et al., 2008; Schmitt and Ultes, 2015). All are often acquired through interaction-based studies1 . Others have employed corpus-based evaluation by comparing textual system responses with transcriptions of actual interaction as absolute evaluation criterion where the response in the corpus is treated as ground truth (Serban et al., 2016; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2015). Text comparison metrics like BLEU (Papineni et al., 2002) have been adopted from machine translation to"
2020.sigdial-1.38,W14-4337,0,0.0261985,"Statistical Spoken Dialogue System Toolkit (Ultes et al., 2017b) with an agendabased user simulator (Schatzmann and Young, 2009). For each trial, a GP-SARSA (Gaˇsi´c and Young, 2014) policy model was trained—a learning algorithm known for its high sample-efficiency— with dialogues in the Cambridge restaurants domain about finding restaurants in Cambridge, UK. The domain comprises three slots used as search constraints (area, price range, food type). For belief state tracking—updating the probability distribution over all possible dialogue states in each turn—the focus belief tracker is used (Henderson et al., 2014). Prompts were generated using the SC-LSTM (Wen et al., 2015) natural language generator implementation of PyDial. To ensure consistency, the standardised Environment 1 from Casanueva et al. (2017) is used. The interaction quality is estimated using a BiLSTM with self-attention as described by Ultes (2019). For each trial of the task success and the interaction quality set-ups, a policy was trained with 40,000 dialogues and evaluated after each 1,000 training dialogues with 100 evaluation dialogues. The absolute performance of each set-up in terms of task success rate (TSR), average interactio"
2020.sigdial-1.38,P16-1094,0,0.0210517,"., 2015; Wen et al., 2017). Other measures are user satisfaction (Walker et al., 1997; Chu-Carroll and Nickerson, 2000; Dzikovska et al., 2011; Ultes et al., 2015; Wen et al., 2016; Ultes et al., 2017a) or quality of interaction (M¨oller et al., 2008; Schmitt and Ultes, 2015). All are often acquired through interaction-based studies1 . Others have employed corpus-based evaluation by comparing textual system responses with transcriptions of actual interaction as absolute evaluation criterion where the response in the corpus is treated as ground truth (Serban et al., 2016; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2015). Text comparison metrics like BLEU (Papineni et al., 2002) have been adopted from machine translation to evaluate how well the system response matches the one in the database, e.g., (Li et al., 2016b; Sordoni et al., 2015). This way of evaluating has been criticised widely as a system response that is different from the one in the data base can still be a valid system response simply leading to a different subsequent dialogue. Furthermore, the BLEU score evaluation hardly correlates with human judgements (Liu et al., 2016; Novikova et al., 2017). Dismissing text similarit"
2020.sigdial-1.38,D16-1127,0,0.0297631,"., 2015; Wen et al., 2017). Other measures are user satisfaction (Walker et al., 1997; Chu-Carroll and Nickerson, 2000; Dzikovska et al., 2011; Ultes et al., 2015; Wen et al., 2016; Ultes et al., 2017a) or quality of interaction (M¨oller et al., 2008; Schmitt and Ultes, 2015). All are often acquired through interaction-based studies1 . Others have employed corpus-based evaluation by comparing textual system responses with transcriptions of actual interaction as absolute evaluation criterion where the response in the corpus is treated as ground truth (Serban et al., 2016; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2015). Text comparison metrics like BLEU (Papineni et al., 2002) have been adopted from machine translation to evaluate how well the system response matches the one in the database, e.g., (Li et al., 2016b; Sordoni et al., 2015). This way of evaluating has been criticised widely as a system response that is different from the one in the data base can still be a valid system response simply leading to a different subsequent dialogue. Furthermore, the BLEU score evaluation hardly correlates with human judgements (Liu et al., 2016; Novikova et al., 2017). Dismissing text similarit"
2020.sigdial-1.38,D16-1230,0,0.0511482,"Missing"
2020.sigdial-1.38,W15-4640,0,0.0193168,"., 2017). Other measures are user satisfaction (Walker et al., 1997; Chu-Carroll and Nickerson, 2000; Dzikovska et al., 2011; Ultes et al., 2015; Wen et al., 2016; Ultes et al., 2017a) or quality of interaction (M¨oller et al., 2008; Schmitt and Ultes, 2015). All are often acquired through interaction-based studies1 . Others have employed corpus-based evaluation by comparing textual system responses with transcriptions of actual interaction as absolute evaluation criterion where the response in the corpus is treated as ground truth (Serban et al., 2016; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2015). Text comparison metrics like BLEU (Papineni et al., 2002) have been adopted from machine translation to evaluate how well the system response matches the one in the database, e.g., (Li et al., 2016b; Sordoni et al., 2015). This way of evaluating has been criticised widely as a system response that is different from the one in the data base can still be a valid system response simply leading to a different subsequent dialogue. Furthermore, the BLEU score evaluation hardly correlates with human judgements (Liu et al., 2016; Novikova et al., 2017). Dismissing text similarity measures as not use"
2020.sigdial-1.38,D17-1238,0,0.0443608,"Missing"
2020.sigdial-1.38,P02-1040,0,0.108904,"et al., 1997; Chu-Carroll and Nickerson, 2000; Dzikovska et al., 2011; Ultes et al., 2015; Wen et al., 2016; Ultes et al., 2017a) or quality of interaction (M¨oller et al., 2008; Schmitt and Ultes, 2015). All are often acquired through interaction-based studies1 . Others have employed corpus-based evaluation by comparing textual system responses with transcriptions of actual interaction as absolute evaluation criterion where the response in the corpus is treated as ground truth (Serban et al., 2016; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2015). Text comparison metrics like BLEU (Papineni et al., 2002) have been adopted from machine translation to evaluate how well the system response matches the one in the database, e.g., (Li et al., 2016b; Sordoni et al., 2015). This way of evaluating has been criticised widely as a system response that is different from the one in the data base can still be a valid system response simply leading to a different subsequent dialogue. Furthermore, the BLEU score evaluation hardly correlates with human judgements (Liu et al., 2016; Novikova et al., 2017). Dismissing text similarity measures as not useful for dialogue evaluation, however, is overhasty and shor"
2020.sigdial-1.38,P16-1056,0,0.0390256,"Missing"
2020.sigdial-1.38,N15-1020,0,0.0534788,"Missing"
2020.sigdial-1.38,P16-1230,1,0.935656,"Missing"
2020.sigdial-1.38,W19-5902,1,0.810791,"of 19 down to −T which is consistent with related work in which binary task success (TS) was used to define the reward as: RT S = −T + 1T S · 20 , 0.8 0.2 4.1.1 Policy Training For the evaluation, two policies are trained to reflect two different set-ups. One set-up uses the conventional task success as main reward component as heavily used within the literature (Gaˇsi´c and Young, 2014; Vandyke et al., 2015; Su et al., 2016, e.g.) and the other set-up uses the interaction quality (IQ) (Schmitt and Ultes, 2015) representing user satisfaction as described by Ultes et al. (Ultes et al., 2017a; Ultes, 2019). IQ is defined on a five-point scale from five (satisfied) down to one (extremely unsatisfied). To derive a reward from this value, RIQ = −T + (iq − 1) · 5 0.9 Total Match Rate # Training Dialogues 0.978 0.989 0.984 1.000 Trial 0 10,000 20,000 30,000 40,000 2 Table 2: Similarity measures for testing convergence of each trial (random seed) for RT S empmloying task success and RIQ employing interaction quality for Creal . ment using the PyDial Statistical Spoken Dialogue System Toolkit (Ultes et al., 2017b) with an agendabased user simulator (Schatzmann and Young, 2009). For each trial, a GP-SA"
2020.sigdial-1.38,W15-4649,1,0.716768,"s then transferred into text by a natural language generator. An implicit behaviour model uses a neural network to learn a text response directly based on text input thus combining user input interpretation, dialogue context integration, and dialogue response selection in one model. Absolute measures to evaluate the performance of these behaviour models through the interaction with real or simulated users are, for example, task success or dialogue length (Gaˇsi´c and Young, 2014; Lemon and Pietquin, 2007; Daubigney et al., 2012; Levin and Pieraccini, 1997; Young et al., 2013; Su et al., 2016; Ultes et al., 2015; Wen et al., 2017). Other measures are user satisfaction (Walker et al., 1997; Chu-Carroll and Nickerson, 2000; Dzikovska et al., 2011; Ultes et al., 2015; Wen et al., 2016; Ultes et al., 2017a) or quality of interaction (M¨oller et al., 2008; Schmitt and Ultes, 2015). All are often acquired through interaction-based studies1 . Others have employed corpus-based evaluation by comparing textual system responses with transcriptions of actual interaction as absolute evaluation criterion where the response in the corpus is treated as ground truth (Serban et al., 2016; Sordoni et al., 2015; Li et a"
2020.sigdial-1.38,P17-4013,1,0.921605,"Missing"
2020.sigdial-1.38,P97-1035,0,0.656738,"aviour model uses a neural network to learn a text response directly based on text input thus combining user input interpretation, dialogue context integration, and dialogue response selection in one model. Absolute measures to evaluate the performance of these behaviour models through the interaction with real or simulated users are, for example, task success or dialogue length (Gaˇsi´c and Young, 2014; Lemon and Pietquin, 2007; Daubigney et al., 2012; Levin and Pieraccini, 1997; Young et al., 2013; Su et al., 2016; Ultes et al., 2015; Wen et al., 2017). Other measures are user satisfaction (Walker et al., 1997; Chu-Carroll and Nickerson, 2000; Dzikovska et al., 2011; Ultes et al., 2015; Wen et al., 2016; Ultes et al., 2017a) or quality of interaction (M¨oller et al., 2008; Schmitt and Ultes, 2015). All are often acquired through interaction-based studies1 . Others have employed corpus-based evaluation by comparing textual system responses with transcriptions of actual interaction as absolute evaluation criterion where the response in the corpus is treated as ground truth (Serban et al., 2016; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2015). Text comparison metrics like BLEU (Papineni et"
2020.sigdial-1.38,N16-1015,0,0.0392986,"Missing"
2020.sigdial-1.38,D15-1199,0,0.0417222,"Missing"
2020.sigdial-1.38,E17-1042,1,0.895432,"Missing"
2021.sigdial-1.39,2020.acl-main.371,0,0.0153061,"Results for the annotated structure and the automatically generated ones on the topic Marriage. Upper table: Ratio of positive and overall ratings. Lower table: p-values of pairwise comparison with Fisher’s exact test and Benjamini-Hochberg correction. As for the written feedback, multiple annotators reported confusing formulations of the argument as the major difficulty of the task. Since this is a direct consequence of the heterogeneous sources the arguments are retrieved from, it is hard to address in the pipeline. Therefore, approaches to automatically summarize or reformulate arguments (Bar-Haim et al., 2020; Schiller et al., 2021) could be beneficial to improve the performance. tree is directly influenced by the relation classification (and hence by the clustering as well), it varies between the structures with and without clustering. Therefore, the individual arguments can appear in a different context, which arguably also leads to a different perception through the study participants. On average, no significant difference between the two approaches could be found and the choice of the optimal configuration hence depends on the available data for each topic. The direct comparison with an annota"
2021.sigdial-1.39,W15-0504,0,0.0410028,"Missing"
2021.sigdial-1.39,P19-3022,0,0.0113662,"ning (Lawrence and Reed, 2020). Argument search engines provide users with a (ranked) list of arguments related to a given search query, in some instances also including their stance/polarity towards the topic. 369 3.1 General Approach Over the last years, different approaches to argument search were investigated that follow different paradigms (Ajjour et al., 2019). Systems introduced so far include the one developed in the scope of IBM project debater (Levy et al., 2018), ArgumenText (Stab et al., 2018), args.me (Wachsmuth et al., 2017b), TARGER (Chernodub et al., 2019) and PerspectroScope (Chen et al., 2019). The general applicability of argument search engines in the context of dialogue systems was assessed in (Rach et al., 2020a) where ArgumenText and args.me were compared to a baseline system. Although a mapping into argument structures was not addressed, we use the discussed results to select a suitable search engine for the present work. Our model of choice is ArgumenText since it retrieves arguments on a sentence level (which is preferable in a dialogue context), performs reliable in comparison with the investigated baseline and additionally provides an API that allows for clustering the re"
2021.sigdial-1.39,P19-3031,0,0.0150314,"an application from the field of argument mining (Lawrence and Reed, 2020). Argument search engines provide users with a (ranked) list of arguments related to a given search query, in some instances also including their stance/polarity towards the topic. 369 3.1 General Approach Over the last years, different approaches to argument search were investigated that follow different paradigms (Ajjour et al., 2019). Systems introduced so far include the one developed in the scope of IBM project debater (Levy et al., 2018), ArgumenText (Stab et al., 2018), args.me (Wachsmuth et al., 2017b), TARGER (Chernodub et al., 2019) and PerspectroScope (Chen et al., 2019). The general applicability of argument search engines in the context of dialogue systems was assessed in (Rach et al., 2020a) where ArgumenText and args.me were compared to a baseline system. Although a mapping into argument structures was not addressed, we use the discussed results to select a suitable search engine for the present work. Our model of choice is ArgumenText since it retrieves arguments on a sentence level (which is preferable in a dialogue context), performs reliable in comparison with the investigated baseline and additionally provides"
2021.sigdial-1.39,D18-1241,0,0.0124862,"uctures that encode arguments and their relations to ensure a consistent and challenging interaction (Rach et al., 2018b; Sakai et al., 2020). Despite the advantages on the formal side, this dependency limits the range of topics that can be discussed by a system as the required structures are often either annotated by hand (Rach et al., 2019; Sakai et al., 2018b) or acquired in time-consuming data collections (Chalaguine and Hunter, 2019). This limitation renders the corresponding systems inflexible, especially in comparison to recent data-driven approaches in domains like question answering (Choi et al., 2018). To address this issue, we propose a combination of argument search technology (Ajjour et al., 2019) with dialogue systems of the discussed kind. Our approach maps the list of pro and con arguments retrieved with an argument search engine for a given topic into a general tree structure that encodes bipolar relations (support and attack) between the individual arguments (see Figure 1). In doing so, our approach combines the strong points of both data-driven and formal models for argumentation and enables a corresponding system to discuss literally any topic on which the search engine can find"
2021.sigdial-1.39,N19-1423,0,0.0112947,"Missing"
2021.sigdial-1.39,W19-4004,0,0.0211506,"ing is good and compared different combinations of the approaches to create the tree structure. Clustering prior to the relation classification was not considered in this step, as it is investigated thoroughly in the final evaluation. Five annotators without task-related background were asked to label each argument pair with a relation in the resulting tree structure in each of the annotation categories contradiction, entailment, specificity, paraphrase and local relevance with yes or no. The first four categories are based on an investigation of the interactions between semantic relations by Gold et al. (2019), the last category was proposed in (Wachsmuth et al., 2017a). As in this latter work, we use the labels of the three most agreeing annotators for each category in order to eliminate outliers. The Fleiss’ Kappa (Fleiss, 1971) values yields a substantial (0.66) up to perfect (0.82) agreement (Landis and Koch, 1977). A pair of arguments is concluded to actually hold a relation if it is rated with yes in at least one category by majority vote. For our baseline (SVM), this is the case with BILP 371 Speech Act Attacks Surrenders claim(φi ) why(φi ) concede(φi ) retract(φi ) argue(φj → φi ) argue ex"
2021.sigdial-1.39,W18-5215,0,0.0181282,"in their system. Although the underlying formal frameworks of all these systems allow for complex dialogues, the topics that can be addressed are limited by the time-consuming generation of the argument structures. We propose an approach to generate structures of this kind automatically and independently of a specific topic. In addition, data-based approaches were also investigated. The chatbot introduced by Rakshit et al. (2019) utilizes semantic similarity measures to retrieve arguments from an argument corpus to generate a response. A similar approach was compared to a generative model by Le et al. (2018) that was trained on a corpus of debate posts on various topics. Although especially the generative approach is focused on providing topic flexibility, aspects like user adaptation or strategy optimization as addressed in some of the previously discussed works are not (yet) considered in these systems. Our approach bridges the gap between formal and data-driven argumentation through a combination of argument search with formal models. Related Work 3 This section provides an overview of related work with a focus on argument retrieval for argumentative dialogue systems. The arguably most promine"
2021.sigdial-1.39,C18-1176,0,0.0239379,"investigated in different scenarios. The Argument Search Argument search has recently evolved as an application from the field of argument mining (Lawrence and Reed, 2020). Argument search engines provide users with a (ranked) list of arguments related to a given search query, in some instances also including their stance/polarity towards the topic. 369 3.1 General Approach Over the last years, different approaches to argument search were investigated that follow different paradigms (Ajjour et al., 2019). Systems introduced so far include the one developed in the scope of IBM project debater (Levy et al., 2018), ArgumenText (Stab et al., 2018), args.me (Wachsmuth et al., 2017b), TARGER (Chernodub et al., 2019) and PerspectroScope (Chen et al., 2019). The general applicability of argument search engines in the context of dialogue systems was assessed in (Rach et al., 2020a) where ArgumenText and args.me were compared to a baseline system. Although a mapping into argument structures was not addressed, we use the discussed results to select a suitable search engine for the present work. Our model of choice is ArgumenText since it retrieves arguments on a sentence level (which is preferable in a dialogu"
2021.sigdial-1.39,2020.lrec-1.65,1,0.880032,"arch query, in some instances also including their stance/polarity towards the topic. 369 3.1 General Approach Over the last years, different approaches to argument search were investigated that follow different paradigms (Ajjour et al., 2019). Systems introduced so far include the one developed in the scope of IBM project debater (Levy et al., 2018), ArgumenText (Stab et al., 2018), args.me (Wachsmuth et al., 2017b), TARGER (Chernodub et al., 2019) and PerspectroScope (Chen et al., 2019). The general applicability of argument search engines in the context of dialogue systems was assessed in (Rach et al., 2020a) where ArgumenText and args.me were compared to a baseline system. Although a mapping into argument structures was not addressed, we use the discussed results to select a suitable search engine for the present work. Our model of choice is ArgumenText since it retrieves arguments on a sentence level (which is preferable in a dialogue context), performs reliable in comparison with the investigated baseline and additionally provides an API that allows for clustering the retrieved arguments thematically. In the following, a sentence retrieved by the search engine is denoted as argument φ and its"
2021.sigdial-1.39,D19-1410,0,0.0120256,"ment (Stab et al., 2018). Besides the arguments and their stance, the search engine also provides multiple confidence values of which we use the one for stance (cs ) and argument detection (ca ) to derive the final confidence as c = ca × cs and rank the retrieved arguments accordingly. In addition, we utilize ArgumenText’s Cluster API to group the retrieved arguments thematically. It determines similarity scores for argument pairs which are then applied to form clusters based on aspects addressed within the arguments. The Cluster API relies on an optimized version of the Sentence-BERT method (Reimers and Gurevych, 2019) that makes use of an efficient bi-encoder that has been trained with additional samples (“Augmented SBERT”) from a cross-encoder (Thakur et al., 2021). The utilized supervised approach to learn argument similarity was shown to outperform 1 2 https://api.argumentsearch.com http://commoncrawl.org unsupervised approaches based on BERT embeddings by 10pp (Reimers et al., 2019). 4 From Arguments to Structures In the following, the mapping of the retrieved arguments into an argument structure is discussed. Although some structures utilized by the systems discussed in Section 2 differ to a certain e"
2021.sigdial-1.39,P19-1054,1,0.815101,". It determines similarity scores for argument pairs which are then applied to form clusters based on aspects addressed within the arguments. The Cluster API relies on an optimized version of the Sentence-BERT method (Reimers and Gurevych, 2019) that makes use of an efficient bi-encoder that has been trained with additional samples (“Augmented SBERT”) from a cross-encoder (Thakur et al., 2021). The utilized supervised approach to learn argument similarity was shown to outperform 1 2 https://api.argumentsearch.com http://commoncrawl.org unsupervised approaches based on BERT embeddings by 10pp (Reimers et al., 2019). 4 From Arguments to Structures In the following, the mapping of the retrieved arguments into an argument structure is discussed. Although some structures utilized by the systems discussed in Section 2 differ to a certain extent, they all require information about the relations between the individual arguments. We hence pursue a modular pipeline approach that first determines possible relations between the arguments and subsequently maps them into a specific structure. In case the required structure cannot be inferred from the herein discussed one, the second module can be adapted accordingly"
2021.sigdial-1.39,C14-1142,0,0.0152276,"extent, they all require information about the relations between the individual arguments. We hence pursue a modular pipeline approach that first determines possible relations between the arguments and subsequently maps them into a specific structure. In case the required structure cannot be inferred from the herein discussed one, the second module can be adapted accordingly. This section builds on the work in (Schindler, 2020). The code of the complete pipeline is publicly available3 . 4.1 Target Structure The herein considered target structure is based on the argument annotation scheme in (Stab and Gurevych, 2014), which distinguishes three different types of argument components (Major Claim, Claim, Premise) and two directed relations between them (support and attack). Each component has one unique relation towards another component but can be targeted by multiple others. To keep the structure as general as possible, we abstract from this framework in the sense that we are not distinguishing different component types for the retrieved arguments and only focus on finding the best fitting relation of each component towards another (or the main topic, i.e. the search query). Consequently, the resulting st"
2021.sigdial-1.39,J17-3005,0,0.0511466,"Missing"
2021.sigdial-1.39,W18-5008,0,0.155158,"uding full scale debates against a human debater (Slonim et al., 2021), persuasion (Chalaguine and Hunter, 2020) and customer support (Galitsky, 2019). Due to the complex nature of this type of interaction, many systems rely on topic-specific argument structures that encode arguments and their relations to ensure a consistent and challenging interaction (Rach et al., 2018b; Sakai et al., 2020). Despite the advantages on the formal side, this dependency limits the range of topics that can be discussed by a system as the required structures are often either annotated by hand (Rach et al., 2019; Sakai et al., 2018b) or acquired in time-consuming data collections (Chalaguine and Hunter, 2019). This limitation renders the corresponding systems inflexible, especially in comparison to recent data-driven approaches in domains like question answering (Choi et al., 2018). To address this issue, we propose a combination of argument search technology (Ajjour et al., 2019) with dialogue systems of the discussed kind. Our approach maps the list of pro and con arguments retrieved with an argument search engine for a given topic into a general tree structure that encodes bipolar relations (support and attack) betwe"
2021.sigdial-1.39,2021.naacl-main.28,1,0.80651,"e (cs ) and argument detection (ca ) to derive the final confidence as c = ca × cs and rank the retrieved arguments accordingly. In addition, we utilize ArgumenText’s Cluster API to group the retrieved arguments thematically. It determines similarity scores for argument pairs which are then applied to form clusters based on aspects addressed within the arguments. The Cluster API relies on an optimized version of the Sentence-BERT method (Reimers and Gurevych, 2019) that makes use of an efficient bi-encoder that has been trained with additional samples (“Augmented SBERT”) from a cross-encoder (Thakur et al., 2021). The utilized supervised approach to learn argument similarity was shown to outperform 1 2 https://api.argumentsearch.com http://commoncrawl.org unsupervised approaches based on BERT embeddings by 10pp (Reimers et al., 2019). 4 From Arguments to Structures In the following, the mapping of the retrieved arguments into an argument structure is discussed. Although some structures utilized by the systems discussed in Section 2 differ to a certain extent, they all require information about the relations between the individual arguments. We hence pursue a modular pipeline approach that first determ"
2021.sigdial-1.39,L18-1627,0,0.0248159,"Missing"
2021.sigdial-1.39,2021.naacl-main.34,1,0.731978,"ted structure and the automatically generated ones on the topic Marriage. Upper table: Ratio of positive and overall ratings. Lower table: p-values of pairwise comparison with Fisher’s exact test and Benjamini-Hochberg correction. As for the written feedback, multiple annotators reported confusing formulations of the argument as the major difficulty of the task. Since this is a direct consequence of the heterogeneous sources the arguments are retrieved from, it is hard to address in the pipeline. Therefore, approaches to automatically summarize or reformulate arguments (Bar-Haim et al., 2020; Schiller et al., 2021) could be beneficial to improve the performance. tree is directly influenced by the relation classification (and hence by the clustering as well), it varies between the structures with and without clustering. Therefore, the individual arguments can appear in a different context, which arguably also leads to a different perception through the study participants. On average, no significant difference between the two approaches could be found and the choice of the optimal configuration hence depends on the available data for each topic. The direct comparison with an annotated structure revealed r"
2021.sigdial-1.39,N18-5005,1,0.749415,"Missing"
2021.sigdial-1.39,E17-1017,0,0.425777,"ent search has recently evolved as an application from the field of argument mining (Lawrence and Reed, 2020). Argument search engines provide users with a (ranked) list of arguments related to a given search query, in some instances also including their stance/polarity towards the topic. 369 3.1 General Approach Over the last years, different approaches to argument search were investigated that follow different paradigms (Ajjour et al., 2019). Systems introduced so far include the one developed in the scope of IBM project debater (Levy et al., 2018), ArgumenText (Stab et al., 2018), args.me (Wachsmuth et al., 2017b), TARGER (Chernodub et al., 2019) and PerspectroScope (Chen et al., 2019). The general applicability of argument search engines in the context of dialogue systems was assessed in (Rach et al., 2020a) where ArgumenText and args.me were compared to a baseline system. Although a mapping into argument structures was not addressed, we use the discussed results to select a suitable search engine for the present work. Our model of choice is ArgumenText since it retrieves arguments on a sentence level (which is preferable in a dialogue context), performs reliable in comparison with the investigated"
2021.sigdial-1.39,W17-5106,0,0.381848,"ent search has recently evolved as an application from the field of argument mining (Lawrence and Reed, 2020). Argument search engines provide users with a (ranked) list of arguments related to a given search query, in some instances also including their stance/polarity towards the topic. 369 3.1 General Approach Over the last years, different approaches to argument search were investigated that follow different paradigms (Ajjour et al., 2019). Systems introduced so far include the one developed in the scope of IBM project debater (Levy et al., 2018), ArgumenText (Stab et al., 2018), args.me (Wachsmuth et al., 2017b), TARGER (Chernodub et al., 2019) and PerspectroScope (Chen et al., 2019). The general applicability of argument search engines in the context of dialogue systems was assessed in (Rach et al., 2020a) where ArgumenText and args.me were compared to a baseline system. Although a mapping into argument structures was not addressed, we use the discussed results to select a suitable search engine for the present work. Our model of choice is ArgumenText since it retrieves arguments on a sentence level (which is preferable in a dialogue context), performs reliable in comparison with the investigated"
2021.sigdial-1.42,2020.findings-emnlp.347,0,0.027663,"s principal reward components. Previous work on RL-based dialogue policy learning focused either on TS or US as the principal reward component. Task success can be computed (Schatzmann and Young, 2009; Gaˇsi´c et al., 2013, e.g.) or estimated (El Asri et al., 2014b; Su et al., 2015; Vandyke et al., 2015; Su et al., 2016) only when information about the task and underlying goal are known in advance. Integrating US into the reward by using the PARADISE (Walker et al., 1997) framework (Walker, 2000; Rieser and Lemon, 2008; El Asri et al., 2013, e.g.) or through a measure called response quality (Bodigutla et al., 2020, e.g.). Both are not suitable for this research as PARADISE directly incorporates task knowledge and response quality incorporates functionality of back-end services. Ultes et al. (2017a; 2019) showed that a pretrained interaction quality reward estimator can lead to a policy that is able to produce successful dialogues while achieving higher user satisfaction. This has been shown across different domains, including the domain that is used in this work. However, success declines with increasing noise in the communication channel, increasing differences in domain structure, and less co-operati"
2021.sigdial-1.42,D18-1547,1,0.841966,"Missing"
2021.sigdial-1.42,W17-5520,1,0.811218,"nnotated system-user-exchanges from the Let’s Go bus information system (Raux et al., 2006; Eskenazi et al., 2008) of Carnegie Mellon University in Pittsburgh, PA. The system provided information about bus schedules and connections to actual users with real needs and was live from 2006 until 2016. Each turn of these 200 dialogues has been annotated with IQ (representing the quality of the dialogue up to the current turn) by three experts. The final IQ label has been assigned using the median of the three individual labels. Subsequent work applied deep neural networks achieving an UAR of 0.45 (Rach et al., 2017) and a bi-directional LSTM (Hochreiter and Schmidhuber, 1997) achieving an UAR of 0.54 (Ultes, 2019). Previous work has used the LEGO corpus with a full IQ feature set (which includes additional partly domain-related information) achieving an UAR in a turn-wise cross-validation setup of 0.55 using ordinal regression (El Asri et al., 2014a), 0.53 using a two-level SVM approach (Ultes and Minker, 2013), and 0.51 using a hybrid-HMM (Ultes and Minker, 2014). Human performance on the same task is 0.69 UAR (Schmitt and Ultes, 2015). Multi-objective Reinforcement Learning The task of reinforcement Le"
2021.sigdial-1.42,rieser-lemon-2008-automatic,0,0.0581693,"ed dialog policy and (2) analysing the performance and learned behaviour when blending TS and IQ as principal reward components. Previous work on RL-based dialogue policy learning focused either on TS or US as the principal reward component. Task success can be computed (Schatzmann and Young, 2009; Gaˇsi´c et al., 2013, e.g.) or estimated (El Asri et al., 2014b; Su et al., 2015; Vandyke et al., 2015; Su et al., 2016) only when information about the task and underlying goal are known in advance. Integrating US into the reward by using the PARADISE (Walker et al., 1997) framework (Walker, 2000; Rieser and Lemon, 2008; El Asri et al., 2013, e.g.) or through a measure called response quality (Bodigutla et al., 2020, e.g.). Both are not suitable for this research as PARADISE directly incorporates task knowledge and response quality incorporates functionality of back-end services. Ultes et al. (2017a; 2019) showed that a pretrained interaction quality reward estimator can lead to a policy that is able to produce successful dialogues while achieving higher user satisfaction. This has been shown across different domains, including the domain that is used in this work. However, success declines with increasing n"
2021.sigdial-1.42,schmitt-etal-2012-parameterized,1,0.761124,"atisfied) down to 1 (extremely unsatisfied). The input consists of domain-independent interaction parameters that incorporate turn-level information from the automatic speech recognition (ASR) output and the preceding system action. Furthermore, temporal features are computed by taking sums, means or counts of the turn-based information for a window of the last three system-user-exchanges1 and the complete dialogue. Ultes et al. (2017a, 2015) use a feature set of 16 parameters to train a support vector machine (SVM) (Vapnik, 1995; Chang and Lin, 2011) with linear kernel using the LEGO corpus (Schmitt et al., 2012) achieving an unweighted average recall2 (UAR) of 0.44 in a dialog-wise cross-validation setup. The LEGO corpus consists of 200 dialogues with a total of 4,885 annotated system-user-exchanges from the Let’s Go bus information system (Raux et al., 2006; Eskenazi et al., 2008) of Carnegie Mellon University in Pittsburgh, PA. The system provided information about bus schedules and connections to actual users with real needs and was live from 2006 until 2016. Each turn of these 200 dialogues has been annotated with IQ (representing the quality of the dialogue up to the current turn) by three exper"
2021.sigdial-1.42,P16-1230,1,0.870603,"Missing"
2021.sigdial-1.42,W19-5902,1,0.763728,"ng, dialogue state tracking, dialogue policy execution, and natural language generation. For many years, research on modular spoken dialogue systems has rendered this decision making task of finding the optimal policy as a reinforcement learning (RL) problem that optimises an expected long-term future reward. The principal reward component has previously been either task success (TS) (Gaˇsi´c and Young, 2014; Daubigney et al., 2012; Levin and Pieraccini, 1997; Young et al., 2013; Su et al., 2016, 2015; Lemon and Pietquin, 2007; Ultes et al., 2018) or user satisfaction (US) (e.g. Walker, 2000; Ultes, 2019) independently. The goal of this paper is to apply both, TS and US, as principal reward components at the same time and to gain insights into the learned dialogue behaviour. This requires a learning setup that allows multiple principle reward components simultaneously and an analysis method with a structured procedure to probe learned dialog policies. This is achieved through a multi-objective reinforcement learning (MORL) setup (Ultes et al., 2017b) and an analysis method that builds upon work from Ultes and Maier (2020). The chosen MORL setup employs a linear reward scalarisation that combin"
2021.sigdial-1.42,W17-5509,1,0.87458,"Missing"
2021.sigdial-1.42,W18-5032,1,0.891372,"Missing"
2021.sigdial-1.42,W15-4649,1,0.876413,"Missing"
2021.sigdial-1.42,2020.sigdial-1.38,1,0.908065,"Pietquin, 2007; Ultes et al., 2018) or user satisfaction (US) (e.g. Walker, 2000; Ultes, 2019) independently. The goal of this paper is to apply both, TS and US, as principal reward components at the same time and to gain insights into the learned dialogue behaviour. This requires a learning setup that allows multiple principle reward components simultaneously and an analysis method with a structured procedure to probe learned dialog policies. This is achieved through a multi-objective reinforcement learning (MORL) setup (Ultes et al., 2017b) and an analysis method that builds upon work from Ultes and Maier (2020). The chosen MORL setup employs a linear reward scalarisation that combines the principal reward components TS and interaction quality (IQ) (Schmitt and Ultes, 2015)—a more objective measure for modelling US. The two main contributions of this work are (1) a universal behaviour analysis method that aims at investigating the influence of multiple learning objectives on the learned dialog policy and (2) analysing the performance and learned behaviour when blending TS and IQ as principal reward components. Previous work on RL-based dialogue policy learning focused either on TS or US as the princi"
2021.sigdial-1.42,W13-4018,1,0.763246,"ue up to the current turn) by three experts. The final IQ label has been assigned using the median of the three individual labels. Subsequent work applied deep neural networks achieving an UAR of 0.45 (Rach et al., 2017) and a bi-directional LSTM (Hochreiter and Schmidhuber, 1997) achieving an UAR of 0.54 (Ultes, 2019). Previous work has used the LEGO corpus with a full IQ feature set (which includes additional partly domain-related information) achieving an UAR in a turn-wise cross-validation setup of 0.55 using ordinal regression (El Asri et al., 2014a), 0.53 using a two-level SVM approach (Ultes and Minker, 2013), and 0.51 using a hybrid-HMM (Ultes and Minker, 2014). Human performance on the same task is 0.69 UAR (Schmitt and Ultes, 2015). Multi-objective Reinforcement Learning The task of reinforcement Learning (RL) is to find the optimal policy π ∗ that maximises a potentially delayed objective (the reward function r) (Sutton and Barto, 1998). In multi-objective reinforcement learning (MORL), the objective function consist of multiple dimensions so that a reward r becomes a vector r = (r1 , r2 , . . . , rm ), where m is the number of objectives. A scalarisation function f uses weights w for the diff"
2021.sigdial-1.42,W14-4328,1,0.784469,"IQ label has been assigned using the median of the three individual labels. Subsequent work applied deep neural networks achieving an UAR of 0.45 (Rach et al., 2017) and a bi-directional LSTM (Hochreiter and Schmidhuber, 1997) achieving an UAR of 0.54 (Ultes, 2019). Previous work has used the LEGO corpus with a full IQ feature set (which includes additional partly domain-related information) achieving an UAR in a turn-wise cross-validation setup of 0.55 using ordinal regression (El Asri et al., 2014a), 0.53 using a two-level SVM approach (Ultes and Minker, 2013), and 0.51 using a hybrid-HMM (Ultes and Minker, 2014). Human performance on the same task is 0.69 UAR (Schmitt and Ultes, 2015). Multi-objective Reinforcement Learning The task of reinforcement Learning (RL) is to find the optimal policy π ∗ that maximises a potentially delayed objective (the reward function r) (Sutton and Barto, 1998). In multi-objective reinforcement learning (MORL), the objective function consist of multiple dimensions so that a reward r becomes a vector r = (r1 , r2 , . . . , rm ), where m is the number of objectives. A scalarisation function f uses weights w for the different objectives to map the vector representation to a"
2021.sigdial-1.42,P17-4013,1,0.818649,"Pieraccini, 1997; Young et al., 2013; Su et al., 2016, 2015; Lemon and Pietquin, 2007; Ultes et al., 2018) or user satisfaction (US) (e.g. Walker, 2000; Ultes, 2019) independently. The goal of this paper is to apply both, TS and US, as principal reward components at the same time and to gain insights into the learned dialogue behaviour. This requires a learning setup that allows multiple principle reward components simultaneously and an analysis method with a structured procedure to probe learned dialog policies. This is achieved through a multi-objective reinforcement learning (MORL) setup (Ultes et al., 2017b) and an analysis method that builds upon work from Ultes and Maier (2020). The chosen MORL setup employs a linear reward scalarisation that combines the principal reward components TS and interaction quality (IQ) (Schmitt and Ultes, 2015)—a more objective measure for modelling US. The two main contributions of this work are (1) a universal behaviour analysis method that aims at investigating the influence of multiple learning objectives on the learned dialog policy and (2) analysing the performance and learned behaviour when blending TS and IQ as principal reward components. Previous work on"
2021.sigdial-1.42,W12-1819,1,0.770554,"s on multi-objective reinforcement learning and interaction quality modelling: Interaction Quality Estimation The interaction quality (IQ) (Schmitt and Ultes, 2015) represents a less subjective variant of user satisfaction: instead of being acquired from users directly, experts annotate pre-recorded dialogues to avoid the large variance that is often encountered when users rate their dialogues directly (Schmitt and Ultes, 2015). Interaction quality shows a good correlation with user satisfaction (Ultes et al., 2013) and fulfils the requirements necessary for its application in dialog systems (Ultes et al., 2012, 2016). Estimating IQ has been cast as a turn-level classification problem where the target classes are the distinct IQ values ranging from 5 (satisfied) down to 1 (extremely unsatisfied). The input consists of domain-independent interaction parameters that incorporate turn-level information from the automatic speech recognition (ASR) output and the preceding system action. Furthermore, temporal features are computed by taking sums, means or counts of the turn-based information for a window of the last three system-user-exchanges1 and the complete dialogue. Ultes et al. (2017a, 2015) use a fe"
2021.sigdial-1.42,N13-1064,1,0.781034,"in Sections 5 and 6. 2 Preliminaries The presented work builds upon previously published approaches on multi-objective reinforcement learning and interaction quality modelling: Interaction Quality Estimation The interaction quality (IQ) (Schmitt and Ultes, 2015) represents a less subjective variant of user satisfaction: instead of being acquired from users directly, experts annotate pre-recorded dialogues to avoid the large variance that is often encountered when users rate their dialogues directly (Schmitt and Ultes, 2015). Interaction quality shows a good correlation with user satisfaction (Ultes et al., 2013) and fulfils the requirements necessary for its application in dialog systems (Ultes et al., 2012, 2016). Estimating IQ has been cast as a turn-level classification problem where the target classes are the distinct IQ values ranging from 5 (satisfied) down to 1 (extremely unsatisfied). The input consists of domain-independent interaction parameters that incorporate turn-level information from the automatic speech recognition (ASR) output and the preceding system action. Furthermore, temporal features are computed by taking sums, means or counts of the turn-based information for a window of the"
2021.sigdial-1.42,P97-1035,0,0.701459,"e of multiple learning objectives on the learned dialog policy and (2) analysing the performance and learned behaviour when blending TS and IQ as principal reward components. Previous work on RL-based dialogue policy learning focused either on TS or US as the principal reward component. Task success can be computed (Schatzmann and Young, 2009; Gaˇsi´c et al., 2013, e.g.) or estimated (El Asri et al., 2014b; Su et al., 2015; Vandyke et al., 2015; Su et al., 2016) only when information about the task and underlying goal are known in advance. Integrating US into the reward by using the PARADISE (Walker et al., 1997) framework (Walker, 2000; Rieser and Lemon, 2008; El Asri et al., 2013, e.g.) or through a measure called response quality (Bodigutla et al., 2020, e.g.). Both are not suitable for this research as PARADISE directly incorporates task knowledge and response quality incorporates functionality of back-end services. Ultes et al. (2017a; 2019) showed that a pretrained interaction quality reward estimator can lead to a policy that is able to produce successful dialogues while achieving higher user satisfaction. This has been shown across different domains, including the domain that is used in this w"
C16-1025,J81-4005,0,0.682625,"Missing"
C16-1025,W14-4340,1,0.913591,"et al., 2011; Deoras and Sarikaya, 2013; Sarikaya et al., 2014). Spoken language understanding from unaligned data, in which utterances are annotated with an abstract semantics, faces the additional challenge of not knowing which specific words are relevant for extracting the semantics. This problem was tackled in (Zhou and He, 2011), by using conditional random fields (CRFs) driven by finely-tuned hand-crafted features. Other discriminative approaches that deal with unaligned data use some form of delexicalisation or mapping of the input to known ontological concepts (Henderson et al., 2012; Henderson et al., 2014a). The main disadvantage of delexicalisation is the difficulty in scaling it, not only to larger and more complex dialogue domains but also to handle the many forms of language variation. We propose in this paper a semantic decoder that learns from unaligned data (Figure 1) and that exploits rich semantic distributed word representations instead of delexicalisation. The semantic decoder predicts the dialogue act and the set of slot-value pairs from a set of n-best hypotheses returned by an automatic speech recognition (ASR). The prediction is made in two steps. First, a deep learning architec"
C16-1025,W14-4337,0,0.278647,"et al., 2011; Deoras and Sarikaya, 2013; Sarikaya et al., 2014). Spoken language understanding from unaligned data, in which utterances are annotated with an abstract semantics, faces the additional challenge of not knowing which specific words are relevant for extracting the semantics. This problem was tackled in (Zhou and He, 2011), by using conditional random fields (CRFs) driven by finely-tuned hand-crafted features. Other discriminative approaches that deal with unaligned data use some form of delexicalisation or mapping of the input to known ontological concepts (Henderson et al., 2012; Henderson et al., 2014a). The main disadvantage of delexicalisation is the difficulty in scaling it, not only to larger and more complex dialogue domains but also to handle the many forms of language variation. We propose in this paper a semantic decoder that learns from unaligned data (Figure 1) and that exploits rich semantic distributed word representations instead of delexicalisation. The semantic decoder predicts the dialogue act and the set of slot-value pairs from a set of n-best hypotheses returned by an automatic speech recognition (ASR). The prediction is made in two steps. First, a deep learning architec"
C16-1025,P14-1062,0,0.0187706,"rder to perform joint intent detection and slot filling. All these models use word-level semantic annotations. However, providing these word-level semantic annotations is costly since it requires specialised annotators. (Zhou and He, 2011) has proposed learning CRFs from unaligned data, however they use manually tuned lexical or syntactic features. In this work we avoid the need for word-level annotation by exploiting distributed word embeddings and using deep learning for feature representation. Convolutional Neural Networks (CNNs) have been used previously for sentiment analysis (Kim, 2014; Kalchbrenner et al., 2014) and in this work we explore a similar CNN to the one presented by Kim (2014) for generating a sentence representation. However unlike Kim (2014), the input in not a single well formed sentence but a set of ill-formed ASR hypotheses. Additionally, the softmax layer used for binary classification (i.e., positive or negative sentiment) is replaced by a softmax layer for multiclass dialogue act prediction and a further softmax layer is added for each distinct slot in the domain. (Chen and He, 2015) proposed a CNN for generating intent embeddings in SLU, which uses tri-letter input vectors. Instea"
C16-1025,D14-1181,0,0.0306459,"ar CRF in order to perform joint intent detection and slot filling. All these models use word-level semantic annotations. However, providing these word-level semantic annotations is costly since it requires specialised annotators. (Zhou and He, 2011) has proposed learning CRFs from unaligned data, however they use manually tuned lexical or syntactic features. In this work we avoid the need for word-level annotation by exploiting distributed word embeddings and using deep learning for feature representation. Convolutional Neural Networks (CNNs) have been used previously for sentiment analysis (Kim, 2014; Kalchbrenner et al., 2014) and in this work we explore a similar CNN to the one presented by Kim (2014) for generating a sentence representation. However unlike Kim (2014), the input in not a single well formed sentence but a set of ill-formed ASR hypotheses. Additionally, the softmax layer used for binary classification (i.e., positive or negative sentiment) is replaced by a softmax layer for multiclass dialogue act prediction and a further softmax layer is added for each distinct slot in the domain. (Chen and He, 2015) proposed a CNN for generating intent embeddings in SLU, which uses tri-"
C16-1025,P15-2130,1,0.879225,"Missing"
C16-1025,D14-1162,0,0.0801578,"2014) for generating a sentence representation. However unlike Kim (2014), the input in not a single well formed sentence but a set of ill-formed ASR hypotheses. Additionally, the softmax layer used for binary classification (i.e., positive or negative sentiment) is replaced by a softmax layer for multiclass dialogue act prediction and a further softmax layer is added for each distinct slot in the domain. (Chen and He, 2015) proposed a CNN for generating intent embeddings in SLU, which uses tri-letter input vectors. Instead, in this paper the models are initialised with GloVe word embeddings (Pennington et al., 2014). These GloVe embeddings were trained in an unsupervised fashion on a large amount of data to model the contextual similarity and correlation between words. Chen and He’s model aims to learn the embeddings for utterances and intents such that utterances with similar intents are close to each other in the continuous space. Although we share the same spirit, we use sentence embeddings not only for intent creativecommons.org/licenses/by/4.0/ 259 (or dialogue act) recognition but also for slot-filling within a dialogue system and we combine them with embeddings for dialogue context. Approaches for"
C16-1025,W14-4339,0,0.187447,"Missing"
D16-1233,D14-1179,0,0.0476362,"Missing"
D16-1233,W14-4340,1,0.927408,"ns and alleviates the vanishing gradient problem; (3) it appears to learn transparent and interpretable subspaces of the conditioning vector. 2 Related Work Machine learning approaches to task-oriented dialogue system design have cast the problem as a partially observable Markov Decision Process (POMDP) (Young et al., 2013) with the aim of using reinforcement learning (RL) to train dialogue policies online through interactions with real users (Gaˇsi´c et al., 2013). In order to make RL tractable, the state and action space must be carefully designed (Young et al., 2010) and the understanding (Henderson et al., 2014; Mrkˇsi´c et al., 2015) and generation (Wen et al., 2015b; Wen et al., 2016b) modules were assumed available or trained standalone on supervised corpora. Due to the underlying hand-coded semantic representation (Traum, 1999), the conversation is far from natural and the comprehension capability is limited. This motivates the use of neural networks to model dialogues from end to end as a conditional generation problem. Interest in generating natural language using NNs can be attributed to the success of RNN LMs for large vocabulary speech recognition (Mikolov et al., 2010; Mikolov et al., 2011"
D16-1233,P11-1055,0,0.0137807,"collected using Amazon Mechanical Turk. An NNbased dialogue model was also proposed to learn from the collected dataset and was shown to be able to assist human subjects to complete specific tasks. Snapshot learning can be viewed as a special form of weak supervision (also known as distant- or self supervision) (Craven and Kumlien, 1999; Snow et al., 2004), in which supervision signals are heuristically labelled by matching unlabelled corpora with entities or attributes in a structured database. It has been widely applied to relation extraction (Mintz et al., 2009) and information extraction (Hoffmann et al., 2011) in which facts from a knowledge base (e.g. Freebase) were used as objectives to train classifiers. Recently, self supervision was also used in memory networks (Hill et al., 2016) to improve the discriminative power of memory attention. Conceptually, snapshot learning is related to curriculum learning (Bengio et al., 2009). Instead of learning easier examples before difficult ones, snapshot learning creates an easier target for each example. In practice, snapshot learning is similar to deeply supervised nets (Lee et al., 2015) in which companion objectives are generated from intermediary layer"
D16-1233,N16-1014,0,0.0318639,"t al., 2015; Hermann et al., 2015; Ling et al., 2016) have been shown to be very effective improving performance using a dynamic source aggregation strategy. To model dialogue as conditional generation, a sequence-to-sequence learning (Sutskever et al., 2014) framework has been adopted. Vinyals and Le (2015) trained the same model on several conversation datasets and showed that the model can generate plausible conversations. However, Serban et al. (2015b) discovered that the majority of the generated responses are generic due to the maximum likelihood criterion, which was latter addressed by Li et al. (2016a) using a maximum mutual information decoding strategy. Furthermore, the lack of a consistent system persona was also studied in Li et al. (2016b). Despite its demonstrated potential, a major barrier for this line of research is data collection. Many works (Lowe et al., 2015; Serban et al., 2015a; Dodge et al., 2016) have investigated conversation datasets for developing chat bot or QA-like general purpose conversation agents. However, collecting data to develop goal oriented dialogue systems that can help users to complete a task in a specific domain remains difficult. In a recent work by We"
D16-1233,P16-1094,0,0.0186793,"t al., 2015; Hermann et al., 2015; Ling et al., 2016) have been shown to be very effective improving performance using a dynamic source aggregation strategy. To model dialogue as conditional generation, a sequence-to-sequence learning (Sutskever et al., 2014) framework has been adopted. Vinyals and Le (2015) trained the same model on several conversation datasets and showed that the model can generate plausible conversations. However, Serban et al. (2015b) discovered that the majority of the generated responses are generic due to the maximum likelihood criterion, which was latter addressed by Li et al. (2016a) using a maximum mutual information decoding strategy. Furthermore, the lack of a consistent system persona was also studied in Li et al. (2016b). Despite its demonstrated potential, a major barrier for this line of research is data collection. Many works (Lowe et al., 2015; Serban et al., 2015a; Dodge et al., 2016) have investigated conversation datasets for developing chat bot or QA-like general purpose conversation agents. However, collecting data to develop goal oriented dialogue systems that can help users to complete a task in a specific domain remains difficult. In a recent work by We"
D16-1233,P16-1057,0,0.0393118,"Missing"
D16-1233,W15-4640,0,0.0167479,"been adopted. Vinyals and Le (2015) trained the same model on several conversation datasets and showed that the model can generate plausible conversations. However, Serban et al. (2015b) discovered that the majority of the generated responses are generic due to the maximum likelihood criterion, which was latter addressed by Li et al. (2016a) using a maximum mutual information decoding strategy. Furthermore, the lack of a consistent system persona was also studied in Li et al. (2016b). Despite its demonstrated potential, a major barrier for this line of research is data collection. Many works (Lowe et al., 2015; Serban et al., 2015a; Dodge et al., 2016) have investigated conversation datasets for developing chat bot or QA-like general purpose conversation agents. However, collecting data to develop goal oriented dialogue systems that can help users to complete a task in a specific domain remains difficult. In a recent work by Wen et al. (2016a), this problem was addressed by designing an online, parallel version of Wizard-of-Oz data collection (Kelley, 1984) which allows large scale and cheap in-domain conversation data to be collected using Amazon Mechanical Turk. An NNbased dialogue model was also"
D16-1233,N16-1086,0,0.0998745,"oviding both model interpretability and better performance. Thirdly, snapshot learning leads to consistent performance improvements independent of which architecture is used. 1 Introduction Recurrent Neural Network (RNN)-based conditional language models (LM) have been shown to be very effective in tackling a number of real world problems, such as machine translation (MT) (Cho et al., 2014) and image caption generation (Karpathy and Fei-Fei, 2015). Recently, RNNs were applied to task of generating sentences from an explicit semantic representation (Wen et al., 2015a). Attention-based methods (Mei et al., 2016) and Long Short-term Memory (LSTM)-like (Hochreiter Neural conversational agents (Vinyals and Le, 2015; Shang et al., 2015) are direct extensions of the sequence-to-sequence model (Sutskever et al., 2014) in which a conversation is cast as a source to target transduction problem. However, these models are still far from real world applications because they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2016) and aggregate useful information into their responses. Recent work by Wen et al. (2016a)"
D16-1233,P09-1113,0,0.0102347,"ale and cheap in-domain conversation data to be collected using Amazon Mechanical Turk. An NNbased dialogue model was also proposed to learn from the collected dataset and was shown to be able to assist human subjects to complete specific tasks. Snapshot learning can be viewed as a special form of weak supervision (also known as distant- or self supervision) (Craven and Kumlien, 1999; Snow et al., 2004), in which supervision signals are heuristically labelled by matching unlabelled corpora with entities or attributes in a structured database. It has been widely applied to relation extraction (Mintz et al., 2009) and information extraction (Hoffmann et al., 2011) in which facts from a knowledge base (e.g. Freebase) were used as objectives to train classifiers. Recently, self supervision was also used in memory networks (Hill et al., 2016) to improve the discriminative power of memory attention. Conceptually, snapshot learning is related to curriculum learning (Bengio et al., 2009). Instead of learning easier examples before difficult ones, snapshot learning creates an easier target for each example. In practice, snapshot learning is similar to deeply supervised nets (Lee et al., 2015) in which compani"
D16-1233,P15-2130,1,0.896091,"Missing"
D16-1233,P02-1040,0,0.0983833,"ies, we decode all the trained models with the average log probability of tokens in the sentence. We applied beam search with a beamwidth equal to 10, the search stops when an end-of-sentence token is generated. In order to consider language variability, we ran decoding until 5 candidates were obtained and performed evaluation on them. Metrics We compared models trained with different recipes by performing a corpus-based evaluation in which the model is used to predict each system response in the held-out test set. Three evaluation metrics were used: BLEU score (on top-1 and top5 candidates) (Papineni et al., 2002), slot matching rate and objective task success rate (Su et al., 2015). The dialogue is marked as successful if both: (1) the offered entity matches the task that was specified to the user, and (2) the system answered all the associated information requests (e.g. what is the address?) from the user. The slot matching rate is the percentage of delexicalised tokens (e.g. [s.food] and [v.area]1 ) appear in the candidate also appear in the (a) Hybrid LSTM w/o snapshot learning (b) Hybrid LSTM w/ snapshot learning Figure 3: Learned attention heat maps over trackers. The first three columns in each"
D16-1233,P15-1152,0,0.033149,"provements independent of which architecture is used. 1 Introduction Recurrent Neural Network (RNN)-based conditional language models (LM) have been shown to be very effective in tackling a number of real world problems, such as machine translation (MT) (Cho et al., 2014) and image caption generation (Karpathy and Fei-Fei, 2015). Recently, RNNs were applied to task of generating sentences from an explicit semantic representation (Wen et al., 2015a). Attention-based methods (Mei et al., 2016) and Long Short-term Memory (LSTM)-like (Hochreiter Neural conversational agents (Vinyals and Le, 2015; Shang et al., 2015) are direct extensions of the sequence-to-sequence model (Sutskever et al., 2014) in which a conversation is cast as a source to target transduction problem. However, these models are still far from real world applications because they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2016) and aggregate useful information into their responses. Recent work by Wen et al. (2016a), however, proposed an end-to-end trainable neural dialogue system that can assist users to complete specific tasks. Their"
D16-1233,W15-4639,1,0.905933,"Missing"
D16-1233,D15-1199,1,0.906064,"Missing"
D16-1233,N16-1015,1,0.901342,"Missing"
D16-1233,W16-0105,0,0.0581401,"s from an explicit semantic representation (Wen et al., 2015a). Attention-based methods (Mei et al., 2016) and Long Short-term Memory (LSTM)-like (Hochreiter Neural conversational agents (Vinyals and Le, 2015; Shang et al., 2015) are direct extensions of the sequence-to-sequence model (Sutskever et al., 2014) in which a conversation is cast as a source to target transduction problem. However, these models are still far from real world applications because they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2016) and aggregate useful information into their responses. Recent work by Wen et al. (2016a), however, proposed an end-to-end trainable neural dialogue system that can assist users to complete specific tasks. Their system used both distributed and symbolic representations to capture user intents, and these collectively condition a NN language generator to generate system responses. Due to the diversity of the conditioning information sources, the best way to represent and combine them is non-trivial. 2153 Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, page"
D18-1547,W17-5526,0,0.240706,"Missing"
D18-1547,W11-2002,0,0.0691455,"ed on building task-oriented dialogue systems (Young et al., 2013) that can help with specific tasks such as flight reservation (Seneff and Polifroni, 2000) ⇤ The work was done while at the University of Cambridge. or bus information (Raux et al., 2005). As the need of hands-free use cases continues to grow, building a conversational agent that can handle tasks across different application domains has become more and more prominent (Ram et al., 2018). Dialogues systems are inherently hard to build because there are several layers of complexity: the noise and uncertainty in speech recognition (Black et al., 2011); the ambiguity when understanding human language (Williams et al., 2013); the need to integrate third-party services and dialogue context in the decision-making (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005). These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho"
D18-1547,2005.sigdial-1.14,0,0.0630783,"falling behind by a large margin in comparison to the results on the Cam676 corpus taking into account both Inform and Success metrics. As most of dialogues span over at least two domains, the model has to be much more effective in order to execute a successful dialogue. Moreover, the BLEU score on the MultiWOZ is lower than the one reported on the Cam676 dataset. This is mainly caused by the much more diverse linguistic expressions observed in the MultiWOZ dataset. 5.3 Dialogue-Act-to-Text Generation Natural Language Generation from a structured meaning representation (Oh and Rudnicky, 2000; Bohus and Rudnicky, 2005) has been a very popular research topic in the community, and the lack of data has been a long standing block for the field to adopt more machine learning methods. Due to the additional annotation of the system acts, the MultiWOZ dataset serves as a new benchmark for studying natural language generation from a structured meaning representation. In order to verify the difficulty of the collected dataset for the language generation task, we compare it to the SFX dataset (see Table 1), which consists of around 5k dialogue act and natural language sentence pairs. We trained the same Semantically C"
D18-1547,bunt-2006-dimensions,0,0.0323307,"inspected and corrections were reported to annotators. Workers were asked to re-run a new trial dialogue. Having passed the second test, they were allowed to start annotating real dialogues. This procedure resulted in a restricted set of annotators performing high quality annotations. Appendix A contains a demonstration of a created system. Arguably, the most challenging and timeconsuming part of any dialogue data collection is the process of annotating dialogue acts. One of the major challenges of this task is the definition of a set and structure of dialogue acts (Traum and Hinkelman, 1992; Bunt, 2006). In general, a dialogue act consists of the intent (such as request or inform) and slot-value pairs. For example, the act 3.5 Data Quality inform(domain=hotel,price=expensive) Data collection was performed in a two-step prohas the intent inform, where the user is informing cess. First, all dialogues were collected and then the system to constrain the search to expensive the annotation process was launched. This setup hotels. allowed the dialogue act annotators to also report Expecting a big discrepancy in annotations beerrors (e.g., not following the task or confusing tween annotators, we ini"
D18-1547,W17-5506,0,0.618535,"ng (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005). These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016), and even end-to-end dialogue modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic labels (Hemphill et al., 1990; Williams et al., 2013; Asri et al., 2017; Wen et al., 2017; Eric et al., 2017; Shah et al., 2018); and corpora without semantic labels but with an implicit user goal in mind (Ritter et al., 2010; Lowe et al., 2015). Despite these efforts, aforement"
D18-1547,H90-1021,0,0.938681,"il et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016), and even end-to-end dialogue modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic labels (Hemphill et al., 1990; Williams et al., 2013; Asri et al., 2017; Wen et al., 2017; Eric et al., 2017; Shah et al., 2018); and corpora without semantic labels but with an implicit user goal in mind (Ritter et al., 2010; Lowe et al., 2015). Despite these efforts, aforementioned datasets are usually constrained in one or more dimensions such as missing proper annotations, only available in a limited capacity, lacking multi-domain use cases, or having a negli5016 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5016–5026 c Brussels, Belgium, October 31 - November 4, 2018. 2"
D18-1547,N16-1014,0,0.0205127,"r et al., 2010) dataset, the Reddit conversations (Schrading et al., 2015), and the Ubuntu technical support corpus (Lowe et al., 2015). Although previous work (Vinyals and Le, 2015) has shown that a large learning system can learn to generate interesting responses from these corpora, the lack of grounding conversations onto an existing knowledge base or APIs limits the usability of developed systems. Due to the lack of an explicit goal in the conversation, recent studies have shown that systems trained with this type of corpus not only struggle in generating consistent and diverse responses (Li et al., 2016) but are also extremely hard to evaluate (Liu et al., 2016). In this paper, we focus on a particular type of human-to-human data collection. The Wizardof-Oz framework (WOZ) (Kelley, 1984) was first proposed as an iterative approach to improve user experiences when designing a conversational system. The goal of WOZ data collection is to log down the conversation for future system development. One of the earliest dataset collected in this fashion is the ATIS corpus (Hemphill et al., 1990), where conversations between a client and an airline help-desk operator were recorded. More recently, Wen et"
D18-1547,I17-1074,0,0.0276924,"taurant domain. Although not directly comparable, Table 3 shows that the performance of the model is consecutively poorer on the new dataset compared to WOZ2.0. These results demonstrate how demanding is the new dataset as the conversations are richer and much longer. 5.2 Dialogue-Context-to-Text Generation After a robust dialogue state tracking module is built, the next challenge becomes the dialogue management and response generation components. These problems can either be addressed separately (Young et al., 2013), or jointly in an end-to-end fashion (Bordes et al., 2017; Wen et al., 2017; Li et al., 2017). In order to establish a clear benchmark where the performance of the composite of dialogue management and response generation is completely independent of the belief tracking, we experimented with a baseline neural response generation model with an oracle beliefstate obtained from the wizard annotations as discussed in Section 3.3.5 Following Wen et al. (2017) which frames the dialogue as a context to response mapping problem, a sequence-to-sequence model (Sutskever et al., 2014) is augmented with a belief tracker and a discrete database accessing component as additional features to inform t"
D18-1547,D16-1230,0,0.0496515,"Missing"
D18-1547,W14-4337,0,0.772007,"into account noisy conditions often experienced in real interactions (Black et al., 2011). Human-to-Machine Since collecting dialogue corpus for a task-specific application from scratch is difficult, most of the task-oriented dialogue corpora are fostered based on an existing dialogue system. One famous example of this kind is the Let’s Go Bus Information System which offers live bus schedule information over the phone (Raux et al., 2005) leading to the first Dialogue State Tracking Challenge (Williams et al., 2013). Taking the idea of the Let’s Go system forward, the second and third DSTCs (Henderson et al., 2014b,c) have produced bootstrapped human-machine datasets for a restaurant search domain in the Cambridge area, UK. Since then, DSTCs have become one of the central research topics in the dialogue community (Kim et al., 2016, 2017). While human-to-machine data collection is an obvious solution for dialogue system develop5017 ment, it is only possible with a provision of an existing working system. Therefore, this chicken (system)-and-egg (data) problem limits the use of this type of data collection to existing system improvement instead of developing systems in a completely new domain. What is ev"
D18-1547,W15-4640,0,0.2722,"Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic labels (Hemphill et al., 1990; Williams et al., 2013; Asri et al., 2017; Wen et al., 2017; Eric et al., 2017; Shah et al., 2018); and corpora without semantic labels but with an implicit user goal in mind (Ritter et al., 2010; Lowe et al., 2015). Despite these efforts, aforementioned datasets are usually constrained in one or more dimensions such as missing proper annotations, only available in a limited capacity, lacking multi-domain use cases, or having a negli5016 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5016–5026 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics Metric DSTC2 SFX WOZ2.0 FRAMES KVRET M2M MultiWOZ # Dialogues Total # turns Total # tokens Avg. turns per dialogue Avg. tokens per turn Total unique tokens # Slots # Valu"
D18-1547,W14-4340,0,0.797945,"into account noisy conditions often experienced in real interactions (Black et al., 2011). Human-to-Machine Since collecting dialogue corpus for a task-specific application from scratch is difficult, most of the task-oriented dialogue corpora are fostered based on an existing dialogue system. One famous example of this kind is the Let’s Go Bus Information System which offers live bus schedule information over the phone (Raux et al., 2005) leading to the first Dialogue State Tracking Challenge (Williams et al., 2013). Taking the idea of the Let’s Go system forward, the second and third DSTCs (Henderson et al., 2014b,c) have produced bootstrapped human-machine datasets for a restaurant search domain in the Cambridge area, UK. Since then, DSTCs have become one of the central research topics in the dialogue community (Kim et al., 2016, 2017). While human-to-machine data collection is an obvious solution for dialogue system develop5017 ment, it is only possible with a provision of an existing working system. Therefore, this chicken (system)-and-egg (data) problem limits the use of this type of data collection to existing system improvement instead of developing systems in a completely new domain. What is ev"
D18-1547,W13-4073,0,0.0586227,"build because there are several layers of complexity: the noise and uncertainty in speech recognition (Black et al., 2011); the ambiguity when understanding human language (Williams et al., 2013); the need to integrate third-party services and dialogue context in the decision-making (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005). These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016), and even end-to-end dialogue modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic la"
D18-1547,D16-1032,0,0.0124938,"liams et al., 2013); the need to integrate third-party services and dialogue context in the decision-making (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005). These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016), and even end-to-end dialogue modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic labels (Hemphill et al., 1990; Williams et al., 2013; Asri et al., 2017; Wen et al., 2017; Eric et al., 2017; Shah et al., 2018); and corpora without semantic labels but with a"
D18-1547,P17-1163,1,0.87487,"Missing"
D18-1547,Q17-1022,1,0.736153,"Missing"
D18-1547,W00-0306,0,0.205088,"l on MultiWOZ is still falling behind by a large margin in comparison to the results on the Cam676 corpus taking into account both Inform and Success metrics. As most of dialogues span over at least two domains, the model has to be much more effective in order to execute a successful dialogue. Moreover, the BLEU score on the MultiWOZ is lower than the one reported on the Cam676 dataset. This is mainly caused by the much more diverse linguistic expressions observed in the MultiWOZ dataset. 5.3 Dialogue-Act-to-Text Generation Natural Language Generation from a structured meaning representation (Oh and Rudnicky, 2000; Bohus and Rudnicky, 2005) has been a very popular research topic in the community, and the lack of data has been a long standing block for the field to adopt more machine learning methods. Due to the additional annotation of the system acts, the MultiWOZ dataset serves as a new benchmark for studying natural language generation from a structured meaning representation. In order to verify the difficulty of the collected dataset for the language generation task, we compare it to the SFX dataset (see Table 1), which consists of around 5k dialogue act and natural language sentence pairs. We trai"
D18-1547,P02-1040,0,0.101374,"Missing"
D18-1547,P18-2069,1,0.766406,"Missing"
D18-1547,N10-1020,0,0.522396,"modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic labels (Hemphill et al., 1990; Williams et al., 2013; Asri et al., 2017; Wen et al., 2017; Eric et al., 2017; Shah et al., 2018); and corpora without semantic labels but with an implicit user goal in mind (Ritter et al., 2010; Lowe et al., 2015). Despite these efforts, aforementioned datasets are usually constrained in one or more dimensions such as missing proper annotations, only available in a limited capacity, lacking multi-domain use cases, or having a negli5016 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5016–5026 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics Metric DSTC2 SFX WOZ2.0 FRAMES KVRET M2M MultiWOZ # Dialogues Total # turns Total # tokens Avg. turns per dialogue Avg. tokens per turn Total unique t"
D18-1547,D15-1309,0,0.0339104,"t al., 2016). The limited understanding capability of the initial system may prompt the users to adapt to simpler input examples that the system can understand but are not necessarily natural in conversations. Human-to-Human Arguably, the best strategy to build a natural conversational system may be to have a system that can directly mimic human behaviors through learning from a large amount of real human-human conversations. With this idea in mind, several large-scale dialogue corpora have been released in the past, such as the Twitter (Ritter et al., 2010) dataset, the Reddit conversations (Schrading et al., 2015), and the Ubuntu technical support corpus (Lowe et al., 2015). Although previous work (Vinyals and Le, 2015) has shown that a large learning system can learn to generate interesting responses from these corpora, the lack of grounding conversations onto an existing knowledge base or APIs limits the usability of developed systems. Due to the lack of an explicit goal in the conversation, recent studies have shown that systems trained with this type of corpus not only struggle in generating consistent and diverse responses (Li et al., 2016) but are also extremely hard to evaluate (Liu et al., 2016"
D18-1547,W00-0303,0,0.506497,"one of the long-standing challenges in computer science and artificial intelligence since the Dartmouth Proposal (McCarthy et al., 1955). As human conversation is inherently complex and ambiguous, learning an open-domain conversational AI that can carry on arbitrary tasks is still very far-off (Vinyals and Le, 2015). As a consequence, instead of focusing on creating ambitious conversational agents that can reach human-level intelligence, industrial practice has focused on building task-oriented dialogue systems (Young et al., 2013) that can help with specific tasks such as flight reservation (Seneff and Polifroni, 2000) ⇤ The work was done while at the University of Cambridge. or bus information (Raux et al., 2005). As the need of hands-free use cases continues to grow, building a conversational agent that can handle tasks across different application domains has become more and more prominent (Ram et al., 2018). Dialogues systems are inherently hard to build because there are several layers of complexity: the noise and uncertainty in speech recognition (Black et al., 2011); the ambiguity when understanding human language (Williams et al., 2013); the need to integrate third-party services and dialogue contex"
D18-1547,N16-1015,1,0.902963,"Missing"
D18-1547,D15-1199,1,0.881212,"Missing"
D18-1547,E17-1042,1,0.819561,"Missing"
D18-1547,W13-4065,0,0.636123,"t can help with specific tasks such as flight reservation (Seneff and Polifroni, 2000) ⇤ The work was done while at the University of Cambridge. or bus information (Raux et al., 2005). As the need of hands-free use cases continues to grow, building a conversational agent that can handle tasks across different application domains has become more and more prominent (Ram et al., 2018). Dialogues systems are inherently hard to build because there are several layers of complexity: the noise and uncertainty in speech recognition (Black et al., 2011); the ambiguity when understanding human language (Williams et al., 2013); the need to integrate third-party services and dialogue context in the decision-making (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005). These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016"
D18-1547,W16-3601,0,\N,Missing
E17-1042,W14-4340,1,0.407798,"Introduction Building a task-oriented dialogue system such as a hotel booking or a technical support service is difficult because it is application-specific and there is usually limited availability of training data. To mitigate this problem, recent machine learning approaches to task-oriented dialogue system design have cast the problem as a partially observable Markov Decision Process (POMDP) (Young et al., 2013) with the aim of using reinforcement learning (RL) to train dialogue policies online through interactions with real users (Gaši´c et al., 2013). However, the language understanding (Henderson et al., 2014; Yao et al., 2014) and language generation (Wen et al., 2015b; Wen et al., 2016) modules still rely on supervised learning and therefore need corpora to train on. Furthermore, to make RL tractable, the state and action space must be carefully designed (Young et al., 2013; Young et al., 2010), which may restrict the expressive power and learnability of the model. Also, the reward functions needed to train such models are difficult to design and hard to measure at run-time (Su et al., 2015; Su et al., 2016). At the other end of the spectrum, sequence to sequence learning (Sutskever et al., 2014"
E17-1042,P82-1020,0,0.852845,"Missing"
E17-1042,P15-1152,0,0.0310789,"d therefore need corpora to train on. Furthermore, to make RL tractable, the state and action space must be carefully designed (Young et al., 2013; Young et al., 2010), which may restrict the expressive power and learnability of the model. Also, the reward functions needed to train such models are difficult to design and hard to measure at run-time (Su et al., 2015; Su et al., 2016). At the other end of the spectrum, sequence to sequence learning (Sutskever et al., 2014) has inspired several efforts to build end-to-end trainable, non-task-oriented conversational systems (Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2015b). This family of approaches treats dialogue as a source to target sequence transduction problem, applying an encoder network (Cho et al., 2014) to encode a user query into a distributed vector representing its semantics, which then conditions a decoder network to generate each system response. These models typically require a large amount of data to train. They allow the creation of effective chatbot type systems but they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2015"
E17-1042,P16-1230,1,0.812856,"Missing"
E17-1042,W15-4639,1,0.762536,"Missing"
E17-1042,D15-1199,1,0.0638233,"Missing"
E17-1042,N16-1015,1,0.0427593,"Missing"
I17-1092,W03-1601,0,0.0435491,"lection of System Actions User Action Elaborateness/Indirectness Generator Core Statement Knowledge Integration Subject/Predicate/Object Related RDF Triplets Knowledge Base Figure 1: Partial architecture of the KRISTINA system, enhanced by the proposed algorithm. tences from a more structured representation. With regard to surface realisation, one characteristic of good generators is their ability to provide variation in the generated sentences, which has been explored, among others, by Wen et al. (2015). With a similar goal, efforts towards the paraphrasing of sentences have been made (e.g. (Kozlowski et al., 2003; Langkilde and Knight, 1998)). Those approaches provide variation at the word level and preserve the semantic content of a sentence. They are complemented by our approach that focuses on variations of the semantic content of a system action. The content selection task is concerned with choosing relevant information that is to be communicated in the generated text, often with the goal of creating summaries (e.g. (Duboue and McKeown, 2003; Barzilay and Lapata, 2005)). While this research area certainly provides important insights to the generation of elaborateness, they need to be considered wi"
I17-1092,P98-1116,0,0.0767059,"s User Action Elaborateness/Indirectness Generator Core Statement Knowledge Integration Subject/Predicate/Object Related RDF Triplets Knowledge Base Figure 1: Partial architecture of the KRISTINA system, enhanced by the proposed algorithm. tences from a more structured representation. With regard to surface realisation, one characteristic of good generators is their ability to provide variation in the generated sentences, which has been explored, among others, by Wen et al. (2015). With a similar goal, efforts towards the paraphrasing of sentences have been made (e.g. (Kozlowski et al., 2003; Langkilde and Knight, 1998)). Those approaches provide variation at the word level and preserve the semantic content of a sentence. They are complemented by our approach that focuses on variations of the semantic content of a system action. The content selection task is concerned with choosing relevant information that is to be communicated in the generated text, often with the goal of creating summaries (e.g. (Duboue and McKeown, 2003; Barzilay and Lapata, 2005)). While this research area certainly provides important insights to the generation of elaborateness, they need to be considered with respect to the peculiariti"
I17-1092,H05-1042,0,0.0533774,"explored, among others, by Wen et al. (2015). With a similar goal, efforts towards the paraphrasing of sentences have been made (e.g. (Kozlowski et al., 2003; Langkilde and Knight, 1998)). Those approaches provide variation at the word level and preserve the semantic content of a sentence. They are complemented by our approach that focuses on variations of the semantic content of a system action. The content selection task is concerned with choosing relevant information that is to be communicated in the generated text, often with the goal of creating summaries (e.g. (Duboue and McKeown, 2003; Barzilay and Lapata, 2005)). While this research area certainly provides important insights to the generation of elaborateness, they need to be considered with respect to the peculiarities of dialogue. Instead of providing an overview over the most important information in a larger amount of data, the goal of our work is to augment an already determined piece of information with relevant further information. Hence, content selection is more concerned with filtering information, while our approach focuses on adding information. Related Work Adaptive DMs can be beneficial to the user experience (Ultes et al., 2015; Bertr"
I17-1092,W16-3610,1,0.828813,"their preferences in a conversation is demanding work. Approaches to the automatic generation of system actions, such as (Kadlec et al., 2015), have been presented to facilitate that process. However, those approaches often consider only system actions that are necessary from a functional point of view. There is no variety of system actions produced that would enable the DM to adapt to specific users characteristics or preferences. However, automatically generating variants of system actions can greatly increase the adaptability of a DM and thereby improve the user experience. Studies (e.g. (Miehle et al., 2016; Pragst et al., 2017)) have shown that elaborateness and indirectness can be useful in adaptive DM. Here, elaborateness refers to the amount of additional information provided to the user and the level of indirectness describes how concretely information is addressed by a speaker. We have proposed the automatic generation of elaborateness and indirectness in (Pragst et al., 2016). In this work, we introduce an algorithm that, given a core statement on a semantic level, automatically creates more elaborated or indirect versions of that statement by retrieving semantic content from a knowledge"
I17-1092,W03-1016,0,0.0849349,"sentences, which has been explored, among others, by Wen et al. (2015). With a similar goal, efforts towards the paraphrasing of sentences have been made (e.g. (Kozlowski et al., 2003; Langkilde and Knight, 1998)). Those approaches provide variation at the word level and preserve the semantic content of a sentence. They are complemented by our approach that focuses on variations of the semantic content of a system action. The content selection task is concerned with choosing relevant information that is to be communicated in the generated text, often with the goal of creating summaries (e.g. (Duboue and McKeown, 2003; Barzilay and Lapata, 2005)). While this research area certainly provides important insights to the generation of elaborateness, they need to be considered with respect to the peculiarities of dialogue. Instead of providing an overview over the most important information in a larger amount of data, the goal of our work is to augment an already determined piece of information with relevant further information. Hence, content selection is more concerned with filtering information, while our approach focuses on adding information. Related Work Adaptive DMs can be beneficial to the user experienc"
I17-1092,W16-5506,1,0.794544,"dapt to specific users characteristics or preferences. However, automatically generating variants of system actions can greatly increase the adaptability of a DM and thereby improve the user experience. Studies (e.g. (Miehle et al., 2016; Pragst et al., 2017)) have shown that elaborateness and indirectness can be useful in adaptive DM. Here, elaborateness refers to the amount of additional information provided to the user and the level of indirectness describes how concretely information is addressed by a speaker. We have proposed the automatic generation of elaborateness and indirectness in (Pragst et al., 2016). In this work, we introduce an algorithm that, given a core statement on a semantic level, automatically creates more elaborated or indirect versions of that statement by retrieving semantic content from a knowledge base (KB) and assessing its relevance to the original In a dialogue system, the dialogue manager selects one of several system actions and thereby determines the system’s behaviour. Defining all possible system actions in a dialogue system by hand is a tedious work. While efforts have been made to automatically generate such system actions, those approaches are mostly focused on p"
I17-1092,W15-4649,1,0.912882,"show that the results of our algorithm are mostly perceived similarly to human generated elaborateness and indirectness and can be used to adapt a conversation to the current user and situation. We also discuss where the results of our algorithm are still lacking and how this could be improved: Taking into account the conversation topic as well as the culture of the user is likely to have beneficial effect on the user’s perception. 1 Introduction In a dialogue system (DS), the dialogue manager (DM) is responsible for choosing the system’s contribution to a conversation. Several studies (e.g. (Ultes et al., 2015; Bertrand et al., 2011; 915 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 915–925, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP statement. Additionally, we ascertain that elaborateness and indirectness are suitable options for providing adaptability to the DM, and that our automatically generated system actions are mostly perceived similarly compared to human instances of elaborated and indirect statements. We further examine the circumstances under which the perception of automatically generated system actions deviates from hum"
I17-1092,D15-1199,0,0.0128131,"ction 5. Finally, we draw a conclusion in Section 6. 2 Dialogue Manager System Action Language Generation Selection of System Actions User Action Elaborateness/Indirectness Generator Core Statement Knowledge Integration Subject/Predicate/Object Related RDF Triplets Knowledge Base Figure 1: Partial architecture of the KRISTINA system, enhanced by the proposed algorithm. tences from a more structured representation. With regard to surface realisation, one characteristic of good generators is their ability to provide variation in the generated sentences, which has been explored, among others, by Wen et al. (2015). With a similar goal, efforts towards the paraphrasing of sentences have been made (e.g. (Kozlowski et al., 2003; Langkilde and Knight, 1998)). Those approaches provide variation at the word level and preserve the semantic content of a sentence. They are complemented by our approach that focuses on variations of the semantic content of a system action. The content selection task is concerned with choosing relevant information that is to be communicated in the generated text, often with the goal of creating summaries (e.g. (Duboue and McKeown, 2003; Barzilay and Lapata, 2005)). While this rese"
I17-1092,P14-1004,0,0.0151015,"13) or emotion (Andr´e et al., 2004; Gnjatovi´c and R¨osner, 2008; Pittermann and Pittermann, 2007). Komatani et al. (2005) use the amount of information presented as adaptation mechanism to the user’s knowledge and the degree of urgency. Such architectures provide the decision making process necessary for choosing the best suited system action. However, they depend on the availability of suitable system actions to perform optimally. To facilitate the process of defining system actions, efforts have been made to model dialogues automatically, e.g (Beveridge and Fox, 2006; Kadlec et al., 2015; Zhai and Williams, 2014; Niraula et al., 2014). Those approaches are mostly focused on functional system behaviour. Only system actions that are necessary to solve a task are defined, limiting the possibilities for adaptation. Our goal is to generate variants of system actions that address the same functionality, and thereby increase the adaptability. Our efforts to generate variants of system actions is paralleled by a number of tasks in the area of natural language generation. Natural language generators produce human-readable sen3 System Architecture We embed our approach to the generation of elaborateness and in"
I17-1092,C98-1112,0,\N,Missing
L18-1124,W15-1830,0,0.0609982,"Missing"
L18-1124,D11-1014,0,0.195484,"discuss related work in Section 2, before introducing our approach to the generation of DVMs in Section 3. Here, we also evaluate the validity of the generated DVMs. In Section 4, we propose potential applications for those models. Finally, we draw our conclusion in Section 5. 2. Related Work A number of different approaches to the representation of sentences in vector space have been proposed, e.g. utilising recurrent neural networks (Sutskever et al., 2014; Palangi et al., 2016), convolutional neural networks (Shen et al., 2014; Kalchbrenner et al., 2014; Hu et al., 2014) and autoencoders (Socher et al., 2011). Those approaches typically do not take into account surrounding sentences for the generation of the sentence vector, instead relying on the words in the sentence only. Tsunoo et al. (2017) implement sentence vectors with recurrent neural networks and additionally use a bidirectional Long Short-Term Memory to capture the impact of adjacent sentences. However, this additional information is not utilised to improve the vector representation of the sentence, but to model a story transition. Some machine translation approaches, such as (Zhang et al., 2014; Hermann and Blunsom, 2014), rely on mapp"
L18-1124,N15-1020,0,0.0361407,"ctors (Kiros et al., 2015) are sentence embeddings that are generated in a similar manner as word vector representations, and therefore similar to the dialogue vector models we propose. Rather than using the words in the sentence itself as basis to create a vector representation, those vectors are generated taking into account surrounding sentences. However, this representation is trained on novels rather than dialogue. In our work, we focus specifically on dialogue and its peculiarities. In the area of conversational response generation, neural network approaches are commonly utilised (e.g. (Sordoni et al., 2015)). Here, previous utterances in a conversation are used to generate a vector representation of the dialogue context that the response generation is based on. While the vector representation is based on adjacent sentences, a vector in such a model does not represent a singular utterance, but rather the entirety of the preceding utterances. Cerisara et al. (2017) investigate the usability of word2vec representations for dialogue act recognition. Similarly to our work, their goal is to determine the function of an utterance in the dialogue context. In this endeavour, they use word vectors in comb"
L18-1124,P14-1011,0,0.0248421,"014; Hu et al., 2014) and autoencoders (Socher et al., 2011). Those approaches typically do not take into account surrounding sentences for the generation of the sentence vector, instead relying on the words in the sentence only. Tsunoo et al. (2017) implement sentence vectors with recurrent neural networks and additionally use a bidirectional Long Short-Term Memory to capture the impact of adjacent sentences. However, this additional information is not utilised to improve the vector representation of the sentence, but to model a story transition. Some machine translation approaches, such as (Zhang et al., 2014; Hermann and Blunsom, 2014), rely on mapping sentences in different languages into a joint vector space. Here, the correct mapping is determined taking into account not adjacent sentences, but corresponding sentences in another language. Skip thought vectors (Kiros et al., 2015) are sentence embeddings that are generated in a similar manner as word vector representations, and therefore similar to the dialogue vector models we propose. Rather than using the words in the sentence itself as basis to create a vector representation, those vectors are generated taking into account surrounding sente"
L18-1625,W15-4603,0,0.149687,"ffer and Pennebaker, 2002; Brennan, 1996; Pickering and Garrod, 2004; Nenkova et al., 2008). Moreover, various studies suggest to adapt Spoken Dialogue Systems to the user in a similar way (Cassell and Bickmore, 2003; ForbesRiley et al., 2008; Stenchikova and Stent, 2007; Reitter et al., 2006; Mairesse and Walker, 2010). By adapting the system’s behaviour to the user, the conversation agent may appear more familiar and trustworthy and the dialogue may be more effective. Therefore, current research focuses on user-adaptive Spoken Dialogue Systems, e.g. (Honold et al., 2014; Ultes et al., 2015; Casanueva et al., 2015). Pragst et al. (2015) specifically focus on the adaptiveness of Dialogue Management to the cultural background and the emotional state of the user. Our aim is to design a Spoken Dialogue System which adapts to the user’s communication idiosyncrasies. According to various cultural models for Human-Human Interaction (Hofstede, 2009; Elliott et al., 2016; Kaplan, 1966; Lewis, 2010), different cultures prefer different communication styles. Moreover, Burleson (2003) presents a study of culture and gender differences in close relationships, emotion and interpersonal communication. Empirical resear"
L18-1625,W16-3610,1,0.419002,"cultural differences is reviewed. It is shown that social constructionist theories, like the different cultures view of gender, anticipate differences among social groups. These differences influence forms and functions of social relationships, the character of emotional experiences and the uses to which communication is put. However, it is unclear which cultural idiosyncrasies found in Human-Human Interaction may be transferred to Human-Computer Interaction as it has been shown that there exist clear differences in Human-Human Interaction and Human-Computer Interaction (Doran et al., 2003). Miehle et al. (2016) showed that communication idiosyncrasies found in Human-Human Interaction may also be observed during Human-Computer Interaction in a Spoken Dialogue System context. Moreover, cultural differences between Germany and Japan have been identified. However, not all results are consistent with the existing cultural models for Human-Human Interaction and the authors infer that the communication patterns are not only influenced by the culture, but also by the dialogue domain and other user states and traits. In order to obtain a more detailed view, the study described in the work at hand is composed"
L18-1625,P08-2043,0,0.692125,"anguage. Today, we are able to communicate with various computer applications via speech. However, the usability and acceptance of Spoken Dialogue Systems is rather low and in public opinion, such systems often fall into disrepute (Hempel, 2008). For Human-Human Interaction, it has been shown that people adapt their interaction styles to one another across many levels of utterance production when they communicate, e.g. by matching each other’s behaviour or synchronising the timing of behaviour (Burgoon et al., 2007; Niederhoffer and Pennebaker, 2002; Brennan, 1996; Pickering and Garrod, 2004; Nenkova et al., 2008). Moreover, various studies suggest to adapt Spoken Dialogue Systems to the user in a similar way (Cassell and Bickmore, 2003; ForbesRiley et al., 2008; Stenchikova and Stent, 2007; Reitter et al., 2006; Mairesse and Walker, 2010). By adapting the system’s behaviour to the user, the conversation agent may appear more familiar and trustworthy and the dialogue may be more effective. Therefore, current research focuses on user-adaptive Spoken Dialogue Systems, e.g. (Honold et al., 2014; Ultes et al., 2015; Casanueva et al., 2015). Pragst et al. (2015) specifically focus on the adaptiveness of Dia"
L18-1625,N06-2031,0,0.677405,"s often fall into disrepute (Hempel, 2008). For Human-Human Interaction, it has been shown that people adapt their interaction styles to one another across many levels of utterance production when they communicate, e.g. by matching each other’s behaviour or synchronising the timing of behaviour (Burgoon et al., 2007; Niederhoffer and Pennebaker, 2002; Brennan, 1996; Pickering and Garrod, 2004; Nenkova et al., 2008). Moreover, various studies suggest to adapt Spoken Dialogue Systems to the user in a similar way (Cassell and Bickmore, 2003; ForbesRiley et al., 2008; Stenchikova and Stent, 2007; Reitter et al., 2006; Mairesse and Walker, 2010). By adapting the system’s behaviour to the user, the conversation agent may appear more familiar and trustworthy and the dialogue may be more effective. Therefore, current research focuses on user-adaptive Spoken Dialogue Systems, e.g. (Honold et al., 2014; Ultes et al., 2015; Casanueva et al., 2015). Pragst et al. (2015) specifically focus on the adaptiveness of Dialogue Management to the cultural background and the emotional state of the user. Our aim is to design a Spoken Dialogue System which adapts to the user’s communication idiosyncrasies. According to vario"
L18-1625,2007.sigdial-1.29,0,0.809958,"n public opinion, such systems often fall into disrepute (Hempel, 2008). For Human-Human Interaction, it has been shown that people adapt their interaction styles to one another across many levels of utterance production when they communicate, e.g. by matching each other’s behaviour or synchronising the timing of behaviour (Burgoon et al., 2007; Niederhoffer and Pennebaker, 2002; Brennan, 1996; Pickering and Garrod, 2004; Nenkova et al., 2008). Moreover, various studies suggest to adapt Spoken Dialogue Systems to the user in a similar way (Cassell and Bickmore, 2003; ForbesRiley et al., 2008; Stenchikova and Stent, 2007; Reitter et al., 2006; Mairesse and Walker, 2010). By adapting the system’s behaviour to the user, the conversation agent may appear more familiar and trustworthy and the dialogue may be more effective. Therefore, current research focuses on user-adaptive Spoken Dialogue Systems, e.g. (Honold et al., 2014; Ultes et al., 2015; Casanueva et al., 2015). Pragst et al. (2015) specifically focus on the adaptiveness of Dialogue Management to the cultural background and the emotional state of the user. Our aim is to design a Spoken Dialogue System which adapts to the user’s communication idiosyncrasi"
L18-1625,W15-4649,1,0.604704,"al., 2007; Niederhoffer and Pennebaker, 2002; Brennan, 1996; Pickering and Garrod, 2004; Nenkova et al., 2008). Moreover, various studies suggest to adapt Spoken Dialogue Systems to the user in a similar way (Cassell and Bickmore, 2003; ForbesRiley et al., 2008; Stenchikova and Stent, 2007; Reitter et al., 2006; Mairesse and Walker, 2010). By adapting the system’s behaviour to the user, the conversation agent may appear more familiar and trustworthy and the dialogue may be more effective. Therefore, current research focuses on user-adaptive Spoken Dialogue Systems, e.g. (Honold et al., 2014; Ultes et al., 2015; Casanueva et al., 2015). Pragst et al. (2015) specifically focus on the adaptiveness of Dialogue Management to the cultural background and the emotional state of the user. Our aim is to design a Spoken Dialogue System which adapts to the user’s communication idiosyncrasies. According to various cultural models for Human-Human Interaction (Hofstede, 2009; Elliott et al., 2016; Kaplan, 1966; Lewis, 2010), different cultures prefer different communication styles. Moreover, Burleson (2003) presents a study of culture and gender differences in close relationships, emotion and interpersonal commun"
N13-1064,W09-3926,0,0.0705595,"Missing"
N13-1064,hara-etal-2010-estimation,0,0.482579,"he ratings ranging from 1-5 are used as target variable for statistical classifiers using a set of automatically derivable interaction parameters as input. They achieve a MR/R of 0.58. 1 MR/R is equal to Unweighted Average Recall (UAR) which is explained in Section 4. 571 2.2 User Ratings An approach presented by Engelbrecht et al. (2009) uses Hidden Markov Models (HMMs) to model the SDS as a process evolving over time. User Satisfaction was predicted at any point within the dialogue on a 5 point scale. Evaluation was performed based on labels the users applied themselves during the dialogue. Hara et al. (2010) derived turn level ratings from an overall score applied by the users after the dialogue. Using n-gram models reflecting the dialogue history, the achieved results for recognizing User Satisfaction on a 5 point scale showed to be hardly above chance. Work by Schmitt et al. (2011b) deals with determining User Satisfaction from ratings applied by the users themselves during the dialogues. A statistical classification model was trained using automatically derived interaction parameter to predict User Satisfaction for each system-user-exchange on a 5-point scale achieving an MR/R of 0.49. 3 Corpu"
N13-1064,W10-4304,0,0.100695,"complete a questionnaire after completing the dialogue. Moreover, in the PARADISE framework, only quality measurement for the whole dialogue (or system) is allowed. However, this is not suitable for using quality information for online adaption of the dialogue (cf. (Ultes et al., 2012)). Furthermore, PARADISE relies on questionnaires while we focus on work using singlevalued ratings. Numerous work on predicting User Satisfaction as a single-valued rating task for each system-userexchange has been performed in both categories. This work is briefly presented in the following. 2.1 Expert Ratings Higashinaka et al. (2010a) proposed a model to predict turn-wise ratings for human-human dialogues (transcribed conversation) and human-machine dialogues (text from chat system). Ratings ranging from 1-7 were applied by two expert raters labeling “Smoothness”, “Closeness”, and “Willingness” not achieving a Match Rate per Rating (MR/R)1 of more than 0.2-0.24. This results are only slightly above the random baseline of 0.14. Further work by Higashinaka et al. (2010b) uses ratings for overall dialogues to predict ratings for each systemuser-exchange. Again, evaluating in three user satisfaction categories “Smoothness”,"
N13-1064,W11-2020,1,0.23612,"heir expertise in the field of Human Computer Interaction or Spoken Dialogue Systems: They may be novices or have a high expertise. With experts or expert raters, we refer to people who are not participating in the dialogue thus constituting a completely different set of people. Expert raters listen to recorded dialogues after the interactions and rate them by assuming the point of view of the actual person performing the dialogue. These experts are supposed to have some experience with dialogue systems. In this work, expert raters were “advanced students of computer science and engineering” (Schmitt et al., 2011a). For User Satisfaction, ratings applied by the users seem to be clearly the better choice over ratings applied by third persons. However, determining true User Satisfaction is only possible by asking real users interacting with the system. Ideally, the ratings are applied by users talking to a system employed in the field, e.g., commercial systems, as these users have real concerns. For such Spoken Dialogue Systems, though, it is not easy to get users to apply quality ratings to the dialogue – especially for each system-userexchange. The users would have to rate either by pressing a button"
N13-1064,schmitt-etal-2012-parameterized,1,0.552417,"Missing"
N13-1064,W12-1819,1,0.363191,"ser Interfaces enabling speech communication of different complexity reaching from simple spoken commands up to complex dialogues. Besides the spoken words, the speech signal also may be used to acquire information about the user state, e.g., about their emotional state (cf., e.g., (Polzehl et al., 2011))). By additional analysis of the humancomputer-dialogues, even more abstract information may be derived, e.g., the quality of the system (cf., e.g., (Engelbrecht and M¨oller, 2010)). System quality information may be used to adapt the system’s behavior online during the ongoing dialogue (cf. (Ultes et al., 2012)). For determining the quality of Spoken Dialogue Systems, several aspects are of interest. M¨oller et al. (2009) presented a taxonomy of quality criteria. They describe quality as a bipartite issue consisting of Quality of Service (QoS) and Quality of Experience (QoE). Quality of Service describes objective criteria like dialogue duration or number of turns. While these are well-defined items that can be determined easily, Quality of Experience, which describes the user experience with subjective criteria, is more vague and without a sound definition, e.g., User Satisfaction (US). Subjective"
N13-1064,P97-1035,0,0.754825,"ows. First, we give a brief overview of work done in both categories (user ratings vs. expert ratings) in Section 2 and present our choice of data the analysis in this paper is based on in Section 3. Further, evaluation metrics are illustrated in Section 4 and approaches on facilitating prediction of user rater scores by expert rater information are presented in Section 5 followed by an evaluation and discussion of the results in Section 6. 2 Significant Related Work Predicting User Satisfaction for SDSs has been in the focus of research for many years, most famously the PARADISE framework by Walker et al. (1997). The authors assume a linear dependency between quantitative parameters derived from the dialogue and US, modeling this dependency using linear regression. Unfortunately, for generating the regression model, weighting factors have to be computed for each system anew. This generates high costs as dialogues have to be performed with real users where each user further has to complete a questionnaire after completing the dialogue. Moreover, in the PARADISE framework, only quality measurement for the whole dialogue (or system) is allowed. However, this is not suitable for using quality information"
N18-2112,W13-4035,1,0.892395,"Missing"
N18-2112,J08-4002,0,0.0337305,"ious state of the art in several dialogue domains and environments, without the need of any additional reward signal. 1 Introduction Task-oriented Spoken Dialogue Systems (SDS), in the form of personal assistants, have recently gained much attention in both academia and industry. One of the most important modules of a SDS is the Dialogue Manager (DM) (or policy), the module in charge of deciding the next action in each dialogue turn. Reinforcement Learning (RL) (Sutton and Barto, 1999) has been studied for several years as a promising approach to model dialogue management (Levin et al., 1998; Henderson et al., 2008; Pietquin et al., 2011; Young et al., 2013; Casanueva et al., 2015; Su et al., 2016). However, as the dialogue state space increases, the number of possible trajectories needed to be ex∗ Currently at PolyAI, inigo@poly-ai.com 714 Proceedings of NAACL-HLT 2018, pages 714–719 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics and a primitive action is chosen from the previously selected subset. Our model does not require any modification of the reward function and the hierarchical architecture is fully specified by the structured database representation o"
N18-2112,W14-4337,0,0.399409,"k Abstract plored grows exponentially, making traditional RL methods not scalable to large domains. Hierarchical RL (HRL), in the form of temporal abstraction, has been proposed in order to mitigate this problem (Cuay´ahuitl et al., 2010, 2016; Budzianowski et al., 2017; Peng et al., 2017). However, proposed HRL methods require that the task is defined in a hierarchical structure, which is usually handcrafted. In addition, they usually require additional rewards for each subtask. Space abstraction, instead, has been successfully applied to dialogue tasks such as Dialogue State Tracking (DST) (Henderson et al., 2014b), and policy transfer between domains (Gaˇsi´c et al., 2013, 2015; Wang et al., 2015). For DST, a set of binary classifiers can be defined for each slot, with shared parameters, learning a general way to track slots. The policy transfer method presented in (Wang et al., 2015), named Domain Independent Parametrisation (DIP), transforms the belief state into a slot-dependent fixed size representation using a handcrafted feature function. This idea could also be applied to large domains, since it can be used to learn a general way to act in any slot. In slot-filling dialogues, a HRL method that"
N18-2112,W14-4340,0,0.157148,"k Abstract plored grows exponentially, making traditional RL methods not scalable to large domains. Hierarchical RL (HRL), in the form of temporal abstraction, has been proposed in order to mitigate this problem (Cuay´ahuitl et al., 2010, 2016; Budzianowski et al., 2017; Peng et al., 2017). However, proposed HRL methods require that the task is defined in a hierarchical structure, which is usually handcrafted. In addition, they usually require additional rewards for each subtask. Space abstraction, instead, has been successfully applied to dialogue tasks such as Dialogue State Tracking (DST) (Henderson et al., 2014b), and policy transfer between domains (Gaˇsi´c et al., 2013, 2015; Wang et al., 2015). For DST, a set of binary classifiers can be defined for each slot, with shared parameters, learning a general way to track slots. The policy transfer method presented in (Wang et al., 2015), named Domain Independent Parametrisation (DIP), transforms the belief state into a slot-dependent fixed size representation using a handcrafted feature function. This idea could also be applied to large domains, since it can be used to learn a general way to act in any slot. In slot-filling dialogues, a HRL method that"
N18-2112,W17-5512,1,0.804157,"Missing"
N18-2112,D17-1237,0,0.186662,"Missing"
N18-2112,W15-4603,1,0.858699,"without the need of any additional reward signal. 1 Introduction Task-oriented Spoken Dialogue Systems (SDS), in the form of personal assistants, have recently gained much attention in both academia and industry. One of the most important modules of a SDS is the Dialogue Manager (DM) (or policy), the module in charge of deciding the next action in each dialogue turn. Reinforcement Learning (RL) (Sutton and Barto, 1999) has been studied for several years as a promising approach to model dialogue management (Levin et al., 1998; Henderson et al., 2008; Pietquin et al., 2011; Young et al., 2013; Casanueva et al., 2015; Su et al., 2016). However, as the dialogue state space increases, the number of possible trajectories needed to be ex∗ Currently at PolyAI, inigo@poly-ai.com 714 Proceedings of NAACL-HLT 2018, pages 714–719 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics and a primitive action is chosen from the previously selected subset. Our model does not require any modification of the reward function and the hierarchical architecture is fully specified by the structured database representation of the system (i.e. the ontology), requiring no additional design. 2"
N18-2112,W15-4654,1,0.930822,"domains. Hierarchical RL (HRL), in the form of temporal abstraction, has been proposed in order to mitigate this problem (Cuay´ahuitl et al., 2010, 2016; Budzianowski et al., 2017; Peng et al., 2017). However, proposed HRL methods require that the task is defined in a hierarchical structure, which is usually handcrafted. In addition, they usually require additional rewards for each subtask. Space abstraction, instead, has been successfully applied to dialogue tasks such as Dialogue State Tracking (DST) (Henderson et al., 2014b), and policy transfer between domains (Gaˇsi´c et al., 2013, 2015; Wang et al., 2015). For DST, a set of binary classifiers can be defined for each slot, with shared parameters, learning a general way to track slots. The policy transfer method presented in (Wang et al., 2015), named Domain Independent Parametrisation (DIP), transforms the belief state into a slot-dependent fixed size representation using a handcrafted feature function. This idea could also be applied to large domains, since it can be used to learn a general way to act in any slot. In slot-filling dialogues, a HRL method that relies on space abstraction, such as Feudal RL (FRL) (Dayan and Hinton, 1993), should"
P16-1230,W15-4653,1,0.73836,"Missing"
P16-1230,J11-1006,0,0.094076,"Missing"
P16-1230,P00-1013,0,0.664241,"Missing"
P16-1230,W15-4655,1,0.636188,"Missing"
P16-1230,P10-1040,0,0.0392136,"Missing"
P16-1230,W15-4649,1,0.866139,"Missing"
P16-1230,P97-1035,0,0.904945,"Missing"
P16-1230,W15-4603,0,\N,Missing
P17-4013,P17-1163,1,0.129908,"Missing"
P17-4013,P16-1230,1,0.713713,"Missing"
P17-4013,W14-4337,0,0.0162902,"odel for the CamRestaurants domain is provided. Evaluation To evaluate the dialogues, there are currently two success-based modules implemented. The objective task success evaluator compares the constraints and requests the system identifies with the true values. The latter may either be derived from the user simulator or, in real dialogues, by specifying a predefined task. For real dialogues, a subjective task success evaluator may also be applied which queries the user about the outcome of the dialogue. Belief Tracker For tracking the belief state, the rule-based focus tracker is available (Henderson et al., 2014). The implementation is domainindependent. All domain-specific information is drawn from the ontology. 4 www.apache.org/licenses/LICENSE-2.0 76 User Simulation The implementation of the simulated user uses the agenda-based user simulator (Schatzmann et al., 2006). The simulator contains the user model and an error model thus creating a n-best-list of user acts to simulate the noisy speech channel. By using a set of generally applicable parameters, the simulator may be applied for all domains. The domain-specific information is taken from the ontology. 4 training dialogues, the policies achieve"
P17-4013,N16-1015,1,0.253976,"Missing"
P17-4013,W16-3602,0,0.0466362,"ting algorithms (e.g., evaluating understanding or generation components in an interaction). Hence, to stimulate research and make it easy for people to get involved in statistical spoken dialogue systems, we present PyDial, a multi-domain statistical spoken dialogue system toolkit. PyDial is implemented in Python and is actively used by the Cambridge Dialogue Systems Group. PyDial supports multi-domain applications in which a conversation may range over a number of different topics. This introduces a variety of new research issues including generalised belief tracking (Mrkˇsi´c et al., 2015; Lee and Stent, 2016) rapid policy adaptation and parallel learning (Gaˇsi´c et al., 2015a,b) and natural language generation (Wen et al., 2016). Designing speech interfaces to machines has been a focus of research for many years. These Spoken Dialogue Systems (SDSs) are typically based on a modular architecture consisting of input processing modules speech recognition and semantic decoding, dialogue management modules belief tracking and policy, and output processing modules language generation and speech synthesis (see Fig. 1). Statistical SDS are speech interfaces where all SDS modules are based on statistical"
P17-4013,D15-1199,1,0.0538685,"Missing"
P17-4013,E17-1042,1,0.160833,"Missing"
P17-4013,P16-4012,0,0.0542417,", easy extensibility, and domain-independent implementations of the respective dialogue system modules. The toolkit is available for download under the Apache 2.0 license. Speech Synthesis Language Generation Belief State Policy et al., 2013; Wen et al., 2015; Su et al., 2016; Wen et al., 2017; Mrkˇsi´c et al., 2017). Despite the rich body of research on statistical SDS, there is still no common platform or open toolkit available. Other toolkit implementations usually focus on single modules (e.g. (Williams et al., 2010; Ultes and Minker, 2014) or are not full-blown statistical systems (e.g. (Lison and Kennington, 2016; Bohus and Rudnicky, 2009)). The availability of a toolkit targetted specifically at statistical dialogue systems would enable people new to the field would be able to get involved more easily, results to be compared more easily, and researchers to focus on their specific research questions instead of re-implementing algorithms (e.g., evaluating understanding or generation components in an interaction). Hence, to stimulate research and make it easy for people to get involved in statistical spoken dialogue systems, we present PyDial, a multi-domain statistical spoken dialogue system toolkit. P"
P17-4013,P15-2130,1,0.581038,"Missing"
schmitt-etal-2012-parameterized,W09-3950,0,\N,Missing
schmitt-etal-2012-parameterized,W11-2020,1,\N,Missing
schmitt-etal-2012-parameterized,rieser-lemon-2008-automatic,0,\N,Missing
schmitt-etal-2012-parameterized,N04-1006,0,\N,Missing
sidorov-etal-2014-comparison,batliner-etal-2004-stupid,0,\N,Missing
sidorov-etal-2014-comparison,W09-3918,1,\N,Missing
sidorov-etal-2014-comparison,schmitt-etal-2012-parameterized,1,\N,Missing
sidorov-etal-2014-comparison,vogt-andre-2006-improving,0,\N,Missing
ultes-etal-2014-first,W12-1819,1,\N,Missing
ultes-etal-2014-first,W11-2020,1,\N,Missing
ultes-etal-2014-first,schmitt-etal-2012-parameterized,1,\N,Missing
ultes-etal-2014-first,N13-1064,1,\N,Missing
W12-1819,W09-3926,0,0.166392,"Missing"
W12-1819,hara-etal-2010-estimation,0,0.128251,"adaption of the dialogue strategy to the dialogue performance requires exchange-level performance measures. Therefor, Dialogue-level approaches are of no use. Furthermore, previous presented methods for exchange-level quality measuring could not achieve satisfying accuracy in predicting dialogue quality (Engelbrecht et al., 2009; Higashinaka et al., 2010). Features serving as input variables for a classification algorithm must be automatically derivable from the dialogue system modules. This is important because other features, e.g., manually annotated dialogue acts (Higashinaka et al., 2010; Hara et al., 2010), produce high costs and are also not available immediately during run-time in order to use them as additional input to the Dialogue Manager. Furthermore, for creating a general quality metric, features have to be domain-independent, i.e., not depending on the task domain of the dialogue system. Another important issue is the consistency of the labels. Labels applied by the users themselves are subject to large fluctuations among the different users (Lindgaard and Dudek, 2003). As this results in inconsistent labels, which do not suffice for creating a generally valid quality model, ratings ap"
W12-1819,W10-4304,0,0.89034,"n Dialogue Systems. However, the issue of 2 Related Work In recent years, several studies have been published on determining the qualitative performance of a SDS. Engelbrecht et al. (2009) predicted User Satisfaction on a five-point scale at any point within the dialogue using Hidden Markov Models (HMMs). Evaluation was based on labels the users applied themselves during a Wizard-of-Oz experiment. To guarantee for comparable conditions, the dialogue flow was controlled by predefined scenarios creating transcripts with equal length for each scenario. Further work based on HMMs was presented by Higashinaka et al. (2010). The HMM was trained on US rated at each exchange. These exchange ratings were derived from ratings for the whole dialogue. The authors compare their approach with HMMs trained on manually annotated exchanges achieving a better performance for the latter. 49 NAACL-HLT 2012 Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data, pages 49–52, c Montr´eal, Canada, June 7, 2012. 2012 Association for Computational Linguistics In order to predict US, Hara et al. (2010) created n-gram models from dialogue acts (DA). Based on dialogues from real users interacting with"
W12-1819,W11-2020,1,0.73144,"om the dialogue modules they constitute the exchange level. Based on this, counts, sums, means, and frequencies of exchange level parameters from multiple exchanges are computed to constitute the dialogue level (all exchanges up to the current one) and the window level (the three previous exchanges). A corpus containing the labeled data has been published recently (Schmitt et al., in press) containing 200 calls annotated by three expert labelers, resulting in a total of 4,885 labeled exchanges. Using statistical classification of IQ based on SVMs achieves an Unweighted Average Recall of 0.58 (Schmitt et al., 2011a). 4 Quality-Adaptive Spoken Dialogue Management The goal of our work is to enable Dialogue Managers to directly adapt to information about the quality of the ongoing dialogue. We present two different approaches that outline our ongoing and future work. 4.1 Dialogue Design-Patterns for Quality Adaption Rule-based Dialogue Managers are still state-of-theart for commercial SDSs. It is hardly arguable that making the rules quality-dependent is a promising 51 way for dialogue improvement. However, the number of possibilities for adapting the dialogue strategy to the dialogue quality is high. Bas"
W12-1819,schmitt-etal-2012-parameterized,1,\N,Missing
W13-4018,W12-1819,1,0.764449,".g., on the exchange level. To overcome this issue, work by Schmitt et al. (2011) introduced a new metric for measuring the performance of an SDS on the exchange level called Interaction Quality (IQ). They used statistical classification methods to automatically derive the quality based on interaction parameters. Quality labels were applied by expert raters after the dialogue on the exchange level, i.e., for each systemuser-exchange. Automatically derived parameters were then used as features for creating a statistical classification model using static feature vectors. Based on the same data, Ultes et al. (2012a) put an emphasis on the sequential character of the IQ measure by applying temporal statistical classification using Hidden Markov Models (HMMs) and Continuous Hidden Markov Models (CHMMs). However, statistical classifiers usually do not achieve perfect performance, i.e., there will always be misclassification. While most work focuses on applying different statistical models and improving them (Section 2), learning the error to correct the result afterwards represents a different approach. Therefore, we present our approach on estimating the error of IQ recognition models to correct their hy"
W13-4018,W09-3926,0,0.327545,"Missing"
W13-4018,hara-etal-2010-estimation,0,0.168312,"level parameters Figure 1: The three different modeling levels representing the interaction at exchange en . the SDS as a process evolving over time. Performance ratings on a 5 point scale (“bad”, “poor”, “fair”, “good”, “excellent”) have been applied by the users during the dialogue. Higashinaka et al. (2010) proposed a model for predicting turn-wise ratings for human-human dialogues analyzed on a transcribed conversation and human-machine dialogues with text from a chat system. Ratings ranging from 1 to 7 were applied by two expert raters labeling for smoothness, closeness, and willingness. Hara et al. (2010) derived turn level ratings from overall ratings of the dialogue which were applied by the users afterwards on a five point scale. Using n-grams to model the dialogue, results for distinguishing between six classes at any point in the dialogue showed to be hardly above chance. 3 4 Error Estimation Model Error correction may be incorporated into the statistical classification process by a two-stage approach, which is depicted in Figure 2. At the first stage, a statistical classification model is created using interaction parameters as input and IQ as target variable. For this work, a Support Ve"
W13-4018,P97-1035,0,0.36458,"m’s performance (cf. (Ultes et al., 2012b)). In human-machine dialogues, however, there is no easy way of deriving the user’s satisfaction level. Moreover, asking real users for answering questions about the system performance requires them to spend more time talking to the machine than necessary. It can be assumed that a regular user does not want to do this as human-machine dialogues usually have no conversational character but are task oriented. Hence, automatic approaches are the preferred choice. Famous work on determining the satisfaction level automatically is the PARADISE framework by Walker et al. (1997). Assuming a linear dependency between objective measures and User Satisfaction (US), a linear regression model is applied to determine US on the dialogue level. This is not 2 Related Work on Dialogue Quality Besides Schmitt et al., other research groups have performed numerous work on predicting subjective quality measures on an exchange level, all not incorporating any form of error correction. Engelbrecht et al. (2009) presented an approach using Hidden Markov Models (HMMs) to model 122 Proceedings of the SIGDIAL 2013 Conference, pages 122–126, c Metz, France, 22-24 August 2013. 2013 Associ"
W13-4018,W11-2020,1,0.944347,"rmed numerous work on predicting subjective quality measures on an exchange level, all not incorporating any form of error correction. Engelbrecht et al. (2009) presented an approach using Hidden Markov Models (HMMs) to model 122 Proceedings of the SIGDIAL 2013 Conference, pages 122–126, c Metz, France, 22-24 August 2013. 2013 Association for Computational Linguistics e1 … en-2 en-1 en en+1 … are computed to constitute the dialogue level (all exchanges up to the current one) and the window level (the three previous exchanges). A complete list of parameters is listed in (Schmitt et al., 2012). Schmitt et al. (2011) performed IQ recognition on this data using linear SVMs. They achieved an Unweighted Average Recall (UAR) of 0.58 based on 10-fold cross-validation. Ultes et al. (2012a) applied HMMs and CHMMs using 6-fold cross validation and a reduced feature set achieving an UAR of 0.44 for HMMs and 0.39 for CHMMs. exchange level parameters window level parameters dialogue level parameters Figure 1: The three different modeling levels representing the interaction at exchange en . the SDS as a process evolving over time. Performance ratings on a 5 point scale (“bad”, “poor”, “fair”, “good”, “excellent”) hav"
W13-4018,schmitt-etal-2012-parameterized,1,0.841934,"earch groups have performed numerous work on predicting subjective quality measures on an exchange level, all not incorporating any form of error correction. Engelbrecht et al. (2009) presented an approach using Hidden Markov Models (HMMs) to model 122 Proceedings of the SIGDIAL 2013 Conference, pages 122–126, c Metz, France, 22-24 August 2013. 2013 Association for Computational Linguistics e1 … en-2 en-1 en en+1 … are computed to constitute the dialogue level (all exchanges up to the current one) and the window level (the three previous exchanges). A complete list of parameters is listed in (Schmitt et al., 2012). Schmitt et al. (2011) performed IQ recognition on this data using linear SVMs. They achieved an Unweighted Average Recall (UAR) of 0.58 based on 10-fold cross-validation. Ultes et al. (2012a) applied HMMs and CHMMs using 6-fold cross validation and a reduced feature set achieving an UAR of 0.44 for HMMs and 0.39 for CHMMs. exchange level parameters window level parameters dialogue level parameters Figure 1: The three different modeling levels representing the interaction at exchange en . the SDS as a process evolving over time. Performance ratings on a 5 point scale (“bad”, “poor”, “fair”, “"
W14-4328,W11-2020,1,0.673831,"resented in Section 6 and their results discussion in Section 7. 2 s1 u1 s2 u2 e1 e2 s3 u3 … sn un e3 en Figure 1: A dialogue may be separated into a sequence of system-user-exchanges where each exchange ei consists of a system turn si followed by a user turn ui . Significant Related Work their work about Interaction Quality (IQ) for Spoken Dialogue Systems. In contrast to user satisfaction, the labels were applied by expert annotators after the dialogue at the exchange level. Automatically derived parameters were used as features for creating a statistical model using static feature vectors. Schmitt et al. (2011) performed IQ recognition on the LEGO corpus (see Section 3) using linear SVMs. They achieved an UAR2 of 0.58 based on 10-fold cross-validation which is clearly above the random baseline of 0.2. Ultes et al. (2012a) put an emphasis on the sequential character of the IQ measure by applying a Hidden Markov Models (HMMs) and a Conditioned Hidden Markov Models (CHMMs). Both have been applied using 6-fold cross validation and a reduced feature set of the LEGO corpus achieving an UAR2 of 0.44 for HMMs and 0.39 for CHMMs. While Ultes et al. (2012a) used generic Gaussian Mixture Models to model the ob"
W14-4328,W09-3926,0,0.281798,"Missing"
W14-4328,schmitt-etal-2012-parameterized,1,0.915818,"t al. (2010) derived turn level ratings from overall ratings of the dialogue which were applied by the users after the interaction on a five point scale within an online questionnaire. Using ngrams to model the dialogue by calculating n-gram occurrence frequencies for each satisfaction value showed that results for distinguishing between six classes at any point in the dialogue to be hardly above chance. A more robust measure for user satisfaction has been presented by Schmitt et al. (2011) within 2 3 The LEGO Corpus For Interaction Quality (IQ) estimation, we use the LEGO corpus published by Schmitt et al. (2012). Interaction Quality is defined similarly to user satisfaction: While the latter represents the true disposition of the user, IQ is the disposition of the user assumed by an expert annotator. Here, expert annotators are people who listen to recorded dialogues after the interactions and rate them by assuming the point of view of the actual person performing the dialogue. These experts are supposed to have some experience with dialogue systems. In this work, expert annotators were “advanced students of computer science and engineering” (Schmitt et al., 2011), i.e., grad students. The LEGO corpu"
W14-4328,hara-etal-2010-estimation,0,0.128202,"ing) and a 6-dimensional input vector. While Engelbrecht et al. (2009) relied on only 6 input variables, we will pursue an approach with 29 input variables. Moreover, we will investigate dialogues of a real world dialogue system annotated with quality labels by expert annotators. Higashinaka et al. (2010) proposed a model for predicting turn-wise ratings for human-human dialogues. Ratings ranging from 1 to 7 were applied by two expert annotators labeling for smoothness, closeness, and willingness. They achieved an UAR2 of only 0.2-0.24 which is only slightly above the random baseline of 0.14. Hara et al. (2010) derived turn level ratings from overall ratings of the dialogue which were applied by the users after the interaction on a five point scale within an online questionnaire. Using ngrams to model the dialogue by calculating n-gram occurrence frequencies for each satisfaction value showed that results for distinguishing between six classes at any point in the dialogue to be hardly above chance. A more robust measure for user satisfaction has been presented by Schmitt et al. (2011) within 2 3 The LEGO Corpus For Interaction Quality (IQ) estimation, we use the LEGO corpus published by Schmitt et a"
W14-4328,W12-1819,1,0.829654,"abling automatically derived user satisfaction within the dialogue management allows for adaption of the ongoing dialogue (Ultes et al., 2012b). First work on deriving subjective metrics automatically has been performed by Walker et al. (1997) resulting in the PARADISE framework, which is the current quasi-standard in this field. Briefly explained, a linear dependency is assumed between dialogue parameters and user satisfaction to estimate qualitative performance on the dialogue level. Measuring the performance of complete dialogues does not allow for adapting to the user during the dialogue (Ultes et al., 2012b). Hence, performance measures which provide a measurement for each system-user-exchange1 are of interest. Approaches based on Hidden Markov Models (HMMs) are widely used for sequence modeling. Therefore, Engelbrecht et al. (2009) used these models for predicting the dialogue quality on the exchange level. Similar to this, we presented work on estimating Interaction Quality using HMMs and Conditioned HMMs (Ultes et al., 2012a). In this contribution, we investigate an approach for recognizing the dialogue quality using a hybrid Markovian model. Here, hybrid means combining statistical approach"
W14-4328,N13-1064,1,0.327902,"Missing"
W14-4328,P97-1035,0,0.802975,"Missing"
W15-4649,W12-1606,0,0.0249534,"the system” are excluded from all statistics in this paper. Three objective metrics are used to evaluate the dialogue performance: the average dialogue length (ADL), the dialogue completion rate (DCR) and task success rate (TSR). The ADL is modeled by the average number of exchanges per completed dialogue. A dialogue is regarded as being completed if the system provides a result— whether correct or not—to the user. Hence, DCR represents the ratio of dialogues for which the system was able to provide a result, i.e., provide schedule information: the user. The Let’s Go User Simulator (LGUS) by Lee and Eskenazi (2012) is used for evaluation to replace the need for human evaluators. The dialogue goal of Let’s Go consists of four slots: bus number, departure place, arrival place, and travel time. However, the bus number is not mandatory. The original system contains more than 300,000 arrival or departure places, respectively. To acquire information about the specific goal of the user, the system may use one out of nine system actions to which the user responds with a subset of six user actions. In LGUS, the user actions are accompanied with a confidence score simulating automatic speech recognition performan"
W15-4649,W09-3926,0,0.0119963,"Missing"
W15-4649,hara-etal-2010-estimation,0,0.013805,"o the user knowledge. For both, only simulated or predefined user states are used while this work uses a real estimation module deriving the user satisfaction. Using user ratings to improve the dialogue performance in a reinforcement learning (RL) approach has been presented by Walker (2000), Rieser and Lemon (2008), Janarthanam and Lemon (2008), and Gaˇsi´c et al. (2013). Walker applied RL to a MDP-based dialogue system ELVIS 2.2 Interaction Quality While there is numerous work on investigating turn-wise quality ratings for SDSs, e.g., Engelbrecht et al. (2009), Higashinaka et al. (2010) and Hara et al. (2010), the Interaction Quality paradigm by Schmitt et al. (2011) seems to be the only metric fulfilling the requirements for adapting the dialogue online (Ultes et al., 2012). For rendering an SDS adaptive to the user’s satisfaction level, a module is needed to automatically derive the satisfaction from the ongoing interaction. For creating this module, usually, dialogues have to be annotated with ratings describing the user’s satisfaction level. Schmitt et al. (2015) proposed a measure called “Interaction Quality” (IQ) which fulfills the requirements of a 375 e1 e1 e2 e2 e3 e3 … en en-2 en-1 en en"
W15-4649,P08-1073,0,0.428925,"ech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics for accessing emails over the phone. They modeled the reward function using the PARADISE framework (Walker et al., 1997) showing that the resulting policy improved the system performance in terms of user satisfaction significantly. The resulting best policy showed, among other aspects, that the system-initiative strategy was found to work best. The group of Lemon also employed PARADISE for modelling the reward function. Using reinforcement learning, they found an optimal dialogue strategy for result presentation (Rieser and Lemon, 2008) or referring expressions (Janarthanam and Lemon, 2008) for natural language generation. For a POMDP-based dialogue manager, Gaˇsi´c et al. use a reward function based on user ratings to train the optimized policy. The user ratings are acquired using Amazon Mechanical Turk. They show that their approach converges much faster than conventional approaches using a user simulator. However, their approach does not allow for adapting the course of the dialogue online but relies on a pre-optimized dialogue strategy. Finally, not directly providing user adaptivity but allowing for reacting to specific"
W15-4649,W11-2020,1,0.838042,"poken Dialogue (SDS) research. Today, commercial systems are still inflexible and do not adapt to users or the dialogue flow. This usually results in bad performance and in frequently unsuccessful dialogues. In recent years, adaptation strategies have been investigated for rendering SDS more flexible and robust. The aim of those strategies is to adapt the dialogue flow based on observations that are made during an ongoing dialogue. One approach to observe and score the interaction between the system and the user is the Interaction Quality (IQ) (Schmitt and Ultes, 2015) originally presented by Schmitt et al. (2011). Their Interaction Quality paradigm is one of the first metrics which can be used for this purpose. A pilot user study on adapting the dialogue to the Interaction Quality by Ultes et al. (2014b) in a limited 1 Automatic optimization aims at maximizing a reward function. If IQ was contributing positively to this reward function, optimisation would naturally result in an increase in IQ. As we do not perform optimization, this correlation does not automatically exist 374 Proceedings of the SIGDIAL 2015 Conference, pages 374–383, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for"
W15-4649,schmitt-etal-2012-parameterized,1,0.939853,"vel parameters are only computed out of the last three exchanges. These interaction parameters are used as input variables to a statistical classification module. The statistical model is trained based on annotated dialogues of the Lets Go Bus Information System in Pittsburgh, USA (Raux et al., 2006). Each of the 4,885 exchanges (200 calls) has been annotated by three different raters resulting in a rating agreement of κ = 0.54. The final IQ value of the three raters is derived using the median. Furthermore, the raters had to follow labeling guidelines to enable a consistent labeling process (Schmitt et al., 2012). Schmitt et al. (2011) estimated IQ with a Support Vector Machine using only automatically 2 derivable parameters achieving an unweighted average recall of 0.59. 3 Quality-Adaptive Dialogue Within this section, we describe one part of the main contribution of rendering the dialogue initiative adaptive to Interaction Quality and compare the resulting strategy to several non-adaptive strategies. Conventional dialogue initiative categories are user initiative, system initiative, and mixed initiative (McTear, 2004). As there are different interpretations of what these initiative categories mean,"
W15-4649,W12-1819,1,0.806174,"er ratings to improve the dialogue performance in a reinforcement learning (RL) approach has been presented by Walker (2000), Rieser and Lemon (2008), Janarthanam and Lemon (2008), and Gaˇsi´c et al. (2013). Walker applied RL to a MDP-based dialogue system ELVIS 2.2 Interaction Quality While there is numerous work on investigating turn-wise quality ratings for SDSs, e.g., Engelbrecht et al. (2009), Higashinaka et al. (2010) and Hara et al. (2010), the Interaction Quality paradigm by Schmitt et al. (2011) seems to be the only metric fulfilling the requirements for adapting the dialogue online (Ultes et al., 2012). For rendering an SDS adaptive to the user’s satisfaction level, a module is needed to automatically derive the satisfaction from the ongoing interaction. For creating this module, usually, dialogues have to be annotated with ratings describing the user’s satisfaction level. Schmitt et al. (2015) proposed a measure called “Interaction Quality” (IQ) which fulfills the requirements of a 375 e1 e1 e2 e2 e3 e3 … en en-2 en-1 en en+1 … exchange level parameters window level parameters: {#}, {Mean}, etc. dialogue level parameters: #, Mean, etc. Figure 1: The three different modeling levels represen"
W15-4649,N13-1064,1,0.669835,"e current exchange; the window level, capturing important parameters from the previous n dialogue steps (here n = 3); the dialogue level, measuring overall performance values from the entire previous interaction. quality metric for adaptive dialogue identified by Ultes et al. (2012). For Schmitt et al., the main aspect of user satisfaction is that it is assigned by real users. However, this seems to be impractical in many real world scenarios. Hence, the usage of expert raters is proposed. Further studies have also shown a high correlation between quality ratings applied by experts and users (Ultes et al., 2013). The IQ paradigm is based on automatically deriving interaction parameters from the SDS and feed these parameters into a statistical classification module which predicts the IQ level of the ongoing interaction at the current system-userexchange 2 . The interaction parameters are rendered on three levels (see Figure 1): the exchange level, the window level, and the dialogue level. The exchange level comprises parameters derived from SDS modules Automatic Speech Recognizer, Spoken Language Understanding, and Dialogue Management directly. Parameters on the window and the dialogue level are sums,"
W15-4649,ultes-etal-2014-first,1,0.782437,"dialogues. In recent years, adaptation strategies have been investigated for rendering SDS more flexible and robust. The aim of those strategies is to adapt the dialogue flow based on observations that are made during an ongoing dialogue. One approach to observe and score the interaction between the system and the user is the Interaction Quality (IQ) (Schmitt and Ultes, 2015) originally presented by Schmitt et al. (2011). Their Interaction Quality paradigm is one of the first metrics which can be used for this purpose. A pilot user study on adapting the dialogue to the Interaction Quality by Ultes et al. (2014b) in a limited 1 Automatic optimization aims at maximizing a reward function. If IQ was contributing positively to this reward function, optimisation would naturally result in an increase in IQ. As we do not perform optimization, this correlation does not automatically exist 374 Proceedings of the SIGDIAL 2015 Conference, pages 374–383, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics for accessing emails over the phone. They modeled the reward function using the PARADISE framework (Walker et al., 1997) showing that the resulting policy improved the"
W15-4649,P97-1035,0,0.760123,"pting the dialogue to the Interaction Quality by Ultes et al. (2014b) in a limited 1 Automatic optimization aims at maximizing a reward function. If IQ was contributing positively to this reward function, optimisation would naturally result in an increase in IQ. As we do not perform optimization, this correlation does not automatically exist 374 Proceedings of the SIGDIAL 2015 Conference, pages 374–383, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics for accessing emails over the phone. They modeled the reward function using the PARADISE framework (Walker et al., 1997) showing that the resulting policy improved the system performance in terms of user satisfaction significantly. The resulting best policy showed, among other aspects, that the system-initiative strategy was found to work best. The group of Lemon also employed PARADISE for modelling the reward function. Using reinforcement learning, they found an optimal dialogue strategy for result presentation (Rieser and Lemon, 2008) or referring expressions (Janarthanam and Lemon, 2008) for natural language generation. For a POMDP-based dialogue manager, Gaˇsi´c et al. use a reward function based on user ra"
W16-5506,W03-1601,0,0.319133,"erceived as aggressive. An example for different levels of directness is saying either ‘Take an aspirin.’ or ‘People often use aspirin when they have a headache.’ tovi´c and R¨osner, 2008; Pittermann and Pittermann, 2007), among many others, has been implemented. While such architectures provide the means to execute an adaptive dialogue strategy, they rely on predefined system actions to provide a variety of system actions for adaptation. In the area of language generation, paraphrasing is a major field of research and a lot of approaches for automating paraphrasing have been discussed, e.g. (Kozlowski et al., 2003; Langkilde and Knight, 1998). While this research addresses the generation of variations in the language output with the same semantic content, we focus on variations of the semantic content of a system action. There have been efforts to model dialogue flows automatically, e.g (Beveridge and Fox, 2006; Niraula et al., 2014; Zhai and Williams, 2014; Kadlec et al., 2015). Their focus lies on the automatic extraction of complete dialogue flows and is strictly task-oriented. While in some of those examples system actions are extracted automatically, those system actions are reproductions. Also, n"
W16-5506,P98-1116,0,0.20944,"An example for different levels of directness is saying either ‘Take an aspirin.’ or ‘People often use aspirin when they have a headache.’ tovi´c and R¨osner, 2008; Pittermann and Pittermann, 2007), among many others, has been implemented. While such architectures provide the means to execute an adaptive dialogue strategy, they rely on predefined system actions to provide a variety of system actions for adaptation. In the area of language generation, paraphrasing is a major field of research and a lot of approaches for automating paraphrasing have been discussed, e.g. (Kozlowski et al., 2003; Langkilde and Knight, 1998). While this research addresses the generation of variations in the language output with the same semantic content, we focus on variations of the semantic content of a system action. There have been efforts to model dialogue flows automatically, e.g (Beveridge and Fox, 2006; Niraula et al., 2014; Zhai and Williams, 2014; Kadlec et al., 2015). Their focus lies on the automatic extraction of complete dialogue flows and is strictly task-oriented. While in some of those examples system actions are extracted automatically, those system actions are reproductions. Also, no variants are provided as th"
W16-5506,C98-1112,0,\N,Missing
W16-5506,P14-1004,0,\N,Missing
W17-5509,W15-4603,1,0.833217,"ccessfully used: k((b, a), (b0 , a0 )) = δ(a, a0 ) · klin (b, b0 ) . (5) ! = f (rt+1 , w) + γf (Rt+1 , w) (8) must hold. This is true in case of using a linear scalarization function f (Eq. 6). To alter the kernel accordingly, a linear kernel for w is added to the state kernel1 resulting in k((b, a, w), (b0 , a0 , w0 )) (4)  = δ(a, a0 ) · klin (b, b0 ) + klin (w, w0 ) . (9) It consists of a linear kernel for the continuous belief representation b and the δ-kernel for the discrete system action a. 1 A similar type of kernel extension has been proposed previously in a different context, e.g., (Casanueva et al., 2015). 66 a suitable weight configuration, a single-objective policy may be trained. Algorithm 1: Training of the MO-GPSARSA. 1 2 3 4 5 6 7 8 Input: dialogue success reward rs , dialogue length penalty rl foreach training dialogue do select ws , wl randomly execute dialogue and record (bt , at , w) in D for each turn t // dialogue length penalty r ← wl · |D |· rl // dialogue success reward if dialogue successful then r ← r + wr · rs update GP using D and r reset D 4 The reward balancing method described in the previous section is applied to six domains: finding TVs, laptops, restaurants or hotels ("
W17-5509,P16-1230,1,0.850667,"Missing"
W17-5509,P17-4013,1,0.893124,"Missing"
W17-5509,E06-2009,0,\N,Missing
W17-5512,W11-2033,0,0.206061,"Missing"
W17-5512,P15-2130,1,0.831098,"Missing"
W17-5512,D17-1237,0,0.0557702,"ing problem and is normally tackled using reinforcement learning (RL). Many approaches to policy management over single domains have been proposed over the last years with ability to learn from scratch (Fatemi et al., 2016; Gaˇsi´c and Young, 2014; Su et al., 2016; Williams and Zweig, 2016). The goal of this work is to propose a coherent framework for a system capable of managing con86 Proceedings of the SIGDIAL 2017 Conference, pages 86–92, c Saarbr¨ucken, Germany, 15-17 August 2017. 2017 Association for Computational Linguistics logue systems to more complex scenarios. Parallel to our work, Peng et al. (2017) proposed another HRL approach, using deep Q-networks as an approximator. In separate work, we found deep Qnetworks to be unstable (Su et al., 2017); in this work, we focus on more robust estimators. The contributions of this paper are threefold. First, we adapt and validate the option framework (Sutton et al., 1999b) for a multi-domain dialogue system. Second, we demonstrate that hierarchical learning for dialogue systems works well with function approximation using the GPSARSA algorithm. We chose the Gaussian process as the function approximator as it provides uncertainty estimates which can"
W17-5512,W16-3613,0,0.0983431,"Missing"
W17-5512,W17-5518,1,0.876284,"Missing"
W17-5512,P17-4013,1,0.753335,"Missing"
W17-5512,D14-1007,0,0.0577099,"Missing"
W17-5518,W17-5512,1,0.87681,"Missing"
W17-5518,W15-4653,1,0.862045,"Missing"
W17-5518,J08-4002,0,0.733963,"ng neural networkbased dialogue models, mostly in text-based systems (Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2015; Wen et al., 2017; Bordes et al., 2017). These systems are directly trained on past dialogues without detailed specification of the internal dialogue state. However, there are two key limitations of using SL in SDS. Firstly, the effect of selecting an action on the future course of the dialogue is not considered and this may result in sub-optimal behaviour. Secondly, there will often be a large number of dialogue states which are not covered by the training data (Henderson et al., 2008; Li et al., 2014). Moreover, there is no reason to suppose that the recorded dialogue participants are acting optimally, especially in high noise levels. These problems are exacerbated in larger domains where multi-step planning is needed. In this paper, we propose a network-based approach to policy learning which combines the best of both SL- and RL-based dialogue management, and which capitalises on recent advances in deep RL (Mnih et al., 2015), especially off-policy algorithms (Wang et al., 2017). The main contribution of this paper is two-fold: 2 Related Work RL-based approaches to dialo"
W17-5518,W14-4340,1,0.82311,"-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management Pei-Hao Su, Paweł Budzianowski, Stefan Ultes, Milica Gaˇsi´c, and Steve Young Department of Engineering, University of Cambridge, Cambridge, UK {phs26, pfb30, su259, mg436, sjy11}@cam.ac.uk Abstract domain that the system can talk about. The development of a robust SDS traditionally requires a substantial amount of hand-crafted rules combined with various statistical components. This includes a spoken language understanding module (Chen et al., 2016; Yang et al., 2017), a dialogue belief state tracker (Henderson et al., 2014; Perez and Liu, 2016; Mrkˇsi´c et al., 2017) to predict user intent and track the dialogue history, a dialogue policy (Young et al., 2013; Gaˇsi´c and Young, 2014; Budzianowski et al., 2017) to determine the dialogue flow, and a natural language generator (Rieser and Lemon, 2009; Wen et al., 2015; Hu et al., 2017) to convert conceptual representations into system responses. In a task-oriented SDS, teaching a system how to respond appropriately in all situations is nontrivial. Traditionally, this dialogue management component has been designed manually using flow charts. More recently, it has"
W17-5518,P17-1163,1,0.900144,"Missing"
W17-5518,E09-1078,0,0.0608583,"k Abstract domain that the system can talk about. The development of a robust SDS traditionally requires a substantial amount of hand-crafted rules combined with various statistical components. This includes a spoken language understanding module (Chen et al., 2016; Yang et al., 2017), a dialogue belief state tracker (Henderson et al., 2014; Perez and Liu, 2016; Mrkˇsi´c et al., 2017) to predict user intent and track the dialogue history, a dialogue policy (Young et al., 2013; Gaˇsi´c and Young, 2014; Budzianowski et al., 2017) to determine the dialogue flow, and a natural language generator (Rieser and Lemon, 2009; Wen et al., 2015; Hu et al., 2017) to convert conceptual representations into system responses. In a task-oriented SDS, teaching a system how to respond appropriately in all situations is nontrivial. Traditionally, this dialogue management component has been designed manually using flow charts. More recently, it has been formulated as a planning problem and solved using reinforcement learning (RL) to optimise a dialogue policy through interaction with users (Levin and Pieraccini, 1997; Roy et al., 2000; Williams and Young, 2007; Jurˇc´ıcˇ ek et al., 2011). In this framework, the system learn"
W17-5518,P00-1013,0,0.165669,"wski et al., 2017) to determine the dialogue flow, and a natural language generator (Rieser and Lemon, 2009; Wen et al., 2015; Hu et al., 2017) to convert conceptual representations into system responses. In a task-oriented SDS, teaching a system how to respond appropriately in all situations is nontrivial. Traditionally, this dialogue management component has been designed manually using flow charts. More recently, it has been formulated as a planning problem and solved using reinforcement learning (RL) to optimise a dialogue policy through interaction with users (Levin and Pieraccini, 1997; Roy et al., 2000; Williams and Young, 2007; Jurˇc´ıcˇ ek et al., 2011). In this framework, the system learns by a trial and error process governed by a potentially delayed learning objective called the reward. This reward is designed to encapsulate the desired behavioural features of the dialogue. Typically it provides a positive reward for success plus a per turn penalty to encourage short dialogues (El Asri et al., 2014; Su et al., 2015a; Vandyke et al., 2015; Su et al., 2016b). To allow the system to be trained on-line, Bayesian sample-efficient learning algorithms have been proposed (Gaˇsi´c and Young, 20"
W17-5518,D16-1127,0,0.0506184,"cy. Better initialisation of GPRL has been studied in the context of domain adaptation by specifying a GP prior or re-using an existing model which is then pre-trained for the new domain (Gaˇsi´c et al., 2013). A number of authors have proposed training a standard neural-network policy in two stages (Fatemi et al., 2016; Su et al., 2016a; Williams et al., 2017). Asadi and Williams (2016) also explored off-policy RL methods for dialogue policy learning. All these studies were conducted in simulation, using error-free text-based input. A similar approach was also used in a conversational model (Li et al., 2016). In contrast, our work introduces two new sample-efficient actor-critic methods, combines both two-stage policy learning and off-policy RL, and testing at differing noise levels. 3 Figure 1: A2C, TRACER and eNACER architectures using feed-forward neural networks. or policy-based methods. In both cases, the goal is to find an optimal policy π ∗ that maximises the PT −1 t discounted total return R = t=0 γ rt (bt , at ) over a dialogue with T turns where rt (bt , at ) is the reward when taking action at in dialogue belief state bt at turn t and γ is the discount factor. The main difference betwe"
W17-5518,P15-1152,0,0.0430799,"Missing"
W17-5518,E17-1042,1,0.886139,"Missing"
W17-5518,D15-1199,1,0.88724,"Missing"
W17-5518,P17-1062,0,0.279183,"ptimised Gaussian kernel learned using SL from a dialogue corpus has been proposed (Chen et al., 2015). The resulting kernel was more accurate on data correlation and achieved better performance, however, the SL corpus did not help to initialise a better policy. Better initialisation of GPRL has been studied in the context of domain adaptation by specifying a GP prior or re-using an existing model which is then pre-trained for the new domain (Gaˇsi´c et al., 2013). A number of authors have proposed training a standard neural-network policy in two stages (Fatemi et al., 2016; Su et al., 2016a; Williams et al., 2017). Asadi and Williams (2016) also explored off-policy RL methods for dialogue policy learning. All these studies were conducted in simulation, using error-free text-based input. A similar approach was also used in a conversational model (Li et al., 2016). In contrast, our work introduces two new sample-efficient actor-critic methods, combines both two-stage policy learning and off-policy RL, and testing at differing noise levels. 3 Figure 1: A2C, TRACER and eNACER architectures using feed-forward neural networks. or policy-based methods. In both cases, the goal is to find an optimal policy π ∗"
W17-5518,P16-1230,1,0.846522,"Missing"
W17-5518,W15-4655,1,0.766604,"Missing"
W17-5518,P17-4013,1,0.817383,"w. Note that yt is evaluated by a target network w− which is updated less frequently than the network w to stabilise learning, and the expectation is over the tuples (bt , at , rt+1 , bt+1 ) sampled from the experience replay pool described in §3.1.2. DQN often suffers from over-estimation on Qvalues as the max operator is used to select an action as well as to evaluate it. Double DQN (DDQN) (Van Hasselt et al., 2016) is thus used to de-couple the action selection and Q-value estimation to achieve better performance. Experimental Results Our experiments utilised the software tool-kit PyDial (Ultes et al., 2017), which provides a platform for modular SDS. The target application is a live telephone-based SDS providing restaurant information for the Cambridge (UK) area. The task is to learn a policy which manages the dialogue flow and delivers requested information to the user. The domain consists of approximately 100 venues, each with 6 slots out of which 3 can be used by the system to constrain the search (food-type, area and price-range) and 3 are system-informable properties (phone-number, address and postcode) available once a database entity has been found. The input for all models was the full d"
W17-5518,W16-3613,0,\N,Missing
W17-5520,W09-3926,0,0.0879334,"Missing"
W17-5520,hara-etal-2010-estimation,0,0.06097,"Missing"
W17-5520,W10-4304,0,0.104423,"itute of Communication Engineering, Ulm University {vorname.nachname}@uni-ulm.de 2 Department of Engineering, University of Cambridge, UK su259@cam.ac.uk Abstract manually optimized, pre-computed temporal information (as employed in previous work) is no longer required. Diverse approaches for estimating the US were already proposed, including n-gram models (Hara et al., 2010) and Hidden Markov Models (Higashinaka et al., 2010a; Engelbrech et al., 2009) in different scenarios. Although the results were above the random baseline, the respective improvement was only minor. As it was discussed by Higashinaka et al. (2010b), one difficulty of this task lies in the subjective nature of US since it depends on the appreciation of the user. IQ is a more objective approach to US that relies on the rating of experts instead of users (Schmitt and Ultes, 2015) and thus closes the gap between subjective valuation and objective criteria. The respective rating is given on a scale between 1 (extremely unsatisfied) and five (satisfied) after listening to audio records of the dialogue in question. A detailed study on the correlation between the IQ and a measure of the real US was provided by Ultes et al. (2013) and various"
W17-5520,W11-2020,1,0.836784,"Missing"
W17-5520,schmitt-etal-2012-parameterized,1,0.876318,"ewed scenario. The herein employed architecture is thus built of a LSTM unit, consisting of two stacked LSTM cells, followed by a two-layer perceptron unit with sigmoid activation functions. The latter one is given as FM LP : yt → (g2 ◦ g1 )(yt ) (1) gi (yt ) = (2) sigm(WiT yt + bi ) Figure 1: Sketch of the deep learning architecture in use. The left part contains the two stacked LSTM cells followed by a softmax normalization unit. The output is fed into a two layer perceptron with sigmoid activation functions. 3 The LEGO Corpus To appropriately compare our results, we employ the LEGO coprus (Schmitt et al., 2012)—the same corpus as the authors of previous work. It is based on the ”Let’s Go Bus Information System” of the Carnegie Mellon university in Pittsburg (Raux et al., 2006) and consists of 200 dialogues including 4884 system-user exchanges. Each exchange was assigned with features from three instances of where Wi denotes the weight matrix, bi a bias vector and sigm the element-wise sigmoid function. A LSTM cell on the other hand can be seen as function f : xt , ct−1 , ht−1 → ht , ct (4) (3) 165 e1 e1 e2 e2 e3 e3 … en en-2 en-1 en en+1 … exchange level parameters window level parameters: {#}, {Mea"
W17-5520,W12-1819,1,0.751024,"Missing"
W17-5520,N13-1064,1,0.690172,"ssed by Higashinaka et al. (2010b), one difficulty of this task lies in the subjective nature of US since it depends on the appreciation of the user. IQ is a more objective approach to US that relies on the rating of experts instead of users (Schmitt and Ultes, 2015) and thus closes the gap between subjective valuation and objective criteria. The respective rating is given on a scale between 1 (extremely unsatisfied) and five (satisfied) after listening to audio records of the dialogue in question. A detailed study on the correlation between the IQ and a measure of the real US was provided by Ultes et al. (2013) and various approaches including Hidden Markov Models (Ultes et al., 2014b; Ultes and Minker, 2014), Support Vector Machines (Schmitt et al., 2011; Ultes and Minker, 2013), Ordinal Regression (El Asri et al., 2014) and Recurrent Neural Networks (Pragst et al., 2017) have been employed to estimate the IQ from exchange parameters. Although the results show a significant improvement to alternative approaches, the classification relies in each case on precomputed features modeling the dialogue history (so called temporal features). Despite the good results, using temporal features requires insigh"
W17-5520,ultes-etal-2014-first,1,0.705424,"subjective nature of US since it depends on the appreciation of the user. IQ is a more objective approach to US that relies on the rating of experts instead of users (Schmitt and Ultes, 2015) and thus closes the gap between subjective valuation and objective criteria. The respective rating is given on a scale between 1 (extremely unsatisfied) and five (satisfied) after listening to audio records of the dialogue in question. A detailed study on the correlation between the IQ and a measure of the real US was provided by Ultes et al. (2013) and various approaches including Hidden Markov Models (Ultes et al., 2014b; Ultes and Minker, 2014), Support Vector Machines (Schmitt et al., 2011; Ultes and Minker, 2013), Ordinal Regression (El Asri et al., 2014) and Recurrent Neural Networks (Pragst et al., 2017) have been employed to estimate the IQ from exchange parameters. Although the results show a significant improvement to alternative approaches, the classification relies in each case on precomputed features modeling the dialogue history (so called temporal features). Despite the good results, using temporal features requires insight into the correlations between the dialogue history and the IQ score as t"
W17-5520,W13-4018,1,0.647679,"tive approach to US that relies on the rating of experts instead of users (Schmitt and Ultes, 2015) and thus closes the gap between subjective valuation and objective criteria. The respective rating is given on a scale between 1 (extremely unsatisfied) and five (satisfied) after listening to audio records of the dialogue in question. A detailed study on the correlation between the IQ and a measure of the real US was provided by Ultes et al. (2013) and various approaches including Hidden Markov Models (Ultes et al., 2014b; Ultes and Minker, 2014), Support Vector Machines (Schmitt et al., 2011; Ultes and Minker, 2013), Ordinal Regression (El Asri et al., 2014) and Recurrent Neural Networks (Pragst et al., 2017) have been employed to estimate the IQ from exchange parameters. Although the results show a significant improvement to alternative approaches, the classification relies in each case on precomputed features modeling the dialogue history (so called temporal features). Despite the good results, using temporal features requires insight into the correlations between the dialogue history and the IQ score as the timespan covered by the temporal information significantly influences the outcome (Ultes et al."
W17-5520,W14-4328,1,0.574142,"US since it depends on the appreciation of the user. IQ is a more objective approach to US that relies on the rating of experts instead of users (Schmitt and Ultes, 2015) and thus closes the gap between subjective valuation and objective criteria. The respective rating is given on a scale between 1 (extremely unsatisfied) and five (satisfied) after listening to audio records of the dialogue in question. A detailed study on the correlation between the IQ and a measure of the real US was provided by Ultes et al. (2013) and various approaches including Hidden Markov Models (Ultes et al., 2014b; Ultes and Minker, 2014), Support Vector Machines (Schmitt et al., 2011; Ultes and Minker, 2013), Ordinal Regression (El Asri et al., 2014) and Recurrent Neural Networks (Pragst et al., 2017) have been employed to estimate the IQ from exchange parameters. Although the results show a significant improvement to alternative approaches, the classification relies in each case on precomputed features modeling the dialogue history (so called temporal features). Despite the good results, using temporal features requires insight into the correlations between the dialogue history and the IQ score as the timespan covered by the"
W17-5521,L16-1435,1,0.845456,"f Engineering, University of Cambridge, Cambridge, UK {kyusongl,tianchez,yulund,edcai,arlu,max}@cs.cmu.edu 1 {pincus, traum}@ict.usc.edu 2 {su259,lmr46,mg436,sjy11}@eng.cam.ac.uk Abstract what users might expect, given their exposure to the Amazon ECHO1 and Google HOME2 , etc. In order to get a flow of users started, DialPort developers expanded the number of connected systems to make the portal offerings more attractive and relevant. They also made the interface easier to use. By the end of March 2017, in addition to the above systems, the portal also included Mr. Clue, a word game from USC (Pincus and Traum, 2016), a restaurant opinion bot (Let’s Discuss, CMU), and a bus information system derived from Let’s Go (Raux et al., 2005). The portal offers users the option of typing or talking and of seeing an agent or just hearing it. With few connected systems in previous versions it was difficult to assess the portal’s switching mechanisms. The increased number of systems challenges the portal to make better decisions and have better a switching strategy. It also demands changes in the frequency of recommendations to connected systems. And it challenged the nature of the agent: some users prefer no visual"
W17-5521,P94-1001,1,0.116125,"the use of a visual agent, the absence of both graphical and speech response, feedback and portal behavior. Some ES need graphics to supplement their verbal information. Since Mr Clue keeps score and timing of users’ answers, its instructions and scores are shown on a blackboard. Let’s Go shows a map with the bus trajectory from departure to arrival. Feedback and communication The portal gives users feedback for: available topics, system state, and present system state. Skylar doesn’t interrupt the dialog with a list of topics. Rather 171 to the way in which they made their earlier requests (Traum and Allen, 1994). For example, the weather system should produce the natural Yes it’s going to rain instead of a full weather report, for the third question above. We thus keep the user’s initial request intent in the global dialog context and share it with the relevant ESes. The recommendation policy has been improved in two ways: 1) All participating system developers agreed that Skylar should give ES recommendations on a rotating basis so that all systems are recommended equally. Skylar no longer makes a recommendation at the end of each system turn. Recommendations are made about every four turns and, as"
W17-5521,P17-4013,1,0.820805,"atabase of restaurant reviews obtained from Zomato and Yelp. We formed a list of general discussion points for restaurants (service, atmosphere, etc). For each discussion point, a list of relevant keywords was compiled using WordNet, thesaurus, and by categorizing the most frequently words found in reviews. Cambridge The Cambridge restaurant information system helps users find a restaurant in Cambridge, UK based on the area, the price range or the food type. The current database has just over 100 restaurants and is implemented using the multi-domain statistical dialogue system toolkit PyDial (Ultes et al., 2017). To connect PyDial to Dialport, PyDial’s dialogue server interface is used. It is implemented as an HTTP server expecting JSON messages from the Dialport client. The system runs a trained dialogue policy based on the GP-SARSA algorithm (Gaˇsi´c et al., 2010). Other Systems QuBot, a chatbot from Pohang University and CMU, is used for out-of-domain handling. Let’sForecast, from CMU, uses the NOAA website. Let’s Eat from CMU is based on Yelp, finding restaurants for cities that Cambridge does not cover and for Cambridge if that system is down. Let’s Go, derived from the Let’s Go system (Raux et"
W17-5521,W10-4334,1,\N,Missing
W18-5002,L18-1124,1,0.909965,"and Scheutz (2013) address both the understanding and the generation of indirect speech acts. Their approach combines idiomatic and plan-based approaches. In plan-based approaches, a planning model that contains potential goals as well as actions with pre-and post conditions needs to be defined manually in order to anticipate the user’s plan and thereby identify the intent of an utterance. Our approach aims to eliminate the explicit preparation of the planning model, and instead relies on patterns learned from a large amount of examples. In our work, we utilise a Dialogue Vector Model (DVM) (Pragst et al., 2018) to assess whether two utterances express the same intent in a dialogue. A number of different approaches to the representation of sentences in vector space have been proposed, e.g. utilising recurrent neural networks (Sutskever et al., 2014; Palangi et al., 2016; Tsunoo et al., 2017), convolutional neural networks (Shen et al., 2014; Kalchbrenner et al., 2014; Hu et al., 2014) and autoencoders (Socher 3 Changing the Level of Directness Our work is concerned with the exchange of utterances for functionally similar ones with differing levels of directness. We define functional similarity as the"
W18-5002,D11-1014,0,0.254395,"Missing"
W18-5002,P14-1062,0,0.0167754,"identify the intent of an utterance. Our approach aims to eliminate the explicit preparation of the planning model, and instead relies on patterns learned from a large amount of examples. In our work, we utilise a Dialogue Vector Model (DVM) (Pragst et al., 2018) to assess whether two utterances express the same intent in a dialogue. A number of different approaches to the representation of sentences in vector space have been proposed, e.g. utilising recurrent neural networks (Sutskever et al., 2014; Palangi et al., 2016; Tsunoo et al., 2017), convolutional neural networks (Shen et al., 2014; Kalchbrenner et al., 2014; Hu et al., 2014) and autoencoders (Socher 3 Changing the Level of Directness Our work is concerned with the exchange of utterances for functionally similar ones with differing levels of directness. We define functional similarity as the degree to which two utterances can be used interchangeably in a dialogue as they express the same meaning. Substituting a direct/indirect utterance with its respective counterpart can be achieved by performing the following steps: 12 context or using the context to predict the utterance. The resulting vector representation groups sentences that are used in a"
W18-5002,W16-3610,1,0.844686,"and Feghali (1997), among others. Answering the question ‘How is the weather?’ with ‘Let’s rather stay inside.’ gives no concrete in11 Proceedings of the SIGDIAL 2018 Conference, pages 11–19, c Melbourne, Australia, 12-14 July 2018. 2018 Association for Computational Linguistics Current Utterance guage analysis. The second area of dialogue system that can benefit from taking into account indirectness is the language generation. Studies could show that under specific circumstances indirectness is preferred not only from human conversation partners, but also in human-computer interaction (e.g. (Miehle et al., 2016; Pragst et al., 2017)). Therefore, dialogue systems that can adjust the level of directness in their output to the user and their circumstances should be able to provide an improved user experience. If a certain level of directness is determined to be desirable with regards to the current circumstances, our algorithm can determine whether the utterance chosen as system output possesses the targeted level of directness and exchange it for a more suitable alternative if it does not. In the following, we will discuss related work, before presenting our general approach and its concrete implement"
W18-5032,T78-1013,0,0.649284,"depicted in Figure 6. Each level produces its own belief and based on that, the system is able to act on each level. On the world level, the system might produce general dialogue behaviour like greetings or engage in a dialogue to adequately identify the entity which is addressed by the user input. On the entity level, the system talks to the user to acquire information about the concrete entity the user is talking about, e.g., to find a matching entity in the knowledge base. In addition to belief tracking, we would like to introduce another concept called focus of attention. Based on work by Grosz (1978), we define the current focus of attention F for each conversational world as a subset of conversational entities in this world F ⊆ W . Hence, the task of focus tracking is to find the new set of conversational entities which is in the current focus of attention based on the user input and the updated belief state. Even though the concept of focus is not mandatory, it may be helpful when framing the reinforcement learning problem as it allows to limit the size of the input to the reinforcement learning algorithm as well as the number of actions available to the learning algorithm at a given ti"
W18-5032,W17-5512,1,0.834933,"Missing"
W18-5032,W14-4337,0,0.0129861,"he influence of the user addressing the relation instead of the correct value (e.g., ”restaurant in the same area as the hotel” vs. ”restaurant in the centre”), we have extended the simulated agenda-based user (Schatzmann and Young, 2009) with a probability r of the user addressing the relation instead of the value. The higher r, the more often the user addresses the relation. The user simulator is equipped with an additional error model to simulate the semantic error rate (SER) caused in a real system by the noisy speech channel. For belief tracking, an extended version of the focus tracker (Henderson et al., 2014)—an effective rule-based tracker—was used for the conversational entities and the conversational world that also discounts probabilities if the respective value has been rejected by the user. As a simulated interaction is on the semantic level, no semantic dewhere s is the slot, v is the value, and bi the belief of the i-th conversational entity involved in the merging process. wi = 1 − bis (∅) is the weight of the i-th conversational entity where bis (∅) represents the probability where no information about slot s has yet been shared with the system. bi either refers to the belief bo of the c"
W18-5032,W16-3602,0,0.0677983,"elation 1 (Object 1 with Object 2) area: same Object 2 (Restaurant) name: Golden House area: centre Restaurant name area food … Figure 1: A dialogue between the system (S) and a user (U) about a restaurant and a hotel in the same area along with the mapping of fractions of the dialogue to the respective objects (of predefined types) and the relation. All objects and relations reside inside a conversational world. a comprehensive and consistent way of modelling these probabilities by defining and maintaining entity-based states. Work on statistical dialogue state modelling (Young et al., 2010; Lee and Stent, 2016; Schulz et al., 2017) also contain a variant of objects but is still based on the MDDM thus not offering any mechanism to model multiple entities or relations between objects. Ramachandran and Ratnaparkhi (2015) proposed a belief tracking approach using relational trees. However, they only consider static relations present in the ontology and are not able to handle dynamic relations. mapped to an object or a relation in the conversational world or may be mapped to the world itself (grey). In the example, the first part (blue) is about Object 1 of type hotel. When the focus shifts towards Obje"
W18-5032,N18-2112,1,0.861372,"Missing"
W18-5032,D16-1127,0,0.0585474,"tical SDS are model-based approaches1 and usually assume a modular architecture (see Fig. 2). The problem of learning the next system action is framed as a partially-observable Markov decision process (POMDP) that accounts for the uncertainty inherent in spoken communication. This uncertainty is modelled in the belief state b(s) representing a probability over all states s. Reinforcement learning (RL) is used in such a sequential decision-making process where the decision-model (the policy π) is trained based on 1 Model-free approaches like end-to-end generative networks (Serban et al., 2016; Li et al., 2016) have interesting properties (e.g., they only need text data for training) but they still seem to be limited in terms of dialogue structure complexity (not linguistic complexity) in cases where content from a structured knowledge base needs to be incorporated. Approaches where incorporating this information is learned along with the system responses based on dialogue data (Eric and Manning, 2017) seem hard to scale. 274 Speech Recognition Semantic Decoding Belief State Tracking Natural Language Generation Dialogue Policy waveform around domains which encapsulate all relevant information as a s"
W18-5032,W11-2033,0,0.0319607,"g of relations, Section 5 describes a prototype implementation and shows the benefits of the CEDM in experiments with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminology that will be used in this work an"
W18-5032,W17-5506,0,0.0888807,"earning (RL) is used in such a sequential decision-making process where the decision-model (the policy π) is trained based on 1 Model-free approaches like end-to-end generative networks (Serban et al., 2016; Li et al., 2016) have interesting properties (e.g., they only need text data for training) but they still seem to be limited in terms of dialogue structure complexity (not linguistic complexity) in cases where content from a structured knowledge base needs to be incorporated. Approaches where incorporating this information is learned along with the system responses based on dialogue data (Eric and Manning, 2017) seem hard to scale. 274 Speech Recognition Semantic Decoding Belief State Tracking Natural Language Generation Dialogue Policy waveform around domains which encapsulate all relevant information as a section of the dialogue state that belongs to a given topic, e.g., finding a restaurant or hotel. However, the resulting flat state that is widely used (Williams et al., 2005; Young et al., 2010; Thomson and Young, 2010; Lee and Stent, 2016; Schulz et al., 2017, e.g.) is not intuitive to model complex dialogue structures like relations. To overcome this limitation, we propose the conversational en"
W18-5032,D17-1237,0,0.0164082,"with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminology that will be used in this work and to illustrate the necessity of adequate modelling of relations, Figure 1 shows an example dialogue about hotels and re"
W18-5032,P17-1062,0,0.0294715,"tributes that represent the same concepts like area. Note that these relations are dynamic relations that may be drawn between objects in a conversation. This is different to static relations which are often used in knowledge bases to describe how concepts relate to each other. (2) For most real-world problems, finding the exact optimal Q-values is not feasible. Instead, RL algorithms have been proposed for dialogue policy learning based on approximating the Q-function directly or employing the policy gradient theorem (Williams and Young, 2006; Daubigney et al., 2012; Gaˇsi´c and Young, 2014; Williams et al., 2017; Su et al., 2017; Casanueva et al., 2017; Papangelis and Stylianou, 2017). Aside from the policy model, the dialogue model plays an important role: it defines the structure and internal links of the dialogue state as well as the system and user acts (i.e., the semantics the system can understand). Thus, the policy model is only able to learn system behaviour based on what is defined by the dialogue model. By defining the dialogue state, the dialogue model further represents an abstraction over the task ontology or knowledge base restricting the view on the information that is relevant so that"
W18-5032,2005.sigdial-1.4,1,0.759296,"not linguistic complexity) in cases where content from a structured knowledge base needs to be incorporated. Approaches where incorporating this information is learned along with the system responses based on dialogue data (Eric and Manning, 2017) seem hard to scale. 274 Speech Recognition Semantic Decoding Belief State Tracking Natural Language Generation Dialogue Policy waveform around domains which encapsulate all relevant information as a section of the dialogue state that belongs to a given topic, e.g., finding a restaurant or hotel. However, the resulting flat state that is widely used (Williams et al., 2005; Young et al., 2010; Thomson and Young, 2010; Lee and Stent, 2016; Schulz et al., 2017, e.g.) is not intuitive to model complex dialogue structures like relations. To overcome this limitation, we propose the conversational entity dialogue model which will be described in detail in the following section. Ontology Speech Synthesis Dialogue Manager Figure 2: The modular statistical dialogue system architecture. The dialogue manager takes the semantic interpretation as input to track the belief state. The updated state is then used by the dialogue policy to decide on the next system action. 4 sam"
W18-5032,W15-4609,0,0.0231936,"estaurant and a hotel in the same area along with the mapping of fractions of the dialogue to the respective objects (of predefined types) and the relation. All objects and relations reside inside a conversational world. a comprehensive and consistent way of modelling these probabilities by defining and maintaining entity-based states. Work on statistical dialogue state modelling (Young et al., 2010; Lee and Stent, 2016; Schulz et al., 2017) also contain a variant of objects but is still based on the MDDM thus not offering any mechanism to model multiple entities or relations between objects. Ramachandran and Ratnaparkhi (2015) proposed a belief tracking approach using relational trees. However, they only consider static relations present in the ontology and are not able to handle dynamic relations. mapped to an object or a relation in the conversational world or may be mapped to the world itself (grey). In the example, the first part (blue) is about Object 1 of type hotel. When the focus shifts towards Object 2 of type restaurant (green) at U3, the user also addresses the relation (red) in the same area between Object 1 and Object 2. Addressing a relation in this way could still be captured by the semantic interpre"
W18-5032,W10-4317,0,0.00972338,"1), no context information would be available. To capture these dialogue structures, the dialogue model and the corresponding dialogue state must be able to represent them adequately. The proposed CEDM achieves this by modelling state information about conversational entities instead of domains. More precisely, it models separate states about the objects (e.g., the hotel or restaurant) and the relations. Previous work on dialogue modelling already incorporated the idea of objects or entities to be the principal component of the dialogue state (Grosz, 1977; Bilange, 1991; Montoro et al., 2004; Xu and Seneff, 2010; Heinroth and Minker, 2013). However, these dialogue models are not based on statistical dialogue processing where a probability distribution over all dialogue states needs to be modelled and maintained. This additional complexity, though, cannot be incorporated in a straight-forward way into the proposed models. In contrast, the CEDM offers 3 Statistical Spoken Dialogue Systems Statistical SDS are model-based approaches1 and usually assume a modular architecture (see Fig. 2). The problem of learning the next system action is framed as a partially-observable Markov decision process (POMDP) th"
W18-5032,W17-2626,0,0.0313453,"Missing"
W18-5032,W17-5518,1,0.884593,"g at one aspect of the CEDM, the modelling of relations, Section 5 describes a prototype implementation and shows the benefits of the CEDM in experiments with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminol"
W18-5032,P17-4013,1,0.884457,"Missing"
W18-5032,D14-1007,0,0.0314208,"s, Section 5 describes a prototype implementation and shows the benefits of the CEDM in experiments with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminology that will be used in this work and to illustrate the"
W18-5038,P17-4013,1,0.888459,"Missing"
W18-5038,W15-4654,0,0.0758487,"Cambridge, UK {ic340,pfb30,mg436}@cam.ac.uk Abstract a hierarchical RL method that divides a task spatially rather than temporally, decomposing the decisions into several steps and using different levels of abstraction for each sub-decision. When applied to domains with large state and action spaces, FDM showed an impressive performance increase compared to traditional RL policies. However, the method presented in Casanueva et al. (2018), named FDQN1 , relied on handcrafted feature functions in order to abstract the state space. These functions, named Domain Independent Parametrisation (DIP) (Wang et al., 2015), are used to transform the belief of each slot into a fixed size representation using a large set of rules. In this paper, we demonstrate that the feature functions needed to abstract the belief state in each sub-decision can be jointly learned with the policy. We introduce two methods to do it, based on feed forward neural networks and recurrent neural networks respectively. A modification of the original FDQN architecture is also introduced which stabilizes learning, avoiding overfitting of the policy to a single action. Policies with jointly learned feature functions achieve similar perfor"
W18-5038,W13-4035,1,0.88484,"Missing"
W18-5038,J08-4002,0,0.0200507,"ature functions. In this work, we show that these feature functions can be learned jointly with the policy model while obtaining similar performance, even outperforming the handcrafted features in several environments and domains. 1 Introduction In task-oriented Spoken Dialogue Systems (SDS), the Dialogue Manager (DM) (or policy) is the module in charge of deciding the next action in each dialogue turn. One of the most popular approaches to model the DM is Reinforcement Learning (RL) (Sutton and Barto, 1999), having been studied for several years (Levin et al., 1998; Williams and Young, 2007; Henderson et al., 2008; Pietquin et al., 2011; Gaˇsi´c et al., 2013; Young et al., 2013). However, as the dialogue state space increases, the number of possible trajectories needed to be explored grows exponentially, making traditional RL methods not scalable to large domains. Recently, Feudal Dialogue Management (FDM) (Casanueva et al., 2018) has shown to increase the scalability to large domains. This approach is based on Feudal RL (Dayan and Hinton, 1993), ∗ 2 Background Dialogue management can be cast as a continuous MDP (Young et al., 2013) composed of a finite set of actions A, a continuous multivariate belie"
W18-5039,K16-1002,0,0.0461717,"erates words until it outputs an end-of-sentence (eos) token. Optimization When the decoder in the CVAE is powerful on its own, it tends to ignore the latent variable z since the encoder fails to encode enough information into z. Regularization methods can be introduced in order to push the encoder towards learning a good representation of the latent variable z. Since the KL-component of the VLB does not contribute towards learning a meaningful z, increasing the weight of it gradually from 0 to 1 during training helps to encode a better representation in z. This method is termed KL-annealing (Bowman et al., 2016). In addition, inspired by (Zhao et al., 2017), we introduce a regularization method using another NN which is trained to use z to recover the condition c. The NN is split into three separate FC NNs of one layer each, which independently Semantically Conditioned VAE The structure of our model is depicted in Fig. 1, which, conditioned on an SR, generates the system’s word-level response x. An SR consists of three components: the domain, a dialogue act and a set of slot-value pairs. Slots are attributes required to appear in x (e.g. a hotel’s area). A slot can have a value. Then the two are call"
W18-5039,P04-1011,0,0.333445,"Hsiang Tseng, Florian Kreyssig, Paweł Budzianowski, ˜ Inigo Casanueva, Yen-Chen Wu, Stefan Ultes, Milica Gaˇsi´c Department of Engineering, University of Cambridge, Cambridge, UK {bht26,flk24,pfb30,ic340,ycw30,su259,mg436}@cam.ac.uk Abstract duce natural language containing the desired information. Traditionally NLG was based on templates (Cheyer and Guzzoni, 2014), which produce grammatically-correct sentences that contain all desired information. However, the lack of variation of these sentences made these systems seem tedious and monotonic. Trainable generators (Langkilde and Knight, 1998; Stent et al., 2004) can generate several sentences for the same SR, but the dependence on pre-defined operations limits their potential. Corpus-based approaches (Oh and Rudnicky, 2000; Mairesse and Walker, 2011) learn to generate natural language directly from data without pre-defined rules. However, they usually require alignment between the sentence and the SR. Recently, Wen et al. (2015b) proposed an RNN-based approach, which outperformed previous methods on several metrics. However, the generated sentences often did not include all desired attributes. The variational autoencoder (Kingma and Welling, 2013) en"
W18-5039,W15-4639,1,0.931535,"Missing"
W18-5039,N16-1015,1,0.915737,"Missing"
W18-5039,P98-1116,0,0.321055,"Spoken Dialogue Systems Bo-Hsiang Tseng, Florian Kreyssig, Paweł Budzianowski, ˜ Inigo Casanueva, Yen-Chen Wu, Stefan Ultes, Milica Gaˇsi´c Department of Engineering, University of Cambridge, Cambridge, UK {bht26,flk24,pfb30,ic340,ycw30,su259,mg436}@cam.ac.uk Abstract duce natural language containing the desired information. Traditionally NLG was based on templates (Cheyer and Guzzoni, 2014), which produce grammatically-correct sentences that contain all desired information. However, the lack of variation of these sentences made these systems seem tedious and monotonic. Trainable generators (Langkilde and Knight, 1998; Stent et al., 2004) can generate several sentences for the same SR, but the dependence on pre-defined operations limits their potential. Corpus-based approaches (Oh and Rudnicky, 2000; Mairesse and Walker, 2011) learn to generate natural language directly from data without pre-defined rules. However, they usually require alignment between the sentence and the SR. Recently, Wen et al. (2015b) proposed an RNN-based approach, which outperformed previous methods on several metrics. However, the generated sentences often did not include all desired attributes. The variational autoencoder (Kingma"
W18-5039,D15-1199,1,0.90761,"Missing"
W18-5039,J11-3002,0,0.0240783,",flk24,pfb30,ic340,ycw30,su259,mg436}@cam.ac.uk Abstract duce natural language containing the desired information. Traditionally NLG was based on templates (Cheyer and Guzzoni, 2014), which produce grammatically-correct sentences that contain all desired information. However, the lack of variation of these sentences made these systems seem tedious and monotonic. Trainable generators (Langkilde and Knight, 1998; Stent et al., 2004) can generate several sentences for the same SR, but the dependence on pre-defined operations limits their potential. Corpus-based approaches (Oh and Rudnicky, 2000; Mairesse and Walker, 2011) learn to generate natural language directly from data without pre-defined rules. However, they usually require alignment between the sentence and the SR. Recently, Wen et al. (2015b) proposed an RNN-based approach, which outperformed previous methods on several metrics. However, the generated sentences often did not include all desired attributes. The variational autoencoder (Kingma and Welling, 2013) enabled for the first time the generation of complicated, high-dimensional data such as images. The conditional variational autoencoder (CVAE) (Sohn et al., 2015), firstly proposed for image gen"
W18-5039,W00-0306,0,0.674841,"e, Cambridge, UK {bht26,flk24,pfb30,ic340,ycw30,su259,mg436}@cam.ac.uk Abstract duce natural language containing the desired information. Traditionally NLG was based on templates (Cheyer and Guzzoni, 2014), which produce grammatically-correct sentences that contain all desired information. However, the lack of variation of these sentences made these systems seem tedious and monotonic. Trainable generators (Langkilde and Knight, 1998; Stent et al., 2004) can generate several sentences for the same SR, but the dependence on pre-defined operations limits their potential. Corpus-based approaches (Oh and Rudnicky, 2000; Mairesse and Walker, 2011) learn to generate natural language directly from data without pre-defined rules. However, they usually require alignment between the sentence and the SR. Recently, Wen et al. (2015b) proposed an RNN-based approach, which outperformed previous methods on several metrics. However, the generated sentences often did not include all desired attributes. The variational autoencoder (Kingma and Welling, 2013) enabled for the first time the generation of complicated, high-dimensional data such as images. The conditional variational autoencoder (CVAE) (Sohn et al., 2015), fi"
W18-5039,P17-1061,0,0.0723263,"Missing"
W18-5039,C98-1112,0,\N,Missing
W18-5039,P17-2080,0,\N,Missing
W18-5606,P14-1062,0,0.0188464,"h the therapy can be accessed (Hansen et al., 2002). This 44 Proceedings of the 9th International Workshop on Health Text Mining and Information Analysis (LOUHI 2018), pages 44–54 c Brussels, Belgium, October 31, 2018. 2018 Association for Computational Linguistics follow represent the main contribution of this work: a CBT ontology in Section 4, a labelled dataset in Section 5, and models for language understanding in Section 6. We present the results in Section 7 and our conclusion in Section 8. 2 derstanding, sentiment analysis or dialogue belief tracking (Collobert et al., 2011; Kim, 2014; Kalchbrenner et al., 2014; Le and Mikolov, 2014a; Rojas Barahona et al., 2016; Mrkˇsi´c et al., 2017). In this work we consider understanding of mental health concepts of as a classification task. To facilitate this process, we use distributed representations. Background A dialogue system can be treated as a trainable statistical model suitable for goal-oriented information seeking dialogues (Young, 2002). In these dialogues, the user has a clear goal that he or she is trying to achieve and this involves extracting particular information from a back-end database. A structured representation of the database, the ontolo"
W18-5606,D14-1181,0,0.0106963,"Missing"
W18-5606,D16-1127,0,0.0274042,"am.ac.uk Abstract gives automated systems a huge advantage over conventional therapies, as they can be used continuously with marginal extra cost. Health assistants that can deliver therapy, have gained great interest in recent years (Bickmore et al., 2005; Fitzpatrick et al., 2017). These systems however are largely based on hand-crafted rules. On the other hand, the main research effort in statistical approaches to conversational systems has focused on limited-domain information seeking dialogues (Schatzmann et al., 2006; Geist and Pietquin, 2011; Gasic and Young, 2014; Fatemi et al., 2016; Li et al., 2016; Williams et al., 2017). In this paper we introduce a new task: understanding of mental health concepts derived from Cognitive Behavioural Therapy (CBT). We present an ontology that is formulated according to Cognitive Behavioural Therapy principles. We label a high quality mental health corpus, which exhibits targeted psychological phenomena. We use the whole unlabelled dataset to train distributed representations of words and sentences. We then investigate two approaches for classifying the user input according to the defined ontology. The first model involves a convolutional neural network"
W18-5606,W16-3613,0,0.0606818,"Missing"
W18-5606,P11-1015,0,0.193493,"Missing"
W18-5606,P17-1163,0,0.0359961,"Missing"
W18-5606,D14-1162,0,0.0844391,"Missing"
W18-5606,P17-1062,0,0.0153634,"gives automated systems a huge advantage over conventional therapies, as they can be used continuously with marginal extra cost. Health assistants that can deliver therapy, have gained great interest in recent years (Bickmore et al., 2005; Fitzpatrick et al., 2017). These systems however are largely based on hand-crafted rules. On the other hand, the main research effort in statistical approaches to conversational systems has focused on limited-domain information seeking dialogues (Schatzmann et al., 2006; Geist and Pietquin, 2011; Gasic and Young, 2014; Fatemi et al., 2016; Li et al., 2016; Williams et al., 2017). In this paper we introduce a new task: understanding of mental health concepts derived from Cognitive Behavioural Therapy (CBT). We present an ontology that is formulated according to Cognitive Behavioural Therapy principles. We label a high quality mental health corpus, which exhibits targeted psychological phenomena. We use the whole unlabelled dataset to train distributed representations of words and sentences. We then investigate two approaches for classifying the user input according to the defined ontology. The first model involves a convolutional neural network (CNN) operating over di"
W18-5606,C16-1025,1,\N,Missing
W19-5902,W17-5520,1,0.929147,"e interaction parameter levels may be learned instead by using recurrent neural networks Thus only the exchange level parameters et are considered (see Table 1) Long Short-Term Memory (LSTM) cells are at the core of the model and have originally been proposed by Hochreiter yt = softmax(lt ) (9) For estimating the interaction quality using a BiLSTM the proposed architecture frames the task as a classification problem where each sequence is labelled with one IQ value Thus for 14 Table 3: Performance of the proposed LSTM-based variants with the dialogue-wise cross-validation setup. The models by Rach et al. (2017) and Ultes et al. (2015) have been re-implemented. The BiLSTM with attention mechanism performs best in all evaluation metrics. Table 2: Performance of the proposed LSTM-based variants with the traditional cross-validation setup. Due to overlapping sub-dialogues in the train and test sets, the performance of the LSTM-based models achieve unrealistically high performance. LSTM BiLSTM LSTM+att BiLSTM+att UAR κ ρ 0.78 0.78 0.74 0.75 0.85 0.85 0.82 0.83 0.91 0.92 0.91 0.91 eA 0.99 101 0.99 100 0.99 101 0.99 93 Rach et al. (2017) 0.55 0.68 0.83 0.94 Ultes et al. (2015) 0.55 0.89 - 5 (10) (11) Exper"
W19-5902,rieser-lemon-2008-automatic,0,0.723761,"ue. This allows the reward estimator to be applicable for learning in unseen domains. The originally applied IQ estimator heavily relies on handcrafted temporal features. In this work, we will present a deep learning-based IQ estimator that utilises the capabilities of recurrent neural networks to get rid of all handcrafted fea1 The relation of US and IQ has been closely investigated in (Schmitt and Ultes, 2015; Ultes et al., 2013). 11 Proceedings of the SIGDial 2019 Conference, pages 11–20 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for Computational Linguistics Walker, 2000; Rieser and Lemon, 2008b,a) by using the PARADISE framework (Walker et al., 1997). However, PARADISE relies on the existence of explicit task success information which is usually hard to obtain. Furthermore, to derive user ratings within that framework, users have to answer a questionnaire which is usually not feasible in real world settings. To overcome this, PARADISE has been used in conjunction with expert judges instead (El Asri et al., 2012, 2013) to enable unintrusive acquisition of dialogues. However, the problem of mapping the results of the questionnaire to a scalar reward value still exists. Therefore, we"
W19-5902,P08-1073,0,0.0414634,"ue. This allows the reward estimator to be applicable for learning in unseen domains. The originally applied IQ estimator heavily relies on handcrafted temporal features. In this work, we will present a deep learning-based IQ estimator that utilises the capabilities of recurrent neural networks to get rid of all handcrafted fea1 The relation of US and IQ has been closely investigated in (Schmitt and Ultes, 2015; Ultes et al., 2013). 11 Proceedings of the SIGDial 2019 Conference, pages 11–20 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for Computational Linguistics Walker, 2000; Rieser and Lemon, 2008b,a) by using the PARADISE framework (Walker et al., 1997). However, PARADISE relies on the existence of explicit task success information which is usually hard to obtain. Furthermore, to derive user ratings within that framework, users have to answer a questionnaire which is usually not feasible in real world settings. To overcome this, PARADISE has been used in conjunction with expert judges instead (El Asri et al., 2012, 2013) to enable unintrusive acquisition of dialogues. However, the problem of mapping the results of the questionnaire to a scalar reward value still exists. Therefore, we"
W19-5902,schmitt-etal-2012-parameterized,1,0.938612,"automatic speech recognition (ASR) output and the preceding system action. Most previous approaches used this information, which is available at every turn, to compute temporal features by taking sums, means or counts from the turn-based information for a window of the last 3 system-user-exchanges2 and the complete dialogue (see Fig. 2). The baseline IQ estimation approach as applied by Ultes et al. (2017a) (and originating from Ultes et al. (2015)) used a feature set of 16 parameters as shown in Table 1 with a support vector machine (SVM) (Vapnik, 1995; Chang and Lin, 2011). The LEGO corpus (Schmitt et al., 2012) provides data for training and testing and consists of 200 dialogues (4,885 turns) from the Let’s Go bus information system (Raux et al., 2006). There, users with real needs were able to call the system to get information about the bus schedule. Each turn of these 200 dialogues has been annotated with IQ (representing the quality of the dialogue up to the current turn) by three experts. The final IQ label has been assigned using the median of the three individual labels. Previous work has used the LEGO corpus with 2 Exchange level &lt;latexit sha1_base64=&quot;Jb19Hy94NRcldwg+Pilg6BWpahc=&quot;>AAAHqHiclV"
W19-5902,W14-4337,0,0.0604675,"f-attention 15 +0.12 Table 4: Statistics of the domains the IQ reward estimator is trained on (LetsGo) and applied to (rest). 0.00 UAR +0.08 +0.06 Domain CamRestaurants CamHotels SFRestaurants SFHotels Laptops eA LSTM BiLSTM BiLSTM+att Rach et al. (2017) LSTM+att CR CH SR SH L # constraints # DB items 4 - 3 5 6 6 6 110 33 271 182 126 is very sample efficient and may even be used to learn a policy directly through real human interaction (Gaˇsi´c et al., 2013). The decisions of the policy are based on a summary space representation of the dialogue state tracker. In this work, the focus tracker (Henderson et al., 2014)—an effective rule-based tracker— is used. For each dialogue decision, the policy chooses exactly one summary action out of a set of summary actions which are based on general dialogue acts like request, confirm or inform. The exact number of system actions varies for the domains and ranges from 16 to 25. To measure the dialogue performance, the task success rate (TSR) and the average interaction quality (AIQ) are measured: the TSR represents the ratio of dialogues for which the system was able to provide the correct result. AIQ is calculated based on the estimated IQ values of the respective"
W19-5902,P16-1230,1,0.924196,"Missing"
W19-5902,P98-2219,0,0.36097,"Missing"
W19-5902,W15-4649,1,0.937247,"mator. are the distinct IQ values. The input consists of domain-independent variables called interaction parameters. These parameters incorporate information from the automatic speech recognition (ASR) output and the preceding system action. Most previous approaches used this information, which is available at every turn, to compute temporal features by taking sums, means or counts from the turn-based information for a window of the last 3 system-user-exchanges2 and the complete dialogue (see Fig. 2). The baseline IQ estimation approach as applied by Ultes et al. (2017a) (and originating from Ultes et al. (2015)) used a feature set of 16 parameters as shown in Table 1 with a support vector machine (SVM) (Vapnik, 1995; Chang and Lin, 2011). The LEGO corpus (Schmitt et al., 2012) provides data for training and testing and consists of 200 dialogues (4,885 turns) from the Let’s Go bus information system (Raux et al., 2006). There, users with real needs were able to call the system to get information about the bus schedule. Each turn of these 200 dialogues has been annotated with IQ (representing the quality of the dialogue up to the current turn) by three experts. The final IQ label has been assigned usi"
W19-5902,P97-1035,0,0.917024,"arning in unseen domains. The originally applied IQ estimator heavily relies on handcrafted temporal features. In this work, we will present a deep learning-based IQ estimator that utilises the capabilities of recurrent neural networks to get rid of all handcrafted fea1 The relation of US and IQ has been closely investigated in (Schmitt and Ultes, 2015; Ultes et al., 2013). 11 Proceedings of the SIGDial 2019 Conference, pages 11–20 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for Computational Linguistics Walker, 2000; Rieser and Lemon, 2008b,a) by using the PARADISE framework (Walker et al., 1997). However, PARADISE relies on the existence of explicit task success information which is usually hard to obtain. Furthermore, to derive user ratings within that framework, users have to answer a questionnaire which is usually not feasible in real world settings. To overcome this, PARADISE has been used in conjunction with expert judges instead (El Asri et al., 2012, 2013) to enable unintrusive acquisition of dialogues. However, the problem of mapping the results of the questionnaire to a scalar reward value still exists. Therefore, we use interaction quality (Section 3) in this work because i"
W19-5902,W13-4018,1,0.931736,"Missing"
W19-5902,W14-4328,1,0.886952,"Missing"
W19-5902,P17-4013,1,0.920792,"Missing"
W19-5902,N13-1064,1,0.915611,"r estimating the reward. The estimation model is thus based on domain-independent, interaction-related features which do not have any information available about the goal of the dialogue. This allows the reward estimator to be applicable for learning in unseen domains. The originally applied IQ estimator heavily relies on handcrafted temporal features. In this work, we will present a deep learning-based IQ estimator that utilises the capabilities of recurrent neural networks to get rid of all handcrafted fea1 The relation of US and IQ has been closely investigated in (Schmitt and Ultes, 2015; Ultes et al., 2013). 11 Proceedings of the SIGDial 2019 Conference, pages 11–20 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for Computational Linguistics Walker, 2000; Rieser and Lemon, 2008b,a) by using the PARADISE framework (Walker et al., 1997). However, PARADISE relies on the existence of explicit task success information which is usually hard to obtain. Furthermore, to derive user ratings within that framework, users have to answer a questionnaire which is usually not feasible in real world settings. To overcome this, PARADISE has been used in conjunction with expert judges instead (El Asri"
