2020.wnut-1.80,{HLTRI} at {W}-{NUT} 2020 Shared Task-3: {COVID}-19 Event Extraction from {T}witter Using Multi-Task Hopfield Pooling,2020,-1,-1,2,0,13771,maxwell weinzierl,Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020),0,"Extracting structured knowledge involving self-reported events related to the COVID-19 pandemic from Twitter has the potential to inform surveillance systems that play a critical role in public health. The event extraction challenge presented by the W-NUT 2020 Shared Task 3 focused on the identification of five types of events relevant to the COVID-19 pandemic and their respective set of pre-defined slots encoding demographic, epidemiological, clinical as well as spatial, temporal or subjective knowledge. Our participation in the challenge led to the design of a neural architecture for jointly identifying all Event Slots expressed in a tweet relevant to an event of interest. This architecture uses COVID-Twitter-BERT as the pre-trained language model. In addition, to learn text span embeddings for each Event Slot, we relied on a special case of Hopfield Networks, namely Hopfield pooling. The results of the shared task evaluation indicate that our system performs best when it is trained on a larger dataset, while it remains competitive when training on smaller datasets."
2020.lrec-1.276,The Language of Brain Signals: Natural Language Processing of Electroencephalography Reports,2020,-1,-1,2,0,17205,ramon maldonado,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Brain signals are captured by clinical electroencephalography (EEG) which is an excellent tool for probing neural function. When EEG tests are performed, a textual EEG report is generated by the neurologist to document the findings, thus using language that describes the brain signals and its clinical correlations. Even with the impetus provided by the BRAIN initiative (brainitititive.nih.gov), there are no annotations available in texts that capture language describing the brain activities and their correlations with various pathologies. In this paper we describe an annotation effort carried out on a large corpus of EEG reports, providing examples of EEG-specific and clinically relevant concepts. In addition, we detail our annotation schema for brain signal attributes. We also discuss the resulting annotation of long-distance relations between concepts in EEG reports. By exemplifying a self-attention joint-learning to predict similar annotations in the EEG report corpus, we discuss the promising results, hoping that our effort will inform the design of novel knowledge capture techniques that will include the language of brain signals."
L16-1732,Embedding Open-domain Common-sense Knowledge from Text,2016,22,0,2,1,19800,travis goodwin,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Our ability to understand language often relies on common-sense knowledge â background information the speaker can assume is known by the reader. Similarly, our comprehension of the language used in complex domains relies on access to domain-specific knowledge. Capturing common-sense and domain-specific knowledge can be achieved by taking advantage of recent advances in open information extraction (IE) techniques and, more importantly, of knowledge embeddings, which are multi-dimensional representations of concepts and relations. Building a knowledge graph for representing common-sense knowledge in which concepts discerned from noun phrases are cast as vertices and lexicalized relations are cast as edges leads to learning the embeddings of common-sense knowledge accounting for semantic compositionality as well as implied knowledge. Common-sense knowledge is acquired from a vast collection of blogs and books as well as from WordNet. Similarly, medical knowledge is learned from two large sets of electronic health records. The evaluation results of these two forms of knowledge are promising: the same knowledge acquisition methodology based on learning knowledge embeddings works well both for common-sense knowledge and for medical knowledge Interestingly, the common-sense knowledge that we have acquired was evaluated as being less neutral than than the medical knowledge, as it often reflected the opinion of the knowledge utterer. In addition, the acquired medical knowledge was evaluated as more plausible than the common-sense knowledge, reflecting the complexity of acquiring common-sense knowledge due to the pragmatics and economicity of language."
W14-3410,Structuring Operative Notes using Active Learning,2014,23,2,2,1,14570,kirk roberts,Proceedings of {B}io{NLP} 2014,0,"We present an active learning method for placing the event mentions in an operative note into a pre-specified event structure. Event mentions are first classified into action, peripheral action, observation, and report events. The actions are further classified into their appropriate location within the event structure. We examine how utilizing active learning significantly reduces the time needed to completely annotate a corpus of 2,820 appendectomy notes."
goodwin-harabagiu-2014-clinical,Clinical Data-Driven Probabilistic Graph Processing,2014,14,3,2,1,19800,travis goodwin,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Electronic Medical Records (EMRs) encode an extraordinary amount of medical knowledge. Collecting and interpreting this knowledge, however, belies a significant level of clinical understanding. Automatically capturing the clinical information is crucial for performing comparative effectiveness research. In this paper, we present a data-driven approach to model semantic dependencies between medical concepts, qualified by the beliefs of physicians. The dependencies, captured in a patient cohort graph of clinical pictures and therapies is further refined into a probabilistic graphical model which enables efficient inference of patient-centered treatment or test recommendations (based on probabilities). To perform inference on the graphical model, we describe a technique of smoothing the conditional likelihood of medical concepts by their semantically-similar belief values. The experimental results, as compared against clinical guidelines are very promising."
J14-2004,Unsupervised Event Coreference Resolution,2014,74,35,2,1,39977,cosmin bejan,Computational Linguistics,0,"The task of event coreference resolution plays a critical role in many natural language processing applications such as information extraction, question answering, and topic detection and tracking. In this article, we describe a new class of unsupervised, nonparametric Bayesian models with the purpose of probabilistically inferring coreference clusters of event mentions from a collection of unlabeled documents. In order to infer these clusters, we automatically extract various lexical, syntactic, and semantic features for each event mention from the document collection. Extracting a rich set of features for each event mention allows us to cast event coreference resolution as the task of grouping together the mentions that share the same features they have the same participating entities, share the same location, happen at the same time, etc..n n Some of the most important challenges posed by the resolution of event coreference in an unsupervised way stem from a the choice of representing event mentions through a rich set of features and b the ability of modeling events described both within the same document and across multiple documents. Our first unsupervised model that addresses these challenges is a generalization of the hierarchical Dirichlet process. This new extension presents the hierarchical Dirichlet process's ability to capture the uncertainty regarding the number of clustering components and, additionally, takes into account any finite number of features associated with each event mention. Furthermore, to overcome some of the limitations of this extension, we devised a new hybrid model, which combines an infinite latent class model with a discrete time series model. The main advantage of this hybrid model stands in its capability to automatically infer the number of features associated with each event mention from data and, at the same time, to perform an automatic selection of the most informative features for the task of event coreference. The evaluation performed for solving both within-and cross-document event coreference shows significant improvements of these models when compared against two baselines for this task."
W13-0118,The Impact of Selectional Preference Agreement on Semantic Relational Similarity,2013,25,3,2,1,35379,bryan rink,Proceedings of the 10th International Conference on Computational Semantics ({IWCS} 2013) {--} Long Papers,0,"Relational similarity is essential to analogical reasoning. Automatically determining the degree to which a pair of words belongs to a semantic relation (relational similarity) is greatly improved by considering the selectional preferences of the relation. To determine selectional preferences, we induced semantic classes through a Latent Dirichlet Allocation (LDA) method that operates on dependency parse contexts of single words. When assigning relational similarities to pairs of words, if the agreement of selectional preferences is considered alone, a correlation of 0.334 is obtained against the manual ranking outperforming the previously best reported score of 0.229."
W13-0119,Recognizing Spatial Containment Relations between Event Mentions,2013,36,11,3,1,14570,kirk roberts,Proceedings of the 10th International Conference on Computational Semantics ({IWCS} 2013) {--} Long Papers,0,"In this paper, we present an approach for recognizing spatial containment relations that hold between event mentions. Event mentions refer to real-world events that have spatio-temporal properties. While the temporal aspect of event relations has been well-studied, the spatial aspect has received relatively little attention. The difficulty in this task is the highly implicit nature of event locations in discourse. We present a supervised method that is designed to capture both explicit and implicit spatial relation information. Our approach outperforms the only known previous method by a 14 point increase in F1-measure."
S12-1055,{UTD}: Determining Relational Similarity Using Lexical Patterns,2012,12,14,2,1,35379,bryan rink,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"In this paper we present our approach for assigning degrees of relational similarity to pairs of words in the SemEval-2012 Task 2. To measure relational similarity we employed lexical patterns that can match against word pairs within a large corpus of 12 million documents. Patterns are weighted by obtaining statistically estimated lower bounds on their precision for extracting word pairs from a given relation. Finally, word pairs are ranked based on a model predicting the probability that they belong to the relation of interest. This approach achieved the best results on the SemEval 2012 Task 2, obtaining a Spearman correlation of 0.229 and an accuracy on reproducing human answers to MaxDiff questions of 39.4%."
S12-1056,{UTD}-{S}p{RL}: A Joint Approach to Spatial Role Labeling,2012,11,18,2,1,14570,kirk roberts,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"We present a joint approach for recognizing spatial roles in SemEval-2012 Task 3. Candidate spatial relations, in the form of triples, are heuristically extracted from sentences with high recall. The joint classification of spatial roles is then cast as a binary classification over the candidates. This joint approach allows for a rich feature set based on the complete relation instead of individual relation arguments. Our best official submission achieves an F1-measure of 0.573 on relation recognition, best in the task and outperforming the previous best result on the same data set (0.500)."
S12-1063,{UTDHLT}: {COPACETIC} System for Choosing Plausible Alternatives,2012,15,10,4,1,19800,travis goodwin,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"The Choice of Plausible Alternatives (COPA) task in SemEval-2012 presents a series of forced-choice questions wherein each question provides a premise and two viable cause or effect scenarios. The correct answer is the cause or effect that is the most plausible. This paper describes the COPACETIC system developed by the University of Texas at Dallas (UTD) for this task. We approach this task by casting it as a classification problem and using features derived from bigram co-occurrences, TimeML temporal links between events, single-word polarities from the Harvard General Inquirer, and causal syntactic dependency structures within the gigaword corpus. Additionally, we show that although each of these components improves our score for this evaluation, the difference in accuracy between using all of these features and using bigram co-occurrence information alone is not statistically significant."
roberts-etal-2012-empatweet,{E}mpa{T}weet: Annotating and Detecting Emotions on {T}witter,2012,14,118,5,1,14570,kirk roberts,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The rise of micro-blogging in recent years has resulted in significant access to emotion-laden text. Unlike emotion expressed in other textual sources (e.g., blogs, quotes in newswire, email, product reviews, or even clinical text), micro-blogs differ by (1) placing a strict limit on length, resulting radically in new forms of emotional expression, and (2) encouraging users to express their daily thoughts in real-time, often resulting in far more emotion statements than might normally occur. In this paper, we introduce a corpus collected from Twitter with annotated micro-blog posts (or ÂtweetsÂ) annotated at the tweet-level with seven emotions: ANGER, DISGUST, FEAR, JOY, LOVE, SADNESS, and SURPRISE. We analyze how emotions are distributed in the data we annotated and compare it to the distributions in other emotion-annotated corpora. We also used the annotated corpus to train a classifier that automatically discovers the emotions in tweets. In addition, we present an analysis of the linguistic style used for expressing emotions our corpus. We hope that these observations will lead to the design of novel emotion detection techniques that account for linguistic style and psycholinguistic theories."
roberts-etal-2012-annotating,Annotating Spatial Containment Relations Between Events,2012,16,6,3,1,14570,kirk roberts,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"A significant amount of spatial information in textual documents is hidden within the relationship between events. While humans have an intuitive understanding of these relationships that allow us to recover an object's or event's location, currently no annotated data exists to allow automatic discovery of spatial containment relations between events. We present our process for building such a corpus of manually annotated spatial relations between events. Events form complex predicate-argument structures that model the participants in the event, their roles, as well as the temporal and spatial grounding. In addition, events are not presented in isolation in text; there are explicit and implicit interactions between events that often participate in event structures. In this paper, we focus on five spatial containment relations that may exist between events: (1) SAME, (2) CONTAINS, (3) OVERLAPS, (4) NEAR, and (5) DIFFERENT. Using the transitive closure across these spatial relations, the implicit location of many events and their participants can be discovered. We discuss our annotation schema for spatial containment relations, placing it within the pre-existing theories of spatial representation. We also discuss our annotation guidelines for maintaining annotation quality as well as our process for augmenting SpatialML with spatial containment relations between events. Additionally, we outline some baseline experiments to evaluate the feasibility of developing supervised systems based on this corpus. These results indicate that although the task is challenging, automated methods are capable of discovering spatial containment relations between events."
D11-1048,A generative model for unsupervised discovery of relations and argument classes from clinical texts,2011,15,11,2,1,35379,bryan rink,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a generative model for the automatic discovery of relations between entities in electronic medical records. The model discovers relation instances and their types by determining which context tokens express the relation. Additionally, the valid semantic classes for each type of relation are determined. We show that the model produces clusters of relation trigger words which better correspond with manually annotated relations than several existing clustering techniques. The discovered relations reveal some of the implicit semantic structure present in patient records."
D11-1091,Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions,2011,18,9,2,1,14570,kirk roberts,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"Metonymic language is a pervasive phenomenon. Metonymic type shifting, or argument type coercion, results in a selectional restriction violation where the argument's semantic class differs from the class the predicate expects. In this paper we present an un-supervised method that learns the selectional restriction of arguments and enables the detection of argument coercion. This method also generates an enhanced probabilistic resolution of logical metonymies. The experimental results indicate substantial improvements the detection of coercions and the ranking of metonymic interpretations."
S10-1056,{UTDM}et: Combining {W}ord{N}et and Corpus Data for Argument Coercion Detection,2010,10,2,2,1,14570,kirk roberts,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"This paper describes our system for the classification of argument coercion for SemEval-2010 Task 7. We present two approaches to classifying an argument's semantic class, which is then compared to the predicate's expected semantic class to detect coercions. The first approach is based on learning the members of an arbitrary semantic class using WordNet's hypernymy structure. The second approach leverages automatically extracted semantic parse information from a large corpus to identify similar arguments by the predicates that select them. We show the results these approaches obtain on the task as well as how they can improve a traditional feature-based approach."
S10-1057,{UTD}: Classifying Semantic Relations by Combining Lexical and Semantic Resources,2010,5,123,2,1,35379,bryan rink,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"This paper describes our system for SemEval-2010 Task 8 on multi-way classification of semantic relations between nominals. First, the type of semantic relation is classified. Then a relation type-specific classifier determines the relation direction. Classification is performed using SVM classifiers and a number of features that capture the context, semantic role affiliation, and possible pre-existing relations of the nominals. This approach achieved an F1 score of 82.19% and an accuracy of 77.92%."
P10-1143,Unsupervised Event Coreference Resolution with Rich Linguistic Features,2010,29,90,2,1,39977,cosmin bejan,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"This paper examines how a new class of nonparametric Bayesian models can be effectively applied to an open-domain event coreference task. Designed with the purpose of clustering complex linguistic objects, these models consider a potentially infinite number of features and categorical outcomes. The evaluation performed for solving both within- and cross-document event coreference shows significant improvements of the models when compared against two baselines for this task."
hickl-harabagiu-2010-unsupervised,Unsupervised Discovery of Collective Action Frames for Socio-Cultural Analysis,2010,-1,-1,2,0.714286,46074,andrew hickl,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,None
roberts-etal-2010-linguistic,A Linguistic Resource for Semantic Parsing of Motion Events,2010,17,0,4,1,14570,kirk roberts,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents a corpus of annotated motion events and their event structure. We consider motion events triggered by a set of motion evoking words and contemplate both literal and figurative interpretations of them. Figurative motion events are extracted into the same event structure but are marked as figurative in the corpus. To represent the event structure of motion, we use the FrameNet annotation standard, which encodes motion in over 70 frames. In order to acquire a diverse set of texts that are different from FrameNet's, we crawled blog and news feeds for five different domains: sports, newswire, finance, military, and gossip. We then annotated these documents with an automatic FrameNet parser. Its output was manually corrected to account for missing and incorrect frames as well as missing and incorrect frame elements. The corpus, UTD-MotionEvent, may act as a resource for semantic parsing, detection of figurative language, spatial reasoning, and other tasks."
bejan-harabagiu-2008-linguistic,A Linguistic Resource for Discovering Event Structures and Resolving Event Coreference,2008,12,28,2,1,39977,cosmin bejan,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper, we present a linguistic resource that annotates event structures in texts. We consider an event structure as a collection of events that interact with each other in a given situation. We interpret the interactions between events as event relations. In this regard, we propose and annotate a set of six relations that best capture the concept of event structure. These relations are: subevent, reason, purpose, enablement, precedence and related. A document from this resource can encode multiple event structures and an event structure can be described across multiple documents. In order to unify event structures, we also annotate inter- and intra-document event coreference. Moreover, we provide methodologies for automatic discovery of event structures from texts. First, we group the events that constitute an event structure into event clusters and then, we use supervised learning frameworks to classify the relations that exist between events from the same cluster"
W07-1420,Textual Entailment Through Extended Lexical Overlap and Lexico-Semantic Matching,2007,8,26,4,0,48974,rod adams,Proceedings of the {ACL}-{PASCAL} Workshop on Textual Entailment and Paraphrasing,0,"This paper presents two systems for textual entailment, both employing decision trees as a supervised learning algorithm. The first one is based primarily on the concept of lexical overlap, considering a bag of words similarity overlap measure to form a mapping of terms in the hypothesis to the source text. The second system is a lexico-semantic matching between the text and the hypothesis that attempts an alignment between chunks in the hypothesis and chunks in the text, and a representation of the text and hypothesis as two dependency graphs. Their performances are compared and their positive and negative aspects are analyzed."
S07-1101,{UTD}-{HLT}-{CG}: Semantic Architecture for Metonymy Resolution and Classification of Nominal Relations,2007,10,11,3,0,46203,cristina nicolae,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"In this paper we present a semantic architecture that was employed for processing two different SemEval 2007 tasks: Task 4 (Classification of Semantic Relations between Nominals) and Task 8 (Metonymy Resolution). The architecture uses multiple forms of syntactic, lexical, and semantic information to inform a classification-based approach that generates a different model for each machine learning algorithm that implements the classification. We used decision trees, decision rules, logistic regression and lazy classifiers. A voting module selects the best performing module for each task evaluated in SemEval 2007. The paper details the results obtained when using the semantic architecture."
W06-3004,Enhanced Interactive Question-Answering with Conditional Random Fields,2006,10,7,2,1,46074,andrew hickl,Proceedings of the Interactive Question Answering Workshop at {HLT}-{NAACL} 2006,0,"This paper describes a new methodology for enhancing the quality and relevance of suggestions provided to users of interactive Q/A systems. We show that by using Conditional Random Fields to combine relevance feedback gathered from users along with information derived from discourse structure and coherence, we can accurately identify irrelevant suggestions with nearly 90% F-measure."
W06-0705,Using Scenario Knowledge in Automatic Question Answering,2006,14,2,1,1,13772,sanda harabagiu,Proceedings of the Workshop on Task-Focused Summarization and Question Answering,0,"This paper describes a novel framework for using scenario knowledge in open-domain Question Answering (Q/A) applications that uses a state-of-the-art textual entailment system (Hickl et al., 2006b) in order to discover textual information relevant to the set of topics associated with a scenario description. An intrinsic and an extrinsic evaluation of this method is presented in the context of an automatic Q/A system and results from several user scenarios are discussed."
P06-4007,{FERRET}: Interactive Question-Answering for Real-World Environments,2006,6,20,4,1,46074,andrew hickl,Proceedings of the {COLING}/{ACL} 2006 Interactive Presentation Sessions,0,"This paper describes FERRET, an interactive question-answering (Q/A) system designed to address the challenges of integrating automatic Q/A applications into real-world environments. FERRET utilizes a novel approach to Q/A - known as predictive questioning - which attempts to identify the questions (and answers) that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario."
P06-1114,Methods for Using Textual Entailment in Open-Domain Question Answering,2006,15,172,1,1,13772,sanda harabagiu,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Work on the semantics of questions has argued that the relation between a question and its answer(s) can be cast in terms of logical entailment. In this paper, we demonstrate how computational systems designed to recognize textual entailment can be used to enhance the accuracy of current open-domain automatic question answering (Q/A) systems. In our experiments, we show that when textual entailment information is used to either filter or rank answers returned by a Q/A system, accuracy can be increased by as much as 20% overall."
lacatusu-etal-2006-impact,Impact of Question Decomposition on the Quality of Answer Summaries,2006,13,20,3,1,50578,finley lacatusu,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,Generating answers to complex questions in the form of multi-document summaries requires access to question decomposition methods. In this paper we present three methods for decomposing complex questions and we evaluate their impact on the responsiveness of the answers they enable.
harabagiu-bejan-2006-answer,An Answer Bank for Temporal Inference,2006,12,11,1,1,13772,sanda harabagiu,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Answering questions that ask about temporal information involves several forms of inference. In order to develop question answering capabilities that benefit from temporal inference, we believe that a large corpus of questions and answers that are discovered based on temporal information should be available. This paper describes our methodology for creating AnswerTime-Bank, a large corpus of questions and answers on which Question Answering systems can operate using complex temporal inference."
P05-1026,Experiments with Interactive Question-Answering,2005,13,59,1,1,13772,sanda harabagiu,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"This paper describes a novel framework for interactive question-answering (Q/A) based on predictive questioning. Generated off-line from topic representations of complex scenarios, predictive questions represent requests for information that capture the most salient (and diverse) aspects of a topic. We present experimental results from large user studies (featuring a fully-implemented interactive Q/A system named FERRET) that demonstrates that surprising performance is achieved by integrating predictive questions into the context of a Q/A dialogue."
W04-2501,Strategies for Advanced Question Answering,2004,-1,-1,1,1,13772,sanda harabagiu,Proceedings of the Workshop on Pragmatics of Question Answering at {HLT}-{NAACL} 2004,0,None
W04-2502,Answering Questions Using Advanced Semantics and Probabilistic Inference,2004,-1,-1,2,0,28561,srini narayanan,Proceedings of the Workshop on Pragmatics of Question Answering at {HLT}-{NAACL} 2004,0,None
W04-2505,"Intentions, Implicatures and Processing of Complex Questions",2004,18,8,1,1,13772,sanda harabagiu,Proceedings of the Workshop on Pragmatics of Question Answering at {HLT}-{NAACL} 2004,0,In this paper we introduce two methods for deriving the intentional structure of complex questions. Techniques that enable the derivation of implied information are also presented. We show that both the intentional structure and the implicatures enabled by it are essential components of Q/A systems capable of successfully processing complex questions. The results of our evaluation support the claim that there are multiple interactions between the process of answer finding and the coercion of intentions and implicatures.
W04-2506,A Novel Approach to Focus Identification in Question/Answering Systems,2004,-1,-1,2,0,4033,alessandro moschitti,Proceedings of the Workshop on Pragmatics of Question Answering at {HLT}-{NAACL} 2004,0,None
W04-2508,Experiments with Interactive Question Answering in Complex Scenarios,2004,-1,-1,4,1,46074,andrew hickl,Proceedings of the Workshop on Pragmatics of Question Answering at {HLT}-{NAACL} 2004,0,None
W04-0819,Semantic parsing based on {F}rame{N}et,2004,6,7,5,1,39977,cosmin bejan,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"This paper describes our method based on Support Vector Machines for automatically assigning semantic roles to constituents of English sentences. This method employs four different feature sets, one of which being first reported herein. The combination of features as well as the extended training data we considered have produced in the Senseval-3 experiments an F1-score of 92.5% for the unrestricted case and of 76.3% for the restricted case."
lacatusu-etal-2004-multi,Multi-Document Summarization Using Multiple-Sequence Alignment,2004,7,2,3,1,50578,finley lacatusu,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper describes a novel clustering-based text summarization system that uses Multiple Sequence Alignment to improve the alignment of sentences within topic clusters. While most current clustering-based summarization systems base their summaries only on the common information contained in a collection of highly-related sentences, our system constructs more informative summaries that incorporate both the redundant and unique contributions of the sentences in the cluster. When evaluated using ROUGE, the summaries produced by our system represent a substantial improvement over the baseline, which is at 63{\%} of the human performance."
morarescu-harabagiu-2004-namenet,{N}ame{N}et: a Self-Improving Resource for Name Classification,2004,2,2,2,0,52296,paul morarescu,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents a semantically structured resource of more than 1,600 Name Classes. This structure is based on the noun hypernymy hierarchies in WordNet, expanded and validated by corpus evidence collected from the World Wide Web. The set of seed examples provided by WordNet is boostrapped and the used to automatically construct an annotated training corpus for each Name Class. The resulting Named Entity resource enables a supervised Named Entity Recognizer to identify all the encoded Name Classes with high accuracy and without any human intervention."
C04-1084,Incremental Topic Representations,2004,7,22,1,1,13772,sanda harabagiu,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"We consider the problem of modeling information about the topic discussed in a text. We describe in this paper two incremental enhancements of the topic signatures introduced by (Lin and Hovy, 2000). The first enhancement considers topic representations in terms of relevant topic relations instead of relevant terms. The second enhancement is based on ranking the topic themes. Topic representations are integrated in two NLP applications: Information Extraction and Multi-Document Summarization. Our experiments show that incorporating the two enhanced representations in both applications produces substantial improvements over previously-proposed topic representations that can be acquired automatically."
C04-1100,Question Answering Based on Semantic Structures,2004,23,178,2,0,28561,srini narayanan,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,The ability to answer complex questions posed in Natural Language depends on (1) the depth of the available semantic representations and (2) the inferential mechanisms they support. In this paper we describe a QA architecture where questions are analyzed and candidate answers generated by 1) identifying predicate argument structures and semantic frames from the input and 2) performing structured probabilistic inference using the extracted relations in the context of a domain and scenario model. A novel aspect of our system is a scalable and expressive representation of actions and events based on Coordinated Probabilistic Relational Models (CPRM). In this paper we report on the ability of the implemented system to perform several forms of probabilistic and temporal inferences to extract answers to complex questions. The results indicate enhanced accuracy over current state-of-the-art Q/A systems.
P03-1002,Using Predicate-Argument Structures for Information Extraction,2003,12,310,2,0,673,mihai surdeanu,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"In this paper we present a novel, customizable IE paradigm that takes advantage of predicate-argument structures. We also introduce a new way of automatically identifying predicate argument structures, which is central to our IE paradigm. It is based on: (1) an extended set of features; and (2) inductive decision tree learning. The experimental results prove our claim that accurate predicate-argument structures enable high quality IE results."
N03-1022,{COGEX}: A Logic Prover for Question Answering,2003,7,180,3,0.451984,16607,dan moldovan,Proceedings of the 2003 Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Recent TREC results have demonstrated the need for deeper text understanding methods. This paper introduces the idea of automated reasoning applied to question answering and shows the feasibility of integrating a logic prover into a Question Answering system. The approach is to transform questions and answer passages into logic representations. World knowledge axioms as well as linguistic axioms are supplied to the prover which renders a deep understanding of the relationship between question text and answer text. Moreover, the trace of the proofs provide answer justifications. The results show that the prover boosts the performance of the QA system on TREC questions by 30%."
P02-1005,Performance Issues and Error Analysis in an Open-Domain Question Answering System,2002,22,64,3,0.451984,16607,dan moldovan,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents an in-depth analysis of a state-of-the-art Question Answering system. Several scenarios are examined: (1) the performance of each module in a serial baseline system, (2) the impact of feedbacks and the insertion of a logic prover, and (3) the impact of various lexical resources. The main conclusion is that the overall performance depends on the depth of natural language processing resources and the tools used for answer finding."
harabagiu-etal-2002-multidocument,Multidocument Summarization with {GIST}exter,2002,13,16,1,1,13772,sanda harabagiu,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,This paper presents the architecture and the multidocument summarization techniques implemented in the GISTEXTER system. The paper presents an algorithm for producing incremental multi-document summaries if extraction templates of good quality are available. An empirical method of generating ad-hoc templates that can be populated with information extracted from texts by automatically acquired extraction patterns is also presented. The results of GISTEXTER in the DUC-2001 evaluations account for the advantages of using the techniques presented in this paper.
C02-1169,Open-Domain Voice-Activated Question Answering,2002,14,33,1,1,13772,sanda harabagiu,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,Voice-Activated Question Answering (VAQA) systems represent the next generation capability for universal access by integrating state-of-the-art in question answering Q&A and automatic speech recognition (ASR) in such a way that the performance of the combined system is better than the individual components. This paper presents an implemented VAQA system and describes the techniques that enable the terative refinement of both Q&A and ASR. The results of our experiments show that spoken questions can be processed with surprising accuracy when using our VAQA implementation.
W01-1206,Answer Mining from On-Line Documents,2001,10,14,2,1,20519,marius pasca,Proceedings of the {ACL} 2001 Workshop on Open-Domain Question Answering,0,"Mining the answer of a natural language open-domain question in a large collection of on-line documents is made possible by the recognition of the expected answer type in relevant text passages. If the technology of retrieving texts where the answer might be found is well developed, few studies have been devoted to the recognition of the answer type.This paper presents a unified model of answer types for open-domain Question/Answering that enables the discovery of exact answers. The evaluation of the model, performed on real-world questions, considers both the correctness and the coverage of the answer types as well as their contribution to answer precision."
P01-1037,The Role of Lexico-Semantic Feedback in Open-Domain Textual Question-Answering,2001,14,72,1,1,13772,sanda harabagiu,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents an open-domain textual Question-Answering system that uses several feedback loops to enhance its performance. These feedback loops combine in a new way statistical results with syntactic, semantic or pragmatic information derived from texts and lexical databases. The paper presents the contribution of each feedback loop to the overall performance of 76% human-assessed precise answers."
N01-1008,Text and Knowledge Mining for Coreference Resolution,2001,16,78,1,1,13772,sanda harabagiu,Second Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Traditionally coreference is resolved by satisfying a combination of salience, syntactic, semantic and discourse constraints. The acquisition of such knowledge is time-consuming, difficult and error-prone. Therefore, we present a knowledge minimalist methodology of mining coreference rules from annotated text corpora. Semantic consistency evidence, which is a form of knowledge required by coreference, is easily retrieved from WordNet. Additional consistency knowledge is discovered by a meta-bootstrapping algorithm applied to unlabeled texts."
J01-2009,Book Reviews: Advances in Information Retrieval: Recent Research from the Center for Intelligent Information Retrieval,2001,7,0,1,1,13772,sanda harabagiu,Computational Linguistics,0,None
P00-1071,The Structure and Performance of an Open-Domain Question Answering System,2000,5,152,2,0.409608,16607,dan moldovan,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents the architecture, operation and results obtained with the LASSO Question Answering system developed in the Natural Language Processing Laboratory at SMU. To find answers, the system relies on a combination of syntactic and semantic techniques. The search for the answer is based on a novel form of indexing called paragraph indexing. A score of 55.5% for short answers and 64.5% for long answers was achieved at the TREC-8 competition."
harabagiu-maiorano-2000-acquisition,Acquisition of Linguistic Patterns for Knowledge-based Information Extraction,2000,14,21,1,1,13772,sanda harabagiu,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"In this paper we present a new method of automatic acquisition of linguistic patterns for Information Extraction, as implemented in the CICERO system. Our approach combines lexico-semantic information available from the WordNet database with collocating data extracted from training corpora. Due to the open-domain nature of the WordNet information and the immediate availability of large collections of texts, our method can be easily ported to open-domain Information Extraction."
C00-1043,Experiments with Open-Domain Textual Question Answering,2000,6,155,1,1,13772,sanda harabagiu,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"This paper describes the integration of several knowledge-based natural language processing techniques into a Question Answering system, capable of mining textual answers from large collections of texts. Surprizing quality is achieved when several lightweight knowledge-based NLP techniques complement mostly shallow, surface-based approaches."
A00-1020,Multilingual Coreference Resolution,2000,19,34,1,1,13772,sanda harabagiu,Sixth Applied Natural Language Processing Conference,0,"In this paper we present a new, multilingual data-driven method for coreference resolution as implemented in the SWIZZLE system. The results obtained after training this system on a bilingual corpus of English and Romanian tagged texts, outperformed coreference resolution in each of the individual languages."
W99-0501,{W}ord{N}et 2 - A Morphologically and Semantically Enhanced Resource,1999,0,154,1,1,13772,sanda harabagiu,{SIGLEX}99: Standardizing Lexical Resources,0,None
W99-0104,Knowledge-Lean Coreference Resolution and its Relation to Textual Cohesion and Coherence,1999,0,20,1,1,13772,sanda harabagiu,The Relation of Discourse/Dialogue Structure and Reference,0,None
W98-0720,Deriving Metonymic Coercions from {W}ord{N}et,1998,10,19,1,1,13772,sanda harabagiu,Usage of {W}ord{N}et in Natural Language Processing Systems,0,"This paper presents a method for deriving metonymic coercions from the knowledge available in WordNet. Two different classes of metonymies are inferred by using (1) lexico-semantic connections between concepts or (2) morphological cues and logical formulae defining lexical concepts. In both cases the derivation of metonymic paths is based on approximations of sortal constraints retrieved from WordNet. This novel method of inferring coercions validates the related knowledge through coreference links. As a result, metonymic coercions are potentially useful for the recognition of coreferring entities in information extraction systems. 1 Problem description The pervasive phenomenon of metonymy raises a problem for the interpretation of real-world texts. Metonymies are figures of speech in which, according to the literature definition from (Lakoff and Johnson, 1990), one entity is used to refer to another, that is related to it. Characteristic of a metonymic reading of a textual expression is the fact that the satisfaction of sortal constraints guides the coercion to related knowledge. The comprehensive account of the semantics of meaning transfers presented in (Nunberg, 1995) indicates that coercions need to be embedded in a conceptual and lexico-semantic space, ideally provided by a linguistic knowledge base. Nunberg also notes that coercions are licensed by pragmatic circumstances, specifically pertaining to the Gricean principles (Grice, 1975). In this paper, we revisit the notion of metonymy and address the computational aspects of its resolution in the context of the relational semantics provided by the recently released WordNet 1.6 lexical database (www.cogsci.princeton.edu/~wn ). Following the lessons learned from the WordNetbased inference of Gricean implicatures, reported in (Harabagiu et al., 1996), a novel methodology of producing metonymic paths was devised. The coercions combine WordNet relations with st'142 mantic information derived from conceptual definitions. In WordNet (Miller, 1995) synony m words are structured in synsets, underlying a linguistic concept. Every synset is associated with a gloss, representing a textual definition, that can be translated in a logical form following the notation introduced in (Hobbs, 1986-1). This formalism, used in the implementation of TACITUS (Hobbs, 1986-2), accommodates a large variety of discourse inferences and, moreover, provides an elegant manner of localizing ambiguities, as was shown in (Bear and Hobbs, 1988). Conceptual support from linguistic knowledge bases was already considered in the implementation of several metonymy resolution systems (e.g. (Markerr and Hahn, 1997), (Fass, 1991) (Hobbs. 1986-2)), but none of these systems provided with more inferential flexibility than the typical coercion classes formulated by Lakoff (Lakoff and Johnson, 1990). We propose here a metonymy resolution approach that accounts for an open class of coercions. Similarly to Nunberg (Nunberg, 1995) and more recently to Markert and Hahn (Markert and Hahn, 1997), we find metonymy and nominal reference resolution to be two interacting processes; therefore, the proposed computational model validates metonymies through coreference links. 2 Classes of metonymic coercions Stallard proposed in (Stallard, 1993) a distinction between two kinds of metonymy: (1) referential raetonymy, in which the referent of a nominal predicate argument requires coercion and (2) predicative metonymy, featuring the coercion of the predicate usually corresponding to a verbal lexicalization. In his study, Stallard focuses on metonymic inferences required by a specific performative context, characterized by wh-questions and imperatives. His formalization of referential and predicative metonymies is based on the logical form readings of utterances from the DARPA ATIS (Air Travel Information Service) domain (MADCOW. 1992), a question-answering database about commercial air flights, comprising questions of the form:"
P96-1051,An Application of {W}ord{N}et to Prepositional Attachment,1996,3,10,1,1,13772,sanda harabagiu,34th Annual Meeting of the Association for Computational Linguistics,1,This paper presents a method for word sense disambiguation and coherence understanding of prepositional relations. The method relies on information provided by WordNet 1.5. We first classify prepositional attachments according to semantic equivalence of phrase heads and then apply inferential heuristics for understanding the validity of prepositional structures.
