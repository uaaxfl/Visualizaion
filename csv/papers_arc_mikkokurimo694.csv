2021.nodalida-main.9,Speaker Verification Experiments for Adults and Children Using Shared Embedding Spaces,2021,-1,-1,4,0,2632,tuomas kaseva,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"For children, the system trained on a large corpus of adult speakers performed worse than a system trained on a much smaller corpus of children{'}s speech. This is due to the acoustic mismatch between training and testing data. To capture more acoustic variability we trained a shared system with mixed data from adults and children. The shared system yields the best EER for children with no degradation for adults. Thus, the single system trained with mixed data is applicable for speaker verification for both adults and children."
2021.nodalida-main.10,Spectral modification for recognition of children{'}s speech undermismatched conditions,2021,-1,-1,4,0,2633,hemant kathania,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"In this paper, we propose spectral modification by sharpening formants and by reducing the spectral tilt to recognize children{'}s speech by automatic speech recognition (ASR) systems developed using adult speech. In this type of mismatched condition, the ASR performance is degraded due to the acoustic and linguistic mismatch in the attributes between children and adult speakers. The proposed method is used to improve the speech intelligibility to enhance the children{'}s speech recognition using an acoustic model trained on adult speech. In the experiments, WSJCAM0 and PFSTAR are used as databases for adults{'} and children{'}s speech, respectively. The proposed technique gives a significant improvement in the context of the DNN-HMM-based ASR. Furthermore, we validate the robustness of the technique by showing that it performs well also in mismatched noise conditions."
2021.nodalida-main.36,Grapheme-Based Cross-Language Forced Alignment: Results with Uralic Languages,2021,-1,-1,3,1,2695,juho leinonen,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"Forced alignment is an effective process to speed up linguistic research. However, most forced aligners are language-dependent, and under-resourced languages rarely have enough resources to train an acoustic model for an aligner. We present a new Finnish grapheme-based forced aligner and demonstrate its performance by aligning multiple Uralic languages and English as an unrelated language. We show that even a simple non-expert created grapheme-to-phoneme mapping can result in useful word alignments."
2020.wnut-1.16,Service registration chatbot: collecting and comparing dialogues from {AMT} workers and service{'}s users,2020,-1,-1,5,0,13676,luca molteni,Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020),0,"Crowdsourcing is the go-to solution for data collection and annotation in the context of NLP tasks. Nevertheless, crowdsourced data is noisy by nature; the source is often unknown and additional validation work is performed to guarantee the dataset{'}s quality. In this article, we compare two crowdsourcing sources on a dialogue paraphrasing task revolving around a chatbot service. We observe that workers hired on crowdsourcing platforms produce lexically poorer and less diverse rewrites than service users engaged voluntarily. Notably enough, on dialogue clarity and optimality, the two paraphrase sources{'} human-perceived quality does not differ significantly. Furthermore, for the chatbot service, the combined crowdsourced data is enough to train a transformer-based Natural Language Generation (NLG) system. To enable similar services, we also release tools for collecting data and training the dialogue-act-based transformer-based NLG module."
2020.textgraphs-1.8,Graph-based Syntactic Word Embeddings,2020,-1,-1,2,0,14384,ragheb alghezi,Proceedings of the Graph-based Methods for Natural Language Processing (TextGraphs),0,"We propose a simple and efficient framework to learn syntactic embeddings based on information derived from constituency parse trees. Using biased random walk methods, our embeddings not only encode syntactic information about words, but they also capture contextual information. We also propose a method to train the embeddings on multiple constituency parse trees to ensure the encoding of global syntactic representation. Quantitative evaluation of the embeddings show a competitive performance on POS tagging task when compared to other types of embeddings, and qualitative evaluation reveals interesting facts about the syntactic typology learned by these embeddings."
2020.sltu-1.6,Effects of Language Relatedness for Cross-lingual Transfer Learning in Character-Based Language Models,2020,-1,-1,4,0,13677,mittul singh,Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL),0,"Character-based Neural Network Language Models (NNLM) have the advantage of smaller vocabulary and thus faster training times in comparison to NNLMs based on multi-character units. However, in low-resource scenarios, both the character and multi-character NNLMs suffer from data sparsity. In such scenarios, cross-lingual transfer has improved multi-character NNLM performance by allowing information transfer from a source to the target language. In the same vein, we propose to use cross-lingual transfer for character NNLMs applied to low-resource Automatic Speech Recognition (ASR). However, applying cross-lingual transfer to character NNLMs is not as straightforward. We observe that relatedness of the source language plays an important role in cross-lingual pretraining of character NNLMs. We evaluate this aspect on ASR tasks for two target languages: Finnish (with English and Estonian as source) and Swedish (with Danish, Norwegian, and English as source). Prior work has observed no difference between using the related or unrelated language for multi-character NNLMs. We, however, show that for character-based NNLMs, only pretraining with a related language improves the ASR performance, and using an unrelated language may deteriorate it. We also observe that the benefits are larger when there is much lesser target data than source data."
2020.lrec-1.486,{M}orfessor {EM}+{P}rune: Improved Subword Segmentation with Expectation Maximization and Pruning,2020,0,1,3,1,13980,stigarne gronroos,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Data-driven segmentation of words into subword units has been used in various natural language processing applications such as automatic speech recognition and statistical machine translation for almost 20 years. Recently it has became more widely adopted, as models based on deep neural networks often benefit from subword units even for morphologically simpler languages. In this paper, we discuss and compare training algorithms for a unigram subword model, based on the Expectation Maximization algorithm and lexicon pruning. Using English, Finnish, North Sami, and Turkish data sets, we show that this approach is able to find better solutions to the optimization problem defined by the Morfessor Baseline model than its original recursive training algorithm. The improved optimization also leads to higher morphological segmentation accuracy when compared to a linguistic gold standard. We publish implementations of the new algorithms in the widely-used Morfessor software package."
W19-1701,A user study to compare two conversational assistants designed for people with hearing impairments,2019,-1,-1,4,0,24793,anja virkkunen,Proceedings of the Eighth Workshop on Speech and Language Processing for Assistive Technologies,0,"Participating in conversations can be difficult for people with hearing loss, especially in acoustically challenging environments. We studied the preferences the hearing impaired have for a personal conversation assistant based on automatic speech recognition (ASR) technology. We created two prototypes which were evaluated by hearing impaired test users. This paper qualitatively compares the two based on the feedback obtained from the tests. The first prototype was a proof-of-concept system running real-time ASR on a laptop. The second prototype was developed for a mobile device with the recognizer running on a separate server. In the mobile device, augmented reality (AR) was used to help the hearing impaired observe gestures and lip movements of the speaker simultaneously with the transcriptions. Several testers found the systems useful enough to use in their daily lives, with majority preferring the mobile AR version. The biggest concern of the testers was the accuracy of the transcriptions and the lack of speaker identification."
W19-0302,{N}orth {S}{\\'a}mi morphological segmentation with low-resource semi-supervised sequence labeling,2019,0,0,3,1,13980,stigarne gronroos,Proceedings of the Fifth International Workshop on Computational Linguistics for Uralic Languages,0,None
W18-6410,Cognate-aware morphological segmentation for multilingual neural translation,2018,0,0,3,1,13980,stigarne gronroos,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"This article describes the Aalto University entry to the WMT18 News Translation Shared Task. We participate in the multilingual subtrack with a system trained under the constrained condition to translate from English to both Finnish and Estonian. The system is based on the Transformer model. We focus on improving the consistency of morphological segmentation for words that are similar orthographically, semantically, and distributionally; such words include etymological cognates, loan words, and proper names. For this, we introduce Cognate Morfessor, a multilingual variant of the Morfessor method. We show that our approach improves the translation quality particularly for Estonian, which has less resources for training the translation model."
W18-6439,The {M}e{MAD} Submission to the {WMT}18 Multimodal Translation Task,2018,0,10,3,1,13980,stigarne gronroos,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"This paper describes the MeMAD project entry to the WMT Multimodal Machine Translation Shared Task. We propose adapting the Transformer neural machine translation (NMT) architecture to a multi-modal setting. In this paper, we also describe the preliminary experiments with text-only translation systems leading us up to this choice. We have the top scoring system for both English-to-German and English-to-French, according to the automatic metrics for flickr18. Our experiments show that the effect of the visual features in our system is small. Our largest gains come from the quality of the underlying text-only NMT system. We find that appropriate use of additional data is effective."
W18-0208,New Baseline in Automatic Speech Recognition for {N}orthern {S}{\\'a}mi,2018,0,0,4,1,2695,juho leinonen,Proceedings of the Fourth International Workshop on Computational Linguistics of Uralic Languages,0,None
W17-4727,Extending hybrid word-character neural machine translation with multi-task learning of morphological analysis,2017,0,3,3,1,13980,stigarne gronroos,Proceedings of the Second Conference on Machine Translation,0,None
W17-0208,Acoustic Model Compression with {MAP} adaptation,2017,6,0,2,0,13678,katri leino,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W16-2312,Hybrid Morphological Segmentation for Phrase-Based Machine Translation,2016,0,2,3,1,13980,stigarne gronroos,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,None
J16-1003,A Comparative Study of Minimally Supervised Morphological Segmentation,2016,59,8,5,1,35500,teemu ruokolainen,Computational Linguistics,0,"This article presents a comparative study of a subfield of morphology learning referred to as minimally supervised morphological segmentation. In morphological segmentation, word forms are segmented into morphs, the surface forms of morphemes. In the minimally supervised data-driven learning setting, segmentation models are learned from a small number of manually annotated word forms and a large set of unannotated word forms. In addition to providing a literature survey on published methods, we present an in-depth empirical comparison on three diverse model families, including a detailed error analysis. Based on the literature survey, we conclude that the existing methodology contains substantial work on generative morph lexicon-based approaches and methods based on discriminative boundary detection. As for which approach has been more successful, both the previous work and the empirical evaluation presented here strongly imply that the current state of the art is yielded by the discriminative boundary detection methodology."
W15-3010,Tuning Phrase-Based Segmented Translation for a Morphologically Complex Target Language,2015,11,2,3,1,13980,stigarne gronroos,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This article describes the Aalto University entry to the English-to-Finnish shared translation task in WMT 2015. The system participates in the constrained condition, but in addition we impose some further constraints, using no language-specific resources beyond those provided in the task. We use a morphological segmenter, Morfessor FlatCat, but train and tune it in an unsupervised manner. The system could thus be used for another language pair with a morphologically complex target language, without needing modification or additional resources."
W15-2803,Towards Reliable Automatic Multimodal Content Analysis,2015,5,0,5,0,36891,olliphilippe lautenbacher,Proceedings of the Fourth Workshop on Vision and Language,0,"This poster presents a pilot where audio description is used to enhance automatic content analysis, for a project aiming at creating a tool for easy access to large AV archives."
P14-2043,Part-of-Speech Tagging using Conditional Random Fields: Exploiting Sub-Label Dependencies for Improved Accuracy,2014,13,9,4,0,1308,miikka silfverberg,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We discuss part-of-speech (POS) tagging in presence of large, fine-grained label sets using conditional random fields (CRFs). We propose improving tagging accuracy by utilizing dependencies within sub-components of the fine-grained labels. These sub-label dependencies are incorporated into the CRF model via a (relatively) straightforward feature extraction scheme. Experiments on five languages show that the approach can yield significant improvement in tagging accuracy in case the labels have sufficiently rich inner structure."
varjokallio-kurimo-2014-toolkit,A Toolkit for Efficient Learning of Lexical Units for Speech Recognition,2014,12,3,2,0,34405,matti varjokallio,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"String segmentation is an important and recurring problem in natural language processing and other domains. For morphologically rich languages, the amount of different word forms caused by morphological processes like agglutination, compounding and inflection, may be huge and causes problems for traditional word-based language modeling approach. Segmenting text into better modelable units is thus an important part of the modeling task. This work presents methods and a toolkit for learning segmentation models from text. The methods may be applied to lexical unit selection for speech recognition and also other segmentation tasks."
E14-4015,Accelerated Estimation of Conditional Random Fields using a Pseudo-Likelihood-inspired Perceptron Variant,2014,22,0,3,1,35500,teemu ruokolainen,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"We discuss a simple estimation approach for conditional random fields (CRFs). The approach is derived heuristically by defining a variant of the classic perceptron algorithm in spirit of pseudo-likelihood for maximum likelihood estimation. The resulting approximative algorithm has a linear time complexity in the size of the label set and contains a minimal amount of tunable hyper-parameters. Consequently, the algorithm is suitable for learning CRFbased part-of-speech (POS) taggers in presence of large POS label sets. We present experiments on five languages. Despite its heuristic nature, the algorithm provides surprisingly competetive accuracies and running times against reference methods."
E14-4017,Painless Semi-Supervised Morphological Segmentation using Conditional Random Fields,2014,23,14,4,1,35500,teemu ruokolainen,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"We discuss data-driven morphological segmentation, in which word forms are segmented into morphs, that is the surface forms of morphemes. We extend a recent segmentation approach based on conditional random fields from purely supervised to semi-supervised learning by exploiting available unsupervised segmentation techniques. We integrate the unsupervised techniques into the conditional random field model via feature set augmentation. Experiments on three diverse languages show that this straightforward semi-supervised extension greatly improves the segmentation accuracy of the purely supervised CRFs in a computationally efficient manner."
E14-2006,{M}orfessor 2.0: Toolkit for statistical morphological segmentation,2014,13,22,4,1,14672,peter smit,Proceedings of the Demonstrations at the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Morfessor is a family of probabilistic machine learning methods for finding the morphological segmentation from raw text data. Recent developments include the development of semi-supervised methods for utilizing annotated data. Morfessor 2.0 is a rewrite of the original, widely-used Morfessor 1.0 software, with well documented command-line tools and library interface. It includes new features such as semi-supervised learning, online training, and integrated evaluation code."
C14-1111,{M}orfessor {F}lat{C}at: An {HMM}-Based Method for Unsupervised and Semi-Supervised Learning of Morphology,2014,18,25,4,1,13980,stigarne gronroos,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"Morfessor is a family of methods for learning morphological segmentations of words based on unannotated data. We introduce a new variant of Morfessor, FlatCat, that applies a hidden Markov model structure. It builds on previous work on Morfessor, sharing model components with the popular Morfessor Baseline and Categories-MAP variants. Our experiments show that while unsupervised FlatCat does not reach the accuracy of Categories-MAP, with semisupervised learning it provides state-of-the-art results in the Morpho Challenge 2010 tasks for English, Finnish, and Turkish."
W13-3504,Supervised Morphological Segmentation in a Low-Resource Learning Setting using Conditional Random Fields,2013,20,24,4,1,35500,teemu ruokolainen,Proceedings of the Seventeenth Conference on Computational Natural Language Learning,0,"We discuss data-driven morphological segmentation, in which word forms are segmented into morphs, the surface forms of morphemes. Our focus is on a lowresource learning setting, in which only a small amount of annotated word forms are available for model training, while unannotated word forms are available in abundance. The current state-of-art methods 1) exploit both the annotated and unannotated data in a semi-supervised manner, and 2) learn morph lexicons and subsequently uncover segmentations by generating the most likely morph sequences. In contrast, we discuss 1) employing only the annotated data in a supervised manner, while entirely ignoring the unannotated data, and 2) directly learning to predict morph boundaries given their local sub-string contexts instead of learning the morph lexicons. Specifically, we employ conditional random fields, a popular discriminative log-linear model for segmentation. We present experiments on two data sets comprising five diverse languages. We show that the fully supervised boundary prediction approach outperforms the state-of-art semi-supervised morph lexicon approaches on all languages when using the same annotated data sets."
2013.iwslt-papers.9,Studies on training text selection for conversational {F}innish language modeling,2013,12,2,2,0,16068,seppo enarvi,Proceedings of the 10th International Workshop on Spoken Language Translation: Papers,0,"Current ASR and MT systems do not operate on conversational Finnish, because training data for colloquial Finnish has not been available. Although speech recognition performance on literary Finnish is already quite good, those systems have very poor baseline performance in conversational speech. Text data for relevant vocabulary and language models can be collected from the Internet, but web data is very noisy and most of it is not helpful for learning good models. Finnish language is highly agglutinative, and written phonetically. Even phonetic reductions and sandhi are often written down in informal discussions. This increases vocabulary size dramatically and causes word-based selection methods to fail. Our selection method explicitly optimizes the perplexity of a subword language model on the development data, and requires only very limited amount of speech transcripts as development data. The language models have been evaluated for speech recognition using a new data set consisting of generic colloquial Finnish."
W12-2705,Unsupervised Vocabulary Adaptation for Morph-based Language Models,2012,4,4,2,0,42298,andre mansikkaniemi,Proceedings of the {NAACL}-{HLT} 2012 Workshop: Will We Ever Really Replace the N-gram Model? On the Future of Language Modeling for {HLT},0,Modeling of foreign entity names is an important unsolved problem in morpheme-based modeling that is common in morphologically rich languages. In this paper we present an unsupervised vocabulary adaptation method for morph-based speech recognition. Foreign word candidates are detected automatically from in-domain text through the use of letter n-gram perplexity. Over-segmented foreign entity names are restored to their base forms in the morph-segmented in-domain text for easier and more reliable modeling and recognition. The adapted pronunciation rules are finally generated with a trainable grapheme-to-phoneme converter. In ASR performance the unsupervised method almost matches the ability of supervised adaptation in correctly recognizing foreign entity names.
W10-2211,Morpho Challenge 2005-2010: Evaluations and Results,2010,9,14,1,1,2635,mikko kurimo,Proceedings of the 11th Meeting of the {ACL} Special Interest Group on Computational Morphology and Phonology,0,None
W10-1729,Applying Morphological Decompositions to Statistical Machine Translation,2010,13,3,4,0.888889,2696,sami virpioja,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the Aalto submission for the German-to-English and the Czech-to-English translation tasks of the ACL 2010 Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR. Statistical machine translation has focused on using words, and longer phrases constructed from words, as tokens in the system. In contrast, we apply different morphological decompositions of words using the unsupervised Morfessor algorithms. While translation models trained using the morphological decompositions did not improve the BLEU scores, we show that the Minimum Bayes Risk combination with a word-based translation model produces significant improvements for the German-to-English translation. However, we did not see improvements for the Czech-to-English translations."
P10-4009,Personalising Speech-To-Speech Translation in the {EMIME} Project,2010,19,18,1,1,2635,mikko kurimo,Proceedings of the {ACL} 2010 System Demonstrations,0,"In the EMIME project we have studied unsupervised cross-lingual speaker adaptation. We have employed an HMM statistical framework for both speech recognition and synthesis which provides transformation mechanisms to adapt the synthesized voice in TTS (text-to-speech) using the recognized voice in ASR (automatic speech recognition). An important application for this research is personalised speech-to-speech translation that will use the voice of the speaker in the input language to utter the translated sentences in the output language. In mobile environments this enhances the users' interaction across language barriers by making the output speech sound more like the original speaker's way of speaking, even if she or he could not speak the output language."
P10-2056,Domain Adaptation of Maximum Entropy Language Models,2010,11,9,2,0,31668,tanel alumae,Proceedings of the {ACL} 2010 Conference Short Papers,0,"We investigate a recently proposed Bayesian adaptation method for building style-adapted maximum entropy language models for speech recognition, given a large corpus of written language data and a small corpus of speech transcripts. Experiments show that the method consistently outperforms linear interpolation which is typically used in such cases."
N09-5004,Morpho Challenge - Evaluation of algorithms for unsupervised learning of morphology in various tasks and languages,2009,8,0,1,1,2635,mikko kurimo,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Demonstration Session",0,"After the release of the open source software implementation of Morfessor algorithm, a series of several open evaluations has been organized for unsupervised morpheme analysis and morpheme-based speech recognition and information retrieval. The unsupervised morpheme analysis is a particularly attractive approach for speech and language technology for the morphologically complex languages. When the amount of distinct word forms becomes prohibitive for the construction of a sufficient lexicon, it is important that the words can be segmented into smaller meaningful language modeling units. In this presentation we will demonstrate the results of the evaluations, the baseline systems built using the open source tools, and invite research groups to participate in the next evaluation where the task is to enhance statistical machine translation by morpheme analysis."
N09-2019,Minimum {B}ayes Risk Combination of Translation Hypotheses from Alternative Morphological Decompositions,2009,24,32,3,0,23877,adria gispert,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,We describe a simple strategy to achieve translation performance improvements by combining output from identical statistical machine translation systems trained on alternative morphological decompositions of the source language. Combination is done by means of Minimum Bayes Risk decoding over a shared N-best list. When translating into English from two highly inflected languages such as Arabic and Finnish we obtain significant improvements over simply selecting the best morphological decomposition.
N09-2049,Analysing Recognition Errors in Unlimited-Vocabulary Speech Recognition,2009,8,6,2,0,45641,teemu hirsimaki,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"We analyze the recognition errors made by a morph-based continuous speech recognition system, which practically allows an unlimited vocabulary. Examining the role of the acoustic and language models in erroneous regions shows how speaker adaptive training (SAT) and discriminative training with minimum phone frame error (MPFE) criterion decrease errors in different error classes. Analyzing the errors with respect to word frequencies and manually classified error types reveals the most potential areas for improving the system."
I08-3020,Speech to speech machine translation: Biblical chatter from {F}innish to {E}nglish,2008,10,1,4,0,46909,david ellis,Proceedings of the {IJCNLP}-08 Workshop on {NLP} for Less Privileged Languages,0,"Speech-to-speech machine translation is in some ways the peak of natural language pro- cessing, in that it deals directly with our original, oral mode of communication (as opposed to derived written language). As such, it presents challenges that are not to be taken lightly. Although existing technology covers each of the steps in the process, from speech recognition to synthesis, deriving a model of translation that is effective in the domain of spoken language is an interesting and challenging task. If we could teach our algorithms to learn as children acquire lan- guage, the result would be useful both for language technology and cognitive science. We propose several potential approaches, an implementation of a multi-path model that translates recognized morphemes alongside words, and a web-interface to test our speech translation tool as trained for Finnish to En- glish. We also discuss current approaches to machine translation and the problems they face in adapting simultaneously to morpho- logically rich languages and to the spoken modality."
P07-1012,Vocabulary Decomposition for {E}stonian Open Vocabulary Speech Recognition,2007,8,12,2,0,41181,antti puurula,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"Speech recognition in many morphologically rich languages suffers from a very high out-of-vocabulary (OOV) ratio. Earlier work has shown that vocabulary decomposition methods can practically solve this problem for a subset of these languages. This paper compares various vocabulary decomposition approaches to open vocabulary speech recognition, using Estonian speech recognition as a benchmark. Comparisons are performed utilizing large models of 60000 lexical items and smaller vocabularies of 5000 items. A large vocabulary model based on a manually constructed morphological tagger is shown to give the lowest word error rate, while the unsupervised morphology discovery method Morfessor Baseline gives marginally weaker results. Only the Morfessor-based approach is shown to adequately scale to smaller vocabulary sizes."
N07-1048,Analysis of Morph-Based Speech Recognition and the Modeling of Out-of-Vocabulary Words Across Languages,2007,27,18,3,0.882353,203,mathias creutz,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"We analyze subword-based language models (LMs) in large-vocabulary continuous speech recognition across four xe2x80x9cmorphologically richxe2x80x9d languages: Finnish, Estonian, Turkish, and Egyptian Colloquial Arabic. By estimating n-gram LMs over sequences of morphs instead of words, better vocabulary coverage and reduced data sparsity is obtained. Standard word LMs suffer from high out-of-vocabulary (OOV) rates, whereas the morph LMs can recognize previously unseen word forms by concatenating morphs. We show that the morph LMs generally outperform the word LMs and that they perform fairly well on OOVs without compromising the accuracy obtained for in-vocabulary words."
N06-1062,Unlimited vocabulary speech recognition for agglutinative languages,2006,21,63,1,1,2635,mikko kurimo,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,"It is practically impossible to build a word-based lexicon for speech recognition in agglutinative languages that would cover all the relevant words. The problem is that words are generally built by concatenating several prefixes and suffixes to the word roots. Together with compounding and inflections this leads to millions of different, but still frequent word forms. Due to inflections, ambiguity and other phenomena, it is also not trivial to automatically split the words into meaningful parts. Rule-based morphological analyzers can perform this splitting, but due to the handcrafted rules, they also suffer from an out-of-vocabulary problem. In this paper we apply a recently proposed fully automatic and rather language and vocabulary independent way to build sub-word lexica for three different agglutinative languages. We demonstrate the language portability as well by building a successful large vocabulary speech recognizer for each language and show superior recognition performance compared to the corresponding word-based reference systems."
