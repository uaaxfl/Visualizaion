2021.naacl-main.48,Implicitly Abusive Language {--} What does it actually look like and why are we not getting there?,2021,-1,-1,2,0,3381,michael wiegand,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Abusive language detection is an emerging field in natural language processing which has received a large amount of attention recently. Still the success of automatic detection is limited. Particularly, the detection of implicitly abusive language, i.e. abusive language that is not conveyed by abusive words (e.g. dumbass or scum), is not working well. In this position paper, we explain why existing datasets make learning implicit abuse difficult and what needs to be changed in the design of such datasets. Arguing for a divide-and-conquer strategy, we present a list of subtypes of implicitly abusive language and formulate research tasks and questions for future research."
2021.konvens-1.13,Who is we? Disambiguating the referents of first person plural pronouns in parliamentary debates,2021,-1,-1,2,0,5564,ines rehbein,Proceedings of the 17th Conference on Natural Language Processing (KONVENS 2021),0,None
2021.eacl-main.27,Implicitly Abusive Comparisons {--} A New Dataset and Linguistic Analysis,2021,-1,-1,3,0,3381,michael wiegand,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,We examine the task of detecting implicitly abusive comparisons (e.g. {``}Your hair looks like you have been electrocuted{''}). Implicitly abusive comparisons are abusive comparisons in which abusive words (e.g. {``}dumbass{''} or {``}scum{''}) are absent. We detail the process of creating a novel dataset for this task via crowdsourcing that includes several measures to obtain a sufficiently representative and unbiased set of comparisons. We also present classification experiments that include a range of linguistic features that help us better understand the mechanisms underlying abusive comparisons.
2021.eacl-main.28,Exploiting Emojis for Abusive Language Detection,2021,-1,-1,2,0,3381,michael wiegand,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"We propose to use abusive emojis, such as the {``}middle finger{''} or {``}face vomiting{''}, as a proxy for learning a lexicon of abusive words. Since it represents extralinguistic information, a single emoji can co-occur with different forms of explicitly abusive utterances. We show that our approach generates a lexicon that offers the same performance in cross-domain classification of abusive microposts as the most advanced lexicon induction method. Such an approach, in contrast, is dependent on manually annotated seed words and expensive lexical resources for bootstrapping (e.g. WordNet). We demonstrate that the same emojis can also be effectively used in languages other than English. Finally, we also show that emojis can be exploited for classifying mentions of ambiguous words, such as {``}fuck{''} and {``}bitch{''}, into generally abusive and just profane usages."
2020.udw-1.16,{I}{'}ve got a construction looks funny {--} representing and recovering non-standard constructions in {UD},2020,-1,-1,1,1,3382,josef ruppenhofer,Proceedings of the Fourth Workshop on Universal Dependencies (UDW 2020),0,"The UD framework defines guidelines for a crosslingual syntactic analysis in the framework of dependency grammar, with the aim of providing a consistent treatment across languages that not only supports multilingual NLP applications but also facilitates typological studies. Until now, the UD framework has mostly focussed on bilexical grammatical relations. In the paper, we propose to add a constructional perspective and discuss several examples of spoken-language constructions that occur in multiple languages and challenge the current use of basic and enhanced UD relations. The examples include cases where the surface relations are deceptive, and syntactic amalgams that either involve unconnected subtrees or structures with multiply-headed dependents. We argue that a unified treatment of constructions across languages will increase the consistency of the UD annotations and thus the quality of the treebanks for linguistic analysis."
2020.lrec-1.566,Fine-grained Named Entity Annotations for {G}erman Biographic Interviews,2020,-1,-1,1,1,3382,josef ruppenhofer,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We present a fine-grained NER annotations with 30 labels and apply it to German data. Building on the OntoNotes 5.0 NER inventory, our scheme is adapted for a corpus of transcripts of biographic interviews by adding categories for AGE and LAN(guage) and also features extended numeric and temporal categories. Applying the scheme to the spoken data as well as a collection of teaser tweets from newspaper sites, we can confirm its generality for both domains, also achieving good inter-annotator agreement. We also show empirically how our inventory relates to the well-established 4-category NER inventory by re-annotating a subset of the GermEval 2014 NER coarse-grained dataset with our fine label inventory. Finally, we use a BERT-based system to establish some baseline models for NER tagging on our two new datasets. Global results in in-domain testing are quite high on the two datasets, near what was achieved for the coarse inventory on the CoNLLL2003 data. Cross-domain testing produces much lower results due to the severe domain differences."
2020.lrec-1.606,Doctor Who? Framing Through Names and Titles in {G}erman,2020,-1,-1,3,1,17870,esther berg,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Entity framing is the selection of aspects of an entity to promote a particular viewpoint towards that entity. We investigate entity framing of political figures through the use of names and titles in German online discourse, enhancing current research in entity framing through titling and naming that concentrates on English only. We collect tweets that mention prominent German politicians and annotate them for stance. We find that the formality of naming in these tweets correlates positively with their stance. This confirms sociolinguistic observations that naming and titling can have a status-indicating function and suggests that this function is dominant in German tweets mentioning political figures. We also find that this status-indicating function is much weaker in tweets from users that are politically left-leaning than in tweets by right-leaning users. This is in line with observations from moral psychology that left-leaning and right-leaning users assign different importance to maintaining social hierarchies."
2020.lrec-1.616,Enhancing a Lexicon of Polarity Shifters through the Supervised Classification of Shifting Directions,2020,-1,-1,3,1,14816,marc schulder,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The sentiment polarity of an expression (whether it is perceived as positive, negative or neutral) can be influenced by a number of phenomena, foremost among them negation. Apart from closed-class negation words like {``}no{''}, {``}not{''} or {``}without{''}, negation can also be caused by so-called polarity shifters. These are content words, such as verbs, nouns or adjectives, that shift polarities in their opposite direction, e.g. {``}abandoned{''} in {``}abandoned hope{''} or {``}alleviate{''} in {``}alleviate pain{''}. Many polarity shifters can affect both positive and negative polar expressions, shifting them towards the opposing polarity. However, other shifters are restricted to a single shifting direction. {``}Recoup{''} shifts negative to positive in {``}recoup your losses{''}, but does not affect the positive polarity of {``}fortune{''} in {``}recoup a fortune{''}. Existing polarity shifter lexica only specify whether a word can, in general, cause shifting, but they do not specify when this is limited to one shifting direction. To address this issue we introduce a supervised classifier that determines the shifting direction of shifters. This classifier uses both resource-driven features, such as WordNet relations, and data-driven features like in-context polarity conflicts. Using this classifier we enhance the largest available polarity shifter lexicon."
2020.lrec-1.645,Treebanking User-Generated Content: A Proposal for a Unified Representation in {U}niversal {D}ependencies,2020,-1,-1,8,0,16433,manuela sanguinetti,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The paper presents a discussion on the main linguistic phenomena of user-generated texts found in web and social media, and proposes a set of annotation guidelines for their treatment within the Universal Dependencies (UD) framework. Given on the one hand the increasing number of treebanks featuring user-generated content, and its somewhat inconsistent treatment in these resources on the other, the aim of this paper is twofold: (1) to provide a short, though comprehensive, overview of such treebanks - based on available literature - along with their main features and a comparative analysis of their annotation criteria, and (2) to propose a set of tentative UD-based annotation guidelines, to promote consistent treatment of the particular phenomena found in these types of texts. The main goal of this paper is to provide a common framework for those teams interested in developing similar resources in UD, thus enabling cross-linguistic consistency, which is a principle that has always been in the spirit of UD."
2020.lrec-1.731,A New Resource for {G}erman Causal Language,2020,-1,-1,2,0,5564,ines rehbein,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We present a new resource for German causal language, with annotations in context for verbs, nouns and prepositions. Our dataset includes 4,390 annotated instances for more than 150 different triggers. The annotation scheme distinguishes three different types of causal events (CONSEQUENCE , MOTIVATION, PURPOSE). We also provide annotations for semantic roles, i.e. of the cause and effect for the causal event as well as the actor and affected party, if present. In the paper, we present inter-annotator agreement scores for our dataset and discuss problems for annotating causal language. Finally, we present experiments where we frame causal annotation as a sequence labelling problem and report baseline results for the prediciton of causal arguments and for predicting different types of causation."
2020.lrec-1.878,Improving Sentence Boundary Detection for Spoken Language Transcripts,2020,-1,-1,2,0,5564,ines rehbein,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper presents experiments on sentence boundary detection in transcripts of spoken dialogues. Segmenting spoken language into sentence-like units is a challenging task, due to disfluencies, ungrammatical or fragmented structures and the lack of punctuation. In addition, one of the main bottlenecks for many NLP applications for spoken language is the small size of the training data, as the transcription and annotation of spoken language is by far more time-consuming and labour-intensive than processing written language. We therefore investigate the benefits of data expansion and transfer learning and test different ML architectures for this task. Our results show that data expansion is not straightforward and even data from the same domain does not always improve results. They also highlight the importance of modelling, i.e. of finding the best architecture and data representation for the task at hand. For the detection of boundaries in spoken language transcripts, we achieve a substantial improvement when framing the boundary detection problem assentence pair classification task, as compared to a sequence tagging approach."
W19-7811,twee{D}e {--} A {U}niversal {D}ependencies treebank for {G}erman tweets,2019,0,0,2,0,5564,ines rehbein,"Proceedings of the 18th International Workshop on Treebanks and Linguistic Theories (TLT, SyntaxFest 2019)",0,None
W19-2101,Not My President: How Names and Titles Frame Political Figures,2019,-1,-1,3,1,17870,esther berg,Proceedings of the Third Workshop on Natural Language Processing and Computational Social Science,0,"Naming and titling have been discussed in sociolinguistics as markers of status or solidarity. However, these functions have not been studied on a larger scale or for social media data. We collect a corpus of tweets mentioning presidents of six G20 countries by various naming forms. We show that naming variation relates to stance towards the president in a way that is suggestive of a framing effect mediated by respectfulness. This confirms sociolinguistic theory of naming and titling as markers of status."
N19-1060,{D}etection of {A}busive {L}anguage: the {P}roblem of {B}iased {D}atasets,2019,0,15,2,0,3381,michael wiegand,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,We discuss the impact of data bias on abusive language detection. We show that classification scores on popular datasets reported in previous work are much lower under realistic settings in which this bias is reduced. Such biases are most notably observed on datasets that are created by focused sampling instead of random sampling. Datasets with a higher proportion of implicit abuse are more affected than datasets with a lower proportion.
N19-1211,{D}etecting {D}erogatory {C}ompounds {--} {A}n {U}nsupervised {A}pproach,2019,0,0,3,0,3381,michael wiegand,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,We examine the new task of detecting derogatory compounds (e.g. {``}curry muncher{''}). Derogatory compounds are much more difficult to detect than derogatory unigrams (e.g. {``}idiot{''}) since they are more sparsely represented in lexical resources previously found effective for this task (e.g. Wiktionary). We propose an unsupervised classification approach that incorporates linguistic properties of compounds. It mostly depends on a simple distributional representation. We compare our approach against previously established methods proposed for extracting derogatory unigrams.
N18-1095,Inducing a Lexicon of Abusive Words {--} a Feature-Based Approach,2018,0,3,2,0.435513,3381,michael wiegand,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,We address the detection of abusive words. The task is to identify such words among a set of negative polar expressions. We propose novel features employing information from both corpora and lexical resources. These features are calibrated on a small manually annotated base lexicon which we use to produce a large lexicon. We show that the word-level information we learn cannot be equally derived from a large dataset of annotated microposts. We demonstrate the effectiveness of our (domain-independent) lexicon in the cross-domain detection of abusive microposts.
L18-1097,Disambiguation of Verbal Shifters,2018,0,0,3,0.435513,3381,michael wiegand,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1222,Introducing a Lexicon of Verbal Polarity Shifters for {E}nglish,2018,0,1,3,1,14816,marc schulder,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1613,Building a Morphological Treebank for {G}erman from a Linguistic Database,2018,0,1,2,0,23377,petra steiner,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-1010,Sprucing up the trees {--} Error detection in treebanks,2018,0,1,2,0,5564,ines rehbein,Proceedings of the 27th International Conference on Computational Linguistics,0,"We present a method for detecting annotation errors in manually and automatically annotated dependency parse trees, based on ensemble parsing in combination with Bayesian inference, guided by active learning. We evaluate our method in different scenarios: (i) for error detection in dependency treebanks and (ii) for improving parsing accuracy on in- and out-of-domain data."
C18-1213,Automatically Creating a Lexicon of Verbal Polarity Shifters: Mono- and Cross-lingual Methods for {G}erman,2018,0,0,3,1,14816,marc schulder,Proceedings of the 27th International Conference on Computational Linguistics,0,"In this paper we use methods for creating a large lexicon of verbal polarity shifters and apply them to German. Polarity shifters are content words that can move the polarity of a phrase towards its opposite, such as the verb {``}abandon{''} in {``}abandon all hope{''}. This is similar to how negation words like {``}not{''} can influence polarity. Both shifters and negation are required for high precision sentiment analysis. Lists of negation words are available for many languages, but the only language for which a sizable lexicon of verbal polarity shifters exists is English. This lexicon was created by bootstrapping a sample of annotated verbs with a supervised classifier that uses a set of data- and resource-driven features. We reproduce and adapt this approach to create a German lexicon of verbal polarity shifters. Thereby, we confirm that the approach works for multiple languages. We further improve classification by leveraging cross-lingual information from the English shifter lexicon. Using this improved approach, we bootstrap a large number of German verbal polarity shifters, reducing the annotation effort drastically. The resulting German lexicon of verbal polarity shifters is made publicly available."
C18-1325,Distinguishing affixoid formations from compounds,2018,0,0,1,1,3382,josef ruppenhofer,Proceedings of the 27th International Conference on Computational Linguistics,0,"We study German affixoids, a type of morpheme in between affixes and free stems. Several properties have been associated with them {--} increased productivity; a bleached semantics, which is often evaluative and/or intensifying and thus of relevance to sentiment analysis; and the existence of a free morpheme counterpart {--} but not been validated empirically. In experiments on a new data set that we make available, we put these key assumptions from the morphological literature to the test and show that despite the fact that affixoids generate many low-frequency formations, we can classify these as affixoid or non-affixoid instances with a best F1-score of 74{\%}."
W17-0813,Catching the Common Cause: Extraction and Annotation of Causal Relations and their Participants,2017,24,0,2,0.472445,5564,ines rehbein,Proceedings of the 11th Linguistic Annotation Workshop,0,"In this paper, we present a simple, yet effective method for the automatic identification and extraction of causal relations from text, based on a large English-German parallel corpus. The goal of this effort is to create a lexical resource for German causal relations. The resource will consist of a lexicon that describes constructions that trigger causality as well as the participants of the causal event, and will be augmented by a corpus with annotated instances for each entry, that can be used as training data to develop a system for automatic classification of causal relations. Focusing on verbs, our method harvested a set of 100 different lexical triggers of causality, including support verb constructions. At the moment, our corpus includes over 1,000 annotated instances. The lexicon and the annotated data will be made available to the research community."
ruppenhofer-etal-2017-evaluating,Evaluating the morphological compositionality of polarity,2017,16,1,1,1,3382,josef ruppenhofer,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"Unknown words are a challenge for any NLP task, including sentiment analysis. Here, we evaluate the extent to which sentiment polarity of complex words can be predicted based on their morphological make-up. We do this on German as it has very productive processes of derivation and compounding and many German hapax words, which are likely to bear sentiment, are morphologically complex. We present results of supervised classification experiments on new datasets with morphological parses and polarity annotations."
P17-1107,Detecting annotation noise in automatically labelled data,2017,23,6,2,0.472445,5564,ines rehbein,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We introduce a method for error detection in automatically annotated text, aimed at supporting the creation of high-quality language resources at affordable cost. Our method combines an unsupervised generative model with human supervision from active learning. We test our approach on in-domain and out-of-domain data in two languages, in AL simulations and in a real world setting. For all settings, the results show that our method is able to detect annotation errors with high precision and high recall."
I17-1063,Towards Bootstrapping a Polarity Shifter Lexicon using Linguistic Features,2017,34,4,3,1,14816,marc schulder,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"We present a major step towards the creation of the first high-coverage lexicon of polarity shifters. In this work, we bootstrap a lexicon of verbs by exploiting various linguistic features. Polarity shifters, such as {``}abandon{''}, are similar to negations (e.g. {``}not{''}) in that they move the polarity of a phrase towards its inverse, as in {``}abandon all hope{''}. While there exist lists of negation words, creating comprehensive lists of polarity shifters is far more challenging due to their sheer number. On a sample of manually annotated verbs we examine a variety of linguistic features for this task. Then we build a supervised classifier to increase coverage. We show that this approach drastically reduces the annotation effort while ensuring a high-precision lexicon. We also show that our acquired knowledge of verbal polarity shifters improves phrase-level sentiment analysis."
N16-1092,Separating Actor-View from Speaker-View Opinion Expressions using Linguistic Features,2016,20,0,3,0.637627,3381,michael wiegand,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We examine different features and classifiers for the categorization of opinion words into actor and speaker view. To our knowledge, this is the first comprehensive work to address sentiment views on the word level taking into consideration opinion verbs, nouns and adjectives. We consider many high-level features requiring only few labeled training data. A detailed feature analysis produces linguistic insights into the nature of sentiment views. We also examine how far global constraints between different opinion words help to increase classification performance. Finally, we show that our (prior) word-level annotation correlates with contextual sentiment views."
N16-1094,Opinion Holder and Target Extraction on Opinion Compounds {--} A Linguistic Approach,2016,42,5,3,0.637627,3381,michael wiegand,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present an approach to the new task of opinion holder and target extraction on opinion compounds. Opinion compounds (e.g. user rating or victim support) are noun compounds whose head is an opinion noun. We do not only examine features known to be effective for noun compound analysis, such as paraphrases and semantic classes of heads and modifiers, but also propose novel features tailored to this new task. Among them, we examine paraphrases that jointly consider holders and targets, a verb detour in which noun heads are replaced by related verbs, a global head constraint allowing inferencing between different compounds, and the categorization of the sentiment view that the head conveys."
L16-1460,Effect Functors for Opinion Inference,2016,12,3,1,1,3382,josef ruppenhofer,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Sentiment analysis has so far focused on the detection of explicit opinions. However, of late implicit opinions have received broader attention, the key idea being that the evaluation of an event type by a speaker depends on how the participants in the event are valued and how the event itself affects the participants. We present an annotation scheme for adding relevant information, couched in terms of so-called effect functors, to German lexical items. Our scheme synthesizes and extends previous proposals. We report on an inter-annotator agreement study. We also present results of a crowdsourcing experiment to test the utility of some known and some new functors for opinion inference where, unlike in previous work, subjects are asked to reason from event evaluation to participant evaluation."
W15-2910,Extending effect annotation with lexical decomposition,2015,12,4,1,1,3382,josef ruppenhofer,"Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"In this contribution, we report on an effort to annotate German data with information relevant to opinion inference. Such information has previously been referred to as effect or couched in terms of eventevaluation functors. We extend the theory and present an extensive scheme that combines both approaches and thus extends the set of inference-relevant predicates. Using these guidelines to annotate 726 German synsets, we achieve good inter-annotator agreement."
W15-2921,Opinion Holder and Target Extraction for Verb-based Opinion Predicates {--} The Problem is Not Solved,2015,30,1,3,0.637627,3381,michael wiegand,"Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,We offer a critical review of the current state of opinion role extraction involving opinion verbs. We argue that neither the currently available lexical resources nor the manually annotated text corpora are sufficient to appropriately study this task. We introduce a new corpus focusing on opinion roles of opinion verbs from the Subjectivity Lexicon and show potential benefits of this corpus. We also demonstrate that state-of-the-art classifiers perform rather poorly on this new dataset compared to the standard dataset for the task showing that there still remains significant research to be done.
R15-1071,Ordering adverbs by their scaling effect on adjective intensity,2015,26,5,1,1,3382,josef ruppenhofer,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"In recent years, theoretical and computational linguistics has paid much attention to linguistic items that form scales. In NLP, much research has focused on ordering adjectives by intensity (tiny < small). Here, we address the task of automatically ordering English adverbs by their intensifying or diminishing effect on adjectives (e.g. extremely small < very small). We experiment with 4 different methods: 1) using the association strength between adverbs and adjectives; 2) exploiting scalar patterns (such as not only X but Y); 3) using the metadata of product reviews; 4) clustering. The method that performs best is based on the use of metadata and ranks adverbs by their scaling factor relative to unmodified adjectives."
K15-1022,Opinion Holder and Target Extraction based on the Induction of Verbal Categories,2015,40,7,2,0.637627,3381,michael wiegand,Proceedings of the Nineteenth Conference on Computational Natural Language Learning,0,"We present an approach for opinion role induction for verbal predicates. Our model rests on the assumption that opinion verbs can be divided into three different types where each type is associated with a characteristic mapping between semantic roles and opinion holders and targets. In several experiments, we demonstrate the relevance of those three categories for the task. We show that verbs can easily be categorized with semi-supervised graphbased clustering and some appropriate similarity metric. The seeds are obtained through linguistic diagnostics. We evaluate our approach against a new manually-compiled opinion role lexicon and perform in-context classification."
W14-4721,Dimensions of Metaphorical Meaning,2014,15,5,2,0,19304,andrew gargett,Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex),0,"Recent work suggests that concreteness and imageability play an important role in the meanings of figurative expressions. We investigate this idea in several ways. First, we try to define more precisely the context within which a figurative expression may occur, by parsing a corpus annotated for metaphor. Next, we add both concreteness and imageability as xe2x80x9cfeaturesxe2x80x9d to the parsed metaphor corpus, by marking up words in this corpus using a psycholinguistic database of scores for concreteness and imageability. Finally, we carry out detailed statistical analyses of the augmented version of the original metaphor corpus, cross-matching the features of concreteness and imageability with others in the corpus such as parts of speech and dependency relations, in order to investigate in detail the use of such features in predicting whether a given expression is metaphorical or not."
E14-4023,Comparing methods for deriving intensity scores for adjectives,2014,22,9,1,1,3382,josef ruppenhofer,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"We compare several different corpusbased and lexicon-based methods for the scalar ordering of adjectives. Among them, we examine for the first time a lowresource approach based on distinctivecollexeme analysis that just requires a small predefined set of adverbial modifiers. While previous work on adjective intensity mostly assumes one single scale for all adjectives, we group adjectives into different scales which is more faithful to human perception. We also apply the methods to both polar and non-polar adjectives, showing that not all methods are equally suitable for both types of adjectives."
W13-0111,Towards Weakly Supervised Resolution of Null Instantiations,2013,-1,-1,2,0,22652,philip gorinski,Proceedings of the 10th International Conference on Computational Semantics ({IWCS} 2013) {--} Long Papers,0,None
N13-1059,Predicative Adjectives: An Unsupervised Criterion to Extract Subjective Adjectives,2013,10,2,2,0.421203,3381,michael wiegand,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We examine predicative adjectives as an unsupervised criterion to extract subjective adjectives. We do not only compare this criterion with a weakly supervised extraction method but also with gradable adjectives, i.e. another highly subjective subset of adjectives that can be extracted in an unsupervised fashion. In order to prove the robustness of this extraction method, we will evaluate the extraction with the help of two different state-of-the-art sentiment lexicons (as a gold standard)."
W12-3716,Semantic frames as an anchor representation for sentiment analysis,2012,20,14,1,1,3382,josef ruppenhofer,Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis,0,"Current work on sentiment analysis is characterized by approaches with a pragmatic focus, which use shallow techniques in the interest of robustness but often rely on ad-hoc creation of data sets and methods. We argue that progress towards deep analysis depends on a) enriching shallow representations with linguistically motivated, rich information, and b) focussing different branches of research and combining ressources to create synergies with related work in NLP. In the paper, we propose SentiFrameNet, an extension to FrameNet, as a novel representation for sentiment analysis that is tailored to these aims."
clematide-etal-2012-mlsa,{MLSA} {---} A Multi-layered Reference Corpus for {G}erman Sentiment Analysis,2012,16,20,6,0,1321,simon clematide,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper, we describe MLSA, a publicly available multi-layered reference corpus for German-language sentiment analysis. The construction of the corpus is based on the manual annotation of 270 German-language sentences considering three different layers of granularity. The sentence-layer annotation, as the most coarse-grained annotation, focuses on aspects of objectivity, subjectivity and the overall polarity of the respective sentences. Layer 2 is concerned with polarity on the word- and phrase-level, annotating both subjective and factual language. The annotations on Layer 3 focus on the expression-level, denoting frames of private states such as objective and direct speech events. These three layers and their respective annotations are intended to be fully independent of each other. At the same time, exploring for and discovering interactions that may exist between different layers should also be possible. The reliability of the respective annotations was assessed using the average pairwise agreement and Fleiss' multi-rater measures. We believe that MLSA is a beneficial resource for sentiment analysis research, algorithms and applications that focus on the German language."
ruppenhofer-rehbein-2012-yes,Yes we can!? Annotating {E}nglish modal verbs,2012,0,7,1,1,3382,josef ruppenhofer,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper presents an annotation scheme for English modal verbs together with sense-annotated data from the news domain. We describe our annotation scheme and discuss problematic cases for modality annotation based on the inter-annotator agreement during the annotation. Furthermore, we present experiments on automatic sense tagging, showing that our annotations do provide a valuable training resource for NLP systems."
R11-1046,In Search of Missing Arguments: A Linguistic Approach,2011,11,14,1,1,3382,josef ruppenhofer,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"Semantic argument structures are often incomplete in that core arguments are not locally instantiated. However, many of these implicit arguments can be linked to referents in the wider context. In this paper we explore a number of linguistically motivated strategies for identifying and resolving such null instantiations (NIs). We show that a more sophisticated model for identifying definite NIs can lead to noticeable performance gains over the state-ofthe-art for NI resolution."
R11-1064,Learning Script Participants from Unlabeled Data,2011,26,11,3,0,21823,michaela regneri,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"We introduce a system that learns the participants of arbitrary given scripts. This system processes data from web experiments, in which each participant can be realized with different expressions. It computes participants by encoding semantic similarity and global structural information into an Integer Linear Program. An evaluation against a gold standard shows that we significantly outperform two informed baselines."
P11-1005,Evaluating the Impact of Coder Errors on Active Learning,2011,22,1,2,1,5564,ines rehbein,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"Active Learning (AL) has been proposed as a technique to reduce the amount of annotated data needed in the context of supervised classification. While various simulation studies for a number of NLP tasks have shown that AL works well on goldstandard data, there is some doubt whether the approach can be successful when applied to noisy, real-world data sets. This paper presents a thorough evaluation of the impact of annotation noise on AL and shows that systematic noise resulting from biased coder decisions can seriously harm the AL process. We present a method to filter out inconsistent annotations during AL and show that this makes AL far more robust when applied to noisy data."
S10-1008,{S}em{E}val-2010 Task 10: Linking Events and Their Participants in Discourse,2010,6,67,1,1,3382,josef ruppenhofer,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"We describe the SemEval-2010 shared task on Linking Events and Their Participants in Discourse. This task is an extension to the classical semantic role labeling task. While semantic role labeling is traditionally viewed as a sentence-internal task, local semantic argument structures clearly interact with each other in a larger context, e.g., by sharing references to specific discourse entities or events. In the shared task we looked at one particular aspect of cross-sentence links between argument structures, namely linking locally uninstantiated roles to their co-referents in the wider discourse context (if such co-referents exist). This task is potentially beneficial for a number of NLP applications, such as information extraction, question answering or text summarization."
ruppenhofer-etal-2010-speaker,Speaker Attribution in Cabinet Protocols,2010,10,4,1,1,3382,josef ruppenhofer,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Historical cabinet protocols are a useful resource which enable historians to identify the opinions expressed by politicians on different subjects and at different points of time. While cabinet protocols are often available in digitized form, so far the only method to access their information content is by keyword-based search, which often returns sub-optimal results. We present a method for enriching German cabinet protocols with information about the originators of statements. This requires automatic speaker attribution. Unlike many other approaches, our method can also deal with cases in which the speaker is not explicitly identified in the sentence itself. Such cases are very common in our domain. To avoid costly manual annotation of training data, we design a rule-based system which exploits morpho-syntactic cues. We show that such a system obtains good results, especially with respect to recall which is particularly important for information access."
ruppenhofer-etal-2010-generating,Generating {F}rame{N}ets of Various Granularities: The {F}rame{N}et Transformer,2010,12,5,1,1,3382,josef ruppenhofer,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We present a method and a software tool, the FrameNet Transformer, for deriving customized versions of the FrameNet database based on frame and frame element relations. The FrameNet Transformer allows users to iteratively coarsen the FrameNet sense inventory in two ways. First, the tool can merge entire frames that are related by user-specified relations. Second, it can merge word senses that belong to frames related by specified relations. Both methods can be interleaved. The Transformer automatically outputs format-compliant FrameNet versions, including modified corpus annotation files that can be used for automatic processing. The customized FrameNet versions can be used to determine which granularity is suitable for particular applications. In our evaluation of the tool, we show that our method increases accuracy of statistical semantic parsers by reducing the number of word-senses (frames) per lemma, and increasing the number of annotated sentences per lexical unit and frame. We further show in an experiment on the FATE corpus that by coarsening FrameNet we do not incur a significant loss of information that is relevant to the Recognizing Textual Entailment task."
rehbein-ruppenhofer-2010-theres,There{'}s no Data like More Data? Revisiting the Impact of Data Size on a Classification Task,2010,20,1,2,1,5564,ines rehbein,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In the paper we investigate the impact of data size on a Word Sense Disambiguation task (WSD). We question the assumption that the knowledge acquisition bottleneck, which is known as one of the major challenges for WSD, can be solved by simply obtaining more and more training data. Our case study on 1,000 manually annotated instances of the German verb ''``drohen'''' (threaten) shows that the best performance is not obtained when training on the full data set, but by carefully selecting new training instances with regard to their informativeness for the learning process (Active Learning). We present a thorough evaluation of the impact of different sampling methods on the data sets and propose an improved method for uncertainty sampling which dynamically adapts the selection of new instances to the learning progress of the classifier, resulting in more robust results during the initial stages of learning. A qualitative error analysis identifies problems for automatic WSD and discusses the reasons for the great gap in performance between human annotators and our automatic WSD system."
C10-1107,Bringing Active Learning to Life,2010,19,5,2,1,5564,ines rehbein,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"Active learning has been applied to different NLP tasks, with the aim of limiting the amount of time and cost for human annotation. Most studies on active learning have only simulated the annotation scenario, using prelabelled gold standard data. We present the first active learning experiment for Word Sense Disambiguation with human annotators in a realistic environment, using fine-grained sense distinctions, and investigate whether AL can reduce annotation cost and boost classifier performance when applied to a real-world task."
W09-3003,Assessing the benefits of partial automatic pre-labeling for frame-semantic annotation,2009,13,10,2,1,5564,ines rehbein,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"In this paper, we present the results of an experiment in which we assess the usefulness of partial semi-automatic annotation for frame labeling. While we found no conclusive evidence that it can speed up human annotation, automatic pre-annotation does increase its overall quality."
W09-2417,{S}em{E}val-2010 Task 10: Linking Events and Their Participants in Discourse,2009,18,19,1,1,3382,josef ruppenhofer,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"In this paper, we describe the SemEval-2010 shared task on Linking Events and Their Participants in Discourse. This task is a variant of the classical semantic role labelling task. The novel aspect is that we focus on linking local semantic argument structures across sentence boundaries. Specifically, the task aims at linking locally uninstantiated roles to their co-referents in the wider discourse context (if such co-referents exist). This task is potentially beneficial for a number of NLP applications and we hope that it will not only attract researchers from the semantic role labelling community but also from co-reference resolution and information extraction."
W08-0122,Discourse Level Opinion Relations: An Annotation Study,2008,16,26,2,0,12223,swapna somasundaran,Proceedings of the 9th {SIG}dial Workshop on Discourse and Dialogue,0,"This work proposes opinion frames as a representation of discourse-level associations that arise from related opinion targets and which are common in task-oriented meeting dialogs. We define the opinion frames and explain their interpretation. Additionally we present an annotation scheme that realizes the opinion frames and via human annotation studies, we show that these can be reliably identified."
ruppenhofer-etal-2008-finding,Finding the Sources and Targets of Subjective Expressions,2008,23,59,1,1,3382,josef ruppenhofer,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"As many popular text genres such as blogs or news contain opinions by multiple sources and about multiple targets, finding the sources and targets of subjective expressions becomes an important sub-task for automatic opinion analysis systems. We argue that while automatic semantic role labeling systems (ASRL) have an important contribution to make, they cannot solve the problem for all cases. Based on the experience of manually annotating opinions, sources, and targets in various genres, we present linguistic phenomena that require knowledge beyond that of ASRL systems. In particular, we address issues relating to the attribution of opinions to sources; sources and targets that are realized as zero-forms; and inferred opinions. We also discuss in some depth that for arguing attitudes we need to be able to recover propositions and not only argued-about entities. A recurrent theme of the discussion is that close attention to specific discourse contexts is needed to identify sources and targets correctly."
C08-1101,Discourse Level Opinion Interpretation,2008,16,63,3,0,12223,swapna somasundaran,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,This work proposes opinion frames as a representation of discourse-level associations which arise from related opinion topics. We illustrate how opinion frames help gather more information and also assist disambiguation. Finally we present the results of our experiments to detect these associations.
2007.sigdial-1.5,Detecting Arguing and Sentiment in Meetings,2007,22,57,2,0,12223,swapna somasundaran,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,This paper analyzes opinion categories like Sentiment and Arguing in meetings. We first annotate the categories manually. We then develop genre-specific lexicons using interesting function word combinations for detecting the opinions. We analyze relations between dialog structure information and opinion expression in context of multiparty discourse. Finally we show that classifiers using lexical and discourse knowledge have significant improvement over baseline.
