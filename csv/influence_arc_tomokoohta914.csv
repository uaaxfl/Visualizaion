E12-2021,W05-0620,0,0.0614673,"Missing"
E12-2021,doddington-etal-2004-automatic,0,0.0628567,"an be set up to support most text annotation tasks. The most basic annotation primitive identifies a text span and assigns it a type (or tag or label), marking for e.g. POS-tagged tokens, chunks or entity mentions (Figure 1 top). These base annotations can be connected by binary relations – either directed or undirected – which can be configured for e.g. simple relation extraction, or verb frame annotation BRAT (Figure 1 middle and bottom). n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2). Additional aspects of annotations can be marked using attributes, binary or multi-valued flags that can be added to other annotations. Finally, annotators can attach free-form text notes to any annotation. In addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples). F"
E12-2021,J02-3001,0,0.0249721,", allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2). Additional aspects of annotations can be marked using attributes, binary or multi-valued flags that can be added to other annotations. Finally, annotators can attach free-form text notes to any annotation. In addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples). Further, both the BRAT client and server implement full support for the Unicode standard, which allow the tool to support the annotation of text using e.g. Chinese or Devan¯agar¯ı characters. BRAT is distributed with examples from over 20 corpora for a variety of tasks, involving texts in seven different languages and including examples from corpora such as those introduced for the CoNLL shared tasks on language-independent named entity recognition (Tjong Kim Sang and De Meulder, 2003) and mult"
E12-2021,W11-1801,1,0.354037,"Missing"
E12-2021,W03-3017,0,0.0113928,"dheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2). Additional aspects of annotations can be marked using attributes, binary or multi-valued flags that can be added to other annotations. Finally, annotators can attach free-form text notes to any annotation. In addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples). Further, both the BRAT client and server implement full support for the Unicode standard, which allow the tool to support the annotation of text using e.g. Chinese or Devan¯agar¯ı characters. BRAT is distributed with examples from over 20 corpora for a variety of tasks, involving texts in seven different languages and including examples from corpora such as those introduced for the CoNLL shared tasks on language-independent named entity recognition (Tjong Kim Sang and De Meulder, 2003) and multilingual dependency parsing (Buchholz and Marsi, 2006). BRAT also imple"
E12-2021,N06-4006,0,0.00738235,"the semantic class disambiguation component (Stenetorp et al., 2011a). Although further research is needed to establish the benefits of this approach in various annotation tasks, we view the results of this initial experiment as promising regarding the potential of our approach to using machine learning to support annotation efforts. 5 informed by experience from several annotation tasks and research efforts spanning more than a decade. A variety of previously introduced annotation tools and approaches also served to guide our design decisions, including the fast annotation mode of Knowtator (Ogren, 2006), the search capabilities of the XConc tool (Kim et al., 2008), and the design of web-based systems such as MyMiner (Salgado et al., 2010), and GATE Teamware (Cunningham et al., 2011). Using machine learning to accelerate annotation by supporting human judgements is well documented in the literature for tasks such as entity annotation (Tsuruoka et al., 2008) and translation (Mart´ınezG´omez et al., 2011), efforts which served as inspiration for our own approach. BRAT , along with conversion tools and extensive documentation, is freely available under the open-source MIT license from its homepa"
E12-2021,W11-1816,1,0.207231,"Missing"
E12-2021,X96-1048,0,0.137156,"lly configurable and can be set up to support most text annotation tasks. The most basic annotation primitive identifies a text span and assigns it a type (or tag or label), marking for e.g. POS-tagged tokens, chunks or entity mentions (Figure 1 top). These base annotations can be connected by binary relations – either directed or undirected – which can be configured for e.g. simple relation extraction, or verb frame annotation BRAT (Figure 1 middle and bottom). n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2). Additional aspects of annotations can be marked using attributes, binary or multi-valued flags that can be added to other annotations. Finally, annotators can attach free-form text notes to any annotation. In addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), and dependency annotation (Nivre, 2003)"
E12-2021,W08-0605,1,0.44524,"experience from several annotation tasks and research efforts spanning more than a decade. A variety of previously introduced annotation tools and approaches also served to guide our design decisions, including the fast annotation mode of Knowtator (Ogren, 2006), the search capabilities of the XConc tool (Kim et al., 2008), and the design of web-based systems such as MyMiner (Salgado et al., 2010), and GATE Teamware (Cunningham et al., 2011). Using machine learning to accelerate annotation by supporting human judgements is well documented in the literature for tasks such as entity annotation (Tsuruoka et al., 2008) and translation (Mart´ınezG´omez et al., 2011), efforts which served as inspiration for our own approach. BRAT , along with conversion tools and extensive documentation, is freely available under the open-source MIT license from its homepage at http://brat.nlplab.org Acknowledgements The authors would like to thank early adopters of BRAT who have provided us with extensive feedback and feature suggestions. This work was supported by Grant-in-Aid for Specially Promoted Research (MEXT, Japan), the UK Biotechnology and Biological Sciences Research Council (BBSRC) under project Automated Biologic"
E12-2021,W06-2920,0,\N,Missing
E12-2021,W03-0419,0,\N,Missing
E12-2021,P05-1013,0,\N,Missing
I05-2038,W04-3111,0,0.0170745,"e phrase illustrated in Figure 2a and Figure 2b shows another problem of the annotation scheme. Both annotators fail to indicate that it is ‘mediated’ that was to be after ‘IL-1’ because there is no mechanism of coindexing a null element with a part of a token. This problem of ellipsis can frequently occur in research abstracts, and it can be argued that the tokenization criteria must be changed for texts in biomedical domain (Yamamoto and Sa224 tou, 2004) so that such fragment as ‘IL-18’ and ‘mediated’ in ‘IL-18-ediated’ should be regarede as separate tokens. The Pennsylvania biology corpus (Kulick et al., 2004) partially solves this problem by separating a token where two or more subtokens are connected with hyphens, but in the cases where a shared part of the word is not separated by a hyphen (e.g. ‘metric’ of ‘stereo- and isometric alleles’) the word including the part is left uncut. The current GTB follows the GENIA corpus that it retains the tokenization criteria of the original Penn Treebank, but this must be reconsidered in future. For analysis of coordination with ellipsis, if the information on full forms is available, one strategy would be to leave the inside structure of coordination unann"
I05-2038,C04-1204,1,0.801337,"Missing"
I05-2038,tateisi-tsujii-2004-part,1,0.929229,"text of GTB is that of the GENIA corpus constructed at University of Tokyo (Kim et al., 2003), which is a collection of research abstracts selected from the search results of MEDLINE database with keywords (MeSH terms) human, blood cells and transcription factors. In the GENIA corpus, the abstracts are encoded in an XML scheme where each abstract is numbered with MEDLINE UID and contains title and abstract. The text of title and abstract is segmented into sentences in which biological terms are annotated with their semantic classes. The GENIA corpus is also annotated for part-ofspeech (POS) (Tateisi and Tsujii, 2004), and coreference is also annotated in a part of the GENIA corpus by MedCo project at Institute for Infocomm Research, Singapore (Yang et al, 2004). GTB is the addition of syntactic information to the GENIA corpus. By annotating various linguistic information on a same set of text, the GENIA corpus will be a resource not only for individual purpose such as named entity extraction or training parsers but also for integrated systems such as information extraction using deep linguistic analysis. Similar attempt of constructing integrated corpora is being done in University of Pennsylvania, where"
I05-2038,wermter-hahn-2004-annotated,0,0.0405149,"Missing"
I05-2038,A00-1031,0,0.0065685,"Missing"
L16-1607,anick-etal-2014-identification,0,0.0203449,"time mobile devices, Mac lower bound, cost, sentence Asia, space, between human, Eugene Charniak CRF, algorithm qualitative, new five, two-fold, several can, cannot, need to it, they Miyao and Tsujii 2008, [1] English, natural language NLP, biomedicine ERLA, universities F=0.98 Table 1: Entity tags, definitions and examples: names in monospaced font denotes the class in IAO (algorithms, materials, tools, and data used in invention), EFFECT (effects of a technology that can be expressed as a pair comprising an attribute and a value), and ATTRIBUTE and VALUE (attribute and value in the effect). Anick et al. (2014) extracted technology terms defined as Artifact (object created as a result of some process), Process/Technique (method for creation) or Field (a discipline or a scientific area relating to creation) using a corpus in which mentions of entities playing these roles are labeled. Roth and Klein (2015) extracted terms that denote an ACTION, ACTOR, OBJECT, and PROPERTY, using an annotated dataset in which entity mentions are labeled based on the ontology defined by Roth et al. (2014). In their ontology concepts are classified according to roles that things can play in a particular operation, such a"
L16-1607,I11-1001,0,0.225982,"based analysis such as information extraction (IE) concerning the methodological aspects of research papers and patents for analyzing technical trends and discovering emerging research fields. Their focus is on determining how things such as systems and data are developed and used. Consequently, in the annotated corpora used for establishing the systems for these purposes, things described in a document are labeled and classified according to their role in a certain context, such as application domain, method, and product. Some studies attach role-based labels to entity mentions. For example, Gupta and Manning (2011), in establishing a method for identifying the technical trends from abstracts in the ACL anthology 2 , extracted the FOCUS (main contribution of the article), DOMAIN (application domain), and TECHNIQUE (a method or tool used to achieve the FOCUS). The corpus used for the study attaches these labels directly to mentions of the corresponding entities. Similarly, Fukuda et al. (2012) annotated and classified entities in patent documents as TECHNOLOGY 2 3836 https://aclweb.org/anthology/ Type THING OCCURRENT PROCESS TIME CONTINUANT ARTIFACT DATA-ITEM LOCATION PERSON PLAN QUALITY QUANTITY MODALITY"
L16-1607,S10-1004,0,0.0371118,"DOMAIN (an area of study); and FORMULA (a mathematical formula). In addition, we defined the following compound or “ambiguous” types to handle systematic ambiguity in 3 Annotated Data Our dataset was constructed from 400 abstracts of research papers (250 abstracts from the ACL anthology and 150 from the ACM digital library 3 ). In the ACL subset, 150 abstracts were randomly selected from the entire set and the remaining 100 were randomly selected from the set used by Gupta and Manning (2011). The abstracts in the ACM subset were randomly selected from the set used for the SEMEVAL-2010 task 5 (Kim et al., 2010). Errors in text resulting from PDF conversion were manually corrected. Annotation was performed by a single annotator (the second author). A screenshot of the brat system (Stenetorp et al., 2012) is given in Figure 1 as an annotation example. In 1959 sentences in the ACL set, 14887 entities and 13310 relations were identified. In the 1213 sentences in the ACM set, the numbers of identified entities and relations were 12463 and 11201, respectively. The distributions of entity and relation types, in proportion, in the two domains are shown in Figures 2 and 3. The results shown in Figure 2 indic"
L16-1607,P03-1054,0,0.00501384,"riginal annotation on the same part of the abstract shown in Figure 1, converted to standoff format for displaying in brat. Their annotation is sparser than ours (Figure 1), annotating only terms related to the topic of the paper as a whole. For extraction, they used heuristic rules based on trigger words and Stanford dependencies such as “A term is FOCUS if it is the direct object of the verb present” as seed rules. Then, the rule set was enhanced by iteratively adding the head words of extracted phrases as the triggers. The abstracts were tokenized using the Stanford parser (version 3.4.1) (Klein and Manning 2003), and the tokens are labeled with binary labels for inclusion in GuptaManning terms for each topic class (FOCUS, DOMAIN, and TECHNIQUE). Then, the support vector classifier from the python scikit-learn 0.17 package (Pedregosa et al., 2011) with a linear kernel was used to predict the labels. We tested several combinations of the features from the Stanford parser and our annotation. The features from the Stanford parser were parts of speech (P in Table 5) and the triplet of type, direction (head or argument), and the part of speech of the token it depends/depended on, for each dependency involv"
L16-1607,J08-1002,1,0.854996,"Missing"
L16-1607,D14-1200,0,0.0358364,"Missing"
L16-1607,W09-3716,0,0.0330807,"otactic component (...). The three components mentioned are entities of different types, i.e., lexicon is a dataset (DATA-ITEM), and the others are program functions (PLAN). The current convention uses IS-A relation to relate components and lexicon etc., which is impossible without violating Rule-IS. This suggests that we need to define a new relation for role-playing and a new type or types for “role” words such as components. We also found that ambiguity and metonymic constructions cause annotation difficulty. These violations suggest a need for a type-coercion mechanism, such as dot-types (Pustejovsky et al. 2009). For example, when a process uses parameters, the names of the parameters can denote “the invocation of the process with the parameters” (e. g. RM pairs extracted can perform the mapping, where RM pairs extracted denotes a process using the pairs as parameters) and the name of data structure is used for both the data structure itself and the content of the data (Bigrams and trigrams are commonly used in statistical natural language processing). They lead to the annotation of APPLY-TO relation between DATAITEM and PROCESS, which violates Rule-APP. Another type of the problem is the ambiguity b"
L16-1607,W04-2401,0,0.0369304,"Missing"
L16-1607,W15-0403,0,0.0213946,"gs, definitions and examples: names in monospaced font denotes the class in IAO (algorithms, materials, tools, and data used in invention), EFFECT (effects of a technology that can be expressed as a pair comprising an attribute and a value), and ATTRIBUTE and VALUE (attribute and value in the effect). Anick et al. (2014) extracted technology terms defined as Artifact (object created as a result of some process), Process/Technique (method for creation) or Field (a discipline or a scientific area relating to creation) using a corpus in which mentions of entities playing these roles are labeled. Roth and Klein (2015) extracted terms that denote an ACTION, ACTOR, OBJECT, and PROPERTY, using an annotated dataset in which entity mentions are labeled based on the ontology defined by Roth et al. (2014). In their ontology concepts are classified according to roles that things can play in a particular operation, such as a participant, actor, object, and property. Another type of approach to capturing the structure of entity roles is to annotate the relationship between entities to label the entities as “things in a certain context” and “how they are related to other things in the same context”. Kameda et al. (20"
L16-1607,W14-2410,0,0.0296543,"ressed as a pair comprising an attribute and a value), and ATTRIBUTE and VALUE (attribute and value in the effect). Anick et al. (2014) extracted technology terms defined as Artifact (object created as a result of some process), Process/Technique (method for creation) or Field (a discipline or a scientific area relating to creation) using a corpus in which mentions of entities playing these roles are labeled. Roth and Klein (2015) extracted terms that denote an ACTION, ACTOR, OBJECT, and PROPERTY, using an annotated dataset in which entity mentions are labeled based on the ontology defined by Roth et al. (2014). In their ontology concepts are classified according to roles that things can play in a particular operation, such as a participant, actor, object, and property. Another type of approach to capturing the structure of entity roles is to annotate the relationship between entities to label the entities as “things in a certain context” and “how they are related to other things in the same context”. Kameda et al. (2013), using Related Work sections from the proceedings of the Association for the Advancement of Artificial Intelligence (AAAI2010), identified the papertopic relation along with the me"
L16-1607,D07-1111,0,0.0605503,"Missing"
L16-1607,E12-2021,1,0.768208,"taset was constructed from 400 abstracts of research papers (250 abstracts from the ACL anthology and 150 from the ACM digital library 3 ). In the ACL subset, 150 abstracts were randomly selected from the entire set and the remaining 100 were randomly selected from the set used by Gupta and Manning (2011). The abstracts in the ACM subset were randomly selected from the set used for the SEMEVAL-2010 task 5 (Kim et al., 2010). Errors in text resulting from PDF conversion were manually corrected. Annotation was performed by a single annotator (the second author). A screenshot of the brat system (Stenetorp et al., 2012) is given in Figure 1 as an annotation example. In 1959 sentences in the ACL set, 14887 entities and 13310 relations were identified. In the 1213 sentences in the ACM set, the numbers of identified entities and relations were 12463 and 11201, respectively. The distributions of entity and relation types, in proportion, in the two domains are shown in Figures 2 and 3. The results shown in Figure 2 indicate that software (PLAN, PLAN-OR-PROCESS) is more frequently discussed than hardware (ARTIFACT) in both the general computer science/technology domain (ACM) and the natural language processing sub"
L16-1607,W13-2318,1,0.777851,"Missing"
L16-1607,tateisi-etal-2014-annotation,1,0.890874,"gence (AAAI2010), identified the papertopic relation along with the method-purpose relation among concepts described in the paper in order to construct a network representing the methods developed in one study and used by others and to evaluate the influence of the research. Nassour-Kassis et al. (2015) identified the mentions of tasks and attributes and linked them with one of 6 types (Means-End, Instance-of, Consists-of, Associated-with, Contributes-to, and Compares-to) of relations, using ten articles on summarization for building a conceptual map in the natural language processing domain. Tateisi et al. (2014) developed a corpus on research articles from Journal of Information Processing Society of Japan (IPSJ Journal) where relationship among OBJECTS (named entities), MEASURE (judgment and evaluation, including numbers), and TERM (general technical concepts other than OBJECT and MEASURE) are identified and labeled with one of 16 types such as Apply-to (method-purpose), Evaluate (evaluation objectevaluation result), and Attribute (object-attribute), and developed a prototype of a keyword-based search system in which results can be filtered according to the relations involving the keyword. Those wor"
ohta-etal-2006-linguistic,I05-2038,1,\N,Missing
ohta-etal-2006-linguistic,W05-1308,0,\N,Missing
ohta-etal-2006-linguistic,W04-1207,0,\N,Missing
ohta-etal-2006-linguistic,W05-0304,0,\N,Missing
ohta-etal-2006-linguistic,W04-3111,0,\N,Missing
ohta-etal-2006-linguistic,tateisi-tsujii-2004-part,1,\N,Missing
ohta-etal-2006-linguistic,W04-1201,0,\N,Missing
P06-1128,P05-1022,0,0.00458241,"atabases. For biomedical terms other than genes/gene products, the Unified Medical Language System (UMLS) meta-thesaurus (Lindberg et al., 1993) is a large database that contains various names of biomedical and health-related concepts. Ontology databases provide mappings between textual expressions and entities in the real world. For example, Table 1 indicates that CRP, MGC88244, and PTX1 denote the same gene conceptually. Hence, these resources enable us to canonicalize variations of textual expressions of ontological entities. 2.2 Parsing technologies Recently, state-of-the-art CFG parsers (Charniak and Johnson, 2005) can compute phrase structures of natural sentences at fairly high accuracy. These parsers have been used in various NLP tasks including IE and text mining. In addition, parsers that compute deeper analyses, such as predicate argument structures, have become available for 1018 the processing of real-world sentences (Miyao and Tsujii, 2005). Predicate argument structures are canonicalized representations of sentence meanings, and express the semantic relations of words explicitly. Figure 1 shows an output of an HPSG parser (Miyao and Tsujii, 2005) for the sentence “A normal serum CRP measuremen"
P06-1128,I05-1018,1,0.746453,"aphies of articles, about half of which have abstracts. Research on IE and text mining in biomedical science has focused mainly on MEDLINE. In the present paper, we target all articles indexed in MEDLINE at the end of 2004 (14,785,094 articles). The following sections explain in detail off-/on-line processing for the text retrieval system for MEDLINE. 3.1 Off-line processing: HPSG parsing and term recognition We first parsed all sentences using an HPSG parser (Miyao and Tsujii, 2005) to obtain their predicate argument structures. Because our target is biomedical texts, we re-trained a parser (Hara et al., 2005) with the GENIA treebank (Tateisi et al., 2005), and also applied a bidirectional part-ofspeech tagger (Tsuruoka and Tsujii, 2005) trained with the GENIA treebank as a preprocessor. Because parsing speed is still unrealistic for parsing the entire MEDLINE on a single machine, we used two geographically separated computer clusters having 170 nodes (340 Xeon CPUs). These clusters are separately administered and not dedicated for use in the present study. In order to effectively use such an environment, GXP (Taura, 2004) was used to connect these clusters and distribute the load among them. Our p"
P06-1128,W04-3102,0,0.0566302,"nd: Resources and Tools for Semantic Annotations The proposed system for the retrieval of relational concepts is a product of recent developments in NLP resources and tools. In this section, ontology databases, deep parsers, and search algorithms for structured data are introduced. 2.1 Ontology databases Ontology databases are collections of words and phrases in specific domains. Such databases have been constructed extensively for the systematic management of domain knowledge by organizing textual expressions of ontological entities that are detached from actual sentences. For example, GENA (Koike and Takagi, 2004) is a database of genes and gene products that is semi-automatically collected from well-known databases, including HUGO, OMIM, Genatlas, Locuslink, GDB, MGI, FlyBase, WormBase, Figure 1: An output of HPSG parsing Figure 2: A predicate argument structure CYGD, and SGD. Table 1 shows an example of a GENA entry. “Symbol” and “Name” denote short forms and nomenclatures of genes, respectively. “Species” represents the organism species in which this gene is observed. “Synonym” is a list of synonyms and name variations. “Product” gives a list of products of this gene, such as proteins coded by this"
P06-1128,P05-1011,1,0.829945,"advance with semantic structures and are stored in a structured database. User requests are converted on the fly into patterns of these semantic annotations, and texts are retrieved by matching these patterns with the pre-computed semantic annotations. The accurate retrieval of relational concepts is attained because we can precisely describe relational concepts using semantic annotations. In addition, real-time retrieval is possible because semantic annotations are computed in advance. This framework has been implemented for a text retrieval system for MEDLINE. We first apply a deep parser (Miyao and Tsujii, 2005) and a dictionary-based term recognizer (Tsuruoka and Tsujii, 2004) to MEDLINE and obtain annotations of predicate argument structures and ontological identifiers of genes, gene products, diseases, and events. We then provide a search engine for these annotated sentences. User requests are converted into queries of region algebra (Clarke et al., 1995) extended with variables (Masuda et al., 2006) on these annotations. A search engine for the extended region algebra efficiently finds sentences having semantic annotations that match the input queries. In this paper, we evaluate this system with"
P06-1128,I05-2038,1,0.581796,"abstracts. Research on IE and text mining in biomedical science has focused mainly on MEDLINE. In the present paper, we target all articles indexed in MEDLINE at the end of 2004 (14,785,094 articles). The following sections explain in detail off-/on-line processing for the text retrieval system for MEDLINE. 3.1 Off-line processing: HPSG parsing and term recognition We first parsed all sentences using an HPSG parser (Miyao and Tsujii, 2005) to obtain their predicate argument structures. Because our target is biomedical texts, we re-trained a parser (Hara et al., 2005) with the GENIA treebank (Tateisi et al., 2005), and also applied a bidirectional part-ofspeech tagger (Tsuruoka and Tsujii, 2005) trained with the GENIA treebank as a preprocessor. Because parsing speed is still unrealistic for parsing the entire MEDLINE on a single machine, we used two geographically separated computer clusters having 170 nodes (340 Xeon CPUs). These clusters are separately administered and not dedicated for use in the present study. In order to effectively use such an environment, GXP (Taura, 2004) was used to connect these clusters and distribute the load among them. Our processes were given the lowest priority so that"
P06-1128,H05-1059,1,0.143897,"ainly on MEDLINE. In the present paper, we target all articles indexed in MEDLINE at the end of 2004 (14,785,094 articles). The following sections explain in detail off-/on-line processing for the text retrieval system for MEDLINE. 3.1 Off-line processing: HPSG parsing and term recognition We first parsed all sentences using an HPSG parser (Miyao and Tsujii, 2005) to obtain their predicate argument structures. Because our target is biomedical texts, we re-trained a parser (Hara et al., 2005) with the GENIA treebank (Tateisi et al., 2005), and also applied a bidirectional part-ofspeech tagger (Tsuruoka and Tsujii, 2005) trained with the GENIA treebank as a preprocessor. Because parsing speed is still unrealistic for parsing the entire MEDLINE on a single machine, we used two geographically separated computer clusters having 170 nodes (340 Xeon CPUs). These clusters are separately administered and not dedicated for use in the present study. In order to effectively use such an environment, GXP (Taura, 2004) was used to connect these clusters and distribute the load among them. Our processes were given the lowest priority so that our task would not disturb other users. We finished parsing the entire MEDLINE in"
P06-4005,P05-1011,1,0.777319,"Missing"
P06-4005,I05-1018,1,0.813084,"eather conditions forced them to scrub Monday’s scheduled return.” 3 MEDIE: a search engine for MEDLINE Figure 2 shows the top page of the MEDIE. MEDIE is an intelligent search engine for the accurate retrieval of relational concepts from MEDLINE 2 (Miyao et al., 2006). Prior to retrieval, all sentences are annotated with predicate argument structures and ontological identifiers by applying Enju and a term recognizer. 3.1 Automatically Annotated Corpus First, we applied a POS analyzer and then Enju. The POS analyzer and HPSG parser are trained by using the GENIA corpus (Tsuruoka et al., 2005; Hara et al., 2005), which comprises around 2,000 MEDLINE abstracts annotated with POS and Penn Treebank style syntactic parse trees (Tateisi et al., 2005). The HPSG parser generates parse trees in a stand-off format that can be converted to XML by combining it with the original text. We also annotated technical terms of genes and diseases in our developed corpus. Technical terms are annotated simply by exact matching of dictio2 Functions of MEDIE 4 Info-PubMed: a GUI-based MEDLINE search tool Info-PubMed is a MEDLINE search tool with GUI, helping users to find information about biomedical entities such as genes"
P06-4005,W05-1511,1,0.867094,"Missing"
P06-4005,I05-2038,1,0.900999,"e predicate type (e.g., adjective, intransitive verb), wh is the head word of the predicate, a is the argument label (MOD, ARG1, ..., ARG4), and wa is the head word of the argument. Precision/recall is the ratio of tuples correctly identified by the parser. The lexicon of the grammar was extracted from Sections 02-21 of Penn Treebank (39,832 sentences). In the table, ‘HPSG-PTB’ means that the statistical model was trained on Penn Treebank. ‘HPSG-GENIA’ means that the statistical model was trained on both Penn Treebank and GENIA treebank as described in (Hara et al., 2005). The GENIA treebank (Tateisi et al., 2005) consists of 500 abstracts (4,446 sentences) extracted from MEDLINE. Figure 1 shows a part of the parse tree and feaRecently, biomedical researchers have been facing the vast repository of research papers, e.g. MEDLINE. These researchers are eager to search biomedical correlations such as protein-protein or gene-disease associations. The use of natural language processing technology is expected to reduce their burden, and various attempts of information extraction using NLP has been being made (Blaschke and Valencia, 2002; Hao et al., 2005; Chun et al., 2006). However, the framework of traditi"
P06-4005,W04-3102,0,0.0153543,"of Informatics, Kogakuin University ¶ Information Technology Center, University of Tokyo † 1 http://www-tsujii.is.s.u-tokyo.ac.jp/enju/ 17 Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 17–20, c Sydney, July 2006. 2006 Association for Computational Linguistics nary entries and the terms separated by space, tab, period, comma, hat, colon, semi-colon, brackets, square brackets and slash in MEDLINE. The entire dictionary was generated by applying the automatic generation method of name variations (Tsuruoka and Tsujii, 2004) to the GENA dictionary for the gene names (Koike and Takagi, 2004) and the UMLS (Unified Medical Language System) meta-thesaurus for the disease names (Lindberg et al., 1993). It was generated by applying the name-variation generation method, and we obtained 4,467,855 entries of a gene and disease dictionary. 3.2 MEDIE provides three types of search, semantic search, keyword search, GCL search. GCL search provides us the most fundamental and powerful functions in which users can specify the boolean relations, linear order relation and structural relations with variables. Trained users can enjoy all functions in MEDIE by the GCL search, but it is not easy for"
P06-4005,P06-1128,1,\N,Missing
W00-1704,W98-1507,0,0.0605934,"ties” and the tasks we attempt involve recognition and classification of the names of substances and their locations, just as named entity recognition task in MUC conferences. We therefore try to model our annotation task after the definition of “EnameX” (Chincor, 1998a) of MUC conferences. Unlike in MUC conferences, we don’t make a precise definition of how the recognized names are used in further information extraction task such as event identification, because we want the recognition technology to be independent of the further task. Our work is also compared to word-sense annotation (e.g.,(Bruce and Wiebe, 1998)) where instances of words that have multiple senses are labelled for the sense it denotes according to a certain dictionary or thesaurus. We first built a conceptual model (ontology) of substances and sources (substance location), and designed a tag set based on the ontology which conforms to SGML/XML format. Using the tag set, we annotated the entities such names that appears in the abstracts of research papers taken from the MEDLINE database. In this paper we report on this new corpus, its ontological basis, and our experience in designing the annotation scheme. Experimental results are sho"
W00-1704,M98-1001,0,0.0143654,"sentations than the methods based on dictionaries and hand-constructed heuristic rules. We think that a corpus-based, machine-learning approach is quite promising, and to support this we are building a corpus of annotated abstracts taken from National Library of Medicine (NLM)’s MEDLINE database. Corpus annotation is now a key topic for all areas of natural language processing and linguistically annotated corpus such as treebanks are now established. In information extraction task, annotated corpora have been made mainly for the judgment set of information extraction competitions such as MUC (Chinchor, 1998). We think that technical terms of a scientific domain share common characteristics with the “Named Entities” and the tasks we attempt involve recognition and classification of the names of substances and their locations, just as named entity recognition task in MUC conferences. We therefore try to model our annotation task after the definition of “EnameX” (Chincor, 1998a) of MUC conferences. Unlike in MUC conferences, we don’t make a precise definition of how the recognized names are used in further information extraction task such as event identification, because we want the recognition tech"
W00-1704,M98-1028,0,0.067007,"sing and linguistically annotated corpus such as treebanks are now established. In information extraction task, annotated corpora have been made mainly for the judgment set of information extraction competitions such as MUC (Chinchor, 1998). We think that technical terms of a scientific domain share common characteristics with the “Named Entities” and the tasks we attempt involve recognition and classification of the names of substances and their locations, just as named entity recognition task in MUC conferences. We therefore try to model our annotation task after the definition of “EnameX” (Chincor, 1998a) of MUC conferences. Unlike in MUC conferences, we don’t make a precise definition of how the recognized names are used in further information extraction task such as event identification, because we want the recognition technology to be independent of the further task. Our work is also compared to word-sense annotation (e.g.,(Bruce and Wiebe, 1998)) where instances of words that have multiple senses are labelled for the sense it denotes according to a certain dictionary or thesaurus. We first built a conceptual model (ontology) of substances and sources (substance location), and designed a"
W00-1704,M98-1024,0,0.127633,"sing and linguistically annotated corpus such as treebanks are now established. In information extraction task, annotated corpora have been made mainly for the judgment set of information extraction competitions such as MUC (Chinchor, 1998). We think that technical terms of a scientific domain share common characteristics with the “Named Entities” and the tasks we attempt involve recognition and classification of the names of substances and their locations, just as named entity recognition task in MUC conferences. We therefore try to model our annotation task after the definition of “EnameX” (Chincor, 1998a) of MUC conferences. Unlike in MUC conferences, we don’t make a precise definition of how the recognized names are used in further information extraction task such as event identification, because we want the recognition technology to be independent of the further task. Our work is also compared to word-sense annotation (e.g.,(Bruce and Wiebe, 1998)) where instances of words that have multiple senses are labelled for the sense it denotes according to a certain dictionary or thesaurus. We first built a conceptual model (ontology) of substances and sources (substance location), and designed a"
W00-1704,P99-1032,0,0.0500168,"Missing"
W03-1313,W03-2416,1,0.916478,"emas, XPointer, SAX, etc. The higher level standards, of meta-data (RDF) and ontologies (OWL) have been especially influential in encoding biomedical resources. However, there remains the question how to best encode the structure of the text themselves, how to mark-up added linguistic analyses, and how to implement linkages between the text and and further resources, such as lexica, thesauri and ontologies. As discussed in (Ide and Brew, 2000), in order to qualify as a “good” annotated corpus, its encoding should provide for reusabilty and extensibily. In this paper we build on previous work (Erjavec et al., 2003) and show how to develop a standardised encoding for biomedical corpora. We base our discussion on the case of the GENIA corpus (Ohta et al., 2002), which is originaly encoded in GPML, the GENIA Project Markup Language, an XML DTD. We re-encode the corpus into a standardised annotation scheme, based on the Text Encoding Initiative Guidelines P4 (Sperberg-McQueen and Burnard, 2002), and specify a constructive mapping from the original DTD to the developed encoding via a XSLT transformation. One of the motivations for such an re-encoding is that TEI is well-designed and widely accepted architect"
W03-1313,W02-1706,0,0.0309681,"r direct reference to the token stream of the text, so if this is incorrect, errors will propagate to all other annotations. It is also interesting to note that current annotation practice is more and more leaning toward standoff markup, i.e., annotations that are separated from the primary data (text) and make reference to it only via pointers. However, it is beneficial to have some markup in the primary data to which it is possible to refer, and this markup is, almost exclusivelly, that of tokens; see e.g., (Freese et al., 2003). Version V1.1 of GENIA has been also annotated with LTG tools (Grover et al., 2002). In short, the corpus is tokenised, and then part-of-speech tagged with two taggers, each one using a different tagset, and the nouns and verbs lemmatised. Additionally, the deverbal nominalisations are assigned their verbal stems. The conversion to TEI is also able to handle this additional markup, by using the TEI.analysis module. The word and punctuation tokens are encoded as hwi and hci elements respectively, which are further marked with type and lemma and the locally defined c1, c2 and vstem. An example of such markup is given in Figure 3. Given the high density of technical terms, biom"
W06-1634,H94-1020,0,0.10923,"Missing"
W06-1634,P03-1029,0,0.0540281,"ons for information like protein-protein interactions. Full parsing is more effective for acquiring generalized data from long-length words than shallow parsing. The sentences at left in Figure 1 exemplify the advantages of full parsing. The gerund “activating” in the last sentence takes a non-local semantic subject “ENTITY1”, and shallow parsing cannot recognize this relation because “ENTITY1” and “activating” are in different phrases. Full parsing, on the other hand, can identify both the subject of the whole sentence and the semantic subject of “activating” have been shared. 3 Related Work Sudo et al. (2003), Culotta and Sorensen (2004) and Bunescu and Mooney (2005) acquired substructures derived from dependency trees as extraction patterns for IE in general domains. Their approaches were similar to our approach using PASs derived from full parsing. However, one problem with their systems is that they could not treat non-local dependencies such as semantic subjects of gerund constructions (discussed in Section 2), and thus rules acquired from the constructions were partial. Bunescu and Mooney (2006) also learned extraction patterns for protein-protein interactions by SVM with a generalized subseq"
W06-1634,P04-1056,0,0.125732,"Missing"
W06-1634,H05-1091,0,0.0138968,"s. Full parsing is more effective for acquiring generalized data from long-length words than shallow parsing. The sentences at left in Figure 1 exemplify the advantages of full parsing. The gerund “activating” in the last sentence takes a non-local semantic subject “ENTITY1”, and shallow parsing cannot recognize this relation because “ENTITY1” and “activating” are in different phrases. Full parsing, on the other hand, can identify both the subject of the whole sentence and the semantic subject of “activating” have been shared. 3 Related Work Sudo et al. (2003), Culotta and Sorensen (2004) and Bunescu and Mooney (2005) acquired substructures derived from dependency trees as extraction patterns for IE in general domains. Their approaches were similar to our approach using PASs derived from full parsing. However, one problem with their systems is that they could not treat non-local dependencies such as semantic subjects of gerund constructions (discussed in Section 2), and thus rules acquired from the constructions were partial. Bunescu and Mooney (2006) also learned extraction patterns for protein-protein interactions by SVM with a generalized subsequence kernel. Their patterns are sequences of words, POSs,"
W06-1634,P05-1052,0,0.0403215,"within the high-recall range. Compared to theirs, one of our problems is that our method could not handle attributives. One example is “binding property of ENTITY1 to ENTITY2”. We could not obtain “binding” because the smallest set of PASs connecting “ENTITY1” and “ENTITY2” includes only the PASs of “property”, “of” and “to”. To handle these attributives, we need distinguish necessary attributives from those that are general4 by semantic analysis or bootstrapping. Another approach to improve our method is to include local information in sentences, such as surface words between protein names. Zhao and Grishman (2005) reported that adding local information to deep syntactic information improved IE results. This approach is also applicable to IE in other domains, where related entities are in a short 5.3.2 Lack of Necessary Patterns and Learning of Inappropriate Patterns There are two different reasons causing the problems with the lack of necessary patterns and the learning of inappropriate patterns: (1) the training corpus was not sufﬁciently large to saturate IE accuracy and (2) our method of pattern construction was too limited. Effect of Training Corpus Size To investigate whether the training corpus w"
W06-1634,P04-1054,0,0.0565752,"like protein-protein interactions. Full parsing is more effective for acquiring generalized data from long-length words than shallow parsing. The sentences at left in Figure 1 exemplify the advantages of full parsing. The gerund “activating” in the last sentence takes a non-local semantic subject “ENTITY1”, and shallow parsing cannot recognize this relation because “ENTITY1” and “activating” are in different phrases. Full parsing, on the other hand, can identify both the subject of the whole sentence and the semantic subject of “activating” have been shared. 3 Related Work Sudo et al. (2003), Culotta and Sorensen (2004) and Bunescu and Mooney (2005) acquired substructures derived from dependency trees as extraction patterns for IE in general domains. Their approaches were similar to our approach using PASs derived from full parsing. However, one problem with their systems is that they could not treat non-local dependencies such as semantic subjects of gerund constructions (discussed in Section 2), and thus rules acquired from the constructions were partial. Bunescu and Mooney (2006) also learned extraction patterns for protein-protein interactions by SVM with a generalized subsequence kernel. Their patterns"
W06-1634,P05-1053,0,0.0780532,"Missing"
W09-1301,doddington-etal-2004-automatic,0,0.0136738,"e.g. database curation efforts, most domain RE efforts target relations involving biologically relevant changes in the involved entities, commonly to the complete exclusion of static relations. However, static relations such as entity membership in a family and one entity being a part of another are not only 1 relevant IE targets in themselves but can also play an important supporting role in IE systems not primarily targeting them. In this paper, we investigate the role of static relations in causal RE and event extraction. Here, we use relation extraction in the MUC and ACE (Sundheim, 1995; Doddington et al., 2004) sense to refer to the task of extracting binary relations, ordered pairs of entities, where both participating entities must be specified and their roles (agent, patient, etc.) are fixed by the relation. By contrast, event extraction is understood to involve events (things that happen) and representations where the number and roles of participants may vary more freely. We refer to relations where one one entity causes another to change as causal relations; typical domain examples are phosphorylation and activation. Static relations, by contrast, hold between two entities without implication o"
W09-1301,S07-1003,0,0.00870172,"Missing"
W09-1301,W09-1401,1,0.666271,"well studied and several biomedProceedings of the Workshop on BioNLP, pages 1–9, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics ical NER systems are available (see e.g. (Wilbur et al., 2007; Leaman and Gonzalez, 2008)), and most domain IE approaches are NE-driven: a typical way to cast the RE task is as deciding for each pair of co-occurring NEs whether a relevant relation is stated for them in context. Like the previous LLL and BioCreative2-PPI relation extraction tasks (N´edellec, 2005; Krallinger et al., 2007), the BioNLP’09 shared task on event extraction (Kim et al., 2009) similarly proceeds from NEs, requiring participants to detect events and determine the roles given NEs play in them. Any domain IE approach targeting nontrivial causal NE relations or events necessarily involves decisions relating to static relations. Consider, for example, the decision whether to extract a relation between NE1 and NE2 in the following cases (affects should here be understood as a placeholder for any relevant statement of causal relation): 1) NE1 affects NE2 gene 2) NE1 affects NE2 promoter 3) NE1 affects NE2 mutant 4) NE1 affects NE2 antibody 5) NE1 affects NE2 activator The"
W09-1301,de-marneffe-etal-2006-generating,0,0.054107,"Missing"
W09-1301,W01-0511,0,0.0903008,"nt relations To avoid unnecessary division of relations that imply in our context similar interpretation and processing, we define a task-specific Variant relation that encompasses a set of possible relation types holding between an NE and its variants along multiple different axes. One significant class of cases annotated as Variant includes expressions such as NE gene and NE protein, under the interpretation that NE refers to the abstract information that is “realized” as either DNA, RNA or protein form, and the entity to one of these realizations (for alternative interpretations, see e.g. (Rosario and Hearst, 2001; Heimonen et al., 2008)). The Variant relation is also used to annotate NEentity relations where the entity expresses a different state of the NE, such as a phosphorylated or mutated state. While each possible post-translational modification, for example, could alternatively be assigned a specific relation type, in the present IE context these would only increase the difficulty of the task without increasing the applicability of the resulting annotation. the corpus contained frequent cases where the stated relationship of the NE to the entity involved different types of relevant relations (e."
W09-1301,M95-1002,0,0.226052,"biologists and e.g. database curation efforts, most domain RE efforts target relations involving biologically relevant changes in the involved entities, commonly to the complete exclusion of static relations. However, static relations such as entity membership in a family and one entity being a part of another are not only 1 relevant IE targets in themselves but can also play an important supporting role in IE systems not primarily targeting them. In this paper, we investigate the role of static relations in causal RE and event extraction. Here, we use relation extraction in the MUC and ACE (Sundheim, 1995; Doddington et al., 2004) sense to refer to the task of extracting binary relations, ordered pairs of entities, where both participating entities must be specified and their roles (agent, patient, etc.) are fixed by the relation. By contrast, event extraction is understood to involve events (things that happen) and representations where the number and roles of participants may vary more freely. We refer to relations where one one entity causes another to change as causal relations; typical domain examples are phosphorylation and activation. Static relations, by contrast, hold between two enti"
W09-1301,I05-2038,1,0.170621,"ation criteria, NE and entity types, granularity of relations, etc.), we find the outcome — which was neither planned for nor forced on the data — a very encouraging sign of the sufficiency of the task setting for this and related domain IE tasks. 3.4 We created the data set by building on the annotation of the GENIA Event corpus (Kim et al., 2008), making use of the rich set of annotations already contained in the corpus: term annotation for NEs and other entities (Ohta et al., 2002), annotation of events between these terms, and treebank structure closely following the Penn Treebank scheme (Tateisi et al., 2005). Other/Out annotation We apply a catch-all category, Other/Out, for annotating candidate (NE, entity) pairs between which there is no relevant static relation. This label is thus applied to a number of quite different cases: causal relations, both implied (e.g. NE receptors, NE response element) and explicitly stated (NE binds the [site]), relations where the entity is considered too far removed from the NE to support reliable inference of a role for the NE in causal relations/events involving the entity (e.g. [antibodies] for NE), and cases where no relation is stated (e.g. NE and other [pro"
W09-1401,P05-1022,0,0.128444,"of event extraction, we prepared publicly available BioNLP resources readily available for the shared task. Several fundamental BioNLP tools were provided through U-Compare (Kano et al., 2009)2 , which included tools for tokenization, sentence segmentation, part-of-speech tagging, chunking and syntactic parsing. Participants were also provided with the syntactic analyses created by a selection of parsers. We applied two mainstream Penn Treebank (PTB) phrase structure parsers: the Bikel parser3 , implementing Collins’ parsing model (Bikel, 2004) and trained on PTB, and the reranking parser of (Charniak and Johnson, 2005) with the self-trained biomedical parsing model of (McClosky and Charniak, 2008)4 . We also applied the GDep5 , native dependency parser trained on the GENIA Treebank 2 http://u-compare.org/ http://www.cis.upenn.edu/∼dbikel/software.html 4 http://www.cs.brown.edu/∼dmcc/biomedical.html 5 http://www.cs.cmu.edu/∼sagae/parser/gdep/ 3 Team UTurku JULIELab Task 1-1-- Org 3C+2BI 1C+2L+2B ConcordU 1-3 3C Word Porter OpenNLP Porter Stanford UT+DBCLS 12- 2C Porter VIBGhent UTokyo 1-3 1-- 2C+1B 3C Porter, GTag UNSW UZurich 1-1-- 1C+1B 3C ASU+HU+BU 123 6C+2BI LingPipe, Morpha Porter Cam UAntwerp 1-12- 3C"
W09-1401,M98-1001,0,0.713763,"sub-tasks, each of which addresses bio-molecular event extraction at a different level of specificity. The data was developed based on the GENIA event corpus. The shared task was run over 12 weeks, drawing initial interest from 42 teams. Of these teams, 24 submitted final results. The evaluation results are encouraging, indicating that state-of-the-art performance is approaching a practically applicable level and revealing some remaining challenges. 1 Introduction The history of text mining (TM) shows that shared tasks based on carefully curated resources, such as those organized in the MUC (Chinchor, 1998), TREC (Voorhees, 2007) and ACE (Strassel et al., 2008) events, have significantly contributed to the progress of their respective fields. This has also been the case in bio-TM. Examples include the TREC Genomics track (Hersh et al., 2007), JNLPBA (Kim et al., 2004), LLL (N´edellec, 2005), and BioCreative (Hirschman et al., 2007). While the first two addressed bio-IR (information retrieval) and bio-NER (named entity recognition), respectively, the last two focused on bio-IE (information extraction), seeking relations between bio-molecules. With the emergence of NER systems with performance cap"
W09-1401,de-marneffe-etal-2006-generating,0,0.604282,"Missing"
W09-1401,W04-1213,1,0.414702,"ted final results. The evaluation results are encouraging, indicating that state-of-the-art performance is approaching a practically applicable level and revealing some remaining challenges. 1 Introduction The history of text mining (TM) shows that shared tasks based on carefully curated resources, such as those organized in the MUC (Chinchor, 1998), TREC (Voorhees, 2007) and ACE (Strassel et al., 2008) events, have significantly contributed to the progress of their respective fields. This has also been the case in bio-TM. Examples include the TREC Genomics track (Hersh et al., 2007), JNLPBA (Kim et al., 2004), LLL (N´edellec, 2005), and BioCreative (Hirschman et al., 2007). While the first two addressed bio-IR (information retrieval) and bio-NER (named entity recognition), respectively, the last two focused on bio-IE (information extraction), seeking relations between bio-molecules. With the emergence of NER systems with performance capable of supporting practical applications, the recent interest of the bio-TM community is shifting toward IE. Similarly to LLL and BioCreative, the BioNLP’09 Shared Task (the BioNLP task, hereafter) also addresses bio-IE, but takes a definitive step further toward f"
W09-1401,P08-2026,0,0.440867,"ailable for the shared task. Several fundamental BioNLP tools were provided through U-Compare (Kano et al., 2009)2 , which included tools for tokenization, sentence segmentation, part-of-speech tagging, chunking and syntactic parsing. Participants were also provided with the syntactic analyses created by a selection of parsers. We applied two mainstream Penn Treebank (PTB) phrase structure parsers: the Bikel parser3 , implementing Collins’ parsing model (Bikel, 2004) and trained on PTB, and the reranking parser of (Charniak and Johnson, 2005) with the self-trained biomedical parsing model of (McClosky and Charniak, 2008)4 . We also applied the GDep5 , native dependency parser trained on the GENIA Treebank 2 http://u-compare.org/ http://www.cis.upenn.edu/∼dbikel/software.html 4 http://www.cs.brown.edu/∼dmcc/biomedical.html 5 http://www.cs.cmu.edu/∼sagae/parser/gdep/ 3 Team UTurku JULIELab Task 1-1-- Org 3C+2BI 1C+2L+2B ConcordU 1-3 3C Word Porter OpenNLP Porter Stanford UT+DBCLS 12- 2C Porter VIBGhent UTokyo 1-3 1-- 2C+1B 3C Porter, GTag UNSW UZurich 1-1-- 1C+1B 3C ASU+HU+BU 123 6C+2BI LingPipe, Morpha Porter Cam UAntwerp 1-12- 3C 3C Porter GTag UNIMAN 1-- 4C+2BI Porter GTag SCAI UAveiro USzeged 1-1-1-3 1C 1C+"
W09-1401,W09-1313,1,0.461582,"differences in annotation principles compared to other biomedical NE corpora. For instance, the NE annotation in the widely applied GENETAG corpus (Tanabe et al., 2005) does not differentiate proteins from genes, while GENIA annotation does. Such differences have caused significant inconsistency in methods and resources following different annotation schemes. To remove or reduce the inconsistency, GENETAG-style NE annotation, which we term gene-or-gene-product (GGP) annotation, has been added to the GENIA corpus, with appropriate revision of the original annotation. For details, we refer to (Ohta et al., 2009). The NE annotation used in the BioNLP task data is based on this annotation. 3.2 Argument revision The GENIA event annotation was made based on the GENIA event ontology, which uses a loose typing system for the arguments of each event class. For example, in Figure 2(a), it is expressed that the binding event involves two proteins, TRAF2 and CD40, and that, in the case of CD40, its cytoplasmic domain takes part in the binding. Without constraints on the type of theme arguments, the following two annotations are both legitimate: (Type:Binding, Theme:TRAF2, Theme:CD40) (Type:Binding, Theme:TRAF2"
W09-1401,W09-1301,1,0.380624,"om (a) PMID7541987 (simplified), (b) PMID10224278, (c) PMID10090931, (d) PMID9243743, (e) PMID7635985. (Type:Binding, Theme1:TRAF2, Theme2:CD40, Site2:cytoplasmic domain) Note that the protein, CD40, and its domain, cytoplasmic domain, are associated by argument numbering. To resolve issues related to the mapping between proteins and related entities systematically, we introduced partial static relation annotation for relations such as Part-Whole, drawing in part on similar annotation of the BioInfer corpus (Pyysalo et al., 2007). For details of this part of the revision process, we refer to (Pyysalo et al., 2009). Figure 2 shows some challenging cases. In (b), the site GATA motifs is not identified as an argument of the binding event, because the protein containing it is not stated. In (c), among the two sites (PEBP2 site and promoter) of the gene GM-CSF, only the more specific one, PEBP2, is annotated. The equivalent entity annotation in the revised GENIA corpus covers also cases other than simple apposition, illustrated in Figure 3. A frequent case in biomedical literature involves use of the slash symbol (“/”) to state synonyms. The slash symbol is ambiguous as it is used also to indicate dimerized"
W09-1401,strassel-etal-2008-linguistic,0,0.0454823,"r event extraction at a different level of specificity. The data was developed based on the GENIA event corpus. The shared task was run over 12 weeks, drawing initial interest from 42 teams. Of these teams, 24 submitted final results. The evaluation results are encouraging, indicating that state-of-the-art performance is approaching a practically applicable level and revealing some remaining challenges. 1 Introduction The history of text mining (TM) shows that shared tasks based on carefully curated resources, such as those organized in the MUC (Chinchor, 1998), TREC (Voorhees, 2007) and ACE (Strassel et al., 2008) events, have significantly contributed to the progress of their respective fields. This has also been the case in bio-TM. Examples include the TREC Genomics track (Hersh et al., 2007), JNLPBA (Kim et al., 2004), LLL (N´edellec, 2005), and BioCreative (Hirschman et al., 2007). While the first two addressed bio-IR (information retrieval) and bio-NER (named entity recognition), respectively, the last two focused on bio-IE (information extraction), seeking relations between bio-molecules. With the emergence of NER systems with performance capable of supporting practical applications, the recent i"
W09-1401,I05-2038,1,0.385704,"bioinformaticians (BI), biologists (B) and liguists (L). This may be attributed in part to the fact that the event extraction task required complex computational modeling. The role of computer scientists may be emphasized in part due to the fact that the task was novel to most participants, requiring particular efforts in framework design and implementation and computational resources. This also suggests there is room for improvement from more input from biologists. In total, 42 teams showed interest in the shared task and registered for participation, and 24 teams sub7.2 Evaluation results (Tateisi et al., 2005), and a version of the C&C CCG deep parser6 adapted to biomedical text (Rimell and Clark, 2008). The text of all documents was segmented and tokenized using the GENIA Sentence Splitter and the GENIA Tagger, provided by U-Compare. The same segmentation was enforced for all parsers, which were run using default settings. Both the native output of each parser and a representation in the popular Stanford Dependency (SD) format (de Marneffe et al., 2006) were provided. The SD representation was created using the Stanford tools7 to convert from the PTB scheme, the custom conversion introduced by (Ri"
W09-1401,J04-4004,0,\N,Missing
W10-1903,W09-1403,0,0.198686,"Missing"
W10-1903,W09-1313,1,0.711856,"applied to statements that involve the occurrence of a change in the state of an entity – even if stated as having occurred in the past, or only hypothetically – but not in cases merely discussing the state or properties of entities, even if these can serve as the basis for inference that a specific change has occurred. We found that many of the spans an2.5 Annotation results The new PTM annotation covers 157 PubMed abstracts. Following the model of the BioNLP shared task, all mentions of specific gene or gene product names in the abstracts were annotated, applying the annotation criteria of (Ohta et al., 2009). This new named entity annotation covers 1031 gene/gene product mentions, thus averaging more than six mentions per annotated abstract. In total, 422 events of which 405 are of the novel PTM 23 Event type Glycosylation Hydroxylation Methylation Acetylation Positive reg. Phosphorylation Protein modification TOTAL Count 122 103 90 90 12 3 2 422 applies a pipeline architecture consisting of three supervised classification-based modules: a trigger detector, an event edge detector, and an event detector. In evaluation on the BioNLP shared task test data, the system extracted phosphorylation events"
W10-1903,W09-1401,1,0.848379,"and the specific modified site are expected to be of more practical interest. However, we note that the greater number of multi-argument events is expected to make the dataset more challenging as an extraction target. 3 Evaluation 3.2 To estimate the capacity of the newly annotated resource to support the extraction of the targeted PTM events and the performance of current event extraction methods at open-domain PTM extraction, we performed a set of experiments using an event extraction method competitive with the state of the art, as established in the BioNLP shared task on event extraction (Kim et al., 2009a; Bj¨orne et al., 2009). 3.1 Data Preparation The corpus data was split into training and test sets on the document level with a sampling strategy that aimed to preserve a roughly 3:1 ratio of occurrences of each event type between training and test data. The test data was held out during system development and parameter selection and only applied in a single final experiment. The event extraction system was trained using the 112 abstracts of the training set, further using 24 of the abstracts Methods 6 We note that in the BioNLP shared task data, all arguments were contained within single se"
W10-1903,P06-4005,1,\N,Missing
W10-1903,P06-1128,1,\N,Missing
W10-1919,P08-2026,0,0.0668102,"Missing"
W10-1919,W09-1402,0,0.0253425,"Missing"
W10-1919,W09-1313,1,0.872817,"Missing"
W10-1919,de-marneffe-etal-2006-generating,0,0.0410254,"Missing"
W10-1919,W09-1401,1,\N,Missing
W10-1921,S07-1003,0,0.0472074,"Missing"
W10-1921,W09-2415,0,0.023149,"Missing"
W10-1921,W09-1301,1,0.931667,"have evolved from extracting simple binary relations between genes or proteins to a more expressive event representation (Kim et al., 2009). Furthermore, new data sets have been developed targeting relations between genes and gene products (GGPs) and a broader category of entities, covering terms that can not be annotated as named entities (NEs) but that are still highly relevant for biomedical information extraction (Ohta et al., 2009b). In contrast to relations involving change or causality, the annotation for this data covers relations such as part-of, here termed “static relations” (SR) (Pyysalo et al., 2009). In addition to providing enhanced representation of biological processes, the SR data set also offers interesting opportunities to improve on event extraction. As an example, consider the sentence presented in Figure 2, in which “c-Rel” and “p50” are both annotated as being subunits of the 144 Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 144–152, c Uppsala, Sweden, 15 July 2010. 2010 Association for Computational Linguistics Event type Gene expression Transcription Protein catabolism Localization Phosphorylation Binding Regulation Positive regul"
W10-1921,W09-1419,1,0.907894,"Missing"
W10-1921,W09-1401,1,0.931626,"” and “transcription starts”. These two terms provide more detailed information on the regulation event. Thus, by combining the two types of annotation, a text mining algorithm will be able to provide a more detailed representation of the extracted information. This would be in particular beneficial in practical applications such as abstract summarization or integration of the predictions into complex regulatory pathways. Introduction Recently, biomedical text mining tools have evolved from extracting simple binary relations between genes or proteins to a more expressive event representation (Kim et al., 2009). Furthermore, new data sets have been developed targeting relations between genes and gene products (GGPs) and a broader category of entities, covering terms that can not be annotated as named entities (NEs) but that are still highly relevant for biomedical information extraction (Ohta et al., 2009b). In contrast to relations involving change or causality, the annotation for this data covers relations such as part-of, here termed “static relations” (SR) (Pyysalo et al., 2009). In addition to providing enhanced representation of biological processes, the SR data set also offers interesting opp"
W10-1921,P03-1054,0,0.00281811,"in text by using automatically curated dictionaries. Subsequently, candidate events are formed by combining these triggers with an appropriate number of GGPs co-occurring in the same sentence. For each distinct event type, a classifier is then built using all training examples for that specific type. Final predictions are merged for all types, forming a complex interaction graph for each article in the test set. To distinguish between positive instances and negatives, the framework extracts rich feature vecTo derive syntactic patterns, dependency parsing is applied using the Stanford parser (Klein and Manning, 2003; De Marneffe et al., 2006). Specifically, for each candidate event, the smallest subgraph is built including the relevant nodes for the trigger and the GGP names. Each edge in this subgraph then gives rise to a pattern including the information from the connecting nodes (or vertices) in combination with the syntactic relation specified by the edge. Trigger words and GGP names are blinded by replacing their text with the strings protx and trigger (respectively), resulting in highly general features. Figure 3 depicts an exemplary dependency graph. For the Binding event between c-Rel and p50, th"
W10-1921,D09-1013,0,0.0455981,"Missing"
W10-1921,de-marneffe-etal-2006-generating,0,\N,Missing
W10-1921,W09-1313,1,\N,Missing
W10-1921,S10-1006,0,\N,Missing
W11-0214,W09-1401,1,0.957728,"relations representing associations such as protein-protein interactions (Pyysalo et al., 2008; Tikk et al., 2010). In recent years, an increasing number of resources and methods pursuing more detailed representations of extracted information are becoming available (Pyysalo et al., 2007; Kim et al., 2008; Thompson et al., 2009; Bj¨orne et al., 2010). The main thrust of this move toward structured, finegrained information extraction falls under the heading of event extraction (Ananiadou et al., 2010), an approach popularized and represented in particular by the BioNLP Shared Task (BioNLP ST) (Kim et al., 2009a; Kim et al., 2011). While a detailed representation of extracted information on biomolecular events has several potential applications ranging from semantic search to database curation support (Ananiadou et al., 2010), the number of practical applications making use of this technology has arguably so far been rather limited. In this study, we pursue in particular the opportunities that event extraction holds for pathway annotation support,1 arguing that the match between The construction of pathways is a major focus of present-day biology. Typical pathways involve large numbers of entities o"
W11-0214,W11-1801,1,0.896597,"Missing"
W11-0214,P09-1113,0,0.0159016,"bustness. Conversion from pathways into the event representation opens up a number of opportunities, such as the ability to directly query large-scale event repositories (e.g. (Bj¨orne et al., 2010)) for specific pathway reactions. For pathways where reactions are marked with literature references, conversion further allows event annotations relevant to specific documents to be created automatically, sparing manual annotation costs. While such event annotations will not be bound to specific text expressions, they could be used through the application of techniques such as distant supervision (Mintz et al., 2009). As a first attempt, the conversion introduced in this work is limited in a number of ways, but we hope it can serve as a starting point for both wider adoption of pathway resources for event extraction and further research into accurate conversions between the two. The conversion software, SBML-to-event, is freely available for research purposes. 6 Discussion and Conclusions Over the last decade, the bio-community has invested enormous efforts in the construction of detailed models of the function of a large variety of biological systems in the form of pathways. These efforts toward building"
W11-0214,W09-1313,1,0.927341,"pe Drug. The same holds (with somewhat less specificity) for GENIA I NOR GANIC COMPOUND . Finally, although annotated in GENIA, the category of protein complexes has no correspondence among the entities considered in the BioNLP ST representation. Thus, information extraction systems applying the core BioNLP ST entity types will entirely lack coverage for protein complexes and will not be able 6 While the term P ROTEIN appears to suggest that the class consists only of protein forms, these entities are in fact annotated in the BioNLP ST data according to the GENIA gene/gene product guidelines (Ohta et al., 2009) and thus include also DNA and RNA forms. The type could arguably more accurately be named G ENE OR GENE PRODUCT. Pathway CellDesigner BioPAX State transition BiochemicalReaction Truncation BiochemicalReaction Transcription BiochemicalReaction Translation BiochemicalReaction Association ComplexAssembly Dissociation ComplexAssembly Transport Transport w/reaction Degradation Degradation Catalysis Catalysis Physical stimulation Control Modulation Control Trigger Control Inhibition Control Event ST’11 (see Table 3) Catabolism Catabolism Transcription Transcription Binding Binding Localization Loca"
W11-0214,W11-1803,1,0.87717,"Missing"
W11-0214,W11-1804,1,0.847779,"Missing"
W11-0215,W11-1828,0,0.226162,"Missing"
W11-0215,W09-1402,0,0.0757843,"Missing"
W11-0215,W10-1904,1,0.895723,"Missing"
W11-0215,W09-1403,0,0.369926,"Missing"
W11-0215,W11-1801,1,0.888281,"Missing"
W11-0215,C10-1088,1,0.850253,"criteria of the BioNLP Shared Task. The evaluation is event instance-based and uses the standard precision/recall/F1 -score metrics. We modified the shared task evaluation software to support the newly defined event types and ran experiments with the standard approximate span matching and partial recursive matching criteria (see (Kim et al., 2009)). We further follow the EPI task evaluation in reporting results separately for the extraction of only Theme and Cause arguments (core task) and for the full argument set. 5.2 Event extraction method We applied the EventMine event extraction system (Miwa et al., 2010a; Miwa et al., 2010b), an SVMbased pipeline system using an architecture similar to that of the best-performing system in the BioNLP ST’09 (Bj¨orne et al., 2009); we refer to the studies of Miwa et al. for detailed description of the base system. For analysing sentence structure, we applied the mogura 2.4.1 (Matsuzaki and Miyao, 2007) and GDep beta2 (Sagae and Tsujii, 2007) parsers. For the present study, we modified the base EventMine system as follows. First, to improve efficiency and generalizability, instead of using all words as trigger candidates as in the base system, we filtered candi"
W11-0215,nawaz-etal-2010-meta,0,0.0203,"egulation of modifi1 GO structure and statistics from data retrieved Dec. 2010. Figure 2: Comparison of hypothetical text-bound GO annotation with specific terms (top) and event annotation with general GO terms (bottom). cation, as these are captured using separate events in the applied representation, as illustrated in Figure 1. For an analogous reason, we do not separately include type-level distinctions for “magnitude” variants of terms (e.g. monoubiquitination, polyubiquitination) as these can be systematically modeled as aspects that can mark any event (cf. the low/neutral/high Manner of Nawaz et al. (2010)). Second, a number of the GO terms identify reactions that are in scope of previously defined (nonmodification) event types in existing resources. To avoid introducing redundant or conflicting annotation with e.g. the GENIA Event corpus (Kim et al., 2008) or BioNLP ST resources, we excluded terms that involve predominantly (or exclusively) noncovalent binding (included in the scope of the event type B INDING) and terms involving the removal of or binding between the amino acids of a protein, including protein maturation by peptide bond cleavage (annotated – arguably somewhat inaccurately – as"
W11-0215,W09-1313,1,0.83441,"performance. 4 Annotation This section presents the entity and event annotation approach, document selection, and the statistics of the created annotation. 8 The remarkably high coverage for a single type reflects the Zipfian distribution of the modification types; see e.g. Ohta et al. (2010). 4.1 To maximize compatibility with existing eventannotated resources, we chose to follow the general representation and annotation guidelines applied in the annotation of GENIA/BioNLP ST resources, specifically the BioNLP ST 2011 EPI task corpus. Correspondingly, we followed the GENIA gene/gene product (Ohta et al., 2009) annotation guidelines for marking protein mentions, extended the GENIA event corpus guidelines (Kim et al., 2008) for the annotation of protein modification events, and marked C ATALYSIS events following the EPI task representation. For compatibility, we also marked event negation and speculation as in these resources. We followed the GO definitions for individual modification types, and in the rare cases where a modification discussed in text had no existing GO definition, we extrapolated from the way in which protein modifications are generally defined in GO, consulting other domain ontolog"
W11-0215,W10-1903,1,0.913681,"ced substantially in recent years, shifting from the detection of simple binary associations such as protein-protein interactions toward resources and methods for the extraction of multiple types of structured associations of varying numbers participants in specific roles. These IE approaches are frequently termed event extraction (Ananiadou et al., 2010). While protein modifications have been considered in numerous IE studies in the domain (e.g. (Friedman et al., 2001; Rzhetsky et al., 2004; Hu et al., 2005; Narayanaswamy et al., 2005; Saric et al., 2006; Yuan et al., 2006; Lee et al., 2008; Ohta et al., 2010), event extraction efforts have brought increased focus also on the extraction of protein modifications: in the BioNLP Shared Task series that has popularized event extraction, the 2009 shared task (Kim et al., 2009) involved the extraction of nine event types including one PTM, and in the 2011 follow-up event (Kim et al., 2011) the Epigenetics and Post-translational modifications (EPI) task (Ohta et al., 2011) targeted six PTM types, their re114 Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 114–123, c Portland, Oregon, USA, June 23-24, 2011. 2"
W11-0215,W11-1803,1,0.879677,"Missing"
W11-0215,D07-1111,1,0.793565,"he EPI task evaluation in reporting results separately for the extraction of only Theme and Cause arguments (core task) and for the full argument set. 5.2 Event extraction method We applied the EventMine event extraction system (Miwa et al., 2010a; Miwa et al., 2010b), an SVMbased pipeline system using an architecture similar to that of the best-performing system in the BioNLP ST’09 (Bj¨orne et al., 2009); we refer to the studies of Miwa et al. for detailed description of the base system. For analysing sentence structure, we applied the mogura 2.4.1 (Matsuzaki and Miyao, 2007) and GDep beta2 (Sagae and Tsujii, 2007) parsers. For the present study, we modified the base EventMine system as follows. First, to improve efficiency and generalizability, instead of using all words as trigger candidates as in the base system, we filtered candidates using a dictionary extracted from training data and expanded by using the UMLS specialist lexicon (Bodenreider, 2004) and the “hypernyms” and “similar to” relations in WordNet (Fellbaum, 120 1998). Second, to allow generalization across argument types, we added support for solving a single classification problem for event argument detection instead of solving multiple"
W11-1801,S10-1006,0,0.034309,"Missing"
W11-1801,W11-1802,1,0.673169,"ined bio-IE in these directions is emphasized as the main theme of the second event. This paper summarizes the entire BioNLP-ST 2011, covering the relationships between tasks and similar broad issues. Each task is presented in detail in separate overview papers and extraction systems in papers by participants. 1 Proceedings of BioNLP Shared Task 2011 Workshop, pages 1–6, c Portland, Oregon, USA, 24 June, 2011. 2011 Association for Computational Linguistics 2 Main tasks BioNLP-ST 2011 includes four main tracks (with five tasks) representing fine-grained bio-IE. 2.1 Genia task (GE) The GE task (Kim et al., 2011) preserves the task definition of BioNLP-ST 2009, arranged based on the Genia corpus (Kim et al., 2008). The data represents a focused domain of molecular biology: transcription factors in human blood cells. The purpose of the GE task is two-fold: to measure the progress of the community since the last event, and to evaluate generalization of the technology to full papers. For the second purpose, the provided data is composed of two collections: the abstract collection, identical to the BioNLP-ST 2009 data, and the new full paper collection. Progress on the task is measured through the unchang"
W11-1801,W10-1905,1,0.365086,"t.Bossy@jouy.inra.fr Ngan Nguyen Jun’ichi Tsujii University of Tokyo Microsoft Research Asia 7-3-1 Hongo, Bunkyo-ku, Tokyo 5 Dan Ling Street, Haiian District, Beijing nltngan@is.s.u-tokyo.ac.jp jtsujii@microsoft.com Abstract mance. Also, as the complexity of the task was high and system development time limited, we encouraged focus on fine-grained IE by providing gold annotation for named entities as well as various supporting resources. BioNLP-ST 2009 attracted wide attention, with 24 teams submitting final results. The task setup and data since have served as the basis for numerous studies (Miwa et al., 2010b; Poon and Vanderwende, 2010; Vlachos, 2010; Miwa et al., 2010a; Bj¨orne et al., 2010). The BioNLP Shared Task 2011, an information extraction task held over 6 months up to March 2011, met with community-wide participation, receiving 46 final submissions from 24 teams. Five main tasks and three supporting tasks were arranged, and their results show advances in the state of the art in fine-grained biomedical domain information extraction and demonstrate that extraction methods successfully generalize in various aspects. 1 Introduction The BioNLP Shared Task (BioNLP-ST, hereafter) series repres"
W11-1801,W11-1811,1,0.812584,"Missing"
W11-1801,W10-1903,1,0.814538,"Missing"
W11-1801,W11-1803,1,0.724562,"Missing"
W11-1801,N10-1123,0,0.139216,"Ngan Nguyen Jun’ichi Tsujii University of Tokyo Microsoft Research Asia 7-3-1 Hongo, Bunkyo-ku, Tokyo 5 Dan Ling Street, Haiian District, Beijing nltngan@is.s.u-tokyo.ac.jp jtsujii@microsoft.com Abstract mance. Also, as the complexity of the task was high and system development time limited, we encouraged focus on fine-grained IE by providing gold annotation for named entities as well as various supporting resources. BioNLP-ST 2009 attracted wide attention, with 24 teams submitting final results. The task setup and data since have served as the basis for numerous studies (Miwa et al., 2010b; Poon and Vanderwende, 2010; Vlachos, 2010; Miwa et al., 2010a; Bj¨orne et al., 2010). The BioNLP Shared Task 2011, an information extraction task held over 6 months up to March 2011, met with community-wide participation, receiving 46 final submissions from 24 teams. Five main tasks and three supporting tasks were arranged, and their results show advances in the state of the art in fine-grained biomedical domain information extraction and demonstrate that extraction methods successfully generalize in various aspects. 1 Introduction The BioNLP Shared Task (BioNLP-ST, hereafter) series represents a community-wide move to"
W11-1801,W09-1301,1,0.390547,"sk (Pyysalo et al., 2011b) involves the recognition of two binary part-of relations between entities: P ROTEIN -C OMPONENT and S UBUNITC OMPLEX. The task is motivated by specific challenges: the identification of the components of proteins in text is relevant e.g. to the recognition of Site arguments (cf. GE, EPI and ID tasks), and relations between proteins and their complexes relevant to any task involving them. REL setup is informed by recent semantic relation tasks (Hendrickx et al., 2010). The task data, consisting of new annotations for GE data, extends a previously introduced resource (Pyysalo et al., 2009; Ohta et al., 2010a). Supporting tasks 3.3 Gene renaming task (REN) BioNLP-ST 2011 includes three supporting tasks designed to assist in primary the extraction tasks. Other supporting resources made available to participants are presented in (Stenetorp et al., 2011). 3.1 Protein coreference task (CO) The CO task (Nguyen et al., 2011) concerns the recognition of coreferences to protein references. It is motivated from a finding from BioNLP-ST 2009 result analysis: coreference structures in biomedical text hinder the extraction results of fine-grained IE systems. While finding connections betwe"
W11-1801,W10-1919,1,0.755144,"diseases from full-text publica2 tions. The task follows the basic design of BioNLPST 2009, and the ID entities and extraction targets are a superset of the GE ones. The task extends considerably on core entities, adding to P ROTEIN four new entity types, including C HEMICAL and O RGANISM. The events extend on the GE definitions in allowing arguments of the new entity types as well as in introducing a new event category for high-level biological processes. The task was implemented in collaboration with domain experts and informed by prior studies on domain information extraction requirements (Pyysalo et al., 2010; Ananiadou et al., 2011), including the support of systems such as PATRIC (http://patricbrc.org). 2.4 Bacteria track The bacteria track consists of two tasks, BB and BI. 2.4.1 Bacteria biotope task (BB) The aim of the BB task (Bossy et al., 2011) is to extract the habitats of bacteria mentioned in textbooklevel texts written for non-experts. The texts are Web pages about the state of the art knowledge about bacterial species. BB targets general relations, Localization and PartOf , and is challenging in that texts contain more coreferences than usual, habitat references are not necessarily nam"
W11-1801,W11-1804,1,0.768915,"Missing"
W11-1801,W11-1812,1,0.906991,"elevant to task topics, including major protein modification types and their reverse reactions. For capturing the ways in which different entities participate in these events, the task extends the GE argument roles with two new roles specific to the domain, Sidechain and Contextgene. The task design and setup are oriented toward the needs of pathway extraction and curation for domain databases (Wu et al., 2003; Ongenaert et al., 2008) and are informed by previous studies on extraction of the target events (Ohta et al., 2010b; Ohta et al., 2010c). 2.3 Infectious diseases task (ID) The ID task (Pyysalo et al., 2011a) concerns the extraction of events relevant to biomolecular mechanisms of infectious diseases from full-text publica2 tions. The task follows the basic design of BioNLPST 2009, and the ID entities and extraction targets are a superset of the GE ones. The task extends considerably on core entities, adding to P ROTEIN four new entity types, including C HEMICAL and O RGANISM. The events extend on the GE definitions in allowing arguments of the new entity types as well as in introducing a new event category for high-level biological processes. The task was implemented in collaboration with domai"
W11-1801,W11-1816,1,0.850837,"Missing"
W11-1801,I05-2038,1,0.684261,"O task (Nguyen et al., 2011) concerns the recognition of coreferences to protein references. It is motivated from a finding from BioNLP-ST 2009 result analysis: coreference structures in biomedical text hinder the extraction results of fine-grained IE systems. While finding connections between event triggers and protein references is a major part of event extraction, it becomes much harder if one is replaced with a coreferencing expression. The CO task seeks to address this problem. The data sets for the task were produced based on MedCO annotation (Su et al., 2008) and other Genia resources (Tateisi et al., 2005; Kim et al., 2008). 3 The REN task (Jourde et al., 2011) objective is to extract renaming pairs of Bacillus subtilis gene/protein names from PubMed abstracts, motivated by discrepancies between nomenclature databases that interfere with search and complicate normalization. REN relations partially overlap several concepts: explicit renaming mentions, synonymy, and renaming deduced from biological proof. While the task is related to synonymy relation extraction (Yu and Agichtein, 2003), it has a novel definition of renaming, one name permanently replacing the other. 4 Schedule Table 2 shows the"
W11-1801,W10-1901,0,0.042682,"University of Tokyo Microsoft Research Asia 7-3-1 Hongo, Bunkyo-ku, Tokyo 5 Dan Ling Street, Haiian District, Beijing nltngan@is.s.u-tokyo.ac.jp jtsujii@microsoft.com Abstract mance. Also, as the complexity of the task was high and system development time limited, we encouraged focus on fine-grained IE by providing gold annotation for named entities as well as various supporting resources. BioNLP-ST 2009 attracted wide attention, with 24 teams submitting final results. The task setup and data since have served as the basis for numerous studies (Miwa et al., 2010b; Poon and Vanderwende, 2010; Vlachos, 2010; Miwa et al., 2010a; Bj¨orne et al., 2010). The BioNLP Shared Task 2011, an information extraction task held over 6 months up to March 2011, met with community-wide participation, receiving 46 final submissions from 24 teams. Five main tasks and three supporting tasks were arranged, and their results show advances in the state of the art in fine-grained biomedical domain information extraction and demonstrate that extraction methods successfully generalize in various aspects. 1 Introduction The BioNLP Shared Task (BioNLP-ST, hereafter) series represents a community-wide move toward fine-grain"
W11-1801,W09-1401,1,\N,Missing
W11-1801,W11-1809,1,\N,Missing
W11-1801,W11-1810,1,\N,Missing
W11-1803,W11-1828,0,0.113486,"Missing"
W11-1803,W09-1403,0,0.0278857,"Missing"
W11-1803,P05-1022,0,0.0198621,"sk, machine learning-based systems remain dominant overall, although there is considerable divergence in the specific methods applied. In addition to domain mainstays such as support vector machines and maximum entropy models, we find increased application of joint models (Riedel et al., 2011; McClosky et al., 2011; Riedel and McCallum, 2011) as opposed to pure pipeline systems (Bj¨orne and Salakoski, 2011; Quirk et al., 2011) . Remarkably, the application of full pars21 ing together with dependency-based representations of syntactic analyses is adopted by all participants, with the parser of Charniak and Johnson (2005) with the biomedical domain model of McClosky (2009) is applied in all but one system (Liu et al., 2011) and the Stanford Dependency representation (de Marneffe et al., 2006) in all. These choices may be motivated in part by the success of systems using the tools in the previous shared task and the availability of the analyses as supporting resources (Stenetorp et al., 2011). Despite the availability of PTM and DNA methylation resources other than those specifically introduced for the task and the P HOSPHORYLATION annotations in the GE task (Kim et al., 2011b), no participant chose to apply ot"
W11-1803,de-marneffe-etal-2006-generating,0,0.0986335,"Missing"
W11-1803,W11-1827,0,0.255622,"her than those specifically introduced for the task and the P HOSPHORYLATION annotations in the GE task (Kim et al., 2011b), no participant chose to apply other corpora for training. With the exception of externally acquired unlabeled data such as PubMed-derived word clusters applied by three groups, the task results thus reflect a closed task setting in which only the given data is used for training. 5.2 Evaluation results Table 4 presents a the primary results by event type, and Table 5 summarizes these results. We note that only two teams, UTurku (Bj¨orne and Salakoski, 2011) and ConcordU (Kilicoglu and Bergler, 2011), predicted event modifications, and only UTurku predicted additional (non-core) event arguments (data not shown). The other five systems thus addressed MSRCCP- ConUTurku FAUST NLP UMass Stanford BTMG cordU Size H YDROXYLATION 42.25 10.26 10.20 12.80 9.45 12.84 6.32 139 D EHYDROXYLATION - 1 67.12 51.61 50.00 49.18 40.98 47.06 44.44 130 P HOSPHORYLATION D EPHOSPHORYLATION 0.00 0.00 0.00 0.00 0.00 50.00 0.00 3 75.34 72.95 67.88 72.94 67.44 70.87 69.97 340 U BIQUITINATION D EUBIQUITINATION 54.55 40.00 0.00 31.58 0.00 42.11 14.29 17 60.21 31.21 34.54 23.82 31.02 15.65 8.22 416 DNA METHYLATION DNA"
W11-1803,W11-1801,1,0.73904,"Missing"
W11-1803,W11-1802,0,0.660347,"ation, events are typed n-ary associations of participants (entities or other events) in specific roles. Events are bound to specific expressions in text (the event trigger or text binding) and are primary objects of annotation, allowing them to be marked in turn e.g. as negated or as participants in other events. Figure 2 illustrates these concepts. In its specific formulation, EPI broadly follows the definition of the BioNLP’09 shared task on event extraction. Basic modification events are defined similarly to the P HOSPHORYLATION event type targeted in the ’09 and the 2011 GE and ID tasks (Kim et al., 2011b; Pyysalo et al., 2011b), with the full task extending previously defined arguments with two additional ones, Sidechain and Contextgene. 2.1 Entities The EPI task follows the general policy of the BioNLP Shared Task in isolating the basic task of named entity recognition from the event extraction task by providing task participants with manually annotated gene and gene product entities as a starting point for extraction. The entity types follow the BioNLP’09 Shared Task scheme, where genes and their products are simply marked as P ROTEIN.1 In addition to the given P ROTEIN entities, some even"
W11-1803,W11-1826,0,0.0276367,"fic methods applied. In addition to domain mainstays such as support vector machines and maximum entropy models, we find increased application of joint models (Riedel et al., 2011; McClosky et al., 2011; Riedel and McCallum, 2011) as opposed to pure pipeline systems (Bj¨orne and Salakoski, 2011; Quirk et al., 2011) . Remarkably, the application of full pars21 ing together with dependency-based representations of syntactic analyses is adopted by all participants, with the parser of Charniak and Johnson (2005) with the biomedical domain model of McClosky (2009) is applied in all but one system (Liu et al., 2011) and the Stanford Dependency representation (de Marneffe et al., 2006) in all. These choices may be motivated in part by the success of systems using the tools in the previous shared task and the availability of the analyses as supporting resources (Stenetorp et al., 2011). Despite the availability of PTM and DNA methylation resources other than those specifically introduced for the task and the P HOSPHORYLATION annotations in the GE task (Kim et al., 2011b), no participant chose to apply other corpora for training. With the exception of externally acquired unlabeled data such as PubMed-derive"
W11-1803,W11-1806,0,0.132325,". The full task results are considered the primary evaluation for the task e.g. for the purposes of determining the ranking of participating systems. 5 5.1 Results Participation Table 3 summarizes the participating groups and the features of their extraction systems. We note that, similarly to the ’09 task, machine learning-based systems remain dominant overall, although there is considerable divergence in the specific methods applied. In addition to domain mainstays such as support vector machines and maximum entropy models, we find increased application of joint models (Riedel et al., 2011; McClosky et al., 2011; Riedel and McCallum, 2011) as opposed to pure pipeline systems (Bj¨orne and Salakoski, 2011; Quirk et al., 2011) . Remarkably, the application of full pars21 ing together with dependency-based representations of syntactic analyses is adopted by all participants, with the parser of Charniak and Johnson (2005) with the biomedical domain model of McClosky (2009) is applied in all but one system (Liu et al., 2011) and the Stanford Dependency representation (de Marneffe et al., 2006) in all. These choices may be motivated in part by the success of systems using the tools in the previous shared ta"
W11-1803,W09-1313,1,0.127393,"Missing"
W11-1803,W10-1903,1,0.788921,"Missing"
W11-1803,W11-0215,1,0.844108,"yped n-ary associations of participants (entities or other events) in specific roles. Events are bound to specific expressions in text (the event trigger or text binding) and are primary objects of annotation, allowing them to be marked in turn e.g. as negated or as participants in other events. Figure 2 illustrates these concepts. In its specific formulation, EPI broadly follows the definition of the BioNLP’09 shared task on event extraction. Basic modification events are defined similarly to the P HOSPHORYLATION event type targeted in the ’09 and the 2011 GE and ID tasks (Kim et al., 2011b; Pyysalo et al., 2011b), with the full task extending previously defined arguments with two additional ones, Sidechain and Contextgene. 2.1 Entities The EPI task follows the general policy of the BioNLP Shared Task in isolating the basic task of named entity recognition from the event extraction task by providing task participants with manually annotated gene and gene product entities as a starting point for extraction. The entity types follow the BioNLP’09 Shared Task scheme, where genes and their products are simply marked as P ROTEIN.1 In addition to the given P ROTEIN entities, some events involve other entiti"
W11-1803,W11-1804,1,0.370325,"Missing"
W11-1803,W11-1825,0,0.0576857,"ranking of participating systems. 5 5.1 Results Participation Table 3 summarizes the participating groups and the features of their extraction systems. We note that, similarly to the ’09 task, machine learning-based systems remain dominant overall, although there is considerable divergence in the specific methods applied. In addition to domain mainstays such as support vector machines and maximum entropy models, we find increased application of joint models (Riedel et al., 2011; McClosky et al., 2011; Riedel and McCallum, 2011) as opposed to pure pipeline systems (Bj¨orne and Salakoski, 2011; Quirk et al., 2011) . Remarkably, the application of full pars21 ing together with dependency-based representations of syntactic analyses is adopted by all participants, with the parser of Charniak and Johnson (2005) with the biomedical domain model of McClosky (2009) is applied in all but one system (Liu et al., 2011) and the Stanford Dependency representation (de Marneffe et al., 2006) in all. These choices may be motivated in part by the success of systems using the tools in the previous shared task and the availability of the analyses as supporting resources (Stenetorp et al., 2011). Despite the availability"
W11-1803,W11-1807,0,0.057453,"are considered the primary evaluation for the task e.g. for the purposes of determining the ranking of participating systems. 5 5.1 Results Participation Table 3 summarizes the participating groups and the features of their extraction systems. We note that, similarly to the ’09 task, machine learning-based systems remain dominant overall, although there is considerable divergence in the specific methods applied. In addition to domain mainstays such as support vector machines and maximum entropy models, we find increased application of joint models (Riedel et al., 2011; McClosky et al., 2011; Riedel and McCallum, 2011) as opposed to pure pipeline systems (Bj¨orne and Salakoski, 2011; Quirk et al., 2011) . Remarkably, the application of full pars21 ing together with dependency-based representations of syntactic analyses is adopted by all participants, with the parser of Charniak and Johnson (2005) with the biomedical domain model of McClosky (2009) is applied in all but one system (Liu et al., 2011) and the Stanford Dependency representation (de Marneffe et al., 2006) in all. These choices may be motivated in part by the success of systems using the tools in the previous shared task and the availability of t"
W11-1803,W11-1808,0,0.285928,"extract core targets. The full task results are considered the primary evaluation for the task e.g. for the purposes of determining the ranking of participating systems. 5 5.1 Results Participation Table 3 summarizes the participating groups and the features of their extraction systems. We note that, similarly to the ’09 task, machine learning-based systems remain dominant overall, although there is considerable divergence in the specific methods applied. In addition to domain mainstays such as support vector machines and maximum entropy models, we find increased application of joint models (Riedel et al., 2011; McClosky et al., 2011; Riedel and McCallum, 2011) as opposed to pure pipeline systems (Bj¨orne and Salakoski, 2011; Quirk et al., 2011) . Remarkably, the application of full pars21 ing together with dependency-based representations of syntactic analyses is adopted by all participants, with the parser of Charniak and Johnson (2005) with the biomedical domain model of McClosky (2009) is applied in all but one system (Liu et al., 2011) and the Stanford Dependency representation (de Marneffe et al., 2006) in all. These choices may be motivated in part by the success of systems using the tools in"
W11-1803,W11-1816,1,0.608476,"Missing"
W11-1803,W09-1401,1,\N,Missing
W11-1804,W11-1828,0,0.0564394,"Missing"
W11-1804,P05-1022,0,0.0320164,"ced to only core arguments, event modifications are removed, and resulting duplicate events removed. We term this the core task. In terms of the subtask division applied in the BioNLP’09 Shared Task and the GE task of 2011, the core task is analogous to subtask 1 and the full task analogous to the combination of subtasks 1–3. 5 5.1 Results Participation Final results to the task were successfully submitted by seven participants. Table 5 summarizes the information provided by the participating teams. We note that full parsing is applied in all systems, with the specific choice of the parser of Charniak and Johnson (2005) with the biomedical domain model of McClosky (2009) and conversion into the Stanford Dependency representation (de Marneffe et al., 2006) being adopted by five participants. Further, five of the seven systems are predominantly machine learning-based. These can be seen as extensions of trends that were noted in analysis of the BioNLP Rank Team Org 1 FAUST 3NLP 2 UMass 1NLP 3 Stanford 3NLP Word CoreNLP, SnowBall CoreNLP, SnowBall CoreNLP 4 ConcordU 2NLP - 5 UTurku 6 PNNL 7 PredX 1BI Porter 1CS, 1NLP, Porter 2BI 1CS, 1NLP LGP NLP Parse Trig. McCCJ + SD Arg. Events Group. Other resources Modif. C"
W11-1804,de-marneffe-etal-2006-generating,0,0.13301,"Missing"
W11-1804,W11-1827,0,0.406561,"ons are largely compatible with ID ones (see detailed results below). This is encouraging for future applications of the event extraction approach: as manual annotation requires considerable effort and time, the ability to use existing annotations is important for the feasibility of adaptation of the approach to new domains. While several participants made use of supporting syntactic analyses provided by the organizers (Stenetorp et al., 2011), none applied the analyses for supporting tasks, such as coreference or entity relation extraction results – at least in cases due to time constraints (Kilicoglu and Bergler, 2011). 5.2 Evaluation results Table 6 presents the primary results by event type, and Table 7 summarizes these results. The full task requires the extraction of additional arguments and event modifications and involves multiple novel challenges from previously addressed domain tasks including a new subdomain, full-text documents, several new entity types and a new event category. 31 Team FAUST UMass Stanford ConcordU UTurku PNNL PredX recall 48.03 46.92 46.30 49.00 37.85 27.75 22.56 prec. 65.97 62.02 55.86 40.27 48.62 52.36 35.18 F-score 55.59 53.42 50.63 44.21 42.57 36.27 27.49 Table 7: Primary ev"
W11-1804,W11-1801,1,0.755037,"Missing"
W11-1804,W11-1802,0,0.446286,"ected by participants addressing the full task. 2.2 Relations The ID task involves one relation, E QUIV, defining entities (of any of the core types) to be equivalent. This relation is used to annotate abbreviations and local aliases and it is not a target of extraction, but provided for reference and applied in evaluation, where references to any of a set of equivalent entities are treated identically. 2.3 Events The primary extraction targets of the ID task are the event types summarized in Table 1. These are a superset of those targeted in the BioNLP ST’09 and its repeat, the 2011 GE task (Kim et al., 2011b). This design makes it possible to study aspects of domain adaptation by having the same extraction targets in two subdomains of biomedicine, that of transcription factors in human blood cells (GE) and infectious diseases. The events in the ID task extend on those of GE in the inclusion of additional entity types as participants in previously considered event types and the introduction of a new type, P ROCESS. We next briefly discuss the semantics of these events, defined (as in GE) with reference to the communitystandard Gene Ontology (Ashburner et al., 2000). We refer to (Kim et al., 2008;"
W11-1804,W11-1806,0,0.20456,"Missing"
W11-1804,W11-1818,0,0.0187268,"Missing"
W11-1804,W09-1313,1,0.0825789,"es is not part of the ID task. As named entity recognition (NER) is considered in other prominent domain evaluations (Krallinger et al., 2008), we have chosen to isolate aspects of extraction performance relating to NER from the main task of interest, event extraction, by providing participants with human-created gold annotations for core entities. These annotations are briefly presented in the following. Mentions of names of genes and their products (RNA and proteins) are annotated with a single type, without differentiating between subtypes, following the guidelines of the GENIA GGP corpus (Ohta et al., 2009). This type is named P RO TEIN to maintain consistency with related tasks (e.g. BioNLP ST’09), despite slight inaccuracy for cases specifically referencing RNA or DNA forms. Two-component systems, consisting of two proteins, frequently have names derived from the names of the proteins involved (e.g. PhoP-PhoR or SsrA/SsrB). Mentions of TCSs are annotated as T WO - COMPONENT- SYSTEM, nesting P ROTEIN annotations if present. Regulons and operons are collections of genes whose expression is jointly regulated. Like the names of TCSs, their names may derive from the names of the involved genes and"
W11-1804,W11-1803,1,0.370525,"Missing"
W11-1804,W10-1919,1,0.809456,"2010 2008–2010 2008–2010 2007–2010 2008–2010 2008–2009 2007–2008 Entity type P ROTEIN C HEMICAL O RGANISM T WO - COMPONENT- SYSTEM prec. 54.64 32.24 90.38 87.69 rec. 39.64 19.05 47.70 47.24 F 45.95 23.95 62.44 61.40 Table 3: Automatic core entity tagging performance. Table 2: Corpus composition. Journals in which selected articles were published with number of articles (#) and publication years. following tools and settings were adopted, with parameters tuned on initial annotation for two documents: design was guided by previous studies on NER and event extraction in a closely related domain (Pyysalo et al., 2010; Ananiadou et al., 2011). P ROTEIN: NeMine (Sasaki et al., 2008) trained on the JNLPBA data (Kim et al., 2004) with threshold 0.05, filtered to only GENE and PROTEIN types. 3.1 O RGANISM: Linnaeus (Gerner et al., 2010) with “variant matching” for species names variants. Document selection The training and test data were drawn from the primary text content of recent full-text PMC open access documents selected by infectious diseases domain experts (Virginia Tech team) as representative publications on two-component regulatory systems. Table 2 presents some characteristics of the corpus composi"
W11-1804,W11-1807,0,0.0968254,"Missing"
W11-1804,W11-1808,0,0.49423,"Missing"
W11-1804,W08-0609,1,0.0820893,"Entity type P ROTEIN C HEMICAL O RGANISM T WO - COMPONENT- SYSTEM prec. 54.64 32.24 90.38 87.69 rec. 39.64 19.05 47.70 47.24 F 45.95 23.95 62.44 61.40 Table 3: Automatic core entity tagging performance. Table 2: Corpus composition. Journals in which selected articles were published with number of articles (#) and publication years. following tools and settings were adopted, with parameters tuned on initial annotation for two documents: design was guided by previous studies on NER and event extraction in a closely related domain (Pyysalo et al., 2010; Ananiadou et al., 2011). P ROTEIN: NeMine (Sasaki et al., 2008) trained on the JNLPBA data (Kim et al., 2004) with threshold 0.05, filtered to only GENE and PROTEIN types. 3.1 O RGANISM: Linnaeus (Gerner et al., 2010) with “variant matching” for species names variants. Document selection The training and test data were drawn from the primary text content of recent full-text PMC open access documents selected by infectious diseases domain experts (Virginia Tech team) as representative publications on two-component regulatory systems. Table 2 presents some characteristics of the corpus composition. To focus efforts on natural language text likely to express"
W11-1804,W11-1816,1,0.465395,"Missing"
W11-1804,W09-1401,1,\N,Missing
W11-1804,W04-1213,0,\N,Missing
W11-1804,C10-1088,1,\N,Missing
W11-1812,W11-1828,0,0.0979135,"Missing"
W11-1812,W09-1402,0,0.0278135,"Missing"
W11-1812,P05-1022,0,0.0187501,"Missing"
W11-1812,de-marneffe-etal-2006-generating,0,0.214276,"Missing"
W11-1812,W11-1824,0,0.318099,"he available training data. 6 Discussion The REL task was explicitly cast in a support role for the main event extraction tasks, and REL participants were encouraged to make their predictions of the task extraction targets for the various main task datasets available to main task participants. The UTurku team responded to this call for supporting analyses, running their top-ranking REL task system on all main task datasets and making its output available as a supporting resource (Stenetorp et al., 2011). In the main tasks, we are so far aware of one application of this data: the BMI@ASU team (Emadzadeh et al., 2011) applied the UTurku REL predictions as part of their GE task system for resolving the Site arguments in events such as B IND ING and P HOSPHORYLATION (see Figure 1). While more extensive use of the data would have been desirable, we find this application of the REL analyses very appropriate to our general design for the role of the supporting and main tasks and hope to see other groups pursue similar possibilities in future work. 86 7 Conclusions We have presented the preparation, resources, results and analysis of the Entity Relations (REL) task, a supporting task of the BioNLP Shared Task 20"
W11-1812,W11-1827,0,0.0177329,"Relation matching is exact: for a submitted relation to match a gold one, both its type and the related entities must match. 5 5.1 Closky (2009), converted into Stanford Dependency form using the Stanford tools (de Marneffe et al., 2006). These specific choices may perhaps be influenced by the success of systems building on them in the 2009 shared task (e.g. Bj¨orne et al. (2009)). While UTurku (Bj¨orne and Salakoski, 2011) and VIBGhent (Van Landeghem et al., 2011) further agree in the choice of Support Vector Machines for the recognition of entities and the extraction of relations, ConcordU (Kilicoglu and Bergler, 2011) and HCMUS (Le Minh et al., 2011) pursue approaches building on dictionary- and rule-based extraction. Only the VIBGhent system makes use of resources external to those provided for the task, extracting specific semantic entity types from the GENIA corpus as well as inducing word similarities from a large unannotated corpus of PubMed abstracts. 5.2 Results Participation Table 2 summarizes the participating groups and approaches. We find a remarkable number of similarities between the approaches of the systems, with all four utilizing full parsing and a dependency representation of the syntacti"
W11-1812,W11-1801,1,0.80836,"Missing"
W11-1812,W11-1802,0,0.0934158,"256 Protein 9,297 2,080 3,589 Relation 1,857 480 497 P ROTEIN -C OMPONENT 1,302 314 334 S UBUNIT-C OMPLEX 555 166 163 Table 1: REL dataset statistics. and a complex that it is a subunit of. Following the biological motivation and the general practice in the shared task to term genes and gene products P RO TEIN for simplicity, we named these two relations P ROTEIN -C OMPONENT and S UBUNIT-C OMPLEX. Figure 1 shows an illustration of a simple relation with an associated event (not part of REL). Events with Site arguments such as that shown in the figure are targeted in the GE, EPI, and ID tasks (Kim et al., 2011b; Ohta et al., 2011; Pyysalo et al., 2011) that REL is intended to support. 3 Data The task dataset consists of new annotations for the GENIA corpus (Kim et al., 2008), building on the existing biomedical term annotation (Ohta et al., 2002), the gene and gene product name annotation (Ohta et al., 2009) and the syntactic annotation (Tateisi et al., 2005) of the corpus. The general features of the annotation are presented by Pyysalo et al. (2009), describing a previous release of a subset of the data. The REL task annotation effort extended the coverage of the previously released annotation to"
W11-1812,W11-1822,0,0.122014,"Missing"
W11-1812,W11-1811,1,0.729969,"Missing"
W11-1812,W09-1313,1,0.356791,"P RO TEIN for simplicity, we named these two relations P ROTEIN -C OMPONENT and S UBUNIT-C OMPLEX. Figure 1 shows an illustration of a simple relation with an associated event (not part of REL). Events with Site arguments such as that shown in the figure are targeted in the GE, EPI, and ID tasks (Kim et al., 2011b; Ohta et al., 2011; Pyysalo et al., 2011) that REL is intended to support. 3 Data The task dataset consists of new annotations for the GENIA corpus (Kim et al., 2008), building on the existing biomedical term annotation (Ohta et al., 2002), the gene and gene product name annotation (Ohta et al., 2009) and the syntactic annotation (Tateisi et al., 2005) of the corpus. The general features of the annotation are presented by Pyysalo et al. (2009), describing a previous release of a subset of the data. The REL task annotation effort extended the coverage of the previously released annotation to all relations of the targeted types stated within sentence scope in the GENIA corpus. For compatibility with the BioNLP ST’09 and its repeat as the GE task in 2011 (Kim et al., 2011b), the REL task training/development/test set division of the GENIA corpus abstracts matches that of the BioNLP ST’09 data"
W11-1812,W11-1803,1,0.742344,"Missing"
W11-1812,W09-1301,1,0.95227,"ity Relations in BioNLP ST’11. This paper presents the Entity Relations (REL) supporting task. Task Setting In the design of the REL task, we followed the general policy of the shared task in assuming named entity recognition (NER) as a given starting point: participants were provided with manually annotated gold standard annotations identifying gene/protein names in all of the training, development, and final test data. By limiting effects due to NER performance, the task remains more specifically focused on the key challenge studied. Following the results and analysis from previous studies (Pyysalo et al., 2009; Ohta et al., 2010), we chose to limit the task specifically to relations involving a gene/protein named entity (NE) and one other entity. Fixing one entity involved in each relation to an NE helps assure that the relations are “anchored” to real-world entities, and the specific choice of the gene/protein NE class further provides a category with several existing systems and substantial ongoing efforts addressing the identification of those referents through named entity recognition and normalization (Leaman and Gonzalez, 2008; Hakenberg et al., 2008; Krallinger et al., 2008; Morgan et al., 2"
W11-1812,W11-1804,1,0.69244,"Missing"
W11-1812,W11-1816,1,0.600281,"Missing"
W11-1812,I05-2038,1,0.155548,"tions P ROTEIN -C OMPONENT and S UBUNIT-C OMPLEX. Figure 1 shows an illustration of a simple relation with an associated event (not part of REL). Events with Site arguments such as that shown in the figure are targeted in the GE, EPI, and ID tasks (Kim et al., 2011b; Ohta et al., 2011; Pyysalo et al., 2011) that REL is intended to support. 3 Data The task dataset consists of new annotations for the GENIA corpus (Kim et al., 2008), building on the existing biomedical term annotation (Ohta et al., 2002), the gene and gene product name annotation (Ohta et al., 2009) and the syntactic annotation (Tateisi et al., 2005) of the corpus. The general features of the annotation are presented by Pyysalo et al. (2009), describing a previous release of a subset of the data. The REL task annotation effort extended the coverage of the previously released annotation to all relations of the targeted types stated within sentence scope in the GENIA corpus. For compatibility with the BioNLP ST’09 and its repeat as the GE task in 2011 (Kim et al., 2011b), the REL task training/development/test set division of the GENIA corpus abstracts matches that of the BioNLP ST’09 data. The statistics of the corpus are presented in Tabl"
W11-1812,W10-1921,1,0.819205,"Missing"
W11-1812,W11-1821,0,0.0685336,"Missing"
W11-1812,W09-1401,1,\N,Missing
W11-1816,I05-2038,1,\N,Missing
W11-1816,W11-1825,0,\N,Missing
W11-1816,de-marneffe-etal-2006-generating,0,\N,Missing
W11-1816,W11-1802,1,\N,Missing
W11-1816,W11-1803,1,\N,Missing
W11-1816,J93-2004,0,\N,Missing
W11-1816,W11-1812,1,\N,Missing
W11-1816,D10-1096,0,\N,Missing
W11-1816,N10-1123,0,\N,Missing
W11-1816,J08-1002,1,\N,Missing
W11-1816,J04-4004,0,\N,Missing
W11-1816,W06-2920,0,\N,Missing
W11-1816,W09-1401,1,\N,Missing
W11-1816,P96-1025,0,\N,Missing
W11-1816,D07-1111,1,\N,Missing
W11-1816,P05-1022,0,\N,Missing
W11-1816,P06-1055,0,\N,Missing
W11-1816,P08-1006,1,\N,Missing
W11-1816,W10-3006,0,\N,Missing
W11-1816,P04-1014,0,\N,Missing
W11-1816,W07-2416,0,\N,Missing
W11-1816,C10-1088,1,\N,Missing
W11-1816,W11-1809,0,\N,Missing
W11-1816,W11-1824,0,\N,Missing
W11-1816,W11-1810,0,\N,Missing
W11-1816,W11-1801,1,\N,Missing
W11-1816,W11-1804,1,\N,Missing
W12-2410,W11-1828,1,0.799541,"Missing"
W12-2410,W09-1402,1,0.89609,"Missing"
W12-2410,W10-1904,1,0.854996,"Missing"
W12-2410,P05-1022,0,0.0136407,"et VBZ is agent> VBN mediated IN by . . NN CKI EPI detection TEES 2.3 <Theme <Site Entity Serine Theme> Cause> Phosphorylation phosphorylation Protein of T-bet Protein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Each sentence with at least one entity is then parsed (C). EPI events and REL relations are extracted from the parsed sentences (D) and foll"
W12-2410,W03-1018,0,0.0217666,"ed by CKI . McCJ-parser + Stanford Conversion <nsubjpass <nn NN Serine prep_of> NN phosphorylation D IN of REL detection <auxpass NN T-bet VBZ is agent> VBN mediated IN by . . NN CKI EPI detection TEES 2.3 <Theme <Site Entity Serine Theme> Cause> Phosphorylation phosphorylation Protein of T-bet Protein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Ea"
W12-2410,W09-1401,1,0.800261,"by existing PubMed-scale event extraction efforts. The methods and data introduced in this study are freely available from bionlp.utu.fi. 1 Introduction Biomedical domain information extraction has in recent years seen a shift from focus on the extraction of simple pairwise relations (Pyysalo et al., 2008; Tikk et al., 2010) towards the extraction of events, represented as structured associations of arbitrary numbers of participants in specific roles (Ananiadou et al., 2010). Domain event extraction has been popularized in particular by the BioNLP Shared Task (ST) challenges in 2009 and 2011 (Kim et al., 2009; Kim et al., 2011). While the BioNLP ST’09 emphasized protein interactions and regulatory relationships, the expressive event formalism can also be applied to the extraction of statements regarding the properties of individual proteins. Accordingly, the EPI (Epigenetics and Post-Translational Modifications) subchallenge of the BioNLP ST’11 provided corpora and competitive evaluations for the detection of epigenetics and post-translational modification (PTM) events, while the REL (Entity Relations) subchallenge covers structural and complex membership relations of proteins (Ohta et al., 2011b;"
W12-2410,W11-1801,1,0.780089,"ein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Each sentence with at least one entity is then parsed (C). EPI events and REL relations are extracted from the parsed sentences (D) and following conversion to the BioNLP ST format are imported into a database (E). (Adapted from Bj¨orne and Salakoski (2011)). The extraction of events"
W12-2410,de-marneffe-etal-2006-generating,0,0.0781296,"Missing"
W12-2410,N10-1004,0,0.0126786,"d IN by . . NN CKI EPI detection TEES 2.3 <Theme <Site Entity Serine Theme> Cause> Phosphorylation phosphorylation Protein of T-bet Protein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Each sentence with at least one entity is then parsed (C). EPI events and REL relations are extracted from the parsed sentences (D) and following conversion"
W12-2410,W10-1903,1,0.868585,"Missing"
W12-2410,W11-1803,1,0.805324,"ein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Each sentence with at least one entity is then parsed (C). EPI events and REL relations are extracted from the parsed sentences (D) and following conversion to the BioNLP ST format are imported into a database (E). (Adapted from Bj¨orne and Salakoski (2011)). The extraction of events"
W12-2410,W09-1301,1,0.907084,"Missing"
W12-2410,W11-1812,1,0.693859,"ein Catalysis is mediated by CKI . is mediated by CKI . <Protein-Component Entity Serine E Protein phosphorylation REL of T-bet tion, protein/gene names are detected and sentences are parsed. TEES handles all these preprocessing steps via a pipeline of tool wrappers for the GENIA Sentence Splitter (Kazama and Tsujii, 2003), the BANNER named entity recognizer (Leaman and Gonzalez, 2008), the McClosky-Charniak-Johnson (McCCJ) parser (Charniak and Johnson, 2005; McClosky, 2010) and the Stanford tools (de Marneffe et al., 2006). For a detailed description of TEES we refer to Bj¨orne and Salakoski (2011) and for the computational requirements of PubMed-scale event extraction to Bj¨orne et al. (2010). EPI conversion to ST format and database import Figure 1: Event and relation extraction. Article text is split into sentences (A), where gene/protein entities are detected and normalized to their Entrez Gene IDs (B). Each sentence with at least one entity is then parsed (C). EPI events and REL relations are extracted from the parsed sentences (D) and following conversion to the BioNLP ST format are imported into a database (E). (Adapted from Bj¨orne and Salakoski (2011)). The extraction of events"
W12-2410,W11-1816,1,0.886081,"Missing"
W12-2410,W10-1921,1,0.898429,"Missing"
W12-2412,W11-1828,0,0.0929443,"Missing"
W12-2412,W11-1820,0,0.0684248,"Missing"
W12-2412,P11-1098,0,0.0165262,"c span of text supporting extracted information,5 the requirement of the BioNLP ST setting that the output of event extraction systems must identify specific text spans for each entity and event makes it complex or impossible to address the task using a number of IE methods that might otherwise represent feasible approaches to event extraction. 5 For example, for curation support tasks, this allows the human curator to easily check the correctness of extracted information and helps to select “evidence sentences”, as included in many databases. 104 For example, Patwardhan and Riloff (2007) and Chambers and Jurafsky (2011) consider an IE approach where the extraction targets are MUC-4 style document-level templates (Sundheim, 1991), the former a supervised system and the latter fully unsupervised. These methods and many like them for tasks such as ACE (Doddington et al., 2004) work on the document level, and can thus not be readily applied or evaluated against the existing annotations for the BioNLP shared tasks. Enabling the application of such approaches to the BioNLP ST could bring valuable new perspectives to event extraction. 4.3 Alternative evaluation We propose a new mode of evaluation that otherwise fol"
W12-2412,doddington-etal-2004-automatic,0,0.282956,"IE methods that might otherwise represent feasible approaches to event extraction. 5 For example, for curation support tasks, this allows the human curator to easily check the correctness of extracted information and helps to select “evidence sentences”, as included in many databases. 104 For example, Patwardhan and Riloff (2007) and Chambers and Jurafsky (2011) consider an IE approach where the extraction targets are MUC-4 style document-level templates (Sundheim, 1991), the former a supervised system and the latter fully unsupervised. These methods and many like them for tasks such as ACE (Doddington et al., 2004) work on the document level, and can thus not be readily applied or evaluated against the existing annotations for the BioNLP shared tasks. Enabling the application of such approaches to the BioNLP ST could bring valuable new perspectives to event extraction. 4.3 Alternative evaluation We propose a new mode of evaluation that otherwise follows the primary BioNLP ST evaluation criteria, but incorporates the following two exceptions: 1. remove the requirement to match trigger spans 2. only require entity texts, not spans, to match The first alternative criterion has also been previously consider"
W12-2412,W11-1824,0,0.0264993,"Missing"
W12-2412,P10-1160,0,0.0661515,"Missing"
W12-2412,W11-1827,0,0.568696,"Missing"
W12-2412,W11-1801,1,0.941981,"ed in context to determine whether they express an event, as well as a related class of events whose type must be disambiguated with reference to context (“ambiguous type”) are comparatively frequent in the three tasks, while EPI in particular involves many cases where a trigger is shared between multiple events – an issue for approaches that assume each token can be assigned at most a single class. Finally, we noted a number of cases that we judged to be errors in the gold annotation; the number is broadly in line with the reported inter-annotator agreement for the data (see e.g. Ohta et al. (2011)). While there is an unavoidable subjective component to evaluations such as this, we note that a similar evaluation performed following the BioNLP Shared Task 2009 using test set data reached broadly comparable results (Kim et al., 2011a). The newly compiled dataset represents the first opportunity for those without direct access to the test set data and submissions to directly assess the task results, as demonstrated here. We hope that this resource will 103 New Perspectives to Event Extraction As discussed in Section 2, the BioNLP ST event extraction task is “text-bound”: each entity and ev"
W12-2412,W11-1822,0,0.0679042,"Missing"
W12-2412,W11-1826,0,0.0323279,"Missing"
W12-2412,P11-1163,0,0.0329128,"l only, this approach has a number of important benefits, such as allowing machine learning methods for event extraction to be directly trained on fully and specifically annotated data without the need to apply frequently errorprone heuristics (Mintz et al., 2009) or develop machine learning methods addressing the mapping between text expressions and document-level annotations (Riedel et al., 2010). Many of the most successful event extraction approaches involve direct training of machine learning methods using the textbound annotations (Riedel and McCallum, 2011; Bj¨orne and Salakoski, 2011; McClosky et al., 2011). However, while the availability of text-bound annotations in data provided to task participants is clearly a benefit, there are drawbacks to the choice of exclusive focus on text-bound annotations in system output, including issues relating to evaluation and the applicability of methods to the task. In the following section, we discuss some of these issues and propose alternatives to representation and evaluation addressing them. 4.1 Evaluation The evaluation of the BioNLP ST is instance-based and text-bound: each event in gold annotation and each event extracted by a system is considered in"
W12-2412,P09-1113,0,0.0205423,"tly assess the task results, as demonstrated here. We hope that this resource will 103 New Perspectives to Event Extraction As discussed in Section 2, the BioNLP ST event extraction task is “text-bound”: each entity and event annotation is associated with a specific span of text. Contrasted to the alternative approach where annotations are document-level only, this approach has a number of important benefits, such as allowing machine learning methods for event extraction to be directly trained on fully and specifically annotated data without the need to apply frequently errorprone heuristics (Mintz et al., 2009) or develop machine learning methods addressing the mapping between text expressions and document-level annotations (Riedel et al., 2010). Many of the most successful event extraction approaches involve direct training of machine learning methods using the textbound annotations (Riedel and McCallum, 2011; Bj¨orne and Salakoski, 2011; McClosky et al., 2011). However, while the availability of text-bound annotations in data provided to task participants is clearly a benefit, there are drawbacks to the choice of exclusive focus on text-bound annotations in system output, including issues relating"
W12-2412,W11-1803,1,0.935394,"ed in context to determine whether they express an event, as well as a related class of events whose type must be disambiguated with reference to context (“ambiguous type”) are comparatively frequent in the three tasks, while EPI in particular involves many cases where a trigger is shared between multiple events – an issue for approaches that assume each token can be assigned at most a single class. Finally, we noted a number of cases that we judged to be errors in the gold annotation; the number is broadly in line with the reported inter-annotator agreement for the data (see e.g. Ohta et al. (2011)). While there is an unavoidable subjective component to evaluations such as this, we note that a similar evaluation performed following the BioNLP Shared Task 2009 using test set data reached broadly comparable results (Kim et al., 2011a). The newly compiled dataset represents the first opportunity for those without direct access to the test set data and submissions to directly assess the task results, as demonstrated here. We hope that this resource will 103 New Perspectives to Event Extraction As discussed in Section 2, the BioNLP ST event extraction task is “text-bound”: each entity and ev"
W12-2412,D07-1075,0,0.0343243,"IE systems to identify a specific span of text supporting extracted information,5 the requirement of the BioNLP ST setting that the output of event extraction systems must identify specific text spans for each entity and event makes it complex or impossible to address the task using a number of IE methods that might otherwise represent feasible approaches to event extraction. 5 For example, for curation support tasks, this allows the human curator to easily check the correctness of extracted information and helps to select “evidence sentences”, as included in many databases. 104 For example, Patwardhan and Riloff (2007) and Chambers and Jurafsky (2011) consider an IE approach where the extraction targets are MUC-4 style document-level templates (Sundheim, 1991), the former a supervised system and the latter fully unsupervised. These methods and many like them for tasks such as ACE (Doddington et al., 2004) work on the document level, and can thus not be readily applied or evaluated against the existing annotations for the BioNLP shared tasks. Enabling the application of such approaches to the BioNLP ST could bring valuable new perspectives to event extraction. 4.3 Alternative evaluation We propose a new mode"
W12-2412,W11-1804,1,0.922475,"ed in context to determine whether they express an event, as well as a related class of events whose type must be disambiguated with reference to context (“ambiguous type”) are comparatively frequent in the three tasks, while EPI in particular involves many cases where a trigger is shared between multiple events – an issue for approaches that assume each token can be assigned at most a single class. Finally, we noted a number of cases that we judged to be errors in the gold annotation; the number is broadly in line with the reported inter-annotator agreement for the data (see e.g. Ohta et al. (2011)). While there is an unavoidable subjective component to evaluations such as this, we note that a similar evaluation performed following the BioNLP Shared Task 2009 using test set data reached broadly comparable results (Kim et al., 2011a). The newly compiled dataset represents the first opportunity for those without direct access to the test set data and submissions to directly assess the task results, as demonstrated here. We hope that this resource will 103 New Perspectives to Event Extraction As discussed in Section 2, the BioNLP ST event extraction task is “text-bound”: each entity and ev"
W12-2412,W11-1812,1,0.828716,"ferring to the real-world entities in text, the overall task is “text-bound” in the sense of requiring not only the extraction of targeted statements from text, but also the identification of specific regions of text expressing each piece of extracted information. Events can further be marked with modifiers identifying additional features such as being explicitly negated or stated in a speculative context. Figure 1 shows an illustration of event annotations. This BioNLP ST 2009 formulation of the event extraction task was followed also in three 2011 main tasks: the GE (Kim et al., 2011c), ID (Pyysalo et al., 2011a) and EPI (Ohta et al., 2011) tasks. A variant of this representation that omits event triggers was applied in the BioNLP ST 2011 bacteria track (Bossy et al., 2011), and simpler, binary relationtype representations were applied in three supporting tasks (Nguyen et al., 2011; Pyysalo et al., 2011b; Jourde et al., 2011). Due to the challenges of consistent evaluation and processing for tasks involvIn this section, we present the new collection of automatically created event analyses and demonstrate one use of the data through an evaluation of events that no system could successfully extract. 3"
W12-2412,W11-1825,0,0.02855,"P ST 2011 bacteria track (Bossy et al., 2011), and simpler, binary relationtype representations were applied in three supporting tasks (Nguyen et al., 2011; Pyysalo et al., 2011b; Jourde et al., 2011). Due to the challenges of consistent evaluation and processing for tasks involvIn this section, we present the new collection of automatically created event analyses and demonstrate one use of the data through an evaluation of events that no system could successfully extract. 3.1 Following the BioNLP ST 2011, the MSR-NLP group called for the release of outputs from various participating systems (Quirk et al., 2011) and made analyses of their system available.2 Despite the obvious benefits of the availability of these resources, we are not aware of other groups following this example prior to the time of this publication. To create the combined resource, we approached each group that participated in the three targeted BioNLP ST 2011 main tasks to ask for their support to the creation of a dataset including analyses from their event extraction systems. This suggestion met with the support of all but a few groups that were approached.3 The groups providing analyses from their systems into this merged resou"
W12-2412,D11-1001,0,0.0233845,"alternative approach where annotations are document-level only, this approach has a number of important benefits, such as allowing machine learning methods for event extraction to be directly trained on fully and specifically annotated data without the need to apply frequently errorprone heuristics (Mintz et al., 2009) or develop machine learning methods addressing the mapping between text expressions and document-level annotations (Riedel et al., 2010). Many of the most successful event extraction approaches involve direct training of machine learning methods using the textbound annotations (Riedel and McCallum, 2011; Bj¨orne and Salakoski, 2011; McClosky et al., 2011). However, while the availability of text-bound annotations in data provided to task participants is clearly a benefit, there are drawbacks to the choice of exclusive focus on text-bound annotations in system output, including issues relating to evaluation and the applicability of methods to the task. In the following section, we discuss some of these issues and propose alternatives to representation and evaluation addressing them. 4.1 Evaluation The evaluation of the BioNLP ST is instance-based and text-bound: each event in gold annotation"
W12-2412,W11-1808,0,0.31655,"Missing"
W12-2412,W11-1816,1,0.901463,"Missing"
W12-2412,H91-1059,0,0.261268,"on systems must identify specific text spans for each entity and event makes it complex or impossible to address the task using a number of IE methods that might otherwise represent feasible approaches to event extraction. 5 For example, for curation support tasks, this allows the human curator to easily check the correctness of extracted information and helps to select “evidence sentences”, as included in many databases. 104 For example, Patwardhan and Riloff (2007) and Chambers and Jurafsky (2011) consider an IE approach where the extraction targets are MUC-4 style document-level templates (Sundheim, 1991), the former a supervised system and the latter fully unsupervised. These methods and many like them for tasks such as ACE (Doddington et al., 2004) work on the document level, and can thus not be readily applied or evaluated against the existing annotations for the BioNLP shared tasks. Enabling the application of such approaches to the BioNLP ST could bring valuable new perspectives to event extraction. 4.3 Alternative evaluation We propose a new mode of evaluation that otherwise follows the primary BioNLP ST evaluation criteria, but incorporates the following two exceptions: 1. remove the re"
W12-2412,W10-1921,1,0.866603,"Missing"
W12-2412,W11-1821,0,0.0439833,"Missing"
W12-2412,W11-0204,0,0.0629482,"Missing"
W12-2412,W11-1805,0,0.0284448,"Missing"
W12-2412,W11-1802,1,\N,Missing
W12-2412,W11-1809,0,\N,Missing
W12-2412,W11-1811,1,\N,Missing
W12-2412,W11-1810,0,\N,Missing
W12-3806,W11-1828,0,0.0482957,"Missing"
W12-3806,W10-3001,0,0.0645895,"Missing"
W12-3806,W10-3010,0,0.161775,"sk, and although negation and speculation were also considered in three main tasks for the 2011 follow-up event (Kim et al., 2011a), the trend continued, with only two participants addressing the negation/speculation aspects of the task. We are aware of only two studies exploring the relationship between the cue-and-scope and event-based representations: in a manual analysis of scope overlap with tagged events, Vincze et al. (2011) identified a number of issues and mismatches in annotation scope and criteria, which may explain in part the lack of methods combining these two lines of research. Kilicoglu and Bergler (2010) approached the problem from the opposite direction and used an existing EE system to extract cue-and-scope annotations in the CoNLL-2010 Shared Task. In this work, we take a high-level perspective, 48 seeking to bridge the linguistically oriented framework and the more application-oriented event framework to overcome the mismatches demonstrated by Vincze et al. (2011). Specifically, we aim to determine how cue-and-scope recognition systems can be used to produce a state-of-the-art negation/speculation detection system for the EE task. 2 Resources Several existing resources can support the inv"
W12-3806,W11-1827,0,0.0114523,"us used to train the CLiPSNESP system, the GE test set does not, and thus test set results are not expected to be overfit. We noted when performing development set experiments that training machine learning-based methods on the negation/speculation annotations of the event-annotated corpora was problematic due to the sparseness of these flags in the annotation. To address this issue, we merge the training data of the three corpora in all experiments with machine learning methods. 5.2 Baseline methods We use the event analyses created by the UTurku (Bj¨orne and Salakoski, 2011) and UConcordia (Kilicoglu and Bergler, 2011) systems for the BioNLP 2011, the only systems that included negation and speculation analyses. To investigate the impact on a system that did not include a negation/speculation component, we further consider analyses created Negation (R/P/F) EPI GE ID H HR 29.23/31.67/30.40 27.69/32.73/30.00 53.92/52.84/53.38 53.24/71.89/61.18 44.00/31.88/36.97 44.00/37.93/40.74 M ME MC MCE 47.69/20.00/28.18 60.00/66.10/62.90 40.00/74.29/52.00 58.46/73.08/64.96 43.00/25.25/31.82 58.36/70.08/63.69 58.36/76.34/66.15 61.77/83.03/70.84 46.00/26.74/33.82 54.00/69.23/60.67 52.00/61.90/56.52 58.00/70.73/63.74 Table"
W12-3806,W09-1401,1,0.94131,"ion/Speculation Annotations: A Bridge Not Too Far Pontus Stenetorp1 Sampo Pyysalo2,3 Tomoko Ohta2,3 Sophia Ananiadou2,3 and Jun’ichi Tsujii2,3,4 1 Department of Computer Science, University of Tokyo, Tokyo, Japan 2 School of Computer Science, University of Manchester, Manchester, United Kingdom 3 National Centre for Text Mining, University of Manchester, Manchester, United Kingdom 4 Microsoft Research Asia, Beijing, People’s Republic of China {pontus,smp,okap}@is.s.u-tokyo.ac.jp sophia.ananiadou@manchester.ac.uk jtsujii@microsoft.com Abstract some marking of certainty and polarity (LDC, 2005; Kim et al., 2009; Saur and Pustejovsky, 2009; Kim et al., 2011a; Thompson et al., 2011). We study two approaches to the marking of extra-propositional aspects of statements in text: the task-independent cue-and-scope representation considered in the CoNLL-2010 Shared Task, and the tagged-event representation applied in several recent event extraction tasks. Building on shared task resources and the analyses from state-of-the-art systems representing the two broad lines of research, we identify specific points of mismatch between the two perspectives and propose ways of addressing them. We demonstrate the feas"
W12-3806,W11-1801,1,0.855017,"addressing the latter task in detail. Only three out of the 24 participants in the BioNLP Shared Task 2009 submitted results for the non-mandatory negation/speculation task, and although negation and speculation were also considered in three main tasks for the 2011 follow-up event (Kim et al., 2011a), the trend continued, with only two participants addressing the negation/speculation aspects of the task. We are aware of only two studies exploring the relationship between the cue-and-scope and event-based representations: in a manual analysis of scope overlap with tagged events, Vincze et al. (2011) identified a number of issues and mismatches in annotation scope and criteria, which may explain in part the lack of methods combining these two lines of research. Kilicoglu and Bergler (2010) approached the problem from the opposite direction and used an existing EE system to extract cue-and-scope annotations in the CoNLL-2010 Shared Task. In this work, we take a high-level perspective, 48 seeking to bridge the linguistically oriented framework and the more application-oriented event framework to overcome the mismatches demonstrated by Vincze et al. (2011). Specifically, we aim to determine"
W12-3806,W11-1802,0,0.0691394,"Missing"
W12-3806,W11-1806,0,0.142886,"2.43 48.08/51.02/49.50 25.65/10.84/15.24 22.08/42.24/29.00 27.27/50.30/35.37 31.82/53.85/40.00 45.83/10.58/17.19 29.17/28.00/28.57 37.50/31.03/33.96 33.33/42.11/37.21 Table 5: Results for Speculation for our two heuristics and the four combinations of ML features. by the FAUST system, which achieved the highest performance at two of the three tasks considered (Riedel et al., 2011). The UTurku system is a pipeline ML-based EE system, while the UConcordia system is strictly rule-based. FAUST is an ML-based model combination system incorporating information from the parser-based Stanford system (McClosky et al., 2011) and the jointly-modelled UMass system (Riedel and McCallum, 2011). We also performed preliminary experiments for the other released submissions to the BioNLP 2011 Shared Task, but due to space limitations focus only on the three above-mentioned systems. results tables we abbreviate the feature set names as done in Table 3 and use H for the heuristic method and R for its root extension. As our machine learning component we use LIBLINEAR (Fan et al., 2008) with a L2-regularised L2-loss SVM model. We optimise the SVM regularisation parameter C using 10-fold cross-validation on the training data."
W12-3806,W09-1304,0,0.0270192,"icallyoriented and task-oriented perspectives on negation/speculation detection. In this study, we make use of the following resources. First, we study the three BioNLP 2011 Shared Task corpora that include annotation for negation and speculation: the GE, EPI and ID main task corpora (Table 1). Second, we make use of supporting analyses provided for these corpora in response to a call sent by the BioNLP Shared Task organisers to the developers of third-party systems (Stenetorp et al., 2011). Specifically, we use the output of the BiographTA NeSp Scope Labeler (here referred to as CLiPS-NESP) (Morante and Daelemans, 2009; Morante et al., 2010) provided by the University of Antwerp CLiPS center. This system provides cue-and-scope analyses for negation and speculation and was demonstrated to have state-of-the-art performance at the relevant CoNLL-2010 Shared Task. Finally, we make use of the event analyses created by systems that participated in the BioNLP Shared Task, made available to the research community for the majority of the shared task submissions (Pyysalo et al., 2012). These analyses represent the stateof-the-art in event extraction and their capability to detect event structures as well as marking t"
W12-3806,W10-3006,0,0.158592,"Missing"
W12-3806,W11-1803,1,0.674875,"addressing the latter task in detail. Only three out of the 24 participants in the BioNLP Shared Task 2009 submitted results for the non-mandatory negation/speculation task, and although negation and speculation were also considered in three main tasks for the 2011 follow-up event (Kim et al., 2011a), the trend continued, with only two participants addressing the negation/speculation aspects of the task. We are aware of only two studies exploring the relationship between the cue-and-scope and event-based representations: in a manual analysis of scope overlap with tagged events, Vincze et al. (2011) identified a number of issues and mismatches in annotation scope and criteria, which may explain in part the lack of methods combining these two lines of research. Kilicoglu and Bergler (2010) approached the problem from the opposite direction and used an existing EE system to extract cue-and-scope annotations in the CoNLL-2010 Shared Task. In this work, we take a high-level perspective, 48 seeking to bridge the linguistically oriented framework and the more application-oriented event framework to overcome the mismatches demonstrated by Vincze et al. (2011). Specifically, we aim to determine"
W12-3806,W11-1804,1,0.674411,"addressing the latter task in detail. Only three out of the 24 participants in the BioNLP Shared Task 2009 submitted results for the non-mandatory negation/speculation task, and although negation and speculation were also considered in three main tasks for the 2011 follow-up event (Kim et al., 2011a), the trend continued, with only two participants addressing the negation/speculation aspects of the task. We are aware of only two studies exploring the relationship between the cue-and-scope and event-based representations: in a manual analysis of scope overlap with tagged events, Vincze et al. (2011) identified a number of issues and mismatches in annotation scope and criteria, which may explain in part the lack of methods combining these two lines of research. Kilicoglu and Bergler (2010) approached the problem from the opposite direction and used an existing EE system to extract cue-and-scope annotations in the CoNLL-2010 Shared Task. In this work, we take a high-level perspective, 48 seeking to bridge the linguistically oriented framework and the more application-oriented event framework to overcome the mismatches demonstrated by Vincze et al. (2011). Specifically, we aim to determine"
W12-3806,W12-2412,1,0.850965,"(Stenetorp et al., 2011). Specifically, we use the output of the BiographTA NeSp Scope Labeler (here referred to as CLiPS-NESP) (Morante and Daelemans, 2009; Morante et al., 2010) provided by the University of Antwerp CLiPS center. This system provides cue-and-scope analyses for negation and speculation and was demonstrated to have state-of-the-art performance at the relevant CoNLL-2010 Shared Task. Finally, we make use of the event analyses created by systems that participated in the BioNLP Shared Task, made available to the research community for the majority of the shared task submissions (Pyysalo et al., 2012). These analyses represent the stateof-the-art in event extraction and their capability to detect event structures as well as marking them for negation and speculation. The above three resources present us with many opportunities to relate scope-based annotations to three highly relevant event-based corpora containing negation/speculation annotations. 3 Manual Analysis To gain deeper insight into the data and the challenges in combining the cue-and-scope and eventoriented perspectives, we performed a manual analysis of the corpus annotations using the manually Name Negated Events Speculated Ev"
W12-3806,W11-1807,0,0.0123498,"27/50.30/35.37 31.82/53.85/40.00 45.83/10.58/17.19 29.17/28.00/28.57 37.50/31.03/33.96 33.33/42.11/37.21 Table 5: Results for Speculation for our two heuristics and the four combinations of ML features. by the FAUST system, which achieved the highest performance at two of the three tasks considered (Riedel et al., 2011). The UTurku system is a pipeline ML-based EE system, while the UConcordia system is strictly rule-based. FAUST is an ML-based model combination system incorporating information from the parser-based Stanford system (McClosky et al., 2011) and the jointly-modelled UMass system (Riedel and McCallum, 2011). We also performed preliminary experiments for the other released submissions to the BioNLP 2011 Shared Task, but due to space limitations focus only on the three above-mentioned systems. results tables we abbreviate the feature set names as done in Table 3 and use H for the heuristic method and R for its root extension. As our machine learning component we use LIBLINEAR (Fan et al., 2008) with a L2-regularised L2-loss SVM model. We optimise the SVM regularisation parameter C using 10-fold cross-validation on the training data. We use the training, development and test set partition provided"
W12-3806,W11-1808,0,0.183789,"addressing the latter task in detail. Only three out of the 24 participants in the BioNLP Shared Task 2009 submitted results for the non-mandatory negation/speculation task, and although negation and speculation were also considered in three main tasks for the 2011 follow-up event (Kim et al., 2011a), the trend continued, with only two participants addressing the negation/speculation aspects of the task. We are aware of only two studies exploring the relationship between the cue-and-scope and event-based representations: in a manual analysis of scope overlap with tagged events, Vincze et al. (2011) identified a number of issues and mismatches in annotation scope and criteria, which may explain in part the lack of methods combining these two lines of research. Kilicoglu and Bergler (2010) approached the problem from the opposite direction and used an existing EE system to extract cue-and-scope annotations in the CoNLL-2010 Shared Task. In this work, we take a high-level perspective, 48 seeking to bridge the linguistically oriented framework and the more application-oriented event framework to overcome the mismatches demonstrated by Vincze et al. (2011). Specifically, we aim to determine"
W12-3806,W11-1816,1,0.908546,"Missing"
W12-3806,W08-0606,0,0.206797,"ons of text statements have explicitly included Although extra-propositional aspects are recognised as important, there is no clear consensus on how to address their annotation and extraction from text. Some comparatively early efforts focused on the detection of negation cue phrases associated with specific (previously detected) terms through regular expression-based rules (Chapman et al., 2001). A number of later efforts identified the scope of negation cues with phrases in constituency analyses in sentence structure (Huang and Lowe, 2007). Drawing in part on this work, the BioScope corpus (Vincze et al., 2008) applied a representation where both cues and their associated scopes are marked as contiguous spans of text (Figure 1 bottom). This approach was also applied in the CoNLL-2010 Shared Task (Farkas et al., 2010), in which 13 participating groups proposed approaches for Task 2, which required the identification of uncertainty cues and their associated scopes in text. In the following, we will term this task-independent, linguisticallymotivated approach as the cue-and-scope representation (please see Vincze et al. (2008) for details regarding the representation). For IE efforts, more task-oriente"
W12-4304,H92-1045,0,0.108814,"g. For PubMed, we simply selected a random set of citations and extracted their abstract and title texts. For PMC, we initially extracted all non-overlapping section texts (PMC XML <sec> elements) as well as caption texts (<caption> elements), and then selected a random set of extracts. This selection seeks to maximize the diversity of the texts in the full-text section of the corpus, and the selection of extracts larger than isolated sentences aims to allow the corpus to be used to study methods making use of broader context, e.g. by incorporating constraints such as one sense per discourse (Gale et al., 1992). 2 3 We selected a total of 500 documents using this protocol, half from PubMed and half from PMC document extracts. (Descriptive statistics of the abstracts and full-text extracts subcorpora are given later in Table 3.) 2.6 Annotation Process Primary annotation was created by a PhD biologist with extensive experience in domain information extraction and text annotation (TO). The use of any relevant resources, such as the full article being annotated or species-specific anatomy ontologies in the OBO foundry, was encouraged for resolving unclear or ambiguous cases during annotation. Initial an"
W12-4304,W10-1909,0,0.127256,"rehensive analysis must include entities at multiple levels of biological organization, from the molecular to the organism level. The detection of references to anatomical entities such as “kidney” and “blood” is thus required for the automatic structured analysis of biomedical scientific text. Although a wealth of lexical and ontological resources covering anatomical entities are available (Rosse and Mejino, 2003; Smith et al., 2007; Bodenreider, 2004; Haendel et al., 2009), such resources do not alone confer the ability to reliably detect mentions of anatomical entities in natural language (Gerner et al., 2010a; Travillian et al., 2011; Pyysalo et al., 2012b). To support the development and evaluation of reliable anatomical entity mention detection methods, corpus resources annotated specifically for the task are necessary. In this study, we aim to create a reference standard for evaluating methods for anatomical entity mention detection and for training machine learningbased methods for the task. We seek to select a set of texts that are representative of the relevant scientific literature, i.e. open-domain in the sense of avoiding bias toward, for example, specific species, levels of biological o"
W12-4304,W04-1213,0,0.115942,"ue to occupying different levels at different stages of development, we adopt a separate D EVELOPING ANATOMICAL STRUCTURE category, as done also in e.g. Uberon (Haendel et al., 2009). 1 http://obofoundry.org/ 28 Annotation Scope We diverge from the scope of anatomy ontologies in two important aspects in our annotation. First, ontologies of anatomy commonly incorporate everything from molecules to whole organisms within their scope. However, in entity mention detection, many molecular level anatomical entities fall within the scope of the established gene/protein mention detection tasks (e.g. (Kim et al., 2004; Tanabe et al., 2005)), and whole organism mentions similarly largely within what is covered by existing methods and resources for organism mention detection (Gerner et al., 2010b; Naderi et al., 2011). To avoid overlap with established tasks and to focus on the novel aspects of anatomical entity mention detection, we exclude biological macromolecules and mentions of organism names from the scope of our annotation, as argued in (Pyysalo et al., 2012b). Second, these ontologies typically represent canonical anatomy, an idealized state that is rarely (if ever) encountered in reality (Bada and H"
W12-4304,W11-1901,0,0.0257235,"mical entities (e.g. “muscle tissue”). Both names and nominal mentions are annotated similarly, without distinction. We exclude pronouns (it, that) from annotation even when they un29 cytoplasm Tissue Part-of Cell of phagocytic microglia Frag Tissue thyroid and eye muscle membranes Figure 2: Part-of relation marking entity mention spanning a prepositional phrase (above) and Frag relation marking coordination with ellipsis (below). ambiguously refer to an anatomical entity; we consider the identification and resolution of such mentions part of the distinct coreference resolution task (see e.g. Pradhan et al. (2011)). In addition to names and nominal mentions, we mark adjectives that have an unambiguous sense of relating to a specific anatomical entity. Thus, for example, both “kidney” and “renal” (relating to the kidneys) are annotated as O RGAN in expressions such as “kidney failure” and “renal failure”. The choice to annotate adjectival references is motivated by the expected needs of applications making use of automatically detected anatomical entity mentions. For example, for semantic search targeting documents relating to organ failure, a document discussing “renal failure” is obviously relevant an"
W12-4304,E12-2021,1,0.874312,"Missing"
W12-4304,W03-0419,0,0.0245807,"Missing"
W13-2001,W11-1802,1,0.929598,"tand-off: the texts of the documents are kept separate from the annotations that refer to specific spans of texts through character offsets. More detail and examples can be found on the BioNLP-ST’13 web site. 2.1 Genia Event Extraction (GE) Originally the design and implementation of the GE task was based on the Genia event corpus (Kim et al., 2008) that represents domain knowledge of NFκB proteins. It was first organized as the sole task of the initial 2009 edition of BioNLP-ST (Kim et al., 2009). While in 2009 the data sets consisted only of Medline abstracts, in its second edition in 2011 (Kim et al., 2011b), it was extended to include full text articles to measure the generalization of the technology to full text papers. For its third edition this year, the GE task is organized with the goal of making it a more “real” task useful for knowledge base construction. The first design choice is to construct the data sets with recent full papers only, so that the extracted pieces of information could represent up-to-date knowledge of the domain. Second, the coreference annotations are integrated into the event annotations, to encourage the use of these co-reference features in the solution of the eve"
W13-2001,P05-1022,0,0.0190745,"Date 4 Participation GE 1-2-3 EVEX BioNLP-ST’13 organization BioNLP-ST’13 was split in three main periods. During thirteen weeks from mid-January to the first week of April, the participants prepared their systems with the training data. Supporting resources were delivered to participants during this period. Supporting resources were provided by the organizers and by three external providers after a public call for contribution. They range from tokenizers to entity detection tools, mostly focusing on syntactic parsing (Enju (Miyao and Tsujii, 2008), Stanford (Klein and Manning, 2002), McCCJ (Charniak and Johnson, 2005)). The test data were made available for 10 days before the participants had to submit their final results using on-line services. The evaluation results were TEES-2.1 • • BioSEM • NCBI • DlutNLP • HDS 4NLP • NICTA • USheff • UZH • HCMUS • • • • • CG PC GRO GRN BB 1 - 2-3 • • NaCTeM • • NCBI • RelAgent • UET-NII • ISI • OSEE U. of Ljubljana K.U. Leuven IRISATexMex Boun • • • • • • • • • • • • • • LIPN • LIMSI • • • Table 3: Participating teams per task. BioNLP-ST 2013 received 38 submissions from 22 teams (Table 3). One third, or seven teams, participated in multiple tasks. Only one team, UTur"
W13-2001,W11-0214,1,0.829223,"t Error Rate (Makhoul et al., 1999) that is more adapted to graph comparison than the usual Recall, Precision and F-score measures. Pathway Curation (PC) The PC task focuses on the automatic extraction of biomolecular reactions from text with the aim of supporting the development, evaluation and maintenance of biomolecular pathway models. The PC task setting and its document selection protocol account for both signaling and metabolic pathways. The 23 event types, including chemical modifications (Pyysalo et al., 2011b), are defined primarily with respect to the Systems Biology Ontology (SBO) (Ohta et al., 2011b; Ohta et al., 2011c), involving 4 SBO entity types. The PC task corpus was newly annotated for the task and consists of 525 PubMed abstracts, chosen for the relevance to specific pathway reactions selected from SBML models registered in BioModels and PANTHER DB repositories (Mi and Thomas, 2009). The corpus was manually annotated for over 12,000 events on top of close to 16,000 entities. 2.4 Gene Regulation Network in Bacteria (GRN) 2.6 Bacteria Biotopes (BB) The Bacteria Biotope (BB) task concerns the extraction of locations in which bacteria live and the categorization of these habitats wi"
W13-2001,W12-4304,1,0.844492,"Missing"
W13-2001,W09-1401,1,0.905104,"Missing"
W13-2001,W11-1801,1,0.712795,"Missing"
W13-2001,J08-1002,0,\N,Missing
W13-2001,W11-0215,1,\N,Missing
W13-2001,W11-1810,1,\N,Missing
W13-2008,W11-1828,0,0.0112182,"Missing"
W13-2008,W13-2003,0,0.0164694,"Missing"
W13-2008,W11-1826,0,0.0290686,"Missing"
W13-2008,P05-1022,0,0.140045,"Missing"
W13-2008,W13-2010,0,0.0333957,"Missing"
W13-2008,W11-1806,0,0.0334856,"Missing"
W13-2008,W11-1816,1,0.890054,"Missing"
W13-2008,W13-2012,1,0.200549,"Missing"
W13-2008,J08-1002,0,0.0344355,"Missing"
W13-2008,W12-4304,1,0.922588,"ns. For other categories of annotation, correct (gold standard) annotations are provided also for test data. 2.1 Table 1: Entity types. Indentation corresponds to is-a structure. Labels in gray identify groupings defined for organization only, not annotated types. Development Theme Cancer Equiv Cancer progression of chronic myeloid leukemia (CML) Figure 2: Example Equiv relation. drawn primarily from the Common Anatomy Reference Ontology (Haendel et al., 2008), a small, species-independent upper-level ontology based on the Foundational Model of Anatomy (Rosse and Mejino Jr, 2003). We refer to Ohta et al. (2012) for more detailed discussion of the anatomical entity type definitions. Entities The entity types defined in the CG task are shown in Table 1. The molecular level entity types largely match the scope of types such as P ROTEIN and C HEMICAL included in previous ST tasks (Kim et al., 2012; Pyysalo et al., 2012b). However, the CG types are more fine grained, and the types P RO TEIN DOMAIN OR REGION and DNA DOMAIN OR REGION are used in favor of the non-specific type E NTITY, applied in a number of previous tasks for additional event arguments (see Section 2.3). The definitions of the anatomical e"
W13-2008,W13-2011,0,0.0422743,"Missing"
W13-2008,D07-1111,0,0.0149447,"Missing"
W13-2008,de-marneffe-etal-2006-generating,0,\N,Missing
W13-2008,W11-1801,1,\N,Missing
W13-2008,E12-2021,1,\N,Missing
W13-2009,P05-1022,0,0.013255,"could provide further insight into the relative strengths and weaknesses of these two systems. Table 6: Primary evaluation results Event Extraction System8 (Bj¨orne et al., 2011) (TEES). The two systems share the same overall architecture, a one-best pipeline with SVMbased stages for event trigger detection, triggerargument relation detection, argument grouping into event structures, and modification prediction. The feature representations of both systems draw on substructures of dependency-like representations of sentence syntax, derived from full parses of input sentences. TEES applies the Charniak and Johnson (2005) parser with the McClosky (2009) biomedical model, converting the phrasestructure parses into dependencies using the Stanford tools (de Marneffe et al., 2006). By contrast, EventMine uses a combination of the predicateargument structure analyses created by the deep parser Enju (Miyao and Tsujii, 2008) and the output of the the GDep best-first shift-reduce dependency parser (Sagae and Tsujii, 2007). All three parsers have models trained in part on the biomedical domain GENIA treebank (Tateisi et al., 2005). Interestingly, both systems make use of the GE task data, but the application of EventMi"
W13-2009,W08-0608,0,0.0128679,"Missing"
W13-2009,W11-1828,0,0.0171244,"Missing"
W13-2009,W11-0214,1,0.596369,"in interactions (Krallinger et al., 2007; Pyysalo et al., 2008; Tikk et al., 2010). However, most such efforts have employed simple representations, such as entity pairs, that are not sufficient for capturing molecular reactions to the level of detail required to support the curation of pathway models. Additionally, previous efforts have not directly involved the semantics (e.g. reaction type definitions) of such models. Perhaps in part due to these reasons, natural language processing and information extraction methods have not been widely embraced by biomedical pathway curation communities (Ohta et al., 2011c; Ohta et al., 2011a). We believe that the extraction of structured event representations (Figure 1) pursued in the BioNLP Shared Tasks offers many opportunities to make significant contributions to support the development, evaluation and maintenance of biomolecular pathways. The Pathway Curation (PC) task, a main task of the BioNLP Shared Task 2013, is proposed as a step toward realizing these opportunities. The PC task aims to evaluate the applicability of event extraction systems to pathway curation and to encourage the further development of methods for related tasks. The design of the ta"
W13-2009,W12-4304,1,0.900591,"Missing"
W13-2009,W11-0215,1,0.854069,"iyao and Tsujii, 2008) and the output of the the GDep best-first shift-reduce dependency parser (Sagae and Tsujii, 2007). All three parsers have models trained in part on the biomedical domain GENIA treebank (Tateisi et al., 2005). Interestingly, both systems make use of the GE task data, but the application of EventMine extends on this considerably by applying a stacked model (Miwa et al., 2013b) with predictions also from models trained on the BioNLP ST 2011 EPI and ID tasks (Pyysalo et al., 2012) as well as from four corpora introduced outside of the shared tasks by Thompson et al. (2011), Pyysalo et al. (2011), Ohta et al. (2011b) and Ohta et al. (2011c). 4.2 5 Although participation in this initial run of the PC task was somewhat limited, the two participating systems have been applied to a large variety of event extraction tasks over the last years and have shown consistently competitive performance with the state of the art (Bj¨orne and Salakoski, 2011; Miwa et al., 2012). It is thus reasonable to assume that the higher performance achieved by the Evaluation results Table 6 summarizes the primary evaluation results. The two systems demonstrate broadly similar performance in terms of F-scores, wi"
W13-2009,D07-1111,1,0.639577,"prediction. The feature representations of both systems draw on substructures of dependency-like representations of sentence syntax, derived from full parses of input sentences. TEES applies the Charniak and Johnson (2005) parser with the McClosky (2009) biomedical model, converting the phrasestructure parses into dependencies using the Stanford tools (de Marneffe et al., 2006). By contrast, EventMine uses a combination of the predicateargument structure analyses created by the deep parser Enju (Miyao and Tsujii, 2008) and the output of the the GDep best-first shift-reduce dependency parser (Sagae and Tsujii, 2007). All three parsers have models trained in part on the biomedical domain GENIA treebank (Tateisi et al., 2005). Interestingly, both systems make use of the GE task data, but the application of EventMine extends on this considerably by applying a stacked model (Miwa et al., 2013b) with predictions also from models trained on the BioNLP ST 2011 EPI and ID tasks (Pyysalo et al., 2012) as well as from four corpora introduced outside of the shared tasks by Thompson et al. (2011), Pyysalo et al. (2011), Ohta et al. (2011b) and Ohta et al. (2011c). 4.2 5 Although participation in this initial run of"
W13-2009,I05-2038,1,0.757182,"s of sentence syntax, derived from full parses of input sentences. TEES applies the Charniak and Johnson (2005) parser with the McClosky (2009) biomedical model, converting the phrasestructure parses into dependencies using the Stanford tools (de Marneffe et al., 2006). By contrast, EventMine uses a combination of the predicateargument structure analyses created by the deep parser Enju (Miyao and Tsujii, 2008) and the output of the the GDep best-first shift-reduce dependency parser (Sagae and Tsujii, 2007). All three parsers have models trained in part on the biomedical domain GENIA treebank (Tateisi et al., 2005). Interestingly, both systems make use of the GE task data, but the application of EventMine extends on this considerably by applying a stacked model (Miwa et al., 2013b) with predictions also from models trained on the BioNLP ST 2011 EPI and ID tasks (Pyysalo et al., 2012) as well as from four corpora introduced outside of the shared tasks by Thompson et al. (2011), Pyysalo et al. (2011), Ohta et al. (2011b) and Ohta et al. (2011c). 4.2 5 Although participation in this initial run of the PC task was somewhat limited, the two participating systems have been applied to a large variety of event"
W13-2009,J08-1002,1,0.790519,"ion, triggerargument relation detection, argument grouping into event structures, and modification prediction. The feature representations of both systems draw on substructures of dependency-like representations of sentence syntax, derived from full parses of input sentences. TEES applies the Charniak and Johnson (2005) parser with the McClosky (2009) biomedical model, converting the phrasestructure parses into dependencies using the Stanford tools (de Marneffe et al., 2006). By contrast, EventMine uses a combination of the predicateargument structure analyses created by the deep parser Enju (Miyao and Tsujii, 2008) and the output of the the GDep best-first shift-reduce dependency parser (Sagae and Tsujii, 2007). All three parsers have models trained in part on the biomedical domain GENIA treebank (Tateisi et al., 2005). Interestingly, both systems make use of the GE task data, but the application of EventMine extends on this considerably by applying a stacked model (Miwa et al., 2013b) with predictions also from models trained on the BioNLP ST 2011 EPI and ID tasks (Pyysalo et al., 2012) as well as from four corpora introduced outside of the shared tasks by Thompson et al. (2011), Pyysalo et al. (2011),"
W13-2009,de-marneffe-etal-2006-generating,0,\N,Missing
W13-2009,W09-1401,1,\N,Missing
W13-2009,E12-2021,1,\N,Missing
