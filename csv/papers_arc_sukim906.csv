U14-1007,A Comparative Study of Weighting Schemes for the Interpretation of Spoken Referring Expressions,2014,12,0,1,1,38922,su kim,Proceedings of the Australasian Language Technology Association Workshop 2014,0,"This paper empirically explores the influence of two types of factors on the interpretation of spoken object descriptions: (1) descriptive attributes, e.g., colour and size; and (2) interpretation stages, e.g., syntax and pragmatics. We also investigate two schemes for combining attributes when estimating the goodness of an interpretation: Multiplicative and Additive. Our results show that the former scheme outperforms the latter, and that the weights assigned to the attributes of a description and the stages of an interpretation influence interpretation accuracy."
U13-1014,Error Detection in Automatic Speech Recognition,2013,15,1,3,0,41182,farshid zavareh,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,"We offer a supervised machine learning approach for recognizing erroneous words in the output of a speech recognizer. We have investigated several sets of features combined with two word configurations, and compared the performance of two classifiers: Decision Trees and Naive Bayes. Evaluation was performed on a corpus of 400 spoken referring expressions, with Decision Trees yielding a high recognition accuracy."
I13-1026,Evaluation of the Scusi? Spoken Language Interpretation System {--} A Case Study,2013,20,4,3,0,4,thomas kleinbauer,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We present a performance evaluation framework for Spoken Language Understanding (SLU) modules, focusing on three elements: (1) characterization of spoken utterances, (2) experimental design, and (3) quantitative evaluation metrics. We then describe the application of our framework to Scusi?xe2x80x94 our SLU system that focuses on referring expressions."
I13-1027,A Noisy Channel Approach to Error Correction in Spoken Referring Expressions,2013,19,3,1,1,38922,su kim,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We offer a noisy channel approach for recognizing and correcting erroneous words in referring expressions. Our mechanism handles three types of errors: it removes noisy input, inserts missing prepositions, and replaces mis-heard words (at present, they are replaced by generic words). Our mechanism was evaluated on a corpus of 295 spoken referring expressions, improving interpretation performance."
Y12-1021,Extracting Keywords from Multi-party Live Chats,2012,21,8,1,1,38922,su kim,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,"Live chats have become a popular form of communication, connecting people all over the globe. We believe that one of the simplest approaches for providing topic information to users joining a chat is keywords. In this paper, we present a method to automatically extract contextually relevant keywords for multi-party live chats. In our work, we identify keywords that are associated with specific dialogue acts as well as the occurrences of keywords across the entire conversation. In this way, we are able to identify distinguishing features of the chat based on structural information derived from live chats and predicted dialogue acts. In evaluation, we find that using structural information and predicted dialogue acts performs well, and that conventional methods do not work well over live chats."
Y12-1050,Classifying Dialogue Acts in Multi-party Live Chats,2012,19,18,1,1,38922,su kim,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,"We consider the task of classifying chat contributions by dialogue act in a multi-party setting. This extends the problem significantly over the 1-1 chat scenario due to the semiasynchronous and xe2x80x9centangledxe2x80x9d nature of the contributions by chat participants. We experiment with a number of machine learning approaches, using different categories of features: lexical, contextual, structural, keyword and dialogue interaction information. For evaluation, we developed gold-standard data using online forums from the USA Library of Congress. We found that, for multi-party dialogues, features based on 1-gram and keywords produced best performance, while features exploiting structure and interaction did not perform as well as previously reported results over 1-to-1 chats."
C12-1167,The Utility of Discourse Structure in Identifying Resolved Threads in Technical User Forums,2012,24,7,2,1,41187,li wang,Proceedings of {COLING} 2012,0,"Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. Automatically identifying whether the problem in a thread has been solved or not can help direct users to threads where the original problem has been solved, hence enhancing their prospects of solving their particular problem. In this paper, we investigate the task of Solvedness classification by exploiting the discourse structure of forum threads. Experimental results show that simple features derived from thread discourse structure can greatly boost the accuracy of Solvedness classification, which has been shown to be very difficult in previous research."
U11-1009,Classifying Domain-Specific Terms Using a Dictionary,2011,24,4,1,1,38922,su kim,Proceedings of the Australasian Language Technology Association Workshop 2011,0,"Automatically building domain-specific ontologies is a highly challenging task as it requires extracting domain-specific terms from a corpus and assigning them relevant domain concept labels. In this paper, we focus on the second task: i.e., assigning domain concepts to domain-specific terms. Motivated by previous approaches in related research (such as word sense disambiguation (WSD) and named entity recognition (NER)) that use semantic similarity among domain concepts, we explore three types of features - contextual, domain concepts, topics - to measure the semantic similarity of terms; we then assign the domain concepts from the best matching terms. As evaluation, we collected domainspecific terms from FOLDOC, a freely available on-line dictionary for the the Computing domain, and defined 9 domain concepts for this domain. Our results show that beyond contextual features, using domain concepts and topics derived from domain-specific terms helps to improve assigning domain concepts to the terms."
D11-1002,Predicting Thread Discourse Structure over Technical Web Forums,2011,55,37,3,1,41187,li wang,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with in situ classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads."
D11-1060,Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus,2011,41,26,1,1,38922,su kim,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"Responding to the need for semantic lexical resources in natural language processing applications, we examine methods to acquire noun compounds (NCs), e.g., orange juice, together with suitable fine-grained semantic interpretations, e.g., squeezed from, which are directly usable as paraphrases. We employ bootstrapping and web statistics, and utilize the relationship between NCs and paraphrasing patterns to jointly extract NCs and such patterns in multiple alternating iterations. In evaluation, we found that having one compound noun fixed yields both a higher number of semantically interpreted NCs and improved accuracy due to stronger semantic restrictions."
W10-2923,Tagging and Linking Web Forum Posts,2010,39,63,1,1,38922,su kim,Proceedings of the Fourteenth Conference on Computational Natural Language Learning,0,"We propose a method for annotating post-to-post discourse structure in online user forum data, in the hopes of improving troubleshooting-oriented information access. We introduce the tasks of: (1) post classification, based on a novel dialogue act tag set; and (2) link classification. We also introduce three feature sets (structural features, post context features and semantic features) and experiment with three discriminative learners (maximum entropy, SVM-HMM and CRF). We achieve above-baseline results for both dialogue act and link classification, with interesting divergences in which feature sets perform well over the two sub-tasks, and go on to perform preliminary investigation of the interaction between post tagging and linking."
W10-0508,Intelligent Linux Information Access by Data Mining: the {ILIAD} Project,2010,7,8,4,0,1468,timothy baldwin,Proceedings of the {NAACL} {HLT} 2010 Workshop on Computational Linguistics in a World of Social Media,0,"We propose an alternative to conventional information retrieval over Linux forum data, based on thread-, post- and user-level analysis, interfaced with an information retrieval engine via reranking."
U10-1006,Thread-level Analysis over Technical User Forum Data,2010,13,8,2,1,41187,li wang,Proceedings of the Australasian Language Technology Association Workshop 2010,0,"This research focuses on improving information access over troubleshootingoriented technical user forums via threadlevel analysis. We describe a modular task formulation and novel dataset, and go on to describe a series of preliminary classification experiments over the data. We find that a class composition strategy achieves the best results, surpassing multiclass classification approaches."
S10-1004,{S}em{E}val-2010 Task 5 : Automatic Keyphrase Extraction from Scientific Articles,2010,19,199,1,1,38922,su kim,Proceedings of the 5th International Workshop on Semantic Evaluation,0,This paper describes Task 5 of the Workshop on Semantic Evaluation 2010 (SemEval-2010). Systems are to automatically assign keyphrases or keywords to given scientific articles. The participating systems were evaluated by matching their extracted keyphrases against manually assigned ones. We present the overall ranking of the submitted systems and discuss our findings to suggest future directions for this task.
S10-1006,{S}em{E}val-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals,2010,4,98,2,0.418724,16715,iris hendrickx,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"SemEval-2 Task 8 focuses on Multi-way classification of semantic relations between pairs of nominals. The task was designed to compare different approaches to semantic relation classification and to provide a standard testbed for future research. This paper defines the task, describes the training and test data and the process of their creation, lists the participating systems (10 teams, 28 runs), and discusses their results."
S10-1007,{S}em{E}val-2 Task 9: The Interpretation of Noun Compounds Using Paraphrasing Verbs and Prepositions,2010,28,27,2,1,45588,cristina butnariu,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"Previous research has shown that the meaning of many noun-noun compounds N1 N2 can be approximated reasonably well by paraphrasing clauses of the form 'N2 that ... N1', where '...' stands for a verb with or without a preposition. For example, malaria mosquito is a 'mosquito that carries malaria'. Evaluating the quality of such paraphrases is the theme of Task 9 at SemEval-2010. This paper describes some background, the task definition, the process of data collection and the task results. We also venture a few general conclusions before the participating teams present their systems at the SemEval-2010 workshop. There were 5 teams who submitted 7 systems."
D10-1084,Classifying Dialogue Acts in One-on-One Live Chats,2010,33,49,1,1,38922,su kim,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"We explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums, an increasingly popular means of providing customer service. In particular, we investigate the effectiveness of various features and machine learners for this task. While a simple bag-of-words approach provides a solid baseline, we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance; learners that account for sequential dependencies (CRFs) show the best performance. We report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data."
C10-1065,Evaluating N-gram based Evaluation Metrics for Automatic Keyphrase Extraction,2010,23,31,1,1,38922,su kim,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"This paper describes a feasibility study of n-gram-based evaluation metrics for automatic keyphrase extraction. To account for near-misses currently ignored by standard evaluation metrics, we adapt various evaluation metrics developed for machine translation and summarization, and also the R-precision evaluation metric from keyphrase evaluation. In evaluation, the R-precision metric is found to achieve the highest correlation with human annotations. We also provide evidence that the degree of semantic similarity varies with the location of the partially-matching component words."
W09-2902,Re-examining Automatic Keyphrase Extraction Approaches in Scientific Articles,2009,-1,-1,1,1,38922,su kim,"Proceedings of the Workshop on Multiword Expressions: Identification, Interpretation, Disambiguation and Applications ({MWE} 2009)",0,None
W09-2905,A re-examination of lexical association measures,2009,13,24,2,0,46937,hung hoang,"Proceedings of the Workshop on Multiword Expressions: Identification, Interpretation, Disambiguation and Applications ({MWE} 2009)",0,"We review lexical Association Measures (AMs) that have been employed by past work in extracting multiword expressions. Our work contributes to the understanding of these AMs by categorizing them into two groups and suggesting the use of rank equivalence to group AMs with the same ranking performance. We also examine how existing AMs can be adapted to better rank English verb particle constructions and light verb constructions. Specifically, we suggest normalizing (Pointwise) Mutual Information and using marginal frequencies to construct penalization terms. We empirically validate the effectiveness of these modified AMs in detection tasks in English, performed on the Penn Treebank, which shows significant improvement over the original AMs."
W09-2415,{S}em{E}val-2010 Task 8: Multi-Way Classification of Semantic Relations Between Pairs of Nominals,2009,28,203,2,0.418724,16715,iris hendrickx,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"We present a brief overview of the main challenges in the extraction of semantic relations from English text, and discuss the shortcomings of previous data sets and shared tasks. This leads us to introduce a new task, which will be part of SemEval-2010: multi-way classification of mutually exclusive semantic relations between pairs of common nominals. The task is designed to compare different approaches to the problem and to provide a standard testbed for future research, which can benefit many applications in Natural Language Processing."
W09-2416,{S}em{E}val-2010 Task 9: The Interpretation of Noun Compounds Using Paraphrasing Verbs and Prepositions,2009,22,39,2,1,45588,cristina butnariu,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"We present a brief overview of the main challenges in understanding the semantics of noun compounds and consider some known methods. We introduce a new task to be part of SemEval-2010: the interpretation of noun compounds using paraphrasing verbs and prepositions. The task is meant to provide a standard testbed for future research on noun compound semantics. It should also promote paraphrase-based approaches to the problem, which can benefit many NLP applications."
U09-1013,Extracting Domain-Specific Words - A Statistical Approach,2009,0,5,1,1,38922,su kim,Proceedings of the Australasian Language Technology Association Workshop 2009,0,None
I08-2108,{MRD}-based Word Sense Disambiguation: Further Extending {L}esk,2008,12,14,2,0,1468,timothy baldwin,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"This paper reconsiders the task of MRDbased word sense disambiguation, in extending the basic Lesk algorithm to investigate the impact onWSD performance of different tokenisation schemes, scoring mechanisms, methods of gloss extension and filtering methods. In experimentation over the Lexeed Sensebank and the Japanese Senseval2 dictionary task, we demonstrate that character bigrams with sense-sensitive gloss extension over hyponyms and hypernyms enhances WSD performance."
I08-1074,Benchmarking Noun Compound Interpretation,2008,22,6,1,1,38922,su kim,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"In this paper we provide benchmark results for two classes of methods used in interpreting noun compounds (NCs): semantic similarity-based methods and their hybrids. We evaluate the methods using 7-way and binary class data from the nominal pair interpretation task of SEMEVAL-2007.1 We summarize and analyse our results, with the intention of providing a framework for benchmarking future research in this area."
U07-1009,Extending Sense Collocations in Interpreting Noun Compounds,2007,21,5,1,1,38922,su kim,Proceedings of the Australasian Language Technology Workshop 2007,0,"This paper investigates the task of noun compound interpretation, building on the sense collocation approach proposed by Moldovan et al. (2004). Our primary task is to evaluate the impact of similar words on the sense collocation method, and decrease the sensitivity of the classifiers by expanding the range of sense collocations via different semantic relations. Our method combines hypernyms, hyponyms and sister words of the component nouns, based on WORDNET. The data used in our experiments was taken from the nominal pair interpretation task of SEMEVAL-2007 (4th International Workshop on Semantic Evaluation 2007). In our evaluation, we test 7-way and 2-way class data, and show that the inclusion of hypernyms improves the performance of the sense collocation method, while the inclusion of hyponym and sister word information leads to a deterioration in performance."
S07-1049,{MELB}-{KB}: Nominal Classification as Noun Compound Interpretation,2007,9,6,1,1,38922,su kim,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"In this paper, we outline our approach to interpreting semantic relations in nominal pairs in SemEval-2007 task #4: Classification of Semantic Relations between Nominals. We build on two baseline approaches to interpreting noun compounds: sense collocation, and constituent similarity. These are consolidated into an overall system in combination with co-training, to expand the training data. Our two systems attained an average F-score over the test data of 58.7% and 57.8%, respectively."
S07-1050,{MELB}-{MKB}: Lexical Substitution system based on Relatives in Context,2007,5,11,2,0.446429,13902,david martinez,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"In this paper we describe the MELB-MKB system, as entered in the SemEval-2007 lexical substitution task. The core of our system was the Relatives in Context unsupervised approach, which ranked the candidate substitutes by web-lookup of the word sequences built combining the target context and each substitute. Our system ranked third in the final evaluation, performing close to the top-ranked system."
W06-2605,Discourse Parsing: Learning {FOL} Rules based on Rich Verb Semantic Representations to automatically label Rhetorical Relations,2006,16,4,3,0,1466,rajen subba,Proceedings of the Workshop on Learning Structured Information in Natural Language Applications,0,We report on our work to build a discourse parser (SemDP) that uses semantic features of sentences. We use an Inductive Logic Programming (ILP) System to exploit rich verb semantics of clauses to induce rules for discourse parsing. We demonstrate that ILP can be used to learn from highly structured natural language data and that the performance of a discourse parsing model that only uses semantic information is comparable to that of the state of the art syntactic discourse parsers.
W06-2110,Automatic Identification of {E}nglish Verb Particle Constructions using Linguistic Features,2006,20,10,1,1,38922,su kim,Proceedings of the Third {ACL}-{SIGSEM} Workshop on Prepositions,0,"This paper presents a method for identifying token instances of verb particle constructions (VPCs) automatically, based on the output of the RASP parser. The proposed method pools together instances of VPCs and verb-PPs from the parser output and uses the sentential context of each such instance to differentiate VPCs from verb-PPs. We show our technique to perform at an F-score of 97.4% at identifying VPCs in Wall Street Journal and Brown Corpus data taken from the Penn Tree-bank."
P06-2064,Interpreting Semantic Relations in Noun Compounds via Verb Semantics,2006,20,64,1,1,38922,su kim,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"We propose a novel method for automatically interpreting compound nouns based on a predefined set of semantic relations. First we map verb tokens in sentential contexts to a fixed set of seed verbs using WordNet::Similarity and Moby's Thesaurus. We then match the sentences with semantic relations based on the semantics of the seed verbs and grammatical roles of the head noun and modifier. Based on the semantics of the matched sentences, we then build a classifier using TiMBL. The performance of our final system at interpreting NCs is 52.6%."
I05-1082,Automatic Interpretation of Noun Compounds Using {W}ord{N}et Similarity,2005,22,77,1,1,38922,su kim,Second International Joint Conference on Natural Language Processing: Full Papers,0,"The paper introduces a method for interpreting novel noun compounds with semantic relations. The method is built around word similarity with pre-tagged noun compounds, based on WordNet::Similarity. Over 1,088 training instances and 1,081 test instances from the Wall Street Journal in the Penn Treebank, the proposed method was able to correctly classify 53.3% of the test noun compounds. We also investigated the relative contribution of the modifier and the head noun in noun compounds of different semantic types."
