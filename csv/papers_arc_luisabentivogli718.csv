2021.findings-acl.313,How to Split: the Effect of Word Segmentation on Gender Bias in Speech Translation,2021,-1,-1,3,0.681818,5746,marco gaido,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.emnlp-main.128,Is {``}moby dick{''} a Whale or a Bird? Named Entities and Terminology in Speech Translation,2021,-1,-1,4,0.681818,5746,marco gaido,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Automatic translation systems are known to struggle with rare words. Among these, named entities (NEs) and domain-specific terms are crucial, since errors in their translation can lead to severe meaning distortions. Despite their importance, previous speech translation (ST) studies have neglected them, also due to the dearth of publicly available resources tailored to their specific evaluation. To fill this gap, we i) present the first systematic analysis of the behavior of state-of-the-art ST systems in translating NEs and terminology, and ii) release NEuRoparl-ST, a novel benchmark built from European Parliament speeches annotated with NEs and terminology. Our experiments on the three language directions covered by our benchmark (enâes/fr/it) show that ST systems correctly translate 75{--}80{\%} of terms and 65{--}70{\%} of NEs, with very low performance (37{--}40{\%}) on person names."
2021.acl-long.224,Cascade versus Direct Speech Translation: Do the Differences Still Make a Difference?,2021,-1,-1,1,1,8246,luisa bentivogli,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Five years after the first published proofs of concept, direct approaches to speech translation (ST) are now competing with traditional cascade solutions. In light of this steady progress, can we claim that the performance gap between the two is closed? Starting from this question, we present a systematic comparison between state-of-the-art systems representative of the two paradigms. Focusing on three language directions (English-German/Italian/Spanish), we conduct automatic and manual evaluations, exploiting high-quality professional post-edits and annotations. Our multi-faceted analysis on one of the few publicly available ST benchmarks attests for the first time that: i) the gap between the two paradigms is now closed, and ii) the subtle differences observed in their behavior are not sufficient for humans neither to distinguish them nor to prefer one over the other."
2020.eamt-1.51,{CEF} Data Marketplace: Powering a Long-term Supply of Language Data,2020,-1,-1,7,0,20880,amir kamran,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"We describe the CEF Data Marketplace project, which focuses on the development of a trading platform of translation data for language professionals: translators, machine translation (MT) developers, language service providers (LSPs), translation buyers and government bodies. The CEF Data Marketplace platform will be designed and built to manage and trade data for all languages and domains. This project will open a continuous and longterm supply of language data for MT and other machine learning applications."
2020.coling-main.350,Breeding Gender-aware Direct Speech Translation Systems,2020,-1,-1,3,0.681818,5746,marco gaido,Proceedings of the 28th International Conference on Computational Linguistics,0,"In automatic speech translation (ST), traditional cascade approaches involving separate transcription and translation steps are giving ground to increasingly competitive and more robust direct solutions. In particular, by translating speech audio data without intermediate transcription, direct ST models are able to leverage and preserve essential information present in the input (e.g.speaker{'}s vocal characteristics) that is otherwise lost in the cascade framework. Although such ability proved to be useful for gender translation, direct ST is nonetheless affected by gender bias just like its cascade counterpart, as well as machine translation and numerous other natural language processing applications. Moreover, direct ST systems that exclusively rely on vocal biometric features as a gender cue can be unsuitable or even potentially problematic for certain users. Going beyond speech signals, in this paper we compare different approaches to inform direct ST models about the speaker{'}s gender and test their ability to handle gender translation from English into Italian and French. To this aim, we manually annotated large datasets with speak-ers{'} gender information and used them for experiments reflecting different possible real-world scenarios. Our results show that gender-aware direct ST solutions can significantly outperform strong {--} but gender-unaware {--} direct ST models. In particular, the translation of gender-marked words can increase up to 30 points in accuracy while preserving overall translation quality."
2020.acl-main.619,Gender in Danger? Evaluating Speech Translation Technology on the {M}u{ST}-{SHE} Corpus,2020,-1,-1,1,1,8246,luisa bentivogli,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Translating from languages without productive grammatical gender like English into gender-marked languages is a well-known difficulty for machines. This difficulty is also due to the fact that the training data on which models are built typically reflect the asymmetries of natural languages, gender bias included. Exclusively fed with textual data, machine translation is intrinsically constrained by the fact that the input sentence does not always contain clues about the gender identity of the referred human entities. But what happens with speech translation, where the input is an audio signal? Can audio provide additional information to reduce gender bias? We present the first thorough investigation of gender bias in speech translation, contributing with: i) the release of a benchmark useful for future studies, and ii) the comparison of different technologies (cascade and end-to-end) on two language directions (English-Italian/French)."
W19-6711,Do translator trainees trust machine translation? An experiment on post-editing and revision,2019,0,0,4,0,4945,randy scansani,"Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks",0,None
W19-6608,{MAGMAT}ic: A Multi-domain Academic Gold Standard with Manual Annotation of Terminology for Machine Translation Evaluation,2019,0,0,2,0,4945,randy scansani,Proceedings of Machine Translation Summit XVII: Research Track,0,None
N19-1202,{M}u{ST}-{C}: a {M}ultilingual {S}peech {T}ranslation {C}orpus,2019,0,29,3,0,5735,mattia gangi,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Current research on spoken language translation (SLT) has to confront with the scarcity of sizeable and publicly available training corpora. This problem hinders the adoption of neural end-to-end approaches, which represent the state of the art in the two parent tasks of SLT: automatic speech recognition and machine translation. To fill this gap, we created MuST-C, a multilingual speech translation corpus whose size and quality will facilitate the training of end-to-end systems for SLT from English into 8 languages. For each target language, MuST-C comprises at least 385 hours of audio recordings from English TED Talks, which are automatically aligned at the sentence level with their manual transcriptions and translations. Together with a description of the corpus creation methodology (scalable to add new data and cover new languages), we provide an empirical verification of its quality and SLT results computed with a state-of-the-art approach on each language direction."
D19-1140,Machine Translation for Machines: the Sentiment Classification Use Case,2019,0,0,2,0,14231,amirhossein tebbifakhr,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"We propose a neural machine translation (NMT) approach that, instead of pursuing adequacy and fluency ({``}human-oriented{''} quality criteria), aims to generate translations that are best suited as input to a natural language processing component designed for a specific downstream task (a {``}machine-oriented{''} criterion). Towards this objective, we present a reinforcement learning technique based on a new candidate sampling strategy, which exploits the results obtained on the downstream task as weak feedback. Experiments in sentiment classification of Twitter data in German and Italian show that feeding an English classifier with {``}machine-oriented{''} translations significantly improves its performance. Classification results outperform those obtained with translations produced by general-purpose NMT models as well as by an approach based on reinforcement learning. Moreover, our results on both languages approximate the classification accuracy computed on gold standard English tweets."
L16-1562,{WAGS}: A Beautiful {E}nglish-{I}talian Benchmark Supporting Word Alignment Evaluation on Rare Words,2016,25,0,1,1,8246,luisa bentivogli,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents WAGS (Word Alignment Gold Standard), a novel benchmark which allows extensive evaluation of WA tools on out-of-vocabulary (OOV) and rare words. WAGS is a subset of the Common Test section of the Europarl English-Italian parallel corpus, and is specifically tailored to OOV and rare words. WAGS is composed of 6,715 sentence pairs containing 11,958 occurrences of OOV and rare words up to frequency 15 in the Europarl Training set (5,080 English words and 6,878 Italian words), representing almost 3{\%} of the whole text. Since WAGS is focused on OOV/rare words, manual alignments are provided for these words only, and not for the whole sentences. Two off-the-shelf word aligners have been evaluated on WAGS, and results have been compared to those obtained on an existing benchmark tailored to full text alignment. The results obtained confirm that WAGS is a valuable resource, which allows a statistically sound evaluation of WA systems{'} performance on OOV and rare words, as well as extensive data analyses. WAGS is publicly released under a Creative Commons Attribution license."
D16-1025,Neural versus Phrase-Based Machine Translation Quality: a Case Study,2016,29,33,1,1,8246,luisa bentivogli,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,"Within the field of Statistical Machine Translation (SMT), the neural approach (NMT) has recently emerged as the first technology able to challenge the long-standing dominance of phrase-based approaches (PBMT). In particular, at the IWSLT 2015 evaluation campaign, NMT outperformed well established state-of-the-art PBMT systems on English-German, a language pair known to be particularly hard because of morphology and syntactic differences. To understand in what respects NMT provides better translation quality than PBMT, we perform a detailed analysis of neural versus phrase-based SMT outputs, leveraging high quality post-edits performed by professional translators on the IWSLT data. For the first time, our analysis provides useful insights on what linguistic phenomena are best modeled by neural models -- such as the reordering of verbs -- while pointing out other aspects that remain to be improved."
2015.iwslt-evaluation.1,The {IWSLT} 2015 Evaluation Campaign,2015,18,51,4,0,10592,mauro cettolo,Proceedings of the 12th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
S14-2001,{S}em{E}val-2014 Task 1: Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment,2014,23,179,2,0,10198,marco marelli,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper presents the task on the evaluation of Compositional Distributional Semantics Models on full sentences organized for the first time within SemEval2014. Participation was open to systems based on any approach. Systems were presented with pairs of sentences and were evaluated on their ability to predict human judgments on (i) semantic relatedness and (ii) entailment. The task attracted 21 teams, most of which participated in both subtasks. We received 17 submissions in the relatedness subtask (for a total of 66 runs) and 18 in the entailment subtask (65 runs)."
marelli-etal-2014-sick,A {SICK} cure for the evaluation of compositional distributional semantic models,2014,14,202,4,0,10198,marco marelli,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Shared and internationally recognized benchmarks are fundamental for the development of any computational system. We aim to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them. SICK consists of about 10,000 English sentence pairs that include many examples of the lexical, syntactic and semantic phenomena that CDSMs are expected to account for, but do not require dealing with other aspects of existing sentential data sets (idiomatic multiword expressions, named entities, telegraphic language) that are not within the scope of CDSMs. By means of crowdsourcing techniques, each pair was annotated for two crucial semantic tasks: relatedness in meaning (with a 5-point rating scale as gold score) and entailment relation between the two elements (with three possible gold labels: entailment, contradiction, and neutral). The SICK data set was used in SemEval-2014 Task 1, and it freely available for research purposes."
D14-1172,Assessing the Impact of Translation Errors on Machine Translation Quality with Mixed-effects Models,2014,30,10,3,0,3526,marcello federico,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Learning from errors is a crucial aspect of improving expertise. Based on this notion, we discuss a robust statistical framework for analysing the impact of different error types on machine translation (MT) output quality. Our approach is based on linear mixed-effects models, which allow the analysis of error-annotated MT output taking into account the variability inherent to the specific experimental setting from which the empirical observations are drawn. Our experiments are carried out on different language pairs involving Chinese, Arabic and Russian as target languages. Interesting findings are reported, concerning the impact of different error types both at the level of human perception of quality and with respect to performance results measured with automatic metrics."
C14-2026,{MT}-{EQ}u{A}l: a Toolkit for Human Assessment of Machine Translation Output,2014,4,14,2,0,39811,christian girardi,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: System Demonstrations",0,"MT-EQuAl (Machine Translation Errors, Quality, Alignment) is a toolkit for human assessment of Machine Translation (MT) output. MT-EQuAl implements three different tasks in an integrated environment: annotation of translation errors, translation quality rating (e.g. adequacy and fluency, relative ranking of alternative translations), and word alignment. The toolkit is webbased and multi-user, allowing large scale and remotely managed manual annotation projects. It incorporates a number of project management functions and sophisticated progress monitoring capabilities. The implemented evaluation tasks are configurable and can be adapted to several specific annotation needs. The toolkit is open source and released under Apache 2.0 license."
2014.iwslt-evaluation.1,Report on the 11th {IWSLT} evaluation campaign,2014,-1,-1,4,0.16178,10592,mauro cettolo,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"The paper overviews the 11th evaluation campaign organized by the IWSLT workshop. The 2014 evaluation offered multiple tracks on lecture transcription and translation based on the TED Talks corpus. In particular, this year IWSLT included three automatic speech recognition tracks, on English, German and Italian, five speech translation tracks, from English to French, English to German, German to English, English to Italian, and Italian to English, and five text translation track, also from English to French, English to German, German to English, English to Italian, and Italian to English. In addition to the official tracks, speech and text translation optional tracks were offered, globally involving 12 other languages: Arabic, Spanish, Portuguese (B), Hebrew, Chinese, Polish, Persian, Slovenian, Turkish, Dutch, Romanian, Russian. Overall, 21 teams participated in the evaluation, for a total of 76 primary runs submitted. Participants were also asked to submit runs on the 2013 test set (progress test set), in order to measure the progress of systems with respect to the previous year. All runs were evaluated with objective metrics, and submissions for two of the official text translation tracks were also evaluated with human post-editing."
S13-2005,{S}emeval-2013 Task 8: Cross-lingual Textual Entailment for Content Synchronization,2013,18,20,4,0.543324,5083,matteo negri,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper presents the second round of the task on Cross-lingual Textual Entailment for Content Synchronization, organized within SemEval-2013. The task was designed to promote research on semantic inference over texts written in different languages, targeting at the same time a real application scenario. Participants were presented with datasets for different language pairs, where multi-directional entailment relations (xe2x80x9cforwardxe2x80x9d, xe2x80x9cbackwardxe2x80x9d, xe2x80x9cbidirectionalxe2x80x9d, xe2x80x9cno entailmentxe2x80x9d) had to be identified. We report on the training and test data used for evaluation, the process of their creation, the participating systems (six teams, 61 runs), the approaches adopted and the results achieved."
S13-2045,{S}em{E}val-2013 Task 7: The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge,2013,26,71,6,0,41055,myroslava dzikovska,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"We present the results of the Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge, aiming to bring together researchers in educational NLP technology and textual entailment. The task of giving feedback on student answers requires semantic inference and therefore is related to recognizing textual entailment. Thus, we offered to the community a 5-way student response labeling task, as well as 3-way and 2way RTE-style tasks on educational data. In addition, a partial entailment task was piloted. We present and compare results from 9 participating teams, and discuss future directions."
2013.iwslt-evaluation.1,Report on the 10th {IWSLT} evaluation campaign,2013,-1,-1,4,0.16178,10592,mauro cettolo,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"The paper overviews the tenth evaluation campaign organized by the IWSLT workshop. The 2013 evaluation offered multiple tracks on lecture transcription and translation based on the TED Talks corpus. In particular, this year IWSLT included two automatic speech recognition tracks, on English and German, three speech translation tracks, from English to French, English to German, and German to English, and three text translation track, also from English to French, English to German, and German to English. In addition to the official tracks, speech and text translation optional tracks were offered involving 12 other languages: Arabic, Spanish, Portuguese (B), Italian, Chinese, Polish, Persian, Slovenian, Turkish, Dutch, Romanian, Russian. Overall, 18 teams participated in the evaluation for a total of 217 primary runs submitted. All runs were evaluated with objective metrics on a current test set and two progress test sets, in order to compare the progresses against systems of the previous years. In addition, submissions of one of the official machine translation tracks were also evaluated with human post-editing."
S12-1053,{S}emeval-2012 Task 8: Cross-lingual Textual Entailment for Content Synchronization,2012,21,45,4,0.586749,5083,matteo negri,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper presents the first round of the task on Cross-lingual Textual Entailment for Content Synchronization, organized within SemEval-2012. The task was designed to promote research on semantic inference over texts written in different languages, targeting at the same time a real application scenario. Participants were presented with datasets for different language pairs, where multi-directional entailment relations (forward, backward, bidirectional, no_entailment) had to be identified. We report on the training and test data used for evaluation, the process of their creation, the participating systems (10 teams, 92 runs), the approaches adopted and the results achieved."
negri-etal-2012-chinese,{C}hinese Whispers: Cooperative Paraphrase Acquisition,2012,18,11,5,0.586749,5083,matteo negri,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present a framework for the acquisition of sentential paraphrases based on crowdsourcing. The proposed method maximizes the lexical divergence between an original sentence s and its valid paraphrases by running a sequence of paraphrasing jobs carried out by a crowd of non-expert workers. Instead of collecting direct paraphrases of s, at each step of the sequence workers manipulate semantically equivalent reformulations produced in the previous round. We applied this method to paraphrase English sentences extracted from Wikipedia. Our results show that, keeping at each round n the most promising paraphrases (i.e. the more lexically dissimilar from those acquired at round n-1), the monotonic increase of divergence allows to collect good-quality paraphrases in a cost-effective manner."
federico-etal-2012-iwslt,The {IWSLT} 2011 Evaluation Campaign on Automatic Talk Translation,2012,18,30,3,0.116694,3526,marcello federico,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We report here on the eighth evaluation campaign organized in 2011 by the IWSLT workshop series. That IWSLT 2011 evaluation focused on the automatic translation of public talks and included tracks for speech recognition, speech translation, text translation, and system combination. Unlike in previous years, all data supplied for the evaluation has been publicly released on the workshop website, and is at the disposal of researchers interested in working on our benchmarks and in comparing their results with those published at the workshop. This paper provides an overview of the IWSLT 2011 evaluation campaign, and describes the data supplied, the evaluation infrastructure made available to participants, and the subjective evaluation carried out."
2012.eamt-1.56,Crowd-based {MT} Evaluation for non-{E}nglish Target Languages,2012,-1,-1,3,0,12388,michael paul,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,None
D11-1062,Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora,2011,14,61,2,0.586749,5083,matteo negri,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"We address the creation of cross-lingual textual entailment corpora by means of crowd-sourcing. Our goal is to define a cheap and replicable data collection methodology that minimizes the manual work done by expert annotators, without resorting to preprocessing tools or already annotated monolingual datasets. In line with recent works emphasizing the need of large-scale annotation efforts for textual entailment, our work aims to: i) tackle the scarcity of data available to train and evaluate systems, and ii) promote the recourse to crowdsourcing as an effective way to reduce the costs of data collection without sacrificing quality. We show that a complex data creation task, for which even experts usually feature low agreement scores, can be effectively decomposed into simple subtasks assigned to non-expert annotators. The resulting dataset, obtained from a pipeline of different jobs routed to Amazon Mechanical Turk, contains more than 1,600 aligned pairs for each combination of texts-hypotheses in English, Italian and German."
2011.mtsummit-papers.59,Getting Expert Quality from the Crowd for Machine Translation Evaluation,2011,-1,-1,1,1,8246,luisa bentivogli,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.iwslt-evaluation.1,Overview of the {IWSLT} 2011 evaluation campaign,2011,25,52,2,0.116694,3526,marcello federico,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We report here on the eighth Evaluation Campaign organized by the IWSLT workshop. This year, the IWSLT evaluation focused on the automatic translation of public talks and included tracks for speech recognition, speech translation, text translation, and system combination. Unlike previous years, all data supplied for the evaluation has been publicly released on the workshop website, and is at the disposal of researchers interested in working on our benchmarks and in comparing their results with those published at the workshop. This paper provides an overview of the IWSLT 2011 Evaluation Campaign, which includes: descriptions of the supplied data and evaluation specifications of each track, the list of participants specifying their submitted runs, a detailed description of the subjective evaluation carried out, the main findings of each exercise drawn from the results and the system descriptions prepared by the participants, and, finally, several detailed tables reporting all the evaluation results."
W10-3503,Extending {E}nglish {ACE} 2005 Corpus Annotation with Ground-truth Links to {W}ikipedia,2010,13,19,1,1,8246,luisa bentivogli,Proceedings of the 2nd Workshop on {T}he {P}eople{'}s {W}eb {M}eets {NLP}: {C}ollaboratively {C}onstructed {S}emantic {R}esources,0,This paper describes an on-going annotation effort which aims at adding a manual annotation layer connecting an existing annotated corpus such as the English ACE-2005 Corpus to Wikipedia. The annotation layer is intended for the evaluation of accuracy of linking to Wikipedia in the framework of a coreference resolution system.
bentivogli-etal-2010-building,Building Textual Entailment Specialized Data Sets: a Methodology for Isolating Linguistic Phenomena Relevant to Inference,2010,9,34,1,1,8246,luisa bentivogli,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper proposes a methodology for the creation of specialized data sets for Textual Entailment, made of monothematic Text-Hypothesis pairs (i.e. pairs in which only one linguistic phenomenon relevant to the entailment relation is highlighted and isolated). The expected benefits derive from the intuition that investigating the linguistic phenomena separately, i.e. decomposing the complexity of the TE problem, would yield an improvement in the development of specific strategies to cope with them. The annotation procedure assumes that humans have knowledge about the linguistic phenomena relevant to inference, and a classification of such phenomena both into fine grained and macro categories is suggested. We experimented with the proposed methodology over a sample of pairs taken from the RTE-5 data set, and investigated critical issues arising when entailment, contradiction or unknown pairs are considered. The result is a new resource, which can be profitably used both to advance the comprehension of the linguistic phenomena relevant to entailment judgments and to make a first step towards the creation of large-scale specialized data sets."
abad-etal-2010-resource,A Resource for Investigating the Impact of Anaphora and Coreference on Inference.,2010,12,7,2,0,32584,azad abad,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Discourse phenomena play a major role in text processing tasks. However, so far relatively little study has been devoted to the relevance of discourse phenomena for inference. Therefore, an experimental study was carried out to assess the relevance of anaphora and coreference for Textual Entailment (TE), a prominent inference framework. First, the annotation of anaphoric and coreferential links in the RTE-5 Search data set was performed according to a specifically designed annotation scheme. As a result, a new data set was created where all anaphora and coreference instances in the entailing sentences which are relevant to the entailment judgment are solved and annotated.. A by-product of the annotation is a new ÂaugmentedÂ data set, where all the referring expressions which need to be resolved in the entailing sentences are replaced by explicit expressions. Starting from the final output of the annotation, the actual impact of discourse phenomena on inference engines was investigated, identifying the kind of operations that the systems need to apply to address discourse phenomena and trying to find direct mappings between these operation and annotation types."
W06-2713,Representing and Accessing Multilevel Linguistic Annotation using the {MEANING} Format,2006,3,3,2,1,42361,emanuele pianta,Proceedings of the 5th Workshop on {NLP} and {XML} ({NLPXML}-2006): Multi-Dimensional Markup in Natural Language Processing,0,"We present an XML annotation format (MEANING Annotation Format, MAF) specifically designed to represent and integrate different levels of linguistic annotations and a tool that provides flexible access to them (MEANING Browser). We describe our experience in integrating linguistic annotations coming from different sources, and the solutions we adopted to implement efficient access to corpora annotated with the Meaning Format."
W04-2214,"Revising the {W}ordnet Domains Hierarchy: semantics, coverage and balancing",2004,8,142,1,1,8246,luisa bentivogli,Proceedings of the Workshop on Multilingual Linguistic Resources,0,"The continuous expansion of the multilingual information society has led in recent years to a pressing demand for multilingual linguistic resources suitable to be used for different applications.n n In this paper we present the WordNet Domains Hierarchy (WDH), a language-independent resource composed of 164, hierarchically organized, domain labels (e.g. Architecture, Sport, Medicine). Although WDH has been successfully applied to various Natural Language Processing tasks, the first available version presented some problems, mostly related to the lack of a clear semantics of the domain labels. Other correlated issues were the coverage and the balancing of the domains. We illustrate a new version of WDH addressing these problems by an explicit and systematic reference to the Dewey Decimal Classification. The new version of WDH has a better defined semantics and is applicable to a wider range of tasks."
C04-1053,Evaluating Cross-Language Annotation Transfer in the {M}ulti{S}em{C}or Corpus,2004,19,26,1,1,8246,luisa bentivogli,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"In this paper we illustrate and evaluate an approach to the creation of high quality linguistically annotated resources based on the exploitation of aligned parallel corpora. This approach is based on the assumption that if a text in one language has been annotated and its translation has not, annotations can be transferred from the source text to the target using word alignment as a bridge. The transfer approach has been tested in the creation of the MultiSemCor corpus, an English/Italian parallel corpus created on the basis of the English SemCor corpus. In MultiSemCor texts are aligned at the word level and semantically annotated with a shared inventory of senses. We present some experiments carried out to evaluate the different steps involved in the methodology. The results of the evaluation suggest that the cross-language annotation transfer methodology is a promising solution allowing for the exploitation of existing (mostly English) annotated resources to bootstrap the creation of annotated corpora in new (resource-poor) languages with greatly reduced human effort."
C04-1156,Knowledge Intensive Word Alignment with {KNOWA},2004,8,9,2,1,42361,emanuele pianta,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"In this paper we present KNOWA, an English/Italian word aligner, developed at ITC-irst, which relies mostly on information contained in bilingual dictionaries. The performances of KNOWA are compared with those of GIZA, a state of the art statistics-based alignment algorithm. The two algorithms are evaluated on the EuroCor and MultiSemCor tasks, that is on two English/Italian publicly available parallel corpora. The results of the evaluation show that, given the nature and the size of the available English-Italian parallel corpora, a language-resource-based word aligner such as KNOWA can outperform a fully statistics-based algorithm such as GIZA."
E03-1018,Beyond Lexical Units: Enriching {W}ord{N}ets with Phrasets,2003,5,16,1,1,8246,luisa bentivogli,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In this paper we present a proposal to extend WordNet-like lexical databases by adding phrasets, i.e. sets of free combinations of words which are recurrently used to express a concept (let's call them recurrent free phrases). Phrasets are a useful source of information for different NLP tasks, and particularly in a multilingual environment to manage lexical gaps. Two experiments are presented to check the possibility of acquiring recurrent free phrases from dictionaries and corpora."
bentivogli-pianta-2002-opportunistic,Opportunistic Semantic Tagging,2002,12,4,1,1,8246,luisa bentivogli,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"Building semantically annotated corpora from scratch is a time consuming activity requiring very specialized resources. In this paper we present a pilot study carried out to test a methodology that can be used to create a semantically annotated corpus by exploiting information contained in an already annotated corpus. The main hypothesis underlying the proposed methodology is that, given a text and its translation into another language, the translation preserves to a large extent the meaning of the source language text. This means that if one of the two texts is already semantically tagged, and if we can align at the appropriate level the parallel texts, it should be possible to transfer the semantic annotation from the tagged text to its translation. More specifically, in our experiment we considered word level semantic annotation. The pilot study has been carried out on six texts taken from the SemCor corpus and their Italian translations. To test the methodology we implemented an annotation transfer system based on an English/Italian word aligner, developed at ITC-irst, which relies mostly on information contained in bilingual dictionaries."
bentivogli-etal-2000-coping,Coping with Lexical Gaps when Building Aligned Multilingual Wordnets,2000,7,10,1,1,8246,luisa bentivogli,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"In this paper we present a methodology for automatically classifying the translation equivalents of a machine readable bilingual dictionary in three main groups: lexical units, lexical gaps (that is cases when a lexical concept of a language does not have a correspondent in the other language) and translation equivalents that need to be manually classified as lexical units or lexical gaps. This preventive classification reduces the manual work necessary to cope with lexical gaps in the construction of aligned multilingual wordnets."
