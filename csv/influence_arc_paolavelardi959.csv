2020.lrec-1.283,P82-1004,0,0.705922,"d the Wikipedia category hierarchy. MKGDB, thanks the versatility of the Neo4j graph database manager technology, is intended to favour and help the development of open-domain natural language processing applications relying on knowledge bases, such as information extraction, hypernymy discovery, topic clustering, and others. Our resource consists of a large hypernymy graph which counts more than 37 million nodes and more than 81 million hypernymy relations. Keywords: knowledge graphs, graph databases, hypernymy graphs 1. Introduction Since the end of the last century, both semantic networks (Allen and Frisch, 1982) and knowledge graphs (KGs) are playing the important role of representing entities and relations with high reliability, explainability, and reusability (Bonatti et al., 2018). KGs have had an impact on the development of many fields of research (Camacho-Collados et al., 2018) ranging from the Semantic Web (Shadbolt et al., 2006) to Natural Language Processing (NLP)1 . In order to speed up and support the development of novel knowledge-based applications, we present MKGDB, a (very) large scale graph database created as a combination of multiple taxonomy backbones, extracted 2 from 5 existing k"
2020.lrec-1.283,P98-1013,0,0.7942,"Missing"
2020.lrec-1.283,S15-2151,1,0.896922,"Missing"
2020.lrec-1.283,N18-6004,0,0.0579629,"ction, hypernymy discovery, topic clustering, and others. Our resource consists of a large hypernymy graph which counts more than 37 million nodes and more than 81 million hypernymy relations. Keywords: knowledge graphs, graph databases, hypernymy graphs 1. Introduction Since the end of the last century, both semantic networks (Allen and Frisch, 1982) and knowledge graphs (KGs) are playing the important role of representing entities and relations with high reliability, explainability, and reusability (Bonatti et al., 2018). KGs have had an impact on the development of many fields of research (Camacho-Collados et al., 2018) ranging from the Semantic Web (Shadbolt et al., 2006) to Natural Language Processing (NLP)1 . In order to speed up and support the development of novel knowledge-based applications, we present MKGDB, a (very) large scale graph database created as a combination of multiple taxonomy backbones, extracted 2 from 5 existing knowledge graphs namely: ConceptNet (Speer et al., 2017), DBpedia (Lehmann et al., 2015), WebIsAGraph (Faralli et al., 2019), WordNet (Fellbaum, 1998) and the Wikipedia hierarchy of categories. The resource combines multiple lexical knowledge graphs representing entities and hy"
2020.lrec-1.283,E17-1056,1,0.917461,"nd crafted by human experts (like WordNet and others). Thanks to the availability of different streams of knowledge and the versatility of graph database technologies, we exploit methodologies leveraging topological features from multiple knowledge graphs. As an example, MKGDB contains a high number of crosslink edges (edges connecting nodes belonging to different knowledge graphs) which are fundamental information in algorithms such as linking and mining heterogeneous data (P and Jurek-Loughrey, 2018), entity alignment between knowledge graphs (Trisedya et al., 2019) and noisy graph pruning (Faralli et al., 2017). Our resource is compiled on top of the Neo4j platform3 . The Neo4j, in comparison to other state of art technologies (see Section 2. for a review on graph database systems), offers both a scalable solution enabling to manage large scale graphs and specific textual based indexing functionalities to 1 Michael Galkin, Knowledge Natural Language Processing @ https://towardsdatascience.com/ knowledge-graph-bb78055a7884 2 at time of writing 3 https://neo4j.com/ Graphs in ACL 2019, better support natural language processing applications. Other filed of applications and studies that might benefit fr"
2020.lrec-1.283,L16-1056,1,0.844391,"ledge representation, but they do not model commonsense and domain specific knowledge. To cope with the absence of domain/application specific information, other efforts are focusing on knowledge acquisition techniques to mine information from heterogeneous sources, and even from the entire Web. Examples in this direction are: graph based approaches such as OntolearnReloaded (Velardi et al., 2013) or (Biemann et al., 2018) where the authors present a distributional semantics-based end-to-end framework for the enrichment of lexical semantic resources, or Probase (Wu et al., 2012) and WebIsADB (Seitner et al., 2016), where lexical syntactic patterns are used to mine hypernymy relations from Web-scale corpora. The main problem of the above mining techniques is related to the acquisition of noisy or wrong information, which requires human supervision or additional algorithmic efforts to be identified and removed. In the above described context, the MKGDB resource, by combining both human curated and noisy hypernymy graphs, may facilitate the development of novel approaches dedicated to minimizing the human supervision required in current state of the art methodologies. Knowledge Base management technologie"
2020.lrec-1.283,J13-3007,1,0.852313,"Graphs in ACL 2019, better support natural language processing applications. Other filed of applications and studies that might benefit from the availability of MKGDB are, for example: • applications aimed at generating graph embeddings (Wang et al., 2017) where combining knowledge graphs can partially solve the sparsity problem; • studies aimed at extracting or inducing faceted/multimodal domain knowledge graphs (Liu et al., 2019); • studies devoted to the definition of novel benchmarks for the tasks of knowledge graph refinement (Paulheim, 2016), or taxonomy induction (Bordea et al., 2015) (Velardi et al., 2013); • distributional and topological based methodologies for the enrichment of lexical resources (Biemann et al., 2018); • empirical studies of graph algorithms applied to large scale real graphs. The rest of this paper is organized as follows: • Section 2. describes the state of the art on knowledge graphs and graph database technologies; • Section 3. provides details about the MKGDB resource, and detailed statistics about the topology of the graph; and • Section 4. summarizes the contributions of this paper. 2. Related work Large-scale lexical Knowledge Bases: As described in (Camacho-Collados"
A92-1013,J89-1002,0,\N,Missing
A92-1013,J90-1003,0,\N,Missing
A92-1013,H91-1067,0,\N,Missing
A92-1013,P91-1036,0,\N,Missing
A92-1013,E87-1040,1,\N,Missing
A92-1013,C90-1005,0,\N,Missing
A92-1013,E87-1006,0,\N,Missing
A92-1013,P91-1030,0,\N,Missing
A92-1013,P91-1019,0,\N,Missing
A92-1013,P90-1034,0,\N,Missing
A92-1013,P91-1027,0,\N,Missing
A92-1013,W91-0212,0,\N,Missing
A92-1013,C90-3010,0,\N,Missing
A92-1013,P89-1022,0,\N,Missing
A92-1013,P90-1032,0,\N,Missing
A97-1055,J96-4006,1,\N,Missing
A97-1055,C96-1005,0,\N,Missing
A97-1055,C96-1038,0,\N,Missing
A97-1055,C94-2113,0,\N,Missing
A97-1055,A92-1013,1,\N,Missing
A97-1055,C94-2119,0,\N,Missing
A97-1055,C92-2070,0,\N,Missing
A97-1055,C94-2195,0,\N,Missing
A97-1055,P94-1038,0,\N,Missing
A97-1055,P93-1024,0,\N,Missing
C04-1150,J04-2002,1,\N,Missing
C90-2066,J87-3007,0,\N,Missing
C90-2066,C88-1012,0,\N,Missing
C90-2066,C88-2112,0,\N,Missing
C90-2066,A88-1021,0,\N,Missing
C90-2066,P89-1023,1,\N,Missing
C98-1045,C94-1074,0,0.0918327,"Missing"
C98-1045,A97-1029,0,0.081216,"Missing"
C98-1045,A97-1028,0,0.0848666,"Missing"
C98-1045,M91-1028,0,\N,Missing
C98-1045,A97-1030,0,\N,Missing
C98-1045,J95-4004,0,\N,Missing
C98-1045,H92-1045,0,\N,Missing
C98-1045,M95-1006,0,\N,Missing
C98-1045,M95-1011,0,\N,Missing
cucchiarelli-etal-2004-automatic,J04-2002,1,\N,Missing
cucchiarelli-etal-2004-automatic,J02-3001,0,\N,Missing
E87-1040,P79-1003,0,\N,Missing
E87-1040,T75-2001,0,\N,Missing
J01-1005,C96-1005,0,0.0105868,"ntexts. The formula also has parameters (k, ~, fl), estimated by running systematic experiments. Standard statistical techniques have been used to balance experimental conditions and the sources of variance. 3. Using WordNet for Context Generalization One of the stated objectives of this paper is to investigate the effect of context generalization (the a d d e n d ESLB in the formula of the evidence) on our sense tagging task. The use of on-line thesauri for context generalization has already been investigated with limited success (Hearst and Schuetze 1993; Brill and Resnik 1994; Resnik 1997; Agirre and Rigau 1996). Though the idea of using thesauri for context expansion is quite common, there are no clear indications that this is actually useful in terms of performance. However, studying the effect of context expansion for a PN tagging task in particular is relevant because: PNs m a y be hypothesized to have a unique sense in a text, and even in a domain corpus. Therefore, we can reliably consider as potential sense indicators all the contexts in which a PN appears. The only source of ambiguity is then the w o r d wi co-occurring in a syntactic context with a PN, esli(wi, U_PN), but since in ESLB we gr"
J01-1005,C94-1074,0,0.0613756,"Missing"
J01-1005,C94-2195,0,0.0432683,"ce of unreliable or uninformative contexts. The formula also has parameters (k, ~, fl), estimated by running systematic experiments. Standard statistical techniques have been used to balance experimental conditions and the sources of variance. 3. Using WordNet for Context Generalization One of the stated objectives of this paper is to investigate the effect of context generalization (the a d d e n d ESLB in the formula of the evidence) on our sense tagging task. The use of on-line thesauri for context generalization has already been investigated with limited success (Hearst and Schuetze 1993; Brill and Resnik 1994; Resnik 1997; Agirre and Rigau 1996). Though the idea of using thesauri for context expansion is quite common, there are no clear indications that this is actually useful in terms of performance. However, studying the effect of context expansion for a PN tagging task in particular is relevant because: PNs m a y be hypothesized to have a unique sense in a text, and even in a domain corpus. Therefore, we can reliably consider as potential sense indicators all the contexts in which a PN appears. The only source of ambiguity is then the w o r d wi co-occurring in a syntactic context with a PN, es"
J01-1005,P98-1045,1,0.888807,"Missing"
J01-1005,H92-1045,0,0.253203,"Missing"
J01-1005,C94-2119,0,0.0691719,"Missing"
J01-1005,W93-0106,0,0.0175454,"ther to reduce the influence of unreliable or uninformative contexts. The formula also has parameters (k, ~, fl), estimated by running systematic experiments. Standard statistical techniques have been used to balance experimental conditions and the sources of variance. 3. Using WordNet for Context Generalization One of the stated objectives of this paper is to investigate the effect of context generalization (the a d d e n d ESLB in the formula of the evidence) on our sense tagging task. The use of on-line thesauri for context generalization has already been investigated with limited success (Hearst and Schuetze 1993; Brill and Resnik 1994; Resnik 1997; Agirre and Rigau 1996). Though the idea of using thesauri for context expansion is quite common, there are no clear indications that this is actually useful in terms of performance. However, studying the effect of context expansion for a PN tagging task in particular is relevant because: PNs m a y be hypothesized to have a unique sense in a text, and even in a domain corpus. Therefore, we can reliably consider as potential sense indicators all the contexts in which a PN appears. The only source of ambiguity is then the w o r d wi co-occurring in a syntacti"
J01-1005,C92-2070,0,\N,Missing
J01-1005,C98-1045,1,\N,Missing
J04-2002,P99-1008,0,0.163946,"Missing"
J04-2002,P89-1010,0,0.242457,"he stand-alone procedure. 3.1 Phase 1: Terminology Extraction Terminology is the set of words or word strings that convey a single (possibly complex) meaning within a given community. In a sense, terminology is the surface appearance, in texts, of the domain knowledge of a community. Because of their low ambiguity and high specificity, these words are also particularly useful for conceptualizing a knowledge domain or for supporting the creation of a domain ontology. Candidate terminological expressions are usually captured with more or less shallow techniques, ranging from stochastic methods (Church and Hanks 1989; Yamamoto and Church 2001) to more sophisticated syntactic approaches (Jacquemin 1997). 154 Navigli and Velardi 1 Learning Domain Ontologies terminology extraction candidate extraction domain corpus terminology filtering Natural Language Processor contrastive corpora 2 semantic interpretation semantic disambiguation Inductive learner WordNet identification of taxonomic relations Lexical Resources identification of conceptual relations 3 ontology integration and updating Domain Concept Forest Figure 3 The architecture of OntoLearn. Obviously, richer syntactic information positively influences"
J04-2002,J02-3001,0,0.0226129,"rland and Charniak (1999) propose a method for extracting whole-part relations from corpora and enrich an ontology with this information. Few papers propose methods of extensively enriching an ontology with domain terms. For example, Vossen (2001) uses statistical methods and string inclusion to create lexicalized trees, as we do (see Figure 4). However, no semantic disambiguation of terms is performed. Very often, in fact, ontology-learning papers regard domain terms as concepts. A statistical classifier for automatic identification of semantic roles between co-occuring terms is presented in Gildea and Jurafsky (2002). In order to tag texts with the appropriate semantic role, Gildea and Jurafsky use a training set of fifty thousand sentences manually annotated within the FrameNet semantic labeling project. Finally, in Maedche and Staab (2000, 2001), an architecture is presented to help ontology engineers in the difficult task of creating an ontology. The main contribution of this work is in the area of ontology engineering, although machine-learning methods are also proposed to automatically enrich the ontology with semantic relations. 6. Conclusions and Ongoing Developments We believe that the OntoLearn s"
J04-2002,magnini-cavaglia-2000-integrating,0,0.0141039,"of word senses is automatically built using a variety of knowledge source: 1. WordNet. In WordNet, in addition to synsets, the following information is provided: (a) (b) (c) (d) a textual sense definition (gloss); hyperonymy links (i.e., kind-of relations: for example, bus#1 is a kind of public transport#1); meronymy relations (i.e., part-of relations: for example, bus#1 has part roof#2 and window#2); other syntactic-semantic relations, as detailed later, not systematically provided throughout the lexical knowledge base. 2. Domain labels6 extracted by a semiautomatic methodology described in Magnini and Cavaglia (2000) for assigning domain information (e.g., tourism, zoology, sport) to WordNet synsets. 3. Annotated corpora providing examples of word sense usages in contexts: 6 Domain labels have been kindly made available by the IRST to our institution for research purposes. 159 Computational Linguistics (a) Volume 30, Number 2 SemCor7 is a corpus in which each word in a sentence is assigned a sense selected from the WordNet sense inventory for that word. Examples of a SemCor document are the following: Color#1 was delayed#1 until 1935, the widescreen#1 until the early#1 fifties#1. Movement#7 itself was#7 t"
J04-2002,W01-1005,1,0.570092,"Missing"
J04-2002,J01-1001,0,0.0563672,"e. 3.1 Phase 1: Terminology Extraction Terminology is the set of words or word strings that convey a single (possibly complex) meaning within a given community. In a sense, terminology is the surface appearance, in texts, of the domain knowledge of a community. Because of their low ambiguity and high specificity, these words are also particularly useful for conceptualizing a knowledge domain or for supporting the creation of a domain ontology. Candidate terminological expressions are usually captured with more or less shallow techniques, ranging from stochastic methods (Church and Hanks 1989; Yamamoto and Church 2001) to more sophisticated syntactic approaches (Jacquemin 1997). 154 Navigli and Velardi 1 Learning Domain Ontologies terminology extraction candidate extraction domain corpus terminology filtering Natural Language Processor contrastive corpora 2 semantic interpretation semantic disambiguation Inductive learner WordNet identification of taxonomic relations Lexical Resources identification of conceptual relations 3 ontology integration and updating Domain Concept Forest Figure 3 The architecture of OntoLearn. Obviously, richer syntactic information positively influences the quality of the result t"
J04-2002,1993.mtsummit-1.10,0,0.0794304,"d in the task of identifying the key domain conceptualizations and describing them according to the organizational backbones established by the foundational ontology. The result of this effort is referred to as the core ontology (CO), which usually includes a few hundred application domain concepts. While many ontology projects eventually succeed in the task of defining a core ontology,1 populating the third level, which we call the specific domain ontology (SDO), is the actual barrier that very few projects have been able to overcome (e.g., WordNet [Fellbaum 1995], Cyc [Lenat 1993], and EDR [Yokoi 1993]), but they pay a price for this inability in terms of inconsistencies and limitations.2 It turns out that, although domain ontologies are recognized as crucial resources for the Semantic Web, in practice they are not available and when available, they are rarely used outside specific research environments. So which features are most needed to build usable ontologies? • Coverage: The domain concepts must be there; the SDO must be sufficiently (for the application purposes) populated. Tools are needed to extensively support the task of identifying the relevant concepts and the relations among"
J04-2002,alfonseca-manandhar-2002-improving,0,\N,Missing
J04-2002,J90-1003,0,\N,Missing
J04-2002,1995.mtsummit-1.17,0,\N,Missing
J13-3007,P99-1008,0,0.0221969,"(on WordNet and MeSH sub-hierarchies). Section 5 is dedicated to concluding remarks. 2. Related Work Two main approaches are used to learn an ontology from text: rule-based and distributional approaches. Rule-based approaches use predefined rules or heuristic patterns to extract terms and relations. These approaches are typically based on lexico-syntactic patterns, first introduced by Hearst (1992). Instances of relations are harvested from text by applying patterns aimed at capturing a certain type of relation (e.g., X is a kind of Y). Such lexico-syntactic patterns can be defined manually (Berland and Charniak 1999; Kozareva, Riloff, and Hovy 2008) or obtained by means of bootstrapping techniques (Girju, Badulescu, and Moldovan 2006; Pantel and Pennacchiotti 2006). In the latter case, a number of term pairs in the wanted relation are manually picked and the relation is sought within text corpora or the Web. Other rule-based approaches learn a taxonomy by applying heuristics to collaborative resources such as Wikipedia (Suchanek, Kasneci, and Weikum 2008; Ponzetto and Strube 2011), also with the supportive aid of computational lexicons such as WordNet (Ponzetto and Navigli 2009). Distributional approache"
J13-3007,P13-1052,1,0.804884,"Missing"
J13-3007,W06-2609,0,0.0920079,"Missing"
J13-3007,D12-1129,1,0.834207,"Missing"
J13-3007,N12-1051,0,0.317925,"Missing"
J13-3007,J06-1005,0,0.0107522,"Missing"
J13-3007,C92-2082,0,0.631997,"nomyinduction algorithm in Section 3. In Section 4 we present our experiments, and discuss the results. Evaluation is both qualitative (on new A RTIFICIAL I NTELLIGENCE and F INANCE taxonomies), and quantitative (on WordNet and MeSH sub-hierarchies). Section 5 is dedicated to concluding remarks. 2. Related Work Two main approaches are used to learn an ontology from text: rule-based and distributional approaches. Rule-based approaches use predefined rules or heuristic patterns to extract terms and relations. These approaches are typically based on lexico-syntactic patterns, first introduced by Hearst (1992). Instances of relations are harvested from text by applying patterns aimed at capturing a certain type of relation (e.g., X is a kind of Y). Such lexico-syntactic patterns can be defined manually (Berland and Charniak 1999; Kozareva, Riloff, and Hovy 2008) or obtained by means of bootstrapping techniques (Girju, Badulescu, and Moldovan 2006; Pantel and Pennacchiotti 2006). In the latter case, a number of term pairs in the wanted relation are manually picked and the relation is sought within text corpora or the Web. Other rule-based approaches learn a taxonomy by applying heuristics to collabo"
J13-3007,D10-1108,0,0.652252,"to existing ones in WordNet, with no evaluation of a full-fledged structured taxonomy and no restriction to a specific domain. A related, weakly supervised approach aimed at categorizing named entities, and attaching them to WordNet leaves, was proposed by Pasca (2004). Other approaches use formal concept analysis (Cimiano, Hotho, and Staab 2005), probabilistic and information-theoretic measures to learn taxonomies from a folksonomy (Tang et al. 2009), and Markov logic networks and syntactic parsing applied to domain text (Poon and Domingos 2010). The work closest to ours is that presented by Kozareva and Hovy (2010). From an initial given set of root concepts and basic level terms, the authors first use Hearst-like lexico-syntactic patterns iteratively to harvest new terms from the Web. As a result a set of hyponym–hypernym relations is obtained. Next, in order to induce taxonomic relations between intermediate concepts, the Web is searched again with surface patterns. Finally, nodes from the resulting graph are removed if the out-degree is below a threshold, and edges are pruned by removing cycles and selecting the longest path in the case of multiple paths between concept pairs. Kozareva and Hovy’s met"
J13-3007,P08-1119,0,0.0180555,"Missing"
J13-3007,J04-2002,1,0.809207,"Navigli 2009). A quite recent challenge, referred to as ontology learning, consists of automatically or semi-automatically creating a lexicalized ontology using textual data from corpora or the Web (Gomez-Perez and Manzano-Mancho 2003; Biemann 2005; Maedche and Staab 2009; Petasis et al. 2011). As a result of ontology learning, the heavy requirements of manual ontology construction can be drastically reduced. In this paper we deal with the problem of learning a taxonomy (i.e., the backbone of an ontology) entirely from scratch. Very few systems in the literature address this task. OntoLearn (Navigli and Velardi 2004) was one of the earliest contributions in this area. In OntoLearn taxonomy learning was accomplished in four steps: terminology extraction, derivation of term sub-trees via string inclusion, disambiguation of domain terms using a novel Word Sense Disambiguation algorithm, and combining the subtrees into a taxonomy. The use of a static, general-purpose repository of semantic knowledge, namely, WordNet (Miller et al. 1990; Fellbaum 1998), prevented the system from learning taxonomies in technical domains, however. In this paper we present OntoLearn Reloaded, a graph-based algorithm for learning"
J13-3007,W04-0844,1,0.79442,"Missing"
J13-3007,P10-1134,1,0.899033,"ed for the A RTIFICIAL I NTELLIGENCE and F INANCE domains. Seeing that we use high-level concepts, the set U can be considered domain-independent. Other choices are of course possible, especially if an upper ontology for a given domain is already available. For each term t ∈ T (i) (initially, i = 0), we first check whether t is an upper term (i.e., t ∈ U). If it is, we just skip it (because we do not aim at extending the taxonomy beyond an upper term). Otherwise, definition sentences are sought for t in the domain corpus and in a portion of the Web. To do so we use Word-Class Lattices (WCLs) (Navigli and Velardi 2010, introduced hereafter), which is a domain-independent machine-learned classifier that identifies definition sentences for the given term t, together with the corresponding hypernym (i.e., lexical generalization) in each sentence. For each term in our set T (i) , we then automatically extract definition candidates from the domain corpus, Web documents, and Web glossaries, by harvesting all the sentences that contain t. To obtain on-line glossaries we use a Web glossary extraction system (Velardi, Navigli, and D’Amadio 2008). Definitions can also be obtained via a lightweight bootstrapping proc"
J13-3007,J07-2002,0,0.0073904,"hiotti 2006). In the latter case, a number of term pairs in the wanted relation are manually picked and the relation is sought within text corpora or the Web. Other rule-based approaches learn a taxonomy by applying heuristics to collaborative resources such as Wikipedia (Suchanek, Kasneci, and Weikum 2008; Ponzetto and Strube 2011), also with the supportive aid of computational lexicons such as WordNet (Ponzetto and Navigli 2009). Distributional approaches, instead, model ontology learning as a clustering or classification task, and draw primarily on the notions of distributional similarity (Pado and Lapata 2007; Cohen and Widdows 2009), clustering of formalized statements (Poon and Domingos 2010), or hierarchical random graphs (Fountain and Lapata 2012). Such approaches are based on the assumption that paradigmatically-related concepts2 appear in similar contexts and their main advantage is that they are able to discover relations that do not explicitly appear in the text. They are typically less accurate, however, and the selection of feature types, notion of context, and similarity metrics vary considerably depending on the specific approach used. 1 http://lcl.uniroma1.it/ontolearn reloaded and ht"
J13-3007,P06-1015,0,0.0113948,"logy from text: rule-based and distributional approaches. Rule-based approaches use predefined rules or heuristic patterns to extract terms and relations. These approaches are typically based on lexico-syntactic patterns, first introduced by Hearst (1992). Instances of relations are harvested from text by applying patterns aimed at capturing a certain type of relation (e.g., X is a kind of Y). Such lexico-syntactic patterns can be defined manually (Berland and Charniak 1999; Kozareva, Riloff, and Hovy 2008) or obtained by means of bootstrapping techniques (Girju, Badulescu, and Moldovan 2006; Pantel and Pennacchiotti 2006). In the latter case, a number of term pairs in the wanted relation are manually picked and the relation is sought within text corpora or the Web. Other rule-based approaches learn a taxonomy by applying heuristics to collaborative resources such as Wikipedia (Suchanek, Kasneci, and Weikum 2008; Ponzetto and Strube 2011), also with the supportive aid of computational lexicons such as WordNet (Ponzetto and Navigli 2009). Distributional approaches, instead, model ontology learning as a clustering or classification task, and draw primarily on the notions of distributional similarity (Pado and Lap"
J13-3007,J11-2004,0,0.0241973,"Missing"
J13-3007,P10-1031,0,0.0211135,"manually picked and the relation is sought within text corpora or the Web. Other rule-based approaches learn a taxonomy by applying heuristics to collaborative resources such as Wikipedia (Suchanek, Kasneci, and Weikum 2008; Ponzetto and Strube 2011), also with the supportive aid of computational lexicons such as WordNet (Ponzetto and Navigli 2009). Distributional approaches, instead, model ontology learning as a clustering or classification task, and draw primarily on the notions of distributional similarity (Pado and Lapata 2007; Cohen and Widdows 2009), clustering of formalized statements (Poon and Domingos 2010), or hierarchical random graphs (Fountain and Lapata 2012). Such approaches are based on the assumption that paradigmatically-related concepts2 appear in similar contexts and their main advantage is that they are able to discover relations that do not explicitly appear in the text. They are typically less accurate, however, and the selection of feature types, notion of context, and similarity metrics vary considerably depending on the specific approach used. 1 http://lcl.uniroma1.it/ontolearn reloaded and http://ontolearn.org. 2 Because we are concerned with lexical taxonomies, in this paper w"
J13-3007,P06-1101,0,0.263873,"Missing"
J13-3007,storrer-wellinghoff-2006-automated,0,0.0367539,"In arts, a chiaroscuro]DF [is]VF [a monochrome picture]GF . [In mathematics, a graph]DF [is]VF [a data structure]GF [that consists of . . . ]R EST . [In computer science, a pixel]DF [is]VF [a dot]GF [that is part of a computer image]R EST . [Myrtales]DF [are an order of]VF [ flowering plants]GF [placed as a basal group . . . ]R EST . 3.2.1 Word-Class Lattices. We now describe our WCL algorithm for the classification of definitional sentences and hypernym extraction. Our model is based on a formal notion of textual definition. Specifically, we assume a definition contains the following fields (Storrer and Wellinghoff 2006): r r r r The D EFINIENDUM field (DF): this part of the definition includes the definiendum (that is, the word being defined) and its modifiers (e.g., “In computer science, a pixel”); The D EFINITOR field (VF): which includes the verb phrase used to introduce the definition (e.g., “is”); The D EFINIENS field (GF): which includes the genus phrase (usually including the hypernym, e.g., “a dot”); The R EST field (RF): which includes additional clauses that further specify the differentia of the definiendum with respect to its genus (e.g., “that is part of a computer image”). To train our definiti"
J13-3007,W09-4410,0,0.0225445,"es additional clauses that further specify the differentia of the definiendum with respect to its genus (e.g., “that is part of a computer image”). To train our definition extraction algorithm, a data set of textual definitions was manually annotated with these fields, as shown in Table 4.8 Furthermore, the singleor multi-word expression denoting the hypernym was also tagged. In Table 4, for each sentence the definiendum and its hypernym are marked in bold and italics, respectively. Unlike other work in the literature dealing with definition extraction (Hovy et al. 2003; Fahmi and Bouma 2006; Westerhout 2009; Zhang and Jiang 2009), we covered not only a variety of definition styles in our training set, in addition to the classic X is a Y pattern, but also a variety of domains. Therefore, our WCL algorithm requires no re-training when changing the application domain, as experimentally demonstrated by Navigli and Velardi (2010). Table 5 shows some non-trivial patterns for the VF field. 8 Available on-line at: http://lcl.uniroma1.it/wcl. 672 Velardi, Faralli, and Navigli OntoLearn Reloaded Table 5 Some nontrivial patterns for the VF field. is a term used to describe is the genus of is a term that re"
J13-3007,P09-1031,0,0.038379,"adigmatically-related concepts2 appear in similar contexts and their main advantage is that they are able to discover relations that do not explicitly appear in the text. They are typically less accurate, however, and the selection of feature types, notion of context, and similarity metrics vary considerably depending on the specific approach used. 1 http://lcl.uniroma1.it/ontolearn reloaded and http://ontolearn.org. 2 Because we are concerned with lexical taxonomies, in this paper we use the words concepts and terms interchangeably. 667 Computational Linguistics Volume 39, Number 3 Recently, Yang and Callan (2009) presented a semi-supervised taxonomy induction framework that integrates contextual, co-occurrence, and syntactic dependencies, lexico-syntactic patterns, and other features to learn an ontology metric, calculated in terms of the semantic distance for each pair of terms in a taxonomy. Terms are incrementally clustered on the basis of their ontology metric scores. In their work, the authors assume that the set of ontological concepts C is known, therefore taxonomy learning is limited to finding relations between given pairs in C. In the experiments, they only use the word senses within a parti"
J13-3007,S10-1013,0,\N,Missing
J91-2002,J87-3006,0,0.03149,"Missing"
J91-2002,J87-3007,0,0.0423305,"Missing"
J91-2002,J89-3002,0,0.0287897,"Missing"
J91-2002,E87-1006,0,0.0578258,"articipant person, organization theme transaction cause communication_exchange manner interesting important effective ... example 2 from (Niremburg 1987): person = isa creature agent_of take put find speech-action mental-action consist_of hand foot... source_of speech-action destination_of speech-action power human speed slow mass human Figure 2 Examples of collocative meaning representation in the literature 4.1 What Is Given The input to the system is: . a list of syntactic collocates, e.g. subject-verb, verb-object, noun-preposition-noun, noun-adjective, etc. extracted through morphologic (Russo 1987) and syntactic analysis of the selected corpus. The level at which syntactic analysis should be performed to derive collocates is a matter of debate. In Smadja (1989) it is suggested that parsing can be avoided by simply examining the neighborhood of a word w at a distance of +5. Our experience demonstrates that this algorithm produces too many collocations, of which a minority are actually semantically related. At the other extreme is full syntactic parsing, as performed in Velardi (1989). This is computationally too expensive for large corpora and fails to produce useful collocations when se"
J91-2002,C69-0201,0,0.165396,"of linguists,psychologists,and computer scientists. We believe that, just to take one example, a poor knowledgeof the results and methods of lexicography,linguistics,and cognitivesciencein part motivatesthe nonstrikingsuccess of NLP in developing large-scalesystems(Velardi 1990). 154 Velardi et al. Encoding Semantic Knowledge example 1 from (Leech 1981): boy = +animate - a d u l t +male example 2 from (Mel~uk 1987): help = Y carrying out Z, X uses his resources W in order for W to help Y to carry out Z; the use of resources by X and the carrying out of Z by Y are simultaneous example 3 from (Schank 1972): throw = actor PROPELs and object from a source LOCation to a destination LOCation Figure 1 Examples of conceptual meaning representation in the literature data. One of the largest hand-encoded semantic lexicons (Dahlgren 1989 and Dahlgren, communication to AAAI90 Stanford seminars) was built by asking subjects to freelist features common to objects. Despite the scientific interest of such experiments, they cannot be extensively repeated for the purpose of acquiring several thousand word sense definitions. On-line corpora and dictionaries are widely available today and provide experimental ev"
J91-2002,C90-2066,1,0.810139,"s..."" (Anderson 1989). Implementation, because consistency becomes a major problem when the size of the lexicon exceeds a few hundred entries. Psycholinguistic experiments, such as verbal protocols, are more appropriate, because they produce observable and measurable 1 This is not to say that there is a clear cut amongthe interests of linguists,psychologists,and computer scientists. We believe that, just to take one example, a poor knowledgeof the results and methods of lexicography,linguistics,and cognitivesciencein part motivatesthe nonstrikingsuccess of NLP in developing large-scalesystems(Velardi 1990). 154 Velardi et al. Encoding Semantic Knowledge example 1 from (Leech 1981): boy = +animate - a d u l t +male example 2 from (Mel~uk 1987): help = Y carrying out Z, X uses his resources W in order for W to help Y to carry out Z; the use of resources by X and the carrying out of Z by Y are simultaneous example 3 from (Schank 1972): throw = actor PROPELs and object from a source LOCation to a destination LOCation Figure 1 Examples of conceptual meaning representation in the literature data. One of the largest hand-encoded semantic lexicons (Dahlgren 1989 and Dahlgren, communication to AAAI90 St"
J91-2002,P89-1022,0,0.175709,"Missing"
J91-2002,P89-1023,1,\N,Missing
J91-2002,J87-3003,0,\N,Missing
J96-4006,W93-0107,1,0.829092,"Missing"
J96-4006,1995.tmi-1.8,0,0.0319317,"Missing"
L18-1444,Q15-1038,0,0.0181848,"gy that was first presented in (Faralli et al., 2015) and improved in (Faralli et al., 2017), summarized in what follows: 1. Selection of candidate senses: For any f in Ft , find a (possibly empty) list of candidate wikipages, using BabelNet synonym sets (in BabelNet, each ”BabelSynset” points to a unique Wikipedia entry (Navigli and Ponzetto, 2012)); 2. BoW Disambiguation: Compute the bag-of-words (BoW) similarity between the user description in f ’s Twitter account and each candidate wikipage. The BoW representation for each wikipage is obtained from its associated BabelNet relations (Delli Bovi et al., 2015); 3. Structural Similarity: If no wikipages can be found with a sufficient level of similarity (as for the previous example of Bill Gates), select from f ’s friendship list those friends already mapped to a wikipage (if any), and compute the similarity between those wikipages and candidate wikipages. 3.4. Anecdotic examples and evaluation We provide hereafter examples of the process outlined in previous Sections. For the sake of space, we consider only examples of interests extracted from users’ messages. 1. detection of ”interesting” tweets We collect all tweets containing the selected hashta"
navigli-etal-2010-annotated,degorski-etal-2008-definition,0,\N,Missing
navigli-etal-2010-annotated,P04-1030,0,\N,Missing
navigli-etal-2010-annotated,P99-1016,0,\N,Missing
navigli-etal-2010-annotated,W07-1706,0,\N,Missing
navigli-etal-2010-annotated,A92-1011,0,\N,Missing
navigli-etal-2010-annotated,P06-1101,0,\N,Missing
navigli-etal-2010-annotated,P09-1031,0,\N,Missing
navigli-etal-2010-annotated,P08-1115,0,\N,Missing
navigli-etal-2010-annotated,P10-1134,1,\N,Missing
navigli-etal-2010-annotated,N09-1046,0,\N,Missing
navigli-etal-2010-annotated,E09-1082,0,\N,Missing
navigli-etal-2010-annotated,storrer-wellinghoff-2006-automated,0,\N,Missing
navigli-velardi-2002-automatic,W01-1005,1,\N,Missing
P10-1134,W09-4405,0,0.331994,"Missing"
P10-1134,P99-1016,0,0.0192162,"true definitions, but rather text fragments providing some relevant fact about a target term. For example, sentences like: “Bollywood is a Bombay-based film industry” and “700 or more films produced by India with 200 or more from Bollywood” are both “vital” answers for the question “Bollywood”, according to TREC classification, but the second sentence is not a definition. Hypernym Extraction. The literature on hypernym extraction offers a higher variability of methods, from simple lexical patterns (Hearst, 1992; Oakes, 2005) to statistical and machine learning techniques (Agirre et al., 2000; Caraballo, 1999; Dolan et al., 1993; Sanfilippo and Pozna´nski, 1992; Ritter et al., 2009). One of the highest-coverage methods is proposed by Snow et al. (2004). They first search sentences that contain two terms which are known to be in a taxonomic relation (term pairs are taken from WordNet (Miller et al., 1990)); then they parse the sentences, and automatically extract patterns from the parse trees. Finally, they train a hypernym classifer based on these features. Lexico-syntactic patterns are generated for each sentence relating a term to its hypernym, and a dependency parser is used to represent them."
P10-1134,P04-1030,0,0.0495768,"eliminating redundant information. In computational linguistics, lattices have been used to model in a compact way many sequences of symbols, each representing an alternative hypothesis. Lattice-based methods differ in the types of nodes (words, phonemes, concepts), the interpretation of links (representing either a sequential or hierarchical ordering between nodes), their means of creation, and the scoring method used to extract the best consensus output from the lattice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summari"
P10-1134,degorski-etal-2008-definition,0,0.295924,"Missing"
P10-1134,P08-1115,0,0.00917987,"tice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summarization, the use of word lattices has been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symbols like in word/phoneme lattices, and nodes are clusters of salient words aggregated using synonymy, similarity, or subtrees of"
P10-1134,N09-1046,0,0.010217,"ation, and the scoring method used to extract the best consensus output from the lattice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summarization, the use of word lattices has been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symbols like in word/phoneme lattices, and"
P10-1134,W06-2609,0,0.295431,"Missing"
P10-1134,C92-2082,0,0.725169,"s: http://trec.nist. gov 1319 ble2 . In fact, the TREC evaluation datasets cannot be considered true definitions, but rather text fragments providing some relevant fact about a target term. For example, sentences like: “Bollywood is a Bombay-based film industry” and “700 or more films produced by India with 200 or more from Bollywood” are both “vital” answers for the question “Bollywood”, according to TREC classification, but the second sentence is not a definition. Hypernym Extraction. The literature on hypernym extraction offers a higher variability of methods, from simple lexical patterns (Hearst, 1992; Oakes, 2005) to statistical and machine learning techniques (Agirre et al., 2000; Caraballo, 1999; Dolan et al., 1993; Sanfilippo and Pozna´nski, 1992; Ritter et al., 2009). One of the highest-coverage methods is proposed by Snow et al. (2004). They first search sentences that contain two terms which are known to be in a taxonomic relation (term pairs are taken from WordNet (Miller et al., 1990)); then they parse the sentences, and automatically extract patterns from the parse trees. Finally, they train a hypernym classifer based on these features. Lexico-syntactic patterns are generated for"
P10-1134,C08-1049,0,0.0168628,"al ordering between nodes), their means of creation, and the scoring method used to extract the best consensus output from the lattice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder et al., 2009). In more complex text processing tasks, such as information retrieval, information extraction and summarization, the use of word lattices has been postulated but is considered unrealistic because of the dimension of the hypothesis space. To reduce this problem, concept lattices have been proposed (Carpineto and Romano, 2005; Klein, 2008; Zhong et al., 2008). Here links represent hierarchical relations, rather than the sequential order of symb"
P10-1134,navigli-etal-2010-annotated,1,0.848242,"Missing"
P10-1134,E09-1068,1,0.907741,"efinitional, that is they provide a formal explanation for the term of interest. While it is not feasible to manually search texts for definitions, this task can be automatized by means of Machine Learning (ML) and Natural Language Processing (NLP) techniques. Automatic definition extraction is useful not only in the construction of glossaries, but also in many other NLP tasks. In ontology learning, definitions are used to create and enrich concepts with textual information (Gangemi et al., 2003), and extract taxonomic and non-taxonomic relations (Snow et al., 2004; Navigli and Velardi, 2006; Navigli, 2009a). Definitions are also harvested in Question Answering to deal with “what is” questions (Cui et al., 2007; Saggion, 2004). In eLearning, they are used to help students assimilate knowledge (Westerhout and Monachesi, 2007), etc. Much of the current literature focuses on the use of lexico-syntactic patterns, inspired by Hearst’s (1992) seminal work. However, these methods suffer both from low recall and precision, as definitional sentences occur in highly variable syntactic structures, and because the most frequent definitional pattern – X is a Y – is inherently very noisy. In this paper we pr"
P10-1134,saggion-2004-identifying,0,0.153579,"ch texts for definitions, this task can be automatized by means of Machine Learning (ML) and Natural Language Processing (NLP) techniques. Automatic definition extraction is useful not only in the construction of glossaries, but also in many other NLP tasks. In ontology learning, definitions are used to create and enrich concepts with textual information (Gangemi et al., 2003), and extract taxonomic and non-taxonomic relations (Snow et al., 2004; Navigli and Velardi, 2006; Navigli, 2009a). Definitions are also harvested in Question Answering to deal with “what is” questions (Cui et al., 2007; Saggion, 2004). In eLearning, they are used to help students assimilate knowledge (Westerhout and Monachesi, 2007), etc. Much of the current literature focuses on the use of lexico-syntactic patterns, inspired by Hearst’s (1992) seminal work. However, these methods suffer both from low recall and precision, as definitional sentences occur in highly variable syntactic structures, and because the most frequent definitional pattern – X is a Y – is inherently very noisy. In this paper we propose a generalized form of word lattices, called Word-Class Lattices (WCLs), as an alternative to lexico-syntactic pattern"
P10-1134,A92-1011,0,0.0897244,"Missing"
P10-1134,E09-1082,0,0.0308979,"tomata (NFA). The lattice structure has the purpose of preserving the salient differences among distinct sequences, while eliminating redundant information. In computational linguistics, lattices have been used to model in a compact way many sequences of symbols, each representing an alternative hypothesis. Lattice-based methods differ in the types of nodes (words, phonemes, concepts), the interpretation of links (representing either a sequential or hierarchical ordering between nodes), their means of creation, and the scoring method used to extract the best consensus output from the lattice (Schroeder et al., 2009). In speech processing, phoneme or word lattices (Campbell et al., 2007; Mathias and Byrne, 2006; Collins et al., 2004) are used as an interface between speech recognition and understanding. Lat1318 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics tices are adopted also in Chinese word segmentation (Jiang et al., 2008), decompounding in German (Dyer, 2009), and to represent classes of translation models in machine translation (Dyer et al., 2008; Schroeder"
P10-1134,storrer-wellinghoff-2006-automated,0,0.390114,"in order to demonstrate the independence of the method from the annotated dataset. WCLs are shown to generalize over lexico-syntactic patterns, and outperform well-known approaches to definition and hypernym extraction. The paper is organized as follows: Section 2 discusses related work, WCLs are introduced in Section 3 and illustrated by means of an example in Section 4, experiments are presented in Section 5. We conclude the paper in Section 6. 2 Related Work Definition Extraction. A great deal of work is concerned with definition extraction in several languages (Klavans and Muresan, 2001; Storrer and Wellinghoff, 2006; Gaudio and Branco, 2007; Iftene et al., 2007; Westerhout and Monachesi, 2007; Przepi´orkowski et al., 2007; Deg´orski et al., 2008). The majority of these approaches use symbolic methods that depend on lexico-syntactic patterns or features, which are manually crafted or semi-automatically learned (Zhang and Jiang, 2009; Hovy et al., 2003; Fahmi and Bouma, 2006; Westerhout, 2009). Patterns are either very simple sequences of words (e.g. “refers to”, “is defined as”, “is a”) or more complex sequences of words, parts of speech and chunks. A fully automated method is instead proposed by Borg et"
P10-1134,W09-4410,0,0.536955,"Missing"
P10-1134,W07-1706,0,\N,Missing
P89-1023,E87-1006,0,0.194993,"Missing"
P89-1023,J87-3002,0,0.0512156,"Missing"
P89-1023,J87-3006,0,\N,Missing
P89-1023,J87-3007,0,\N,Missing
P89-1023,E87-1040,1,\N,Missing
P89-1023,C86-1051,0,\N,Missing
P89-1023,T75-2001,0,\N,Missing
P98-1045,C94-1074,0,0.158364,"c e external evidence, using a corpus-driven algorithm to incrementally update the gazetteer and classification of unknown PNs in running texts. For each esli in E S L let: es li(wj, m od(typei, Wk)) =esli(x, PN U) where x=wj or Wk and PN_U =Wk or wj, typei is the syntactic type of esl (e.g. N-diN, N_N, V-per-N ecc), and further let: The algorithm to classify unknown proper n o u n s uses the f o l l o w i n g linguistic resources: a (raw text) learning corpus in the same domain as the application, a shallow corpus parser, a ""seed"" gazetteer, and a dictionary of synonyms. The shallow parser (Basili et al. 1994), e x t r a c t s f r o m the l e a r n i n g c o r p u s elementary syntactic relations such as subject-object, noun-preposition-noun, etc. A s y n t a c t i c link (hereafter esl) is represented as: pl(esli (x, PN_U) be the plausibility of a detected esl. The plausibility is a measure of the statistical evidence of a detected syntactic link (Basili et al, 1994b), that depends upon local (i.e. at the sentence level) syntactic ambiguity and global corpus evidence. Finally, let: E S L A be a set of esls defined as follows: for each esli(x,PN_U) in E S L put in E S L A the set of e s l j ( x , P"
P98-1045,A97-1029,0,0.0860159,"Missing"
P98-1045,A97-1028,0,0.0789363,"Missing"
P98-1045,M91-1028,0,\N,Missing
P98-1045,A97-1030,0,\N,Missing
P98-1045,J95-4004,0,\N,Missing
P98-1045,H92-1045,0,\N,Missing
P98-1045,M95-1006,0,\N,Missing
P98-1045,M95-1011,0,\N,Missing
R13-1084,N13-1097,0,0.0628781,"Missing"
R13-1084,W10-1105,0,0.0681689,"Missing"
R13-1084,C92-2082,0,\N,Missing
R13-1084,W07-1007,0,\N,Missing
velardi-etal-2012-new,C92-2082,0,\N,Missing
velardi-etal-2012-new,P09-1031,0,\N,Missing
velardi-etal-2012-new,P10-1134,1,\N,Missing
velardi-etal-2012-new,D10-1108,0,\N,Missing
velardi-etal-2012-new,J13-3007,1,\N,Missing
W00-0105,J99-2002,0,\N,Missing
W00-0105,J98-1001,0,\N,Missing
W00-0105,P98-1045,1,\N,Missing
W00-0105,C98-1045,1,\N,Missing
W01-1005,J96-1001,0,\N,Missing
W01-1005,J96-3009,0,\N,Missing
W01-1005,W97-0314,1,\N,Missing
W04-0844,magnini-cavaglia-2000-integrating,0,0.0130992,"sociation for Computational Linguistics Structural Semantic Interconnection: a knowledge-based approach to Word Sense Disambiguation export#1 ss food#1 goods#1 clothing#1 kin ss d -o f glo consumer consumption#1 goods#1 to p ic ss k in d glo -of market#1 g lo ss gloss merchandise #1 d-o s f s glo f business activity#1 industry#2 gloss d -o service#1 k in monopoly#1 kind-o f production#1 g ha s lo ss -k i nd k in d -o f LDC http://www.ldc.upenn.edu/ nd 1 enterprise#1 g lo -k i We build a structural representation of word senses using a variety of knowledge sources, i.e. WordNet, Domain Labels (Magnini and Cavaglia, 2000), annotated corpora like SemCor and LDCDSO1. We use this information to automatically commerce#1 activity#1 rt -p a ha s express#1 has-part f kind-o commercial enterprise#2 transportation#5 kind-of artifact#1 trading#1 h as Building structural representations of word senses f -o f 2 kind-o k in d Our approach to WSD lies in the structural pattern recognition framework. Structural or syntactic pattern recognition (Bunke and Sanfeliu, 1990) has proven to be effective when the objects to be classified contain an inherent, identifiable organization, such as image data and time-series data. For the"
W06-0501,W02-1028,0,0.0418531,"Missing"
W06-0501,J04-2002,1,\N,Missing
W17-4204,P10-1023,0,0.0285232,"ta-clusters, the set of novel entities Rinovel is: [flag of scotland, william wallace, countries of the united kingdom, mary queen of scots, tony blair, braveheart] and all the others are also found in news. Step 5. Classification of information and communication needs: In addition to recommendations, we automatically assign a category both to event clusters mN i in news, and to related entities in Twitter and Wikipedia aligned metaclusters mTi and mW i , in order to detect recurrent discussion topics and search patterns in relation to specific event types. To do so, we exploit both BabelNet (Navigli and Ponzetto, 2010), # clusters News Twitter Wikipedia 9396 4737 5450 # m.clusters 829 413 535 av. size m.clusters 122.46 136.76 6.44 Table 2: Statistics on data and results a large-scale multilingual semantic network2 , and the Wikipedia Category graph. 3 Discussion To conduct our study, we created three datasets: Wikipedia PageViews (W), On-line News (N) and Twitter messages (T). Data was collected during 4 months from June 1st, 2014 to September 30th. Table 2 shows some statistics. Note that Wikipedia clusters are smaller, since cluster members are only named entities (page views). We defined the following ev"
W93-0107,P90-1034,0,0.032756,"nature of the event they describe, that is better expressed by the roles played by its arguments in a sentence. Psycholinguistie studies on verb semantics outline the relevance of thematic roles, especially in eategorisation activities Keil, (1989), Jackendoff (1983) and indicate the argument structure of verbs as playing a central role in language acquisition Pinker (1989). In NLP, representing verb semantics with their thematic roles is a consolidated practice, even though theoretical researches (Pustejovski (1991)) propose more rich and formal representation frameworks. More recent papers Hindle (1990), Pereira and Tishby (1992) proposed to cluster nouns on the basis of a metric derived from the distribution of subject, verb and object in the texts. Both papers use as a source of information large corpora, but differ in the type of statistical approach used to determine word similarity. These studies, though valuable, leave several open problems: 1) 2) 3) 4) A metric of conceptual closeness based on mere syntactic similarity is questionable, particularly if applied to verbs. In fact, the argument structure of verbs is variegated and poorly overlapping. Furthermore, subject and object relati"
W93-0107,J91-4003,0,0.0247141,"Missing"
W94-0102,P88-1013,0,0.0206968,"ried over to a Multi-parser. Instead of a CLAWS-style Markovian tagger, for each target parsing scheme a grammar and parser can be extracted directly from the corresponding training Treebank. A Context-Free Grammar can be elicited directly by extracting each non-terminal and its immediate-daughterscqu~&apos;nce, to become the left-hand-side and right-handside respectively of a context-free grammar rule [6]; frequencies of constituents in the training treebank can be used to make this a Probabilistic Context Free Grammar [49], useable in a treebank-trained probabilistic parser such as those in [2], [29], [9], [50]. Rather than producing a single, fully correct parse-tree for each input sentence, these probabilistic Treebank-trained p~rser generally output an ordered list of possible parsetrees, with a probability or weight attached to each. As with the procedure for developing a partial tagmapping, we need only devise source-to-target parsetree-constituent mappings in cases where the targetparser&apos;s &apos;best&apos; parsetree is not fully correct. A s s e s s m e n t o f t h e M u l t i - T r e e b a n k as a Benchmark for Grammars &apos;this requires analysis of the substantive differences beetw,&apos;en differ"
W98-0711,H92-1001,0,0.0228412,"Missing"
W98-0711,W95-0105,0,0.0354099,"Missing"
W98-0711,C96-1005,0,0.0554083,"Missing"
W98-0711,C96-1038,0,0.0622062,"Missing"
W98-0711,A97-1055,1,0.877498,"Missing"
W98-0711,C94-2113,0,0.0754246,"Missing"
W98-0711,W97-0206,0,0.039865,"Missing"
W98-0711,W93-0106,0,0.0490201,"Missing"
W98-0711,C92-2070,0,0.145979,"Missing"
W98-0711,W99-0624,0,0.0752319,"Missing"
W98-0711,H92-1045,0,0.0690167,"Missing"
