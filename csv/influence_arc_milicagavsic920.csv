C16-1025,J81-4005,0,0.682625,"Missing"
C16-1025,W14-4340,1,0.913591,"et al., 2011; Deoras and Sarikaya, 2013; Sarikaya et al., 2014). Spoken language understanding from unaligned data, in which utterances are annotated with an abstract semantics, faces the additional challenge of not knowing which specific words are relevant for extracting the semantics. This problem was tackled in (Zhou and He, 2011), by using conditional random fields (CRFs) driven by finely-tuned hand-crafted features. Other discriminative approaches that deal with unaligned data use some form of delexicalisation or mapping of the input to known ontological concepts (Henderson et al., 2012; Henderson et al., 2014a). The main disadvantage of delexicalisation is the difficulty in scaling it, not only to larger and more complex dialogue domains but also to handle the many forms of language variation. We propose in this paper a semantic decoder that learns from unaligned data (Figure 1) and that exploits rich semantic distributed word representations instead of delexicalisation. The semantic decoder predicts the dialogue act and the set of slot-value pairs from a set of n-best hypotheses returned by an automatic speech recognition (ASR). The prediction is made in two steps. First, a deep learning architec"
C16-1025,W14-4337,0,0.278647,"et al., 2011; Deoras and Sarikaya, 2013; Sarikaya et al., 2014). Spoken language understanding from unaligned data, in which utterances are annotated with an abstract semantics, faces the additional challenge of not knowing which specific words are relevant for extracting the semantics. This problem was tackled in (Zhou and He, 2011), by using conditional random fields (CRFs) driven by finely-tuned hand-crafted features. Other discriminative approaches that deal with unaligned data use some form of delexicalisation or mapping of the input to known ontological concepts (Henderson et al., 2012; Henderson et al., 2014a). The main disadvantage of delexicalisation is the difficulty in scaling it, not only to larger and more complex dialogue domains but also to handle the many forms of language variation. We propose in this paper a semantic decoder that learns from unaligned data (Figure 1) and that exploits rich semantic distributed word representations instead of delexicalisation. The semantic decoder predicts the dialogue act and the set of slot-value pairs from a set of n-best hypotheses returned by an automatic speech recognition (ASR). The prediction is made in two steps. First, a deep learning architec"
C16-1025,P14-1062,0,0.0187706,"rder to perform joint intent detection and slot filling. All these models use word-level semantic annotations. However, providing these word-level semantic annotations is costly since it requires specialised annotators. (Zhou and He, 2011) has proposed learning CRFs from unaligned data, however they use manually tuned lexical or syntactic features. In this work we avoid the need for word-level annotation by exploiting distributed word embeddings and using deep learning for feature representation. Convolutional Neural Networks (CNNs) have been used previously for sentiment analysis (Kim, 2014; Kalchbrenner et al., 2014) and in this work we explore a similar CNN to the one presented by Kim (2014) for generating a sentence representation. However unlike Kim (2014), the input in not a single well formed sentence but a set of ill-formed ASR hypotheses. Additionally, the softmax layer used for binary classification (i.e., positive or negative sentiment) is replaced by a softmax layer for multiclass dialogue act prediction and a further softmax layer is added for each distinct slot in the domain. (Chen and He, 2015) proposed a CNN for generating intent embeddings in SLU, which uses tri-letter input vectors. Instea"
C16-1025,D14-1181,0,0.0306459,"ar CRF in order to perform joint intent detection and slot filling. All these models use word-level semantic annotations. However, providing these word-level semantic annotations is costly since it requires specialised annotators. (Zhou and He, 2011) has proposed learning CRFs from unaligned data, however they use manually tuned lexical or syntactic features. In this work we avoid the need for word-level annotation by exploiting distributed word embeddings and using deep learning for feature representation. Convolutional Neural Networks (CNNs) have been used previously for sentiment analysis (Kim, 2014; Kalchbrenner et al., 2014) and in this work we explore a similar CNN to the one presented by Kim (2014) for generating a sentence representation. However unlike Kim (2014), the input in not a single well formed sentence but a set of ill-formed ASR hypotheses. Additionally, the softmax layer used for binary classification (i.e., positive or negative sentiment) is replaced by a softmax layer for multiclass dialogue act prediction and a further softmax layer is added for each distinct slot in the domain. (Chen and He, 2015) proposed a CNN for generating intent embeddings in SLU, which uses tri-"
C16-1025,P15-2130,1,0.879225,"Missing"
C16-1025,D14-1162,0,0.0801578,"2014) for generating a sentence representation. However unlike Kim (2014), the input in not a single well formed sentence but a set of ill-formed ASR hypotheses. Additionally, the softmax layer used for binary classification (i.e., positive or negative sentiment) is replaced by a softmax layer for multiclass dialogue act prediction and a further softmax layer is added for each distinct slot in the domain. (Chen and He, 2015) proposed a CNN for generating intent embeddings in SLU, which uses tri-letter input vectors. Instead, in this paper the models are initialised with GloVe word embeddings (Pennington et al., 2014). These GloVe embeddings were trained in an unsupervised fashion on a large amount of data to model the contextual similarity and correlation between words. Chen and He’s model aims to learn the embeddings for utterances and intents such that utterances with similar intents are close to each other in the continuous space. Although we share the same spirit, we use sentence embeddings not only for intent creativecommons.org/licenses/by/4.0/ 259 (or dialogue act) recognition but also for slot-filling within a dialogue system and we combine them with embeddings for dialogue context. Approaches for"
C16-1025,W14-4339,0,0.187447,"Missing"
D15-1199,D10-1049,0,0.00888891,"00). Ratnaparkhi (2002) later addressed some of the limitations of class-based LMs in the over-generation phase by using a modified generator based on a syntactic dependency tree. Mairesse and Young (2014) proposed a phrase-based NLG system based on factored LMs that can learn from a semantically aligned corpus. Although active learning (Mairesse et al., 2010) was also proposed to allow learning online directly from users, the requirement for human annotated alignments limits the scalability of the system. Another similar approach casts NLG as a template extraction and matching problem, e.g., Angeli et al. (2010) train a set of log-linear models to make a series of generation decisions to choose the most suitable template for realisation. Kondadadi et al. (2013) later show that the outputs can be further improved by an SVM reranker making them comparable to human-authored texts. However, template matching approaches do not generalise well to unseen combinations of semantic elements. The use of neural network-based (NN) approaches to NLG is relatively unexplored. The stock reporter system ANA by Kukich (1987) is perhaps the first NN-based generator, although generation was only done at the phrase level"
D15-1199,P13-1138,0,0.0106159,"n a syntactic dependency tree. Mairesse and Young (2014) proposed a phrase-based NLG system based on factored LMs that can learn from a semantically aligned corpus. Although active learning (Mairesse et al., 2010) was also proposed to allow learning online directly from users, the requirement for human annotated alignments limits the scalability of the system. Another similar approach casts NLG as a template extraction and matching problem, e.g., Angeli et al. (2010) train a set of log-linear models to make a series of generation decisions to choose the most suitable template for realisation. Kondadadi et al. (2013) later show that the outputs can be further improved by an SVM reranker making them comparable to human-authored texts. However, template matching approaches do not generalise well to unseen combinations of semantic elements. The use of neural network-based (NN) approaches to NLG is relatively unexplored. The stock reporter system ANA by Kukich (1987) is perhaps the first NN-based generator, although generation was only done at the phrase level. Recent advances in recurrent neural network-based language models (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) have demonstrated the value of"
D15-1199,P98-1116,0,0.0372841,"mmon and widely adopted today is the rule-based (or template-based) approach (Cheyer and Guzzoni, 2007; Mirkovic and Cavedon, 2011). Despite its robustness and adequacy, the frequent repetition of identical, rather stilted, output forms make talking to a rule-based generator rather tedious. Furthermore, the approach does not easily scale to large open domain systems(Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 2014). Hence approaches to NLG are required that can be readily scaled whilst meeting the above requirements. The trainable generator approach exemplified by the HALOGEN (Langkilde and Knight, 1998) and SPaRKy system (Stent et al., 2004) provides a possible way forward. These systems include specific trainable modules within the generation framework to allow the model to adapt to different domains (Walker et al., 2007), or reproduce certain style (Mairesse and Walker, 2011). However, these approaches still require a handcrafted generator to define the decision space within which statistics can be used for optimisation. The resulting utterances are therefore constrained by the predefined syntax and any domain-specific colloquial responses must be added manually. More recently, corpus-base"
D15-1199,J11-3002,0,0.00986564,"r tedious. Furthermore, the approach does not easily scale to large open domain systems(Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 2014). Hence approaches to NLG are required that can be readily scaled whilst meeting the above requirements. The trainable generator approach exemplified by the HALOGEN (Langkilde and Knight, 1998) and SPaRKy system (Stent et al., 2004) provides a possible way forward. These systems include specific trainable modules within the generation framework to allow the model to adapt to different domains (Walker et al., 2007), or reproduce certain style (Mairesse and Walker, 2011). However, these approaches still require a handcrafted generator to define the decision space within which statistics can be used for optimisation. The resulting utterances are therefore constrained by the predefined syntax and any domain-specific colloquial responses must be added manually. More recently, corpus-based methods (Oh and Rudnicky, 2000; Mairesse and Young, 2014; Wen et al., 2015) have received attention as access to data becomes increasingly available. By defining a flexible learning structure, corpus-based methods aim to learn generation directly from data by adopting an over-g"
D15-1199,J14-4003,1,0.768759,"2004) provides a possible way forward. These systems include specific trainable modules within the generation framework to allow the model to adapt to different domains (Walker et al., 2007), or reproduce certain style (Mairesse and Walker, 2011). However, these approaches still require a handcrafted generator to define the decision space within which statistics can be used for optimisation. The resulting utterances are therefore constrained by the predefined syntax and any domain-specific colloquial responses must be added manually. More recently, corpus-based methods (Oh and Rudnicky, 2000; Mairesse and Young, 2014; Wen et al., 2015) have received attention as access to data becomes increasingly available. By defining a flexible learning structure, corpus-based methods aim to learn generation directly from data by adopting an over-generation and reranking paradigm (Oh and Rudnicky, 2000), in which final responses are obtained by reranking a set of candidates generated from a stochastic generator. Learning from data directly enables the system to mimic human responses more naturally, removes the dependency on predefined rules, and makes the system easier to build and extend to other domains. As detailed"
D15-1199,P10-1157,1,0.933767,"Missing"
D15-1199,W00-0306,0,0.402023,"Missing"
D15-1199,P02-1040,0,0.123792,"ning each of the collected corpus into a training, validation, and testing set in the ratio 3:1:1. The frequency of each action type and slot-value pair differs quite markedly across the corpus, hence up-sampling was used to make the corpus more uniform. Since our generator works stochastically and the trained networks can differ depending on the initialisation, all the results shown below3 were averaged over 5 randomly initialised networks. For each DA, we overgenerated 20 utterances and selected the top 5 realisations after reranking. The BLEU-4 metric was used for the objective evaluation (Papineni et al., 2002). Multiple references for each test DA were obtained by mapping them back to the distinct set of DAs, grouping those delexicalised surface forms that have the same DA specification, and then lexicalising those surface forms back to utterances. In addition, the slot error rate (ERR) as described in Section 3.5 was computed as an auxiliary metric alongside the BLEU score. However, for the experiments it is computed at the corpus level, by averaging slot errors over each of the top 5 realisations in the entire corpus. The trade-off weights α between keyword and key phrase detectors as mentioned i"
D15-1199,D14-1162,0,0.117677,"Missing"
D15-1199,W09-3941,0,0.020353,"planning maps input semantic symbols into an intermediary form representing the utterance, e.g. a tree-like or template structure, then surface realisation converts the intermediate structure into the final text (Walker et al., 2002; Stent et al., 2004). Although statistical sentence planning has been explored previously, for example, generating the most likely context-free derivations given a corpus (Belz, 2008) or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2010), these methods still rely on a pre-existing, handcrafted generator. To minimise handcrafting, Stent and Molina (2009) proposed learning sentence planning rules directly from a corpus of utterances labelled with Rhetorical Structure Theory (RST) discourse relations (Mann and Thompson, 1988). However, the required corpus labelling is expensive and additional handcrafting is still needed to map the sentence plan to a valid syntactic form. As noted above, corpus-based NLG aims at learning generation decisions from data with minimal dependence on rules and heuristics. A pioneer in this direction is the class-based n-gram language model (LM) approach proposed by Oh and Rudnicky (2000). Ratnaparkhi (2002) later add"
D15-1199,D14-1074,0,0.0628496,"level. Recent advances in recurrent neural network-based language models (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) have demonstrated the value of distributed representations and the ability to model arbitrarily long dependencies. Sutskever et al. (2011) describes a simple variant of the RNN that can generate meaningful sentences by learning from a character-level corpus. More recently, Karpathy and Fei-Fei (2014) have demonstrated that an RNNLM is capable of generating image descriptions by conditioning the network model on a pre-trained convolutional image feature representation. Zhang and Lapata (2014) also describes interesting work using RNNs to generate 1712 Chinese poetry. A forerunner of the system presented here is described in Wen et al. (2015), in which a forward RNN generator, a CNN reranker, and a backward RNN reranker are trained jointly to generate utterances. Although the system was easy to train and extend to other domains, a heuristic gate control was needed to ensure that all of the attribute-value information in the system’s response was accurately captured by the generated utterance. Furthermore, the handling of unusual slot-value pairs by the CNN reranker was rather arbit"
D15-1199,P04-1011,0,0.63393,"(or template-based) approach (Cheyer and Guzzoni, 2007; Mirkovic and Cavedon, 2011). Despite its robustness and adequacy, the frequent repetition of identical, rather stilted, output forms make talking to a rule-based generator rather tedious. Furthermore, the approach does not easily scale to large open domain systems(Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 2014). Hence approaches to NLG are required that can be readily scaled whilst meeting the above requirements. The trainable generator approach exemplified by the HALOGEN (Langkilde and Knight, 1998) and SPaRKy system (Stent et al., 2004) provides a possible way forward. These systems include specific trainable modules within the generation framework to allow the model to adapt to different domains (Walker et al., 2007), or reproduce certain style (Mairesse and Walker, 2011). However, these approaches still require a handcrafted generator to define the decision space within which statistics can be used for optimisation. The resulting utterances are therefore constrained by the predefined syntax and any domain-specific colloquial responses must be added manually. More recently, corpus-based methods (Oh and Rudnicky, 2000; Maire"
D15-1199,D14-1003,0,0.0241886,"remaining problem in the structure described so far is that the LSTM generator selects words based only on the preceding history, whereas some sentence forms depend on the backward context. Previously, bidirectional networks (Schuster and 1714 Figure 2: The Deep LSTM generator structure by stacking multiple LSTM layers on top of the DA cell. The skip connection was adopted to mitigate the vanishing gradient, while the dropout was applied on dashed connections to prevent co-adaptation and overfitting. Paliwal, 1997) have been shown to be effective for sequential problems (Graves et al., 2013a; Sundermeyer et al., 2014). However, applying a bidirectional network directly in the SC-LSTM generator is not straightforward since the generation process is sequential in time. Hence instead of integrating the bidirectional information into one network, we trained another SC-LSTM from backward context to choose best candidates from the forward generator outputs. In our experiments, we also found that by tying the keyword detector weights Wwr (see Equations 7 and 12) of both the forward and backward networks together makes the generator less sensitive to random initialisation. 3.4 Training The forward generator and th"
D15-1199,W15-4639,1,0.451846,"Missing"
D15-1199,E09-1078,0,\N,Missing
D15-1199,C98-1112,0,\N,Missing
D16-1233,D14-1179,0,0.0476362,"Missing"
D16-1233,W14-4340,1,0.927408,"ns and alleviates the vanishing gradient problem; (3) it appears to learn transparent and interpretable subspaces of the conditioning vector. 2 Related Work Machine learning approaches to task-oriented dialogue system design have cast the problem as a partially observable Markov Decision Process (POMDP) (Young et al., 2013) with the aim of using reinforcement learning (RL) to train dialogue policies online through interactions with real users (Gaˇsi´c et al., 2013). In order to make RL tractable, the state and action space must be carefully designed (Young et al., 2010) and the understanding (Henderson et al., 2014; Mrkˇsi´c et al., 2015) and generation (Wen et al., 2015b; Wen et al., 2016b) modules were assumed available or trained standalone on supervised corpora. Due to the underlying hand-coded semantic representation (Traum, 1999), the conversation is far from natural and the comprehension capability is limited. This motivates the use of neural networks to model dialogues from end to end as a conditional generation problem. Interest in generating natural language using NNs can be attributed to the success of RNN LMs for large vocabulary speech recognition (Mikolov et al., 2010; Mikolov et al., 2011"
D16-1233,P11-1055,0,0.0137807,"collected using Amazon Mechanical Turk. An NNbased dialogue model was also proposed to learn from the collected dataset and was shown to be able to assist human subjects to complete specific tasks. Snapshot learning can be viewed as a special form of weak supervision (also known as distant- or self supervision) (Craven and Kumlien, 1999; Snow et al., 2004), in which supervision signals are heuristically labelled by matching unlabelled corpora with entities or attributes in a structured database. It has been widely applied to relation extraction (Mintz et al., 2009) and information extraction (Hoffmann et al., 2011) in which facts from a knowledge base (e.g. Freebase) were used as objectives to train classifiers. Recently, self supervision was also used in memory networks (Hill et al., 2016) to improve the discriminative power of memory attention. Conceptually, snapshot learning is related to curriculum learning (Bengio et al., 2009). Instead of learning easier examples before difficult ones, snapshot learning creates an easier target for each example. In practice, snapshot learning is similar to deeply supervised nets (Lee et al., 2015) in which companion objectives are generated from intermediary layer"
D16-1233,N16-1014,0,0.0318639,"t al., 2015; Hermann et al., 2015; Ling et al., 2016) have been shown to be very effective improving performance using a dynamic source aggregation strategy. To model dialogue as conditional generation, a sequence-to-sequence learning (Sutskever et al., 2014) framework has been adopted. Vinyals and Le (2015) trained the same model on several conversation datasets and showed that the model can generate plausible conversations. However, Serban et al. (2015b) discovered that the majority of the generated responses are generic due to the maximum likelihood criterion, which was latter addressed by Li et al. (2016a) using a maximum mutual information decoding strategy. Furthermore, the lack of a consistent system persona was also studied in Li et al. (2016b). Despite its demonstrated potential, a major barrier for this line of research is data collection. Many works (Lowe et al., 2015; Serban et al., 2015a; Dodge et al., 2016) have investigated conversation datasets for developing chat bot or QA-like general purpose conversation agents. However, collecting data to develop goal oriented dialogue systems that can help users to complete a task in a specific domain remains difficult. In a recent work by We"
D16-1233,P16-1094,0,0.0186793,"t al., 2015; Hermann et al., 2015; Ling et al., 2016) have been shown to be very effective improving performance using a dynamic source aggregation strategy. To model dialogue as conditional generation, a sequence-to-sequence learning (Sutskever et al., 2014) framework has been adopted. Vinyals and Le (2015) trained the same model on several conversation datasets and showed that the model can generate plausible conversations. However, Serban et al. (2015b) discovered that the majority of the generated responses are generic due to the maximum likelihood criterion, which was latter addressed by Li et al. (2016a) using a maximum mutual information decoding strategy. Furthermore, the lack of a consistent system persona was also studied in Li et al. (2016b). Despite its demonstrated potential, a major barrier for this line of research is data collection. Many works (Lowe et al., 2015; Serban et al., 2015a; Dodge et al., 2016) have investigated conversation datasets for developing chat bot or QA-like general purpose conversation agents. However, collecting data to develop goal oriented dialogue systems that can help users to complete a task in a specific domain remains difficult. In a recent work by We"
D16-1233,P16-1057,0,0.0393118,"Missing"
D16-1233,W15-4640,0,0.0167479,"been adopted. Vinyals and Le (2015) trained the same model on several conversation datasets and showed that the model can generate plausible conversations. However, Serban et al. (2015b) discovered that the majority of the generated responses are generic due to the maximum likelihood criterion, which was latter addressed by Li et al. (2016a) using a maximum mutual information decoding strategy. Furthermore, the lack of a consistent system persona was also studied in Li et al. (2016b). Despite its demonstrated potential, a major barrier for this line of research is data collection. Many works (Lowe et al., 2015; Serban et al., 2015a; Dodge et al., 2016) have investigated conversation datasets for developing chat bot or QA-like general purpose conversation agents. However, collecting data to develop goal oriented dialogue systems that can help users to complete a task in a specific domain remains difficult. In a recent work by Wen et al. (2016a), this problem was addressed by designing an online, parallel version of Wizard-of-Oz data collection (Kelley, 1984) which allows large scale and cheap in-domain conversation data to be collected using Amazon Mechanical Turk. An NNbased dialogue model was also"
D16-1233,N16-1086,0,0.0998745,"oviding both model interpretability and better performance. Thirdly, snapshot learning leads to consistent performance improvements independent of which architecture is used. 1 Introduction Recurrent Neural Network (RNN)-based conditional language models (LM) have been shown to be very effective in tackling a number of real world problems, such as machine translation (MT) (Cho et al., 2014) and image caption generation (Karpathy and Fei-Fei, 2015). Recently, RNNs were applied to task of generating sentences from an explicit semantic representation (Wen et al., 2015a). Attention-based methods (Mei et al., 2016) and Long Short-term Memory (LSTM)-like (Hochreiter Neural conversational agents (Vinyals and Le, 2015; Shang et al., 2015) are direct extensions of the sequence-to-sequence model (Sutskever et al., 2014) in which a conversation is cast as a source to target transduction problem. However, these models are still far from real world applications because they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2016) and aggregate useful information into their responses. Recent work by Wen et al. (2016a)"
D16-1233,P09-1113,0,0.0102347,"ale and cheap in-domain conversation data to be collected using Amazon Mechanical Turk. An NNbased dialogue model was also proposed to learn from the collected dataset and was shown to be able to assist human subjects to complete specific tasks. Snapshot learning can be viewed as a special form of weak supervision (also known as distant- or self supervision) (Craven and Kumlien, 1999; Snow et al., 2004), in which supervision signals are heuristically labelled by matching unlabelled corpora with entities or attributes in a structured database. It has been widely applied to relation extraction (Mintz et al., 2009) and information extraction (Hoffmann et al., 2011) in which facts from a knowledge base (e.g. Freebase) were used as objectives to train classifiers. Recently, self supervision was also used in memory networks (Hill et al., 2016) to improve the discriminative power of memory attention. Conceptually, snapshot learning is related to curriculum learning (Bengio et al., 2009). Instead of learning easier examples before difficult ones, snapshot learning creates an easier target for each example. In practice, snapshot learning is similar to deeply supervised nets (Lee et al., 2015) in which compani"
D16-1233,P15-2130,1,0.896091,"Missing"
D16-1233,P02-1040,0,0.0983833,"ies, we decode all the trained models with the average log probability of tokens in the sentence. We applied beam search with a beamwidth equal to 10, the search stops when an end-of-sentence token is generated. In order to consider language variability, we ran decoding until 5 candidates were obtained and performed evaluation on them. Metrics We compared models trained with different recipes by performing a corpus-based evaluation in which the model is used to predict each system response in the held-out test set. Three evaluation metrics were used: BLEU score (on top-1 and top5 candidates) (Papineni et al., 2002), slot matching rate and objective task success rate (Su et al., 2015). The dialogue is marked as successful if both: (1) the offered entity matches the task that was specified to the user, and (2) the system answered all the associated information requests (e.g. what is the address?) from the user. The slot matching rate is the percentage of delexicalised tokens (e.g. [s.food] and [v.area]1 ) appear in the candidate also appear in the (a) Hybrid LSTM w/o snapshot learning (b) Hybrid LSTM w/ snapshot learning Figure 3: Learned attention heat maps over trackers. The first three columns in each"
D16-1233,P15-1152,0,0.033149,"provements independent of which architecture is used. 1 Introduction Recurrent Neural Network (RNN)-based conditional language models (LM) have been shown to be very effective in tackling a number of real world problems, such as machine translation (MT) (Cho et al., 2014) and image caption generation (Karpathy and Fei-Fei, 2015). Recently, RNNs were applied to task of generating sentences from an explicit semantic representation (Wen et al., 2015a). Attention-based methods (Mei et al., 2016) and Long Short-term Memory (LSTM)-like (Hochreiter Neural conversational agents (Vinyals and Le, 2015; Shang et al., 2015) are direct extensions of the sequence-to-sequence model (Sutskever et al., 2014) in which a conversation is cast as a source to target transduction problem. However, these models are still far from real world applications because they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2016) and aggregate useful information into their responses. Recent work by Wen et al. (2016a), however, proposed an end-to-end trainable neural dialogue system that can assist users to complete specific tasks. Their"
D16-1233,W15-4639,1,0.905933,"Missing"
D16-1233,D15-1199,1,0.906064,"Missing"
D16-1233,N16-1015,1,0.901342,"Missing"
D16-1233,W16-0105,0,0.0581401,"s from an explicit semantic representation (Wen et al., 2015a). Attention-based methods (Mei et al., 2016) and Long Short-term Memory (LSTM)-like (Hochreiter Neural conversational agents (Vinyals and Le, 2015; Shang et al., 2015) are direct extensions of the sequence-to-sequence model (Sutskever et al., 2014) in which a conversation is cast as a source to target transduction problem. However, these models are still far from real world applications because they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2016) and aggregate useful information into their responses. Recent work by Wen et al. (2016a), however, proposed an end-to-end trainable neural dialogue system that can assist users to complete specific tasks. Their system used both distributed and symbolic representations to capture user intents, and these collectively condition a NN language generator to generate system responses. Due to the diversity of the conditioning information sources, the best way to represent and combine them is non-trivial. 2153 Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, page"
D18-1547,W17-5526,0,0.240706,"Missing"
D18-1547,W11-2002,0,0.0691455,"ed on building task-oriented dialogue systems (Young et al., 2013) that can help with specific tasks such as flight reservation (Seneff and Polifroni, 2000) ⇤ The work was done while at the University of Cambridge. or bus information (Raux et al., 2005). As the need of hands-free use cases continues to grow, building a conversational agent that can handle tasks across different application domains has become more and more prominent (Ram et al., 2018). Dialogues systems are inherently hard to build because there are several layers of complexity: the noise and uncertainty in speech recognition (Black et al., 2011); the ambiguity when understanding human language (Williams et al., 2013); the need to integrate third-party services and dialogue context in the decision-making (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005). These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho"
D18-1547,2005.sigdial-1.14,0,0.0630783,"falling behind by a large margin in comparison to the results on the Cam676 corpus taking into account both Inform and Success metrics. As most of dialogues span over at least two domains, the model has to be much more effective in order to execute a successful dialogue. Moreover, the BLEU score on the MultiWOZ is lower than the one reported on the Cam676 dataset. This is mainly caused by the much more diverse linguistic expressions observed in the MultiWOZ dataset. 5.3 Dialogue-Act-to-Text Generation Natural Language Generation from a structured meaning representation (Oh and Rudnicky, 2000; Bohus and Rudnicky, 2005) has been a very popular research topic in the community, and the lack of data has been a long standing block for the field to adopt more machine learning methods. Due to the additional annotation of the system acts, the MultiWOZ dataset serves as a new benchmark for studying natural language generation from a structured meaning representation. In order to verify the difficulty of the collected dataset for the language generation task, we compare it to the SFX dataset (see Table 1), which consists of around 5k dialogue act and natural language sentence pairs. We trained the same Semantically C"
D18-1547,bunt-2006-dimensions,0,0.0323307,"inspected and corrections were reported to annotators. Workers were asked to re-run a new trial dialogue. Having passed the second test, they were allowed to start annotating real dialogues. This procedure resulted in a restricted set of annotators performing high quality annotations. Appendix A contains a demonstration of a created system. Arguably, the most challenging and timeconsuming part of any dialogue data collection is the process of annotating dialogue acts. One of the major challenges of this task is the definition of a set and structure of dialogue acts (Traum and Hinkelman, 1992; Bunt, 2006). In general, a dialogue act consists of the intent (such as request or inform) and slot-value pairs. For example, the act 3.5 Data Quality inform(domain=hotel,price=expensive) Data collection was performed in a two-step prohas the intent inform, where the user is informing cess. First, all dialogues were collected and then the system to constrain the search to expensive the annotation process was launched. This setup hotels. allowed the dialogue act annotators to also report Expecting a big discrepancy in annotations beerrors (e.g., not following the task or confusing tween annotators, we ini"
D18-1547,W17-5506,0,0.618535,"ng (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005). These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016), and even end-to-end dialogue modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic labels (Hemphill et al., 1990; Williams et al., 2013; Asri et al., 2017; Wen et al., 2017; Eric et al., 2017; Shah et al., 2018); and corpora without semantic labels but with an implicit user goal in mind (Ritter et al., 2010; Lowe et al., 2015). Despite these efforts, aforement"
D18-1547,H90-1021,0,0.938681,"il et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016), and even end-to-end dialogue modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic labels (Hemphill et al., 1990; Williams et al., 2013; Asri et al., 2017; Wen et al., 2017; Eric et al., 2017; Shah et al., 2018); and corpora without semantic labels but with an implicit user goal in mind (Ritter et al., 2010; Lowe et al., 2015). Despite these efforts, aforementioned datasets are usually constrained in one or more dimensions such as missing proper annotations, only available in a limited capacity, lacking multi-domain use cases, or having a negli5016 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5016–5026 c Brussels, Belgium, October 31 - November 4, 2018. 2"
D18-1547,N16-1014,0,0.0205127,"r et al., 2010) dataset, the Reddit conversations (Schrading et al., 2015), and the Ubuntu technical support corpus (Lowe et al., 2015). Although previous work (Vinyals and Le, 2015) has shown that a large learning system can learn to generate interesting responses from these corpora, the lack of grounding conversations onto an existing knowledge base or APIs limits the usability of developed systems. Due to the lack of an explicit goal in the conversation, recent studies have shown that systems trained with this type of corpus not only struggle in generating consistent and diverse responses (Li et al., 2016) but are also extremely hard to evaluate (Liu et al., 2016). In this paper, we focus on a particular type of human-to-human data collection. The Wizardof-Oz framework (WOZ) (Kelley, 1984) was first proposed as an iterative approach to improve user experiences when designing a conversational system. The goal of WOZ data collection is to log down the conversation for future system development. One of the earliest dataset collected in this fashion is the ATIS corpus (Hemphill et al., 1990), where conversations between a client and an airline help-desk operator were recorded. More recently, Wen et"
D18-1547,I17-1074,0,0.0276924,"taurant domain. Although not directly comparable, Table 3 shows that the performance of the model is consecutively poorer on the new dataset compared to WOZ2.0. These results demonstrate how demanding is the new dataset as the conversations are richer and much longer. 5.2 Dialogue-Context-to-Text Generation After a robust dialogue state tracking module is built, the next challenge becomes the dialogue management and response generation components. These problems can either be addressed separately (Young et al., 2013), or jointly in an end-to-end fashion (Bordes et al., 2017; Wen et al., 2017; Li et al., 2017). In order to establish a clear benchmark where the performance of the composite of dialogue management and response generation is completely independent of the belief tracking, we experimented with a baseline neural response generation model with an oracle beliefstate obtained from the wizard annotations as discussed in Section 3.3.5 Following Wen et al. (2017) which frames the dialogue as a context to response mapping problem, a sequence-to-sequence model (Sutskever et al., 2014) is augmented with a belief tracker and a discrete database accessing component as additional features to inform t"
D18-1547,D16-1230,0,0.0496515,"Missing"
D18-1547,W14-4337,0,0.772007,"into account noisy conditions often experienced in real interactions (Black et al., 2011). Human-to-Machine Since collecting dialogue corpus for a task-specific application from scratch is difficult, most of the task-oriented dialogue corpora are fostered based on an existing dialogue system. One famous example of this kind is the Let’s Go Bus Information System which offers live bus schedule information over the phone (Raux et al., 2005) leading to the first Dialogue State Tracking Challenge (Williams et al., 2013). Taking the idea of the Let’s Go system forward, the second and third DSTCs (Henderson et al., 2014b,c) have produced bootstrapped human-machine datasets for a restaurant search domain in the Cambridge area, UK. Since then, DSTCs have become one of the central research topics in the dialogue community (Kim et al., 2016, 2017). While human-to-machine data collection is an obvious solution for dialogue system develop5017 ment, it is only possible with a provision of an existing working system. Therefore, this chicken (system)-and-egg (data) problem limits the use of this type of data collection to existing system improvement instead of developing systems in a completely new domain. What is ev"
D18-1547,W15-4640,0,0.2722,"Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic labels (Hemphill et al., 1990; Williams et al., 2013; Asri et al., 2017; Wen et al., 2017; Eric et al., 2017; Shah et al., 2018); and corpora without semantic labels but with an implicit user goal in mind (Ritter et al., 2010; Lowe et al., 2015). Despite these efforts, aforementioned datasets are usually constrained in one or more dimensions such as missing proper annotations, only available in a limited capacity, lacking multi-domain use cases, or having a negli5016 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5016–5026 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics Metric DSTC2 SFX WOZ2.0 FRAMES KVRET M2M MultiWOZ # Dialogues Total # turns Total # tokens Avg. turns per dialogue Avg. tokens per turn Total unique tokens # Slots # Valu"
D18-1547,W14-4340,0,0.797945,"into account noisy conditions often experienced in real interactions (Black et al., 2011). Human-to-Machine Since collecting dialogue corpus for a task-specific application from scratch is difficult, most of the task-oriented dialogue corpora are fostered based on an existing dialogue system. One famous example of this kind is the Let’s Go Bus Information System which offers live bus schedule information over the phone (Raux et al., 2005) leading to the first Dialogue State Tracking Challenge (Williams et al., 2013). Taking the idea of the Let’s Go system forward, the second and third DSTCs (Henderson et al., 2014b,c) have produced bootstrapped human-machine datasets for a restaurant search domain in the Cambridge area, UK. Since then, DSTCs have become one of the central research topics in the dialogue community (Kim et al., 2016, 2017). While human-to-machine data collection is an obvious solution for dialogue system develop5017 ment, it is only possible with a provision of an existing working system. Therefore, this chicken (system)-and-egg (data) problem limits the use of this type of data collection to existing system improvement instead of developing systems in a completely new domain. What is ev"
D18-1547,W13-4073,0,0.0586227,"build because there are several layers of complexity: the noise and uncertainty in speech recognition (Black et al., 2011); the ambiguity when understanding human language (Williams et al., 2013); the need to integrate third-party services and dialogue context in the decision-making (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005). These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016), and even end-to-end dialogue modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic la"
D18-1547,D16-1032,0,0.0124938,"liams et al., 2013); the need to integrate third-party services and dialogue context in the decision-making (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005). These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016), and even end-to-end dialogue modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic labels (Hemphill et al., 1990; Williams et al., 2013; Asri et al., 2017; Wen et al., 2017; Eric et al., 2017; Shah et al., 2018); and corpora without semantic labels but with a"
D18-1547,P17-1163,1,0.87487,"Missing"
D18-1547,Q17-1022,1,0.736153,"Missing"
D18-1547,W00-0306,0,0.205088,"l on MultiWOZ is still falling behind by a large margin in comparison to the results on the Cam676 corpus taking into account both Inform and Success metrics. As most of dialogues span over at least two domains, the model has to be much more effective in order to execute a successful dialogue. Moreover, the BLEU score on the MultiWOZ is lower than the one reported on the Cam676 dataset. This is mainly caused by the much more diverse linguistic expressions observed in the MultiWOZ dataset. 5.3 Dialogue-Act-to-Text Generation Natural Language Generation from a structured meaning representation (Oh and Rudnicky, 2000; Bohus and Rudnicky, 2005) has been a very popular research topic in the community, and the lack of data has been a long standing block for the field to adopt more machine learning methods. Due to the additional annotation of the system acts, the MultiWOZ dataset serves as a new benchmark for studying natural language generation from a structured meaning representation. In order to verify the difficulty of the collected dataset for the language generation task, we compare it to the SFX dataset (see Table 1), which consists of around 5k dialogue act and natural language sentence pairs. We trai"
D18-1547,P02-1040,0,0.101374,"Missing"
D18-1547,P18-2069,1,0.766406,"Missing"
D18-1547,N10-1020,0,0.522396,"modelling (Zhao and Eskenazi, 2016; Wen et al., 2017; Eric et al., 2017). To drive the progress of building dialogue systems using data-driven approaches, a number of conversational corpora have been released in the past. Based on whether a structured annotation scheme is used to label the semantics, these corpora can be roughly divided into two categories: corpora with structured semantic labels (Hemphill et al., 1990; Williams et al., 2013; Asri et al., 2017; Wen et al., 2017; Eric et al., 2017; Shah et al., 2018); and corpora without semantic labels but with an implicit user goal in mind (Ritter et al., 2010; Lowe et al., 2015). Despite these efforts, aforementioned datasets are usually constrained in one or more dimensions such as missing proper annotations, only available in a limited capacity, lacking multi-domain use cases, or having a negli5016 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5016–5026 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics Metric DSTC2 SFX WOZ2.0 FRAMES KVRET M2M MultiWOZ # Dialogues Total # turns Total # tokens Avg. turns per dialogue Avg. tokens per turn Total unique t"
D18-1547,D15-1309,0,0.0339104,"t al., 2016). The limited understanding capability of the initial system may prompt the users to adapt to simpler input examples that the system can understand but are not necessarily natural in conversations. Human-to-Human Arguably, the best strategy to build a natural conversational system may be to have a system that can directly mimic human behaviors through learning from a large amount of real human-human conversations. With this idea in mind, several large-scale dialogue corpora have been released in the past, such as the Twitter (Ritter et al., 2010) dataset, the Reddit conversations (Schrading et al., 2015), and the Ubuntu technical support corpus (Lowe et al., 2015). Although previous work (Vinyals and Le, 2015) has shown that a large learning system can learn to generate interesting responses from these corpora, the lack of grounding conversations onto an existing knowledge base or APIs limits the usability of developed systems. Due to the lack of an explicit goal in the conversation, recent studies have shown that systems trained with this type of corpus not only struggle in generating consistent and diverse responses (Li et al., 2016) but are also extremely hard to evaluate (Liu et al., 2016"
D18-1547,W00-0303,0,0.506497,"one of the long-standing challenges in computer science and artificial intelligence since the Dartmouth Proposal (McCarthy et al., 1955). As human conversation is inherently complex and ambiguous, learning an open-domain conversational AI that can carry on arbitrary tasks is still very far-off (Vinyals and Le, 2015). As a consequence, instead of focusing on creating ambitious conversational agents that can reach human-level intelligence, industrial practice has focused on building task-oriented dialogue systems (Young et al., 2013) that can help with specific tasks such as flight reservation (Seneff and Polifroni, 2000) ⇤ The work was done while at the University of Cambridge. or bus information (Raux et al., 2005). As the need of hands-free use cases continues to grow, building a conversational agent that can handle tasks across different application domains has become more and more prominent (Ram et al., 2018). Dialogues systems are inherently hard to build because there are several layers of complexity: the noise and uncertainty in speech recognition (Black et al., 2011); the ambiguity when understanding human language (Williams et al., 2013); the need to integrate third-party services and dialogue contex"
D18-1547,N16-1015,1,0.902963,"Missing"
D18-1547,D15-1199,1,0.881212,"Missing"
D18-1547,E17-1042,1,0.819561,"Missing"
D18-1547,W13-4065,0,0.636123,"t can help with specific tasks such as flight reservation (Seneff and Polifroni, 2000) ⇤ The work was done while at the University of Cambridge. or bus information (Raux et al., 2005). As the need of hands-free use cases continues to grow, building a conversational agent that can handle tasks across different application domains has become more and more prominent (Ram et al., 2018). Dialogues systems are inherently hard to build because there are several layers of complexity: the noise and uncertainty in speech recognition (Black et al., 2011); the ambiguity when understanding human language (Williams et al., 2013); the need to integrate third-party services and dialogue context in the decision-making (Traum and Larsson, 2003; Paek and Pieraccini, 2008); and finally, the ability to generate natural and engaging responses (Stent et al., 2005). These difficulties have led to the same solution of using statistical framework and machine learning for various system components, such as natural language understanding (Henderson et al., 2013; Mesnil et al., 2015; Mrkˇsi´c et al., 2017a), dialogue management (Gaˇsi´c and Young, 2014; Tegho et al., 2018), language generation (Wen et al., 2015; Kiddon et al., 2016"
D18-1547,W16-3601,0,\N,Missing
E17-1042,W14-4340,1,0.407798,"Introduction Building a task-oriented dialogue system such as a hotel booking or a technical support service is difficult because it is application-specific and there is usually limited availability of training data. To mitigate this problem, recent machine learning approaches to task-oriented dialogue system design have cast the problem as a partially observable Markov Decision Process (POMDP) (Young et al., 2013) with the aim of using reinforcement learning (RL) to train dialogue policies online through interactions with real users (Gaši´c et al., 2013). However, the language understanding (Henderson et al., 2014; Yao et al., 2014) and language generation (Wen et al., 2015b; Wen et al., 2016) modules still rely on supervised learning and therefore need corpora to train on. Furthermore, to make RL tractable, the state and action space must be carefully designed (Young et al., 2013; Young et al., 2010), which may restrict the expressive power and learnability of the model. Also, the reward functions needed to train such models are difficult to design and hard to measure at run-time (Su et al., 2015; Su et al., 2016). At the other end of the spectrum, sequence to sequence learning (Sutskever et al., 2014"
E17-1042,P82-1020,0,0.852845,"Missing"
E17-1042,P15-1152,0,0.0310789,"d therefore need corpora to train on. Furthermore, to make RL tractable, the state and action space must be carefully designed (Young et al., 2013; Young et al., 2010), which may restrict the expressive power and learnability of the model. Also, the reward functions needed to train such models are difficult to design and hard to measure at run-time (Su et al., 2015; Su et al., 2016). At the other end of the spectrum, sequence to sequence learning (Sutskever et al., 2014) has inspired several efforts to build end-to-end trainable, non-task-oriented conversational systems (Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2015b). This family of approaches treats dialogue as a source to target sequence transduction problem, applying an encoder network (Cho et al., 2014) to encode a user query into a distributed vector representing its semantics, which then conditions a decoder network to generate each system response. These models typically require a large amount of data to train. They allow the creation of effective chatbot type systems but they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2015"
E17-1042,P16-1230,1,0.812856,"Missing"
E17-1042,W15-4639,1,0.762536,"Missing"
E17-1042,D15-1199,1,0.0638233,"Missing"
E17-1042,N16-1015,1,0.0427593,"Missing"
N16-1015,P14-2023,0,0.0784359,"d-coded grammars (Langkilde and Knight, 1998; Walker et al., 2002). Many existing adaptation approaches (Wen et al., 2013; Shi et al., 2015; Chen et al., 2015) can be directly applied due to the 120 Proceedings of NAACL-HLT 2016, pages 120–129, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics flexibility of the underlying RNN language model (RNNLM) architecture (Mikolov et al., 2010). Discriminative training (DT) has been successfully used to train RNNs for various tasks. By optimising directly against the desired objective function such as BLEU score (Auli and Gao, 2014) or Word Error Rate (Kuo et al., 2002), the model can explore its output space and learn to discriminate between good and bad hypotheses. In this paper we show that DT can enable a generator to learn more efficiently when in-domain data is scarce. The paper presents an incremental recipe for training multi-domain language generators based on a purely data-driven, RNN-based generation model. Following a review of related work in section 2, section 3 describes the detailed RNN generator architecture. The data counterfeiting approach for synthesising an in-domain dataset is introduced in section"
N16-1015,D14-1132,0,0.0192427,"et al. (2015) applied curriculum learning to RNNLM adaptation. Discriminative training (DT) (Collins, 2002) is an alternative to the maximum likelihood (ML) criterion. For classification, DT can be split into two phases: (1) decoding training examples using the current model and scoring them, and (2) adjusting the model parameters to maximise the separation between the correct target annotation and the competing incorrect annotations. It has been successfully applied to many research problems, such as speech recognition (Kuo et al., 2002; Voigtlaender et al., 2015) and MT (He and Deng, 2012; Auli et al., 2014). Recently, Auli and Gao (2014) trained an RNNLM with a DT objective and showed improved performance on an MT task. However, their RNN probabilities only served as input features to a phrase-based MT system. 3 The Neural Language Generator The neural language generation model (Wen et al., 2015a; Wen et al., 2015b) is a RNNLM (Mikolov et al., 2010) augmented with semantic input features such as a dialogue act1 (DA) denoting the required semantics of the generated output. At every time step t, the model consumes the 1-hot representation of both the DA dt and a token wt 2 to update its internal s"
N16-1015,P07-1056,0,0.0619326,", 2007) and mimicking personality traits (Mairesse and Walker, 2011). Lemon (2008) proposed a Reinforcement Learning (RL) framework in which policy and NLG components can be jointly optimised and adapted based on online user feedback. In contrast, Mairesse et al. (2010) has proposed using active learning to mitigate the data sparsity problem when training datadriven NLG systems. Furthermore, Cuayhuitl et al. (2014) trained statistical surface realisers from unlabelled data by an automatic slot labelling technique. In general, feature-based adaptation is perhaps the most widely used technique (Blitzer et al., 2007; Pan and Yang, 2010; Duan et al., 2012). By exploiting correlations and similarities between data points, it has been successfully applied to problems like speaker adaptation (Gauvain and Lee, 1994; Leggetter and Woodland, 1995) and various tasks in natural language processing (Daum´e III, 2009). In contrast, model-based adaptation is particularly useful for language modeling (LM) (Bellegarda, 2004). Mixture-based topic LMs (Gildea and Hofmann, 1999) are widely used in N-gram LMs for domain adaptation. Similar ideas have been applied to applications that require adapting LMs, such as machine"
N16-1015,W02-1001,0,0.0403925,"(Wen et al., 2012). Domain adaptation for Neural Network (NN)based LMs has also been studied in the past. A feature augmented RNNLM was first proposed by Mikolov and Zweig (2012), but later applied to multi-genre broadcast speech recognition (Chen et al., 2015) and personalised language modeling (Wen et al., 2013). These methods are based on finetuning existing network parameters on adaptation data. However, careful regularisation is often necessary (Yu et al., 2013). In a slightly different area, Shi et al. (2015) applied curriculum learning to RNNLM adaptation. Discriminative training (DT) (Collins, 2002) is an alternative to the maximum likelihood (ML) criterion. For classification, DT can be split into two phases: (1) decoding training examples using the current model and scoring them, and (2) adjusting the model parameters to maximise the separation between the correct target annotation and the competing incorrect annotations. It has been successfully applied to many research problems, such as speech recognition (Kuo et al., 2002; Voigtlaender et al., 2015) and MT (He and Deng, 2012; Auli et al., 2014). Recently, Auli and Gao (2014) trained an RNNLM with a DT objective and showed improved p"
N16-1015,P12-1031,0,0.0504083,"different area, Shi et al. (2015) applied curriculum learning to RNNLM adaptation. Discriminative training (DT) (Collins, 2002) is an alternative to the maximum likelihood (ML) criterion. For classification, DT can be split into two phases: (1) decoding training examples using the current model and scoring them, and (2) adjusting the model parameters to maximise the separation between the correct target annotation and the competing incorrect annotations. It has been successfully applied to many research problems, such as speech recognition (Kuo et al., 2002; Voigtlaender et al., 2015) and MT (He and Deng, 2012; Auli et al., 2014). Recently, Auli and Gao (2014) trained an RNNLM with a DT objective and showed improved performance on an MT task. However, their RNN probabilities only served as input features to a phrase-based MT system. 3 The Neural Language Generator The neural language generation model (Wen et al., 2015a; Wen et al., 2015b) is a RNNLM (Mikolov et al., 2010) augmented with semantic input features such as a dialogue act1 (DA) denoting the required semantics of the generated output. At every time step t, the model consumes the 1-hot representation of both the DA dt and a token wt 2 to u"
N16-1015,W08-1122,0,0.0473989,"Missing"
N16-1015,W06-1405,0,0.00971362,") are typically developed according to a well-defined ontology, which provides a structured representation of the domain data that the dialogue system can talk about, such as searching for a restaurant or shopping for a laptop. Unlike conventional approaches employing a substantial amount of handcrafting for In past decades, adaptive NLG has been studied from linguistic perspectives, such as systems that learn to tailor user preferences (Walker et al., 2007), convey a specific personality trait (Mairesse and Walker, 2008; Mairesse and Walker, 2011), or align with their conversational partner (Isard et al., 2006). Domain adaptation was first addressed by Hogan et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) fstructures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based language generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation decisions directly from dialogue act (DA)-utterance pairs without any semantic annotations (Mair"
N16-1015,W07-0733,0,0.0167372,"10; Duan et al., 2012). By exploiting correlations and similarities between data points, it has been successfully applied to problems like speaker adaptation (Gauvain and Lee, 1994; Leggetter and Woodland, 1995) and various tasks in natural language processing (Daum´e III, 2009). In contrast, model-based adaptation is particularly useful for language modeling (LM) (Bellegarda, 2004). Mixture-based topic LMs (Gildea and Hofmann, 1999) are widely used in N-gram LMs for domain adaptation. Similar ideas have been applied to applications that require adapting LMs, such as machine translation (MT) (Koehn and Schroeder, 2007) and personalised speech recognition (Wen et al., 2012). Domain adaptation for Neural Network (NN)based LMs has also been studied in the past. A feature augmented RNNLM was first proposed by Mikolov and Zweig (2012), but later applied to multi-genre broadcast speech recognition (Chen et al., 2015) and personalised language modeling (Wen et al., 2013). These methods are based on finetuning existing network parameters on adaptation data. However, careful regularisation is often necessary (Yu et al., 2013). In a slightly different area, Shi et al. (2015) applied curriculum learning to RNNLM adapt"
N16-1015,P98-1116,0,0.0477187,"an et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) fstructures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based language generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation decisions directly from dialogue act (DA)-utterance pairs without any semantic annotations (Mairesse and Young, 2014) or hand-coded grammars (Langkilde and Knight, 1998; Walker et al., 2002). Many existing adaptation approaches (Wen et al., 2013; Shi et al., 2015; Chen et al., 2015) can be directly applied due to the 120 Proceedings of NAACL-HLT 2016, pages 120–129, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics flexibility of the underlying RNN language model (RNNLM) architecture (Mikolov et al., 2010). Discriminative training (DT) has been successfully used to train RNNs for various tasks. By optimising directly against the desired objective function such as BLEU score (Auli and Gao, 2014) or Word Error Rate (Kuo"
N16-1015,P08-1020,0,0.0479934,"small amount of data is available in the domain. 1 Introduction Modern Spoken Dialogue Systems (SDS) are typically developed according to a well-defined ontology, which provides a structured representation of the domain data that the dialogue system can talk about, such as searching for a restaurant or shopping for a laptop. Unlike conventional approaches employing a substantial amount of handcrafting for In past decades, adaptive NLG has been studied from linguistic perspectives, such as systems that learn to tailor user preferences (Walker et al., 2007), convey a specific personality trait (Mairesse and Walker, 2008; Mairesse and Walker, 2011), or align with their conversational partner (Isard et al., 2006). Domain adaptation was first addressed by Hogan et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) fstructures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based language generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation dec"
N16-1015,J11-3002,0,0.0459034,"ilable in the domain. 1 Introduction Modern Spoken Dialogue Systems (SDS) are typically developed according to a well-defined ontology, which provides a structured representation of the domain data that the dialogue system can talk about, such as searching for a restaurant or shopping for a laptop. Unlike conventional approaches employing a substantial amount of handcrafting for In past decades, adaptive NLG has been studied from linguistic perspectives, such as systems that learn to tailor user preferences (Walker et al., 2007), convey a specific personality trait (Mairesse and Walker, 2008; Mairesse and Walker, 2011), or align with their conversational partner (Isard et al., 2006). Domain adaptation was first addressed by Hogan et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) fstructures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based language generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation decisions directly from dialogu"
N16-1015,J14-4003,1,0.577231,"006). Domain adaptation was first addressed by Hogan et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) fstructures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based language generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation decisions directly from dialogue act (DA)-utterance pairs without any semantic annotations (Mairesse and Young, 2014) or hand-coded grammars (Langkilde and Knight, 1998; Walker et al., 2002). Many existing adaptation approaches (Wen et al., 2013; Shi et al., 2015; Chen et al., 2015) can be directly applied due to the 120 Proceedings of NAACL-HLT 2016, pages 120–129, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics flexibility of the underlying RNN language model (RNNLM) architecture (Mikolov et al., 2010). Discriminative training (DT) has been successfully used to train RNNs for various tasks. By optimising directly against the desired objective function such as BLEU"
N16-1015,P10-1157,1,0.916076,"Missing"
N16-1015,P15-2130,1,0.12451,"Missing"
N16-1015,P02-1040,0,0.119975,"the laptop domain and 7K distinct DAs in the TV domain. We then used AMT workers to collect just one realisation for each DA. Since the resulting datasets have a much larger input space but only one training example for each DA, the system must learn partial realisations of concepts and be able to recombine and apply them to unseen DAs. Also note that the number of act types and slots of the new ontology is larger, which makes NLG in both laptop and TV domains much harder. 7 Corpus-based Evaluation We first assess generator performance using two objective evaluation metrics, the BLEU-4 score (Papineni et al., 2002) and slot error rate ERR (Wen et al., 2015b). Slot error rates were calculated by averaging slot errors over each of the top 5 realisations in the entire corpus. We used multiple references to compute the BLEU scores when available (i.e. for the restaurant and hotel domains). In order to better 125 compare results across different methods, we plotted the BLEU and slot error rate curves against different amounts of adaptation data. Note that in the graphs the x-axis is presented on a log-scale. 7.1 Experimental Setup The generators were implemented using the Theano library (Bergstra et al., 201"
N16-1015,P04-1011,0,0.222077,"an thus generate a sequence of tokens by repeatedly sampling the current output distribution to obtain the next input token until an end-ofsentence sign is generated. Finally, the generated sequence is lexicalised3 to form the target utterance. The Semantically Conditioned Long Short-term Memory Network (SC-LSTM) (Wen et al., 2015b) is a specialised extension of the LSTM network (Hochreiter and Schmidhuber, 1997) for language generation which has previously been shown capable of learning generation decisions from paired DA-utterances end-to-end without a modular pipeline (Walker et al., 2002; Stent et al., 2004). Like LSTM, SC-LSTM relies on a vector of memory cells ct ∈ Rn and a set of elementwise multiplication gates to control how information is stored, forgotten, and exploited inside the network. The SCLSTM architecture used in this paper is defined by the following equations,       A combination of an action type and a set of slot-value pairs. e.g. inform(name=”Seven days”,food=”chinese”) 2 We use token instead of word because our model operates on text for which slot values are replaced by their corresponding slot tokens. We call this procedure delexicalisation. 3 The process of replacing"
N16-1015,H94-1039,0,0.081629,"Missing"
N16-1015,W15-4639,1,0.663718,"Missing"
N16-1015,D15-1199,1,0.528094,"Missing"
N16-1015,C98-1112,0,\N,Missing
N16-1015,P07-1033,0,\N,Missing
N16-1018,P14-2131,0,0.0264055,"oVe vectors before and after counter-fitting Introduction Many popular methods that induce representations for words rely on the distributional hypothesis – the assumption that semantically similar or related words appear in similar contexts. This hypothesis supports unsupervised learning of meaningful word rep´ resentations from large corpora (Curran, 2003; O S´eaghdha and Korhonen, 2014; Mikolov et al., 2013; Pennington et al., 2014). Word vectors trained using these methods have proven useful for many downstream tasks including machine translation (Zou et al., 2013) and dependency parsing (Bansal et al., 2014). One drawback of learning word embeddings from co-occurrence information in corpora is that it tends to coalesce the notions of semantic similarity and conceptual association (Hill et al., 2014b). Furthermore, even methods that can distinguish similarity from association (e.g., based on syntactic co-occurrences) will generally fail to tell synonyms from antonyms (Mohammad et al., 2008). For example, words such as east and west or expensive and inexpensive appear in near-identical contexts, which means that distributional models produce very similar word vectors for such words. Examples of suc"
N16-1018,P08-1118,0,0.0153105,"Missing"
N16-1018,P15-2076,0,0.038284,"Missing"
N16-1018,N15-1184,0,0.19487,"pages 142–148, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics (e.g. cheaper and pricey) is critical for the performance of dialogue systems. In particular, a dialogue system can be led seriously astray by false synonyms. We propose a method that addresses these two drawbacks by using synonymy and antonymy relations drawn from either a general lexical resource or an application-specific ontology to fine-tune distributional word vectors. Our method, which we term counter-fitting, is a lightweight post-processing procedure in the spirit of retrofitting (Faruqui et al., 2015). The second row of Table 1 illustrates the results of counter-fitting: the nearest neighbours capture true similarity much more intuitively than the original GloVe vectors. The procedure improves word vector quality regardless of the initial word vectors provided as input.1 By applying counter-fitting to the Paragram-SL999 word vectors provided by Wieting et al. (2015), we achieve new state-of-the-art performance on SimLex-999, a dataset designed to measure how well different models judge semantic similarity between words (Hill et al., 2014b). We also show that the counter-fitting method can"
N16-1018,N13-1092,0,0.0298598,"Missing"
N16-1018,D12-1057,0,0.0473899,"Missing"
N16-1018,W14-4337,1,0.107819,"ent descent (SGD) for 20 epochs. An end-to-end run of counter-fitting takes less than two minutes on a laptop with four CPUs. 3.1 Injecting Dialogue Domain Ontologies into Vector Space Representations Dialogue state tracking (DST) models capture users’ goals given their utterances. Goals are represented as sets of constraints expressed by slot-value pairs such as [food: Indian] or [parking: allowed]. The set of slots S and the set of values Vs for each slot make up the ontology of a dialogue domain. In this paper we adopt the recurrent neural network (RNN) framework for tracking suggested in (Henderson et al., 2014d; Henderson et al., 2014c; Mrkˇsi´c et al., 2015). Rather than using a spoken language understanding (SLU) decoder to convert user utterances into meaning representations, this model operates directly on the n-gram features extracted from the automated speech recognition (ASR) hypotheses. A drawback of this approach is that the RNN model can only perform exact string matching to detect the slot names and values mentioned by the user. It cannot recognise synonymous words such as pricey and expensive, or even subtle morphological variations such as moderate and moderately. A simple way to mitig"
N16-1018,W14-4340,1,0.930369,"ent descent (SGD) for 20 epochs. An end-to-end run of counter-fitting takes less than two minutes on a laptop with four CPUs. 3.1 Injecting Dialogue Domain Ontologies into Vector Space Representations Dialogue state tracking (DST) models capture users’ goals given their utterances. Goals are represented as sets of constraints expressed by slot-value pairs such as [food: Indian] or [parking: allowed]. The set of slots S and the set of values Vs for each slot make up the ontology of a dialogue domain. In this paper we adopt the recurrent neural network (RNN) framework for tracking suggested in (Henderson et al., 2014d; Henderson et al., 2014c; Mrkˇsi´c et al., 2015). Rather than using a spoken language understanding (SLU) decoder to convert user utterances into meaning representations, this model operates directly on the n-gram features extracted from the automated speech recognition (ASR) hypotheses. A drawback of this approach is that the RNN model can only perform exact string matching to detect the slot names and values mentioned by the user. It cannot recognise synonymous words such as pricey and expensive, or even subtle morphological variations such as moderate and moderately. A simple way to mitig"
N16-1018,D15-1242,0,0.191706,"f dialogue domain ontologies into word vector space representations to facilitate the construction of semantic dictionaries which improve DST performance across two different dialogue domains. Our tool and word vectors are available at github.com/nmrksic/counter-fitting. 2 Related Work Most work on improving word vector representations using lexical resources has focused on bringing words which are known to be semantically related closer together in the vector space. Some methods modify the prior or the regularization of the original training procedure (Yu and Dredze, 2014; Bian et al., 2014; Kiela et al., 2015). Wieting et al. (2015) use the Paraphrase Database (Ganitkevitch et al., 2013) to train word vectors which emphasise word similarity over word relatedness. These word vectors achieve the current state-of-the-art performance on the SimLex-999 dataset and are used as input for counter-fitting in our experiments. 1 When we write “improve”, we refer to improving the vector space for a specific purpose. We do not expect that a vector space fine-tuned for semantic similarity will give better results on semantic relatedness. As Mohammad et al. (2008) observe, antonymous concepts are related but not"
N16-1018,P15-1145,0,0.0291586,"r distributional methods are well-known in the semantics community. Most prior work focuses on extracting antonym pairs from text rather than exploiting them (Lin et al., 2003; Mohammad et al., 2008; Turney, 2008; Hashimoto et al., 2012; Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015), who build a standard distributional model from co-occurrences based on symmetric patterns, with specified antonymy patterns counted as negative co-occurrences; and Ono et al. (2015), who use thesauri and distributional data to train word embeddings specialised for capturing antonymy. 3 Counter-fitting Word Vectors to Linguistic Constraints Our starting p"
N16-1018,P02-1047,0,0.0195161,"yweight” procedures do. Faruqui et al.’s (2015) retrofitting approach uses similarity constraints from WordNet and other resources to pull similar words closer together. The complications caused by antonymy for distributional methods are well-known in the semantics community. Most prior work focuses on extracting antonym pairs from text rather than exploiting them (Lin et al., 2003; Mohammad et al., 2008; Turney, 2008; Hashimoto et al., 2012; Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015), who build a standard distributional model from co-occurrences based on symmetric patterns, with specified antonymy patterns counted as negative co-occurre"
N16-1018,D08-1103,0,0.0296778,"2014; Mikolov et al., 2013; Pennington et al., 2014). Word vectors trained using these methods have proven useful for many downstream tasks including machine translation (Zou et al., 2013) and dependency parsing (Bansal et al., 2014). One drawback of learning word embeddings from co-occurrence information in corpora is that it tends to coalesce the notions of semantic similarity and conceptual association (Hill et al., 2014b). Furthermore, even methods that can distinguish similarity from association (e.g., based on syntactic co-occurrences) will generally fail to tell synonyms from antonyms (Mohammad et al., 2008). For example, words such as east and west or expensive and inexpensive appear in near-identical contexts, which means that distributional models produce very similar word vectors for such words. Examples of such anomalies in GloVe vectors can be seen in Table 1, where words such as cheaper and inexpensive are deemed similar to (their antonym) expensive. A second drawback is that similarity and antonymy can be application- or domain-specific. In our case, we are interested in exploiting distributional knowledge for the dialogue state tracking task (DST). The DST component of a dialogue system"
N16-1018,J13-3004,0,0.0178637,"procedures that use lexical knowledge to refine off-the-shelf word vectors without requiring large corpora for (re-)training as the aforementioned “heavyweight” procedures do. Faruqui et al.’s (2015) retrofitting approach uses similarity constraints from WordNet and other resources to pull similar words closer together. The complications caused by antonymy for distributional methods are well-known in the semantics community. Most prior work focuses on extracting antonym pairs from text rather than exploiting them (Lin et al., 2003; Mohammad et al., 2008; Turney, 2008; Hashimoto et al., 2012; Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015),"
N16-1018,P15-2130,1,0.312954,"Missing"
N16-1018,N15-1100,0,0.0467596,"ffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015), who build a standard distributional model from co-occurrences based on symmetric patterns, with specified antonymy patterns counted as negative co-occurrences; and Ono et al. (2015), who use thesauri and distributional data to train word embeddings specialised for capturing antonymy. 3 Counter-fitting Word Vectors to Linguistic Constraints Our starting point is an indexed set of word vectors V = {v1 , v2 , . . . , vN } with one vector for each word in the vocabulary. We will inject semantic relations into this vector space to produce new word vectors V 0 = {v0 1 , v0 2 , . . . , v0 N }. For antonymy and synonymy we have a set of constraints A and S, respectively. The elements of each set are pairs of word indices; for example, each pair (i, j) in S is such that the i-th"
N16-1018,P15-2070,0,0.0699134,"Missing"
N16-1018,D14-1162,0,0.123725,"inexpensive costly pricy overpriced pricey afford British American Australian Britain European England Brits London BBC UK Britain Table 1: Nearest neighbours for target words using GloVe vectors before and after counter-fitting Introduction Many popular methods that induce representations for words rely on the distributional hypothesis – the assumption that semantically similar or related words appear in similar contexts. This hypothesis supports unsupervised learning of meaningful word rep´ resentations from large corpora (Curran, 2003; O S´eaghdha and Korhonen, 2014; Mikolov et al., 2013; Pennington et al., 2014). Word vectors trained using these methods have proven useful for many downstream tasks including machine translation (Zou et al., 2013) and dependency parsing (Bansal et al., 2014). One drawback of learning word embeddings from co-occurrence information in corpora is that it tends to coalesce the notions of semantic similarity and conceptual association (Hill et al., 2014b). Furthermore, even methods that can distinguish similarity from association (e.g., based on syntactic co-occurrences) will generally fail to tell synonyms from antonyms (Mohammad et al., 2008). For example, words such as e"
N16-1018,K15-1026,0,0.0258896,"Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015), who build a standard distributional model from co-occurrences based on symmetric patterns, with specified antonymy patterns counted as negative co-occurrences; and Ono et al. (2015), who use thesauri and distributional data to train word embeddings specialised for capturing antonymy. 3 Counter-fitting Word Vectors to Linguistic Constraints Our starting point is an indexed set of word vectors V = {v1 , v2 , . . . , vN } with one vector for each word in the vocabulary. We will inject semantic relations into this vector space to produce new word vectors V 0 = {v0 1 , v0 2 , . . . , v0 N }. For"
N16-1018,C08-1114,0,0.0231998,"nterest in lightweight post-processing procedures that use lexical knowledge to refine off-the-shelf word vectors without requiring large corpora for (re-)training as the aforementioned “heavyweight” procedures do. Faruqui et al.’s (2015) retrofitting approach uses similarity constraints from WordNet and other resources to pull similar words closer together. The complications caused by antonymy for distributional methods are well-known in the semantics community. Most prior work focuses on extracting antonym pairs from text rather than exploiting them (Lin et al., 2003; Mohammad et al., 2008; Turney, 2008; Hashimoto et al., 2012; Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Se"
N16-1018,Q15-1025,0,0.312489,"ither a general lexical resource or an application-specific ontology to fine-tune distributional word vectors. Our method, which we term counter-fitting, is a lightweight post-processing procedure in the spirit of retrofitting (Faruqui et al., 2015). The second row of Table 1 illustrates the results of counter-fitting: the nearest neighbours capture true similarity much more intuitively than the original GloVe vectors. The procedure improves word vector quality regardless of the initial word vectors provided as input.1 By applying counter-fitting to the Paragram-SL999 word vectors provided by Wieting et al. (2015), we achieve new state-of-the-art performance on SimLex-999, a dataset designed to measure how well different models judge semantic similarity between words (Hill et al., 2014b). We also show that the counter-fitting method can inject knowledge of dialogue domain ontologies into word vector space representations to facilitate the construction of semantic dictionaries which improve DST performance across two different dialogue domains. Our tool and word vectors are available at github.com/nmrksic/counter-fitting. 2 Related Work Most work on improving word vector representations using lexical re"
N16-1018,D12-1111,0,0.0507046,"text rather than exploiting them (Lin et al., 2003; Mohammad et al., 2008; Turney, 2008; Hashimoto et al., 2012; Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015), who build a standard distributional model from co-occurrences based on symmetric patterns, with specified antonymy patterns counted as negative co-occurrences; and Ono et al. (2015), who use thesauri and distributional data to train word embeddings specialised for capturing antonymy. 3 Counter-fitting Word Vectors to Linguistic Constraints Our starting point is an indexed set of word vectors V = {v1 , v2 , . . . , vN } with one vector for each word in the vocabulary. We will i"
N16-1018,P14-2089,0,0.0344864,"er-fitting method can inject knowledge of dialogue domain ontologies into word vector space representations to facilitate the construction of semantic dictionaries which improve DST performance across two different dialogue domains. Our tool and word vectors are available at github.com/nmrksic/counter-fitting. 2 Related Work Most work on improving word vector representations using lexical resources has focused on bringing words which are known to be semantically related closer together in the vector space. Some methods modify the prior or the regularization of the original training procedure (Yu and Dredze, 2014; Bian et al., 2014; Kiela et al., 2015). Wieting et al. (2015) use the Paraphrase Database (Ganitkevitch et al., 2013) to train word vectors which emphasise word similarity over word relatedness. These word vectors achieve the current state-of-the-art performance on the SimLex-999 dataset and are used as input for counter-fitting in our experiments. 1 When we write “improve”, we refer to improving the vector space for a specific purpose. We do not expect that a vector space fine-tuned for semantic similarity will give better results on semantic relatedness. As Mohammad et al. (2008) observe,"
N16-1018,D13-1141,0,0.0235628,"arest neighbours for target words using GloVe vectors before and after counter-fitting Introduction Many popular methods that induce representations for words rely on the distributional hypothesis – the assumption that semantically similar or related words appear in similar contexts. This hypothesis supports unsupervised learning of meaningful word rep´ resentations from large corpora (Curran, 2003; O S´eaghdha and Korhonen, 2014; Mikolov et al., 2013; Pennington et al., 2014). Word vectors trained using these methods have proven useful for many downstream tasks including machine translation (Zou et al., 2013) and dependency parsing (Bansal et al., 2014). One drawback of learning word embeddings from co-occurrence information in corpora is that it tends to coalesce the notions of semantic similarity and conceptual association (Hill et al., 2014b). Furthermore, even methods that can distinguish similarity from association (e.g., based on syntactic co-occurrences) will generally fail to tell synonyms from antonyms (Mohammad et al., 2008). For example, words such as east and west or expensive and inexpensive appear in near-identical contexts, which means that distributional models produce very similar"
N18-2112,W13-4035,1,0.892395,"Missing"
N18-2112,J08-4002,0,0.0337305,"ious state of the art in several dialogue domains and environments, without the need of any additional reward signal. 1 Introduction Task-oriented Spoken Dialogue Systems (SDS), in the form of personal assistants, have recently gained much attention in both academia and industry. One of the most important modules of a SDS is the Dialogue Manager (DM) (or policy), the module in charge of deciding the next action in each dialogue turn. Reinforcement Learning (RL) (Sutton and Barto, 1999) has been studied for several years as a promising approach to model dialogue management (Levin et al., 1998; Henderson et al., 2008; Pietquin et al., 2011; Young et al., 2013; Casanueva et al., 2015; Su et al., 2016). However, as the dialogue state space increases, the number of possible trajectories needed to be ex∗ Currently at PolyAI, inigo@poly-ai.com 714 Proceedings of NAACL-HLT 2018, pages 714–719 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics and a primitive action is chosen from the previously selected subset. Our model does not require any modification of the reward function and the hierarchical architecture is fully specified by the structured database representation o"
N18-2112,W14-4337,0,0.399409,"k Abstract plored grows exponentially, making traditional RL methods not scalable to large domains. Hierarchical RL (HRL), in the form of temporal abstraction, has been proposed in order to mitigate this problem (Cuay´ahuitl et al., 2010, 2016; Budzianowski et al., 2017; Peng et al., 2017). However, proposed HRL methods require that the task is defined in a hierarchical structure, which is usually handcrafted. In addition, they usually require additional rewards for each subtask. Space abstraction, instead, has been successfully applied to dialogue tasks such as Dialogue State Tracking (DST) (Henderson et al., 2014b), and policy transfer between domains (Gaˇsi´c et al., 2013, 2015; Wang et al., 2015). For DST, a set of binary classifiers can be defined for each slot, with shared parameters, learning a general way to track slots. The policy transfer method presented in (Wang et al., 2015), named Domain Independent Parametrisation (DIP), transforms the belief state into a slot-dependent fixed size representation using a handcrafted feature function. This idea could also be applied to large domains, since it can be used to learn a general way to act in any slot. In slot-filling dialogues, a HRL method that"
N18-2112,W14-4340,0,0.157148,"k Abstract plored grows exponentially, making traditional RL methods not scalable to large domains. Hierarchical RL (HRL), in the form of temporal abstraction, has been proposed in order to mitigate this problem (Cuay´ahuitl et al., 2010, 2016; Budzianowski et al., 2017; Peng et al., 2017). However, proposed HRL methods require that the task is defined in a hierarchical structure, which is usually handcrafted. In addition, they usually require additional rewards for each subtask. Space abstraction, instead, has been successfully applied to dialogue tasks such as Dialogue State Tracking (DST) (Henderson et al., 2014b), and policy transfer between domains (Gaˇsi´c et al., 2013, 2015; Wang et al., 2015). For DST, a set of binary classifiers can be defined for each slot, with shared parameters, learning a general way to track slots. The policy transfer method presented in (Wang et al., 2015), named Domain Independent Parametrisation (DIP), transforms the belief state into a slot-dependent fixed size representation using a handcrafted feature function. This idea could also be applied to large domains, since it can be used to learn a general way to act in any slot. In slot-filling dialogues, a HRL method that"
N18-2112,W17-5512,1,0.804157,"Missing"
N18-2112,D17-1237,0,0.186662,"Missing"
N18-2112,W15-4603,1,0.858699,"without the need of any additional reward signal. 1 Introduction Task-oriented Spoken Dialogue Systems (SDS), in the form of personal assistants, have recently gained much attention in both academia and industry. One of the most important modules of a SDS is the Dialogue Manager (DM) (or policy), the module in charge of deciding the next action in each dialogue turn. Reinforcement Learning (RL) (Sutton and Barto, 1999) has been studied for several years as a promising approach to model dialogue management (Levin et al., 1998; Henderson et al., 2008; Pietquin et al., 2011; Young et al., 2013; Casanueva et al., 2015; Su et al., 2016). However, as the dialogue state space increases, the number of possible trajectories needed to be ex∗ Currently at PolyAI, inigo@poly-ai.com 714 Proceedings of NAACL-HLT 2018, pages 714–719 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics and a primitive action is chosen from the previously selected subset. Our model does not require any modification of the reward function and the hierarchical architecture is fully specified by the structured database representation of the system (i.e. the ontology), requiring no additional design. 2"
N18-2112,W15-4654,1,0.930822,"domains. Hierarchical RL (HRL), in the form of temporal abstraction, has been proposed in order to mitigate this problem (Cuay´ahuitl et al., 2010, 2016; Budzianowski et al., 2017; Peng et al., 2017). However, proposed HRL methods require that the task is defined in a hierarchical structure, which is usually handcrafted. In addition, they usually require additional rewards for each subtask. Space abstraction, instead, has been successfully applied to dialogue tasks such as Dialogue State Tracking (DST) (Henderson et al., 2014b), and policy transfer between domains (Gaˇsi´c et al., 2013, 2015; Wang et al., 2015). For DST, a set of binary classifiers can be defined for each slot, with shared parameters, learning a general way to track slots. The policy transfer method presented in (Wang et al., 2015), named Domain Independent Parametrisation (DIP), transforms the belief state into a slot-dependent fixed size representation using a handcrafted feature function. This idea could also be applied to large domains, since it can be used to learn a general way to act in any slot. In slot-filling dialogues, a HRL method that relies on space abstraction, such as Feudal RL (FRL) (Dayan and Hinton, 1993), should"
P10-1157,C00-1007,0,0.0274535,"the human gold standard with a fraction of the data. 1 Introduction The field of natural language generation (NLG) is one of the last areas of computational linguistics to embrace statistical methods. Over the past decade, statistical NLG has followed two lines of research. The first one, pioneered by Langkilde and Knight (1998), introduces statistics in the generation process by training a model which reranks candidate outputs of a handcrafted generator. While their HAL OGEN system uses an n-gram language model trained on news articles, other systems have used hierarchical syntactic models (Bangalore and Rambow, 2000), models trained on user ratings of ∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and funded by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). utterance quality (Walker et al., 2002), or alignment models trained on speaker-specific corpora (Isard et al., 2006). A second line of research has focused on introducing statistics at the generation decision level, by training models that find the set of generation parameters maximising an objective function, e.g. producing a target linguistic style (Paiva and Evans,"
P10-1157,N03-2002,0,0.00862214,"cross contexts. For example, if reject(area(centre)) was never observed at training time, P (r = centre of town|s = reject(area(centre))) will be estimated by backing off to P (r = centre of town|h = centre). BAGEL can thus generate ‘there are no venues in the centre of town’ if the phrase ‘centre of town’ was associated with the concept centre in a different context, such as inform(area(centre)). The final realisation model is illustrated in Fig. 2: (8) Conditional probability distributions are represented as factored language models smoothed using Witten-Bell interpolated backoff smoothing (Bilmes and Kirchhoff, 2003), according to the backoff graphs in Fig. 3. Variables which are the furthest away in time are dropped first, and partial stack variables are dropped last as they are observed the most. It is important to note that generating unseen semantic stacks requires all possible mandatory semantic stacks in the target domain to be predefined, in order for all stack unigrams to be assigned a smoothed non-zero probability. 3.2 High cardinality concept abstraction While one should expect a trainable generator to learn multiple lexical realisations for lowcardinality semantic concepts, learning lexical rea"
P10-1157,P10-1088,0,0.0145279,"A ++ did not perform well on our data—possibly because of the coarse granularity of our semantic representation—future work should evaluate the generalisation performance of synchronous CFGs in a dialogue system domain. Although we do not know of any work on active learning for NLG, previous work has used active learning for semantic parsing and information extraction (Thompson et al., 1999; Tang et al., 2002), spoken language understanding (Tur et al., 2003), speech recognition (Hakkani-T¨ur et al., 2002), word alignment (Sassano, 2002), and more recently for statistical machine translation (Bloodgood and Callison-Burch, 2010). While certaintybased methods have been widely used, future work should investigate the performance of committeebased active learning for NLG, in which examples are selected based on the level of disagreement between models trained on subsets of the data (Freund et al., 1997). 7 Discussion and conclusion This paper presents and evaluates BAGEL, a statistical language generator that can be trained entirely from data, with no handcrafting required beyond the semantic annotation. All the required subtasks—i.e. content ordering, aggregation, lexical selection and realisation—are learned from data"
P10-1157,P08-1022,0,0.0245612,"ith the mean informativeness score, over all folds of all systems tested (n = 70, p &lt; .01). This is lower than previous correlations reported by Reiter and Belz (2009) in the shipping forecast domain with nonexpert judges (r = .80), possibly because our domain is larger and more open to subjectivity. 6 Related work While most previous work on trainable NLG relies on a handcrafted component (see Section 1), recent research has started exploring fully datadriven NLG models. Factored language models have recently been used for surface realisation within the OpenCCG framework (White et al., 2007; Espinosa et al., 2008). More generally, chart generators for different grammatical formalisms have been trained from syntactic treebanks (White et al., 2007; Nakanishi et al., 2005), as well as from semantically-annotated treebanks (Varges and Mellish, 2001). However, a major difference with our approach is that BAGEL uses domain-specific data to generate a surface form directly from semantic concepts, without any syntactic annotation (see Section 7 for further discussion). 1559 This work is strongly related to Wong and Mooney’s WASP−1 generation system (2007), which combines a language model with an inverted synch"
P10-1157,W06-1405,0,0.0132302,"in the generation process by training a model which reranks candidate outputs of a handcrafted generator. While their HAL OGEN system uses an n-gram language model trained on news articles, other systems have used hierarchical syntactic models (Bangalore and Rambow, 2000), models trained on user ratings of ∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and funded by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). utterance quality (Walker et al., 2002), or alignment models trained on speaker-specific corpora (Isard et al., 2006). A second line of research has focused on introducing statistics at the generation decision level, by training models that find the set of generation parameters maximising an objective function, e.g. producing a target linguistic style (Paiva and Evans, 2005; Mairesse and Walker, 2008), generating the most likely context-free derivations given a corpus (Belz, 2008), or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2009). While such methods do not suffer from the computational cost of an overgeneration phase, they still require a handcrafted generator to define"
P10-1157,P98-1116,0,0.0278944,"rs. A human evaluation shows that BAGEL can generate natural and informative utterances from unseen inputs in the information presentation domain. Additionally, generation performance on sparse datasets is improved significantly by using certainty-based active learning, yielding ratings close to the human gold standard with a fraction of the data. 1 Introduction The field of natural language generation (NLG) is one of the last areas of computational linguistics to embrace statistical methods. Over the past decade, statistical NLG has followed two lines of research. The first one, pioneered by Langkilde and Knight (1998), introduces statistics in the generation process by training a model which reranks candidate outputs of a handcrafted generator. While their HAL OGEN system uses an n-gram language model trained on news articles, other systems have used hierarchical syntactic models (Bangalore and Rambow, 2000), models trained on user ratings of ∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and funded by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). utterance quality (Walker et al., 2002), or alignment models trained on spe"
P10-1157,N07-2038,1,0.673558,"inform: presenting information about a restaurant (see Table 1), and (b) reject: informing that the user’s constraints cannot be met (e.g., ‘There is no cheap restaurant in the centre’). Our domain contains 8 restaurant attributes: name, food, near, pricerange, postcode, phone, address, and area, out of which food, pricerange, and area are treated as enumerable.3 Our input semantic space is approximated by the set of information presentation dialogue acts produced over 20,000 simulated dialogues between our statistical dialogue manager (Young et al., 2010) and an agenda-based user simulator (Schatzmann et al., 2007), which results in 202 unique dialogue acts after replacing nonenumerable values by a generic symbol. Each dialogue act contains an average of 4.48 mandatory semantic stacks. As one of our objectives is to test whether BAGEL can learn from data provided by a large sample of untrained annotators, we collected a corpus of semantically-aligned utterances using Amazon’s Mechanical Turk data collection service. A crucial aspect of data collection for NLG is to ensure that the annotators understand the meaning of the semantics to be conveyed. Annotators were first asked to provide an utterance match"
P10-1157,P02-1016,0,0.022591,"m a meaning representation to natural language. WASP−1 relies on G IZA ++ to align utterances with derivations of the meaning representation (Och and Ney, 2003). Although early experiments showed that G IZA ++ did not perform well on our data—possibly because of the coarse granularity of our semantic representation—future work should evaluate the generalisation performance of synchronous CFGs in a dialogue system domain. Although we do not know of any work on active learning for NLG, previous work has used active learning for semantic parsing and information extraction (Thompson et al., 1999; Tang et al., 2002), spoken language understanding (Tur et al., 2003), speech recognition (Hakkani-T¨ur et al., 2002), word alignment (Sassano, 2002), and more recently for statistical machine translation (Bloodgood and Callison-Burch, 2010). While certaintybased methods have been widely used, future work should investigate the performance of committeebased active learning for NLG, in which examples are selected based on the level of disagreement between models trained on subsets of the data (Freund et al., 1997). 7 Discussion and conclusion This paper presents and evaluates BAGEL, a statistical language generat"
P10-1157,N01-1001,0,0.0909503,"possibly because our domain is larger and more open to subjectivity. 6 Related work While most previous work on trainable NLG relies on a handcrafted component (see Section 1), recent research has started exploring fully datadriven NLG models. Factored language models have recently been used for surface realisation within the OpenCCG framework (White et al., 2007; Espinosa et al., 2008). More generally, chart generators for different grammatical formalisms have been trained from syntactic treebanks (White et al., 2007; Nakanishi et al., 2005), as well as from semantically-annotated treebanks (Varges and Mellish, 2001). However, a major difference with our approach is that BAGEL uses domain-specific data to generate a surface form directly from semantic concepts, without any syntactic annotation (see Section 7 for further discussion). 1559 This work is strongly related to Wong and Mooney’s WASP−1 generation system (2007), which combines a language model with an inverted synchronous CFG parsing model, effectively casting the generation task as a translation problem from a meaning representation to natural language. WASP−1 relies on G IZA ++ to align utterances with derivations of the meaning representation ("
P10-1157,P08-1020,1,0.620959,"s trained on user ratings of ∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and funded by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). utterance quality (Walker et al., 2002), or alignment models trained on speaker-specific corpora (Isard et al., 2006). A second line of research has focused on introducing statistics at the generation decision level, by training models that find the set of generation parameters maximising an objective function, e.g. producing a target linguistic style (Paiva and Evans, 2005; Mairesse and Walker, 2008), generating the most likely context-free derivations given a corpus (Belz, 2008), or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2009). While such methods do not suffer from the computational cost of an overgeneration phase, they still require a handcrafted generator to define the generation decision space within which statistics can be used to find an optimal solution. This paper presents BAGEL (Bayesian networks for generation using active learning), an NLG system that can be fully trained from aligned data. While the main requirement of the generator is t"
P10-1157,2007.mtsummit-ucnlg.4,0,0.0979539,"ness score and .35 with the mean informativeness score, over all folds of all systems tested (n = 70, p &lt; .01). This is lower than previous correlations reported by Reiter and Belz (2009) in the shipping forecast domain with nonexpert judges (r = .80), possibly because our domain is larger and more open to subjectivity. 6 Related work While most previous work on trainable NLG relies on a handcrafted component (see Section 1), recent research has started exploring fully datadriven NLG models. Factored language models have recently been used for surface realisation within the OpenCCG framework (White et al., 2007; Espinosa et al., 2008). More generally, chart generators for different grammatical formalisms have been trained from syntactic treebanks (White et al., 2007; Nakanishi et al., 2005), as well as from semantically-annotated treebanks (Varges and Mellish, 2001). However, a major difference with our approach is that BAGEL uses domain-specific data to generate a surface form directly from semantic concepts, without any syntactic annotation (see Section 7 for further discussion). 1559 This work is strongly related to Wong and Mooney’s WASP−1 generation system (2007), which combines a language mode"
P10-1157,W05-1510,0,0.0239054,"Missing"
P10-1157,N07-1022,0,0.190551,"Missing"
P10-1157,J03-1002,0,0.0232322,". However, a major difference with our approach is that BAGEL uses domain-specific data to generate a surface form directly from semantic concepts, without any syntactic annotation (see Section 7 for further discussion). 1559 This work is strongly related to Wong and Mooney’s WASP−1 generation system (2007), which combines a language model with an inverted synchronous CFG parsing model, effectively casting the generation task as a translation problem from a meaning representation to natural language. WASP−1 relies on G IZA ++ to align utterances with derivations of the meaning representation (Och and Ney, 2003). Although early experiments showed that G IZA ++ did not perform well on our data—possibly because of the coarse granularity of our semantic representation—future work should evaluate the generalisation performance of synchronous CFGs in a dialogue system domain. Although we do not know of any work on active learning for NLG, previous work has used active learning for semantic parsing and information extraction (Thompson et al., 1999; Tang et al., 2002), spoken language understanding (Tur et al., 2003), speech recognition (Hakkani-T¨ur et al., 2002), word alignment (Sassano, 2002), and more r"
P10-1157,P05-1008,0,0.0178359,"nd Rambow, 2000), models trained on user ratings of ∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and funded by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). utterance quality (Walker et al., 2002), or alignment models trained on speaker-specific corpora (Isard et al., 2006). A second line of research has focused on introducing statistics at the generation decision level, by training models that find the set of generation parameters maximising an objective function, e.g. producing a target linguistic style (Paiva and Evans, 2005; Mairesse and Walker, 2008), generating the most likely context-free derivations given a corpus (Belz, 2008), or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2009). While such methods do not suffer from the computational cost of an overgeneration phase, they still require a handcrafted generator to define the generation decision space within which statistics can be used to find an optimal solution. This paper presents BAGEL (Bayesian networks for generation using active learning), an NLG system that can be fully trained from aligned data. While the main requi"
P10-1157,P02-1040,0,0.0991268,"m(type(restaurant)) inform(area) inform(area(riverside)) inform(area) inform inform(food) inform(food(French)) inform(food) END ht START X inform restaurant area riverside area inform food French food END lt START inform(name) EMPTY inform(type) inform inform(area) inform EMPTY inform inform(food) inform END Table 2: Example utterance annotation used to estimate the conditional probability distributions of the models in Figs. 1 and 2 ( rt =realisation phrase, st =semantic stack, ht =stack head, lt =stack tail). 5.2 BLEU score evaluation We first evaluate BAGEL using the BLEU automated metric (Papineni et al., 2002), which measures the word n-gram overlap between the generated utterances and the 2 reference paraphrases over a test corpus (with n up to 4). While BLEU suffers from known issues such as a bias towards statistical NLG systems (Reiter and Belz, 2009), it provides useful information when comparing similar systems. We evaluate BAGEL for different training set sizes, model dependencies, and active learning parameters. Our results are averaged over a 10-fold cross-validation over distinct dialogue acts, i.e. dialogue acts used for testing are not seen at training time,5 and all systems are tested"
P10-1157,J09-4008,0,0.0721372,"rm inform(area) inform EMPTY inform inform(food) inform END Table 2: Example utterance annotation used to estimate the conditional probability distributions of the models in Figs. 1 and 2 ( rt =realisation phrase, st =semantic stack, ht =stack head, lt =stack tail). 5.2 BLEU score evaluation We first evaluate BAGEL using the BLEU automated metric (Papineni et al., 2002), which measures the word n-gram overlap between the generated utterances and the 2 reference paraphrases over a test corpus (with n up to 4). While BLEU suffers from known issues such as a bias towards statistical NLG systems (Reiter and Belz, 2009), it provides useful information when comparing similar systems. We evaluate BAGEL for different training set sizes, model dependencies, and active learning parameters. Our results are averaged over a 10-fold cross-validation over distinct dialogue acts, i.e. dialogue acts used for testing are not seen at training time,5 and all systems are tested on the same folds. The training and test sets respectively contain an average of 181 and 21 distinct dialogue acts, and each dialogue act is associated with two paraphrases, resulting in 362 training utterances. 4 The normalisation process took aroun"
P10-1157,E09-1078,0,\N,Missing
P10-1157,P02-1064,0,\N,Missing
P10-1157,C98-1112,0,\N,Missing
P15-2130,P07-1056,0,0.0840533,"ks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, o"
P15-2130,W13-4071,0,0.0605453,"f tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex sem"
P15-2130,W13-4067,0,0.253377,"We believe that this work is the first to address the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speec"
P15-2130,W13-4073,1,0.727859,"2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in pa"
P15-2130,W14-4337,1,0.15618,"Missing"
P15-2130,W13-4065,0,0.0341703,"Missing"
P15-2130,W14-4340,1,0.809231,"state tracking component of a dialog system is responsible for interpreting the users’ utterances and thus updating the system’s belief state: a probability distribution over all possible states of the dialog. This belief state is used by the system to decide what to do next. Recurrent Neural Networks (RNNs) are well suited to dialog state tracking, as their ability to capture contextual information allows them to model and label complex dynamic sequences (Graves, 2012). In recent shared tasks, approaches based on {diarmuid, blaise}@vocaliq.com these models have shown competitive performance (Henderson et al., 2014d; Henderson et al., 2014c). This approach is particularly well suited to our goal of building open-domain dialog systems, as it does not require handcrafted domain-specific resources for semantic interpretation. We propose a method for training multi-domain RNN dialog state tracking models. Our hierarchical training procedure first uses all the data available to train a very general belief tracking model. This model learns the most frequent and general dialog features present across the various domains. The general model is then specialised for each domain, learning domain-specific behaviour"
P15-2130,W13-4066,0,0.0119824,"the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, a"
P15-2130,W13-4069,0,0.0115194,"omain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the"
P15-2130,W10-2607,0,0.0181402,"ing state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, our work is the first attempt to build a belief tracker capable of operating across disjoint dialog domains. 3 Dialog State Tracking using RNNs Belief tracking models capture use"
P15-2130,N06-1020,0,0.0101323,"; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output spa"
P15-2130,N10-1004,0,0.00780112,"ief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the s"
P15-2130,W14-4339,0,\N,Missing
P16-1230,W15-4653,1,0.73836,"Missing"
P16-1230,J11-1006,0,0.094076,"Missing"
P16-1230,P00-1013,0,0.664241,"Missing"
P16-1230,W15-4655,1,0.636188,"Missing"
P16-1230,P10-1040,0,0.0392136,"Missing"
P16-1230,W15-4649,1,0.866139,"Missing"
P16-1230,P97-1035,0,0.904945,"Missing"
P16-1230,W15-4603,0,\N,Missing
P17-4013,P17-1163,1,0.129908,"Missing"
P17-4013,P16-1230,1,0.713713,"Missing"
P17-4013,W14-4337,0,0.0162902,"odel for the CamRestaurants domain is provided. Evaluation To evaluate the dialogues, there are currently two success-based modules implemented. The objective task success evaluator compares the constraints and requests the system identifies with the true values. The latter may either be derived from the user simulator or, in real dialogues, by specifying a predefined task. For real dialogues, a subjective task success evaluator may also be applied which queries the user about the outcome of the dialogue. Belief Tracker For tracking the belief state, the rule-based focus tracker is available (Henderson et al., 2014). The implementation is domainindependent. All domain-specific information is drawn from the ontology. 4 www.apache.org/licenses/LICENSE-2.0 76 User Simulation The implementation of the simulated user uses the agenda-based user simulator (Schatzmann et al., 2006). The simulator contains the user model and an error model thus creating a n-best-list of user acts to simulate the noisy speech channel. By using a set of generally applicable parameters, the simulator may be applied for all domains. The domain-specific information is taken from the ontology. 4 training dialogues, the policies achieve"
P17-4013,N16-1015,1,0.253976,"Missing"
P17-4013,W16-3602,0,0.0466362,"ting algorithms (e.g., evaluating understanding or generation components in an interaction). Hence, to stimulate research and make it easy for people to get involved in statistical spoken dialogue systems, we present PyDial, a multi-domain statistical spoken dialogue system toolkit. PyDial is implemented in Python and is actively used by the Cambridge Dialogue Systems Group. PyDial supports multi-domain applications in which a conversation may range over a number of different topics. This introduces a variety of new research issues including generalised belief tracking (Mrkˇsi´c et al., 2015; Lee and Stent, 2016) rapid policy adaptation and parallel learning (Gaˇsi´c et al., 2015a,b) and natural language generation (Wen et al., 2016). Designing speech interfaces to machines has been a focus of research for many years. These Spoken Dialogue Systems (SDSs) are typically based on a modular architecture consisting of input processing modules speech recognition and semantic decoding, dialogue management modules belief tracking and policy, and output processing modules language generation and speech synthesis (see Fig. 1). Statistical SDS are speech interfaces where all SDS modules are based on statistical"
P17-4013,D15-1199,1,0.0538685,"Missing"
P17-4013,E17-1042,1,0.160833,"Missing"
P17-4013,P16-4012,0,0.0542417,", easy extensibility, and domain-independent implementations of the respective dialogue system modules. The toolkit is available for download under the Apache 2.0 license. Speech Synthesis Language Generation Belief State Policy et al., 2013; Wen et al., 2015; Su et al., 2016; Wen et al., 2017; Mrkˇsi´c et al., 2017). Despite the rich body of research on statistical SDS, there is still no common platform or open toolkit available. Other toolkit implementations usually focus on single modules (e.g. (Williams et al., 2010; Ultes and Minker, 2014) or are not full-blown statistical systems (e.g. (Lison and Kennington, 2016; Bohus and Rudnicky, 2009)). The availability of a toolkit targetted specifically at statistical dialogue systems would enable people new to the field would be able to get involved more easily, results to be compared more easily, and researchers to focus on their specific research questions instead of re-implementing algorithms (e.g., evaluating understanding or generation components in an interaction). Hence, to stimulate research and make it easy for people to get involved in statistical spoken dialogue systems, we present PyDial, a multi-domain statistical spoken dialogue system toolkit. P"
P17-4013,P15-2130,1,0.581038,"Missing"
P18-2069,W13-4067,0,0.456345,"Missing"
P18-2069,E17-1042,1,0.799449,"Missing"
P18-2069,Q15-1025,0,0.0211985,"y terms to compute the belief state distribution. In this way, the model parameters only learn to model the interactions between turn utterances and ontology terms in the semantic space, rather than the mapping from utterances to states. Consequently, information is shared between both slots and across domains. Additionally, the number of parameters does not increase with the ontology size. Domain tracking is considered as a separate task but is learned jointly with the belief state tracking of the slots and values. The proposed model uses semantically specialized pre-trained word embeddings (Wieting et al., 2015). To encode the user and system utterances, we employed 7 independent bi-directional LSTMs (Graves and Schmidhuber, 2005). Three of them are used to encode the system utterance for domain, slot and value tracking respectively. Similarly, three Bi-LSTMs encode the user utterance while and the last one is used to track the user affirmation. A variant of the CNNs as a feature extractor, similar to the one used in the NBT-CNN (Mrkˇsi´c et al., 2017) is also employed. In recent years, a plethora of research has been generated on belief tracking (Williams et al., 2016). For the purposes of this pape"
P18-2069,W14-4340,0,0.351031,"Update Since dialogue systems in the real-world operate in noisy environments, a robust BT should utilize the flow of the conversation to reduce the uncertainty in the belief state distribution. This can be achieved by passing the output of the decision maker, at each turn, as an input to an RNN that runs over the dialogue turns as shown in Figure 1, which allows the gradients to be propagated across turns. This alleviates the problem of tuning hyper-parameters for rule-based updates. To avoid the vanishing gradient problem, three networks were tested: a simple RNN, an RNN with a memory cell (Henderson et al., 2014a) and a LSTM. The RNN with a memory cell proved to give the best results. In addition to the fact that it reduces the vanishing gradient problem, this variant is less complex than an LSTM, which makes training easier. Furthermore, a variant of RNN used for domain tracking has all its weights of the form: Wi = αi I, where αi is a distinct learnable parameter for hidden, memory and previous state layers and I is the identity matrix. Similarly, weights of the RNN used to track the slots and values is of the form: Wj = γj I + λj (1 − I), where γj and λj are the learnable parameters. These two var"
P18-2069,W14-4339,0,0.34979,"Missing"
P18-2069,P14-1062,0,0.0366634,"ses a simple update rule, p(st ) = βp(st−1 ) + λy, where p(st ) is the belief state at time step t, y is the output of the binary decision maker of the NBT and β and λ are tunable parameters. The NBT leverages semantic information from the word embeddings to resolve lexical/morphological ambiguity and maximize the shared parameters across the values of each slot. However, it only applies to a single domain and does not share parameters across slots. 433 Figure 1: The proposed model architecture, using Bi-LSTMs as encoders. Other variants of the model use CNNs as feature extractors (Kim, 2014; Kalchbrenner et al., 2014). 4.1 4.2 Domain Tracking Figure 1 presents the system architecture with two bi-directional LSTM networks as information encoders running over the word embeddings of the user and system utterances. The last hidden states of the forward and backward layers are concatenated to produce hdusr , hdsys of size L for the user and system utterances respectively. In the second variant of the model, CNNs are used to produce these vectors (Kim, 2014; Kalchbrenner et al., 2014). To detect the presence of the domain in the dialogue turn, element-wise multiplication is used as a similarity metric between th"
P18-2069,D14-1181,0,0.00396815,"slot. It uses a simple update rule, p(st ) = βp(st−1 ) + λy, where p(st ) is the belief state at time step t, y is the output of the binary decision maker of the NBT and β and λ are tunable parameters. The NBT leverages semantic information from the word embeddings to resolve lexical/morphological ambiguity and maximize the shared parameters across the values of each slot. However, it only applies to a single domain and does not share parameters across slots. 433 Figure 1: The proposed model architecture, using Bi-LSTMs as encoders. Other variants of the model use CNNs as feature extractors (Kim, 2014; Kalchbrenner et al., 2014). 4.1 4.2 Domain Tracking Figure 1 presents the system architecture with two bi-directional LSTM networks as information encoders running over the word embeddings of the user and system utterances. The last hidden states of the forward and backward layers are concatenated to produce hdusr , hdsys of size L for the user and system utterances respectively. In the second variant of the model, CNNs are used to produce these vectors (Kim, 2014; Kalchbrenner et al., 2014). To detect the presence of the domain in the dialogue turn, element-wise multiplication is used as a"
P18-2069,P17-1163,0,0.674945,"Missing"
P18-2069,P18-2018,0,0.525009,"Missing"
Q17-1022,S15-1003,0,0.0166028,"scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexical information into pretrained collections of word vectors. Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and"
Q17-1022,Q16-1031,0,0.0184747,"gual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train distributed representations ‘from scratch’ by co"
Q17-1022,P98-1013,0,0.0636087,"gue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train distributed representations ‘from scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexical information into pretrained collections of word vectors. Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating"
Q17-1022,P14-2131,0,0.0313084,"ract-repel. These include: 1) the ATTRACTR EPEL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories:"
Q17-1022,D14-1082,0,0.0239881,"lude: 1) the ATTRACTR EPEL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train dis"
Q17-1022,P06-1038,0,0.011388,"enson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and distributional data to train embeddings specialized for capturing antonymy. Faruqui and Dyer (2015) use many different lexicons to create interpretable sparse binary vectors which achieve competitive performance across a range of intrinsic evaluation tasks. In theory, word representations produced by models which consider distributional and lexical information jointly could be as good (or better) than representations produced by fine-tuning distributional vecto"
Q17-1022,P14-1129,0,0.0264494,"Missing"
Q17-1022,D16-1136,0,0.0135803,"differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al., 2013a; Gouws et al., 2015; Duong et al., 2016), cross-lingual information retrieval (Vuli´c and Moens, 2015; Mitra et al., 2016), and transfer learning for reso"
Q17-1022,ehrmann-etal-2014-representing,0,0.0525517,"ural language processing. The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; Ó Séaghdha and Korhonen, 2014; Levy and Goldberg, 2014). Recently, methods that go beyond stand-alone unsupervised learning have gained increased popularity. We then deploy the ATTRACT-R EPEL algorithm in a multilingual setting, using semantic relations extracted from BabelNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014), a cross-lingual lexical resource, to inject constraints between words of different languages into the word representations. This allows us to embed vector spaces of multiple languages into a single vector space, exploiting information from high-resource languages to improve the word representations of lower-resource ones. Table 1 illustrates the effects of cross-lingual ATTRACT-R EPEL specialization by showing the nearest neighbors for three English words across three cross-lingual spaces. 309 Transactions of the Association for Computational Linguistics, vol. 5, pp. 309–324, 2017. Action Ed"
Q17-1022,E14-1049,0,0.359731,"al., 2013; Soyer et al., 2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al., 2013a; Gouws et al., 2015; Duong et al., 2016), cross-lingual information retrieval (Vu"
Q17-1022,P15-2076,0,0.0360459,"borne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and distributional data to train embeddings specialized for capturing antonymy. Faruqui and Dyer (2015) use many different lexicons to create interpretable sparse binary vectors which achieve competitive performance across a range of intrinsic evaluation tasks. In theory, word representations produced by models which consider distributional and lexical information jointly could be as good (or better) than representations produced by fine-tuning distributional vectors. However, their performance has not surpassed that of fine-tuning methods.3 Fine-Tuning Pre-trained Vectors Rothe and Schütze (2015) fine-tune word vector spaces to improve the representations of synsets/lexemes found in WordNet. F"
Q17-1022,N15-1184,0,0.532158,"s using Monolingual and Cross-Lingual Constraints Nikola Mrkši´c1,2 , Ivan Vuli´c1 , Diarmuid Ó Séaghdha2 , Ira Leviant3 Roi Reichart3 , Milica Gaši´c1 , Anna Korhonen1 , Steve Young1,2 1 University of Cambridge 2 Apple Inc. 3 Technion, IIT Abstract These models typically build on distributional ones by using human- or automatically-constructed knowledge bases to enrich the semantic content of existing word vector collections. Often this is done as a postprocessing step, where the distributional word vectors are refined to satisfy constraints extracted from a lexical resource such as WordNet (Faruqui et al., 2015; Wieting et al., 2015; Mrkši´c et al., 2016). We term this approach semantic specialization. We present ATTRACT-R EPEL, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. ATTRACT-R EPEL facilitates the use of constraints from mono- and crosslingual resources, yielding semantically specialized cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct highquality vector spaces for a plethora of different languages, facilitating semantic transfer from high-"
Q17-1022,ganitkevitch-callison-burch-2014-multilingual,0,0.0509444,"Missing"
Q17-1022,N13-1092,0,0.0261119,"Missing"
Q17-1022,D16-1235,1,0.905072,"Missing"
Q17-1022,D14-1012,0,0.0360428,"tion datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train distributed representations ‘from scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexical information into"
Q17-1022,P15-1119,0,0.0296068,"Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al., 2013a; Gouws et al., 2015; Duong et al., 2016), cross-lingual information retrieval (Vuli´c and Moens, 2015; Mitra et al., 2016), and transfer learning for resource-lean languages (Søgaard et al., 2015; Guo et al., 2015). However, prior work on cross-lingual word embedding has tended not to exploit pre-existing linguistic resources such as BabelNet. In this work, we make use of cross-lingual constraints derived from such repositories to induce high-quality cross-lingual vector spaces by facilitating semantic transfer from highto lower-resource languages. In our experiments, we show that cross-lingual vector spaces produced by ATTRACT-R EPEL consistently outperform a representative selection of five strong cross-lingual word embedding models in both intrinsic and extrinsic evaluation across several languages."
Q17-1022,W14-4337,0,0.0396757,"re expressed by slot-value pairs such as [price: cheap] or [food: Thai]. For modular task-based systems, the Dialogue State Tracking (DST) component is in charge of maintaining the belief state, which is the system’s internal distribution over the possible states of the dialogue. Figure 1 shows the correct dialogue state for each turn of an example dialogue. Unseen Data/Labels As dialogue ontologies can be very large, many of the possible class labels (i.e., the various food types or street names) will not occur in the training set. To overcome this problem, delexicalization-based DST models (Henderson et al., 2014c; Henderson et al., 2014b; Mrkši´c et al., 2015; Wen et al., 2017) replace occurrences of ontology values with generic tags which facilitate transfer learning across different ontology values. This is done through exact matching supplemented with semantic lexicons which encode rephrasings, morphology and other linguistic variation. For instance, such lexicons would be required to deal with the underlined non-exact matches in Figure 1. Exact Matching as a Bottleneck Semantic lexicons can be hand-crafted for small dialogue domains. Mrkši´c et al. (2016) showed that semantically specialized vect"
Q17-1022,W14-4340,1,0.938481,"re expressed by slot-value pairs such as [price: cheap] or [food: Thai]. For modular task-based systems, the Dialogue State Tracking (DST) component is in charge of maintaining the belief state, which is the system’s internal distribution over the possible states of the dialogue. Figure 1 shows the correct dialogue state for each turn of an example dialogue. Unseen Data/Labels As dialogue ontologies can be very large, many of the possible class labels (i.e., the various food types or street names) will not occur in the training set. To overcome this problem, delexicalization-based DST models (Henderson et al., 2014c; Henderson et al., 2014b; Mrkši´c et al., 2015; Wen et al., 2017) replace occurrences of ontology values with generic tags which facilitate transfer learning across different ontology values. This is done through exact matching supplemented with semantic lexicons which encode rephrasings, morphology and other linguistic variation. For instance, such lexicons would be required to deal with the underlined non-exact matches in Figure 1. Exact Matching as a Bottleneck Semantic lexicons can be hand-crafted for small dialogue domains. Mrkši´c et al. (2016) showed that semantically specialized vect"
Q17-1022,P14-1006,0,0.0667397,"ts models with state-of-the-art performance, none of which learn representations jointly. 2.2 Cross-Lingual Word Representations Most existing models which induce cross-lingual word representations rely on cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Soyer et al., 2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual"
Q17-1022,J15-4004,1,0.925417,"multilingual DST models, which brings further performance improvements. 1 In this paper we advance the semantic specialization paradigm in a number of ways. We introduce a new algorithm, ATTRACT-R EPEL, that uses synonymy and antonymy constraints drawn from lexical resources to tune word vector spaces using linguistic information that is difficult to capture with conventional distributional training. Our evaluation shows that ATTRACT-R EPEL outperforms previous methods which make use of similar lexical resources, achieving state-of-the-art results on two word similarity datasets: SimLex-999 (Hill et al., 2015) and SimVerb-3500 (Gerz et al., 2016). Introduction Word representation learning has become a research area of central importance in modern natural language processing. The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; Ó Séaghdha and Korhonen, 2014; Levy and Goldberg, 2014). Recently, methods that go beyond stand-alone unsupervised learning have gained increased popularity. We the"
Q17-1022,D15-1127,0,0.0127607,"our method to use existing cross-lingual resources to tie distributional vector spaces of different languages into a unified vector space which benefits from positive semantic transfer between its constituent languages. 3 The SimLex-999 web page (www.cl.cam.ac.uk/ ~fh295/simlex.html) lists models with state-of-the-art performance, none of which learn representations jointly. 2.2 Cross-Lingual Word Representations Most existing models which induce cross-lingual word representations rely on cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Soyer et al., 2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; V"
Q17-1022,D14-1070,0,0.0192932,"chart, 2015). To show that our approach yields semantically informative vectors for lower-resource languages, we collect intrinsic evaluation datasets for Hebrew and Croatian and show that cross-lingual specialization significantly improves word vector quality in these two (comparatively) low-resource languages. In the second part of the paper, we explore the use of ATTRACT-R EPEL-specialized vectors in a downstream application. One important motivation for training word vectors is to improve the lexical coverage of supervised models for language understanding tasks, e.g., question answering (Iyyer et al., 2014) or textual entailment (Rocktäschel et al., 2016). In 1 Some (negative) effects of the distributional hypothesis do persist. For example, nl_krieken (Dutch for cherries), is identified as a synonym for en_morning, presumably because the idiom ‘het krieken van de dag’ translates to ‘the crack of dawn’. 2 Our approach is not suited for languages for which no lexical resources exist. However, many languages have some coverage in cross-lingual lexicons. For instance, BabelNet 3.7 automatically aligns WordNet to Wikipedia, providing accurate cross-lingual mappings between 271 languages. In our eval"
Q17-1022,N15-1070,0,0.0340476,"ons to create interpretable sparse binary vectors which achieve competitive performance across a range of intrinsic evaluation tasks. In theory, word representations produced by models which consider distributional and lexical information jointly could be as good (or better) than representations produced by fine-tuning distributional vectors. However, their performance has not surpassed that of fine-tuning methods.3 Fine-Tuning Pre-trained Vectors Rothe and Schütze (2015) fine-tune word vector spaces to improve the representations of synsets/lexemes found in WordNet. Faruqui et al. (2015) and Jauhar et al. (2015) use synonymy constraints in a procedure termed retrofitting to bring the vectors of semantically similar words close together, while Wieting et al. (2015) modify the skip-gram objective function to fine-tune word vectors by injecting paraphrasing constraints from PPDB. Mrkši´c et al. (2016) build on the retrofitting approach by jointly injecting synonymy and antonymy constraints; the same idea is reassessed by Nguyen et al. (2016). Kim et al. (2016a) further expand this line of work by incorporating semantic intensity information for the constraints, while Recski et al. (2016) use ensembles o"
Q17-1022,D15-1245,0,0.0248451,"EL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train distributed representations"
Q17-1022,D15-1242,0,0.0418903,"epresentations ‘from scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexical information into pretrained collections of word vectors. Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use sy"
Q17-1022,W16-1607,0,0.169112,"Missing"
Q17-1022,C12-1089,0,0.0230184,"eover, we show that starting from distributional vectors allows our method to use existing cross-lingual resources to tie distributional vector spaces of different languages into a unified vector space which benefits from positive semantic transfer between its constituent languages. 3 The SimLex-999 web page (www.cl.cam.ac.uk/ ~fh295/simlex.html) lists models with state-of-the-art performance, none of which learn representations jointly. 2.2 Cross-Lingual Word Representations Most existing models which induce cross-lingual word representations rely on cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Soyer et al., 2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al."
Q17-1022,2005.mtsummit-papers.11,0,0.0253673,"into a shared cross-lingual space. Ideally, sharing information across languages should lead to improved semantic content for each language, especially for those with limited monolingual resources. Antonymy BabelNet is also used to extract both monolingual and cross-lingual antonymy constraints. Following Faruqui et al. (2015), who found PPDB constraints more beneficial than the WordNet ones, we do not use BabelNet for monolingual synonymy. Availability of Resources Both PPDB and BabelNet are created automatically. However, PPDB relies on large, high-quality parallel corpora such as Europarl (Koehn, 2005). In total, Multilingual PPDB provides collections of paraphrases for 22 languages. On the other hand, BabelNet uses Wikipedia’s interlanguage links and statistical machine translation (Google Translate) to provide cross-lingual mappings for 271 languages. In our evaluation, we show that PPDB and BabelNet can be used jointly to improve word representations for lower-resource languages by tying them into bilingual spaces with high-resource ones. We validate this claim on Hebrew and Croatian, which act as ‘lower-resource’ languages because of their lack of any PPDB resource and their relatively"
Q17-1022,P15-1027,0,0.0203234,"2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al., 2013a; Gouws et al., 2015; Duong et al., 2016), cross-lingual information retrieval (Vuli´c and Moens, 2015; Mi"
Q17-1022,P14-2050,0,0.10357,"use of similar lexical resources, achieving state-of-the-art results on two word similarity datasets: SimLex-999 (Hill et al., 2015) and SimVerb-3500 (Gerz et al., 2016). Introduction Word representation learning has become a research area of central importance in modern natural language processing. The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; Ó Séaghdha and Korhonen, 2014; Levy and Goldberg, 2014). Recently, methods that go beyond stand-alone unsupervised learning have gained increased popularity. We then deploy the ATTRACT-R EPEL algorithm in a multilingual setting, using semantic relations extracted from BabelNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014), a cross-lingual lexical resource, to inject constraints between words of different languages into the word representations. This allows us to embed vector spaces of multiple languages into a single vector space, exploiting information from high-resource languages to improve the word representations of lower-resource ones. T"
Q17-1022,P15-1145,0,0.0286255,"Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and d"
Q17-1022,W15-1521,0,0.0244293,". 3 The SimLex-999 web page (www.cl.cam.ac.uk/ ~fh295/simlex.html) lists models with state-of-the-art performance, none of which learn representations jointly. 2.2 Cross-Lingual Word Representations Most existing models which induce cross-lingual word representations rely on cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Soyer et al., 2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shar"
Q17-1022,P15-2130,1,0.34097,"Missing"
Q17-1022,N16-1018,1,0.276948,"Missing"
Q17-1022,P17-1163,1,0.07397,"Missing"
Q17-1022,P16-2074,0,0.108128,"-trained Vectors Rothe and Schütze (2015) fine-tune word vector spaces to improve the representations of synsets/lexemes found in WordNet. Faruqui et al. (2015) and Jauhar et al. (2015) use synonymy constraints in a procedure termed retrofitting to bring the vectors of semantically similar words close together, while Wieting et al. (2015) modify the skip-gram objective function to fine-tune word vectors by injecting paraphrasing constraints from PPDB. Mrkši´c et al. (2016) build on the retrofitting approach by jointly injecting synonymy and antonymy constraints; the same idea is reassessed by Nguyen et al. (2016). Kim et al. (2016a) further expand this line of work by incorporating semantic intensity information for the constraints, while Recski et al. (2016) use ensembles of rich concept dictionaries to further improve a combined collection of semantically specialized word vectors. ATTRACT-R EPEL is an instance of the second family of models, providing a portable, light-weight approach for incorporating external knowledge into arbitrary vector spaces. In our experiments, we show that ATTRACT-R EPEL outperforms previously proposed post-processors, setting the new state-of-art performance on the widely"
Q17-1022,N15-1100,0,0.0338437,"ducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and distributional data to train embeddings specialized for capturing antonymy. Faruqui and Dyer (2015) use many different lexicons to create interpretable sparse binary vectors which achieve competitive performance across a range of intrinsic evaluation tasks. In theory, word representations produced by models which consider distributional and lexical information jointly could be as good (or better) than representations produced by fine-tuning distributional vectors. However, their performance has not surpassed that of fine-tuning methods.3 Fine-Tunin"
Q17-1022,Q16-1030,0,0.48294,"de WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and distributional data to train embeddings specialized for capturing antonymy. Faruqui and Dyer (2"
Q17-1022,D14-1162,0,0.11428,"t ATTRACT-R EPEL outperforms previous methods which make use of similar lexical resources, achieving state-of-the-art results on two word similarity datasets: SimLex-999 (Hill et al., 2015) and SimVerb-3500 (Gerz et al., 2016). Introduction Word representation learning has become a research area of central importance in modern natural language processing. The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; Ó Séaghdha and Korhonen, 2014; Levy and Goldberg, 2014). Recently, methods that go beyond stand-alone unsupervised learning have gained increased popularity. We then deploy the ATTRACT-R EPEL algorithm in a multilingual setting, using semantic relations extracted from BabelNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014), a cross-lingual lexical resource, to inject constraints between words of different languages into the word representations. This allows us to embed vector spaces of multiple languages into a single vector space, exploiting information from high-resource languages to i"
Q17-1022,N15-1058,0,0.0309108,"Missing"
Q17-1022,W16-1622,0,0.0658587,"al. (2015) and Jauhar et al. (2015) use synonymy constraints in a procedure termed retrofitting to bring the vectors of semantically similar words close together, while Wieting et al. (2015) modify the skip-gram objective function to fine-tune word vectors by injecting paraphrasing constraints from PPDB. Mrkši´c et al. (2016) build on the retrofitting approach by jointly injecting synonymy and antonymy constraints; the same idea is reassessed by Nguyen et al. (2016). Kim et al. (2016a) further expand this line of work by incorporating semantic intensity information for the constraints, while Recski et al. (2016) use ensembles of rich concept dictionaries to further improve a combined collection of semantically specialized word vectors. ATTRACT-R EPEL is an instance of the second family of models, providing a portable, light-weight approach for incorporating external knowledge into arbitrary vector spaces. In our experiments, we show that ATTRACT-R EPEL outperforms previously proposed post-processors, setting the new state-of-art performance on the widely used SimLex-999 word similarity dataset. Moreover, we show that starting from distributional vectors allows our method to use existing cross-lingual"
Q17-1022,P15-1173,0,0.0714818,"Missing"
Q17-1022,K15-1026,1,0.312629,"al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and distributional data to train embeddings specialized for capturing antonymy. Faruqui and Dyer (2015) use many different lexicons to create interpretable sparse binary vectors which achieve competitive performance across a range of intrinsic evaluation tasks. In theory, word representations produced by models which consider distributional and lexical information jointly could be as good (or better) than represe"
Q17-1022,P13-1045,0,0.0159713,"ithub.com/nmrksic/ attract-repel. These include: 1) the ATTRACTR EPEL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly)"
Q17-1022,D13-1170,0,0.0047346,"ithub.com/nmrksic/ attract-repel. These include: 1) the ATTRACTR EPEL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly)"
Q17-1022,P15-1165,0,0.0197866,"Missing"
Q17-1022,P10-1040,0,0.0185912,"tian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train distributed representations ‘from scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexica"
Q17-1022,P16-1157,0,0.028014,"ual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al., 2013a; Gouws et al., 2015; Duong et al., 2016), cross-lingual information retrieval (Vuli´c and Moens, 2015; Mitra et al., 2016), and transfer learning for resource-lean languages (Søgaard"
Q17-1022,P16-2084,1,0.84249,"Missing"
Q17-1022,P16-1024,1,0.758571,"Missing"
Q17-1022,E17-1042,1,0.780077,"Missing"
Q17-1022,Q15-1025,0,0.116195,"d Cross-Lingual Constraints Nikola Mrkši´c1,2 , Ivan Vuli´c1 , Diarmuid Ó Séaghdha2 , Ira Leviant3 Roi Reichart3 , Milica Gaši´c1 , Anna Korhonen1 , Steve Young1,2 1 University of Cambridge 2 Apple Inc. 3 Technion, IIT Abstract These models typically build on distributional ones by using human- or automatically-constructed knowledge bases to enrich the semantic content of existing word vector collections. Often this is done as a postprocessing step, where the distributional word vectors are refined to satisfy constraints extracted from a lexical resource such as WordNet (Faruqui et al., 2015; Wieting et al., 2015; Mrkši´c et al., 2016). We term this approach semantic specialization. We present ATTRACT-R EPEL, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. ATTRACT-R EPEL facilitates the use of constraints from mono- and crosslingual resources, yielding semantically specialized cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct highquality vector spaces for a plethora of different languages, facilitating semantic transfer from high- to lower-resource one"
Q17-1022,D16-1157,0,0.0166515,"nsfer (+0.19 / +0.11 over monolingual specialization), with Italian vectors’ performance coming close to the top-performing English ones. 316 Comparison to Baselines Table 3 gives an exhaustive comparison of ATTRACT-R EPEL to counterfitting: ATTRACT-R EPEL achieved substantially stronger performance in all experiments. We believe these results conclusively show that the contextsensitive updates and L2 regularization employed by ATTRACT-R EPEL present a better alternative to the context-insensitive attract/repel terms and pair-wise regularization employed by counter-fitting.11 State-of-the-Art Wieting et al. (2016) note that the hyperparameters of the widely used Paragram-SL999 vectors (Wieting et al., 2015) are tuned on SimLex999, and as such are not comparable to methods which hold out the dataset. This implies that further work which uses these vectors (e.g., (Mrkši´c et al., 11 To understand the relative importance of the contextsensitive updates and the change in regularization, we can compare the two methods to the retrofitting procedure (Faruqui et al., 2015). Retrofitting uses L2 regularization (like ATTRACTR EPEL) and a ‘global’ attract term (like counter-fitting). The performance of retrofitti"
Q17-1022,D12-1111,0,0.0614025,"Missing"
Q17-1022,P14-2089,0,0.0246193,") into two categories: a) those which train distributed representations ‘from scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexical information into pretrained collections of word vectors. Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches s"
Q17-1022,D13-1141,0,0.0291883,"rce-intensive. All resources related to this paper are available at www.github.com/nmrksic/ attract-repel. These include: 1) the ATTRACTR EPEL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical enta"
Q17-1022,J14-3005,1,\N,Missing
Q17-1022,C98-1013,0,\N,Missing
W08-0119,2007.sigdial-1.37,0,0.0521487,"Missing"
W08-0119,P00-1013,0,0.016619,"ilding spoken dialogue systems which can both model these uncertainties and support policies which are robust to their effects (Young, 2002; Williams and Young, 2007a). The key idea of the POMDP is that the underlying dialogue state is hidden and dialogue management policies must therefore be based not on a single state estimate but on a distribution over all states. Whilst POMDPs are attractive theoretically, in practice, they are notoriously intractable for anything other than small state/action spaces. Hence, practical examples of their use were initially restricted to very simple domains (Roy et al., 2000; Zhang et al., 2001). More recently, however, a number of techniques have been suggested which do allow POMDPs to be scaled to handle real world tasks. The two generic mechanisms which facilitate this scaling are factoring the state space and performing policy optimisation in a reduced summary state space (Williams and Young, 2007a; Williams and Young, 2007b). Based on these ideas, a number of real-world POMDP-based systems have recently emerged. The most complex entity which must be represented in the state space is the user’s goal. In the Bayesian Update of Dialogue State (BUDS) system, the"
W08-0119,W07-0302,1,0.715176,"malisation constant (Kaelbling et al., 1998). The first term on the RHS of (1) is called the observation model and the term inside the summation is called the transition model. Maintaining this belief state as the dialogue evolves is called belief monitoring. sd Speech Understanding 1 au au Belief Estimator .. (Bui et al., 2007a; Bui et al., 2007b). An alternative approach taken in the Hidden Information State (HIS) system is to retain a complete representation of the user’s goal, but partition states into equivalence classes and prune away very low probability partitions (Young et al., 2007; Thomson et al., 2007; Williams and Young, 2007b). Whichever approach is taken, a key issue in a real POMDP-based dialogue system is its ability to be robust to noise and that is the issue that is addressed in this paper. Using the HIS system as an exemplar, evaluation results are presented for a real-world tourist information task using both simulated and real users. The results show that a POMDP system can learn noise robust policies and that N-best outputs from the speech understanding component can be exploited to further improve robustness. The paper is structured as follows. Firstly, in Section 2 a brief ove"
W09-3938,N07-2038,1,0.813235,"y Space Master Space The CUED Spoken Dialogue System Grnd UInfo ... affirm(...) Uinfo UInfo ... inform(...) b(1) ... Add items from hyp 1 Yes b(2) p h last status status uact Policy Compatible with hyp 1? No Try next Sort Figure 1: Master-summary Space Mapping. moving all act items and leaving only a reduced set of dialogue act types. When mapping back into master space, the necessary items (i.e. slot-value pairs) are inferred by inspecting the most likely dialogue state hypotheses. The optimal policy is obtained using reinforcement learning in interaction with an agenda based simulated user (Schatzmann et al., 2007). At the end of each dialogue a reward is given to the system: +20 for a successful completion and -1 for each turn. A grid-based optimisation is used to obtain the optimal policy (see next section). At each turn the belief is mapped to a summary point from which a summary action can be determined. The summary action is then mapped back to a master action by adding the relevant information. HIS Dialogue Manager The unobserved dialogue state of the HIS dialogue manager consists of the user goal, the dialogue history and the user action. The user goal is represented by a partition which is a tre"
W10-4323,N07-2038,1,0.614261,"er to generate a sufficiently large number of interactions to learn from, this effectiveness depends largely on the quality of such a user simulator. An important requirement for a simulator is for it to be realistic, i.e., it should generate behaviour that is similar to that of real users. Trained policies are then more likely to perform better on real users, and evaluation results on simulated data are more likely to predict results on real data more accurately. 2 Agenda-based user simulation In agenda-based user simulation, user acts are generated on the basis of a user goal and an agenda (Schatzmann et al., 2007a). The simulator presented here is developed and used for a tourist in∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 116–123, c The University of Tokyo, September 24-25, 2010. 2010 Association for Computational Linguistics 116 formation application, but is sufficiently generic to accommodate slot-filling applications in any domain.1 The user"
W10-4323,2007.sigdial-1.48,1,0.95671,"er to generate a sufficiently large number of interactions to learn from, this effectiveness depends largely on the quality of such a user simulator. An important requirement for a simulator is for it to be realistic, i.e., it should generate behaviour that is similar to that of real users. Trained policies are then more likely to perform better on real users, and evaluation results on simulated data are more likely to predict results on real data more accurately. 2 Agenda-based user simulation In agenda-based user simulation, user acts are generated on the basis of a user goal and an agenda (Schatzmann et al., 2007a). The simulator presented here is developed and used for a tourist in∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 116–123, c The University of Tokyo, September 24-25, 2010. 2010 Association for Computational Linguistics 116 formation application, but is sufficiently generic to accommodate slot-filling applications in any domain.1 The user"
W12-1609,W09-3902,0,0.0733392,"Missing"
W12-1609,E09-1081,0,0.0278828,"Missing"
W13-4035,W10-4323,1,0.713546,"Missing"
W13-4035,P99-1024,0,0.0861553,"ing Department {mg436,cb404,mh521,dk449,mos25,brmt2,pt344,sjy}@eng.cam.ac.uk Abstract restaurant where I can eat outside”. In order to make this possible, techniques will be needed to extend and adapt existing dialogue policies. Adaptation can be viewed as a process of improving action selection in a different condition to the one in which the policy was originally trained. While adaptation has been extensively studied in speech recognition (see an overview in (Gales and Young, 2007)), in spoken dialogue systems it is still relatively novel and covers a wide range of possible research topics (Litman and Pan, 1999; Litman and Pan, 2002; Georgila and Lemon, 2004; Janarthanam and Lemon, 2010). A recent trend in statistical dialogue modelling has been to model dialogue as a partially observable Markov decision process (POMDP). This provides increased robustness to errors in speech understanding and automatic dialogue policy optimisation via reinforcement learning (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007; Young et al., 2010; Thomson and Young, 2010). A POMDP-based dialogue manager maintains a distribution over every possible dialogue state at every dialogue turn. This is called the b"
W13-4035,W10-4334,1,0.899559,"Missing"
W13-4035,P00-1013,0,0.0644165,". While adaptation has been extensively studied in speech recognition (see an overview in (Gales and Young, 2007)), in spoken dialogue systems it is still relatively novel and covers a wide range of possible research topics (Litman and Pan, 1999; Litman and Pan, 2002; Georgila and Lemon, 2004; Janarthanam and Lemon, 2010). A recent trend in statistical dialogue modelling has been to model dialogue as a partially observable Markov decision process (POMDP). This provides increased robustness to errors in speech understanding and automatic dialogue policy optimisation via reinforcement learning (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007; Young et al., 2010; Thomson and Young, 2010). A POMDP-based dialogue manager maintains a distribution over every possible dialogue state at every dialogue turn. This is called the belief state. Based on that distribution the system chooses the action that gives the highest expected reward, measured by the Q-function. The Q-function for a belief state and an action is the expected cumulative reward that can be obtained if that action is taken in that belief state. The optimisation typically requires O(105 ) to O(106 ) dialogues, so is normally don"
W13-4035,W10-4324,0,0.0246016,".ac.uk Abstract restaurant where I can eat outside”. In order to make this possible, techniques will be needed to extend and adapt existing dialogue policies. Adaptation can be viewed as a process of improving action selection in a different condition to the one in which the policy was originally trained. While adaptation has been extensively studied in speech recognition (see an overview in (Gales and Young, 2007)), in spoken dialogue systems it is still relatively novel and covers a wide range of possible research topics (Litman and Pan, 1999; Litman and Pan, 2002; Georgila and Lemon, 2004; Janarthanam and Lemon, 2010). A recent trend in statistical dialogue modelling has been to model dialogue as a partially observable Markov decision process (POMDP). This provides increased robustness to errors in speech understanding and automatic dialogue policy optimisation via reinforcement learning (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007; Young et al., 2010; Thomson and Young, 2010). A POMDP-based dialogue manager maintains a distribution over every possible dialogue state at every dialogue turn. This is called the belief state. Based on that distribution the system chooses the action that giv"
W14-4336,P13-1123,1,0.850652,"Missing"
W14-4336,W13-4026,1,0.906157,"LG) components. We demonstrate a mobile application in English and Mandarin to test and evaluate components of the Parlance dialogue system for interactive search under real-world conditions. 1 Introduction With the advent of evaluations “in the wild”, emphasis is being put on converting research prototypes into mobile applications that can be used for evaluation and data collection by real users downloading the application from the market place. This is the motivation behind the work demonstrated here where we present a modular framework whereby research components from the Parlance project (Hastie et al., 2013) can be plugged in, tested and evaluated in a mobile environment. The goal of Parlance is to perform interactive search through speech in multiple languages. The domain for the demonstration system is interactive search for restaurants in Cambridge, UK for Mandarin and San Francisco, USA for English. The scenario is that Mandarin speaking tourists would be able to download the application and use it to learn about restaurants in English speaking towns and cities. 2 Figure 1: Overview of the Parlance Mandarin mobile application system architecture Figure 2: Overview of the Parlance English mobi"
W15-4639,D10-1049,0,0.0325542,"ural than a rule-based generator. Moreover, by sampling utterances from the top reranked output, our system can also generate linguistically varied utterances. Section 4.4 provides a more detailed analysis of the contribution of each component of the system to the final performance. We conclude with a brief summary and future work in Section 5. 2 Statistical approaches have also been studied for sentence planning, for example, generating the most likely context-free derivations given a corpus (Belz, 2008) or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2010). Angeli et al. (2010) train a set of log-linear models to predict individual generation decisions given the previous ones, using only domain-independent features. Along similar lines, by casting NLG as a template extraction and reranking problem, Kondadadi et al. (2013) show that outputs produced by an SVM reranker are comparable to human-authored texts. The use of neural network-based approaches to NLG is relatively unexplored. The stock reporter system ANA by Kukich (1987) is a network based NLG system, in which the generation task is divided into a sememe-to-morpheme network followed by a morpheme-to-phrase net"
W15-4639,P14-1062,0,0.0291783,"icalised corpus (Henderson et al., 2014) whereby each value has been replaced by a symbol representing its corresponding slot. In a final postprocessing phase, these slot symbols are converted back to the corresponding slot values. While generating, the RNN generator is conditioned on an auxiliary dialogue act feature and a controlling gate to over-generate candidate utterances for subsequent reranking. In order to account for arbitrary slot-value pairs that cannot be routinely delexicalized in our corpus, Section 3.1 describes a convolutional neural network (CNN) (Collobert and Weston, 2008; Kalchbrenner et al., 2014) sentence model which is used to validate the semantic consistency of candidate utterances during reranking. Finally, by adding a backward RNNLM reranker into the model in Section 3.2, output fluency is further improved. Training and decoding details of the proposed system are described in Section 3.3 and 3.4. Section 4 presents an evaluation of the proposed system in the context of an application providing information about restaurants in the San Francisco area. In Section 4.2, we first show that new generator outperforms Oh and Rudnicky (2000)’s utterance class LM approach using objective me"
W15-4639,D14-1181,0,0.0047919,"ave been investigated to learn distributed representations for phrases and even sentences by training models using different structures (Collobert and Weston, 2008; Socher et al., 2013). Convolutional Neural Networks (CNNs) were first studied in computer vision for object recognition (Lecun et al., 1998). By stacking several convolutional-pooling layers followed by a fully connected feed-forward network, CNNs are claimed to be able to extract several levels of translational-invariant features that are useful in classification tasks. The convolutional sentence model (Kalchbrenner et al., 2014; Kim, 2014) adopts the same methodology but collapses the two dimensional convolution and pooling process into a single dimension. The resulting model is claimed to represent the state-of-the-art for many speech and NLP related tasks (Kalchbrenner et al., 2014; Sainath et al., 2013). 3 erated (Karpathy and Fei-Fei, 2014) or some required constraint is satisfied (Zhang and Lapata, 2014), the network can produce a sequence of tokens which can be lexicalised to form the required utterance. In order to ensure that the generated utterance represents the intended meaning, the input vectors wt are augmented by"
W15-4639,P13-1138,0,0.0157102,"the system to the final performance. We conclude with a brief summary and future work in Section 5. 2 Statistical approaches have also been studied for sentence planning, for example, generating the most likely context-free derivations given a corpus (Belz, 2008) or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2010). Angeli et al. (2010) train a set of log-linear models to predict individual generation decisions given the previous ones, using only domain-independent features. Along similar lines, by casting NLG as a template extraction and reranking problem, Kondadadi et al. (2013) show that outputs produced by an SVM reranker are comparable to human-authored texts. The use of neural network-based approaches to NLG is relatively unexplored. The stock reporter system ANA by Kukich (1987) is a network based NLG system, in which the generation task is divided into a sememe-to-morpheme network followed by a morpheme-to-phrase network. Recent advances in recurrent neural network-based language models (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) have demonstrated the value of distributed representations and the ability to model arbitrarily long dependencies for both"
W15-4639,P98-1116,0,0.0438205,"Z, UK {thw28,mg436,dk449,nm480,phs26,djv27,sjy}@cam.ac.uk Abstract 2014). However, due to the difficulty of collecting semantically-annotated corpora, the use of data-driven NLG for SDS remains relatively unexplored and rule-based generation remains the norm for most systems (Cheyer and Guzzoni, 2007; Mirkovic and Cavedon, 2011). The goal of the NLG component of an SDS is to map an abstract dialogue act consisting of an act type and a set of attribute-value pairs1 into an appropriate surface text (see Table 1 below for some examples). An early example of a statistical NLG system is HALOGEN by Langkilde and Knight (1998) which uses an n-gram language model (LM) to rerank a set of candidates generated by a handcrafted generator. In order to reduce the amount of handcrafting and make the approach more useful in SDS, Oh and Rudnicky (2000) replaced the handcrafted generator with a set of word-based n-gram LM-based generators, one for each dialogue type and then reranked the generator outputs using a set of rules to produce the final response. Although Oh and Rudnicky (2000)’s approach limits the amount of handcrafting to a small set of post-processing rules, their system incurs a large computational cost in the"
W15-4639,P13-1123,0,0.044241,"een made in applying statistical methods to automate the speech understanding and dialogue management components of an SDS, including making them more easily extensible to other application domains (Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 1 Here and elsewhere, attributes are frequently referred to as slots. 275 Proceedings of the SIGDIAL 2015 Conference, pages 275–284, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics face realisation converts the intermediate structure into the final text (Walker et al., 2002; Stent et al., 2004; Dethlefs et al., 2013). As noted above, one of the first statistical NLG methods that requires almost no handcrafting or semantic alignments was an n-gram based approach by Oh and Rudnicky (2000). Ratnaparkhi (2002) later addressed the limitations of n-gram LMs in the overgeneration phase by using a more sophisticated generator based on a syntactic dependency tree. log act-utterance pairs without any semantic alignments between the two. We start in Section 3 by presenting a generator based on a recurrent neural network language model (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) which is trained on a delexi"
W15-4639,J14-4003,1,0.937579,"-based generators, one for each dialogue type and then reranked the generator outputs using a set of rules to produce the final response. Although Oh and Rudnicky (2000)’s approach limits the amount of handcrafting to a small set of post-processing rules, their system incurs a large computational cost in the over-generation phase and it is difficult to ensure that all of the required semantics are covered by the selected output. More recently, a phrase-based NLG system called BAGEL trained from utterances aligned with coarse-grained semantic concepts has been described (Mairesse et al., 2010; Mairesse and Young, 2014). By implicitly modelling paraphrases, Bagel can generate linguistically varied utterances. However, collecting semantically-aligned corpora is expensive and time consuming, which limits Bagel’s scalability to new domains. This paper presents a neural network based NLG system that can be fully trained from diaThe natural language generation (NLG) component of a spoken dialogue system (SDS) usually needs a substantial amount of handcrafting or a well-labeled dataset to be trained on. These limitations add significantly to development costs and make cross-domain, multi-lingual dialogue systems i"
W15-4639,P10-1157,1,0.922895,"Missing"
W15-4639,D13-1170,0,0.00157564,"utterance, and simple unconstrained RNNLMs which rely on emConventional approaches to NLG typically divide the task into sentence planning, and surface realisation. Sentence planning maps input semantic symbols into an intermediary tree-like or template structure representing the utterance, then sur276 bedding at the word level (Mikolov et al., 2013; Pennington et al., 2014) are rather poor at this. As a consequence, new methods have been investigated to learn distributed representations for phrases and even sentences by training models using different structures (Collobert and Weston, 2008; Socher et al., 2013). Convolutional Neural Networks (CNNs) were first studied in computer vision for object recognition (Lecun et al., 1998). By stacking several convolutional-pooling layers followed by a fully connected feed-forward network, CNNs are claimed to be able to extract several levels of translational-invariant features that are useful in classification tasks. The convolutional sentence model (Kalchbrenner et al., 2014; Kim, 2014) adopts the same methodology but collapses the two dimensional convolution and pooling process into a single dimension. The resulting model is claimed to represent the state-o"
W15-4639,P04-1011,0,0.760574,"icant progress has been made in applying statistical methods to automate the speech understanding and dialogue management components of an SDS, including making them more easily extensible to other application domains (Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 1 Here and elsewhere, attributes are frequently referred to as slots. 275 Proceedings of the SIGDIAL 2015 Conference, pages 275–284, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics face realisation converts the intermediate structure into the final text (Walker et al., 2002; Stent et al., 2004; Dethlefs et al., 2013). As noted above, one of the first statistical NLG methods that requires almost no handcrafting or semantic alignments was an n-gram based approach by Oh and Rudnicky (2000). Ratnaparkhi (2002) later addressed the limitations of n-gram LMs in the overgeneration phase by using a more sophisticated generator based on a syntactic dependency tree. log act-utterance pairs without any semantic alignments between the two. We start in Section 3 by presenting a generator based on a recurrent neural network language model (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) whic"
W15-4639,D14-1003,0,0.0201042,"cases. Secondly, a backward RNNLM is used to rerank utterances presented in reverse order. 3.1 where h is the size of embedding and k = 1 . . . K. Last, the K pooled feature vectors hk are passed through a nonlinearity function to obtain the final feature map. 3.2 As noted earlier, the quality of an RNN language model may be improved if both forward and backward contexts are considered. Previously, bidirectional RNNs (Schuster and Paliwal, 1997) have been shown to be effective for handwriting recognition (Graves et al., 2008), speech recognition (Graves et al., 2013), and machine translation (Sundermeyer et al., 2014). However, applying a bidirectional RNN directly in our generator is not straightforward since the generation process is sequential in time. Hence instead of integrating the bidirectional information into a single unified network, the forward and backward contexts are utilised separately by firstly generating candidates using the forward RNN generator, then using the log-likelihood computed by a backward RNNLM to rerank the candidates. Convolutional Sentence Model The CNN sentence model is shown in Figure 2. Given a candidate utterance of length n, an utterance matrix U is constructed by stack"
W15-4639,W00-0306,0,0.597199,"Missing"
W15-4639,P02-1040,0,0.112861,"y (Bergstra et al., 2010; Bastien et al., 2012). The system was trained by partitioning the 5193 utterances into a training set, validation set, and testing set in the ratio 3:1:1, respectively. The frequency of each action type and slot-value pair differs quite markedly across the corpus, hence up-sampling was used to make the corpus more uniform. Since our generator works stochastically and the trained networks can differ depending on the initialisation, all the results shown below4 were averaged over 10 randomly initialised networks. The BLEU-4 metric was used for the objective evaluation (Papineni et al., 2002). Multiple references for each test dialogue act were obtained by mapping them back to the 228 distinct dialogue acts, merging those delexicalised templates that have the same dialogue act specification, and then lexicalising those templates back to Decoding R = −(costf RN N + costbRN N + costCN N ). Experiments (9) In order to severely penalise nonsensical utterances, λ is set to 100 for both the proposed RNN system and our implementation of Oh and Rudnicky (2000)’s n-gram based system. This reranking criterion is used for both the automatic evaluation in Section 4.2 and the human evaluation"
W15-4639,D14-1162,0,0.111104,"escribes interesting work using RNNs to generate Chinese poetry. Related Work A specific requirement of NLG for dialogue systems is that the concepts encoded in the abstract system dialogue act must be conveyed accurately by the generated surface utterance, and simple unconstrained RNNLMs which rely on emConventional approaches to NLG typically divide the task into sentence planning, and surface realisation. Sentence planning maps input semantic symbols into an intermediary tree-like or template structure representing the utterance, then sur276 bedding at the word level (Mikolov et al., 2013; Pennington et al., 2014) are rather poor at this. As a consequence, new methods have been investigated to learn distributed representations for phrases and even sentences by training models using different structures (Collobert and Weston, 2008; Socher et al., 2013). Convolutional Neural Networks (CNNs) were first studied in computer vision for object recognition (Lecun et al., 1998). By stacking several convolutional-pooling layers followed by a fully connected feed-forward network, CNNs are claimed to be able to extract several levels of translational-invariant features that are useful in classification tasks. The"
W15-4639,H94-1039,0,0.0636546,"rk structure which can be trained on dialogue act-utterance pairs without any semantic alignments or predefined grammar trees. Objective metrics suggest that this new model outperforms previous methods under the same experimental conditions. Results of an evaluation by human judges indicate that it produces not only high quality but linguistically varied utterances which are preferred compared to n-gram and rule-based systems. 1 Introduction Conventional spoken dialogue systems (SDS) are expensive to build because many of the processing components require a substantial amount of handcrafting (Ward and Issar, 1994; Bohus and Rudnicky, 2009). In the past decade, significant progress has been made in applying statistical methods to automate the speech understanding and dialogue management components of an SDS, including making them more easily extensible to other application domains (Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 1 Here and elsewhere, attributes are frequently referred to as slots. 275 Proceedings of the SIGDIAL 2015 Conference, pages 275–284, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics face realisation converts the intermedia"
W15-4639,D14-1074,0,0.0261123,"have demonstrated the value of distributed representations and the ability to model arbitrarily long dependencies for both speech recognition and machine translation tasks. Sutskever et al. (2011) describes a simple variant of the RNN that can generate meaningful sentences by learning from a character-level corpus. More recently, Karpathy and Fei-Fei (2014) have demonstrated that an RNNLM is capable of generating image descriptions by conditioning the network model on a pre-trained convolutional image feature representation. This work provides a key inspiration for the system described here. Zhang and Lapata (2014) describes interesting work using RNNs to generate Chinese poetry. Related Work A specific requirement of NLG for dialogue systems is that the concepts encoded in the abstract system dialogue act must be conveyed accurately by the generated surface utterance, and simple unconstrained RNNLMs which rely on emConventional approaches to NLG typically divide the task into sentence planning, and surface realisation. Sentence planning maps input semantic symbols into an intermediary tree-like or template structure representing the utterance, then sur276 bedding at the word level (Mikolov et al., 2013"
W15-4639,E09-1078,0,\N,Missing
W15-4639,C98-1112,0,\N,Missing
W15-4653,W10-4334,1,0.865416,"Missing"
W15-4653,W14-4340,0,0.0539342,"confirm this in a real user trial. 1 Introduction Spoken dialogue systems enable human-computer interaction via speech. The dialogue management component has two aims: to maintain the dialogue state based on the current spoken language understanding input and the conversation history, and choose a response according to its dialogue policy. To provide robustness to the input errors, a number of statistical approaches are proposed to track a distribution over all dialogue states at every dialogue turn, called the belief state (Young et al., 2013; Thomson and Young, 2010; Williams et al., 2013; Henderson et al., 2014; Sun et al., 2014). The system response is then based on the belief state, rather than an inaccurate estimate of the most likely dialogue state. ∗ Lu Chen was supported by the NICaiA project (the EU FP7 No. 247619). Pei-Hao Su is supported by Cambridge Trust and the Ministry of Education, Taiwan. 407 Proceedings of the SIGDIAL 2015 Conference, pages 407–411, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics 2 GP-Sarsa and hyper-parameter optimisation the function value is only expected to be similar to some other function value if both kernels have a"
W15-4653,W13-4065,0,0.0179933,"ing dialogue policy. We confirm this in a real user trial. 1 Introduction Spoken dialogue systems enable human-computer interaction via speech. The dialogue management component has two aims: to maintain the dialogue state based on the current spoken language understanding input and the conversation history, and choose a response according to its dialogue policy. To provide robustness to the input errors, a number of statistical approaches are proposed to track a distribution over all dialogue states at every dialogue turn, called the belief state (Young et al., 2013; Thomson and Young, 2010; Williams et al., 2013; Henderson et al., 2014; Sun et al., 2014). The system response is then based on the belief state, rather than an inaccurate estimate of the most likely dialogue state. ∗ Lu Chen was supported by the NICaiA project (the EU FP7 No. 247619). Pei-Hao Su is supported by Cambridge Trust and the Ministry of Education, Taiwan. 407 Proceedings of the SIGDIAL 2015 Conference, pages 407–411, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics 2 GP-Sarsa and hyper-parameter optimisation the function value is only expected to be similar to some other function valu"
W15-4653,N07-2038,0,\N,Missing
W17-5509,W15-4603,1,0.833217,"ccessfully used: k((b, a), (b0 , a0 )) = δ(a, a0 ) · klin (b, b0 ) . (5) ! = f (rt+1 , w) + γf (Rt+1 , w) (8) must hold. This is true in case of using a linear scalarization function f (Eq. 6). To alter the kernel accordingly, a linear kernel for w is added to the state kernel1 resulting in k((b, a, w), (b0 , a0 , w0 )) (4)  = δ(a, a0 ) · klin (b, b0 ) + klin (w, w0 ) . (9) It consists of a linear kernel for the continuous belief representation b and the δ-kernel for the discrete system action a. 1 A similar type of kernel extension has been proposed previously in a different context, e.g., (Casanueva et al., 2015). 66 a suitable weight configuration, a single-objective policy may be trained. Algorithm 1: Training of the MO-GPSARSA. 1 2 3 4 5 6 7 8 Input: dialogue success reward rs , dialogue length penalty rl foreach training dialogue do select ws , wl randomly execute dialogue and record (bt , at , w) in D for each turn t // dialogue length penalty r ← wl · |D |· rl // dialogue success reward if dialogue successful then r ← r + wr · rs update GP using D and r reset D 4 The reward balancing method described in the previous section is applied to six domains: finding TVs, laptops, restaurants or hotels ("
W17-5509,P16-1230,1,0.850667,"Missing"
W17-5509,P17-4013,1,0.893124,"Missing"
W17-5509,E06-2009,0,\N,Missing
W17-5512,W11-2033,0,0.206061,"Missing"
W17-5512,P15-2130,1,0.831098,"Missing"
W17-5512,D17-1237,0,0.0557702,"ing problem and is normally tackled using reinforcement learning (RL). Many approaches to policy management over single domains have been proposed over the last years with ability to learn from scratch (Fatemi et al., 2016; Gaˇsi´c and Young, 2014; Su et al., 2016; Williams and Zweig, 2016). The goal of this work is to propose a coherent framework for a system capable of managing con86 Proceedings of the SIGDIAL 2017 Conference, pages 86–92, c Saarbr¨ucken, Germany, 15-17 August 2017. 2017 Association for Computational Linguistics logue systems to more complex scenarios. Parallel to our work, Peng et al. (2017) proposed another HRL approach, using deep Q-networks as an approximator. In separate work, we found deep Qnetworks to be unstable (Su et al., 2017); in this work, we focus on more robust estimators. The contributions of this paper are threefold. First, we adapt and validate the option framework (Sutton et al., 1999b) for a multi-domain dialogue system. Second, we demonstrate that hierarchical learning for dialogue systems works well with function approximation using the GPSARSA algorithm. We chose the Gaussian process as the function approximator as it provides uncertainty estimates which can"
W17-5512,W16-3613,0,0.0983431,"Missing"
W17-5512,W17-5518,1,0.876284,"Missing"
W17-5512,P17-4013,1,0.753335,"Missing"
W17-5512,D14-1007,0,0.0577099,"Missing"
W17-5518,W17-5512,1,0.87681,"Missing"
W17-5518,W15-4653,1,0.862045,"Missing"
W17-5518,J08-4002,0,0.733963,"ng neural networkbased dialogue models, mostly in text-based systems (Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2015; Wen et al., 2017; Bordes et al., 2017). These systems are directly trained on past dialogues without detailed specification of the internal dialogue state. However, there are two key limitations of using SL in SDS. Firstly, the effect of selecting an action on the future course of the dialogue is not considered and this may result in sub-optimal behaviour. Secondly, there will often be a large number of dialogue states which are not covered by the training data (Henderson et al., 2008; Li et al., 2014). Moreover, there is no reason to suppose that the recorded dialogue participants are acting optimally, especially in high noise levels. These problems are exacerbated in larger domains where multi-step planning is needed. In this paper, we propose a network-based approach to policy learning which combines the best of both SL- and RL-based dialogue management, and which capitalises on recent advances in deep RL (Mnih et al., 2015), especially off-policy algorithms (Wang et al., 2017). The main contribution of this paper is two-fold: 2 Related Work RL-based approaches to dialo"
W17-5518,W14-4340,1,0.82311,"-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management Pei-Hao Su, Paweł Budzianowski, Stefan Ultes, Milica Gaˇsi´c, and Steve Young Department of Engineering, University of Cambridge, Cambridge, UK {phs26, pfb30, su259, mg436, sjy11}@cam.ac.uk Abstract domain that the system can talk about. The development of a robust SDS traditionally requires a substantial amount of hand-crafted rules combined with various statistical components. This includes a spoken language understanding module (Chen et al., 2016; Yang et al., 2017), a dialogue belief state tracker (Henderson et al., 2014; Perez and Liu, 2016; Mrkˇsi´c et al., 2017) to predict user intent and track the dialogue history, a dialogue policy (Young et al., 2013; Gaˇsi´c and Young, 2014; Budzianowski et al., 2017) to determine the dialogue flow, and a natural language generator (Rieser and Lemon, 2009; Wen et al., 2015; Hu et al., 2017) to convert conceptual representations into system responses. In a task-oriented SDS, teaching a system how to respond appropriately in all situations is nontrivial. Traditionally, this dialogue management component has been designed manually using flow charts. More recently, it has"
W17-5518,P17-1163,1,0.900144,"Missing"
W17-5518,E09-1078,0,0.0608583,"k Abstract domain that the system can talk about. The development of a robust SDS traditionally requires a substantial amount of hand-crafted rules combined with various statistical components. This includes a spoken language understanding module (Chen et al., 2016; Yang et al., 2017), a dialogue belief state tracker (Henderson et al., 2014; Perez and Liu, 2016; Mrkˇsi´c et al., 2017) to predict user intent and track the dialogue history, a dialogue policy (Young et al., 2013; Gaˇsi´c and Young, 2014; Budzianowski et al., 2017) to determine the dialogue flow, and a natural language generator (Rieser and Lemon, 2009; Wen et al., 2015; Hu et al., 2017) to convert conceptual representations into system responses. In a task-oriented SDS, teaching a system how to respond appropriately in all situations is nontrivial. Traditionally, this dialogue management component has been designed manually using flow charts. More recently, it has been formulated as a planning problem and solved using reinforcement learning (RL) to optimise a dialogue policy through interaction with users (Levin and Pieraccini, 1997; Roy et al., 2000; Williams and Young, 2007; Jurˇc´ıcˇ ek et al., 2011). In this framework, the system learn"
W17-5518,P00-1013,0,0.165669,"wski et al., 2017) to determine the dialogue flow, and a natural language generator (Rieser and Lemon, 2009; Wen et al., 2015; Hu et al., 2017) to convert conceptual representations into system responses. In a task-oriented SDS, teaching a system how to respond appropriately in all situations is nontrivial. Traditionally, this dialogue management component has been designed manually using flow charts. More recently, it has been formulated as a planning problem and solved using reinforcement learning (RL) to optimise a dialogue policy through interaction with users (Levin and Pieraccini, 1997; Roy et al., 2000; Williams and Young, 2007; Jurˇc´ıcˇ ek et al., 2011). In this framework, the system learns by a trial and error process governed by a potentially delayed learning objective called the reward. This reward is designed to encapsulate the desired behavioural features of the dialogue. Typically it provides a positive reward for success plus a per turn penalty to encourage short dialogues (El Asri et al., 2014; Su et al., 2015a; Vandyke et al., 2015; Su et al., 2016b). To allow the system to be trained on-line, Bayesian sample-efficient learning algorithms have been proposed (Gaˇsi´c and Young, 20"
W17-5518,D16-1127,0,0.0506184,"cy. Better initialisation of GPRL has been studied in the context of domain adaptation by specifying a GP prior or re-using an existing model which is then pre-trained for the new domain (Gaˇsi´c et al., 2013). A number of authors have proposed training a standard neural-network policy in two stages (Fatemi et al., 2016; Su et al., 2016a; Williams et al., 2017). Asadi and Williams (2016) also explored off-policy RL methods for dialogue policy learning. All these studies were conducted in simulation, using error-free text-based input. A similar approach was also used in a conversational model (Li et al., 2016). In contrast, our work introduces two new sample-efficient actor-critic methods, combines both two-stage policy learning and off-policy RL, and testing at differing noise levels. 3 Figure 1: A2C, TRACER and eNACER architectures using feed-forward neural networks. or policy-based methods. In both cases, the goal is to find an optimal policy π ∗ that maximises the PT −1 t discounted total return R = t=0 γ rt (bt , at ) over a dialogue with T turns where rt (bt , at ) is the reward when taking action at in dialogue belief state bt at turn t and γ is the discount factor. The main difference betwe"
W17-5518,P15-1152,0,0.0430799,"Missing"
W17-5518,E17-1042,1,0.886139,"Missing"
W17-5518,D15-1199,1,0.88724,"Missing"
W17-5518,P17-1062,0,0.279183,"ptimised Gaussian kernel learned using SL from a dialogue corpus has been proposed (Chen et al., 2015). The resulting kernel was more accurate on data correlation and achieved better performance, however, the SL corpus did not help to initialise a better policy. Better initialisation of GPRL has been studied in the context of domain adaptation by specifying a GP prior or re-using an existing model which is then pre-trained for the new domain (Gaˇsi´c et al., 2013). A number of authors have proposed training a standard neural-network policy in two stages (Fatemi et al., 2016; Su et al., 2016a; Williams et al., 2017). Asadi and Williams (2016) also explored off-policy RL methods for dialogue policy learning. All these studies were conducted in simulation, using error-free text-based input. A similar approach was also used in a conversational model (Li et al., 2016). In contrast, our work introduces two new sample-efficient actor-critic methods, combines both two-stage policy learning and off-policy RL, and testing at differing noise levels. 3 Figure 1: A2C, TRACER and eNACER architectures using feed-forward neural networks. or policy-based methods. In both cases, the goal is to find an optimal policy π ∗"
W17-5518,P16-1230,1,0.846522,"Missing"
W17-5518,W15-4655,1,0.766604,"Missing"
W17-5518,P17-4013,1,0.817383,"w. Note that yt is evaluated by a target network w− which is updated less frequently than the network w to stabilise learning, and the expectation is over the tuples (bt , at , rt+1 , bt+1 ) sampled from the experience replay pool described in §3.1.2. DQN often suffers from over-estimation on Qvalues as the max operator is used to select an action as well as to evaluate it. Double DQN (DDQN) (Van Hasselt et al., 2016) is thus used to de-couple the action selection and Q-value estimation to achieve better performance. Experimental Results Our experiments utilised the software tool-kit PyDial (Ultes et al., 2017), which provides a platform for modular SDS. The target application is a live telephone-based SDS providing restaurant information for the Cambridge (UK) area. The task is to learn a policy which manages the dialogue flow and delivers requested information to the user. The domain consists of approximately 100 venues, each with 6 slots out of which 3 can be used by the system to constrain the search (food-type, area and price-range) and 3 are system-informable properties (phone-number, address and postcode) available once a database entity has been found. The input for all models was the full d"
W17-5518,W16-3613,0,\N,Missing
W18-5007,W16-3613,0,0.103748,"Missing"
W18-5007,D17-1234,0,0.0142093,"gement task is often formulated as a reinforcement learning (RL) 60 Proceedings of the SIGDIAL 2018 Conference, pages 60–69, c Melbourne, Australia, 12-14 July 2018. 2018 Association for Computational Linguistics the size of the recorded corpus usually falls short of the requirements for training a statistical DM. However, even if the size of the corpus is large enough the optimal dialogue strategy is likely not to be contained within it. the most popular off-line training tools for reinforcement learning based Spoken Dialogue Systems (Koo et al., 2015; Fatemi et al., 2016; Chen et al., 2017; Chang et al., 2017; Casanueva et al., 2018; Weisz et al., 2018; Shah et al., 2018). The remainder of this paper is organised as follows. Section 2 briefly describes task-oriented dialogue. Section 3 describes the motivation for the NUS and discusses related work. Section 4 explains the structure of the NUS, how it is trained and how it is deployed for training a DM’s policy. Sections 5 and 6 present the experimental setup and results. Finally, Section 7 gives conclusions. 2 A solution is to transform the static corpus into a dynamic tool: a user simulator. The user simulator (US) is trained on a dialogue corpus"
W18-5007,W14-4337,0,0.0116439,". The aforementioned work focuses on user simulation at the semantic level. Multiple issues arise from this approach. Firstly, annotating the user-response with the correct semantics is costly. More data could be collected, if the US were to output natural language. Secondly, research suggests that the two modules of an SDS performing Spoken Language Understanding (SLU) and belief tracking should be jointly trained as a single entity (Mrkˇsi´c et al., 2017; Sun et al., 2016, 2014; Zilka and Jurcicek, 2015; Ramadan et al., 2018). In fact in the second Dialogue State Tracking Challenge (DSTC2) (Henderson et al., 2014), the data of which this work uses, systems which used no external SLU module outperformed all systems that only used an external SLU Module1 . Training the policy of a DM in a simulated environment, when also using a joint system for SLU and belief tracking is not possible without a US that produces natural language. Thirdly, a US is sometimes augmented with an error model which generates a set of competing hypotheses with associated confidence scores trying to replicate the errors of the speech recogniser. When the error model matches the characteristics of the speech recogniser more accurat"
W18-5007,D17-1260,0,0.0121726,"this dialogue management task is often formulated as a reinforcement learning (RL) 60 Proceedings of the SIGDIAL 2018 Conference, pages 60–69, c Melbourne, Australia, 12-14 July 2018. 2018 Association for Computational Linguistics the size of the recorded corpus usually falls short of the requirements for training a statistical DM. However, even if the size of the corpus is large enough the optimal dialogue strategy is likely not to be contained within it. the most popular off-line training tools for reinforcement learning based Spoken Dialogue Systems (Koo et al., 2015; Fatemi et al., 2016; Chen et al., 2017; Chang et al., 2017; Casanueva et al., 2018; Weisz et al., 2018; Shah et al., 2018). The remainder of this paper is organised as follows. Section 2 briefly describes task-oriented dialogue. Section 3 describes the motivation for the NUS and discusses related work. Section 4 explains the structure of the NUS, how it is trained and how it is deployed for training a DM’s policy. Sections 5 and 6 present the experimental setup and results. Finally, Section 7 gives conclusions. 2 A solution is to transform the static corpus into a dynamic tool: a user simulator. The user simulator (US) is trained"
W18-5007,I17-1074,0,0.0358634,". However, speech recogni1 tion errors are badly modelled based on user semantics since they arise (mostly) due to the phonetics of the spoken words and not their semantics (Goldwater et al., 2010). Thus, an SDS that is trained with a natural language based error model is likely to outperform one trained with a semantic error model when tested on real users. Sequenceto-sequence learning for word-level user simulation is performed in (Crook and Marin, 2017), though the model is not conditioned on any goal and hence not used for policy optimisation. A word-level user simulator was also used in (Li et al., 2017) where it was built by augmenting the ABUS with a natural language generator. 4 Neural User Simulator Ontology Goal Generator Feature Extractor Spoken Dialogue System Request-Vector Accepted Venue Original Request-Vector Feature History User Utterance Sequence to Sequence Model Figure 1: General Architecture of the Neural User Simulator. The System Output is passed to the Feature Extractor. It generates a new feature vector that is appended to the Feature History, which is passed to the sequence-to-sequence model to produce the user utterance. At the start of the dialogue the Goal Generator ge"
W18-5007,P17-1163,0,0.0559272,"Missing"
W18-5007,W14-4343,0,0.0440163,"Missing"
W18-5007,P18-2069,1,0.877101,"Missing"
W18-5007,P17-4013,1,0.902295,"Missing"
W18-5007,P00-1013,0,0.358758,"Missing"
W18-5007,N07-2038,0,0.91541,"al and possibly changes it during a dialogue. This allows the model to be deployed for training more sophisticated DM policies. To achieve this, a method is proposed that transforms the goal-labels of the used dataset (DSTC2) into labels whose behaviour can be replicated during deployment. The NUS is trained on dialogues between real users and an SDS in a restaurant recommendation domain. Compared to much of the related work on user simulation, we use the trained NUS to train the policy of a reinforcement learning based SDS. In order to evaluate the NUS, an Agenda-Based User-Simulator (ABUS) (Schatzmann et al., 2007) is used to train another policy. The two policies are compared against each other by using crossmodel evaluation (Schatztmann et al., 2005). This means to train on one model and to test on the other. Furthermore, both trained policies are tested on real users. On both evaluation tasks the NUS outperforms the ABUS, which is currently one of User Simulators are one of the major tools that enable offline training of task-oriented dialogue systems. For this task the Agenda-Based User Simulator (ABUS) is often used. The ABUS is based on handcrafted rules and its output is in semantic form. Issues"
W18-5032,T78-1013,0,0.649284,"depicted in Figure 6. Each level produces its own belief and based on that, the system is able to act on each level. On the world level, the system might produce general dialogue behaviour like greetings or engage in a dialogue to adequately identify the entity which is addressed by the user input. On the entity level, the system talks to the user to acquire information about the concrete entity the user is talking about, e.g., to find a matching entity in the knowledge base. In addition to belief tracking, we would like to introduce another concept called focus of attention. Based on work by Grosz (1978), we define the current focus of attention F for each conversational world as a subset of conversational entities in this world F ⊆ W . Hence, the task of focus tracking is to find the new set of conversational entities which is in the current focus of attention based on the user input and the updated belief state. Even though the concept of focus is not mandatory, it may be helpful when framing the reinforcement learning problem as it allows to limit the size of the input to the reinforcement learning algorithm as well as the number of actions available to the learning algorithm at a given ti"
W18-5032,W17-5512,1,0.834933,"Missing"
W18-5032,W14-4337,0,0.0129861,"he influence of the user addressing the relation instead of the correct value (e.g., ”restaurant in the same area as the hotel” vs. ”restaurant in the centre”), we have extended the simulated agenda-based user (Schatzmann and Young, 2009) with a probability r of the user addressing the relation instead of the value. The higher r, the more often the user addresses the relation. The user simulator is equipped with an additional error model to simulate the semantic error rate (SER) caused in a real system by the noisy speech channel. For belief tracking, an extended version of the focus tracker (Henderson et al., 2014)—an effective rule-based tracker—was used for the conversational entities and the conversational world that also discounts probabilities if the respective value has been rejected by the user. As a simulated interaction is on the semantic level, no semantic dewhere s is the slot, v is the value, and bi the belief of the i-th conversational entity involved in the merging process. wi = 1 − bis (∅) is the weight of the i-th conversational entity where bis (∅) represents the probability where no information about slot s has yet been shared with the system. bi either refers to the belief bo of the c"
W18-5032,W16-3602,0,0.0677983,"elation 1 (Object 1 with Object 2) area: same Object 2 (Restaurant) name: Golden House area: centre Restaurant name area food … Figure 1: A dialogue between the system (S) and a user (U) about a restaurant and a hotel in the same area along with the mapping of fractions of the dialogue to the respective objects (of predefined types) and the relation. All objects and relations reside inside a conversational world. a comprehensive and consistent way of modelling these probabilities by defining and maintaining entity-based states. Work on statistical dialogue state modelling (Young et al., 2010; Lee and Stent, 2016; Schulz et al., 2017) also contain a variant of objects but is still based on the MDDM thus not offering any mechanism to model multiple entities or relations between objects. Ramachandran and Ratnaparkhi (2015) proposed a belief tracking approach using relational trees. However, they only consider static relations present in the ontology and are not able to handle dynamic relations. mapped to an object or a relation in the conversational world or may be mapped to the world itself (grey). In the example, the first part (blue) is about Object 1 of type hotel. When the focus shifts towards Obje"
W18-5032,N18-2112,1,0.861372,"Missing"
W18-5032,D16-1127,0,0.0585474,"tical SDS are model-based approaches1 and usually assume a modular architecture (see Fig. 2). The problem of learning the next system action is framed as a partially-observable Markov decision process (POMDP) that accounts for the uncertainty inherent in spoken communication. This uncertainty is modelled in the belief state b(s) representing a probability over all states s. Reinforcement learning (RL) is used in such a sequential decision-making process where the decision-model (the policy π) is trained based on 1 Model-free approaches like end-to-end generative networks (Serban et al., 2016; Li et al., 2016) have interesting properties (e.g., they only need text data for training) but they still seem to be limited in terms of dialogue structure complexity (not linguistic complexity) in cases where content from a structured knowledge base needs to be incorporated. Approaches where incorporating this information is learned along with the system responses based on dialogue data (Eric and Manning, 2017) seem hard to scale. 274 Speech Recognition Semantic Decoding Belief State Tracking Natural Language Generation Dialogue Policy waveform around domains which encapsulate all relevant information as a s"
W18-5032,W11-2033,0,0.0319607,"g of relations, Section 5 describes a prototype implementation and shows the benefits of the CEDM in experiments with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminology that will be used in this work an"
W18-5032,W17-5506,0,0.0888807,"earning (RL) is used in such a sequential decision-making process where the decision-model (the policy π) is trained based on 1 Model-free approaches like end-to-end generative networks (Serban et al., 2016; Li et al., 2016) have interesting properties (e.g., they only need text data for training) but they still seem to be limited in terms of dialogue structure complexity (not linguistic complexity) in cases where content from a structured knowledge base needs to be incorporated. Approaches where incorporating this information is learned along with the system responses based on dialogue data (Eric and Manning, 2017) seem hard to scale. 274 Speech Recognition Semantic Decoding Belief State Tracking Natural Language Generation Dialogue Policy waveform around domains which encapsulate all relevant information as a section of the dialogue state that belongs to a given topic, e.g., finding a restaurant or hotel. However, the resulting flat state that is widely used (Williams et al., 2005; Young et al., 2010; Thomson and Young, 2010; Lee and Stent, 2016; Schulz et al., 2017, e.g.) is not intuitive to model complex dialogue structures like relations. To overcome this limitation, we propose the conversational en"
W18-5032,D17-1237,0,0.0164082,"with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminology that will be used in this work and to illustrate the necessity of adequate modelling of relations, Figure 1 shows an example dialogue about hotels and re"
W18-5032,P17-1062,0,0.0294715,"tributes that represent the same concepts like area. Note that these relations are dynamic relations that may be drawn between objects in a conversation. This is different to static relations which are often used in knowledge bases to describe how concepts relate to each other. (2) For most real-world problems, finding the exact optimal Q-values is not feasible. Instead, RL algorithms have been proposed for dialogue policy learning based on approximating the Q-function directly or employing the policy gradient theorem (Williams and Young, 2006; Daubigney et al., 2012; Gaˇsi´c and Young, 2014; Williams et al., 2017; Su et al., 2017; Casanueva et al., 2017; Papangelis and Stylianou, 2017). Aside from the policy model, the dialogue model plays an important role: it defines the structure and internal links of the dialogue state as well as the system and user acts (i.e., the semantics the system can understand). Thus, the policy model is only able to learn system behaviour based on what is defined by the dialogue model. By defining the dialogue state, the dialogue model further represents an abstraction over the task ontology or knowledge base restricting the view on the information that is relevant so that"
W18-5032,2005.sigdial-1.4,1,0.759296,"not linguistic complexity) in cases where content from a structured knowledge base needs to be incorporated. Approaches where incorporating this information is learned along with the system responses based on dialogue data (Eric and Manning, 2017) seem hard to scale. 274 Speech Recognition Semantic Decoding Belief State Tracking Natural Language Generation Dialogue Policy waveform around domains which encapsulate all relevant information as a section of the dialogue state that belongs to a given topic, e.g., finding a restaurant or hotel. However, the resulting flat state that is widely used (Williams et al., 2005; Young et al., 2010; Thomson and Young, 2010; Lee and Stent, 2016; Schulz et al., 2017, e.g.) is not intuitive to model complex dialogue structures like relations. To overcome this limitation, we propose the conversational entity dialogue model which will be described in detail in the following section. Ontology Speech Synthesis Dialogue Manager Figure 2: The modular statistical dialogue system architecture. The dialogue manager takes the semantic interpretation as input to track the belief state. The updated state is then used by the dialogue policy to decide on the next system action. 4 sam"
W18-5032,W15-4609,0,0.0231936,"estaurant and a hotel in the same area along with the mapping of fractions of the dialogue to the respective objects (of predefined types) and the relation. All objects and relations reside inside a conversational world. a comprehensive and consistent way of modelling these probabilities by defining and maintaining entity-based states. Work on statistical dialogue state modelling (Young et al., 2010; Lee and Stent, 2016; Schulz et al., 2017) also contain a variant of objects but is still based on the MDDM thus not offering any mechanism to model multiple entities or relations between objects. Ramachandran and Ratnaparkhi (2015) proposed a belief tracking approach using relational trees. However, they only consider static relations present in the ontology and are not able to handle dynamic relations. mapped to an object or a relation in the conversational world or may be mapped to the world itself (grey). In the example, the first part (blue) is about Object 1 of type hotel. When the focus shifts towards Object 2 of type restaurant (green) at U3, the user also addresses the relation (red) in the same area between Object 1 and Object 2. Addressing a relation in this way could still be captured by the semantic interpre"
W18-5032,W10-4317,0,0.00972338,"1), no context information would be available. To capture these dialogue structures, the dialogue model and the corresponding dialogue state must be able to represent them adequately. The proposed CEDM achieves this by modelling state information about conversational entities instead of domains. More precisely, it models separate states about the objects (e.g., the hotel or restaurant) and the relations. Previous work on dialogue modelling already incorporated the idea of objects or entities to be the principal component of the dialogue state (Grosz, 1977; Bilange, 1991; Montoro et al., 2004; Xu and Seneff, 2010; Heinroth and Minker, 2013). However, these dialogue models are not based on statistical dialogue processing where a probability distribution over all dialogue states needs to be modelled and maintained. This additional complexity, though, cannot be incorporated in a straight-forward way into the proposed models. In contrast, the CEDM offers 3 Statistical Spoken Dialogue Systems Statistical SDS are model-based approaches1 and usually assume a modular architecture (see Fig. 2). The problem of learning the next system action is framed as a partially-observable Markov decision process (POMDP) th"
W18-5032,W17-2626,0,0.0313453,"Missing"
W18-5032,W17-5518,1,0.884593,"g at one aspect of the CEDM, the modelling of relations, Section 5 describes a prototype implementation and shows the benefits of the CEDM in experiments with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminol"
W18-5032,P17-4013,1,0.884457,"Missing"
W18-5032,D14-1007,0,0.0314208,"s, Section 5 describes a prototype implementation and shows the benefits of the CEDM in experiments with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminology that will be used in this work and to illustrate the"
W18-5038,P17-4013,1,0.888459,"Missing"
W18-5038,W15-4654,0,0.0758487,"Cambridge, UK {ic340,pfb30,mg436}@cam.ac.uk Abstract a hierarchical RL method that divides a task spatially rather than temporally, decomposing the decisions into several steps and using different levels of abstraction for each sub-decision. When applied to domains with large state and action spaces, FDM showed an impressive performance increase compared to traditional RL policies. However, the method presented in Casanueva et al. (2018), named FDQN1 , relied on handcrafted feature functions in order to abstract the state space. These functions, named Domain Independent Parametrisation (DIP) (Wang et al., 2015), are used to transform the belief of each slot into a fixed size representation using a large set of rules. In this paper, we demonstrate that the feature functions needed to abstract the belief state in each sub-decision can be jointly learned with the policy. We introduce two methods to do it, based on feed forward neural networks and recurrent neural networks respectively. A modification of the original FDQN architecture is also introduced which stabilizes learning, avoiding overfitting of the policy to a single action. Policies with jointly learned feature functions achieve similar perfor"
W18-5038,W13-4035,1,0.88484,"Missing"
W18-5038,J08-4002,0,0.0200507,"ature functions. In this work, we show that these feature functions can be learned jointly with the policy model while obtaining similar performance, even outperforming the handcrafted features in several environments and domains. 1 Introduction In task-oriented Spoken Dialogue Systems (SDS), the Dialogue Manager (DM) (or policy) is the module in charge of deciding the next action in each dialogue turn. One of the most popular approaches to model the DM is Reinforcement Learning (RL) (Sutton and Barto, 1999), having been studied for several years (Levin et al., 1998; Williams and Young, 2007; Henderson et al., 2008; Pietquin et al., 2011; Gaˇsi´c et al., 2013; Young et al., 2013). However, as the dialogue state space increases, the number of possible trajectories needed to be explored grows exponentially, making traditional RL methods not scalable to large domains. Recently, Feudal Dialogue Management (FDM) (Casanueva et al., 2018) has shown to increase the scalability to large domains. This approach is based on Feudal RL (Dayan and Hinton, 1993), ∗ 2 Background Dialogue management can be cast as a continuous MDP (Young et al., 2013) composed of a finite set of actions A, a continuous multivariate belie"
W18-5039,K16-1002,0,0.0461717,"erates words until it outputs an end-of-sentence (eos) token. Optimization When the decoder in the CVAE is powerful on its own, it tends to ignore the latent variable z since the encoder fails to encode enough information into z. Regularization methods can be introduced in order to push the encoder towards learning a good representation of the latent variable z. Since the KL-component of the VLB does not contribute towards learning a meaningful z, increasing the weight of it gradually from 0 to 1 during training helps to encode a better representation in z. This method is termed KL-annealing (Bowman et al., 2016). In addition, inspired by (Zhao et al., 2017), we introduce a regularization method using another NN which is trained to use z to recover the condition c. The NN is split into three separate FC NNs of one layer each, which independently Semantically Conditioned VAE The structure of our model is depicted in Fig. 1, which, conditioned on an SR, generates the system’s word-level response x. An SR consists of three components: the domain, a dialogue act and a set of slot-value pairs. Slots are attributes required to appear in x (e.g. a hotel’s area). A slot can have a value. Then the two are call"
W18-5039,P04-1011,0,0.333445,"Hsiang Tseng, Florian Kreyssig, Paweł Budzianowski, ˜ Inigo Casanueva, Yen-Chen Wu, Stefan Ultes, Milica Gaˇsi´c Department of Engineering, University of Cambridge, Cambridge, UK {bht26,flk24,pfb30,ic340,ycw30,su259,mg436}@cam.ac.uk Abstract duce natural language containing the desired information. Traditionally NLG was based on templates (Cheyer and Guzzoni, 2014), which produce grammatically-correct sentences that contain all desired information. However, the lack of variation of these sentences made these systems seem tedious and monotonic. Trainable generators (Langkilde and Knight, 1998; Stent et al., 2004) can generate several sentences for the same SR, but the dependence on pre-defined operations limits their potential. Corpus-based approaches (Oh and Rudnicky, 2000; Mairesse and Walker, 2011) learn to generate natural language directly from data without pre-defined rules. However, they usually require alignment between the sentence and the SR. Recently, Wen et al. (2015b) proposed an RNN-based approach, which outperformed previous methods on several metrics. However, the generated sentences often did not include all desired attributes. The variational autoencoder (Kingma and Welling, 2013) en"
W18-5039,W15-4639,1,0.931535,"Missing"
W18-5039,N16-1015,1,0.915737,"Missing"
W18-5039,P98-1116,0,0.321055,"Spoken Dialogue Systems Bo-Hsiang Tseng, Florian Kreyssig, Paweł Budzianowski, ˜ Inigo Casanueva, Yen-Chen Wu, Stefan Ultes, Milica Gaˇsi´c Department of Engineering, University of Cambridge, Cambridge, UK {bht26,flk24,pfb30,ic340,ycw30,su259,mg436}@cam.ac.uk Abstract duce natural language containing the desired information. Traditionally NLG was based on templates (Cheyer and Guzzoni, 2014), which produce grammatically-correct sentences that contain all desired information. However, the lack of variation of these sentences made these systems seem tedious and monotonic. Trainable generators (Langkilde and Knight, 1998; Stent et al., 2004) can generate several sentences for the same SR, but the dependence on pre-defined operations limits their potential. Corpus-based approaches (Oh and Rudnicky, 2000; Mairesse and Walker, 2011) learn to generate natural language directly from data without pre-defined rules. However, they usually require alignment between the sentence and the SR. Recently, Wen et al. (2015b) proposed an RNN-based approach, which outperformed previous methods on several metrics. However, the generated sentences often did not include all desired attributes. The variational autoencoder (Kingma"
W18-5039,D15-1199,1,0.90761,"Missing"
W18-5039,J11-3002,0,0.0240783,",flk24,pfb30,ic340,ycw30,su259,mg436}@cam.ac.uk Abstract duce natural language containing the desired information. Traditionally NLG was based on templates (Cheyer and Guzzoni, 2014), which produce grammatically-correct sentences that contain all desired information. However, the lack of variation of these sentences made these systems seem tedious and monotonic. Trainable generators (Langkilde and Knight, 1998; Stent et al., 2004) can generate several sentences for the same SR, but the dependence on pre-defined operations limits their potential. Corpus-based approaches (Oh and Rudnicky, 2000; Mairesse and Walker, 2011) learn to generate natural language directly from data without pre-defined rules. However, they usually require alignment between the sentence and the SR. Recently, Wen et al. (2015b) proposed an RNN-based approach, which outperformed previous methods on several metrics. However, the generated sentences often did not include all desired attributes. The variational autoencoder (Kingma and Welling, 2013) enabled for the first time the generation of complicated, high-dimensional data such as images. The conditional variational autoencoder (CVAE) (Sohn et al., 2015), firstly proposed for image gen"
W18-5039,W00-0306,0,0.674841,"e, Cambridge, UK {bht26,flk24,pfb30,ic340,ycw30,su259,mg436}@cam.ac.uk Abstract duce natural language containing the desired information. Traditionally NLG was based on templates (Cheyer and Guzzoni, 2014), which produce grammatically-correct sentences that contain all desired information. However, the lack of variation of these sentences made these systems seem tedious and monotonic. Trainable generators (Langkilde and Knight, 1998; Stent et al., 2004) can generate several sentences for the same SR, but the dependence on pre-defined operations limits their potential. Corpus-based approaches (Oh and Rudnicky, 2000; Mairesse and Walker, 2011) learn to generate natural language directly from data without pre-defined rules. However, they usually require alignment between the sentence and the SR. Recently, Wen et al. (2015b) proposed an RNN-based approach, which outperformed previous methods on several metrics. However, the generated sentences often did not include all desired attributes. The variational autoencoder (Kingma and Welling, 2013) enabled for the first time the generation of complicated, high-dimensional data such as images. The conditional variational autoencoder (CVAE) (Sohn et al., 2015), fi"
W18-5039,P17-1061,0,0.0723263,"Missing"
W18-5039,C98-1112,0,\N,Missing
W18-5039,P17-2080,0,\N,Missing
W18-5606,P14-1062,0,0.0188464,"h the therapy can be accessed (Hansen et al., 2002). This 44 Proceedings of the 9th International Workshop on Health Text Mining and Information Analysis (LOUHI 2018), pages 44–54 c Brussels, Belgium, October 31, 2018. 2018 Association for Computational Linguistics follow represent the main contribution of this work: a CBT ontology in Section 4, a labelled dataset in Section 5, and models for language understanding in Section 6. We present the results in Section 7 and our conclusion in Section 8. 2 derstanding, sentiment analysis or dialogue belief tracking (Collobert et al., 2011; Kim, 2014; Kalchbrenner et al., 2014; Le and Mikolov, 2014a; Rojas Barahona et al., 2016; Mrkˇsi´c et al., 2017). In this work we consider understanding of mental health concepts of as a classification task. To facilitate this process, we use distributed representations. Background A dialogue system can be treated as a trainable statistical model suitable for goal-oriented information seeking dialogues (Young, 2002). In these dialogues, the user has a clear goal that he or she is trying to achieve and this involves extracting particular information from a back-end database. A structured representation of the database, the ontolo"
W18-5606,D14-1181,0,0.0106963,"Missing"
W18-5606,D16-1127,0,0.0274042,"am.ac.uk Abstract gives automated systems a huge advantage over conventional therapies, as they can be used continuously with marginal extra cost. Health assistants that can deliver therapy, have gained great interest in recent years (Bickmore et al., 2005; Fitzpatrick et al., 2017). These systems however are largely based on hand-crafted rules. On the other hand, the main research effort in statistical approaches to conversational systems has focused on limited-domain information seeking dialogues (Schatzmann et al., 2006; Geist and Pietquin, 2011; Gasic and Young, 2014; Fatemi et al., 2016; Li et al., 2016; Williams et al., 2017). In this paper we introduce a new task: understanding of mental health concepts derived from Cognitive Behavioural Therapy (CBT). We present an ontology that is formulated according to Cognitive Behavioural Therapy principles. We label a high quality mental health corpus, which exhibits targeted psychological phenomena. We use the whole unlabelled dataset to train distributed representations of words and sentences. We then investigate two approaches for classifying the user input according to the defined ontology. The first model involves a convolutional neural network"
W18-5606,W16-3613,0,0.0606818,"Missing"
W18-5606,P11-1015,0,0.193493,"Missing"
W18-5606,P17-1163,0,0.0359961,"Missing"
W18-5606,D14-1162,0,0.0844391,"Missing"
W18-5606,P17-1062,0,0.0153634,"gives automated systems a huge advantage over conventional therapies, as they can be used continuously with marginal extra cost. Health assistants that can deliver therapy, have gained great interest in recent years (Bickmore et al., 2005; Fitzpatrick et al., 2017). These systems however are largely based on hand-crafted rules. On the other hand, the main research effort in statistical approaches to conversational systems has focused on limited-domain information seeking dialogues (Schatzmann et al., 2006; Geist and Pietquin, 2011; Gasic and Young, 2014; Fatemi et al., 2016; Li et al., 2016; Williams et al., 2017). In this paper we introduce a new task: understanding of mental health concepts derived from Cognitive Behavioural Therapy (CBT). We present an ontology that is formulated according to Cognitive Behavioural Therapy principles. We label a high quality mental health corpus, which exhibits targeted psychological phenomena. We use the whole unlabelled dataset to train distributed representations of words and sentences. We then investigate two approaches for classifying the user input according to the defined ontology. The first model involves a convolutional neural network (CNN) operating over di"
W18-5606,C16-1025,1,\N,Missing
