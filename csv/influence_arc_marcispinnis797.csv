2013.mtsummit-posters.11,W03-2201,0,0.0442047,"ted (i.e., the output is the same as the input). This issue can be solved if SMT systems provide a runtime integration with existing terminology databases or terminology collections provided by users. Such research has already been proposed, for instance, the popular Moses SMT platform allows the pre-processing of the translatable content during translation by providing possible translation equivalents for phrases. Carl and Langlais (2002) in their research showed that using terminology dictionaries in such a way could increase the translation performance for the English-French language pair. Babych and Hartley (2003) showed that for NE (namely, organisation names) special “do-not-translate” lists allowed increasing translation quality for the English-Russian language pair using a similar pre-processing technique that restricts translation of identified phrases. However, such approaches have been investigated either for languages with simple morphology or categories of phrases that are rarely translated or even left untranslated (e.g., many company and organisation names). A recent study in the FP7 project TTC (2013) has shown that for English-Latvian the preprocessing does not yield positive results for t"
2013.mtsummit-posters.11,bouamor-etal-2012-identifying,0,0.0253222,"on we describe our solution of handling terminology in SMT via online terminology services being developed within the TaaS project. The conceptual design for the integration of terminology services into SMT is also outlined within this paper. Finally, we make conclusions and outline future work in the proposed direction. 2 Related work: terminology handling in statistical machine translation There are several research works reporting improvements of translation quality in terms of automatic machine translation evaluation metrics after integration of multiword expressions in a parallel corpus. Bouamor et al. (2012) observed a gain of +0.3 BLEU points for French-English SMT. Nikoulina et al. (2012) proposed a framework for integrating Named Entities (NE) within SMT. It was shown that the introduced model can lead to +2-3 BLEU points improvement over a baseline system for two different test sets. Current SMT phrase-based models, including Moses (Koehn et al., 2007), do not handle terminology translation. Although domain adaptation can be done using additional in-domain training data (Koehn and Schroeder, 2007), such an approach is very resource intensive and requires SMT model training for each specific d"
2013.mtsummit-posters.11,W02-1402,0,0.0360807,"is the absence of terms in phrase-based SMT translation models. The lack of language (terminology) resources causes the “so-called” missing terminology to be ignored and not translated (i.e., the output is the same as the input). This issue can be solved if SMT systems provide a runtime integration with existing terminology databases or terminology collections provided by users. Such research has already been proposed, for instance, the popular Moses SMT platform allows the pre-processing of the translatable content during translation by providing possible translation equivalents for phrases. Carl and Langlais (2002) in their research showed that using terminology dictionaries in such a way could increase the translation performance for the English-French language pair. Babych and Hartley (2003) showed that for NE (namely, organisation names) special “do-not-translate” lists allowed increasing translation quality for the English-Russian language pair using a similar pre-processing technique that restricts translation of identified phrases. However, such approaches have been investigated either for languages with simple morphology or categories of phrases that are rarely translated or even left untranslate"
2013.mtsummit-posters.11,chen-eisele-2010-integrating,0,0.0276662,"pport for additional phrase table usage along with a general domain phrase table, as well as explicit user-specified translation of known phrases. The above mentioned methods show their potential. However, a certain adaptation of these methods is needed for morphologically rich languages. Another way how to include terminology in phrase-based SMT is through a specific feature which indicates terms in a translation table (Pinnis and Skadiņš, 2012). Using additional phrase tables and explicit user-specified translations of known phrases is a general practice in SMT for different purposes (e.g., Chen and Eisele (2010) use it to create hybrid SMT systems). However, it is not explicitly used for integrating terminology in SMT systems. If we focus on building a domain specific SMT engine, pooling together all available data (especially a significant portion of data that is out of the desired domain) can lead to negative changes in quality, since the out-of-domain training data will overwhelm the in-domain data (Koehn and Schroeder, 2007). Unfortunately, this drawback of domain specific SMT, when only in-domain data is used, is its failure to capture generalisations relevant to the target language. This can le"
2013.mtsummit-posters.11,itagaki-aikawa-2008-post,0,0.0189555,"method is not stable when translating into morphologically rich languages, or the languages with the high level of inflection (e.g., the Baltic and Slavic languages). For such languages the task of terminology translation would also require a morphological synthesiser to be integrated into an SMT system in order to synthesise the correct inflected word form (or word forms for multiword terms) in case a morphologically rich language is used as the target language. 282 There has been research done in terminology translation and in usage of user-provided terminology, in particular. For instance, Itagaki and Aikawa (2008) proposed a module called “Term Swapper” that operated as a wrapper around an SMT system. Okuma et al. (2008) proposed a method for term substitution with high frequency terms from the training data and translation by analogy. The Moses SMT system also provides support for additional phrase table usage along with a general domain phrase table, as well as explicit user-specified translation of known phrases. The above mentioned methods show their potential. However, a certain adaptation of these methods is needed for morphologically rich languages. Another way how to include terminology in phra"
2013.mtsummit-posters.11,J82-2005,0,0.616811,"Missing"
2013.mtsummit-posters.11,W07-0733,0,0.337602,"chine translation evaluation metrics after integration of multiword expressions in a parallel corpus. Bouamor et al. (2012) observed a gain of +0.3 BLEU points for French-English SMT. Nikoulina et al. (2012) proposed a framework for integrating Named Entities (NE) within SMT. It was shown that the introduced model can lead to +2-3 BLEU points improvement over a baseline system for two different test sets. Current SMT phrase-based models, including Moses (Koehn et al., 2007), do not handle terminology translation. Although domain adaptation can be done using additional in-domain training data (Koehn and Schroeder, 2007), such an approach is very resource intensive and requires SMT model training for each specific domain. In cases when language resources are very limited or a user requires translation of a document that is written in a different domain, not covered by available SMT models, domain adaptation is not applicable. This means that terminology diversity within domains is not well-managed with current approaches. For example, a term „tablet” is ambiguous – it can refer to a popular consumer electronics product (a tablet computer), a number of sheets of paper fastened together along one edge (WordNet"
2013.mtsummit-posters.11,lewis-etal-2010-achieving,0,0.0336971,"Missing"
2013.mtsummit-posters.11,P10-2041,0,0.119895,"Missing"
2013.mtsummit-posters.11,W12-5701,0,0.0515697,"services being developed within the TaaS project. The conceptual design for the integration of terminology services into SMT is also outlined within this paper. Finally, we make conclusions and outline future work in the proposed direction. 2 Related work: terminology handling in statistical machine translation There are several research works reporting improvements of translation quality in terms of automatic machine translation evaluation metrics after integration of multiword expressions in a parallel corpus. Bouamor et al. (2012) observed a gain of +0.3 BLEU points for French-English SMT. Nikoulina et al. (2012) proposed a framework for integrating Named Entities (NE) within SMT. It was shown that the introduced model can lead to +2-3 BLEU points improvement over a baseline system for two different test sets. Current SMT phrase-based models, including Moses (Koehn et al., 2007), do not handle terminology translation. Although domain adaptation can be done using additional in-domain training data (Koehn and Schroeder, 2007), such an approach is very resource intensive and requires SMT model training for each specific domain. In cases when language resources are very limited or a user requires translat"
2014.eamt-1.43,P07-2045,0,0.0135804,"Missing"
2014.eamt-1.43,P02-1040,0,0.095246,"Missing"
2014.eamt-1.43,2011.eamt-1.7,1,0.797112,"ories (TM) with machine translation solutions adapted for the particular domain or customer requirements. Building usable machine translation systems for less-resourced languages with complex morphology and syntax is difficult due to a lack of © 2014 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. 1 http://www.kantanmt.com https://www.letsmt.eu 3 http://www.tauyou.com 2 209 2 but useless for translation from English to Estonian and Hungarian (Verleysen, 2013). We started our experiments in 2011 with a simplified scenario (Skadiņš et al., 2011). In the following years we extended this evaluation with new languages as described in Section 4 and made a numerous improvements followed by other evaluation experiment as described in Section 5. Related Work Although experiments on the application of MT for assisting humans in professional translation started more than four decades ago (e.g., Bisbey and Kay 1972; Kay, 1980), it got more attention from the research community only in the late 1990s, with various studies on post-editing and machine translatability (e.g., Berry, 1997; Bruckner and Plitt, 2001). A comprehensive overview of resea"
2014.eamt-1.43,steinberger-etal-2012-dgt,0,0.123986,"roductivity. The experiment was performed for four language pairs: English-Latvian, EnglishPolish, English-Czech and English-Hungarian with domain specific SMT systems. 4.1 MT Systems The MT systems were slightly different for different language pairs depending on available training resources. We used domain specific training data available to the companies participating in the experiment. For English-Latvian MT we used the best available MT system (Skadiņš et al., 2010) that also includes knowledge about Latvian morphology and some out-of-domain publicly available training data, like DGT-TM (Steinberger et al., 2012) and OPUS EMEA (Tiedemann, 2009). Two different SMT systems where trained for Polish and Czech. The first Polish MT engine (v1) was trained using all available parallel data from localization company production data (data of various clients); the second MT engine (v2) 212 was trained on smaller client specific data. The first Czech MT engine (v1) was trained using small client specific parallel data from localization company production data and the Czech National Corpus (topic: tech domain)5; the second MT engine (v2) was trained using only company production data (data of various clients). We"
2014.eamt-1.43,P12-3008,1,0.838957,"Missing"
2014.eamt-1.43,1997.mtsummit-systems.6,0,0.0356196,"Missing"
2014.eamt-1.43,W11-2107,0,0.0467248,"Missing"
2014.eamt-1.43,2009.mtsummit-commercial.5,0,0.0440929,"Missing"
2015.eamt-1.13,W14-4803,0,0.0724209,"ain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can significantly improve translation quality of an out-of-domain system (up to +2.13 BLEU points). Their method specifically addressed morphologically rich languages by identifying terms in different inflected forms using stemming tools. Similar work that shows significant quality improvements has been recently performed by Arcan et al. (2014a) for the English-Italian language pair. They use a term collection to create a ” fill-up” translation model that consists of a pre-trained SMT system’s phrase table merged with a phrase table created from the bilingual terminology. However, all these methods require to re-train the whole SMT system (or at least re-tune the SMT system) if new in-domain data becomes available. For many translation tasks such a scenario is not economically justifiable. Furthermore, if we have already trained a relatively good SMT system (let it be a general domain system or a close-domain system to the domain t"
2015.eamt-1.13,2014.amta-researchers.5,0,0.0650165,"ain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can significantly improve translation quality of an out-of-domain system (up to +2.13 BLEU points). Their method specifically addressed morphologically rich languages by identifying terms in different inflected forms using stemming tools. Similar work that shows significant quality improvements has been recently performed by Arcan et al. (2014a) for the English-Italian language pair. They use a term collection to create a ” fill-up” translation model that consists of a pre-trained SMT system’s phrase table merged with a phrase table created from the bilingual terminology. However, all these methods require to re-train the whole SMT system (or at least re-tune the SMT system) if new in-domain data becomes available. For many translation tasks such a scenario is not economically justifiable. Furthermore, if we have already trained a relatively good SMT system (let it be a general domain system or a close-domain system to the domain t"
2015.eamt-1.13,W03-2201,0,0.259877,"ng of SMT systems. For instance, the Moses SMT system supports input data (in the Moses XML format) that is enriched with externally generated translation candidates. Using this methodology, Carl & Langlais (2002) used term dictionaries to pre-process source text and achieved an increase in translation quality for the English-French language pair. Similarly, Arcan et al. (2014a) identify exactly matched terms and provide translation equivalents from the Wiki Machine1 by performing context-based disambiguation if there are multiple translation equivalents for a single term for English-Italian. Babych & Hartley (2003) showed that inclusion of certain named entities in “do-not-translate” lists allowed to increase translation quality for the English-Russian language pair. Recently dynamic translation and language models (Bertoldi, 2014) have been investigated for integration of terminology into SMT (Arcan et al., 2014b) for English-Italian. It is evident that most of the related research has, however, mostly focused on languages with simple morphology or translation of phrases that are rarely 1 The Wiki Machine is available https://bitbucket.org/fbk/thewikimachine online at: 90 translated or even left untran"
2015.eamt-1.13,W09-0432,0,0.0195316,"terminology translation quality in the SMT suggestions. Therefore, effective methods that can benefit from custom term collections are necessary. Researchers have tried to address the terminology integration challenge directly by using indomain term collections and indirectly by tackling the broader challenge of domain adaptation. Significant research efforts have been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to specific domains (to name but a few, Koehn & Schroeder (2007), Bertoldi & Federico (2009), Hildebrand et al. (2005), and many others). Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT. E.g., Bouamor et al. (2012) showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can s"
2015.eamt-1.13,bouamor-etal-2012-identifying,0,0.13697,"tion challenge directly by using indomain term collections and indirectly by tackling the broader challenge of domain adaptation. Significant research efforts have been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to specific domains (to name but a few, Koehn & Schroeder (2007), Bertoldi & Federico (2009), Hildebrand et al. (2005), and many others). Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT. E.g., Bouamor et al. (2012) showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can significantly improve translation quality of an out-of-domain system (up to +2.13 BLEU points). Their method specifically addressed morphologically rich languages by identifying terms"
2015.eamt-1.13,W02-1402,0,0.167192,"we have already trained a relatively good SMT system (let it be a general domain system or a close-domain system to the domain that is needed), we should be able to tailor it to the required domain with the help of just the right bilingual terminology. Consequently, considerable research efforts have been focussed also on dynamic integration methods for term collections in SMT that do not require re-training of SMT systems. For instance, the Moses SMT system supports input data (in the Moses XML format) that is enriched with externally generated translation candidates. Using this methodology, Carl & Langlais (2002) used term dictionaries to pre-process source text and achieved an increase in translation quality for the English-French language pair. Similarly, Arcan et al. (2014a) identify exactly matched terms and provide translation equivalents from the Wiki Machine1 by performing context-based disambiguation if there are multiple translation equivalents for a single term for English-Italian. Babych & Hartley (2003) showed that inclusion of certain named entities in “do-not-translate” lists allowed to increase translation quality for the English-Russian language pair. Recently dynamic translation and l"
2015.eamt-1.13,C14-2028,0,0.0655285,"Missing"
2015.eamt-1.13,2005.eamt-1.19,0,0.0431302,"ity in the SMT suggestions. Therefore, effective methods that can benefit from custom term collections are necessary. Researchers have tried to address the terminology integration challenge directly by using indomain term collections and indirectly by tackling the broader challenge of domain adaptation. Significant research efforts have been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to specific domains (to name but a few, Koehn & Schroeder (2007), Bertoldi & Federico (2009), Hildebrand et al. (2005), and many others). Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT. E.g., Bouamor et al. (2012) showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can significantly improve trans"
2015.eamt-1.13,P07-2045,0,0.00682195,"Missing"
2015.eamt-1.13,W07-0733,0,0.0235323,"e possible to ensure high terminology translation quality in the SMT suggestions. Therefore, effective methods that can benefit from custom term collections are necessary. Researchers have tried to address the terminology integration challenge directly by using indomain term collections and indirectly by tackling the broader challenge of domain adaptation. Significant research efforts have been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to specific domains (to name but a few, Koehn & Schroeder (2007), Bertoldi & Federico (2009), Hildebrand et al. (2005), and many others). Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT. E.g., Bouamor et al. (2012) showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in"
2015.eamt-1.13,W12-5701,0,0.0174593,"support from languagespecific stemming tools to identify terms in different inflected forms. 2.2 are in total 18 inflection rules specified for 99 term phrase patterns from TWSC. • The second method (Corpus) is language independent and relies on the SMT system’s monolingual corpus (e.g., the corpus that is used for language modelling) to identify inflected forms of terms using a similar method to the Fast Term Identification. Inflected Form Generation The next pre-processing step after term identification is the generation of translation candidates for the identified terms. Previous research (Nikoulina et al., 2012; Carl & Langlais, 2002; Babych & Hartley, 2003) on source text pre-processing has not given special attention to this question, because the bilingual term collections already “provide” translation equivalents. However, the issue is that the terms that are provided in the bilingual term collections are usually in their canonical forms. For morphologically rich languages the canonical forms in many contexts are not the required inflected forms. Because of the focus on language pairs that do not require (or require very limited) morphological generation (e.g., English-French, English-German, etc"
2015.eamt-1.13,P02-1040,0,0.0957496,"been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to specific domains (to name but a few, Koehn & Schroeder (2007), Bertoldi & Federico (2009), Hildebrand et al. (2005), and many others). Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT. E.g., Bouamor et al. (2012) showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can significantly improve translation quality of an out-of-domain system (up to +2.13 BLEU points). Their method specifically addressed morphologically rich languages by identifying terms in different inflected forms using stemming tools. Similar work that shows significant quality improvements has been recently performed by Arcan et al. (2014a) for the English-Ita"
2015.eamt-1.13,2014.eamt-1.43,1,0.826618,"Missing"
2015.eamt-1.13,steinberger-etal-2012-dgt,0,0.0302338,"analysed, which pre-processing configuration allows achieving better results (see Figure 3). This analysis was performed for English-Latvian using a term collection that was created by a professional translator from the tuning-data. The term collection consists of 644 term pairs (terms were included only in their canonical forms). The results show that all combiAutomatic Evaluation The automatic evaluation was performed for three language pairs (English-German, Latvian, and Lithuanian) using general domain SMT systems that were trained in the LetsMT platform using the DGT-TM parallel corpus (Steinberger et al., 2012) (the releases of 2007, 2011, and 2012). For evaluation, the author uses a proprietary parallel corpus of 872 sentence pairs in the automotive domain (technical documentation from car service manuals). The original data set was available for English-Latvian, therefore, the remaining two data sets for German and Lithuanian were prepared by professional translators. For English-Latvian an in-domain tuning set of 1,745 sentence pairs was available; for the remaining systems held-out sets of 2,000 sentence pairs from the training data were used for SMT system tuning. The results of the baseline sy"
2015.eamt-1.13,P12-3008,0,0.0488542,"Missing"
2020.amta-user.11,hajlaoui-etal-2014-dcep,0,0.0264368,"Missing"
2020.amta-user.11,P18-4020,0,0.0250187,"Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 2: MT User Track Page 219 monolingual documents, and performed cross-lingual alignment with consecutive parallel data extraction to acquire parallel corpora. • Translation memories from Tilde’s partner. The in-domain data that were used to finetune NMT systems were provided by Hieronymus, thereby ensuring that the trained NMT systems are tailored specifically to the Swiss language context. 3.2 NMT System Training and Domain Adaptation For the training of NMT models, we use the Marian NMT toolkit (Junczys-Dowmunt et al., 2018) as it provides the most efficient implementation for training and inference of any standard NMT model. We use Marian’s standard configuration4 of the transformer-base model (Vaswani et al., 2017). We select training batch sizes dynamically so that they fit in a workspace of 9,00022,500 MB (depending on GPU specification). We train models with early stopping (Prechelt, 1998), using ten consecutive evaluations with no improvement in translation quality on the development set as the stopping criterion. The high level view of NMT system training: 1. First, pre-process all data using Tilde’s paral"
2020.amta-user.11,2005.mtsummit-papers.11,0,0.426361,"Missing"
2020.amta-user.11,P02-1040,0,0.109556,"vide subword-unit-based statistical alignments as an additional input data stream for learning guided alignments, which are important for formatting-rich document translation and integration in computer-assisted translation tools. 6. Finally, we adapt the systems, thereby ensuring conformity to Swiss language specificities and style. Domain adaptation is performed using a 1-1 mix of in-domain Swiss data with an equal amount randomly sampled from the remaining data. 3.3 NMT System Quality Figure 1 gives results of automatic evaluation of translation quality of LexMachina MT systems using BLEU (Papineni et al., 2002) metric. The performance of publicly available Google Translate general domain systems is given for the reference. Results show that LexMachina MT systems yield substantially better quality (12.3 BLEU higher on average) than the publicly available counterparts. The substantial difference in performance suggests that the strategy to approaching Hieronymus’ requirements for Swiss language and domain-specific MT systems as a two-fold domain adaptation problem has been successful. 4 https://github.com/marian-nmt/marian-examples/tree/master/transformer Proceedings of the 14th Conference of the Asso"
2020.amta-user.11,L18-1214,1,0.868964,"Missing"
2020.amta-user.11,W17-0235,0,0.0250472,"Missing"
2020.amta-user.11,steinberger-etal-2012-dgt,0,0.0681275,"Missing"
2020.amta-user.11,P12-3008,0,0.0815454,"Missing"
2020.amta-user.25,E17-3017,0,0.0315605,"esidency (back in 2017 and 2018) were trained using Nematus (Sennrich et al., 2017), an NMT toolkit that allowed us to develop recurrent neural network-based NMT models with multiplicative long short-term memory (MLSTM) units (Krause et al., 2016; Pinnis et al., 2017). The models were deployed in Tilde MT using the AmuNMT decoder (Junczys-Dowmunt et al., 2016), which is faster than Nematus and allows using models trained with Nematus. At the end of 2018, we re-trained the models of the Estonian EU Council Presidency using Transformer (Vaswani et al., 2017) models from the Sockeye NMT toolkit (Hieber et al., 2017). We selected Sockeye as it allowed us to train the best-performing NMT systems at the WMT 2018 shared task on news translation for EN↔ET (Bojar et al., 2018; Pinnis et al., 2018a). However, as Sockeye was relatively slow and did not have features necessary for high-quality formatting-rich document translation, all other NMT systems were developed using the Marian NMT toolkit (Junczys-Dowmunt et al., 2018). Marian provides support for guided alignments that are necessary to support formattingrich document translation. A list that shows which NMT toolkits were used for the different custom NMT"
2020.amta-user.25,P18-4020,0,0.0165287,"ows using models trained with Nematus. At the end of 2018, we re-trained the models of the Estonian EU Council Presidency using Transformer (Vaswani et al., 2017) models from the Sockeye NMT toolkit (Hieber et al., 2017). We selected Sockeye as it allowed us to train the best-performing NMT systems at the WMT 2018 shared task on news translation for EN↔ET (Bojar et al., 2018; Pinnis et al., 2018a). However, as Sockeye was relatively slow and did not have features necessary for high-quality formatting-rich document translation, all other NMT systems were developed using the Marian NMT toolkit (Junczys-Dowmunt et al., 2018). Marian provides support for guided alignments that are necessary to support formattingrich document translation. A list that shows which NMT toolkits were used for the different custom NMT systems of the EU Council Presidency Translator is given in Table 1. Custom NMT systems for all EU Council presidencies were trained using domain-specific MT system training recipes. Baseline models were trained using both in-domain and out-ofdomain data, after which NMT models were fine-tuned on in-domain (presidency-specific) datasets. The in-domain datasets depending on each presidency were collected by"
2020.amta-user.25,W18-1910,1,0.897554,"Missing"
2020.amta-user.25,W17-4737,1,0.485981,"Missing"
2020.amta-user.25,W18-6423,1,0.890635,"Missing"
2020.amta-user.25,L18-1214,1,0.901276,"Missing"
2020.amta-user.25,W16-6301,0,0.0259608,"an Health Organization (PAHO) has developed their MT system already in 1980, starting with English and Spanish and later extending to Portuguese (Aymerich, 2005). The World Intellectual Property Organization (WIPO) has developed its MT tool, WIPO Translate, for ten languages (Pouliquen, 2017) and primary use it for patent translation but also offer it to other UN bodies (Pouliquen et al., 2013) and international organizations, such as the International Monetary Fund (IMF), Food and Agriculture Organization (FAO), International Telecommunication Union (ITU), and World Trade Organization (WTO) (Pouliquen, 2016). The European Patent Office has cooperated with Google by providing its data and using Google Translate technologies for patent search. European Commission (EC) started to use a customized version of the MT system Systran in 1976, becoming one of the first large-scale adopters of MT(Petrits, 2001). In 2010, the European Commission began to develop its MT system based on the Moses toolkit and released it as the MT@EC tool in 2013 with support for all 24 official languages of the European Union (EU) (Eisele et al., 2011). In 2017, EC migrated its MT platform to neural MT (NMT) technologies and"
2020.amta-user.25,2013.mtsummit-user.7,0,0.0265317,"esidency. 1 Introduction Large international organizations face the challenge of language barriers in their everyday work; thus, it is not surprising that they show a strong interest in machine translation (MT). The Pan American Health Organization (PAHO) has developed their MT system already in 1980, starting with English and Spanish and later extending to Portuguese (Aymerich, 2005). The World Intellectual Property Organization (WIPO) has developed its MT tool, WIPO Translate, for ten languages (Pouliquen, 2017) and primary use it for patent translation but also offer it to other UN bodies (Pouliquen et al., 2013) and international organizations, such as the International Monetary Fund (IMF), Food and Agriculture Organization (FAO), International Telecommunication Union (ITU), and World Trade Organization (WTO) (Pouliquen, 2016). The European Patent Office has cooperated with Google by providing its data and using Google Translate technologies for patent search. European Commission (EC) started to use a customized version of the MT system Systran in 1976, becoming one of the first large-scale adopters of MT(Petrits, 2001). In 2010, the European Commission began to develop its MT system based on the Mos"
2020.amta-user.25,2014.amta-users.13,1,0.424181,"Missing"
2020.eamt-1.60,P16-1009,0,0.0333115,"ll provide a capacity service to eTranslation by building a near-human-professionalquality neural engine farm which includes all EU ∗ language combinations. State-of-the-art technologies such as the transformer (Vaswani et al., 2017) architecture will be implemented. Moreover, lower-resourced languages (for example, Irish or Maltese) will be a challenge, and more effort will be required to obtain well-performing engines for them. In order to obtain the best results, we will experiment with techniques to supplement the original data, such as generating synthetic data by doing back-translation (Sennrich et al., 2016), checking of sentence alignments, transfer learning (Zoph et al., 2016) and unsupervised learning on a monolingual corpus (Artetxe et al., 2019). In addition to providing the trained engines, the NTEU consortium will gather and clean data from all language combinations so that the engines can be retrained with other technologies in the future. As part of the national digital data gathering efforts, NTEU will also act as a bridge between previous efforts, putting to work the results of the ELRC6 repository and other European data gathering efforts such as the NEC TM7 and ParaCrawl8 projects. T"
2020.eamt-1.60,D16-1163,0,0.0182973,"ssionalquality neural engine farm which includes all EU ∗ language combinations. State-of-the-art technologies such as the transformer (Vaswani et al., 2017) architecture will be implemented. Moreover, lower-resourced languages (for example, Irish or Maltese) will be a challenge, and more effort will be required to obtain well-performing engines for them. In order to obtain the best results, we will experiment with techniques to supplement the original data, such as generating synthetic data by doing back-translation (Sennrich et al., 2016), checking of sentence alignments, transfer learning (Zoph et al., 2016) and unsupervised learning on a monolingual corpus (Artetxe et al., 2019). In addition to providing the trained engines, the NTEU consortium will gather and clean data from all language combinations so that the engines can be retrained with other technologies in the future. As part of the national digital data gathering efforts, NTEU will also act as a bridge between previous efforts, putting to work the results of the ELRC6 repository and other European data gathering efforts such as the NEC TM7 and ParaCrawl8 projects. Therefore, the project will promote the free flow of data between public"
2020.wmt-1.15,abdelali-etal-2014-amara,0,0.030657,"sed to train the unconstrained systems were Open Subtitles from the Opus corpus (Tiedemann, 2016), ParaCrawl (Ban´on et al., 2020) (although it was discarded due to noise found in the corpus), DGT Translation Memories (Steinberger et al., 2012), Microsoft Translation and User Interface Strings Glossaries3 from multiple releases up to 2018, the Tilde MODEL corpus (Rozis and Skadin¸sˇ , 2017), WikiMatrix (Schwenk et al., 2019), Digital Corpus of the European Parliament (Hajlaoui et al., 2014), JRC-Acquis (Steinberger et al., 2006), Europarl (Koehn, 2005), and the QCRI Educational Domain Corpus (Abdelali et al., 2014). 2.1 Data Filtering and Pre-Processing First, we filtered data using Tilde’s parallel data filtering methods (Pinnis, 2018) that allow discarding sentence pairs that are corrupted, have low content overlap, feature wrong language content, feature too high non-letter ratio, etc. The exact filter configuration is defined in the paper by (Pinnis, 2018). Then, we pre-processed all data using Tilde’s parallel data pre-processing workflow that nor1 http://www.statmt.org/wmt20/translation-task.html https://www.tilde.com/products-and-services/datalibrary 3 https://www.microsoft.com/en-us/language/tra"
2020.wmt-1.15,2020.acl-main.417,0,0.0625889,"Missing"
2020.wmt-1.15,W18-6478,0,0.150514,"e translation toolkit. Additionally, we experiment with different parallel and monolingual data selection schemes, as well as sampled backtranslation. Our final models are ensembles of Transformer base and Transformer big models which feature right-to-left re-ranking. 1 2 Introduction This year, we developed both constrained and unconstrained NMT systems for the English↔Polish language pair. We base our methods on the submissions of the previous years (Pinnis et al., 2017b, 2018, 2019) including methods for parallel data filtering from Pinnis (2018). Specifically, we lean on Pinnis (2018) and Junczys-Dowmunt (2018) for data selection and filtering, (Pinnis et al., 2017b) for morphologically motivated sub-word units and synthetic data generation, Edunov et al. (2018) for sampled back-translation and finally Morishita et al. (2018) for re-ranking with right-to-left models. We use the Marian toolkit (Junczys-Dowmunt et al., 2018) to train models of Transformer architecture (Vaswani et al., 2017). Although document level NMT as showcased by (Junczys-Dowmunt, 2019) have yielded promising results for the English-German language pair, we were not able to collect sufficient document level data for the English-P"
2020.wmt-1.15,W19-5321,0,0.0217936,"s (Pinnis et al., 2017b, 2018, 2019) including methods for parallel data filtering from Pinnis (2018). Specifically, we lean on Pinnis (2018) and Junczys-Dowmunt (2018) for data selection and filtering, (Pinnis et al., 2017b) for morphologically motivated sub-word units and synthetic data generation, Edunov et al. (2018) for sampled back-translation and finally Morishita et al. (2018) for re-ranking with right-to-left models. We use the Marian toolkit (Junczys-Dowmunt et al., 2018) to train models of Transformer architecture (Vaswani et al., 2017). Although document level NMT as showcased by (Junczys-Dowmunt, 2019) have yielded promising results for the English-German language pair, we were not able to collect sufficient document level data for the English-Polish language pair. As a result, all our systems this year translate individual sentences. Data For training of the constrained NMT systems, we used data from the WMT 2020 shared task on news translation1 . For unconstrained systems, we used data from the Tilde Data Library2 . The 10 largest publicly available datasets that were used to train the unconstrained systems were Open Subtitles from the Opus corpus (Tiedemann, 2016), ParaCrawl (Ban´on et a"
2020.wmt-1.15,2005.mtsummit-papers.11,0,0.0232384,"The 10 largest publicly available datasets that were used to train the unconstrained systems were Open Subtitles from the Opus corpus (Tiedemann, 2016), ParaCrawl (Ban´on et al., 2020) (although it was discarded due to noise found in the corpus), DGT Translation Memories (Steinberger et al., 2012), Microsoft Translation and User Interface Strings Glossaries3 from multiple releases up to 2018, the Tilde MODEL corpus (Rozis and Skadin¸sˇ , 2017), WikiMatrix (Schwenk et al., 2019), Digital Corpus of the European Parliament (Hajlaoui et al., 2014), JRC-Acquis (Steinberger et al., 2006), Europarl (Koehn, 2005), and the QCRI Educational Domain Corpus (Abdelali et al., 2014). 2.1 Data Filtering and Pre-Processing First, we filtered data using Tilde’s parallel data filtering methods (Pinnis, 2018) that allow discarding sentence pairs that are corrupted, have low content overlap, feature wrong language content, feature too high non-letter ratio, etc. The exact filter configuration is defined in the paper by (Pinnis, 2018). Then, we pre-processed all data using Tilde’s parallel data pre-processing workflow that nor1 http://www.statmt.org/wmt20/translation-task.html https://www.tilde.com/products-and-ser"
2020.wmt-1.15,W18-6421,0,0.0831858,"big models which feature right-to-left re-ranking. 1 2 Introduction This year, we developed both constrained and unconstrained NMT systems for the English↔Polish language pair. We base our methods on the submissions of the previous years (Pinnis et al., 2017b, 2018, 2019) including methods for parallel data filtering from Pinnis (2018). Specifically, we lean on Pinnis (2018) and Junczys-Dowmunt (2018) for data selection and filtering, (Pinnis et al., 2017b) for morphologically motivated sub-word units and synthetic data generation, Edunov et al. (2018) for sampled back-translation and finally Morishita et al. (2018) for re-ranking with right-to-left models. We use the Marian toolkit (Junczys-Dowmunt et al., 2018) to train models of Transformer architecture (Vaswani et al., 2017). Although document level NMT as showcased by (Junczys-Dowmunt, 2019) have yielded promising results for the English-German language pair, we were not able to collect sufficient document level data for the English-Polish language pair. As a result, all our systems this year translate individual sentences. Data For training of the constrained NMT systems, we used data from the WMT 2020 shared task on news translation1 . For unconst"
2020.wmt-1.15,W19-5333,0,0.0482205,"Missing"
2020.wmt-1.15,W18-6486,1,0.926718,"nsformer base models that we train using the Marian machine translation toolkit. Additionally, we experiment with different parallel and monolingual data selection schemes, as well as sampled backtranslation. Our final models are ensembles of Transformer base and Transformer big models which feature right-to-left re-ranking. 1 2 Introduction This year, we developed both constrained and unconstrained NMT systems for the English↔Polish language pair. We base our methods on the submissions of the previous years (Pinnis et al., 2017b, 2018, 2019) including methods for parallel data filtering from Pinnis (2018). Specifically, we lean on Pinnis (2018) and Junczys-Dowmunt (2018) for data selection and filtering, (Pinnis et al., 2017b) for morphologically motivated sub-word units and synthetic data generation, Edunov et al. (2018) for sampled back-translation and finally Morishita et al. (2018) for re-ranking with right-to-left models. We use the Marian toolkit (Junczys-Dowmunt et al., 2018) to train models of Transformer architecture (Vaswani et al., 2017). Although document level NMT as showcased by (Junczys-Dowmunt, 2019) have yielded promising results for the English-German language pair, we were n"
2020.wmt-1.15,W17-4737,1,0.892997,"Missing"
2020.wmt-1.15,W19-5335,1,0.885839,"Missing"
2020.wmt-1.15,W18-6423,1,0.838642,"Missing"
2020.wmt-1.15,W17-0235,0,0.0310239,"Missing"
2020.wmt-1.15,steinberger-etal-2012-dgt,0,0.0607645,"Missing"
2020.wmt-1.15,steinberger-etal-2006-jrc,0,0.0356076,"data from the Tilde Data Library2 . The 10 largest publicly available datasets that were used to train the unconstrained systems were Open Subtitles from the Opus corpus (Tiedemann, 2016), ParaCrawl (Ban´on et al., 2020) (although it was discarded due to noise found in the corpus), DGT Translation Memories (Steinberger et al., 2012), Microsoft Translation and User Interface Strings Glossaries3 from multiple releases up to 2018, the Tilde MODEL corpus (Rozis and Skadin¸sˇ , 2017), WikiMatrix (Schwenk et al., 2019), Digital Corpus of the European Parliament (Hajlaoui et al., 2014), JRC-Acquis (Steinberger et al., 2006), Europarl (Koehn, 2005), and the QCRI Educational Domain Corpus (Abdelali et al., 2014). 2.1 Data Filtering and Pre-Processing First, we filtered data using Tilde’s parallel data filtering methods (Pinnis, 2018) that allow discarding sentence pairs that are corrupted, have low content overlap, feature wrong language content, feature too high non-letter ratio, etc. The exact filter configuration is defined in the paper by (Pinnis, 2018). Then, we pre-processed all data using Tilde’s parallel data pre-processing workflow that nor1 http://www.statmt.org/wmt20/translation-task.html https://www.ti"
2020.wmt-1.15,L16-1559,0,0.0150133,"as showcased by (Junczys-Dowmunt, 2019) have yielded promising results for the English-German language pair, we were not able to collect sufficient document level data for the English-Polish language pair. As a result, all our systems this year translate individual sentences. Data For training of the constrained NMT systems, we used data from the WMT 2020 shared task on news translation1 . For unconstrained systems, we used data from the Tilde Data Library2 . The 10 largest publicly available datasets that were used to train the unconstrained systems were Open Subtitles from the Opus corpus (Tiedemann, 2016), ParaCrawl (Ban´on et al., 2020) (although it was discarded due to noise found in the corpus), DGT Translation Memories (Steinberger et al., 2012), Microsoft Translation and User Interface Strings Glossaries3 from multiple releases up to 2018, the Tilde MODEL corpus (Rozis and Skadin¸sˇ , 2017), WikiMatrix (Schwenk et al., 2019), Digital Corpus of the European Parliament (Hajlaoui et al., 2014), JRC-Acquis (Steinberger et al., 2006), Europarl (Koehn, 2005), and the QCRI Educational Domain Corpus (Abdelali et al., 2014). 2.1 Data Filtering and Pre-Processing First, we filtered data using Tilde"
2020.wmt-1.73,J82-2005,0,0.70788,"Missing"
2020.wmt-1.73,N19-3002,0,0.0397096,"25.8 percentage points. 1 Introduction Most modern natural language processing (NLP) systems learn from natural language data. Findings of social sciences and corpus linguistics, however, indicate various forms of bias in the way humans *First authors with equal contribution. use language (Coates, 1987; Butler, 1990; FuertesOlivera, 2007; Rickford, 2016). Thus the resulting NLP resources and systems also suffer from the same socially constructed biases, as well as inaccuracies and incompleteness (Jørgensen et al., 2015; Hovy and Søgaard, 2015; Prates et al., 2019; Vanmassenhove et al., 2019; Bordia and Bowman, 2019; Davidson et al., 2019; Tan and Celis, 2019). Due to the prevalent use of NLP systems, their susceptibility to social biases becomes an increasingly significant concern as NLP systems not only reflect the biases learned but also amplify and perpetuate them further (Hovy and Spruit, 2016; Crawford, 2017; HLEG, 2019). This work concerns mitigating the manifestations of gender bias in the outputs of neural machine translation (NMT) systems in scenarios where the source language does not encode the information about gender that is required in the target language. An example is the translation of"
2020.wmt-1.73,D16-1245,0,0.0145538,"target language sentence during inference. Thus, we use co-reference resolution tools and extract the referential gender information from the source sentence instead. To do so, we first use co-reference resolution tools to obtain the co-reference graph. We then identify sub-graphs which contain gendered pronouns. Finally, we propagate the gender information within the graph and annotate the antecedents (see Figure 2). We set the annotations for the remaining unannotated words to U. We use neural co-reference resolution tools by AllenNLP 3 (Lee et al., 2017) and Hugging Face4 (based on work by Clark and Manning (2016)). We refer to these systems as TGA AllenNLP and TGA HuggingFace respectively. We also report the performance of NMT with TGA, when TGA use oracle information directly taken from WinoMT datasets and refer to these as TGA Oracle. Table 2: Performance of morphological taggers on gender feature classification evaluated on the Universal Dependencies test set. could also render WinoMT evaluation unreliable. Thus we first benchmark several morphological taggers on grammatical gender feature classification. We use Latvian as a development language because of the availability of lexicon-based and data"
2020.wmt-1.73,W19-3504,0,0.0255467,"1 Introduction Most modern natural language processing (NLP) systems learn from natural language data. Findings of social sciences and corpus linguistics, however, indicate various forms of bias in the way humans *First authors with equal contribution. use language (Coates, 1987; Butler, 1990; FuertesOlivera, 2007; Rickford, 2016). Thus the resulting NLP resources and systems also suffer from the same socially constructed biases, as well as inaccuracies and incompleteness (Jørgensen et al., 2015; Hovy and Søgaard, 2015; Prates et al., 2019; Vanmassenhove et al., 2019; Bordia and Bowman, 2019; Davidson et al., 2019; Tan and Celis, 2019). Due to the prevalent use of NLP systems, their susceptibility to social biases becomes an increasingly significant concern as NLP systems not only reflect the biases learned but also amplify and perpetuate them further (Hovy and Spruit, 2016; Crawford, 2017; HLEG, 2019). This work concerns mitigating the manifestations of gender bias in the outputs of neural machine translation (NMT) systems in scenarios where the source language does not encode the information about gender that is required in the target language. An example is the translation of the English sentence “T"
2020.wmt-1.73,N13-1073,0,0.0202822,"Missing"
2020.wmt-1.73,P15-2079,0,0.0164991,"show that this allows improving accuracy on the WinoMT test set by up to 25.8 percentage points. 1 Introduction Most modern natural language processing (NLP) systems learn from natural language data. Findings of social sciences and corpus linguistics, however, indicate various forms of bias in the way humans *First authors with equal contribution. use language (Coates, 1987; Butler, 1990; FuertesOlivera, 2007; Rickford, 2016). Thus the resulting NLP resources and systems also suffer from the same socially constructed biases, as well as inaccuracies and incompleteness (Jørgensen et al., 2015; Hovy and Søgaard, 2015; Prates et al., 2019; Vanmassenhove et al., 2019; Bordia and Bowman, 2019; Davidson et al., 2019; Tan and Celis, 2019). Due to the prevalent use of NLP systems, their susceptibility to social biases becomes an increasingly significant concern as NLP systems not only reflect the biases learned but also amplify and perpetuate them further (Hovy and Spruit, 2016; Crawford, 2017; HLEG, 2019). This work concerns mitigating the manifestations of gender bias in the outputs of neural machine translation (NMT) systems in scenarios where the source language does not encode the information about gender"
2020.wmt-1.73,P16-2096,0,0.0308099,"(Coates, 1987; Butler, 1990; FuertesOlivera, 2007; Rickford, 2016). Thus the resulting NLP resources and systems also suffer from the same socially constructed biases, as well as inaccuracies and incompleteness (Jørgensen et al., 2015; Hovy and Søgaard, 2015; Prates et al., 2019; Vanmassenhove et al., 2019; Bordia and Bowman, 2019; Davidson et al., 2019; Tan and Celis, 2019). Due to the prevalent use of NLP systems, their susceptibility to social biases becomes an increasingly significant concern as NLP systems not only reflect the biases learned but also amplify and perpetuate them further (Hovy and Spruit, 2016; Crawford, 2017; HLEG, 2019). This work concerns mitigating the manifestations of gender bias in the outputs of neural machine translation (NMT) systems in scenarios where the source language does not encode the information about gender that is required in the target language. An example is the translation of the English sentence “The secretary asked for details.” into Latvian. In English, the gender of “secretary” is ambiguous. In Latvian, however, there is a choice between the masculine noun “sekret¯ars” and the feminine noun “sekret¯are”. In cases when sentences do not contain the necessar"
2020.wmt-1.73,W15-4302,0,0.0122834,"s on five language pairs show that this allows improving accuracy on the WinoMT test set by up to 25.8 percentage points. 1 Introduction Most modern natural language processing (NLP) systems learn from natural language data. Findings of social sciences and corpus linguistics, however, indicate various forms of bias in the way humans *First authors with equal contribution. use language (Coates, 1987; Butler, 1990; FuertesOlivera, 2007; Rickford, 2016). Thus the resulting NLP resources and systems also suffer from the same socially constructed biases, as well as inaccuracies and incompleteness (Jørgensen et al., 2015; Hovy and Søgaard, 2015; Prates et al., 2019; Vanmassenhove et al., 2019; Bordia and Bowman, 2019; Davidson et al., 2019; Tan and Celis, 2019). Due to the prevalent use of NLP systems, their susceptibility to social biases becomes an increasingly significant concern as NLP systems not only reflect the biases learned but also amplify and perpetuate them further (Hovy and Spruit, 2016; Crawford, 2017; HLEG, 2019). This work concerns mitigating the manifestations of gender bias in the outputs of neural machine translation (NMT) systems in scenarios where the source language does not encode the i"
2020.wmt-1.73,W04-3250,0,0.248424,"ositive effect on BLEU, thus confirming our hypothesis why and how the NMT system learns to rely on TGA as an additional source of information during training (see Table 4). It is equally important, however, that, when training NMT systems to use TGA, it does not degrade their performance when gender information is not necessary or is unavailable. Thus we test our systems for such cases by setting all TGA values to U and compare them to the baseline systems (see Table 4). To test for statistically significant differences between the results of NMT systems we use pairwise bootstrap resampling (Koehn, 2004) and significance threshold of 0.05. Results indicate no statistically significant differences between systems using uninformative TGA values and their baseline counterparts with an exception of results for EN-RU systems (∆0.4 BLEU), which we find to be statistically significant. M:F 4.9 1.7 2.6 2.3 Table 3: Results on WinoMT test suite. is the least biased with the M:F ratio being much lower – 2.6 (see the last column of Table 3). Our baseline systems for EN-DE, EN-FR and EN-RU language pairs, however, show comparable ∆G and WinoMT accuracy results to those reported by Stanovsky et al. (2019)"
2020.wmt-1.73,P07-2045,0,0.00745218,"S – difference in accuracy between the set of sentences that either align with or diverge from the gender stereotypes of each profession. Saunders and Byrne (2020) also propose to report M:F – ratio of translations using masculine and feminine antecedents. 3 Experimental Setting Languages and Data In all our experiments, we choose one source language without grammatical gender and five Indo-European languages in which nouns have grammatical gender (see Table 1). For all language pairs, we use training data from WMT news translation tasks. We do the necessary cleaning and filtering with Moses (Koehn et al., 2007) pre-processing tools. To see how TGA is affected by data size, we also use much larger EN-LV propriEN-DE EN-FR EN-LV EN-LV EN-LT EN-RU Source # Sent. News Test WMT19 WMT15 Tilde WMT17 WMT19 WMT17 64.1M 39.1M 22.7M 4.5M 3.6M 25.0M 2018 2015 2017 2017 2019 2015 Table 1: Training data set source and size in millions of sentences prior to adding TGA. etary data that we obtain from Tilde Data Libarary by combining all EN-LV parallel corpora. The proprietary data are pre-processed using the Tilde MT platform (Pinnis et al., 2018). Table 1 summarizes training data source and size statistics prior to"
2020.wmt-1.73,D17-1018,0,0.0123705,"g target language words. We do not have access to the target language sentence during inference. Thus, we use co-reference resolution tools and extract the referential gender information from the source sentence instead. To do so, we first use co-reference resolution tools to obtain the co-reference graph. We then identify sub-graphs which contain gendered pronouns. Finally, we propagate the gender information within the graph and annotate the antecedents (see Figure 2). We set the annotations for the remaining unannotated words to U. We use neural co-reference resolution tools by AllenNLP 3 (Lee et al., 2017) and Hugging Face4 (based on work by Clark and Manning (2016)). We refer to these systems as TGA AllenNLP and TGA HuggingFace respectively. We also report the performance of NMT with TGA, when TGA use oracle information directly taken from WinoMT datasets and refer to these as TGA Oracle. Table 2: Performance of morphological taggers on gender feature classification evaluated on the Universal Dependencies test set. could also render WinoMT evaluation unreliable. Thus we first benchmark several morphological taggers on grammatical gender feature classification. We use Latvian as a development l"
2020.wmt-1.73,W19-3822,0,0.174851,"ng that not only the animate nouns but also the rest of the sentence is reinflected from masculine to feminine (or vice-versa), thus preserving the morpho-syntactic agreement of the whole sentence. The applicability of this line of work is still to be established as reinflecting sentences with co-references or pairs of parallel sentences in NMT pose an additional challenge. A different take on addressing gender biases in NMT outputs is the work on alternative generation: given a gender-ambiguous source sentence and its translation, provide an alternative translation using the opposite gender. Habash et al. (2019) approach this as a gender classification and reinflection task for target language sentences to address the first person singular cases when translating from English into Arabic. Bau et al. (2018) analyze trained NMT models to identify neurons that control various features, including gender information, that are used to generate the target sentence. In practice, however, such solutions are limited to simple source sentences where only one alternative in the target language is possible. A complementary approach is addressing gender bias in NMT as a problem of domain mismatch. When translating"
2020.wmt-1.73,P18-2050,0,0.0146842,"his as a gender classification and reinflection task for target language sentences to address the first person singular cases when translating from English into Arabic. Bau et al. (2018) analyze trained NMT models to identify neurons that control various features, including gender information, that are used to generate the target sentence. In practice, however, such solutions are limited to simple source sentences where only one alternative in the target language is possible. A complementary approach is addressing gender bias in NMT as a problem of domain mismatch. When translating TED talks, Michel and Neubig (2018) propose to adapt the NMT model for each speaker’s attributes, thus also implicitly addressing previously poorly translated first-person singular cases. Saunders and Byrne (2020) describe methods for NMT model adaptation using a handcrafted gender-balanced dataset and a translation re-scoring scheme based on the adapted models. The closest line of work to ours is the work on the incorporation of external gender information in the NMT input. Elaraby et al. (2018) and Vanmassenhove et al. (2018) prepend training data sentences with speaker gender information to improve spoken language translatio"
2020.wmt-1.73,W19-3807,0,0.0968454,"es, thus also implicitly addressing previously poorly translated first-person singular cases. Saunders and Byrne (2020) describe methods for NMT model adaptation using a handcrafted gender-balanced dataset and a translation re-scoring scheme based on the adapted models. The closest line of work to ours is the work on the incorporation of external gender information in the NMT input. Elaraby et al. (2018) and Vanmassenhove et al. (2018) prepend training data sentences with speaker gender information to improve spoken language translation when translating into languages with grammatical gender. Moryossef et al. (2019) undertakes a similar approach at the inference time using phrases (e.g. “she said:”) that imply the speaker’s gender. The methods proposed in this work differ from the previous work in terms of annotation granularity: we propose to use token level annotations, while the previous work used one annotation per sentence. As our training data annotations are solely based on grammatical gender, preparing them does not require any external gender information. Thus our approach is also simpler in terms of training data preparation compared to the previous work (Elaraby et al., 2018; Vanmassenhove et"
2020.wmt-1.73,2020.eamt-1.50,0,0.0150553,"ry by combining all EN-LV parallel corpora. The proprietary data are pre-processed using the Tilde MT platform (Pinnis et al., 2018). Table 1 summarizes training data source and size statistics prior to adding TGA. For all systems and language pairs, we use byte pair encoding (BPE) (Gage, 1994; Sennrich et al., 2016) to prepare joint source and target language BPE sub-word vocabularies. We use 30K BPE merge operations and use a vocabulary threshold of 50. NMT Systems We use the default configuration of the Transformer (Vaswani et al., 2017) NMT model implementation of the Sockeye NMT toolkit (Hieber et al., 2020). The exception is the use of source-side factors (Sennrich and Haddow, 2016) with the dimensionality of 8 for systems using TGA, which changes the model’s combined source embedding dimensionality from 512 to 520. We train all models using early stopping with patience of 10 based on their development set perplexity (Prechelt, 1998). 632 Morphological Taggers The preparation of training data with TGA and WinoMT evaluation relies on the outputs of a morphological tagger. If the tagger produces biased outputs, the TGA annotations might become too noisy to be useful. Furthermore, a biased morpholo"
2020.wmt-1.73,W13-5624,0,0.0599713,"Missing"
2020.wmt-1.73,P02-1040,0,0.108677,"th TGA requires statistical word alignments between words of source and target language sentences and a target language morphological tagger. To obtain word alignments, we use fast align (Dyer et al., 2013). To obtain grammatical gender information of target language words, we use the Stanza morphological tagger. When training NMT systems with TGA, we combine two copies of the original training data: one where all source-side 1 https://github.com/ UniversalDependencies/UD_Latvian-LVTB 2 https://github.com/PeterisP/LVTagger 633 Evaluation We evaluate general translation quality using the BLEU (Papineni et al., 2002) metric evaluated over WMT test sets. To calculate BLEU, we use SacreBLEU5 (Post, 2018) on cased, detokenized data. Reference test sets are only preprocessed using Moses punctuation normalization script6 . We use the WinoMT test suite (Stanovsky et al., 2019) to measure gender bias of our NMT systems. 4 Results and Discussion Results from experiments evaluating gender bias using the WinoMT test suite are provided in Table 3. First, we observe that all baseline systems show a strong bias towards generating translations using masculine forms. The EN-RU baseline system is the most biased as it pr"
2020.wmt-1.73,P16-1162,0,0.0103784,"propriEN-DE EN-FR EN-LV EN-LV EN-LT EN-RU Source # Sent. News Test WMT19 WMT15 Tilde WMT17 WMT19 WMT17 64.1M 39.1M 22.7M 4.5M 3.6M 25.0M 2018 2015 2017 2017 2019 2015 Table 1: Training data set source and size in millions of sentences prior to adding TGA. etary data that we obtain from Tilde Data Libarary by combining all EN-LV parallel corpora. The proprietary data are pre-processed using the Tilde MT platform (Pinnis et al., 2018). Table 1 summarizes training data source and size statistics prior to adding TGA. For all systems and language pairs, we use byte pair encoding (BPE) (Gage, 1994; Sennrich et al., 2016) to prepare joint source and target language BPE sub-word vocabularies. We use 30K BPE merge operations and use a vocabulary threshold of 50. NMT Systems We use the default configuration of the Transformer (Vaswani et al., 2017) NMT model implementation of the Sockeye NMT toolkit (Hieber et al., 2020). The exception is the use of source-side factors (Sennrich and Haddow, 2016) with the dimensionality of 8 for systems using TGA, which changes the model’s combined source embedding dimensionality from 512 to 520. We train all models using early stopping with patience of 10 based on their developm"
2020.wmt-1.73,L18-1214,1,0.889575,"Missing"
2020.wmt-1.73,P19-1164,0,0.353116,"noun “sekret¯ars” and the feminine noun “sekret¯are”. In cases when sentences do not contain the necessary information, NMT systems opt for translations which they have seen in training data most frequently. Acquiring the necessary information, however, might require analysis of the text beyond the level of individual sentences or require incorporation of external knowledge. Falling back to biases, however, happens not only in the absence of the required information as NMT systems produce stereotyped translations even when clues about the subject’s correct gender are present in the sentence (Stanovsky et al., 2019). This is in line with findings by Vanmassenhove et al. (2019) who suggest that NMT systems produce biased outputs not only because of the biases 629 Proceedings of the 5th Conference on Machine Translation (WMT), pages 629–638 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics present in data but also due to their tendency to exacerbate them. To provide means for incorporation of external and explicit gender information, we propose a method for training NMT systems to use wordlevel gender annotations. To prepare training data, we project grammatical gender informat"
2020.wmt-1.73,W18-6319,0,0.0342387,"and a target language morphological tagger. To obtain word alignments, we use fast align (Dyer et al., 2013). To obtain grammatical gender information of target language words, we use the Stanza morphological tagger. When training NMT systems with TGA, we combine two copies of the original training data: one where all source-side 1 https://github.com/ UniversalDependencies/UD_Latvian-LVTB 2 https://github.com/PeterisP/LVTagger 633 Evaluation We evaluate general translation quality using the BLEU (Papineni et al., 2002) metric evaluated over WMT test sets. To calculate BLEU, we use SacreBLEU5 (Post, 2018) on cased, detokenized data. Reference test sets are only preprocessed using Moses punctuation normalization script6 . We use the WinoMT test suite (Stanovsky et al., 2019) to measure gender bias of our NMT systems. 4 Results and Discussion Results from experiments evaluating gender bias using the WinoMT test suite are provided in Table 3. First, we observe that all baseline systems show a strong bias towards generating translations using masculine forms. The EN-RU baseline system is the most biased as it produces only one translation hypothesis with a feminine antecedent for every 8.4 hypothe"
2020.wmt-1.73,2020.acl-demos.14,0,0.0379594,"Missing"
2020.wmt-1.73,N18-2002,0,0.127788,"Missing"
2020.wmt-1.73,2020.acl-main.690,0,0.742426,"l. (2018) analyze trained NMT models to identify neurons that control various features, including gender information, that are used to generate the target sentence. In practice, however, such solutions are limited to simple source sentences where only one alternative in the target language is possible. A complementary approach is addressing gender bias in NMT as a problem of domain mismatch. When translating TED talks, Michel and Neubig (2018) propose to adapt the NMT model for each speaker’s attributes, thus also implicitly addressing previously poorly translated first-person singular cases. Saunders and Byrne (2020) describe methods for NMT model adaptation using a handcrafted gender-balanced dataset and a translation re-scoring scheme based on the adapted models. The closest line of work to ours is the work on the incorporation of external gender information in the NMT input. Elaraby et al. (2018) and Vanmassenhove et al. (2018) prepend training data sentences with speaker gender information to improve spoken language translation when translating into languages with grammatical gender. Moryossef et al. (2019) undertakes a similar approach at the inference time using phrases (e.g. “she said:”) that imply"
2020.wmt-1.73,W16-2209,0,0.0842086,"gender annotations (TGA). For training, we use data where regular source language words are annotated with the grammatical gender of their target language translations. We obtain such data by, first, morphologically tagging target language sentences to obtain information about their grammatical gender—F for feminine, M for masculine, N for neuter, and U for cases where grammatical gender is unavailable. Then, we use word-level statistical alignments to project this information from the target language to the source language words (see Figure 1 for an illustration). We use source-side factors (Sennrich and Haddow, 2016) to integrate the projected annotations as an additional input stream of the NMT system. To ensure that the NMT systems are capable of producing adequate translations when gender annotations are not available—a frequently expected case at the test time—we apply TGA dropout. We do so by randomly replacing annotations for a random number of words with U. While useful for animate nouns, such annotations might seem otherwise redundant because the majority of nouns in training data can be expected to be inanimate. However, for some inanimate nouns, the target language grammatical gender annotations"
2020.wmt-1.73,K17-3009,0,0.0480334,"Missing"
2020.wmt-1.73,D18-1334,0,0.139947,"y approach is addressing gender bias in NMT as a problem of domain mismatch. When translating TED talks, Michel and Neubig (2018) propose to adapt the NMT model for each speaker’s attributes, thus also implicitly addressing previously poorly translated first-person singular cases. Saunders and Byrne (2020) describe methods for NMT model adaptation using a handcrafted gender-balanced dataset and a translation re-scoring scheme based on the adapted models. The closest line of work to ours is the work on the incorporation of external gender information in the NMT input. Elaraby et al. (2018) and Vanmassenhove et al. (2018) prepend training data sentences with speaker gender information to improve spoken language translation when translating into languages with grammatical gender. Moryossef et al. (2019) undertakes a similar approach at the inference time using phrases (e.g. “she said:”) that imply the speaker’s gender. The methods proposed in this work differ from the previous work in terms of annotation granularity: we propose to use token level annotations, while the previous work used one annotation per sentence. As our training data annotations are solely based on grammatical gender, preparing them does not"
2020.wmt-1.73,W19-6622,0,0.344055,"the WinoMT test set by up to 25.8 percentage points. 1 Introduction Most modern natural language processing (NLP) systems learn from natural language data. Findings of social sciences and corpus linguistics, however, indicate various forms of bias in the way humans *First authors with equal contribution. use language (Coates, 1987; Butler, 1990; FuertesOlivera, 2007; Rickford, 2016). Thus the resulting NLP resources and systems also suffer from the same socially constructed biases, as well as inaccuracies and incompleteness (Jørgensen et al., 2015; Hovy and Søgaard, 2015; Prates et al., 2019; Vanmassenhove et al., 2019; Bordia and Bowman, 2019; Davidson et al., 2019; Tan and Celis, 2019). Due to the prevalent use of NLP systems, their susceptibility to social biases becomes an increasingly significant concern as NLP systems not only reflect the biases learned but also amplify and perpetuate them further (Hovy and Spruit, 2016; Crawford, 2017; HLEG, 2019). This work concerns mitigating the manifestations of gender bias in the outputs of neural machine translation (NMT) systems in scenarios where the source language does not encode the information about gender that is required in the target language. An examp"
2020.wmt-1.73,N18-2003,0,0.231256,"MT system learns to rely on these annotations when and where they are available. In particular, in experiments on five language pairs, we show that the methods proposed here can be used in tandem with off-the-shelf co-reference resolution tools to improve accuracy on the WinoMT challenge set (Stanovsky et al., 2019) by up to 25.8 percentage points. 1.1 Related work Recent recommendations for ethics guidelines for trustworthy AI recommend removing socially constructed biases at the source, the training data, prior to model training (HLEG, 2019). An example of work on debiasing training data is Zhao et al. (2018) where authors identified sentences containing animate nouns and changed their grammatical gender to the opposite. Zmigrod et al. (2019) take it further by ensuring that not only the animate nouns but also the rest of the sentence is reinflected from masculine to feminine (or vice-versa), thus preserving the morpho-syntactic agreement of the whole sentence. The applicability of this line of work is still to be established as reinflecting sentences with co-references or pairs of parallel sentences in NMT pose an additional challenge. A different take on addressing gender biases in NMT outputs i"
2020.wmt-1.73,P19-1161,0,0.150376,", we show that the methods proposed here can be used in tandem with off-the-shelf co-reference resolution tools to improve accuracy on the WinoMT challenge set (Stanovsky et al., 2019) by up to 25.8 percentage points. 1.1 Related work Recent recommendations for ethics guidelines for trustworthy AI recommend removing socially constructed biases at the source, the training data, prior to model training (HLEG, 2019). An example of work on debiasing training data is Zhao et al. (2018) where authors identified sentences containing animate nouns and changed their grammatical gender to the opposite. Zmigrod et al. (2019) take it further by ensuring that not only the animate nouns but also the rest of the sentence is reinflected from masculine to feminine (or vice-versa), thus preserving the morpho-syntactic agreement of the whole sentence. The applicability of this line of work is still to be established as reinflecting sentences with co-references or pairs of parallel sentences in NMT pose an additional challenge. A different take on addressing gender biases in NMT outputs is the work on alternative generation: given a gender-ambiguous source sentence and its translation, provide an alternative translation u"
2021.eacl-main.271,P19-1294,0,0.153039,"previous work in term translation accuracy when translating into Latvian. 1 Introduction Translation into morphologically complex languages involves 1) making a lexical choice for a word in the target language and 2) finding its morphological form that is suitable for the morphosyntactic context of the target sentence. Most of the recent work on terminology translation, however, 1 Relevant materials and code: https://github. com/tilde-nlp/terminology_translation has assumed that the correct morphological forms are apriori known (Hokamp and Liu, 2017; Post and Vilar, 2018; Hasler et al., 2018; Dinu et al., 2019; Song et al., 2020; Susanto et al., 2020; Dougal and Lonsdale, 2020). Thus previous work has approached terminology translation predominantly as a problem of making sure that the decoder’s output contains lexically and morphologically prespecified target language terms. While useful in some cases and some languages, such approaches come short of addressing terminology translation into morphologically complex languages where each word can have many morphological surface forms. For terminology translation to be viable for translation into morphologically complex languages, terminology constrain"
2021.eacl-main.271,2020.lrec-1.593,0,0.0152441,"into Latvian. 1 Introduction Translation into morphologically complex languages involves 1) making a lexical choice for a word in the target language and 2) finding its morphological form that is suitable for the morphosyntactic context of the target sentence. Most of the recent work on terminology translation, however, 1 Relevant materials and code: https://github. com/tilde-nlp/terminology_translation has assumed that the correct morphological forms are apriori known (Hokamp and Liu, 2017; Post and Vilar, 2018; Hasler et al., 2018; Dinu et al., 2019; Song et al., 2020; Susanto et al., 2020; Dougal and Lonsdale, 2020). Thus previous work has approached terminology translation predominantly as a problem of making sure that the decoder’s output contains lexically and morphologically prespecified target language terms. While useful in some cases and some languages, such approaches come short of addressing terminology translation into morphologically complex languages where each word can have many morphological surface forms. For terminology translation to be viable for translation into morphologically complex languages, terminology constraints have to be soft. That is, terminology translation has to account f"
2021.eacl-main.271,N13-1073,0,0.0287949,"ta that is available in the Tilde Data Libarary with an exception for English-Estonian for which 3106 2 https://iate.europa.eu Figure 1: Example of forms used in human evaluation. we use data from WMT 2018. The size of the parallel corpora after pre-processing using the Tilde MT platform (Pinnis et al., 2018) and filtering tools (Pinnis, 2018) is given in Table 2. To prepare data with TLA, we first lemmatise and part-of-speech (POS) tag the target language side of parallel corpora. For lemmatisation and POS tagging, we use pre-trained Stanza3 (Qi et al., 2020) models. We then use fast align4 (Dyer et al., 2013) to learn word alignments between the target language lemmas and source language inflected words. We only annotate verbs or nouns. To generate sentences with varying proportions of annotated and unannotated words, we first generate a sentence level annotation threshold uniformly at random from the interval [0.6, 1.0). Similarly, for each word in the source language sentence, we generate another number uniformly at random from the interval [0.0, 1.0). If the latter is larger than the sentence level annotation threshold, we annotate the respective word with its target language lemma. We use the"
2021.eacl-main.271,2020.eamt-1.29,0,0.482755,"ms found in either IATE2 or Wiktionary as done by Dinu et al. (2019), we annotate random source language words. This relaxes the requirement for curated bilingual dictionaries for training data preparation. Second, rather than providing exactly those target language forms that are used in the target sentence, we use target lemma annotations (TLA) instead (see Table 1 for examples). We hypothesise that in order to benefit from such annotations, the NMT model will have to learn copy-and-inflect behaviour instead of simple copying as proposed by Dinu et al. (2019). Our work is similar to work by Exel et al. (2020) in which authors also aim to achieve copy-andinflect behaviour. However, authors limit their annotations to only those terms for which their base forms differ by no more than two characters from the forms required in the target language sentence. Thus wordforms undergoing longer affix change or inflections accompanied by such linguistic phenomena as consonant mutation, consonant gradation or other stem change are never included in training data. 3 Experimental Setup Languages and Data. As our focus is on morphologically complex languages, in our experiments we translate from English into Latv"
2021.eacl-main.271,N18-2081,0,0.117,"Missing"
2021.eacl-main.271,P17-1141,0,0.131218,"Missing"
2021.eacl-main.271,W04-3250,0,0.422079,"Missing"
2021.eacl-main.271,P02-1040,0,0.112279,"Missing"
2021.eacl-main.271,W18-6486,1,0.834152,"h of the Indo-European language family) as well as Estonian (Finnic branch of the Uralic language family). For comparability with the previous work, we also use EnglishGerman (Germanic branch of the Indo-European language family). For all language pairs, we use all data that is available in the Tilde Data Libarary with an exception for English-Estonian for which 3106 2 https://iate.europa.eu Figure 1: Example of forms used in human evaluation. we use data from WMT 2018. The size of the parallel corpora after pre-processing using the Tilde MT platform (Pinnis et al., 2018) and filtering tools (Pinnis, 2018) is given in Table 2. To prepare data with TLA, we first lemmatise and part-of-speech (POS) tag the target language side of parallel corpora. For lemmatisation and POS tagging, we use pre-trained Stanza3 (Qi et al., 2020) models. We then use fast align4 (Dyer et al., 2013) to learn word alignments between the target language lemmas and source language inflected words. We only annotate verbs or nouns. To generate sentences with varying proportions of annotated and unannotated words, we first generate a sentence level annotation threshold uniformly at random from the interval [0.6, 1.0). Similar"
2021.eacl-main.271,L18-1214,1,0.897862,"Missing"
2021.eacl-main.271,N18-1119,0,0.0321331,"g translations of the same 768 sentences in English, Estonian, German, Latvian, and Lithuanian. ATS contains about 1.1k term occurrences from a glossary prepared by professional translators. When annotating terms in the source text, we use only the dictionary forms of term translations, since in practical applications having access to the correct inflections (surface forms) is unrealistic. We compare our work with an NMT system without means for terminology integration (Baseline) and the previous work by Dinu et al. (2019) (ETA). Although our preliminary experiments with constrained decoding (Post and Vilar, 2018) (CD) confirmed the findings by Dinu et al. (2019) that strict enforcement of constraints leads to lower-thanbaseline quality, we nevertheless include them for completeness sake. Similarly to the previous work, we use two auto5 https://github.com/mtresearcher/ terminology_dataset 6 https://github.com/tilde-nlp/ terminology_translation 3107 IATE EN-DE Automotive Test Suite EN-ET EN-LV EN-DE EN-LT BLEU Acc. BLEU Acc. BLEU Acc. BLEU Acc. BLEU Acc. Baseline CD ETA 29.7 28.5 29.9 81.7 99.7 96.2 26.5 22.9 33.2† 46.2 99.7 94.0 19.6 14.9 17.8 46.7 98.0 92.4 30.6 23.5 27.4 62.2 99.3 93.4 25.3 18.1 28.8"
2021.eacl-main.271,2020.acl-demos.14,0,0.0235023,"age family). For all language pairs, we use all data that is available in the Tilde Data Libarary with an exception for English-Estonian for which 3106 2 https://iate.europa.eu Figure 1: Example of forms used in human evaluation. we use data from WMT 2018. The size of the parallel corpora after pre-processing using the Tilde MT platform (Pinnis et al., 2018) and filtering tools (Pinnis, 2018) is given in Table 2. To prepare data with TLA, we first lemmatise and part-of-speech (POS) tag the target language side of parallel corpora. For lemmatisation and POS tagging, we use pre-trained Stanza3 (Qi et al., 2020) models. We then use fast align4 (Dyer et al., 2013) to learn word alignments between the target language lemmas and source language inflected words. We only annotate verbs or nouns. To generate sentences with varying proportions of annotated and unannotated words, we first generate a sentence level annotation threshold uniformly at random from the interval [0.6, 1.0). Similarly, for each word in the source language sentence, we generate another number uniformly at random from the interval [0.0, 1.0). If the latter is larger than the sentence level annotation threshold, we annotate the respect"
2021.eacl-main.271,W16-2209,0,0.014929,"o yields substantial improvements over the previous work (Dinu et al., 2019) when tested on the morphologically complex Baltic and Uralic languages. 2 Method: Target Lemma Annotations To train NMT systems that allow applying terminology constraints Dinu et al. (2019) prepare training data by amending source language terms with their exact target annotations (ETA). To inform the NMT model about the nature of each token (i.e., whether it is a source language term, its target language translation or a regular source language word), the authors use an additional input stream— source-side factors (Sennrich and Haddow, 2016). Their method, however, is limited to cases in which the provided annotation matches the required target form and can be copied verbatim, thus performing poorly in cases where the surface forms of terms in the target language differ from those used to annotate source language sentences (Dinu et al., 2019). This constitutes a problem for the method’s practical applicability in real-life scenarios. In this 27.6M 2.4M 22.6M 22.1M ATS Test WMT17+IATE 768 768 768 768 581 - Table 2: Training and evaluation data sizes in numbers of sentences. WMT2017 + IATE stands for the English-German test set fro"
2021.eacl-main.271,2020.acl-main.325,0,0.12128,"racy when translating into Latvian. 1 Introduction Translation into morphologically complex languages involves 1) making a lexical choice for a word in the target language and 2) finding its morphological form that is suitable for the morphosyntactic context of the target sentence. Most of the recent work on terminology translation, however, 1 Relevant materials and code: https://github. com/tilde-nlp/terminology_translation has assumed that the correct morphological forms are apriori known (Hokamp and Liu, 2017; Post and Vilar, 2018; Hasler et al., 2018; Dinu et al., 2019; Song et al., 2020; Susanto et al., 2020; Dougal and Lonsdale, 2020). Thus previous work has approached terminology translation predominantly as a problem of making sure that the decoder’s output contains lexically and morphologically prespecified target language terms. While useful in some cases and some languages, such approaches come short of addressing terminology translation into morphologically complex languages where each word can have many morphological surface forms. For terminology translation to be viable for translation into morphologically complex languages, terminology constraints have to be soft. That is, terminology"
aker-etal-2014-bilingual,steinberger-etal-2012-dgt,0,\N,Missing
aker-etal-2014-bilingual,C00-2163,0,\N,Missing
aker-etal-2014-bilingual,P07-1108,0,\N,Missing
aker-etal-2014-bilingual,P06-1011,0,\N,Missing
aker-etal-2014-bilingual,J03-1002,0,\N,Missing
aker-etal-2014-bilingual,P09-1018,0,\N,Missing
aker-etal-2014-bilingual,W13-2502,0,\N,Missing
aker-etal-2014-bilingual,R13-1074,1,\N,Missing
aker-etal-2014-bilingual,C12-2003,1,\N,Missing
aker-etal-2014-bilingual,P13-1040,1,\N,Missing
borzovs-etal-2014-terminology,henriksen-etal-2006-eurotermbank,0,\N,Missing
borzovs-etal-2014-terminology,P07-2045,0,\N,Missing
I17-1038,2009.mtsummit-commercial.6,0,0.132956,"Missing"
I17-1038,aziz-etal-2012-pet,0,0.0332997,"Missing"
I17-1038,W11-2123,0,0.0168791,"split the list into documents consisting of 100 segments so that the original sequence of sentences is preserved, and translated the documents SMT and NMT systems were evaluated on a heldout set of 1000 randomly selected sentence pairs. 2 ChrF2 0.7586 0.7065 Figure 1: Human comparative evaluation results for SMT and NMT systems The SMT system is a standard phrase-based system that was trained on the Tilde MT platform (Vasil¸jevs et al., 2012) with Moses (Koehn et al., 2007). The system features a 7-gram translation model and a 5-gram language model. The language model was trained with KenLM (Heafield, 2011). The system was tuned with MERT (Bertoldi et al., 2009) using a held-out set of 2,000 sentence pairs. 3.2 NIST 9.45±0.18 8.63±0.15 Table 2: Automatic evaluation results Table 1: Statistics of the training corpora 3.1 BLEU 46.57±1.46 38.44±1.62 http://www.ema.europa.eu/ 375 Sentence Source BLEU - Human 100.00 SMT 41.38 NMT 24.42 Text Seek medical advice straight away if you develop a severe rash, itching or shortness of breath or difficulty breathing. Nekav¯ejoties mekl¯ejiet medic¯ınisku pal¯ıdz¯ıbu , ja Jums par¯ad¯as izsitumi , rodas nieze vai elpas tr¯ukums , vai apgr¯utin¯ata elpoˇsana ."
I17-1038,D16-1025,0,0.0302211,"2015). Today machine translation is experiencing a paradigm shift from (phrase-based) statistical machine translation (SMT) to neural machine translation (NMT). The first results obtained in recent years are promising, as it can be seen from the results of WMT 2016 (Bojar et al., 2016) and WMT 2017 (Bojar et al., 2017). As NMT becomes more and more popular, the question of what can we expect from NMT in terms of quality becomes very important. Recent analysis of English to German SMT and NMT outputs of manual transcripts of short speeches showed that NMT can decrease the post-editing effort (Bentivogli et al., 2016). A comparison of NMT and SMT systems for nine language directions (English to and from Czech, German, Romanian, Russian, and English to Finnish) on news stories made by Toral and S´anchez-Cartagena (2017) showed that translations produced by NMT systems are more fluent and more accurate in terms of word order compared to translations produced by SMT systems. By analyzing of manually error-annotated outputs of generic EnglishCroatian MT systems, Klubiˇcka et al. (2017) found that NMT handles all types of agreement better than SMT (including factored models). In this paper, we delve further int"
I17-1038,D07-1091,0,0.0317668,"m errors, that characterize the morphological richness of Latvian, are frequent for both systems, but slightly fewer in NMT outputs. 1 Introduction For many years, the central problem in machine translation (MT) has been the quality. MT quality has been recognized as a complicated research question when translation is performed into a morphologically rich (and also under-resourced) language with a relatively free word order, e.g., Bulgarian, Croatian, Estonian, Finnish, Greek or Latvian. Possible solutions for widely used statistical machine translation have been studied for many years (e.g., Koehn and Hoang 2007; Tamchyna 373 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 373–383, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP translations of manual transcripts of TED talks 1 . They found that NMT decreases post-editing effort, but degrades faster than SMT for longer sentences. They also found that NMT output contains fewer morphology errors, lexical errors and substantially fewer word order errors. Toral and S´anchez-Cartagena (2017) compared NMT and SMT systems submitted to WMT16 news translation task for nine translation directions (Eng"
I17-1038,P07-2045,0,0.00705139,"from Post-edits? Post-editing process For post-editing, we compiled a list of 22,500 segments (360,000 words) from EMEA documents. Then, we split the list into documents consisting of 100 segments so that the original sequence of sentences is preserved, and translated the documents SMT and NMT systems were evaluated on a heldout set of 1000 randomly selected sentence pairs. 2 ChrF2 0.7586 0.7065 Figure 1: Human comparative evaluation results for SMT and NMT systems The SMT system is a standard phrase-based system that was trained on the Tilde MT platform (Vasil¸jevs et al., 2012) with Moses (Koehn et al., 2007). The system features a 7-gram translation model and a 5-gram language model. The language model was trained with KenLM (Heafield, 2011). The system was tuned with MERT (Bertoldi et al., 2009) using a held-out set of 2,000 sentence pairs. 3.2 NIST 9.45±0.18 8.63±0.15 Table 2: Automatic evaluation results Table 1: Statistics of the training corpora 3.1 BLEU 46.57±1.46 38.44±1.62 http://www.ema.europa.eu/ 375 Sentence Source BLEU - Human 100.00 SMT 41.38 NMT 24.42 Text Seek medical advice straight away if you develop a severe rash, itching or shortness of breath or difficulty breathing. Nekav¯ej"
I17-1038,2016.amta-users.8,1,0.767633,"Missing"
I17-1038,2015.iwslt-papers.10,0,0.0235837,"Missing"
I17-1038,W17-4737,1,0.844308,"Missing"
I17-1038,E17-2045,0,0.0530078,"Missing"
I17-1038,E17-3017,0,0.0414516,"Missing"
I17-1038,P12-3008,0,0.0386289,"Missing"
I17-1038,W16-2323,0,0.0255274,". The toolkit allows training attention-based encoder-decoder models with gated recurrent units in the recurrent layers. For word splitting in sub-word units, we use the byte pair encoding tools from the subword-nmt toolkit (Sennrich et al., 2015). The NMT system was trained using a vocabulary of 40,000 word parts (39,500 for byte pair encoding), a projection (embedding) layer of 500 dimensions, recurrent units of 1024 dimensions, a batch size of 20 and dropout enabled. All other parameters were set to the default parameters as used by the developers of Nematus for their WMT 2016 submissions (Sennrich et al., 2016). 3.3 4 4.1 MT System Evaluation What Can Be Learned from Post-edits? Post-editing process For post-editing, we compiled a list of 22,500 segments (360,000 words) from EMEA documents. Then, we split the list into documents consisting of 100 segments so that the original sequence of sentences is preserved, and translated the documents SMT and NMT systems were evaluated on a heldout set of 1000 randomly selected sentence pairs. 2 ChrF2 0.7586 0.7065 Figure 1: Human comparative evaluation results for SMT and NMT systems The SMT system is a standard phrase-based system that was trained on the Tild"
I17-1038,2011.eamt-1.7,1,0.896488,"Missing"
I17-1038,2006.amta-papers.25,0,0.202581,"Missing"
I17-1038,E17-1100,0,0.0467591,"Missing"
L16-1124,H92-1073,0,0.793362,"dictation systems, it was necessary to create a specific corpus that would: 1) better capture the speaking characteristics of speakers when dictating text to a computer and 2) contain spoken commands common to dictation scenarios (e.g., punctuation, formatting, special symbol, and action commands). Therefore, in this paper, we present the Dictated Speech Corpus (DSC) that has been created to address these requirements. Speech corpora creation with spoken commands and speech recognition system development with spoken command support has been investigated also in related research. For instance, Paul and Baker (1992) and Bernstein and Danielson (1992) created speech corpora for English continuous speech recognition with both verbalised and non-verbalised punctuation marks. Digalakis et al. (2003) created a speech recognition system for Greek that could handle special symbol and formatting commands, however they were introduced only in the speech recognition system and were omitted from their speech corpus. Enravi (2012) in his thesis stressed the importance of spoken command support in dictation systems. Rusko et al. (2011) developed a dictation system for Slovak that supported spoken commands for punctua"
L16-1124,pinnis-etal-2014-designing,1,0.849102,"ecognition corpus, dictation systems, Latvian 1. Introduction Automatic speech recognition (ASR) technologies for Latvian have a relatively short history because even three years ago (i.e., in 2013 and before) there was no orthographically annotated speech corpus, which could be used for ASR purposes, available. However, there have been attempts to develop ASR systems for broadcast speech recognition (Oparin et al, 2013) in the Quaero project (Lamel, 2012) using acoustic model bootstrapping. Since the creation of the first orthographically and phonetically annotated speech corpus for Latvian (Pinnis et al., 2014) – the Latvian Speech Recognition Corpus (LSRC), ASR technologies for Latvian have been actively researched (e.g., Salimbajevs & Pinnis, 2014, Salimbajevs & Strigins, 2015b), and different application scenarios that have resulted in practical applications with ASR capabilities (e.g., Vīra & Vasiļjevs, 2014; Salimbajevs & Strigins, 2015a; Znotiņš & Dargis, 2014; Znotiņš et. al., 2015) have been investigated. However, the technology has yet to reach a level where it is applicable in dictation scenarios in text editors. For the development of dictation systems, it was necessary to create a specif"
L16-1124,W15-1837,1,0.830435,"ven three years ago (i.e., in 2013 and before) there was no orthographically annotated speech corpus, which could be used for ASR purposes, available. However, there have been attempts to develop ASR systems for broadcast speech recognition (Oparin et al, 2013) in the Quaero project (Lamel, 2012) using acoustic model bootstrapping. Since the creation of the first orthographically and phonetically annotated speech corpus for Latvian (Pinnis et al., 2014) – the Latvian Speech Recognition Corpus (LSRC), ASR technologies for Latvian have been actively researched (e.g., Salimbajevs & Pinnis, 2014, Salimbajevs & Strigins, 2015b), and different application scenarios that have resulted in practical applications with ASR capabilities (e.g., Vīra & Vasiļjevs, 2014; Salimbajevs & Strigins, 2015a; Znotiņš & Dargis, 2014; Znotiņš et. al., 2015) have been investigated. However, the technology has yet to reach a level where it is applicable in dictation scenarios in text editors. For the development of dictation systems, it was necessary to create a specific corpus that would: 1) better capture the speaking characteristics of speakers when dictating text to a computer and 2) contain spoken commands common to dictation scena"
L16-1124,H92-1076,0,\N,Missing
L18-1214,chen-eisele-2012-multiun,0,0.0151017,"U GPU CPU CPU GPU CPU CPU GPU 3.1. CPU CPU GPU 1. Source-source or target-target entries in parallel data (equal source/target entries are filtered out). monolingual) for training MT engines. It stores publicly available and proprietary parallel and monolingual corpora as well as multilingual term collections that users can use to train their MT systems within the Tilde MT platform. Several of the largest (publicly available) parallel corpora in the Tilde Data Library are the DGT-TM (Steinberger et al., 2012), Tilde MODEL (Rozis and Skadin¸sˇ, 2017), Open Subtitles (Tiedemann, 2009), MultiUN (Chen and Eisele, 2012), DCEP (Hajlaoui et al., 2014), JRC-Acquis (Steinberger et al., 2006), Europarl (Koehn, 2005), Microsoft Translation Memories and UI Strings Glossaries (Microsoft, 2015). The Tilde Data Library stores approximately 12.35 billion parallel segments for 58 languages and over 4 million terms for more than 125 languages. 2. Sentence splitting issues (segments >1000 symbols or >400 tokens are filtered out; the numerical thresholds here and further can be adjusted for each individual training task). 3. Data corruption through optical character recognition (OCR), e.g., when processing PDF documents (s"
L18-1214,N13-1073,0,0.0482411,"he byte order mark 3. Removal of escaped characters (e.g., ”
”) 4. Decoding of XML entities, normalisation of whitespace characters 5. Removal of empty braces and curly tags (specific to parallel corpora extracted from some CAT tools) 6. Separation of ligatures into letters (specific to parallel corpora extracted using OCR methods) 3.2. 3.3. SMT and NMT Model Training After the data is pre-processed, SMT or NMT models are trained. During configuration of an MT system, users can freely select whether to train an SMT or an NMT model. For SMT models, word alignment is performed using fastalign (Dyer et al., 2013), after which a 7-gram translation and the wbe-msd-bidirectional-fe-allff 9 reordering models are built. For language modelling, the KenLM (Heafield, 2011) toolkit is used (the n-gram order can be specified by the users). SMT systems are tuned using MERT (Bertoldi et al., 2009). For NMT models, training data is further pre-processed by introducing unknown phenomena (i.e., unknown word tokens) within training data following the methodology by Pinnis et al. (2017b). Then, an NMT model is trained using the configuration specified by the user (e.g., the vocabulary size, embedding and hidden layer"
L18-1214,C14-2028,0,0.0752326,"Missing"
L18-1214,hajlaoui-etal-2014-dcep,0,0.403067,"Missing"
L18-1214,W11-2123,0,0.0118532,"s and curly tags (specific to parallel corpora extracted from some CAT tools) 6. Separation of ligatures into letters (specific to parallel corpora extracted using OCR methods) 3.2. 3.3. SMT and NMT Model Training After the data is pre-processed, SMT or NMT models are trained. During configuration of an MT system, users can freely select whether to train an SMT or an NMT model. For SMT models, word alignment is performed using fastalign (Dyer et al., 2013), after which a 7-gram translation and the wbe-msd-bidirectional-fe-allff 9 reordering models are built. For language modelling, the KenLM (Heafield, 2011) toolkit is used (the n-gram order can be specified by the users). SMT systems are tuned using MERT (Bertoldi et al., 2009). For NMT models, training data is further pre-processed by introducing unknown phenomena (i.e., unknown word tokens) within training data following the methodology by Pinnis et al. (2017b). Then, an NMT model is trained using the configuration specified by the user (e.g., the vocabulary size, embedding and hidden layer dimensions, whether to use dropout, the learning rate, gradient clipping, etc. parameters can be freely configured). To ensure the stability of the system,"
L18-1214,J82-2005,0,0.718254,"Missing"
L18-1214,P07-2045,0,0.00508831,"ns); train SMT and NMT systems; integrate the systems through computer assisted translation (CAT) tool plugins or the Tilde MT external API in users’ translation and multilingual content creation workflows; and perform translation of text snippets, documents of various popular formats, and websites directly in the Tilde MT graphical user interface or using a widget that can be integrated in any website. 2.1. SMT and NMT System Support Tilde MT supports two MT paradigms: statistical machine translation and neural machine translation. The platform allows to train Moses phrase-based SMT systems (Koehn et al., 2007) and attention-based encoder-decoder NMT systems with multiplicative long short-term memory units using the Nematus toolkit (Sennrich et al., 2017). The platform has been designed to allow switching to different NMT engines easily. For translation, Nematus NMT models are converted to Marian (formerly AmuNMT) NMT models (Junczys-Dowmunt et al., 2016) that allow reaching much higher translation speed (up to 10 times faster compared to Nematus in non-batched translation scenarios). 2.2. Cloud-based Infrastructure To facilitate on-demand training and deployment of MT systems, it is important for t"
L18-1214,2005.mtsummit-papers.11,0,0.0189227,"ta (equal source/target entries are filtered out). monolingual) for training MT engines. It stores publicly available and proprietary parallel and monolingual corpora as well as multilingual term collections that users can use to train their MT systems within the Tilde MT platform. Several of the largest (publicly available) parallel corpora in the Tilde Data Library are the DGT-TM (Steinberger et al., 2012), Tilde MODEL (Rozis and Skadin¸sˇ, 2017), Open Subtitles (Tiedemann, 2009), MultiUN (Chen and Eisele, 2012), DCEP (Hajlaoui et al., 2014), JRC-Acquis (Steinberger et al., 2006), Europarl (Koehn, 2005), Microsoft Translation Memories and UI Strings Glossaries (Microsoft, 2015). The Tilde Data Library stores approximately 12.35 billion parallel segments for 58 languages and over 4 million terms for more than 125 languages. 2. Sentence splitting issues (segments >1000 symbols or >400 tokens are filtered out; the numerical thresholds here and further can be adjusted for each individual training task). 3. Data corruption through optical character recognition (OCR), e.g., when processing PDF documents (segments containing tokens with >50 symbols are filtered out). 4. Redundancy issues (duplicate"
L18-1214,W17-4737,1,0.883487,"Missing"
L18-1214,R13-1074,1,0.866461,"PE) (Sennrich et al., 2015). For NMT systems, tokens can be split using a morphological analyser8 and processed with BPE. 1. Incorrect language filtering using a language detection tool (Shuyo, 2010). 7. Source side factorisation. Tilde MT supports NMT models that use linguistic input features (Sennrich and Haddow, 2016). Therefore, the source side can be factored using language-specific factorisation tools (depending on the source language - either part-of-speech or morphological taggers or syntactic parsers). 2. Low content overlap filtering using the cross-lingual alignment tool MPAligner (Pinnis, 2013). 3. Digit mismatch filtering, which showed to be effective in identifying parallel corpora sentence segmentation issues. After filtering, each valid segment is cleaned in order to further reduce noise and to remove potential non-translatable text fragments, which will be processed by the formatting tag handling method in the translation workflow prior to decoding but are not necessary during training. The following are the main cleaning steps: 1. Removal of HTML and XML tags, 2. Removal of the byte order mark 3. Removal of escaped characters (e.g., ”
”) 4. Decoding of XML entities, normalisa"
L18-1214,W15-4912,1,0.882736,"Missing"
L18-1214,W16-2209,0,0.0390092,"://www.memoq.com 1345 to the filters used for SMT systems, for NMT systems Tilde MT performs also the following filtering steps to ensure that the parallel corpora are filtered more strictly (Pinnis et al., 2017c): 6. Morphology-driven word splitting (MWS) (Pinnis et al., 2017b) or byte-pair encoding (BPE) (Sennrich et al., 2015). For NMT systems, tokens can be split using a morphological analyser8 and processed with BPE. 1. Incorrect language filtering using a language detection tool (Shuyo, 2010). 7. Source side factorisation. Tilde MT supports NMT models that use linguistic input features (Sennrich and Haddow, 2016). Therefore, the source side can be factored using language-specific factorisation tools (depending on the source language - either part-of-speech or morphological taggers or syntactic parsers). 2. Low content overlap filtering using the cross-lingual alignment tool MPAligner (Pinnis, 2013). 3. Digit mismatch filtering, which showed to be effective in identifying parallel corpora sentence segmentation issues. After filtering, each valid segment is cleaned in order to further reduce noise and to remove potential non-translatable text fragments, which will be processed by the formatting tag hand"
L18-1214,E17-3017,0,0.0616881,"Missing"
L18-1214,steinberger-etal-2006-jrc,0,0.0268069,"target-target entries in parallel data (equal source/target entries are filtered out). monolingual) for training MT engines. It stores publicly available and proprietary parallel and monolingual corpora as well as multilingual term collections that users can use to train their MT systems within the Tilde MT platform. Several of the largest (publicly available) parallel corpora in the Tilde Data Library are the DGT-TM (Steinberger et al., 2012), Tilde MODEL (Rozis and Skadin¸sˇ, 2017), Open Subtitles (Tiedemann, 2009), MultiUN (Chen and Eisele, 2012), DCEP (Hajlaoui et al., 2014), JRC-Acquis (Steinberger et al., 2006), Europarl (Koehn, 2005), Microsoft Translation Memories and UI Strings Glossaries (Microsoft, 2015). The Tilde Data Library stores approximately 12.35 billion parallel segments for 58 languages and over 4 million terms for more than 125 languages. 2. Sentence splitting issues (segments >1000 symbols or >400 tokens are filtered out; the numerical thresholds here and further can be adjusted for each individual training task). 3. Data corruption through optical character recognition (OCR), e.g., when processing PDF documents (segments containing tokens with >50 symbols are filtered out). 4. Redu"
L18-1214,steinberger-etal-2012-dgt,0,0.0384787,"and authorisation Logic layer Translation service Data layer 3. High performance computing (HPC) cluster CPU CPU GPU CPU CPU GPU CPU CPU GPU 3.1. CPU CPU GPU 1. Source-source or target-target entries in parallel data (equal source/target entries are filtered out). monolingual) for training MT engines. It stores publicly available and proprietary parallel and monolingual corpora as well as multilingual term collections that users can use to train their MT systems within the Tilde MT platform. Several of the largest (publicly available) parallel corpora in the Tilde Data Library are the DGT-TM (Steinberger et al., 2012), Tilde MODEL (Rozis and Skadin¸sˇ, 2017), Open Subtitles (Tiedemann, 2009), MultiUN (Chen and Eisele, 2012), DCEP (Hajlaoui et al., 2014), JRC-Acquis (Steinberger et al., 2006), Europarl (Koehn, 2005), Microsoft Translation Memories and UI Strings Glossaries (Microsoft, 2015). The Tilde Data Library stores approximately 12.35 billion parallel segments for 58 languages and over 4 million terms for more than 125 languages. 2. Sentence splitting issues (segments >1000 symbols or >400 tokens are filtered out; the numerical thresholds here and further can be adjusted for each individual training t"
L18-1214,P12-3008,1,0.915908,"Missing"
L18-1214,W15-4924,1,0.90535,"Missing"
L18-1595,chen-eisele-2012-multiun,0,0.0689472,"Missing"
L18-1595,W11-2123,0,0.0404262,"– Encoder and decoder cell type - transformer; – Maximum sentence length of 128; – 6-layer encoder with convolutional embeddings; – 6-layer transformer decoder; – Each block (self-attention or feed-forward network) is ∗ Pre-processed with layer normalization; ∗ Post-processed with dropout and a residual connection; • SMT one-way models (SMT) – Word alignment performed using fast-align (Dyer et al., 2013); – 7-gram translation models and the ‘wbe-msdbidirectional-fe-allff‘ reordering models; • Recurrent neural network models – Maximum sentence length of 50; – Language model trained with KenLM (Heafield, 2011); – Multiplicative long short-term memory (Krause et al., 2017) (MLSTM) shallow one-way (MLSTM-SU - the baseline model) – Tuned using the improved MERT (Bertoldi et al., 2009). ∗ Encoder and decoder cell type – MLSTM (same as used by Pinnis et al. (2017)); ∗ A shared subword unit vocabulary (Sennrich et al., 2016) of 25,000 tokens; Common parameters for all multilingual multi-way experiments: • Multilingual training data was shuffled in equal batches per translation direction and with the target language identifier added before each sentence as described by Johnson et al. (2016). – Gated recur"
L18-1595,E17-3017,0,0.0382538,"data during training and inference. We did, however, experiment with different encoder and decoder cell types and add slight modifications to the data iterator module for it to automatically read the multilingual multi-way training data in equal batches for each translation direction and prepend the target language symbol at the beginning of each source sentence. Our recurrent neural network NMT systems were trained with Nematus (Sennrich et al., 2017) using four main configurations. For training of the NMT systems with convolutional neural networks and transformer networks, we used Sockeye (Hieber et al., 2017). All SMT systems were trained using using the Moses (Koehn et al., 2007) toolkit in the Tilde MT platform (Vasil¸jevs et al., 2012). The details of the models are as follows: – Encoder and decoder cell type - transformer; – Maximum sentence length of 128; – 6-layer encoder with convolutional embeddings; – 6-layer transformer decoder; – Each block (self-attention or feed-forward network) is ∗ Pre-processed with layer normalization; ∗ Post-processed with dropout and a residual connection; • SMT one-way models (SMT) – Word alignment performed using fast-align (Dyer et al., 2013); – 7-gram transl"
L18-1595,P07-2045,0,0.0184643,"erent encoder and decoder cell types and add slight modifications to the data iterator module for it to automatically read the multilingual multi-way training data in equal batches for each translation direction and prepend the target language symbol at the beginning of each source sentence. Our recurrent neural network NMT systems were trained with Nematus (Sennrich et al., 2017) using four main configurations. For training of the NMT systems with convolutional neural networks and transformer networks, we used Sockeye (Hieber et al., 2017). All SMT systems were trained using using the Moses (Koehn et al., 2007) toolkit in the Tilde MT platform (Vasil¸jevs et al., 2012). The details of the models are as follows: – Encoder and decoder cell type - transformer; – Maximum sentence length of 128; – 6-layer encoder with convolutional embeddings; – 6-layer transformer decoder; – Each block (self-attention or feed-forward network) is ∗ Pre-processed with layer normalization; ∗ Post-processed with dropout and a residual connection; • SMT one-way models (SMT) – Word alignment performed using fast-align (Dyer et al., 2013); – 7-gram translation models and the ‘wbe-msdbidirectional-fe-allff‘ reordering models; •"
L18-1595,P02-1040,0,0.101548,"Skadin¸a et al., 2012). In the multilingual multi-way model training scenarios, we concatenated 16 th of each 2000 sentence validation dataset, resulting in batches of 333 sentences from each translation direction, which we used as development data. As for evaluation data – we used the ACCURAT balanced evaluation corpus (Skadin¸sˇ et al., 2010) consisting of 512 sentences in each translation direction, for which the Russian version was prepared by in-house translators. 4. Results In this section, we describe the results of our experiments. We evaluate MT system translation quality using BLEU (Papineni et al., 2002). we also analyse translation speed and GPU memory usage during translation, as well as training duration. While training models for multiple translation directions, we were mainly focused on improving the transTranslation Quality Table 2 shows how each of the models that we described in the previous section compares to the baseline in terms of development and evaluation data translation quality. When we compare the baseline one-way model (MLSTM-SU) to the other one-way models, the results show that the GRUDU and FConv-U models reach lower translation quality on all development sets and all bu"
L18-1595,W17-4737,1,0.872301,"Missing"
L18-1595,R13-1074,1,0.878565,"Missing"
L18-1595,P16-1162,0,0.0740983,"nection; • SMT one-way models (SMT) – Word alignment performed using fast-align (Dyer et al., 2013); – 7-gram translation models and the ‘wbe-msdbidirectional-fe-allff‘ reordering models; • Recurrent neural network models – Maximum sentence length of 50; – Language model trained with KenLM (Heafield, 2011); – Multiplicative long short-term memory (Krause et al., 2017) (MLSTM) shallow one-way (MLSTM-SU - the baseline model) – Tuned using the improved MERT (Bertoldi et al., 2009). ∗ Encoder and decoder cell type – MLSTM (same as used by Pinnis et al. (2017)); ∗ A shared subword unit vocabulary (Sennrich et al., 2016) of 25,000 tokens; Common parameters for all multilingual multi-way experiments: • Multilingual training data was shuffled in equal batches per translation direction and with the target language identifier added before each sentence as described by Johnson et al. (2016). – Gated recurrent units (GRU) ∗ Encoder and decoder cell type – GRU; ∗ Shallow multilingual multi-way (GRU-SM) · 1-layer encoder and 1-layer decoder; ∗ Deep - one-way (GRU-DU) and multilingual multi-way (GRU-DM) · 4-layer encoder and 4-layer decoder; · 2 GRU transition operations applied in the encoder layer; 4 GRU transition"
L18-1595,skadina-etal-2012-collecting,1,0.898834,"Missing"
L18-1595,steinberger-etal-2012-dgt,0,0.0800151,"Missing"
L18-1595,P12-3008,0,0.0563148,"Missing"
P12-3016,P12-3016,1,0.0512347,"Missing"
P12-3016,I08-1013,0,0.218261,"Missing"
P12-3016,P00-1056,0,0.308786,"le. The evaluation results suggest that the comparability scores reliably reflect comparability levels. In addition, there is a strong correlation between human defined comparability levels and the confidence scores derived from the comparability metric, as the Pearson R correlation scores vary between 0.966 and 0.999, depending on the language pair. The Dictionary based metric (Su and Babych, 2012b) is a lightweight approach, which uses bilingual dictionaries to lexically map documents from one language to another. The dictionaries are automatically generated via word alignment using GIZA++ (Och and Ney, 2000) on parallel corpora. For each word in the source language, the top two translation candidates (based on the word alignment probability in GIZA++) are retrieved as possible translations into the target language. This metric provides a much faster lexical translation process, although word-for-word lexical mapping produces less reliable translations than MT based translations. Moreover, the lower quality of text translation in the dictionary based metric does not necessarily degrade its performance in predicting comparability levels of comparable document pairs. The evaluation on the gold stand"
P12-3016,P95-1050,0,0.370603,"Missing"
P12-3016,W97-0119,0,0.234424,"Missing"
P12-3016,N10-1063,0,0.0457099,". At the same time, comparable corpora, i.e., non-parallel bi- or multilingual text resources such as daily news articles and large knowledge bases like Wikipedia, are much more widely available than parallel translation data. While methods for the use of parallel corpora in machine translation are well studied (Koehn, 2010), similar techniques for comparable corpora have not been thoroughly worked out. Only the latest research has shown that language pairs and domains with little parallel data can benefit from the exploitation of comparable corpora (Munteanu and Marcu, 2005; Lu et al., 2010; Smith et al., 2010; Abdul-Rauf and Schwenk, 2009 and 2011). In this paper we present the ACCURAT toolkit1 - a collection of tools that are capable of analysing comparable corpora and extracting parallel data which can be used to improve the performance of statistical and rule/example-based MT systems. Although the toolkit may be used for parallel data acquisition for open (broad) domain systems, it will be most beneficial for under-resourced languages or specific domains which are not covered by available parallel resources. The ACCURAT toolkit produces:  comparable document pairs with comparability scores, al"
P12-3016,W08-0509,0,0.0424775,"). LEXACC requires aligned document pairs (also m to n alignments) for sentence extraction. It also allows extraction from comparable corpora as a whole; however, precision may decrease due to larger search space. LEXACC scores sentence pairs according to five lexical overlap and structural matching feature functions. These functions are combined using linear interpolation with weights trained for each language pair and direction using logistic regression. The feature functions are:  a lexical (translation) overlap score for content words (nouns, verbs, adjectives, and adverbs) using GIZA++ (Gao and Vogel, 2008) format dictionaries;  a lexical (translation) overlap score for functional words (all except content words) constrained by the content word alignment from the previous feature;  the alignment obliqueness score, a measure that quantifies the degree to which the relative positions of source and target aligned words differ;  a score indicating whether strong content word translations are found at the beginning and the end of each sentence in the given pair;  a punctuation score which indicates whether the sentences have identical sentence ending punctuation. For different language pairs, the"
P12-3016,N03-1017,0,0.00518591,"necessarily degrade its performance in predicting comparability levels of comparable document pairs. The evaluation on the gold standard shows a strong correlation (between 0.883 and 0.999) between human defined comparability levels and the confidence scores of the metric. 2.2 Parallel Sentence Extractor Comparable Corpora from Phrase-based statistical translation models are among the most successful translation models that currently exist (Callison-Burch et al., 2010). Usually, phrases are extracted from parallel corpora by means of symmetrical word alignment 93 and/or by phrase generation (Koehn et al., 2003). Our toolkit exploits comparable corpora in order to find and extract comparable sentences for SMT training using a tool named LEXACC (Ştefănescu et al., 2012). LEXACC requires aligned document pairs (also m to n alignments) for sentence extraction. It also allows extraction from comparable corpora as a whole; however, precision may decrease due to larger search space. LEXACC scores sentence pairs according to five lexical overlap and structural matching feature functions. These functions are combined using linear interpolation with weights trained for each language pair and direction using l"
P12-3016,J10-4005,0,0.0447505,"recent decades, data-driven approaches have significantly advanced the development of machine translation (MT). However, lack of sufficient bilingual linguistic resources for many languages and domains is still one of the major obstacles for further advancement of automated translation. At the same time, comparable corpora, i.e., non-parallel bi- or multilingual text resources such as daily news articles and large knowledge bases like Wikipedia, are much more widely available than parallel translation data. While methods for the use of parallel corpora in machine translation are well studied (Koehn, 2010), similar techniques for comparable corpora have not been thoroughly worked out. Only the latest research has shown that language pairs and domains with little parallel data can benefit from the exploitation of comparable corpora (Munteanu and Marcu, 2005; Lu et al., 2010; Smith et al., 2010; Abdul-Rauf and Schwenk, 2009 and 2011). In this paper we present the ACCURAT toolkit1 - a collection of tools that are capable of analysing comparable corpora and extracting parallel data which can be used to improve the performance of statistical and rule/example-based MT systems. Although the toolkit ma"
P12-3016,P06-1011,0,0.162192,"Missing"
P12-3016,W11-1205,0,0.0453047,"ducing bilingual NE or term dictionaries. The workflow also accepts pre-processed documents, thus skipping the tagging process. Since all tools use command line interfaces, task automation and workflow specification can be done with simple console/terminal scripts. All tools can be run on the Windows operating system (some are also platform independent). 1 Overview of the Workflows 2 The toolkit’s tools are integrated within two workflows (visualised in Figure 1). This section provides an overview of the main tools and methods in the toolkit. A full list of tools is described in ACCURAT D2.6. (2011). 2.1 Figure 1. Workflows of the ACCURAT toolkit. The workflow for parallel data mining from comparable corpora aligns comparable corpora in the document level (section 2.1). This step is crucial as the further steps are computationally intensive. To minimise search space, documents are aligned with possible candidates that are likely to contain parallel data. Then parallel sentence pairs are extracted from the aligned comparable corpora (section 2.2). The workflow for named entity (NE) and terminology extraction and mapping from comparable corpora extracts data in a dictionarylike format. Pro"
P12-3016,pinnis-2012-latvian,1,0.443653,"Missing"
P12-3016,su-babych-2012-development,1,0.644215,"Missing"
P12-3016,W12-0102,1,0.920916,"orkflow tags NEs or terms in all documents using 92 Tools and Methods Comparability Metrics We define comparability by how useful a pair of documents is for parallel data extraction. The higher the comparability score, the more likely two documents contain more overlapping parallel data. The methods are developed to perform lightweight comparability estimation that minimises search space of relatively large corpora (e.g., 10,000 documents in each language). There are two comparability metric tools in the toolkit: a translation based and a dictionary based metric. The Translation based metric (Su and Babych, 2012a) uses MT APIs for document translation into English. Then four independent similarity feature functions are applied to a document pair:  Lexical feature ― both documents are preprocessed (tokenised, lemmatised, and stop-words are filtered) and then vectorised. The lexical overlap score is calculated as a cosine similarity function over the vectors of two documents.  Structural feature ― the difference of sentence counts and content word counts (equally interpolated).  Keyword feature ― the cosine similarity of top 20 keywords.  NE feature ― the cosine similarity of NEs (extracted using S"
P12-3016,2012.eamt-1.37,1,0.831478,"Missing"
P12-3016,E09-1003,0,\N,Missing
P12-3016,W10-1703,0,\N,Missing
pinnis-2012-latvian,W09-3538,0,\N,Missing
pinnis-2012-latvian,W03-0419,0,\N,Missing
pinnis-2012-latvian,W02-2024,0,\N,Missing
pinnis-2012-latvian,W09-2208,0,\N,Missing
pinnis-2012-latvian,P05-1045,0,\N,Missing
pinnis-etal-2014-designing,oostdijk-etal-2002-experiences,0,\N,Missing
pinnis-etal-2014-designing,amdal-etal-2008-rundkast,0,\N,Missing
pinnis-etal-2014-designing,W07-2411,1,\N,Missing
pinnis-etal-2014-designing,federico-etal-2000-development,0,\N,Missing
pinnis-etal-2014-designing,W07-2406,0,\N,Missing
pinnis-etal-2014-designing,oostdijk-2000-spoken,0,\N,Missing
pinnis-etal-2014-designing,goedertier-etal-2000-orthographic,0,\N,Missing
R13-1074,P98-1069,0,0.29429,"Missing"
R13-1074,P07-2045,0,0.00484231,"aria, 7-13 September 2013.  Rewrites the token with letters from the English alphabet (simple transliteration); letters that cannot be rewritten (e.g., the Russian softening and hardening marks “ь” and “ъ”) are removed and letters that correspond to multiple letters in the English alphabet are expanded (e.g., the Russian “ш” and Latvian “š” are rewritten as “sh” in English).  Finds top N translation equivalents in the other language using a probabilistic dictionary, e.g., in the Giza++ format (Och and Ney, 2003).  Finds top M transliteration equivalents in the other language using a Moses (Koehn et al., 2007) character-based SMT system. maximised character alignment maps that has been created for term and term phrase mapping in term-tagged comparable corpora. The method allows mapping of multi-word terms and terms with different numbers of tokens in the source and target language parts – two term mapping scenarios that have not been sufficiently addressed by previous research. The mapper has been specifically designed to address term mapping between European languages (including languages with different alphabets based on Latin, Cyrillic and Greek) and it allows integrating linguistic resources to"
R13-1074,C10-1070,0,0.0413897,"Missing"
R13-1074,E09-1057,0,0.0576288,"Missing"
R13-1074,J03-1002,0,0.00622905,"sing 562 Proceedings of Recent Advances in Natural Language Processing, pages 562–570, Hissar, Bulgaria, 7-13 September 2013.  Rewrites the token with letters from the English alphabet (simple transliteration); letters that cannot be rewritten (e.g., the Russian softening and hardening marks “ь” and “ъ”) are removed and letters that correspond to multiple letters in the English alphabet are expanded (e.g., the Russian “ш” and Latvian “š” are rewritten as “sh” in English).  Finds top N translation equivalents in the other language using a probabilistic dictionary, e.g., in the Giza++ format (Och and Ney, 2003).  Finds top M transliteration equivalents in the other language using a Moses (Koehn et al., 2007) character-based SMT system. maximised character alignment maps that has been created for term and term phrase mapping in term-tagged comparable corpora. The method allows mapping of multi-word terms and terms with different numbers of tokens in the source and target language parts – two term mapping scenarios that have not been sufficiently addressed by previous research. The mapper has been specifically designed to address term mapping between European languages (including languages with diffe"
R13-1074,C04-1089,0,0.0675262,"Missing"
R13-1074,steinberger-etal-2012-dgt,0,0.0847034,"e 57 pairs were mapped using the simple transliteration method. Evidently, adding resources allows significantly increasing the mapped term amount. It is also visible that the best results are achieved by using all linguistic resources. Finally, term mapping was performed for 22 language pairs of the EuroVoc thesaurus with English as the source language. The results are given in Table 2. The evaluation was performed using direct source-to-target and target-tosource linguistic resources. The resources were built using Giza++ probabilistic dictionaries extracted from the DGT-TM parallel corpus (Steinberger et al., 2012). The evaluation results show that the author’s method significantly outperforms results reported earlier by Ştefănescu (2012) – an F1 score of 46.3 and 51.1 for English-Latvian and EnglishRomanian when using the same probabilistic dictionaries. The term mapping method proposed by Ştefănescu (2012) differs from the author’s method in that it maps terms either with the Levenshtein distance based similarity metric or dictionary based exact match look-up. The author’s proposed method, however, maps term tokens in sub-word level using maximised character alignment maps and applies Levenshtein dist"
R13-1074,W12-0102,0,0.0222756,"r and for terms in the medical domain. Latvian was selected as one of the languages for this evaluation as it is a morphologically rich language and it is important to show that the method can be easily applicable to languages where terms are not always in their base forms. Following the term mapping workflow proposed by Pinnis et al. (2012), two monolingual corpora were collected from the Web using the Focussed Monolingual Crawler (Mastropavlos and Papavassiliou, 2011). The acquired corpora (12,697 Latvian and 21,900 English documents) were then aligned in document level with the DictMetric (Su and Babych, 2012) comparability metric (59,600 document pairs were produced). The terms were tagged in the monolingual documents with TWSC (Pinnis et al., 2012). The term tagging step produced a total of 198,401 unique Latvian and 352,934 unique English terms. The reason why document alignment is a necessary step before mapping can be easily explained with the large number of monolingual terms. If the terms would be mapped between the two monolingual lists, the mapper would have to handle a search space of 70 billion term pairs and require over 91 days to complete (using direct linguistic resources). With docu"
R13-1074,P99-1067,0,0.217789,"Missing"
R13-1074,C98-1066,0,\N,Missing
R13-1074,2011.eamt-1.31,0,\N,Missing
R13-1074,skadina-etal-2012-collecting,1,\N,Missing
skadina-etal-2012-collecting,W06-2810,0,\N,Missing
skadina-etal-2012-collecting,E06-1020,0,\N,Missing
skadina-etal-2012-collecting,W11-1217,0,\N,Missing
skadina-etal-2012-collecting,E09-1003,0,\N,Missing
skadina-etal-2012-collecting,W07-1702,0,\N,Missing
skadina-etal-2012-collecting,J03-3002,0,\N,Missing
skadina-etal-2012-collecting,W09-1605,0,\N,Missing
skadina-etal-2012-collecting,P02-1040,0,\N,Missing
skadina-etal-2012-collecting,J05-4003,0,\N,Missing
skadina-etal-2012-collecting,C10-1073,0,\N,Missing
skadina-etal-2012-collecting,R11-1106,0,\N,Missing
skadina-etal-2012-collecting,P07-2045,0,\N,Missing
skadina-etal-2012-collecting,P12-3016,1,\N,Missing
skadina-etal-2012-collecting,2005.mtsummit-papers.11,0,\N,Missing
skadina-etal-2012-collecting,aker-etal-2012-light,1,\N,Missing
skadina-etal-2012-collecting,su-babych-2012-development,1,\N,Missing
skadina-etal-2012-collecting,pinnis-2012-latvian,1,\N,Missing
skadina-etal-2012-collecting,C10-2054,0,\N,Missing
skadina-etal-2012-collecting,P00-1056,0,\N,Missing
W15-4912,W14-4803,0,0.072807,"ed gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can signiﬁcantly improve translation quality of an out-of-domain system (up to +2.13 BLEU points). Their method speciﬁcally addressed morphologically rich languages by identifying terms in different inﬂected forms using stemming tools. Similar work that shows signiﬁcant quality improvements has been recently performed by Arcan et al. (2014a) for the English-Italian language pair. They use a term collection to create a ” ﬁll-up” translation model that consists of a pre-trained SMT system’s phrase table merged with a phrase table created from the bilingual terminology. However, all these methods require to re-train the whole SMT system (or at least re-tune the SMT system) if new in-domain data becomes available. For many translation tasks such a scenario is not economically justiﬁable. Furthermore, if we have already trained a relatively good SMT system (let it be a general domain system or a close-domain system to the domain tha"
W15-4912,2014.amta-researchers.5,0,0.0649455,"ed gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can signiﬁcantly improve translation quality of an out-of-domain system (up to +2.13 BLEU points). Their method speciﬁcally addressed morphologically rich languages by identifying terms in different inﬂected forms using stemming tools. Similar work that shows signiﬁcant quality improvements has been recently performed by Arcan et al. (2014a) for the English-Italian language pair. They use a term collection to create a ” ﬁll-up” translation model that consists of a pre-trained SMT system’s phrase table merged with a phrase table created from the bilingual terminology. However, all these methods require to re-train the whole SMT system (or at least re-tune the SMT system) if new in-domain data becomes available. For many translation tasks such a scenario is not economically justiﬁable. Furthermore, if we have already trained a relatively good SMT system (let it be a general domain system or a close-domain system to the domain tha"
W15-4912,W03-2201,0,0.270992,"ng of SMT systems. For instance, the Moses SMT system supports input data (in the Moses XML format) that is enriched with externally generated translation candidates. Using this methodology, Carl & Langlais (2002) used term dictionaries to pre-process source text and achieved an increase in translation quality for the English-French language pair. Similarly, Arcan et al. (2014a) identify exactly matched terms and provide translation equivalents from the Wiki Machine1 by performing context-based disambiguation if there are multiple translation equivalents for a single term for English-Italian. Babych & Hartley (2003) showed that inclusion of certain named entities in “do-not-translate” lists allowed to increase translation quality for the English-Russian language pair. Recently dynamic translation and language models (Bertoldi, 2014) have been investigated for integration of terminology into SMT (Arcan et al., 2014b) for English-Italian. It is evident that most of the related research has, however, mostly focused on languages with simple morphology or translation of phrases that are rarely 1 The Wiki Machine is available https://bitbucket.org/fbk/thewikimachine online at: 90 translated or even left untran"
W15-4912,W09-0432,0,0.0191929,"gh terminology translation quality in the SMT suggestions. Therefore, effective methods that can beneﬁt from custom term collections are necessary. Researchers have tried to address the terminology integration challenge directly by using indomain term collections and indirectly by tackling the broader challenge of domain adaptation. Signiﬁcant research efforts have been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to speciﬁc domains (to name but a few, Koehn & Schroeder (2007), Bertoldi & Federico (2009), Hildebrand et al. (2005), and many others). Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT. E.g., Bouamor et al. (2012) showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can s"
W15-4912,bouamor-etal-2012-identifying,0,0.103643,"ration challenge directly by using indomain term collections and indirectly by tackling the broader challenge of domain adaptation. Signiﬁcant research efforts have been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to speciﬁc domains (to name but a few, Koehn & Schroeder (2007), Bertoldi & Federico (2009), Hildebrand et al. (2005), and many others). Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT. E.g., Bouamor et al. (2012) showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can signiﬁcantly improve translation quality of an out-of-domain system (up to +2.13 BLEU points). Their method speciﬁcally addressed morphologically rich languages by identifying terms in"
W15-4912,W02-1402,0,0.227965,"we have already trained a relatively good SMT system (let it be a general domain system or a close-domain system to the domain that is needed), we should be able to tailor it to the required domain with the help of just the right bilingual terminology. Consequently, considerable research efforts have been focussed also on dynamic integration methods for term collections in SMT that do not require re-training of SMT systems. For instance, the Moses SMT system supports input data (in the Moses XML format) that is enriched with externally generated translation candidates. Using this methodology, Carl & Langlais (2002) used term dictionaries to pre-process source text and achieved an increase in translation quality for the English-French language pair. Similarly, Arcan et al. (2014a) identify exactly matched terms and provide translation equivalents from the Wiki Machine1 by performing context-based disambiguation if there are multiple translation equivalents for a single term for English-Italian. Babych & Hartley (2003) showed that inclusion of certain named entities in “do-not-translate” lists allowed to increase translation quality for the English-Russian language pair. Recently dynamic translation and l"
W15-4912,C14-2028,0,0.112918,"Missing"
W15-4912,2005.eamt-1.19,0,0.0432728,"uality in the SMT suggestions. Therefore, effective methods that can beneﬁt from custom term collections are necessary. Researchers have tried to address the terminology integration challenge directly by using indomain term collections and indirectly by tackling the broader challenge of domain adaptation. Signiﬁcant research efforts have been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to speciﬁc domains (to name but a few, Koehn & Schroeder (2007), Bertoldi & Federico (2009), Hildebrand et al. (2005), and many others). Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT. E.g., Bouamor et al. (2012) showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can signiﬁcantly improve transl"
W15-4912,P07-2045,0,0.00783619,"Missing"
W15-4912,W07-0733,0,0.0492753,"t be possible to ensure high terminology translation quality in the SMT suggestions. Therefore, effective methods that can beneﬁt from custom term collections are necessary. Researchers have tried to address the terminology integration challenge directly by using indomain term collections and indirectly by tackling the broader challenge of domain adaptation. Signiﬁcant research efforts have been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to speciﬁc domains (to name but a few, Koehn & Schroeder (2007), Bertoldi & Federico (2009), Hildebrand et al. (2005), and many others). Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT. E.g., Bouamor et al. (2012) showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in"
W15-4912,W12-5701,0,0.0171724,"ho-syntactically valid term phrases actually correspond to a term from the term collection. • The ﬁrst two methods rely heavily on linguistic tools that can signiﬁcantly affect the translation speed. Therefore, the third method (Fast Term Identiﬁcation or Fast) performs a left-to-right search in the source text using minimal linguistic support from languagespeciﬁc stemming tools to identify terms in different inﬂected forms. 2.2 Inﬂected Form Generation The next pre-processing step after term identiﬁcation is the generation of translation candidates for the identiﬁed terms. Previous research (Nikoulina et al., 2012; Carl & Langlais, 2002; Babych & Hartley, 2003) on source text pre-processing has not given special attention to this question, because the bilingual term collections already “provide” translation equivalents. However, the issue is that the terms that are provided in the bilingual term collections are usually in their canonical forms. For morphologically rich languages the canonical forms in many contexts are not the required inﬂected forms. Because of the focus on language pairs that do not require (or require very limited) morphological generation (e.g., English-French, English-German, etc."
W15-4912,P02-1040,0,0.0979664,"e been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to speciﬁc domains (to name but a few, Koehn & Schroeder (2007), Bertoldi & Federico (2009), Hildebrand et al. (2005), and many others). Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT. E.g., Bouamor et al. (2012) showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU (Papineni et al., 2002) points. In terms of direct terminology integration, Pinnis & Skadin¸sˇ (2012) have shown that the addition of terms to the parallel corpus and the introduction of a bilingual terminology identifying feature in the translation model can signiﬁcantly improve translation quality of an out-of-domain system (up to +2.13 BLEU points). Their method speciﬁcally addressed morphologically rich languages by identifying terms in different inﬂected forms using stemming tools. Similar work that shows signiﬁcant quality improvements has been recently performed by Arcan et al. (2014a) for the English-Italian"
W15-4912,2014.eamt-1.43,1,0.829097,"Missing"
W15-4912,steinberger-etal-2012-dgt,0,0.118052,"r analysed, which pre-processing conﬁguration allows achieving better results (see Figure 3). This analysis was performed for English-Latvian using a term collection that was created by a professional translator from the tuning-data. The term collection consists of 644 term pairs (terms were included only in their canonical forms). The results show that all combiAutomatic Evaluation The automatic evaluation was performed for three language pairs (English-German, Latvian, and Lithuanian) using general domain SMT systems that were trained in the LetsMT platform using the DGT-TM parallel corpus (Steinberger et al., 2012) (the releases of 2007, 2011, and 2012). For evaluation, the author uses a proprietary parallel corpus of 872 sentence pairs in the automotive domain (technical documentation from car service manuals). The original data set was available for English-Latvian, therefore, the remaining two data sets for German and Lithuanian were prepared by professional translators. For English-Latvian an in-domain tuning set of 1,745 sentence pairs was available; for the remaining systems held-out sets of 2,000 sentence pairs from the training data were used for SMT system tuning. The results of the baseline sy"
W15-4912,P12-3008,0,0.197726,"Missing"
W16-2320,W16-2304,1,0.833347,"factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. T"
W16-2320,W05-0909,0,0.583183,"ions from multiple hypotheses which are obtained from different translation approaches, i.e., the systems described in the previous section. A system combination implementation developed at RWTH Aachen University (Freitag et al., 2014a) is used to combine the outputs of the different engines. The consensus translations outperform the individual hypotheses in terms of translation quality. The first step in system combination is the generation of confusion networks (CN) from I input translation hypotheses. We need pairwise alignments between the input hypotheses, which are obtained from METEOR (Banerjee and Lavie, 2005). The hypotheses are then reordered to match a selected skeleton hypothesis in terms of word ordering. We generate I different CNs, each having one of the input systems as the skeleton hypothesis, and the final lattice is the union of all I generated CNs. In Figure 1 an example of a confusion network with I = 4 input translations is depicted. Decoding of a confusion network finds the best path in the network. Each arc is assigned a score of a linear model combination of M different models, which includes word penalty, 3-gram language model trained on the input hypotheses, a binary primary syst"
W16-2320,P13-2071,1,0.873371,"odel trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ quest_files/features_blackbox_baseline_ 17 https://github.com/rsennrich/nematus 348 the large building the large home a big huge house house a newsdev2016/1 and newsdev2016/2. The first part was used as development set while t"
W16-2320,D15-1129,1,0.847985,"training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integrates a discriminative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based loc"
W16-2320,N13-1073,0,0.034805,"preordering model of (de Gispert et al., 2015). The preordering model is trained for 30 iterations on the full MGIZA-aligned training data. We use two language models, built using KenLM. The first is a 5-gram language model trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ ques"
W16-2320,J04-2004,0,0.0194677,"en systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probabilit"
W16-2320,2011.mtsummit-papers.30,0,0.020392,"-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 201"
W16-2320,N12-1047,0,0.591808,"rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using the Berkeley parser (Petrov et al., 2006). For model prediction during tuning and decoding, we use parsed versions of the development and test sets. We train the rule selection model using VW and tune the weights of the translation model using batch MIRA (Cherry and Foster, 2012). The 5-gram language model is trained using KenLM (Heafield et al., 2013) on the Romanian part of the Common Crawl corpus concatenated with the Romanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but also its lemma and morphological tag. On the input, we include lemmas, POS tags and information from dependency parses (lemma of the parent node and syntactic relation), all encoded as additional factors. The main difference from a standard p"
W16-2320,E14-2008,1,0.72015,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,P05-1033,0,0.151933,"ative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combin"
W16-2320,J07-2003,0,0.558191,"this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the bou"
W16-2320,W14-3310,1,0.909876,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,D14-1179,0,0.0138582,"Missing"
W16-2320,2014.iwslt-evaluation.7,1,0.925781,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,D08-1089,0,0.0211464,", built using KenLM. The first is a 5-gram language model trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ quest_files/features_blackbox_baseline_ 17 https://github.com/rsennrich/nematus 348 the large building the large home a big huge house house a newsdev2016/1 and newsdev2016/2. T"
W16-2320,N15-1105,0,0.046766,"Missing"
W16-2320,W08-0509,0,0.06624,"probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshuffling the training corpus between epochs. We validate the model every 10 000 minibatches via B LEU on a validation set, and perform early stopping on B LEU. Decoding is performed with beam search with a beam size of 12. A more detailed description of the system, and more experimental results, can be found in (Sennrich et al., 2016a). 3.10 3.11 USFD’s phrase-based system is built using the Moses toolkit, with MGIZA (Gao and Vogel, 2008) for word alignment and KenLM (Heafield et al., 2013) for language model training. We use all available parallel data for the translation model. A single 5-gram language model is built using all the target side of the parallel data and a subpart of the monolingual Romanian corpora selected with Xenc-v2 (Rousseau, 2013). For the latter we use all the parallel data as in-domain data and the first half of newsdev2016 as development set. The feature weights are tuned with MERT (Och, 2003) on the first half of newsdev2016. The system produces distinct 1000-best lists, for which we extend the featur"
W16-2320,W16-2315,1,0.820309,"vs et al., 2012) that features language-specific data filtering and cleaning modules. Tilde’s system was trained on all available parallel data. Two language models are trained using KenLM (Heafield, 2011): 1) a 5-gram model using the Europarl and SETimes2 corpora, and 2) a 3-gram model using the Common Crawl corpus. We also apply a custom tokenization tool that takes into account specifics of the Romanian language and handles non-translatable entities (e.g., file paths, 347 up with entries from a background phrase table extracted from the automatically produced News Crawl 2015 parallel data. Huck et al. (2016) give a more in-depth description of the Edinburgh/LMU hierarchical machine translation system, along with detailed experimental results. 3.9 built from only News Crawl 2015, with singleton 3-grams and above pruned out. The weights of all these features and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural Sy"
W16-2320,D07-1103,0,0.032902,"bbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT ("
W16-2320,W14-3360,0,0.0191919,"NMT system on newsdev2016/2, but lags behind on newstest2016. Removing the by itself weakest system shows a slight degradation on newsdev2016/2 and newstest2016, hinting that it still provides valuable information. Table 2 shows a comparison between all systems by scoring the translation output against each other in T ER and B LEU. We see that the neural networks outputs differ the most from all the other systems. Figure 1: System A: the large building; System B: the large home; System C: a big house; System D: a huge house; Reference: the big house. classes were generated using the method of Green et al. (2014). 4 System Combination System combination produces consensus translations from multiple hypotheses which are obtained from different translation approaches, i.e., the systems described in the previous section. A system combination implementation developed at RWTH Aachen University (Freitag et al., 2014a) is used to combine the outputs of the different engines. The consensus translations outperform the individual hypotheses in terms of translation quality. The first step in system combination is the generation of confusion networks (CN) from I input translation hypotheses. We need pairwise alig"
W16-2320,P07-2045,1,0.010375,", 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based"
W16-2320,P13-2121,0,0.0645203,"Missing"
W16-2320,W11-2123,0,0.124165,"nslation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all singletons with KenLM (Heafield, 2011). We use the in-domain monolingual corpus, the Romanian side of the parallel corpora and a subset of the (out-of-domain) Common Crawl corpus as training data. We select indomain sentences from the latter using the MooreLewis (Moore and Lewis, 2010) filtering method, Translation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phras"
W16-2320,N04-1022,0,0.037676,"f the Romanian language and handles non-translatable entities (e.g., file paths, 347 up with entries from a background phrase table extracted from the automatically produced News Crawl 2015 parallel data. Huck et al. (2016) give a more in-depth description of the Edinburgh/LMU hierarchical machine translation system, along with detailed experimental results. 3.9 built from only News Crawl 2015, with singleton 3-grams and above pruned out. The weights of all these features and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpu"
W16-2320,2015.iwslt-papers.3,1,0.744353,"g. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn e"
W16-2320,J06-4004,0,0.106202,"Missing"
W16-2320,2009.iwslt-papers.4,0,0.0984189,"target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT (Och, 2003) towards the B LEU metric. 3.6 3.8 The UEDIN-LMU HPBT system is a hierarchical phrase-based machine translation system (Chiang, 2005) built jointly by the University of Edinburgh and LMU Munich. The system is based on the open source Moses implementation of the hierarchical phrase-based paradigm (Hoang et al., 2009). In addition to a set of standard features in a log-linear combination, a number of non-standard enhancements are employed to achieve improved translation quality. Specifically, we integrate individual language models trained over the separate corpora (News Crawl 2015, Europarl, SETimes2) directly into the log-linear combination of the system and let MIRA (Cherry and Foster, 2012) optimize their weights along with all other features in tuning, rather than relying on a single linearly interpolated language model. We add another background language model estimated over a concatenation of all Ro"
W16-2320,P10-2041,0,0.0238386,"ontaining the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all singletons with KenLM (Heafield, 2011). We use the in-domain monolingual corpus, the Romanian side of the parallel corpora and a subset of the (out-of-domain) Common Crawl corpus as training data. We select indomain sentences from the latter using the MooreLewis (Moore and Lewis, 2010) filtering method, Translation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using"
W16-2320,P07-1019,0,0.236745,"grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language"
W16-2320,2012.amta-papers.19,1,0.778005,"common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual engines, followed by a brief overview of our system combination approach (Section 4). We then summarize our empirical results in Section 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set usin"
W16-2320,W11-2211,1,0.902733,"ty words, and no lower limit to the amount of words covered by right-hand side non-terminals at extraction time. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. In order to promote better reordering decisions, we implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013) and extend our system with it. The model scores orientation classes (monotone, swap, discontinuous) for each rule application in decoding. We finally follow the approach outlined by Huck et al. (2011) for lightly-supervised training of hierarchical systems. We automatically translate parts (1.2M sentences) of the monolingual Romanian News Crawl 2015 corpus to English with a Romanian→English phrase-based statistical machine translation system (Williams et al., 2016). The foreground phrase table extracted from the human-generated parallel data is filled RWTH Neural System The second system provided by the RWTH is an attention-based recurrent neural network similar to (Bahdanau et al., 2015). The implementation is based on Blocks (van Merri¨enboer et al., 2015) and Theano (Bergstra et al., 20"
W16-2320,W13-2264,1,0.852517,"stic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additio"
W16-2320,W13-2258,1,0.869431,"extraction, we impose less strict extraction constraints than the Moses defaults. We extract more hierarchical rules by allowing for a maximum of ten symbols on the source side, a maximum span of twenty words, and no lower limit to the amount of words covered by right-hand side non-terminals at extraction time. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. In order to promote better reordering decisions, we implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013) and extend our system with it. The model scores orientation classes (monotone, swap, discontinuous) for each rule application in decoding. We finally follow the approach outlined by Huck et al. (2011) for lightly-supervised training of hierarchical systems. We automatically translate parts (1.2M sentences) of the monolingual Romanian News Crawl 2015 corpus to English with a Romanian→English phrase-based statistical machine translation system (Williams et al., 2016). The foreground phrase table extracted from the human-generated parallel data is filled RWTH Neural System The second system prov"
W16-2320,E99-1010,0,0.040797,"ion 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and th"
W16-2320,P03-1021,0,0.501814,". To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT (Och, 2003) towards the B LEU metric. 3.6 3.8 The UEDIN-LMU HPBT system is a hierarchical phrase-based machine translation system (Chiang, 2005) built jointly by the University of Edinburgh and LMU Munich. The system is based on the open source Moses implementation of the hierarchical phrase-based paradigm (Hoang et al., 2009). In addition to a set of standard features in a log-linear combination, a number of non-standard enhancements are employed to achieve improved translation quality. Specifically, we integrate individual language models trained over the separate corpora (News Crawl 2015, Europarl, SE"
W16-2320,D14-1003,1,0.932306,"with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language model (Sundermeyer et al., 2012) and a LSTM-based bidirectional joined model (BJM) (Sundermeyer et al., 2014a). The models have a class-factored output layer (Goodman, 2001; Morin and Bengio, 2005) to speed up training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integrates a discriminative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule appli"
W16-2320,P06-1055,0,0.0121776,"anslation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using the Berkeley parser (Petrov et al., 2006). For model prediction during tuning and decoding, we use parsed versions of the development and test sets. We train the rule selection model using VW and tune the weights of the translation model using batch MIRA (Cherry and Foster, 2012). The 5-gram language model is trained using KenLM (Heafield et al., 2013) on the Romanian part of the Common Crawl corpus concatenated with the Romanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but als"
W16-2320,2007.tmi-papers.21,0,0.0230136,"n 2. Section 3 covers the characteristics of the different individual engines, followed by a brief overview of our system combination approach (Section 4). We then summarize our empirical results in Section 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add t"
W16-2320,P16-1161,1,0.729045,"omanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but also its lemma and morphological tag. On the input, we include lemmas, POS tags and information from dependency parses (lemma of the parent node and syntactic relation), all encoded as additional factors. The main difference from a standard phrasebased setup is the addition of a feature-rich discriminative translation model which is conditioned on both source- and target-side context (Tamchyna et al., 2016). The motivation for using this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-"
W16-2320,tufis-etal-2008-racais,0,0.107217,"Missing"
W16-2320,P16-1009,1,0.78198,"and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpus into English (Sennrich et al., 2016b), which we combine with the original parallel data in a 1-to-1 ratio. We use minibatches of size 80, a maximum sentence length of 50, word embeddings of size 500, and hidden layers of size 1024. We apply dropout to all layers (Gal, 2015), with dropout probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshufflin"
W16-2320,P12-3008,0,0.0597108,"Missing"
W16-2320,P16-1162,1,0.259658,"and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpus into English (Sennrich et al., 2016b), which we combine with the original parallel data in a 1-to-1 ratio. We use minibatches of size 80, a maximum sentence length of 50, word embeddings of size 500, and hidden layers of size 1024. We apply dropout to all layers (Gal, 2015), with dropout probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshufflin"
W16-2320,W10-1738,1,0.885055,"rget-side context (Tamchyna et al., 2016). The motivation for using this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical ph"
W16-2320,P15-4020,1,0.815128,"data for the translation model. A single 5-gram language model is built using all the target side of the parallel data and a subpart of the monolingual Romanian corpora selected with Xenc-v2 (Rousseau, 2013). For the latter we use all the parallel data as in-domain data and the first half of newsdev2016 as development set. The feature weights are tuned with MERT (Och, 2003) on the first half of newsdev2016. The system produces distinct 1000-best lists, for which we extend the feature set with the 17 baseline black-box features from sentencelevel Quality Estimation (QE) produced with Quest++4 (Specia et al., 2015). The 1000-best lists are then reranked and the top-best hypothesis extracted using the nbest rescorer available within the Moses toolkit. 3.12 UvA We use a phrase-based machine translation system (Moses) with a distortion limit of 6 and lexicalized reordering. Before translation, the English source side is preordered using the neural preordering model of (de Gispert et al., 2015). The preordering model is trained for 30 iterations on the full MGIZA-aligned training data. We use two language models, built using KenLM. The first is a 5-gram language model trained on all available data. Words in"
W16-2320,W16-2327,1,0.84726,"Missing"
W16-2320,D13-1138,1,0.859072,"(Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language model (Sundermeyer et al., 2012) and a LSTM-based bidirectional joined model (BJM) (Sundermeyer et al., 2014a). The models have a class-factored output layer (Goodman, 2001; Morin and Bengio, 2005) to speed up training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integra"
W16-2320,2002.tmi-tutorials.2,0,0.0608664,"omanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all"
W17-4734,W05-0909,0,0.158301,"ions from multiple hypotheses which are obtained from different translation approaches, i.e., the systems described in the previous section. A system combination implementation developed at RWTH Aachen University (Freitag et al., 2014a) is used to combine the outputs of the different engines. The consensus translations outperform the individual hypotheses in terms of translation quality. The first step in system combination is the generation of confusion networks (CN) from I input translation hypotheses. We need pairwise alignments between the input hypotheses, which are obtained from METEOR (Banerjee and Lavie, 2005). The hypotheses are then reordered to match a selected skeleton hypothesis in terms of word ordering. We generate I different CNs, each having one of the input systems as the skeleton hypothesis, and the final lattice is the union of all I generated CNs. In Figure 1 an example of a confusion network with I = 4 input translations is depicted. Decoding of a confusion network finds the best path in the network. Each arc is assigned a score of a linear model combination of M different models, which includes word penalty, 3-gram language model trained on the input hypotheses, a binary primary syst"
W17-4734,P09-1064,0,0.0328843,"translations. pothesis, and a binary voting feature for each system. The binary voting feature for a system is 1 if and only if the decoded word is from that system, and 0 otherwise. The different model weights for system combination are trained with MERT (Och, 2003) and optimized towards 8·B LEU −T ER. 4.2 Consensus-based System Selection 5 Experimental Evaluation As a secondary solution for system combination, we used USFD’s consensus-based n-nbest list selection approach (Blain et al., 2017) for system combination by combining each system’s output in the form of a n-best list. Inspired by DeNero et al. (2009)’s work on consensus-based Minimum Bayes Risk (MBR) decoding which compares different types of similarity metrics (B LEU, W ER, etc.) under a SMT setup, USFD designed a reranking approach to empirically evaluate the effect of consensus on the varying n-best list in NMT. Given a n-best list, each translation hypothesis is scored against the other MT candidates of the search space towards an automatic metric. In our experiment we considered three automatic metrics amongst the most widely used and which have been shown to be well correlated with human judgments (Bojar et al., 2016): B LEU, B EER"
W17-4734,D17-1209,1,0.891192,"Missing"
W17-4734,E14-2008,1,0.856971,"many 2 Charles University, Prague, Czech Republic 3 Karlsruhe Institute of Technology, Karlsruhe, Germany 4 LIMSI, CNRS, Universit´e Paris Saclay, 91 403 Orsay, France 5 Tilde, Riga, Latvia 6 University of Amsterdam, Amsterdam, Netherlands 7 University of Edinburgh, Edinburgh, UK 8 University of Sheffield, Sheffield, UK Abstract English→Latvian translation engines which have been set up by different project partners. The outputs of all these individual engines are combined using the system combination approach as implemented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Peter et al., 2016; Freitag et al., 2013, 2014b,c). As an alternative way of combining our systems, all outputs have been merged as the form of a n-best list and a consensus-based system-selection applied to obtain as best translation hypothesis the candidate that is most similar to the most likely translations amongst those systems. This paper describes the joint submission of the QT21 projects for the English→Latvian tran"
W17-4734,W16-2302,1,0.832947,". Inspired by DeNero et al. (2009)’s work on consensus-based Minimum Bayes Risk (MBR) decoding which compares different types of similarity metrics (B LEU, W ER, etc.) under a SMT setup, USFD designed a reranking approach to empirically evaluate the effect of consensus on the varying n-best list in NMT. Given a n-best list, each translation hypothesis is scored against the other MT candidates of the search space towards an automatic metric. In our experiment we considered three automatic metrics amongst the most widely used and which have been shown to be well correlated with human judgments (Bojar et al., 2016): B LEU, B EER (Stanojevic and Simaan, 2014) or C HR F (Popovic, 2015). The entire list of MT candidates is then entirely re-ranked according to the averaged score of each candidate. Different from most re-ranking approaches which make use of additional information usually treated as new model components and combined with the existing ones, we here focus only on the MT candidates. The difference between the consensus-based n-best list selection and an oracle translation is the absence Since only one development set was provided we split the given development set into two parts: newsdev2017/1 a"
W17-4734,W14-3310,1,0.870459,"many 2 Charles University, Prague, Czech Republic 3 Karlsruhe Institute of Technology, Karlsruhe, Germany 4 LIMSI, CNRS, Universit´e Paris Saclay, 91 403 Orsay, France 5 Tilde, Riga, Latvia 6 University of Amsterdam, Amsterdam, Netherlands 7 University of Edinburgh, Edinburgh, UK 8 University of Sheffield, Sheffield, UK Abstract English→Latvian translation engines which have been set up by different project partners. The outputs of all these individual engines are combined using the system combination approach as implemented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Peter et al., 2016; Freitag et al., 2013, 2014b,c). As an alternative way of combining our systems, all outputs have been merged as the form of a n-best list and a consensus-based system-selection applied to obtain as best translation hypothesis the candidate that is most similar to the most likely translations amongst those systems. This paper describes the joint submission of the QT21 projects for the English→Latvian tran"
W17-4734,W17-4703,1,0.884283,"Missing"
W17-4734,2014.iwslt-evaluation.7,1,0.873477,"many 2 Charles University, Prague, Czech Republic 3 Karlsruhe Institute of Technology, Karlsruhe, Germany 4 LIMSI, CNRS, Universit´e Paris Saclay, 91 403 Orsay, France 5 Tilde, Riga, Latvia 6 University of Amsterdam, Amsterdam, Netherlands 7 University of Edinburgh, Edinburgh, UK 8 University of Sheffield, Sheffield, UK Abstract English→Latvian translation engines which have been set up by different project partners. The outputs of all these individual engines are combined using the system combination approach as implemented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Peter et al., 2016; Freitag et al., 2013, 2014b,c). As an alternative way of combining our systems, all outputs have been merged as the form of a n-best list and a consensus-based system-selection applied to obtain as best translation hypothesis the candidate that is most similar to the most likely translations amongst those systems. This paper describes the joint submission of the QT21 projects for the English→Latvian tran"
W17-4734,W17-4737,1,0.831634,"Missing"
W17-4734,W11-2123,0,0.0435093,"o this end, k-best hypothesis from the dictionary were generated, as well as the n-best hypothesis 3.4 Tilde The Tilde system is a Moses phrase-based SMT system that was trained on the Tilde MT platform (Vasil¸jevs et al., 2012). The system was trained using all available parallel data - 1.74 million unique sentence pairs after filtering, and 3 million unique sentence pairs that were acquired by re-translating a random selection of indomain monolingual sentences with a neural machine translation system (Pinnis et al., 2017). The system has a 5-gram language model that was trained using KenLM (Heafield, 2011) on all available monolingual data (27.83 million unique sentences). 3.5 UEDIN The University of Edinburgh’s system is an attentional encoder-decoder (Bahdanau et al., 2015), trained using the Nematus toolkit (Sennrich et al., 2017c). As training data, we used all parallel and synthetic data, which was tokenized, truecased, and filtered as described in Section 2. After filtering, the data was segmented into subword units using byte-pair-encoding (BPE), for which we used 90,000 operations, jointly learned over both sides of the parallel corpora. We used word embeddings of size 512 and hidden la"
W17-4734,W15-3049,0,0.0536506,"Missing"
W17-4734,E17-2025,0,0.0291776,"l and synthetic data, which was tokenized, truecased, and filtered as described in Section 2. After filtering, the data was segmented into subword units using byte-pair-encoding (BPE), for which we used 90,000 operations, jointly learned over both sides of the parallel corpora. We used word embeddings of size 512 and hidden layers of size 1024, with the size of the source and target network vocabularies fixed to the size of the respective BPE vocabularies. In order to reduce the size of the models, the target-side embedding weights were tied with the transpose of 350 the output weight matrix (Press and Wolf, 2017). We used a deep transition architecture inspired by the one proposed by Zilly et al. (2016) for language modelling. In experiments conducted during feature development, we found that this gave consistent improvements across multiple language pairs. We also applied layer normalisation (Ba et al., 2016) to all recurrent and feed-forward layers, except for layers that are followed by a softmax. In preliminary experiments, we found that using layer normalisation led to faster convergence and resulted in slightly better performance. We trained the models with adam (Kingma and Ba, 2015), using a le"
W17-4734,E17-3017,0,0.0486901,"Missing"
W17-4734,P17-4012,0,0.0301124,"stem for the WMT 2017 shared task for machine translation of news 1 are seven individual 1 http://www.statmt.org/wmt17/ translation-task.html 348 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 348–357 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics tool. The number of sentences being removed is approximately 50000. in Neural Monkey. Instead, the translations were generated using greedy search. 3 3.2 Translation Systems The neural machine translation models from KIT are built with the OpenNMT framework (Klein et al., 2017), which is a multi-layer LSTM encoder decoder network. We trained the models with 2.1 million parallel sentence pairs concatenated with 2.8 million pairs from backtranslation provided by University of Edinburgh. The networks have 1024 hidden units for each of 2 LSTM layers for both encoder and decoder. Furthermore, we experiment a number of features with the baseline: First, we found out that using a context gate to mask activities between the decoder hidden state and the source context vector before producing the distribution at each time step (Tu et al., 2016a) is simple yet beneficial for p"
W17-4734,D17-1159,0,0.0716203,"Missing"
W17-4734,D16-1096,0,0.0289091,"rom backtranslation provided by University of Edinburgh. The networks have 1024 hidden units for each of 2 LSTM layers for both encoder and decoder. Furthermore, we experiment a number of features with the baseline: First, we found out that using a context gate to mask activities between the decoder hidden state and the source context vector before producing the distribution at each time step (Tu et al., 2016a) is simple yet beneficial for performance. Second, we strengthen the attentional network with a coverage vector accumulating the previous attentional information, similar to the work of Mi et al. (2016) and Tu et al. (2016b). Using the two techniques helps improve the BLEU score on the newsdev2017 set by 1.1 (tokenized) BLEU. By using ensembling 3 networks with different configs and rescoring using a model trained with reversed target sentences, we managed to reach 26.96 BLEU score for the development set, which yields 2.8 point of improvement compared to the baseline model. Details about the effect of each technique is described in Pham et al. (2017) Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 KIT CUNI The CUNI component of"
W17-4734,P03-1021,0,0.0379532,"re case-sensitive. of reference translation: each translation hypothesis is scored against all the other hypotheses used as references while in an oracle translation each translation hypothesis is scored against a single reference. This results in obtaining as best translation hypothesis the candidate that is most similar to the most likely translations. pothesis, and a binary voting feature for each system. The binary voting feature for a system is 1 if and only if the decoded word is from that system, and 0 otherwise. The different model weights for system combination are trained with MERT (Och, 2003) and optimized towards 8·B LEU −T ER. 4.2 Consensus-based System Selection 5 Experimental Evaluation As a secondary solution for system combination, we used USFD’s consensus-based n-nbest list selection approach (Blain et al., 2017) for system combination by combining each system’s output in the form of a n-best list. Inspired by DeNero et al. (2009)’s work on consensus-based Minimum Bayes Risk (MBR) decoding which compares different types of similarity metrics (B LEU, W ER, etc.) under a SMT setup, USFD designed a reranking approach to empirically evaluate the effect of consensus on the varyi"
W17-4734,P16-1162,0,0.11892,"he effect of each technique is described in Pham et al. (2017) Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 KIT CUNI The CUNI component of the system was built using Neural Monkey2 (Helcl and Libovick´y, 2017), a flexible sequence-to-sequence toolkit implementing primarily the Bahdanau et al. (2015) model but useful also in multi-modal translation and multi-task training. We used essentially the baseline setup of the system as released for the WMT17 NMT Training Task3 (Bojar et al., 2017) for an 8GB GPU card. This involves BPE (Sennrich et al., 2016) with 30k merges, maximum sentence length for both source and target limited to 50 (BPE) tokens, no dropout and embeddings (both source and target) of 600, vocabulary shared between encoder and decoder, attention and conditional GRU (Firat and Cho, 2016). We experimented with the RNN size of the encoder and decoder and increased them to 800 instead of 600, at the expense of reducing batch size to 10. The batch size of 30 with this enlarged model would still fit into our GPU card but this run was prematurely interrupted due to a hardware failure and we noticed that it converges slower in terms"
W17-4734,W14-3354,0,0.0640118,"Missing"
W17-4734,P16-5005,0,0.0206781,"with the OpenNMT framework (Klein et al., 2017), which is a multi-layer LSTM encoder decoder network. We trained the models with 2.1 million parallel sentence pairs concatenated with 2.8 million pairs from backtranslation provided by University of Edinburgh. The networks have 1024 hidden units for each of 2 LSTM layers for both encoder and decoder. Furthermore, we experiment a number of features with the baseline: First, we found out that using a context gate to mask activities between the decoder hidden state and the source context vector before producing the distribution at each time step (Tu et al., 2016a) is simple yet beneficial for performance. Second, we strengthen the attentional network with a coverage vector accumulating the previous attentional information, similar to the work of Mi et al. (2016) and Tu et al. (2016b). Using the two techniques helps improve the BLEU score on the newsdev2017 set by 1.1 (tokenized) BLEU. By using ensembling 3 networks with different configs and rescoring using a model trained with reversed target sentences, we managed to reach 26.96 BLEU score for the development set, which yields 2.8 point of improvement compared to the baseline model. Details about th"
W17-4734,P16-1008,0,0.0235141,"with the OpenNMT framework (Klein et al., 2017), which is a multi-layer LSTM encoder decoder network. We trained the models with 2.1 million parallel sentence pairs concatenated with 2.8 million pairs from backtranslation provided by University of Edinburgh. The networks have 1024 hidden units for each of 2 LSTM layers for both encoder and decoder. Furthermore, we experiment a number of features with the baseline: First, we found out that using a context gate to mask activities between the decoder hidden state and the source context vector before producing the distribution at each time step (Tu et al., 2016a) is simple yet beneficial for performance. Second, we strengthen the attentional network with a coverage vector accumulating the previous attentional information, similar to the work of Mi et al. (2016) and Tu et al. (2016b). Using the two techniques helps improve the BLEU score on the newsdev2017 set by 1.1 (tokenized) BLEU. By using ensembling 3 networks with different configs and rescoring using a model trained with reversed target sentences, we managed to reach 26.96 BLEU score for the development set, which yields 2.8 point of improvement compared to the baseline model. Details about th"
W17-4734,P12-3008,0,0.0243602,"Missing"
W17-4737,W11-2123,0,0.195273,"data for NMT system training are given in Table 2. It can be seen that the synthetic data creation process increased the size of the training data four times. 4 SMT Systems SMT systems were trained using Moses (Koehn et al., 2007) in the Tilde MT platform (Vasil¸jevs et al., 2012). All systems were trained using the filtered training data (see Table 1). Word alignment was performed using fast-align (Dyer et al., 2013). All SMT systems feature 7-gram translation models and the wbe-msd-bidirectional-feallff 2 reordering models. The systems have two language models that were trained using KenLM (Heafield, 2011) - an in-domain language model trained on the news article and news commentary corpora and an out-of-domain language model trained on the remaining monolingual data. The systems were tuned using MERT on the newsdev2017 data set. 5 NMT System Architecture The NMT system architecture is based on the implementation available with the Nematus toolkit that was used by Sennrich et al. (2016) to produce 2 More about the different types of reordering models in Moses can be found online at http://www.statmt.org/moses/?n=FactoredTraining.BuildReo rderingModel 376 Factor Word part Position Lemma Part-of-"
W17-4737,W04-3250,0,0.273597,"Missing"
W17-4737,P07-2045,0,0.0120886,"e best results could be achieved with a proportion of 1-to-1. The back-translated parallel corpora were also supplemented with sentence pairs where content words with unambiguous alignments were randomly replaced with unknown word placeholders. Finally, the additional synthetic data were added to the existing training data. The statistics of the synthetic corpora and the final training data for NMT system training are given in Table 2. It can be seen that the synthetic data creation process increased the size of the training data four times. 4 SMT Systems SMT systems were trained using Moses (Koehn et al., 2007) in the Tilde MT platform (Vasil¸jevs et al., 2012). All systems were trained using the filtered training data (see Table 1). Word alignment was performed using fast-align (Dyer et al., 2013). All SMT systems feature 7-gram translation models and the wbe-msd-bidirectional-feallff 2 reordering models. The systems have two language models that were trained using KenLM (Heafield, 2011) - an in-domain language model trained on the news article and news commentary corpora and an out-of-domain language model trained on the remaining monolingual data. The systems were tuned using MERT on the newsdev2"
W17-4737,D17-1151,0,0.0613872,"Missing"
W17-4737,W13-1809,1,0.843174,"al., 2017a) than SMT systems, therefore, we performed parallel data filtering to reduce potential non-parallelities and the negative effect of noise on the NMT systems. The filtering consisted of the following steps: 4. Truecasing. The Moses truecase.perl was used to truecase the first word of each sentence. 5. Morphology-driven word splitting (Pinnis et al., 2017b). Tokens were split using a morphological analyser and further processed with byte pair encoding (BPE) (Sennrich et al., 2015) to ensure an open vocabulary. For both languages, we used morphological analysers that were developed by Deksne (2013) using finite state transducer technology. 1. Long sentence filtering (longer than 1500 symbols or 80 tokens). 2. Sentence length difference filter (sentence pairs with a length ratio smaller than 0.3 were filtered out). 6. Factorisation. Following the work of Sennrich and Haddow (2016), who showed that linguistic input features allow increasing NMT system translation quality, we developed our NMT systems using factored models. Therefore, the source data were further factored using a language-specific tag3. Incorrect language filtering using a language detection tool (Shuyo, 2010). 1 Tilde Dat"
W17-4737,P14-5010,0,0.00672404,".81M 4.51M / 1.92M 369.85M / 335.55M 39.28M / 15.78M 128.28M / 87.60M 39.28M / 15.78M 416.36M / 360.01M After filtering (Unique) Parallel Monolingual 1.61M 27.75M 1.61M 330.23M 12.69M 81.68M 12.69M 351.99M Table 1: Training data statistics (sentence counts) for SMT and NMT systems before and after filtering Lang. pair ger or parser. For Latvian, we used an averaged perceptron-based morpho-syntactic tagger (Nikiforovs, 2014) that was trained on the data from Pinnis and Goba (2011). For English, we used the lexicalized probabilistic parser (Klein et al., 2002) from the Stanford CoreNLP toolkit (Manning et al., 2014). 3.3 (C) (U) en-lv lv-en en-lv lv-en Synth. <UNK> sent. 1.48M 1.48M 11.66M 11.66M Retransl. sent. 3.09M 3.09M 21.69M 21.36M Total 6.19M 6.19M 46.04M 45.71M Table 2: Synthetic data and final NMT model training data statistics Synthetic Data Similarly to the method by Pinnis et al. (2017b) that allows training NMT models that are more robust to unknown and rarely occurring words, we supplemented the parallel training data with synthetic parallel training sentences. To create the synthetic corpus, we performed word alignment on the parallel corpus using fast-align (Dyer et al., 2013). Then, we r"
W17-4737,W16-2323,0,0.503137,"work architectures have been introduced for other sequence processing tasks, some of which, like the multiplicative LSTM (MLSTM) units (Krause et al., 2016), promise advantages even over deep recurrent network architectures. For data pre-processing, we have shown that the language agnostic word splitting method using byte pair encoding (BPE) inconsistently splits words for morphologically rich languages and that the method can be improved by linguistically motivating word splitting (Pinnis et al., 2017b). For the WMT 2017 shared task in news translation, we build upon the NMT toolkit Nematus (Sennrich et al., 2016) that achieved the best results in the WMT 2016 shared task. We also incorporate in our systems the latest advancements in the field, for instance, MLSTM recurrent layers, morphology-driven word splitting, better handling of unknown and rare words with robust NMT models, and hybrid methods. The improvements over the baseline NMT model have allowed us to develop the best scoring systems for the English-Latvian and Latvian-English translation directions. The paper is further structured as follows: Section 2 provides an overview of our WMT 2017 systems, Section 3 describes the data and the differ"
W17-4737,P02-1040,0,0.114863,"s translated with the NMT system. Our NMT models have been trained to leave the unknown word place-holders untranslated, i.e., to pass them through to the target side (Pinnis et al., 2017b). The capability of the NMT system to pass the place-holders through unchanged is vital for the further steps to work. 6. Finally, the Moses XML document is translated with the SMT system. In the hybrid set-up, the same pre-processing and post-processing steps are used as for the individual NMT and SMT systems. 7 Results We evaluated all MT systems using multiple automatic evaluation metrics including BLEU (Papineni et al., 2002), BEER 2.0 (Stanojevic and Sima’an, 2014), CharacTER (Wang et al., 2016), 3. After translation, the NMT model’s produced attention matrix is used to perform word alignment. Here, we also identify which source words correspond to each place378 Scenario Lang. pair en-lv (C) lv-en en-lv (U) lv-en System SMT NMT Hybrid SMT NMT Hybrid SMT NMT Hybrid SMT NMT Hybrid BLEU (CS) 12.98 (12.36-13.60) †19.49 (18.71-20.28) †19.52 (18.70-20.34) 15.47 (14.88-16.06) †20.01 (19.31-20.64) †20.06 (19.45-20.71) 20.43 (19.57-21.28) 20.04 (19.22-20.78) 20.08 (19.30-20.85) 19.05 (18.42-19.67) †22.02 (21.38-22.63) †22"
W17-4737,R13-1074,1,0.906609,"Missing"
W17-4737,2006.amta-papers.25,0,0.369765,"Missing"
W17-4737,H93-1040,0,0.711224,"Missing"
W17-4737,W14-3354,0,0.0769879,"Missing"
W17-4737,P12-3008,0,0.178389,"Missing"
W17-4737,W16-2342,0,0.0361682,"the unknown word place-holders untranslated, i.e., to pass them through to the target side (Pinnis et al., 2017b). The capability of the NMT system to pass the place-holders through unchanged is vital for the further steps to work. 6. Finally, the Moses XML document is translated with the SMT system. In the hybrid set-up, the same pre-processing and post-processing steps are used as for the individual NMT and SMT systems. 7 Results We evaluated all MT systems using multiple automatic evaluation metrics including BLEU (Papineni et al., 2002), BEER 2.0 (Stanojevic and Sima’an, 2014), CharacTER (Wang et al., 2016), 3. After translation, the NMT model’s produced attention matrix is used to perform word alignment. Here, we also identify which source words correspond to each place378 Scenario Lang. pair en-lv (C) lv-en en-lv (U) lv-en System SMT NMT Hybrid SMT NMT Hybrid SMT NMT Hybrid SMT NMT Hybrid BLEU (CS) 12.98 (12.36-13.60) †19.49 (18.71-20.28) †19.52 (18.70-20.34) 15.47 (14.88-16.06) †20.01 (19.31-20.64) †20.06 (19.45-20.71) 20.43 (19.57-21.28) 20.04 (19.22-20.78) 20.08 (19.30-20.85) 19.05 (18.42-19.67) †22.02 (21.38-22.63) †22.06 (21.41-22.74) BEER 2.0 0.5086 0.5478 0.5482 0.5219 0.5494 0.5496 0.5"
W17-4737,E17-3017,0,0.122137,"Missing"
W17-4737,W16-2209,0,0.193296,"se the first word of each sentence. 5. Morphology-driven word splitting (Pinnis et al., 2017b). Tokens were split using a morphological analyser and further processed with byte pair encoding (BPE) (Sennrich et al., 2015) to ensure an open vocabulary. For both languages, we used morphological analysers that were developed by Deksne (2013) using finite state transducer technology. 1. Long sentence filtering (longer than 1500 symbols or 80 tokens). 2. Sentence length difference filter (sentence pairs with a length ratio smaller than 0.3 were filtered out). 6. Factorisation. Following the work of Sennrich and Haddow (2016), who showed that linguistic input features allow increasing NMT system translation quality, we developed our NMT systems using factored models. Therefore, the source data were further factored using a language-specific tag3. Incorrect language filtering using a language detection tool (Shuyo, 2010). 1 Tilde Data Library is a parallel and monolingual data repository of the Tilde MT platform (http://www.tilde.com/mt/). 375 Scenario Constrained Unconstrained Lang. pair en-lv lv-en en-lv lv-en Before filtering (Total / Unique) Parallel Monolingual 4.51M / 1.92M 38.13M / 28.81M 4.51M / 1.92M 369.8"
W18-1910,W17-4755,0,0.0139463,"h system was rather insignificant (only 0.15 BLEU points). This may be partially explained by the significantly smaller amount of in-domain monolingual data that were available for the creation of the synthetic parallel corpus. After training and adaptation, we performed automatic evaluation of all NMT systems (both baseline and adapted systems) using BLEU (Papineni et al., 2002), ChrF2 (Popovi´c, 2015), and CharacTER (Wang et al., 2016) (one standard and two newer evaluation metrics that show higher correlation scores to human judgements compared to BLEU for Slavic and Finno-Ugric languages (Bojar et al., 2017)). The results of the evaluation are given in Table 2. The table includes also evaluation results for Google Translate18 and the English-Estonian and Estonian-English CEF eTranslation systems. The evaluation was performed using two different evaluation sets: 1) the ACCURAT balanced evaluation set (Skadin¸a et al. (2012); a broad domain evaluation set), and 2) an evaluation set created from the parallel corpora of the Estonian EU Council Presidency website (covering also news on various events and topics concerning the Presidency). The results show that both 17 https://www.eu2017.ee/ 18 https:/"
W18-1910,N13-1073,0,0.0405056,"or URL address, various tag and alphanumeric code, etc.) identification, tokenization, and truecasing. • Following the methodology by Pinnis et al. (2017a), for the Bulgarian EU Presidency we trained NMT models that are more robust to unknown phenomena than vanilla NMT models. To do this, we supplemented the parallel corpus with a synthetic version of the same parallel corpus, which had content words replaced with unknown word tokens in a random manner. To make sure that the same words were replaced on both (source and target) sides, we performed word alignment of the corpus using fast-align (Dyer et al., 2013) and restricted the replacement to only those content words that had non-ambiguous (one-to-one) word alignments. • Once the data were pre-processed, NMT models were trained using the Nematus (Sennrich et al., 2017) toolkit. All NMT models were sub-word (Sennrich et al., 2015) level attention-based encoder-decoder models with multiplicative long short-term memory units (MLSTM; Krause et al. (2016)). For training, we used the MLSTM model implementation and the NMT training configuration defined by Pinnis et al. (2017b). More specifically, the NMT models were trained using a vocabulary of 25,000"
W18-1910,hajlaoui-etal-2014-dcep,0,0.0234155,"Missing"
W18-1910,2005.mtsummit-papers.11,0,0.0875981,"Missing"
W18-1910,P02-1040,0,0.100549,"em adaptation process, is depicted in Figure 3. The figure shows that domain adaptation did improve translation quality for the English-Estonian NMT system (by more than one BLEU point), however, the quality increase for the Estonian-English system was rather insignificant (only 0.15 BLEU points). This may be partially explained by the significantly smaller amount of in-domain monolingual data that were available for the creation of the synthetic parallel corpus. After training and adaptation, we performed automatic evaluation of all NMT systems (both baseline and adapted systems) using BLEU (Papineni et al., 2002), ChrF2 (Popovi´c, 2015), and CharacTER (Wang et al., 2016) (one standard and two newer evaluation metrics that show higher correlation scores to human judgements compared to BLEU for Slavic and Finno-Ugric languages (Bojar et al., 2017)). The results of the evaluation are given in Table 2. The table includes also evaluation results for Google Translate18 and the English-Estonian and Estonian-English CEF eTranslation systems. The evaluation was performed using two different evaluation sets: 1) the ACCURAT balanced evaluation set (Skadin¸a et al. (2012); a broad domain evaluation set), and 2) a"
W18-1910,W17-4737,1,0.822128,"Missing"
W18-1910,W15-3049,0,0.0298868,"Missing"
W18-1910,W17-0235,0,0.0226854,"Missing"
W18-1910,E17-3017,0,0.0503219,"Missing"
W18-1910,skadina-etal-2012-collecting,1,0.840607,"pted systems) using BLEU (Papineni et al., 2002), ChrF2 (Popovi´c, 2015), and CharacTER (Wang et al., 2016) (one standard and two newer evaluation metrics that show higher correlation scores to human judgements compared to BLEU for Slavic and Finno-Ugric languages (Bojar et al., 2017)). The results of the evaluation are given in Table 2. The table includes also evaluation results for Google Translate18 and the English-Estonian and Estonian-English CEF eTranslation systems. The evaluation was performed using two different evaluation sets: 1) the ACCURAT balanced evaluation set (Skadin¸a et al. (2012); a broad domain evaluation set), and 2) an evaluation set created from the parallel corpora of the Estonian EU Council Presidency website (covering also news on various events and topics concerning the Presidency). The results show that both 17 https://www.eu2017.ee/ 18 https://translate.google.com Proceedings of AMTA 2018, vol. 2: MT Users&apos; Track Boston, March 17 - 21, 2018 |Page 78 34.45 34.6 35 30 Beginning of domain adaptation BLEU 25 23.79 24.92 20 English-Estonian Estonian-English 15 Production models 10 5 0 0 500 1000 1500 2000 Weight updates (thousands) 2500 Figure 3: Training progres"
W18-1910,steinberger-etal-2012-dgt,0,0.0547725,"Missing"
W18-1910,P12-3008,0,0.0581299,"Missing"
W18-1910,W16-2342,0,0.0136526,"s that domain adaptation did improve translation quality for the English-Estonian NMT system (by more than one BLEU point), however, the quality increase for the Estonian-English system was rather insignificant (only 0.15 BLEU points). This may be partially explained by the significantly smaller amount of in-domain monolingual data that were available for the creation of the synthetic parallel corpus. After training and adaptation, we performed automatic evaluation of all NMT systems (both baseline and adapted systems) using BLEU (Papineni et al., 2002), ChrF2 (Popovi´c, 2015), and CharacTER (Wang et al., 2016) (one standard and two newer evaluation metrics that show higher correlation scores to human judgements compared to BLEU for Slavic and Finno-Ugric languages (Bojar et al., 2017)). The results of the evaluation are given in Table 2. The table includes also evaluation results for Google Translate18 and the English-Estonian and Estonian-English CEF eTranslation systems. The evaluation was performed using two different evaluation sets: 1) the ACCURAT balanced evaluation set (Skadin¸a et al. (2012); a broad domain evaluation set), and 2) an evaluation set created from the parallel corpora of the E"
W18-6423,aker-etal-2014-bilingual,1,0.845913,"MT 2017, isolated sentence pair filtering for the WMT 2018 submissions was supplemented with a maximum content overlap filter (i.e. only one target sentence for each source sentence was preserved and vice versa based on the content overlap filter’s score for each sentence pair). For filtering, we required probabilistic dictionaries, which were obtained from the parallel corpora (different dictionaries for the constrained and unconstrained scenarios) using fast align (Dyer et al., 2013). The dictionaries were filtered using the transliteration-based probabilistic dictionary filtering method by Aker et al. (2014). During filtering, we identified that one of the corpora that were provided by the organisers contained a significant amount of data corruption. It was the Estonian↔English ParaCrawl corpus3 . The corpus consisted of 1.30 million sentence pairs out of which 0.77 million were identified as being corrupt. To reduce the high level of noise, this corpus was filtered using stricter content overlap (a threshold of 0.3 instead of 0.1) and language adherence filters (both the language detection and the valid alphabet filters had to validate a sentence pair instead of just one of the filters) than all"
W18-6423,P07-2045,0,0.0257028,"eeded. 2 Tilde Data Library is an integral component of the Tilde MT platform that provides access to parallel and monolingual data for MT system development (http://www.tilde. com/mt/). 3 474 https://paracrawl.eu/download.html Workflow Full Light Scenario (C) (U) (C) Before filtering (Total / Unique) 2,178,025 / 1,932,954 75,215,347 / 24,660,087 2,178,025 After filtering (Unique) 968,232 18,755,230 998,679 Table 1: Training data statistics (sentence counts) before and after filtering Lang. pair • Then, the data are tokenised using the Tilde MT regular expression-based tokeniser. • The Moses (Koehn et al., 2007) truecasing script truecase.perl is used to truecase the first word of every sentence. Backtransl. sent. Full workflow en-et 0.97M (C) et-en 0.97M en-et 16.21M (U) et-en 18.39M Light workflow en-et 2.11M (C) et-en 2.05M • Then, tokens are split into sub-word units (Sennrich et al., 2015) using byte-pair encoding (BPE) (Gage, 1994). For the constrained and unconstrained systems, we use BPE models consisting of 24,500 and 49,500 merging operations respectively. Synth. <UNK> sent. Total 1.72M 1.79M 28.10M 30.77M 3.65M 3.73M 63.07M 67.91M 3.11M 3.04M Table 2: Synthetic data and final NMT model tra"
W18-6423,P18-1008,0,0.0637124,"Missing"
W18-6423,P14-5010,0,0.00390956,"ennrich et al., 2015) using byte-pair encoding (BPE) (Gage, 1994). For the constrained and unconstrained systems, we use BPE models consisting of 24,500 and 49,500 merging operations respectively. Synth. <UNK> sent. Total 1.72M 1.79M 28.10M 30.77M 3.65M 3.73M 63.07M 67.91M 3.11M 3.04M Table 2: Synthetic data and final NMT model training data statistics • Finally, data for the constrained systems are factored using an averaged perceptron-based morpho-syntactic tagger (Nikiforovs, 2014) for Estonian and the lexicalized probabilistic parser (Klein et al., 2002) from the Stanford CoreNLP toolkit (Manning et al., 2014) for English. Similarly to Sennrich and Haddow (2016), we introduce also a factor indicating a word part’s position in a word (beginning, middle, end, or the word part represents the whole word - B, I, E, or O). As a result, the Estonian data consist of the the following factors: word part, position, lemma, and morpho-syntactic tag. The English data consist of the following factors: word part, position, lemma, part-of-speech tag, and syntactic function. the parallel corpora and randomly replaced one to three unambiguously (one-to-one) aligned content words with unknown word identifiers. These"
W18-6423,P02-1040,0,0.102205,"els in an ensemble. NMT Systems In order to train the NMT systems, we used the Nematus (Sennrich et al., 2017b) (for MLSTM models) and Sockeye (Hieber et al., 2017) (for Transformer models) toolkits. All models were trained until convergence (i.e., until an early stopping criterion was met). 4.1 • For the tilde-nc-nmt (unconstrained NMT) systems, we performed model averaging of the best four models. • For the tilde-c-nmt-comb Estonian-English system, we performed majority voting (see Section 4.3) of translations produced by six different runs of different constrained systems (using best BLEU (Papineni et al., 2002) models, averaged models, ensembled averaged models, ensembled models, and larger beam search (10 instead of 5)). Full Workflow First, we trained constrained system baseline models using the filtered datasets. For baseline models, we used the MLSTM and transf configurations (see Table 3). Then, we used the best-performing models (based on translation quality on the vali476 Figure 1: NMT system training progress (BLEU scores on the validation set) for English-Estonian (left) and Estonian-English (right). Note that batch size may differ between different architectures and BLEU scores are calcula"
W18-6423,W18-6486,1,0.712809,"that were available in the Tilde Data Library2 . All parallel corpora were filtered (see Section 3.1.1), pre-processed (see Section 3.1.2), and supplemented with additional generated data (see Section 3.1.3). 3.1.2 Data Pre-processing All corpora were pre-processed using the parallel data pre-processing workflow from the Tilde MT platform (Pinnis et al., 2018) that performs the following pre-processing steps: 3.1.1 Data Filtering As NMT systems are sensitive to noise in parallel data (Pinnis et al., 2017a), all parallel data were filtered using the parallel data filtering methods described by Pinnis (2018). The parallel corpora filtering methods remove sentence pairs that have indications of data corruption or low parallelity (e.g., source-target length ratio, content overlap, digit mismatch, language adherence, etc.) issues. • First, parallel corpora are cleaned by removing HTML and XML tags, decoding escaped symbols, normalising whitespaces and punctuation marks, replacing control characters with spaces, etc. This step is performed only on the training data. • Then, non-translatable entities, such as email addresses, URLs, file paths, etc. are identified and replaced with place-holders. This"
W18-6423,W14-3348,0,0.0223134,"but it was also noticable in our Transformer model outputs. 4.3 System Combination We attempted to increase the quality of existing translations by employing a voting scheme in which multiple machine translation outputs are combined to produce a single translation. We used a custom implementation of the majority voting algorithm (Freitag et al., 2014) to combine six of our best-scoring outputs in the Estonian-English translation direction in the constrained scenario. We did not perform the combination for EnglishEstonian due to lack of support for alignment extraction for Estonian in Meteor (Denkowski and Lavie, 2014). MT system translation combination happens on the sentence level. The majority voting scheme assumes a single base translation hypothesis (primary hypothesis) which is aligned at the word level to each of the other hypotheses (secondary hypotheses). The alignments are used to generate a table of all possible word translations relative to each position in the primary hypothesis. The table is then used to count the number of occurrences of different translations. The word translations with 5 Results We performed automatic evaluation of the NMT systems using the SacreBLEU evaluation tool (Post,"
W18-6423,W18-1910,1,0.738066,"Missing"
W18-6423,N13-1073,0,0.659786,"ms, however, the data, taking into account their relatively large size, were not factored. Contrary to Tilde’s submissions for WMT 2017, isolated sentence pair filtering for the WMT 2018 submissions was supplemented with a maximum content overlap filter (i.e. only one target sentence for each source sentence was preserved and vice versa based on the content overlap filter’s score for each sentence pair). For filtering, we required probabilistic dictionaries, which were obtained from the parallel corpora (different dictionaries for the constrained and unconstrained scenarios) using fast align (Dyer et al., 2013). The dictionaries were filtered using the transliteration-based probabilistic dictionary filtering method by Aker et al. (2014). During filtering, we identified that one of the corpora that were provided by the organisers contained a significant amount of data corruption. It was the Estonian↔English ParaCrawl corpus3 . The corpus consisted of 1.30 million sentence pairs out of which 0.77 million were identified as being corrupt. To reduce the high level of noise, this corpus was filtered using stricter content overlap (a threshold of 0.3 instead of 0.1) and language adherence filters (both th"
W18-6423,H93-1040,0,0.694039,"Missing"
W18-6423,E14-2008,0,0.0295364,"rce sentence and the translation. Then named entity recognition (based on dictionary look-up) was performed on the source text and, if a named entity was found, the target translation was validated against the entries in the dic477 Figure 2: NMT system training progress (SacreBLEU scores on the validation set) for English-Estonian (left) and Estonian-English (right). the highest count at each position constitute the resulting combined hypothesis. To acquire the necessary word alignments we used Meteor. Meteor outputs were then converted to a more easily manageable form using the Jane toolkit (Freitag et al., 2014) (we used an awk script distributed with Jane). The majority voting algorithm was implemented in Python. consecutive repeating n-grams and repeating ngrams that have a preposition between them (i.e., victim of the victim) with a single n-gram. This problem was more apparent in RNN-based NMT systems, but it was also noticable in our Transformer model outputs. 4.3 System Combination We attempted to increase the quality of existing translations by employing a voting scheme in which multiple machine translation outputs are combined to produce a single translation. We used a custom implementation o"
W18-6423,E17-3017,0,0.0267947,"for splitting into subword units. The filters were applied to the given parallel sentences, monolingual news sentences before performing back-translation, and both sets of synthetic parallel sentences that resulted from backtranslating the monolingual news. 4 • For the tilde-c-nmt (constrained NMT) systems, we performed model averaging of the best four models (according to perplexity) of the three different run NMT systems and deployed the averaged models in an ensemble. NMT Systems In order to train the NMT systems, we used the Nematus (Sennrich et al., 2017b) (for MLSTM models) and Sockeye (Hieber et al., 2017) (for Transformer models) toolkits. All models were trained until convergence (i.e., until an early stopping criterion was met). 4.1 • For the tilde-nc-nmt (unconstrained NMT) systems, we performed model averaging of the best four models. • For the tilde-c-nmt-comb Estonian-English system, we performed majority voting (see Section 4.3) of translations produced by six different runs of different constrained systems (using best BLEU (Papineni et al., 2002) models, averaged models, ensembled averaged models, ensembled models, and larger beam search (10 instead of 5)). Full Workflow First, we trai"
W18-6423,W17-4737,1,0.807129,"Missing"
W18-6423,L18-1214,1,0.746635,"Missing"
W18-6423,W18-6319,0,0.0214249,"2014). MT system translation combination happens on the sentence level. The majority voting scheme assumes a single base translation hypothesis (primary hypothesis) which is aligned at the word level to each of the other hypotheses (secondary hypotheses). The alignments are used to generate a table of all possible word translations relative to each position in the primary hypothesis. The table is then used to count the number of occurrences of different translations. The word translations with 5 Results We performed automatic evaluation of the NMT systems using the SacreBLEU evaluation tool (Post, 2018). The results (see Table 4) show that the Transformer models achieved better results than the MLSTM-based models. For the constrained scenarios, both ensembles of averaged models achieved higher scores than each individual averaged model. It is also evident that the unconstrained models (tilde-nc-nmt) achieved the best results. Although the unconstrained models were not trained on factored data, the datasets were 17 times larger than the constrained datasets. However, the difference is rather minimal and shows that the current NMT architectures may not able to learn effectively from large data"
W18-6423,W17-4738,1,0.808412,"g only filtered parallel datasets (Parallel-only in Figure 2). Then, we back-translated the first batches of monolingual news data and trained intermediate NMT systems (Parallel + First Back-translated). Finally, we used the intermediate NMT systems to backtranslate the second batches of monolingual news data and trained final NMT systems (Parallel + Second Back-translated). The training progress in Figure 2 shows that the English-Estonian system benefits from the additional data, but the system in the other direction – not so much. For the final translations, we used a postprocessing script (Rikters et al., 2017) to replace When the NMT systems had translated a sentence, source-to-target word alignment was extracted from the source sentence and the translation. Then named entity recognition (based on dictionary look-up) was performed on the source text and, if a named entity was found, the target translation was validated against the entries in the dic477 Figure 2: NMT system training progress (SacreBLEU scores on the validation set) for English-Estonian (left) and Estonian-English (right). the highest count at each position constitute the resulting combined hypothesis. To acquire the necessary word a"
W18-6423,W17-4739,0,0.0576835,"ion (NMT) is a rapidly changing research area. Since 2016 when NMT systems first showed to achieve significantly better results than statistical machine translation (SMT) systems (Bojar et al., 2016), the dominant neural network (NN) architectures for NMT have changed on a yearly (and even more frequent) basis. The state-of-the-art in 2016 were shallow attention-based recurrent neural networks (RNN) with gated recurrent units (GRU) (Sennrich et al., 2016) in recurrent layers. In 2017 (Bojar et al., 2017), multiplicative long short-term memory (MLSTM) units (Pinnis et al., 2017c) and deep GRU (Sennrich et al., 2017a) models were introduced in NMT. The same year, selfattentional (Transformer) models were introduced (Vaswani et al., 2017). Consequently, in 2018, most of the top scoring systems in the shared task on news translation of the Third Conference on Machine Translation (WMT) were trained using Transformer models1 . However, it is already evident that the state-of-the-art architectures will 2 System Overview For the WMT 2018 shared task on news translation, Tilde submitted both constrained and unconstrained NMT systems (7 in total). The following is a list of the five MT systems submitted: • Const"
W18-6423,W16-2209,0,0.026178,"BPE) (Gage, 1994). For the constrained and unconstrained systems, we use BPE models consisting of 24,500 and 49,500 merging operations respectively. Synth. <UNK> sent. Total 1.72M 1.79M 28.10M 30.77M 3.65M 3.73M 63.07M 67.91M 3.11M 3.04M Table 2: Synthetic data and final NMT model training data statistics • Finally, data for the constrained systems are factored using an averaged perceptron-based morpho-syntactic tagger (Nikiforovs, 2014) for Estonian and the lexicalized probabilistic parser (Klein et al., 2002) from the Stanford CoreNLP toolkit (Manning et al., 2014) for English. Similarly to Sennrich and Haddow (2016), we introduce also a factor indicating a word part’s position in a word (beginning, middle, end, or the word part represents the whole word - B, I, E, or O). As a result, the Estonian data consist of the the following factors: word part, position, lemma, and morpho-syntactic tag. The English data consist of the following factors: word part, position, lemma, part-of-speech tag, and syntactic function. the parallel corpora and randomly replaced one to three unambiguously (one-to-one) aligned content words with unknown word identifiers. These synthetic corpora were added to the parallel corpora,"
W18-6423,W16-2323,0,0.0231324,"r English-Estonian and Estonian-English translation directions. The submitted systems were trained using Transformer models. 1 Introduction Neural machine translation (NMT) is a rapidly changing research area. Since 2016 when NMT systems first showed to achieve significantly better results than statistical machine translation (SMT) systems (Bojar et al., 2016), the dominant neural network (NN) architectures for NMT have changed on a yearly (and even more frequent) basis. The state-of-the-art in 2016 were shallow attention-based recurrent neural networks (RNN) with gated recurrent units (GRU) (Sennrich et al., 2016) in recurrent layers. In 2017 (Bojar et al., 2017), multiplicative long short-term memory (MLSTM) units (Pinnis et al., 2017c) and deep GRU (Sennrich et al., 2017a) models were introduced in NMT. The same year, selfattentional (Transformer) models were introduced (Vaswani et al., 2017). Consequently, in 2018, most of the top scoring systems in the shared task on news translation of the Third Conference on Machine Translation (WMT) were trained using Transformer models1 . However, it is already evident that the state-of-the-art architectures will 2 System Overview For the WMT 2018 shared task o"
W18-6486,D17-1319,0,0.0571758,"based probabilistic dictionary filtering method by Aker et al. (2014). Introduction Parallel data filtering for statistical machine translation (SMT) has shown to be a challenging task. Stricter filtering does not always yield positive results (Zarin¸a et al., 2015). This phenomenon can be explained with the higher robustness to noise of SMT systems, i.e., it does not harm the model if there are some incorrect translation candidates for a word or a phrase if the majority are still correct. However, there are also positive examples where data filtering allows improving SMT translation quality (Xu and Koehn, 2017). Neural machine translation (NMT), on the other hand, is much more sensitive to noise that is present in parallel data (Khayrallah and Koehn, 2018). From our own experience (as also shown by the experiments below), stricter filtering allows NMT models to show faster training tendencies and reach higher overall translation quality. In this paper, we describe Tilde’s methods for parallel data filtering for NMT system development and Tilde’s submissions to the WMT 2018 shared task on parallel data filtering. The paper is further structured as follows: Section 2 describes the data used in the fil"
W18-6486,aker-etal-2014-bilingual,1,0.886511,"deduplicated subset1 of the GermanEnglish ParaCrawl corpus2 . It consists of one billion words and 104,002,521 sentence pairs. For filtering, we require source-to-target and target-to-source probabilistic dictionaries. The dictionaries for the WMT 2018 experiments were acquired by 1) performing word alignment of the parallel corpora from the WMT 2018 shared task on news translation3 (excluding the filtered ParaCrawl corpus) using fast align (Dyer et al., 2013), and 2) performing raw probabilistic dictionary filtering using the transliteration-based probabilistic dictionary filtering method by Aker et al. (2014). Introduction Parallel data filtering for statistical machine translation (SMT) has shown to be a challenging task. Stricter filtering does not always yield positive results (Zarin¸a et al., 2015). This phenomenon can be explained with the higher robustness to noise of SMT systems, i.e., it does not harm the model if there are some incorrect translation candidates for a word or a phrase if the majority are still correct. However, there are also positive examples where data filtering allows improving SMT translation quality (Xu and Koehn, 2017). Neural machine translation (NMT), on the other h"
W18-6486,W15-4924,0,0.204376,"Missing"
W18-6486,N13-1073,0,0.0484542,"Data The parallel data filtering experiments were performed on a German-English corpus that was provided by the WMT 2018 organisers. The corpus was a raw deduplicated subset1 of the GermanEnglish ParaCrawl corpus2 . It consists of one billion words and 104,002,521 sentence pairs. For filtering, we require source-to-target and target-to-source probabilistic dictionaries. The dictionaries for the WMT 2018 experiments were acquired by 1) performing word alignment of the parallel corpora from the WMT 2018 shared task on news translation3 (excluding the filtered ParaCrawl corpus) using fast align (Dyer et al., 2013), and 2) performing raw probabilistic dictionary filtering using the transliteration-based probabilistic dictionary filtering method by Aker et al. (2014). Introduction Parallel data filtering for statistical machine translation (SMT) has shown to be a challenging task. Stricter filtering does not always yield positive results (Zarin¸a et al., 2015). This phenomenon can be explained with the higher robustness to noise of SMT systems, i.e., it does not harm the model if there are some incorrect translation candidates for a word or a phrase if the majority are still correct. However, there are a"
W18-6486,P18-4020,0,0.0821375,"Missing"
W18-6486,W18-2709,0,0.163185,"ion (SMT) has shown to be a challenging task. Stricter filtering does not always yield positive results (Zarin¸a et al., 2015). This phenomenon can be explained with the higher robustness to noise of SMT systems, i.e., it does not harm the model if there are some incorrect translation candidates for a word or a phrase if the majority are still correct. However, there are also positive examples where data filtering allows improving SMT translation quality (Xu and Koehn, 2017). Neural machine translation (NMT), on the other hand, is much more sensitive to noise that is present in parallel data (Khayrallah and Koehn, 2018). From our own experience (as also shown by the experiments below), stricter filtering allows NMT models to show faster training tendencies and reach higher overall translation quality. In this paper, we describe Tilde’s methods for parallel data filtering for NMT system development and Tilde’s submissions to the WMT 2018 shared task on parallel data filtering. The paper is further structured as follows: Section 2 describes the data used in the filtering experiments, Section 3 provides details on the filter3 Filtering Methods Although the filtering task required to score sentence pairs and not"
W18-6486,P02-1040,0,0.102744,"systems show rather poor performance, indicating the necessity of careful data cleaning. It is also evident that the Filtered and Max Filtered datasets contain too much noise among the highest scored sentence pairs. The reason for this is because the content overlap filter (by design) does not look at whether a sentence pair is a reciprocal translation. It tries to identify, just like a word alignment tool, which words in the source sentence correspond to which words in the target sentence, and non-translated words can be paired easily. 5 Results Automatic evaluation results in terms of BLEU (Papineni et al., 2002) scores are provided in Table 2. For all systems, we used the ‘test.sh’ script that was provided by the organisers in order to translate the test set and evaluate each model’s translation quality. The evaluation results illustrate the same dataset rankings as the training progress chart. The best results are achieved by using the Max Filtered+ dataset. We were also interested in seeing whether the filtering methods (by improving the parallel data quality) also allow improving out-of-vocabulary (OOV) word rates on the development set. It is evident in Table 2 that the OOV rate decreases by addi"
W18-6486,R13-1074,1,0.806204,"er - validates whether neither the source nor the target sentence contains words that contain question marks between letters (e.g., ‘flie?en’ instead of ‘fließen’, ‘gr??ere’ instead of ‘gr¨oßere‘, etc.). Such words indicate encoding corruption in data, therefore, sentences containing such words are deleted. 7. Stricter sentence length ratio filter - validates whether the longest sentence (in terms of characters is less than two times longer than the shortest sentence. 8. Low content overlap filter - validates whether the content overlap according to the cross-lingual alignment tool MPAligner (Pinnis, 2013) is over a threshold. Because the content overlap metric produced by 4. Digit mismatch filter - validates whether all digits that can be found in the source sentence 941 sentence pairs were separated into different lists according to sentence lengths and sorted according to the content overlap scores in a descending order. Then, sentences were ranked by assigning the highest score to the best-scored unigram sentence, the second highest score to the best-scored bigram sentence, etc. We performed such rescoring, because the filtering assigned higher scores to shorter segments, thereby skewing th"
W18-6486,L18-1214,1,0.729046,"Missing"
W19-2207,S12-1059,0,0.0703153,"Missing"
W19-2207,P05-1045,0,0.0134553,"Missing"
W19-2207,W17-4511,0,0.0172487,"ons, subsections, paragraphs, etc. cor59 of-words sentence representations, our approach tries to improve on this, by analysing the texts first. Searching the embedding space of all words used in the text, we cluster similar words so that morphological variants of a word like “tree” and “trees” or “eat” and “eating”, but also synonyms like “fast” and “rapid” are considered as belonging to the same cluster. Based on these groupings we encode all documents and then calculate the weights for the sentences using TF-IDF. The second tool is based on the concept of centroids (Rossiello et al., 2017; Ghalandari, 2017) and benefits from the composability of word embeddings. Initially, keywords and concepts are extracted from the document. By composing their embeddings, the centroid is created, which represents the document’s condensed meaningful information. It is then projected into the embedding space together with all sentence embeddings. Sentences receive relevance scores depending on their distance to the centroid in the embedding space. To avoid redundancy in the summary, sentences that are too similar to the ones already added to the summary are not used. Both tools can be used for multiple languages"
W19-2207,boella-etal-2012-nlp,0,0.319513,"Missing"
W19-2207,N16-1030,0,0.277206,"Missing"
W19-2207,W16-3503,1,0.729762,"specific relations such as activity requires permit or permit was issued on date. So far, such relations can be recognized in English language texts, but training for German, Spanish and Dutch, using the 3.13 Question Answering The Question Answering (QA) service accepts a natural language question and responds with an 61 of the containerised microservices we use OpenShift; alternative technologies such as, among others, Kubernetes, could also be used. In our project we conceptualise the specific requirements of the different use cases as content curation workflows (Schneider and Rehm, 2018b; Bourgonje et al., 2016a,b; Rehm et al., 2018). Workflows are defined as the execution of specific services to perform the processing of one or more documents under the umbrella of a certain task or use case. The specification of a workflow includes its input and output as well as the functionality it is supposed to perform: annotate or enrich a document, add a document to the knowledge base, search for information, etc. The project offers compliance-related features and functionalities through common services and data sets included in the LKG. Workflows make use of these services to implement the required functiona"
W19-2207,P18-2020,0,0.36431,"Missing"
W19-2207,P02-1040,0,0.103502,"l) which are available for English, German, Spanish and Dutch, among others. In order to compare documents in two different languages, machine translation between them, or to a third language must be available. The semantic similarity service is a prototype, requiring further testing and refining. ing background data curation processes. The synchronous translation service endpoint serves translation functionality for texts and documents annotated with the Natural Language Processing Interchange Format ontology (NIF) (Hellmann et al., 2013). The systems were automatically evaluated using BLEU (Papineni et al., 2002) on held-out evaluation sets. The sets were created from the indomain parts of the parallel corpora used for training of the NMT systems. Table 5 contains statistics of the training data and the automatic evaluation results of the NMT systems. 3.11 Semantic Similarity Legal Knowledge Graph Population For the definition of our Knowledge Graph, we benefit from predefined vocabularies such as EUROVOC. However, their knowledge is limited to that intended by their creators, and their level of specificity and focus will, in general, not match the ones required for an application. One possible option"
W19-2207,W17-1003,0,0.0146932,"cument to identify sections, subsections, paragraphs, etc. cor59 of-words sentence representations, our approach tries to improve on this, by analysing the texts first. Searching the embedding space of all words used in the text, we cluster similar words so that morphological variants of a word like “tree” and “trees” or “eat” and “eating”, but also synonyms like “fast” and “rapid” are considered as belonging to the same cluster. Based on these groupings we encode all documents and then calculate the weights for the sentences using TF-IDF. The second tool is based on the concept of centroids (Rossiello et al., 2017; Ghalandari, 2017) and benefits from the composability of word embeddings. Initially, keywords and concepts are extracted from the document. By composing their embeddings, the centroid is created, which represents the document’s condensed meaningful information. It is then projected into the embedding space together with all sentence embeddings. Sentences receive relevance scores depending on their distance to the centroid in the embedding space. To avoid redundancy in the summary, sentences that are too similar to the ones already added to the summary are not used. Both tools can be used for"
W19-2207,D14-1162,0,0.0819742,"on services (Allahyari et al., 2017). While extractive summarisation has been popular in the past, the progress in neural technologies has renewed the interest in abstractive summarisation, i. e., generating new sentences that capture a document’s meaning. This approach requires highly complex models and a lot of training data. In the absence of labeled training data, extractive methods are often used as the basis for abstractive methods, by assigning relevance scores to sentences in an unsupervised way. Abstractive summarisation is often augmented using word embeddings (Mikolov et al., 2013; Pennington et al., 2014) that provide a shared semantic space for those strongly related sentences that do no share the same but similar or related words. We develop two methods. The first tool is based on TF-IDF (Neto et al., 2000). This is a popular baseline as it is easy to implement, unsupervised, and language independent. Instead of using bag3.10 Machine Translation To enable multilingualism and cross-lingual extraction, linking and search, we use the Machine Translation (MT) service Tilde MT11 . In order to populate and process the Legal Knowledge Graph in a multilingual way, custom Neural Machine Translation ("
W19-2207,S10-1071,0,0.0609821,"Missing"
W19-2207,D17-1035,0,0.0234888,"Missing"
W19-5335,P18-4020,0,0.0479191,"Missing"
W19-5335,N13-1073,0,0.0394888,"ween systems trained on randomly selected data for back-translation and data selected using LMs (with sorted in the name) is given in Figure 6. In our submissions for WMT 2018, we introduced an automatic named entity (NE) postediting (ANEPE) workflow (Pinnis et al., 2018a), which allowed to fix translations of NEs (consisting of one word) and non-translatable words after NMT decoding. The method depends on the quality of word alignments. Because then we did not have methods to extract reliable word alignments from Transformer models, we had to rely on external word alignment using fast align (Dyer et al., 2013). This resulted in many misalignments and unalignments, and incorrect postedits. This year, we trained all models using the guided alignment method implemented in Marian (Junczys-Dowmunt et al., 2018). Although we still had to pre-process training data using fast align, the NMT models learned to produce more reliable word alignments. We also extended the ANEPE method to support multi-word NEs and non-translatable phrases. The method works as described further. Using collections of NEs and non-translatable phrases, we perform dictionary-based NE recognition in the source text. Then, for each re"
W19-5335,P02-1040,0,0.111672,"ing 60 either had alignment issues or the target words were too dissimilar from the entries in the NE collection. We applied ANEPE for all our submissions. 5 System English-Lithuanian (u) best 4 ens. (u) best 2 ens. (c) best 5 ens. (u) sa-∼qh-1-to-3 (u) sa-qh+-big-1-to-3 (c) best 3 ens. (c) sa-qh+-1-to-3.3 (c) sa-∼qh-1-to-1.7 (c) sa-∼qh-1-to-1 Lithuanian-English (u) best 5 ens. (c) best 5 ens. (u) so-beam∼qh-1-to-1 (u) so-sa-qh+-bigl035-1-to-2 (u) so-sa-qh-1-to-2 (c) so-sa-∼qh-1-to-3.2 (c) so-sa-qh-1-to-3.2 (c) sa-1-to-3.3 Results Automatic evaluation results of our final systems using BLEU4 (Papineni et al., 2002) are given in Table 2. To acquire final translations, we performed also ensembling of the best-performing individual models. For submission, we selected the best-performing models for both translation directions and both scenarios. However, it is evident that other models were able to translate the NewsTest 2019 evaluation set better (for 3 out of 4 submissions). Although this can be expected, when deciding, which systems to submit, we did not account for the change of the evaluation strategy, i.e., the fact that the evaluation set contained only texts originally written in the source language"
W19-5335,D18-1045,0,0.172905,"ware (with access to one or two graphical processing units) and with the goal of producing models suitable for production. In our experiments, we investigated methods for corpora filtering (the Tilde MT parallel data filtering (TMTF) and normalisation workflow (Pinnis, 2018) together with dual conditional cross-entropy filtering (DCCEF) (Junczys-Dowmunt, 2018)), training data pre-processing using the methods described by Pinnis et al. (2018a), a new optimisation method, the quasi-hyperbolic Adam, proposed by Ma and Yarats (2018), back-translation with sampling-based decoding (e.g., as done by Edunov et al. (2018)) and by targeting rare words (Fadaee and Monz, 2018) and in-domain subsets of the monolingual data, and automatic linguistically informed post-editing of named entities and non-translatable phrases. This year, Tilde participated in the shared task on news translation for the English↔Lithuanian language pair. We trained constrained and unconstrained systems for both translation directions. The paper is further structured as follows: Section 2 describes the data used for training, Section 3 describes the main NMT model training experiments, Section 4 describes our experiments on automatic post-"
W19-5335,W18-6486,1,0.893678,"the shared task on news translation of the 2019 Conference on Machine Translation was comprised of combining different methods that showed promising results in scientific publications published in 2018, and analysing whether the methods allowed increasing the overall quality of NMT systems when training NMT models using just modest hardware (with access to one or two graphical processing units) and with the goal of producing models suitable for production. In our experiments, we investigated methods for corpora filtering (the Tilde MT parallel data filtering (TMTF) and normalisation workflow (Pinnis, 2018) together with dual conditional cross-entropy filtering (DCCEF) (Junczys-Dowmunt, 2018)), training data pre-processing using the methods described by Pinnis et al. (2018a), a new optimisation method, the quasi-hyperbolic Adam, proposed by Ma and Yarats (2018), back-translation with sampling-based decoding (e.g., as done by Edunov et al. (2018)) and by targeting rare words (Fadaee and Monz, 2018) and in-domain subsets of the monolingual data, and automatic linguistically informed post-editing of named entities and non-translatable phrases. This year, Tilde participated in the shared task on new"
W19-5335,D18-1040,0,0.0991422,"g units) and with the goal of producing models suitable for production. In our experiments, we investigated methods for corpora filtering (the Tilde MT parallel data filtering (TMTF) and normalisation workflow (Pinnis, 2018) together with dual conditional cross-entropy filtering (DCCEF) (Junczys-Dowmunt, 2018)), training data pre-processing using the methods described by Pinnis et al. (2018a), a new optimisation method, the quasi-hyperbolic Adam, proposed by Ma and Yarats (2018), back-translation with sampling-based decoding (e.g., as done by Edunov et al. (2018)) and by targeting rare words (Fadaee and Monz, 2018) and in-domain subsets of the monolingual data, and automatic linguistically informed post-editing of named entities and non-translatable phrases. This year, Tilde participated in the shared task on news translation for the English↔Lithuanian language pair. We trained constrained and unconstrained systems for both translation directions. The paper is further structured as follows: Section 2 describes the data used for training, Section 3 describes the main NMT model training experiments, Section 4 describes our experiments on automatic post-editing of named entities, Section 5 summarises our a"
W19-5335,W17-4737,1,0.882486,"Missing"
W19-5335,W18-6478,0,0.18648,"ion was comprised of combining different methods that showed promising results in scientific publications published in 2018, and analysing whether the methods allowed increasing the overall quality of NMT systems when training NMT models using just modest hardware (with access to one or two graphical processing units) and with the goal of producing models suitable for production. In our experiments, we investigated methods for corpora filtering (the Tilde MT parallel data filtering (TMTF) and normalisation workflow (Pinnis, 2018) together with dual conditional cross-entropy filtering (DCCEF) (Junczys-Dowmunt, 2018)), training data pre-processing using the methods described by Pinnis et al. (2018a), a new optimisation method, the quasi-hyperbolic Adam, proposed by Ma and Yarats (2018), back-translation with sampling-based decoding (e.g., as done by Edunov et al. (2018)) and by targeting rare words (Fadaee and Monz, 2018) and in-domain subsets of the monolingual data, and automatic linguistically informed post-editing of named entities and non-translatable phrases. This year, Tilde participated in the shared task on news translation for the English↔Lithuanian language pair. We trained constrained and unco"
W19-5335,W18-6423,1,0.845855,"Missing"
W19-5335,L18-1214,1,0.900836,"Missing"
W19-5335,W18-6319,0,0.0585443,"Missing"
W19-5335,P16-1009,0,0.0955341,"Missing"
W19-5335,W16-2323,0,0.0210826,"ious year’s competition and combine them with recent advancements in the field. We also present a new method to ensure source domain adherence in back-translated data. Our systems achieved a shared first place in human evaluation. 1 Introduction Since the paradigm-shifting success of neural machine translation (NMT) systems at the 2016 Conference on Machine Translation (WMT) (Bojar et al., 2016), NMT methods and neural network architectures applied in NMT have been annually improved. In 2016, the best-performing systems were based on recurrent neural networks with gated recurrent units (GRU) (Sennrich et al., 2016; Bojar et al., 2016). In 2017, deep GRU models (Sennrich et al.) and models based on shallow multiplicative long short-term memory units (MLSTM; (Pinnis et al., 2017b)) allowed achieving the best results (Bojar et al., a). In 2018, the majority of best-performing systems were based on self-attentional (Vaswani et al., 2017) (Transformer) models (Bojar et al., b). A year has passed, and the majority of bestperforming systems submitted to the shared task on news translation of WMT 2019 are still based on Transformer networks. However, improvements are evident in other areas (e.g., usage of docu"
W19-6732,W05-0909,0,0.113502,"ted to the same amount as the initial training data, the backtranslated synthetic parallel corpora were added to the initial training data and final (domain-specific) systems were trained from scratch. For the remaining systems (English-Estonian and EnglishLithuanian), domain adaptation of the initial models was performed using continued training. 6 Evaluating iADAATPA’s MT Systems The evaluation of all iADAATPA’s MT systems was carried out following current MT assessment practices (see Castilho et al. (2018)) with a combination of automatic evaluation metrics (AEMs) – including BLEU, METEOR (Banerjee and Lavie, 2005), TER and chrF (Popovi´c, 2015) – and human evaluation, consisting of assessing fluency, adequacy and ranking against a baseline. The Adequacy rating was based on the statement “The translated sentence conveys the meaning of the original...”, which was to be completed with a 3point Likert scale (1-Poorly, 2-Fairly, 3-Well). The Fluency rating was based on the statement “The translated sentence is grammatically...”, which was to be completed with a 3-point Likert scale (1Incomprehensible, 2-Fair, 3-Flawless). The Ranking assessment was based on asking the translators to rate the translations fr"
W19-6732,W17-4712,0,0.0182245,"provided by the PA) and generic training data set. Engine customization The data was cleaned using the Bicleaner tool (S´anchez-Cartagena et al., 2018). Moreover, embeddings for case inforDublin, Aug. 19-23, 2019 |p. 180 Use-case Language pair Gazette Gazette R&D R&D Spanish→English Spanish→Basque English→Spanish Basque→Spanish # segments init train 0 34.2M 820k 820k 0 36.3M 0 4.6M Table 3: Data used to train Prompsit NMT systems mation and byte pair encoding tokenization were added. The models were trained with multidomain data and we improved performance following a domain-mixing approach (Britz et al., 2017). The domain information was indicated using special tokens for each target sequence. The domain prediction was based only on the source as the extra token was added at target-side and there was no need for a priori domain information. This approach allowed the model to improve the quality for each domain. 4 Prompsit Prompsit is a language technology (LT) provider with a strong focus on tailored MT services involving data curation, training and development of other multilingual applications. 4.1 Prompsit’s MT systems Language pairs and domains Prompsit partnered with SESIAD, the Spanish State"
W19-6732,W15-3049,0,0.0398645,"Missing"
W19-6732,P17-2061,0,0.0297506,"didates for new monolingual and bilingual dictionary entries from a word-aligned parallel corpus generated with ruLearn (S´anchezCartagena et al., 2016). For NMT systems, based on OpenNMT, automatic segmentation of long sentences and linguistically informed word segmentation for Basque (S´anchez-Cartagena, 2018) were added to the corpus pre-processing pipeline. Moreover, to ensure translation consistency, carefully designed terminology to restrict translation hypotheses and named entity recognition to control the translation of proper names, places, etc. was added. Finally, mixed fine-tuning (Chu et al., 2017) was applied to some systems to balance the weight of the different sources of training data. 5 Tilde Tilde is an LSP and LT developer offering customized MT system development, as well as a wide range of other cloud-based and stand-alone LT tools and services for terminology management, spelling and grammar checking, speech recognition and synthesis, personalised virtual assistants, and other applications. It provides onpremise and cloud-based LT solutions to public and private organisations as well as LT productivity tools to individual users. 5.1 Tilde’s MT systems Language pairs and domain"
W19-6732,W18-6488,1,0.890711,"Missing"
W19-6732,goldhahn-etal-2012-building,0,0.0372147,"Missing"
W19-6732,C14-1182,0,0.0531557,"Missing"
W19-6732,2005.mtsummit-papers.11,0,0.0191017,"ized: News and Events, President Office, School of Applied Languages and Intercultural Studies, and Fiontar – Irish Language Research. The language pairs consisted of English as the source for all the neural MT (NMT) engines into Bulgarian, Dutch, French, German, Irish, Italian, Polish, Portuguese, Romanian, and Spanish. 2.2 Data Acquisition The data used in the customization of KantanMT’s engines was selected from publicly available sources, such as the DGT (European Commission’s Directorate-General for Translation), EMEA (European Medicines Agency), ECB (European Central Bank) and EuroParl (Koehn, 2005).3 Table 1 shows the training data for KantanMT’s NMT systems. 2.3 Engine Customization All initial NMT engines were developed using the Torch implementation of the OpenNMT framework.4 The development test reference set, used to generate automated scores and to establish a performance baseline for each engine, consisted of 500 segments chosen at random from the live DCU website. Both recurrent and transformer neural models were trained. The model with the best overall automated scores was then selected as the final release candidate. (For the purposes of engine selection, F-Measure, TER (Snove"
W19-6732,P02-1040,0,0.123127,"aining data for KantanMT’s NMT systems. 2.3 Engine Customization All initial NMT engines were developed using the Torch implementation of the OpenNMT framework.4 The development test reference set, used to generate automated scores and to establish a performance baseline for each engine, consisted of 500 segments chosen at random from the live DCU website. Both recurrent and transformer neural models were trained. The model with the best overall automated scores was then selected as the final release candidate. (For the purposes of engine selection, F-Measure, TER (Snover et al., 2006), BLEU (Papineni et al., 2002), and Perplexity were used as automated scores.) 3 4 https://www.statmt.org/europarl/ http://www.opennmt.net/ Proceedings of MT Summit XVII, volume 2 Language pair Spanish→Catalan Spanish→English Spanish→French Spanish→German Spanish→Italian Spanish→Portuguese Spanish→Russian # segments init train 30k 13.6M 30k 14.6M 30k 14.6M 30k 14.5M 30k 14.5M 30k 14.6M 30k 13.8M Table 2: Data used to train Pangeanic NMT systems 3 Pangeanic Pangeanic (Yuste et al., 2010) is a Language Service Provider (LSP) specialised in Natural Language Processing and MT. It provides solutions to cognitive companies, inst"
W19-6732,W17-4737,1,0.889461,"Missing"
W19-6732,2006.amta-papers.25,0,0.17659,"2005).3 Table 1 shows the training data for KantanMT’s NMT systems. 2.3 Engine Customization All initial NMT engines were developed using the Torch implementation of the OpenNMT framework.4 The development test reference set, used to generate automated scores and to establish a performance baseline for each engine, consisted of 500 segments chosen at random from the live DCU website. Both recurrent and transformer neural models were trained. The model with the best overall automated scores was then selected as the final release candidate. (For the purposes of engine selection, F-Measure, TER (Snover et al., 2006), BLEU (Papineni et al., 2002), and Perplexity were used as automated scores.) 3 4 https://www.statmt.org/europarl/ http://www.opennmt.net/ Proceedings of MT Summit XVII, volume 2 Language pair Spanish→Catalan Spanish→English Spanish→French Spanish→German Spanish→Italian Spanish→Portuguese Spanish→Russian # segments init train 30k 13.6M 30k 14.6M 30k 14.6M 30k 14.5M 30k 14.5M 30k 14.6M 30k 13.8M Table 2: Data used to train Pangeanic NMT systems 3 Pangeanic Pangeanic (Yuste et al., 2010) is a Language Service Provider (LSP) specialised in Natural Language Processing and MT. It provides solution"
W19-6732,tiedemann-2012-parallel,0,0.0856107,"Missing"
W19-6732,2010.amta-commercial.4,0,0.0489296,"es was then selected as the final release candidate. (For the purposes of engine selection, F-Measure, TER (Snover et al., 2006), BLEU (Papineni et al., 2002), and Perplexity were used as automated scores.) 3 4 https://www.statmt.org/europarl/ http://www.opennmt.net/ Proceedings of MT Summit XVII, volume 2 Language pair Spanish→Catalan Spanish→English Spanish→French Spanish→German Spanish→Italian Spanish→Portuguese Spanish→Russian # segments init train 30k 13.6M 30k 14.6M 30k 14.6M 30k 14.5M 30k 14.5M 30k 14.6M 30k 13.8M Table 2: Data used to train Pangeanic NMT systems 3 Pangeanic Pangeanic (Yuste et al., 2010) is a Language Service Provider (LSP) specialised in Natural Language Processing and MT. It provides solutions to cognitive companies, institutions, translation professionals, and corporations. 3.1 Pangeanic’s MT systems Language pairs and domains Pangeanic’s usecases were for two Spanish PAs: (1) Generalitat Valenciana (regional administration) translating from Spanish into and out of English, French, Catalan/Valencian, German, Italian, Russian; and (2) Segittur (tourism administration) translating from Spanish into and out of English, French, German, Italian, Portuguese. For this purpose, NM"
