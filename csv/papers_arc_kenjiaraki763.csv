2020.gebnlp-1.5,Can Existing Methods Debias Languages Other than {E}nglish? First Attempt to Analyze and Mitigate {J}apanese Word Embeddings,2020,-1,-1,4,0,19261,masashi takeshita,Proceedings of the Second Workshop on Gender Bias in Natural Language Processing,0,"It is known that word embeddings exhibit biases inherited from the corpus, and those biases reflect social stereotypes. Recently, many studies have been conducted to analyze and mitigate biases in word embeddings. Unsupervised Bias Enumeration (UBE) (Swinger et al., 2019) is one of approach to analyze biases for English, and Hard Debias (Bolukbasi et al., 2016) is the common technique to mitigate gender bias. These methods focused on English, or, in smaller extent, on Indo-European languages. However, it is not clear whether these methods can be generalized to other languages. In this paper, we apply these analyzing and mitigating methods, UBE and Hard Debias, to Japanese word embeddings. Additionally, we examine whether these methods can be used for Japanese. We experimentally show that UBE and Hard Debias cannot be sufficiently adapted to Japanese embeddings."
N19-1186,Word Embedding-Based Automatic {MT} Evaluation Metric using Word Position Information,2019,0,0,2,0,26162,hiroshi echizenya,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"We propose a new automatic evaluation metric for machine translation. Our proposed metric is obtained by adjusting the Earth Mover{'}s Distance (EMD) to the evaluation task. The EMD measure is used to obtain the distance between two probability distributions consisting of some signatures having a feature and a weight. We use word embeddings, sentence-level tf-idf, and cosine similarity between two word embeddings, respectively, as the features, weight, and the distance between two features. Results show that our proposed metric can evaluate machine translation based on word meaning. Moreover, for distance, cosine similarity and word position information are used to address word-order differences. We designate this metric as Word Embedding-Based automatic MT evaluation using Word Position Information (WE{\_}WPI). A meta-evaluation using WMT16 metrics shared task set indicates that our WE{\_}WPI achieves the highest correlation with human judgment among several representative metrics."
L18-1569,Comparison of Pun Detection Methods Using {J}apanese Pun Corpus,2018,0,0,2,0,30125,motoki yatsu,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W16-5413,Automatic Evaluation of Commonsense Knowledge for Refining {J}apanese {C}oncept{N}et,2016,0,1,3,0,33487,seiya shudo,Proceedings of the 12th Workshop on {A}sian Language Resources ({ALR}12),0,"In this paper we present two methods for automatic common sense knowledge evaluation for Japanese entries in ConceptNet ontology. Our proposed methods utilize text-mining approach: one with relation clue words and WordNet synonyms, and one without. Both methods were tested with a blog corpus. The system based on our proposed methods reached relatively high precision score for three relations (MadeOf, UsedFor, AtLocation), which is comparable with previous research using commercial search engines and simpler input. We analyze errors and discuss problems of common sense evaluation, both manual and automatic and propose ideas for further improvements."
W14-3349,Application of Prize based on Sentence Length in Chunk-based Automatic Evaluation of Machine Translation,2014,11,2,2,0,26162,hiroshi echizenya,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"As described in this paper, we propose a new automatic evaluation metric for machine translation. Our metric is based on chunking between the reference and candidate translation. Moreover, we apply a prize based on sentence-length to the metric, dissimilar from penalties in BLEU or NIST. We designate this metric as Automatic Evaluation of Machine Translation in which the Prize is Applied to a Chunkbased metric (APAC). Through metaevaluation experiments and comparison with several metrics, we confirmed that our metric shows stable correlation with human judgment."
W14-2610,Emotive or Non-emotive: That is The Question,2014,14,2,4,1,21782,michal ptaszynski,"Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"In this research we focus on discriminating between emotive (emotionally loaded) and non-emotive sentences. We define the problem from a linguistic point of view assuming that emotive sentences stand out both lexically and grammatically. We verify this assumption experimentally by comparing two sets of such sentences in Japanese. The comparison is based on words, longer n-grams as well as more sophisticated patterns. In the classification weuse a novelunsupervised learning algorithm based on the idea of language combinatorics. The method reached results comparable to the state of the art, while the fact that it is fully automatic makes it more efficient and language independent."
R13-1030,Automatic Evaluation Metric for Machine Translation that is Independent of Sentence Length,2013,14,1,2,0,26162,hiroshi echizenya,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"We propose new automatic evaluation metric to evaluate machine translation. Different from most similar metrics, our proposed metric does not depend heavily on sentence length. In most metrics based on f-measure comparisons of reference and candidate translations, the relative weight of each mismatched word in short sentences is larger than it in long sentences. Therefore, the evaluation score becomes disproportionally low in short sentences even when only one non-matching word exists. In our metric, the weight of each mismatched word is kept small even in short sentences. We designate our metric as Automatic Evaluation Metric that is Independent of Sentence Length (AILE). Experimental results indicate that AILE has the highest correlation with human judgments among some leading metrics."
I13-1066,Detecting Cyberbullying Entries on Informal School Websites Based on Category Relevance Maximization,2013,1,13,6,0,41676,taisei nitta,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We propose a novel method to detect cyberbullying entries on the Internet. xe2x80x9cCyberbullyingxe2x80x9d is defined as humiliating and slandering behavior towards other people through Internet services, such as BBS, Twitter or e-mails. In Japan members of Parent-Teacher Association (PTA) perform manual Web site monitoring called xe2x80x9cnet-patrolxe2x80x9d to stop such activities. Unfortunately, reading through the whole Web manually is an uphill task. We propose a method of automatic detection of cyberbullying entries. In the proposed method we first use seed words from three categories to calculate semantic orientation score PMI-IR and then maximize the relevance of categories. In the experiment we checked the cases where the test data contains 50% (laboratory condition) and 12% (real world condition) of cyberbullying entries. In both cases the proposed method outperformed baseline settings."
W12-6102,Optimization for Efficient Determination of Chunk in Automatic Evaluation for Machine Translation,2012,0,2,2,1,26162,hiroshi echizenya,Proceedings of the First International Workshop on Optimization Techniques for Human Language Technology,0,None
W12-3714,Automatically Annotating A Five-Billion-Word Corpus of {J}apanese Blogs for Affect and Sentiment Analysis,2012,32,8,3,1,21782,michal ptaszynski,Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis,0,"This paper presents our research on automatic annotation of a five-billion-word corpus of Japanese blogs with information on affect and sentiment. We first perform a study in emotion blog corpora to discover that there has been no large scale emotion corpus available for the Japanese language. We choose the largest blog corpus for the language and annotate it with the use of two systems for affect analysis: ML-Ask for word- and sentence-level affect analysis and CAO for detailed analysis of emoticons. The annotated information includes affective features like sentence subjectivity (emotive/non-emotive) or emotion classes (joy, sadness, etc.), useful in affect analysis. The annotations are also generalized on a 2-dimensional model of affect to obtain information on sentence valence/polarity (positive/negative) useful in sentiment analysis. The annotations are evaluated in several ways. Firstly, on a test set of a thousand sentences extracted randomly and evaluated by over forty respondents. Secondly, the statistics of annotations are compared to other existing emotion blog corpora. Finally, the corpus is applied in several tasks, such as generation of emotion object ontology or retrieval of emotional and moral consequences of actions."
clark-araki-2012-two,Two Database Resources for Processing Social Media {E}nglish Text,2012,6,2,2,0,42922,eleanor clark,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This research focuses on text processing in the sphere of English-language social media. We introduce two database resources. The first, CECS (Casual English Conversion System) database, a lexicon-type resource of 1,255 entries, was constructed for use in our experimental system for the automated normalization of casual, irregularly-formed English used in communications such as Twitter. Our rule-based approach primarily aims to avoid problems caused by user creativity and individuality of language when Twitter-style text is used as input in Machine Translation, and to aid comprehension for non-native speakers of English. Although the database is still under development, we have so far carried out two evaluation experiments using our system which have shown positive results. The second database, CEGS (Casual English Generation System) phoneme database contains sets of alternative spellings for the phonemes in the CMU Pronouncing Dictionary, designed for use in a system for generating phoneme-based casual English text from regular English input; in other words, automatically producing humanlike creative sentences as an AI task. This paper provides an overview of the necessity, method, application and evaluation of both resources."
P10-1012,Automatic Evaluation Method for Machine Translation Using Noun-Phrase Chunking,2010,10,12,2,1,26162,hiroshi echizenya,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"As described in this paper, we propose a new automatic evaluation method for machine translation using noun-phrase chunking. Our method correctly determines the matching words between two sentences using corresponding noun phrases. Moreover, our method determines the similarity between two sentences in terms of the noun-phrase order of appearance. Evaluation experiments were conducted to calculate the correlation among human judgments, along with the scores produced using automatic evaluation methods for MT outputs obtained from the 12 machine translation systems in NTCIR-7. Experimental results show that our method obtained the highest correlations among the methods in both sentence-level adequacy and fluency."
N09-2017,Evaluation of a System for Noun Concepts Acquisition from Utterances about Images ({SINCA}) Using Daily Conversation Data,2009,8,1,2,0,17153,yuzu uchida,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"For a robot working in an open environment, a task-oriented language capability will not be sufficient. In order to adapt to the environment, such a robot will have to learn language dynamically. We developed a System for Noun Concepts Acquisition from utterances about Images, SINCA in short. It is a language acquisition system without knowledge of grammar and vocabulary, which learns noun concepts from user utterances. We recorded a video of a child's daily life to collect dialogue data that was spoken to and around him. The child is a member of a family consisting of the parents and his sister. We evaluated the performance of SINCA using the collected data. In this paper, we describe the algorithms of SINCA and an evaluation experiment. We work on Japanese language acquisition, however our method can easily be adapted to other languages."
sjobergh-araki-2008-multi,A Multi-Lingual Dictionary of Dirty Words,2008,5,5,2,1,48505,jonas sjobergh,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We present a multi-lingual dictionary of dirty words. We have collected about 3,200 dirty words in several languages and built a database of these. The language with the most words in the database is English, though there are several hundred dirty words in for instance Japanese too. Words are classified into their general meaning, such as what part of the human anatomy they refer to. Words can also be assigned a nuance label to indicate if it is a cute word used when speaking to children, a very rude word, a clinical word etc. The database is available online and will hopefully be enlarged over time. It has already been used in research on for instance automatic joke generation and emotion detection."
sjobergh-araki-2008-poorly,What is poorly Said is a Little Funny,2008,11,1,2,1,48505,jonas sjobergh,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We implement several different methods for generating jokes in English. The common theme is to intentionally produce poor utterances by breaking GriceÂs maxims of conversation. The generated jokes are evaluated and compared to human made jokes. They are in general quite weak jokes, though there are a few high scoring jokes and many jokes that score higher than the most boring human joke."
D08-1040,A Casual Conversation System Using Modality and Word Associations Retrieved from the Web,2008,9,43,3,0,48692,shinsuke higuchi,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"In this paper we present a textual dialogue system that uses word associations retrieved from the Web to create propositions. We also show experiment results for the role of modality generation. The proposed system automatically extracts sets of words related to a conversation topic set freely by a user. After the extraction process, it generates an utterance, adds a modality and verifies the semantic reliability of the proposed sentence. We evaluate word associations extracted form the Web, and the results of adding modality. Over 80% of the extracted word associations were evaluated as correct. Adding modality improved the system significantly for all evaluation criteria. We also show how our system can be used as a simple and expandable platform for almost any kind of experiment with human-computer textual conversation in Japanese. Two examples with affect analysis and humor generation are given."
C08-2028,A Complete and Modestly Funny System for Generating and Performing {J}apanese Stand-Up Comedy,2008,2,8,2,1,48505,jonas sjobergh,Coling 2008: Companion volume: Posters,0,"We present a complete system that generates Japanese stand-up comedy. Different modules generating different types of jokes are tied together into a performance where all jokes are connected in some way to the other jokes. The script is converted to speech and two robots perform the comedy routine. Evaluations show that the performances are perceived as funny by many, almost half the evaluation scores for the total impression were 4 or 5 (top score)."
W07-2463,Recreating Humorous Split Compound Errors in {S}wedish by Using Grammaticality,2007,-1,-1,2,1,48505,jonas sjobergh,Proceedings of the 16th Nordic Conference of Computational Linguistics ({NODALIDA} 2007),0,None
W07-0209,Semi-supervised Algorithm for Human-Computer Dialogue Mining,2007,6,0,2,1,44060,calkin montero,Proceedings of the Second Workshop on {T}ext{G}raphs: Graph-Based Algorithms for Natural Language Processing,0,"This paper describes the analysis of weak local coherence utterances during humancomputer conversation through the application of an emergent data mining technique, data crystallization. Results reveal that by adding utterances with weak local relevance the performance of a baseline conversational partner, in terms of user satisfaction, showed betterment."
N07-4010,{OMS}-{J}: An Opinion Mining System for {J}apanese Weblog Reviews Using a Combination of Supervised and Unsupervised Approaches,2007,3,5,2,0,49285,guangwei wang,Proceedings of Human Language Technologies: The Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics ({NAACL}-{HLT}),0,We introduce a simple opinion mining system for analyzing Japanese Weblog reviews called OMS-J. OMS-J is designed to provide an intuitive visual GUI of opinion mining graphs for a comparison of different products of the same type to help a user make a quick purchase decision. We first use an opinion mining method using a combination of supervised (a Naive Bayes Classifier) and unsupervised (an improved SO-PMI: Semantic Orientation Using Pointwise Mutual Information) learning.
N07-2048,Modifying {SO}-{PMI} for {J}apanese Weblog Opinion Mining by Using a Balancing Factor and Detecting Neutral Expressions,2007,5,25,2,0,49285,guangwei wang,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,"We propose a variation of the SO-PMI algorithm for Japanese, for use in Weblog Opinion Mining. SO-PMI is an unsupervised approach proposed by Turney that has been shown to work well for English. We first used the SO-PMI algorithm on Japanese in a way very similar to Turney's original idea. The result of this trial leaned heavily toward positive opinions. We then expanded the reference words to be sets of words, tried to introduce a balancing factor and to detect neutral expressions. After these modifications, we achieved a well-balanced result: both positive and negative accuracy exceeded 70%. This shows that our proposed approach not only adapted the SO-PMI for Japanese, but also modified it to analyze Japanese opinions more effectively."
2007.sigdial-1.22,Analysis of User Reactions to Turn-Taking Failures in Spoken Dialogue Systems,2007,6,10,5,0,14948,mikio nakano,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"This paper presents the results of an analysis of user reactions towards system failures in turn-taking in human-computer dialogues. When a system utterance and a user utterance start with a small time difference, the user may stop his/her utterance. In addition, when the user utterance ends soon after the overlap starts, the possibility of the utterance being discontinued is high. Based on this analysis, it is suggested that the degradation in speech recognition performance can be predicted using utterance overlapping information."
2007.mtsummit-papers.21,Automatic evaluation of machine translation based on recursive acquisition of an intuitive common parts continuum,2007,-1,-1,2,0.857143,26162,hiroshi echizenya,Proceedings of Machine Translation Summit XI: Papers,0,None
P06-4002,Is It Correct? {--} Towards Web-Based Evaluation of Automatic Natural Language Phrase Generation,2006,15,4,2,1,44060,calkin montero,Proceedings of the {COLING}/{ACL} 2006 Interactive Presentation Sessions,0,This paper describes a novel approach for the automatic generation and evaluation of a trivial dialogue phrases database. A trivial dialogue phrase is defined as an expression used by a chatbot program as the answer of a user input. A transfer-like genetic algorithm (GA) method is used to generating the trivial dialogue phrases for the creation of a natural language generation (NLG) knowledge base. The automatic evaluation of a generated phrase is performed by producing n-grams and retrieving their frequencies from the World Wide Web (WWW). Preliminary experiments show very positive results.
W05-1010,Automatic Acquisition of Bilingual Rules for Extraction of Bilingual Word Pairs from Parallel Corpora,2005,16,1,2,0.666667,26162,hiroshi echizenya,Proceedings of the {ACL}-{SIGLEX} Workshop on Deep Lexical Acquisition,0,"In this paper, we propose a new learning method to solve the sparse data problem in automatic extraction of bilingual word pairs from parallel corpora with various languages. Our learning method automatically acquires rules, which are effective to solve the sparse data problem, only from parallel corpora without any bilingual resource (e.g., a bilingual dictionary, machine translation systems) beforehand. We call this method Inductive Chain Learning (ICL). The ICL can limit the search scope for the decision of equivalents. Using ICL, the recall in three systems based on similarity measures improved respectively 8.0, 6.1 and 6.0 percentage points. In addition, the recall value of GIZA improved 6.6 percentage points using ICL."
I05-2018,Detecting the Countability of {E}nglish Compound Nouns Using Web-based Models,2005,7,4,2,0,24725,jing peng,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"In this paper, we proposed an approach for detecting the countability of English compound nouns treating the web as a large corpus of words. We classified compound nouns into three classes: countable, uncountable, plural only. Our detecting algorithm is based on simple, viable n-gram models, whose parameters can be obtained using the WWW search engine Google. The detecting thresholds are optimized on the small training set. Finally we experimentally showed that our algorithm based on these simple models could perform the promising results with a precision of 89.2% on the total test set."
2003.mtsummit-papers.14,Effectiveness of automatic extraction of bilingual collocations using recursive chain-link-type learning,2003,0,2,2,0.8,26162,hiroshi echizenya,Proceedings of Machine Translation Summit IX: Papers,0,None
W02-1812,A Word Segmentation Method with Dynamic Adapting to Text Using Inductive Learning,2002,3,8,2,0,53155,zhongjian wang,{COLING}-02: The First {SIGHAN} Workshop on {C}hinese Language Processing,0,"We have proposed a method of word segmentation for non-segmented language using Inductive Learning. This method uses only surface information of a text, so that it has an advantage that is entirely not dependent on any specific language. In this method, we consider that a character string of appearing frequently in a text has a high possibility as a word. The method predicts unknown words by recursively extracting common character strings. With the proposed method, the segmentation results can adapt to different users and fields. To evaluate effectivety for Chinese word segmentation and adaptability for different fields, we have done the evaluation experiment with Chinese text of the two fields."
W02-0707,Evaluation of Direct Speech Translation Method Using Inductive Learning for Conversations in the Travel Domain,2002,6,1,3,0,15888,koji murakami,Proceedings of the {ACL}-02 Workshop on Speech-to-Speech Translation: Algorithms and Systems,0,"This paper evaluates a direct speech translation Method with waveforms using the Inductive Learning method for short conversation. The method is able to work without conventional speech recognition and speech synthesis because syntactic expressions are not needed for translation in the proposed method. We focus only on acoustic characteristics of speech waveforms of source and target languages without obtaining character strings from utterances. This speech translation method can be utilized for any language because the system has no processing dependent on an individual character of a specific language. Therefore, we can utilize the speech of a handicapped person who is not able to be treated by conventional speech recognition systems, because we do not need to segment the speech into phonemes, syllables, or words to realize speech translation. Our method is realized by learning translation rules that have acoustic correspondence between two languages inductively. In this paper, we deal with a translation between Japanese and English."
C02-1158,Study of Practical Effectiveness for Machine Translation Using Recursive Chain-link-type Learning,2002,14,8,2,0.5,26162,hiroshi echizenya,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"A number of machine translation systems based on the learning algorithms are presented. These methods acquire translation rules from pairs of similar sentences in a bilingual text corpora. This means that it is difficult for the systems to acquire the translation rules from sparse data. As a result, these methods require large amounts of training data in order to acquire high-quality translation rules. To overcome this problem, we propose a method of machine translation using a Recursive Chain-link-type Learning. In our new method, the system can acquire many new high-quality translation rules from sparse translation examples based on already acquired translation rules. Therefore, acquisition of new translation rules results in the generation of more new translation rules. Such a process of acquisition of translation rules is like a linked chain. From the results of evaluation experiments, we confirmed the effectiveness of Recursive Chain-link-type Learning."
2000.bcs-1.5,Effectiveness of layering translation rules based on transition networks in machine translation using inductive learning with genetic algorithms,2000,-1,-1,2,0.666667,26162,hiroshi echizenya,Proceedings of the International Conference on Machine Translation and Multilingual Applications in the new Millennium: MT 2000,0,None
Y99-1030,Sub-Sentential Alignment Method by Analogy,1999,4,4,2,0,54828,tantely andriamanankasina,"Proceedings of the 13th Pacific Asia Conference on Language, Information and Computation",0,"This paper describes a method for searching word correspondences between pairs of translation sentences. In the Example-Based Machine Translation, translation patterns can be extracted easily if word correspondences between pair of translation sentences are defined. The popular methods for aligning bilingual corpus at a sub-sentential level are unable to produce reliable result when the size of the corpus is limited, because they are based on statistics. We propose a method for incrementing a word correspondence-included initial corpus automatically. It is appropriate for new languages whose huge corpus as well as machine readable dictionaries are still not available. The method was evaluated with French-Japanese spoken language texts. As the number of translation examples goes beyond 1,000, more than 80.0% of correct word correspondence rates were earned."
Y99-1031,A Study of Performance Evaluation for {GA}-{ILMT} Using Travel {E}nglish,1999,6,3,2,0,26162,hiroshi echizenya,"Proceedings of the 13th Pacific Asia Conference on Language, Information and Computation",0,"Recently, many machine translation systems have been developed. However, for translation of conversation, correct translation rates and quality of translation are particularly low. This is due to machine translation systems not being able to generate translation results which fit the context of the conversation . We previously proposed a method of Machine Translation Using Inductive Learning with Genetic Algorithms(GA-ILMT). We compare this system's results to two others that use rule-based translation method, and evaluate the results of experiments done with GA-ILMT, measuring it's performance when applied to travel English. As a result of the evaluation experiments, we confirmed that GA-ILMT can generate translation results which are more appropriate to the context of the conversation."
1999.mtsummit-1.75,Example-based machine translation of part-of-speech tagged sentences by recursive division,1999,8,8,2,0,54828,tantely andriamanankasina,Proceedings of Machine Translation Summit VII,0,"Example-Based Machine Translation can be applied to languages whose resources like dictionaries, reliable syntactic analyzers are hardly available because it can learn from new translation examples. However, difficulties still remain in translation of sentences which are not fully covered by the matching sentence. To solve that problem, we present in this paper a translation method which recursively divides a sentence and translates each part separately. In addition, we evaluate an analogy-based word-level alignment method which predicts word correspondences between source and translation sentences of new translation examples. The translation method was implemented in a French-Japanese machine translation system and spoken language text were used as examples. Promising translation results were earned and the effectiveness of the alignment method in the translation was confirmed."
A97-2006,An Improvement in the Selection Process of Machine Translation Using Inductive Learning with Genetic Algorithms,1997,3,0,2,0,26162,hiroshi echizenya,Fifth Conference on Applied Natural Language Processing: Descriptions of System Demonstrations and Videos,0,"We proposed a method of machine translation using inductive learning with genetic algorithms, and confirmed the effectiveness of applying genetic algorithms. However, the system based on this method produces many erroneous translation rules that cannot be completely removed from the dictionary. Therefore, we need to improve how to apply genetic algorithms to be able to remove erroneous translation rules from the dictionary. In this paper, we describe this improvement in the selection process and the results of evaluation experiments."
C96-2178,Machine Translation Method Using Inductive Learning with Genetic Algorithms,1996,7,13,2,0,26162,hiroshi echizenya,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"We have proposed a method of machine translation, which acquires translation rules from translation examples using inductive learning, and have evaluated the method. And we have confirmed that the method requires many translation examples. To resolve this problem, we applied genetic algorithms and evaluated it by some experiments. We confirmed that the accuracy rate of translation increased from 52.8% to 61.9% by applying genetic algorithms."
