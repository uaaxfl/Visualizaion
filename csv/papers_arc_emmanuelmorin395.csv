2020.lrec-1.556,Where are we in Named Entity Recognition from Speech?,2020,0,0,5,1,17778,antoine caubriere,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Named entity recognition (NER) from speech is usually made through a pipeline process that consists in (i) processing audio using an automatic speech recognition system (ASR) and (ii) applying a NER to the ASR outputs. The latest data available for named entity extraction from speech in French were produced during the ETAPE evaluation campaign in 2012. Since the publication of ETAPE{'}s campaign results, major improvements were done on NER and ASR systems, especially with the development of neural approaches for both of these components. In addition, recent studies have shown the capability of End-to-End (E2E) approach for NER / SLU tasks. In this paper, we propose a study of the improvements made in speech recognition and named entity recognition for pipeline approaches. For this type of systems, we propose an original 3-pass approach. We also explore the capability of an E2E system to do structured NER. Finally, we compare the performances of ETAPE{'}s systems (state-of-the-art systems in 2012) with the performances obtained using current technologies. The results show the interest of the E2E approach, which however remains below an updated pipeline approach."
2020.jeptalnrecital-jep.8,O{\\`u} en sommes-nous dans la reconnaissance des entit{\\'e}s nomm{\\'e}es structur{\\'e}es {\\`a} partir de la parole ? (Where are we in Named Entity Recognition from speech ?),2020,-1,-1,5,1,17778,antoine caubriere,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 1 : Journ{\\'e}es d'{\\'E}tudes sur la Parole",0,"La reconnaissance des entit{\'e}s nomm{\'e}es (REN) {\`a} partir de la parole est traditionnellement effectu{\'e}e par l{'}interm{\'e}diaire d{'}une cha{\^\i}ne de composants, exploitant un syst{\`e}me de reconnaissance de la parole (RAP), puis un syst{\`e}me de REN appliqu{\'e} sur les transcriptions automatiques. Les derni{\`e}res donn{\'e}es disponibles pour la REN structur{\'e}es {\`a} partir de la parole en fran{\c{c}}ais proviennent de la campagne d{'}{\'e}valuation ETAPE en 2012. Depuis la publication des r{\'e}sultats, des am{\'e}liorations majeures ont {\'e}t{\'e} r{\'e}alis{\'e}es pour les syst{\`e}mes de REN et de RAP. Notamment avec le d{\'e}veloppement des syst{\`e}mes neuronaux. De plus, certains travaux montrent l{'}int{\'e}r{\^e}t des approches de bout en bout pour la t{\^a}che de REN dans la parole. Nous proposons une {\'e}tude des am{\'e}liorations en RAP et REN dans le cadre d{'}une cha{\^\i}ne de composants, ainsi qu{'}une nouvelle approche en trois {\'e}tapes. Nous explorons aussi les capacit{\'e}s d{'}une approche bout en bout pour la REN structur{\'e}es. Enfin, nous comparons ces deux types d{'}approches {\`a} l{'}{\'e}tat de l{'}art de la campagne ETAPE. Nos r{\'e}sultats montrent l{'}int{\'e}r{\^e}t de l{'}approche bout en bout, qui reste toutefois en de{\c{c}}{\`a} d{'}une cha{\^\i}ne de composants enti{\`e}rement mise {\`a} jour."
2020.coling-main.527,Data Selection for Bilingual Lexicon Induction from Specialized Comparable Corpora,2020,-1,-1,3,0,21642,martin laville,Proceedings of the 28th International Conference on Computational Linguistics,0,"Narrow specialized comparable corpora are often small in size. This particularity makes it difficult to build efficient models to acquire translation equivalents, especially for less frequent and rare words. One way to overcome this issue is to enrich the specialized corpora with out-of-domain resources. Although some recent studies have shown improvements using data augmentation, the enrichment method was roughly conducted by adding out-of-domain data with no particular attention given to how to enrich words and how to do it optimally. In this paper, we contrast several data selection techniques to improve bilingual lexicon induction from specialized comparable corpora. We first apply two well-established data selection techniques often used in machine translation that is: Tf-Idf and cross entropy. Then, we propose to exploit BERT for data selection. Overall, all the proposed techniques improve the quality of the extracted bilingual lexicons by a large margin. The best performing model is the cross entropy, obtaining a gain of about 4 points in MAP while decreasing computation time by a factor of 10."
2020.bucc-1.9,{TALN}/{LS}2{N} Participation at the {BUCC} Shared Task: Bilingual Dictionary Induction from Comparable Corpora,2020,-1,-1,3,0,21642,martin laville,Proceedings of the 13th Workshop on Building and Using Comparable Corpora,0,"This paper describes the TALN/LS2N system participation at the Building and Using Comparable Corpora (BUCC) shared task. We first introduce three strategies: (i) a word embedding approach based on fastText embeddings; (ii) a concatenation approach using both character Skip-Gram and character CBOW models, and finally (iii) a cognates matching approach based on an exact match string similarity. Then, we present the applied strategy for the shared task which consists in the combination of the embeddings concatenation and the cognates matching approaches. The covered languages are French, English, German, Russian and Spanish. Overall, our system mixing embeddings concatenation and perfect cognates matching obtained the best results while compared to individual strategies, except for English-Russian and Russian-English language pairs for which the concatenation approach was preferred."
2019.jeptalnrecital-long.6,Curriculum d{'}apprentissage : reconnaissance d{'}entit{\\'e}s nomm{\\'e}es pour l{'}extraction de concepts s{\\'e}mantiques (Curriculum learning : named entity recognition for semantic concept extraction),2019,-1,-1,5,1,17778,antoine caubriere,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume I : Articles longs,0,"Dans cet article, nous pr{\'e}sentons une approche de bout en bout d{'}extraction de concepts s{\'e}mantiques de la parole. En particulier, nous mettons en avant l{'}apport d{'}une cha{\^\i}ne d{'}apprentissage successif pilot{\'e}e par une strat{\'e}gie de curriculum d{'}apprentissage. Dans la cha{\^\i}ne d{'}apprentissage mise en place, nous exploitons des donn{\'e}es fran{\c{c}}aises annot{\'e}es en entit{\'e}s nomm{\'e}es que nous supposons {\^e}tre des concepts plus g{\'e}n{\'e}riques que les concepts s{\'e}mantiques li{\'e}s {\`a} une application informatique sp{\'e}cifique. Dans cette {\'e}tude, il s{'}agit d{'}extraire des concepts s{\'e}mantiques dans le cadre de la t{\^a}che MEDIA. Pour renforcer le syst{\`e}me propos{\'e}, nous exploitons aussi des strat{\'e}gies d{'}augmentation de donn{\'e}es, un mod{\`e}le de langage 5-gramme, ainsi qu{'}un mode {\'e}toile aidant le syst{\`e}me {\`a} se concentrer sur les concepts et leurs valeurs lors de l{'}apprentissage. Les r{\'e}sultats montrent un int{\'e}r{\^e}t {\`a} l{'}utilisation des donn{\'e}es d{'}entit{\'e}s nomm{\'e}es, permettant un gain relatif allant jusqu{'}{\`a} 6,5 {\%}."
L18-1069,Crowdsourcing-based Annotation of the Accounting Registers of the {I}talian Comedy,2018,0,1,5,0,29572,adeline granet,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-1080,Leveraging Meta-Embeddings for Bilingual Lexicon Extraction from Specialized Comparable Corpora,2018,0,1,2,0.86522,16811,amir hazem,Proceedings of the 27th International Conference on Computational Linguistics,0,"Recent evaluations on bilingual lexicon extraction from specialized comparable corpora have shown contrasted performance while using word embedding models. This can be partially explained by the lack of large specialized comparable corpora to build efficient representations. Within this context, we try to answer the following questions: First, (i) among the state-of-the-art embedding models, whether trained on specialized corpora or pre-trained on large general data sets, which one is the most appropriate model for bilingual terminology extraction? Second (ii) is it worth it to combine multiple embeddings trained on different data sets? For that purpose, we propose the first systematic evaluation of different word embedding models for bilingual terminology extraction from specialized comparable corpora. We emphasize how the character-based embedding model outperforms other models on the quality of the extracted bilingual lexicons. Further more, we propose a new efficient way to combine different embedding models learned from specialized and general-domain data sets. Our approach leads to higher performance than the best individual embedding model."
C18-1125,Transfer Learning for a Letter-Ngrams to Word Decoder in the Context of Historical Handwriting Recognition with Scarce Resources,2018,0,1,2,0,29572,adeline granet,Proceedings of the 27th International Conference on Computational Linguistics,0,"Lack of data can be an issue when beginning a new study on historical handwritten documents. In order to deal with this, we present the character-based decoder part of a multilingual approach based on transductive transfer learning for a historical handwriting recognition task on Italian Comedy Registers. The decoder must build a sequence of characters that corresponds to a word from a vector of letter-ngrams. As learning data, we created a new dataset from untapped resources that covers the same domain and period of our Italian Comedy data, as well as resources from common domains, periods, or languages. We obtain a 97.42{\%} Character Recognition Rate and a 86.57{\%} Word Recognition Rate on our Italian Comedy data, despite a lexical coverage of 67{\%} between the Italian Comedy data and the training data. These results show that an efficient system can be obtained by a carefully selecting the datasets used for the transfer learning."
C18-1242,Towards a unified framework for bilingual terminology extraction of single-word and multi-word terms,2018,0,2,2,0,7806,jingshu liu,Proceedings of the 27th International Conference on Computational Linguistics,0,Extracting a bilingual terminology for multi-word terms from comparable corpora has not been widely researched. In this work we propose a unified framework for aligning bilingual terms independently of the term lengths. We also introduce some enhancements to the context-based and the neural network based approaches. Our experiments show the effectiveness of our enhancements of previous works and the system can be adapted in specialized domains.
2018.jeptalnrecital-long.2,Alignement de termes de longueur variable en corpus comparables sp{\\'e}cialis{\\'e}s (Alignment of variable length terms in specialized comparable corpora),2018,0,0,2,0,7806,jingshu liu,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"Nous proposons dans cet article une adaptation de l{'}approche compositionnelle {\'e}tendue capable d{'}aligner des termes de longueurs variables {\`a} partir de corpus comparables, en modifiant la repr{\'e}sentation des termes complexes. Nous proposons {\'e}galement de nouveaux modes de pond{\'e}ration pour l{'}approche standard qui am{\'e}liorent les r{\'e}sultats des approches {\'e}tat de l{'}art pour les termes simples et complexes en domaine de sp{\'e}cialit{\'e}."
2018.jeptalnrecital-long.9,Ordonnancement de r{\\'e}ponses dans les syst{\\`e}mes de dialogue bas{\\'e} sur une similarit{\\'e} contexte/r{\\'e}ponse (Response ranking in dialogue systems based on context-response similarity),2018,-1,-1,4,0,29984,basma boussaha,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"Construire des syst{\`e}mes de dialogue qui conversent avec les humains afin de les aider dans leurs t{\^a}ches quotidiennes est devenu une priorit{\'e}. Certains de ces syst{\`e}mes produisent des dialogues en cherchant le meilleur {\'e}nonc{\'e} (r{\'e}ponse) parmi un ensemble d{'}{\'e}nonc{\'e}s candidats. Le choix de la r{\'e}ponse est conditionn{\'e} par l{'}historique de la conversation appel{\'e} contexte. Ces syst{\`e}mes ordonnent les {\'e}nonc{\'e}s candidats par leur ad{\'e}quation au contexte, le meilleur est ensuite choisi. Les approches existantes {\`a} base de r{\'e}seaux de neurones profonds sont performantes pour cette t{\^a}che. Dans cet article, nous am{\'e}liorons une approche {\'e}tat de l{'}art {\`a} base d{'}un dual encodeur LSTM. En se basant sur la similarit{\'e} s{\'e}mantique entre le contexte et la r{\'e}ponse, notre approche apprend {\`a} mieux distinguer les bonnes r{\'e}ponses des mauvaises. Les r{\'e}sultats exp{\'e}rimentaux sur un large corpus de chats d{'}Ubuntu montrent une am{\'e}lioration significative de 7, 6 et 2 points sur le Rappel@(1, 2 et 5) respectivement par rapport au meilleur syst{\`e}me {\'e}tat de l{'}art."
2018.jeptalnrecital-long.14,D{\\'e}codeur neuronal pour la transcription de documents manuscrits anciens (Neural decoder for the transcription of historical handwritten documents),2018,-1,-1,2,0,29572,adeline granet,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"L{'}absence de donn{\'e}es annot{\'e}es peut {\^e}tre une difficult{\'e} majeure lorsque l{'}on s{'}int{\'e}resse {\`a} l{'}analyse de documents manuscrits anciens. Pour contourner cette difficult{\'e}, nous proposons de diviser le probl{\`e}me en deux, afin de pouvoir s{'}appuyer sur des donn{\'e}es plus facilement accessibles. Dans cet article nous pr{\'e}sentons la partie d{\'e}codeur d{'}un encodeur-d{\'e}codeur multimodal utilisant l{'}apprentissage par transfert de connaissances pour la transcription des titres de pi{\`e}ces de la Com{\'e}die Italienne. Le d{\'e}codeur transforme un vecteur de n-grammes au niveau caract{\`e}res en une s{\'e}quence de caract{\`e}res correspondant {\`a} un mot. L{'}apprentissage par transfert de connaissances est r{\'e}alis{\'e} principalement {\`a} partir d{'}une nouvelle ressource inexploit{\'e}e contemporaine {\`a} la Com{\'e}die-Italienne et th{\'e}matiquement proche ; ainsi que d{'}autres ressources couvrant d{'}autres domaines, des langages diff{\'e}rents et m{\^e}me des p{\'e}riodes diff{\'e}rentes. Nous obtenons 97,27{\%} de caract{\`e}res bien reconnus sur les donn{\'e}es de la Com{\'e}die-Italienne, ainsi que 86,57{\%} de mots correctement g{\'e}n{\'e}r{\'e}s malgr{\'e} une couverture de 67,58{\%} uniquement entre la Com{\'e}die-Italienne et l{'}ensemble d{'}apprentissage. Les exp{\'e}riences montrent qu{'}un tel syst{\`e}me peut {\^e}tre une approche efficace dans le cadre d{'}apprentissage par transfert."
W17-4206,Language-based Construction of Explorable News Graphs for Journalists,2017,5,1,4,1,31698,remi bois,Proceedings of the 2017 {EMNLP} Workshop: Natural Language Processing meets Journalism,0,"Faced with ever-growing news archives, media professionals are in need of advanced tools to explore the information surrounding specific events. This problem is most commonly answered by browsing news datasets, going from article to article and viewing unaltered original content. In this article, we introduce an efficient way to generate links between news items, allowing such browsing through an easily explorable graph, and enrich this graph by automatically typing links in order to inform the user on the nature of the relation between two news pieces. User evaluations are conducted on real world data with journalists in order to assess for the interest of both the graph representation and link typing in a press reviewing task, showing the system to be of significant help for their work."
I17-1069,Bilingual Word Embeddings for Bilingual Terminology Extraction from Specialized Comparable Corpora,2017,0,2,2,1,16811,amir hazem,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"Bilingual lexicon extraction from comparable corpora is constrained by the small amount of available data when dealing with specialized domains. This aspect penalizes the performance of distributional-based approaches, which is closely related to the reliability of word{'}s cooccurrence counts extracted from comparable corpora. A solution to avoid this limitation is to associate external resources with the comparable corpus. Since bilingual word embeddings have recently shown efficient models for learning bilingual distributed representation of words, we explore different word embedding models and show how a general-domain comparable corpus can enrich a specialized comparable corpus via neural networks"
L16-1661,Improving Bilingual Terminology Extraction from Comparable Corpora via Multiple Word-Space Models,2016,24,1,2,1,16811,amir hazem,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"There is a rich flora of word space models that have proven their efficiency in many different applications including information retrieval (Dumais, 1988), word sense disambiguation (Schutze, 1992), various semantic knowledge tests (Lund et al., 1995; Karlgren, 2001), and text categorization (Sahlgren, 2005). Based on the assumption that each model captures some aspects of word meanings and provides its own empirical evidence, we present in this paper a systematic exploration of the principal corpus-based word space models for bilingual terminology extraction from comparable corpora. We find that, once we have identified the best procedures, a very simple combination approach leads to significant improvements compared to individual models."
C16-1321,Efficient Data Selection for Bilingual Terminology Extraction from Comparable Corpora,2016,0,5,2,1,16811,amir hazem,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Comparable corpora are the main alternative to the use of parallel corpora to extract bilingual lexicons. Although it is easier to build comparable corpora, specialized comparable corpora are often of modest size in comparison with corpora issued from the general domain. Consequently, the observations of word co-occurrences which are the basis of context-based methods are unreliable. We propose in this article to improve word co-occurrences of specialized comparable corpora and thus context representation by using general-domain data. This idea, which has been already used in machine translation task for more than a decade, is not straightforward for the task of bilingual lexicon extraction from specific-domain comparable corpora. We go against the mainstream of this task where many studies support the idea that adding out-of-domain documents decreases the quality of lexicons. Our empirical evaluation shows the advantages of this approach which induces a significant gain in the accuracy of extracted lexicons."
2016.jeptalnrecital-poster.18,"Extraction d{'}opinions ambig{\\\u}es dans des corpus d{'}avis clients (Ambiguous opinion extraction in user feedbacks)""",2016,-1,-1,2,0,35929,joseph lark,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Posters),0,Nous d{\'e}tectons dans des corpus d{'}avis clients en fran{\c{c}}ais des expressions d{'}opinion ne contenant pas de marqueur d{'}opinion explicitement positif ou n{\'e}gatif. Nous proc{\'e}dons pour cela en deux {\'e}tapes en nous appuyant sur des m{\'e}thodes existantes : nous identifions ces expressions {\`a} l{'}aide de fen{\^e}tres de mots puis nous les classifions en polarit{\'e}. Le processus global pr{\'e}sente des r{\'e}sultats satisfaisants pour notre cadre applicatif demandant une haute pr{\'e}cision.
2016.jeptalnrecital-long.3,Comparaison d{'}approches de classification automatique des actes de dialogue dans un corpus de conversations {\\'e}crites en ligne sur diff{\\'e}rentes modalit{\\'e}s (A comparison of automatic dialog act recognition approaches in a multimodal corpus of online written conversations),2016,-1,-1,3,0,35008,soufian salim,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs),0,"L{'}analyse des conversations {\'e}crites porteuses de demandes d{'}assistance est un enjeu important pour le d{\'e}veloppement de nouvelles technologies li{\'e}es au support client. Dans cet article, nous nous int{\'e}ressons {\`a} l{'}analyse d{'}un m{\^e}me type d{'}{\'e}change sur un canal diff{\'e}rent : les conversations se d{\'e}roulant sur les plate-formes d{'}entraide entre utilisateurs. Nous comparons des approches de classification supervis{\'e}es sur trois modalit{\'e}s des CMR 1 diff{\'e}rentes {\`a} m{\^e}me th{\'e}matique : des courriels, forums et chats issus de la communaut{\'e} Ubuntu. Le syst{\`e}me emploie une taxonomie fine bas{\'e}e sur le sch{\'e}ma DIT++. D{'}autres exp{\'e}riences sont d{\'e}taill{\'e}es, et nous rapportons les r{\'e}sultats obtenus avec diff{\'e}rentes approches et diff{\'e}rents traits sur les diff{\'e}rentes parties de notre corpus multimodal."
2016.jeptalnrecital-long.14,Extraction de lexiques bilingues {\\`a} partir de corpus comparables sp{\\'e}cialis{\\'e}s {\\`a} travers une langue pivot (Bilingual lexicon extraction from specialized comparable corpora using a pivot language),2016,-1,-1,2,0,35947,alexis linard,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs),0,"L{'}extraction de lexiques bilingues {\`a} partir de corpus comparables se r{\'e}alise traditionnellement en s{'}appuyant sur deux langues. Des travaux pr{\'e}c{\'e}dents en extraction de lexiques bilingues {\`a} partir de corpus parall{\`e}les ont d{\'e}montr{\'e} que l{'}utilisation de plus de deux langues peut {\^e}tre utile pour am{\'e}liorer la qualit{\'e} des alignements extraits. Nos travaux montrent qu{'}il est possible d{'}utiliser la m{\^e}me strat{\'e}gie pour des corpus comparables. Nous avons d{\'e}fini deux m{\'e}thodes originales impliquant des langues pivots et nous les avons {\'e}valu{\'e}es sur quatre langues et deux langues pivots en particulier. Nos exp{\'e}rimentations ont montr{\'e} que lorsque l{'}alignement entre la langue source et la langue pivot est de bonne qualit{\'e}, l{'}extraction du lexique en langue cible s{'}en trouve am{\'e}lior{\'e}e."
W15-3405,Attempting to Bypass Alignment from Comparable Corpora via Pivot Language,2015,29,3,3,0,35947,alexis linard,Proceedings of the Eighth Workshop on Building and Using Comparable Corpora,0,"Alignment enhanced. from comparable corpora usually involves two languages, one source and one target language. Previous works on bilingual lexicon extraction from parallel corpora demonstrated that more than two languages can be useful to improve the alignments. Our works have investigated to which extent a third language could be interesting to bypass the original alignment. We have defined two original alignment approaches involving pivot languages and we have evaluated over four languages and two pivot languages in particular. The experiments have shown that in some cases the quality of the extracted lexicon has been"
W15-3413,{LINA}: Identifying Comparable Documents from {W}ikipedia,2015,11,6,1,1,17779,emmanuel morin,Proceedings of the Eighth Workshop on Building and Using Comparable Corpora,0,"This paper describes the LINA system for the BUCC 2015 shared track. Following (Enright and Kondrak, 2007), our system identify comparable documents by collecting counts of hapax words. We extend this method by filtering out document pairs sharing target documents using pigeonhole reasoning and cross-lingual information ."
2015.jeptalnrecital-court.16,{CAN{\\'E}PHORE} : un corpus fran{\\c{c}}ais pour la fouille d{'}opinion cibl{\\'e}e,2015,-1,-1,2,0,35929,joseph lark,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"La fouille d{'}opinion cibl{\'e}e (aspect-based sentiment analysis) fait l{'}objet ces derni{\`e}res ann{\'e}es d{'}un int{\'e}r{\^e}t particulier, visible dans les sujets des r{\'e}centes campagnes d{'}{\'e}valuation comme SemEval 2014 et 2015 ou bien DEFT 2015. Cependant les corpus annot{\'e}s et publiquement disponibles permettant l{'}{\'e}valuation de cette t{\^a}che sont rares. Dans ce travail nous pr{\'e}sentons en premier lieu un corpus fran{\c{c}}ais librement accessible de 10 000 tweets manuellement annot{\'e}s. Nous accompagnons ce corpus de r{\'e}sultats de r{\'e}f{\'e}rence pour l{'}extraction de marqueurs d{'}opinion non supervis{\'e}e. Nous pr{\'e}sentons ensuite une m{\'e}thode am{\'e}liorant les r{\'e}sultats de cette extraction, en suivant une approche semi-supervis{\'e}e."
2015.jeptalnrecital-court.17,Extraction de Contextes Riches en Connaissances en corpus sp{\\'e}cialis{\\'e}s,2015,-1,-1,2,0,27613,firas hmida,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Les banques terminologiques et les dictionnaires sont des ressources pr{\'e}cieuses qui facilitent l{'}acc{\`e}s aux connaissances des domaines sp{\'e}cialis{\'e}s. Ces ressources sont souvent assez pauvres et ne proposent pas toujours pour un terme {\`a} illustrer des exemples permettant d{'}appr{\'e}hender le sens et l{'}usage de ce terme. Dans ce contexte, nous proposons de mettre en {\oe}uvre la notion de Contextes Riches en Connaissances (CRC) pour extraire directement de corpus sp{\'e}cialis{\'e}s des exemples de contextes illustrant son usage. Nous d{\'e}finissons un cadre unifi{\'e} pour exploiter tout {\`a} la fois des patrons de connaissances et des collocations avec une qualit{\'e} acceptable pour une r{\'e}vision humaine."
2015.jeptalnrecital-court.30,Vers une typologie de liens entre contenus journalistiques,2015,-1,-1,3,1,31698,remi bois,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Nous pr{\'e}sentons une typologie de liens pour un corpus multim{\'e}dia ancr{\'e} dans le domaine journalistique. Bien que plusieurs typologies aient {\'e}t{\'e} cr{\'e}{\'e}es et utilis{\'e}es par la communaut{\'e}, aucune ne permet de r{\'e}pondre aux enjeux de taille et de vari{\'e}t{\'e} soulev{\'e}s par l{'}utilisation d{'}un corpus large comprenant des textes, des vid{\'e}os, ou des {\'e}missions radiophoniques. Nous proposons donc une nouvelle typologie, premi{\`e}re {\'e}tape visant {\`a} la cr{\'e}ation et la cat{\'e}gorisation automatique de liens entre des fragments de documents afin de proposer de nouveaux modes de navigation au sein d{'}un grand corpus. Plusieurs exemples d{'}instanciation de la typologie sont pr{\'e}sent{\'e}s afin d{'}illustrer son int{\'e}r{\^e}t."
P14-1121,Looking at Unbalanced Specialized Comparable Corpora for Bilingual Lexicon Extraction,2014,29,11,1,1,17779,emmanuel morin,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"The main work in bilingual lexicon extraction from comparable corpora is based on the implicit hypothesis that corpora are balanced. However, the historical contextbased projection method dedicated to this task is relatively insensitive to the sizes of each part of the comparable corpus. Within this context, we have carried out a study on the influence of unbalanced specialized comparable corpora on the quality of bilingual terminology extraction through different experiments. Moreover, we have introduced a regression model that boosts the observations of word cooccurrences used in the context-based projection method. Our results show that the use of unbalanced specialized comparable corpora induces a significant gain in the quality of extracted lexicons."
W13-2504,A Comparison of Smoothing Techniques for Bilingual Lexicon Extraction from Comparable Corpora,2013,32,4,2,1,16811,amir hazem,Proceedings of the Sixth Workshop on Building and Using Comparable Corpora,0,"Smoothing is a central issue in language modeling and a prior step in different natural language processing (NLP) tasks. However, less attention has been given to it for bilingual lexicon extraction from comparable corpora. If a first work to improve the extraction of low frequency words showed significant improvement while using distance-based averaging (Pekar et al., 2006), no investigation of the many smoothing techniques has been carried out so far. In this paper, we present a study of some widelyused smoothing algorithms for language n-gram modeling (Laplace, Good-Turing, Kneser-Ney...). Our main contribution is to investigate how the different smoothing techniques affect the performance of the standard approach (Fung, 1998) traditionally used for bilingual lexicon extraction. We show that using smoothing as a preprocessing step of the standard approach increases its performance significantly."
N13-1030,Keyphrase Extraction for N-best Reranking in Multi-Sentence Compression,2013,23,36,2,0,4245,florian boudin,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,Multi-Sentence Compression (MSC) is the task of generating a short single sentence summary from a cluster of related sentences. This paper presents an N-best reranking method based on keyphrase extraction. Compression candidates generated by a word graph-based MSC approach are reranked according to the number and relevance of keyphrases they contain. Both manual and automatic evaluations were performed using a dataset made of clusters of newswire sentences. Results show that the proposed method significantly improves the informativity of the generated compressions.
I13-1046,Ranking Translation Candidates Acquired from Comparable Corpora,2013,14,3,3,0,41661,rima harastani,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Domain-specific bilingual lexicons extracted from domain-specific comparable corpora provide for one term a list of ranked translation candidates. This study proposes to re-rank these translation candidates. We suggest that a term and its translation appear in comparable sentences that can be extracted from domainspecific comparable corpora. For a source term and a list of translation candidates, we propose a method to identify and align the best source and target sentences that contain the term and its translation candidates. We report results with two language pairs (French-English and FrenchGerman) using domain-specific comparable corpora. Our method significantly improves the top 1, top 5 and top 10 precisions of a domain-specific bilingual lexicon, and thus, provides a better user-"
I13-1196,Word Co-occurrence Counts Prediction for Bilingual Terminology Extraction from Comparable Corpora,2013,23,4,2,1,16811,amir hazem,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Methods dealing with bilingual lexicon extraction from comparable corpora are often based on word co-occurrence observation and are by essence more effective when using large corpora. In most cases, specialized comparable corpora are of small size, and this particularity has a direct impact on bilingual terminology extraction results. In order to overcome insufficient data coverage and to make word co-occurrence statistics more reliable, we propose building a predictive model of word co-occurrence counts. We compare different predicting models with the traditional Standard Approach and show that once we have identified the best procedures, our method increases significantly the performance of extracting word translations from comparable corpora."
F13-1018,Bilingual Lexicon Extraction from Comparable Corpora by Combining Contextual Representations (Extraction de lexiques bilingues {\\`a} partir de corpus comparables par combinaison de repr{\\'e}sentations contextuelles) [in {F}rench],2013,0,0,2,1,16811,amir hazem,Proceedings of TALN 2013 (Volume 1: Long Papers),0,None
F13-1023,"Identification, Alignment, and Tranlsation of Relational Adjectives from Comparable Corpora (Identification, alignement, et traductions des adjectifs relationnels en corpus comparables) [in {F}rench]",2013,0,0,3,0,41661,rima harastani,Proceedings of TALN 2013 (Volume 1: Long Papers),0,None
hazem-morin-2012-adaptive,Adaptive Dictionary for Bilingual Lexicon Extraction from Comparable Corpora,2012,19,14,2,1,16811,amir hazem,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"One of the main resources used for the task of bilingual lexicon extraction from comparable corpora is : the bilingual dictionary, which is considered as a bridge between two languages. However, no particular attention has been given to this lexicon, except its coverage, and the fact that it can be issued from the general language, the specialised one, or a mix of both. In this paper, we want to highlight the idea that a better consideration of the bilingual dictionary by studying its entries and filtering the non-useful ones, leads to a better lexicon extraction and thus, reach a higher precision. The experiments are conducted on a medical domain corpora. The French-English specialised corpus 'breast cancer' of 1 million words. We show that the empirical results obtained with our filtering process improve the standard approach traditionally dedicated to this task and are promising for future work."
F12-2011,Compositionnalit{\\'e} et contextes issus de corpus comparables pour la traduction terminologique (Compositionality and Context for Bilingual Lexicon Extraction from Comparable Corpora) [in {F}rench],2012,0,0,1,1,17779,emmanuel morin,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
C12-1046,Extraction of Domain-Specific Bilingual Lexicon from Comparable Corpora: Compositional Translation and Ranking,2012,28,14,3,0,30007,estelle delpech,Proceedings of {COLING} 2012,0,"This paper proposes a method for extracting translations of morphologically constructed terms from comparable corpora. The method is based on compositional translation and exploits translation equivalences at the morpheme-level, which allows for the generation of fertile translations (translation pairs in which the target term has more words than the source term). Ranking methods relying on corpus-based and translation-based features are used to select the best candidate translation. We obtain an average precision of 91% on the Top1 candidate translation. The method was tested on two language pairs (English-French and English-German) and with a small specialized comparable corpora (400k words per language)."
C12-1110,Revising the Compositional Method for Terminology Acquisition from Comparable Corpora,2012,27,8,1,1,17779,emmanuel morin,Proceedings of {COLING} 2012,0,"In this paper, we present a new method that improves the alignment of equivalent terms monolingually acquired from bilingual comparable corpora: the Compositional Method with Context-Based Projection (CMCBP). Our overall objective is to identify and to translate high specialized terminology made up of multi-word terms acquired from comparable corpora. Our evaluation in the medical domain and for two pairs of languages demonstrates that CMCBP outperforms the state-of-art compositional approach commonly used for translationally equivalent multi-word term discovery from comparable corpora."
2012.amta-papers.5,Identification of Fertile Translations in Comparable Corpora: A Morpho-Compositional Approach,2012,20,2,3,0,30007,estelle delpech,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,This paper defines a method for lexicon in the biomedical domain from comparable corpora. The method is based on compositional translation and exploits morpheme-level translation equivalences. It can generate translations for a large variety of morphologically constructed words and can also generate {'}fertile{'} translations. We show that fertile translations increase the overall quality of the extracted lexicon for English to French translation.
W11-1205,Bilingual Lexicon Extraction from Comparable Corpora Enhanced with Parallel Corpora,2011,23,31,1,1,17779,emmanuel morin,Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web,0,"In this article, we present a simple and effective approach for extracting bilingual lexicon from comparable corpora enhanced with parallel corpora. We make use of structural characteristics of the documents comprising the comparable corpus to extract parallel sentences with a high degree of quality. We then use state-of-the-art techniques to build a specialized bilingual lexicon from these sentences and evaluate the contribution of this lexicon when added to the comparable corpus-based alignment technique. Finally, the value of this approach is demonstrated by the improvement of translation accuracy for medical words."
W11-1206,Bilingual Lexicon Extraction from Comparable Corpora as Metasearch,2011,23,8,2,1,16811,amir hazem,Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web,0,"In this article we present a novel way of looking at the problem of automatic acquisition of pairs of translationally equivalent words from comparable corpora. We first present the standard and extended approaches traditionally dedicated to this task. We then reinterpret the extended method, and motivate a novel model to reformulate this approach inspired by the metasearch engines in information retrieval. The empirical results show that performances of our model are always better than the baseline obtained with the extended approach and also competitive with the standard approach."
2011.jeptalnrecital-long.13,"Degr{\\'e} de comparabilit{\\'e}, extraction lexicale bilingue et recherche d{'}information interlingue (Degree of comparability, bilingual lexical extraction and cross-language information retrieval)",2011,-1,-1,3,0,9573,bo li,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Nous {\'e}tudions dans cet article le probl{\`e}me de la comparabilit{\'e} des documents composant un corpus comparable afin d{'}am{\'e}liorer la qualit{\'e} des lexiques bilingues extraits et les performances des syst{\`e}mes de recherche d{'}information interlingue. Nous proposons une nouvelle approche qui permet de garantir un certain degr{\'e} de comparabilit{\'e} et d{'}homog{\'e}n{\'e}it{\'e} du corpus tout en pr{\'e}servant une grande part du vocabulaire du corpus d{'}origine. Nos exp{\'e}riences montrent que les lexiques bilingues que nous obtenons sont d{'}une meilleure qualit{\'e} que ceux obtenus avec les approches pr{\'e}c{\'e}dentes, et qu{'}ils peuvent {\^e}tre utilis{\'e}s pour am{\'e}liorer significativement les syst{\`e}mes de recherche d{'}information interlingue."
2011.jeptalnrecital-long.19,M{\\'e}tarecherche pour l{'}extraction lexicale bilingue {\\`a} partir de corpus comparables (Metasearch for bilingual lexical extraction from comparable corpora),2011,-1,-1,2,1,16811,amir hazem,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Nous pr{\'e}sentons dans cet article une nouvelle mani{\`e}re d{'}aborder le probl{\`e}me de l{'}acquisition automatique de paires de mots en relation de traduction {\`a} partir de corpus comparables. Nous d{\'e}crivons tout d{'}abord les approches standard et par similarit{\'e} interlangue traditionnellement d{\'e}di{\'e}es {\`a} cette t{\^a}che. Nous r{\'e}interpr{\'e}tons ensuite la m{\'e}thode par similarit{\'e} interlangue et motivons un nouveau mod{\`e}le pour reformuler cette approche inspir{\'e}e par les m{\'e}tamoteurs de recherche d{'}information. Les r{\'e}sultats empiriques que nous obtenons montrent que les performances de notre mod{\`e}le sont toujours sup{\'e}rieures {\`a} celles obtenues avec l{'}approche par similarit{\'e} interlangue, mais aussi comme {\'e}tant comp{\'e}titives par rapport {\`a} l{'}approche standard."
2011.jeptalnrecital-demonstration.6,{TTC} {T}erm{S}uite : une cha{\\^\\i}ne de traitement pour la fouille terminologique multilingue ({TTC} {T}erm{S}uite: a processing chain for multilingual terminology mining),2011,-1,-1,4,0,5603,beatrice daille,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,
W09-3110,Compilation of Specialized Comparable Corpora in {F}rench and {J}apanese,2009,27,9,2,0,5695,lorraine goeuriot,Proceedings of the 2nd Workshop on Building and Using Comparable Corpora: from Parallel to Non-parallel Corpora ({BUCC}),0,"We present in this paper the development of a specialized comparable corpora compilation tool, for which quality would be close to a manually compiled corpus. The comparability is based on three levels: domain, topic and type of discourse. Domain and topic can be filtered with the keywords used through web search. But the detection of the type of discourse needs a wide linguistic analysis. The first step of our work is to automate the detection of the type of discourse that can be found in a scientific domain (science and popular science) in French and Japanese languages. First, a contrastive stylistic analysis of the two types of discourse is done on both languages. This analysis leads to the creation of a reusable, generic and robust typology. Machine learning algorithms are then applied to the typology, using shallow parsing. We obtain good results, with an average precision of 80% and an average recall of 70% that demonstrate the efficiency of this typology. This classification tool is then inserted in a corpus compilation tool which is a text collection treatment chain realized through IBM UIMA system. Starting from two specialized web documents collection in French and Japanese, this tool creates the corresponding corpus."
2009.mtsummit-posters.14,Anchor Points for Bilingual Lexicon Extraction from Small Comparable Corpora,2009,13,16,2,0,44356,emmanuel prochasson,Proceedings of Machine Translation Summit XII: Posters,0,"We examine the contribution of reliable elements in Frenchxe2x80x93 and Englishxe2x80x93Japanese alignment from comparable corpora, using transliterated elements and scientific compounds as anchor points among context-vectors of elements to align. We highlight those elements in context-vector normalisation to give them a higher priority in context-vector comparison. We carry out experiments on small comparable corpora to show that those elements can efficiently be used to improve the quality of the alignment."
2009.jeptalnrecital-long.6,Apport d{'}un corpus comparable d{\\'e}s{\\'e}quilibr{\\'e} {\\`a} l{'}extraction de lexiques bilingues,2009,-1,-1,1,1,17779,emmanuel morin,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Les principaux travaux en extraction de lexiques bilingues {\`a} partir de corpus comparables reposent sur l{'}hypoth{\`e}se implicite que ces corpus sont {\'e}quilibr{\'e}s. Cependant, les diff{\'e}rentes m{\'e}thodes computationnelles associ{\'e}es sont relativement insensibles {\`a} la taille de chaque partie du corpus. Dans ce contexte, nous {\'e}tudions l{'}influence que peut avoir un corpus comparable d{\'e}s{\'e}quilibr{\'e} sur la qualit{\'e} des terminologies bilingues extraites {\`a} travers diff{\'e}rentes exp{\'e}riences. Nos r{\'e}sultats montrent que sous certaines conditions l{'}utilisation d{'}un corpus comparable d{\'e}s{\'e}quilibr{\'e} peut engendrer un gain significatif dans la qualit{\'e} des lexiques extraits."
2009.jeptalnrecital-long.10,Influence des points d{'}ancrage pour l{'}extraction lexicale bilingue {\\`a} partir de corpus comparables sp{\\'e}cialis{\\'e}s,2009,-1,-1,2,0,44356,emmanuel prochasson,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"L{'}extraction de lexiques bilingues {\`a} partir de corpus comparables affiche de bonnes performances pour des corpus volumineux mais chute fortement pour des corpus d{'}une taille plus modeste. Pour pallier cette faiblesse, nous proposons une nouvelle contribution au processus d{'}alignement lexical {\`a} partir de corpus comparables sp{\'e}cialis{\'e}s qui vise {\`a} renforcer la significativit{\'e} des contextes lexicaux en s{'}appuyant sur le vocabulaire sp{\'e}cialis{\'e} du domaine {\'e}tudi{\'e}. Les exp{\'e}riences que nous avons r{\'e}alis{\'e}es en ce sens montrent qu{'}une meilleure prise en compte du vocabulaire sp{\'e}cialis{\'e} permet d{'}am{\'e}liorer la qualit{\'e} des lexiques extraits."
2009.jeptalnrecital-court.43,Un nouveau sch{\\'e}ma de pond{\\'e}ration pour la cat{\\'e}gorisation de documents manuscrits,2009,-1,-1,2,0,30952,sebastian saldarriaga,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Les sch{\'e}mas de pond{\'e}ration utilis{\'e}s habituellement en cat{\'e}gorisation de textes, et plus g{\'e}n{\'e}ralement en recherche d{'}information (RI), ne sont pas adapt{\'e}s {\`a} l{'}utilisation de donn{\'e}es li{\'e}es {\`a} des textes issus d{'}un processus de reconnaissance de l{'}{\'e}criture. En particulier, les candidats-mot {\`a} la reconnaissance ne pourraient {\^e}tre exploit{\'e}s sans introduire de fausses occurrences de termes dans le document. Dans cet article nous pr{\'e}sentons un nouveau sch{\'e}ma de pond{\'e}ration permettant d{'}exploiter les listes de candidats-mot. Il permet d{'}estimer le pouvoir discriminant d{'}un terme en fonction de la probabilit{\'e} a posteriori d{'}un candidat-mot dans une liste de candidats. Les r{\'e}sultats montrent que le taux de classification de documents fortement d{\'e}grad{\'e}s peut {\^e}tre am{\'e}lior{\'e} en utilisant le sch{\'e}ma propos{\'e}."
I08-1013,An Effective Compositional Model for Lexical Alignment,2008,22,8,2,0.716781,5603,beatrice daille,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"The automatic compilation of bilingual dictionaries from comparable corpora has been successful for single-word terms (SWTs), but remains disappointing for multi-word terms (MWTs). One of the main problems is the insufficient coverage of the bilingual dictionary. Using the compositional translation method improved the results, but still shows some limits for MWTs of different syntactic structures. In this paper, we propose to bridge the gap between syntactic structures through morphological links. The results show a significant improvement in the compositional translation of MWTs that demonstrate the efficiency of the morphologically based-method for lexical alignment."
P07-1084,"Bilingual Terminology Mining - Using Brain, not brawn comparable corpora",2007,13,84,1,1,17779,emmanuel morin,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"Current research in text mining favours the quantity of texts over their quality. But for bilingual terminology mining, and for many language pairs, large comparable corpora are not available. More importantly, as terms are defined vis-a-vis a specific domain with a restricted register, it is expected that the quality rather than the quantity of the corpus matters more in terminology mining. Our hypothesis, therefore, is that the quality of the corpus is more important than the quantity and ensures the quality of the acquired terminological resources. We show how important the type of discourse is as a characteristic of the comparable corpus."
I05-1062,{F}rench-{E}nglish Terminology Extraction from Comparable Corpora,2005,17,44,2,1,5603,beatrice daille,Second International Joint Conference on Natural Language Processing: Full Papers,0,"This article presents a method of extracting bilingual lexica composed of single-word terms (SWTs) and multi-word terms (MWTs) from comparable corpora of a technical domain. First, this method extracts MWTs in each language, and then uses statistical methods to align single words and MWTs by exploiting the term contexts. After explaining the difficulties involved in aligning MWTs and specifying our approach, we show the adopted process for bilingual terminology extraction and the resources used in our experiments. Finally, we evaluate our approach and demonstrate its significance, particularly in relation to non-compositional MWT alignment."
daille-etal-2004-french,{F}rench-{E}nglish Multi-word Term Alignment Based on Lexical Context Analysis,2004,10,5,3,1,5603,beatrice daille,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This article presents a method of extracting bilingual lexica composed of single-word terms (SWTs) and multi-word terms (MWTs) from comparable corpora of a technical domain. First, this method extracts MWTs in each language, and then uses statistical methods to align single words and MWTs by exploiting the term contexts. After explaining the difficulties involved in aligning MWTs and specifying our approach, we show the adopted process for bilingual terminology extraction and the resources used in our experiments. Finally, we evaluate our approach and demonstrate its significance, particularly in relation to non-compositional MWT alignment."
2004.jeptalnrecital-long.13,Extraction de terminologies bilingues {\\`a} partir de corpus comparables,2004,-1,-1,1,1,17779,emmanuel morin,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente une m{\'e}thode pour extraire, {\`a} partir de corpus comparables d{'}un domaine de sp{\'e}cialit{\'e}, un lexique bilingue comportant des termes simples et complexes. Cette m{\'e}thode extrait d{'}abord les termes complexes dans chaque langue, puis les aligne {\`a} l{'}aide de m{\'e}thodes statistiques exploitant le contexte des termes. Apr{\`e}s avoir rappel{\'e} les difficult{\'e}s que pose l{'}alignement des termes complexes et pr{\'e}cis{\'e} notre approche, nous pr{\'e}sentons le processus d{'}extraction de terminologies bilingues adopt{\'e} et les ressources utilis{\'e}es pour nos exp{\'e}rimentations. Enfin, nous {\'e}valuons notre approche et d{\'e}montrons son int{\'e}r{\^e}t en particulier pour l{'}alignement de termes complexes non compositionnels."
2003.jeptalnrecital-poster.15,Apport d{'}un mod{\\`e}le de langage statistique pour la reconnaissance de l{'}{\\'e}criture manuscrite en ligne,2003,-1,-1,2,0,53042,freddy perraud,Actes de la 10{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Dans ce travail, nous {\'e}tudions l{'}apport d{'}un mod{\`e}le de langage pour am{\'e}liorer les performances des syst{\`e}mes de reconnaissance de l{'}{\'e}criture manuscrite en-ligne. Pour cela, nous avons explor{\'e} des mod{\`e}les bas{\'e}s sur des approches statistiques construits par apprentissage sur des corpus {\'e}crits. Deux types de mod{\`e}les ont {\'e}t{\'e} {\'e}tudi{\'e}s : les mod{\`e}les n-grammes et ceux de type n-classes. En vue de l{'}int{\'e}gration dans un syst{\`e}me de faible capacit{\'e} (engin nomade), un mod{\`e}le n-classe combinant crit{\`e}res syntaxiques et contextuels a {\'e}t{\'e} d{\'e}fini, il a permis d{'}obtenir des r{\'e}sultats surpassant ceux donn{\'e}s avec un mod{\`e}le beaucoup plus lourd de type n-gramme. Les r{\'e}sultats pr{\'e}sent{\'e}s ici montrent qu{'}il est possible de prendre en compte les sp{\'e}cificit{\'e}s d{'}un langage en vue de reconna{\^\i}tre l{'}{\'e}criture manuscrite avec des mod{\`e}les de taille tout {\`a} fait raisonnable."
fourour-etal-2002-incremental,Incremental Recognition and Referential Categorization of {F}rench Proper Names,2002,8,2,2,0,53521,nordine fourour,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper presents Nemesis, a French proper name (PN) recognizer for Large-scale Information Extraction (IE), whose specifications have been elaborated through corpus investigation both in terms of referential categories and graphical structures. The graphical criteria are used to identify proper names and the referential classification to categorize them. The system is a classical one: it is rule-based and uses specialized lexicons without any linguistic preprocessing. Its originality consists on a modular architecture which includes a learning process. The system up to now recognizes anthroponyms and toponyms with performance achieving 95 % of precision and 90 % of recall."
P99-1050,Projecting Corpus-Based Semantic Links on a Thesaurus,1999,10,45,1,1,17779,emmanuel morin,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,Hypernym links acquired through an information extraction procedure are projected on multi-word terms through the recognition of semantic variations. The quality of the projected links resulting from corpus-based acquisition is compared with projected links extracted from a technical thesaurus.
