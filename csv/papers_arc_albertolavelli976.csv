2020.smm4h-1.15,{FBK}@{SMM}4{H}2020: {R}o{BERT}a for Detecting Medications on {T}witter,2020,-1,-1,2,0,14632,silvia casola,Proceedings of the Fifth Social Media Mining for Health Applications Workshop {\\&} Shared Task,0,"This paper describes a classifier for tweets that mention medications or supplements, based on a pretrained transformer. We developed such a system for our participation in Subtask 1 of the Social Media Mining for Health Application workshop, which featured an extremely unbalanced dataset. The model showed promising results, with an F1 of 0.8 (task mean: 0.66)."
2020.lrec-1.259,Comparing Machine Learning and Deep Learning Approaches on {NLP} Tasks for the {I}talian Language,2020,-1,-1,2,0,1501,bernardo magnini,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We present a comparison between deep learning and traditional machine learning methods for various NLP tasks in Italian. We carried on experiments using available datasets (e.g., from the Evalita shared tasks) on two sequence tagging tasks (i.e., named entities recognition and nominal entities recognition) and four classification tasks (i.e., lexical relations among words, semantic relations among sentences, sentiment analysis and text classification). We show that deep learning approaches outperform traditional machine learning algorithms in sequence tagging, while for classification tasks that heavily rely on semantics approaches based on feature engineering are still competitive. We think that a similar analysis could be carried out for other languages to provide an assessment of machine learning / deep learning models across different languages."
L18-1279,{P}o{STWITA}-{UD}: an {I}talian {T}witter Treebank in {U}niversal {D}ependencies,2018,0,2,3,1,16433,manuela sanguinetti,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-6526,Annotating {I}talian Social Media Texts in {U}niversal {D}ependencies,2017,0,4,4,1,16433,manuela sanguinetti,Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017),0,None
S13-2057,{FBK}-irst : A Multi-Phase Kernel Based Approach for Drug-Drug Interaction Detection and Classification that Exploits Linguistic Information,2013,13,50,2,1,5863,md chowdhury,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper presents the multi-phase relation extraction (RE) approach which was used for the DDI Extraction task of SemEval 2013. As a preliminary step, the proposed approach indirectly (and automatically) exploits the scope of negation cues and the semantic roles of involved entities for reducing the skewness in the training data as well as discarding possible negative instances from the test data. Then, a state-of-the-art hybrid kernel is used to train a classifier which is later applied on the instances of the test data not filtered out by the previous step. The official results of the task show that our approach yields an F-score of 0.80 for DDI detection and an F-score of 0.65 for DDI detection and classification. Our system obtained significantly higher results than all the other participating teams in this shared task and has been ranked 1st."
S13-2077,{FBK}: Sentiment Analysis in {T}witter with Tweetsted,2013,6,9,4,1,5863,md chowdhury,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper presents the Tweetsted system implemented for the SemEval 2013 task on Sentiment Analysis in Twitter. In particular, we participated in Task B on Message Polarity Classification in the Constrained setting. The approach is based on the exploitation of various resources such as SentiWordNet and LIWC. Official results show that our approach yields a F-score of 0.5976 for Twitter messages (11th out of 35) and a F-score of 0.5487 for SMS messages (8th out of 28 participants)."
N13-1093,Exploiting the Scope of Negations and Heterogeneous Features for Relation Extraction: A Case Study for Drug-Drug Interaction Extraction,2013,18,17,2,1,5863,md chowdhury,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,This paper presents an approach that exploits the scope of negation cues for relation extraction (RE) without the need of using any specifically annotated dataset for building a separate negation scope detection classifier. New features are proposed which are used in two different stages. These also include non-target entity specific features. The proposed RE approach outperforms the previous state of the art for drug-drug interaction (DDI) extraction.
chowdhury-lavelli-2012-evaluation,An Evaluation of the Effect of Automatic Preprocessing on Syntactic Parsing for Biomedical Relation Extraction,2012,21,2,2,1,5863,md chowdhury,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Relation extraction (RE) is an important text mining task which is the basis for further complex and advanced tasks. In state-of-the-art RE approaches, syntactic information obtained through parsing plays a crucial role. In the context of biomedical RE previous studies report usage of various automatic preprocessing techniques applied before parsing the input text. However, these studies do not specify to what extent such techniques improve RE results and to what extent they are corpus specific as well as parser specific. In this paper, we aim at addressing these issues by using various preprocessing techniques, two syntactic tree kernel based RE approaches and two different parsers on 5 widely used benchmark biomedical corpora of the protein-protein interaction (PPI) extraction task. We also provide analyses of various corpus characteristics to verify whether there are correlations between these characteristics and the RE results obtained. These analyses of corpus characteristics can be exploited to compare the 5 PPI corpora."
alicante-etal-2012-treebank,A treebank-based study on the influence of {I}talian word order on parsing performance,2012,21,5,4,0,43088,anita alicante,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The aim of this paper is to contribute to the debate on the issues raised by Morphologically Rich Languages, and more precisely to investigate, in a cross-paradigm perspective, the influence of the constituent order on the data-driven parsing of one of such languages(i.e. Italian). It shows therefore new evidence from experiments on Italian, a language characterized by a rich verbal inflection, which leads to a widespread diffusion of the proâdrop phenomenon and to a relatively free word order. The experiments are performed by using state-of-the-art data-driven parsers (i.e. MaltParser and Berkeley parser) and are based on an Italian treebank available in formats that vary according to two dimensions, i.e. the paradigm of representation (dependency vs. constituency) and the level of detail of linguistic information."
bongelli-etal-2012-corpus,A Corpus of Scientific Biomedical Texts Spanning over 168 Years Annotated for Uncertainty,2012,35,3,7,0,43214,ramona bongelli,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Uncertainty language permeates biomedical research and is fundamental for the computer interpretation of unstructured text. And yet, a coherent, cognitive-based theory to interpret Uncertainty language and guide Natural Language Processing is, to our knowledge, non-existing. The aim of our project was therefore to detect and annotate Uncertainty markers â which play a significant role in building knowledge or beliefs in readers' minds â in a biomedical research corpus. Our corpus includes 80 manually annotated articles from the British Medical Journal randomly sampled from a 168-year period. Uncertainty markers have been classified according to a theoretical framework based on a combined linguistic and cognitive theory. The corpus was manually annotated according to such principles. We performed preliminary experiments to assess the manually annotated corpus and establish a baseline for the automatic detection of Uncertainty markers. The results of the experiments show that most of the Uncertainty markers can be recognized with good accuracy."
E12-1043,"Combining Tree Structures, Flat Features and Patterns for Biomedical Relation Extraction",2012,27,26,2,1,5863,md chowdhury,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Kernel based methods dominate the current trend for various relation extraction tasks including protein-protein interaction (PPI) extraction. PPI information is critical in understanding biological processes. Despite considerable efforts, previously reported PPI extraction results show that none of the approaches already known in the literature is consistently better than other approaches when evaluated on different benchmark PPI corpora. In this paper, we propose a novel hybrid kernel that combines (automatically collected) dependency patterns, trigger words, negative cues, walk features and regular expression patterns along with tree kernel and shallow linguistic kernel. The proposed kernel outperforms the exiting state-of-the-art approaches on the BioInfer corpus, the largest PPI benchmark corpus available. On the other four smaller benchmark corpora, it performs either better or almost as good as the existing approaches. Moreover, empirical results show that the proposed hybrid kernel attains considerably higher precision than the existing approaches, which indicates its capability of learning more accurate models. This also demonstrates that the different types of information that we use are able to complement each other for relation extraction."
C12-2021,Impact of Less Skewed Distributions on Efficiency and Effectiveness of Biomedical Relation Extraction,2012,28,9,2,1,5863,md chowdhury,Proceedings of {COLING} 2012: Posters,0,"Like in other NLP tasks, it has been claimed that advances of machine learning (ML) based approaches to relation extraction (RE) are hampered by the imbalanced distribution of positive and negative instances in the annotated training data. Usually, the number of negative instances is much larger than that of the positive ones and such skewness also exists in the test data. In this paper, we aim at addressing the problem of imbalanced distribution by automatically curbing less informative negative instances. We propose some criteria for identifying such instances and incorporate them in an existing state-of-the-art RE approach. Empirical results on 5 benchmark biomedical corpora show that our proposed approach improves both recall and F1 scores. At the same time, there is a large drop in the number of negative instances and in execution runtime as well."
W11-0412,Assessing the practical usability of an automatically annotated corpus,2011,16,8,2,1,5863,md chowdhury,Proceedings of the 5th Linguistic Annotation Workshop,0,"The creation of a gold standard corpus (GSC) is a very laborious and costly process. Silver standard corpus (SSC) annotation is a very recent direction of corpus development which relies on multiple systems instead of human annotators. In this paper, we investigate the practical usability of an SSC when a machine learning system is trained on it and tested on an unseen benchmark GSC. The main focus of this paper is how an SSC can be maximally exploited. In this process, we inspect several hypotheses which might have influenced the idea of SSC creation. Empirical results suggest that some of the hypotheses (e.g. a positive impact of a large SSC despite of having wrong and missing annotations) are not fully correct. We show that it is possible to automatically improve the quality and the quantity of the SSC annotations. We also observe that considering only those sentences of SSC which contain annotations rather than the full SSC results in a performance boost."
W11-0216,A Study on Dependency Tree Kernels for Automatic Extraction of Protein-Protein Interaction,2011,24,27,2,0,44436,faisal chowdhury,Proceedings of {B}io{NLP} 2011 Workshop,0,"Kernel methods are considered the most effective techniques for various relation extraction (RE) tasks as they provide higher accuracy than other approaches. In this paper, we introduce new dependency tree (DT) kernels for RE by improving on previously proposed dependency tree structures. These are further enhanced to design more effective approaches that we call mildly extended dependency tree (MEDT) kernels. The empirical results on the protein-protein interaction (PPI) extraction task on the AIMed corpus show that tree kernels based on our proposed DT structures achieve higher accuracy than previously proposed DT and phrase structure tree (PST) kernels."
W10-1911,Disease Mention Recognition with Specific Features,2010,19,33,2,1,5863,md chowdhury,Proceedings of the 2010 Workshop on Biomedical Natural Language Processing,0,"Despite an increasing amount of research on biomedical named entity recognition, there has been not enough work done on disease mention recognition. Difficulty of obtaining adequate corpora is one of the key reasons which hindered this particular research. Previous studies argue that correct identification of disease mentions is the key issue for further improvement of the disease-centric knowledge extraction tasks. In this paper, we present a machine learning based approach that uses a feature set tailored for disease mention recognition and outperforms the state-of-the-art results. The paper also discusses why a feature set for the well studied gene/protein mention recognition task is not necessarily equally effective for other biomedical semantic types such as diseases."
bosco-etal-2010-comparing,Comparing the Influence of Different Treebank Annotations on Dependency Parsing,2010,11,16,10,1,17906,cristina bosco,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"As the interest of the NLP community grows to develop several treebanks also for languages other than English, we observe efforts towards evaluating the impact of different annotation strategies used to represent particular languages or with reference to particular tasks. This paper contributes to the debate on the influence of resources used for the training and development on the performance of parsing systems. It presents a comparative analysis of the results achieved by three different dependency parsers developed and tested with respect to two treebanks for the Italian language, namely TUT and ISST--TANL, which differ significantly at the level of both corpus composition and adopted dependency representations."
bosco-etal-2008-comparing,Comparing {I}talian parsers on a common Treebank: the {EVALITA} experience,2008,27,14,6,1,17906,cristina bosco,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The EVALITA 2007 Parsing Task has been the first contest among parsing systems for Italian. It is the first attempt to compare the approaches and the results of the existing parsing systems specific for this language using a common treebank annotated using both a dependency and a constituency-based format. The development data set for this parsing competition was taken from the Turin University Treebank, which is annotated both in dependency and constituency format. The evaluation metrics were those standardly applied in CoNLL and PARSEVAL. The results of the parsing results are very promising and higher than the state-of-the-art for dependency parsing of Italian. An analysis of such results is provided, which takes into account other experiences in treebank-driven parsing for Italian and for other Romance languages (in particular, the CoNLL X {\&} 2007 shared tasks for dependency parsing). It focuses on the characteristics of data sets, i.e. type of annotation and size, parsing paradigms and approaches applied also to languages other than Italian."
S07-1028,{FBK}-{IRST}: Kernel Methods for Semantic Relation Extraction,2007,7,29,2,0.833333,38355,claudio giuliano,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"We present an approach for semantic relation extraction between nominals that combines shallow and deep syntactic processing and semantic information using kernel methods. Two information sources are considered: (i) the whole sentence where the relation appears, and (ii) WordNet synsets and hypernymy relations of the candidate nominals. Each source of information is represented by kernel functions. In particular, five basic kernel functions are linearly combined and weighted under different conditions. The experiments were carried out using support vector machines as classifier. The system achieves an overall F1 of 71.8% on the Classification of Semantic Relations between Nominals task at SemEval-2007."
W06-2202,Simple Information Extraction ({SIE}): A Portable and Effective {IE} System,2006,17,5,2,0.833333,38355,claudio giuliano,Proceedings of the Workshop on Adaptive Text Extraction and Mining ({ATEM} 2006),0,None
E06-1051,Exploiting Shallow Linguistic Information for Relation Extraction from Biomedical Literature,2006,12,246,2,0.833333,38355,claudio giuliano,11th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We propose an approach for extracting relations between entities from biomedical literature based solely on shallow linguistic information. We use a combination of kernel functions to integrate two different information sources: (i) the whole sentence where the relation appears, and (ii) the local contexts around the interacting entities. We performed experiments on extracting gene and protein interactions from two different data sets. The results show that our approach outperforms most of the previous methods based on syntactic and semantic information."
E06-1052,Investigating a Generic Paraphrase-Based Approach for Relation Extraction,2006,14,77,5,0,45587,lorenza romano,11th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Unsupervised paraphrase acquisition has been an active research field in recent years, but its effective coverage and performance have rarely been evaluated. We propose a generic paraphrase-based approach for Relation Extraction (RE), aiming at a dual goal: obtaining an applicative evaluation scheme for paraphrase acquisition and obtaining a generic and largely unsupervised configuration for RE. We analyze the potential of our approach and evaluate an implemented prototype of it using an RE dataset. Our findings reveal a high potential for unsupervised paraphrase acquisition. We also identify the need for novel robust models for matching paraphrases in texts, which should address syntactic complexity and variability."
lavelli-etal-2002-sissa,{S}i{SSA}: An Infrastructure for Developing {NLP} Applications,2002,9,1,1,1,14633,alberto lavelli,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"In recent years there has been a growing interest in the commercial deployment of NLP technologies. This paper presents SiSSA, a project whose main aim is that of developing an infrastructure for prototyping, editing and validation of NLP application architectures. The system will provide the user with a graphical environment for (1) selecting the NLP activities relevant for the particular NLP task and the associated linguistic processors that execute them; (2) connecting new linguistic processors to SiSSA; (3) checking that the chosen architectural hypothesis corresponds to the functional specifications of the given application. The proposed infrastructure makes crucial use of state-of-the-art software technologies (CORBA, XML, RDF) to integrate different linguistic processors in an effective way. In the paper the definition of a metaformalism for the unification of different formalisms for grammar description is also briefly presented."
W01-1505,{S}i{SSA} - An Infrastructure for {NLP} Application Development,2001,4,1,1,1,14633,alberto lavelli,Proceedings of the {ACL} 2001 Workshop on Sharing Tools and Resources,0,"Recently there has been a growing interest in infrastructures for sharing NLP tools and resources. This paper presents SiSSA, a project that aims at developing an infrastructure for prototyping, editing and validation of NLP application architectures. The system will provide the user with a graphical environment for (1) selecting the NLP activities relevant for the particular NLP task and the associated linguistic processors that execute them; (2) connecting new linguistic processors to SiSSA; (3) checking that the chosen architectural hypothesis corresponds to the functional specifications of the given application.The TRACTOR philosophy is to accept deposits of resources in any format, and to distribute them in the form in which they are received (with small changes if possible such as additional documentation, and putting a browsable version or sample online.) In addition, certain standards are recommended and help is offered to providers who wish to make their resources conformant with the standards. This lack of standardisation is not simply a pragmatic measure in the face of problems of heterogeneity, but is based on a profound scepticism towards current resource standardisation practice. In the future, TRACTOR aims to build up particularly parallel corpora and tools for processing and extracting meaning from such resources."
2000.iwpt-1.31,Grammar Organization for Cascade-based Parsing in Information Extraction,2000,-1,-1,2,0.75,18107,fabio ciravegna,Proceedings of the Sixth International Workshop on Parsing Technologies,0,
E99-1014,Full Text Parsing using Cascades of Rules: an Information Extraction Perspective,1999,7,24,2,1,18107,fabio ciravegna,Ninth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"This paper proposes an approach to full parsing suitable for Information Extraction from texts. Sequences of cascades of rules deterministically analyze the text, building unambiguous structures. Initially basic chunks are analyzed; then argumental relations are recognized; finally modifier attachment is performed and the global parse tree is built. The approach was proven to work for three languages and different domains. It was implemented in the IE module of FACILE, a EU project for multilingual text classification and IE."
W97-1503,Participatory Design for Linguistic Engineering: the Case of the {GEPPETTO} Development Environment,1997,-1,-1,2,1,18107,fabio ciravegna,Computational Environments for Grammar Development and Linguistic Engineering,0,None
1997.iwpt-1.8,Controlling Bottom-Up Chart Parsers through Text Chunking,1997,-1,-1,2,1,18107,fabio ciravegna,Proceedings of the Fifth International Workshop on Parsing Technologies,0,"In this paper we propose to use text chunking for controlling a bottom-up parser. As it is well known, during analysis such parsers produce many constituents not contributing to the final solution(s). Most of these constituents are introduced due to t he parser inability of checking the input context around them. Preliminary text chunking allows to focus directly on the constituents that seem more likely and to prune the search space in the case some satisfactory solutions are found. Preliminary experiments show that a CYK-like parser controlled through chunking is definitely more efficient than a traditional parser without significantly losing in correctness. Moreover the quality of possible partial results produced by the controlled parser is high. The strategy is particularly suited for tasks like Information Extraction from text (IE) where sentences are often long and complex and it is very difficult to have a complete coverage. Hence, there is a strong necessity of focusing on the most likely solutions; furthermore, in IE the quality of partial results is important ."
1995.iwpt-1.18,On Parsing Control for Efficient Text Analysis,1995,-1,-1,2,1,18107,fabio ciravegna,Proceedings of the Fourth International Workshop on Parsing Technologies,0,
A92-1003,An Approach to Multilevel Semantics for Applied Systems,1992,20,9,1,1,14633,alberto lavelli,Third Conference on Applied Natural Language Processing,0,"Multilevel semantics has been proposed as a powerful architecture for semantic analysis. We propose a methodology that, while maintaining the generality of the multilevel approach, is able to establish formal constraints over the possible ways to organize the level hierarchy. More precisely, we propose a strong version of the multilevel approach in which a level can be defined if and only if it is possible to characterize a meaningfulness notion peculiar to that level. Within such an architecture each level reached during the analysis computes its meaningfulness value; this result is then handled according to modalities that are peculiar to that level.The component described in this paper was designed to be portable with respect to the application domain and so far has been tested as the semantic analysis component of two multimedial dialog systems, ALFresco and MAIA."
E91-1006,Bidirectional Parsing of {L}exicalized {T}ree {A}djoining {G}rammars,1991,10,17,1,1,14633,alberto lavelli,Fifth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In this paper a bidirectional parser for Lexicalized Tree Adjoining Grammars will be presented. The algorithm takes advantage of a peculiar characteristic of Lexicalized TAGs, i.e. that each elementary tree is associated with a lexical item, called its anchor. The algorithm employs a mixed strategy: it works bottom-up from the lexical anchors and then expands (partial) analyses making top-down predictions. Even if such an algorithm does not improve the worst-case time bounds of already known TAGs parsing methods, it could be relevant from the perspective of linguistic information processing, because it employs lexical information in a more direct way."
C90-3033,"When Something Is Missing: Ellipsis, Coordination and the Chart",1990,20,8,1,1,14633,alberto lavelli,{COLING} 1990 Volume 3: Papers presented to the 13th International Conference on Computational Linguistics,0,"This paper deals with two linguistic phenomena which are usually considered cases of ill-formedness by the computational linguistics community: intersentential ellipsis and coordination (possibly with gaps). We present an original solution, if compared to those already known for the two phenomena. This solution is conceived within a relevant approach to parsing, i.e. chart parsing, and is coherent with the basic ideas of this approach."
