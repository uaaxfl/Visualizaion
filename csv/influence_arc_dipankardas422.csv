2016.gwc-1.35,C04-1054,0,0.652071,"Missing"
2018.gwc-1.2,W98-1118,0,0.201476,"2.0 and the development 2 http://alexabe.pbworks.com/f/Dictionary+of+Medical+ Terms+4th+Ed.-+(Malestrom).pdf steps of WME 3.0; Section 5 discusses the validation process of the proposed lexicon; finally, Section 6 illustrates the concluding remarks and future scopes of the research. 2 Background Biomedical information extraction is treated as one of the challenging research tasks as it deals with available medical corpora that are either unstructured or semi-structured. Hence, a domainspecific lexicon becomes an essential component to convert a structured corpus from the unstructured corpus (Borthwick et al., 1998). Also, it helps in extracting the subjective and conceptual information related to medical concepts from the corpus. Various researchers have tried to build various ontologies and lexicons such as UMLS, SNOMED-CT (Systematized Nomenclature of Medicine-Clinical Terms), MWN (Medical WordNet), SentiHealth, and WordNet of Medical Events (WME 1.0 and WME 2.0) etc. in the domain of healthcare (Miller and Fellbaum, 1998; Smith and Fellbaum, 2004; Asghar et al., 2016; Asghar et al., 2014). UMLS helps to enhance the access to biomedical literature by facilitating the development of computer systems th"
2018.gwc-1.2,C16-1251,1,0.921398,"al., 2010a; Cambria et al., 2010b). However, medical text is in general unstructured since doctors do not like to fill forms and prefer free-form notes of their observations. Hence, a lexical design is difficult due to lack of any prior knowledge of medical terms and contexts. Therefore, we are motivated to enhance a medical lexicon namely WordNet of Medical Events (WME 2.0) which helps to identify medical concepts and their features. In order to enrich this lexicon, we have employed various well-known resources like conventional WordNet, SentiWordNet (Esuli and Sebastiani, 2006), SenticNet (Cambria et al., 2016), Bing Liu (Liu, 2012), and Taboada’s Adjective list (Taboada et al., 2011) and a preprocessed English medical dictionary1 on top of WME 1.0 and WME 2.0 lexicons (Mondal et al., 2015; Mondal et al., 2016). WME 1.0 contains 6415 number of medical concepts and their glosses, POS, polarity scores, and sentiment. Thereafter, Mondal et. al., (2016) enhanced WME 1.0 by adding few more features as affinity score, gravity score, and SSW to the medical concepts and presented as WME 2.0. The affinity and gravity scores present the hidden link between the pair of medical concepts and the concept with the"
2018.gwc-1.2,esuli-sebastiani-2006-sentiwordnet,0,0.45784,"non-experts such as patients (Cambria et al., 2010a; Cambria et al., 2010b). However, medical text is in general unstructured since doctors do not like to fill forms and prefer free-form notes of their observations. Hence, a lexical design is difficult due to lack of any prior knowledge of medical terms and contexts. Therefore, we are motivated to enhance a medical lexicon namely WordNet of Medical Events (WME 2.0) which helps to identify medical concepts and their features. In order to enrich this lexicon, we have employed various well-known resources like conventional WordNet, SentiWordNet (Esuli and Sebastiani, 2006), SenticNet (Cambria et al., 2016), Bing Liu (Liu, 2012), and Taboada’s Adjective list (Taboada et al., 2011) and a preprocessed English medical dictionary1 on top of WME 1.0 and WME 2.0 lexicons (Mondal et al., 2015; Mondal et al., 2016). WME 1.0 contains 6415 number of medical concepts and their glosses, POS, polarity scores, and sentiment. Thereafter, Mondal et. al., (2016) enhanced WME 1.0 by adding few more features as affinity score, gravity score, and SSW to the medical concepts and presented as WME 2.0. The affinity and gravity scores present the hidden link between the pair of medical"
2018.gwc-1.2,2016.gwc-1.35,1,0.918354,"fficult due to lack of any prior knowledge of medical terms and contexts. Therefore, we are motivated to enhance a medical lexicon namely WordNet of Medical Events (WME 2.0) which helps to identify medical concepts and their features. In order to enrich this lexicon, we have employed various well-known resources like conventional WordNet, SentiWordNet (Esuli and Sebastiani, 2006), SenticNet (Cambria et al., 2016), Bing Liu (Liu, 2012), and Taboada’s Adjective list (Taboada et al., 2011) and a preprocessed English medical dictionary1 on top of WME 1.0 and WME 2.0 lexicons (Mondal et al., 2015; Mondal et al., 2016). WME 1.0 contains 6415 number of medical concepts and their glosses, POS, polarity scores, and sentiment. Thereafter, Mondal et. al., (2016) enhanced WME 1.0 by adding few more features as affinity score, gravity score, and SSW to the medical concepts and presented as WME 2.0. The affinity and gravity scores present the hidden link between the pair of medical concepts and the concept with the various source of glosses respectively. SSW of a medical concept refers the similar sentiment words (SSW) which follow the common sentiment property. In the current research, we have focused on enriching"
2018.gwc-1.2,C04-1054,0,0.0643487,"unstructured or semi-structured. Hence, a domainspecific lexicon becomes an essential component to convert a structured corpus from the unstructured corpus (Borthwick et al., 1998). Also, it helps in extracting the subjective and conceptual information related to medical concepts from the corpus. Various researchers have tried to build various ontologies and lexicons such as UMLS, SNOMED-CT (Systematized Nomenclature of Medicine-Clinical Terms), MWN (Medical WordNet), SentiHealth, and WordNet of Medical Events (WME 1.0 and WME 2.0) etc. in the domain of healthcare (Miller and Fellbaum, 1998; Smith and Fellbaum, 2004; Asghar et al., 2016; Asghar et al., 2014). UMLS helps to enhance the access to biomedical literature by facilitating the development of computer systems that understand biomedical language (Bodenreider, 2004). SNOMED-CT is a standardized, multilingual vocabulary that contains clinical terminologies and assists in exchanging the electronic healthcare information among physicians (Donnelly, 2006). Furthermore, Fellbaum and Smith (2004) proposed Medical WordNet (MWN) with two subnetworks e.g., Medical FactNet (MFN) and Medical BeliefNet (MBN) for justifying the consumer health. The MWN follows"
2018.gwc-1.2,J11-2001,0,0.35707,"structured since doctors do not like to fill forms and prefer free-form notes of their observations. Hence, a lexical design is difficult due to lack of any prior knowledge of medical terms and contexts. Therefore, we are motivated to enhance a medical lexicon namely WordNet of Medical Events (WME 2.0) which helps to identify medical concepts and their features. In order to enrich this lexicon, we have employed various well-known resources like conventional WordNet, SentiWordNet (Esuli and Sebastiani, 2006), SenticNet (Cambria et al., 2016), Bing Liu (Liu, 2012), and Taboada’s Adjective list (Taboada et al., 2011) and a preprocessed English medical dictionary1 on top of WME 1.0 and WME 2.0 lexicons (Mondal et al., 2015; Mondal et al., 2016). WME 1.0 contains 6415 number of medical concepts and their glosses, POS, polarity scores, and sentiment. Thereafter, Mondal et. al., (2016) enhanced WME 1.0 by adding few more features as affinity score, gravity score, and SSW to the medical concepts and presented as WME 2.0. The affinity and gravity scores present the hidden link between the pair of medical concepts and the concept with the various source of glosses respectively. SSW of a medical concept refers th"
2019.icon-1.17,A92-1018,0,0.808522,"Missing"
2019.icon-1.17,P07-2056,0,0.0995736,"Missing"
2019.icon-1.17,J95-2001,0,0.515605,"Missing"
2019.icon-1.17,J88-1003,0,0.601832,"Missing"
2019.icon-1.17,J94-2001,0,0.783527,"Missing"
2019.icon-1.17,C90-3038,0,0.78336,"Missing"
2019.icon-1.17,W16-5804,0,0.0637624,"Missing"
2019.icon-1.17,H92-1022,0,0.736268,"Missing"
2019.icon-1.17,W16-5811,1,0.837745,"Missing"
2019.icon-1.17,N03-1028,0,0.481393,"Missing"
2020.icon-adapmt.1,W17-3204,0,0.0642154,"Missing"
2020.icon-adapmt.1,Q17-1026,0,0.0179153,"ed on the transformer architecture, and worked on the principle of APE. The description of the all the three systems and the training process for the same is given in Sections 3.1, 3.2 and 3.3 respectively. 3.1 Statistical Machine Translation For designing the model we followed some standard preprocessing steps on 2,50,480 sentence pairs, which are discussed below. 3.1.1 Moses 3.2 Neural Machine Translation In order to develop the NMT framework, we decided to employ a character-level neural machine translation system. The Character based NMT (CNMT) is based on the architecture as described in Lee et al. (2017) and it relies on the sequence-to-sequence (Sutskever et al., 2014) model. We opted for character embedding based NMT for this task because of the benefits it provides over word embedding based NMT. The benefits, as stated in Chung et al. (2016), are Preprocessing The following steps were applied to preprocess and clean the data before using it for training our Statistical machine translation model. We used the NLTK toolkit7 for performing the steps. • Tokenization: Given a character sequence and a defined document unit, tokenization is the task of chopping it up into pieces, called tokens. In"
2020.icon-adapmt.1,P02-1040,0,0.108574,"he second parallel corpus was used to tune the model. For this, we fed the SMT system with the English part of the second parallel corpus. In turn, the SMT model gave us the translation of these sentences as output. These outputs were then considered as source sentences to an NMT model and the Hindi part of the second parallel corpus was considered as the target. The architecture of the hybrid model is shown in Figure 3. 4 Evaluation For evaluation purposes, the organizers provided us with a test data of 507 sentences. Upon evaluation, the performance of our systems was calculated using BLEU (Papineni et al., 2002) metric and they are shown in Table 1. 5 6 Conclusion The present paper describes the systems submitted to the translation shared task organized by ICON 2020: 17th International Conference on Natural Language Processing. We participated in the English-Hindi translation task and the training data belonged to the general domain. Three systems, Discussion From Table 1, we can see that SMT performs very well when participating languages belong to a lowresourced setting (Banerjee et al., 2018; Koehn and 4 SMT, NMT, and a hybrid model was trained using these data. The models were pretty straightforw"
2020.icon-adapmt.1,Y18-3013,0,0.0226102,"Missing"
2020.icon-adapmt.1,P06-4018,0,0.0110992,"parallel corpora were provided by the organizers for training the translation systems. Among these, we decided on using the parallel corpus from CVIT-PIB2 and CVIT-MKB3 . Another high-quality corpus from TDIL4 was also used to train our developed systems. The number of parallel sentences in the CVIT-MKB dataset was 5,272, in the CVIT-PIB dataset were 1,95,208, and in the TDIL dataset were 50,000. In total, we were able to arrange for parallel English-Hindi corpora of 2,50,480 sentences. The data was then tokenized to be used for our further experiments. For tokenizing the English data, NLTK5 (Bird, 2006) was used and for tokenizing the Hindi data, Indic NLP Library6 (Kunchukuttan, 2020) was used. 3 • Cleaning: Long sentences (No. of tokens > 80) were removed. 3.1.2 Moses is a statistical machine translation system that allows you to automatically train translation models for any language pair when trained with a large collection of translated texts (parallel corpus). Once the model has been trained, an efficient search algorithm quickly finds the highest probability translation among the exponential number of choices. We trained Moses using 2,50,480 sentence pairs provided by the organizers,"
2020.icon-adapmt.1,P16-1160,0,0.0320307,"For designing the model we followed some standard preprocessing steps on 2,50,480 sentence pairs, which are discussed below. 3.1.1 Moses 3.2 Neural Machine Translation In order to develop the NMT framework, we decided to employ a character-level neural machine translation system. The Character based NMT (CNMT) is based on the architecture as described in Lee et al. (2017) and it relies on the sequence-to-sequence (Sutskever et al., 2014) model. We opted for character embedding based NMT for this task because of the benefits it provides over word embedding based NMT. The benefits, as stated in Chung et al. (2016), are Preprocessing The following steps were applied to preprocess and clean the data before using it for training our Statistical machine translation model. We used the NLTK toolkit7 for performing the steps. • Tokenization: Given a character sequence and a defined document unit, tokenization is the task of chopping it up into pieces, called tokens. In our case, these tokens were words, 2 http://preon.iiit.ac.in/ jerin/resources/datasets/pib v0.2.tar http://preon.iiit.ac.in/ jerin/resources/datasets/mkb-v0.tar 4 https://tdil.meity.gov.in/ 5 https://www.nltk.org/ 6 https://github.com/anoopkunc"
2020.icon-adapmt.1,W11-2123,0,0.0265724,"ences (No. of tokens > 80) were removed. 3.1.2 Moses is a statistical machine translation system that allows you to automatically train translation models for any language pair when trained with a large collection of translated texts (parallel corpus). Once the model has been trained, an efficient search algorithm quickly finds the highest probability translation among the exponential number of choices. We trained Moses using 2,50,480 sentence pairs provided by the organizers, with English as the source language and Hindi as the target language. For building the Language Model we used KenLM8 (Heafield, 2011) with 3-grams from the target corpus. Training the Moses statistical MT system resulted in the generation of the Phrase Model and Translation Model that helps in translating between source-target language pairs. Moses scores the phrase in the phrase table with respect to a given source sentence and produces the best-scored phrases as output. Machine Translation After the English-Hindi parallel corpora were compiled, we proceeded to develop our MT systems. As discussed earlier, the first two MT systems were based on SMT and NMT. The third MT system was a hybrid system, using both SMT and NMT, b"
2020.icon-adapmt.1,P07-2045,0,0.0203198,"the fourth spot in the competition leaderboard. 1 • SubTask 1 : To show sentence level Machine translation capability for on General domain. • SubTask 2 : To show sentence level Machine translation capability for on specified domains. We took part in the first sub-task and proceeded with developing translation systems with the help of the provided English-Hindi parallel corpus. Using the provided parallel corpus, we developed three systems. The first two systems was based on Statistical Machine Translation (SMT) and Neural Machine Translation (NMT). For training the SMT system, Moses Toolkit (Koehn et al., 2007) was used. The NMT system was a character based seq-to-seq model, that was trained using Bi-Directional Long Short-Term Memory (LSTM) cells (Hochreiter and Schmidhuber, 1997). The third system was a hybrid system, that works on the principles of Automated Post Editing (APE). In this model, a transformer (Vaswani et al., 2017) based NMT model was used to post edit the outputs, generated by an SMT based translation system. The rest of the paper is organized as follows. Section 2 describes the parallel corpus that was used to train the above-mentioned translation systems. Section 3 contains the d"
2020.semeval-1.171,S19-2088,1,0.827296,"word-level language tags were ENG (English), HIN (Hindi), and O (Other) for symbols, mentions, and hashtags. The organizers provided a trial and a training data set and after adding both, we could gather 17,000 code-mixed instances. We further divided this data into two parts; (i.) 15,000 instances as training data and (ii.) 2,000 instances as validation data. 3 Methodology Our approach included converting the given tweets into a sequence of words and then run the Grid Search Cross-Validation algorithm on the processed tweet. Initially, the tweets were pre-processed using methods as done by (Garain and Basu, 2019a) to remove the following: 1. 2. 3. 4. 5. Removing mentions Removing punctuation Removing URLs Contracting white space Extracting words from hashtags The last step consisted of taking advantage of the Pascal Casing of hashtags (e.g. #CoronaVirus). A simple regex can extract all words. This extraction results in better performance mainly because words in hashtags, to some extent, may convey sentiments of hate. They play an important role during the model-training stage. 3.1 Feature Extraction After obtaining clean tweets, various features were extracted by treating them as a sequence of words."
2020.semeval-1.171,S19-2133,1,0.826448,"word-level language tags were ENG (English), HIN (Hindi), and O (Other) for symbols, mentions, and hashtags. The organizers provided a trial and a training data set and after adding both, we could gather 17,000 code-mixed instances. We further divided this data into two parts; (i.) 15,000 instances as training data and (ii.) 2,000 instances as validation data. 3 Methodology Our approach included converting the given tweets into a sequence of words and then run the Grid Search Cross-Validation algorithm on the processed tweet. Initially, the tweets were pre-processed using methods as done by (Garain and Basu, 2019a) to remove the following: 1. 2. 3. 4. 5. Removing mentions Removing punctuation Removing URLs Contracting white space Extracting words from hashtags The last step consisted of taking advantage of the Pascal Casing of hashtags (e.g. #CoronaVirus). A simple regex can extract all words. This extraction results in better performance mainly because words in hashtags, to some extent, may convey sentiments of hate. They play an important role during the model-training stage. 3.1 Feature Extraction After obtaining clean tweets, various features were extracted by treating them as a sequence of words."
2020.semeval-1.171,2020.semeval-1.257,1,0.811032,"Missing"
2020.semeval-1.171,D14-1162,0,0.0827884,"Missing"
2020.semeval-1.171,C16-1234,0,0.0275238,"Missing"
2021.dravidianlangtech-1.4,2020.peoples-1.5,0,0.439296,"Missing"
2021.dravidianlangtech-1.4,2021.dravidianlangtech-1.17,0,0.0791384,"Missing"
2021.dravidianlangtech-1.4,2018.gwc-1.10,0,0.0237566,"Missing"
2021.dravidianlangtech-1.4,2021.ltedi-1.30,0,0.0366455,"Missing"
2021.dravidianlangtech-1.4,2020.peoples-1.6,0,0.0743382,"Missing"
2021.dravidianlangtech-1.4,2020.vardial-1.6,0,0.0540313,"Missing"
2021.dravidianlangtech-1.4,W14-5152,0,0.045565,"Missing"
2021.dravidianlangtech-1.4,2020.semeval-1.171,1,0.706796,"the Indian languages that are spoken by the majority of the population, like Hindi and Bengali, the same cannot be said for under-resourced languages such as, Tamil, Telugu, and Malayalam. For over 2600 years, recorded Tamil literature has been documented. Sangam literature, the earliest period of Tamil literature, is dated from around 600 BC- 300 AD. Among the Dravidian languages, Tamil has the oldest existing literature. Tamil is the oldest living language in India. Moreover, with the advent of social media, sentiment analysis research has become even more wide-spread (Mahata et al., 2020; Garain et al., 2020) as it takes into account conversations of customers around the social space and puts them into context. But, in the context of the Indian subcontinent, social media texts are not in one language and are largely code-mixed in nature. This is because India, has had much foreign acquaintance historically, and this has led the diaspora to adopt English as one of their official languages. Due to this, much of the Indian population are familiar with English as well as one or more regional languages (Mahata et al., 2019). This leads to communication in sentences, which contain more than one language"
2021.dravidianlangtech-1.4,2021.dravidianlangtech-1.30,0,0.0353618,"Missing"
2021.dravidianlangtech-1.4,voss-etal-2014-finding,0,0.0278001,"re developed using traditional ML algorithms.Finally, section 5 and 6 deals with the evaluation of our model and the concluding remarks. 2 these kinds of data are more or less always written in the Roman script, analyzing these kinds of data, with help of NLP tools, becomes even more difficult. Over the years, many experiments have been performed on code-mixed data. These include language identification, sentiment analysis, etc., to name a few. Language identification tasks have been earlier performed on various language pairs, such as Spanish-English (Negr´on Goldbarg, 2009), French-English (Voss et al., 2014), Hindi-English (Vyas et al., 2014; Das and Gamb¨ack, 2014) and Bengali-English (Das and Gamb¨ack, 2014). While these experiments were conducted with the help of dictionary word matching and ML-based algorithms such as Support Vector Machines (SVM), word-based logistic regression classifiers, and Latent Direchlet Allocation (LDA) (Blei et al., 2003), we use more state-of-the-art deep learning approaches to achieve the same. Also, sentiment analysis or opinion mining from code-mixed data is a trivial task because • Generally, code-mixed data is noisy in nature and requires cleaning and normaliz"
2021.dravidianlangtech-1.4,D14-1105,0,0.0327356,"lgorithms.Finally, section 5 and 6 deals with the evaluation of our model and the concluding remarks. 2 these kinds of data are more or less always written in the Roman script, analyzing these kinds of data, with help of NLP tools, becomes even more difficult. Over the years, many experiments have been performed on code-mixed data. These include language identification, sentiment analysis, etc., to name a few. Language identification tasks have been earlier performed on various language pairs, such as Spanish-English (Negr´on Goldbarg, 2009), French-English (Voss et al., 2014), Hindi-English (Vyas et al., 2014; Das and Gamb¨ack, 2014) and Bengali-English (Das and Gamb¨ack, 2014). While these experiments were conducted with the help of dictionary word matching and ML-based algorithms such as Support Vector Machines (SVM), word-based logistic regression classifiers, and Latent Direchlet Allocation (LDA) (Blei et al., 2003), we use more state-of-the-art deep learning approaches to achieve the same. Also, sentiment analysis or opinion mining from code-mixed data is a trivial task because • Generally, code-mixed data is noisy in nature and requires cleaning and normalization. • It needs several steps su"
2021.dravidianlangtech-1.4,2021.dravidianlangtech-1.16,0,0.0661037,"Missing"
2021.dravidianlangtech-1.4,2020.trac-1.6,0,0.0954703,"Missing"
C12-2090,H92-1023,0,0.0908623,"Missing"
C12-2090,A00-1031,0,0.223768,"Missing"
C12-2090,H92-1022,0,0.32804,"Missing"
C12-2090,J95-4004,0,0.130528,"Missing"
C12-2090,E09-1015,0,0.0402471,"Missing"
C12-2090,A92-1018,0,0.300951,"Missing"
C12-2090,P07-2056,0,0.0416637,"Missing"
C12-2090,O12-1029,1,0.841103,"ectively. KEYWORDS : Kokborok, POS Tagger, Suffix, Prefix, CRF, SVM, Morph analyser. Proceedings of COLING 2012: Posters, pages 923–932, COLING 2012, Mumbai, December 2012. 923 1 Introduction From the very beginning, POS tagging has been playing its significant roles in several Natural Language Processing (NLP) applications such as chunking, parsing, developing Information Extraction systems, semantic processing, Question Answering (QA), Summarization, Event Tracking etc. To the best of our knowledge, no prior work on POS tagging has been done for Kokborok except the development of a stemmer (Patra et al., 2012). Thus, in this paper, we have basically described the development of a POS tagger in Kokborok, a less privileged native language of the Borok people of Tripura, a state in North Eastern part of India. Kokborok is also spoken by neighboring states such as Assam, Manipur, Mizoram and the countries like Bangladesh, Myanmar etc. The language comprises of more than 2.5 millions of people1 and belongs to Tibeto-Burman (TB) language family. It has several unique features if compared with other South-Asian Tibeto-Burman languages. Kokborok literatures were written in Koloma or Swithaih borok script w"
C12-2090,W96-0213,0,0.378955,"Missing"
C12-2090,P06-2100,0,0.0347638,"Missing"
C12-2090,I08-3015,1,\N,Missing
C16-1186,baccianella-etal-2010-sentiwordnet,0,0.0252202,"Missing"
C16-1186,bakliwal-etal-2012-hindi,0,0.0291119,"ssed in the following subsections. Preprocessing: First we cleaned the lyrics dataset by removing the junk characters and HTML tags. Subsequently we removed the duplicate lines as it was observed that the starting stanza is usually repeated in the song at least a few times. Therefore, we removed these duplicate sentences to remove the biasness in the lyric. 3.2.1 Sentiment Lexicons (SL) The emotion or sentiment words are one of the most important features for mood classification from lyrics. These words in the Hindi lyrics were identified using three lexicons - Hindi Subjective Lexicon (HSL) (Bakliwal et al., 2012), Hindi SentiWordnet (HSW) (Joshi et al., 2010) and Hindi Wordnet Affect (HWA) (Das et al., 2012). Similarly, we used two lexicons - SentiWordNet (Baccianellaet al., 2010) (SWN) and WordNetAffect (Strapparava and Valitutti, 2004) (WA) for identifying the sentiment words from the lyrics of the Western songs. It was observed that the number of sentiment words found in the lyrics of Hindi songs was less than the number of sentiment words found in the lyrics of Western 1983 songs. The main reason was that the the performances of the POS tagger and stemmer/lemmatizer for Hindi language were not up"
C16-1186,W13-4104,1,0.740743,"songs. This paper is organized as follows: Section 2 introduces the mood taxonomy and describes the process of dataset preparation. Section 3 describes the audio and lyrics features. The FFNNs and the developed systems with comparison are described in the section 4. Finally, the conclusion is drawn in Section 5. 2 2.1 Mood Taxonomy and Dataset Mood Taxonomy We chose the Russell’s circumplex model (Russell, 1980) to build our own mood taxonomy. The circumplex model and a subset of this dimensional model have been used earlier for several mood classification studies (Ujlambkar and Attar, 2012; Patra et al., 2013a; Patra et al., 2013b; Patra et al., 2015c; Patra et al., 2016a; Patra et al., 2016b). The circumplex model is based on valence and arousal, which is widely accepted by the research community. Valence indicates the positivity and negativity of emotions whereas arousal indicates the emotional intensity. The mood taxonomy is prepared by clustering the similar affect words of the circumplex model into a single class and each class contains three affect words of the circumplex model as shown in Figure 1. Each of our mood classes has distinct positions in terms of arousal and valence. We considere"
C16-1186,W15-5939,1,0.57059,"nal License. http://creativecommons.org/licenses/by/4.0/ 1 https://www.cia.gov/library/publications/the-world-factbook/fields/2098.html License details: 1980 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 1980–1989, Osaka, Japan, December 11-17 2016. Figure 1: Russell’s circumplex model of 28 affect words (Russell, 1980) In order to deal with the above mentioned issues, the contributions of the authors are given below. 1. We employed our earlier proposed mood taxonomy for music mood classification in Hindi and Western songs (Patra et al., 2015c; Patra et al., 2016a; Patra et al., 2016b). 2. We annotated the audio and lyrics of the Hindi and Western songs using the above mood taxonomy. 3. We observed difference in mood while annotating the mood at the time of listening to the music and reading its corresponding lyric in case of the Hindi songs. 4. We identified important features using correlation based feature selection technique. 5. The Feed Forward Neural Networks (FFNNs) is implemented for mood classification purpose. 6. We have developed a multimodal system based on the audio and lyrics of the songs. This paper is organized as"
C16-1186,strapparava-valitutti-2004-wordnet,0,0.0392257,"a is usually repeated in the song at least a few times. Therefore, we removed these duplicate sentences to remove the biasness in the lyric. 3.2.1 Sentiment Lexicons (SL) The emotion or sentiment words are one of the most important features for mood classification from lyrics. These words in the Hindi lyrics were identified using three lexicons - Hindi Subjective Lexicon (HSL) (Bakliwal et al., 2012), Hindi SentiWordnet (HSW) (Joshi et al., 2010) and Hindi Wordnet Affect (HWA) (Das et al., 2012). Similarly, we used two lexicons - SentiWordNet (Baccianellaet al., 2010) (SWN) and WordNetAffect (Strapparava and Valitutti, 2004) (WA) for identifying the sentiment words from the lyrics of the Western songs. It was observed that the number of sentiment words found in the lyrics of Hindi songs was less than the number of sentiment words found in the lyrics of Western 1983 songs. The main reason was that the the performances of the POS tagger and stemmer/lemmatizer for Hindi language were not up to the mark. The CRF based Shallow Parser5 is available for POS tagging and lemmatization, but it also did not perform well on the lyrics data because of the free word order nature of Hindi language. Most of the inflected sentime"
I13-1078,W10-3208,1,0.846591,"on developing sentiment lexicon with three sentiment classes. For instance, Takamura et al. (2005) have developed a lexicon of emotion words tagged with the classes desirable and undesirable using Spin model. A number of other polarity sentiment lexicons are available in English such as SentiWordNet 3.0 (Esuli et al., 2010), Subjectivity Word List (Wilson et al., 2005), WordNet-Affect list (Strapparava et al., 2004), Taboada‟s adjective list (Taboada et al., 2006). On the other hand, several polarity sentiment lexicons have been developed in different languages like Hindi, Bengali and Telegu (Das and Bandyopadhyay, 2010), Japanese (Torii et al., 2012) etc. Among all these publicly available sentiment lexicons, SentiWordNet is one of the well-known and widely used ones (number of citations is higher than other resources 1 ), having been uti1 http://citeseerx.ist.psu.edu/index 674 International Joint Conference on Natural Language Processing, pages 674–679, Nagoya, Japan, 14-18 October 2013. lized in several applications such as sentiment analysis, opinion mining and emotion analysis. Undoubtedly, manual compilation is the best way to create such an emotion lexicon but is much expensive in terms of time and hum"
I13-1078,esuli-sebastiani-2006-sentiwordnet,0,0.13151,"Missing"
I13-1078,strapparava-valitutti-2004-wordnet,0,0.533599,"Missing"
I13-1078,P07-2034,0,0.0562995,"Missing"
I13-1078,P05-1017,1,0.957128,"ional classes like happy, sad, fear, anger, surprise and disgust. In the previous example, frequent appearance of words from the happy class in a blog document would imply that the writer of the comment is quite happy with the new rule proposed by the Government. Several works have been conducted on building emotional corpora in different languages such as in English (Aman and Szpakowicz, 2007), Chinese (Yang et al., 2007; Quan and Ren, 2010), and Bengali (Das and Bandyopadhyay, 2010) etc. All these works have focused on developing sentiment lexicon with three sentiment classes. For instance, Takamura et al. (2005) have developed a lexicon of emotion words tagged with the classes desirable and undesirable using Spin model. A number of other polarity sentiment lexicons are available in English such as SentiWordNet 3.0 (Esuli et al., 2010), Subjectivity Word List (Wilson et al., 2005), WordNet-Affect list (Strapparava et al., 2004), Taboada‟s adjective list (Taboada et al., 2006). On the other hand, several polarity sentiment lexicons have been developed in different languages like Hindi, Bengali and Telegu (Das and Bandyopadhyay, 2010), Japanese (Torii et al., 2012) etc. Among all these publicly availabl"
I13-1078,N07-1037,1,0.824129,"ives if the adjectives appear in a conjunctive form in the corpus. If the adjectives are connected by “and”, the link belongs to SL. If they are connected by “but”, the link belongs to DL. We call this network the gloss-thesaurus-corpus network (GTC). We have used gloss-thesauruscorpus network in our experiments. ferent values of β. Then the accuracies were computed manually as well as using the WordNet Affect lexicon. We also classified the words into two classes, i.e. positive and negative. The accuracies of two classes were calculated using the SentiWordNet. 4.2 5.1 Classification of Words Takamura et al., (2007) used the Potts model for extracting semantic orientation of phrases (pair of adjective and a noun): positive, negative or neutral. In contrast to that, we have used the Potts model for identifying the emotional class (es) of a word. We have used one seed word from each class to start with the experiment. Each seed word is assigned a class manually. We therefore estimate the state of nodes in the lexical network for each class of emotions. The only drawback is that, it could not assign any emotional class to a word which is not present in the lexical network. These words may be referred to as"
I13-1078,J11-2001,0,0.100786,"Missing"
I13-1078,baccianella-etal-2010-sentiwordnet,0,0.423122,"Missing"
I13-1078,H05-1044,0,0.0227693,"ks have been conducted on building emotional corpora in different languages such as in English (Aman and Szpakowicz, 2007), Chinese (Yang et al., 2007; Quan and Ren, 2010), and Bengali (Das and Bandyopadhyay, 2010) etc. All these works have focused on developing sentiment lexicon with three sentiment classes. For instance, Takamura et al. (2005) have developed a lexicon of emotion words tagged with the classes desirable and undesirable using Spin model. A number of other polarity sentiment lexicons are available in English such as SentiWordNet 3.0 (Esuli et al., 2010), Subjectivity Word List (Wilson et al., 2005), WordNet-Affect list (Strapparava et al., 2004), Taboada‟s adjective list (Taboada et al., 2006). On the other hand, several polarity sentiment lexicons have been developed in different languages like Hindi, Bengali and Telegu (Das and Bandyopadhyay, 2010), Japanese (Torii et al., 2012) etc. Among all these publicly available sentiment lexicons, SentiWordNet is one of the well-known and widely used ones (number of citations is higher than other resources 1 ), having been uti1 http://citeseerx.ist.psu.edu/index 674 International Joint Conference on Natural Language Processing, pages 674–679, N"
I13-1078,P97-1023,0,0.0600689,"ork is shown in Table 1. Next, we assign weights W = (wij) to links as follows: By minimizing F(n) under the condition that ( ) ,∑ , we obtain the following fixed point equation for : ( ) Potts Model for Construction of Emotional Lexicon No. of words 20497 3751 55285 8482 Table 1. Statistics of Lexical network We have also constructed another network, the gloss thesaurus network (GT), by linking syno676 nyms, antonyms and hypernyms, in addition to the above linked words. Only antonym links are in DL. We enhanced the gloss-thesaurus network with co-occurrence information extracted from corpus. Hatzivassiloglou and McKeown (1997) focused on conjunctive expressions such as “simple and well-received” and “simplistic but well-received”, where the former pair of words tend to have the same semantic orientation, and the latter tend to have the opposite orientation. Following their method, we connect two adjectives if the adjectives appear in a conjunctive form in the corpus. If the adjectives are connected by “and”, the link belongs to SL. If they are connected by “but”, the link belongs to DL. We call this network the gloss-thesaurus-corpus network (GTC). We have used gloss-thesauruscorpus network in our experiments. fere"
I13-1078,W11-1710,1,0.822398,"Missing"
I13-1078,taboada-etal-2006-methods,0,\N,Missing
I17-4023,C16-1251,0,0.0161755,"SentiWordNet 3 and SenticNet 4 reSubtasks Description and Feature Extraction Subtask-A: Subtask-A aims to produce a ranked list of k reviews based on its predicted usefulness while simultaneously trying to reduce the redundancy among the ranked list. In the given data, the usefulness rating feature is a user-collected field. We have observed from the development and training datasets that certain 2 www.nltk.org/ http://sentiwordnet.isti.cnr.it/s 4 http://sentic.net/ 3 139 The following section describes the overall evaluation process for all the subtasks. sources (Esuli and Sebastiani, 2006; Cambria et al., 2016). For example, the following review has been labeled with the sentiment features such as number of sentiment words (6), number of negations (2), number of positive words (5), and number of negative words (1). ”It arrived quickly, looks sturdy and doesn’t take too much room in the trunk, but I haven’t needed it yet, so only 4 stars.” 2.3 3 Evaluation In order to evaluate the output of the proposed modules as top-k reviews from the given reviews set for all three subtasks, we have taken help of the organizers provided evaluation metrics (Singh et al., a). The metrics are presented for all the th"
I17-4023,esuli-sebastiani-2006-sentiwordnet,0,0.0711958,"es have been extracted using SentiWordNet 3 and SenticNet 4 reSubtasks Description and Feature Extraction Subtask-A: Subtask-A aims to produce a ranked list of k reviews based on its predicted usefulness while simultaneously trying to reduce the redundancy among the ranked list. In the given data, the usefulness rating feature is a user-collected field. We have observed from the development and training datasets that certain 2 www.nltk.org/ http://sentiwordnet.isti.cnr.it/s 4 http://sentic.net/ 3 139 The following section describes the overall evaluation process for all the subtasks. sources (Esuli and Sebastiani, 2006; Cambria et al., 2016). For example, the following review has been labeled with the sentiment features such as number of sentiment words (6), number of negations (2), number of positive words (5), and number of negative words (1). ”It arrived quickly, looks sturdy and doesn’t take too much room in the trunk, but I haven’t needed it yet, so only 4 stars.” 2.3 3 Evaluation In order to evaluate the output of the proposed modules as top-k reviews from the given reviews set for all three subtasks, we have taken help of the organizers provided evaluation metrics (Singh et al., a). The metrics are p"
I17-4023,I17-4003,0,0.0654236,"Missing"
I17-4030,D14-1181,0,0.00496315,"Missing"
O10-2008,A00-2004,0,0.226136,"ons among words in a sentence. The current trend in the emotion analysis area is exploring machine learning techniques [28], which consider the problem as text categorization or analogous to topic classification that underscores the difference between machine learning methods and human-produced baseline models [29]. Affective text shared task on news headlines at SemEval 2007 for emotion and valence level identification [20] has drawn the focus to this field. Prior work in identification of opinion holders has sometimes identified only a single opinion per sentence [30], and sometimes several [1]. Identification of opinion holders for Question Answering with supporting annotation task was attempted in the very beginning [17]. Before that, another work on labeling the arguments of the verbs with their semantic roles using a novel frame matching technique was carried out in [31]. Based on the traditional perspectives, another work discussed in [35] uses an emotion knowledge base for extracting emotion holder. The machine learning based classification task for “not holder”, “weak holder”, “medium holder”, or “strong holder” is described in [34]. Kim and Hovy [11] identified opinion holde"
O10-2008,P09-2038,1,0.870621,"said that he was remembering this beautiful comic while reading your poem. Emotional Expression: সুnর েকৗতুক (beautiful comic), Holder: Topic: কিবতা (poem) < writer, রােশদ (Rashed) &gt;, The information of emotion is useful for the domain of Question Answering (QA), Information Retrieval (IR), product reviews, social media, stock markets, and customer relationship management. Especially, the blog posts contain instant views, updated views or influenced views regarding single or multiple topics. Blogs are the communicative and informative repository of text based emotional contents in the Web 2.0 [2]. Researches on emotion show that blogs play the role of a substrate to analyze the reactions of different emotional enzymes. Many blogs act as online diary of the blogger reporting on the blogger’s daily activities and surroundings. Sometimes, blog posts are annotated by other bloggers. Large blog data set is also suitable for machine learning models. Thus the present task deals with the identification of users’ emotion on different topics from a Bengali blog corpus [7]. Each sentence of the Bengali blog corpus is annotated with the emotional components such as emotional expression (word/phra"
O10-2008,W10-3207,1,0.792524,"e or multiple topics. Blogs are the communicative and informative repository of text based emotional contents in the Web 2.0 [2]. Researches on emotion show that blogs play the role of a substrate to analyze the reactions of different emotional enzymes. Many blogs act as online diary of the blogger reporting on the blogger’s daily activities and surroundings. Sometimes, blog posts are annotated by other bloggers. Large blog data set is also suitable for machine learning models. Thus the present task deals with the identification of users’ emotion on different topics from a Bengali blog corpus [7]. Each sentence of the Bengali blog corpus is annotated with the emotional components such as emotional expression (word/phrase), intensity, associated holder and topic(s). Ekman’s six emotion classes (anger, disgust, fear, happy, sad and surprise) along with three types of intensities (high, general and low) are annotated at sentence level. The 3367 sentences with respect to eight different potential topics along with 22 different blog users are considered for conducting the present task. The emotion topic annotated in each of the sentences is directly linked with the topic of the document th"
O10-2008,esuli-sebastiani-2006-sentiwordnet,0,0.0117151,"e pre-processed to build up a general list that contains all member verbs and their available syntactic frames with holder and topic related thematic information (e.g. Experiencer, Agent, Actor, Beneficiary and Topic, Theme, Event etc.). The pre-processed list is searched to acquire the syntactic frames of each verb. Semantic Features Emotion/Affect Words (EW): The presence of a word in the WordNet Affect lists [6] identifies the emotion/affect words. Intensifiers (INTF): The Bengali SentiWordNet is being developed by replacing each word entry in the synonymous set of the English SentiWordNet [9] by its possible set of Bengali 357 synsets using a synset based English to Bengali bilingual dictionary being developed as part of the EILMT project5. The chunks containing JJ (adjective) and RB (adverb) tagged elements are considered as intensifiers. If the intensifier is found in the SentiWordNet, then the positive and negative scores of the intensifier are retrieved from the SentiWordNet. The intensifier is classified into the list of positive (pos) (INTFpos) or negative (neg) (INTFneg) for which the average retrieved score is higher. Multiword Expressions: Reduplication (সn সn sanda sanda"
O10-2008,W06-0301,0,0.114255,"In psychology and common use, emotion is an aspect of a person&apos;s mental state of being, normally based in or tied to the person’s internal (physical) and external (social) sensory feeling [21]. The source or holder of an emotional expression is the speaker or writer or experiencer [17]. Extraction of emotion holder is important for discriminating between emotions that are viewed from different perspectives [22]. By grouping opinion holders of different stance on diverse social and political issues, we can a have better understanding of the relationships among countries or among organizations [11]. Topic is the real world object, event, or abstract entity that is the primary subject of the emotion or opinion as intended by the holder and the topic depends on the context in which its associated emotional expression occurs [15]. The following Bengali sentence shows the emotional expression, its associated holder and topic. As the sentence is collected from a blog post, the writer is also considered as a default holder [17]. Example 1: 350 Proceedings of the 22nd Conference on Computational Linguistics and Speech Processing (ROCLING 2010), Pages 350-363, Puli, Nantou,Taiwan, September 201"
O10-2008,stoyanov-cardie-2008-annotating,0,0.201407,"xpression is the speaker or writer or experiencer [17]. Extraction of emotion holder is important for discriminating between emotions that are viewed from different perspectives [22]. By grouping opinion holders of different stance on diverse social and political issues, we can a have better understanding of the relationships among countries or among organizations [11]. Topic is the real world object, event, or abstract entity that is the primary subject of the emotion or opinion as intended by the holder and the topic depends on the context in which its associated emotional expression occurs [15]. The following Bengali sentence shows the emotional expression, its associated holder and topic. As the sentence is collected from a blog post, the writer is also considered as a default holder [17]. Example 1: 350 Proceedings of the 22nd Conference on Computational Linguistics and Speech Processing (ROCLING 2010), Pages 350-363, Puli, Nantou,Taiwan, September 2010. রােশদ বেলেছন আপনার কিবতাটা পড়েত িগেয় (Rashed) (bolechen) (apnar) (kobitata) (porte) (giye) তার ei সুnর েকৗতুকটা মেন পড়িছেলা। (tar) (ei) (sundar) (koutukta) (mone) (porchilo). Rashed said that he was remembering this beautiful comi"
O10-2008,C08-1103,0,0.0638536,"hallow chunked portions formed by removing emotional expressions and holders are identified as the responsible spans that contain one or more potential emotion topics. The words of the shallow chunks containing POS tags of NNP or NNC are allowed to include as emotion topics. User-Topic Coreference: The identified holders and topics associated with an emotional expression in each of the sentences are coreferent if they share the same emotional expression. The emotion topic is intended by the emotion holder and the topic depends on the context in which its associated emotional expression occurs [16]. Based on the hypothesis, a rule based unsupervised technique is devised to identify the coreference between user and topic with Fi 1 Th D it respect to a particular type of emotional expression if the chunks responsible for emotion holder or topic are the immediate neighboring chunks of the emotional expression. [4. Supervised Framework] Topic coreference resolution resembles another well-known problem in NLP - noun phrase (NP) coreference resolution that considers machine learning frameworks [26] [27]. Therefore, we adapt a standard machine learning based approach to user-topic coreference"
O10-2008,P07-2034,0,0.068903,"Missing"
O10-2008,passonneau-2004-computing,0,0.0281459,"les and problems in mind, we hypothesize that the notion of user-topic coreference will facilitate both the manual and automatic identification of emotional views: Two components of emotion such as holders and topics are emotion coreferent if they share the same emotional expressions. The baseline system extracts the emotional expressions using Bengali WordNet Affect lists [6]. An unsupervised system is developed for identifying emotion holders and topics with respect to the emotional expressions. The co reference of the emotion topics and emotion holders is measured using Passonneau’s (2004) [24] generalization of Krippendorff’s (1980) [25] α metric. On the other hand, The Support Vector Machine [10] based supervised classifier is employed for coreference classification. Each of the input vectors containing emotional expression, associated holder and topic is prepared from each of the annotated Bengali blog sentences. The feature vector is prepared based on the information present in the sentences containing lexical, syntactic, semantic, rhetoric and overlapping features (word, part-of speech (POS), Named Entity (NE)). Training with 2234 sentences, the feature analysis has been conduc"
O10-2008,P02-1014,0,0.0207741,"holder and the topic depends on the context in which its associated emotional expression occurs [16]. Based on the hypothesis, a rule based unsupervised technique is devised to identify the coreference between user and topic with Fi 1 Th D it respect to a particular type of emotional expression if the chunks responsible for emotion holder or topic are the immediate neighboring chunks of the emotional expression. [4. Supervised Framework] Topic coreference resolution resembles another well-known problem in NLP - noun phrase (NP) coreference resolution that considers machine learning frameworks [26] [27]. Therefore, we adapt a standard machine learning based approach to user-topic coreference resolution. The Support Vector Machine (SVM) [10] based supervised framework has been used to extract the input vectors that contain emotional expressions, users or holders and topics. The system is trained with 2234 sentences. The best feature set is identified using the 630 development sentences. The Information Gain Based Pruning (IGBP), Admissible Tag Sequence (ATS), Class Splitting technique and Emotional Composition features are applied 354 on the development set and it improves the performanc"
O10-2008,J01-4004,0,0.0819284,"r and the topic depends on the context in which its associated emotional expression occurs [16]. Based on the hypothesis, a rule based unsupervised technique is devised to identify the coreference between user and topic with Fi 1 Th D it respect to a particular type of emotional expression if the chunks responsible for emotion holder or topic are the immediate neighboring chunks of the emotional expression. [4. Supervised Framework] Topic coreference resolution resembles another well-known problem in NLP - noun phrase (NP) coreference resolution that considers machine learning frameworks [26] [27]. Therefore, we adapt a standard machine learning based approach to user-topic coreference resolution. The Support Vector Machine (SVM) [10] based supervised framework has been used to extract the input vectors that contain emotional expressions, users or holders and topics. The system is trained with 2234 sentences. The best feature set is identified using the 630 development sentences. The Information Gain Based Pruning (IGBP), Admissible Tag Sequence (ATS), Class Splitting technique and Emotional Composition features are applied 354 on the development set and it improves the performance of"
O10-2008,H05-1073,0,0.0272984,"sms are specified in Section 5. Finally Section 6 concludes the paper. [2. Related Work] In order to estimate affects in text, the model proposed in [19] processes symbolic cues and employs natural language processing techniques for word/phrase/sentence level analysis, considering relations among words in a sentence. The current trend in the emotion analysis area is exploring machine learning techniques [28], which consider the problem as text categorization or analogous to topic classification that underscores the difference between machine learning methods and human-produced baseline models [29]. Affective text shared task on news headlines at SemEval 2007 for emotion and valence level identification [20] has drawn the focus to this field. Prior work in identification of opinion holders has sometimes identified only a single opinion per sentence [30], and sometimes several [1]. Identification of opinion holders for Question Answering with supporting annotation task was attempted in the very beginning [17]. Before that, another work on labeling the arguments of the verbs with their semantic roles using a novel frame matching technique was carried out in [31]. Based on the traditional"
O10-2008,W09-3411,1,0.92493,"corresponding dictionary forms of 374 Bengali verbs containing simple and light verb entries. The dictionary forms of the Bengali compound or conjunct verbs are made by 355 incorporating the dictionary forms of the light verbs with their preceding noun words that are tagged as ‘NN’ present in the retrieved lexical patterns. English Equivalent Synset Identification: The determination of equivalent English verbs of a Bengali verb is carried out using a Bengali to English bilingual dictionary4. The method to extract the English equivalent synsets of the Bengali verbs is based on the work done in [32]. We have identified the equivalent English verb synsets of the Bengali verb entries that are present in the dictionary. For example, the dictionary entries for simple verb ভােলাবাসা bhalobasa ‘love’ and conjunct verb আনn ananda করা kara ‘enjoy’ are as follows. < ভােলাবাসা [bhālōbāsā] v to love, to be amorous to wards; to like; to have attachment or affection, fondness for …&gt; < আনn করা v. to rejoice; to make merry.…&gt; Different synonyms for a Bengali verb having the same sense are separated using “,” and different senses are separated using “;” in the dictionary. The synonyms including similar"
O10-2008,H05-1043,0,0.0129919,"ask for “not holder”, “weak holder”, “medium holder”, or “strong holder” is described in [34]. Kim and Hovy [11] identified opinion holder with topic from media text using semantic role labeling. An anaphor resolution based opinion holder identification method exploiting lexical and syntactic information from online news documents was attempted in [36]. The syntactic models of identifying emotion holder for English emotional verbs are developed in [5]. In the related area of opinion topic extraction, different researchers contributed their efforts. Some of the works are mentioned in [13] [18] [37]. But, all these works are based on lexicon look up and are applied on the domain of product reviews. The topic annotation task on the MPQA corpus is described in [15]. The authors have pointed out that the target spans alone are insufficient for many applications as they neither contain information indicating which opinions are about the same topic, nor provide a concise textual representation of the topics. The method of identifying an opinion with its holder and topic from online news is described in [11]. The model extracts opinion topics for subjective expressions signaled by verbs and ad"
O10-2008,H05-2017,0,\N,Missing
O10-2008,S07-1013,0,\N,Missing
O12-1029,E09-1015,0,0.312967,"Missing"
O12-1029,I08-3012,1,0.899222,"Missing"
O13-2004,W09-3411,1,0.892196,"Missing"
O13-2004,H05-1045,0,0.0811028,"Missing"
O13-2004,P09-2038,1,0.882947,"Missing"
O13-2004,esuli-sebastiani-2006-sentiwordnet,0,0.0958314,"Missing"
O13-2004,W06-0301,0,0.0692385,"Missing"
O13-2004,P02-1014,0,0.227546,"Missing"
O13-2004,H05-1043,0,0.169323,"Missing"
O13-2004,J01-4004,0,0.0884919,"Missing"
O13-2004,stoyanov-cardie-2008-annotating,0,0.0394572,"Missing"
O13-2004,C08-1103,0,0.0464725,"Missing"
P09-2038,esuli-sebastiani-2006-sentiwordnet,0,0.0368184,"Missing"
P09-2038,H05-1073,0,0.40079,"Missing"
P09-2038,S07-1013,0,\N,Missing
P09-2038,P07-2034,0,\N,Missing
S10-1045,de-marneffe-etal-2006-generating,0,0.0564326,"Missing"
S10-1045,W09-2415,0,\N,Missing
S14-2063,N07-1038,0,0.0348543,"ed on topic modelling, that use Latent Dirichlet Allocation (LDA) (Brody and Elhadad, 2010). But, the standard Latent Dirichlet Allocation (LDA) is not exactly suitable for the task of aspect detection due to their inherent nature of capturing global topics in the data, rather than finding local aspects related to the predefined entity. This approach was further modified in Sentence-LDA (SLDA) and Aspect and Sentiment Unification Model (ASUM) (Jo and Oh, 2011). Similarly, the identification of focussed text spans for opinion topics and targets were identified in (Das and Bandyopadhyay, 2010). Snyder and Barzilay (2007) addressed the problem of identifying categories for multiple related aspect terms appeared in the text. For instance, in a restaurant review, such categories may include food, ambience and service etc. In our task, we call them as aspect or review categories. The authors implemented the Good Grief decoding algorithm on a corpus collected on restaurant review4, which outperforms over the famous PRank algorithm (Crammer and Singer, 2001). Ganu et al., (2009) have classified the restaurant reviews collected from City search New York5 into six categories namely Food, Service, Price, Ambience, Ane"
S14-2063,I13-1078,1,0.851195,"ciated with each category has also been identified and both the experiments were carried out using Support Vector Machine classifiers. Finally, they implemented the regression based model containing MATLAB regression 4 5 function (mvregress) to give rating (1 to 5) to each review. To determine the sentiment or polarity of the aspect term and aspect category, we need a prior sentiment annotated lexicon. Several works have been conducted on building emotional corpora in different English languages such as SentiWordNet (Baccianella et al., 2010), WordNet Affect (Strapparava and Valitutti, 2004) (Patra et al., 2013) etc. Among all these publicly available sentiment lexicons, SentiWordNet is one of the well-known and widely used ones (number of citations is higher than other resources6) that has been utilized in several applications such as sentiment analysis, opinion mining and emotion analysis. Several works have been performed on the automated opinion detection or polarity identification from reviews (Yu and Hatzivassiloglou, 2003; Hu and Liu, 2004). Yu and Hatzivassiloglou (2003) has focused on characterizing opinions and facts in a generic manner, without examining who the opinion holder is or what t"
S14-2063,H05-1043,0,0.0610235,"en observed that most of the previous works on aspect detection were based on information extraction, to find the most frequent noun phrases (Hu and Liu, 2004). This approach is generally useful in finding aspects which are strongly associated with a single noun. But, one principal disadvantage of this approach is that it cannot detect the aspect terms which are of low frequency and noun phrases (e.g., different names of dishes like Biryani, Dosa and Uttapam etc. for the aspect category, “food”). The proposed work of such problem involves semantic hierarchy, rule-based or combination of both (Popescu and Etzioni 2005). More recent approaches of aspect detection are based on topic modelling, that use Latent Dirichlet Allocation (LDA) (Brody and Elhadad, 2010). But, the standard Latent Dirichlet Allocation (LDA) is not exactly suitable for the task of aspect detection due to their inherent nature of capturing global topics in the data, rather than finding local aspects related to the predefined entity. This approach was further modified in Sentence-LDA (SLDA) and Aspect and Sentiment Unification Model (ASUM) (Jo and Oh, 2011). Similarly, the identification of focussed text spans for opinion topics and target"
S14-2063,N10-1122,0,0.365362,"and Liu, 2004). This approach is generally useful in finding aspects which are strongly associated with a single noun. But, one principal disadvantage of this approach is that it cannot detect the aspect terms which are of low frequency and noun phrases (e.g., different names of dishes like Biryani, Dosa and Uttapam etc. for the aspect category, “food”). The proposed work of such problem involves semantic hierarchy, rule-based or combination of both (Popescu and Etzioni 2005). More recent approaches of aspect detection are based on topic modelling, that use Latent Dirichlet Allocation (LDA) (Brody and Elhadad, 2010). But, the standard Latent Dirichlet Allocation (LDA) is not exactly suitable for the task of aspect detection due to their inherent nature of capturing global topics in the data, rather than finding local aspects related to the predefined entity. This approach was further modified in Sentence-LDA (SLDA) and Aspect and Sentiment Unification Model (ASUM) (Jo and Oh, 2011). Similarly, the identification of focussed text spans for opinion topics and targets were identified in (Das and Bandyopadhyay, 2010). Snyder and Barzilay (2007) addressed the problem of identifying categories for multiple rel"
S14-2063,W06-0301,0,0.112082,"Missing"
S14-2063,strapparava-valitutti-2004-wordnet,0,0.264056,"Missing"
S14-2063,baccianella-etal-2010-sentiwordnet,0,0.0535732,"Food, Service, Price, Ambience, Anecdotes, and Miscellaneous. Sentiment associated with each category has also been identified and both the experiments were carried out using Support Vector Machine classifiers. Finally, they implemented the regression based model containing MATLAB regression 4 5 function (mvregress) to give rating (1 to 5) to each review. To determine the sentiment or polarity of the aspect term and aspect category, we need a prior sentiment annotated lexicon. Several works have been conducted on building emotional corpora in different English languages such as SentiWordNet (Baccianella et al., 2010), WordNet Affect (Strapparava and Valitutti, 2004) (Patra et al., 2013) etc. Among all these publicly available sentiment lexicons, SentiWordNet is one of the well-known and widely used ones (number of citations is higher than other resources6) that has been utilized in several applications such as sentiment analysis, opinion mining and emotion analysis. Several works have been performed on the automated opinion detection or polarity identification from reviews (Yu and Hatzivassiloglou, 2003; Hu and Liu, 2004). Yu and Hatzivassiloglou (2003) has focused on characterizing opinions and facts in"
S14-2063,W03-1017,0,0.118729,"orks have been conducted on building emotional corpora in different English languages such as SentiWordNet (Baccianella et al., 2010), WordNet Affect (Strapparava and Valitutti, 2004) (Patra et al., 2013) etc. Among all these publicly available sentiment lexicons, SentiWordNet is one of the well-known and widely used ones (number of citations is higher than other resources6) that has been utilized in several applications such as sentiment analysis, opinion mining and emotion analysis. Several works have been performed on the automated opinion detection or polarity identification from reviews (Yu and Hatzivassiloglou, 2003; Hu and Liu, 2004). Yu and Hatzivassiloglou (2003) has focused on characterizing opinions and facts in a generic manner, without examining who the opinion holder is or what the opinion is about. Then, they have identified the polarity or sentiment of the fact using Naive Bayes classifier. Hu and Liu, (2004) has summarized the customer review and then identified the sentiment of that review. They have achieved promising accuracy in case of identifying polarity of the reviews. 3 Data The sentences collected from the customer reviews of Restaurants and Laptops are used in these tasks. The traini"
S14-2063,S14-2004,0,0.0342398,"011). For example, in case of Laptop reviews, “touchpad” is considered an aspect. Similarly, given a predefined entity, an aspect term describes a specific aspect of that entity (e.g., for the entity “restaurant”, “wine” can be an aspect term). Aspect term can be appeared as a single word (e.g., “menu”) or multiple words (“side dish”). It is observed that for a particular entity, one or more number of aspect terms can be grouped into a single category (e.g., aspect terms “drinks”, “main course” belongs to the same category, “food”). The main goal of the Aspect Based Sentiment Analysis (ABSA) (Pontiki et al., 2014) task is to identify the aspect terms and their categories from the given target entities as well as to identify the sentiments expressed towards each of the aspect terms. The datasets provided by the shared task organizers consist of customer reviews with human-annotations. We have participated in all of the four tasks. A combination of Conditional Random Field (CRF) based machine learning algorithm and rule based techniques has been adopted for identifying the aspect term, aspect category and their sentiments. We have used several features like Part of Speech (POS), Stanford dependency relat"
S14-2063,H05-2017,0,\N,Missing
S16-1071,W11-1701,0,0.292205,"Missing"
S16-1071,baccianella-etal-2010-sentiwordnet,0,0.0568222,"“#HillaryClinton” in the topic bag “Hillary”. Further, we checked the topic bags manually and removed some unrelated words collected using the WordNet. The detailed word level statistics of the topic bags are given in Table 1. At first, we checked that whether a tweet contains any word from the corresponding target related topic bag or not. If no word is present, then we tagged that tweet as ‘NONE’ and no further processing is performed on that tweet. Further, this topic bags are used along with the dependency information. 3.1.2 Sentiment Words We have used three lexicons namely SentiWordNet (Baccianella et al., 2010), NRC Emotion Lexicon (Mohammad and Turney, 2013), and NRC Hashtag Emotion Lexicon (Mohammad, 2012) for our experiments along with manually created lexicons for each of the targets. Moreover, two bags were created for each of the targets namely ‘favor’ and ‘against’ bags. Hashtags are also included in the above lexicons. The word level statistics of the ‘favor’ and ‘against’ bags are given in Table 1. We used the frequency of the sentiment words matched with the above sentiment or emotion lexicons as features. Again, we used these lexicons in the later experiments also. 2 https://rednoise.org/"
S16-1071,I13-1191,0,0.0181398,"outlook towards specific targets and propositions rather than simply considering whether the speaker is angry or happy (Mohammad et al., 2016). Stance detection even becomes more difficult when it is performed on the short texts like tweets. The latter being an important sub-field of sentiment analysis/opinion mining. Automatic stance detection can be used in several applications such as information retrieval, text summarization, and textual entailment. More recent approaches to stance detection have been performed using linguistic rules on online debate dataset (Somasundaran and Wiebe, 2009; Hasan and Ng, 2013; Sridhar et al., 2014) and NPOV Corpus from Wikipedia (Recasens et al., 2013). To the best of our knowledge, not much computational attempts have been performed on tweets for stance detection. It is also observed that both the supervised and unsupervised machine learning algorithms have been implemented for identifying the stance and several features like n-gram, frame semantic features, and dependency were used in stance detection tasks (Somasundaran and Wiebe, 2009; Anand et al., 2011; Sridhar et al., 2014). We participated in the SemEval 2016-Task 6: Detecting Stance in Tweets.1 The main g"
S16-1071,S16-1003,0,0.0429807,"Missing"
S16-1071,S12-1033,0,0.0347167,"related words collected using the WordNet. The detailed word level statistics of the topic bags are given in Table 1. At first, we checked that whether a tweet contains any word from the corresponding target related topic bag or not. If no word is present, then we tagged that tweet as ‘NONE’ and no further processing is performed on that tweet. Further, this topic bags are used along with the dependency information. 3.1.2 Sentiment Words We have used three lexicons namely SentiWordNet (Baccianella et al., 2010), NRC Emotion Lexicon (Mohammad and Turney, 2013), and NRC Hashtag Emotion Lexicon (Mohammad, 2012) for our experiments along with manually created lexicons for each of the targets. Moreover, two bags were created for each of the targets namely ‘favor’ and ‘against’ bags. Hashtags are also included in the above lexicons. The word level statistics of the ‘favor’ and ‘against’ bags are given in Table 1. We used the frequency of the sentiment words matched with the above sentiment or emotion lexicons as features. Again, we used these lexicons in the later experiments also. 2 https://rednoise.org/rita/reference/RiWordNet.html each of the simple sentences, we removed the stopwords (except the ne"
S16-1071,S14-2063,1,0.85197,"a simple sentence, we tagged it as positive. If there are only two sentiment words, one with positive and other as negative, we tagged the sentence as negative. It is observed that the frequency of the negative instances is much higher than the positive instances in the training data. Finally, we counted the number of positive and negative instances in a tweet and used as features. 3.2 Classification Framework Figure 1: Dependency relations from Stanford Parser 3.1.3 Dependency Information It is found in the literature that the dependency relations act as useful feature in sentiment analysis (Patra et al., 2014a; Patra et al., 2014b). Thus, we used the Stanford Parser3 to get the dependency relations. We searched for the word pairs in dependency relations that consist of two component words, one of which is present in either ‘favor’ or ‘against’ bag, whereas the other one is present in SentiWordNet. In the above Figure 1, we found a relation “dobj(support-7, campaign-9)”. The word ‘campaign’ is present in the ‘favor’ bag for the target “Hillary Clinton” and the word ‘support’ is present in SentiWordNet as positive. This relation is considered as favor positive type. Similarly, three other types name"
S16-1071,P13-1162,0,0.0276676,"dering whether the speaker is angry or happy (Mohammad et al., 2016). Stance detection even becomes more difficult when it is performed on the short texts like tweets. The latter being an important sub-field of sentiment analysis/opinion mining. Automatic stance detection can be used in several applications such as information retrieval, text summarization, and textual entailment. More recent approaches to stance detection have been performed using linguistic rules on online debate dataset (Somasundaran and Wiebe, 2009; Hasan and Ng, 2013; Sridhar et al., 2014) and NPOV Corpus from Wikipedia (Recasens et al., 2013). To the best of our knowledge, not much computational attempts have been performed on tweets for stance detection. It is also observed that both the supervised and unsupervised machine learning algorithms have been implemented for identifying the stance and several features like n-gram, frame semantic features, and dependency were used in stance detection tasks (Somasundaran and Wiebe, 2009; Anand et al., 2011; Sridhar et al., 2014). We participated in the SemEval 2016-Task 6: Detecting Stance in Tweets.1 The main goal of this task is to identify stance present in a tweet towards a specific t"
S16-1071,P09-1026,0,0.0355757,"about the author’s evaluative outlook towards specific targets and propositions rather than simply considering whether the speaker is angry or happy (Mohammad et al., 2016). Stance detection even becomes more difficult when it is performed on the short texts like tweets. The latter being an important sub-field of sentiment analysis/opinion mining. Automatic stance detection can be used in several applications such as information retrieval, text summarization, and textual entailment. More recent approaches to stance detection have been performed using linguistic rules on online debate dataset (Somasundaran and Wiebe, 2009; Hasan and Ng, 2013; Sridhar et al., 2014) and NPOV Corpus from Wikipedia (Recasens et al., 2013). To the best of our knowledge, not much computational attempts have been performed on tweets for stance detection. It is also observed that both the supervised and unsupervised machine learning algorithms have been implemented for identifying the stance and several features like n-gram, frame semantic features, and dependency were used in stance detection tasks (Somasundaran and Wiebe, 2009; Anand et al., 2011; Sridhar et al., 2014). We participated in the SemEval 2016-Task 6: Detecting Stance in"
S16-1071,W14-2715,0,0.272571,"ific targets and propositions rather than simply considering whether the speaker is angry or happy (Mohammad et al., 2016). Stance detection even becomes more difficult when it is performed on the short texts like tweets. The latter being an important sub-field of sentiment analysis/opinion mining. Automatic stance detection can be used in several applications such as information retrieval, text summarization, and textual entailment. More recent approaches to stance detection have been performed using linguistic rules on online debate dataset (Somasundaran and Wiebe, 2009; Hasan and Ng, 2013; Sridhar et al., 2014) and NPOV Corpus from Wikipedia (Recasens et al., 2013). To the best of our knowledge, not much computational attempts have been performed on tweets for stance detection. It is also observed that both the supervised and unsupervised machine learning algorithms have been implemented for identifying the stance and several features like n-gram, frame semantic features, and dependency were used in stance detection tasks (Somasundaran and Wiebe, 2009; Anand et al., 2011; Sridhar et al., 2014). We participated in the SemEval 2016-Task 6: Detecting Stance in Tweets.1 The main goal of this task is to"
S16-1108,W14-3348,0,0.00981648,"btain our stop http://www.nltk.org/book/ch02.html word list Edit Distance Ratio 6 .8958 Table 2: Edit Distance Ratio Unigram matching without stop-word The unigram overlap count feature indicates the number of non stop-words that appear in both sentence pairs. 2 Table 1 illustrates the operation of this feature on an STS sentence pair. The words ”to” and ”on” are present in both sentences, but we excluded them as stopwords for the purposes of the unigram overlap count. 3.2 Levenshtein Distance from 703 3.3 Meteor METEOR is a well known evaluation metric from the machine translation community (Denkowski and Lavie, 2014). The method incorporates linguistic analysis modules but in a manner that is lightweight, efficient and robust to the noisy data generated by machine translation systems. The method operates by first computing an alignment between the individual words in a sentence pair. In additional to matching identical words with each other, METEOR also supports matching words based on synonymy relationships in WordNet, entries in a paraphrase database or by word stem. The metric Sentence Pairs Two green and white trains sitting on the tracks. Two green and white trains on tracks. A cat standing on tree b"
S16-1152,N15-2002,0,0.0129605,"words decreases the readability of the document. Thus, the complex word identification (CWI) task aims to classify those challenging words in a sentence with respect to a particular target audience. For example, in the following sentence, the words in italics are complex words. These words are related to biology and are rarely used in our daily life. e.g. “The first amniotes, such as Casineria, resembled small lizards and evolved from amphibian reptiliomorphs about 340 million years ago.” Some research has been performed in CWI task in comparison to the lexical simplification (Shardlow, 2013; Paetzold, 2015). The important features which have been used previously in the CWI task are frequency thresholding and lexical matching etc. (Shardlow, 2013). Some motivations of the CWI task are to understand the defining characteristics of the words which are challenging for non-native speakers to interpret. Another is assessing an individual’s vocabulary limitations from the group he is a part of. We have participated in the SemEval 2016-Task 11: Complex Word Identification2 (Paetzold and Specia, 2016). The main goal of this task is to identify the complex words from English sentences. We identified highl"
S16-1152,P13-3015,0,0.429879,"use of complex words decreases the readability of the document. Thus, the complex word identification (CWI) task aims to classify those challenging words in a sentence with respect to a particular target audience. For example, in the following sentence, the words in italics are complex words. These words are related to biology and are rarely used in our daily life. e.g. “The first amniotes, such as Casineria, resembled small lizards and evolved from amphibian reptiliomorphs about 340 million years ago.” Some research has been performed in CWI task in comparison to the lexical simplification (Shardlow, 2013; Paetzold, 2015). The important features which have been used previously in the CWI task are frequency thresholding and lexical matching etc. (Shardlow, 2013). Some motivations of the CWI task are to understand the defining characteristics of the words which are challenging for non-native speakers to interpret. Another is assessing an individual’s vocabulary limitations from the group he is a part of. We have participated in the SemEval 2016-Task 11: Complex Word Identification2 (Paetzold and Specia, 2016). The main goal of this task is to identify the complex words from English sentences. We"
S16-1152,S12-1046,0,0.0675581,"Missing"
S16-1152,S16-1085,0,\N,Missing
S16-1204,P99-1008,0,0.29514,"ds often find it difficult to find an annotated corpora in similar domain. A major part of the previous researches on automatic semantic classification of words was developed based on the method first proposed by Hearst, that the presence of certain lexico-syntactic patterns can indicate a particular semantic relationship between two noun phrases (Hearst, 1992). This paper introduced six basic lexical patterns. This rule based approach was further extended in subsequent works bringing out more valid patterns, either handcrafted or learned from training corpus for semantic relation extraction (Berland and Charniak, 1999) (Kozareva et al., 2008) (Widdows and Dorow, 2002). Pattern based results are effective and reliable, scores high on precision measure. However, these methods suffer in terms of recall. Later, a few distributional approaches were proposed by different authors making use of the large corpora present in (Guido Boella, 2014) (Navigli and Velardi, 2010). Machine learning based methods make use of features like term co-occurrence, semantic similarity or other syntantic information from text collection. Precision of these machine learning based approaches is lower compared to pattern based approach."
S16-1204,S16-1168,0,0.145217,"Missing"
S16-1204,P84-1036,0,0.449789,"ces that were prohibited is: - hypernym-hyponym relations from the WordNet 1 , - skos:broader and skos:narrower relations from EuroVoc 2 , - the Google product taxonomy 3 , - the Taxonomy of fields and their subfields provided for the National Academies of Sciences, Engineering, and Medicine 4 . However, in contrast, we were free to add more terms if needed to the term lists that were provided by the organizers. 3 Related Work Hypernym detection from text is one of the most popular hierarchical relation extraction tasks in ontology learning for which research work dates back to at least 1984 (Calzolari, 1984). Hypernym can be described as a linguistic term for a word whose meaning includes the meanings of other words, which are known as hyponyms. For instance, flower is a hypernym of daisy and rose. On the other hand, 1 daisy and rose are some of the hyponyms of flower. In simple words, this relation deals with identifying the concepts and finding the particular superclass they fit in. Manually constructing these kind of relations from text is a time-consuming and labourintensive procedure. Hence, the researchers felt the need to make this process automatic. The methods proposed can broadly be cat"
S16-1204,C92-2082,0,0.548322,"The methods proposed can broadly be categorized into two: supervised and unsupervised. While the unsupervised methods can identify and extract semantic relations from plain text without the need of any preannotated text corpora, the supervised methods often find it difficult to find an annotated corpora in similar domain. A major part of the previous researches on automatic semantic classification of words was developed based on the method first proposed by Hearst, that the presence of certain lexico-syntactic patterns can indicate a particular semantic relationship between two noun phrases (Hearst, 1992). This paper introduced six basic lexical patterns. This rule based approach was further extended in subsequent works bringing out more valid patterns, either handcrafted or learned from training corpus for semantic relation extraction (Berland and Charniak, 1999) (Kozareva et al., 2008) (Widdows and Dorow, 2002). Pattern based results are effective and reliable, scores high on precision measure. However, these methods suffer in terms of recall. Later, a few distributional approaches were proposed by different authors making use of the large corpora present in (Guido Boella, 2014) (Navigli and"
S16-1204,P08-1119,0,0.0677871,"Missing"
S16-1204,S15-2157,0,0.0149287,"e effective and reliable, scores high on precision measure. However, these methods suffer in terms of recall. Later, a few distributional approaches were proposed by different authors making use of the large corpora present in (Guido Boella, 2014) (Navigli and Velardi, 2010). Machine learning based methods make use of features like term co-occurrence, semantic similarity or other syntantic information from text collection. Precision of these machine learning based approaches is lower compared to pattern based approach. The simple morpho-syntactic approach also proved to yield a decent result (Lefever, 2015) (Sang et al., 2011). In recent years, several researches are being carried out to extract semantic relations from texts in other languages. 4 System Description https://wordnet.princeton.edu/ In the present challenge, we had to keep three main http://eurovoc.europa.eu/ points in mind. We wanted to make a single sys3 https://www.google.com/basepages/producttype/taxonomy.entem appropriate for a multilingual setup (Dutch, US.txt 4 http://sites.nationalacademies.org/PGA/Resdoc/PGA 044522 French, Italian and English). However, it became 2 1311 more difficult as we were not allowed to use any of th"
S16-1204,P10-1134,0,0.0290025,"arst, 1992). This paper introduced six basic lexical patterns. This rule based approach was further extended in subsequent works bringing out more valid patterns, either handcrafted or learned from training corpus for semantic relation extraction (Berland and Charniak, 1999) (Kozareva et al., 2008) (Widdows and Dorow, 2002). Pattern based results are effective and reliable, scores high on precision measure. However, these methods suffer in terms of recall. Later, a few distributional approaches were proposed by different authors making use of the large corpora present in (Guido Boella, 2014) (Navigli and Velardi, 2010). Machine learning based methods make use of features like term co-occurrence, semantic similarity or other syntantic information from text collection. Precision of these machine learning based approaches is lower compared to pattern based approach. The simple morpho-syntactic approach also proved to yield a decent result (Lefever, 2015) (Sang et al., 2011). In recent years, several researches are being carried out to extract semantic relations from texts in other languages. 4 System Description https://wordnet.princeton.edu/ In the present challenge, we had to keep three main http://eurovoc.e"
S16-1204,C02-1114,0,0.0810653,"ra in similar domain. A major part of the previous researches on automatic semantic classification of words was developed based on the method first proposed by Hearst, that the presence of certain lexico-syntactic patterns can indicate a particular semantic relationship between two noun phrases (Hearst, 1992). This paper introduced six basic lexical patterns. This rule based approach was further extended in subsequent works bringing out more valid patterns, either handcrafted or learned from training corpus for semantic relation extraction (Berland and Charniak, 1999) (Kozareva et al., 2008) (Widdows and Dorow, 2002). Pattern based results are effective and reliable, scores high on precision measure. However, these methods suffer in terms of recall. Later, a few distributional approaches were proposed by different authors making use of the large corpora present in (Guido Boella, 2014) (Navigli and Velardi, 2010). Machine learning based methods make use of features like term co-occurrence, semantic similarity or other syntantic information from text collection. Precision of these machine learning based approaches is lower compared to pattern based approach. The simple morpho-syntactic approach also proved"
S17-2073,P15-1070,0,0.0413635,"tract The problem of detection and interpretation of English puns falls under the area of word sense disambiguation in natural language processing, which deals with the sense of a word used in a sentence from the readers’ perspective. We have tried to design a system to identify puns from a sentence by developing a cyclic dependency– based system which is implemented based on some rules which are actually statistical inferences taken from a set of random data collected from the Web. 1 Introduction Extensive research has been done in the field of modelling and detecting puns (Hempelmann, 2003; Miller and Gurevych, 2015). The context or the sense depends largely on the perspective and knowledge of the reader about a particular language. For example, in the sentence, ‘I was a banker but I lost interest,’ the word in italics conveys two different meanings or ‘senses’ in the sentence. So, the word ‘interest’ could be called a pun. A pun is the exploitation of the various meanings of a word or words with phonetic similarity but different meanings. Our system is a rule-based implementation of a dependency network and a hidden Markov model. 2 Dataset and Preprocessing In the present shared task (Miller et al., 2017"
S17-2073,S17-2005,0,0.139524,"and Gurevych, 2015). The context or the sense depends largely on the perspective and knowledge of the reader about a particular language. For example, in the sentence, ‘I was a banker but I lost interest,’ the word in italics conveys two different meanings or ‘senses’ in the sentence. So, the word ‘interest’ could be called a pun. A pun is the exploitation of the various meanings of a word or words with phonetic similarity but different meanings. Our system is a rule-based implementation of a dependency network and a hidden Markov model. 2 Dataset and Preprocessing In the present shared task (Miller et al., 2017), participants are provided with a trial dataset and a test dataset. No training data was supplied due to the large cardinality of such words or contexts in general. In case of the subtask on pun detection (Subtask 1), the test data was subdivided into two sets: a homographic set containing 2250 contexts, and a heterographic set containing 1780 contexts. On the other hand, in case of Subtask 2, another set of data was provided and that set was also subdivided into homographic and heterographic sets. For training purposes, or rather to analyze the contexts statistically, a dataset was collected"
S17-2073,N03-1033,0,0.0529768,"of speech using NLTK, an open-source package for NLP written in Python. For example, the sentence, ‘I was a banker but I lost interest.’ is tagged using the Stanford NLP parser as follows: [(‘I’, ‘PRP’), (‘was’, ‘VBD’), (‘a’, ‘DT’), (‘banker’, ‘NN’), (‘but’, ‘CC’), (‘I’, ‘PRP’), (‘lost’, ‘VBD’), (‘interest’, ‘NN’), (‘.’, ‘.’)] We also generate the parse tree for the sentence, which looks as in Figure 1. Using such parse trees, the clauses are identified and used for our further tasks. 3 System Framework We have used a hidden Markov model (Ghahramani, 2001) and incorporated cyclic dependency (Toutanova et al., 2003) in order to detect points of pun occurrences in English sentences. The probability has been calculated with respect to each word being pun in a sentence. To calculate the probability, the parts of speech of the words immediately surrounding the target word are considered and the probability is increased accordingly. 3.1 Features To train the system, 413 sentences, each containing a pun, has been analyzed. The probability of stop 432 Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), pages 432–435, c Vancouver, Canada, August 3 - 4, 2017. 2017 Association fo"
S19-2105,W18-4411,0,0.406543,"Missing"
S19-2105,D14-1162,0,0.0846091,"Huang, 2017) discusses the Bi-LSTM with attention mechanism with learning components context improved the classifier performance. Figure 1: Sub Task A:CNN-BiLSTM-Attention (Founta et al., 2018) studied different forms of abusive behaviour and made public annotated corpus of 80K Tweets categorized into 8 labels like Hate, aggressive, cyber bullying, normal , Spam. 3 3.1 Methodology Task A:CNN-BiLSTM-Attention In this model first we converted all the words to their unique index. Then all the unique index in the sentences were mapped to their real valued vectors of Dimensions 100 using Glove by (Pennington et al., 2014) from Embedding Matrix. Convolution layers is used to extract useful information by convolving i words at a time using learnable kernel of size i*h where i = [2,3,4] and h is of size equal to the dimensions. The element wise dot product is performed to get the feature map f1 . N numbers of filters are used to get feature map = [f1 ,f2 ...fn ]. Pooling reduces the size of representation by selecting max value from each feature map which is then passed to the BiLSTM layer with 100 hidden units. The sentence level representation is then passed to activation layers to capture the important keyword"
S19-2105,W17-3010,0,0.0281948,"Missing"
S19-2105,W17-1101,0,0.0212488,"This task consist of classifying between offensive and not offensive comments Task B: The Offensive language was further needs to be classified into Targeted(TIN) and UnTargeted(UNT). Task C: The targeted offensive needs to be further classified into Individual(IND), Group(GRP) and Other(OTH). 2 Related Work (Nockleby, 2000) defined hate speech as any communication that demean any person or any group on the basis of race, color, gender, ethnicity, sexual orientation, and nationality. (Kowalski et al., 2014) defined cyber aggression as using digital media to intentionally harm another person. (Schmidt and Wiegand, 2017) presents a survey on the existing research in this field and different set of features used in machine learning and Deep learning were discussed. (Silva et al., 2016) proposed and validated sentence structure to detect hate speech and also used this to construct hate speech datasets. They also provided the characteristics study to identify the main targets of hate speech in Twitter and Whisper. They designed two rules i.e I<intensity><user intent><hate Target> and <one word> people ex:”black people”,”maxican” people. (Waseem, 2016) examined the performance of classification based on training"
S19-2105,W16-5618,0,0.0324016,"tal media to intentionally harm another person. (Schmidt and Wiegand, 2017) presents a survey on the existing research in this field and different set of features used in machine learning and Deep learning were discussed. (Silva et al., 2016) proposed and validated sentence structure to detect hate speech and also used this to construct hate speech datasets. They also provided the characteristics study to identify the main targets of hate speech in Twitter and Whisper. They designed two rules i.e I<intensity><user intent><hate Target> and <one word> people ex:”black people”,”maxican” people. (Waseem, 2016) examined the performance of classification based on training performed on amateur and expert annotations. (Ross et al., 2017) concluded that hate speech requires significantly better definitions and Introduction Due to the exponential rise in the usage of internet user generated content in the form of blogs, posts, comments etc. have been increased manifold. Some users also using this platform to target any individual or any particular group on social media on the basis of certain attributes, sharing different views. Many studies have been conducted on offensive language, hate speech, cyberbu"
S19-2105,W17-3013,0,0.039401,"Missing"
S19-2105,gao-huang-2017-detecting,0,0.0431432,"Missing"
S19-2105,W17-3012,0,0.0938893,"Missing"
S19-2105,N12-1084,0,0.415163,"Missing"
S19-2105,W18-4401,0,0.078276,"Missing"
S19-2105,malmasi-zampieri-2017-detecting,0,0.130909,"Missing"
W09-3411,C94-1042,0,0.248761,"Missing"
W09-3411,W98-1505,0,0.0189298,"erbs that resulted in extremely low yields for subcategorization frame acquisition is described in (Brent, 1991). A rule based system for automatically acquiring six verb subcategorization frames and their frequencies from a large corpus is mentioned in (Ushioda et al., 1993). An open class vocabulary of 35,000 words was analyzed manually in (Briscoe and Carroll, 1997) for subcategorization frames and predicate associations. The result was compared against associations in ANLT and COMLEX. Variations of subcategorization frequencies across corpus type (written vs. spoken) have been studied in (Carroll and Rooth, 1998). A mechanism for resolving verb class ambiguities using subcategorization frames is reported in (Lapata and Brew, 1999). All these works deal with English. Several works on the term classification of verb diathesis roles or the lexical semantics of predicates in natural language have been reported in ((McCarthy, 2001), 1 2 System Outline 3.2 Identification and Selection of Verbs Our previous work (Das et.al., 2009) on the acquisition of Bengali subcategorization frames from the same Bengali news corpus was carried out for the most frequent verb “ দখা” (dekha) (see) in that corpus. The next hi"
W09-3411,C00-2100,0,0.0356902,"corpus. Linguists have suggested that these frames do appear in Bengali and hence can be acquired. The rest of the paper is organized as follows. Section 2 gives the description of the related works carried out in this area. Section 3 describes the framework for the acquisition of subcategorization frames for ten compound Bengali verbs. Evaluation results of the system are discussed in section 4. Finally section 5 concludes the paper. 2 (Korhonen, 2002), (Stevenson and Merlo, 1999) and (Walde, 1998)). A cross lingual work on learning verbargument structure for Czech language is described in (Sarkar and Zeman, 2000). (Samantaray, 2007) gives a method of acquiring different subcategorization frames for the purpose of machine aided translation system for Indian languages. The work on subcategorization frame acquisition of Japanese verbs using breadth-first algorithm is described in (Muraki et al., 1997). 3 We have developed several modules for the acquisition of verb subcategorization frames from the Bengali newspaper corpus. The modules consist of POS tagging and chunking, Identification and Selection of Verbs, English Verb Determination, Frames Acquisition from VerbNet and Bengali Verb Subcategorization"
W09-3411,1997.tmi-1.20,0,0.206225,"Missing"
W09-3411,W93-0109,0,0.330908,"Missing"
W09-3411,P91-1027,0,0.253749,"Missing"
W09-3411,W99-0632,0,0.0675342,"Missing"
W09-3411,E99-1007,0,0.0340222,"Missing"
W09-3411,P98-1013,0,0.172537,"Missing"
W09-3411,A92-1012,0,0.0167423,"Missing"
W09-3411,A97-1052,0,0.0963679,"Missing"
W09-3411,J87-3002,0,\N,Missing
W09-3411,H91-1067,0,\N,Missing
W09-3411,W02-0907,0,\N,Missing
W09-3411,C98-1013,0,\N,Missing
W09-3411,P93-1032,0,\N,Missing
W10-3207,J96-2004,0,0.180191,"Missing"
W10-3207,H05-1073,0,0.17506,"the paper. 2 Related Work One of the most well known tasks of annotating the private states in texts is carried out by (Wiebe et al., 2005). They manually annotated the private states including emotions, opinions, and sentiment in a 10,000-sentence corpus (the MPQA corpus) of news articles. The opinion holder information is also annotated in the MPQA corpus but the topic annotation task has been initiated later by (Stoyanov and Cardie, 2008a). In contrast, the present annotation strategy includes the fine-grained emotion classes and specially handles the emoticons present in the blog posts. (Alm et al., 2005) have considered eight emotion categories (angry, disgusted, fearful, 48 to the above emotion entities, the present approach also includes the annotation of single or multiple emotion topics in a target span. Recent study shows that non-native English speakers support the growing use of the Internet 2. This raises the demand of linguistic resources for languages other than English. Bengali is the fifth popular language in the World, second in India and the national language in Bangladesh but it is less computerized compared to English. To the best of our knowledge, at present, there is no such"
W10-3207,passonneau-2006-measuring,0,0.015194,"<EW_F> 0 </EW_F> '  1  <NEG> </NEG> </ES_Su></ES_A> <ES_H>1 <top2c>   </top2c> 13e  ei <EW_H> 4  </EW_H>  13+- </ES_H> 3.3 Emotional expressions are words or strings of words that are selected by the annotators. The agreement is carried out between the sets of text spans selected by the two annotators for each of the emotional expressions. As there is no fixed category in this case, we have employed two different strategies instead of kappa () to calculate the agreement between annotators. Firstly, we chose the measure of agreement on set-valued items (MASI) (Passonneau, 2006) that was used for measuring agreement on co reference annotation (Passonneau, 2004) and in the semantic and pragmatic annotation (Passonneau, 2006). MASI is a distance between sets whose value is 1 for identical sets, and 0 for disjoint sets. For sets A and B it is defined as: MASI = J * M, where the Jaccard metric is: “Figure 1. Annotated sample of the corpus” 3.2 Agreement of Sentential Emotion and Intensity Three annotators identified as A1, A2 and A3 have used an open source graphical tool to carry out the annotation 4 . As the Ekman’s emotion classes and intensity types belong to some de"
W10-3207,P09-2038,1,0.873776,"Missing"
W10-3207,D09-1150,0,0.0648,"Missing"
W10-3207,C08-1111,0,0.0416724,"Missing"
W10-3207,passonneau-2004-computing,0,\N,Missing
W10-3207,H05-1045,0,\N,Missing
W10-3207,P07-2034,0,\N,Missing
W10-3207,stoyanov-cardie-2008-annotating,0,\N,Missing
W10-3706,W09-2906,0,0.745863,"Missing"
W10-3706,W06-1205,0,\N,Missing
W10-3706,C08-2007,0,\N,Missing
W11-0803,W03-1812,0,0.298219,"Missing"
W11-0803,W10-3710,1,0.445025,"Missing"
W11-0803,J90-1003,0,0.11651,"ental results and the various observations derived from our research are discussed in Section 5. Finally, Section 6 concludes the paper. 8 Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World (MWE 2011), pages 8–13, c Portland, Oregon, USA, 23 June 2011. 2011 Association for Computational Linguistics 2 Related Work A number of research activities regarding MWE identification have been carried out in various languages like English, German and many other European languages. The statistical co-occurrence measurements such as Mutual Information (MI) (Church and Hans, 1990), Log-Likelihood (Dunning, 1993) and Salience (Kilgarriff and Rosenzweig, 2000) have been suggested for identification of MWEs. An unsupervised graph-based algorithm to detect the compositionality of MWEs has been proposed in (Korkontzelos and Manandhar 2009). In case of Indian languages, an approach in compound noun MWE extraction (Kunchukuttan and Damani, 2008) and a classification based approach for Noun-Verb collocations (Venkatapathy and Joshi, 2009) have been reported. In Bengali, the works on automated extraction of MWEs are limited in number. One method of automatic extraction of Noun-"
W11-0803,P09-2017,0,0.0219319,", pages 8–13, c Portland, Oregon, USA, 23 June 2011. 2011 Association for Computational Linguistics 2 Related Work A number of research activities regarding MWE identification have been carried out in various languages like English, German and many other European languages. The statistical co-occurrence measurements such as Mutual Information (MI) (Church and Hans, 1990), Log-Likelihood (Dunning, 1993) and Salience (Kilgarriff and Rosenzweig, 2000) have been suggested for identification of MWEs. An unsupervised graph-based algorithm to detect the compositionality of MWEs has been proposed in (Korkontzelos and Manandhar 2009). In case of Indian languages, an approach in compound noun MWE extraction (Kunchukuttan and Damani, 2008) and a classification based approach for Noun-Verb collocations (Venkatapathy and Joshi, 2009) have been reported. In Bengali, the works on automated extraction of MWEs are limited in number. One method of automatic extraction of Noun-Verb MWE in Bengali (Agarwal et al., 2004) has been carried out using significance function. In contrast, we have proposed a clustering technique to identify Bengali MWEs using semantic similarity measurement. It is worth noting that the conducted experiments"
W11-0803,passonneau-2006-measuring,0,0.0269213,"Missing"
W11-0803,H05-1113,0,0.0368216,"Missing"
W11-0904,baccianella-etal-2010-sentiwordnet,0,0.0590986,"Missing"
W11-0904,banea-etal-2008-bootstrapping,0,0.0707488,"Missing"
W11-0904,S07-1094,0,0.0622787,"Missing"
W11-0904,J02-3001,0,0.0596275,"Missing"
W11-0904,S07-1067,0,0.045748,"Missing"
W11-0904,S10-1077,1,0.88507,"Missing"
W11-0904,strapparava-valitutti-2004-wordnet,0,0.169951,"Missing"
W11-0904,stoyanov-cardie-2008-annotating,0,0.18126,"o annotate emotional content. Our motivation is that though events and sentiments are closely coupled with each other from social, psychological and commercial perspectives, very little attention has been given about their detection and analysis. To the best of our knowledge, only a few tasks have been attempted (Fukuhara et al., 2007) (Das et al., 2010). 21 Sometimes, the opinion topics are not necessarily spatially coherent as there may be two opinions in the same sentence on different topics, as well as opinions that are on the same topic separated by opinions that do not share that topic (Stoyanov and Cardie 2008). The authors have established their hypothesis by applying the coreference technique. Similarly, we have adopted the co-reference technique based on basic rhetoric components for identifying the association between event and sentiment expressions. In addition to that, we have also employed the lexical equivalence approach for identifying their association. 3 Event Identification In this work, we propose a hybrid approach for event identification from the text under the TempEval-2010 framework. We use Conditional Random Field (CRF) as the underlying machine learning algorithm. We observe that"
W11-0904,de-marneffe-etal-2006-generating,0,\N,Missing
W11-0904,P00-1010,0,\N,Missing
W11-0904,W00-1308,0,\N,Missing
W11-0904,S07-1013,0,\N,Missing
W11-0904,S10-1063,0,\N,Missing
W11-0904,N04-1030,0,\N,Missing
W11-1710,S07-1022,0,0.050743,"Missing"
W11-1710,baccianella-etal-2010-sentiwordnet,0,0.442447,"Missing"
W11-1710,banea-etal-2008-bootstrapping,0,0.0606121,"Missing"
W11-1710,esuli-sebastiani-2006-sentiwordnet,0,0.559548,"Missing"
W11-1710,P97-1023,0,0.0953214,"e rest of the paper is organized as follows. Different developmental phases of the Japanese WordNet Affect are described in Section 3. Prepa3 http://wordnet.princeton.edu/wordnet/download/ http://sentiwordnet.isti.cnr.it/ 5 http://mecab.sourceforge.net/ 6 http://translate.google.com/# 4 81 ration of the translated Japanese corpus, different experiments and evaluations based on morphology and the annotated emotion scores are elaborated in Section 4. Finally Section 5 concludes the paper. 2 Related Works The extraction and annotation of subjective terms started with machine learning approaches (Hatzivassiloglou and McKeown, 1997). Some well known sentiment lexicons have been developed, such as subjective adjective list (Baroni and Vegnaduzzo, 2004), English SentiWordNet (Esuli et. al., 2006), Taboada’s adjective list (Voll and Taboada, 2007), SubjectivityWord List (Banea et al., 2008) etc. Andreevskaia and Bergler (2006) present a method for extracting positive or negative sentiment bearing adjectives from WordNet using the Sentiment Tag Extraction Program (STEP). The proposed methods in (Wiebe and Riloff, 2006) automatically generate resources for subjectivity analysis for a new target language from the available res"
W11-1710,W10-0204,0,0.0222294,"y in the experiments on English as well as Japanese lexicons. But, it was also aimed for sentiment bearing words. Instead of English WordNet Affect (Strapparava and Valitutti, 2004), there are a few attempts in other languages such as, Russian and Romanian (Bobicev et al., 2010), Bengali (Das and Bandyopadhyay, 2010) etc. Our present approach is similar to some of these approaches but in contrast, we have evaluated our Japanese WordNet Affect on the SemEval 2007 affect sensing corpus translated into Japanese. In recent trends, the application of mechanical turk for generating emotion lexicon (Mohammad and Turney, 2010) shows promising results. In the present task, we have incorporated the open source, available and accessible resources to achieve our goals. 3 3.1 Developmental Phases WordNet Affect The English WordNet Affect, based on Ekman’s six emotion types is a small lexical resource compared to the complete WordNet but its affective annotation helps in emotion analysis. Some collection of WordNet Affect synsets was provided as a resource for the shared task of Affective Text in SemEval2007. The whole data is provided in six files named by the six emotions. Each file contains a list of synsets and one s"
W11-1710,strapparava-valitutti-2004-wordnet,0,0.671974,"Missing"
W11-1710,W09-3401,0,\N,Missing
W11-1710,S07-1013,0,\N,Missing
W11-1710,P05-1017,1,\N,Missing
W11-3709,H05-1073,0,0.0326818,"natural language. Natural language domains such as News (Strapparava and Mihalcea, 2007) and Blogs (Mishne and Rijke, 2006) are also becoming a popular, communicative and informative repository of text based emotional contents in the Web 2.0 for mining and summarizing opinion at word, sentence and document level granularities (Ku et al., 2006). The model proposed in (Neviarouskaya et al., 2007) processes symbolic cues and employs NLP techniques to estimate the affects in text. Machine learning techniques were used either to predict text-based emotions based on the SNoW learning architecture (Alm et al., 2005) or to identify the mood of the authors during reading and writing (Yang et al., 2009). The ISEAR corpus was used in (Boldrini et al., 2010) for the experiments concerning emotional expressions and fine-grained analysis of affect in text. Their aim was to build the subjectivity expression models and they did not explore the intensity or physiological variables in case of identifying emotions. Psychiatric query document retrieval can assist individuals to locate query documents relevant to their depression-related problems efficiently and effectively (Yeh et. al., 2008). A DSM-IV based screenin"
W11-3709,baccianella-etal-2010-sentiwordnet,0,0.0158159,"Missing"
W12-5004,O12-1029,1,0.824052,"from the Bible and the story books and the stemmed data are checked manually. Then we have assigned the POS and the English meaning manually. 46 The stemming algorithm used for the development of root dictionary is given below and Table 9 shows the root dictionary entries. Kokborok Achuk POS Verb English Sit TABLE 9 – Root Dictionary Entries. 3.2 Stemming algorithm for generating Root Words The algorithm is designed to remove both multiple suffixes as well as prefixes from the inflected words. It has been observed that the boundary of root words in Kokborok change after addition of suffixes (Patra et al., 2012). Thus we have added some rules in the algorithm as boundary changes after addition of suffixes. The algorithm is given below. 3.2.1 Prefix Stripping Algorithm 1. 2. repeat the step 2 until all the prefixes are removed read the prefix, if matched then store it in array and decrease the length of string else read another prefix. 3. If length of string &gt;2 then go for suffix stripping, else exit 3.2.2 1. 2. 3. Suffix Stripping Algorithm repeat the step 2 until all the suffixes are removed read the largest suffix, if matched then check for rules. then store it in array and decrease the length of s"
W13-4104,W12-5310,0,0.169885,"osed for the image emotion classification as we cannot say a piece of music is disgust. In music psychology, our traditional approach is to describe mood using the adjective like gloomy, pathetic and hopeful etc. However, there is no standard taxonomy available which is acceptable to the researchers. Russel (1980) proposed the circumplex model of affect based on the two dimensional model. These two dimensions are denoted as “pleasant3 Figure 1. Russell’s circumplex model of 28 affects words To the best of our knowledge, no work has been carried out on Hindi music mood classification. However, Velankar and Sahasrabuddhe (2012) had worked on the preparation of data for Hindustani classical music mood classification. They have performed several sessions for classifying the three Indian Ragas into 13 mood classes. 3 Mood Taxonomy and Data Set In the present task, a standard data set has been used for the mood classification task. This data has been collected manually and prepared by five human annotators. The songs used in the experiments are collected from Indian Hindi music website 4 . This collected data set includes five moods clusters of MIREX. MIREX mood cluster follows the Theyer’s model (Thayer, 1989). 4 http:"
W14-5114,W10-3208,1,0.839958,"al. (2004), which significantly outperforms IBM Model 4 and HMM. Fung (1994) presented K-vec, an alternative alignment strategy that starts by estimating the lexicon. Sentiment detection is the task of determining positive or negative sentiment of words, phrases, sentences and documents. The computational approach to sentiment analysis in textual data requires annotated lexicons with polarity tags (Patra et al., 2013). Research has been carried out on building sentiment or emotional corpora in English (Strapparava and Valitutti, 2004; Baccianella et al., 2010; Patra et al., 2013) and Bengali (Das and Bandyopadhyay, 2010; Das and Bandyopadhyay, 2010a). Identifying the sentiment holder is another task closely related to subjectivity detection (Kim and Hovy, 2004). Several methods have been implemented to identify the sentiment holders such as rule based methods (using dependency information) (Kolya et al., 2012) and supervised machine learning methods (Kim and Hovy, 2004; Kolya et al., 2012). To the best of our knowledge, no prior work on improving SMT systems using aligned sentiment expressions, holders and their corresponding objects have been developed yet. There is research on creating sentiment lexica and"
W14-5114,strapparava-valitutti-2004-wordnet,0,0.263172,"Missing"
W14-5114,D08-1014,0,0.0219678,"cy information) (Kolya et al., 2012) and supervised machine learning methods (Kim and Hovy, 2004; Kolya et al., 2012). To the best of our knowledge, no prior work on improving SMT systems using aligned sentiment expressions, holders and their corresponding objects have been developed yet. There is research on creating sentiment lexica and cross-lingual sentiment identification. Automatic translation is a viable alternative for the construction of resources and tools for subjectivity or sentiment analysis in a new resource-constrained language using a resourcerich language as a starting point (Banea et al., 2008). Banea et al., (2008) generated resources for subjectivity annotation in Spanish and Romanian using English corpora. In context of Indian languages, Das et al., 2010 have developed a sentiment lexicon for Bengali Languages using an English to Bengali MT system. Similarly, a Hindi sentiment corpus has been developed using English to Hindi MT system (Balamurali et al., 2010). Hiroshi et al., (2004) developed a high-precision sentiment analysis system with low development cost, by making use of an existing transfer-based MT engine. 3 Dataset In our experiment, an English-Bengali parallel corpus"
W14-5114,P05-1033,0,0.267679,"Missing"
W14-5114,W04-3248,0,0.0173424,"nment template approach for PB-SMT (Och et al., 2004) allows many-tomany relations between words. A model that uses hierarchical phrases based on synchronous grammars is presented in (Chiang et al., 2005). To date there is little research on English-Bengali SMT: PB-SMT systems can be improved (Pal et al., 2011; 2013) by single tokenizing Multiword Expressions (MWEs) on both sides of the parallel corpus. Researches on alignment were mostly developed for MT tasks (Brown, 1991; Gale and 90 Church, 1993). A Maximum Entropy model based approach for English-Chinese NE alignment has been proposed in Feng et al. (2004), which significantly outperforms IBM Model 4 and HMM. Fung (1994) presented K-vec, an alternative alignment strategy that starts by estimating the lexicon. Sentiment detection is the task of determining positive or negative sentiment of words, phrases, sentences and documents. The computational approach to sentiment analysis in textual data requires annotated lexicons with polarity tags (Patra et al., 2013). Research has been carried out on building sentiment or emotional corpora in English (Strapparava and Valitutti, 2004; Baccianella et al., 2010; Patra et al., 2013) and Bengali (Das and Ba"
W14-5114,J04-4002,0,0.224891,"Missing"
W14-5114,C08-1125,0,0.0655339,"Missing"
W14-5114,C04-1071,0,0.0377596,"ation is a viable alternative for the construction of resources and tools for subjectivity or sentiment analysis in a new resource-constrained language using a resourcerich language as a starting point (Banea et al., 2008). Banea et al., (2008) generated resources for subjectivity annotation in Spanish and Romanian using English corpora. In context of Indian languages, Das et al., 2010 have developed a sentiment lexicon for Bengali Languages using an English to Bengali MT system. Similarly, a Hindi sentiment corpus has been developed using English to Hindi MT system (Balamurali et al., 2010). Hiroshi et al., (2004) developed a high-precision sentiment analysis system with low development cost, by making use of an existing transfer-based MT engine. 3 Dataset In our experiment, an English-Bengali parallel corpus containing 23,492 parallel sentences comprising of 488,026 word tokens from the travel and tourism domain has been used. We randomly selected 500 sentences each for the development set and the test set from the initial parallel corpus. The rest of the sentences were used as the training corpus. The training corpus was filtered with the maximum allowable sentence length of 100 words and sentence le"
W14-5114,P02-1040,0,0.107491,"rie Actions) (Grant No. 317471) and the “Development of English to Indian Languages Machine Translation (EILMT) System - Phase II” project funded by Department of Information Technology, Government of India. Our experiments have been carried out in two directions. First we improved the baseline model using the aligned sentiment phrases. Then, we automatically post-edited the translation output by using the sentiment knowledge of the source input test sentence. The evaluation results are reported in Table 1. The evaluation was carried out using well-known automatic MT evaluation metrics: BLEU (Papineni et al., 2002, NIST (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al., 2006). In experiment 2, the extracted parallel sentiment phrase alignments are incorporated with the existing baseline phrase table and the resulting model performs better than the baseline system. Experiment 3 shows how post-editing the output of experiment 2 brings about further improvements. 7 Conclusions and Future Research In this paper, we successfully illustrated how sentiment analysis can improve the translation of an English-Bengali PB-SMT system. We have also shown how sentiment knowledge is useful"
W14-5114,N10-1029,0,0.0575798,"Missing"
W14-5114,C94-2178,0,0.372118,"Missing"
W14-5114,J93-2003,0,0.107473,"Missing"
W14-5114,N03-1017,0,0.107016,"carried out using the positional information of sentiment components. The rest of the paper is organized in the following manner. Section 2 briefly elaborates the related work. Section 3 provides an overview of the dataset used in our experiments. The proposed system is described in Section 4 while Section 5 provides the system setup for the various experiments. Section 6 includes the experiments and results obtained. Finally, Section 7 concludes and provides avenues for further work. 2 Related Work SMT systems have undergone considerable improvements over the years. Moreover, PB-SMT models (Koehn et al., 2003) outperform wordbased models. The alignment template approach for PB-SMT (Och et al., 2004) allows many-tomany relations between words. A model that uses hierarchical phrases based on synchronous grammars is presented in (Chiang et al., 2005). To date there is little research on English-Bengali SMT: PB-SMT systems can be improved (Pal et al., 2011; 2013) by single tokenizing Multiword Expressions (MWEs) on both sides of the parallel corpus. Researches on alignment were mostly developed for MT tasks (Brown, 1991; Gale and 90 Church, 1993). A Maximum Entropy model based approach for English-Chin"
W14-5114,W04-3250,0,0.269403,"Missing"
W14-5114,2013.mtsummit-papers.8,1,0.870543,"Missing"
W14-5114,W05-0909,0,0.0587776,"English to Indian Languages Machine Translation (EILMT) System - Phase II” project funded by Department of Information Technology, Government of India. Our experiments have been carried out in two directions. First we improved the baseline model using the aligned sentiment phrases. Then, we automatically post-edited the translation output by using the sentiment knowledge of the source input test sentence. The evaluation results are reported in Table 1. The evaluation was carried out using well-known automatic MT evaluation metrics: BLEU (Papineni et al., 2002, NIST (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al., 2006). In experiment 2, the extracted parallel sentiment phrase alignments are incorporated with the existing baseline phrase table and the resulting model performs better than the baseline system. Experiment 3 shows how post-editing the output of experiment 2 brings about further improvements. 7 Conclusions and Future Research In this paper, we successfully illustrated how sentiment analysis can improve the translation of an English-Bengali PB-SMT system. We have also shown how sentiment knowledge is useful for automatic post-editing the MT output. In either case, we"
W14-5114,C04-1200,0,0.0836786,"g the lexicon. Sentiment detection is the task of determining positive or negative sentiment of words, phrases, sentences and documents. The computational approach to sentiment analysis in textual data requires annotated lexicons with polarity tags (Patra et al., 2013). Research has been carried out on building sentiment or emotional corpora in English (Strapparava and Valitutti, 2004; Baccianella et al., 2010; Patra et al., 2013) and Bengali (Das and Bandyopadhyay, 2010; Das and Bandyopadhyay, 2010a). Identifying the sentiment holder is another task closely related to subjectivity detection (Kim and Hovy, 2004). Several methods have been implemented to identify the sentiment holders such as rule based methods (using dependency information) (Kolya et al., 2012) and supervised machine learning methods (Kim and Hovy, 2004; Kolya et al., 2012). To the best of our knowledge, no prior work on improving SMT systems using aligned sentiment expressions, holders and their corresponding objects have been developed yet. There is research on creating sentiment lexica and cross-lingual sentiment identification. Automatic translation is a viable alternative for the construction of resources and tools for subjectiv"
W14-5114,W06-0301,0,0.104449,"Missing"
W14-5114,baccianella-etal-2010-sentiwordnet,0,0.071767,"English-Chinese NE alignment has been proposed in Feng et al. (2004), which significantly outperforms IBM Model 4 and HMM. Fung (1994) presented K-vec, an alternative alignment strategy that starts by estimating the lexicon. Sentiment detection is the task of determining positive or negative sentiment of words, phrases, sentences and documents. The computational approach to sentiment analysis in textual data requires annotated lexicons with polarity tags (Patra et al., 2013). Research has been carried out on building sentiment or emotional corpora in English (Strapparava and Valitutti, 2004; Baccianella et al., 2010; Patra et al., 2013) and Bengali (Das and Bandyopadhyay, 2010; Das and Bandyopadhyay, 2010a). Identifying the sentiment holder is another task closely related to subjectivity detection (Kim and Hovy, 2004). Several methods have been implemented to identify the sentiment holders such as rule based methods (using dependency information) (Kolya et al., 2012) and supervised machine learning methods (Kim and Hovy, 2004; Kolya et al., 2012). To the best of our knowledge, no prior work on improving SMT systems using aligned sentiment expressions, holders and their corresponding objects have been dev"
W14-5114,J93-1003,0,0.359133,"Missing"
W14-5114,J93-1004,0,0.625572,"Missing"
W15-3607,P09-2038,1,0.818641,"spin model, where the semantic orientation of words propagates in two possible directions like electrons. Esuli and Sebastiani’s (2006) approach to develop the SentiWordNet is an adaptation to synset classification based on the training of ternary classifiers for deciding positive and negative (P-N) polarity. Each of the ternary classifiers is generated using the Semisupervised rules. On the other hand, Mohammad, et al., (2010) has performed an extensive analysis of the annotations to better understand the distribution of emotions evoked by terms of different parts of speech. The authors in (Das and Bandyopadhyay, 2009, 2010) created the emotion lexicon and systems for Bengali language. The development of SenticNet (Cambria et al., 2010) was inspired later by (Poria et al., 2013). The authors developed an enriched SenticNet with affective information by assigning emotion labels. Similarly, ConceptNet1 is a multilingual knowledge base, representing words and phrases that people use and the common-sense relationships between them. Balahur et al., (2012) had shown that the task of emotion detection from texts such as the one in the ISEAR corpus (where little or no lexical clues of affect are present) can be be"
W15-3607,W10-0204,0,0.0766963,"Missing"
W15-3607,baccianella-etal-2010-sentiwordnet,0,\N,Missing
W15-3607,balahur-hermida-2012-extending,0,\N,Missing
W15-3607,I13-1078,1,\N,Missing
W15-3607,strapparava-valitutti-2004-wordnet,0,\N,Missing
W15-3607,P05-1017,0,\N,Missing
W15-5939,bakliwal-etal-2012-hindi,0,0.117611,"ss_An 1 49 95 Class_Ca 83 12 91 Class_Ex 85 6 100 Class_Ha 96 4 125 Class_Sa 7 117 461 Total Songs Table 2. Confusion matrix of two annotation schemes and statistics of total songs. 5 Classification Framework We adopted a wide range of textual features such as sentiment Lexicons, stylistic features and ngrams in order to develop the music mood classification framework. We have illustrated all the features below. 5.1 Features based on Sentiment Lexicons: We used three Hindi sentiment lexicons to classify the sentiment words present in the lyrics texts, which are Hindi Subjective Lexicon (HSL) (Bakliwal et al., 2012), Hindi SentiWordnet (HSW) (Joshi et al., 2010) and Hindi Wordnet Affect (HWA) (Das et al., 2012). HSL contains two lists, one is for adjectives (3909 positive, 2974 negative and 1225 neutral) and another is for adverbs (193 positive, 178 negative and 518 neutral). HSW consists of 2168 positive, 1391 negative and 6426 neutral words along with their parts-of-speech (POS) and synset id extracted from the Hindi WordNet. HWA contains 2986, 357, 500, 3185, 801 and 431 words with their parts-of-speech from angry, disgust, fear, happy, sad and surprise classes, respectively. The statistics of the sen"
W15-5939,W12-5310,0,0.225135,"Taxonomy: Preparation of an annotated dataset requires the selection of proper mood classes to be used. With respect to Indian music, limited work on mood detection by considering audio features has been reported till today. Koduri and Indurkhya (2010) worked on the mood classification of South Indian Classical music, i.e. Carnatic music. The main goal of their experiment was to verify the raagas that really evoke a particular rasa(s) (emotion) specific to each user. They considered the taxonomy consisting of ten rasas e.g., Srungaram (Romance, Love), Hasyam (Laughter, Comedy) etc. Similarly, Velankar and Sahasrabuddhe (2012) prepared data for mood classification of Hindustani classical music consisting of 13 mood taxonomies (Happy, Exciting, Satisfaction, Peaceful, Graceful, Gentle, Huge, Surrender, Love, Request, Emotional, Pure, Meditative). Patra et al. (2013a) used the standard MIREX taxonomy for their experiments whereas Ujlambkar and Attar, (2012) experimented based on audio features for five mood classes, namely Happy, Sad, Silent, Excited and Romantic along with three or more subclasses based on two dimensional “Energy and Stress” model. Mood Classification using Audio Features: Automatic music mood class"
W15-5939,W13-4104,1,0.863559,"Missing"
W15-5939,D12-1054,0,0.0298218,"Missing"
W16-2373,P91-1022,0,0.876329,"Missing"
W16-2373,1992.tmi-1.7,0,0.866727,"Missing"
W16-2373,P93-1001,0,0.656613,"Missing"
W16-2373,W14-3323,1,0.872891,"Missing"
W16-2373,P91-1023,0,0.580783,"Missing"
W16-2373,E09-1096,0,0.181034,"Missing"
W16-2373,P11-2026,0,0.518386,"Missing"
W16-2373,J93-1006,0,0.824386,"Missing"
W16-2373,P94-1012,0,0.261372,"Missing"
W16-2373,P93-1003,0,0.690047,"Missing"
W16-2373,2012.eamt-1.62,0,0.227133,"Missing"
W16-2373,P93-1004,0,0.628793,"Missing"
W16-2373,W14-1009,1,0.892146,"Missing"
W16-2373,N10-1063,0,\N,Missing
W16-5810,W14-3902,0,0.0427678,"between different languages as well (Singh and Gorla, 2007). The Bengali-English code-switching phenomenon has historically been explored very little. A few groups have recently begun exploring the possibilities of language identification in these code-mixed situations. However, there are a few fundamental differences between their works and our work. In other research works, some ambiguity is left with regard to the words that are present in both English and Bengali either by removing them (Das and Gamb¨ack, 2013) or by classifying them as mixed (Depending on suffixes or word-level mixing) (Barman et al., 2014). However, such ambiguity needs to be removed, if we are required to utilize such type of data for further analysis or use them for building models of sentiment and/or predictive analysis, since people generally use mixed or ambiguous words in some single language context as well, which is why they code-mix in the first place. In both of the other research works mentioned, the groups composed their own corpus from a Facebook group and the posts and comments by members (Das and Gamb¨ack, 2013; Barman et al., 2014). Both of the groups also use N-gram pruning and dictionary checks. Das and Gamb¨a"
W16-5810,W14-5152,0,0.0310821,"Missing"
W16-5810,D12-1039,0,0.0218506,"6.1 Resources used 6.1.1 Lexicons used The dictionaries we use are the following: 1. English dictionary: We use the Python Enchant library3 for checking English words and their existence in the dictionary. The good thing about Enchant is that the words included are not only in lemma form, but all kinds of morphological transformations are also included, making checks a lot easier. We also create a slang dictionary of our own containing colloquial English text words such as ”LOL” and ”gr8”. We draw from the works of researchers at the University of Melbourne and University of Texas at Dallas (Han et al., 2012; Liu et al., 2011; Liu et al., 2012). We use this in both halves. 3 https://pypi.python.org/pypi/pyenchant/ 84 3. Bengali suffix list: We composed a list of common Bengali suffixes to check for transformed words. As discussed earlier, this helps us to deal with Bengali morphology, which is rather different from English morphology. We use this in both halves. 6.1.2 Training corpora used These were two training corpora we used: 1. Brown corpus: We use the Brown corpus provided in the nltk5 library in Python for a list of English words for creating an English language n-gram profile (Francis and"
W16-5810,C82-1023,0,0.78975,"cript, but a vastly different alphabet as well. This heralds several new problems, which we discuss in the next section. 81 3 Related Work Language identification and patterns in code-mixed data by itself is a field that has been explored for a very long time. Early linguistic research includes the work done in Spanish-English verbal communication by John Lipski, where he identifies the levels of linguistic competence in bilingual people as one of the root causes of code-switching (Lipski, 1978). Aravind Joshi presents a similar argument as well, in the case of Marathi-English code-switching (Joshi, 1982). While that certainly is a big factor, there are other factors as well that we have spoken of earlier. The varying levels of diversity at the national, regional and local levels also influence different varieties of code-switching and between different languages as well (Singh and Gorla, 2007). The Bengali-English code-switching phenomenon has historically been explored very little. A few groups have recently begun exploring the possibilities of language identification in these code-mixed situations. However, there are a few fundamental differences between their works and our work. In other r"
W16-5810,P11-2013,0,0.0145349,"d 6.1.1 Lexicons used The dictionaries we use are the following: 1. English dictionary: We use the Python Enchant library3 for checking English words and their existence in the dictionary. The good thing about Enchant is that the words included are not only in lemma form, but all kinds of morphological transformations are also included, making checks a lot easier. We also create a slang dictionary of our own containing colloquial English text words such as ”LOL” and ”gr8”. We draw from the works of researchers at the University of Melbourne and University of Texas at Dallas (Han et al., 2012; Liu et al., 2011; Liu et al., 2012). We use this in both halves. 3 https://pypi.python.org/pypi/pyenchant/ 84 3. Bengali suffix list: We composed a list of common Bengali suffixes to check for transformed words. As discussed earlier, this helps us to deal with Bengali morphology, which is rather different from English morphology. We use this in both halves. 6.1.2 Training corpora used These were two training corpora we used: 1. Brown corpus: We use the Brown corpus provided in the nltk5 library in Python for a list of English words for creating an English language n-gram profile (Francis and Kuˇcera, 1979). W"
W16-5810,P12-1109,0,0.0142047,"sed The dictionaries we use are the following: 1. English dictionary: We use the Python Enchant library3 for checking English words and their existence in the dictionary. The good thing about Enchant is that the words included are not only in lemma form, but all kinds of morphological transformations are also included, making checks a lot easier. We also create a slang dictionary of our own containing colloquial English text words such as ”LOL” and ”gr8”. We draw from the works of researchers at the University of Melbourne and University of Texas at Dallas (Han et al., 2012; Liu et al., 2011; Liu et al., 2012). We use this in both halves. 3 https://pypi.python.org/pypi/pyenchant/ 84 3. Bengali suffix list: We composed a list of common Bengali suffixes to check for transformed words. As discussed earlier, this helps us to deal with Bengali morphology, which is rather different from English morphology. We use this in both halves. 6.1.2 Training corpora used These were two training corpora we used: 1. Brown corpus: We use the Brown corpus provided in the nltk5 library in Python for a list of English words for creating an English language n-gram profile (Francis and Kuˇcera, 1979). We use this in both"
W16-5811,J95-3006,0,0.077828,"Missing"
W16-5811,H92-1022,0,0.55804,"and Kokkinakis, 1995; Meteer et al., 1991; Merialdo, 1994) are widely used because of the simplicity and the independence of the language models. Most commonly used statistical models are bi-gram, tri-gram and Hidden Markov Model (HMM). The only problem with statistical models is that these kinds of taggers require a large annotated corpus. Machine learning algorithms are statistical in nature but the models are 91 more complicated than simple n-gram. Models for acquiring disambiguation rules and transformation rules from the dataset were constructed in late 80’s and early 90’s (Hindle, 1989; Brill, 1992; Brill, 1995a; Brill, 1995b). Neural networks have also been used for POS tagging (Nakamura et al., 1990; Sch¨utze, 1993; Ma and Isahara, 1998; Eineborg and Gamb¨ack, 1994). POS taggers were also developed using Support Vector Machine (SVM) (Nakagawa et al., 2001). These taggers were more simple and efficient than the previous taggers. The successor of this tagger was developed by Gim´enez and Marquez (2004) and the approach they used for POS tagging was considerably faster than its predecessor. A more recent development was the use of Conditional Random Field (CRF) for POS tagging (Sha and P"
W16-5811,J95-4004,0,0.769427,"s, 1995; Meteer et al., 1991; Merialdo, 1994) are widely used because of the simplicity and the independence of the language models. Most commonly used statistical models are bi-gram, tri-gram and Hidden Markov Model (HMM). The only problem with statistical models is that these kinds of taggers require a large annotated corpus. Machine learning algorithms are statistical in nature but the models are 91 more complicated than simple n-gram. Models for acquiring disambiguation rules and transformation rules from the dataset were constructed in late 80’s and early 90’s (Hindle, 1989; Brill, 1992; Brill, 1995a; Brill, 1995b). Neural networks have also been used for POS tagging (Nakamura et al., 1990; Sch¨utze, 1993; Ma and Isahara, 1998; Eineborg and Gamb¨ack, 1994). POS taggers were also developed using Support Vector Machine (SVM) (Nakagawa et al., 2001). These taggers were more simple and efficient than the previous taggers. The successor of this tagger was developed by Gim´enez and Marquez (2004) and the approach they used for POS tagging was considerably faster than its predecessor. A more recent development was the use of Conditional Random Field (CRF) for POS tagging (Sha and Pereira, 2003;"
W16-5811,W95-0101,0,0.401094,"s, 1995; Meteer et al., 1991; Merialdo, 1994) are widely used because of the simplicity and the independence of the language models. Most commonly used statistical models are bi-gram, tri-gram and Hidden Markov Model (HMM). The only problem with statistical models is that these kinds of taggers require a large annotated corpus. Machine learning algorithms are statistical in nature but the models are 91 more complicated than simple n-gram. Models for acquiring disambiguation rules and transformation rules from the dataset were constructed in late 80’s and early 90’s (Hindle, 1989; Brill, 1992; Brill, 1995a; Brill, 1995b). Neural networks have also been used for POS tagging (Nakamura et al., 1990; Sch¨utze, 1993; Ma and Isahara, 1998; Eineborg and Gamb¨ack, 1994). POS taggers were also developed using Support Vector Machine (SVM) (Nakagawa et al., 2001). These taggers were more simple and efficient than the previous taggers. The successor of this tagger was developed by Gim´enez and Marquez (2004) and the approach they used for POS tagging was considerably faster than its predecessor. A more recent development was the use of Conditional Random Field (CRF) for POS tagging (Sha and Pereira, 2003;"
W16-5811,A92-1018,0,0.90259,"Missing"
W16-5811,J95-2001,0,0.720948,"Missing"
W16-5811,J88-1003,0,0.852006,"Missing"
W16-5811,P11-2008,0,0.182294,"Missing"
W16-5811,P89-1015,0,0.7253,"992; Dermatas and Kokkinakis, 1995; Meteer et al., 1991; Merialdo, 1994) are widely used because of the simplicity and the independence of the language models. Most commonly used statistical models are bi-gram, tri-gram and Hidden Markov Model (HMM). The only problem with statistical models is that these kinds of taggers require a large annotated corpus. Machine learning algorithms are statistical in nature but the models are 91 more complicated than simple n-gram. Models for acquiring disambiguation rules and transformation rules from the dataset were constructed in late 80’s and early 90’s (Hindle, 1989; Brill, 1992; Brill, 1995a; Brill, 1995b). Neural networks have also been used for POS tagging (Nakamura et al., 1990; Sch¨utze, 1993; Ma and Isahara, 1998; Eineborg and Gamb¨ack, 1994). POS taggers were also developed using Support Vector Machine (SVM) (Nakagawa et al., 2001). These taggers were more simple and efficient than the previous taggers. The successor of this tagger was developed by Gim´enez and Marquez (2004) and the approach they used for POS tagging was considerably faster than its predecessor. A more recent development was the use of Conditional Random Field (CRF) for POS taggi"
W16-5811,P98-2131,0,0.204032,"age models. Most commonly used statistical models are bi-gram, tri-gram and Hidden Markov Model (HMM). The only problem with statistical models is that these kinds of taggers require a large annotated corpus. Machine learning algorithms are statistical in nature but the models are 91 more complicated than simple n-gram. Models for acquiring disambiguation rules and transformation rules from the dataset were constructed in late 80’s and early 90’s (Hindle, 1989; Brill, 1992; Brill, 1995a; Brill, 1995b). Neural networks have also been used for POS tagging (Nakamura et al., 1990; Sch¨utze, 1993; Ma and Isahara, 1998; Eineborg and Gamb¨ack, 1994). POS taggers were also developed using Support Vector Machine (SVM) (Nakagawa et al., 2001). These taggers were more simple and efficient than the previous taggers. The successor of this tagger was developed by Gim´enez and Marquez (2004) and the approach they used for POS tagging was considerably faster than its predecessor. A more recent development was the use of Conditional Random Field (CRF) for POS tagging (Sha and Pereira, 2003; Lafferty et al., 2001; Shrivastav et al., 2006). These taggers are better for disambiguation as they find global maximum likeliho"
W16-5811,J94-2001,0,0.805331,"Missing"
W16-5811,H91-1065,0,0.705359,"Missing"
W16-5811,C90-3038,0,0.806135,"icity and the independence of the language models. Most commonly used statistical models are bi-gram, tri-gram and Hidden Markov Model (HMM). The only problem with statistical models is that these kinds of taggers require a large annotated corpus. Machine learning algorithms are statistical in nature but the models are 91 more complicated than simple n-gram. Models for acquiring disambiguation rules and transformation rules from the dataset were constructed in late 80’s and early 90’s (Hindle, 1989; Brill, 1992; Brill, 1995a; Brill, 1995b). Neural networks have also been used for POS tagging (Nakamura et al., 1990; Sch¨utze, 1993; Ma and Isahara, 1998; Eineborg and Gamb¨ack, 1994). POS taggers were also developed using Support Vector Machine (SVM) (Nakagawa et al., 2001). These taggers were more simple and efficient than the previous taggers. The successor of this tagger was developed by Gim´enez and Marquez (2004) and the approach they used for POS tagging was considerably faster than its predecessor. A more recent development was the use of Conditional Random Field (CRF) for POS tagging (Sha and Pereira, 2003; Lafferty et al., 2001; Shrivastav et al., 2006). These taggers are better for disambiguatio"
W16-5811,N13-1039,0,0.166125,"Missing"
W16-5811,P97-1032,0,0.343275,"Missing"
W16-5811,P93-1034,0,0.706129,"Missing"
W16-5811,N03-1028,0,0.341996,"ill, 1992; Brill, 1995a; Brill, 1995b). Neural networks have also been used for POS tagging (Nakamura et al., 1990; Sch¨utze, 1993; Ma and Isahara, 1998; Eineborg and Gamb¨ack, 1994). POS taggers were also developed using Support Vector Machine (SVM) (Nakagawa et al., 2001). These taggers were more simple and efficient than the previous taggers. The successor of this tagger was developed by Gim´enez and Marquez (2004) and the approach they used for POS tagging was considerably faster than its predecessor. A more recent development was the use of Conditional Random Field (CRF) for POS tagging (Sha and Pereira, 2003; Lafferty et al., 2001; Shrivastav et al., 2006). These taggers are better for disambiguation as they find global maximum likelihood estimation. 2.1 POS Taggers for Indian Languages Recently, a large number of researchers are trying to expand the scope of automatic POS taggers so that they can work on complex non European languages. India is a country with rich linguistics so POS taggers for Indian languages are one of the most explored topics. The first effort was to develop a Hindi POS tagger dated back in the nineties (Bharati et al., 1995). This tagger was based on a morphological analyze"
W16-5811,D08-1102,0,0.163785,"Missing"
W16-5811,N03-1033,0,0.14045,"exts. The various language tags used in the training data are en (English), hi (Hindi), bn (Bengali), ta (Tamil), ne (Named entities), acro (Acronyms), univ (Universal) and undef (Undefined). For each input file, we have performed chunking on the raw text to segment the words belonging to different language tag. We haves used the language ids to perform chunking. For each of the language tags, we have created a wordlist belonging to that particular language tag. We also maintain a 93 4.3.1 POS Tagging Using Stanford POS Tagger For our baseline, we trained our system using Stanford POS Tagger (Toutanova et al., 2003). Using the training data, we trained the Stanford POS Tagger initially. The architecture (arch property of the tagger) that we used for training was: words(1,1), unicodeshapes(-1,1), order(2), suffix(4). Four individual models were generated for English, Bengali, Hindi and Tamil. The test data was tagged using these generated models. 4.3.2 POS Tagging Using CRF++ In this work, Conditional Random Field (CRF) has been used to build the framework for wordlevel language identification classifier. We have used CRF++ toolkit 4 which is a simple, customizable, and open source implementation of CRF."
W16-5811,D14-1105,0,0.299369,"Missing"
W16-5811,C98-2127,0,\N,Missing
W16-5814,P05-1045,0,0.0753835,"Code Switching, pages 112–115, c Austin, TX, November 1, 2016. 2016 Association for Computational Linguistics 4. NE: Named Entities- used for proper nouns like people, places, organizations, locations, titles and such. with code-switching possibility between English and Spanish would most likely borrow words from one of these languages. 5. ambiguous: Ambiguous words that exist in both English and Spanish and suh words are hard to be clarified based on the context given. 4. Stanford Named Entity Recognizer: For identifying the named entities, we used the Stanford NER (Named Entity Recognizer) (Finkel et al., 2005) and it’s Python interface in the nltk library3 . 6. FW: Foreign words, which do not appear either in English or in Spanish, but exist in another language and used in that context. 3.2 Algorithm 7. UNK: Unknown words which do not fit any of the above categories and is unrecognizable. 3.2.1 Word Slicing For identifying the mixed words, we use a wordslicing algorithm. It consists of the following steps: 8. Other: Numbers, symbols, emojis, URLs and anything else that is not a ”word”. However, the words beginning with a ”hashtag” (#) are treated as other tag. 1. We keep slicing a word into two par"
W16-5814,D12-1039,0,0.0208391,"of sentences and we were asked to develop a system that would annotate every token in the entire corpus of tweets as one of the given eight labels. 3 Tools and Techniques Used 3.1 Lexicons used The dictionaries we used are the following: 1. English dictionary: We use the Python Enchant library2 for checking the English words and their existence in the dictionary. We also create a slang dictionary of our own containing colloquial English text words such as ”LOL” and ”gr8”. We collected the lexicons from the works of researchers at the University of Melbourne and University of Texas at Dallas (Han et al., 2012; Liu et al., 2011; Liu et al., 2012). 2. Spanish dictionary: We use the Python Enchant library once again for checking of the words’ existence in the Spanish dictionary. 3. Foreign dictionaries: We also use the Italian, French, Portuguese (Brazil), Portuguese (Portugal) and German dictionaries from Python Enchant to check for words’ existence. Since the geographical spread is given, any person 2 • • • • 2. For each of these splits, we check if one part is present in the English dictionary and one part appears in the Spanish dictionary. In such cases, it would be declared as a mixed word. For"
W16-5814,P11-2013,0,0.0157759,"we were asked to develop a system that would annotate every token in the entire corpus of tweets as one of the given eight labels. 3 Tools and Techniques Used 3.1 Lexicons used The dictionaries we used are the following: 1. English dictionary: We use the Python Enchant library2 for checking the English words and their existence in the dictionary. We also create a slang dictionary of our own containing colloquial English text words such as ”LOL” and ”gr8”. We collected the lexicons from the works of researchers at the University of Melbourne and University of Texas at Dallas (Han et al., 2012; Liu et al., 2011; Liu et al., 2012). 2. Spanish dictionary: We use the Python Enchant library once again for checking of the words’ existence in the Spanish dictionary. 3. Foreign dictionaries: We also use the Italian, French, Portuguese (Brazil), Portuguese (Portugal) and German dictionaries from Python Enchant to check for words’ existence. Since the geographical spread is given, any person 2 • • • • 2. For each of these splits, we check if one part is present in the English dictionary and one part appears in the Spanish dictionary. In such cases, it would be declared as a mixed word. For example, if ”abc”"
W16-5814,P12-1109,0,0.0232547,"evelop a system that would annotate every token in the entire corpus of tweets as one of the given eight labels. 3 Tools and Techniques Used 3.1 Lexicons used The dictionaries we used are the following: 1. English dictionary: We use the Python Enchant library2 for checking the English words and their existence in the dictionary. We also create a slang dictionary of our own containing colloquial English text words such as ”LOL” and ”gr8”. We collected the lexicons from the works of researchers at the University of Melbourne and University of Texas at Dallas (Han et al., 2012; Liu et al., 2011; Liu et al., 2012). 2. Spanish dictionary: We use the Python Enchant library once again for checking of the words’ existence in the Spanish dictionary. 3. Foreign dictionaries: We also use the Italian, French, Portuguese (Brazil), Portuguese (Portugal) and German dictionaries from Python Enchant to check for words’ existence. Since the geographical spread is given, any person 2 • • • • 2. For each of these splits, we check if one part is present in the English dictionary and one part appears in the Spanish dictionary. In such cases, it would be declared as a mixed word. For example, if ”abc” was identified as a"
W17-2511,P91-1022,0,0.838247,"Missing"
W17-2511,1992.tmi-1.7,0,0.765608,"Missing"
W17-2511,P93-1001,0,0.447518,"Missing"
W17-2511,W14-3323,0,0.0143851,"tion process from corpora of translated texts. SMT has shown good results for many language pairs and is responsible for the recent surge in terms of popularity of Machine Translation among the research communities. But, for a SMT system to work efficiently, it has to be fed with large parallel corpus, for producing high quality phrase table and translation models (Brown et. al., 1991; Church et. al., 1993; Dagan et. al., 1999). Since availability of large parallel corpus is an issue for low resourced languages, building one from scratch involves high manual labor and cost (Pal et. al., 2014; Tan and Pal, 2014; Mahata et. al., 2016). This is the reason why lot of research has gone into the concept of building parallel corpus, from comparable corpus (JagarlaThe algorithm of the proposed work has been constructed primarily using Moses (Koehn, 2015) toolkit that has been fed with parallel corpus from Europarl2, with French as the source language and English as the target language. Also, the similarity based on sentence length has been used for the preliminary alignment because equivalent sentences in comparable corpus may roughly correspond with respect to length. Cosine Similarity algorithm was used"
W17-2511,E09-1096,0,0.0856275,"Missing"
W17-2511,P91-1023,0,0.698144,"y Algorithm Cosine similarity is particularly used in positive space, where the outcome is neatly bounded in [0, 1]. The formula used in our approach is as fo follows.  cos  Sentence similarity based on sentence length .  ‖‖‖‖ ∑   ∑  ∑  (1) Where &quot;A&quot; and &quot;B&quot; are the translated English sentence and one of the English sentences from the test data found out using the preliminary alig alignment system, respectively. One sentence from the translated English corpus is taken and is matched with the selected sentences in English corpus from heir paper paper, proGale and Church (1991) in their posed a system for aligning corresponding sense tences in a parallel corpora, based on the principle that equivalent sentences should roughly correscorre pond in length—that that is, longer sentences in one language should correspond rrespond to longer sentences iin 57 ACL 2017 Submission sion ***. Confidential review C Copy. DO NOT DISTRIBUTE. the test data, using the Cosine Similari Similarity algorithm. The sentence pair with the highest Cosine SimiSim larity value ue is considered as the final alignment. Sentence_id&apos;s of the selected sentence pair aare extracted and given as outp"
W17-2511,P11-2026,0,0.0507666,"Missing"
W17-2511,J93-1006,0,0.678294,"Missing"
W17-2511,W16-2373,1,0.406854,"Missing"
W17-2511,P93-1003,0,0.522563,"Missing"
W17-2511,2012.eamt-1.62,0,0.0728448,"Missing"
W17-7527,W98-1118,0,0.0430349,"s the dataset preparation and brat representation technique. Section 4 and Section 5 present the proposed relation extraction system and its evaluation approach. Finally, Section 6 presents the concluding remarks related to our study. 2 2.1 Related Work Medical Ontologies and Lexicons Biomedical information extraction research is challenging due to the availability of a large number of daily produced unstructured and semistructured medical corpus. To represent the structured corpus and extracting the subjective and conceptual information from the corpus, a domainspecific lexicon is essential (Borthwick et al., 1998). To this end, the standard vocabularies and ontologies such as UMLS (Unified Medical Language System) and SNOMED-CT (Systematized Nomenclature of Medicine-Clinical Terms), and lexicons like MEN (Medical WordNet) and WME (WordNet of Medical Event) have used by the researchers (Smith and Fellbaum, 2004; Kilgarriff and Fellbaum, 2000; Mondal et al., 2016a). 2.2 Medical Category and Relation Extraction These ontologies and lexicons assist in extracting the relevant information from the corpus such as medical concept categories and relations between medical concepts. Relation Dr-SyDi Explanation a"
W17-7527,embarek-ferret-2008-learning,0,0.0633269,"Missing"
W17-7527,W10-1912,0,0.0809788,"Missing"
W17-7527,C92-2082,0,0.497768,"eparation by a group of medical practitioners. The dataset has been labeled with medical concepts and their categories and proposed eight types of category-based relations in a context. We have acquired the dataset from SemEval-2015 Task-6 and MedicineNet resources which contain around 2000 number of medical contexts. The dataset helps to design and validate the relationship extraction system. II. Relationship extraction plays a key role in identifying the semantic information from the corpus. To extract these relations, we have proposed a linguistic rule-based (Abacha and Zweigenbaum, 2011a; Hearst, 1992) and a feature-oriented ma213 chine learning (Rink et al., 2011; Zhu et al., 2009) approach. The rule-based patterns help to identify the specific relations from the dataset, whereas machine learning approach assists in extracting generalize relations with promising accuracy. For an example, the following medical context is able to extract disease - symptom (illustration, inflammation symptom for the adnexitis disease) and symptom - human anatomy (illustration, inflammation affect the uterus) relations. ”The adnexitis disease characterizes inflammation symptom of attachments of the uterus huma"
W17-7527,P00-1043,0,0.293276,"Missing"
W17-7527,2016.gwc-1.35,1,0.689967,"types of different semantic relations viz. drug-drug, disease-drug, and human anatomy-symptom from the medical context. Thereafter, we have validated both rules and features-oriented approaches and offers an average FMeasures of 0.79 and 0.86 individually. 1 Introduction The availability of medical documents such as reports, discharge summaries, and prescriptions and their related information are growing quickly. In order to extract critical and crucial information, the researchers have applied various statistical and ontology-based approaches with well-known ma212 chine learning classifiers (Mondal et al., 2016b; Uzuner et al., 2011). The extracted informations are medical concepts (terms), categories (classes), and their relations, which assist the experts such as doctors and other medical practitioners as well as the non-experts as patients in understanding the problems (e.g. diseases, symptoms) and their related remedies (e.g. drugs). The medical concepts are presented by the key terms like words or phrases of the corpus whereas the category refers to the fundamental classes of medical concepts such as diseases and symptoms. The assigned categories of medical concepts and their in-between relatio"
W17-7527,H05-1092,0,0.121217,"Missing"
W17-7527,C04-1054,0,0.0422605,"rmation extraction research is challenging due to the availability of a large number of daily produced unstructured and semistructured medical corpus. To represent the structured corpus and extracting the subjective and conceptual information from the corpus, a domainspecific lexicon is essential (Borthwick et al., 1998). To this end, the standard vocabularies and ontologies such as UMLS (Unified Medical Language System) and SNOMED-CT (Systematized Nomenclature of Medicine-Clinical Terms), and lexicons like MEN (Medical WordNet) and WME (WordNet of Medical Event) have used by the researchers (Smith and Fellbaum, 2004; Kilgarriff and Fellbaum, 2000; Mondal et al., 2016a). 2.2 Medical Category and Relation Extraction These ontologies and lexicons assist in extracting the relevant information from the corpus such as medical concept categories and relations between medical concepts. Relation Dr-SyDi Explanation and Example A drug how helps to improve or cure or side effects the diseases or symptoms. Warfarin is also used to reduce the risk of clots causing strokes or heart attacks. Ha-SyDi A disease or symptom which effects a part of the body. A painful inflammation of the big toe and foot. Di-Sy The symptoms"
W17-7536,C16-1186,1,0.914323,"mantic information than audio for some of Hindi songs, i.e., the annotators perceived differ1 https://play.google.com/music/listen https://www.apple.com/music 3 https://www.last.fm 4 https://www.pandora.com 5 https://www.spotify.com 6 https://gaana.com 7 http://www.hungama.com 8 https://www.saavn.com 9 https://www.wynk.in/music S Bandyopadhyay, D S Sharma and R Sangal. Proc. of the 14th Intl. Conference on Natural Language Processing, pages 290–297, c Kolkata, India. December 2017. 2016 NLP Association of India (NLPAI) 2 ent moods while reading lyrics and listening to the corresponding songs (Patra et al., 2016b). People are interested in listening to songs specific to situation and mood (Duncan and Fox, 2005). There is a need for recommendation system based on information within the music as well as the metadata of music such as mood, genre, artist name, and so on. Music similarity measures can help to understand why two music pieces are perceived alike by the listener and to guide the user in efficiently retrieving desired piece of music (Schedl et al., 2011). Query by hamming helps to find an exact song with respect to a query humming. Again, a lyrics based retrieval system could be helpful for s"
W17-7536,W15-5939,1,0.681636,"RADAR was developed by Sasaki et al. (2014) and they visualized the topics of Japaneses lyrics by using a Latent Dirichlet Allocation (LDA). Several experiments were performed on retrieving similar lyrics for Western songs by (Mahedero et al., 2005; Knees et al., 2007; Schedl et al., 2011), Mandarin lyrics by (Wang et al., 2010), and Chinese lyrics by (Han et al., 2015). 2.1 Experiments on Indian Songs MIR in Indian songs is at early stage. Recently, mood classification of Hindi songs have been performed using audio (Ujlambkar and Attar, 2012; Patra et al., 2013; Patra et al., 2016a), lyrics (Patra et al., 2015), and combination of both (Patra et al., 2016b; Patra et al., 2016c). The datasets used in above experiments are small and not adequate for development of recommendation system. Some other tasks like raga identification of south Indian Carnatic music (Sridhar et al., 2011), multimodal sentiment analysis of Telugu songs (Abburi et al., 2016), melody identification of Carnatic music (Koduri et al., 2011), rhythm analysis of Indian art music (Srinivasamurthy et al., 2014) etc. have been performed till date. To the best of author’s knowledge, almost no work exists for retrieving similar lyrics for"
W17-7545,D11-1120,0,0.100632,"Missing"
W17-7555,D10-1008,0,0.0857638,"Missing"
W17-7555,paul-das-2017-identification,1,0.713967,"associativity among them. After that we have tested our model and observed the precision, recall, f-measure, kappa and errors. In the rest of the paper, we have discussed related work and the data preparation steps followed by S Bandyopadhyay, D S Sharma and R Sangal. Proc. of the 14th Intl. Conference on Natural Language Processing, pages 447–455, c Kolkata, India. December 2017. 2016 NLP Association of India (NLPAI) experiments, result and error analysis, visualization of co-occurred Characters and conclusion. 2 Related Work There are a few works done on Character Identification from texts. Paul and Das (2017) proposed a rule based system by which they can extract the Character Adjectives from the Indian mythological text Mahabharata. Valls-Vargas et al. (2015) also proposed a feedback-loop-based approach to identify the characters and their narrative roles where the output of later modules of the pipeline is fed back to earlier ones. Valls-Vargas et al. (2014) proposed a case-based approach to character identification in natural language text in the context of their Voz system. Valls-Vargas et al. (2013) proposed a method for automatically assigning narrative roles to characters in stories. Calix"
W18-6418,W16-2373,1,0.414314,"complish the given task. The current paper documents the preprocessing steps, the description of the submitted system and the results produced using the same. Our system garnered a BLEU score of 12.9. 1 Introduction Machine Translation (MT) is automated translation of one natural language to another using computer software. Translation is a tough task, not only for computers, but humans as well as it incorporates a thorough understanding of the syntax and semantics of both languages. For any MT system to return good translations, it needs good quality and sufficient amount of parallel corpus (Mahata et al., 2016, 2017). In the modern context, MT systems can be categorized into Statistical Machine Translation (SMT) and Neural Machine Translation (NMT). SMT has had its share in making MT very popular among the masses. It includes creating statistical models, whose input parameters are derived from the analysis of bilingual text corpora, created by professional translators (Weaver, 1955). The state-of-art for SMT is Moses Toolkit1 , created by Koehn et al. (2007), incorporates subcomponents like Language Model generation, Word Alignment and Phrase Table generation. Various works have been done in SMT (L"
W18-6418,W17-2511,1,0.336269,"Missing"
W18-6418,D13-1140,0,0.0651378,"u et al., 2014), though relatively new, has shown considerable improvements in the translation results when compared to SMT (Mahata et al., 2018). This includes better fluency of the output and better handling of the Out-of-Vocabulary problem. Unlike SMT, it doesn’t depend on alignment and phrasal unit translations (Kalchbrenner and Blunsom, 2013). On the contrary, it uses an EncoderDecoder approach incorporating Recurrent Neural Cells (Cho et al., 2014). As a result, when given sufficient amount of training data, it gives much more accurate results when compared to SMT (Doherty et al., 2010; Vaswani et al., 2013; Liu et al., 2014). Further, NMT can be of two types, namely Word Level NMT and Character Level NMT. Word Level NMT, though very successful, suffers from a few disadvantages. It are unable to model rare words (Lee et al., 2016). Also, since it does not learn the morphological structure of a language it suffers when accommodating morphologically rich languages (Ling et al., 2015). We can address this issue, by training the models with huge parallel corpus, but, this in turn, produces very complex and resource consuming models that aren’t feasible enough. To combat this, we plan to use Characte"
W18-6418,W14-4012,0,0.359469,"Missing"
W18-6418,D13-1176,0,0.116149,"ine Translation of Finnish to English Sainik Kumar Mahata, Dipankar Das, Sivaji Bandyopadhyay Computer Science and Engineering Jadavpur University, Kolkata, India sainik.mahata@gmail.com, dipankar.dipnil2005@gmail.com, sivaji cse ju@yahoo.com Abstract On the other hand NMT (Bahdanau et al., 2014), though relatively new, has shown considerable improvements in the translation results when compared to SMT (Mahata et al., 2018). This includes better fluency of the output and better handling of the Out-of-Vocabulary problem. Unlike SMT, it doesn’t depend on alignment and phrasal unit translations (Kalchbrenner and Blunsom, 2013). On the contrary, it uses an EncoderDecoder approach incorporating Recurrent Neural Cells (Cho et al., 2014). As a result, when given sufficient amount of training data, it gives much more accurate results when compared to SMT (Doherty et al., 2010; Vaswani et al., 2013; Liu et al., 2014). Further, NMT can be of two types, namely Word Level NMT and Character Level NMT. Word Level NMT, though very successful, suffers from a few disadvantages. It are unable to model rare words (Lee et al., 2016). Also, since it does not learn the morphological structure of a language it suffers when accommodati"
W18-6418,P09-5002,0,0.183812,"the modern context, MT systems can be categorized into Statistical Machine Translation (SMT) and Neural Machine Translation (NMT). SMT has had its share in making MT very popular among the masses. It includes creating statistical models, whose input parameters are derived from the analysis of bilingual text corpora, created by professional translators (Weaver, 1955). The state-of-art for SMT is Moses Toolkit1 , created by Koehn et al. (2007), incorporates subcomponents like Language Model generation, Word Alignment and Phrase Table generation. Various works have been done in SMT (Lopez, 2008; Koehn, 2009) and it has shown good results for many language pairs. 1 2 http://www.statmt.org/moses/ 445 http://www.statmt.org/wmt18/translation-task.html Proceedings of the Third Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 445–448 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64045 nizers provided the required parallel corpora, consisting of 3,255,303 sentence pairs, for training the translation model. The statistics of the parallel corpus is depicted in Table 1 Our model was trained on"
W18-6418,P07-2045,0,0.00827476,"nd semantics of both languages. For any MT system to return good translations, it needs good quality and sufficient amount of parallel corpus (Mahata et al., 2016, 2017). In the modern context, MT systems can be categorized into Statistical Machine Translation (SMT) and Neural Machine Translation (NMT). SMT has had its share in making MT very popular among the masses. It includes creating statistical models, whose input parameters are derived from the analysis of bilingual text corpora, created by professional translators (Weaver, 1955). The state-of-art for SMT is Moses Toolkit1 , created by Koehn et al. (2007), incorporates subcomponents like Language Model generation, Word Alignment and Phrase Table generation. Various works have been done in SMT (Lopez, 2008; Koehn, 2009) and it has shown good results for many language pairs. 1 2 http://www.statmt.org/moses/ 445 http://www.statmt.org/wmt18/translation-task.html Proceedings of the Third Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 445–448 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64045 nizers provided the required parallel corp"
W18-6418,P16-1160,0,0.0543514,"ary problem. Unlike SMT, it doesn’t depend on alignment and phrasal unit translations (Kalchbrenner and Blunsom, 2013). On the contrary, it uses an EncoderDecoder approach incorporating Recurrent Neural Cells (Cho et al., 2014). As a result, when given sufficient amount of training data, it gives much more accurate results when compared to SMT (Doherty et al., 2010; Vaswani et al., 2013; Liu et al., 2014). Further, NMT can be of two types, namely Word Level NMT and Character Level NMT. Word Level NMT, though very successful, suffers from a few disadvantages. It are unable to model rare words (Lee et al., 2016). Also, since it does not learn the morphological structure of a language it suffers when accommodating morphologically rich languages (Ling et al., 2015). We can address this issue, by training the models with huge parallel corpus, but, this in turn, produces very complex and resource consuming models that aren’t feasible enough. To combat this, we plan to use Character level NMT, so that it can learn the morphological aspects of a language and construct a word, character by character, and hence tackle the rare word occurrence problem to some extent. In the current work, we participated in th"
W19-5328,W16-2373,1,0.836578,"n model. The current paper documents the architecture of our model, descriptions of the various modules and the results produced using the same. Our system garnered a BLEU score of 17.6. 1 Introduction Machine Translation (MT) is automated translation of one natural language to another using a computer. Translation, itself, is a very tough task for both humans as well as a computer. It requires a thorough understanding of the syntax and semantics of both the languages under consideration. For producing good translations, a MT system needs good quality and sufficient amount of parallel corpus (Mahata et al., 2016, 2017). In the modern context, MT systems can be categorized into Statistical Machine Translation (SMT) and Neural Machine Translation (NMT). SMT has had its share in making MT very popular among the masses. It includes creating statistical models, whose input parameters are derived from the analysis of bilingual text corpora, created by professional translators (Weaver, 1955). The state-of-art for SMT is Moses Toolkit1 , created by Koehn et al. (2007), incorporates subcomponents like Language Model generation, Word Alignment and Phrase Table generation. Various works have been done in SMT (L"
W19-5328,W17-2511,1,0.890953,"Missing"
W19-5328,W18-6418,1,0.42814,"Missing"
W19-5328,W14-4012,0,0.165722,"Missing"
W19-5328,W11-2123,0,0.0171126,"c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics # sentences in Lt corpus # sentences in En corpus # words in Lt corpus # words in En corpus # word vocab size for Lt corpus # word vocab size for En corpus 9,62,022 9,62,022 1,16,65,937 1,56,22,488 4,88,593 2,27,131 search algorithm quickly finds the highest probability translation among the exponential number of choices. We trained Moses using 7,62,022 sentence pairs provided by WMT2019, with Lithuanian as the source language and English as the target language. For building the Language Model we used KenLM4 (Heafield, 2011) with 7-grams from the target corpus. The English monolingual corpus from WMT2019 was used to build the language model Training the Moses statistical MT system resulted in generation of Phrase Model and Translation Model that helps in translating between source-target language pairs. Moses scores the phrase in the phrase table with respect to a given source sentence and produces best scored phrases as output. Table 1: Statistics of the Lithuanian-English parallel corpus provided by the organizers. ”#” depicts No. of. ”Lt” and ”En” depict Lithuanian and English, respectively. ”vocab” means voca"
W19-5328,P02-1040,0,0.105969,"parametric function outk re2,00,000 translated English sentences and the returns the conditional probability using the next tarspective gold standard 2,00,000 sentences, from get symbol k. the Lithuanian-English sentence pair, were given as input to a word embedding based NMT model. 1 (y t = k |y < t, X) = exp(outk (E y (y t −1), st , ct )) As a result, this constituted our Hybrid model. Z 2.3.2 Testing Z is the normalizing constant, For the testing purpose, 10k Lithuanian Sentences X were fed to the Hybrid model, and the output, j exp(outj (E y (y t − 1), st , ct )) when checked using BLEU (Papineni et al., 2002), resulted in an accuracy of 21.6. The training and The entire model can be trained end-to-end by testing architecture is shown in Figure 1 minimizing the log likelihood which is defined as 3 n N Ty 1 XX L=− logp(y t = y t n , y ¡t n , X n ) N WMT2019 provided us with a test set of Lithuanian sentences in .SGM format. This file was parsed and fed to our hybrid system. The output file was again converted to .SGM format and submitted to the organizers. Our system garnered a BLEU Score of 17.6, when it was scored using automated accuracy metrics. Other accuracy scores are mentioned in Table 2. n="
W19-5328,D13-1176,0,0.0495964,"Rayala, Dipankar Das, Sivaji Bandyopadhyay Computer Science and Engineering Jadavpur University, Kolkata, India sainik.mahata@gmail.com, avishekgarain@gmail.com, mailsofadityar@gmail.com, dipankar.dipnil2005@gmail.com, sivaji cse ju@yahoo.com Abstract On the other hand NMT (Bahdanau et al., 2014), though relatively new, has shown considerable improvements in the translation results when compared to SMT (Mahata et al., 2018b). This includes better fluency of the output and better handling of the Out-of-Vocabulary problem. Unlike SMT, it doesnt depend on alignment and phrasal unit translations (Kalchbrenner and Blunsom, 2013). On the contrary, it uses an EncoderDecoder approach incorporating Recurrent Neural Cells (Cho et al., 2014). As a result, when given sufficient amount of training data, it gives much more accurate results when compared to SMT (Doherty et al., 2010; Vaswani et al., 2013; Liu et al., 2014). For the given task2 , we attempted to create a MT system that can translate sentences from Lithuanian to English. Since, using only SMT or NMT models leads to some or the other disadvantages, we tried to use both in a pipeline. This leads to an improvement of the results over the individual usage of either"
W19-5328,P09-5002,0,0.0209299,"the modern context, MT systems can be categorized into Statistical Machine Translation (SMT) and Neural Machine Translation (NMT). SMT has had its share in making MT very popular among the masses. It includes creating statistical models, whose input parameters are derived from the analysis of bilingual text corpora, created by professional translators (Weaver, 1955). The state-of-art for SMT is Moses Toolkit1 , created by Koehn et al. (2007), incorporates subcomponents like Language Model generation, Word Alignment and Phrase Table generation. Various works have been done in SMT (Lopez, 2008; Koehn, 2009) and it has shown good results for many language pairs. 1 2 http://www.statmt.org/moses/ http://www.statmt.org/wmt19/translation-task.html 283 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 2: Shared Task Papers (Day 1) pages 283–286 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics # sentences in Lt corpus # sentences in En corpus # words in Lt corpus # words in En corpus # word vocab size for Lt corpus # word vocab size for En corpus 9,62,022 9,62,022 1,16,65,937 1,56,22,488 4,88,593 2,27,131 search algorithm quickly finds the high"
W19-5328,D13-1140,0,0.0353085,"u et al., 2014), though relatively new, has shown considerable improvements in the translation results when compared to SMT (Mahata et al., 2018b). This includes better fluency of the output and better handling of the Out-of-Vocabulary problem. Unlike SMT, it doesnt depend on alignment and phrasal unit translations (Kalchbrenner and Blunsom, 2013). On the contrary, it uses an EncoderDecoder approach incorporating Recurrent Neural Cells (Cho et al., 2014). As a result, when given sufficient amount of training data, it gives much more accurate results when compared to SMT (Doherty et al., 2010; Vaswani et al., 2013; Liu et al., 2014). For the given task2 , we attempted to create a MT system that can translate sentences from Lithuanian to English. Since, using only SMT or NMT models leads to some or the other disadvantages, we tried to use both in a pipeline. This leads to an improvement of the results over the individual usage of either SMT or NMT. The main idea was to train a SMT model for translating Lithuanian language to English. Thereafter, a test set was translated using this model. Then, a word embedding based NMT model was trained to learn the mappings between the SMT output (in English) and the"
W19-5328,P07-2045,0,0.00753716,"h the languages under consideration. For producing good translations, a MT system needs good quality and sufficient amount of parallel corpus (Mahata et al., 2016, 2017). In the modern context, MT systems can be categorized into Statistical Machine Translation (SMT) and Neural Machine Translation (NMT). SMT has had its share in making MT very popular among the masses. It includes creating statistical models, whose input parameters are derived from the analysis of bilingual text corpora, created by professional translators (Weaver, 1955). The state-of-art for SMT is Moses Toolkit1 , created by Koehn et al. (2007), incorporates subcomponents like Language Model generation, Word Alignment and Phrase Table generation. Various works have been done in SMT (Lopez, 2008; Koehn, 2009) and it has shown good results for many language pairs. 1 2 http://www.statmt.org/moses/ http://www.statmt.org/wmt19/translation-task.html 283 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 2: Shared Task Papers (Day 1) pages 283–286 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics # sentences in Lt corpus # sentences in En corpus # words in Lt corpus # words in En cor"
W19-5328,P16-1160,0,0.0625872,"Missing"
W19-5328,P14-1140,0,\N,Missing
W19-5328,Q17-1026,0,\N,Missing
W19-5328,P03-1020,0,\N,Missing
W19-5328,W18-6401,0,\N,Missing
Y10-1013,H05-1073,0,0.429018,"Missing"
Y10-1013,P09-2038,1,0.886754,"Missing"
Y10-1013,esuli-sebastiani-2006-sentiwordnet,0,0.0650139,"Missing"
Y10-1013,C04-1200,0,0.0720567,"s compared to the accuracy values of the word level system (Das and Bandyopadhyay, 2009a). The rest of the paper is organized as follows. Section 2 surveys the related work. Preprocessing is described in Section 3. The baseline system is discussed in Section 4. Section 5 describes a supervised framework for identifying the emotional components. Experimental results are discussed in Section 6. Finally Section 7 concludes the paper. 2 Related Work The earlier works on polarity shifters and prior or contextual polarity approaches for sentiment analysis are described in (Polanyi and Zaenen, 2004; Kim and Hovy, 2004). Another related work described in (Wilson et al., 2005) gives the ground to analyze sentiment at phrase levels. The tasks described in (Meena and Prabhakar, 2007) determine the sentential sentiment based on the phrase level information considering the impact of conjuncts or intensifiers. Majority of the above studies are carried out for sentiment expressions whereas our present approach aims to identify emotional expressions and assigns the emotion tags and intensities to the sentences. In order to estimate affects in text, the model proposed in (Neviarouskaya et al., 2007) processes symboli"
Y10-1013,strapparava-valitutti-2004-wordnet,0,0.169324,"Missing"
Y10-1013,P02-1053,0,0.00575441,"Missing"
Y10-1013,H05-1044,0,0.10479,"Missing"
Y10-1013,de-marneffe-etal-2006-generating,0,\N,Missing
Y10-1013,P07-1055,0,\N,Missing
Y10-1071,H05-1045,0,0.18741,"model is discussed in Section 5. Evaluation mechanism along with the associated results is mentioned in Section 6. Finally Section 7 concludes the paper. 2 Related Work The work on labeling the arguments of the verbs with their semantic roles using a novel frame matching technique is mentioned in (Swier and Stevenson, 2004). Identification of the opinion propositions and their holders is described in (Bethard et al., 2004) mainly for verbs. Identification of opinion holders for Question Answering with supporting annotation task has been attempted from the very beginning (Wiebe et al., 2005). (Choi et al., 2005) used the named entities (NEs) to identify the opinion holders with the help of machine learning and pattern-based techniques. Based on the traditional perspectives, another work discussed in (Hu et al., 2006) uses an emotion knowledge base for extracting emotion holder. The machine learning based classification task for “not holder”, “weak holder”, “medium holder”, or “strong holder” is carried out in (Evans, 2007). Kim and Hovy (2006) identified opinion holder with topic from media text using semantic role labeling. An anaphor resolution based opinion holder identification method exploiting"
Y10-1071,P09-2038,1,0.780124,"sts are annotated by other bloggers. The utilization of blog medium containing users’ emotional contents is therefore considered as an affective substrate to analyze the reaction of emotion catalyst like emotion holder. In the present task, identification of emotion holder is attempted for Bengali; a less privileged, less computerized and morphologically rich language. There is no existing emotion holder annotated corpus in Bengali. Manual annotation of emotion holder and the successive interannotator agreements have been carried out on a small set of 500 sentences of the Bengali blog corpus (Das and Bandyopadhyay, 2009). The corpus is tagged with Ekman’s (1993) six emotion types at sentence level. The phrase based similarity clues containing different part-of-speech (POS) combinations of the blog sentences are considered as the probable candidates of emotion holder for the baseline model. * The work reported in this paper was supported by a grant from the India-Japan Cooperative Programme (DSTJST) 2009 Research project entitled “Sentiment Analysis where AI meets Psychology” funded by Department of Science and Technology (DST), Government of India. Copyright 2010 by Dipankar Das and Sivaji Bandyopadhyay 621 6"
Y10-1071,W06-0301,0,0.0307612,"erbs. Identification of opinion holders for Question Answering with supporting annotation task has been attempted from the very beginning (Wiebe et al., 2005). (Choi et al., 2005) used the named entities (NEs) to identify the opinion holders with the help of machine learning and pattern-based techniques. Based on the traditional perspectives, another work discussed in (Hu et al., 2006) uses an emotion knowledge base for extracting emotion holder. The machine learning based classification task for “not holder”, “weak holder”, “medium holder”, or “strong holder” is carried out in (Evans, 2007). Kim and Hovy (2006) identified opinion holder with topic from media text using semantic role labeling. An anaphor resolution based opinion holder identification method exploiting lexical and syntactic information from online news documents is carried out in (Kim et al., 2007). The syntactic models of identifying emotion holder for English emotional verbs are discussed in (Das and Bandyopadhyay, 2010). The above works are closely related to the present one. But the present approach aims to acquire all probable emotion holders from a sentence if there multiple occurrences exist. Apart from utilizing traditional hi"
Y10-1071,W09-3411,1,0.824068,"Missing"
Y10-1071,ruppenhofer-etal-2008-finding,0,\N,Missing
Y10-1071,P93-1032,0,\N,Missing
