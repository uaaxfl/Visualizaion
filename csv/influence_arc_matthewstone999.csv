2020.acl-main.583,N19-1056,1,0.901411,"Missing"
2020.acl-main.583,D17-1098,0,0.0281789,"Missing"
2020.acl-main.583,D18-2029,0,0.0798455,"Missing"
2020.acl-main.583,D19-1469,0,0.190763,"Missing"
2020.acl-main.583,W19-8643,0,0.0514994,"Missing"
2020.acl-main.583,D14-1162,0,0.0825401,"Missing"
2020.acl-main.583,prasad-etal-2008-penn,0,0.689279,"(Chunseong Park et al., 2017), forced attentions (Sadler et al., 2019) and modeling and learning compositional semantics using fine-grained annotations of entities in MSCOCO (Cornia et al., 2019). 2 The first step toward our goals is to characterize image–text coherence and annotate a sizable corpus of image–text pairs with coherence relations. We use an overlapping set of high-level relations, inspired both by theoretical work linking discourse coherence to discourse structure and discourse goals (Roberts, 2012; Webber et al., 1999), and by previous successful discourse annotation campaigns (Prasad et al., 2008). Crucially, following previous work on text (Rohde et al., 2018) and multimodal discourse (Alikhani et al., 2019), Prior Work There are diverse ways to characterize the communicative functions of text and images in multimodal documents (Marsh and Domas White, 2003), any of which can provide the basis for computational work. Some studies emphasize the distinctive cognitive effects of imagery in directing attention; engaging perceptual, spatial and embodied 1 https://github.com/malihealikhani/Crossmodal Coherence Modeling 3 6526 Coherence in Images and Captions Visible, Meta (a) C APTION : fore"
2020.acl-main.583,P19-1272,0,0.0297845,"Missing"
2020.acl-main.583,P12-2018,0,0.0175938,"a different textual-feature extractor. We train and test using an encoder that takes sentence embeddings as input using the hCLSi representation produced by the BERT-base model (Devlin et al., 2018). Results The results of all of our models are presented in Table 3, where we present the F1 scores over each of the individual relations, as well as an overall weighted average. The BERT+ResNet model achieves the highest performance (|t |&gt; 9.54, p &lt; 0.01), with an overall F1 score of 0.67. For the interested reader, we present in the GitHub page the top features of the Naive Bayes SVM classifier (Wang and Manning, 2012). 4.2 Single-Label Prediction To achieve the goal of generating captions with a desired coherence relation to the image, it is important to clearly differentiate between often cooccurring label types (such as Visible and Meta). To this end, we introduce a label-mapping strategy for predicting coherence relations, such that each image–caption pair is assigned a single coherence label. We map the set of human-annotated coherence relations for an image–caption pair to a single label using the following heuristic: 1. If the set contains the Meta label, then the image–caption pair is assigned the M"
2020.acl-main.583,P18-1210,0,0.0242759,"019) and modeling and learning compositional semantics using fine-grained annotations of entities in MSCOCO (Cornia et al., 2019). 2 The first step toward our goals is to characterize image–text coherence and annotate a sizable corpus of image–text pairs with coherence relations. We use an overlapping set of high-level relations, inspired both by theoretical work linking discourse coherence to discourse structure and discourse goals (Roberts, 2012; Webber et al., 1999), and by previous successful discourse annotation campaigns (Prasad et al., 2008). Crucially, following previous work on text (Rohde et al., 2018) and multimodal discourse (Alikhani et al., 2019), Prior Work There are diverse ways to characterize the communicative functions of text and images in multimodal documents (Marsh and Domas White, 2003), any of which can provide the basis for computational work. Some studies emphasize the distinctive cognitive effects of imagery in directing attention; engaging perceptual, spatial and embodied 1 https://github.com/malihealikhani/Crossmodal Coherence Modeling 3 6526 Coherence in Images and Captions Visible, Meta (a) C APTION : forest on a sunny day Visible, Action, Subjective (b) C APTION : youn"
2020.acl-main.583,P99-1006,1,0.458806,"arch (Anderson et al., 2017), a memory network with multiple context information (Chunseong Park et al., 2017), forced attentions (Sadler et al., 2019) and modeling and learning compositional semantics using fine-grained annotations of entities in MSCOCO (Cornia et al., 2019). 2 The first step toward our goals is to characterize image–text coherence and annotate a sizable corpus of image–text pairs with coherence relations. We use an overlapping set of high-level relations, inspired both by theoretical work linking discourse coherence to discourse structure and discourse goals (Roberts, 2012; Webber et al., 1999), and by previous successful discourse annotation campaigns (Prasad et al., 2008). Crucially, following previous work on text (Rohde et al., 2018) and multimodal discourse (Alikhani et al., 2019), Prior Work There are diverse ways to characterize the communicative functions of text and images in multimodal documents (Marsh and Domas White, 2003), any of which can provide the basis for computational work. Some studies emphasize the distinctive cognitive effects of imagery in directing attention; engaging perceptual, spatial and embodied 1 https://github.com/malihealikhani/Crossmodal Coherence M"
2020.acl-main.583,D18-1437,0,0.0293183,"most beautiful horse in the world. Story: horse competes in the event. Introduction The task of image captioning is seemingly straightforward to define: use natural language to generate a description that captures the salient content of an image. Initial datasets, such as MSCOCO (Lin et al., 2014) and Flickr (Young et al., 2014), approached this task directly, by asking crowd workers to describe images in text. Unfortunately, such dedicated annotation efforts cannot yield enough data for training robust generation models; the resulting generated captions are plagued by content hallucinations (Rohrbach et al., 2018; Sharma et al., 2018) that effectively preclude them for being used in real-world applications. In introducing the Conceptual Captions dataset, Sharma et al. (2018) show that this dataset is large enough, at 3.3M examples, to significantly alleviate content hallucination. However, because the technique for creating such a large-scale resource relies on harvesting existing data from the web, it no longer guarantees consistent image–text relations. For example, along with descriptive captions (e.g.,“this is a person in a suit”), the dataset also includes texts that provide contextual background"
2020.acl-main.583,Q14-1006,0,0.0592089,"Output of a coherence-aware model for various coherence relations. Content that establishes the intended relation is underlined. (Photo credit: Blue Destiny / Alamy Stock Photo) Visible: horse and rider jumping a fence. Meta: horse and rider jumping a fence during a race. Subjective: the most beautiful horse in the world. Story: horse competes in the event. Introduction The task of image captioning is seemingly straightforward to define: use natural language to generate a description that captures the salient content of an image. Initial datasets, such as MSCOCO (Lin et al., 2014) and Flickr (Young et al., 2014), approached this task directly, by asking crowd workers to describe images in text. Unfortunately, such dedicated annotation efforts cannot yield enough data for training robust generation models; the resulting generated captions are plagued by content hallucinations (Rohrbach et al., 2018; Sharma et al., 2018) that effectively preclude them for being used in real-world applications. In introducing the Conceptual Captions dataset, Sharma et al. (2018) show that this dataset is large enough, at 3.3M examples, to significantly alleviate content hallucination. However, because the technique for"
2020.acl-main.583,W19-8653,0,0.0370346,"Missing"
2020.acl-main.583,P18-1238,1,0.917076,"Missing"
2020.acl-main.583,miltsakaki-etal-2004-penn,0,\N,Missing
2020.acl-tutorials.3,L18-1019,0,0.0283273,"l Meeting of the Association for Computational Linguistics, pages 10–15 c July 5, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 Coherence is key. Grounding in dialogue systems. Computer systems achieve grounding mechanistically by ensuring they get attention and feedback from their users, tracking user state, and planning actions with reinforcement learning to resolve problematic situations. We will review techniques for maintaining engagement (Sidner et al., 2005; Bohus and Horvitz, 2014; Foster et al., 2017) and problems that arises in joint attention (Kontogiorgos et al., 2018) and turn taking such as incremental interpretation (DeVault and Stone, 2004; DeVault et al., 2011), ambiguity resolution (DeVault and Stone, 2009) and learning flexible dialogue management policies (Henderson et al., 2005). Similar questions have been studied in the context of instruction games (Perera et al., 2018; Thomason et al., 2019; Suhr and Artzi, 2018), and interactive tutoring systems (Yu et al., 2016; Wiggins et al., 2019). Show me a restaurant by the river, serving pasta/Italian food, highly rated and expensive, not child-friendly, located near Cafe Adriatic. (Novikova et al., 2016"
2020.acl-tutorials.3,W15-4720,0,0.0192832,"nting to clarify. Multi-modal systems have diverse opportunities to demonstrate understanding. For example, recent work has aimed to bridge vision, interactive learning, and natural language understanding through language learning tasks based on natural images (Zhang et al., 2018; Kazemzadeh et al., 2014; De Vries et al., 2017a; Kim et al., 2020). The work on visual dialogue games (Geman et al., 2015) brings new resources and models for generating referring expression for referents in images (Suhr et al., 2019; Shekhar et al., 2018), visually grounded spoken language communication (Roy, 2002; Gkatzia et al., 2015), and captioning (Levinboim et al., 2019; Alikhani and Stone, 2019), which can be used creatively to demonstrate how a system understand a user. Figure 1 shows two examples of models that understand and generate referring expressions in multimodal settings. Similarly, robots can demostrate how they understand a task by carring it out—in research on interactive task learning in human-robot interaction (Zarrieß and Schlangen, 2018; Carlmeyer et al., 2018) as well as embodied agents performGrounding in end-to-end language & vision systems. With current advances in neural mod11 elling and the avai"
2020.acl-tutorials.3,L18-1333,0,0.0282114,"i, 2015). A lesson that can be learned from this line of research is that one main factor that affects grounding is the choice of medium of communication. Thus, researchers have developed different techniques and methods for data collection and modeling of multimodal communication (Alikhani et al., 2019; Novikova et al., 2016). Figure 2 shows two example resources that were put together using crowdsourcing and virtual reality systems. We will discuss the strengths and shortcomings of these methods. We pay special attention to non-verbal grounding in languages beyond English, including German (Han and Schlangen, 2018), Swedish (Kontogiorgos, 2017), Japanese (Endrass et al., 2013; Nakano et al., 2003), French (Lemaignan and Alami, 2013; Steels, 2001), Italian (Borghi and Cangelosi, 2014; Taylor et al., 1986), Spanish (Kery et al., 2019), Russian (Janda, 1988), and American sign language (Emmorey and Casey, 1995). These investigations often describe important language-dependent characteristics and cultural differences in studying non-verbal grounding. Grounding in multi-modal systems. Multimodal systems offer the ability to use signals such as nodding, certain hand gestures and gazing at a speaker to communi"
2020.acl-tutorials.3,W17-5539,0,0.162809,"s such as human–robot interaction. In this tutorial, we focus on three main topic areas: 1) grounding in human-human communication; 2) grounding in dialogue systems; and 3) grounding in multi-modal interactive systems, including image-oriented conversations and humanrobot interactions. We highlight a number of achievements of recent computational research in coordinating complex content, show how these results lead to rich and challenging opportunities for doing grounding in more flexible and powerful ways, and canvass relevant insights from the A: A green bike with tan handlebars. B: Got it (Manuvinakurike et al., 2017) A: The green cup is called Bill. B: Ok, the green cup is Bill. [point to the inferred object] (Liu and Chai, 2015) Figure 1: Examples of the generation and interpretation of grounded referring expressions in multimodal interactive settings. Grounding is making sure that the listener understands what the speaker said. literature on human–human conversation. We expect that the tutorial will be of interest to researchers in dialogue systems, computational semantics and cognitive modeling, and hope that it will catalyze research and system building that more directly explores the creative, strate"
2020.acl-tutorials.3,P19-1644,0,0.029026,"stablishing common ground (Mavridis, 2015). However, multi-modal grounding is more than just using pointing to clarify. Multi-modal systems have diverse opportunities to demonstrate understanding. For example, recent work has aimed to bridge vision, interactive learning, and natural language understanding through language learning tasks based on natural images (Zhang et al., 2018; Kazemzadeh et al., 2014; De Vries et al., 2017a; Kim et al., 2020). The work on visual dialogue games (Geman et al., 2015) brings new resources and models for generating referring expression for referents in images (Suhr et al., 2019; Shekhar et al., 2018), visually grounded spoken language communication (Roy, 2002; Gkatzia et al., 2015), and captioning (Levinboim et al., 2019; Alikhani and Stone, 2019), which can be used creatively to demonstrate how a system understand a user. Figure 1 shows two examples of models that understand and generate referring expressions in multimodal settings. Similarly, robots can demostrate how they understand a task by carring it out—in research on interactive task learning in human-robot interaction (Zarrieß and Schlangen, 2018; Carlmeyer et al., 2018) as well as embodied agents performGr"
2020.acl-tutorials.3,P03-1070,0,0.216947,"r that affects grounding is the choice of medium of communication. Thus, researchers have developed different techniques and methods for data collection and modeling of multimodal communication (Alikhani et al., 2019; Novikova et al., 2016). Figure 2 shows two example resources that were put together using crowdsourcing and virtual reality systems. We will discuss the strengths and shortcomings of these methods. We pay special attention to non-verbal grounding in languages beyond English, including German (Han and Schlangen, 2018), Swedish (Kontogiorgos, 2017), Japanese (Endrass et al., 2013; Nakano et al., 2003), French (Lemaignan and Alami, 2013; Steels, 2001), Italian (Borghi and Cangelosi, 2014; Taylor et al., 1986), Spanish (Kery et al., 2019), Russian (Janda, 1988), and American sign language (Emmorey and Casey, 1995). These investigations often describe important language-dependent characteristics and cultural differences in studying non-verbal grounding. Grounding in multi-modal systems. Multimodal systems offer the ability to use signals such as nodding, certain hand gestures and gazing at a speaker to communicate meaning and contribute to establishing common ground (Mavridis, 2015). However,"
2020.acl-tutorials.3,W16-6644,0,0.0195163,"giorgos et al., 2018) and turn taking such as incremental interpretation (DeVault and Stone, 2004; DeVault et al., 2011), ambiguity resolution (DeVault and Stone, 2009) and learning flexible dialogue management policies (Henderson et al., 2005). Similar questions have been studied in the context of instruction games (Perera et al., 2018; Thomason et al., 2019; Suhr and Artzi, 2018), and interactive tutoring systems (Yu et al., 2016; Wiggins et al., 2019). Show me a restaurant by the river, serving pasta/Italian food, highly rated and expensive, not child-friendly, located near Cafe Adriatic. (Novikova et al., 2016) Crystal Island, an interactive narrativecentered virtual learning environment (Rowe et al., 2008) Figure 2: Content and medium affect grounding. This figure shows two examples of interactive multimodal dialogue systems. ing interactive tasks (Gordon et al., 2018; Das et al., 2018) in physically simulated environments (Anderson et al., 2018; Tan and Bansal, 2018) often drawing on the successes of deep learning and reinforcement learning (Branavan et al., 2009; Liu and Chai, 2015). A lesson that can be learned from this line of research is that one main factor that affects grounding is the choi"
2020.acl-tutorials.3,W18-5010,0,0.0261654,"ers, tracking user state, and planning actions with reinforcement learning to resolve problematic situations. We will review techniques for maintaining engagement (Sidner et al., 2005; Bohus and Horvitz, 2014; Foster et al., 2017) and problems that arises in joint attention (Kontogiorgos et al., 2018) and turn taking such as incremental interpretation (DeVault and Stone, 2004; DeVault et al., 2011), ambiguity resolution (DeVault and Stone, 2009) and learning flexible dialogue management policies (Henderson et al., 2005). Similar questions have been studied in the context of instruction games (Perera et al., 2018; Thomason et al., 2019; Suhr and Artzi, 2018), and interactive tutoring systems (Yu et al., 2016; Wiggins et al., 2019). Show me a restaurant by the river, serving pasta/Italian food, highly rated and expensive, not child-friendly, located near Cafe Adriatic. (Novikova et al., 2016) Crystal Island, an interactive narrativecentered virtual learning environment (Rowe et al., 2008) Figure 2: Content and medium affect grounding. This figure shows two examples of interactive multimodal dialogue systems. ing interactive tasks (Gordon et al., 2018; Das et al., 2018) in physically simulated environme"
2020.acl-tutorials.3,P08-1073,0,0.0626781,"Missing"
2020.acl-tutorials.3,W16-3206,0,0.140423,"uations. We will review techniques for maintaining engagement (Sidner et al., 2005; Bohus and Horvitz, 2014; Foster et al., 2017) and problems that arises in joint attention (Kontogiorgos et al., 2018) and turn taking such as incremental interpretation (DeVault and Stone, 2004; DeVault et al., 2011), ambiguity resolution (DeVault and Stone, 2009) and learning flexible dialogue management policies (Henderson et al., 2005). Similar questions have been studied in the context of instruction games (Perera et al., 2018; Thomason et al., 2019; Suhr and Artzi, 2018), and interactive tutoring systems (Yu et al., 2016; Wiggins et al., 2019). Show me a restaurant by the river, serving pasta/Italian food, highly rated and expensive, not child-friendly, located near Cafe Adriatic. (Novikova et al., 2016) Crystal Island, an interactive narrativecentered virtual learning environment (Rowe et al., 2008) Figure 2: Content and medium affect grounding. This figure shows two examples of interactive multimodal dialogue systems. ing interactive tasks (Gordon et al., 2018; Das et al., 2018) in physically simulated environments (Anderson et al., 2018; Tan and Bansal, 2018) often drawing on the successes of deep learning"
2020.acl-tutorials.3,W18-6906,0,0.0279602,"and models for generating referring expression for referents in images (Suhr et al., 2019; Shekhar et al., 2018), visually grounded spoken language communication (Roy, 2002; Gkatzia et al., 2015), and captioning (Levinboim et al., 2019; Alikhani and Stone, 2019), which can be used creatively to demonstrate how a system understand a user. Figure 1 shows two examples of models that understand and generate referring expressions in multimodal settings. Similarly, robots can demostrate how they understand a task by carring it out—in research on interactive task learning in human-robot interaction (Zarrieß and Schlangen, 2018; Carlmeyer et al., 2018) as well as embodied agents performGrounding in end-to-end language & vision systems. With current advances in neural mod11 elling and the availability of large pretrained models in language and vision, multi-modal interaction often is enabled by neural end-to-end architectures with multimodal encodings, e.g. by answering questions abut visual scenes (Antol et al., 2015; Das et al., 2017). It is argued that these shared representations help to ground word meanings. In this tutorial, we will discuss how this type of lexical grounding relates to grounding in dialogue fro"
2020.acl-tutorials.3,P18-1193,0,0.026986,"ns with reinforcement learning to resolve problematic situations. We will review techniques for maintaining engagement (Sidner et al., 2005; Bohus and Horvitz, 2014; Foster et al., 2017) and problems that arises in joint attention (Kontogiorgos et al., 2018) and turn taking such as incremental interpretation (DeVault and Stone, 2004; DeVault et al., 2011), ambiguity resolution (DeVault and Stone, 2009) and learning flexible dialogue management policies (Henderson et al., 2005). Similar questions have been studied in the context of instruction games (Perera et al., 2018; Thomason et al., 2019; Suhr and Artzi, 2018), and interactive tutoring systems (Yu et al., 2016; Wiggins et al., 2019). Show me a restaurant by the river, serving pasta/Italian food, highly rated and expensive, not child-friendly, located near Cafe Adriatic. (Novikova et al., 2016) Crystal Island, an interactive narrativecentered virtual learning environment (Rowe et al., 2008) Figure 2: Content and medium affect grounding. This figure shows two examples of interactive multimodal dialogue systems. ing interactive tasks (Gordon et al., 2018; Das et al., 2018) in physically simulated environments (Anderson et al., 2018; Tan and Bansal, 20"
2020.coling-main.391,E09-1022,1,0.658131,"namics of slot filling dialogues; see Young et al. (2013) for review. However, because we work with written rather than spoken language, our concern is uncertainty at deeper levels of interpretation, including such new dimensions of user simulation as the flexible vocabulary and syntax that users adopt, their strategic variability in producing and interpreting utterances, and their deliberation in coordinating with their interlocutors. While a range of work has attempted to model and learn about such referential and speech act ambiguity from dialogue data, including McRoy and Hirst (1995) and DeVault and Stone (2009), these models have not been used to drive decision-theoretic approaches to clarification. Reinforcement learning in open-domain referential communication has instead focused on simple decisions, such as whether to wait or move forward in incremental dialogue (Manuvinakurike et al., 2017) or asking yes/no questions to resolve ambiguity in visual dialogue (Niu et al., 2019; Shekhar et al., 2019; Zhang et al., 2018). Corpus-based modeling work has shown, however, that natural strategies for collaborative reference are typically substantially more flexible (Clark and Wilkes-Gibbs, 1986; Ginzburg"
2020.coling-main.391,P05-3001,1,0.502548,"tterances that would be likely understood. 3.2 System Architecture Our system tracks the organization and flow of dialogue using a novel formal model of the collaborative reference task. The principles behind this model are described in full in Khalid et al. (2020). We have released our implementation, including a pre-trained RL model, at https://go.rutgers.edu/ tc7k14b, to enable replicability of our results. We highlight key aspects of the implementation here. In brief, unlike approaches based on an information-state update approach (Larsson and Traum, 2000), collaborative discourse theory (DeVault et al., 2005), or a flat state-space (Heeman, 2007), we model utterances as making abstract moves that attach into an evolving discourse structure, as in formal approaches such as SDRT (Lascarides and Asher, 2009). One advantage of this approach is that it enables the system to represent a hierarchical dialogue structure, which is important for maintaining context through clarification episodes, without cumbersome logic for plan recognition or stack manipulation. 3.2.1 Understanding Utterances Our understanding module is based on a probabilistic context free grammar (PCFG): the rules are handcrafted based"
2020.coling-main.391,J95-3003,0,0.580822,"been used to drive decision-theoretic approaches to clarification. Reinforcement learning in open-domain referential communication has instead focused on simple decisions, such as whether to wait or move forward in incremental dialogue (Manuvinakurike et al., 2017) or asking yes/no questions to resolve ambiguity in visual dialogue (Niu et al., 2019; Shekhar et al., 2019; Zhang et al., 2018). Corpus-based modeling work has shown, however, that natural strategies for collaborative reference are typically substantially more flexible (Clark and Wilkes-Gibbs, 1986; Ginzburg 4418 and Cooper, 2004; Heeman and Hirst, 1995; Schlangen, 2004). Our work aims to learn correspondingly more flexible policies. We argue elsewhere (Khalid et al., 2020) that formal models of discourse coherence give important resources to do this. Although we build on that work here, our prior work has not addressed the problem of learning context-sensitive clarification strategies. Appelgren and Lascarides (2020) also consider semantic grounding of color terms and exploit formal models of discourse coherence to do so; however, their work so far assumes dialogue policies (and primitive motor skills) to be fixed and known in advance. In r"
2020.coling-main.391,N07-1034,0,0.0559345,"System Architecture Our system tracks the organization and flow of dialogue using a novel formal model of the collaborative reference task. The principles behind this model are described in full in Khalid et al. (2020). We have released our implementation, including a pre-trained RL model, at https://go.rutgers.edu/ tc7k14b, to enable replicability of our results. We highlight key aspects of the implementation here. In brief, unlike approaches based on an information-state update approach (Larsson and Traum, 2000), collaborative discourse theory (DeVault et al., 2005), or a flat state-space (Heeman, 2007), we model utterances as making abstract moves that attach into an evolving discourse structure, as in formal approaches such as SDRT (Lascarides and Asher, 2009). One advantage of this approach is that it enables the system to represent a hierarchical dialogue structure, which is important for maintaining context through clarification episodes, without cumbersome logic for plan recognition or stack manipulation. 3.2.1 Understanding Utterances Our understanding module is based on a probabilistic context free grammar (PCFG): the rules are handcrafted based on CIC development data; rule weights"
2020.coling-main.391,W17-5539,0,0.0280725,"x that users adopt, their strategic variability in producing and interpreting utterances, and their deliberation in coordinating with their interlocutors. While a range of work has attempted to model and learn about such referential and speech act ambiguity from dialogue data, including McRoy and Hirst (1995) and DeVault and Stone (2009), these models have not been used to drive decision-theoretic approaches to clarification. Reinforcement learning in open-domain referential communication has instead focused on simple decisions, such as whether to wait or move forward in incremental dialogue (Manuvinakurike et al., 2017) or asking yes/no questions to resolve ambiguity in visual dialogue (Niu et al., 2019; Shekhar et al., 2019; Zhang et al., 2018). Corpus-based modeling work has shown, however, that natural strategies for collaborative reference are typically substantially more flexible (Clark and Wilkes-Gibbs, 1986; Ginzburg 4418 and Cooper, 2004; Heeman and Hirst, 1995; Schlangen, 2004). Our work aims to learn correspondingly more flexible policies. We argue elsewhere (Khalid et al., 2020) that formal models of discourse coherence give important resources to do this. Although we build on that work here, our"
2020.coling-main.391,Q15-1008,1,0.924476,"SE conditions where all the patches are visually similar, and SPLIT conditions where the target has a single distractor that’s visually similar. As Figure 2 shows, more challenging contexts elicit a wide range of utterances, including creative, detailed but nevertheless vague expressions. We follow McMahan and Stone (2020) in modeling such strategies through cognitive models of choice under uncertainty. McMahan and Stone (2020) first train a large-scale semantic model of color descriptions using Randall Monroe’s crowdsourced collection of free text descriptions of color patches, as curated by McMahan and Stone (2015). Then, building on prior work in computational pragmatics, they describe a number of psychologically-plausible inference methods for predicting the effectiveness of semantic content in identifying a target referent. For example, speakers might try to anticipate and shape the listener’s interpretive reasoning while drawing on shared and familiar meanings (Monroe and Potts, 2015), speakers might try to signal innovative meanings that would name the target unambiguous (Meo et al., 2014), or speakers might rely exclusively on established and unambiguous meanings, as in classic x0 x1 x2 director:"
2020.coling-main.391,2020.sigdial-1.22,1,0.720601,"n interlocutors, to guide its behavior. We meet this challenge by integrating a reinforcement learning approach to dialogue policy with cognitive models to describe the actions and outcomes available to the system. In particular, our work relies on a new, probabilistic model of contributions to dialogue, as planned by the user and understood by the system. We construct this model by analyzing human behavior and profiling system performance on a benchmark dataset of human–human conversations, drawing on data collection and modeling work from the recent dialogue literature (Monroe et al., 2017; McMahan and Stone, 2020). We use this model at planning time to roll out simulated interactions that track user deliberation, anticipate user dialogue moves at the level of utterance content, and predict task outcomes. We use deep Q-learning (Mnih et al., 2015) to estimate the effectiveness of different actions as a function of dialogue state. Our approach culminates in a context-sensitive policy that decides whether and how to present clarification options to users, contingent on the ambiguity of user input and the predicted outcomes of different resolution strategies. Our work is the first to intelligently deploy a"
2020.coling-main.391,J95-4001,0,0.529569,"at capture the realistic dynamics of slot filling dialogues; see Young et al. (2013) for review. However, because we work with written rather than spoken language, our concern is uncertainty at deeper levels of interpretation, including such new dimensions of user simulation as the flexible vocabulary and syntax that users adopt, their strategic variability in producing and interpreting utterances, and their deliberation in coordinating with their interlocutors. While a range of work has attempted to model and learn about such referential and speech act ambiguity from dialogue data, including McRoy and Hirst (1995) and DeVault and Stone (2009), these models have not been used to drive decision-theoretic approaches to clarification. Reinforcement learning in open-domain referential communication has instead focused on simple decisions, such as whether to wait or move forward in incremental dialogue (Manuvinakurike et al., 2017) or asking yes/no questions to resolve ambiguity in visual dialogue (Niu et al., 2019; Shekhar et al., 2019; Zhang et al., 2018). Corpus-based modeling work has shown, however, that natural strategies for collaborative reference are typically substantially more flexible (Clark and"
2020.coling-main.391,Q17-1023,0,0.382749,"interactions, which let the speaker and the audience share responsibility for reaching a satisfactory mutual understanding (Clark, 1996). This paper contributes to a broader project of building dialogue systems that can do the same. We focus specifically on the problem of asking targeted, effective clarification questions with creative language. The difficulty of this problem is highlighted by the interactions shown in Figure 1, taken from the human-subjects evaluations reported in Section 6. In these dialogues, our system (playing the role of matcher in the referential communication task of Monroe et al. (2017)) uses varying clarification questions to follow up initial color descriptions provided by crowd workers (playing the role of director), and is thereby able to successfully distinguish the target color patches from their contextual distractors. director: matcher: director: matcher: x0 x1 x2 lusher green sea green or bright green? sea green [Selects] director: matcher: director: matcher: x0 x1 x2 light green Do you mean lime green? yes [Selects] Figure 1: Our system (matcher) interacting with crowd workers (director). System and users are presented with the same color patches in random order; t"
2020.coling-main.391,W04-2325,0,0.130494,"sion-theoretic approaches to clarification. Reinforcement learning in open-domain referential communication has instead focused on simple decisions, such as whether to wait or move forward in incremental dialogue (Manuvinakurike et al., 2017) or asking yes/no questions to resolve ambiguity in visual dialogue (Niu et al., 2019; Shekhar et al., 2019; Zhang et al., 2018). Corpus-based modeling work has shown, however, that natural strategies for collaborative reference are typically substantially more flexible (Clark and Wilkes-Gibbs, 1986; Ginzburg 4418 and Cooper, 2004; Heeman and Hirst, 1995; Schlangen, 2004). Our work aims to learn correspondingly more flexible policies. We argue elsewhere (Khalid et al., 2020) that formal models of discourse coherence give important resources to do this. Although we build on that work here, our prior work has not addressed the problem of learning context-sensitive clarification strategies. Appelgren and Lascarides (2020) also consider semantic grounding of color terms and exploit formal models of discourse coherence to do so; however, their work so far assumes dialogue policies (and primitive motor skills) to be fixed and known in advance. In rolling out dialogu"
2020.coling-main.391,P97-1035,0,0.68926,"0.20 and 0.05 in response to A?, A or B?, and A or B or C?, based on approximate rates in the CIC development data. (In light of the evaluation results presented in Section 6, it would be interesting to refine this model based on observed rates when people interact with the system.) In case of error, the director randomly uses one of the alternative descriptive contents maintained as a candidate by the algorithm. 4.3 Reward Function Our initial reward function is designed as a proof of concept for our approach, to embody the commonly observed tradeoff between dialogue length and task success (Walker et al., 1997). Ultimately, we would like to optimize user satisfaction. User satisfaction is not observable, but it can be approximated, following Walker et al. (1997), by correlating user’s reported preferences with other features of the dialogue such as length and task success, based on empirical observations. However, this requires the kind of evaluation results we present in Section 6, which were of course not available during our initial experiments. Instead, we crafted an artificial reward function with typical characteristics, penalizing both dialogue length and task failure. In particular, we opera"
2020.coling-main.391,W18-5015,0,0.0159283,"ir interlocutors. While a range of work has attempted to model and learn about such referential and speech act ambiguity from dialogue data, including McRoy and Hirst (1995) and DeVault and Stone (2009), these models have not been used to drive decision-theoretic approaches to clarification. Reinforcement learning in open-domain referential communication has instead focused on simple decisions, such as whether to wait or move forward in incremental dialogue (Manuvinakurike et al., 2017) or asking yes/no questions to resolve ambiguity in visual dialogue (Niu et al., 2019; Shekhar et al., 2019; Zhang et al., 2018). Corpus-based modeling work has shown, however, that natural strategies for collaborative reference are typically substantially more flexible (Clark and Wilkes-Gibbs, 1986; Ginzburg 4418 and Cooper, 2004; Heeman and Hirst, 1995; Schlangen, 2004). Our work aims to learn correspondingly more flexible policies. We argue elsewhere (Khalid et al., 2020) that formal models of discourse coherence give important resources to do this. Although we build on that work here, our prior work has not addressed the problem of learning context-sensitive clarification strategies. Appelgren and Lascarides (2020)"
2020.coling-main.401,W19-1806,1,0.903884,"y, we contribute a dataset of human–human conversations annotated with lexical aspect and present experiments that show the correlation of telicity with genre and discourse goals. 1 Introduction One of the fascinating aspects of studying aspectual class of verbs in English is its relation with nonverbal categories. Thus, although in origin a property of the verb, the aspectual class interacts in a tight-knit fashion with other words in a sentence. Previous research has discussed the importance of predicting the aspectual classes of verbs for predicting coherence relations in text and imagery (Alikhani and Stone, 2019), predicting links in entailment graphs (Hosseini et al., 2019) and interpreting sign languages (Wilbur, 2003). In addition, knowledge about the aspectual class of a verb phrase, and its influence on the temporal extent and entailments that it licenses, has been leveraged in the past for a number of natural language understanding tasks such as temporal relation extraction (Costa and Branco, 2012), event ordering (Chambers et al., 2014; Modi and Titov, 2014), and statistical machine translation (Lo´aiciga and Grisot, 2016). The Aktionsart (Vendler, 1957) of a verb determines the temporal extent"
2020.coling-main.401,P10-1124,0,0.0258215,"not observe any meaningful performance difference when replacing our bagof-embeddings approach with ELMo (Peters et al., 2018) or BERT (Devlin et al., 2019). While this work was done on English, we aim to use our methodology in a multilingual setup in future work as distributional approaches scale well with growing amounts of data and across languages. Aspect, alongside tense, is a crucial indicator of the temporal extent of a verb as well as the entailments it licenses. In future work we plan to integrate aspectual information for improving the unsupervised construction of entailment graphs (Berant et al., 2010; Hosseini et al., 2018), as well as temporal reasoning, which has been shown recently to be difficult for distributional semantic models (Kober et al., 2019). Aspectual information can be utilised for directional entailment detection by inferring that the event of buying something entails the state of owning that thing, but not the other way round. Determining the telicity of an event also enables fine-grained inferences about whether an event caused a change of state. For example, while the telic context of writing a sonnet in fifteen minutes entails a change to a state where a finished sonn"
2020.coling-main.401,D15-1075,0,0.0165189,"d verbs, such as get, see or know, which have a 3 The annotation protocol is published with the dataset at https://go.rutgers.edu/cb6le5c1. 4548 Figure 1: Frequency distribution of the 10 most frequent verbs (left) and associated label distribution for the 10 most frequent verbs (right). clear majority class, whereas do or look exhibit a much more balanced, and therefore ambiguous label distribution. 4 Experiments The utility of distributional semantic word representations has been shown in a large body of works in recent years (Weeds et al. (2014), Nguyen et al. (2017), Socher et al. (2013), Bowman et al. (2015); passim). In order to compose a verb with its context we apply pointwise addition as a simple distributional composition function. Pointwise addition in neural word embeddings approximates the intersection of their contexts4 (Tian et al., 2017), and has been shown to be an efficient function for contextualising a word in a phrase (Arora et al., 2016; Kober et al., 2017). 4.1 Distributional Models for Predicational Aspect Following previous work on modelling the aspectual class of a verb (Siegel and McKeown, 2000; Friedrich and Palmer, 2014), we treat the problem as a supervised classification"
2020.coling-main.401,Q14-1022,0,0.0719297,"sentence. Previous research has discussed the importance of predicting the aspectual classes of verbs for predicting coherence relations in text and imagery (Alikhani and Stone, 2019), predicting links in entailment graphs (Hosseini et al., 2019) and interpreting sign languages (Wilbur, 2003). In addition, knowledge about the aspectual class of a verb phrase, and its influence on the temporal extent and entailments that it licenses, has been leveraged in the past for a number of natural language understanding tasks such as temporal relation extraction (Costa and Branco, 2012), event ordering (Chambers et al., 2014; Modi and Titov, 2014), and statistical machine translation (Lo´aiciga and Grisot, 2016). The Aktionsart (Vendler, 1957) of a verb determines the temporal extent of the predication as well as whether it causes a change of state for the entities involved (Filip, 2012). As Aktionsart typically refers to the lexical aspect of a verb in isolation, we adopt the terminology of Verkuyl (2005), and refer to the compositionally formed Aktionsart of a verb phrase as predicational aspect. One of the most important distinctions of the predicational aspect of a verb is between states, such as to know or t"
2020.coling-main.401,E12-1027,0,0.624017,"tight-knit fashion with other words in a sentence. Previous research has discussed the importance of predicting the aspectual classes of verbs for predicting coherence relations in text and imagery (Alikhani and Stone, 2019), predicting links in entailment graphs (Hosseini et al., 2019) and interpreting sign languages (Wilbur, 2003). In addition, knowledge about the aspectual class of a verb phrase, and its influence on the temporal extent and entailments that it licenses, has been leveraged in the past for a number of natural language understanding tasks such as temporal relation extraction (Costa and Branco, 2012), event ordering (Chambers et al., 2014; Modi and Titov, 2014), and statistical machine translation (Lo´aiciga and Grisot, 2016). The Aktionsart (Vendler, 1957) of a verb determines the temporal extent of the predication as well as whether it causes a change of state for the entities involved (Filip, 2012). As Aktionsart typically refers to the lexical aspect of a verb in isolation, we adopt the terminology of Verkuyl (2005), and refer to the compositionally formed Aktionsart of a verb phrase as predicational aspect. One of the most important distinctions of the predicational aspect of a verb"
2020.coling-main.401,N19-1423,0,0.0139807,"in a verb phrase, tend to be very reliable indicators of the verb’s aspectual class (Vendler (1957), Dowty (1979), Moens and Steedman (1988), passim). Our model setup was intentionally kept simple as we were primarily concerned with the question whether predicational aspect can be captured with a distributional semantics approach in principle. We note that using more sophisticated models might yield even stronger results, although in preliminary tests, we did not observe any meaningful performance difference when replacing our bagof-embeddings approach with ELMo (Peters et al., 2018) or BERT (Devlin et al., 2019). While this work was done on English, we aim to use our methodology in a multilingual setup in future work as distributional approaches scale well with growing amounts of data and across languages. Aspect, alongside tense, is a crucial indicator of the temporal extent of a verb as well as the entailments it licenses. In future work we plan to integrate aspectual information for improving the unsupervised construction of entailment graphs (Berant et al., 2010; Hosseini et al., 2018), as well as temporal reasoning, which has been shown recently to be difficult for distributional semantic models"
2020.coling-main.401,P97-1020,0,0.514241,"fferent supervised machine learning algorithms to classify the extracted feature vectors into either states or events, or telic or atelic events. Siegel and McKeown (2000) show that their method substantially improves over a majority-class baseline. The first approach to include features derived from a distributional semantic model has been proposed by Friedrich and Palmer (2014). In addition to the linguistic indicator features of Siegel and McKeown (2000), Friedrich and Palmer (2014) extract representative stative, dynamic or mixed verbs from the lexical conceptual structure (LCS) database (Dorr and Olsen, 1997) and subsequently use distributional representations to derive similarity scores for the mined verbs. Another extension to the work of Friedrich and Palmer (2014) has been proposed by Heuschkel (2016), who refines the distributional similarity features by first contextualising a target verb with its subject or object, and only then computing the distributional similarities to the set of representative verbs from the LCS database as in Friedrich and Palmer (2014). All else being equal, Heuschkel (2016) shows that contextualising the distributional representations improves performance on the Asp"
2020.coling-main.401,S16-2002,0,0.350641,"rom the LCS database as in Friedrich and Palmer (2014). All else being equal, Heuschkel (2016) shows that contextualising the distributional representations improves performance on the Asp-ambig dataset of Friedrich and Palmer (2014). In contrast to this line of research we do not make explicit use of any hand-engineered linguistic indicator features but show that these can be picked up in an unsupervised way by composing distributional semantic word representations. The linguistic indicators are furthermore frequently collected on the verb type level instead of on the token level. Similar to Falk and Martin (2016), we are concerned with classifying verb readings; however, we do not use engineered features as Falk and Martin (2016) do, but directly leverage local contextual information in the form of distributional representations. Our approach is also not reliant on the availability of a parallel corpus as in Friedrich and Gateva (2017). The major difference between our approach of using distributional word representations and previous approaches is that we are using the word representations directly for classification, rather than indirectly by computing similarity scores and using these as features."
2020.coling-main.401,D17-1271,0,0.418239,"inguistic indicator features but show that these can be picked up in an unsupervised way by composing distributional semantic word representations. The linguistic indicators are furthermore frequently collected on the verb type level instead of on the token level. Similar to Falk and Martin (2016), we are concerned with classifying verb readings; however, we do not use engineered features as Falk and Martin (2016) do, but directly leverage local contextual information in the form of distributional representations. Our approach is also not reliant on the availability of a parallel corpus as in Friedrich and Gateva (2017). The major difference between our approach of using distributional word representations and previous approaches is that we are using the word representations directly for classification, rather than indirectly by computing similarity scores and using these as features. This furthermore liberates us from the requirement of having a representative seed set of verbs per class to compute the distributional similarities from. 3 Dataset We introduce a new dataset, DIASPORA,2 of human-human conversations annotated with predicational aspect, representing the first dialogue dataset annotated with aspe"
2020.coling-main.401,P14-2085,0,0.759901,"avans and Chodorov (1992), and collected linguistic indicators for lexical aspect from a large corpus. These include the presence of in- or for-adverbials, the tense of the verb or its frequency. Siegel and McKeown (2000) subsequently applied different supervised machine learning algorithms to classify the extracted feature vectors into either states or events, or telic or atelic events. Siegel and McKeown (2000) show that their method substantially improves over a majority-class baseline. The first approach to include features derived from a distributional semantic model has been proposed by Friedrich and Palmer (2014). In addition to the linguistic indicator features of Siegel and McKeown (2000), Friedrich and Palmer (2014) extract representative stative, dynamic or mixed verbs from the lexical conceptual structure (LCS) database (Dorr and Olsen, 1997) and subsequently use distributional representations to derive similarity scores for the mined verbs. Another extension to the work of Friedrich and Palmer (2014) has been proposed by Heuschkel (2016), who refines the distributional similarity features by first contextualising a target verb with its subject or object, and only then computing the distributiona"
2020.coling-main.401,P16-1166,0,0.711369,"assess the suitability of distributional representations for distinguishing states from events (§ 5.1), and telic from atelic events (§ 5.2). Only a completed and telic event licenses a new consequent state. Therefore, modelling predicational aspect is important for deeper text understanding, for example for modelling cause and effect, and especially for inferring consequent states. 5.1 Experiment 1 — States vs. Events For the distinction between states and events we perform experiments on 5 datasets in total. We use the Asp-ambig dataset by Friedrich and Palmer (2014), the SitEnt dataset by Friedrich et al. (2016), our own sub-sampled version of the SitEnt dataset, the Captions dataset by Alikhani and Stone (2019), and our own DIASPORA dataset, proposed in this work. The Asp-ambig dataset is sampled from the Brown corpus (Francis and Kucera, 1979) and is based on 20 frequently occurring verbs whose predicational aspect changes depending on context. For each verb, Friedrich and Palmer (2014) collected 138 sentences, resulting in 2760 examples in total. The dataset 7 If the target verb is the root, then no context is used for that verb. 4550 contains the annotations of whether the verb in context express"
2020.coling-main.401,P14-5010,0,0.00337872,"rough a logistic regression classifier in order to predict the aspectual class of v. This model aims to capture the compositional nature of predicational aspect by integrating local contextual information into the model. Types of Context We investigate two different kinds of context: simple linear context windows of varying length and firstorder dependency contexts. For example for the sentence in Figure 2, a linear context window of size 1 would extract Jane and to for the target verb decided, whereas a dependency-based context would extract Jane and leave. We used the Stanford NLP pipeline (Manning et al., 2014) with default settings for parsing the sentences in our datasets. root xcomp nsubj Jane aux decided to advmod leave early Figure 2: With a linear context window of size 1, Jane and to would be extracted as contexts for the verb decided. With a dependency-based context, Jane and leave would be extracted. For linear context windows we use sizes {1, 2, 3, 5, 10}, and for first-order dependency-based contexts we experiment with using only the head7 of the verb, only its children, or the full first-order context. Incorporating the Full Sentence We furthermore test a model that incorporates the whol"
2020.coling-main.401,W14-1606,0,0.0298338,"arch has discussed the importance of predicting the aspectual classes of verbs for predicting coherence relations in text and imagery (Alikhani and Stone, 2019), predicting links in entailment graphs (Hosseini et al., 2019) and interpreting sign languages (Wilbur, 2003). In addition, knowledge about the aspectual class of a verb phrase, and its influence on the temporal extent and entailments that it licenses, has been leveraged in the past for a number of natural language understanding tasks such as temporal relation extraction (Costa and Branco, 2012), event ordering (Chambers et al., 2014; Modi and Titov, 2014), and statistical machine translation (Lo´aiciga and Grisot, 2016). The Aktionsart (Vendler, 1957) of a verb determines the temporal extent of the predication as well as whether it causes a change of state for the entities involved (Filip, 2012). As Aktionsart typically refers to the lexical aspect of a verb in isolation, we adopt the terminology of Verkuyl (2005), and refer to the compositionally formed Aktionsart of a verb phrase as predicational aspect. One of the most important distinctions of the predicational aspect of a verb is between states, such as to know or to love, and events, suc"
2020.coling-main.401,J88-2003,1,0.597345,"r representation. The approach simply uses all words from a given sentence and composes their corresponding word2vec representations as in Equation 1 above to create an embedding for the whole sentence. Embedding a sentence by adding word vectors has been shown to be an effective method for other NLP tasks such as sentiment analysis (Iyyer et al., 2015) and recognising textual entailment (Wieting et al., 2016). The underlying rationale behind this approach is that the aspectual class of a verb is a function of the sentence as a whole, rather than dependent on local context alone (Moens, 1987; Moens and Steedman, 1988; Dowty, 1991). 5 Experiments We perform experiments that assess the suitability of distributional representations for distinguishing states from events (§ 5.1), and telic from atelic events (§ 5.2). Only a completed and telic event licenses a new consequent state. Therefore, modelling predicational aspect is important for deeper text understanding, for example for modelling cause and effect, and especially for inferring consequent states. 5.1 Experiment 1 — States vs. Events For the distinction between states and events we perform experiments on 5 datasets in total. We use the Asp-ambig datas"
2020.coling-main.401,D17-1022,0,0.0481987,"Missing"
2020.coling-main.401,J88-2005,0,0.606945,"ing distinctions of a verb that relate to its aspectual class should be reflected in its distribution when composed with its context. We therefore intersect word vectors with their context in order to determine a VP’s predicational aspect, and show that we achieve a new state-of-the-art on two datasets. We further evaluate our approach on two new genres: image captions and situated human–human conversations, thereby extending the validity of our findings across a variety of genres. 2 Related Work An early approach to classifying the lexical aspectual class of a verb in context was proposed by Passonneau (1988), who applied a decompositional analysis of the verb to determine the aspectual class for verb occurrences in a restricted domain. The first general-purpose study was conducted by Siegel and McKeown (2000), who built up on earlier work by Klavans and Chodorov (1992), and collected linguistic indicators for lexical aspect from a large corpus. These include the presence of in- or for-adverbials, the tense of the verb or its frequency. Siegel and McKeown (2000) subsequently applied different supervised machine learning algorithms to classify the extracted feature vectors into either states or eve"
2020.coling-main.401,N18-1202,0,0.0337896,"of prepositions or particles in a verb phrase, tend to be very reliable indicators of the verb’s aspectual class (Vendler (1957), Dowty (1979), Moens and Steedman (1988), passim). Our model setup was intentionally kept simple as we were primarily concerned with the question whether predicational aspect can be captured with a distributional semantics approach in principle. We note that using more sophisticated models might yield even stronger results, although in preliminary tests, we did not observe any meaningful performance difference when replacing our bagof-embeddings approach with ELMo (Peters et al., 2018) or BERT (Devlin et al., 2019). While this work was done on English, we aim to use our methodology in a multilingual setup in future work as distributional approaches scale well with growing amounts of data and across languages. Aspect, alongside tense, is a crucial indicator of the temporal extent of a verb as well as the entailments it licenses. In future work we plan to integrate aspectual information for improving the unsupervised construction of entailment graphs (Berant et al., 2010; Hosseini et al., 2018), as well as temporal reasoning, which has been shown recently to be difficult for"
2020.coling-main.401,J00-4004,0,0.924192,"to determine a VP’s predicational aspect, and show that we achieve a new state-of-the-art on two datasets. We further evaluate our approach on two new genres: image captions and situated human–human conversations, thereby extending the validity of our findings across a variety of genres. 2 Related Work An early approach to classifying the lexical aspectual class of a verb in context was proposed by Passonneau (1988), who applied a decompositional analysis of the verb to determine the aspectual class for verb occurrences in a restricted domain. The first general-purpose study was conducted by Siegel and McKeown (2000), who built up on earlier work by Klavans and Chodorov (1992), and collected linguistic indicators for lexical aspect from a large corpus. These include the presence of in- or for-adverbials, the tense of the verb or its frequency. Siegel and McKeown (2000) subsequently applied different supervised machine learning algorithms to classify the extracted feature vectors into either states or events, or telic or atelic events. Siegel and McKeown (2000) show that their method substantially improves over a majority-class baseline. The first approach to include features derived from a distributional"
2020.coling-main.401,D13-1170,0,0.00459162,"are some highly skewed verbs, such as get, see or know, which have a 3 The annotation protocol is published with the dataset at https://go.rutgers.edu/cb6le5c1. 4548 Figure 1: Frequency distribution of the 10 most frequent verbs (left) and associated label distribution for the 10 most frequent verbs (right). clear majority class, whereas do or look exhibit a much more balanced, and therefore ambiguous label distribution. 4 Experiments The utility of distributional semantic word representations has been shown in a large body of works in recent years (Weeds et al. (2014), Nguyen et al. (2017), Socher et al. (2013), Bowman et al. (2015); passim). In order to compose a verb with its context we apply pointwise addition as a simple distributional composition function. Pointwise addition in neural word embeddings approximates the intersection of their contexts4 (Tian et al., 2017), and has been shown to be an efficient function for contextualising a word in a phrase (Arora et al., 2016; Kober et al., 2017). 4.1 Distributional Models for Predicational Aspect Following previous work on modelling the aspectual class of a verb (Siegel and McKeown, 2000; Friedrich and Palmer, 2014), we treat the problem as a sup"
2020.coling-main.401,J86-2003,0,0.24002,"elations in text and imagery (Alikhani and Stone, 2019), predicting links in entailment graphs (Hosseini et al., 2019) and interpreting sign languages (Wilbur, 2003). In addition, knowledge about the aspectual class of a verb phrase, and its influence on the temporal extent and entailments that it licenses, has been leveraged in the past for a number of natural language understanding tasks such as temporal relation extraction (Costa and Branco, 2012), event ordering (Chambers et al., 2014; Modi and Titov, 2014), and statistical machine translation (Lo´aiciga and Grisot, 2016). The Aktionsart (Vendler, 1957) of a verb determines the temporal extent of the predication as well as whether it causes a change of state for the entities involved (Filip, 2012). As Aktionsart typically refers to the lexical aspect of a verb in isolation, we adopt the terminology of Verkuyl (2005), and refer to the compositionally formed Aktionsart of a verb phrase as predicational aspect. One of the most important distinctions of the predicational aspect of a verb is between states, such as to know or to love, and events, such as visit or swim. This distinction is important for identifying the entailments that a given ver"
2020.coling-main.401,C14-1212,0,0.0243232,"the 10 most frequent verbs shows that there are some highly skewed verbs, such as get, see or know, which have a 3 The annotation protocol is published with the dataset at https://go.rutgers.edu/cb6le5c1. 4548 Figure 1: Frequency distribution of the 10 most frequent verbs (left) and associated label distribution for the 10 most frequent verbs (right). clear majority class, whereas do or look exhibit a much more balanced, and therefore ambiguous label distribution. 4 Experiments The utility of distributional semantic word representations has been shown in a large body of works in recent years (Weeds et al. (2014), Nguyen et al. (2017), Socher et al. (2013), Bowman et al. (2015); passim). In order to compose a verb with its context we apply pointwise addition as a simple distributional composition function. Pointwise addition in neural word embeddings approximates the intersection of their contexts4 (Tian et al., 2017), and has been shown to be an efficient function for contextualising a word in a phrase (Arora et al., 2016; Kober et al., 2017). 4.1 Distributional Models for Predicational Aspect Following previous work on modelling the aspectual class of a verb (Siegel and McKeown, 2000; Friedrich and"
2020.sigdial-1.22,D16-1125,0,0.202182,"Missing"
2020.sigdial-1.22,P19-1059,0,0.0707207,"ts might utterances with different origins have on the dynamics of interaction? The increasing availability of corpus data and the increasing power of machine learning methods makes it possible to adopt a quantitative approach to answering such questions. The remainder of this paper offers an initial experiment in this direction. 3 Learning Speaker Reasoning We formulate computational models of speaker reasoning in two steps. First, as described in Section 3.1, we build the XKCD model based on the applicability and cost of color terms, following McMahan and Stone (2015); Monroe et al. (2016); McDowell and Goodman (2019). Second, we describe the linguistic and cooperative reasoning choices of speakers as a function of these learned parameters. As described in Section 3.2, our models of linguistic reasoning use probabilistic models of vagueness to formulate low-cost descriptions that denote the target uniquely (van Deemter, 2006; Meo et al., 2014). Meanwhile, as described in Section 3.3, our models of cooperative reasoning use probabilistic planning to find low-cost utterances likely to be understood by the listener, following the Rational Speech Acts approach (Frank and Goodman, 2012). 3.1 The XKCD Model The"
2020.sigdial-1.22,J06-2002,0,0.175342,"Missing"
2020.sigdial-1.22,Q15-1008,1,0.929449,"the utterances of human speakers? And what effects might utterances with different origins have on the dynamics of interaction? The increasing availability of corpus data and the increasing power of machine learning methods makes it possible to adopt a quantitative approach to answering such questions. The remainder of this paper offers an initial experiment in this direction. 3 Learning Speaker Reasoning We formulate computational models of speaker reasoning in two steps. First, as described in Section 3.1, we build the XKCD model based on the applicability and cost of color terms, following McMahan and Stone (2015); Monroe et al. (2016); McDowell and Goodman (2019). Second, we describe the linguistic and cooperative reasoning choices of speakers as a function of these learned parameters. As described in Section 3.2, our models of linguistic reasoning use probabilistic models of vagueness to formulate low-cost descriptions that denote the target uniquely (van Deemter, 2006; Meo et al., 2014). Meanwhile, as described in Section 3.3, our models of cooperative reasoning use probabilistic planning to find low-cost utterances likely to be understood by the listener, following the Rational Speech Acts approach"
2020.sigdial-1.22,D16-1243,0,0.0632066,"eakers? And what effects might utterances with different origins have on the dynamics of interaction? The increasing availability of corpus data and the increasing power of machine learning methods makes it possible to adopt a quantitative approach to answering such questions. The remainder of this paper offers an initial experiment in this direction. 3 Learning Speaker Reasoning We formulate computational models of speaker reasoning in two steps. First, as described in Section 3.1, we build the XKCD model based on the applicability and cost of color terms, following McMahan and Stone (2015); Monroe et al. (2016); McDowell and Goodman (2019). Second, we describe the linguistic and cooperative reasoning choices of speakers as a function of these learned parameters. As described in Section 3.2, our models of linguistic reasoning use probabilistic models of vagueness to formulate low-cost descriptions that denote the target uniquely (van Deemter, 2006; Meo et al., 2014). Meanwhile, as described in Section 3.3, our models of cooperative reasoning use probabilistic planning to find low-cost utterances likely to be understood by the listener, following the Rational Speech Acts approach (Frank and Goodman, 2"
2020.sigdial-1.22,Q17-1023,0,0.235263,"o be clear, many reference problems have simple, good solutions that any reasoning will find. Differences arise in more complicated cases, when speakers need to exploit the flexibility of linguistic meaning or the ability of the listener to recognize implicatures, and when speakers need to trade off between specific and general referring expressions. For clarity, our discussion illustrates these effects with concrete examples, even though this requires us to anticipate some results from later in the paper. In particular, we draw on attested examples from the Colors in Context (CIC) dataset of Monroe et al. (2017), where a director must signal one target in a display of three color patches. An example is shown in Figure 1. We characterize the examples in terms of the quantitative predictions of models (described in full detail in Section 3), which formalize linguistic reasoning and cooperative reasoning. These models adopt a decision-theoretic approach. Utterances achieve various outcomes with different probabilities. For example, we may be uncertain whether an utterance will be judged appropriate to the context, whether it will be understood correctly—and so whether it will be successful in advancing"
2021.findings-emnlp.291,2020.acl-main.583,1,0.651743,"ormation goals for these captions, and assigns a more adequate score when comparing the Model caption against the Human caption. In this case where a caption that does not just describe the image but elaborates on it, our metric recognizes that the model output is potentially successful (Photo credit: Moorthy Gounder) Introduction An investigation of the descriptions used with im- Lin, 2004; Denkowski and Lavie, 2014; Anderson et al., 2016a). ages on the web shows that image descriptions can have different functions and goals (Kruk et al., So far, however, efforts to develop such expres2019a; Alikhani et al., 2020). For instance, cap- sive captioning models have been hindered by the tions may describe visible entities, activities and lack of automatic metrics that can evaluate their relationships, provide background information that output with respect to their information goals in goes beyond what’s visible, or report the writer’s context. Previous approaches to automatic capown subjective reactions to what’s displayed. By tion evaluation have mostly focused on n-gram drawing on such diverse examples, image caption- measures of similarity to reference output (Vedaning models can learn the different inf"
2021.findings-emnlp.291,N19-1423,0,0.013806,"metric to pre- words are common and used appropriately in the vious ones using a common methodology, ranking generated text. Embedding-based metrics such as the performance of several different caption genera- BLEURT (Sellam et al., 2020) and BERTScore tion systems on out-of-domain images—relying on (Zhang et al., 2020) designed to address this lima new benchmark out-of-domain test set, which we itation are closer to human ratings. BLEURT is publish, providing reference captions for a subset a data-intensive training scheme that is based on of OpenImages (Kuznetsova et al., 2020b). Our BERT (Devlin et al., 2019) fine-tuned on human 3420 Facade of a glass building. A pink flower bush in a garden. The underside of the Arc de Triomphe. Close-up of a fly sitting on a daisy. Man sitting by his artwork looking at a large statue of a man on a horse in a royal courtyard. Woman with an umbrella reading a book sitting in the grass in front of a city skyline. Cowboy on a horse and cowboy on the ground working together to lasso a calf in a pen. Black and white artwork painted on a blue wall. Figure 2: Examples of the ground truth captions that we collected for the COIN dataset. (Photo credits from left to right,"
2021.findings-emnlp.291,2020.emnlp-main.191,0,0.0233321,"ni et al. (2020)’s relations that charory (Hobbs, 1985), which characterizes the infer- acterize inferences between text and images. ences that give discourse units a coherent joint inCoherence-aware models have benefited sevterpretation using a constrained inventory of coher- eral NLP tasks such as gesture interpretation (Lasence relations. In particular, we use the taxonomy carides and Stone, 2009; Pustejovsky and Krishfor image–text coherence developed by Alikhani naswamy, 2020), text summarization (Xu et al., et al. (2020), which for example includes Visible, 2019), machine comprehension (Gao et al., 2020). Story and Subjective relations between the text and The majority of these works use Rhetorical Structhe image. A description and an image stand in a ture Theory (RST) (Mann and Thompson, 1987) Visible relation if the text includes information that and Penn Discourse TreeBank (PDTB) (Prasad is recognizably depicted in the image. Subjective et al., 2008b) datasets to learn and predict these captions react to the content of the image and Story relations between two adjacent text spans. In this captions provide a free-standing description of the line of work, we are the first to present a cohere"
2021.findings-emnlp.291,W19-5357,0,0.0114082,"tion. A subset of 50 random images is used of the reference or generated captions. These serve to rank the captioning systems as described above, as baselines for COSMic. resulting in 400 machine-generated captions total N-gram based The most popular image caption- for the 8 captioning systems. These were then ing metrics are based on precision and recall of n- evaluated by human annotators using the process described in Section 3. The human-scored system grams from generated and reference captions. We level performance for each captioning system on compare with Bleu1 , Bleu2 , Bleu3 , Bleu4 (Guo and Hu, 2019), ROUGEL (Lin, 2004), CIDEr (Vedan- this test set is reported in Table 1 in “Average Hutam et al., 2015), and SPICE (Anderson et al., man Rating”. We measure the alignment between metric2016b). We compute these using their popular 6 assigned and human-assigned scores using the open-source implementation . Kendall (Kendall, 1938) correlation coefficient. In BLEURT We use a pre-trained BLEURT model7 order to calculate the score, we first aggregate all as a baseline for our work. Unlike N-gram based the sample scores and average them. Then we approaches, BLEURT uses BERT-based word em- calculate"
2021.findings-emnlp.291,W14-3348,0,0.00939303,"different coherence relation than the reference (Human) caption. “Coh.” represents the coherence labels for generated and reference captions. Our coherence-aware metric COSMic is aware of the different information goals for these captions, and assigns a more adequate score when comparing the Model caption against the Human caption. In this case where a caption that does not just describe the image but elaborates on it, our metric recognizes that the model output is potentially successful (Photo credit: Moorthy Gounder) Introduction An investigation of the descriptions used with im- Lin, 2004; Denkowski and Lavie, 2014; Anderson et al., 2016a). ages on the web shows that image descriptions can have different functions and goals (Kruk et al., So far, however, efforts to develop such expres2019a; Alikhani et al., 2020). For instance, cap- sive captioning models have been hindered by the tions may describe visible entities, activities and lack of automatic metrics that can evaluate their relationships, provide background information that output with respect to their information goals in goes beyond what’s visible, or report the writer’s context. Previous approaches to automatic capown subjective reactions to w"
2021.findings-emnlp.291,D19-1469,0,0.0253748,"Missing"
2021.findings-emnlp.291,W04-1013,0,0.455583,"that has a different coherence relation than the reference (Human) caption. “Coh.” represents the coherence labels for generated and reference captions. Our coherence-aware metric COSMic is aware of the different information goals for these captions, and assigns a more adequate score when comparing the Model caption against the Human caption. In this case where a caption that does not just describe the image but elaborates on it, our metric recognizes that the model output is potentially successful (Photo credit: Moorthy Gounder) Introduction An investigation of the descriptions used with im- Lin, 2004; Denkowski and Lavie, 2014; Anderson et al., 2016a). ages on the web shows that image descriptions can have different functions and goals (Kruk et al., So far, however, efforts to develop such expres2019a; Alikhani et al., 2020). For instance, cap- sive captioning models have been hindered by the tions may describe visible entities, activities and lack of automatic metrics that can evaluate their relationships, provide background information that output with respect to their information goals in goes beyond what’s visible, or report the writer’s context. Previous approaches to automatic capow"
2021.findings-emnlp.291,P19-1654,0,0.018747,"m left to right, top to bottom: Sharron Mollerus, Northfielder, George M. Groutas, davebloggs007, Tim Adams, Brisbane City Council, Colin Brown, Guilhem Vellut) ratings of generated text. BERTScore, however, computes the similarity score as the average of cosine similarities between predicted tokens and their top matching reference tokens. These metrics however, do not respect the information goal and the purpose for which the model has generated the text. We address this problem by introducing the first coherence-aware generation metric. Similar to SPICE (Anderson et al., 2016b) and VIFIDEL (Madhyastha et al., 2019) we use the information encoded in images. We further propose the addition of coherence relations that facilitate learning with fewer samples by a multimodal metric using pre-trained BERT and ViLBERT. 3 Data Collection We collect two datasets: human judgments for image captions that are generated by coherenceaware captioning systems using Conceptual Captions dataset; and ground-truth labels for the Open Images dataset. With Conceptual Captions corpora we fine-tune ViLBERT with ratings and show that addition of coherence relations can make automated scoring closer to human scoring. We use OpenI"
2021.findings-emnlp.291,P02-1040,0,0.110516,"displayed. By tion evaluation have mostly focused on n-gram drawing on such diverse examples, image caption- measures of similarity to reference output (Vedaning models can learn the different inferential links tam et al., 2014); such surface-level models fail between text and images and use that information to deal with the lexical and syntactic diversity of at generation time to produce descriptions that can image descriptions. More recent approaches more fulfill different discourse goals and inject the de- closely approximate semantic similarity using word sired context into their output (Papineni et al., 2002; embedding-based techniques. These models show 3419 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3419–3430 November 7–11, 2021. ©2021 Association for Computational Linguistics robust performance and achieve a higher correlation with human judgments than that of previous metrics. Nevertheless, they too fail to generalize to the different kinds of content that successful descriptions may exhibit across different goals and contexts. That is, they cannot distinguish reasonable descriptions that happen to differ from reference output in their goals and perspective,"
2021.findings-emnlp.291,prasad-etal-2008-penn,0,0.428949,"in 4 different coherence classes of Meta, Visible, Subjective, Story. These 4,000 image/caption pairs are then presented to human annotators who are asked to select the correct coherence label for each pair: Protocol We hired two expert linguists for data annotation and designed an annotation website to facilitate the annotation procedure. They are native English speakers who identify themselves as 3421 • Meta: the caption talks about when, where, and how the picture is taken. Meta-talk in Schiffrin (1980) • Visible: the caption is true just by looking at the picture. Restatement relation in Prasad et al. (2008a). • Subjective: the captions is the matter of opinion. Evaluation relation in Hobbs (1985). • Story: text and image work like story and illustration. Occasion relation in Hobbs (1985). 1 https://github.com/Merterm/COSMic Figure 3: An illustration of different flavors of COSMic that outputs a score for the generated caption given the image, reference caption, and the coherence-labels for both the captions. (a) COSMic Vanilla uses only global textual and visual features, while (b) COSMic ViLBERT uses combined visio-linguistic features with both local and global focus. This model takes into acc"
2021.findings-emnlp.291,2020.acl-main.704,0,0.0820457,"ing a ROUGE (Lin, 2004), and CIDEr (Vedantam et al., coherence-aware metric. We present a model to 2015), . The major problem of the n-gram simscore a generated caption given the image, refer- ilarity metrics is that they give no credit to synence caption, and the discourse goals of both these onym matches of reference n-grams, even if those captions (Section 4). We compare this metric to pre- words are common and used appropriately in the vious ones using a common methodology, ranking generated text. Embedding-based metrics such as the performance of several different caption genera- BLEURT (Sellam et al., 2020) and BERTScore tion systems on out-of-domain images—relying on (Zhang et al., 2020) designed to address this lima new benchmark out-of-domain test set, which we itation are closer to human ratings. BLEURT is publish, providing reference captions for a subset a data-intensive training scheme that is based on of OpenImages (Kuznetsova et al., 2020b). Our BERT (Devlin et al., 2019) fine-tuned on human 3420 Facade of a glass building. A pink flower bush in a garden. The underside of the Arc de Triomphe. Close-up of a fly sitting on a daisy. Man sitting by his artwork looking at a large statue of a"
2021.findings-emnlp.291,P18-1238,1,0.812053,"Missing"
C04-1181,J03-2002,0,0.0174943,"mation available from domain knowledge and the current task context. In FIGLET’s drawing domain, possibilities include the actual measurements of objects that have already been drawn. They also include the default domain measurements for new objects that task context says could be added. Setting standards by a measurement is our shorthand for adopting an implicit range of compatible standards; these standards remain vague, especially since many options are normally available (Graff, 2000). We treat the use of new candidate standards in interpretation as a case of presupposition accommodation (Bos, 2003). In presupposition accommodation, the interpretation of an utterance must be constructed using a context that differs from the actual context. When speakers use an utterance which requires accommodation, they typically expect that interlocutors will update the dialogue context to include the additional presumptions the utterance requires. We assume that all accommodation is subject to two Gricean constraints. First, we assume whenever possible that an utterance should have a uniquely identifiable intended interpretation in the context in which it is to be interpreted. Second, we assume that w"
C04-1181,P01-1031,0,0.0296934,"dimensions of context systematically, through increasingly lightweight, factored models. The evolving state of real-world activity proceeds predictably according to background plans and principles of coordination (Rich et al., 2001). The status of the dialogue itself is defined by circumscribed obligations to ground prior utterances, follow up open issues, and advance realworld negotiation (Larsson and Traum, 2000). Finally, the evolving state of the linguistic context is a direct outgrowth of the linguistic forms interlocutors use and the linguistic relationships among successive utterances (Ginzburg and Cooper, 2001; Asher and Lascarides, 2003). These compatible models combine directly to characterize an aggregate information state that provides a general background for interpretation (Bunt, 2000). We argue in this paper that such integrated models enable systems to calculate useful, fine-grained utterance interpretations from radically underspecified semantic forms. We focus in particular on vague scalar predicates like small or long. These predicates typify qualitative linguistic expression of quantitative information, and are thus both challenging and commonplace. Building on a multidimensional treatm"
C04-1181,P01-1061,0,0.0156658,"any standard that captures a relevant distinction for vague-predicate in the context. If there is a strongest standard that results in a unique interpretation, it is adopted and integrated into the new linguistic context. 5.3 Parsing and Interpretation Language understanding in FIGLET is mediated by a bottom-up chart parser written in Prolog. As usual, chart edges indicate the presence of recognized partial constituents within the input sequence. In addition, edges now carry constraint networks that specify the contextual reasoning required for understanding. In addition to finite instances (Schuler, 2001), these networks include real constraints that formalize metric and spatial relationships. Interpretation of these networks is carried out incrementally, during parsing; each edge thus records a set of associated candidate interpretations. Since domain reasoning can be somewhat time-intensive in our current implementation, we adopt a strategy of delaying the solution of certain constraints until enough lexical material has accrued that the associated problem-solving is judged tractable (DeVault and Stone, 2003). 6 Assessment and Conclusion In our approach, we specify a genuinely vague semantic"
C16-1022,N16-1181,0,0.0311607,"rinking the horizon of semantic goals. At each step, syntactic operations grow the number of available syntactic choices while limiting the number of semantic goals left to express. In contrast, parsing and understanding begin with the surface form and construct the organized semantic content, either for a downstream decision or just for the structure itself. The most notable works in this line of research are the recurrent neural network grammars (Dyer et al., 2016), a shift-reduce parser and interpreter (Bowman et al., 2016), and a dynamic network for composing other neural network modules (Andreas et al., 2016). Interestingly, there is a common theme of using indexable and dynamic data structures in neural architecture to make long-distance decisions. 7 Conclusion This paper has explored issues in deep learning of probabilistic tree grammars from the standpoint of natural language generation. For NLG, we need models that predict high-probability structures to encode deep linguistic relationships—rather than to infer deep relationships from surface cues. This problem brings new challenges for learning, as it requires us to represent new kinds of linguistic elements and new kinds of structural context"
C16-1022,C00-1007,0,0.60738,"ing techniques, NLG researchers have had to predict choices using factored models with handcrafted representations and strong independence assumptions, in order to avoid combinatorial explosions and address the sparsity of training data. By contrast, in this paper, we leverage recent advances in deep learning to develop new models for syntactic choice that free engineers from many of these decisions, but still generalize more effectively, match human choices more closely, and enable more efficient computations than traditional techniques. We adopt the characterization of syntactic choice from Bangalore and Rambow (2000): the problem is to use a stochastic tree model and a language model to produce a linearized string from an unordered, unlabeled dependency graph. The first step to producing a linearized string is to assign each item an appropriate supertag—a fragment of a parse tree with a leaf left open for the lexical item. This process involves applying a learned model to make predictions for the syntax of each item and then searching over the predictions to find a consistent assignment for the entire sentence. The resulting assignments allow for many possible surface realization outputs because they can"
C16-1022,W00-1401,0,0.117992,"y learn the target distributions. Next, we evaluate the models on the full NLG task, including linearization. The linearization task allows more freedom in supertag classifications because supertags may differ in minor ways, such as the projections present along the spine, which will not affect generation output for a particular target input. The freedom means models may not be penalized based on decisions that don’t matter—thus, at the same time, it also mutes the distinctions between classification decisions. We report a modified edit distance measure, Generation String Accuracy, following (Bangalore et al., 2000). Since linearization uses a beam search, we report statistics both for the top-ranked beam and for the empirically based beam among the candidates computed during search. The difference gives an indication of the effect of the language model in guiding the decisions that remain after supertagging. 3 With respect to the surface form, the only cleaning operations were to merge proper noun phrases into single tokens. Punctuation and other common cleaning operations were not performed. 4 Many of the validation examples had more than 240 possible linearizations. 5 A possible additional data source"
C16-1022,W01-0520,0,0.096764,"iang’s sister-adjunction allows for the flat structures in the Penn Treebank while limiting the formalism to context-free power. 2.2 Grammar Induction In lexicalized tree grammars, the lexicon and the grammatical rules are one and the same. The set of possible grammatical moves which can be made are simultaneously the set of possible words which can be used next. This means that inducing a tree grammar from a data set is a matter of inferring the set of constructions in the data. We follow previous work in using bracketed phrase structure corpora and deterministic rules to induce the grammar (Bangalore et al., 2001; Chiang, 2000). Broadly, the methodology is to split the observed trees into the constituents which make it up, according to the grammar formalism. We use head rules (Chiang, 2000; Collins, 1997; Magerman, 1995) to associate internal nodes in a bracketed tree with the lexical item that owns it. We use additional rules to classify some children as complements, corresponding to substitution sites and root notes of complement trees; and other children as adjuncts, corresponding to insertion trees that combine with the parent node, either to the right or to the left of the head. This allows us to"
C16-1022,P16-1139,0,0.0123091,"d-planning in a generation task produces a growing horizon of syntactic choices while shrinking the horizon of semantic goals. At each step, syntactic operations grow the number of available syntactic choices while limiting the number of semantic goals left to express. In contrast, parsing and understanding begin with the surface form and construct the organized semantic content, either for a downstream decision or just for the structure itself. The most notable works in this line of research are the recurrent neural network grammars (Dyer et al., 2016), a shift-reduce parser and interpreter (Bowman et al., 2016), and a dynamic network for composing other neural network modules (Andreas et al., 2016). Interestingly, there is a common theme of using indexable and dynamic data structures in neural architecture to make long-distance decisions. 7 Conclusion This paper has explored issues in deep learning of probabilistic tree grammars from the standpoint of natural language generation. For NLG, we need models that predict high-probability structures to encode deep linguistic relationships—rather than to infer deep relationships from surface cues. This problem brings new challenges for learning, as it requ"
C16-1022,P00-1058,0,0.448396,"osts because it is mildly context-sensitive in generative power. Several variants reduce the complexity of the formalism by limiting the range of adjunction operations. For example, the Tree Insertion Grammar allows for adjunction as long as it is either a left or right auxiliary tree (Schabes and Waters, 1995). Tree Substitution Grammars, meanwhile, allow for no adjunction and only substitutions (Cohn et al., 2009). We adopt one particular restriction on adjunction, called sisteradjunction or insertion, which allows trees to attach to an interior node and add itself as a first or last child (Chiang, 2000). Chiang’s sister-adjunction allows for the flat structures in the Penn Treebank while limiting the formalism to context-free power. 2.2 Grammar Induction In lexicalized tree grammars, the lexicon and the grammatical rules are one and the same. The set of possible grammatical moves which can be made are simultaneously the set of possible words which can be used next. This means that inducing a tree grammar from a data set is a matter of inferring the set of constructions in the data. We follow previous work in using bracketed phrase structure corpora and deterministic rules to induce the gramm"
C16-1022,N09-1062,0,0.0345176,"root and a distinguished foot note in the auxiliary tree. The lexicalization of the the grammar requires each elementary tree to have at least one lexical item as a leaf. LTAG incurs computational costs because it is mildly context-sensitive in generative power. Several variants reduce the complexity of the formalism by limiting the range of adjunction operations. For example, the Tree Insertion Grammar allows for adjunction as long as it is either a left or right auxiliary tree (Schabes and Waters, 1995). Tree Substitution Grammars, meanwhile, allow for no adjunction and only substitutions (Cohn et al., 2009). We adopt one particular restriction on adjunction, called sisteradjunction or insertion, which allows trees to attach to an interior node and add itself as a first or last child (Chiang, 2000). Chiang’s sister-adjunction allows for the flat structures in the Penn Treebank while limiting the formalism to context-free power. 2.2 Grammar Induction In lexicalized tree grammars, the lexicon and the grammatical rules are one and the same. The set of possible grammatical moves which can be made are simultaneously the set of possible words which can be used next. This means that inducing a tree gram"
C16-1022,P97-1003,0,0.465936,"mmatical rules are one and the same. The set of possible grammatical moves which can be made are simultaneously the set of possible words which can be used next. This means that inducing a tree grammar from a data set is a matter of inferring the set of constructions in the data. We follow previous work in using bracketed phrase structure corpora and deterministic rules to induce the grammar (Bangalore et al., 2001; Chiang, 2000). Broadly, the methodology is to split the observed trees into the constituents which make it up, according to the grammar formalism. We use head rules (Chiang, 2000; Collins, 1997; Magerman, 1995) to associate internal nodes in a bracketed tree with the lexical item that owns it. We use additional rules to classify some children as complements, corresponding to substitution sites and root notes of complement trees; and other children as adjuncts, corresponding to insertion trees that combine with the parent node, either to the right or to the left of the head. This allows us to segment the tree into units of substitution and insertion.1 1 One particular downside of deterministically constructing the grammar this way is that it can produce an excess of superfluous eleme"
C16-1022,de-marneffe-etal-2006-generating,0,0.0174452,"Missing"
C16-1022,N16-1024,0,0.0326079,"in its treatment of state and search. Specifically, forward-planning in a generation task produces a growing horizon of syntactic choices while shrinking the horizon of semantic goals. At each step, syntactic operations grow the number of available syntactic choices while limiting the number of semantic goals left to express. In contrast, parsing and understanding begin with the surface form and construct the organized semantic content, either for a downstream decision or just for the structure itself. The most notable works in this line of research are the recurrent neural network grammars (Dyer et al., 2016), a shift-reduce parser and interpreter (Bowman et al., 2016), and a dynamic network for composing other neural network modules (Andreas et al., 2016). Interestingly, there is a common theme of using indexable and dynamic data structures in neural architecture to make long-distance decisions. 7 Conclusion This paper has explored issues in deep learning of probabilistic tree grammars from the standpoint of natural language generation. For NLG, we need models that predict high-probability structures to encode deep linguistic relationships—rather than to infer deep relationships from surface cues"
C16-1022,P14-1062,0,0.0154223,"ions as a function of those items’ learned features. The resulting ability to generalize across sparse data seems to be one of the most important reasons for the success of deep learning in NLP. The simplest way to embed supertags is to treat each structure as a distinct token that indexes a corresponding learned vector. This places no constraints on the learned similarity function, but it also ignores the hierarchical structure of the elementary trees themselves. Previous work on deep learning with graph structures suggests convolutional neural networks can exploit similarities in structure (Kalchbrenner et al., 2014; Niepert et al., 2016). Thus, we developed analogous techniques to encode supertags based on their underlying tree structure. In particular, to embed a supertag, we embed each node, group the resulting vectors to form a tensor, and then summarize the tensor into a single vector using a series of convolutional neural networks. Note that each elementary tree is a complex structure with nodes labeled by category and assigned a role that enables further tree operations. The root node’s role represents the overall action associated with that elementary tree—either substitution or insertion. The re"
C16-1022,P98-1116,0,0.179649,"dependency trees, documenting the contribution of our modeling techniques to improvements in both accuracy and run time. 1 Introduction Where natural language understanding systems face problems of ambiguity, natural language generation (NLG) systems face problems of choice. A wide coverage NLG system must be able to formulate messages using specialized linguistic elements in the exceptional circumstances where they are appropriate; however, it can only achieve fluency by expressing frequent meanings in routine ways. Empirical methods have thus long been recognized as crucial to NLG; see e.g. Langkilde and Knight (1998). With traditional stochastic modeling techniques, NLG researchers have had to predict choices using factored models with handcrafted representations and strong independence assumptions, in order to avoid combinatorial explosions and address the sparsity of training data. By contrast, in this paper, we leverage recent advances in deep learning to develop new models for syntactic choice that free engineers from many of these decisions, but still generalize more effectively, match human choices more closely, and enable more efficient computations than traditional techniques. We adopt the charact"
C16-1022,Q14-1026,0,0.0284983,"e a high probability assignment for all supertags simultaneously. In this process, tags for children must be chosen consistently with one another, and the resulting probabilistic information must be propagated upward to rerank tags elsewhere in the tree. We solve this problem with an A* algorithm. At each step, 228 the algorithm uses a priority queue to select subtrees based on their inside-outside scores. The inside score is computed as the sum of the log probabilities of the supertags in the subtree. The outside score is the sum of the best supertag for nodes outside the subtree, similar to Lewis and Steedman (2014). Once selected, the subtree is attached to the possible supertags of its parent that are both locally consistent and consistent among its already attached children. These resulting subtrees are placed into the priority queue and the algorithm iterates to progress the search. The search succeeds when the first complete tree has been found.2 4.2 Model 2: Fergus-R Fergus-R is a stochastic tree model implemented in a top-down recurrent tree network and augmented with soft attention. For each node in the input dependency tree, soft attention—a method which learns a vectorized function to weight a"
C16-1022,P95-1037,0,0.441957,"are one and the same. The set of possible grammatical moves which can be made are simultaneously the set of possible words which can be used next. This means that inducing a tree grammar from a data set is a matter of inferring the set of constructions in the data. We follow previous work in using bracketed phrase structure corpora and deterministic rules to induce the grammar (Bangalore et al., 2001; Chiang, 2000). Broadly, the methodology is to split the observed trees into the constituents which make it up, according to the grammar formalism. We use head rules (Chiang, 2000; Collins, 1997; Magerman, 1995) to associate internal nodes in a bracketed tree with the lexical item that owns it. We use additional rules to classify some children as complements, corresponding to substitution sites and root notes of complement trees; and other children as adjuncts, corresponding to insertion trees that combine with the parent node, either to the right or to the left of the head. This allows us to segment the tree into units of substitution and insertion.1 1 One particular downside of deterministically constructing the grammar this way is that it can produce an excess of superfluous elementary trees. We m"
C16-1022,D14-1162,0,0.0821677,"Missing"
C16-1022,J95-4002,0,0.112234,"nction operation modifies the internal structure of a target tree by expanding a node identically-labeled with the root and a distinguished foot note in the auxiliary tree. The lexicalization of the the grammar requires each elementary tree to have at least one lexical item as a leaf. LTAG incurs computational costs because it is mildly context-sensitive in generative power. Several variants reduce the complexity of the formalism by limiting the range of adjunction operations. For example, the Tree Insertion Grammar allows for adjunction as long as it is either a left or right auxiliary tree (Schabes and Waters, 1995). Tree Substitution Grammars, meanwhile, allow for no adjunction and only substitutions (Cohn et al., 2009). We adopt one particular restriction on adjunction, called sisteradjunction or insertion, which allows trees to attach to an interior node and add itself as a first or last child (Chiang, 2000). Chiang’s sister-adjunction allows for the flat structures in the Penn Treebank while limiting the formalism to context-free power. 2.2 Grammar Induction In lexicalized tree grammars, the lexicon and the grammatical rules are one and the same. The set of possible grammatical moves which can be mad"
C16-1022,N16-1035,0,0.0135514,"re stochastic tree models from the standpoint of parsing and understanding. While using the same methods, NLG has different goals and we think the perspective is instructive. Where parsing infers the most probable underlying structure, generation infers the most likely way of expressing a semantic structure. This divergence of goals leads to different concerns, alternatives, and emphasis. The works most similar to ours explicitly model tree structures, but focus on resolving the uncertainty involved with the latent structure of an observed sentence. For example, the top down tree structure of Zhang et al. (2016) expresses the generation of a dependency structure as the decisions of a set of long short-term memory networks. For each decision, the possible options are different tree structures which can produce the target linear form. In contrast, the generation problem is concerned with different linear forms that can result from the same tree structure. In more extensive tasks, the generation problem can include simulated interpretation to inform decisions; using the ease of structural inference from linear form quantifies the understandability of a sentence. Although the methodology presented in thi"
C16-1022,C98-1112,0,\N,Missing
C18-1301,P98-1013,0,0.713648,"in Section 2 with a tour of work on multimodal communication, which has made a strong case for parsing diagrams to organize basic conventional elements into recursive structural relationships, and for interpreting such parses by combining compositional meaning with discourse-based inference. We use this framework in Section 3 to motivate a linguistically-inspired approach to the interpretation of arrows: we characterize arrows into four qualitatively different structures, analogous to verb subcategorization frames; we associate each structure with a meaning, analogous to verb frame semantics (Baker et al., 1998); and we describe the contextual supplementation some structures require, by analogy to the co-compositionality of generative lexicon theory (Pustejovsky, 1998, GLT). The remainder of the paper offers empirical evidence in support of our approach. Our first experiments, presented in Section 4, assess our semantic frames for arrows in light of crowd workers’ judgments about the Kembhavi et al. (2016) data set. People label our categories with high agreement, and the categories account for the overwhelming majority of items in the corpus. Moreover, we find that arrows are normally used in one se"
C18-1301,J09-3002,0,0.027774,"ied from the standpoint of design, as in Horn (1998); psychology, as in Larkin and Simon (1987); computer graphics, as in Agrawala et al. (2003); computer vision, as in Alvarado and Davis (2004); and common-sense reasoning, as in Forbus et al. (2011)—as well as natural language (NL) technology. Our work is most directly inspired by prototypes in mulitmodal communication that use NL techniques either to synthesize communicative presentations, as in Andr´e et al. (1993) and Feiner and McKeown (1993), or to interpret multimodal user input, as in Johnston (1998), Johnston and Bangalore (2005) and Bangalore and Johnston (2009). For example, Johnston (1998) argues for processing diagrams with a syntactic parser, so that systems can recognize their essential hierarchical relationships, and for using a constraint-based grammar formalism, so specific productions can inherit constraints from general rule schemas, as in HPSG (Pollard and Sag, 1994). The success of such efforts shows that NL architectures can effectively capture communicative acts across a diverse range of modalities and contexts. This leads us to ask how we might develop domain-general tools and methodologies that could support such multimodal architectu"
C18-1301,J81-4005,0,0.731919,"Missing"
C18-1301,copestake-flickinger-2000-open,0,0.12745,"r, so that systems can recognize their essential hierarchical relationships, and for using a constraint-based grammar formalism, so specific productions can inherit constraints from general rule schemas, as in HPSG (Pollard and Sag, 1994). The success of such efforts shows that NL architectures can effectively capture communicative acts across a diverse range of modalities and contexts. This leads us to ask how we might develop domain-general tools and methodologies that could support such multimodal architectures—perhaps following the successful application to text of wide-coverage grammars (Copestake and Flickinger, 2000, among others) and parsers (de Marneffe et al., 2006, among others). To pursue this direction, we build on an emerging trend of applying the theory of NL semantics and discourse to multimodal communication, which includes work on the grammar of coreference, such as Schlenker and Chemla (2017) for gesture, and Abusch (2013) and Cohn (2013) for comics, and work on the grammar of coherence, such as Lascarides and Stone (2009) for gesture, and Bateman and Schmidt (2013) and Cumming et al. (2017) for film. Looking at arrows is a novel contribution to this literature. Of course, we can find many lo"
C18-1301,de-marneffe-etal-2006-generating,0,0.0540676,"Missing"
C18-1301,H92-1045,0,0.286782,", by analogy to the co-compositionality of generative lexicon theory (Pustejovsky, 1998, GLT). The remainder of the paper offers empirical evidence in support of our approach. Our first experiments, presented in Section 4, assess our semantic frames for arrows in light of crowd workers’ judgments about the Kembhavi et al. (2016) data set. People label our categories with high agreement, and the categories account for the overwhelming majority of items in the corpus. Moreover, we find that arrows are normally used in one sense per diagram, much as lexical items exhibit one sense per discourse (Gale et al., 1992). Our next experiments, presented in Section 5, assess our approach to contextual interpretation: certain frames must be supplemented with a salient relationship. Assuming one sense per diagram, we train a machine-learning model that predicts this relationship from the textual content of the diagram. The performance of the method corroborates our hypothesis (analogous to GLT) that these relationships can and should be resolved based on relatively shallow encyclopedic knowledge. Our contributions are primarily formal—to characterize the knowledge needed to model diagrams. Fundamental challenges"
C18-1301,P98-1102,0,0.572345,"ng documents. Consequently, diagrams have been studied from the standpoint of design, as in Horn (1998); psychology, as in Larkin and Simon (1987); computer graphics, as in Agrawala et al. (2003); computer vision, as in Alvarado and Davis (2004); and common-sense reasoning, as in Forbus et al. (2011)—as well as natural language (NL) technology. Our work is most directly inspired by prototypes in mulitmodal communication that use NL techniques either to synthesize communicative presentations, as in Andr´e et al. (1993) and Feiner and McKeown (1993), or to interpret multimodal user input, as in Johnston (1998), Johnston and Bangalore (2005) and Bangalore and Johnston (2009). For example, Johnston (1998) argues for processing diagrams with a syntactic parser, so that systems can recognize their essential hierarchical relationships, and for using a constraint-based grammar formalism, so specific productions can inherit constraints from general rule schemas, as in HPSG (Pollard and Sag, 1994). The success of such efforts shows that NL architectures can effectively capture communicative acts across a diverse range of modalities and contexts. This leads us to ask how we might develop domain-general tool"
C18-1301,D14-1181,0,0.00269083,"(it has only 93 datapoints), but we divide the two other groups, turn into and eats, based on three existing categories in AI2D (cycle of rocks, volcano, cycle of life) and three subcategories that we found in food web data (ocean, large birds, big cats). Since the number of blocks is small, we report cross-validation results leaving out one fold as test data. 5.2 Models We used a bag of words (BoW) model with the SVM classifier as our baseline. We compared the baseline to a convolutional neural network (CNN) with one convolution layer over pretrained word embeddings (Collobert et al., 2011; Kim, 2014). We used a max-over-time pooling operation and dropout regularization. See Table. 5. This setting enabled us to measure the effectiveness of considering distributional similarity in our classification task and thus the importance of generalizing based on shallow semantic knowledge. To see how important it is to semantically understand the input by using sequential and structural information, we experiment with hierarchical attention RNNs (Yang et al., 2016). We made a look-up table for vocabulary, converted all words to integers and applied a one hot encoder. Next, we padded the input sequenc"
C18-1301,N16-1174,0,0.0136813,"compared the baseline to a convolutional neural network (CNN) with one convolution layer over pretrained word embeddings (Collobert et al., 2011; Kim, 2014). We used a max-over-time pooling operation and dropout regularization. See Table. 5. This setting enabled us to measure the effectiveness of considering distributional similarity in our classification task and thus the importance of generalizing based on shallow semantic knowledge. To see how important it is to semantically understand the input by using sequential and structural information, we experiment with hierarchical attention RNNs (Yang et al., 2016). We made a look-up table for vocabulary, converted all words to integers and applied a one hot encoder. Next, we padded the input sequences, and fed them through Embedding, LSTM and Dense layers. Model Architectures are described in detail in Appendix A. We trained the models to minimize binary cross entropy. Text was fed in left to right and top to bottom based on the position in the diagram. 6 44 responses consisted of a single verb (differing across subjects: turn into, metamorphose), and 5 included two verbs with similar meanings (develop, turn into), while 7 included nouns or short sente"
E09-1022,J96-1002,0,0.00760509,"the correctness of state sk , we consider only those interpretations arising in states that are retrospectively identified as correct. For each such interpretation, we start from the state where that interpretation is adopted and trace forward to a correct state or to its last surviving descendant. We classify the interpretation the same way as that final state, either correct, eliminated, or dropped. from a set of training examples E = {e1 , ..., en } where, for l = 1..n, we have: el = ( F = fate(it,j ), features(it,j ), features(o), features(sk )). We chose to train maximum entropy models (Berger et al., 1996). Our learning framework is described in Section 4.1; the results in Section 4.2. 4.1 We harvested a training set using this methodology from the transcripts of a previous evaluation experiment designed to exercise COREF’s ambiguity management skills. The data comes from 20 subjects—most of them undergraduates participating for course credit—who interacted with COREF over the web in three rounds of the referential communication each. The number of objects increased from 4 to 9 to 16 across rounds; the roles of director and matcher alternated in each round, with the initial role assigned at ran"
E09-1022,W08-0103,0,0.0411946,"Missing"
E09-1022,J98-2001,0,0.131368,"Missing"
J03-4002,P01-1009,0,0.146503,"phone and picked up the receiver. Here the receiver denotes the receiver associated with (by virtue of being part of) the already-mentioned phone Myra darted to. Coreference and indirect anaphora can be uniformly modeled by saying that the discourse referent eα denoted by an anaphoric expression α is either equal to or associated with an existing discourse referent er , that is, eα =er or eα ∈assoc(er ). But coreference and associative anaphora do not exhaust the space of constructs that derive all or part of their sense from the discourse context and are thus anaphoric. Consider “other NPs” (Bierner 2001a; Bierner and Webber 2000; Modjeska 2001, 2002), as in: (26) Sue grabbed one phone, as Tom darted to the other phone. Although “other NPs” are clearly anaphoric, should the referent of the other phone (eα )—the phone other than the one Sue grabbed (er )—simply be considered a case of eα ∈ assoc(er )? Here are two reasons why they should not. First, in all cases of associative anaphora discussed in the literature, possible associations have depended only on the antecedent er and not on the anaphor. For example, only antecedents that have parts participate in whole-part associations (e.g., phon"
J03-4002,P02-1011,0,0.254166,"situation with anaphors so far, we have coreference when eα =er , indirect anaphora when eα ∈assoc(er ), and lexically specified anaphora when eα =fα (ei ) where ei = er or ei ∈assoc(er ). 3.2 Discourse Adverbials as Lexical Anaphors There is nothing in this generalized approach to discourse anaphora that requires that the source of er be an NP, or that the anaphor be a pronoun or NP. For example, the antecedent er of a singular demonstrative pronoun (in English, this or that) is often an eventuality that derives from a clause, a sentence, or a larger unit in the recent discourse (Asher 1993; Byron 2002; Eckert and Strube 2000; Webber 1991). We will show that this is the case with discourse adverbials as well. The extension we make to the general framework presented above in order to include discourse adverbials as discourse anaphors is to allow more general functions fα to be associated with lexically specified anaphors. In particular, for the discourse adverbials considered in this article, the function associated with an adverbial maps its anaphoric argument—an eventuality derived from the current discourse context—to a function that applies to the interpretation of the adverbial’s matrix"
J03-4002,W02-0204,1,0.645077,"plied to either an existing discourse referent or an entity associated with it through a bridging inference. In the case of the premodifier other, fα applied to its argument produces contextually 11 With respect to how many discourse adverbials there are, Quirk et al. (1972) discuss 60 conjunctions and discourse adverbials under the overall heading time relations and 123 under the overall heading conjuncts. Some entries appear under several headings, so that the total number of conjunctions and discourse adverbials they present is closer to 160. In another enumeration of discourse adverbials, Forbes and Webber (2002) start with all annotations of sentence-level adverbials in the Penn Treebank, then filter them systematically to determine which draw part of their meaning from the preceding discourse and how they do so. What we understand from both of these studies is that there are fewer than 200 adverbials to be considered, many of which are minor variations of one another (in contrast, by contrast, by way of contrast, in comparison, by comparison, by way of comparison that are unlikely to differ in their anaphoric properties, and some of which, such as contrariwise, hitherto, and to cap it all, will occu"
J03-4002,C92-1048,0,0.0487587,"n. So the variables must be the discourse variables usually used to translate other kinds of discourse anaphors.6 These arguments have been directed at the behavioral similarity between discourse adverbials and what we normally take to be discourse anaphors. But this isn’t the only reason to recognize discourse adverbials as anaphors: In the next section, we suggest a framework for anaphora that is broad enough to include discourse adverbials as well as definite and demonstrative pronouns and NPs, along with other discourse phenomena that have been argued to be anaphoric, such as VP ellipsis (Hardt 1992, 1999; Kehler 2002), tense (Partee 1984; Webber 1988) and modality (Kibble 1995; Frank and Kamp 1997; Stone and Hardt 1999). 3. A Framework for Anaphora Here we show how only a single extension to a general framework for discourse anaphora is needed to cover discourse adverbials. The general framework is presented in Section 3.1, and the extension in Section 3.2. 3.1 Discourse Referents and Anaphor Interpretation The simplest discourse anaphors are coreferential: definite pronouns and definite NPs that denote one (or more) discourse referents in focus within the current discourse 6 Although r"
J03-4002,P85-1008,0,0.251834,"ing or deriving an eventuality from the current discourse context that meets the constraints of the adverbial with respect to the eventuality interpretation of the matrix clause. (Examples of this are given throughout the rest of the article.) 3.3 A Logical Form for Eventualities Before using this generalized view of anaphora to show what discourse adverbials contribute to discourse and how they interact with discourse relations that arise from adjacency or explicit discourse connectives, we briefly describe how we represent clausal interpretations in logical form (LF). Essentially, we follow Hobbs (1985) in using a rich ontology and a representation scheme that makes explicit all the individuals and abstract objects (i.e., propositions, facts/beliefs, and eventualities) (Asher 1993) involved in the LF interpretation of an utterance. We do so because we want to make intuitions about individuals, eventualities, lexical meaning, and anaphora as clear as possible. But certainly, other forms of representation are possible. In this LF representation scheme, each clause and each relation between clauses is indexed by the label of its associated abstract object. So, for example, the LF interpretation"
J03-4002,P02-1003,0,0.0133857,"eg SPunct |SPunct | on the one hand Seg on the other hand Seg | not only Seg but also Seg SPunct := S Punctuation Punctuation := . |; |: |? |! S := S Coord S |S Subord S |Subord S S |Sadv S | NP Sadv VP |S Sadv |. . . Coord := and |or |but |so Subord := although |after |because |before |... Sadv := DAdv |SimpleAdv DAdv := instead |otherwise |for example |meanwhile |... SimpleAdv := yesterday |today |surprisingly |hopefully |... Figure 6 PS rules for a discourse grammar. when semantics underspecifies syntactic dependency (as discourse semantics must, on our account) is known to be intractable (Koller and Striegnitz 2002). An effective solution is to generate semantics and syntax simultaneously, which is straightforward with a lexicalized grammar (Stone et al. 2001). Given the importance of various types of inference in discourse understanding, there is a second argument for using a lexicalized discourse grammar that derives from the role of implicature in discourse. Gricean reasoning about implicatures requires a hearer be able to infer the meaningful alternatives that a speaker had in composing a sentence. With lexicalization, these alternatives can be given by a grammar, allowing the hearer, for example, to"
J03-4002,P92-1004,0,0.0506838,"ure context. (Under coreference we include split reference, in which a plural anaphor such as the companies denotes all the separately mentioned companies in focus within the discourse context.) Much has been written about the factors affecting what discourse referents are taken to be in focus. For a recent review by Andrew Kehler, see chapter 18 of Jurafsky and Martin (2000). For the effect of different types of quantifiers on discourse referents and focus, see Kibble (1995). Somewhat more complex than coreference is indirect anaphora (Hellman and Fraurud 1996) (also called partial anaphora [Luperfoy 1992], textual ellipsis [Hahn, Markert, and Strube 1996], associative anaphora [Cosse 1996] bridging anaphora [Clark 1975; Clark and Marshall 1981; Not, Tovena, and Zancanaro 1999], and inferrables [Prince 1992]), in which the anaphor (usually a definite NP) denotes a discourse referent associated with one (or more) discourse referents in the current discourse context; for example, (25) Myra darted to a phone and picked up the receiver. Here the receiver denotes the receiver associated with (by virtue of being part of) the already-mentioned phone Myra darted to. Coreference and indirect anaphora c"
J03-4002,P02-1047,0,0.0341497,"genuine, or they may be eliminated by a lexical specification. Multicomponent TAG tree sets are used to provide an appropriate compositional treatment for quantifiers, which we borrow for interpreting for example (examples (66c–d)). In showing how DLTAG and an interpretative process on its derivations operate, we must, of necessity, gloss over how inference triggered by adjacency or associated with a structural connective provides the intended relation between adjacent discourse 577 Computational Linguistics Volume 29, Number 4 units: It may be a matter simply of statistical inference, as in Marcu and Echihabi (2002), or of more complex inference, as in Hobbs et al. (1993). As we noted, our view is that there are three mechanisms at work in discourse semantics, just as there are in clause-level semantics: Inference isn’t the only process involved. Thus the focus of our presentation here is on how compositional rules and anaphor resolution (which itself often appears to require inference) operate together with inference to yield discourse semantics. We start with previous examples (44) (here (66c)) and (47) (here (66d)) and two somewhat simpler variants (66a–b): (66) a. You shouldn’t trust John because he"
J03-4002,J88-2003,0,0.226457,"ian accomplishment. In example (37), though, there is no culminated eventuality in the discourse context for then), to take as its first argument. (37) a. Go west on Lancaster Avenue. b. Then turn right on County Line. How does (37b) get its interpretation? As with (36d), the relevant elements of (37b) can be represented as α = then Rα = after S = turn right on County Line σ = e3 :turn-right(you, county line) and the unresolved interpretation of (37b) is thus [λ x . after(x, EV)]e3 ≡ after(e3 , EV) 559 Computational Linguistics Volume 29, Number 4 As for resolving EV, in a well-known article, Moens and Steedman (1988) discuss several ways in which an eventuality of one type (e.g., a process) can be coerced into an eventuality of another type (e.g., an accomplishment, which Moens and Steedman call a culminated process). In this case, the matrix argument of then (the eventuality of turning right on County Line) can be used to coerce the process eventuality in (37b) into a culminated process of going west on Lancaster Avenue until County Line. We treat this coercion as a type of associative or bridging inference, as in the examples discussed in section 3.1. That is, e2 = culmination(e1 )∈assoc(e1 ), where e1"
J03-4002,J92-4007,0,0.165676,"discourse structure and discourse semantics, we will continue to assume for as long as possible that an LF representation will suffice. Now it may appear as if there is no difference between treating adverbials as anaphors and treating them as structural connectives, especially in cases like (37) in which the antecedent comes from the immediately left-adjacent context, and in which the only obvious semantic relation between the adjacent sentences appears to be the one expressed by the discourse adverbial. (Of course, there may also be a separate intentional relation between the two sentences [Moore and Pollack 1992], independent of the relation conveyed by the discourse adverbial.) One must distinguish, however, between whether a theory allows a distinction to be made and whether that distinction needs to be made in a particular case. It is clear that there are many examples in which the two approaches (i.e., a purely structural treatment of all connectives, versus one that treats adverbials as linking into the discourse context anaphorically) appear to make the same prediction. We have already, however, demonstrated cases in which a purely structural account makes the wrong prediction, and in the next"
J03-4002,P95-1018,0,0.052621,"get their interpretations in different ways. Consider the two texts in example (69): 580 Webber et al. Anaphora and Discourse Structure α: so β: but α: because_mid β:then then τ1 T1 T3 τ3 * so but * T2 because α: so τ2 1 3 τ1 0 τ2 β: but τ4 T4 3 α: because_mid 1 3 τ4 τ3 0 β: then but because so T2 T1 T3 then T4 Figure 16 Derivation of example (68). (69) a. You should eliminate part 2 before part 3 because part 2 is more susceptible to damage. b. You should eliminate part 2 before part 3. This is because part 2 is more susceptible to damage. Example (69b) is a simpler version of an example in Moser and Moore (1995), in which This is because is treated as an unanalyzed cue phrase, no different from because in (69a). We show here that this isn’t necessary: One can analyze (69b) using compositional semantics and anaphor resolution and achieve the same results. First consider (69a). Given the interpretations of its two component clauses, its overall interpretation follows in the same way as (66a), shown in Figure 12. Now consider (69b) and the derivation shown in Figure 17. Here the initial tree α:because mid T1 α:because_mid τ1 T2 . 0 because TB β: punct1 β: punct1 T1 3 1 τ2 * because α:because_mid 3 T2 TB"
J03-4002,J96-3006,0,0.0132699,"Missing"
J03-4002,W99-0105,0,0.0441425,"Missing"
J03-4002,C88-2120,0,0.594403,"for resolving them. This is explored in section 3. 3. Any theory of discourse must still provide an account of how a sequence of adjacent discourse units (clauses, sentences, and the larger units that they can comprise) means more than just the sum of its component 547 Computational Linguistics Volume 29, Number 4 units. This is a goal that researchers have been pursuing for some time, using both compositional rules and defeasible inference to determine these additional aspects of meaning (Asher and Lascarides 1999; Gardent 1997; Hobbs et al. 1993; Kehler 2002; Polanyi and van den Berg 1996; Scha and Polanyi 1988; Schilder 1997a, 1997b; van den Berg 1996) If that portion of discourse semantics that can be handled by mechanisms already needed for resolving other forms of anaphora and deixis is factored out, there is less need to stretch and possibly distort compositional rules and defeasible inference to handle everything.2 Moreover, recognizing the possibility of two separate relations (one derived anaphorically and one associated with adjacency and/or a structural connective) admits additional richness to discourse semantics. Both points are discussed further in section 4. 4. Understanding discourse"
J03-4002,P98-2204,0,0.0570362,"(iii) Figure 5 Discourse structures for examples (11)–(13). Structural dependencies are indicated by solid lines and dependencies associate with discourse adverbials are indicated by broken lines. (explanation is the inverse of explanation—i.e., with its arguments in reverse order. Such relations are used to maintain the given linear order of clauses.) 551 Computational Linguistics Volume 29, Number 4 (14) Every mani tells every womanj hei meets that shej reminds himi of hisi mother. (15) Suei drives an Alfa Romeo. Shei drives too fast. Maryj races heri on weekends. Shej often beats heri . (Strube 1998) This suggests that in examples (11)–(13), the relationship between the discourse adverbial and its (initial) argument from the previous discourse might usefully be taken to be anaphoric as well.4 2.2 Discourse Adverbials Do Behave like Anaphors There is additional evidence to suggest that otherwise, then, and other discourse adverbials are anaphors. First, anaphors in the form of definite and demonstrative NPs can take implicit material as their referents. For example, in (16) Stack five blocks on top of one another. Now close your eyes and try knocking {the tower, this tower} over with your"
J03-4002,J88-2006,1,0.660385,"usually used to translate other kinds of discourse anaphors.6 These arguments have been directed at the behavioral similarity between discourse adverbials and what we normally take to be discourse anaphors. But this isn’t the only reason to recognize discourse adverbials as anaphors: In the next section, we suggest a framework for anaphora that is broad enough to include discourse adverbials as well as definite and demonstrative pronouns and NPs, along with other discourse phenomena that have been argued to be anaphoric, such as VP ellipsis (Hardt 1992, 1999; Kehler 2002), tense (Partee 1984; Webber 1988) and modality (Kibble 1995; Frank and Kamp 1997; Stone and Hardt 1999). 3. A Framework for Anaphora Here we show how only a single extension to a general framework for discourse anaphora is needed to cover discourse adverbials. The general framework is presented in Section 3.1, and the extension in Section 3.2. 3.1 Discourse Referents and Anaphor Interpretation The simplest discourse anaphors are coreferential: definite pronouns and definite NPs that denote one (or more) discourse referents in focus within the current discourse 6 Although rhetorical structure theory (RST) (Mann and Thompson 19"
J03-4002,P92-1013,1,0.612638,"Missing"
J03-4002,W98-0315,1,0.480953,"scourse clause (Dc ): a clause or a structure composed of discourse clauses. One reason for taking something to be an initial tree is that its local dependencies can be stretched long distance. At the sentence level, the dependency between apples and likes in Apples John likes is localized in all the trees for likes. This dependency can be stretched long distance, as in Apples, Bill thinks John may like. In discourse, as we noted in section 2, local dependencies can be stretched long distance as well, as in (59) a. Although John is generous, he’s hard to find. 16 Although in an earlier paper (Webber and Joshi 1998), we discuss reasons for taking the lexical anchors of the initial trees in Figures 7 and 8 to be feature structures, following the analysis in Knott (1996) and Knott and Mellish (1996), here we just take them to be specific lexical items. 574 Webber et al. Anaphora and Discourse Structure α:contrast Dc Dc On the one hand Dc On the other Figure 8 An initial tree for parallel constructions. This particular tree is for a contrastive construction anchored by on the one hand and on the other hand. b. Although John is generous—for example, he gives money to anyone who asks him for it—he’s hard to f"
J03-4002,P99-1006,1,0.654145,"Missing"
J03-4002,W93-0239,0,0.295266,"me family of discourse relations. But what if the relational meaning conveyed by cue phrases could in fact interact with discourse meaning in multiple ways? Then Knott’s substitution patterns among cue phrases may have reflected these complex interactions, as well as the meanings of individual cue phrases themselves. This article argues that cue phrases do depend on another mechanism for conveying extrasentential meaning—specifically, anaphora. One early hint that adverbial cue phrases (called here discourse connectives) might be anaphoric can be found in an ACL workshop paper in which Janyce Wiebe (1993) used the following example to question the adequacy of tree structures for discourse: (1) a. The car was finally coming toward him. b. He [Chee] finished his diagnostic tests, c. feeling relief. d. But then the car started to turn right. The problem Wiebe noted was that the discourse connectives but and then appear to link clause (1d) to two different things: then to clause (1b) in a sequence relation (i.e., the car’s starting to turn right being the next relevant event after Chee’s finishing his tests) and but to a grouping of clauses (1a) and (1c) (i.e., reporting a contrast between, on the"
J03-4002,J00-4006,0,\N,Missing
J03-4002,C98-2199,0,\N,Missing
N19-1056,W15-0123,0,0.0702774,"Missing"
N19-1056,C18-1301,1,0.926057,"ds are far more effective than a picture” – Feiner and McKeown (1991). Modeling how visual and linguistic information can jointly contribute to coherent and effective communication is a longstanding open problem with implications across cognitive science. As Feiner and McKeown (1991) already observe, it is particularly important for automating the understanding and generation of text–image presentations. Theoretical models have suggested that images and text fit together into integrated presentations via coherence relations that are analogous to those that connect text spans in discourse; see Alikhani and Stone (2018a) and Section 2. This paper follows up this theoretical perspective through systematic corpus investigation. We are inspired by research on text discourse, which has led to large-scale corpora with information about discourse structure and discourse semantics. The Penn Discourse Treebank (PDTB) is one of the most well-known examples (Miltsakaki et al., 2004; Prasad et al., 2008). However, although multimodal corpora increasingly include 2 Discourse Coherence and Text–Image Presentations We begin with an example to motivate our approach and clarify its relationship to previous work. Figure 1 s"
N19-1056,miltsakaki-etal-2004-penn,0,0.159466,"ng and generation of text–image presentations. Theoretical models have suggested that images and text fit together into integrated presentations via coherence relations that are analogous to those that connect text spans in discourse; see Alikhani and Stone (2018a) and Section 2. This paper follows up this theoretical perspective through systematic corpus investigation. We are inspired by research on text discourse, which has led to large-scale corpora with information about discourse structure and discourse semantics. The Penn Discourse Treebank (PDTB) is one of the most well-known examples (Miltsakaki et al., 2004; Prasad et al., 2008). However, although multimodal corpora increasingly include 2 Discourse Coherence and Text–Image Presentations We begin with an example to motivate our approach and clarify its relationship to previous work. Figure 1 shows two steps in an online recipe for a ravioli casserole from the RecipeQA data set (Yagcioglu et al., 2018). The image of Figure 1a shows a moment towards the end of carrying out the “covering” action of the accompanying text; that of Figure 1b shows one instance of the result of the “spooning” actions of the text. Cognitive scientists have argued that su"
N19-1056,W19-1806,1,0.65032,"f the remaining segments of the text. Such correlations set a direction for designing or learning strategies to select when to include imagery. 5 1 2 3 4 5 contribution of this study is that it presents a discourse annotation scheme for cross-modal data, and establishes that annotations for this scheme can be procured from non-expert contributors via crowd-sourcing. Our paper sets the agenda for a range of future research. One obvious example is to extend the approach to other genres of communication with other coherence relations, such as the distinctive coherence of images and caption text (Alikhani and Stone, 2019). Another is to link coherence relations to the structure of multimodal discourse. For example, our methods have not yet addressed whether image–text relations have the same kinds of subordinating or coordinating roles that comparable relations have in structuring text discourse (Asher and Lascarides, 2003). Ultimately, of course, we hope to leverage such corpora to build and apply better models of multimodal communication. Acknowledgments The research presented here is supported by NSF Award IIS-1526723 and through a fellowship from the Rutgers Discovery Informatics Institute. Thanks to Gabri"
N19-1056,W15-2614,0,0.0242572,"etain only recipes with 70 or fewer words per step, for a final count of 516 documents (2,047 image–text pairs). The interface is designed such that if the answer to Question 8 is T RUE, the subject will be prompted with Question 9 and 10. Otherwise, Question 8 is the last question in the list. Agreement. To assess the inter-rater agreement, we determine Cohen’s κ and Fleiss’s κ values. For Cohen’s κ, we randomly selected 150 image–text pairs and assigned each to two participants, obtaining a Cohen’s κ of 0.844, which indicates almost perfect agreement. For Fleiss’s κ (Fleiss and Cohen, 1973; Cocos et al., 2015; Banerjee et al., 1999), we randomly selected 50 text–image pairs, assigned them to five subjects, and computed the average κ. We obtain a score of 0.736, which indicates substantial agreement (Viera et al., 2005). Protocol. We recruit participants through Amazon Mechanical Turk. All subjects were US citizens, agreed to a consent form approved by Rutgers’s institutional review board, and were compensated at an estimated rate of USD 15 an hour. 4 Experiment Interface. Given an image and the corresponding textual instruction from the dataset, participants were requested to answer the following"
N19-1056,P12-2018,0,0.0568739,"icts action in progress). It shows the features most correlated with the classification decision and their log probability estimates. For Q4, not surprisingly, numbers and units are positive instances. More interestingly, verbs of movement and combination are negative instances, perhaps because such steps normally involve material that has already been measured. For Q8, a range of physical action verbs are associated with actions in progress; negative features correlate with steps involved in actions that don’t require ongoing attention (e.g., baking). Table 4 reports top SVM with NB (NBSVM) (Wang and Manning, 2012) features for Q1 that asks subjects to highlight the part of the text that is most related to the image. Action verbs are part of highlighted text, whereas adverbs and quantitative information that cannot be easily depicted in images are part of the remaining segments of the text. Such correlations set a direction for designing or learning strategies to select when to include imagery. 5 1 2 3 4 5 contribution of this study is that it presents a discourse annotation scheme for cross-modal data, and establishes that annotations for this scheme can be procured from non-expert contributors via cro"
N19-1056,P09-1076,0,0.0415355,"in the step but not mentioned in the text. 6. The image shows how to prepare before carrying out the step. 7. The image shows the results of the action that is described in the text. 8. The image depicts an action in progress that is described in the text. 9. The text describes several different actions but the image only depicts one. 10. One would have to repeat the action shown in the image many times in order to complete this step. Work on text has found that text genre heavily influences both the kinds of discourse relations one finds in a corpus and the way those relations are signalled (Webber, 2009). Since our focus is on developing methodology for consistent annotation, we therefore choose to work within a single genre. We selected instructional text because of its concrete, practical subject matter and because of its step-by-step organization, which makes it possible to automatically group together short segments of related text and imagery. Text–Image Pairs. We base our data collection on an existing instructional dataset, RecipeQA (Yagcioglu et al., 2018). This is the only publicly available large-scale dataset of multimodal instructions. It consists of multimodal recipes—textual ins"
N19-1056,L18-1303,0,0.0253104,"cts to the broader discourse. In particular, inferences analogous to those used to interpret text seem to be necessary with such images to recognize their spatio-temporal perspective (Cumming et al., 2017), the objects they depict (Abusch, 2013), and their place in the arc of narrative progression (McCloud, 1993; Cohn, 2013). In fact, such inferences seem to be a general feature of multimodal communication, applying also in the coherent relationships of utterance to co-speech gesture (Lascarides and Stone, 2009) or the coherent relationships of elements in diagrams (Alikhani and Stone, 2018b; Hiippala and Orekhova, 2018). In empirical analyses of text corpora, researchers in projects such as the Penn Discourse Treebank (Miltsakaki et al., 2004; Prasad et al., 2008) have been successful at documenting such effects by annotating discourse structure and discourse semantics via coherence relations. We would like to apply a similar strategy to text– image documents like that shown in Figure 1. However, existing discourse annotation guidelines depend on the distinctive ways that coherence is signaled in text. In text, we find syntactic devices such as structural parallelism, semantic devices such as negation, and p"
P05-3001,J95-3003,0,0.685343,"Missing"
P07-1043,J95-3003,0,0.0603557,"ation problem of TAG grammars with semantic and pragmatic information into a planning problem stated in the widely used Planning Domain Definition Language (PDDL, McDermott (2000)). The encoding provides a clean separation between computation and linguistic modelling and is open to future extensions. It also allows us to benefit from the past and ongoing advances in the performance of off-the-shelf planners (Blum and Furst, 1997; Kautz and Selman, 1998; Hoffmann and Nebel, 2001). While there have been previous systems that encode generation as planning (Cohen and Perrault, 1979; Appelt, 1985; Heeman and Hirst, 1995), our approach is distinguished from these systems by its focus on the grammatically specified contributions 336 of each individual word (and the TAG tree it anchors) to syntax, semantics, and local pragmatics (Hobbs et al., 1993). For example, words directly achieve content goals by adding a corresponding semantic primitive to the conversational record. We deliberately avoid reasoning about utterances as coordinated rational behavior, as earlier systems did; this allows us to get by with a much simpler logic. The problem we solve encompasses the generation of referring expressions (REs) as a"
P07-1043,P02-1003,1,0.87332,"precondition of v. These causal links are drawn as bold edges in Fig. 3. The mapping is unique for substitution edges because subst atoms are removed by every action that has them as their precondition. There may be multiple action instances in the plan that introduce the same atom canadjoin(A, u). In this case, we can freely choose one of these instances as the parent. 3 Sentence generation as planning Now we extend this encoding to deal with semantics and referring expressions. 3.1 Communicative goals In order to use the planner as a surface realization algorithm for TAG along the lines of Koller and Striegnitz (2002), we attach semantic content to each elementary tree and require that the sentence achieves a certain communicative goal. We also use a knowledge base that specifies the speaker’s knowledge, and require that we can only use trees that express information in this knowledge base. We follow Stone et al. (2003) in formalizing the semantic content of a lexicalized elementary tree t as a finite set of atoms; but unlike in earlier approaches, we use the semantic roles in t as the arguments of these atoms. For instance, the semantic content of the “likes” tree in Fig. 1 is {like(self, ag, pat)} (see a"
P07-1043,W98-1419,1,0.807693,"Missing"
P97-1026,J86-3001,0,0.0713489,"nt assumptions about the status of entities and propositions in the discourse, which we model by including in each tree a specification of the contextual conditions under which use of the tree is pragmatically licensed. We have selected four representative pragmatic distinctions for our implementation; however, the framework does not commit one to the use of particular theories. We use the following distinctions. First, entities differ in NEWNESS(Prince, 1981). At any point, an entity is either new or old to the HEARERand either new or old to the DISCOURSE. Second, entities differ in SALIENCE(Grosz and Sidner, 1986; Grosz et al., 1995). Salience assigns each entity a position in a partial order that indicates 200 how accessible it is for reference in the current context. Third, entities are related by salient PARTIALLYORDERED SET (POSET) RELATIONS to other entities in the context (Hirschberg, 1985). These relations include part and whole, subset and superset, and membership in a common class. Finally, the discourse may distinguish some OPEN PROPOSITIONS(propositions containing free variables) as being under discussion (Prince, 1986). We assume that information of these four kinds is available in a model"
P97-1026,J95-2003,0,0.0495784,"status of entities and propositions in the discourse, which we model by including in each tree a specification of the contextual conditions under which use of the tree is pragmatically licensed. We have selected four representative pragmatic distinctions for our implementation; however, the framework does not commit one to the use of particular theories. We use the following distinctions. First, entities differ in NEWNESS(Prince, 1981). At any point, an entity is either new or old to the HEARERand either new or old to the DISCOURSE. Second, entities differ in SALIENCE(Grosz and Sidner, 1986; Grosz et al., 1995). Salience assigns each entity a position in a partial order that indicates 200 how accessible it is for reference in the current context. Third, entities are related by salient PARTIALLYORDERED SET (POSET) RELATIONS to other entities in the context (Hirschberg, 1985). These relations include part and whole, subset and superset, and membership in a common class. Finally, the discourse may distinguish some OPEN PROPOSITIONS(propositions containing free variables) as being under discussion (Prince, 1986). We assume that information of these four kinds is available in a model of the current disco"
P97-1026,J91-4003,0,0.0136267,"sitive NP : &lt; l &gt; x S : &lt;l&gt;&lt;r,havlng&gt; N : &lt;l&gt;x NPJ. : &lt; 2 &gt; h a v e e DetP N S : &lt;1&gt; : &lt;1&gt; [ , Det book I the book(x) (a) N : syntax N* : &lt;1&gt; NP;. t : hayer VP: &lt;1&gt; V syntax I concerns(x, syntax) (b) /have/ NP t : &lt;2&gt; I during(r, having) ^ have(having, hayer, h a v e e ) (c) Figure 2: LTAG trees with semantic specifications figure 2. Ontological promiscuity makes it possible to explore more complicated analyses in this general framework. For example, in (Stone and Doran, 1996), we use reference to properties, actions and belief contexts (Ballim et al., 1991) to describe semantic collocations (Pustejovsky, 1991) and idiomatic composition (Nunberg et al., 1994). 3.3 Pragmatics Different constructions make different assumptions about the status of entities and propositions in the discourse, which we model by including in each tree a specification of the contextual conditions under which use of the tree is pragmatically licensed. We have selected four representative pragmatic distinctions for our implementation; however, the framework does not commit one to the use of particular theories. We use the following distinctions. First, entities differ in NEWNESS(Prince, 1981). At any point, an entity is eithe"
P97-1026,A92-1006,0,0.125041,"yntactic constraints on descriptions in a sentence, and the inferential interactions between multiple descriptions in a sentence. At the same time, it exploits linguistically motivated, declarative specifications of the discourse functions of syntactic constructions to make contextually appropriate syntactic choices. 1 Introduction Since (Meteer, 1991), researchers in natural language generation have recognized the need to refine and reorganize content after the rhetorical organization of arguments and before the syntactic realization of phrases. This process has been named sentence planning (Rambow and Korelsky, 1992). Broadly speaking, it involves aggregating content into sentence-sized units, and then selecting the lexical and syntactic elements that are used in realizing each sentence. Here, we consider this second process. The challenge lies in integrating constraints from syntax, semantics and pragmatics. Although most generation systems pipeline decisions (Reiter, 1994), we believe the most efficient and flexible way to integrate constraints in sentence planning is to synchronize the decisions. In this paper, we provide a natural framework for dealing with interactions and ensuring contextually appro"
P97-1026,C92-1038,0,0.00746842,"DISCOURSEMODEL,cf. alternative semantics (Karttunen and Peters, 1979; Rooth, 1985). Pragmatic analyses of referring expressions model speakers as PLANNINGthose expressions to achieve several different kinds of intentions (Donellan, 1966; Appelt, 3.1 Syntactic specification 1985; Kronfeld, 1986). Given a set of entities to describe and a set of intentions to achieve in describing them, a plan is constructed by applying operators that enrich the content of the description until all intentions are satisfied. Recent work on generating definite referring NPs (Reiter, 1991 ; Dale and Haddock, 1991; Reiter and Dale, 1992; Horacek, 1995) has emphasized how circumscribed instantiations of this procedure can exploit linguistic context and convention to arrive quickly at short, unambiguous descriptions. For example, (Reiter and Dale, 1992) apply generalizations about the salience of properties of objects and conventions about what words make baselevel attributions to incrementally select words for inclusion in a description. (Dale and Haddock, 1991) use a constraint network to represent the distractors described by a complex referring NP, and incrementally select a property or relation that rules out as many alte"
P97-1026,P85-1008,0,0.0441083,"d. Other frameworks have the capability to make comparable specifications; for example, HPSG (Pollard and Sag, 1994) feature structures describe syntax (SUBCAT), semantics (CONTI3NT) and pragmatics (CONTEXT). We choose TAG because it enables local specification of syntactic dependencies in explicit constructions and flexibility in incorporating modifiers; further, it is a constrained grammar formalism with tractable computational properties. Semantics We specify the semantics of trees by applying two principles to the LTAG formalism. First, we adopt an ONTOLOGICALLY PROMISCUOUSrepresentation (Hobbs, 1985) that includes a wide variety of types of entities. Ontological promiscuity offers a simple syntax-semantics interface. The meaning of a tree is just the CONJUNCTION of the meanings of the elementary trees used to derive it, once appropriate parameters are recovered. Such fiat semantics is enjoying a resurgence in NLP; see (Copestake et al., 1997) for an overview and formalism. Second, we constrain these parameters syntactically, by labeling each syntactic node as supplying information about a particular entity or collection of entities, as in Jackendoff&apos;s X-bar semantics (Jackendoff, 1990). A"
P97-1026,W94-0314,0,0.0151528,"e crucial to SPUD, as they are to (McDonald and Pustejovsky, 1985; Joshi, 1987; Yang et al., 1991; Nicolov et al., 1995; Wahlster et al., 1991; Danlos, 1996). What sets SPUD apart is its simultaneous construction of syntax and semantics, and the tripartite, lexicalized, declarative grammatical specifications for constructions it uses. Two contrasts should be emphasized in this regard. (Shieber et al., 1990; Shieber and Schabes, 1991) construct a simultaneous derivation of syntax and semantics but they do not construct the semantics--it is an input to their system. (Prevost and Steedman, 1993; Hoffman, 1994) represent syntax, semantics and pragmatics in a lexicalized framework, but concentrate on information structure rather than the pragmatics of particular constructions. 6 Conclusion Most generation systems pipeline pragmatic, semantic, lexical and syntactic decisions (Reiter, 1994). With the fight formalism, constructing pragmatics, semantics and syntax simultaneously is easier and better. The approach elegantly captures the interaction between pragmatic and syntactic constraints on descriptions in a sentence, and the inferential interactions between multiple descriptions in a sentence. At the"
P97-1026,P86-1029,0,0.12719,"formula. D REFERS to C jUSt in case it distinguishes c from its DISTRACTORS-that is D applies to c but to no other salient alternatives. Given a sufficiently rich logical language, the meaning of a natural language sentence can be represented as a description in this sense, by assuming sentences refer to entities in a DISCOURSEMODEL,cf. alternative semantics (Karttunen and Peters, 1979; Rooth, 1985). Pragmatic analyses of referring expressions model speakers as PLANNINGthose expressions to achieve several different kinds of intentions (Donellan, 1966; Appelt, 3.1 Syntactic specification 1985; Kronfeld, 1986). Given a set of entities to describe and a set of intentions to achieve in describing them, a plan is constructed by applying operators that enrich the content of the description until all intentions are satisfied. Recent work on generating definite referring NPs (Reiter, 1991 ; Dale and Haddock, 1991; Reiter and Dale, 1992; Horacek, 1995) has emphasized how circumscribed instantiations of this procedure can exploit linguistic context and convention to arrive quickly at short, unambiguous descriptions. For example, (Reiter and Dale, 1992) apply generalizations about the salience of properties"
P97-1026,E83-1027,0,0.139979,"ontextually appropriate syntactic choices. References D. Appelt. 1985. Planning English Sentences. Cambridge University Press. A. Ballim, Y. Wilks, and J. Barnden. 1991. Belief ascription, metaphor, and intensional identification. Cognitive Science, 15:133-171. Comparison with related work The strength of the present work is that it captures a number of phenomena discussed elsewhere separately, and does so within a unified framework. With its incremental choices and its emphasis on the consequences of functional choices in the grammar, our algorithm resembles the networks of systemic grammar (Mathiessen, 1983; Yang et al., 1991). However, unlike systemic networks, our system derives its functional choices dynamically using a simple declarative specification of function. Like many sentence planners, we assume that there is a flexible • association between the content input to a sentence planner and the meaning that comes out. Other researchers (Nicolov et al., 1995; Rubinoff, 1992) have assumed that this flexibility comes from a mismatch between input content and grammatical options. In our system, such differences arise from the referential requirements and inferential opportunities that are encou"
P97-1026,P85-1012,0,0.07195,"e have. However, the new goal would still be unsatisfied; in the next iteration, the PP on reserve would be adjoined into the tree to satisfy it: The syntax book, we have on reserve. Because TAG allows adjunction to apply at any time, flexible realization of content is facilitated without need for sophisticated back-tracking (Elhadad and Robin, 1992). The processing of this example may seem simple, but it illustrates the way in which SPUD integrates syntactic, semantic and pragmatic knowledge in realizing sentences. We tackle additional examples in (Stone and Doran, 1996). 5 Previous authors (McDonald and Pustejovsky, 1985; Joshi, 1987) have noted that TAG has many advantages for generation as a syntactic formalism, because of its localization of argument structure. (Joshi, 1987) states that adjunction is a powerful tool for elaborating descriptions. These aspects of TAGs are crucial to SPUD, as they are to (McDonald and Pustejovsky, 1985; Joshi, 1987; Yang et al., 1991; Nicolov et al., 1995; Wahlster et al., 1991; Danlos, 1996). What sets SPUD apart is its simultaneous construction of syntax and semantics, and the tripartite, lexicalized, declarative grammatical specifications for constructions it uses. Two co"
P97-1026,W94-0316,0,0.0183196,"of a variety of entities until the addressee can infer desired conclusions allows the sentence planner to enrich input content, so that descriptions refer successfully (Dale and Haddock, 1991) or reduce it, to eliminate redundancy (McDonald, 1992). Moreover, selecting alternatives on the basis of their syntactic, semantic, and pragmatic contributions to the sentence using TAG allows the sentence planner to choose words in tandem with appropriate syntax (Yang et al., 1991), in a flexible order (Elhadad and Robin, 1992), and, if necessary, in conventional combinations (Smadja and McKeown, 1991; Wanner, 1994). TAG (Joshi et al., 1975) is a grammar formalism built around two operations that combine pairs of trees, SUBSTITUTIONand ADJOINING. A TAG grammar consists of a finite set of ELEMENTARYtrees, which can be combined by these substitution and adjoining operations to produce derived trees recognized by the grammar. In substitution, the root of the first tree is identified with a leaf of the second tree, called the substitution site. Adjoining is a more complicated splicing operation, where the first tree replaces the subtree of the second tree rooted at a node called the adjunction site; that sub"
P97-1026,E93-1039,0,0.0196477,"ns. These aspects of TAGs are crucial to SPUD, as they are to (McDonald and Pustejovsky, 1985; Joshi, 1987; Yang et al., 1991; Nicolov et al., 1995; Wahlster et al., 1991; Danlos, 1996). What sets SPUD apart is its simultaneous construction of syntax and semantics, and the tripartite, lexicalized, declarative grammatical specifications for constructions it uses. Two contrasts should be emphasized in this regard. (Shieber et al., 1990; Shieber and Schabes, 1991) construct a simultaneous derivation of syntax and semantics but they do not construct the semantics--it is an input to their system. (Prevost and Steedman, 1993; Hoffman, 1994) represent syntax, semantics and pragmatics in a lexicalized framework, but concentrate on information structure rather than the pragmatics of particular constructions. 6 Conclusion Most generation systems pipeline pragmatic, semantic, lexical and syntactic decisions (Reiter, 1994). With the fight formalism, constructing pragmatics, semantics and syntax simultaneously is easier and better. The approach elegantly captures the interaction between pragmatic and syntactic constraints on descriptions in a sentence, and the inferential interactions between multiple descriptions in a"
P97-1026,W96-0410,1,\N,Missing
P97-1026,W94-0319,0,\N,Missing
P99-1006,P97-1012,1,0.841173,"Because y ~5&quot;, they cannot together be realised as &quot;Although ~ because y [3 &&quot; with the same meaning as &quot;Although o¢ [3. Because y 8&quot;. The same is true of certain relations whose realisation spans multiple sentences, such as ones realisable as &quot;On the one hand oz. On the other hand 13.&quot; and &quot;Not only T- But also &&quot; Together, they cannot be realised as &quot;On the one hand o¢. Not only T. On the other hand 13. But also &&quot; with the same meaning as in strict sequence. Thus we take such constructions to be structural as well (Webber and Joshi, 1998; Webber et al., 1999). Framework In previous papers (Cristea and Webber, 1997; Webber and Joshi, 1998; Webber et al., 1999), we have argued for using the more complex structures (elementary trees) of a Lexicalized Tree-Adjoining Grammar (LTAG) and its operations (adjoining and substitution) to associate structure and semantics with a sequence of discourse clauses. 2 Here we briefly review how it works. In a lexicalized TAG, each elementary tree has at least one anchor. In the case of discourse, the anchor for an elementary tree may be a lexical item, punctuation or a feature structure that is lexically null. The semantic contribution of a lexical anchor includes both w"
P99-1006,W98-0304,0,0.0231865,"modifier (e.g. &quot;He&apos;s an otherwise happy boy.&quot;) or a clausal modifier (e.g., &quot;The physical layer is different, but otherwise it&apos;s identical to metropolitan networks.&quot;). What is presupposed here are one or more actual properties of the situation under discussion. If the light had been red, John would have stopped. Otherwise, he would have carded straight on. But as it turned out, he never got to the light. 46 (9) You should take a coat with you because otherwise you&apos;ll get cold. Clearly, more remains to be done. First, the approach demands a precise semantics for connectives, as in the work of Grote (1998), Grote et al. (1997), Jayez and Rossari (1998) and Lagerwerf (1998). Secondly, the approach demands an understanding of the attentional characteristics of presuppositions. In particular, preliminary study seems to suggest that p-bearing elements differ in what source can license them, where this source can be located, and what can act as distractors for this source. In fact, these differences seem to resemble the range of differences in the information status (Prince, 1981; Prince, 1992) or familiarity (Gundel et al., 1993) of referential NPs. Consider, for example: and earlier examples. (Not"
P99-1006,J92-4007,0,0.1424,"ventions, etc., can then make defeasible contributions to discourse interpretation that elaborate the nondefeasible propositions contributed by compositional semantics. Introduction Research on discourse structure has, by and large, attempted to associate all meaningful relations between propositions with structural connections between discourse clauses (syntactic clauses or structures composed of them). Recognising that this could mean multiple structural connections between clauses, Rhetorical Structure Theory (Mann and Thompson, 1988) simply stipulates that only a single relation may hold. Moore and Pollack (1992) argue that both informational (semantic) and intentional relations can hold between clauses simultaneously and independently. This suggests that factoring the two kinds of relations might lead to a pair of structures, each still with no more than a single structural connection between any two clauses. But examples of multiple semantic relations are easy to find (Webber et al., 1999). Having structure account for all of them leads to the complexities shown in Figure 1, including the crossing dependencies shown in Fig. l c. These structures are no longer trees, making it difficult to define a c"
P99-1006,P97-1026,1,0.0647756,"1999), we have argued for using the more complex structures (elementary trees) of a Lexicalized Tree-Adjoining Grammar (LTAG) and its operations (adjoining and substitution) to associate structure and semantics with a sequence of discourse clauses. 2 Here we briefly review how it works. In a lexicalized TAG, each elementary tree has at least one anchor. In the case of discourse, the anchor for an elementary tree may be a lexical item, punctuation or a feature structure that is lexically null. The semantic contribution of a lexical anchor includes both what it presupposes and what it asserts (Stone and Doran, 1997; Stone, 1998; Stone and Webber, 1998). A feature structure anchor will either unify with a lexical item with compatible features (Knott and Mellish, 1996), yielding the previous case, or have an empty realisation, though one On the other hand, the p-bearing adverb &quot;then&quot;, which asserts that one eventuality starts after the culmination of another, has only one of its arguments coming structurally. The other argument is presupposed and thus able to come from across a structural boundary, as in (1) a. b. c. d. 1One may still need to admit structures having both a link back and a link forward to"
P99-1006,W98-1419,1,0.852452,"more complex structures (elementary trees) of a Lexicalized Tree-Adjoining Grammar (LTAG) and its operations (adjoining and substitution) to associate structure and semantics with a sequence of discourse clauses. 2 Here we briefly review how it works. In a lexicalized TAG, each elementary tree has at least one anchor. In the case of discourse, the anchor for an elementary tree may be a lexical item, punctuation or a feature structure that is lexically null. The semantic contribution of a lexical anchor includes both what it presupposes and what it asserts (Stone and Doran, 1997; Stone, 1998; Stone and Webber, 1998). A feature structure anchor will either unify with a lexical item with compatible features (Knott and Mellish, 1996), yielding the previous case, or have an empty realisation, though one On the other hand, the p-bearing adverb &quot;then&quot;, which asserts that one eventuality starts after the culmination of another, has only one of its arguments coming structurally. The other argument is presupposed and thus able to come from across a structural boundary, as in (1) a. b. c. d. 1One may still need to admit structures having both a link back and a link forward to different clauses (Gardent, 1997). But"
P99-1006,W98-0315,1,0.532764,"two relations, one realisable as &quot;Although o¢ [3, the other realisable as &quot;Because y ~5&quot;, they cannot together be realised as &quot;Although ~ because y [3 &&quot; with the same meaning as &quot;Although o¢ [3. Because y 8&quot;. The same is true of certain relations whose realisation spans multiple sentences, such as ones realisable as &quot;On the one hand oz. On the other hand 13.&quot; and &quot;Not only T- But also &&quot; Together, they cannot be realised as &quot;On the one hand o¢. Not only T. On the other hand 13. But also &&quot; with the same meaning as in strict sequence. Thus we take such constructions to be structural as well (Webber and Joshi, 1998; Webber et al., 1999). Framework In previous papers (Cristea and Webber, 1997; Webber and Joshi, 1998; Webber et al., 1999), we have argued for using the more complex structures (elementary trees) of a Lexicalized Tree-Adjoining Grammar (LTAG) and its operations (adjoining and substitution) to associate structure and semantics with a sequence of discourse clauses. 2 Here we briefly review how it works. In a lexicalized TAG, each elementary tree has at least one anchor. In the case of discourse, the anchor for an elementary tree may be a lexical item, punctuation or a feature structure that is"
P99-1006,J88-2006,1,0.218389,"at source. However, as with pronominal and definite NP anaphora, while attentional constraints on their interpretation may be influenced by structure, the links themselves are not structural. * Our thanks to Mark Steedman, Katja Markert, Gann Bierner and three ACL&apos;99 reviewers for all their useful comments. 41 The idea of combining compositional semantics with defeasible inference is not new. Neither is the idea of taking certain lexical items as anaphorically presupposing an eventuality or a set of eventualities: It is implicit in all work on the anaphoric nature of tense (cf. Partee (1984), Webber (1988), inter alia) and modality (Stone, 1999). What is new is the way we enable anaphoric presupposition to contribute to semantic relations and modal operators, in a way R1 Ci Ci (a) CI Ci Ck Ci (b) C i R2 Ck Cm (c) Figure 1: Multiple semantic links ( R j ) between discourse clauses ( C i ) : (a) back to the same discourse clause; (b) back to different discourse clauses; (c) back to different discourse clauses, with crossing dependencies. that maintains its semantic features. that does not lead to the violations of tree structure mentioned earlier.t We discuss these differences in more detail in S"
Q15-1008,W14-1607,0,0.262059,"led these categories as regions of suitable perceptual feature spaces. Researchers have explored explicit spaces of high-level perceptual attributes (Farhadi et al., 2009; Silberer et al., 2013), approximations to such spaces (Matuszek et al., 2012), or low-level feature spaces such as Bag of Visual Words (Bruni et al., 2012) or Histogram of Gradients (Krishnamurthy and Kollar, 2013). We specifically follow G¨ardenfors (2000) and J¨ager (2010) in assuming that color categories are convex regions in an underlying color space, and are not just determined by prototypical color values, such as in Andreas and Klein (2014). However, unlike previous grounded semantics, we do not assume that words name categories unequivocally. Speakers may vary in how they interpret a word, so we treat the link between words and categories probabilistically. The difference makes training our model more indirect than previous approaches to grounded meaning. In particular, our model introduces a new layer of uncertainty that describes what category the speaker uses. Similar kinds of uncertainty can be found in Bayesian models of speaker strategy, such as that of Smith et al. (2013). However, this research has assumed that speakers"
Q15-1008,J92-1002,0,0.0333127,"alculated using Eq. 10 across all N data points in the held-out test set. LLV (M ) is used when computing perplexity and Aikake Information Criterion (AIC). We report all measures in bits. LLV (M ) = log2 PM (K true , K said |X) X = log2 PM (kitrue , kisaid |xi ) (10) i A more general measure of model fit is the log likelihood of the color values and their labels jointly across the training set, LL(V ), given the model. It is defined and calculated analogously. Perplexity Perplexity has been used in past research to measure the performance of statistical language models (Jelinek et al., 1977; Brown et al., 1992). Lower perplexity means that the model is less surprised by the data and so describes it more precisely. We use it here to measure how well a model encodes the regularities in color descriptions. Akaike Information Criterion: AIC is derived from information theory (Akaike, 1974) and balances the model’s fit to the data with the complexity of the model by penalizing a larger number of parameters. The intuition is that a smaller AIC indicates a better balance of parameters and model fit. 5.3 Evaluation Results Table 1 summarizes the decision-based evaluation results.6 We see little penalty for"
Q15-1008,P12-1015,0,0.00882088,"semantic primitives in terms of composable categories that let systems discriminate between cases where a word applies and cases where the word does not apply. (Our evaluation compares models of grounded semantics to more direct models of word–world associations.) Previous research has modeled these categories as regions of suitable perceptual feature spaces. Researchers have explored explicit spaces of high-level perceptual attributes (Farhadi et al., 2009; Silberer et al., 2013), approximations to such spaces (Matuszek et al., 2012), or low-level feature spaces such as Bag of Visual Words (Bruni et al., 2012) or Histogram of Gradients (Krishnamurthy and Kollar, 2013). We specifically follow G¨ardenfors (2000) and J¨ager (2010) in assuming that color categories are convex regions in an underlying color space, and are not just determined by prototypical color values, such as in Andreas and Klein (2014). However, unlike previous grounded semantics, we do not assume that words name categories unequivocally. Speakers may vary in how they interpret a word, so we treat the link between words and categories probabilistically. The difference makes training our model more indirect than previous approaches t"
Q15-1008,P96-1041,0,0.287332,"oviding metrics and results that suggest that LUX escapes these objections and captures almost all of the structure in subjects’ responses. 5.1 Alternative Models To test LUX’s representations, we built a brute-force histogram model (HM) that discretizes HSV space and tracks frequency distributions of labels directly in each discretized bin. Similar histogram models have been developed by Chuang et al. (2008) and (Heer and Stone, 2012) to build interfaces for interacting with color that are informed by human categorization and naming. More precisely, our HM uses a linear interpolation method (Chen and Goodman, 1996) to combine three histograms of various granularity.5 This amounts to predicting responses by querying the training data. HM has the potential to expose whether LUX is missing important features of the distribution of color descriptions. We also built a direct model of subjects’ choices of color terms. Instead of appealing to the applicability and availability of a color label, it works with the observed frequency of a color label and a Gaussian model of the probability of a color value for each label, as in Eq. 9: P (k said , k true |x) ∝ P (x|k true )P (k said , k true ) (9) This Gaussian mo"
Q15-1008,J12-1006,0,0.0291171,"Missing"
Q15-1008,Q13-1016,0,0.0364057,"tan one or a tan dog and a white one. prehensibly describe either of two dogs as the tan one. Systems that robustly understand or generate descriptions of colors in situated dialogue need models of meaning that capture this variability. This paper makes two key contributions towards this challenge. First, we present a methodology to infer a corpus-based model of meaning that accounts for possible differences in word usage across different speakers. As we explain in Section 2, our approach differs from the typical perspective in grounded semantics (Tellex et al., 2011a; Matuszek et al., 2012; Krishnamurthy and Kollar, 2013), where a meaning is reduced to a single classifier that collapses patterns of variation. Instead, our model allows for variability in meaning by positing uncertainty in classification boundaries that can get resolved when a speaker chooses to use a word on a specific occasion. We explain the model and its theoretical rationale in Section 3. Second, we develop and release a Lexicon of Uncertain Color Standards (LUX) by applying our methodology to color descriptions. LUX is an interpretation of 829 distinct English color descriptions as distributions over regions of the Hue–Saturation– Value co"
Q15-1008,P13-1056,0,0.0141511,"and perceptual representations, as Chuang et al. (2008) and Heer and Stone (2012) do for color. Grounded semantics involves interpreting semantic primitives in terms of composable categories that let systems discriminate between cases where a word applies and cases where the word does not apply. (Our evaluation compares models of grounded semantics to more direct models of word–world associations.) Previous research has modeled these categories as regions of suitable perceptual feature spaces. Researchers have explored explicit spaces of high-level perceptual attributes (Farhadi et al., 2009; Silberer et al., 2013), approximations to such spaces (Matuszek et al., 2012), or low-level feature spaces such as Bag of Visual Words (Bruni et al., 2012) or Histogram of Gradients (Krishnamurthy and Kollar, 2013). We specifically follow G¨ardenfors (2000) and J¨ager (2010) in assuming that color categories are convex regions in an underlying color space, and are not just determined by prototypical color values, such as in Andreas and Klein (2014). However, unlike previous grounded semantics, we do not assume that words name categories unequivocally. Speakers may vary in how they interpret a word, so we treat the"
Q15-1008,Q14-1006,0,0.0290194,"son to think that this variability conceals consistent meanings. In formal semantics, one of the hallmarks of vague language is that speakers can make it more precise in alternative, incompatible ways (Barker, 2002). We see this in practice as well, for example with the image of Figure 2, where subjects com103 Transactions of the Association for Computational Linguistics, vol. 3, pp. 103–115, 2015. Action Editor: Lillian Lee. c Submission batch: 11/2014; Published 2/2015. 2015 Association for Computational Linguistics. Figure 2: Image by flickr user Joanne Bacon (jlbacon) from the data set of Young et al. (2014), whose subjects describe these dogs as a brown dog and a tan one or a tan dog and a white one. prehensibly describe either of two dogs as the tan one. Systems that robustly understand or generate descriptions of colors in situated dialogue need models of meaning that capture this variability. This paper makes two key contributions towards this challenge. First, we present a methodology to infer a corpus-based model of meaning that accounts for possible differences in word usage across different speakers. As we explain in Section 2, our approach differs from the typical perspective in grounded"
S12-1013,J06-2002,0,0.0751157,"Missing"
W00-1416,W98-0210,0,\N,Missing
W00-1416,J93-4004,0,\N,Missing
W00-1416,W94-0319,0,\N,Missing
W00-1416,A92-1006,0,\N,Missing
W00-1416,P86-1029,0,\N,Missing
W00-1416,P97-1026,1,\N,Missing
W00-1416,W98-1403,0,\N,Missing
W00-1423,P97-1026,1,0.374833,"rsation. We accomplish this by reasoning from a grammar which describes gesture declaratively in terms of its discourse function, semantics and synchrony with speech. 1 Hao Yan* Introduction In this paper, we describe the generation of communicative actions in an implemented embodied conversational agent. Our generation framework adopts a goal-directed view of generation and casts knowledge about communicative action in the form of a grammar that specifies how forms combine, what interpretive effects they impart and in what contexts they are appropriate (Appelt, 1985; Moore, 1994; Dale, 1992; Stone and Doran, 1997). We expand this framework to take into account findings, by ourselves and others, on the relationship between spontaneous coverbal hand gestures and speech. In particular, our agent plans each utterance so that multiple communicative goals may be realized opportunistically by a composite action including not only speech but also coverbal gesture. By describing gesture declaratively in terms of its discourse function, semantics and synchrony with speech, we ensure that coverbal gesture fits the context and the ongoing speech in ways representative of natural human conversation. The result is a"
W00-1423,P98-2204,0,0.0120835,"ation to represent the communicative context. This detail is needed for REA tO achieve a theoretically-motivated realization of the common patterns of speech and gesture we observed in human conversation. For example, a variety of changing features determine whether marked forms in speech and gesture are appropriate in the context. REA&apos;S dialogue manager tracks the changing status of such features as: e Attentionalprominence, represented (as usual in natural language generation) by setting up a context set for each entity (Dale, 1992). Our model of prominence is a simple local one similar to (Strube, 1998). o Cognitive status, including whether an entity is hearer-old or hearer-new (Prince, 1992), and whether an entity is in-focus or not (Gundel et al., 1993). We can assume that houses and their rooms are hearer-new until REA describes them; and that just those entities mentioned in the prior sentence are in-focus. Information structure, including the open propositions or, following (Steedman, 1991 ), themes, which describe the salient questions currently at issue in the discourse (Prince, 1986). In REA&apos;S dialogue, open questions are always general questions about some entity raised by a recent"
W00-1423,W98-0210,0,\N,Missing
W00-1423,P97-1036,0,\N,Missing
W00-1423,E91-1003,0,\N,Missing
W00-1423,P94-1001,0,\N,Missing
W00-1423,W00-2028,1,\N,Missing
W00-1423,P98-1102,0,\N,Missing
W00-1423,C98-1099,0,\N,Missing
W00-1423,C98-2199,0,\N,Missing
W00-2028,C94-2149,0,0.0453454,"Missing"
W00-2028,P85-1008,0,0.170189,"Missing"
W00-2028,J93-4004,0,0.085703,"Missing"
W00-2028,P97-1026,1,0.928694,"Missing"
W00-2028,W98-1419,1,0.868778,"Missing"
W00-2028,P99-1006,1,0.880658,"Missing"
W00-2028,W98-0143,1,0.876531,"Missing"
W00-2028,W98-0106,0,\N,Missing
W02-0111,J00-4006,0,0.003726,"conveniently implemented in stages, we use basic tree operations to introduce Prolog programming, including data structures, recursion and abstraction much as outlined in (Sterling and Shapiro, 1994); then we write a simple chart parser with incremental interpretation, and a simple communicative-intent generator scaled down after (Stone et al., 2001). The third module explores the distinctive problems of specific applications in NLP, including spoken dialogue systems, information retrieval and text classification, spelling correction and shallow tagging applications, and machine translation. Jurafsky and Martin (2000) is our source-book. Concurrently, students pursue a final project, singly or in crossdisciplinary teams, involving a more substantial and potentially innovative implementation. In its overall structure, the course seems quite successful. The initial emphasis on clarifying intuitions about communication puts students on an even footing, as it highlights important ideas about language use without too much dependence on specialized training in language or computation. By the end of the class, students are able to build on the more specifically computational material to come up with substantial a"
W02-0111,P95-1021,0,0.110183,"o. S T C T + ⇒ NP C T’ H  H  H NP Chris C T’ HH V VP*  ADVP NP VP Sandy NP madly loves Figure 1: Substitution (complementation). Figure 3: Parallel analysis in TAGLET and TAG. C* T T C + C’ ⇒ C C’ T’ T’ Figure 2: Forward sister-adjunction (modification.) structure tree containing a distinguished word called the anchor. For complementation, TAGLET adopts TAG’s substitution operation; substitution replaces a leaf node in the head tree with the phrase structure tree associated with the complement. See Figure 1. For modification, TAGLET adopts the the sister-adjunction operation defined in (Rambow et al., 1995); sister-adjunction just adds the modifier subtree as a child of an existing node in the head tree—either on the left of the head (forward sisteradjunction) as in Figure 2, or on the right of the head (backward sister-adjunction). I describe TAGLET formally in Appendix A. TAGLET is equivalent in weak generative power to context-free grammar. That is, any language defined by a TAGLET also has a CFG, and any language defined by a CFG also has a TAGLET. On the other hand context-free languages can have derivations in which all lexical items are arbitrarily far from the root; TAGLET derived struct"
W02-0111,J95-4002,0,0.0114969,"tation model they already have to construct a generator. 5 Conclusion Important as they are, lexicalized grammars can be forbidding. Versions of TAG and combinatory categorial grammars (CCG) (Steedman, 2000), as presented in the literature, require complex bookkeeping for effective computation. When I wrote a CCG parser as an undergraduate, it took me a whole semester to get an implemented handle on the metatheory that governs the interaction of (crossing) composition or type-raising with spurious ambiguity; I still have never written a TAG parser or a CCG generator. Variants of TAG like TIG (Schabes and Waters, 1995) or D-Tree grammars (Rambow et al., 1995) are motivated by linguistic or formal considerations rather than pedagogical or computational ones. Other formalisms come with linguistic assumptions that are hard to manage. Link grammar (Sleator and Temperley, 1993) and other pure dependency formalisms can make it difficult to explore rich hierarchical syntax and the flexibility of modification; HPSG (Pollard and Sag, 1994) comes with a commitment to its complex, rather bewildering regime for formalizing linguistic information as feature structures. Of course, you probably could refine any of these t"
W02-0111,1993.iwpt-1.22,0,0.0308047,"bookkeeping for effective computation. When I wrote a CCG parser as an undergraduate, it took me a whole semester to get an implemented handle on the metatheory that governs the interaction of (crossing) composition or type-raising with spurious ambiguity; I still have never written a TAG parser or a CCG generator. Variants of TAG like TIG (Schabes and Waters, 1995) or D-Tree grammars (Rambow et al., 1995) are motivated by linguistic or formal considerations rather than pedagogical or computational ones. Other formalisms come with linguistic assumptions that are hard to manage. Link grammar (Sleator and Temperley, 1993) and other pure dependency formalisms can make it difficult to explore rich hierarchical syntax and the flexibility of modification; HPSG (Pollard and Sag, 1994) comes with a commitment to its complex, rather bewildering regime for formalizing linguistic information as feature structures. Of course, you probably could refine any of these theories to a simple core—and would get something very like TAGLET. I strongly believe that this distillation is worth the trouble, because lexicalization ties grammar formalisms so closely to the motivations for studying language in the first place. For lingu"
W02-0111,P97-1026,1,0.722152,"with the nominative assigned by the verb: H  HH NP NP S/NP VP/NP S HH Chris V S/NP  who NP thinks S/NP SG CS N VP  NM SG  /he/ VP/NP /know/ The feature values will be preserved by further steps of derivation. V Sandy NM V HH NP NP H HH   H  likes 4.3 Figure 4: TAGLET requires a gap-threading analysis of extraction (or another context-free analysis). Q H  HH  H NP S/NP H  H HH  who NP VP/NP HH  H Chris V Semantics and pragmatics are crucial to NLP. TAGLET lets students explore meaty issues in semantics and pragmatics, using the unification-based semantics proposed in (Stone and Doran, 1997). We view constituents as referential, or better, indexical; we link elementary trees with constraints on these indices and conjoin the constraints in the meaning of a compound structure. This example shows how the strategy depends on a rich ontology: S:e S/NP thinks Building on TAGLET HH  HH  H  H NP VP/NP NP:c Sandy V Chris VP:e H  HH  HH  V:e NP:s ADVP:e likes The use of syntactic features amounts to an intermediate case. In TAGLET derivations (unlike in TAG) nodes accrete children during the course of a derivation but are never rewritten or split. Thus, we can decorate any TAGLE"
W02-0111,W98-1419,1,0.806976,"features amounts to an intermediate case. In TAGLET derivations (unlike in TAG) nodes accrete children during the course of a derivation but are never rewritten or split. Thus, we can decorate any TAGLET node with a single set of syntactic features that is preserved throughout the derivation. Consider the trees for he knows below: NP NM SG CS X /he/   NP HH HH   NM Y CS N VP V  NM The example also shows how the strategy lets us quickly implement, say, the constraint-satisfaction approaches to reference resolution or the planrecognition approaches to discourse integration described in (Stone and Webber, 1998). 4.4 S  loves Sandy madly chris(c) ∧ sandy(s) ∧ love(e, c, s) ∧ mad(e) Y  /know/ When these trees combine, we can immediately unify the number Y of the verb with the pronoun’s Lectures and Assignments Here is a plan for a six-week TAGLET module. The first two weeks introduce data structures and recursive programming in Prolog, with examples drawn from phrase structure trees and syntactic combination; and discuss dynamic-programming parsers, with an aside on convenient implementation using Prolog assertion. As homework, students implement simple tree operations, and build up to definitions o"
W02-0111,P00-1058,0,\N,Missing
W05-0102,E03-2010,0,0.0936562,"alogue systems is a necessary component of a course on computational linguistics and natural language technology. And yet, it is clearly impracticable to have students in a quarterlong or semester-long course build a dialogue system from scratch. For this reason, instructors of these courses have experimented with various options to allow students to view the code of a working dialogue system, tweak code, or build their own application using a dialogue system toolkit. Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al., 2003) toolkits. However, each of these options has turned 9 Matthew Stone Computer Science and Cognitive Science Rutgers University matthew.stone@rutgers.edu out to have disadvantages. Some of the toolkits require too much knowledge of linguistics for the average computer science student, and vice-versa, others require too much programming for the average linguist. What is needed is an extensible dialogue toolkit that allows easy application building for beginning students, and more sophisticated access to, and tweakability of, the models of discourse for advanced students. In addition, as computat"
W05-0102,W02-0111,1,0.883661,"Missing"
W05-0102,P05-3001,1,0.772561,"platforms that are designed exclusively for teaching: there is no synergy with ongoing research efforts. Rich resources are so crucial to any computational treatment of dialogue: annotated corpora, wide-coverage grammars, planrecognizers, context models, and the rest. We can’t afford to start from scratch. We have found this concretely in our work. What got linguists involved in the computational exploration of dialogue semantics at Rutgers was not the special teaching resources Stone created. It was hooking students up with the systems that were being actively developed in ongoing research (DeVault et al., 2005). These research efforts made it practical to provide students with the visualizations, task and context models, and interactive architecture they needed to explore substantive issues in dialogue semantics. Whatever we do will have to closely connect teaching and our ongoing research. 4 Looking ahead Our experience teaching dialogue to interdisciplinary teams through toolkits has been humbling. We have a new appreciation for the differences between coursework and research infrastructure— supporting teaching may be harder, because students require a broader spectrum of implementation, a faster"
W05-0102,W02-0109,0,0.24907,"etter teaching infrastructure in the future. 1 Introduction Hands-on interaction with dialogue systems is a necessary component of a course on computational linguistics and natural language technology. And yet, it is clearly impracticable to have students in a quarterlong or semester-long course build a dialogue system from scratch. For this reason, instructors of these courses have experimented with various options to allow students to view the code of a working dialogue system, tweak code, or build their own application using a dialogue system toolkit. Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al., 2003) toolkits. However, each of these options has turned 9 Matthew Stone Computer Science and Cognitive Science Rutgers University matthew.stone@rutgers.edu out to have disadvantages. Some of the toolkits require too much knowledge of linguistics for the average computer science student, and vice-versa, others require too much programming for the average linguist. What is needed is an extensible dialogue toolkit that allows easy application building for beginning students, and more sophisticated access to, and t"
W05-0102,P06-4018,0,\N,Missing
W08-1102,W00-1423,1,0.784657,"further exciting developments in our understanding of meaning and interpretation as we enrich the social intelligence of NLG. Modeling efforts will remain crucial to the exploration of these new capabilities. When we build and assemble models of actions and interpretations, we get systems that can plan their own behavior simply by exploiting what they know about communication. These systems give new evidence about the information and problem-solving that’s involved. The challenge is that these models must describe semantics and pragmatics, as well as syntax and behavior. My own slow progress (Cassell et al., 2000; Stone et al., 2003; Koller and Stone, 2007) shows that there’s still lots of hard work needed to develop suitable techniques. I keep going because of the methodological payoffs I see on the horizon. Modeling lets us take social intelligence seriously as a general implementation principle, and thus to aim for systems whose multimodal behavior matches the flexibility and coordination that distinguishes our own embodied meanings. More generally, modeling replaces programming with data fitting, and a good model of Acknowledgments To colleagues and coauthors, especially David DeVault and the orga"
W08-1102,C04-1181,1,0.843302,"meanings in interactive conversation are profoundly informed by their social settings. We are a long way from general models that could allow NLG systems to recognize and exploit these connections in the words and other behaviors they use. In my experience, even the simplest social practices, such as interlocutors’ cooperation on an ongoing practical task, require new models of linguistic meaning and discourse context. For example, systems must be creative to evoke the distinctions that matter for their ongoing task, and use meanings that are not programmed or learned but invented on the fly (DeVault and Stone, 2004). They must count on their interlocutors to recognize the background knowledge they presuppose by general inference from the logic of their behavior as a cooperative contribution to the task (Thomason et al., 2006). Such reasoning becomes particularly important in problematic cases, such as when systems must finetune the form and meaning of a clarification request so that the response is more likely to resolve a pending task ambiguity (DeVault and Stone, 2007). I expect many further exciting developments in our understanding of meaning and interpretation as we enrich the social intelligence of"
W08-1102,P07-1043,1,0.807701,"standing of meaning and interpretation as we enrich the social intelligence of NLG. Modeling efforts will remain crucial to the exploration of these new capabilities. When we build and assemble models of actions and interpretations, we get systems that can plan their own behavior simply by exploiting what they know about communication. These systems give new evidence about the information and problem-solving that’s involved. The challenge is that these models must describe semantics and pragmatics, as well as syntax and behavior. My own slow progress (Cassell et al., 2000; Stone et al., 2003; Koller and Stone, 2007) shows that there’s still lots of hard work needed to develop suitable techniques. I keep going because of the methodological payoffs I see on the horizon. Modeling lets us take social intelligence seriously as a general implementation principle, and thus to aim for systems whose multimodal behavior matches the flexibility and coordination that distinguishes our own embodied meanings. More generally, modeling replaces programming with data fitting, and a good model of Acknowledgments To colleagues and coauthors, especially David DeVault and the organizers of INLG 2008, and to NSF IGERT 0549115"
W13-0214,J86-3001,0,0.769753,"by an earlier mention in a related utterance (Gundel et al., 1993). The simplest approach to discourse organization is to represent the state of the discourse with an information state (Poesio and Traum, 1997) and associate each move with an appropriate update. For example, we can model utterances such as (2) and (3) as making moves that contribute step-by-step to broader problem-solving activity; see Lochbaum (1998) or Blaylock (2005). Normally, the information state specifies once and for all how each thread of ongoing activity places relevant real-world entities at the center of attention (Grosz and Sidner, 1986; Poesio and Traum, 1997). We advocate a different approach, based on discourse coherence (Kehler, 2002; Asher and Lascarides, 2003). The idea is that discourse is fundamentally composed of relational contributions, which establish connections that link each utterance by inference to segments of the preceding conversation. The interpretation of an utterance therefore implicitly refers to the interpretation of some prior discourse and comments on it. On coherence approaches, how an utterance attaches to the discourse determines what entities are prominent in interpreting it (Hobbs, 1979). Coher"
W13-0214,P85-1008,0,0.746513,"ps that connect ideas together. The same is true, we argue, for utterances like (1). Child is not just giving the next step in making an omelette, or giving her audience new information about the principles of cooking. She’s describing what’s happening on the screen, in terms she expects her audience to confirm for themselves by examining what they see. An interpreter who doesn’t recognize this about (1) has failed to understand it. To sketch the key formal ingredients of our account, we use a simple dynamic semantics (Muskens, 1996) and an expressive ontology of situations and eventualities (Hobbs, 1985; Kratzer, 2002). Dynamic semantics represents meanings as sequences of updates [v|ϕ] that introduce discourse referents v and characterize them with conditions ϕ. We add an update hπxci introducing a discourse referent x perceptually grounded in c, and an update hσxsi introducing x as the central entity in grounded situation s (provided s does uniquely distinguish one). Where necessary, ∂K marks update K as presupposed. Situations are parts of the world, capturing particular states of particular objects, perhaps as located in particular spatial regions and changing over particular temporal in"
W13-0214,J98-4001,0,0.115035,"inst adopting it. Note that B’s references with that and there succeed even if B produces the utterance without any accompanying gesture or demonstration, because the referent has been activated by an earlier mention in a related utterance (Gundel et al., 1993). The simplest approach to discourse organization is to represent the state of the discourse with an information state (Poesio and Traum, 1997) and associate each move with an appropriate update. For example, we can model utterances such as (2) and (3) as making moves that contribute step-by-step to broader problem-solving activity; see Lochbaum (1998) or Blaylock (2005). Normally, the information state specifies once and for all how each thread of ongoing activity places relevant real-world entities at the center of attention (Grosz and Sidner, 1986; Poesio and Traum, 1997). We advocate a different approach, based on discourse coherence (Kehler, 2002; Asher and Lascarides, 2003). The idea is that discourse is fundamentally composed of relational contributions, which establish connections that link each utterance by inference to segments of the preceding conversation. The interpretation of an utterance therefore implicitly refers to the int"
W13-0214,P92-1004,0,0.391704,"cases too (Allen and Perrault, 1980). Bolt’s system, for example, responded to definite descriptions, as in (3), the same way as it did to demonstratives: it moved those things. (3) Put the cruise ship north of the Dominican Republic. When it’s problematic to use grounded symbols, we can use discourse referents alongside them. Formally, a discourse referent is just a free variable, but it can be associated with anchoring constraints that describe how it is supposed to be linked up with the world (Zeevat, 1999). In practice, anchoring involves representing interpretation in two separate tiers (Luperfoy, 1992). Meaning is represented via variables, the world is represented via suitably grounded symbols, and an evolving assignment of values to variables embodies the system’s understanding of the real-world reference of expressions in discourse. Reconciling grounded reference and discourse anaphora is the job of discourse semantics. We can see this in the planning dialogue of (4), for example. (4) a. A: Let’s put the cruise ship south of Florida. b. B: That won’t fit there. We need to represent A’s utterance as a proposal—a specific kind of problem-solving move that advocates a particular course of a"
W13-0214,N03-2037,0,0.041031,"ribing e and what’s happening simultaneously on the screen in situation s0 . Like all coherence relations, Summary reflects semantic and pragmatic constraints. Semantically, e must be part of s0 . Following Kratzer (2002), this entails that the information describing e is true in s0 . Pragmatically, Summary(s0 , e) holds only if the information describing e provides a good answer about “what’s happening” in s0 . A summary appeals to broad, basic categories to provide essential information. We have in mind something like the “vital nuggets of information” needed to answer definition questions (Voorhees, 2003). For “That’s an omelette” we offer (8), which defines the central entity in situation s0 as an omelette: (8) [e|Summary(s0 , e)]; hσos0 i; [|omelette(e, o)] The update hσos0 i formalizes how the discourse relation makes entities prominent for reference, as we observed in (5). Such updates can capture the interpretation of demonstratives when there’s no explicit pointing or demonstration in the utterance. Not all situated utterances offer a Summary of an unfolding situation. For example, utterances can offer Assessments that invite the audience not to define what’s happening but to appraise it"
W13-0214,W11-2001,0,\N,Missing
W13-4005,P08-2050,0,0.0328873,"Missing"
W13-4005,J96-1002,0,0.0152181,"dels of language in context. Our method partitions the training instances based on how the user chose to solve the NLG problem. If the NLG output string matches what the user actually said here, it becomes a positive training example. If it differs from what the user actually said, it becomes a negative one. 4.2 Machine Learning We can now build a machine learning model of this data set. Given an unlabeled candidate solution to an NLG problem, we want to build a model of the probability that the solution is representative of human behavior in our transcripts. We train a maximum entropy model (Berger et al., 1996) to make the prediction, using the MALLET software package (McCallum, 2002). Given that the generator ultimately wants to choose the best utterance, we could explore approaches to learn rankings directly, such as RankBoost (Freund et al., 2003). Formally, the machine learning model characterizes an input–output pair for NLG with a set of features that would be available to a generator in assessing a candidate output. Each training example pairs an inventory of features with an observed value indicating whether the instance does or does not match the utterance produced by the human user. Given"
W13-4005,E09-1022,1,0.200561,"rdering words more naturally (Langkilde and Knight, 1998) and identifying named entities in line with attested mentions (Siddharthan and Copestake, 2004). However, previous work on training dialogue generation has involved the acquisition or annotation of relevant data ad hoc, for example by collecting human– human dialogue, running Wizard of Oz experiments, or rating system outputs. Our work is different: we use a bootstrapping approach that automatically mines interactions with a running prototype to adapt NLG to match users. As described in Section 2, our work builds on the COREF system of DeVault and Stone (2009). COREF and its users chat together to identify simple objects in a visual scene. COREF is designed with reversible models of language and dialogue—it tracks users’ utterances and its own utterances with the same data structures and represents them as updating the conversational state in parallel ways. Because of this symmetry, COREF’s understanding of each user utterance determines an input–output pair that the system could take as a target for NLG. We explain the significance of learning from such data in Section 3. However, we argue in Sections 4 and 5 that this learning will yield signific"
W13-4005,W08-1111,0,0.013805,"operative relationships and elicit meaningful behavior from one another before they can learn to act effectively together (Zinkevich et al., 2011). Our work helps to establish the connections of these ideas to dialogue. Finally, we note that our work is orthogonal to a range of other research that aims to extend and improve NLG in dialogue through learning. Given specified target utterances, knowledge acquisition techniques can be used to induce new resources that describe those utterances for NLG as well as to optimize the use of those resources to match the corpus (Higashinaka et al., 2006; DeVault et al., 2008). Moreover, given a model of the differential effects of utterances on the conversation, reinforcement learning can be used to identify utterances with the best outcomes (Lemon, 2011; Janarthanam et al., 2011). We see no reason not to combine these techniques with imitation learning in the development of future systems. 4 Data Analysis Each user utterance in COREF’s interaction logs is associated with a particular state of the dialogue and with the utterance plan ultimately identified as its best interpretation. Our method extracts the task moves in the utterance plan as candidate communicativ"
W13-4005,W11-2815,0,0.263386,"in an interpretation model in a similar way. Bootstrapping NLG for dialogue requires new insights, and require us to synthesize of a number of trends in dialogue, in NLG and in social learning. A number of researchers have trained generators for dialogue based on human specifications of desired output. For example, Walker et al. (2002) and Stent et al. (2004) optimize sentence plans based on expert ratings of candidate output utterances. Jordan and Walker (2005) learn rules for predicting the content of referring expressions to match patterns found in corpora of human descriptions in context. Garoufi and Koller (2011) tune the referential strategies of a general-purpose sentence planner based on metrics of utterance effectiveness mined from human–human interactions. Our work involves a new domain and for the first time involves integrated training of all these dimensions of NLG, but we draw closely on the architectures, features and learning techniques developed by these researchers. The key difference that they use data collected, and to some degree hand-annotated, specifically to train NLG. At the same time, a range of research has explored the way existing data sets can imCOREF’s handcrafted NLG search"
W13-4005,P06-1034,0,0.0293613,"quire agents to develop cooperative relationships and elicit meaningful behavior from one another before they can learn to act effectively together (Zinkevich et al., 2011). Our work helps to establish the connections of these ideas to dialogue. Finally, we note that our work is orthogonal to a range of other research that aims to extend and improve NLG in dialogue through learning. Given specified target utterances, knowledge acquisition techniques can be used to induce new resources that describe those utterances for NLG as well as to optimize the use of those resources to match the corpus (Higashinaka et al., 2006; DeVault et al., 2008). Moreover, given a model of the differential effects of utterances on the conversation, reinforcement learning can be used to identify utterances with the best outcomes (Lemon, 2011; Janarthanam et al., 2011). We see no reason not to combine these techniques with imitation learning in the development of future systems. 4 Data Analysis Each user utterance in COREF’s interaction logs is associated with a particular state of the dialogue and with the utterance plan ultimately identified as its best interpretation. Our method extracts the task moves in the utterance plan as"
W13-4005,P98-1116,0,0.0269808,"d NLG search heuristics draw on ideas from Stone et al. (2003) and Dale and Reiter (1995) to prioritize efficient, specific utterances which use preferred descriptive attributes and respect built-in preferences for certain words and constructions. When we implemented these heuristics, we had no intention of revising the model using learning. However, COREF’s strategy never generates human-like overspecification, its lexical and syntactic choices are determined by hand-coded logical constraints, and it offers few tools to discriminate among comparable para33 4.1 prove NLG results. For example, Langkilde and Knight (1998) n-gram statistics to bias a nondeterministic realization system towards frequent utterances. Siddharthan and Copestake (2004) use references in corpora to bootstrap a generator for named entities in text. Such methods, however, have generally focused on offline text generation applications. Our research shows that specific infrastructure must be in place to tune NLG to a dialogue system’s own experience. In addition, our work finds echoes in work across AI on learning by imitation. Interactive robots can learn in new ways by modeling their behavior on competent humans (Breazeal et al., 2005)."
W13-4005,P04-1052,0,0.0190798,"ic utterances which use preferred descriptive attributes and respect built-in preferences for certain words and constructions. When we implemented these heuristics, we had no intention of revising the model using learning. However, COREF’s strategy never generates human-like overspecification, its lexical and syntactic choices are determined by hand-coded logical constraints, and it offers few tools to discriminate among comparable para33 4.1 prove NLG results. For example, Langkilde and Knight (1998) n-gram statistics to bias a nondeterministic realization system towards frequent utterances. Siddharthan and Copestake (2004) use references in corpora to bootstrap a generator for named entities in text. Such methods, however, have generally focused on offline text generation applications. Our research shows that specific infrastructure must be in place to tune NLG to a dialogue system’s own experience. In addition, our work finds echoes in work across AI on learning by imitation. Interactive robots can learn in new ways by modeling their behavior on competent humans (Breazeal et al., 2005). Other domains require agents to develop cooperative relationships and elicit meaningful behavior from one another before they"
W13-4005,P04-1011,0,0.0334969,"3 Related Work Our key contribution is demonstrating that a dialogue system can bootstrap an integrated NLG strategy from interactions with a prototype system by training a model to imitate user utterances. This complements DeVault and Stone (2009), who train an interpretation model in a similar way. Bootstrapping NLG for dialogue requires new insights, and require us to synthesize of a number of trends in dialogue, in NLG and in social learning. A number of researchers have trained generators for dialogue based on human specifications of desired output. For example, Walker et al. (2002) and Stent et al. (2004) optimize sentence plans based on expert ratings of candidate output utterances. Jordan and Walker (2005) learn rules for predicting the content of referring expressions to match patterns found in corpora of human descriptions in context. Garoufi and Koller (2011) tune the referential strategies of a general-purpose sentence planner based on metrics of utterance effectiveness mined from human–human interactions. Our work involves a new domain and for the first time involves integrated training of all these dimensions of NLG, but we draw closely on the architectures, features and learning techn"
W13-4005,C98-1112,0,\N,Missing
W13-4005,W11-2017,0,\N,Missing
W19-1806,P98-1013,0,0.549155,"ldren playing) using a single verb and the related image as the inputs of the system. Our work is different because we are investigating how people write captions for images and not a single verb. We investigate the relationship between tense, aspect and discourse structure in image–text corpora. This will naturally raise the question of whether we can distinguish between what information is in an image caption and how that relates to existing verb classes. We draw on existing verb classifications to capture lexical and grammatical aspects for our empirical study. (Vendler, 1957; Levin, 1993; Baker et al., 1998; Schuler, 2005; Dowty, 1986; Comrie, 1976; Krifka, 1998). 3 COCO, Flickr and VIST are crowdsourced corpora, while CC and the Recipe dataset collect usergenerated text. These corpora are designed to focus on the captioning relations exhibited in Figure 1. VIST asks for descriptive texts to link five images into a short narrative; CC pairs web images with relevant text from associated ALTTEXT HTML attributes. These corpora may exhibit a broader range of inferential connections between image in text, such as the cases of playby-play narrative in Figure 1. Finally, the Recipe dataset collects nat"
W19-1806,D15-1021,0,0.0791434,"ystematically lack the full range of action descriptions that general solutions must handle. We conclude by arguing that future researchers should focus on naturally-occurring examples, where text and images connect in diverse ways, and should explicitly model the coherence relationships between text and images. 2 Related Work Vision–language corpora have inspired a range of approaches for image retrieval and language generation, and increasing awareness of the biases of corpora and models is bringing increased attention to the linguistic characteristics of the corpora (Bernardi et al., 2017; Ferraro et al., 2015). For example, van Miltenburg et al. (2018a) present a taxThus, where vision–language applications in59 K Top 10 Top 30 Top 100 Top 300 COCO 0.599 0.724 0.864 0.948 Flickr 0.594 0.723 0.840 0.934 VIST 0.538 0.669 0.822 0.920 CC 0.390 0.535 0.834 0.930 Recipe 0.392 0.511 0.715 0.862 ANC 0.443 0.563 0.709 0.840 Table 1: Fraction of verbal part-of-speech tokens accounted for by top K verb lemmas, by corpus. Frequent verbs disproportionately dominate in captions. • Google’s Conceptual Captions (CC) (Sharma et al., 2018); and • the Recipe dataset (Yagcioglu et al., 2018). onomy of the ways that sub"
W19-1806,W18-6550,0,0.0384598,"Missing"
W19-1806,W18-3910,0,0.0342588,"Missing"
W19-1806,D15-1162,0,0.0113151,"f illustration relations (and a range of other strategies for achieving coherence across modalities which offer possibilities for future research). To assess what’s distinctive about these corpora, we compare them to two points of reference: the American National Corpus (ANC) which is a balanced corpus of spoken and written English (Leech et al., 2014) and Facebook’s children’s stories (FS) (Hill et al., 2015), a corpus of written narrative. To measure different verb forms, we used partof-speech tags, parses, and dependency labels, computed using the SpaCy natural language processing toolkit (Honnibal and Johnson, 2015), to find verbs and their associated auxiliaries. We then applied rules to classify the verb groups into past or non-past forms (including present, modal, and non-finite forms), and separately into simple (e.g., ran), progressive (e.g., was running) or perfect aspect (e.g., has run). Perfect progressive forms (has been running) are classed with perfect, since they share the focus on a result state not an ongoing activity. We keep a separate count for copular (copula) forms of the verb be—those that relate a subject to a predicate expressed as a noun phrase, Method We study five prominent image"
W19-1806,P18-1238,0,0.0368729,"Missing"
W19-1806,Q14-1006,0,0.0910233,"s), and separately into simple (e.g., ran), progressive (e.g., was running) or perfect aspect (e.g., has run). Perfect progressive forms (has been running) are classed with perfect, since they share the focus on a result state not an ongoing activity. We keep a separate count for copular (copula) forms of the verb be—those that relate a subject to a predicate expressed as a noun phrase, Method We study five prominent image–text corpora that vary in how constrained the relationship is between image and text: • Microsoft Common Objects in Context (COCO) (Lin et al., 2014); • Flickr30K (Flickr) (Young et al., 2014); • Visual Storytelling (VIST) (Huang et al., 2016); 60 adjective phrase or prepositional phrase. 4 2017). We can see that the outputs of these models also exhibit a preponderance of descriptions with FCVs and be/have. The Simplicity of Caption Corpora We begin with the overall finding that motivates our research: Verb use in image–caption corpora is markedly rarer and less diverse than in ANC. Verbs are less frequent overall in image–caption corpora. In ANC, 0.184 of the tokens have verb POS tags; that drops to 0.065 in CC, 0.026 in COCO, 0.017 in VIST and 0.012 in Flickr. (The difference see"
W96-0410,J86-3001,0,0.0856299,"del et al., 1993; Ward, 1985; Ward and Prince, 1991; Prince, 1993; Birner, 1992). The status of entities and propositions in discourse varies along at least four dimensions that are relevant to these specifications. First, entities differ in NEWNESS (Prince, 1981). At any point, an entity is either new or old to the HEARER, according to whether or not the hearer has at least implicit knowledge of the existence of the entity. Analogously, an entity is either new or old to the DISCOURSE, according to whether the discourse contains an earlier reference to it. Second, entities differ in SALIENCE (Grosz and Sidner, 1986; Grosz et al., 1995). At any point, salience assigns each entity a position in a partial order that indicates how accessible it is for reference in the current context. Third, entities are related by material PARTIALLY-ORDEREDSET (POSET) RELATIONS to other entities in the context (Hirschberg, 1985). These relations include part and whole, subset and superset, and membership in a common class; a number of constructions depend on poset relations to signal their connection with context. Finally, the discourse may distinguish some OPEN PROPOSITIONS,propositions containing free variables, as being"
W96-0410,J95-2003,0,0.0351326,"1985; Ward and Prince, 1991; Prince, 1993; Birner, 1992). The status of entities and propositions in discourse varies along at least four dimensions that are relevant to these specifications. First, entities differ in NEWNESS (Prince, 1981). At any point, an entity is either new or old to the HEARER, according to whether or not the hearer has at least implicit knowledge of the existence of the entity. Analogously, an entity is either new or old to the DISCOURSE, according to whether the discourse contains an earlier reference to it. Second, entities differ in SALIENCE (Grosz and Sidner, 1986; Grosz et al., 1995). At any point, salience assigns each entity a position in a partial order that indicates how accessible it is for reference in the current context. Third, entities are related by material PARTIALLY-ORDEREDSET (POSET) RELATIONS to other entities in the context (Hirschberg, 1985). These relations include part and whole, subset and superset, and membership in a common class; a number of constructions depend on poset relations to signal their connection with context. Finally, the discourse may distinguish some OPEN PROPOSITIONS,propositions containing free variables, as being under discussion (Ha"
W96-0410,P85-1008,0,0.584092,"rgument structures are localized within a single elementary tree, even in long-distance relationships. Figure l(c) shows the topicalized tree anchored by have; both of its arguments are substitution sites. Our grammar incorporates two additional principles. First, the grammar is LEXICALIZED (Schabes, 1990): each elementary structure in the grammar contains at least one lexical item. Second, our trees include FEATURES, following (Vijay-Shanker, 1987). We specify the semantics of trees by adapting two principles of computational semantics to the LTAG formalism. First, as originally advocated by Hobbs (1985), we adopt an ONTOLOGICALLY PROMISCUOUSrepresentation that includes a wide variety of types of entities. In particular, abstract entities are introduced to represent the SCOPES of OPERATORS. A predicate is interpreted as if inside a scope when the predicate takes the corresponding abstract entity as an argument. For this paper, we need EVENTUALITIES as abstract representations of spatiotemporal scope and INFORMATION STATES to abstract the scope of modal operators like possibility and belief. Nodes are labeled as supplying information about a particular entity or SPUD This section provides a br"
W96-0410,W94-0317,0,0.0156307,"cussed elsewhere separately, and does so within the unified framework of description. In particular, we treat many types of content as contributing to expressions that refer to semantic objects. The tenses of sentences in discourse refer to times in much the same way pronouns and full NPs refer to individuals (Partee, 1973; Partee, 1984). The modality of sentences may refer to a salient possibility (Roberts, 1986) or provide the content of a salient psychological state (Wiebe, 1994). The rhetorical connection between a sentence and surrounding discourse should also be described with adjuncts (Huang, 1994). Adjuncts giving details about an event should be included only after reasoning that these adjuncts are in fact necessary in context (McDonald, 1992). With its incremental choices and its emphasis on the consequences of functional choices in the grammar, our algorithm resembles the networks of systemic grammar (Mathiessen, 1983; Yang et al., 1991). However, unlike systemic networks, our system derives its functional choices dynamically using a simple declarative specification of function that correlates well with recent linguistic work. Further, like many sentence planners, we assume that the"
W96-0410,P86-1029,0,0.383082,"entity as an argument. For this paper, we need EVENTUALITIES as abstract representations of spatiotemporal scope and INFORMATION STATES to abstract the scope of modal operators like possibility and belief. Nodes are labeled as supplying information about a particular entity or SPUD This section provides a brief overview of the representations and algorithms that Sentence Planning Using Description (SPUD) uses to address the properties of collocations discussed above. SPUD extends the general procedure for building referring expressions that is suggested by the planning paradigm (Appelt, 1985; Kronfeld, 1986). The procedure starts from a set of entities to describe and a set of intentions to achieve in describing them. It then applies operators that enrich the content of the description until all intentions are satisfied. As in realizations like (Dale and Haddock, 1991), we constrain the inference required to generate and evaluate alternatives by limiting the kinds of intentions considered. However, whereas the planning procedures on which we base our system are used only for noun phrases, we apply this procedure to the sentence as a whole using a rich semantic representation; further, although th"
W96-0410,E83-1027,0,0.59259,"Partee, 1984). The modality of sentences may refer to a salient possibility (Roberts, 1986) or provide the content of a salient psychological state (Wiebe, 1994). The rhetorical connection between a sentence and surrounding discourse should also be described with adjuncts (Huang, 1994). Adjuncts giving details about an event should be included only after reasoning that these adjuncts are in fact necessary in context (McDonald, 1992). With its incremental choices and its emphasis on the consequences of functional choices in the grammar, our algorithm resembles the networks of systemic grammar (Mathiessen, 1983; Yang et al., 1991). However, unlike systemic networks, our system derives its functional choices dynamically using a simple declarative specification of function that correlates well with recent linguistic work. Further, like many sentence planners, we assume that there is a flexible association between the content input to a sentence planner and the meaning that comes out. Other researchers (Nicolov et al., 1995; Rubinoff, 1992) have assumed that this flexibility comes from a mismatch between input content and grammatical options. In our system, such differences arise from the referential r"
W96-0410,E89-1001,0,0.0215235,"reflect the expertise of the addressee; however, we shall sidestep this issue here by assuming that certain lexical items are simply listed as basiclevel terms. By itself, these additions are not enough: SPUD must also take salience and basic-level semantics into account in the evaluation of its alternatives. That is: other things being equal, SPUD should choose to incorporate at each stage the C o n v e n t i o n a l c o m b i n a t i o n in SPUD Because LTAG can associate multiple iexical items to a single tree, it is straightforward to list frozen idioms, like call number, in the lexicon (Abeille and Schabes, 1989). These specifications can include idiosyncratic semantic and pragmatic information; grammatical processes like tense marking apply normally. In this section, we describe how SPUD can be made to use words in other conventional combinations. Our proposal involves three steps. First, as in (Reiter and Dale, 1992), we stipulate that some attributes of entities are more important than others, and that some words more naturally describe those attributes. Second, in keeping with ontological promiscuity (Hobbs, 1985), we represent the importance of attributes by the salience of events and states in t"
W96-0410,J87-3006,0,0.100502,"Missing"
W96-0410,E93-1039,0,0.141618,"Pustejovsky, 1985; Joshi, 1987) have noted that TAG has many advantages for generation as a syntactic formalism, because of its localization of argument structure. These aspects of TAGs are crucial for us. Lexicalization allows us to easily specify local semantic and pragmatic constraints imposed by the lexical item in a particular syntactic frame. Various efforts at using TAG for generation (McDonald and Pustejovsky, 1985; Joshi, 1987; Yang et al., 1991; Nicolov et al., 1995; Wahlster et al., 1991) enjoy many of these advantages. Furthermore, (Shieber et al., 1990; Shieber and Schabes, 1991; Prevost and Steedman, 1993; Hoffman, 1994) exploit similar benefits of lexicalization and localization. What sets SPUD apart is its simultaneous construction of syntax and semantics, and the tripartite, lexicalized, declarative gram95 matical specifications for constructions it uses. (Shieber et al., 1990; Shieber and Schabes, 1991 ) construct a simult .~eous derivation of syntax and semantics--but they do not construct the semantics: it is an input to their system. Moreover, they do not represent any pragmatic inforrnatiGn. (Prevost and Steedman, 1993; Hoffman, 1994) do represent the division of sentences into theme a"
W96-0410,J91-4003,0,0.183449,"attempt to indoctrinate a superannuated canine with innovative maneuvers. To naturally reuse familiar meanings, generation systems should exploit opportunities to do so as mea-ing is constructed, not just in transducing meaning to a surface representation. Following this line, the research presented here concerns generating idioms and collocations as part of SENTENCE PLANNING(Kittredge et al., 1991). Our approach uses Lexicalized Tree Adjoining Grammar (LTAG) and takes DESCRIPTION as the paradigm for the final realization of content. We build on the existing insights of linguists (including (Pustejovsky, 1991; Mel'Euk and Polgu~re, 1987; Nunberg et al., 1994)) and implementations (including (Reiter and Dale, 1992; Viegas and Bouillon, 1994; Smadja and McKeown, 1991)). However, our proposal introduces two key features. First, the syntax AND SEMANTICS of collocations is planned incrementally and simultaneously. This simplifies the design of the procedure and the linguistic representations it requires; it grounds the decision to select a particular collocation; and it helps integrate the different decisions that must be made in sentence planning. Second, we treat collocations and idioms not just as l"
W96-0410,C92-1038,0,0.353888,"meanings, generation systems should exploit opportunities to do so as mea-ing is constructed, not just in transducing meaning to a surface representation. Following this line, the research presented here concerns generating idioms and collocations as part of SENTENCE PLANNING(Kittredge et al., 1991). Our approach uses Lexicalized Tree Adjoining Grammar (LTAG) and takes DESCRIPTION as the paradigm for the final realization of content. We build on the existing insights of linguists (including (Pustejovsky, 1991; Mel'Euk and Polgu~re, 1987; Nunberg et al., 1994)) and implementations (including (Reiter and Dale, 1992; Viegas and Bouillon, 1994; Smadja and McKeown, 1991)). However, our proposal introduces two key features. First, the syntax AND SEMANTICS of collocations is planned incrementally and simultaneously. This simplifies the design of the procedure and the linguistic representations it requires; it grounds the decision to select a particular collocation; and it helps integrate the different decisions that must be made in sentence planning. Second, we treat collocations and idioms not just as lexicographic entries, but with full semantics and pragmatics. This allows us to generate specialized uses"
W96-0410,W94-0311,0,0.0902663,"ystems should exploit opportunities to do so as mea-ing is constructed, not just in transducing meaning to a surface representation. Following this line, the research presented here concerns generating idioms and collocations as part of SENTENCE PLANNING(Kittredge et al., 1991). Our approach uses Lexicalized Tree Adjoining Grammar (LTAG) and takes DESCRIPTION as the paradigm for the final realization of content. We build on the existing insights of linguists (including (Pustejovsky, 1991; Mel'Euk and Polgu~re, 1987; Nunberg et al., 1994)) and implementations (including (Reiter and Dale, 1992; Viegas and Bouillon, 1994; Smadja and McKeown, 1991)). However, our proposal introduces two key features. First, the syntax AND SEMANTICS of collocations is planned incrementally and simultaneously. This simplifies the design of the procedure and the linguistic representations it requires; it grounds the decision to select a particular collocation; and it helps integrate the different decisions that must be made in sentence planning. Second, we treat collocations and idioms not just as lexicographic entries, but with full semantics and pragmatics. This allows us to generate specialized uses of words not just in certai"
W96-0410,W94-0316,0,0.182808,"earchers in generation rarely address all of these kinds of conventionality. For example, (Viegas and Bouillon, 1994) handle semantic collocations by implementing Pustejovsky's Generative Lexicon Theory (GLT); modifiers take on specialized meanings derived from salient processes and characteristics associated with the heads they modify. Thus, a long book means a long book to read because of a lexicographic association between books and reading. Similarly, implementations of MTY describe the conventional use of certain modifiers with heads (Mel'~uk and Polgu~re, 1987; Iordanskaja et al., 1991; Wanner, 1994) using Lexical Functions. Thus, a function Magn determines the realization of a concept very, intense, intensely: (3) A Magn escape ~ a narrow escape; to Magn bleed ~ to bleed profusely. Copy area would be handled using the Lexical Function SIoc, which returns the name of the location associated with an activity. (Smadja and 92 ent text. In particular, transduction presupposes that the content of referring expressions has already been established. This means that collocations in definite descriptions either will arise only by accident (or by generate-and-test search) or by a secondary specific"
W96-0410,J94-2004,0,0.0227707,"and then the algorithm repeats. 3.3 Discussion The strength of the present work is that it captures a number of phenomena discussed elsewhere separately, and does so within the unified framework of description. In particular, we treat many types of content as contributing to expressions that refer to semantic objects. The tenses of sentences in discourse refer to times in much the same way pronouns and full NPs refer to individuals (Partee, 1973; Partee, 1984). The modality of sentences may refer to a salient possibility (Roberts, 1986) or provide the content of a salient psychological state (Wiebe, 1994). The rhetorical connection between a sentence and surrounding discourse should also be described with adjuncts (Huang, 1994). Adjuncts giving details about an event should be included only after reasoning that these adjuncts are in fact necessary in context (McDonald, 1992). With its incremental choices and its emphasis on the consequences of functional choices in the grammar, our algorithm resembles the networks of systemic grammar (Mathiessen, 1983; Yang et al., 1991). However, unlike systemic networks, our system derives its functional choices dynamically using a simple declarative specifi"
W96-0410,W94-0314,0,\N,Missing
W96-0410,P85-1012,0,\N,Missing
W98-1419,P85-1008,0,0.511827,"s consideration of syntax and semantics. Reasoningmust enable the generator to assess quickly and reliably at any stage how the hearer will interpret the current sentence, with its -(inc0mplete)syntax,andsemantics. We show that these representational and reasoning requirements are met in the SPUDsystem for sentence planning and realization. 1 Introduction T h e problem we address is that o f producing efficient descriptions of objects, collections, acti0ns, events, etc. (i.e., any generalized individual from a rich ontology for Natural Language such as those described in [2] •and advocated in [9]). We are interested in a particular kind of efficiency that we call textual economy, which presupposes a view of sentence generation as goal-directed activity that has broad support in Natural Language Generation (NLG) research [1, 5, 15, 17]. According to this view, a system has certain communicative intentions that it aims to fulfill in producing a description. For example, the system might have the goal of identifying an individual or action o~ to the hearer, or ensuring that the hearer knows that has property P. Such goals can be satisfied explicitly by assembling appropriate syntactic co"
W98-1419,J88-2003,0,0.0657808,"ucleus(PREP, REMOVING, RESULT) A in(PREP, start(TIME), REMOVED, SOURCE) A (5b) S e m a n t i c s : caused-motion(REMOVING, REMOVER, REMOVED) A away(RESULT, end(TIME), REMOVED, SOURCE) The tree given in (5a) specifies that remove syntactically satisfies a requirement tO include an s, requires a further NP to be included (describing what is removed), and allows the possibility of an explicit vv modifier that describes what the latter has been removed from. 2 The semantics in (5b) consists of a set of features, formulated in an ontologically promiscuous semantics, as advocated in [9]. It follows [14] in viewing events as consisting of a preparatory phase, a transition, and a result state (what is called a nucleus in [14]). The semantics in (5b) describes all parts of a remove event: In the preparatory phase, the object (REMOVED) is in/on SOURCE. It undergoes motion caused by the agent (REMOVER),and ends up away from SOURCE in the result state. Semantic features are used by SPUD in one of two ways. Some make a semantic contribution that specifies n e w information---these add to what new information the speaker can convey with the structure. Others simply impose a semantic requirement that"
W98-1419,J92-4007,0,0.103748,"s of a sentence by incorporating lexico-grammatical entries into a partial sentence one-by-one and incrementally assessing the answers to the questions given above. In this paper, we describe the intermediate representations that allow SPUD to do so, since these representations have been glossed over in earlier presentations [26, 27]. Reasoning in SPUD is performed using a fast modal theorem prover [24, 25] to keep track both of what the sentence entails and what the sentence requires in context. By reasoning about the predicated relationships withinclauses and the informational relationships [16] between clauses, sPUD is able to generate sentences that exhibit two forms of textual economy: referential interdependency among noun phrases within a single clause, and pragmatic overloading of clauses in instructions [7]. For an informal example of the textual economy to be gained by taking advantage of predicated relationships within clauses, consider the scene pictured in Figure 1 and the goal of getting the hearer to take the rabbit currently in the hat out of the hat it&apos;s currently in. Even though there are several rabbits, several hats, and even a rabbit in a bathtub and a flower in a"
W98-1419,J93-4004,0,0.158801,"Missing"
W98-1419,A92-1006,0,0.0291366,"me way: (3a) Hold the cup under the faucet... (3b) ...to wash it. Examples like (1) and• (2) suggest that the natural locality for sentence planning is in a description of a generalized individual. Even though such descriptions may play out over several clauses (or even sentences), the predications within clauses and the informational relations across clauses of a description give rise to similar textual economies, that merit a similar treatment. 2 SPUD• An NLG system must satisfy at least three constraints in mapping the content planned for a sentence onto the string of words that realize it [4, 13, 20]. Any fact to be communicated must be fit into an abstract grammatical structure, including lexical items. Any reference to a domain entity must be elaborated into a description that distinguishes the entity from its distractors--the salient alternatives to it in context. Finally, a surface form must be found for this conceptual material. In one architecture for NLG Systems that is becoming something of a standard [22], these tasks are performed in Separate stages. For example, to refer to a uniquely identifiable entity x from the common ground, first a set of concepts is identified that toget"
W98-1419,W96-0410,1,0.942178,"ses where a single intention to act is used to wholly or partially satisfy several of an agent&apos;s goals simultaneously. i 78 I I il I I il I I I I fl I il Figure 1: &quot;Remove the rabbit from the hat.&quot; • what (generalized) individuals would the hearer take the sentence to refer to? • what would the sentence invite the hearer to conclude about those individuals? • how can this sentence be modified or extended? can the generator recognize and exploit an opportunity for textual economy. These representational and reasoning requirements are met in the SPUD system for sentence planning and realization [26, 27]. SPUD draws on earlier work by Appelt [1] in building sentences using planning techniques, sPUD plans the syntax and semantics of a sentence by incorporating lexico-grammatical entries into a partial sentence one-by-one and incrementally assessing the answers to the questions given above. In this paper, we describe the intermediate representations that allow SPUD to do so, since these representations have been glossed over in earlier presentations [26, 27]. Reasoning in SPUD is performed using a fast modal theorem prover [24, 25] to keep track both of what the sentence entails and what the se"
W98-1419,P97-1026,1,0.939159,"ses where a single intention to act is used to wholly or partially satisfy several of an agent&apos;s goals simultaneously. i 78 I I il I I il I I I I fl I il Figure 1: &quot;Remove the rabbit from the hat.&quot; • what (generalized) individuals would the hearer take the sentence to refer to? • what would the sentence invite the hearer to conclude about those individuals? • how can this sentence be modified or extended? can the generator recognize and exploit an opportunity for textual economy. These representational and reasoning requirements are met in the SPUD system for sentence planning and realization [26, 27]. SPUD draws on earlier work by Appelt [1] in building sentences using planning techniques, sPUD plans the syntax and semantics of a sentence by incorporating lexico-grammatical entries into a partial sentence one-by-one and incrementally assessing the answers to the questions given above. In this paper, we describe the intermediate representations that allow SPUD to do so, since these representations have been glossed over in earlier presentations [26, 27]. Reasoning in SPUD is performed using a fast modal theorem prover [24, 25] to keep track both of what the sentence entails and what the se"
