1995.iwpt-1.8,P89-1018,0,0.0134528,"eebanked corpus of transcribed British radio pro grammes punctuated by the corpus compilers. Both corpora were retagged with determinate punctuation and PoS labelling using _the Acquilex HMM tagger (Elworthy, 1993, 1994) trained on text tagged with a slightly modified version of CLAWS-II labels (Garside et al. , 1987) . 5.1 Coverage and Average Ambiguity To examine the efficiency and coverage of the grammar we applied it to our retagged versions of Susanne and SEC. We used the ANLT chart parser (Carroll, 1 993) , but modified just to count th_e number of possible parses in the parse forests (Billot & Lang, 1989) rather than actually · unpacking them. We also imposed a per-sentence time-out of 30 seconds CPU time, running in Franz· Allegro Common Lisp 4.2 on an HP PA-RISC 715/100 workstation with 96 Mbytes of physical memory. Ve define the &apos;coverage&apos; of the grammar to be the inverse of the proportion of sentences for which no analysis was found-a weak measure since discovery of one or more global analyses does not entail that the correct analysis i� recovered. For both corpora, the majority of sentences analysed successfully received under 100 parses, although there is a long tail in the distribution"
1995.iwpt-1.8,P94-1040,1,0.838779,"that improved coverage of heterogeneous text can be achieved by exploiting textual and grammatical con straints on PoS and punctuation sequences. The experiments show that grammatical coverage can be greatly increased by relaxing subcategorisation constraints, and that text grammatical or punctuation-cued constraints can reduce ambiguity and increase coverage during parsing. To our knowledge these are the first experiments which objectively demonstrate the utility of punctuation for resolving syntactic ambiguity and improving parser coverage. They extend work by Jones ( 1994) and Briscoe and Carroll (1994) by applying a wide-coverage text grammar to substantial quantities of naturally-punctuated text and by quantifying the contribution of punctuation to ambiguity resolution in a well-defined probabilistic parse selection model. Accurate enough parse selection for practical applications will require a more lexic.alised system. Magerman&apos;s ( 1995) parser is an extension of the history-based parsing approach devel oped at IBM (e.g. Black, 1993) in which rules are conditioned on lexical and other (essentially arbitrary) information available in the parse history. In future work, we intend to explor"
1995.iwpt-1.8,A88-1019,0,0.0430331,"on subcategorisation and uses punctuation to reduce ambiguity. The analyses produced by this parser could be utilised for phrase-finding applications, recovery of subcategorisation frames, and other &apos;intermediate&apos; level parsing problems. 2 Part-of-speech Tag Sequence Grammar Several robust parsing systems exploit the comparative success of part-of-speech (PoS) taggers, such as Fidditch (Hindle, 1989) or MITFP (de · Marcken, 1990) , by reducing the input to a determinate sequence of extended PoS labels of the type which can be practically disambiguated in context using a (H)MM PoS tagger (e.g. Church, 1988) . Such approaches, by definition, cannot exploit subcategorisation, and probably achieve some of their robustness as a result. However, such parsers typically also employ heuristic rules, such as &apos;low&apos; attachment of PPs to produce unique &apos;canonical&apos; analyses. This latter step complicates the recovery of predicate argument structure and does not integrate with a probabilistic approach to parsing. We utilised the ANLT metagrammatical formalism to develop a feature-based, declara tive description of PoS label sequences for English. This grammar compiles into a DCG-like grammar of approximately"
1995.iwpt-1.8,C94-1042,0,0.046863,"Missing"
1995.iwpt-1.8,P90-1031,0,0.0200749,"Missing"
1995.iwpt-1.8,E93-1040,0,0.0546539,"Missing"
1995.iwpt-1.8,A94-1009,0,\N,Missing
1995.iwpt-1.8,P89-1015,0,\N,Missing
1995.iwpt-1.8,J93-1002,1,\N,Missing
1995.iwpt-1.8,P95-1037,0,\N,Missing
1997.iwpt-1.6,J93-1002,1,0.880549,"Missing"
1997.iwpt-1.6,1995.iwpt-1.8,1,0.897603,"Missing"
1997.iwpt-1.6,H90-1021,0,0.0197493,"Missing"
1997.iwpt-1.6,J94-1004,0,0.288846,"Missing"
2004.tmi-1.2,P92-1005,0,0.0634629,"nent communication is in terms of sets of MRSs and, thus, can easily be managed in a distributed and (potentially) parallel client – server set-up. Both the analysis and generation grammars ‘publish’ their interface to transfer—i.e. the inventory and synopsis of semantic predicates— in the form of a Semantic Interface specification (‘SEM-I’), such that transfer can operate without knowledge about grammar internals. In practical terms SEM-Is are an important 1 In this respect, MRS is closely related to a tradition of underspecified semantics reflected in, among others, Quasi-Logical Form (QLF; Alshawi & Crouch, 1992), Underspecified Discourse Representation Theory (UDRT; Reyle, 1993), Hole Semantics (Bos, 1995), and the Constraint Language for Lambda Structures (CLLS; Egg, Koller, & Niehren, 2001). development tool (facilitating wellformedness testing of interface representations at all levels), but they also have interesting theoretical status with regard to transfer. The SEM-Is for the Norwegian analysis and English generation grammars, respectively, provide an exhaustive enumeration of legitimate semantic predicates (i.e. the transfer vocabulary) and ‘terms of use’, i.e. for each predicate its set of a"
2004.tmi-1.2,C96-1023,0,0.0187876,"o multiple phases and optionally apply output filters upon the completion of each phase. The LOGON transfer grammar, for example, includes two sets of language-specific MTRs to accommodate grammar-specific idiosyncrasies before and after the core transfer phase, in some cases simply suppressing superfluous information (e.g. predicates introduced by selected-for prepositions and some aspectual markers), in others re-arranging or augmenting semantics to facilitate English generation. Transfer outputs incorporating plural mass nouns, for example, require the insertion of a suitable ‘classifier’ (Bond, Ogura, & Ikehara, 1996), in order to generate, say, two pieces of information instead of the ungrammatical ∗ two informations. temp loc at p temp in p temp temp abstr on p temp afternoon n day n ··· year n Figure 4: Excerpt from predicate hierarchies provided by English SEM-I. Temporal, directional, and other usages of prepositions give rise to distinct, but potentially related, semantic predicates. Likewise, the SEM-I incorporates some ontological information, e.g. a classification of temporal entities, though crucially only to the extent that is actually grammaticized in the language proper. create a non-determin"
2004.tmi-1.2,1995.tmi-1.2,1,0.818746,"Missing"
2004.tmi-1.2,P00-1061,0,0.0112111,"Missing"
2020.lrec-1.638,W11-0207,0,0.0739829,"Missing"
2020.lrec-1.638,J96-1002,0,0.0765188,"timation accuracy with gold r-NEs and with automatically recognized r-NEs. The function f (u, v, l) returns a feature vector for an edge, containing information about the nodes u and v that the edge links. The vector comprises the following features: • words in u and v, and their concatenation; • concatenation of the r-NE tags of u and v; • whether u is in the same, a previous or a subsequent sentence as v; Total In initial experiments, we confirmed that each of these five features improves edge detection accuracy. The weight vector Θ is estimated from the training data by a log-linear model (Berger et al., 1996). Given training data consisting of T manually annotated edge-label pairs (ut , vt , lt ), we maximize the following value: T ∑ 1 s(ut , vt , lt ) − ∥Θ∥2 2 t=1 (2) To evaluate the accuracy of flow graph construction, we used 10-fold cross-validation, splitting the data into 270 recipes for training and 30 recipes for test. When we started from the gold standard r-NE tagging, the overall F1 for edge detection was 71.1. When we started instead from the automatic r-NE tagging, the edge detection F1 reduced to 43.3; the main reason for the large decrease is that an edge will always be wrong if the"
2020.lrec-1.638,P06-4020,1,0.623597,"Missing"
2020.lrec-1.638,J17-4005,0,0.0211918,"Missing"
2020.lrec-1.638,N19-1423,0,0.0135175,"Missing"
2020.lrec-1.638,P14-1134,0,0.0253062,"automatic r-NE tagging accuracy. Section 4 describes the flow graph representation, annotation, the parsing algorithm for computing a flow graph, and an evaluation of its accuracy. Section 5 discusses the main findings and proposes directions for future research. 1 The annotated corpus of English recipes is available at https://sites.google.com/view/yy-lab/ resource/english-recipe-flowgraph 5187 2. Related Work There has been much research into representing the semantics of natural language sentences (Banarescu et al., 2013, inter alia) and developing parsers that output such representations (Flanigan et al., 2014, for example). Semantic representations encode the meanings of linguistic units within a sentence, but do not attempt to capture domainspecific constraints or real-world context. In some domains and applications these latter factors may be very important. (For example, in cooking, a mixture can sometimes be beaten and sometimes not, depending on which ingredients have been added to it). For this reason, approaches to processing text describing procedures often do not attempt to construct general semantic representations, but instead construct more specialised domain- and genre-specific repres"
2020.lrec-1.638,D15-1114,0,0.161737,"the socalled ‘smart kitchen’ (Hashimoto et al., 2008), cooking robots (Bollini et al., 2013), etc. In one recent study, Mori et al. (2014) produced flow graph annotations for 266 cooking recipes written in Japanese. That corpus has been used for testing empirical methods for natural language understanding (Maeta et al., 2015) and intelligent search (Yamakata et al., 2013), Similarly, Jermsurawong and Habash (2014) described a corpus of ingredient trees for recipes, and evaluated methods for constructing these automatically. There have been some attempts at unsupervised processing of recipes (Kiddon et al., 2015, inter alia) but the outputs are much less rich than those obtained by supervised methods. This paper concerns a flow graph corpus for recipes in English; the flow graphs are based on the proposals of Mori et al. (2014) in which the graph nodes are ‘recipe named entities’ (r-NEs). The r-NE types cover domain entities such as ingredients; in addition, Mori et al. argue that r-NE types should also cover actions by the cook / chef (which are often expressed as verbs). Unlike the set of NE types commonly used for general text (Sang and Meulder, 2003)—person name, location, organization, etc.—r-NE"
2020.lrec-1.638,W15-2206,1,0.900918,"r graph representation for analysing recipes. More recent studies have created annotated corpora of procedural text, in order to build machine learningbased systems that extract entity and action information. In the domain of cooking recipes, such information has been shown to be useful for the socalled ‘smart kitchen’ (Hashimoto et al., 2008), cooking robots (Bollini et al., 2013), etc. In one recent study, Mori et al. (2014) produced flow graph annotations for 266 cooking recipes written in Japanese. That corpus has been used for testing empirical methods for natural language understanding (Maeta et al., 2015) and intelligent search (Yamakata et al., 2013), Similarly, Jermsurawong and Habash (2014) described a corpus of ingredient trees for recipes, and evaluated methods for constructing these automatically. There have been some attempts at unsupervised processing of recipes (Kiddon et al., 2015, inter alia) but the outputs are much less rich than those obtained by supervised methods. This paper concerns a flow graph corpus for recipes in English; the flow graphs are based on the proposals of Mori et al. (2014) in which the graph nodes are ‘recipe named entities’ (r-NEs). The r-NE types cover domai"
2020.lrec-1.638,C80-1016,0,0.675358,"representations encode the meanings of linguistic units within a sentence, but do not attempt to capture domainspecific constraints or real-world context. In some domains and applications these latter factors may be very important. (For example, in cooking, a mixture can sometimes be beaten and sometimes not, depending on which ingredients have been added to it). For this reason, approaches to processing text describing procedures often do not attempt to construct general semantic representations, but instead construct more specialised domain- and genre-specific representations. For example, Momouchi (1980) proposed representing the meaning of procedural text as a flow graph, and described algorithms to convert text documents to flow graphs. Hamada et al. (2000) adopted a similar graph representation for analysing recipes. More recent studies have created annotated corpora of procedural text, in order to build machine learningbased systems that extract entity and action information. In the domain of cooking recipes, such information has been shown to be useful for the socalled ‘smart kitchen’ (Hashimoto et al., 2008), cooking robots (Bollini et al., 2013), etc. In one recent study, Mori et al. ("
2020.lrec-1.638,mori-etal-2014-flow,1,0.87404,"Missing"
2020.lrec-1.638,W09-1119,0,0.060558,"T Tool D Duration Q Quantity Ac Action by chef Discontinuous Ac2 Ac (English only) Af Action by food Action by tool At (English only) Sf Food state St Tool state Explanation Eatable; also intermediate products Knife, container, etc. Duration of cooking Quantity of food Verb representing a chef’s action Second, non-contiguous part of a single action by chef Verb representing action of a food Verb representing a tool’s action Food’s initial or intermediate state Tool’s initial or intermediate state Table 1: Recipe named entity (r-NE) tags. investigated (Borthwick, 1999; Sang and Meulder, 2003; Ratinov and Roth, 2009), and many general-purpose NER tools have been developed. In this study, we use one such tool, PWNER (Sasada et al., 2015a), which computes probabilities for all possible NE tags based on pointwise prediction, and searches for the best sequence of tags under the tag sequence constraints. The tool is distinctive in being trainable on data that has been only partially annotated. 3. Recipe Named Entities 3.1. Recipe Named Entity Tags In previous work (Yamakata et al., 2017), we created a corpus of 100 recipes written in English, sampled from the Allrecipes UK/Ireland web site2 and annotated for ‘"
2020.lrec-1.638,W03-0419,0,0.243161,"me attempts at unsupervised processing of recipes (Kiddon et al., 2015, inter alia) but the outputs are much less rich than those obtained by supervised methods. This paper concerns a flow graph corpus for recipes in English; the flow graphs are based on the proposals of Mori et al. (2014) in which the graph nodes are ‘recipe named entities’ (r-NEs). The r-NE types cover domain entities such as ingredients; in addition, Mori et al. argue that r-NE types should also cover actions by the cook / chef (which are often expressed as verbs). Unlike the set of NE types commonly used for general text (Sang and Meulder, 2003)—person name, location, organization, etc.—r-NEs are an example of a domain-specific NE definition. Domain-specific NE definitions are widely used in fields such as bioinformatics (Ben Abacha and Zweigenbaum, 2011). A domainspecific NE definition facilitates the development of intelligent applications that process documents in that particular domain. The task of identifying NEs is called ‘named entity recognition’ (NER). NER is usually formulated as a sequence labeling problem, in which each input token is tagged as being inside or outside an NE (and in some approaches, beginning an NE). In th"
2020.lrec-1.638,E99-1023,0,0.0571792,"ssions (Constant et al., 2017). The other is to cover expressions for the actions by automatic cooking tools (e.g. food processors), which are not yet common in Japan, so the tag was not necessary for recipes in Japanese. Table 1 lists the ten r-NE tags that we use for English recipe annotation. Note that this tag set is compatible with the original. Figure 1 shows the annotation that would be given to the recipe step Preheat oven to 180 C / Gas mark 4. The tag suffixes -B and -I (abbreviating Begin and Inside respectively) indicate NE spans according to the IOB2 text chunking representation (Sang and Veenstra, 1999). A tag is assigned to each word or word-sequence designating a single and indivisible object/action/phenomenon in the cooking domain. For example, Gas mark 6 in the example sentence designates the state of the dial of the oven being at 6, so it is annotated as a single r-NE. Therefore, the first word Gas is annotated as St-B and the subsequent words mark and 6 are both annotated as St-I. The word to is annotated O because it is Outside any named entity. 2 5188 http://allrecipes.co.uk/ Preheat oven to 180 Ac-B C / Gas mark 4 Dataset 100-r 200-r Overall . T-B O St-B St-I O St-B St-I St-I O Figu"
A00-2022,P99-1061,1,0.72281,"t be equal, but could stand in a subtype-supertype relationship. In addition, the feature structure subsumption test is potentially expensive since feature structures are large, typically containing hundreds of nodes. It is therefore an open question whether parsing systems using grammars of this type can gain any advantage from local ambiguity packing. The question is becoming increasingly important, though, as wide-coverage HPSG grammars are starting to be deployed in practical applications-for example for &apos;deep&apos; analysis in the VerbMobil speech-to-speech translation system (Wahlster, 1997; Kiefer, Krieger, Carroll, & Malouf, 1999). 1 In this paper we answer the question by demonstrating that (a) subsumption- and equivalence-based feature structure packing is applicable to large HPSG grammars, and (b) average complexity and time taken for the parsing task can be greatly reduced. In Section 2 we present a new, linear-time, bidirec1A significant body of work on efficient processing with such grammars has been building up recently, with investigations into efficient feature structure operations, abstractmachine-based compilation, CF backbone computation, and finite-state approximation of HPSGderivations, amongst others (F"
A00-2022,2000.iwpt-1.16,0,0.0412401,"Missing"
A00-2022,P99-1075,0,0.013827,"ro- and retroactive local ambiguity packing with large feature structures, and have provided strong empirical evidence that our approach can be applied beneficially to chart parsing with a large, broad-coverage HPSG of English. By comparison to previous work in unification-based parsing we have demonstrated that pro- and retroactive packing are well-suited to achieve optimal packing; furthermore, experimental results obtained with a publicly-available HPSG processing platform confirm that ambiguity packing can greatly reduce average parse complexity for this type of grammars. In related work, Miyao (1999) describes an approach to packing in which alternative feature structures are represented as packed, distributed disjunctions of feature structure fragments. Although the approach may have potential, the shifting of complex accounting into the unification algorithm is at variance with the findings of Kiefer et al. (1999), who report large speed-ups from the elimination of disjunction processing during unification. Unfortunately, the reported evaluation measures and lack of discussion of parser control issues are insufficient to allow a precise comparison. We intend to develop the approach pres"
A00-2022,2000.iwpt-1.19,1,0.831282,"o only one previously derived edge being invalidated. This, of course, is a function of the order in which edges are derived, i.e. the parsing strategy. All the results in Table 2 were obtained with a &apos;right corner&apos; strategy which aims to exhaust computation for any suffix of the input string before moving the input pointer to the left; this is achieved by means of a scoring function end - -start W - (where start and end are the vertices of the derivation that would result from the computation, and n is the total input length) that orders parser tasks in the agenda. However, we have observed (Oepen & Callmeier, 2000) that HPSG-type, highly lexicalized grammars benefit greatly from a bidirectional, &apos;key&apos;-driven, active parsing regime, since they often employ rules with underspecified arguments that are only instantiated by coreference with other daughters (where the &apos;key&apos; daughter is the linguistic head in many but not all constructions). This requirement and the general non-predictability of categories derived for any token substring (in particular with respect to unary rule applications), means that a particular parsing strategy may reduce retroactive packing but cannot avoid it in general. With pro- and"
A00-2022,P85-1018,0,0.227187,"s reflect the exponential increase in total numbers of analyses; the figures show that our packing scheme achieves a very significant speedup, even when unpacking time is included in the comparison. 5 Choosing the Grammar Restrictor and Parsing Strategy In order for the subsumption relation to apply meaningfully to HPSG signs, two conditions must be met. Firstly, parse tree construction must not be duplicated in the feature structures (by means of the HPSG DTRS feature) but be left to the parser (i.e. recorded in the chart); this is achieved in a standard way by feature structure restriction (Shieber, 1985) applied to all passive edges. Secondly, the processing of constraints that do not restrict the search space but build up new (often semantic) structure should be postponed, since they are likely to interfere with subsumption. For example, analyses that differ only with respect to PP attachment would have the same syntax, but differences in semantics may prevent them being packed. This problem can be overcome by using restriction to (temporarily) remove such (semantic) attributes from lexical entries and also from the rule set, before they are input to the parser in the initial parse forest co"
A00-2022,P91-1041,0,0.077682,"we use in a bottom-up, chart-based parsing algorithm incorporating novel, efficient accounting mechanisms to guarantee minimal chart size (Section 3). We present a full-scale evaluation of the techniques on a large corpus (Section 4), and complete the picture with an empirically-based discussion of grammar restrictors and parsing strategies (Section 5). 2 Efficient Subsumption and Equivalence Algorithms Our feature structure subsumption algorithm 2 assumes totally well-typed structures (Carpenter, 1992) and employs similar machinery to the quasi-destructive unification algorithm described by Tomabechi (1991). In particular, it uses temporary pointers in dag nodes, each pointer tagged with a generation counter, to keep track of intermediate results in processing; incrementing the generation counter invalidates all temporary pointers in a single operation. But whereas quasi-destructive unification makes two passes (determining whether the unification will be successful and then copying out the intermediate representation) the subsumption algorithm makes only one pass, checking reentrancies and type-supertype relationships at the same time. 3 The algorithm, shown in Figure 1, also simultaneously tes"
A00-2022,A92-1012,0,\N,Missing
A00-2022,1991.iwpt-1.19,0,\N,Missing
A00-2022,P89-1018,0,\N,Missing
A97-1052,P87-1027,1,0.698428,"ons Programme project LE1-211i 'SPARKLE: Shallow PARsing and Knowledge extraction for Language Engineering', and by SERC/EPSRC Advanced Fellowships to both authors. We would like to thank the COMLEX Syntax development team for allowing us access to pre-release data (for an early experiment), and for useful feedback. 356 Several substantial machine-readable subcategorization dictionaries exist for English, either built largely automatically from machine-readable versions of conventional learners' dictionaries, or manually by (computational) linguists (e.g. the Alvey NL Tools (ANLT) dictionary, Boguraev et al. (1987); the COMLEX Syntax dictionary, Grishman et al. (1994)). Unfortunately, neither approach can yield a genuinely accurate or comprehensive computational lexicon, because both rest ultimately on the manual efforts of lexicographers / linguists and are, therefore, prone to errors of omission and commission which are hard or impossible to detect automatically (e.g. Boguraev & Briscoe, 1989; see also section 3.1 below for an example). Furthermore, manual encoding is labour intensive and, therefore, it is costly to extend it to neologisms, information not currently encoded (such as relative frequency"
A97-1052,P91-1027,0,0.37465,"ized' probabilistic grammars to improve the accuracy of parse ranking, no wide-coverage parser has yet been constructed incorporating probabilities of different subcategorizations for individual predicates, because of the problems of accurately estimating them. These problems suggest that automatic construction or updating of subcategorization dictionaries from textual corpora is a more promising avenue to pursue. Preliminary experiments acquiring a few from sentence subanalyses which begin/end at the boundaries of (specified) predicates. verbal subcategorization classes have been reported by Brent (1991, 1993), Manning (1993), and Ushioda et al. (1993). In these experiments the maximum number of distinct subcategorization classes recognized is sixteen, and only Ushioda et al. attempt to derive relative subcategorization frequency for individual predicates. We describe a new system capable of distinguishing 160 verbal subcategorization classes--a superset of those found in the ANLT and COMLEX Syntax dictionaries. The classes also incorporate information about control of predicative arguments and alternations such as particle movement and extraposition. We report an initial experiment which de"
A97-1052,J93-2002,0,0.87711,"parses and records the number of observations of each subcategorization class. Patterns provide several types of information which can be used to rank or select between patterns in the patternset for a given sentence exemplifying an instance of a predicate, such as the ranking of the parse from which it was extracted or the proportion of subanalyses supporting a specific pattern. Currently, we simply select the pattern supported by the highest ranked parse. However, we are experimenting with alternative approaches. The resulting set of putative classes for a predicate are filtered, following Brent (1993), 358 by hypothesis testing on binomial frequency data. Evaluating putative entries on binomial frequency data requires that we record the total number of patternsets n for a given predicate, and the number of these patternsets containing a pattern supporting an entry for given class m. These figures are straightforwardly computed from the output of the classifier; however, we also require an estimate of the probability that a pattern for class i will occur with a verb which is not a member of subcategorization class i. Brent proposes estimating these probabilities experimentally on the basis"
A97-1052,1995.iwpt-1.8,1,0.645459,"Missing"
A97-1052,P94-1040,1,0.810599,"lace word-tag pairs with lemma-tag pairs, where a lemma is the morphological base or dictionary headword form appropriate for the word, given the PoS assignment made by the tagger. We use an enhanced version of the G A T E project stemmer (Cunningham et al., 1995). 3. A p r o b a b i l i s t i c L R p a r s e r , trained on a treebank, returns ranked analyses (Briscoe &: Carroll, 1993; Carroll, 1993, 1994), using a grammar written in a feature-based unification grammar formalism which assigns 'shallow' phrase structure analyses to tag networks (or 'lattices') returned by the tagger (Briscoe & Carroll, 1994, 1995; Carroll & Briscoe, 1996). 4. A p a t t e r n s e t e x t r a c t o r which extracts subcategorization patterns, including the syntactic categories and head lemmas of constituents, 357 (lb) is parsed successfully by the probabilistic LR parser, and the ranked analyses are returned. Then the patternset extractor locates the subanalyses containing attribute and constructs a patternset. The highest ranked analysis and pattern for this example are shown in Figure 12 . Patterns encode the value of the VSUBCAT feature from the VP rule and the head lemma(s) of each argument. In the case of P P"
A97-1052,W96-0209,1,0.646554,"ith lemma-tag pairs, where a lemma is the morphological base or dictionary headword form appropriate for the word, given the PoS assignment made by the tagger. We use an enhanced version of the G A T E project stemmer (Cunningham et al., 1995). 3. A p r o b a b i l i s t i c L R p a r s e r , trained on a treebank, returns ranked analyses (Briscoe &: Carroll, 1993; Carroll, 1993, 1994), using a grammar written in a feature-based unification grammar formalism which assigns 'shallow' phrase structure analyses to tag networks (or 'lattices') returned by the tagger (Briscoe & Carroll, 1994, 1995; Carroll & Briscoe, 1996). 4. A p a t t e r n s e t e x t r a c t o r which extracts subcategorization patterns, including the syntactic categories and head lemmas of constituents, 357 (lb) is parsed successfully by the probabilistic LR parser, and the ranked analyses are returned. Then the patternset extractor locates the subanalyses containing attribute and constructs a patternset. The highest ranked analysis and pattern for this example are shown in Figure 12 . Patterns encode the value of the VSUBCAT feature from the VP rule and the head lemma(s) of each argument. In the case of P P (I)2) arguments, the pattern al"
A97-1052,P90-1031,0,0.0811131,"Missing"
A97-1052,A94-1009,0,0.0263756,"ted his failure, he said, to no< blank> one buying his books. b he_PPHS1 attribute_VVD his_APP$ failure_NN1 ,_, he_PPHS1 say_VVD ,_, to_II no<blank>one_PN buy_ VVG his_APP$ book_NN2 System 2.1 O v e r v i e w The system consists of the following six components which are applied in sequence to sentences containing a specific predicate in order to retrieve a set of subcategorization classes for that predicate: 1. A t a g g e r , a first-order HMM part-of-speech (PoS) and punctuation tag disambiguator, is used to assign and rank tags for each word and punctuation token in sequences of sentences (Elworthy, 1994). 2. A l e m m a t i z e r is used to replace word-tag pairs with lemma-tag pairs, where a lemma is the morphological base or dictionary headword form appropriate for the word, given the PoS assignment made by the tagger. We use an enhanced version of the G A T E project stemmer (Cunningham et al., 1995). 3. A p r o b a b i l i s t i c L R p a r s e r , trained on a treebank, returns ranked analyses (Briscoe &: Carroll, 1993; Carroll, 1993, 1994), using a grammar written in a feature-based unification grammar formalism which assigns 'shallow' phrase structure analyses to tag networks (or 'latt"
A97-1052,C94-1042,0,0.653301,"ng and Knowledge extraction for Language Engineering', and by SERC/EPSRC Advanced Fellowships to both authors. We would like to thank the COMLEX Syntax development team for allowing us access to pre-release data (for an early experiment), and for useful feedback. 356 Several substantial machine-readable subcategorization dictionaries exist for English, either built largely automatically from machine-readable versions of conventional learners' dictionaries, or manually by (computational) linguists (e.g. the Alvey NL Tools (ANLT) dictionary, Boguraev et al. (1987); the COMLEX Syntax dictionary, Grishman et al. (1994)). Unfortunately, neither approach can yield a genuinely accurate or comprehensive computational lexicon, because both rest ultimately on the manual efforts of lexicographers / linguists and are, therefore, prone to errors of omission and commission which are hard or impossible to detect automatically (e.g. Boguraev & Briscoe, 1989; see also section 3.1 below for an example). Furthermore, manual encoding is labour intensive and, therefore, it is costly to extend it to neologisms, information not currently encoded (such as relative frequency of different subcategorizations), or other (sub)langu"
A97-1052,A92-1022,0,0.018785,"Missing"
A97-1052,C92-2099,0,0.0314067,"we utilize for statistical filtering would need to be estimated, perhaps using the technique described by Brent (1993). However, the entire approach to filtering needs improvement, as evaluation of our results demonstrates that it is the weakest link in our current system. Our system needs further refinement to narrow some subcategorization classes, for example, to choose between differing control options with predicative complements. It also needs supplementing with information about diathesis alternation possibilities (e.g. Levin, 1993) and semantic selection preferences on argument heads. Grishman & Sterling (1992), Poznanski & Sanfilippo (1993), Resnik (1993), Ribas (1994) and others have shown that it is possible to acquire selection preferences from (partially) parsed data. Our system already gathers head lemmas in patterns, so any of these approaches could be applied, in principle. In future work, we intend to extend the system in this direction. The ability to recognize that argument slots of different subcategorization classes for the same predicate share semantic restrictions/preferences would assist recognition that the predicate undergoes specific alternations, this in turn assisting inferences"
A97-1052,P93-1032,0,0.782191,"grammars to improve the accuracy of parse ranking, no wide-coverage parser has yet been constructed incorporating probabilities of different subcategorizations for individual predicates, because of the problems of accurately estimating them. These problems suggest that automatic construction or updating of subcategorization dictionaries from textual corpora is a more promising avenue to pursue. Preliminary experiments acquiring a few from sentence subanalyses which begin/end at the boundaries of (specified) predicates. verbal subcategorization classes have been reported by Brent (1991, 1993), Manning (1993), and Ushioda et al. (1993). In these experiments the maximum number of distinct subcategorization classes recognized is sixteen, and only Ushioda et al. attempt to derive relative subcategorization frequency for individual predicates. We describe a new system capable of distinguishing 160 verbal subcategorization classes--a superset of those found in the ANLT and COMLEX Syntax dictionaries. The classes also incorporate information about control of predicative arguments and alternations such as particle movement and extraposition. We report an initial experiment which demonstrates that this sy"
A97-1052,W93-0108,0,0.0636711,"filtering would need to be estimated, perhaps using the technique described by Brent (1993). However, the entire approach to filtering needs improvement, as evaluation of our results demonstrates that it is the weakest link in our current system. Our system needs further refinement to narrow some subcategorization classes, for example, to choose between differing control options with predicative complements. It also needs supplementing with information about diathesis alternation possibilities (e.g. Levin, 1993) and semantic selection preferences on argument heads. Grishman & Sterling (1992), Poznanski & Sanfilippo (1993), Resnik (1993), Ribas (1994) and others have shown that it is possible to acquire selection preferences from (partially) parsed data. Our system already gathers head lemmas in patterns, so any of these approaches could be applied, in principle. In future work, we intend to extend the system in this direction. The ability to recognize that argument slots of different subcategorization classes for the same predicate share semantic restrictions/preferences would assist recognition that the predicate undergoes specific alternations, this in turn assisting inferences about control, equi and raisin"
A97-1052,C94-2123,0,0.0295959,"using the technique described by Brent (1993). However, the entire approach to filtering needs improvement, as evaluation of our results demonstrates that it is the weakest link in our current system. Our system needs further refinement to narrow some subcategorization classes, for example, to choose between differing control options with predicative complements. It also needs supplementing with information about diathesis alternation possibilities (e.g. Levin, 1993) and semantic selection preferences on argument heads. Grishman & Sterling (1992), Poznanski & Sanfilippo (1993), Resnik (1993), Ribas (1994) and others have shown that it is possible to acquire selection preferences from (partially) parsed data. Our system already gathers head lemmas in patterns, so any of these approaches could be applied, in principle. In future work, we intend to extend the system in this direction. The ability to recognize that argument slots of different subcategorization classes for the same predicate share semantic restrictions/preferences would assist recognition that the predicate undergoes specific alternations, this in turn assisting inferences about control, equi and raising (e.g. Boguraev & Briscoe, 1"
A97-1052,C92-2066,0,0.0177604,"and the senses of a word change between corpora, sublanguages and/or subject domains (Jensen, 1991). In a recent experiment with a wide-coverage parsing system utilizing a lexicalist grammatical framework, Briscoe & Carroll (1993) observed that half of parse failures on unseen test data were caused by inaccurate subcategorization information in the ANLT dictionary. The close connection between sense and subcategorization and between subject domain and sense makes it likely that a fully accurate 'static' subcategorization dictionary of a language is unattainable in any case. Moreover, although Schabes (1992) and others have proposed 'lexicalized' probabilistic grammars to improve the accuracy of parse ranking, no wide-coverage parser has yet been constructed incorporating probabilities of different subcategorizations for individual predicates, because of the problems of accurately estimating them. These problems suggest that automatic construction or updating of subcategorization dictionaries from textual corpora is a more promising avenue to pursue. Preliminary experiments acquiring a few from sentence subanalyses which begin/end at the boundaries of (specified) predicates. verbal subcategorizat"
A97-1052,W93-0109,0,0.74354,"the accuracy of parse ranking, no wide-coverage parser has yet been constructed incorporating probabilities of different subcategorizations for individual predicates, because of the problems of accurately estimating them. These problems suggest that automatic construction or updating of subcategorization dictionaries from textual corpora is a more promising avenue to pursue. Preliminary experiments acquiring a few from sentence subanalyses which begin/end at the boundaries of (specified) predicates. verbal subcategorization classes have been reported by Brent (1991, 1993), Manning (1993), and Ushioda et al. (1993). In these experiments the maximum number of distinct subcategorization classes recognized is sixteen, and only Ushioda et al. attempt to derive relative subcategorization frequency for individual predicates. We describe a new system capable of distinguishing 160 verbal subcategorization classes--a superset of those found in the ANLT and COMLEX Syntax dictionaries. The classes also incorporate information about control of predicative arguments and alternations such as particle movement and extraposition. We report an initial experiment which demonstrates that this system is capable of acquirin"
A97-1052,J87-3002,1,\N,Missing
A97-1052,H91-1067,0,\N,Missing
A97-1052,E95-1016,0,\N,Missing
A97-1052,A92-1011,0,\N,Missing
A97-1052,J93-1002,1,\N,Missing
andersen-etal-2008-bnc,W07-1022,0,\N,Missing
andersen-etal-2008-bnc,P06-4020,1,\N,Missing
andersen-etal-2008-bnc,C94-1103,0,\N,Missing
andersen-etal-2008-bnc,P06-2006,1,\N,Missing
atserias-etal-2004-cross,habash-dorr-2002-handling,0,\N,Missing
atserias-etal-2004-cross,briscoe-carroll-2002-robust,1,\N,Missing
atserias-etal-2004-cross,H92-1045,0,\N,Missing
atserias-etal-2004-cross,magnini-cavaglia-2000-integrating,1,\N,Missing
atserias-etal-2004-cross,agirre-etal-2004-exploring,1,\N,Missing
briscoe-carroll-2002-robust,1995.iwpt-1.8,1,\N,Missing
briscoe-carroll-2002-robust,A00-2018,0,\N,Missing
briscoe-carroll-2002-robust,A00-2022,1,\N,Missing
briscoe-carroll-2002-robust,J93-2006,0,\N,Missing
briscoe-carroll-2002-robust,W98-1114,1,\N,Missing
briscoe-carroll-2002-robust,A94-1009,0,\N,Missing
briscoe-carroll-2002-robust,J02-2003,0,\N,Missing
briscoe-carroll-2002-robust,P00-1017,0,\N,Missing
briscoe-carroll-2002-robust,J03-4003,0,\N,Missing
briscoe-carroll-2002-robust,P01-1034,0,\N,Missing
briscoe-carroll-2002-robust,P99-1061,1,\N,Missing
briscoe-carroll-2002-robust,P90-1031,0,\N,Missing
briscoe-carroll-2002-robust,P98-2247,0,\N,Missing
briscoe-carroll-2002-robust,C98-2242,0,\N,Missing
briscoe-carroll-2002-robust,grover-etal-2000-lt,0,\N,Missing
briscoe-carroll-2002-robust,J93-1002,1,\N,Missing
briscoe-carroll-2002-robust,P94-1040,1,\N,Missing
briscoe-carroll-2002-robust,W01-1808,1,\N,Missing
briscoe-carroll-2002-robust,P01-1019,0,\N,Missing
C02-1013,W97-0810,0,0.0752176,"Missing"
C02-1013,P98-1010,0,0.0381019,"Missing"
C02-1013,A00-2031,0,0.0712413,"Missing"
C02-1013,W97-0307,0,0.0581427,"Missing"
C02-1013,J93-2002,0,0.0371654,"ss than one, and so will not receive full credit from the weighted precision and recall measures. However, these results only tell part of the story. An application using grammatical relation analyses might be interested only in GRs that the parser is fairly confident of being correct. For instance, in unsupervised acquisition of lexical information (such as subcategorisation frames for verbs) from text, the usual methodology is to (partially) analyse the text, retaining only reliable hypotheses which are then filtered based on the amount of evidence for them over the corpus as a whole. Thus, Brent (1993) only creates hypotheses on the basis of instances of verb frames that are reliably and unambiguously cued by closed class items (such as pronouns) so there can be no other attachment possibilities. In recent work on unsupervised learning of prepositional phrase disambiguation, Pantel and Lin (2000) derive training instances only from relevant data appearing in syntactic contexts that are guaranteed to be unambiguous. In our system, the weights on GRs indicate how certain the parser is of the associated relations being correct. We therefore investigated whether more highly weighted GRs are in"
C02-1013,A97-1052,1,0.825922,"ched using lexicalised probabilistic models over headdependent tuples. Bouma, van Noord and Malouf (2001) create dependency treebanks semi-automatically in order to induce dependency-based statistical models for parse selection. Lin (1998), Srinivas (2000) and others have evaluated the accuracy of both phrase structure-based and dependency parsers by matching head-dependent relations against ‘gold standard’ relations, rather than matching (labelled) phrase structure bracketings. Research on unsupervised acquisition of lexical information from corpora, such as argument structure of predicates (Briscoe and Carroll, 1997; McCarthy, 2000), word classes for disambiguation (Clark and Weir, 2001), and collocations (Lin 1999), has used grammatical relation/head/dependent tuples. Such 1 A previous version of this paper was presented at IWPT’01; this version contains new experiments and results. Ted Briscoe Computer Laboratory University of Cambridge JJ Thomson Avenue Cambridge CB3 0FD, UK tuples also constitute a convenient intermediate representation in applications such as information extraction (Palmer et al., 1993; Yeh, 2000), and document retrieval on the Web (Grefenstette, 1997). A variety of different approa"
C02-1013,W99-0629,0,0.0465788,"Missing"
C02-1013,W98-1114,1,0.91687,"Missing"
C02-1013,N01-1013,0,0.0112118,"van Noord and Malouf (2001) create dependency treebanks semi-automatically in order to induce dependency-based statistical models for parse selection. Lin (1998), Srinivas (2000) and others have evaluated the accuracy of both phrase structure-based and dependency parsers by matching head-dependent relations against ‘gold standard’ relations, rather than matching (labelled) phrase structure bracketings. Research on unsupervised acquisition of lexical information from corpora, such as argument structure of predicates (Briscoe and Carroll, 1997; McCarthy, 2000), word classes for disambiguation (Clark and Weir, 2001), and collocations (Lin 1999), has used grammatical relation/head/dependent tuples. Such 1 A previous version of this paper was presented at IWPT’01; this version contains new experiments and results. Ted Briscoe Computer Laboratory University of Cambridge JJ Thomson Avenue Cambridge CB3 0FD, UK tuples also constitute a convenient intermediate representation in applications such as information extraction (Palmer et al., 1993; Yeh, 2000), and document retrieval on the Web (Grefenstette, 1997). A variety of different approaches have been taken for robust extraction of relation/head/dependent tup"
C02-1013,P99-1061,1,0.911215,"Missing"
C02-1013,P99-1041,0,0.0121153,"dency treebanks semi-automatically in order to induce dependency-based statistical models for parse selection. Lin (1998), Srinivas (2000) and others have evaluated the accuracy of both phrase structure-based and dependency parsers by matching head-dependent relations against ‘gold standard’ relations, rather than matching (labelled) phrase structure bracketings. Research on unsupervised acquisition of lexical information from corpora, such as argument structure of predicates (Briscoe and Carroll, 1997; McCarthy, 2000), word classes for disambiguation (Clark and Weir, 2001), and collocations (Lin 1999), has used grammatical relation/head/dependent tuples. Such 1 A previous version of this paper was presented at IWPT’01; this version contains new experiments and results. Ted Briscoe Computer Laboratory University of Cambridge JJ Thomson Avenue Cambridge CB3 0FD, UK tuples also constitute a convenient intermediate representation in applications such as information extraction (Palmer et al., 1993; Yeh, 2000), and document retrieval on the Web (Grefenstette, 1997). A variety of different approaches have been taken for robust extraction of relation/head/dependent tuples, or grammatical relations"
C02-1013,A00-2034,0,0.0125027,"abilistic models over headdependent tuples. Bouma, van Noord and Malouf (2001) create dependency treebanks semi-automatically in order to induce dependency-based statistical models for parse selection. Lin (1998), Srinivas (2000) and others have evaluated the accuracy of both phrase structure-based and dependency parsers by matching head-dependent relations against ‘gold standard’ relations, rather than matching (labelled) phrase structure bracketings. Research on unsupervised acquisition of lexical information from corpora, such as argument structure of predicates (Briscoe and Carroll, 1997; McCarthy, 2000), word classes for disambiguation (Clark and Weir, 2001), and collocations (Lin 1999), has used grammatical relation/head/dependent tuples. Such 1 A previous version of this paper was presented at IWPT’01; this version contains new experiments and results. Ted Briscoe Computer Laboratory University of Cambridge JJ Thomson Avenue Cambridge CB3 0FD, UK tuples also constitute a convenient intermediate representation in applications such as information extraction (Palmer et al., 1993; Yeh, 2000), and document retrieval on the Web (Grefenstette, 1997). A variety of different approaches have been ta"
C02-1013,A00-2022,1,0.793332,"Missing"
C02-1013,P00-1014,0,0.016652,"Missing"
C02-1013,P01-1060,0,0.169153,"Missing"
C02-1013,P00-1017,0,0.0358537,"Missing"
C02-1013,J03-4003,0,\N,Missing
C04-1177,S01-1020,0,\N,Missing
C04-1177,W04-0837,1,\N,Missing
C04-1177,S01-1005,0,\N,Missing
C04-1177,S01-1027,0,\N,Missing
C04-1177,kilgarriff-rosenzweig-2000-english,0,\N,Missing
C04-1177,rose-etal-2002-reuters,0,\N,Missing
C04-1177,O97-1002,0,\N,Missing
C04-1177,briscoe-carroll-2002-robust,1,\N,Missing
C04-1177,P04-1036,1,\N,Missing
C04-1177,J04-1003,0,\N,Missing
C04-1177,P98-2127,0,\N,Missing
C04-1177,C98-2122,0,\N,Missing
C04-1177,magnini-cavaglia-2000-integrating,0,\N,Missing
C08-1135,P07-1056,0,0.117953,"test data that is similar to the training data. To move to another domain one would have to collect annotated data in the new domain and retrain the classifier. Engström (2004) reports decreased accuracy in cross-domain classification since sentiment in different domains is often expressed in different ways. However, it is impossible in practice to have annotated data for all possible domains of interest. Aue and Gamon (2005) attempt to solve the problem of the absence of large amounts of labeled data by customizing sentiment classifiers to new domains using training data from other domains. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers using structural correspondence learning. Read (2005) also observed significant differences between the accuracy of classification of reviews in the same domain but published in different time periods. Recently, there has been a shift of interest towards more fine-grained approaches to processing of sentiment, in which opinion is extracted at the sentence level, sometimes including information about different features of a product that are commented on and/or the opinion holder (Hu and Liu, 2004; Ku et al., 2006). But even in such approa"
C08-1135,P07-1053,0,0.0182103,"Missing"
C08-1135,P07-1055,0,0.0198838,"tigate domain adaptation for sentiment classifiers using structural correspondence learning. Read (2005) also observed significant differences between the accuracy of classification of reviews in the same domain but published in different time periods. Recently, there has been a shift of interest towards more fine-grained approaches to processing of sentiment, in which opinion is extracted at the sentence level, sometimes including information about different features of a product that are commented on and/or the opinion holder (Hu and Liu, 2004; Ku et al., 2006). But even in such approaches, McDonald et al. (2007) note that information about the overall sentiment orientation of a document facilitates more accurate extraction of more specific information from the text. 2.2 Unsupervised Approach One way of tackling the problem of domain dependency could be to use an approach that does not rely on annotated data. Turney (2002) describes a method of sentiment classification using two human-selected seed words (the words poor and excellent) in conjunction with a very large text corpus; the semantic orientation of phrases is computed as their association with the seed words (as measured by pointwise mutual i"
C08-1135,P05-2008,0,0.0314498,"he new domain and retrain the classifier. Engström (2004) reports decreased accuracy in cross-domain classification since sentiment in different domains is often expressed in different ways. However, it is impossible in practice to have annotated data for all possible domains of interest. Aue and Gamon (2005) attempt to solve the problem of the absence of large amounts of labeled data by customizing sentiment classifiers to new domains using training data from other domains. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers using structural correspondence learning. Read (2005) also observed significant differences between the accuracy of classification of reviews in the same domain but published in different time periods. Recently, there has been a shift of interest towards more fine-grained approaches to processing of sentiment, in which opinion is extracted at the sentence level, sometimes including information about different features of a product that are commented on and/or the opinion holder (Hu and Liu, 2004; Ku et al., 2006). But even in such approaches, McDonald et al. (2007) note that information about the overall sentiment orientation of a document facil"
C08-1135,P02-1053,0,0.0167299,"pproaches to processing of sentiment, in which opinion is extracted at the sentence level, sometimes including information about different features of a product that are commented on and/or the opinion holder (Hu and Liu, 2004; Ku et al., 2006). But even in such approaches, McDonald et al. (2007) note that information about the overall sentiment orientation of a document facilitates more accurate extraction of more specific information from the text. 2.2 Unsupervised Approach One way of tackling the problem of domain dependency could be to use an approach that does not rely on annotated data. Turney (2002) describes a method of sentiment classification using two human-selected seed words (the words poor and excellent) in conjunction with a very large text corpus; the semantic orientation of phrases is computed as their association with the seed words (as measured by pointwise mutual information). The sentiment of a document is calculated as the average semantic orientation of all such phrases. Yarowsky (1995) describes a &apos;semi-unsupervised&apos; approach to the problem of sense disambiguation of words, also using a set of initial seeds, in this case a few high quality sense annotations. These annota"
C08-1135,W04-1118,0,0.0179579,"Missing"
C08-1135,P95-1026,0,0.218963,"n of more specific information from the text. 2.2 Unsupervised Approach One way of tackling the problem of domain dependency could be to use an approach that does not rely on annotated data. Turney (2002) describes a method of sentiment classification using two human-selected seed words (the words poor and excellent) in conjunction with a very large text corpus; the semantic orientation of phrases is computed as their association with the seed words (as measured by pointwise mutual information). The sentiment of a document is calculated as the average semantic orientation of all such phrases. Yarowsky (1995) describes a &apos;semi-unsupervised&apos; approach to the problem of sense disambiguation of words, also using a set of initial seeds, in this case a few high quality sense annotations. These annotations are used to start an iterative process of learning information about the contexts in which senses of words appear, in each iteration labeling senses of previously unlabeled word tokens using information from the previous iteration. 2.3 Chinese Language Processing A major issue in processing Chinese text is the fact that words are not delimited in the written language. In many cases, NLP researchers wor"
C08-1135,W03-1017,0,0.0265048,"been annotated with respect to sentiment by the authors of the reviews, and used this data to train supervised classifiers. A number of studies have investigated the impact on classification accuracy of different factors, including choice of feature set, machine learning algorithm, and pre-selection of the segments of text to be classified. For example, Dave et al. (2003) experiment with the use of linguistic, statistical and n-gram features and measures for feature selection and weighting. Pang and Lee (2004) use a graph-based technique to identify and analyze only subjective parts of texts. Yu and Hatzivassiloglou (2003) use semanticallyoriented words for identification of polarity at the sentence level. Most of this work assumes binary classification (positive and negative), some1073 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1073–1080 Manchester, August 2008 times with the addition of a neutral class (in terms of polarity, representing lack of sentiment). While supervised systems generally achieve reasonably high accuracy, they do so only on test data that is similar to the training data. To move to another domain one would have to collect annotated da"
C08-1135,I08-1040,1,0.839617,"turned out to be a good indicator of positive reviews as it was often used in sentences such as “Still, though, it was worth seeing&apos;&apos;. 3 Our Approach Our main goal is to overcome the problem of domain-dependency in sentiment classification. Unsupervised approaches seem promising in this regard, since they do not require annotated training data, just access to sufficient raw text in each domain. We base our approach on a previously described, &apos;almost-unsupervised&apos; system that starts with only a single, human-selected seed 好 (good) and uses an iterative method to extract a training sub-corpus (Zagibalov & Carroll, 2008). The approach does not use a word segmentation module; in this paper we use the term &apos;lexical item&apos; to denote any sequence of Chinese characters that is treated by the system as a unit, whatever it is linguistically — a morpheme, a word or a phrase. 1074 Our initial aim was to investigate ways of improving the classifier by automatically finding a better seed, because Zagibalov & Carroll indicate that in different domains they could, by manual trial and error, find a seed other than 好 (good) which produced better results. To find such a seed automatically, we make two assumptions: 1. Attitude"
C08-1135,P04-1035,0,\N,Missing
C08-1135,W02-1011,0,\N,Missing
C16-1082,W03-1812,0,0.0217383,"eral and non-literal word combinations (Birke and Sarkar, 2006; Cook et al., 2008), whereas others propose a grading containing several MWE types based on semantic idiomaticity, considered as a continuum (Wulff, 2008). Within the Meaning-Text Theory, collocations are sorted according to the notion of lexical functions (Mel’´cuk, 1998), that is, taking into account how the component words are semantically related. Furthermore, some experiments have investigated automatic methods—such as distributional similarity or word embeddings—for the task of classification, leading to fairly good results (Baldwin et al., 2003; McCarthy et al., 2003; Fazly et al., 2007; Rodr´ıguez-Fern´andez et al., 2016). In addition to MWE classification, a great deal of work has been undertaken over the last two decades on MWE acquisition (Ramisch, 2015) and identification (Li et al., 2003; Seretan and Wehrli, 2009; Sporleder and Li, 2009). Precise and detailed syntactic information is crucial for both tasks, and, at the same time, MWE identification can also help parsers obtain better results (Seretan, 2013). Moreover, accurate MWE detection is crucial for MT, since MWEs vary greatly from one language to another, and are not us"
C16-1082,E06-1042,0,0.0463699,"ms to work effectively (Sag et al., 2002), since these kinds of word combinations are very frequent in both text and speech. It is estimated that the number of MWEs in an English speaker’s vocabulary is of the same order of magnitude as that of single words (Jackendoff, 1997), and that at least one MWE is used per sentence on average (Sinclair, 1991). Various classifications of MWEs have been proposed, employing different criteria to match the requirements of a particular kind of target application. Some researchers propose a binary categorisation of literal and non-literal word combinations (Birke and Sarkar, 2006; Cook et al., 2008), whereas others propose a grading containing several MWE types based on semantic idiomaticity, considered as a continuum (Wulff, 2008). Within the Meaning-Text Theory, collocations are sorted according to the notion of lexical functions (Mel’´cuk, 1998), that is, taking into account how the component words are semantically related. Furthermore, some experiments have investigated automatic methods—such as distributional similarity or word embeddings—for the task of classification, leading to fairly good results (Baldwin et al., 2003; McCarthy et al., 2003; Fazly et al., 200"
C16-1082,W07-1102,0,0.0722873,"Missing"
C16-1082,P03-1065,0,0.0404403,"ions are sorted according to the notion of lexical functions (Mel’´cuk, 1998), that is, taking into account how the component words are semantically related. Furthermore, some experiments have investigated automatic methods—such as distributional similarity or word embeddings—for the task of classification, leading to fairly good results (Baldwin et al., 2003; McCarthy et al., 2003; Fazly et al., 2007; Rodr´ıguez-Fern´andez et al., 2016). In addition to MWE classification, a great deal of work has been undertaken over the last two decades on MWE acquisition (Ramisch, 2015) and identification (Li et al., 2003; Seretan and Wehrli, 2009; Sporleder and Li, 2009). Precise and detailed syntactic information is crucial for both tasks, and, at the same time, MWE identification can also help parsers obtain better results (Seretan, 2013). Moreover, accurate MWE detection is crucial for MT, since MWEs vary greatly from one language to another, and are not usually translated word for word. In the context of MT systems, Wehrli (2014) states “the non-identification of collocations dramatically affects the quality of the output”. 3 Linguistic Analysis The linguistic analysis we present here aims at improving MW"
C16-1082,P14-5010,0,0.00587255,"Missing"
C16-1082,W03-1810,1,0.832198,"ord combinations (Birke and Sarkar, 2006; Cook et al., 2008), whereas others propose a grading containing several MWE types based on semantic idiomaticity, considered as a continuum (Wulff, 2008). Within the Meaning-Text Theory, collocations are sorted according to the notion of lexical functions (Mel’´cuk, 1998), that is, taking into account how the component words are semantically related. Furthermore, some experiments have investigated automatic methods—such as distributional similarity or word embeddings—for the task of classification, leading to fairly good results (Baldwin et al., 2003; McCarthy et al., 2003; Fazly et al., 2007; Rodr´ıguez-Fern´andez et al., 2016). In addition to MWE classification, a great deal of work has been undertaken over the last two decades on MWE acquisition (Ramisch, 2015) and identification (Li et al., 2003; Seretan and Wehrli, 2009; Sporleder and Li, 2009). Precise and detailed syntactic information is crucial for both tasks, and, at the same time, MWE identification can also help parsers obtain better results (Seretan, 2013). Moreover, accurate MWE detection is crucial for MT, since MWEs vary greatly from one language to another, and are not usually translated word f"
C16-1082,padro-stanilovsky-2012-freeling,0,0.184284,"Missing"
C16-1082,P16-2081,0,0.0561217,"Missing"
C16-1082,E09-1086,0,0.0182944,"lexical functions (Mel’´cuk, 1998), that is, taking into account how the component words are semantically related. Furthermore, some experiments have investigated automatic methods—such as distributional similarity or word embeddings—for the task of classification, leading to fairly good results (Baldwin et al., 2003; McCarthy et al., 2003; Fazly et al., 2007; Rodr´ıguez-Fern´andez et al., 2016). In addition to MWE classification, a great deal of work has been undertaken over the last two decades on MWE acquisition (Ramisch, 2015) and identification (Li et al., 2003; Seretan and Wehrli, 2009; Sporleder and Li, 2009). Precise and detailed syntactic information is crucial for both tasks, and, at the same time, MWE identification can also help parsers obtain better results (Seretan, 2013). Moreover, accurate MWE detection is crucial for MT, since MWEs vary greatly from one language to another, and are not usually translated word for word. In the context of MT systems, Wehrli (2014) states “the non-identification of collocations dramatically affects the quality of the output”. 3 Linguistic Analysis The linguistic analysis we present here aims at improving MWE processing in MT. More specifically, we base our"
C16-1082,W13-1009,0,0.0697427,"Missing"
C16-1082,vincze-2012-light,0,0.073371,"Missing"
C16-1082,W14-0804,0,0.0175347,"ndez et al., 2016). In addition to MWE classification, a great deal of work has been undertaken over the last two decades on MWE acquisition (Ramisch, 2015) and identification (Li et al., 2003; Seretan and Wehrli, 2009; Sporleder and Li, 2009). Precise and detailed syntactic information is crucial for both tasks, and, at the same time, MWE identification can also help parsers obtain better results (Seretan, 2013). Moreover, accurate MWE detection is crucial for MT, since MWEs vary greatly from one language to another, and are not usually translated word for word. In the context of MT systems, Wehrli (2014) states “the non-identification of collocations dramatically affects the quality of the output”. 3 Linguistic Analysis The linguistic analysis we present here aims at improving MWE processing in MT. More specifically, we base our study on Matxin (Mayor et al., 2011), a rule-based MT system for English-Basque and 2 Whereas English (Germanic) and Spanish (Romance) are Indo-European languages, Basque is a non-Indo-European language which moreover belongs to no known language family. 858 Spanish-Basque translation. One of the problems Matxin has concerning MWEs is that it currently fails to detect"
C88-1012,C86-1016,0,0.0285964,"ent, and describe the implementation of a system which has supported efficient development of a large computational grammar of English? 1. Tools for Grammar Development A number of researzh projects within the broad area of natural language processing (NLP) and theoretical linguistics make use of special purpose programs, which are beginning to be known under the general term of &quot;gm.nmar development environments&quot; (GDEs). Particularly well known examples are reported in Kaplan (1983) (see also Kiparsky, 1985), Shieber (1984), Evans (1985), Phillips and Thompson (1985), Jensen et al. (1986) and Karttunen (1986). In all instances the software packages cited above fall in the class of computational tools used in theoretical (rather than applied) Projects. Thus Kaplan's Grammar-writer's Workbench is an implementation of a particular linguistic theory (Lexical Functional Grammar;, Kaplan and Bresnan, 1982); similarly, Evans' ProGram incorporated an early version of Generalized Phrase Structure Grammar (GPSG, Gazdar and Pullum, 1982), whilst PATR-II is a &quot;virtual linguistic machine&quot;, developed by Shieber as a tool for experimenting with a variety of syntactic theories. These systems differ in their goals"
C88-1012,J85-2001,0,0.0293572,"or the notation is, it incorporates a handle for explicit intervention into the interpretation of the grammar at hand. Sometimes the nature of the task for which the g~ammar is being developed justifies a form~J notation incolporating 'hooks' for explicit procedures. Thus a number of matchine translation (MT) projects~ especially ones employing a ~ransfer strategy, make use of format systems for grammar specification, which, in addition to mapping surface strings into con~esponding language structures, identify operations to be associated with nodes and / or subtrees (Vauquois & Boitet, 1985; Nagao et al., 1985). In general, the effects of the temptation to allow, for example, the EVALuation of arbitrary LISP expressions on the ares of the ATN or the addition of &quot;procedural programming facilities&quot; to the rule-based skeleton of 1BM's PLNLP have been discussed at length in the recent literature addressing the issues of declarative formalisms from a theoretical perspective (see Shieber, 1986a, and references therein). However, from the point of view of developing a realistic grammar with substantial coverage, the opening of the procedural 'back door', while perhaps useful fo: 'patching' the inadequacies"
C88-1012,P85-1021,0,0.0297239,"l;~)rtance. For i~stance, it would bc inappropriate to adopt a direct imp!ementation of, say GPSG, since tire rate of change of the theory itself is likely to make such an implementation obsolete (or at least incapable of irmorporating subsequent linguistic analyses) quite rapidly - . file bdcf lifcspan of Ewms' ProGram is a case in point. ()nly when theou and grammar are beiug developed in very close collaboration, or even wifltin the same group -- - as in, for example, the })ewlctt.-Packard NLP project, whose cornerstotm is the linguistic framewolk of Head-Driven t'hrase Structm'e Grannnar (Proudian and Pollard, 1985; PollaN aud Sag, 1987) - - could such ~ul approach work. l}owever, itr mJ effint like om&quot;a, it is of critical impmtauce to strike the right balance between i)eit~g failhfu[ to the spirit nf a tbeo~y mid being uncommii:ted with respect to a particular vcrsien of it, as well as remaiuing tlexiNe within tile overall iianlcwoN of 'close' or related theories. Attempts to be too flexible, however, arc iikely to lead tit situations of wqich the PATII..II system is an example: the ability to model a wide t' rage of theoretical devices and mr(lyrical ti'amcworks is penalised by its unsuitability &quot;for"
C88-1012,P87-1034,0,0.0332838,"Missing"
C88-1012,C86-1066,0,0.06067,"Missing"
C88-1012,P84-1075,0,0.0908724,"this task, demonstrate how they influence the design of a suitable software environment, and describe the implementation of a system which has supported efficient development of a large computational grammar of English? 1. Tools for Grammar Development A number of researzh projects within the broad area of natural language processing (NLP) and theoretical linguistics make use of special purpose programs, which are beginning to be known under the general term of &quot;gm.nmar development environments&quot; (GDEs). Particularly well known examples are reported in Kaplan (1983) (see also Kiparsky, 1985), Shieber (1984), Evans (1985), Phillips and Thompson (1985), Jensen et al. (1986) and Karttunen (1986). In all instances the software packages cited above fall in the class of computational tools used in theoretical (rather than applied) Projects. Thus Kaplan's Grammar-writer's Workbench is an implementation of a particular linguistic theory (Lexical Functional Grammar;, Kaplan and Bresnan, 1982); similarly, Evans' ProGram incorporated an early version of Generalized Phrase Structure Grammar (GPSG, Gazdar and Pullum, 1982), whilst PATR-II is a &quot;virtual linguistic machine&quot;, developed by Shieber as a tool for"
C88-1012,J85-1003,0,0.079222,"ics: whatever the basis for the notation is, it incorporates a handle for explicit intervention into the interpretation of the grammar at hand. Sometimes the nature of the task for which the g~ammar is being developed justifies a form~J notation incolporating 'hooks' for explicit procedures. Thus a number of matchine translation (MT) projects~ especially ones employing a ~ransfer strategy, make use of format systems for grammar specification, which, in addition to mapping surface strings into con~esponding language structures, identify operations to be associated with nodes and / or subtrees (Vauquois & Boitet, 1985; Nagao et al., 1985). In general, the effects of the temptation to allow, for example, the EVALuation of arbitrary LISP expressions on the ares of the ATN or the addition of &quot;procedural programming facilities&quot; to the rule-based skeleton of 1BM's PLNLP have been discussed at length in the recent literature addressing the issues of declarative formalisms from a theoretical perspective (see Shieber, 1986a, and references therein). However, from the point of view of developing a realistic grammar with substantial coverage, the opening of the procedural 'back door', while perhaps useful fo: 'patch"
C88-1012,C86-1050,0,\N,Missing
E09-1034,afonso-etal-2002-floresta,0,0.11534,"es Nonprojective By gap degree Gap Gap Gap degree 2 degree 3 deg. > 3 13 2 1 359 4 1 10 0 0 427 13 0 188 10 2 351 51 14 81 21 10 19 7 5 29 0 0 WellNested 204 20257 856 4850 1552 1711 550 1008 665 By nestedness Mildly Strongly Ill-Nested Ill-Nested 1 0 96 0 8 0 15 0 191 0 7 0 5 0 71 0 20 0 Table 1: Counts of dependency trees classified by gap degree, and mild and strong ill-nestedness (for their gap degree); appearing in treebanks for Arabic (Hajiˇc et al., 2004), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), Dutch (van der Beek et al., 2002), Latin (Bamman and Crane, 2006), Portuguese (Afonso et al., 2002), Slovene (Dˇzeroski et al., 2006), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). like the fastest known parsers for LTAG, and can be made O(n6 ) if we use unlexicalised dependencies. When the gap degree is greater than 1, the time complexity goes up by a factor of n2 for each extra unit of gap degree, as in parsers for coupled context-free grammars. Most of the non-projective sentences appearing in treebanks are well-nested and have a small gap degree, so this algorithm directly parses the vast majority of the non-projective constructions present in n"
E09-1034,dzeroski-etal-2006-towards,0,0.13524,"Missing"
E09-1034,P99-1059,0,0.353771,"sed to prove the correctness of a parser: for each input string, a parsing schema’s deduction steps allow us to infer a set of items, called valid items for that string. A schema is said to be sound if all valid final items it produces for any arbitrary string are correct for that string. A schema is said to be complete if all correct final items are valid. A correct parsing schema is one which is both sound and complete. In constituency-based parsing schemata, deduction steps usually have grammar rules as side conditions. In the case of dependency parsers it is also possible to use grammars (Eisner and Satta, 1999), but many algorithms use a data-driven approach instead, making individual decisions about which dependencies to create by using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b can have a as a dependent. Deduction steps in non-grammarbased parsers can be tied to the D-rules associated with the links they create. In this way, we obtain a representation of the underlying logic of the parser while abstracting away"
E09-1034,W00-2011,0,0.821295,"only if T is projective. The subtrees induced by nodes wp and wq are interleaved if bwp c ∩ bwq c = ∅ and there are nodes wi , wj ∈ bwp c and wk , wl ∈ bwq c such that i < k < j < l. A dependency tree T is well-nested if it does not contain two interleaved subtrees. A tree that is not well-nested is said to be ill-nested. Note that projective trees are always well-nested, but well-nested trees are not always projective. for well-nested dependency structures of gap degree 1, and prove its correctness. The parser runs in time O(n7 ), the same complexity as the best existing algorithms for LTAG (Eisner and Satta, 2000), and can be optimised to O(n6 ) in the nonlexicalised case; (2) we generalise the previous algorithm to any well-nested dependency structure with gap degree at most k in time O(n5+2k ); (3) we generalise the previous parsers to be able to analyse not only well-nested structures, but also ill-nested structures with gap degree at most k satisfying certain constraints1 , in time O(n4+3k ); and (4) we characterise the set of structures covered by this parser, which we call mildly ill-nested structures, and show that it includes all the trees present in a number of dependency treebanks. 2.2 Depend"
E09-1034,C96-1058,0,0.0911021,"ema is said to be sound if all valid final items it produces for any arbitrary string are correct for that string. A schema is said to be complete if all correct final items are valid. A correct parsing schema is one which is both sound and complete. In constituency-based parsing schemata, deduction steps usually have grammar rules as side conditions. In the case of dependency parsers it is also possible to use grammars (Eisner and Satta, 1999), but many algorithms use a data-driven approach instead, making individual decisions about which dependencies to create by using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b can have a as a dependent. Deduction steps in non-grammarbased parsers can be tied to the D-rules associated with the links they create. In this way, we obtain a representation of the underlying logic of the parser while abstracting away from control structures (the particular model used to create the decisions associated with D-rules). Furthermore, the choice points in the parsing process and the i"
E09-1034,P08-1110,1,0.793227,"Missing"
E09-1034,N09-1061,1,0.851787,"Missing"
E09-1034,P07-1077,0,0.572169,"Spain cgomezr@udc.es David Weir and John Carroll Department of Informatics University of Sussex, United Kingdom {davidw,johnca}@sussex.ac.uk Abstract the problem is intractable in the absence of this assumption (McDonald and Satta, 2007). Nivre and Nilsson (2005) observe that most non-projective dependency structures appearing in practice are “close” to being projective, since they contain only a small proportion of nonprojective arcs. This has led to the study of classes of dependency structures that lie between projective and unrestricted non-projective structures (Kuhlmann and Nivre, 2006; Havelka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: linear context-free rewriting systems (LCFRS) with fan-out k (VijayShanker et al., 1987; Satta, 1992) induce the set of dependency structures with gap degree at most k − 1; coupled context-free grammars in which the maximal rank of a nonterminal is k (Hotz and Pitsch, 1996) induce the set of well-nested dependency structures with gap degree at most k − 1; and LTAGs (Joshi and"
E09-1034,P07-1021,0,0.686144,"Missing"
E09-1034,P06-2066,0,0.641413,"Universidade da Coru˜na, Spain cgomezr@udc.es David Weir and John Carroll Department of Informatics University of Sussex, United Kingdom {davidw,johnca}@sussex.ac.uk Abstract the problem is intractable in the absence of this assumption (McDonald and Satta, 2007). Nivre and Nilsson (2005) observe that most non-projective dependency structures appearing in practice are “close” to being projective, since they contain only a small proportion of nonprojective arcs. This has led to the study of classes of dependency structures that lie between projective and unrestricted non-projective structures (Kuhlmann and Nivre, 2006; Havelka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: linear context-free rewriting systems (LCFRS) with fan-out k (VijayShanker et al., 1987; Satta, 1992) induce the set of dependency structures with gap degree at most k − 1; coupled context-free grammars in which the maximal rank of a nonterminal is k (Hotz and Pitsch, 1996) induce the set of well-nested dependency structures with gap degree at most k − 1; and L"
E09-1034,W07-2216,0,0.488419,"Missing"
E09-1034,H05-1066,0,0.694573,"Missing"
E09-1034,P05-1013,0,0.235701,"ately, the general problem of parsing ill-nested structures is NPcomplete, even when the gap degree is bounded: this set of structures is closely related to LCFRS with bounded fan-out and unbounded production length, and parsing in this formalism has been proven to be NP-complete (Satta, 1992). The reason for this high complexity is the problem of unrestricted crossing configurations, appearing when dependency subtrees are allowed to interleave in every possible way. However, just as it has been noted that most non-projective structures appearing in practice are only “slightly” nonprojective (Nivre and Nilsson, 2005), we characterise a sense in which the structures appearing in treebanks can be viewed as being only “slightly” ill-nested. In this section, we generalise the algorithms WG1 and WGk to parse a proper superset of the set of well-nested structures in polynomial time; and give a characterisation of this new set of structures, which includes all the structures in several dependency treebanks. 4.2 Computational complexity The WGk parser runs in time O(n5+2k ): as in the case of WG1 , the deduction step with most free variables is Combine Shrinking Gap Centre, and in this case it has 5 + 2k free ind"
E09-1034,P92-1012,0,0.86861,"ring in practice are “close” to being projective, since they contain only a small proportion of nonprojective arcs. This has led to the study of classes of dependency structures that lie between projective and unrestricted non-projective structures (Kuhlmann and Nivre, 2006; Havelka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: linear context-free rewriting systems (LCFRS) with fan-out k (VijayShanker et al., 1987; Satta, 1992) induce the set of dependency structures with gap degree at most k − 1; coupled context-free grammars in which the maximal rank of a nonterminal is k (Hotz and Pitsch, 1996) induce the set of well-nested dependency structures with gap degree at most k − 1; and LTAGs (Joshi and Schabes, 1997) induce the set of well-nested dependency structures with gap degree at most 1. These results establish that there must be polynomial-time dependency parsing algorithms for well-nested structures with bounded gap degree, since such parsers exist for their corresponding lexicalised constituency-based formali"
E09-1034,P87-1015,1,0.825185,"Missing"
E09-1034,W03-3023,0,0.231743,"valid final items it produces for any arbitrary string are correct for that string. A schema is said to be complete if all correct final items are valid. A correct parsing schema is one which is both sound and complete. In constituency-based parsing schemata, deduction steps usually have grammar rules as side conditions. In the case of dependency parsers it is also possible to use grammars (Eisner and Satta, 1999), but many algorithms use a data-driven approach instead, making individual decisions about which dependencies to create by using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b can have a as a dependent. Deduction steps in non-grammarbased parsers can be tied to the D-rules associated with the links they create. In this way, we obtain a representation of the underlying logic of the parser while abstracting away from control structures (the particular model used to create the decisions associated with D-rules). Furthermore, the choice points in the parsing process and the information we can use to make decisions are"
E09-1034,W03-2405,0,\N,Missing
E83-1017,J80-1001,0,0.0750028,"Missing"
E99-1029,C96-1034,0,0.021412,"enerated by a lexicalized CFG. But does the EDOL have any other more direct effects on parsing efficiency? On the one hand, it is a consequence of the EDOL that wide-coverage LTAGs are larger than their rule-based counterparts. With larger elementary structures, generalizations are lost regarding the internal structure of the elementary trees. Since parse time depends on g r a m m a r size, this could have an adverse effect on parsing efficiency. However, the problem of g r a m m a r size in TAG has to some extent been addressed both with respect to g r a m m a r encoding (Evans et al., 1995; Candito, 1996) and parsing (Joshi and Srinivas, 1994; Evans and Weir, 1998). On the other hand, if the EDOL hypothesis holds for those dependencies t h a t are being checked by the parser, then the burden of passing feature values around during parsing will be less than in a rule-based framework. If all dependencies that the parser is checking can be stated directly within the elementary structures of the g r a m m a r , they do not need to be computed dynamically during the parsing process by means of feature percolation. For example, there is no need to use a slash feature to establish filler-gap dependen"
E99-1029,W98-0108,1,0.847898,"arsing process by means of feature percolation. For example, there is no need to use a slash feature to establish filler-gap dependencies over unbounded distances across the tree if the EDOL Proceedings of EACL '99 S $ NP[¢~ :,¢¢] S (whom) SNP VP e Figure 1: Localizing a filler-gap dependency makes it possible for the gap and its filler to be located within the same elementary structure. This paper presents an investigation into the extent to which the EDOL reduces the need for feature passing in two existing wide-coverage grammars: the XTAG grammar (XTAG-Group, 1995), and the LEXSYS grammar (Carroll et al., 1998). It can be seen as an evaluation of how well these two grammars make use of the EDOL hypothesis with respect to those dependencies that are being checked by the parser. 2 Parsing Unification-Based Grammars In phrase-structure rule-based parsing, each rule corresponds to a local tree. A rule is applied to a sequence of existing contiguous constituents, if they are compatible with the daughters. In the case of context-free grammar (CFG), the compatibility check is just equality of atomic symbols, and an instantiated daughter is merely the corresponding sub-constituent. However, unification-base"
E99-1029,P91-1042,0,0.0464762,"Missing"
E99-1029,P98-1061,1,0.726463,"any other more direct effects on parsing efficiency? On the one hand, it is a consequence of the EDOL that wide-coverage LTAGs are larger than their rule-based counterparts. With larger elementary structures, generalizations are lost regarding the internal structure of the elementary trees. Since parse time depends on g r a m m a r size, this could have an adverse effect on parsing efficiency. However, the problem of g r a m m a r size in TAG has to some extent been addressed both with respect to g r a m m a r encoding (Evans et al., 1995; Candito, 1996) and parsing (Joshi and Srinivas, 1994; Evans and Weir, 1998). On the other hand, if the EDOL hypothesis holds for those dependencies t h a t are being checked by the parser, then the burden of passing feature values around during parsing will be less than in a rule-based framework. If all dependencies that the parser is checking can be stated directly within the elementary structures of the g r a m m a r , they do not need to be computed dynamically during the parsing process by means of feature percolation. For example, there is no need to use a slash feature to establish filler-gap dependencies over unbounded distances across the tree if the EDOL Pro"
E99-1029,P95-1011,1,0.819731,"ed by a CFG can be generated by a lexicalized CFG. But does the EDOL have any other more direct effects on parsing efficiency? On the one hand, it is a consequence of the EDOL that wide-coverage LTAGs are larger than their rule-based counterparts. With larger elementary structures, generalizations are lost regarding the internal structure of the elementary trees. Since parse time depends on g r a m m a r size, this could have an adverse effect on parsing efficiency. However, the problem of g r a m m a r size in TAG has to some extent been addressed both with respect to g r a m m a r encoding (Evans et al., 1995; Candito, 1996) and parsing (Joshi and Srinivas, 1994; Evans and Weir, 1998). On the other hand, if the EDOL hypothesis holds for those dependencies t h a t are being checked by the parser, then the burden of passing feature values around during parsing will be less than in a rule-based framework. If all dependencies that the parser is checking can be stated directly within the elementary structures of the g r a m m a r , they do not need to be computed dynamically during the parsing process by means of feature percolation. For example, there is no need to use a slash feature to establish fil"
E99-1029,C94-1024,0,0.0291243,"G. But does the EDOL have any other more direct effects on parsing efficiency? On the one hand, it is a consequence of the EDOL that wide-coverage LTAGs are larger than their rule-based counterparts. With larger elementary structures, generalizations are lost regarding the internal structure of the elementary trees. Since parse time depends on g r a m m a r size, this could have an adverse effect on parsing efficiency. However, the problem of g r a m m a r size in TAG has to some extent been addressed both with respect to g r a m m a r encoding (Evans et al., 1995; Candito, 1996) and parsing (Joshi and Srinivas, 1994; Evans and Weir, 1998). On the other hand, if the EDOL hypothesis holds for those dependencies t h a t are being checked by the parser, then the burden of passing feature values around during parsing will be less than in a rule-based framework. If all dependencies that the parser is checking can be stated directly within the elementary structures of the g r a m m a r , they do not need to be computed dynamically during the parsing process by means of feature percolation. For example, there is no need to use a slash feature to establish filler-gap dependencies over unbounded distances across t"
E99-1029,C86-1016,0,0.1196,"Missing"
E99-1029,C90-2039,0,0.0524163,"Missing"
E99-1029,P85-1017,0,0.16914,"Missing"
E99-1029,P95-1021,1,0.821229,"ion of the tree in Figure 2 would cause the .feature structure at the node for the subject to'include pn:+. This, however, does not violate the EDOL hypothesis since this feature is not coreferenced with any other feature in the tree. 3 Analysis of two wide-coverage grammars As we have seen, the EDOL of LTAGs makes it possible, at least in principle, to locally express dependencies which cannot be localized in a CFGbased formalism. In this section we consider two existing grammars: the XTAG grammar, a widecoverage LTAG, and the LEXSYS grammar, a widecoverage D-Tree Substitution G r a m m a r (Rambow et al., 1995). For each g r a m m a r we investigate the extend to which they do not take full advantage of the EDOL and require percolation of features at parse time. There are a number of instances in which dependencies are not localized in the XTAG grammar, most of which involve auxiliary trees. There are Proceedings of EACL '99 three types of auxiliary trees: predicative, modifier and coordination auxiliary trees. In predicative auxiliary trees the anchor is also the head of the tree and becomes the head of the tree resulting from the adjunction. In modifier auxiliary trees, the anchor is not the head"
E99-1029,1995.iwpt-1.8,1,\N,Missing
E99-1029,W96-0209,1,\N,Missing
E99-1029,A94-1009,0,\N,Missing
E99-1029,C96-2183,0,\N,Missing
E99-1029,W97-1306,0,\N,Missing
E99-1029,P91-1041,0,\N,Missing
E99-1029,1991.iwpt-1.19,0,\N,Missing
E99-1029,C98-1059,1,\N,Missing
E99-1029,A97-2017,0,\N,Missing
E99-1042,W97-1306,0,0.03112,"Missing"
E99-1042,1995.iwpt-1.8,1,0.89087,"Missing"
E99-1042,W96-0209,1,0.877834,"Missing"
E99-1042,C96-2183,0,0.329297,"rland Echo, that is also pub<http://osiris.sunderland.ac.uk/~pset/welcome.html>. lished online. Thus, passive sentences such as The scheme was singled out by a recent Government report are found dicult3, despite the presence of the syntactic cues was, -ed and by. We therefore replace passive constructions with corresponding active forms. We are currently integrating further rules to split conjoined sentences and extract embedded clauses. Syntactic simpli cation operates iteratively until a con guration is reached that cannot be simpli ed. This approach is broadly similar to that proposed by (Chandrasekar et al., 1996). One of the many challenges in syntactic simpli cation is the observed e ect of the total length of a text being increased when longer sentences are replaced by multiple shorter ones. Also, the removal of cohesive devices such as conjunctions may result in anaphora crossing sentence boundaries. To maintain text coherence and cohesion (Grodzinsky et al., 1993) an anaphor is replaced by its referent if the containing sentence is split. Lexical Simpli er The lexical simpli er (based on (Devlin, 1999; Devlin and Tait, 1998)) replaces content words with simpler synonyms. It rst retrieves a set of"
E99-1042,C96-2187,0,0.0406021,"Missing"
E99-1042,A94-1009,0,0.0129308,"Missing"
H05-1053,W04-0811,0,\N,Missing
H05-1053,W04-0807,0,\N,Missing
H05-1053,rose-etal-2002-reuters,0,\N,Missing
H05-1053,H93-1061,0,\N,Missing
H05-1053,O97-1002,0,\N,Missing
H05-1053,briscoe-carroll-2002-robust,1,\N,Missing
H05-1053,P04-1036,1,\N,Missing
H05-1053,H92-1045,0,\N,Missing
H05-1053,P98-2127,0,\N,Missing
H05-1053,C98-2122,0,\N,Missing
H05-1053,magnini-cavaglia-2000-integrating,0,\N,Missing
H05-1053,P99-1004,0,\N,Missing
H05-1069,J94-4003,0,0.194512,"lingual approaches: useful data for some words cannot be collected because different senses of polysemous words in one language often translate to the same word in the other. Using parallel corpora can aggravate this problem, because even if a word sense in the source language has a unique translation in the target language, the translation may not occur in the parallel corpora at all, due to the limited size of this resource. To alleviate these problems, researchers seek other bilingual resources such as bilingual dictionaries, together with monolingual resources that can be obtained easily. Dagan and Itai (1994) proposed an approach to WSD using monolingual corpora, a bilingual lexicon and a parser for the source language. One of the problems of this method is that for many languages, accurate parsers do not exist. With a small amount of classified data and a large amount of unclassified data in both the source and the target languages, Li and Li (2004) proposed bilingual bootstrapping. This repeatedly constructs classifiers in the two languages in parallel and boosts the performance of the classifiers by classifying data in each of the languages and by exchanging information regarding the classified"
H05-1069,P02-1033,0,0.0318946,"ged data are available. However, supervised methods suffer from the so-called knowledge acquisition bottleneck: they need large quantities of high quality annotated data 1 This figure refers to the highest accuracy achieved in the Senseval-3 English Lexical Sample task with fine-grained scoring. In recent years, WSD approaches that exploit differences between languages have shown great promise. Several trends are taking place simultaneously under this multilingual paradigm. A classic one is to acquire sense examples using bilingual parallel texts (Gale et al., 1992; Resnik and Yarowsky, 1997; Diab and Resnik, 2002; Ng et al., 2003): given a word-aligned parallel corpus, the different translations in a target language serve as the “sense tags” of an ambiguous word in the source language. For example, Ng et al. (2003) acquired sense examples using English-Chinese parallel corpora, which were manually or automatically aligned at sentence level and then word-aligned using software. A manual selection of target translations was then performed, grouping together senses that share the same translation in Chinese. Finally, the occurrences of the word on the English side of the parallel 547 Proceedings of Human"
H05-1069,S01-1018,0,0.0712969,"Missing"
H05-1069,1992.tmi-1.9,0,0.225546,"ccuracy1 on words for which manually sense-tagged data are available. However, supervised methods suffer from the so-called knowledge acquisition bottleneck: they need large quantities of high quality annotated data 1 This figure refers to the highest accuracy achieved in the Senseval-3 English Lexical Sample task with fine-grained scoring. In recent years, WSD approaches that exploit differences between languages have shown great promise. Several trends are taking place simultaneously under this multilingual paradigm. A classic one is to acquire sense examples using bilingual parallel texts (Gale et al., 1992; Resnik and Yarowsky, 1997; Diab and Resnik, 2002; Ng et al., 2003): given a word-aligned parallel corpus, the different translations in a target language serve as the “sense tags” of an ambiguous word in the source language. For example, Ng et al. (2003) acquired sense examples using English-Chinese parallel corpora, which were manually or automatically aligned at sentence level and then word-aligned using software. A manual selection of target translations was then performed, grouping together senses that share the same translation in Chinese. Finally, the occurrences of the word on the Eng"
H05-1069,S01-1004,0,0.0499104,"ing data for WSD systems from raw monolingual Chinese text, it avoids the problem of the shortage of English sensetagged corpora, and also of the shortage of aligned bilingual corpora. Also, if existing corpora are not big enough, one can always harvest more text from the Web. However, like all methods based on the cross-language translation assumption mentioned above, there are potential problems. For ex549 3 Experiments and Results We firstly describe in detail how we prepared the sense examples and then describe a large scale WSD evaluation on the English Senseval-2 Lexical Sample dataset (Kilgarriff, 2001). The results show that our system trained with the sense examples achieved significantly better accuracy than comparable systems. We also show that when a little manual effort was invested in mapping the English word senses to Chinese monosemous translations, WSD performance improves accordingly. Based on further experiments on a standard binary WSD dataset, we also show that the technique scales up satisfactorily so that more sense examples help achieve better WSD accuracy. 3.1 Building Sense Examples Following the approach described in Section 2, we built sense examples for the 44 words in"
H05-1069,J04-1001,0,0.0467559,"cur in the parallel corpora at all, due to the limited size of this resource. To alleviate these problems, researchers seek other bilingual resources such as bilingual dictionaries, together with monolingual resources that can be obtained easily. Dagan and Itai (1994) proposed an approach to WSD using monolingual corpora, a bilingual lexicon and a parser for the source language. One of the problems of this method is that for many languages, accurate parsers do not exist. With a small amount of classified data and a large amount of unclassified data in both the source and the target languages, Li and Li (2004) proposed bilingual bootstrapping. This repeatedly constructs classifiers in the two languages in parallel and boosts the performance of the classifiers by classifying data in each of the languages and by exchanging information regarding the classified data between two languages. With a certain amount of manual work, they reported promising results, but evaluated on relatively small datasets. In previous work, we proposed to use Chinese monolingual corpora and Chinese-English bilingual dictionaries to acquire sense examples (Wang, 548 2004)2 . We evaluated the sense examples using a vector spa"
H05-1069,P04-1036,1,0.875396,"Missing"
H05-1069,W04-0807,0,0.233595,"Missing"
H05-1069,P03-1058,0,0.0420244,"However, supervised methods suffer from the so-called knowledge acquisition bottleneck: they need large quantities of high quality annotated data 1 This figure refers to the highest accuracy achieved in the Senseval-3 English Lexical Sample task with fine-grained scoring. In recent years, WSD approaches that exploit differences between languages have shown great promise. Several trends are taking place simultaneously under this multilingual paradigm. A classic one is to acquire sense examples using bilingual parallel texts (Gale et al., 1992; Resnik and Yarowsky, 1997; Diab and Resnik, 2002; Ng et al., 2003): given a word-aligned parallel corpus, the different translations in a target language serve as the “sense tags” of an ambiguous word in the source language. For example, Ng et al. (2003) acquired sense examples using English-Chinese parallel corpora, which were manually or automatically aligned at sentence level and then word-aligned using software. A manual selection of target translations was then performed, grouping together senses that share the same translation in Chinese. Finally, the occurrences of the word on the English side of the parallel 547 Proceedings of Human Language Technolo"
H05-1069,W97-0213,0,0.0172087,"or which manually sense-tagged data are available. However, supervised methods suffer from the so-called knowledge acquisition bottleneck: they need large quantities of high quality annotated data 1 This figure refers to the highest accuracy achieved in the Senseval-3 English Lexical Sample task with fine-grained scoring. In recent years, WSD approaches that exploit differences between languages have shown great promise. Several trends are taking place simultaneously under this multilingual paradigm. A classic one is to acquire sense examples using bilingual parallel texts (Gale et al., 1992; Resnik and Yarowsky, 1997; Diab and Resnik, 2002; Ng et al., 2003): given a word-aligned parallel corpus, the different translations in a target language serve as the “sense tags” of an ambiguous word in the source language. For example, Ng et al. (2003) acquired sense examples using English-Chinese parallel corpora, which were manually or automatically aligned at sentence level and then word-aligned using software. A manual selection of target translations was then performed, grouping together senses that share the same translation in Chinese. Finally, the occurrences of the word on the English side of the parallel 5"
H05-1069,P99-1068,0,0.0223174,"“sense tagged” by the appropriate Chinese translations. A classifier was trained on the extracted sense examples and then evaluated on the nouns in Senseval-2 English Lexical Sample dataset. The results appear good numerically, but since the sense groups are not in the gold standard, comparison with other Senseval-2 results is difficult. As discussed by Ng et al., there are several problems with relying on bilingual parallel corpora for data collection. First, parallel corpora, especially accurately aligned parallel corpora are rare, although attempts have been made to mine them from the Web (Resnik, 1999). Second, it is often not possible to distinguish all senses of a word in the source language, by merely relying on parallel corpora, especially when the corpora are relatively small. This is a common problem for bilingual approaches: useful data for some words cannot be collected because different senses of polysemous words in one language often translate to the same word in the other. Using parallel corpora can aggravate this problem, because even if a word sense in the source language has a unique translation in the target language, the translation may not occur in the parallel corpora at a"
H05-1069,P04-2005,1,0.81845,". We tried to analyse whether more sense examples acquired this way would improve WSD accuracy and also whether a little human effort on sense mapping could further improve WSD performance. The reminder of the paper is organised as follows. Section 2 outlines the acquisition algorithm for sense examples. Section 3 describes details of building this resource and demonstrates our application of sense examples to WSD. We also present results and analysis in this section. Finally, we conclude in Section 4 and talk about future work. 2 Acquisition of Sense Examples Following our previous proposal (Wang, 2004), we automatically acquire English sense examples using large quantities of Chinese text and English-Chinese and Chinese-English dictionaries. The Chinese language was chosen because it is a distant language from English and the more distant two languages are, the more likely that senses are lexicalised differently (Resnik and Yarowsky, 1999). The underlying assumption of this approach is that in general each sense of an ambiguous English word corresponds to a distinct translation in Chinese. As shown in Figure 1, firstly, the system translates senses of an English word into Chinese words, usi"
I05-1015,W02-1503,0,0.0307772,"a set of algorithmic refinements, we present two novel techniques: the integration of subsumption-based local ambiguity factoring, and a procedure to selectively unpack the generation forest according to a probability distribution given by a conditional, discriminative model. 1 Introduction A number of wide-coverage precise bi-directional NL grammars have been developed over the past few years. One example is the LinGO English Resource Grammar (ERG) [1], couched in the HPSG framework. Other grammars of similar size and coverage also exist, notable examples using the LFG and the CCG formalisms [2,3]. These grammars are used for generation from logical form input (also termed tactical generation or realization) in circumscribed domains, as part of applications such as spoken dialog systems [4] and machine translation [5]. Grammars like the ERG are lexicalist, in that the majority of information is encoded in lexical entries (or lexical rules) as opposed to being represented in constructions (i.e. rules operating on phrases). The semantic input to the generator for such grammars, often, is a bag of lexical predicates with semantic relationships captured by appropriate instantiation of vari"
I05-1015,2004.tmi-1.2,1,0.599826,"ion given by a conditional, discriminative model. 1 Introduction A number of wide-coverage precise bi-directional NL grammars have been developed over the past few years. One example is the LinGO English Resource Grammar (ERG) [1], couched in the HPSG framework. Other grammars of similar size and coverage also exist, notable examples using the LFG and the CCG formalisms [2,3]. These grammars are used for generation from logical form input (also termed tactical generation or realization) in circumscribed domains, as part of applications such as spoken dialog systems [4] and machine translation [5]. Grammars like the ERG are lexicalist, in that the majority of information is encoded in lexical entries (or lexical rules) as opposed to being represented in constructions (i.e. rules operating on phrases). The semantic input to the generator for such grammars, often, is a bag of lexical predicates with semantic relationships captured by appropriate instantiation of variables associated with predicates and their semantic roles. For these sorts of grammars and ‘flat’ semantic inputs, lexically-driven approaches to realization – such as Shake-and-Bake [6], bag generation from logical form [7],"
I05-1015,C92-2117,0,0.0138245,"og systems [4] and machine translation [5]. Grammars like the ERG are lexicalist, in that the majority of information is encoded in lexical entries (or lexical rules) as opposed to being represented in constructions (i.e. rules operating on phrases). The semantic input to the generator for such grammars, often, is a bag of lexical predicates with semantic relationships captured by appropriate instantiation of variables associated with predicates and their semantic roles. For these sorts of grammars and ‘flat’ semantic inputs, lexically-driven approaches to realization – such as Shake-and-Bake [6], bag generation from logical form [7], chart generation [8], and constraint-based generation [9] – are highly suitable. Alternative approaches based on semantic head-driven generation and more recent variants [10,11] would work less well for lexicalist grammars since these approaches assume a hierarchically structured input logical form. Similarly to parsing with large scale grammars, realization can be computationally expensive. In his presentation of chart generation, Kay [8] describes one source of potential inefficiency and proposes an approach for tackling it. However, Kay does not repor"
I05-1015,P96-1027,0,0.557912,"e ERG are lexicalist, in that the majority of information is encoded in lexical entries (or lexical rules) as opposed to being represented in constructions (i.e. rules operating on phrases). The semantic input to the generator for such grammars, often, is a bag of lexical predicates with semantic relationships captured by appropriate instantiation of variables associated with predicates and their semantic roles. For these sorts of grammars and ‘flat’ semantic inputs, lexically-driven approaches to realization – such as Shake-and-Bake [6], bag generation from logical form [7], chart generation [8], and constraint-based generation [9] – are highly suitable. Alternative approaches based on semantic head-driven generation and more recent variants [10,11] would work less well for lexicalist grammars since these approaches assume a hierarchically structured input logical form. Similarly to parsing with large scale grammars, realization can be computationally expensive. In his presentation of chart generation, Kay [8] describes one source of potential inefficiency and proposes an approach for tackling it. However, Kay does not report on a verification of his approach with an actual grammar."
I05-1015,P01-1028,0,0.0134666,"ority of information is encoded in lexical entries (or lexical rules) as opposed to being represented in constructions (i.e. rules operating on phrases). The semantic input to the generator for such grammars, often, is a bag of lexical predicates with semantic relationships captured by appropriate instantiation of variables associated with predicates and their semantic roles. For these sorts of grammars and ‘flat’ semantic inputs, lexically-driven approaches to realization – such as Shake-and-Bake [6], bag generation from logical form [7], chart generation [8], and constraint-based generation [9] – are highly suitable. Alternative approaches based on semantic head-driven generation and more recent variants [10,11] would work less well for lexicalist grammars since these approaches assume a hierarchically structured input logical form. Similarly to parsing with large scale grammars, realization can be computationally expensive. In his presentation of chart generation, Kay [8] describes one source of potential inefficiency and proposes an approach for tackling it. However, Kay does not report on a verification of his approach with an actual grammar. Carroll et al. [12]  Dan Flickinger"
I05-1015,J90-1004,0,0.245091,"ns (i.e. rules operating on phrases). The semantic input to the generator for such grammars, often, is a bag of lexical predicates with semantic relationships captured by appropriate instantiation of variables associated with predicates and their semantic roles. For these sorts of grammars and ‘flat’ semantic inputs, lexically-driven approaches to realization – such as Shake-and-Bake [6], bag generation from logical form [7], chart generation [8], and constraint-based generation [9] – are highly suitable. Alternative approaches based on semantic head-driven generation and more recent variants [10,11] would work less well for lexicalist grammars since these approaches assume a hierarchically structured input logical form. Similarly to parsing with large scale grammars, realization can be computationally expensive. In his presentation of chart generation, Kay [8] describes one source of potential inefficiency and proposes an approach for tackling it. However, Kay does not report on a verification of his approach with an actual grammar. Carroll et al. [12]  Dan Flickinger and Ann Copestake contributed a lot to the work described in this paper. We also thank Berthold Crysmann, Jan Tore Lønni"
I05-1015,W02-2106,0,0.0615891,"ns (i.e. rules operating on phrases). The semantic input to the generator for such grammars, often, is a bag of lexical predicates with semantic relationships captured by appropriate instantiation of variables associated with predicates and their semantic roles. For these sorts of grammars and ‘flat’ semantic inputs, lexically-driven approaches to realization – such as Shake-and-Bake [6], bag generation from logical form [7], chart generation [8], and constraint-based generation [9] – are highly suitable. Alternative approaches based on semantic head-driven generation and more recent variants [10,11] would work less well for lexicalist grammars since these approaches assume a hierarchically structured input logical form. Similarly to parsing with large scale grammars, realization can be computationally expensive. In his presentation of chart generation, Kay [8] describes one source of potential inefficiency and proposes an approach for tackling it. However, Kay does not report on a verification of his approach with an actual grammar. Carroll et al. [12]  Dan Flickinger and Ann Copestake contributed a lot to the work described in this paper. We also thank Berthold Crysmann, Jan Tore Lønni"
I05-1015,P99-1061,1,0.805095,"dreds or thousands of edges may be produced for non-trivial input semantics, but there are only a relatively small number of logical variables. Indexing edges on these variables involves bookkeeping that turns out not to be worthwhile in practice; logical bit vector operations on edge coverage take negligible time, and these serve to filter out the majority of edge combinations with incompatible indices. The remainder are filtered out efficiently before unification is attempted by a check on which rules can dominate which others, and the quick-check, as developed for unification-based parsing [14]. For the quick-check, it turns out that the same set of feature paths that most frequently lead to unification failure in parsing also work well in generation. 3 We therefore have four operations on bit vectors representing EP coverage (C) in chart edges: concatenation of edges e1 and e2 → e3 : C(e3 ) = OR(C(e1 ), C(e2 )); can edges e1 and e2 combine? AND(C(e1 ), C(e2 )) = 0; do edges e1 and e2 cover the same EPs? C(e1 ) = C(e2 ); do edges e1 , . . . , en cover all input EPs? NOT(OR(C(e1 ), . . . , C(en )) = 0. • • • • 170 J. Carroll and S. Oepen 3.2 Local Ambiguity Factoring In chart parsing"
I05-1015,P89-1018,0,0.233993,"= OR(C(e1 ), C(e2 )); can edges e1 and e2 combine? AND(C(e1 ), C(e2 )) = 0; do edges e1 and e2 cover the same EPs? C(e1 ) = C(e2 ); do edges e1 , . . . , en cover all input EPs? NOT(OR(C(e1 ), . . . , C(en )) = 0. • • • • 170 J. Carroll and S. Oepen 3.2 Local Ambiguity Factoring In chart parsing with context free grammars, the parse forest (a compact representation of the full set of parses) can only be computed in polynomial time if sub-analyses dominated by the same non-terminal and covering the same segment of the input string are ‘packed’, or factored into a single unitary representation [15]. Similar benefits accrue for unification grammars without a context free backbone such as the LinGO ERG, if the category equality test is replaced by feature structure subsumption [16]4 ; also, feature structures representing the derivation history need to be restricted out when applying a rule [17]. The technique can be applied to chart realization if the input span is expressed as coverage of the input semantics. For example, with the input of Figure 1, the two phrases in (2) below would have equivalent feature structures, and we pack the one found second into the one found first, which the"
I05-1015,A00-2022,1,0.90155,"(C(e1 ), . . . , C(en )) = 0. • • • • 170 J. Carroll and S. Oepen 3.2 Local Ambiguity Factoring In chart parsing with context free grammars, the parse forest (a compact representation of the full set of parses) can only be computed in polynomial time if sub-analyses dominated by the same non-terminal and covering the same segment of the input string are ‘packed’, or factored into a single unitary representation [15]. Similar benefits accrue for unification grammars without a context free backbone such as the LinGO ERG, if the category equality test is replaced by feature structure subsumption [16]4 ; also, feature structures representing the derivation history need to be restricted out when applying a rule [17]. The technique can be applied to chart realization if the input span is expressed as coverage of the input semantics. For example, with the input of Figure 1, the two phrases in (2) below would have equivalent feature structures, and we pack the one found second into the one found first, which then acts as the representative edge for all subsequent processing. (2) young Polish athlete |Polish young athlete We have found that packing is crucial to efficiency: realization time is"
I05-1015,P85-1018,0,0.2231,"h context free grammars, the parse forest (a compact representation of the full set of parses) can only be computed in polynomial time if sub-analyses dominated by the same non-terminal and covering the same segment of the input string are ‘packed’, or factored into a single unitary representation [15]. Similar benefits accrue for unification grammars without a context free backbone such as the LinGO ERG, if the category equality test is replaced by feature structure subsumption [16]4 ; also, feature structures representing the derivation history need to be restricted out when applying a rule [17]. The technique can be applied to chart realization if the input span is expressed as coverage of the input semantics. For example, with the input of Figure 1, the two phrases in (2) below would have equivalent feature structures, and we pack the one found second into the one found first, which then acts as the representative edge for all subsequent processing. (2) young Polish athlete |Polish young athlete We have found that packing is crucial to efficiency: realization time is improved by more than an order of magnitude for inputs with more than 500 realizations (see Section 4). Changing pac"
I05-1015,W02-2030,0,0.328106,"edges would be created that extended that phrase without the negation being present. Section 4 shows this technique results in dramatic improvements in realization efficiency. 3.5 Selective Unpacking The selective unpacking procedure outlined in this section allows us to extract a small set of n-best realizations from the generation forest at minimal cost. The global rank order is determined by a conditional Maximum Entropy (ME) model – essentially an adaptation of recent HPSG parse selection work to the realization ranking task [19]. We use a similar set of features to Toutanova and Manning [20], but our procedure differs from theirs in that it applies the stochastic model before unpacking, in a guided search through the generation forest. Thus, we avoid enumerating all candidate realizations. Unlike Malouf and van Noord [21], on the other hand, we avoid an approximative beam search during forest creation and guarantee to produce exactly the n-best realizations (according to the ME model). Further looking at related parse selection work, our procedure is probably most similar to those of Geman and Johnson [22] and Miyao and 5 Implementing collect-semantic-vars() can be efficient: sea"
I05-1015,P02-1036,0,0.060532,"nking task [19]. We use a similar set of features to Toutanova and Manning [20], but our procedure differs from theirs in that it applies the stochastic model before unpacking, in a guided search through the generation forest. Thus, we avoid enumerating all candidate realizations. Unlike Malouf and van Noord [21], on the other hand, we avoid an approximative beam search during forest creation and guarantee to produce exactly the n-best realizations (according to the ME model). Further looking at related parse selection work, our procedure is probably most similar to those of Geman and Johnson [22] and Miyao and 5 Implementing collect-semantic-vars() can be efficient: searching for Skolem constants throughout the full structure, it does a similar amount of computation as a single unification. 172 J. Carroll and S. Oepen 1 → 2 →    2 3 5 6   4 3  5 7     8 6 8 7 9 6 9 7    6 → 10 11 4 →  Fig. 2. Sample generator forest and sub-node decompositions: ovals in the forest (on the left) indicate packing of edges under subsumption, i.e. edges 4 , 7 , 9 , and 11 are not in the generator chart proper. During unpacking, there will be multiple ways of instantiating a chart edge,"
I08-1040,P02-1046,0,0.0159413,"this work uses a binary distinction, and supervised rather than unsupervised approaches. Recent work on classification of terms with respect to opinion (Esuli & Sebastiani, 2006) uses a three-category system to characterize the opinionrelated properties of word meanings, assigning numerical scores to Positive, Negative and Objective categories. The visualization of these scores somewhat resembles our graphs in Section 5, although we use two orthogonal scales rather than three categories; we are also concerned with classification of documents rather than terms. 2.2 Unsupervised Classification Abney (2002) compares two major kinds of unsupervised approach to classification (co-training and the Yarowsky algorithm). As we do not use multiple classifiers our approach is quite far from cotraining. But it is close to the paradigm described by Yarowsky (1995) and Turney (2002) as it also employs self-training based on a relatively small seed data set which is incrementally enlarged with unlabelled samples. But our approach does not use point-wise mutual information. Instead we use relative frequencies of newly found features in a training subcorpus produced by the previous iteration of the classifier"
I08-1040,esuli-sebastiani-2006-sentiwordnet,0,0.0733589,"oach was adopted by Hagedorn et al. (2007), applied to news stories: they defined five classes encoding sentiment intensity and trained their classifier on a manually tagged training corpus. They note that world knowledge is necessary for accurate classification in such open-ended domains. There has also been previous work on determining whether a given text is factual or expresses opinion (Yu & Hatzivassiloglu, 2003; Pang & Lee, 2004); again this work uses a binary distinction, and supervised rather than unsupervised approaches. Recent work on classification of terms with respect to opinion (Esuli & Sebastiani, 2006) uses a three-category system to characterize the opinionrelated properties of word meanings, assigning numerical scores to Positive, Negative and Objective categories. The visualization of these scores somewhat resembles our graphs in Section 5, although we use two orthogonal scales rather than three categories; we are also concerned with classification of documents rather than terms. 2.2 Unsupervised Classification Abney (2002) compares two major kinds of unsupervised approach to classification (co-training and the Yarowsky algorithm). As we do not use multiple classifiers our approach is qu"
I08-1040,W02-1011,0,0.0200584,"Missing"
I08-1040,P04-1035,0,0.133269,"and Lee use discrete classes (although more than two), not a continuum as in our approach, and use supervised machine learning rather than unsupervised techniques. A similar approach was adopted by Hagedorn et al. (2007), applied to news stories: they defined five classes encoding sentiment intensity and trained their classifier on a manually tagged training corpus. They note that world knowledge is necessary for accurate classification in such open-ended domains. There has also been previous work on determining whether a given text is factual or expresses opinion (Yu & Hatzivassiloglu, 2003; Pang & Lee, 2004); again this work uses a binary distinction, and supervised rather than unsupervised approaches. Recent work on classification of terms with respect to opinion (Esuli & Sebastiani, 2006) uses a three-category system to characterize the opinionrelated properties of word meanings, assigning numerical scores to Positive, Negative and Objective categories. The visualization of these scores somewhat resembles our graphs in Section 5, although we use two orthogonal scales rather than three categories; we are also concerned with classification of documents rather than terms. 2.2 Unsupervised Classifi"
I08-1040,P05-1015,0,0.0610351,"2 reviews related work in sentiment classification and more generally in unsupervised training of classifiers. Section 3 describes our datasets, and Section 4 the techniques we use for unsupervised classification and iterative retraining. Sections 5 and 6 describe a number of experiments into how well the approaches work, and Section 7 concludes. 2 2.1 Related Work Sentiment Classification Most previous work on the problem of categorizing opinionated texts has focused on the binary classification of positive and negative sentiment (Turney, 2002; Pang et al., 2002; Dave at al., 2003). However, Pang & Lee (2005) describe an approach closer to ours in which they determine an author&apos;s evaluation with respect to a multi-point scale, similar to the &apos;five-star&apos; sentiment scale widely used on review sites. However, authors of reviews are inconsistent in assigning fine-grained ratings and quite often star systems are not consistent between critics. This makes their approach very author-dependent. The main differences are that Pang and Lee use discrete classes (although more than two), not a continuum as in our approach, and use supervised machine learning rather than unsupervised techniques. A similar appro"
I08-1040,P05-2008,0,0.0985852,"aches based on supervised machine learning. With the rapid growth in textual data and the emergence of new domains of knowledge it is virtually impossible to maintain corpora of tagged data that cover all – or even most – areas of interest. The cost of manual tagging also adds to the problem. Reusing the same corpus for training classifiers for new domains is also not effective: several studies report decreased accuracy in cross-domain classification (Engström, 2004; Aue & Gamon, 2005) a similar problem has also been observed in classification of documents created over different time periods (Read, 2005). In this paper we describe an unsupervised classification technique which is able to build its own sentiment vocabulary starting from a very small seed vocabulary, using iterative retraining to enlarge the vocabulary. In order to avoid problems of domain dependence, the vocabulary is built using text from the same source as the text which is to be classified. In this paper we work with Chinese, but using a very small seed vocabulary may mean that this approach would in principle need very little linguistic adjustment to be applied to a different 305 language. Written Chinese has some specific"
I08-1040,P02-1053,0,0.0319546,"matical analysis. The paper is structured as follows. Section 2 reviews related work in sentiment classification and more generally in unsupervised training of classifiers. Section 3 describes our datasets, and Section 4 the techniques we use for unsupervised classification and iterative retraining. Sections 5 and 6 describe a number of experiments into how well the approaches work, and Section 7 concludes. 2 2.1 Related Work Sentiment Classification Most previous work on the problem of categorizing opinionated texts has focused on the binary classification of positive and negative sentiment (Turney, 2002; Pang et al., 2002; Dave at al., 2003). However, Pang & Lee (2005) describe an approach closer to ours in which they determine an author&apos;s evaluation with respect to a multi-point scale, similar to the &apos;five-star&apos; sentiment scale widely used on review sites. However, authors of reviews are inconsistent in assigning fine-grained ratings and quite often star systems are not consistent between critics. This makes their approach very author-dependent. The main differences are that Pang and Lee use discrete classes (although more than two), not a continuum as in our approach, and use supervised ma"
I08-1040,P95-1026,0,0.0613621,"rties of word meanings, assigning numerical scores to Positive, Negative and Objective categories. The visualization of these scores somewhat resembles our graphs in Section 5, although we use two orthogonal scales rather than three categories; we are also concerned with classification of documents rather than terms. 2.2 Unsupervised Classification Abney (2002) compares two major kinds of unsupervised approach to classification (co-training and the Yarowsky algorithm). As we do not use multiple classifiers our approach is quite far from cotraining. But it is close to the paradigm described by Yarowsky (1995) and Turney (2002) as it also employs self-training based on a relatively small seed data set which is incrementally enlarged with unlabelled samples. But our approach does not use point-wise mutual information. Instead we use relative frequencies of newly found features in a training subcorpus produced by the previous iteration of the classifier. We also use the smallest possible seed vocabulary, containing just a single word; however there are no restrictions regarding the maximum number of items in the seed vocabulary. 3 3.1 Data Seed Vocabulary Our approach starts out with a seed vocabular"
I08-1040,W03-1017,0,0.0596056,"Missing"
I13-1137,C96-1017,0,0.17637,"from root frequencies. Subsequently, the lexicons are iteratively improved by refining the morpheme strengths computed in the previous step. The paper is organized as follows. We survey previous related work (Section 2), and then give a brief introduction to Arabic root and pattern morphology (Section 3). We explain our basic technique for unsupervised lexicon induction in Section 4, followed by the refinement procedure (Section 5). Section 6 describes how the lexicon is used for morphological analysis. Finally, we present an evaluation (Section 7) and conclusions (Section 8). 2 Related Work Beesley (1996) describes one of the first morphological analysis systems for Arabic, based on finite-state techniques with manually acquired lexicons and rules. This kind of approach, although potentially producing an efficient and accurate system, is expensive in time and linguistic expertise, and lacks robustness in terms of extendibility to word types not in the dictionary (Ahmed, 2000). Darwish (2002) describes a semi-automatic technique that learns morphemes and induces rules for deriving stems using an existing dictionary of word and root pairs. It is an easy to build and fairly robust method of perfo"
I13-1137,N01-1024,0,0.0301925,"1012–1016, Nagoya, Japan, 14-18 October 2013. complex broken plural structure of Arabic as a test case. He employs memory-based algorithms, with the aim of gaining insights into human language acquisition. Other researchers have applied statistical and information-theoretic approaches to unsupervised learning of morphology from raw (unannotated) text corpora. Goldsmith (2000, 2006) and Cruetz and Lagus (2005, 2007) use the Minimum Description Length (MDL) principle, considering input data to be ‘compressed’ into a morphologically analysed representation. An alternative perspective adopted by Schone and Jurafsky (2001) induces semantic relatedness between word pairs by Latent Semantic Indexing. Most work on unsupervised learning of morphology has focused on concatenative morphology (Hammarström and Borin, 2011). Studies that have focussed on non-concatenative morphology include that of Rodriguez and Ćavar (2005), who learn roots from artificially generated text using a number of orthographic heuristics, and then apply constraint-based learning to improve the quality of the roots. Xanthos (2008) deciphers roots and patterns from phonetic transcriptions of Arabic text, using MDL to refine the root and pattern"
I13-1137,J11-2002,0,0.0272545,"acquisition. Other researchers have applied statistical and information-theoretic approaches to unsupervised learning of morphology from raw (unannotated) text corpora. Goldsmith (2000, 2006) and Cruetz and Lagus (2005, 2007) use the Minimum Description Length (MDL) principle, considering input data to be ‘compressed’ into a morphologically analysed representation. An alternative perspective adopted by Schone and Jurafsky (2001) induces semantic relatedness between word pairs by Latent Semantic Indexing. Most work on unsupervised learning of morphology has focused on concatenative morphology (Hammarström and Borin, 2011). Studies that have focussed on non-concatenative morphology include that of Rodriguez and Ćavar (2005), who learn roots from artificially generated text using a number of orthographic heuristics, and then apply constraint-based learning to improve the quality of the roots. Xanthos (2008) deciphers roots and patterns from phonetic transcriptions of Arabic text, using MDL to refine the root and pattern structures. Our work differs from these previous approaches in that (1) we learn intercalated morphology, identifying the root and transfixes/ incomplete pattern for words, and (2) we start from"
I13-1137,N09-1024,0,0.0544505,"Missing"
J03-4004,W99-0901,0,0.0636712,"ion to quantifying performance, we analyze the results to investigate the situations in which the selectional preferences achieve the best precision and in which the one-sense-per-discourse heuristic increases performance. 1. Introduction Although selectional preferences are a possible knowledge source in an automatic word sense disambiguation (WDS) system, they are not a panacea. One problem is coverage: Most previous work has focused on acquiring selectional preferences for verbs and applying them to disambiguate nouns occurring at subject and direct object slots (Ribas 1995; McCarthy 1997; Abney and Light 1999; Ciaramita and Johnson 2000; Stevenson and Wilks 2001). In normal running text, however, a large proportion of word tokens do not fall at these slots. There has been some work looking at other slots (Resnik 1997), and on using nominal arguments as disambiguators for verbs (Federici, Montemagni, and Pirrelli 1999; Agirre and Martinez 2001), but the problem of coverage remains. Selectional preferences can be used for WSD in combination with other knowledge sources (Stevenson and Wilks 2001), but there is a need to ascertain when they work well so that they can be utilized to their full advantag"
J03-4004,W01-0703,0,0.0550584,"Missing"
J03-4004,J93-1002,1,0.184643,"Missing"
J03-4004,1995.iwpt-1.8,1,0.845886,"Missing"
J03-4004,E99-1042,1,0.728329,"Missing"
J03-4004,C00-1028,0,0.139046,"formance, we analyze the results to investigate the situations in which the selectional preferences achieve the best precision and in which the one-sense-per-discourse heuristic increases performance. 1. Introduction Although selectional preferences are a possible knowledge source in an automatic word sense disambiguation (WDS) system, they are not a panacea. One problem is coverage: Most previous work has focused on acquiring selectional preferences for verbs and applying them to disambiguate nouns occurring at subject and direct object slots (Ribas 1995; McCarthy 1997; Abney and Light 1999; Ciaramita and Johnson 2000; Stevenson and Wilks 2001). In normal running text, however, a large proportion of word tokens do not fall at these slots. There has been some work looking at other slots (Resnik 1997), and on using nominal arguments as disambiguators for verbs (Federici, Montemagni, and Pirrelli 1999; Agirre and Martinez 2001), but the problem of coverage remains. Selectional preferences can be used for WSD in combination with other knowledge sources (Stevenson and Wilks 2001), but there is a need to ascertain when they work well so that they can be utilized to their full advantage. This article is aimed at"
J03-4004,A94-1009,0,0.0172762,"Missing"
J03-4004,J98-2002,0,0.0845227,"Missing"
J03-4004,W97-0808,1,0.843014,"erage. In addition to quantifying performance, we analyze the results to investigate the situations in which the selectional preferences achieve the best precision and in which the one-sense-per-discourse heuristic increases performance. 1. Introduction Although selectional preferences are a possible knowledge source in an automatic word sense disambiguation (WDS) system, they are not a panacea. One problem is coverage: Most previous work has focused on acquiring selectional preferences for verbs and applying them to disambiguate nouns occurring at subject and direct object slots (Ribas 1995; McCarthy 1997; Abney and Light 1999; Ciaramita and Johnson 2000; Stevenson and Wilks 2001). In normal running text, however, a large proportion of word tokens do not fall at these slots. There has been some work looking at other slots (Resnik 1997), and on using nominal arguments as disambiguators for verbs (Federici, Montemagni, and Pirrelli 1999; Agirre and Martinez 2001), but the problem of coverage remains. Selectional preferences can be used for WSD in combination with other knowledge sources (Stevenson and Wilks 2001), but there is a need to ascertain when they work well so that they can be utilized"
J03-4004,H93-1061,0,0.283296,"Missing"
J03-4004,P96-1006,0,0.013206,"Missing"
J03-4004,W02-0815,0,0.0206244,"yms, for example, substituting letter for missive. Our motivation for using WSD is to filter out inappropriate senses of a word token, so that the substituting synonym is appropriate given the context. For example, in the following sentence we would like to use strategy, rather than dodge, as a substitute for scheme: A recent government study singled out the scheme as an example to others. We are also investigating the disambiguation of verb senses in running text before subcategorization information for the verbs is acquired, in order to produce a subcategorization lexicon specific to sense (Preiss and Korhonen 2002). For example, if subcategorization were acquired specific to sense, rather than verb form, then distinct senses of fire could have different subcategorization entries: fire(1) - sack: fire(2) - shoot: NP V NP NP V NP, NP V Selectional preferences could also then be acquired automatically from sense-tagged data in an iterative approach (McCarthy 2001). 3. Methodology We acquire selectional preferences from automatically preprocessed and parsed text during a training phase. The parser is applied to the test data as well in the runtime phase to identify grammatical relations among nouns, verbs,"
J03-4004,W97-0209,0,0.306333,". 1. Introduction Although selectional preferences are a possible knowledge source in an automatic word sense disambiguation (WDS) system, they are not a panacea. One problem is coverage: Most previous work has focused on acquiring selectional preferences for verbs and applying them to disambiguate nouns occurring at subject and direct object slots (Ribas 1995; McCarthy 1997; Abney and Light 1999; Ciaramita and Johnson 2000; Stevenson and Wilks 2001). In normal running text, however, a large proportion of word tokens do not fall at these slots. There has been some work looking at other slots (Resnik 1997), and on using nominal arguments as disambiguators for verbs (Federici, Montemagni, and Pirrelli 1999; Agirre and Martinez 2001), but the problem of coverage remains. Selectional preferences can be used for WSD in combination with other knowledge sources (Stevenson and Wilks 2001), but there is a need to ascertain when they work well so that they can be utilized to their full advantage. This article is aimed at quantifying the disambiguation performance of automatically acquired selectional preferences in regard to nouns, verbs, and adjectives with respect to a standard test corpus and evaluat"
J03-4004,E95-1016,0,0.0149708,"racy and coverage. In addition to quantifying performance, we analyze the results to investigate the situations in which the selectional preferences achieve the best precision and in which the one-sense-per-discourse heuristic increases performance. 1. Introduction Although selectional preferences are a possible knowledge source in an automatic word sense disambiguation (WDS) system, they are not a panacea. One problem is coverage: Most previous work has focused on acquiring selectional preferences for verbs and applying them to disambiguate nouns occurring at subject and direct object slots (Ribas 1995; McCarthy 1997; Abney and Light 1999; Ciaramita and Johnson 2000; Stevenson and Wilks 2001). In normal running text, however, a large proportion of word tokens do not fall at these slots. There has been some work looking at other slots (Resnik 1997), and on using nominal arguments as disambiguators for verbs (Federici, Montemagni, and Pirrelli 1999; Agirre and Martinez 2001), but the problem of coverage remains. Selectional preferences can be used for WSD in combination with other knowledge sources (Stevenson and Wilks 2001), but there is a need to ascertain when they work well so that they c"
J03-4004,J01-3001,0,0.0222001,"ults to investigate the situations in which the selectional preferences achieve the best precision and in which the one-sense-per-discourse heuristic increases performance. 1. Introduction Although selectional preferences are a possible knowledge source in an automatic word sense disambiguation (WDS) system, they are not a panacea. One problem is coverage: Most previous work has focused on acquiring selectional preferences for verbs and applying them to disambiguate nouns occurring at subject and direct object slots (Ribas 1995; McCarthy 1997; Abney and Light 1999; Ciaramita and Johnson 2000; Stevenson and Wilks 2001). In normal running text, however, a large proportion of word tokens do not fall at these slots. There has been some work looking at other slots (Resnik 1997), and on using nominal arguments as disambiguators for verbs (Federici, Montemagni, and Pirrelli 1999; Agirre and Martinez 2001), but the problem of coverage remains. Selectional preferences can be used for WSD in combination with other knowledge sources (Stevenson and Wilks 2001), but there is a need to ascertain when they work well so that they can be utilized to their full advantage. This article is aimed at quantifying the disambiguat"
J07-4005,briscoe-carroll-2002-robust,1,0.276472,"Missing"
J07-4005,P89-1010,0,0.0609431,"e each word’s total feature frequency was at least 10. A thesaurus entry of size k for a target word w is then defined as the k most similar words to w. A large number of distributional similarity measures have been proposed in the literature (see Weeds 2003 for a review) and comparing them is outside the scope of this work. However, the study of Weeds and Weir (2005) provides interesting insights into what makes a “good” distributional similarity measure in the contexts of semantic similarity prediction and language modeling. In particular, weighting features by pointwise mutual information (Church and Hanks 1989) appears to be beneficial. The pointwise mutual information (I(w, f )) between a word and a feature is calculated as I(w, f ) = log P( f |w) P( f ) (3) Intuitively, this means that the occurrence of a less-common feature is more important in describing a word than a more-common feature. For example, the verb eat is more selective and tells us more about the meaning of its arguments than the verb be. 13 We use sss for the semantic similarity between a WordNet sense and another word, the neighbor. We use sss for the semantic similarity between two WordNet senses, si and a sense of the neighbor"
J07-4005,W03-1022,0,0.00935984,"redominance with automatically induced inventories such as those produced by CBC. Evaluation of induced inventories should be done in the context of an application, because the senses will be keyed to the acquisition corpus and not to WordNet. Induction of senses allows coverage of senses appearing in the data that are not present in a predefined inventory. Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns. 9 We used the demonstration at http://www.isi.edu/~pantel/Content/Demos/LexSem/cbc.htm with the option to include all corpora (TREC-2002, TREC-9, and COSMOS). 562 McCarthy, Koeling, Weeds, and Carroll Acquisition of Predominant Word Senses 4. Method In our method, the predominant sense for a target word is determined from a prevalence ranking of the possible senses for that word. The senses come from a predefined inventory (which might be a dictionary or WordNet-like resource). The ranking is derived using a distributional thesaurus automatically produ"
J07-4005,P05-1004,0,0.0109871,"duced inventories such as those produced by CBC. Evaluation of induced inventories should be done in the context of an application, because the senses will be keyed to the acquisition corpus and not to WordNet. Induction of senses allows coverage of senses appearing in the data that are not present in a predefined inventory. Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns. 9 We used the demonstration at http://www.isi.edu/~pantel/Content/Demos/LexSem/cbc.htm with the option to include all corpora (TREC-2002, TREC-9, and COSMOS). 562 McCarthy, Koeling, Weeds, and Carroll Acquisition of Predominant Word Senses 4. Method In our method, the predominant sense for a target word is determined from a prevalence ranking of the possible senses for that word. The senses come from a predefined inventory (which might be a dictionary or WordNet-like resource). The ranking is derived using a distributional thesaurus automatically produced from a large c"
J07-4005,P00-1064,0,0.0293393,"Missing"
J07-4005,H92-1045,0,0.395155,"Missing"
J07-4005,P05-1050,0,0.030912,"Missing"
J07-4005,O97-1002,0,0.0133586,"measure in the package with no normalizing for gloss length, and the default set of relations: lesk(s1, s2) = |{W1 ∈ definition(s1)} |∩ |{W2 ∈ definition(s2)}| (5) where definitions(s) is the gloss definition of sense s concatenated with the gloss definitions of the senses related to s where the relationships are defined by the de566 McCarthy, Koeling, Weeds, and Carroll Acquisition of Predominant Word Senses fault set of relations in the relations.dat file supplied with the WordNet Similarity package. W ∈ definition(s) is the set of words from the concatenated definitions. jcn This measure (Jiang and Conrath 1997) uses corpus data to populate classes (synsets) in the WordNet hierarchy with frequency counts. Each synset is incremented with the frequency counts (from the corpus) of all words belonging to that synset, directly or via the hyponymy relation. The frequency data is used to calculate the “information content” (IC; Resnik 1995) of a class as follows: IC(s) = −log(p(s)) (6) Jiang and Conrath specify a distance measure: Djcn (s1, s2) = IC(s1) + IC(s2) − 2 × IC(s3) (7) where the third class (s3) is the most informative, or most specific, superordinate synset of the two senses s1 and s2. This is co"
J07-4005,S07-1068,1,0.81821,"Missing"
J07-4005,H05-1053,1,0.810634,"Missing"
J07-4005,J04-1003,0,0.0393479,"elate to and weighting the contribution from these neighbors more. This may however give rise to further errors because of the noise introduced by focusing on individual neighbors. We will explore such directions in future work. 576 McCarthy, Koeling, Weeds, and Carroll Acquisition of Predominant Word Senses In this experiment we did not assign any credit for near misses. In many cases of error the SemCor FS nonetheless received a high prevalence score. In the future we hope to use the score for probability estimation, and combine this with contextual information for WSD as in related work by Lapata and Brew (2004) and Chan and Ng (2005). 6.2 Experiment 2: Frequency and the SemCor First Sense Heuristic In the previous section we described an evaluation of the accuracy of automatically acquired predominant sense information. We carried out the evaluation with respect to SemCor in order to have as much test data as possible. To obtain reasonably reliable gold-standard first-sense data and first-sense heuristic upper bounds, we limited the evaluation to words occurring at least three times in SemCor. Clearly this scenario is unrealistic. For many words, and particularly for nouns, there is very little or n"
J07-4005,P97-1009,0,0.0567575,"is in the future for using our ranking score for estimating probability distributions of senses, because a sufficiently large value of k will be needed to include neighbors for rarer senses. 565 Computational Linguistics Volume 33, Number 4 We chose to use the distributional similarity score described by Lin (1998a) because it is an unparameterized measure which uses pointwise mutual information to weight features and which has been shown (Weeds 2003) to be highly competitive in making predictions of semantic similarity. This measure is based on Lin’s information-theoretic similarity theorem (Lin 1997): The similarity between A and B is measured by the ratio between the amount of information needed to state the commonality of A and B and the information needed to fully describe what A and B are. In our application, if T(w) is the set of features f such that I(w, f ) is positive, then the similarity between two words, w and n, is    f ∈T(w)∩T(n) I(w, f ) + I(n, f )  dss(w, n) =  f ∈T(w) I(w, f ) + f ∈T(n) I(n, f ) (4) However, due to this choice of dss and the openness of the domain, we restrict ourselves to only considering words with a total feature frequency of at least 10. Weeds et"
J07-4005,P98-2127,0,0.763587,"tics Computational Linguistics Volume 33, Number 4 1. Introduction In word sense disambiguation, the “first sense” heuristic (choosing the first, or predominant sense of a word) is used by most state-of-the-art systems as a back-off method when information from the context is not sufficient to make a more informed choice. In this article, we present an in-depth study of a method for automatically acquiring predominant senses for words from raw text (McCarthy et al. 2004a). The method uses distributionally similar words listed as “nearest neighbors” in automatically acquired thesauruses (e.g., Lin 1998a), and takes advantage of the observation that the more prevalent a sense of a word, the more neighbors will relate to that sense, and the higher their distributional similarity scores will be. The senses of a word are defined in a sense inventory. We use WordNet (Fellbaum 1998) because this is widely used, is publicly available, and has plenty of gold-standard evaluation data available (Miller et al. 1993; Cotton et al. 2001; Preiss and Yarowsky 2001; Mihalcea and Edmonds 2004). The distributional strength of the neighbors is associated with the senses of a word using a measure of semantic s"
J07-4005,magnini-cavaglia-2000-integrating,0,0.0318076,"Missing"
J07-4005,S01-1027,0,0.0609412,"Missing"
J07-4005,W00-1326,0,0.0432788,"is based on lexicographer intuition, whereas in WordNet the senses are ordered according to their frequency in SemCor (Miller et al. 1993). There are two major problems with deriving a first sense heuristic from these types of resources. The first is that the predominant sense of a word varies according to the source of the document (McCarthy and Carroll 2003) and with the domain. For example, the first sense of star as derived from SemCor is celestial body, but if one were disambiguating popular news stories then celebrity would be more likely. Domain, topic, and genre are important in WSD (Martinez and Agirre 2000; Magnini et al. 2002) and the sense-frequency distributions of words depend on all of these factors. Any dictionary will provide only a single sense ranking, whether this is derived from sensetagged data as in WordNet, lexicographer intuition as in LDOCE, or inspection of corpus data as in the Oxford Advanced Learner’s Dictionary (Hornby 1989). A fixed order of senses may not reflect the data that an NLP system is dealing with. The second problem with obtaining predominant sense information applies to the use of hand-tagged resources, such as SemCor. Such resources are relatively small due to"
J07-4005,W06-2503,1,0.837506,"Missing"
J07-4005,J03-4004,1,0.708726,"Missing"
J07-4005,P04-1036,1,0.070666,"November 2005; revised submission received: 12 July 2006; accepted for publication 16 February 2007. © 2007 Association for Computational Linguistics Computational Linguistics Volume 33, Number 4 1. Introduction In word sense disambiguation, the “first sense” heuristic (choosing the first, or predominant sense of a word) is used by most state-of-the-art systems as a back-off method when information from the context is not sufficient to make a more informed choice. In this article, we present an in-depth study of a method for automatically acquiring predominant senses for words from raw text (McCarthy et al. 2004a). The method uses distributionally similar words listed as “nearest neighbors” in automatically acquired thesauruses (e.g., Lin 1998a), and takes advantage of the observation that the more prevalent a sense of a word, the more neighbors will relate to that sense, and the higher their distributional similarity scores will be. The senses of a word are defined in a sense inventory. We use WordNet (Fellbaum 1998) because this is widely used, is publicly available, and has plenty of gold-standard evaluation data available (Miller et al. 1993; Cotton et al. 2001; Preiss and Yarowsky 2001; Mihalcea"
J07-4005,W04-0837,1,0.0784347,"November 2005; revised submission received: 12 July 2006; accepted for publication 16 February 2007. © 2007 Association for Computational Linguistics Computational Linguistics Volume 33, Number 4 1. Introduction In word sense disambiguation, the “first sense” heuristic (choosing the first, or predominant sense of a word) is used by most state-of-the-art systems as a back-off method when information from the context is not sufficient to make a more informed choice. In this article, we present an in-depth study of a method for automatically acquiring predominant senses for words from raw text (McCarthy et al. 2004a). The method uses distributionally similar words listed as “nearest neighbors” in automatically acquired thesauruses (e.g., Lin 1998a), and takes advantage of the observation that the more prevalent a sense of a word, the more neighbors will relate to that sense, and the higher their distributional similarity scores will be. The senses of a word are defined in a sense inventory. We use WordNet (Fellbaum 1998) because this is widely used, is publicly available, and has plenty of gold-standard evaluation data available (Miller et al. 1993; Cotton et al. 2001; Preiss and Yarowsky 2001; Mihalcea"
J07-4005,S07-1009,1,0.14586,"Missing"
J07-4005,H93-1061,0,0.94556,"acquiring predominant senses for words from raw text (McCarthy et al. 2004a). The method uses distributionally similar words listed as “nearest neighbors” in automatically acquired thesauruses (e.g., Lin 1998a), and takes advantage of the observation that the more prevalent a sense of a word, the more neighbors will relate to that sense, and the higher their distributional similarity scores will be. The senses of a word are defined in a sense inventory. We use WordNet (Fellbaum 1998) because this is widely used, is publicly available, and has plenty of gold-standard evaluation data available (Miller et al. 1993; Cotton et al. 2001; Preiss and Yarowsky 2001; Mihalcea and Edmonds 2004). The distributional strength of the neighbors is associated with the senses of a word using a measure of semantic similarity which relies on the relationships between word senses, such as hyponyms (available in an inventory such as WordNet) or overlap in the definitions of word senses (available in most dictionaries), or both. In this article we provide a detailed discussion and quantitative analysis of the motivation behind the first sense heuristic, and a full description of our method. We extend previously reported w"
J07-4005,E06-1016,0,0.0343306,"Missing"
J07-4005,S07-1006,0,0.0392996,"Missing"
J07-4005,rose-etal-2002-reuters,0,0.0299999,"Missing"
J07-4005,W04-0811,0,0.114906,"bout 2,000 words, from the Brown corpus (Francis and Kuˇcera 1979) and the complete text of a 19th-century American novel, The Red Badge of Courage, which totals 45,600 words (Landes, Leacock, and Tengi 1998). Approximately half of the words in this corpus are open-class words (nouns, verbs, adjectives, and adverbs) and these have been linked to WordNet senses by human taggers using a software interface. The shortage of training data due to the high costs of tagging texts has motivated research into unsupervised methods for WSD. But in the English all-words tasks in Senseval-2 and Senseval-3 (Snyder and Palmer 2004), systems that did not make use of hand-tagged data (in some form or other) performed substantially worse than those that did. Table 1 summarizes the situation. It gives the precision and recall of the best1 two supervised (S) and unsupervised (U)2 systems for the English all words and English lexical sample for Senseval-23 and -3, along with the first sense baseline (FS) reported by the task organizers.4 This is a simple application of the “first sense” heuristic—that is, using the most common sense of a word for every instance of it in the test corpus, regardless of context. Although context"
J07-4005,J01-3001,0,0.00781404,"discuss directions for future work (Section 8). 2. Motivation The problem of disambiguating the meanings of words in text has received much attention recently, particularly since the inception of the Senseval evaluation exercises (Kilgarriff and Palmer 2000; Preiss and Yarowsky 2001; Mihalcea and Edmonds 2004). One of the standard Senseval tasks (the “all words” task) is to tag each open class word with one of its senses, as listed in a dictionary or thesaurus such as WordNet (Fellbaum 1998). The most accurate word sense disambiguation (WSD) systems use supervised machine learning approaches (Stevenson and Wilks 2001), trained on text which has been sense tagged by hand. However, the performance of these systems is strongly 555 Computational Linguistics Volume 33, Number 4 dependent on the quantity of training data available (Yarowsky and Florian 2002), and manually sense-annotated text is extremely costly to produce (Kilgarriff 1998). The largest all words sense tagged corpus is SemCor, which is 220,000 words taken from 103 passages, each of about 2,000 words, from the Brown corpus (Francis and Kuˇcera 1979) and the complete text of a 19th-century American novel, The Red Badge of Courage, which totals 45,"
J07-4005,J05-4002,1,0.911399,"eatures, f , each with an associated frequency, where each feature is a pair r, x consisting of a grammatical relation name and the other word in the relation. We computed distributional similarity scores for every pair of words of the same PoS where each word’s total feature frequency was at least 10. A thesaurus entry of size k for a target word w is then defined as the k most similar words to w. A large number of distributional similarity measures have been proposed in the literature (see Weeds 2003 for a review) and comparing them is outside the scope of this work. However, the study of Weeds and Weir (2005) provides interesting insights into what makes a “good” distributional similarity measure in the contexts of semantic similarity prediction and language modeling. In particular, weighting features by pointwise mutual information (Church and Hanks 1989) appears to be beneficial. The pointwise mutual information (I(w, f )) between a word and a feature is calculated as I(w, f ) = log P( f |w) P( f ) (3) Intuitively, this means that the occurrence of a less-common feature is more important in describing a word than a more-common feature. For example, the verb eat is more selective and tells us mor"
J07-4005,J90-1003,0,\N,Missing
J07-4005,C98-2122,0,\N,Missing
J10-1007,P06-2006,1,0.879284,"Missing"
J10-1007,J07-4004,0,0.0740923,"Missing"
J10-1007,W03-2401,0,0.0695947,"Missing"
J11-3004,W03-2405,0,0.140806,"Missing"
J11-3004,W06-2922,0,0.801563,"example, the algorithm of Kahane, Nasr, and Rambow (1998) uses a strategy similar to Lombardo and Lesmo (1996), but with the following initializer step instead of the I NITTER and P REDICTOR: I NITTER : [A(•α ), i, i − 1] A(α ) ∈ P ∧ 1 ≤ i ≤ n The initialization step speciﬁed by Kahane, Nasr, and Rambow (1998) differs from this (directly consuming a nonterminal from the input) but this gives an incomplete algorithm. The problem can be ﬁxed either by using the step shown here instead (bottom–up Earley strategy) or by adding an additional step turning it into a bottom–up left-corner parser. 6.2 Attardi (2006) The non-projective parser of Attardi (2006) extends the algorithm of Yamada and Matsumoto (2003), adding additional shift and reduce actions to handle non-projective dependency structures. These extra actions allow the parser to link to nodes that are several positions deep in the stack, creating non-projective links. In particular, Attardi uses six non-projective actions: two actions to link to nodes that are two positions deep, another two actions for nodes that are three positions deep, and a third pair of actions that generalizes the previous ones to n positions deep for any n. Thus, the"
J11-3004,W98-0507,0,0.655301,"dings of intermediate dependency structures are deﬁned as items, and the operations used to combine them are expressed as inference rules. We begin by addressing a number of preliminary issues. Traditional parsing schemata are used to deﬁne grammar-driven parsers, in which the parsing process is guided by some set of rules which are used to license deduction steps. For example, an Earley P REDICTOR step is tied to a particular grammar rule, and can only be executed if such a rule exists. Some dependency parsers are also grammardriven. For example, those described by Lombardo and Lesmo (1996), Barbero et al. (1998), and Kahane, Nasr, and Rambow (1998) are based on the formalizations of dependency grammar CFG-like rules described by Hays (1964) and Gaifman (1965). However, many of the algorithms (Eisner 1996; Yamada and Matsumoto 2003) are not traditionally considered to be grammar-driven, because they do not use an explicit formal grammar; decisions about which dependencies to create are taken individually, using probabilistic models (Eisner 1996) or classiﬁers (Yamada and Matsumoto 2003). These are called data-driven parsers. To express such algorithms as deduction systems, we use the notion of D-rules"
J11-3004,P89-1018,0,0.318893,"ditions for the parser’s deduction steps. Side conditions restrict the inference relation by specifying which combinations of values are permissible for the variables appearing in the antecedents and consequent of deduction steps. This parsing schema speciﬁes a recognizer: Given a set of D-rules and an input string w1 . . . wn , the sentence can be parsed (projectively) under those D-rules if and only if the deduction system infers a coherent ﬁnal item. When executing this schema with a deductive engine, the parse forest can be recovered by following back pointers, as in constituency parsers (Billot and Lang 1989). This schema formalizes a parsing logic which is independent of the order and the way linking decisions are taken. Statistical models can be used to determine whether a step linking words a and b in positions i and j—i.e., having (a, i) → (b, j) as a side condition—is executed or not, and probabilities can be attached to items in order to assign different weights to different analyses of the sentence. The side conditions provide an explicit representation of the choice points where probabilistic decisions are made by the control mechanism that is executing the schema. The same principle appli"
J11-3004,W08-2134,0,0.0122277,"MHk parser has the property of being able to parse any possible dependency structure as long as we make k large enough. 6.4 MST Parser (McDonald et al. 2005) McDonald et al. (2005) describe a parser which ﬁnds a nonprojective analysis for a sentence in O(n2 ) time under a strong independence assumption called an edgefactored model: Each dependency decision is assumed to be independent of all the others (McDonald and Satta 2007). Despite the restrictiveness of this model, this maximum spanning tree (MST) parser achieves state-of-the-art performance for projective and non-projective structures (Che et al. 2008; Nivre and McDonald 2008; Surdeanu et al. 2008). The parser considers the weighted graph formed by all the possible dependencies between pairs of input words, and applies an MST algorithm to ﬁnd a dependency tree covering all the words in the sentence and maximizing the sum of weights. The MST algorithm for directed graphs suggested by McDonald et al. (2005) is not fully constructive: It does not work by building structures and combining them into large structures until it ﬁnds the solution. Instead, the algorithm works by using a greedy strategy to select a candidate set of edges for the spa"
J11-3004,P96-1025,0,0.65053,"nal) items are called correct (ﬁnal) items in the original formulation by Sikkel (1997). 3 Derivable items are called valid items in the original formulation by Sikkel (1997). 545 Computational Linguistics Volume 37, Number 3 Figure 2 Representation of the [i, j, h] item in Collins’s parser, together with one of the dependency structures contained in it (left side); and of the antecedents and consequents of an L-L INK step (right side). White rectangles in an item represent intervals of nodes that have been assigned a head by the parser, and dark squares represent nodes that have no head. 3.1 Collins (1996) One of the most straightforward projective dependency parsing strategies was introduced by Collins (1996), and is based on the CYK bottom–up parsing strategy (Kasami 1965; Younger 1967). Collins’s parser works with dependency trees which are linked to each other by creating links between their heads. The schema for this parser maps every set of D-rules G and input string w1 . . . wn to an instantiated dependency parsing system (ICol96 , H, DCol96 ) such that: Item set: The item set is deﬁned as ICol96 = {[i, j, h] |1 ≤ i ≤ h ≤ j ≤ n}, where item [i, j, h] is deﬁned as the set of forests conta"
J11-3004,N06-1021,0,0.0131231,"number of free variables used in deduction steps of Collins’s parser, it is apparent that its time complexity is O(n5 ): There are O(n5 ) combinations of index values with which each of its L INK steps can be executed.5 This complexity arises because a parentless word (head) may appear in any position in the items generated by the parser; the complexity can be reduced to O(n3 ) by ensuring that parentless words only appear at the ﬁrst or last position of an item. This is the idea behind the parser deﬁned by Eisner (1996), which is still in wide use today (McDonald, Crammer, and Pereira 2005; Corston-Oliver et al. 2006). The parsing schema for this algorithm is deﬁned as follows. Item set: The item set is IEis96 = {[i, j, True, False] |0 ≤ i ≤ j ≤ n} ∪ {[i, j, False, True] |0 ≤ i ≤ j ≤ n} ∪{[i, j, False, False] |0 ≤ i ≤ j ≤ n}, where item [i, j, True, False] corresponds to [i, j, j] ∈ ICol96 , item [i, j, False, True] corresponds to item [i, j, i] ∈ ICol96 , and item [i, j, False, False] is deﬁned as the set of forests 5 For this and the rest of the complexity results in this article, we assume that the linking decision associated with a D-rule can be made in constant time. 547 Computational Linguistics Volu"
J11-3004,W98-0511,0,0.113846,"LETER : [A(αB • β ), i, k] Final items: The ﬁnal item set is {[(S• ), 1, n]}. The schema for Lombardo and Lesmo’s parser is a variant of the Earley constituency parser (cf. Sikkel 1997), with minor changes to adapt it to dependency grammar (for example, the S CANNER always moves the dot over the head symbol ∗, rather than over a terminal symbol). Analogously, other dependency parsing schemata based on CFG-like rules can be obtained by modifying CFG parsing schemata of Sikkel (1997): The algorithm of Barbero et al. (1998) can be obtained from the left-corner parser, and the parser described by Courtin and Genthial (1998) is a variant of the head-corner parser. 3.6 Nivre (2003) Nivre (2003) describes a shift-reduce algorithm for projective dependency parsing, later extended by Nivre, Hall, and Nilsson (2004). With linear-time performance and competitive parsing accuracy (Nivre et al. 2006; Nivre and McDonald 2008), it is one of the parsers included in the MaltParser system (Nivre et al. 2007), which is currently widely used (e.g., Nivre et al. 2007; Surdeanu et al. 2008). The parser proceeds by reading the sentence from left to right, using a stack and four different kinds of transitions between conﬁgurations."
J11-3004,P04-1054,0,0.0273384,"in time O(n4+3k ). Finally, we illustrate how the parsing schema framework can be applied to Link Grammar, a dependency-related formalism. 1. Introduction Dependency parsing involves ﬁnding the structure of a sentence as expressed by a set of directed links (called dependencies) between individual words. Dependency formalisms have attracted considerable interest in recent years, having been successfully applied to tasks such as machine translation (Ding and Palmer 2005; Shen, Xu, and ˜ Weischedel 2008), textual entailment recognition (Herrera, Penas, and Verdejo 2005), ¨ relation extraction (Culotta and Sorensen 2004; Fundel, Kuffner, and Zimmer 2006), and question answering (Cui et al. 2005). Key characteristics of the dependency parsing approach are that dependency structures specify head–modiﬁer and head–complement relationships, which form the basis of predicate–argument structure, but are not represented explicitly in constituency trees; there is no need for dependency parsers to postulate the existence of non-lexical nodes; and some variants of dependency parsers ˜ Campus de Elvina, ˜ s/n, 15071 A Coruna, ˜ Spain. ∗ Facultade de Inform´atica, Universidade da Coruna E-mail: cgomezr@udc.es. ∗∗ School"
J11-3004,P05-1067,0,0.0289662,"t includes all gap degree k structures present in several natural language treebanks (which we call mildly ill-nested structures for gap degree k) in time O(n4+3k ). Finally, we illustrate how the parsing schema framework can be applied to Link Grammar, a dependency-related formalism. 1. Introduction Dependency parsing involves ﬁnding the structure of a sentence as expressed by a set of directed links (called dependencies) between individual words. Dependency formalisms have attracted considerable interest in recent years, having been successfully applied to tasks such as machine translation (Ding and Palmer 2005; Shen, Xu, and ˜ Weischedel 2008), textual entailment recognition (Herrera, Penas, and Verdejo 2005), ¨ relation extraction (Culotta and Sorensen 2004; Fundel, Kuffner, and Zimmer 2006), and question answering (Cui et al. 2005). Key characteristics of the dependency parsing approach are that dependency structures specify head–modiﬁer and head–complement relationships, which form the basis of predicate–argument structure, but are not represented explicitly in constituency trees; there is no need for dependency parsers to postulate the existence of non-lexical nodes; and some variants of depend"
J11-3004,C96-1058,0,0.108842,"parsing schemata are used to deﬁne grammar-driven parsers, in which the parsing process is guided by some set of rules which are used to license deduction steps. For example, an Earley P REDICTOR step is tied to a particular grammar rule, and can only be executed if such a rule exists. Some dependency parsers are also grammardriven. For example, those described by Lombardo and Lesmo (1996), Barbero et al. (1998), and Kahane, Nasr, and Rambow (1998) are based on the formalizations of dependency grammar CFG-like rules described by Hays (1964) and Gaifman (1965). However, many of the algorithms (Eisner 1996; Yamada and Matsumoto 2003) are not traditionally considered to be grammar-driven, because they do not use an explicit formal grammar; decisions about which dependencies to create are taken individually, using probabilistic models (Eisner 1996) or classiﬁers (Yamada and Matsumoto 2003). These are called data-driven parsers. To express such algorithms as deduction systems, we use the notion of D-rules (Covington 1990). D-rules have the form (a, i) → (b, j), which speciﬁes that a word b located at position j in the input string can have the word a in position i as a dependent. Deduction steps i"
J11-3004,H05-1036,0,0.112317,"Missing"
J11-3004,P99-1059,0,0.152783,"PANS step is used to join two items that overlap at a single word, which must have a parent in only one of the items, so that the result of joining trees coming from both items (without creating any dependency link) is a well-formed dependency tree. Final items: The set of ﬁnal items is {[0, n, False, True]}. Note that these items represent dependency trees rooted at the beginning-of-sentence marker 0, which acts as a “dummy head” for the sentence. In order for the algorithm to parse sentences correctly, we need to deﬁne D-rules to allow the real sentence head to be linked to the node 0. 3.3 Eisner and Satta (1999) Eisner and Satta (1999) deﬁne an O(n3 ) parser for split head automaton grammars which can be used for dependency parsing. This algorithm is conceptually simpler than Eisner’s (1996) algorithm, because it only uses items representing single dependency trees, avoiding items of the form [i, j, False, False]. Item set: The item set is IES99 = {[i, j, i] |0 ≤ i ≤ j ≤ n} ∪ {[i, j, j] |0 ≤ i ≤ j ≤ n}, where items are deﬁned as in Collins’s parsing schema. Deduction steps: The deduction steps for this parser are the following: [i, j, i] [ j + 1, k, k] R-L INK : (wi , i) → (wk , k) [i, k, k] [i, j, i"
J11-3004,W00-2011,0,0.793589,"isms. Developing efﬁcient dependency parsing strategies for these sets of structures has considerable practical interest, in particular, making it possible to parse directly with dependencies in a data-driven manner rather than indirectly by constructing intermediate constituency grammars and extracting dependencies from constituency parses. In this section, we make four contributions to this enterprise. Firstly, we deﬁne a parser for well-nested structures of gap degree 1, and prove its correctness. The parser runs in time O(n7 ), the same complexity as the best existing algorithms for LTAG (Eisner and Satta 2000), and can be optimized to O(n6 ) in the nonlexicalized case. Secondly, we generalize our algorithm to any well-nested dependency structure with gap degree at most k, resulting in an algorithm with time complexity O(n5+2k ). Thirdly, we generalize the previous parsers in order to include ill-nested structures with gap degree at most k satisfying certain constraints, giving a parser that runs in time O(n4+3k ). Note that parsing unrestricted ill-nested structures, even when the gap degree is bounded, is NP-complete: These structures are equivalent to LCFRS for which the recognition problem is NP"
J11-3004,P08-1110,1,0.88419,"Missing"
J11-3004,N09-1061,1,0.809783,"ures that we call mildly ill-nested for a given gap degree k, and presented an algorithm that can parse these in time O(n3k+4 ). The practical relevance of this set of structures can be seen in the data obtained from several dependency treebanks, showing that all the sentences contained in them are mildly ill-nested for their gap degree, and thus they are parsable with this algorithm. The strategy used by this algorithm for parsing mildly ill-nested structures has been adapted to solve the problem of ﬁnding minimal fan-out binarizations of LCFRS to improve parsing ´ efﬁciency (see Gomez-Rodr´ ıguez et al. 2009). An interesting line of future work would be to provide implementations of the mildly non-projective dependency parsers presented here, using probabilistic models to guide their linking decisions, and compare their practical performance and accuracy to those of other non-projective dependency parsers. Additionally, our deﬁnition of mildly ill-nested structures is closely related to the way the corresponding parser works. It would be interesting to ﬁnd a more grammar-oriented deﬁnition that would provide linguistic insight into this set of structures. An alternative generalization of the conce"
J11-3004,E09-1034,1,0.563747,"ures that we call mildly ill-nested for a given gap degree k, and presented an algorithm that can parse these in time O(n3k+4 ). The practical relevance of this set of structures can be seen in the data obtained from several dependency treebanks, showing that all the sentences contained in them are mildly ill-nested for their gap degree, and thus they are parsable with this algorithm. The strategy used by this algorithm for parsing mildly ill-nested structures has been adapted to solve the problem of ﬁnding minimal fan-out binarizations of LCFRS to improve parsing ´ efﬁciency (see Gomez-Rodr´ ıguez et al. 2009). An interesting line of future work would be to provide implementations of the mildly non-projective dependency parsers presented here, using probabilistic models to guide their linking decisions, and compare their practical performance and accuracy to those of other non-projective dependency parsers. Additionally, our deﬁnition of mildly ill-nested structures is closely related to the way the corresponding parser works. It would be interesting to ﬁnd a more grammar-oriented deﬁnition that would provide linguistic insight into this set of structures. An alternative generalization of the conce"
J11-3004,P07-1077,0,0.188126,"m called regular dependency grammars. This deduction system can easily be converted into a parsing schema by associating adequate semantics with items. However, we do not show this here for space reasons, because we would ﬁrst have to explain the formalism of regular dependency grammars. 7. Mildly Non-Projective Dependency Parsing For reasons of computational efﬁciency, many practical implementations of dependency parsing are restricted to projective structures. However, some natural language sentences appear to have non-projective syntactic structure, something that arises in many languages (Havelka 2007), and is particularly common in free word order languages such as Czech. Parsing without the projectivity constraint is computationally complex: Although it is possible to parse non-projective structures in quadratic time with respect to input length under a model in which each dependency decision is independent of all the others (as in the parser of McDonald et al. [2005], discussed in Section 6.4), the problem is intractable in the absence of this assumption (McDonald and Satta 2007). Nivre and Nilsson (2005) observe that most non-projective dependency structures appearing in practice contai"
J11-3004,P98-1106,0,0.567797,"Missing"
J11-3004,P07-1021,0,0.460103,"h n. Note that this parsing schema is not correct, because Covington’s algorithm does not prevent the generation of cycles in the dependency graphs it produces. Quoting Covington (2001, page 99), Because the parser operates one word at a time, unity can only be checked at the end of the whole process: did it produce a tree with a single root that comprises all of the words? Therefore, a postprocessing mechanism is needed to determine which of the generated structures are, in fact, valid trees. In the parsing schema, this is reﬂected by the fact that the schema is complete but not sound. Nivre (2007) uses a variant of this algorithm in which cycle detection is used to avoid generating incorrect structures. Other non-projective parsers not covered here can also be represented under the parsing schema framework. For example, Kuhlmann (2010) presents a deduction system for a non-projective parser which uses a grammar formalism called regular dependency grammars. This deduction system can easily be converted into a parsing schema by associating adequate semantics with items. However, we do not show this here for space reasons, because we would ﬁrst have to explain the formalism of regular dep"
J11-3004,P06-2066,0,0.60887,"Missing"
J11-3004,C96-2122,0,0.453149,"a framework, where the encodings of intermediate dependency structures are deﬁned as items, and the operations used to combine them are expressed as inference rules. We begin by addressing a number of preliminary issues. Traditional parsing schemata are used to deﬁne grammar-driven parsers, in which the parsing process is guided by some set of rules which are used to license deduction steps. For example, an Earley P REDICTOR step is tied to a particular grammar rule, and can only be executed if such a rule exists. Some dependency parsers are also grammardriven. For example, those described by Lombardo and Lesmo (1996), Barbero et al. (1998), and Kahane, Nasr, and Rambow (1998) are based on the formalizations of dependency grammar CFG-like rules described by Hays (1964) and Gaifman (1965). However, many of the algorithms (Eisner 1996; Yamada and Matsumoto 2003) are not traditionally considered to be grammar-driven, because they do not use an explicit formal grammar; decisions about which dependencies to create are taken individually, using probabilistic models (Eisner 1996) or classiﬁers (Yamada and Matsumoto 2003). These are called data-driven parsers. To express such algorithms as deduction systems, we us"
J11-3004,P05-1012,0,0.551096,"˜ s/n, 15071 A Coruna, ˜ Spain. ∗ Facultade de Inform´atica, Universidade da Coruna E-mail: cgomezr@udc.es. ∗∗ School of Informatics, University of Sussex, Falmer, Brighton BN1 9QJ, UK. E-mail: J.A.Carroll@sussex.ac.uk. † School of Informatics, University of Sussex, Falmer, Brighton BN1 9QJ, UK. E-mail: D.J.Weir@sussex.ac.uk. Submission received: 21 October 2009; revised submission received: 23 December 2010; accepted for publication: 29 January 2011. © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 3 are able to represent non-projective structures (McDonald et al. 2005), which is important when parsing free word order languages where discontinuous constituents are common. The formalism of parsing schemata, introduced by Sikkel (1997), is a useful tool for the study of constituency parsers, supporting precise, high-level descriptions of parsing algorithms. Potential applications of parsing schemata include devising correctness proofs, extending our understanding of relationships between different algorithms, deriving new variants of existing algorithms, and obtaining efﬁcient implementations ´ automatically (Gomez-Rodr´ ıguez, Vilares, and Alonso 2009). The f"
J11-3004,D07-1013,0,0.145043,"h n. Note that this parsing schema is not correct, because Covington’s algorithm does not prevent the generation of cycles in the dependency graphs it produces. Quoting Covington (2001, page 99), Because the parser operates one word at a time, unity can only be checked at the end of the whole process: did it produce a tree with a single root that comprises all of the words? Therefore, a postprocessing mechanism is needed to determine which of the generated structures are, in fact, valid trees. In the parsing schema, this is reﬂected by the fact that the schema is complete but not sound. Nivre (2007) uses a variant of this algorithm in which cycle detection is used to avoid generating incorrect structures. Other non-projective parsers not covered here can also be represented under the parsing schema framework. For example, Kuhlmann (2010) presents a deduction system for a non-projective parser which uses a grammar formalism called regular dependency grammars. This deduction system can easily be converted into a parsing schema by associating adequate semantics with items. However, we do not show this here for space reasons, because we would ﬁrst have to explain the formalism of regular dep"
J11-3004,H05-1066,0,0.575344,"Missing"
J11-3004,W07-2216,0,0.686108,"Missing"
J11-3004,W03-3017,0,0.804804,"n]}. The schema for Lombardo and Lesmo’s parser is a variant of the Earley constituency parser (cf. Sikkel 1997), with minor changes to adapt it to dependency grammar (for example, the S CANNER always moves the dot over the head symbol ∗, rather than over a terminal symbol). Analogously, other dependency parsing schemata based on CFG-like rules can be obtained by modifying CFG parsing schemata of Sikkel (1997): The algorithm of Barbero et al. (1998) can be obtained from the left-corner parser, and the parser described by Courtin and Genthial (1998) is a variant of the head-corner parser. 3.6 Nivre (2003) Nivre (2003) describes a shift-reduce algorithm for projective dependency parsing, later extended by Nivre, Hall, and Nilsson (2004). With linear-time performance and competitive parsing accuracy (Nivre et al. 2006; Nivre and McDonald 2008), it is one of the parsers included in the MaltParser system (Nivre et al. 2007), which is currently widely used (e.g., Nivre et al. 2007; Surdeanu et al. 2008). The parser proceeds by reading the sentence from left to right, using a stack and four different kinds of transitions between conﬁgurations. The transition system deﬁned by all the possible conﬁgur"
J11-3004,N07-1050,0,0.163235,"length n. Note that this parsing schema is not correct, because Covington’s algorithm does not prevent the generation of cycles in the dependency graphs it produces. Quoting Covington (2001, page 99), Because the parser operates one word at a time, unity can only be checked at the end of the whole process: did it produce a tree with a single root that comprises all of the words? Therefore, a postprocessing mechanism is needed to determine which of the generated structures are, in fact, valid trees. In the parsing schema, this is reﬂected by the fact that the schema is complete but not sound. Nivre (2007) uses a variant of this algorithm in which cycle detection is used to avoid generating incorrect structures. Other non-projective parsers not covered here can also be represented under the parsing schema framework. For example, Kuhlmann (2010) presents a deduction system for a non-projective parser which uses a grammar formalism called regular dependency grammars. This deduction system can easily be converted into a parsing schema by associating adequate semantics with items. However, we do not show this here for space reasons, because we would ﬁrst have to explain the formalism of regular dep"
J11-3004,W04-2407,0,0.0290287,"Missing"
J11-3004,W06-2933,0,0.0439191,"Missing"
J11-3004,P08-1108,0,0.0320374,"Missing"
J11-3004,P05-1013,0,0.575223,"es appear to have non-projective syntactic structure, something that arises in many languages (Havelka 2007), and is particularly common in free word order languages such as Czech. Parsing without the projectivity constraint is computationally complex: Although it is possible to parse non-projective structures in quadratic time with respect to input length under a model in which each dependency decision is independent of all the others (as in the parser of McDonald et al. [2005], discussed in Section 6.4), the problem is intractable in the absence of this assumption (McDonald and Satta 2007). Nivre and Nilsson (2005) observe that most non-projective dependency structures appearing in practice contain only small proportions of non-projective arcs. This has led to the study of sub-classes of the class of all non-projective dependency structures (Kuhlmann and Nivre 2006; Havelka 2007). Kuhlmann (2010) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky, ¨ 2005), relating them to lexicalized constituency grammar forKuhlmann, and Mohl malisms. Speciﬁcally, Kuhlmann shows that linear context-free rewriting systems 562 ´ Gomez-Rodr´ ıguez, Carroll, and Weir Dependency"
J11-3004,P92-1012,0,0.732582,"ontain only small proportions of non-projective arcs. This has led to the study of sub-classes of the class of all non-projective dependency structures (Kuhlmann and Nivre 2006; Havelka 2007). Kuhlmann (2010) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky, ¨ 2005), relating them to lexicalized constituency grammar forKuhlmann, and Mohl malisms. Speciﬁcally, Kuhlmann shows that linear context-free rewriting systems 562 ´ Gomez-Rodr´ ıguez, Carroll, and Weir Dependency Parsing Schemata (LCFRS) with fan-out k (Vijay-Shanker, Weir, and Joshi 1987; Satta 1992) induce the set of dependency structures with gap degree at most k − 1; coupled CFG in which the maximal rank of a nonterminal is k (Hotz and Pitsch 1996) induces the set of wellnested dependency structures with gap degree at most k − 1; and ﬁnally, LTAG (Joshi and Schabes 1997) induces the set of well-nested dependency structures with gap degree at most 1. These results establish that there are polynomial-time dependency parsing algorithms for well-nested structures with bounded gap degree, because such parsers exist for their corresponding lexicalized constituency-based formalisms. Developin"
J11-3004,P08-1066,0,0.0656057,"Missing"
J11-3004,1993.iwpt-1.22,0,0.540082,"Missing"
J11-3004,W08-2121,0,0.0915845,"Missing"
J11-3004,P87-1015,1,0.765065,"Missing"
J11-3004,W03-3023,0,0.0944423,"ata are used to deﬁne grammar-driven parsers, in which the parsing process is guided by some set of rules which are used to license deduction steps. For example, an Earley P REDICTOR step is tied to a particular grammar rule, and can only be executed if such a rule exists. Some dependency parsers are also grammardriven. For example, those described by Lombardo and Lesmo (1996), Barbero et al. (1998), and Kahane, Nasr, and Rambow (1998) are based on the formalizations of dependency grammar CFG-like rules described by Hays (1964) and Gaifman (1965). However, many of the algorithms (Eisner 1996; Yamada and Matsumoto 2003) are not traditionally considered to be grammar-driven, because they do not use an explicit formal grammar; decisions about which dependencies to create are taken individually, using probabilistic models (Eisner 1996) or classiﬁers (Yamada and Matsumoto 2003). These are called data-driven parsers. To express such algorithms as deduction systems, we use the notion of D-rules (Covington 1990). D-rules have the form (a, i) → (b, j), which speciﬁes that a word b located at position j in the input string can have the word a in position i as a dependent. Deduction steps in data-driven parsers can be"
J11-3004,E99-1020,0,\N,Missing
J11-3004,J13-2004,0,\N,Missing
J11-3004,C98-1102,0,\N,Missing
J11-3004,dzeroski-etal-2006-towards,0,\N,Missing
J11-3004,D07-1096,0,\N,Missing
J11-3004,afonso-etal-2002-floresta,0,\N,Missing
J92-3003,P90-1021,0,0.397266,"ed to linguistic descriptions in general, is not a new one. Here we consider a few of the proposals that have appeared in recent years. 15 Classes with one or no variant set yield at m o s t a singleton superclass extension for each FS they a p p l y to, while others m u l t i p l y a FS b y a factor of no m o r e t h a n their total n u m b e r of variant sets. 325 Computational Linguistics Volume 18, Number 3 4.1 Defaults and Reentrancy The notion of 'default extension' employed here resembles the 'priority union' of Kaplan (1987: 180f) and the 'conservative addition' of Shieber (1986b). As Bouma (1990) points out, the result of defaulting under this approach may depend on order of application. To take Bouma's (p. 166) simple example, default unification of the FSs (1) [F a] (2) [C b] with a re-entrant structure (3) c [] l produces different, nonunifying, results: (4) [F [ ] a ] c [] (5) IFc [[]] b ] "" (4) results when (1) applies before (2), and (5) when (2) applies before (1). Similarly, defaulting the FSs (6)[~ (7) [G b] []][] onto a FS (8) [ a] produces one of according to whether (6) applies before (7), in which case the result is (9), or (7) applies before (6), to produce (10). Both si"
J92-3003,E89-1008,0,0.0889542,"tions, computing the global extension of a lexical class will in general involve creation of a larger number of FSs than appear in the result. If v(c) is the number of variant sets in the class c, and f is the function in the natural numbers such that f(0) = 1 and f(k) = k if k > 0,15 the maximum number of FSs constructed for a lexical class with the CPL (cl,... cn) is given by H IIf(v(ci)). i=1 This maximum arises when no failures of strict unification occur. Finally, while the variant set mechanism provides some of the functionality of the lexical rules proposed by Flickinger et al. (1985), Calder (1989), and others, the structure of the ELU lexicon does not admit the full range of capabilities of these more powerful devices; cyclic rule applications cannot be simulated, for example. 4. Some Comparisons As we mentioned briefly in Section 1, the idea of applying inheritance to the lexicon, and indeed to linguistic descriptions in general, is not a new one. Here we consider a few of the proposals that have appeared in recent years. 15 Classes with one or no variant set yield at m o s t a singleton superclass extension for each FS they a p p l y to, while others m u l t i p l y a FS b y a factor"
J92-3003,P85-1032,0,0.519158,"unwanted intermediate solutions, computing the global extension of a lexical class will in general involve creation of a larger number of FSs than appear in the result. If v(c) is the number of variant sets in the class c, and f is the function in the natural numbers such that f(0) = 1 and f(k) = k if k > 0,15 the maximum number of FSs constructed for a lexical class with the CPL (cl,... cn) is given by H IIf(v(ci)). i=1 This maximum arises when no failures of strict unification occur. Finally, while the variant set mechanism provides some of the functionality of the lexical rules proposed by Flickinger et al. (1985), Calder (1989), and others, the structure of the ELU lexicon does not admit the full range of capabilities of these more powerful devices; cyclic rule applications cannot be simulated, for example. 4. Some Comparisons As we mentioned briefly in Section 1, the idea of applying inheritance to the lexicon, and indeed to linguistic descriptions in general, is not a new one. Here we consider a few of the proposals that have appeared in recent years. 15 Classes with one or no variant set yield at m o s t a singleton superclass extension for each FS they a p p l y to, while others m u l t i p l y a"
J92-3003,E89-1025,0,0.0391783,"implementation is discussed. 2. The Lexicon as a Hierarchy 2.1 A n O v e r v i e w of the Formalism An ELU lexicon consists of a number of 'classes,"" each of which is a structured collection of constraint equations encoding information common to a set of words, together with links to other more general ""superclasses.' For example, if an 'intransitive"" class is used to express the common syntactic properties shared by all intransitive verbs, then particular instances of intransitive verbs can be made to inherit this informa2 ""Environnernent Linguistique d'Unification"" (Estival 1990). See also Johnson and Rosner (1989) for a description of the earlier UD system on which ELU is based. 312 Graham Russell et al. A Practical Approach to Multiple Default Inheritance tion by specifying the 'intransitive' class as one of their superclasses--it then becomes unnecessary to specify the relevant properties individually for each such verb. Similarly, the 'intransitive' class need not express any of the more general properties of the 'verb' class. The lexicon may be thought of as a tangled hierarchy of classes linked by inheritance paths, with, at the most specific level, lexical classes and, at the most general, classe"
J92-3003,P84-1008,0,0.0296573,"Missing"
J92-3003,C86-1016,0,0.0452349,"terms of a noncommutative 'overwriting' operation, in which constraint equations may be formulated so as to take precedence over existing structures. These devices permit the construction of heterogeneous systems like that of ELU; one difference between the two would be that, in Shieber's scheme, the statements exhibiting default behavior are ones that have the ability to override others over which they have precedence, whereas in the approach described above the default statements are ones that can be overridden by others that have precedence over them. In the D-PATR environment presented by Karttunen (1986), all templates engage in defaulting: ""... templates and other specifications that occur [in lexical entries] are processed sequentially from left to right. Each item is compiled to a directed graph and superimposed on the graph previously compiled"" (p. 76). Here, then, defaulting occurs as standard; any sequence of statements in a lexical entry may be such that a later statement conceals the effect of an earlier one. Again, the fact that defaulting is interpreted as the overwriting of one structure by another means that structures may be modified in a nonmonotonic fashion. The implementation"
J92-3003,P86-1038,0,0.0443659,"each ci in C yields as its superclass extension a set of FSs, each member of which is input to the remainder of C, (ci+1~... cnl. The global extension of L is then the yield of the most general class in its CPL--expressed in a slightly different way, the global extension of L is the result of applying to A_the CPL of n. 14 The set of lexical items admitted by a lexicon consists of the union of the global extensions of all lexical classes in the lexicon. 3.3 Variant S e t s - - D i s c u s s i o n Variant sets may be thought of as representing a restricted form of disjunction over complex FSs. Kasper and Rounds (1986) show general disjunctive unification to be intractable, since it involves an exponentially complex step of expansion to disjunctive normal form. Note, however, that the alternation embodied in variant sets is guaranteed to be at the 'top level' of FSs only; that is to say, the FSs described by multiple variant sets are already in disjunctive normal form, apart from any atomic disjunctions they may contain. For this reason, multiple variant sets impose no mutual constraints; regardless of whether the information they contain is orthogonal, complementary, or conflicting, the crucial factor is t"
J92-3003,E91-1024,0,0.062032,"another type of lexicon based on finite state morphology; lexicons of this type are accessed via the same interface, and one may be loaded and available for use at the same time as an inheritance-based lexicon. One of the characteristics of the ELU lexicon system that has allowed it to be so well integrated with the other components in the system is that it represents feature structures in exactly the same way that they do. In particular, ELU does not have to convert from one representation to another at the interface to the lexicon, as does DATR when used within a unification grammar system (Kilbury et al. 1991). 7. Summary The popularity of unification as a tool for computational linguistics stems from its declarative, monotonic semantics; however, the price to be paid for the benefits of a pure unification framework is the lack of a satisfactory treatment of exceptions (negation, defaults, etc.). The popularity of default inheritance as a tool for knowledge representation stems from its ability to encode, in a straightforward manner, the type 22 In theory, the system can deal with lexicons admitting up to around 4,000,000 word forms, but the largest lexicon tested to date contains slightly more tha"
J92-3003,C86-1050,0,0.204968,"broke Street, Cambridge CB2 3QG, UK. 1 See, e.g., Evans and Gazdar 1990, Gazdar 1990 (especially the References), much of the material in Daelernans and Gazdar 1990, and the contributions to Briscoe et al. 1991. We discuss some of this work below. (~ 1992 Association for Computational Linguistics Computational Linguistics Volume 18, Number 3 The system described here has been implemented as part of the ELU2 unification grammar development environment for research in machine translation, made up of parser, generator, lexicon, and transfer mechanism. The user language resembles that of PATR-II (Shieber 1986a), but provides a larger range of data types and more powerful means of stating relations between them. Among the requirements imposed by the context within which this system is used are (i) the ability to both analyze and generate complex word forms, (ii) full integration with existing parts of the ELU environment, and (iii) the ability to accommodate a relatively large number of words. In particular, an important objective is to preserve as far as possible the flavor of this type of environment: a specialized programming language for linguistic descriptions, suitable for interpretation by a"
J92-3003,P91-1028,1,\N,Missing
J93-1002,C88-1012,1,0.66618,"sing system incorporating the ANLT grammar (described above), we have implemented a breadth-first, nondeterministic LR parser for unification grammars. This parser is integrated with the Grammar Development Environment (GDE; Carroll et al. 1988) in the ANLT system, and provided as an alternative parser for use with stable grammars for batch parsing of large bodies of text. The existing chart parser, although slower, has been retained since it is more suited to grammar development, because of the speed with which modifications to the grammar can be compiled and its better debugging facilities (Boguraev et al. 1988). Our nondeterministic LR parser is based on Kipps' (1989) reformulation of Tomita's (1987) parsing algorithm and uses a graph-structured stack in the same way. Our parser is driven by the LALR(1) state table computed from the backbone grammar, but in addition on each reduction the parser performs the unifications appropriate to the unification grammar version of the backbone rule involved. The analysis being pursued fails if one of the unifications fails. The parser performs sub-analysis sharing (where if two or more trees have a common sub-analysis, that sub-analysis is represented only once"
J93-1002,P91-1027,0,0.0261499,"Missing"
J93-1002,P89-1010,0,0.0302128,"s John saw the man on the bus again, in which the possibility of a locative interpretation creates a mild preference for the adjectival reading and local attachment. To select the correct analysis in such cases it will be necessary to integrate information concerning word sense collocations into the probabilistic analysis. In this case, we are interested in collocations between the head of a PP complement, a preposition and the head of the phrase being postmodified. In general, these words will not be adjacent in the text, so it will not be possible to use existing approaches unmodified (e.g. Church and Hanks 1989), because these apply to adjacent words in unanalyzed text. Hindle and Rooth (1991) report good results using a mutual information measure of collocation applied within such a structurally defined context, and their approach should carry over to our framework straightforwardly. One way of integrating 'structural' collocational information into the system presented above would be to make use of the semantic component of the (ANLT) grammar. This component pairs logical forms with each distinct syntactic analysis that represent, among other things, the predicate-argument structure of the input. I"
J93-1002,J82-3004,0,0.0130765,"the set returned (or reject them all). However, this approach places a great load on the analyst, who will routinely need to examine large numbers of parses for given sentences. In addition, computation of all possible analyses is likely to be expensive and, in the limit, intractable. Briscoe (1987) demonstrates that the structure of the search space in parse derivations makes a left-to-right, incremental mode of parse selection most efficient. For example, in noun compounds analyzed using a recursive binary-branching rule (N --* N N) the number of analyses correlates with the Catalan series (Church and Patil, 1982), 4 so a 3-word compound has 2 analyses, 4 has 5, 5 has 14, 9 has 1430, and so forth. However, Briscoe (1987:154f) shows that with a simple bounded context parser (with one word lookahead) set up to request help whenever a parse indeterminacy arises, it is possible to select any of the 14 analyses of a 5-word compound with a maximum of 5 interactions and any of the 1430 analyses of a 9-word compound with around 13 interactions. In general, resolution of the first indeterminacy in the input will rule out approximately half the potential analyses, resolution of the next, half of the remaining on"
J93-1002,A92-1018,0,0.0398481,"Missing"
J93-1002,J88-1003,0,0.0337293,"Missing"
J93-1002,P81-1022,0,0.20879,"Missing"
J93-1002,W89-0209,0,0.643236,"129f for an introduction). The two main algorithms utilized are the Viterbi (1967) algorithm and the Baum-Welch algorithm (Baum 1972). These algorithms provide polynomial solutions to the tasks of finding the most probable derivation for a given input and a stochastic regular grammar, and of performing iterative re-estimation of the parameters of a (hidden) stochastic regular grammar by considering all possible derivations over a corpus of inputs, respectively. Baker (1982) demonstrates that Baum-Welch re-estimation can be extended to context-free grammars (CFGs) in Chomsky Normal Form (CNF). Fujisaki et al. (1989) demonstrate that the Viterbi algorithm can be used in conjunction with the CYK parsing algorithm and a CFG in CNF to efficiently select the most probable derivation of a given input. Kupiec (1991) extends Baum-Welch re-estimation to arbitrary (nonCNF) CFGs. Baum-Welch re-estimation can be used with restricted or unrestricted grammars/models in the sense that some of the parameters corresponding to possible productions over a given (non-)terminal category set/set of states can be given an initial probability of zero. Unrestricted grammars/models quickly become impractical because the number of"
J93-1002,J83-3002,0,0.0752601,"Missing"
J93-1002,W89-0221,0,0.0172819,"ries following Alshawi (1992): the packing of sub-analyses is driven by the subsumption relationship between the feature values in their top nodes. An analysis is only packed into one that has already been found if its top node is subsumed by, or is equal to that of the one already found. An analysis, once packed, will thus never need to be unpacked during parsing (as in Tomita's system) since the value of each feature will always be uniquely determined. Our use of local ambiguity packing does not in practice seem to result in exponentially bad performance with respect to sentence length (cf. Johnson 1989) since we have been able to generate packed parse forests for sentences of over 30 words having many thousands of parses. We have implemented a unification version of Schabes' (1991a) chart-based LR-like parser (which is polynomial in sentence length for CF grammars), but experiments with the ANLT grammar suggest that it offers no practical advantages over our Tomita-style parser, and Schabes' table construction algorithm yields less fine-grained and, therefore, less predictive parse tables. Nevertheless, searching the parse forest exhaustively to recover each distinct analysis proved computat"
J93-1002,W89-0220,0,0.0315058,"Missing"
J93-1002,E91-1004,0,0.267758,". (1989) propose a rather inelegant solution for the noun compound case, which involves creating 5582 instances of 4 morphosyntactically identical rules for classes of word forms with distinct bracketing behavior in noun-noun compounds. However, we would like to avoid enlarging the grammar and eventually to integrate probabilistic lexical information with probabilistic structural information in a more modular fashion. Probabilistic CFGs also will not model the context dependence of rule use; for example, an NP is more likely to be expanded as a pronoun in subject position than elsewhere (e.g. Magerman and Marcus 1991), but only one global probability can be associated with the relevant CF production. Thus the probabilistic CFG model predicts (incorrectly) that a) and f) will have the same probability of occurrence. These considerations suggest that we need a technique that allows use of a more adequate grammatical formalism than CFG and a more context-dependent probabilistic model. Our approach is to use the LR parsing technique as a natural way to obtain a finitestate representation of a non-finite-state grammar incorporating information about parse context. In the following sections, we introduce the LR"
J93-1002,E91-1013,0,0.0431095,"difficultto m a k e them in an optimal w a y for the purposes of L R parsing, since both steps involve consideration and comparison of all the categories mentioned in each rule of the grammar. 32 Ted Briscoe and John Carroll Generalized Probabilistic LR Parsing Constructing the LR parse table directly and automatically from a unification grammar would avoid these drawbacks. In this case, the LR parse table would be based on complex categories, with unification of complex categories taking the place of equality of atomic ones in the standard LR parse table construction algorithm (Osborne 1990; Nakazawa 1991). However, this approach is computationally prohibitively expensive: Osborne (1990:26) reports that his implementation (in HP Common Lisp on a Hewlett Packard 9000/350) takes almost 24 hours to construct the LR(0) states for a unification grammar of just 75 productions. 3.2 Constructing a CF B a c k b o n e f r o m a Unification G r a m m a r Our approach, described below, not only extracts unification information from complex categories, but is computationally tractable for realistic sized grammars and also safe from inconsistency. We start with a unification grammar and automatically constru"
J93-1002,1991.iwpt-1.18,0,0.0567747,"irst search using probabilistic information associated with transitions might not yield the desired result given this property. For example, it is not possible to use Viterbi-style optimization of search for the maximally probable parse because this derivation may contain a sub-analysis that will be pruned locally before a subsequent unification failure renders the current most probable analysis impossible. In general, the current breadth-first probabilistic parser is more efficient than its nonprobabilistic counterpart described in the previous section. In contrast to the parser described by Ng and Tomita (1991), our probabilistic parser is able to merge (state and stack) configurations and in all cases still maintain a full record of all the probabilities computed up to that point, since it associates probabilities with partial analyses of the input so far rather than with nodes in the graph-structured stack. We are currently 6 Although we define our probabilistic model relative to the LR parsing technique, it is likely that there is an equivalent encoding in purely grammatical terms. In general our approach corresponds to making the probability of rule application conditional on other rules having"
J93-1002,P92-1017,0,0.0491443,"Missing"
J93-1002,P88-1010,0,0.0168536,"Missing"
J93-1002,J87-3008,0,0.0176419,"us sections, we undertook a preliminary experiment using a subset of LDOCE noun definitions as our test corpus. (The reasons for choosing this corpus are discussed in the introduction.) A corpus of approximately 32,000 noun definitions was created from LDOCE by extracting the definition fields and normalizing the definitions to remove punctuation, font control information, and so forth, s A lexicon was created for this corpus by extracting the appropriate lemmas and matching these against entries in the ANLT lexicon. The 10,600 resultant entries were loaded into the ANLT morphological system (Ritchie et al. 1987) and this sublexicon and the full ANLT grammar formed the starting point for the training process. A total of 246 definitions, selected without regard for their syntactic form, were parsed semi-automatically using the parser described in Section 5. During this process, further rules and lexical entries were created for some definitions that failed to parse. Of the total number, 150 were successfully parsed and 63 lexical entries and 14 rules were added. Some of the rules required reflected general inadequacies in the ANLT grammar; for example, we added rules to deal with new partitives and pre"
J93-1002,P91-1014,0,0.0199574,"g these points, since the parser is as predictive as the backbone grammar and LR technique allow, and the LALR(1) parse table allows one word lookahead to resolve some ambiguities (although, of course, the resolution of a local ambiguity may potentially involve an unlimited amount of lookahead; e.g. Briscoe 1987:125ff). In fact, LR parsing is the most effectively predictive parsing technique for which an automatic compilation procedure is known, but this is somewhat undermined by our use of features, which will block some derivations so that the valid prefix property will no longer hold (e.g. Schabes 1991b). Extensions to the LR technique, for example those using LR-regular grammars (Culic and Cohen 1973; Bermudez 1991), might be used to further cut down on interactions; however, computation of the parse tables to drive such extended LR parsers may prove intractable for large NL grammars (Hektoen 1991). An LR parser faces an indeterminacy when it enters a state in which there is more than one possible action, given the current lookahead. In a particular state there cannot be more than one shift or accept action, but there can be several reduce actions, each specifying a reduction with a differ"
J93-1002,1991.iwpt-1.4,0,0.00854874,"g these points, since the parser is as predictive as the backbone grammar and LR technique allow, and the LALR(1) parse table allows one word lookahead to resolve some ambiguities (although, of course, the resolution of a local ambiguity may potentially involve an unlimited amount of lookahead; e.g. Briscoe 1987:125ff). In fact, LR parsing is the most effectively predictive parsing technique for which an automatic compilation procedure is known, but this is somewhat undermined by our use of features, which will block some derivations so that the valid prefix property will no longer hold (e.g. Schabes 1991b). Extensions to the LR technique, for example those using LR-regular grammars (Culic and Cohen 1973; Bermudez 1991), might be used to further cut down on interactions; however, computation of the parse tables to drive such extended LR parsers may prove intractable for large NL grammars (Hektoen 1991). An LR parser faces an indeterminacy when it enters a state in which there is more than one possible action, given the current lookahead. In a particular state there cannot be more than one shift or accept action, but there can be several reduce actions, each specifying a reduction with a differ"
J93-1002,P83-1017,0,0.120745,"refore, not f o u n d it necessary to use Schabes' (1991a) LR-like tables (with n u m b e r of states guaranteed to be polynomial even in the worst case). 1 of the 3,710 states, 2,200 contain at least 1 action conflict, with a median of 34 conflicts per state. There are a total of 230,000 shift-reduce conflicts and 220,000 reduce-reduce conflicts, fairly uniformly distributed across the terminal lookahead symbols. In half of the latter conflicts, the rules involved have an identical number of daughters. One implication of this finding is that an approach to conflict resolution such as that of Shieber (1983) where reduce-reduce conflicts are resolved in favor of the longer reduction may not suffice to select a unique analysis for realistic NL grammars. 38 Ted Briscoe and John Carroll Generalized Probabilistic LR Parsing Table 1 Sizes of grammar and LALR(1) parse tables. Grammar Number of CFG rules/categories Number of LR(0) states Number of kernel items Total number of actions Pascal2 Modula-23 Tomita, Japanese ANLT (689 PS rules) 158 / 124 227 / 194 800 / ? 1641 / 496 275 373 ? 3710 ? 420 ? 34836 2883 3238 ? 1258451 Table 2 Timings for LALR(1) parse table construction (in seconds of CPU time on"
J93-1002,P84-1075,0,0.00908517,"aining Kleene star daughters is treated as two rules: one omitting the daughters concerned and one with the daughters being Kleene plus. A new nonterminal category is created for each distinct Kleene plus category, and two extra rules are added to the backbone grammar to form a right-branching binary tree structure for it; a parser can easily be modified to flatten this out during processing into the intended flat sequence of categories. Figure 6 gives an example of what such a backbone tree looks like. Grammars written in other, more low-level unification grammar formalisms, such as PATR-I1 (Shieber 1984), commonly employ treatments of the type just described to deal with phenomena such as gapping, coordination, and compounding. However, this method both allows the grammar writer to continue to use the full facilities of the ANLT formalism and allows the algorithmic derivation of an appropriate backbone grammar to support LR parsing. The major task of the backbone grammar is to encode sufficient information (in the atomic categoried CF rules) from the unification grammar to constrain the application of the latter's rules at parse time. The nearly one-to-one mapping of unification grammar rules"
J93-1002,P85-1018,0,0.0241389,"ar writer and is inconsistent with most recent unification-based grammar formalisms, which represent grammatical categories entirely as feature bundles (e.g. Gazdar et al. 1985; Pollard and Sag 1987; Zeevat, Calder, and Klein 1987). In addition, it violates the principle that grammatical formalisms should be declarative and defined independently of parsing procedure, since different definitions of the CF portion of the grammar will, at least, effect the efficiency of the resulting parser and might, in principle, lead to nontermination on certain inputs in a manner similar to that described by Shieber (1985). In what follows, we will assume that the unification-based grammars we are considering are represented in the ANLT object grammar formalism (Briscoe et al. 1987). This formalism is a notational variant of Definite Clause Grammar (e.g. Pereira and Warren 1980), in which rules consist of a mother category and one or more daughter categories, defining possible phrase structure configurations. Categories consist of sets of feature name-value pairs, with the possibility of variable values, which may be bound within a rule, and of category-valued features. Categories are combined using fixed-arity"
J93-1002,E89-1035,1,0.845304,"Missing"
J93-1002,P84-1073,0,0.0248036,"feature w h e n parsing interactively with them (see next section). Table 1 compares the size of the LALR(1) parse table for the ANLT g r a m m a r with others reported in the literature. From these figures, the ANLT g r a m m a r is more than twice the size of Tomita's (combined morphological and syntactic) g r a m m a r for Japanese (Tomita 1987:45). The g r a m m a r itself is about one order of m a g n i t u d e bigger than that of a typical p r o g r a m m i n g language, but the LALR(1) parse table, in terms of n u m b e r of actions, is two orders of m a g n i t u d e bigger. Although Tomita (1984:357) anticipates LR parsing techniques being applied to large N L grammars written in formalisms such as GPSG, the sizes of parse tables for such grammars grow more rapidly than he predicts. However, for large real-world NL grammars such as the ANLT, the table size is still quite manageable despite Johnson's (1989) worst-case complexity result of the n u m b e r of LR(0) states being exponential on g r a m m a r size (leading to a parser with exponentially bad time performance). We have, therefore, not f o u n d it necessary to use Schabes' (1991a) LR-like tables (with n u m b e r of states g"
J93-1002,J87-1004,0,0.348353,"..................................................... 12 i0 ....................................... 13 r4 ........................................................... 13 ....................................... 14 r2 ........................................................... 14 ....................................... acc 14 8 9 ....................................... 9 r9 rg/s8 r9 ........................................................... 15 VP 15 Figure 2 LALR(1) parse table for Grammar 1. 31 Computational Linguistics Volume 19, Number 1 3.1 Creating LR Parse Tables from Unification Grammars Tomita (1987) describes a system for nondeterministic LR parsing of context-free grammars consisting of atomic categories, in which each CF production may be augmented with a set of tests (which perform similar types of operations to those available in a unification grammar). At parse time, whenever a sequence of constituents is about to be reduced into a higher-level constituent using a production, the augmentation associated with the production is invoked to check syntactic or semantic constraints such as agreement, pass attribute values between constituents, and construct a representation of the higher-"
J93-1002,W89-0211,0,0.0444225,"Missing"
J93-1002,1991.iwpt-1.12,0,0.130937,"Missing"
J93-1002,J90-1003,0,\N,Missing
J93-1002,J93-1005,0,\N,Missing
J93-1002,H91-1067,0,\N,Missing
J93-1002,H90-1054,0,\N,Missing
J93-1002,H91-1046,0,\N,Missing
J93-1002,1991.iwpt-1.22,0,\N,Missing
J93-1002,H90-1056,0,\N,Missing
J97-4007,W96-0209,1,0.900872,"Missing"
J97-4007,P96-1025,0,0.080434,"Missing"
J97-4007,A92-1022,0,0.0379764,"Missing"
J97-4007,P95-1037,0,0.094092,"Missing"
N09-2059,W04-3204,0,0.323015,"Missing"
N09-2059,briscoe-carroll-2002-robust,1,0.778211,". (2004) provides a prevalence ranking score to produce a MFS heuristic. We make a slight modification to McCarthy et al.’s prevalence score and use it to estimate the probability distribution over the senses of a word. We use the same resources as McCarthy et al. (2004): a distributional similarity thesaurus and a WordNet semantic similarity measure. The thesaurus was produced using the metric described by Lin (1998) with input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus (BNC) (Leech, 1992) using the RASP parser (Briscoe and Carroll, 2002). The thesaurus consists of entries for each word (w) with the top 50 “nearest neighbours” to w, where the neighbours are words ranked by the distributional similarity that Proceedings of NAACL HLT 2009: Short Papers, pages 233–236, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics they share with w. The WordNet similarity score is obtained with the jcn measure (Jiang and Conrath, 1997) using the WordNet Similarity Package 0.05 (Patwardhan and Pedersen, 2003) and WordNet version 1.6. The jcn measure needs word frequency information, which we obtained from the BNC."
N09-2059,P00-1064,0,0.0877167,"Missing"
N09-2059,O97-1002,0,0.0370294,") with input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus (BNC) (Leech, 1992) using the RASP parser (Briscoe and Carroll, 2002). The thesaurus consists of entries for each word (w) with the top 50 “nearest neighbours” to w, where the neighbours are words ranked by the distributional similarity that Proceedings of NAACL HLT 2009: Short Papers, pages 233–236, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics they share with w. The WordNet similarity score is obtained with the jcn measure (Jiang and Conrath, 1997) using the WordNet Similarity Package 0.05 (Patwardhan and Pedersen, 2003) and WordNet version 1.6. The jcn measure needs word frequency information, which we obtained from the BNC. 2.1 Estimates of Predominance, Probability and Entropy Following McCarthy et al. (2004), we calculate prevalence of each sense of the word (w) using a weighted sum of the distributional similarity scores of the top 50 neighbours of w. The sense of w that has the highest value is the automatically detected MFS (predominant sense). The weights are determined by the WordNet similarity between the sense in question and"
N09-2059,N07-1044,0,0.277898,"ic estimation. As we can see, while precision is higher for lower polysemy, the automatic estimate of entropy can provide a greater increase in precision than polysemy, and frequency does not seem to be strongly correlated with precision. 3.2 precision S ENSEVAL-2 English All Words Dataset The SE 2- EAW task provides a hand-tagged test suite of 5,000 words of running text from three articles from the Penn Treebank II (Palmer et al., 2001). Again, we examine whether precision of the MFS 235 4 Related Work There is promising related work on determining the predominant sense for a MFS heuristic (Lapata and Keller, 2007; Mohammad and Hirst, 2006) but our work is the first to use the ranking score to estimate entropy and apply it to determine the confidence in the MFS heuristic. It is likely that these methods would also have increased precision if the ranking scores were used to estimate entropy. We leave such investigations for further work. Chan and Ng (2005) estimate word sense distributions and demonstrate that sense distribution estimation improves a supervised WSD classifier. They use three sense distribution methods, including that of McCarthy et al. (2004). While the other two methods outperform the"
N09-2059,P98-2127,0,0.0508317,"1 It is also referred to as the first sense heuristic in the literature and in this paper. WSD 233 Method Given a listing of senses from an inventory, the method proposed by McCarthy et al. (2004) provides a prevalence ranking score to produce a MFS heuristic. We make a slight modification to McCarthy et al.’s prevalence score and use it to estimate the probability distribution over the senses of a word. We use the same resources as McCarthy et al. (2004): a distributional similarity thesaurus and a WordNet semantic similarity measure. The thesaurus was produced using the metric described by Lin (1998) with input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus (BNC) (Leech, 1992) using the RASP parser (Briscoe and Carroll, 2002). The thesaurus consists of entries for each word (w) with the top 50 “nearest neighbours” to w, where the neighbours are words ranked by the distributional similarity that Proceedings of NAACL HLT 2009: Short Papers, pages 233–236, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics they share with w. The WordNet similarity score is obtained with the jcn measure (J"
N09-2059,P04-1036,1,0.92448,"Missing"
N09-2059,E06-1016,0,0.229024,"see, while precision is higher for lower polysemy, the automatic estimate of entropy can provide a greater increase in precision than polysemy, and frequency does not seem to be strongly correlated with precision. 3.2 precision S ENSEVAL-2 English All Words Dataset The SE 2- EAW task provides a hand-tagged test suite of 5,000 words of running text from three articles from the Penn Treebank II (Palmer et al., 2001). Again, we examine whether precision of the MFS 235 4 Related Work There is promising related work on determining the predominant sense for a MFS heuristic (Lapata and Keller, 2007; Mohammad and Hirst, 2006) but our work is the first to use the ranking score to estimate entropy and apply it to determine the confidence in the MFS heuristic. It is likely that these methods would also have increased precision if the ranking scores were used to estimate entropy. We leave such investigations for further work. Chan and Ng (2005) estimate word sense distributions and demonstrate that sense distribution estimation improves a supervised WSD classifier. They use three sense distribution methods, including that of McCarthy et al. (2004). While the other two methods outperform the McCarthy et al. method, 3 W"
N09-2059,S01-1005,0,0.039217,"ll due to frequency or polysemy. This is important, since both frequency and polysemy level (assuming a predefined sense inventory) could be obtained without the need for automatic estimation. As we can see, while precision is higher for lower polysemy, the automatic estimate of entropy can provide a greater increase in precision than polysemy, and frequency does not seem to be strongly correlated with precision. 3.2 precision S ENSEVAL-2 English All Words Dataset The SE 2- EAW task provides a hand-tagged test suite of 5,000 words of running text from three articles from the Penn Treebank II (Palmer et al., 2001). Again, we examine whether precision of the MFS 235 4 Related Work There is promising related work on determining the predominant sense for a MFS heuristic (Lapata and Keller, 2007; Mohammad and Hirst, 2006) but our work is the first to use the ranking score to estimate entropy and apply it to determine the confidence in the MFS heuristic. It is likely that these methods would also have increased precision if the ranking scores were used to estimate entropy. We leave such investigations for further work. Chan and Ng (2005) estimate word sense distributions and demonstrate that sense distribut"
N09-2059,C98-2122,0,\N,Missing
P01-1015,W00-1410,1,0.816566,"which all the data levels can be represented in a common framework consisting of networks of typed ‘objects’ connected by typed ‘arrows’. This lingua franca allows NLG modules to manipulate data flexibly and consistently. It also facilitates modular design of NLG systems, and reusability of modules and data sets. However, it does not in itself say anything about how modules in such a system might interact. This paper describes a concrete realisation of the RAGS object and arrows model, OASYS, as applied to a simple but flexible NLG system called RICHES. This is not the first such realisation: Cahill et al., (2000) describes a partial re-implementation of the ‘Caption Generation System’ (Mittal et al., 1999) which includes an objects and arrows ‘whiteboard’. The OASYS system includes more specific proposals for processing and inter-module communication, and RICHES demonstrates how this can be used to support a modular architecture based on small scale functionally-motivated units. 3 OASYS Quote representations These are used to represent literal unanalysed content used by a generator, such as canned text, pictures or tables. OASYS (Objects and Arrows SYStem) is a software library which provides: The rep"
P01-1015,copestake-flickinger-2000-open,0,0.0196598,"7) and FUF/SURGE (Elhadad et al., 1997). Renderer (REND) The Renderer is the module that puts the concrete document together. Guided by the document structure, it produces HTML formatting for the text and positions and references the pictures. Individual sentences are produced for it by LinGO, via the FLO interface. FLO actually processes sentences independently of REND, so when REND makes a request, either the sentence is there already, or the request is queued, and serviced when it becomes available. LinGO The LinGO realiser uses a widecoverage grammar of English in the LKB HPSG framework, (Copestake and Flickinger, 2000). The tactical generation component accepts input in the Minimal Recursion Semantics formalism and produces the target text using a chartdriven algorithm with an optimised treatment of modification (Carroll et al., 1999). No domainspecific tuning of the grammar was required for the RICHES system, only a few additions to the lexicon were necessary. 5 An example: generation in RICHES In this section we show how RICHES generates the first sentence of the example text, Blow your nose so that it is clear and the picture that accompanies the text. The system starts with a rhetorical representation ("
P01-1015,J97-2001,0,0.0233148,"clauses. In addition, SF decides whether a sentence should be imperative, depending on who the reader of the document is (an input parameter to the system). Finalise Lexical Output (FLO) RICHES uses an external sentence realiser component with its own non-RAGS input specification. FLO provides the interface to this realiser, extracting (mostly syntactic) information from OASYS and converting it to the appropriate form for the realiser. Currently, FLO supports the LinGO realiser (Carroll et al., 1999), but we are also looking at FLO modules for RealPro (Lavoie and Rambow, 1997) and FUF/SURGE (Elhadad et al., 1997). Renderer (REND) The Renderer is the module that puts the concrete document together. Guided by the document structure, it produces HTML formatting for the text and positions and references the pictures. Individual sentences are produced for it by LinGO, via the FLO interface. FLO actually processes sentences independently of REND, so when REND makes a request, either the sentence is there already, or the request is queued, and serviced when it becomes available. LinGO The LinGO realiser uses a widecoverage grammar of English in the LKB HPSG framework, (Copestake and Flickinger, 2000). The ta"
P01-1015,A97-1039,0,0.0462862,"example, combining main and subordinate clauses. In addition, SF decides whether a sentence should be imperative, depending on who the reader of the document is (an input parameter to the system). Finalise Lexical Output (FLO) RICHES uses an external sentence realiser component with its own non-RAGS input specification. FLO provides the interface to this realiser, extracting (mostly syntactic) information from OASYS and converting it to the appropriate form for the realiser. Currently, FLO supports the LinGO realiser (Carroll et al., 1999), but we are also looking at FLO modules for RealPro (Lavoie and Rambow, 1997) and FUF/SURGE (Elhadad et al., 1997). Renderer (REND) The Renderer is the module that puts the concrete document together. Guided by the document structure, it produces HTML formatting for the text and positions and references the pictures. Individual sentences are produced for it by LinGO, via the FLO interface. FLO actually processes sentences independently of REND, so when REND makes a request, either the sentence is there already, or the request is queued, and serviced when it becomes available. LinGO The LinGO realiser uses a widecoverage grammar of English in the LKB HPSG framework, (Co"
P01-1015,A00-1017,0,0.0710182,"sity of Sussex Brighton, BN1 9QH, UK johnca@cogs.susx.ac.uk Abstract The RAGS proposals for generic specification of NLG systems includes a detailed account of data representation, but only an outline view of processing aspects. In this paper we introduce a modular processing architecture with a concrete implementation which aims to meet the RAGS goals of transparency and reusability. We illustrate the model with the RICHES system – a generation system built from simple linguisticallymotivated modules. 1 Introduction As part of the RAGS (Reference Architecture for Generation Systems) project, Mellish et al (2000) introduces a framework for the representation of data in NLG systems, the RAGS ‘data model’. This model offers a formally well-defined declarative representation language, which supports the complex and dynamic data requirements of generation systems, e.g. different levels of representation (conceptual to syntax), mixed representations that cut across levels, partial and shared structures and ‘canned’ representations. However  We would like to acknowledge the financial support of the EPSRC (RAGS – Reference Architecture for Generation Systems: grant GR/L77102 to Donia Scott), as well as the"
P01-1015,C00-2093,1,0.828569,"picture should illustrate it. Pic2 The dashed lines indicate flow of information, solid arrows indicate approximately flow of control between modules, double boxes indicate a completely reused module (from another system), while a double box with a dashed outer indicates a module partially reused. Ellipses indicate information sources, as opposed to processing modules. tures, annotated with their SemReps, are part of the picture library, and Media Selection builds small pieces of DocRep referencing the pictures. Document Planner (DP) The Document Planner, based on the ICONOCLAST text planner (Power, 2000) takes the input RhetRep and produces a document structure (DocRep). This specifies aspects such as the text-level (e.g., paragraph, sentence) and the relative ordering of propositions in the DocRep. Its leaves refer to SynReps corresponding to syntactic phrases. This module is pipelined after MS, to make sure that it takes account of any pictures that have been included in the document. Lexical Choice (LC) Lexical choice happens in two stages. In the first stage, LC chooses the lexical items for the predicate of each SynRep. This fixes the basic syntactic structure of the proposition, and the"
P01-1015,W94-0319,0,0.0336301,"ther colleagues at the ITRI, especially Nedjet BouayadAgha. We would also like to acknowledge the contribution of colleagues who worked on the RICHES system previously: Neil Tipper and Rodger Kibble. We are grateful to our anonymous referees for their helpful comments. RAGS, as described in that paper, says very little about the functional structure of an NLG system, or the issues arising from more complex processing regimes (see for example Robin (1994), Inuie et al., (1992) for further discussion). NLG systems, especially end-to-end, applied NLG systems, have many functionalities in common. Reiter (1994) proposed an analysis of such systems in terms of a simple three stage pipeline. More recently Cahill et al (1999) attempted to repeat the analysis, but found that while most systems did implement a pipeline, they did not implement the same pipeline – different functionalities occurred in different ways and different orders in different systems. But this survey did identify a number of core functionalities which seem to occur during the execution of most systems. In order to accommodate this result, a ‘process model’ was sketched which aimed to support both pipelines and more complex control r"
P01-1015,J98-3004,0,\N,Missing
P04-1036,S01-1020,0,\N,Missing
P04-1036,W04-0837,1,\N,Missing
P04-1036,S01-1005,0,\N,Missing
P04-1036,S01-1027,0,\N,Missing
P04-1036,rose-etal-2002-reuters,0,\N,Missing
P04-1036,W97-0808,1,\N,Missing
P04-1036,C04-1146,1,\N,Missing
P04-1036,W03-1022,0,\N,Missing
P04-1036,P00-1064,0,\N,Missing
P04-1036,H93-1061,0,\N,Missing
P04-1036,W02-0907,0,\N,Missing
P04-1036,O97-1002,0,\N,Missing
P04-1036,briscoe-carroll-2002-robust,1,\N,Missing
P04-1036,J04-1003,0,\N,Missing
P04-1036,W01-0715,0,\N,Missing
P04-1036,P98-2127,0,\N,Missing
P04-1036,C98-2122,0,\N,Missing
P04-1036,magnini-cavaglia-2000-integrating,0,\N,Missing
P06-2006,C02-1013,1,0.456801,"nto a sequence of bilexical grammatical relations (GRs) between lexical heads and their dependents. The full system can be extended in a variety of ways – for example, by pruning PoS tags but allowing multiple tag possibilities per word as input to the parser, by incorporating lexical subcategorization into parse selection, by computing GR weights based on the proportion and probability of the n-best analyses yielding them, and so forth – broadly trading accuracy and greater domaindependence against speed and reduced sensitivity to domain-specific lexical behaviour (Briscoe and Carroll, 2002; Carroll and Briscoe, 2002; Watson et al., 2005; Watson, 2006). However, in this paper we focus exclusively on the baseline unlexicalized system. Both Collins’ Model 3 and the XLE Parser use lexicalized models for parse selection trained on the rest of the WSJ PTB. Therefore, although Kaplan et al. demonstrate an improvement in accuracy at some cost to speed, there remain questions concerning viability for applications, at some remove from the financial news domain, for which substantial treebanks are not available. The parser we deploy, like the XLE one, is based on a manually-defined feature-based unification grammar"
P06-2006,C04-1041,0,0.029928,"Missing"
P06-2006,W01-0521,0,0.312595,"Missing"
P06-2006,1997.iwpt-1.16,0,0.547879,"Missing"
P06-2006,N04-1013,0,0.27193,"Missing"
P06-2006,P99-1061,1,0.343253,"Missing"
P06-2006,P03-1054,0,0.0811338,"Missing"
P06-2006,P05-1011,0,0.0262634,"Missing"
P06-2006,W05-1517,1,0.816218,"grammatical relations (GRs) between lexical heads and their dependents. The full system can be extended in a variety of ways – for example, by pruning PoS tags but allowing multiple tag possibilities per word as input to the parser, by incorporating lexical subcategorization into parse selection, by computing GR weights based on the proportion and probability of the n-best analyses yielding them, and so forth – broadly trading accuracy and greater domaindependence against speed and reduced sensitivity to domain-specific lexical behaviour (Briscoe and Carroll, 2002; Carroll and Briscoe, 2002; Watson et al., 2005; Watson, 2006). However, in this paper we focus exclusively on the baseline unlexicalized system. Both Collins’ Model 3 and the XLE Parser use lexicalized models for parse selection trained on the rest of the WSJ PTB. Therefore, although Kaplan et al. demonstrate an improvement in accuracy at some cost to speed, there remain questions concerning viability for applications, at some remove from the financial news domain, for which substantial treebanks are not available. The parser we deploy, like the XLE one, is based on a manually-defined feature-based unification grammar. However, the approa"
P06-2006,briscoe-carroll-2002-robust,1,0.676823,"ic trees, and/or factored into a sequence of bilexical grammatical relations (GRs) between lexical heads and their dependents. The full system can be extended in a variety of ways – for example, by pruning PoS tags but allowing multiple tag possibilities per word as input to the parser, by incorporating lexical subcategorization into parse selection, by computing GR weights based on the proportion and probability of the n-best analyses yielding them, and so forth – broadly trading accuracy and greater domaindependence against speed and reduced sensitivity to domain-specific lexical behaviour (Briscoe and Carroll, 2002; Carroll and Briscoe, 2002; Watson et al., 2005; Watson, 2006). However, in this paper we focus exclusively on the baseline unlexicalized system. Both Collins’ Model 3 and the XLE Parser use lexicalized models for parse selection trained on the rest of the WSJ PTB. Therefore, although Kaplan et al. demonstrate an improvement in accuracy at some cost to speed, there remain questions concerning viability for applications, at some remove from the financial news domain, for which substantial treebanks are not available. The parser we deploy, like the XLE one, is based on a manually-defined featur"
P06-2006,J04-4004,0,\N,Missing
P06-2006,J03-4003,0,\N,Missing
P06-4020,1997.iwpt-1.16,0,0.120691,"ation and of the proportion of such derivations in the forest produced by the parser. A weighted set of GRs from the parse forest is now computed efficiently using a variant of the inside-outside algorithm (Watson et al., 2005). 2.5 Generalised LR Parser A non-deterministic LALR(1) table is constructed automatically from a CF ‘backbone’ compiled from the feature-based grammar. The parser builds a packed parse forest using this table to guide the actions it performs. Probabilities are associated with subanalyses in the forest via those associated with specific actions in cells of the LR table (Inui et al., 1997). The n-best (i.e. most probable) parses can be efficiently extracted by unpacking subanalyses, following pointers to contained subanalyses and choosing alternatives in order of probabilistic ranking. This process backtracks occasionally since unifications are required during the unpacking process and they occasionally fail (see Oepen and Carroll, 2000). The probabilities of actions in the LR table are computed using bootstrapping methods which utilise an unlabelled bracketing of the Susanne Treebank (Watson et al., 2006). This makes the system more easily retrainable after changes in the gram"
P06-4020,P99-1061,1,0.152854,"Missing"
P06-4020,A00-2022,1,0.59298,"rom the feature-based grammar. The parser builds a packed parse forest using this table to guide the actions it performs. Probabilities are associated with subanalyses in the forest via those associated with specific actions in cells of the LR table (Inui et al., 1997). The n-best (i.e. most probable) parses can be efficiently extracted by unpacking subanalyses, following pointers to contained subanalyses and choosing alternatives in order of probabilistic ranking. This process backtracks occasionally since unifications are required during the unpacking process and they occasionally fail (see Oepen and Carroll, 2000). The probabilities of actions in the LR table are computed using bootstrapping methods which utilise an unlabelled bracketing of the Susanne Treebank (Watson et al., 2006). This makes the system more easily retrainable after changes in the grammar and opens up the possibility of quicker tuning to in-domain data. In addition, the structural ranking induced by the parser can be reranked using (in-domain) lexical data which pro3 Evaluation The new system has been evaluated using our reannotation of the PARC dependency bank (DepBank; King et al., 2003)—consisting of 560 sentences chosen randomly"
P06-4020,briscoe-carroll-2002-robust,1,0.223171,"ised training method for the structural parse ranking model. We evaluate the released version on the WSJ using a relational evaluation scheme, and describe how the new release allows users to enhance performance using (in-domain) lexical information. Tokeniser ? PoS Tagger ? Lemmatiser ? Parser/Grammar ? Parse Ranking Model Figure 1: RASP Pipeline 1 Introduction Fourthly, the grammatical relations output has been redesigned to better support further processing. Finally, the training and tuning of the parse ranking model has been made more flexible. The first public release of the RASP system (Briscoe & Carroll, 2002) has been downloaded by over 120 sites and used in diverse natural language processing tasks, such as anaphora resolution, word sense disambiguation, identifying rhetorical relations, resolving metonymy, detecting compositionality in phrasal verbs, and diverse applications, such as topic and sentiment classification, text anonymisation, summarisation, information extraction, and open domain question answering. Briscoe & Carroll (2002) give further details about the first release. Briscoe (2006) provides references and more information about extant use of RASP and fully describes the modificati"
P06-4020,P06-2006,1,0.798254,"Missing"
P06-4020,W05-1517,1,0.615132,"ations to enable appropriate semantic inferences, and addition of a text adjunct (punctuation) relation to the scheme. Factoring rooted, directed graphs of GRs into a set of bilexical dependencies makes it possible to compute the transderivational support for a particular relation and thus compute a weighting which takes account both of the probability of derivations yielding a specific relation and of the proportion of such derivations in the forest produced by the parser. A weighted set of GRs from the parse forest is now computed efficiently using a variant of the inside-outside algorithm (Watson et al., 2005). 2.5 Generalised LR Parser A non-deterministic LALR(1) table is constructed automatically from a CF ‘backbone’ compiled from the feature-based grammar. The parser builds a packed parse forest using this table to guide the actions it performs. Probabilities are associated with subanalyses in the forest via those associated with specific actions in cells of the LR table (Inui et al., 1997). The n-best (i.e. most probable) parses can be efficiently extracted by unpacking subanalyses, following pointers to contained subanalyses and choosing alternatives in order of probabilistic ranking. This pro"
P06-4020,A94-1009,0,0.142719,"Missing"
P08-1110,E99-1020,0,0.0947804,"properties (such as correctness), establish relations between them, derive new parsers from existing ones and obtain efficient implementations automatically (G´omez-Rodr´ıguez et al., 2007). The formalism was initially defined for context-free grammars and later applied to other constituencybased formalisms, such as tree-adjoining grammars ∗ Partially supported by Ministerio de Educaci´on y Ciencia and FEDER (TIN2004-07246-C03, HUM2007-66607-C04), Xunta de Galicia (PGIDIT07SIN005206PR, PGIDIT05PXIC10501PN, PGIDIT05PXIC30501PN, Rede Galega de Proc. da Linguaxe e RI) and Programa de Becas FPU. (Alonso et al., 1999). However, since parsing schemata are defined as deduction systems over sets of constituency trees, they cannot be used to describe dependency parsers. In this paper, we define an analogous formalism that can be used to define, analyze and compare dependency parsers. We use this framework to provide uniform, high-level descriptions for a wide range of well-known algorithms described in the literature, and we show how they formally relate to each other and how we can use these relations and the formalism itself to prove their correctness. 1.1 Parsing schemata Parsing schemata (Sikkel, 1997) pro"
P08-1110,W06-2922,0,0.22437,"Missing"
P08-1110,W98-0507,0,0.956481,"e dependency parsers are also grammar2 wi is shorthand for the marked terminal (wi , i). These are used by Sikkel (1997) to link terminal symbols to string positions so that an input sentence can be represented as a set of trees which are used as initial items (hypotheses) for the deduction system. Thus, a sentence w1 . . . wn produces a set of hypotheses {{w1 (w1 )}, . . . , {wn (wn )}}. 969 Figure 1: Representation of a dependency structure with a tree. The arrows below the words correspond to its associated dependency graph. based: for example, those described by Lombardo and Lesmo (1996), Barbero et al. (1998) and Kahane et al. (1998) are tied to the formalizations of dependency grammar using context-free like rules described by Hays (1964) and Gaifman (1965). However, many of the most widely used algorithms (Eisner, 1996; Yamada and Matsumoto, 2003) do not use a formal grammar at all. In these, decisions about which dependencies to create are taken individually, using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b"
P08-1110,P89-1018,0,0.557318,"schemata for some well-known dependency parsers. As we can see, we use D-rules as side conditions for deduction steps, since this parsing strategy is not grammar-based. Conceptually, the schema we have just defined describes a recogniser: given a set of Drules and an input string wi . . . wn , the sentence can be parsed (projectively) under those D-rules if and only if this deduction system can infer a correct final item. However, when executing this schema with a deductive engine, we can recover the parse forest by following back pointers in the same way as is done with constituency parsers (Billot and Lang, 1989). Of course, boolean D-rules are of limited interest in practice. However, this schema provides a formalization of a parsing strategy which is independent of the way linking decisions are taken in a particular implementation. In practice, statistical models can be used to decide whether a step linking words a and b (i.e., having a → b as a side condition) is executed or not, and probabilities can be attached to items in order to assign different weights to different analyses of the sentence. The same principle applies to the rest of D-rule-based parsers described in this paper. 3.2 Eis96 (Eisn"
P08-1110,P96-1025,0,0.0603299,"arsers. When defining projective parsers, correct final items will be those containing projective parse trees for w1 . . . wn . This distinction is relevant because the concepts of soundness and correctness of parsing schemata are based on correct final items (cf. section 1.1), and we expect correct projective parsers to produce only projective structures, while nonprojective parsers should find all possible structures including nonprojective ones. 3 Some practical examples 3.1 Col96 (Collins, 96) One of the most straightforward projective dependency parsing strategies is the one described by Collins (1996), directly based on the CYK parsing algorithm. This parser works with dependency trees which are linked to each other by creating links between their heads. Its item set is defined as ICol96 = {[i, j, h] |1 ≤ i ≤ h ≤ j ≤ n}, where an item [i, j, h] is defined as the set of forests containing a single projective dependency tree t such that t is grounded, yield (t) = wi . . . wj and head (t) = wh . For an input string w1 . . . wn , the set of hypotheses is H = {[i, i, i] |0 ≤ i ≤ n + 1}, i.e., the set of forests containing a single dependency tree of the form wi (wi ). This same set of hypothese"
P08-1110,N06-1021,0,0.0432819,"he rest of D-rule-based parsers described in this paper. 3.2 Eis96 (Eisner, 96) By counting the number of free variables used in each deduction step of Collins’ parser, we can conclude that it has a time complexity of O(n5 ). This complexity arises from the fact that a parentless word (head) may appear in any position in the partial results generated by the parser; the complexity can be reduced to O(n3 ) by ensuring that parentless words can only appear at the first or last position of an item. This is the principle behind the parser defined by Eisner (1996), which is still in wide use today (Corston-Oliver et al., 2006; McDonald et al., 971 2005a). The item set for Eisner’s parsing schema is IEis96 = {[i, j, T, F ] |0 ≤ i ≤ j ≤ n} ∪ {[i, j, F, T ] |0 ≤ i ≤ j ≤ n} ∪ {[i, j, F, F ] | 0 ≤ i ≤ j ≤ n}, where each item [i, j, T, F ] is defined as the item [i, j, j] ∈ ICol96 , each item [i, j, F, T ] is defined as the item [i, j, i] ∈ ICol96 , and each item [i, j, F, F ] is defined as the set of forests of the form {t1 , t2 } such that t1 and t2 are grounded, head (t1 ) = wi , head (t2 ) = wj , and ∃k ∈ N(i ≤ k &lt; j)/yield (t1 ) = wi . . . wk ∧ yield (t2 ) = wk+1 . . . wj . Note that the flags b, c in an item [i, j"
P08-1110,W98-0511,0,0.583594,"eduction steps for the schema are shown in Figure 2, and the final item set is {[(S.), 1, n]}. As we can see, the schema for Lombardo and Lesmo’s parser resembles the Earley-style parser in Sikkel (1997), with some changes to adapt it to dependency grammar (for example, the Scanner always moves the dot over the head symbol ∗). Analogously, other dependency parsing schemata based on CFG-like rules can be obtained by modifying context-free grammar parsing schemata of Sikkel (1997) in a similar way. The algorithm by Barbero et al. (1998) can be obtained from the leftcorner parser, and the one by Courtin and Genthial (1998) is a variant of the head-corner parser. 3.6 Pseudo-projectivity Pseudo-projective parsers can generate nonprojective analyses in polynomial time by using a projective parsing strategy and postprocessing the results to establish nonprojective links. For example, the algorithm by Kahane et al. (1998) uses a projective parsing strategy like that of LL96, but using the following initializer step instead of the Initter and Predictor:5 Initter 4 [A(α), i, i − 1] sr A(α) ∈ P ∧ 1 ≤ i ≤ n Relations between dependency parsers The framework of parsing schemata can be used to establish relationships betw"
P08-1110,P81-1022,0,0.738346,"ardo and Lesmo, 96) and other Earley-based parsers The algorithms in the above examples are based on taking individual decisions about dependency links, represented by D-rules. Other parsers, such as that of Lombardo and Lesmo (1996), use grammars with context-free like rules which encode the preferred order of dependents for each given governor, as defined by Gaifman (1965). For example, a rule of the form N (Det ∗ P P ) is used to allow N to have Det as left dependent and P P as right dependent. The algorithm by Lombardo and Lesmo (1996) is a version of Earley’s context-free grammar parser (Earley, 1970) using Gaifman’s dependency grammar, and can be written by using an item set ILomLes = {[A(α.β), i, j] |A(αβ) ∈ P ∧ 1 ≤ i ≤ j ≤ n}, where each item [A(α.β), i, j] represents the set of partial dependency trees rooted at A, where the direct children of A are αβ, and the subtrees rooted at α have yield wi . . . wj . The deduction steps for the schema are shown in Figure 2, and the final item set is {[(S.), 1, n]}. As we can see, the schema for Lombardo and Lesmo’s parser resembles the Earley-style parser in Sikkel (1997), with some changes to adapt it to dependency grammar (for example, the Scan"
P08-1110,P99-1059,0,0.512818,"ent dependency trees where the word in position i or j is the head, while items with both flags set to F represent pairs of trees headed at positions i and j, and therefore correspond to disconnected dependency graphs. Deduction steps4 are shown in Figure 2. The set of final items is {[0, n, F, T ]}. Note that these items represent dependency trees rooted at the BOS marker w0 , which acts as a “dummy head” for the sentence. In order for the algorithm to parse sentences correctly, we will need to define D-rules to allow w0 to be linked to the real sentence head. 3.3 ES99 (Eisner and Satta, 99) Eisner and Satta (1999) define an O(n3 ) parser for split head automaton grammars that can be used 4 Alternatively, we could consider items of the form [i, i + 1, F, F ] to be hypotheses for this parsing schema, so we would not need an Initter step. However, we have chosen to use a standard set of hypotheses valid for all parsers because this allows for more straightforward proofs of relations between schemata. for dependency parsing. This algorithm is conceptually simpler than Eis96, since it only uses items representing single dependency trees, avoiding items of the form [i, j, F, F ]. Its item set is IES99 = {[i,"
P08-1110,C96-1058,0,0.925767,"ees which are used as initial items (hypotheses) for the deduction system. Thus, a sentence w1 . . . wn produces a set of hypotheses {{w1 (w1 )}, . . . , {wn (wn )}}. 969 Figure 1: Representation of a dependency structure with a tree. The arrows below the words correspond to its associated dependency graph. based: for example, those described by Lombardo and Lesmo (1996), Barbero et al. (1998) and Kahane et al. (1998) are tied to the formalizations of dependency grammar using context-free like rules described by Hays (1964) and Gaifman (1965). However, many of the most widely used algorithms (Eisner, 1996; Yamada and Matsumoto, 2003) do not use a formal grammar at all. In these, decisions about which dependencies to create are taken individually, using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b can have a as a dependent. Deduction steps in non-grammarbased parsers can be tied to the D-rules associated with the links they create. In this way, we obtain a representation of the semantics of these parsing strat"
P08-1110,P98-1106,0,0.628947,"lso grammar2 wi is shorthand for the marked terminal (wi , i). These are used by Sikkel (1997) to link terminal symbols to string positions so that an input sentence can be represented as a set of trees which are used as initial items (hypotheses) for the deduction system. Thus, a sentence w1 . . . wn produces a set of hypotheses {{w1 (w1 )}, . . . , {wn (wn )}}. 969 Figure 1: Representation of a dependency structure with a tree. The arrows below the words correspond to its associated dependency graph. based: for example, those described by Lombardo and Lesmo (1996), Barbero et al. (1998) and Kahane et al. (1998) are tied to the formalizations of dependency grammar using context-free like rules described by Hays (1964) and Gaifman (1965). However, many of the most widely used algorithms (Eisner, 1996; Yamada and Matsumoto, 2003) do not use a formal grammar at all. In these, decisions about which dependencies to create are taken individually, using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b can have a as a dependent"
P08-1110,C96-2122,0,0.788926,"if such a rule exists. Some dependency parsers are also grammar2 wi is shorthand for the marked terminal (wi , i). These are used by Sikkel (1997) to link terminal symbols to string positions so that an input sentence can be represented as a set of trees which are used as initial items (hypotheses) for the deduction system. Thus, a sentence w1 . . . wn produces a set of hypotheses {{w1 (w1 )}, . . . , {wn (wn )}}. 969 Figure 1: Representation of a dependency structure with a tree. The arrows below the words correspond to its associated dependency graph. based: for example, those described by Lombardo and Lesmo (1996), Barbero et al. (1998) and Kahane et al. (1998) are tied to the formalizations of dependency grammar using context-free like rules described by Hays (1964) and Gaifman (1965). However, many of the most widely used algorithms (Eisner, 1996; Yamada and Matsumoto, 2003) do not use a formal grammar at all. In these, decisions about which dependencies to create are taken individually, using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b,"
P08-1110,P05-1012,0,0.159405,"Missing"
P08-1110,H05-1066,0,0.225193,"Missing"
P08-1110,D07-1013,0,0.0646823,"Missing"
P08-1110,W03-3023,0,0.888754,"used as initial items (hypotheses) for the deduction system. Thus, a sentence w1 . . . wn produces a set of hypotheses {{w1 (w1 )}, . . . , {wn (wn )}}. 969 Figure 1: Representation of a dependency structure with a tree. The arrows below the words correspond to its associated dependency graph. based: for example, those described by Lombardo and Lesmo (1996), Barbero et al. (1998) and Kahane et al. (1998) are tied to the formalizations of dependency grammar using context-free like rules described by Hays (1964) and Gaifman (1965). However, many of the most widely used algorithms (Eisner, 1996; Yamada and Matsumoto, 2003) do not use a formal grammar at all. In these, decisions about which dependencies to create are taken individually, using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b can have a as a dependent. Deduction steps in non-grammarbased parsers can be tied to the D-rules associated with the links they create. In this way, we obtain a representation of the semantics of these parsing strategies that is independent of"
P08-1110,C98-1102,0,\N,Missing
P11-1014,W06-1615,0,0.614812,"number of baselines and previous cross-domain sentiment classification techniques using the benchmark dataset. For all previous techniques we give the results reported in the original papers. The No Thesaurus baseline simulates the effect of not performing any feature expansion. We simply train a binary classifier using unigrams and bigrams as features from the labeled reviews in the source domains and apply the trained classifier on the target domain. This can be considered to be a lower bound that does not perform domain adaptation. SCL is the structural correspondence learning technique of Blitzer et al. (2006). In SCL-MI, features are selected using the mutual information between a feature (unigram or bigram) and a domain label. After selecting salient features, the SCL algorithm is used to train a binary classifier. SFA is the spectral feature alignment technique of Pan et al. (2010). Both the LSA and FALSA techniques are based on latent semantic analysis (Pan et al., 2010). For the Within-Domain baseline, we train a binary classifier using the labeled data from the target domain. This upper baseline represents the classification accuracy we could hope to obtain if we were to have labeled data for"
P11-1014,P07-1056,0,0.937463,"Missing"
P11-1014,P06-4020,1,0.770277,"ines and previous cross-domain sentiment classification techniques using the benchmark dataset. For all previous techniques we give the results reported in the original papers. The No Thesaurus baseline simulates the effect of not performing any feature expansion. We simply train a binary classifier using unigrams and bigrams as features from the labeled reviews in the source domains and apply the trained classifier on the target domain. This can be considered to be a lower bound that does not perform domain adaptation. SCL is the structural correspondence learning technique of Blitzer et al. (2006). In SCL-MI, features are selected using the mutual information between a feature (unigram or bigram) and a domain label. After selecting salient features, the SCL algorithm is used to train a binary classifier. SFA is the spectral feature alignment technique of Pan et al. (2010). Both the LSA and FALSA techniques are based on latent semantic analysis (Pan et al., 2010). For the Within-Domain baseline, we train a binary classifier using the labeled data from the target domain. This upper baseline represents the classification accuracy we could hope to obtain if we were to have labeled data for"
P11-1014,P08-1017,0,0.0228875,"use of unlabeled data enables us to accurately estimate the distribution of words in source and target domains. Our method can learn from a large amount of unlabeled data to leverage a robust cross-domain sentiment classifier. We model the cross-domain sentiment classification problem as one of feature expansion, where we append additional related features to feature vectors that represent source and target domain reviews in order to reduce the mismatch of features between the two domains. Methods that use related features have been successfully used in numerous tasks such as query expansion (Fang, 2008), and document classification (Shen et al., 2009). However, feature expansion techniques have not previously been applied to the task of cross-domain sentiment classification. In our method, we use the automatically created 133 thesaurus to expand feature vectors in a binary classifier at train and test times by introducing related lexical elements from the thesaurus. We use L1 regularized logistic regression as the classification algorithm. (However, the method is agnostic to the properties of the classifier and can be used to expand feature vectors for any binary classifier). L1 regularizati"
P11-1014,P97-1023,0,0.11935,"sensitive thesaurus for feature expansion. Given a labeled or an unlabeled review, we first split the review into individual sentences. We carry out part-of-speech (POS) tagging and lemmatization on each review sentence using the RASP sys134 tem (Briscoe et al., 2006). Lemmatization reduces the data sparseness and has been shown to be effective in text classification tasks (Joachims, 1998). We then apply a simple word filter based on POS tags to select content words (nouns, verbs, adjectives, and adverbs). In particular, previous work has identified adjectives as good indicators of sentiment (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000). Following previous work in cross-domain sentiment classification, we model a review as a bag of words. We select unigrams and bigrams from each sentence. For the remainder of this paper, we will refer to unigrams and bigrams collectively as lexical elements. Previous work on sentiment classification has shown that both unigrams and bigrams are useful for training a sentiment classifier (Blitzer et al., 2007). We note that it is possible to create lexical elements both from source domain labeled reviews as well as from unlabeled reviews in source and target domains. Next, we rep"
P11-1014,W02-1011,0,0.0328941,"learn from multiple source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products. 1 Introduction Users express opinions about products or services they consume in blog posts, shopping sites, or review sites. It is useful for both consumers as well as for producers to know what general public think about a particular product or service. Automatic document level sentiment classification (Pang et al., 2002; Turney, 2002) is the task of classifying a given review with respect to the sentiment expressed by the author of the review. For example, a sentiment classifier might classify a user review about a movie as positive or negative depending on the sentiment 132 expressed in the review. Sentiment classification has been applied in numerous tasks such as opinion mining (Pang and Lee, 2008), opinion summarization (Lu et al., 2009), contextual advertising (Fan and Chang, 2010), and market analysis (Hu and Liu, 2004). Supervised learning algorithms that require labeled data have been successfully us"
P11-1014,N04-1041,0,0.0331408,"have similar distributions are semantically similar. We compute f (u, w) as the pointwise mutual information between a lexical element u and a feature w as follows: c(u,w) N P Pn m j=1 c(u,j) i=1 c(i,w) × N N f (u, w) = log ! (1) Here, c(u, w) denotes the number of review sentences in which a lexical element u and a feature w co-occur, n and m respectively denote the total number of lexical elements and the total number of Pn P m features, and N = i=1 j=1 c(i, j). Pointwise mutual information is known to be biased towards infrequent elements and features. We follow the discounting approach of Pantel & Ravichandran (2004) to overcome this bias. Next, for two lexical elements u and v (represented by feature vectors u and v, respectively), we compute the relatedness τ (v, u) of the feature v to the feature u as follows, P w∈{x|f (v,x)>0} f (u, w) w∈{x|f (u,x)>0} f (u, w) τ (v, u) = P . (2) 1. Note that relatedness is an asymmetric measure by the definition given in Equation 2, and the relatedness τ (v, u) of an element v to another element u is not necessarily equal to τ (u, v), the relatedness of u to v. We use the relatedness measure defined in Equation 2 to construct a sentiment sensitive thesaurus in which,"
P11-1014,P02-1053,0,0.0546106,"e source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products. 1 Introduction Users express opinions about products or services they consume in blog posts, shopping sites, or review sites. It is useful for both consumers as well as for producers to know what general public think about a particular product or service. Automatic document level sentiment classification (Pang et al., 2002; Turney, 2002) is the task of classifying a given review with respect to the sentiment expressed by the author of the review. For example, a sentiment classifier might classify a user review about a movie as positive or negative depending on the sentiment 132 expressed in the review. Sentiment classification has been applied in numerous tasks such as opinion mining (Pang and Lee, 2008), opinion summarization (Lu et al., 2009), contextual advertising (Fan and Chang, 2010), and market analysis (Hu and Liu, 2004). Supervised learning algorithms that require labeled data have been successfully used to build sen"
P14-1058,J10-4006,0,0.21112,"., 2011) groups together words that express similar sentiments in • Using the learnt distribution prediction model, we propose a method to learn a crossdomain POS tagger. • Using the learnt distribution prediction model, we propose a method to learn a crossdomain sentiment classifier. To our knowledge, ours is the first successful attempt to learn a model that predicts the distribution of a word across different domains. 2 Related Work Learning semantic representations for words using documents from a single domain has received much attention lately (Vincent et al., 2010; Socher et al., 2013; Baroni and Lenci, 2010). As we have already discussed, the semantics of a word varies 614 sentence unigrams (surface) unigrams (lemma) unigrams (features) bigrams (lemma) bigrams (features) different domains. The created thesaurus is used to expand feature vectors during train and test stages in a binary classifier. However, unlike our method, SCL, SFA, or SST do not learn a prediction model between word distributions across domains. Prior knowledge of the sentiment of words, such as sentiment lexicons, has been incorporated into cross-domain sentiment classification. He et al. (2011) propose a joint sentiment-topic"
P14-1058,W06-1615,0,0.768872,"ve baselines in both tasks. Because our proposed distribution prediction method is unsupervised and task independent, it is potentially useful for a wide range of DA tasks such entity extraction (Guo et al., 2009) or dependency parsing (McClosky et al., 2010). Our contributions are summarised as follows: The POS of a word is influenced both by its context (contextual bias), and the domain of the document in which it appears (lexical bias). For example, the word signal is predominately used as a noun in MEDLINE, whereas it appears predominantly as an adjective in the Wall Street Journal (WSJ) (Blitzer et al., 2006). Consequently, a tagger trained on WSJ would incorrectly tag signal in MEDLINE. Blitzer et al. (2006) append the source domain labeled data with predicted pivots (i.e. words that appear in both the source and target domains) to adapt a POS tagger to a target domain. Choi and Palmer (2012) propose a cross-domain POS tagging method by training two separate models: a generalised model and a domain-specific model. At tagging time, a sentence is tagged by the model that is most similar to that sentence. Huang and Yates (2009) train a Conditional Random Field (CRF) tagger with features retrieved fr"
P14-1058,D12-1120,0,0.0191454,"words that appear in both the source and target domains) to adapt a POS tagger to a target domain. Choi and Palmer (2012) propose a cross-domain POS tagging method by training two separate models: a generalised model and a domain-specific model. At tagging time, a sentence is tagged by the model that is most similar to that sentence. Huang and Yates (2009) train a Conditional Random Field (CRF) tagger with features retrieved from a smoothing model trained using both source and target domain unlabeled data. Adding latent states to the smoothing model further improves the POS tagging accuracy (Huang and Yates, 2012). Schnabel and Sch¨utze (2013) propose a training set filtering method where they eliminate shorter words from the training data based on the intuition that longer words are more likely to be examples of productive linguistic processes than shorter words. • Given the distribution wS of a word w in a source domain S, we propose a method for learning its distribution wT in a target domain T . The sentiment of a word can vary from one domain to another. In Structural Correspondence Learning (SCL) (Blitzer et al., 2006; Blitzer et al., 2007), a set of pivots are chosen using pointwise mutual infor"
P14-1058,P07-1056,0,0.942627,"the same word is often associated with negative sentimentbearing words such as superficial or formulaic. Consequently, the distributional representations of the word lightweight will differ considerably between the two domains. In this paper, given the distribution wS of a word w in the source domain S, we propose an unsupervised method for predicting its distribution wT in a different target domain T . The ability to predict how the distribution of a word varies from one domain to another is vital for numerous adaptation tasks. For example, unsupervised cross-domain sentiment classification (Blitzer et al., 2007; Aue and Gamon, 2005) involves using sentiment-labeled user reviews from the source domain, and unlabeled reviews from both the source and the target domains to learn a sentiment classifier for the target domain. Domain adaptation (DA) of sentiment classification becomes extremely challenging when the distributions of words in the source and the target domains are very different, because the features learnt from the source domain labeled reviews might not appear in the target domain reviews that must be classified. By predicting the distribution of a word across different domains, we can find"
P14-1058,P11-1014,1,0.95001,"ntwise mutual information. Linear predictors are then learnt to predict the occurrence of those pivots, and SVD is used to construct a lower dimensional representation in which a binary classifier is trained. Spectral Feature Alignment (SFA) (Pan et al., 2010) also uses pivots to compute an alignment between domain specific and domain independent features. Spectral clustering is performed on a bipartite graph representing domain specific and domain independent features to find a lowerdimensional projection between the two sets of features. The cross-domain sentiment-sensitive thesaurus (SST) (Bollegala et al., 2011) groups together words that express similar sentiments in • Using the learnt distribution prediction model, we propose a method to learn a crossdomain POS tagger. • Using the learnt distribution prediction model, we propose a method to learn a crossdomain sentiment classifier. To our knowledge, ours is the first successful attempt to learn a model that predicts the distribution of a word across different domains. 2 Related Work Learning semantic representations for words using documents from a single domain has received much attention lately (Vincent et al., 2010; Socher et al., 2013; Baroni a"
P14-1058,P98-2127,0,0.0360269,"lving a unigram and a bigram. Consequently, in matrix A, we consider co-occurrences only between unigrams vs. unigrams, and bigrams vs. unigrams. We consider each row in A as representing the distribution of a feature (i.e. unigrams or bigrams) in a particular domain over the unigram features extracted from that domain (represented by the columns of A). We apply Positive Pointwise Mutual Information (PPMI) to the cooccurrence matrix A. This is a variation of the Pointwise Mutual Information (PMI) (Church and Hanks, 1990), in which all PMI values that are less than zero are replaced with zero (Lin, 1998; Bullinaria and Levy, 2007). Let F be the matrix that results when PPMI is applied to A. Matrix F has the same number of rows, nr , and columns, nc , as the raw co-occurrence matrix A. Distribution Prediction In-domain Feature Vector Construction Before we tackle the problem of learning a model to predict the distribution of a word across domains, we must first compute the distribution of a word from a single domain. For this purpose, we represent a word w using unigrams and bigrams that co-occur with w in a sentence as follows. Given a document H, such as a user-review of a product, we split"
P14-1058,P06-4020,1,0.711747,"ied to A. Matrix F has the same number of rows, nr , and columns, nc , as the raw co-occurrence matrix A. Distribution Prediction In-domain Feature Vector Construction Before we tackle the problem of learning a model to predict the distribution of a word across domains, we must first compute the distribution of a word from a single domain. For this purpose, we represent a word w using unigrams and bigrams that co-occur with w in a sentence as follows. Given a document H, such as a user-review of a product, we split H into sentences, and lemmatize each word in a sentence using the RASP system (Briscoe et al., 2006). Using a standard stop word list, we filter out frequent non-content unigrams and select the remainder as unigram features to represent a sentence. Next, we generate bigrams of word lemmas and remove any bigrams that consists only of stop words. Bigram features capture negations more accurately than unigrams, and have been found to be useful for sentiment classification tasks. Table 1 shows the unigram and bigram features we extract for a sentence using this procedure. Using data from a single doNote that in addition to the above-mentioned representation, there are many other ways to represen"
P14-1058,N10-1004,0,0.066055,"o steps. Using two popular multi-domain datasets, we evaluate the proposed method in two prediction tasks: (a) predicting the POS of a word in a target domain, and (b) predicting the sentiment of a review in a target domain. Without requiring any task specific customisations, systems based on our distribution prediction method significantly outperform competitive baselines in both tasks. Because our proposed distribution prediction method is unsupervised and task independent, it is potentially useful for a wide range of DA tasks such entity extraction (Guo et al., 2009) or dependency parsing (McClosky et al., 2010). Our contributions are summarised as follows: The POS of a word is influenced both by its context (contextual bias), and the domain of the document in which it appears (lexical bias). For example, the word signal is predominately used as a noun in MEDLINE, whereas it appears predominantly as an adjective in the Wall Street Journal (WSJ) (Blitzer et al., 2006). Consequently, a tagger trained on WSJ would incorrectly tag signal in MEDLINE. Blitzer et al. (2006) append the source domain labeled data with predicted pivots (i.e. words that appear in both the source and target domains) to adapt a P"
P14-1058,P12-2071,0,0.0242231,"ised as follows: The POS of a word is influenced both by its context (contextual bias), and the domain of the document in which it appears (lexical bias). For example, the word signal is predominately used as a noun in MEDLINE, whereas it appears predominantly as an adjective in the Wall Street Journal (WSJ) (Blitzer et al., 2006). Consequently, a tagger trained on WSJ would incorrectly tag signal in MEDLINE. Blitzer et al. (2006) append the source domain labeled data with predicted pivots (i.e. words that appear in both the source and target domains) to adapt a POS tagger to a target domain. Choi and Palmer (2012) propose a cross-domain POS tagging method by training two separate models: a generalised model and a domain-specific model. At tagging time, a sentence is tagged by the model that is most similar to that sentence. Huang and Yates (2009) train a Conditional Random Field (CRF) tagger with features retrieved from a smoothing model trained using both source and target domain unlabeled data. Adding latent states to the smoothing model further improves the POS tagging accuracy (Huang and Yates, 2012). Schnabel and Sch¨utze (2013) propose a training set filtering method where they eliminate shorter"
P14-1058,J07-2002,0,0.0299297,"d remove any bigrams that consists only of stop words. Bigram features capture negations more accurately than unigrams, and have been found to be useful for sentiment classification tasks. Table 1 shows the unigram and bigram features we extract for a sentence using this procedure. Using data from a single doNote that in addition to the above-mentioned representation, there are many other ways to represent the distribution of a word in a particular domain (Turney and Pantel, 2010). For example, one can limit the definition of co-occurrence to words that are linked by some dependency relation (Pado and Lapata, 2007), or extend the window of co-occurrence to the entire document (Baroni and Lenci, 2010). Since the method we propose in Section 3.2 to predict the distribution of a word across domains does not depend on the particular 615 Algorithm 1 Learning a prediction model. feature representation method, any of these alternative methods could be used. To reduce the dimensionality of the feature space, and create dense representations for words, we perform SVD on F. We use the left singular vectors corresponding to the k largest singular ˆ of values to compute a rank k approximation F, F. We perform trunc"
P14-1058,J90-1003,0,0.411652,"cooccurrences of bigrams are rare compared to cooccurrences of unigrams, and co-occurrences involving a unigram and a bigram. Consequently, in matrix A, we consider co-occurrences only between unigrams vs. unigrams, and bigrams vs. unigrams. We consider each row in A as representing the distribution of a feature (i.e. unigrams or bigrams) in a particular domain over the unigram features extracted from that domain (represented by the columns of A). We apply Positive Pointwise Mutual Information (PPMI) to the cooccurrence matrix A. This is a variation of the Pointwise Mutual Information (PMI) (Church and Hanks, 1990), in which all PMI values that are less than zero are replaced with zero (Lin, 1998; Bullinaria and Levy, 2007). Let F be the matrix that results when PPMI is applied to A. Matrix F has the same number of rows, nr , and columns, nc , as the raw co-occurrence matrix A. Distribution Prediction In-domain Feature Vector Construction Before we tackle the problem of learning a model to predict the distribution of a word across domains, we must first compute the distribution of a word from a single domain. For this purpose, we represent a word w using unigrams and bigrams that co-occur with w in a se"
P14-1058,P05-1004,0,0.0329206,"niversity of Sussex Falmer, Brighton, BN1 9QJ, UK Introduction The Distributional Hypothesis, summarised by the memorable line of Firth (1957) – You shall know a word by the company it keeps – has inspired a diverse range of research in natural language processing. In such work, a word is represented by the distribution of other words that co-occur with it. Distributional representations of words have been successfully used in many language processing tasks such as entity set expansion (Pantel et al., 2009), part-of-speech (POS) tagging and chunking (Huang and Yates, 2009), ontology learning (Curran, 2005), computing semantic textual similarity (Besanc¸on et al., 1999), and lexical inference (Kotlerman et al., 2012). 1 In this paper, we use the term domain to refer to a collection of documents about a particular topic, for example reviews of a particular kind of product. 613 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 613–623, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics across different domains, and such variations are not captured by models that only learn a single semantic representation for a w"
P14-1058,P07-1033,0,0.288919,"Missing"
P14-1058,D12-1060,0,0.0154934,"ams (lemma) unigrams (features) bigrams (lemma) bigrams (features) different domains. The created thesaurus is used to expand feature vectors during train and test stages in a binary classifier. However, unlike our method, SCL, SFA, or SST do not learn a prediction model between word distributions across domains. Prior knowledge of the sentiment of words, such as sentiment lexicons, has been incorporated into cross-domain sentiment classification. He et al. (2011) propose a joint sentiment-topic model that imposes a sentiment-prior depending on the occurrence of a word in a sentiment lexicon. Ponomareva and Thelwall (2012) represent source and target domain reviews as nodes in a graph and apply a label propagation algorithm to predict the sentiment labels for target domain reviews from the sentiment labels in source domain reviews. A sentiment lexicon is used to create features for a document. Although incorporation of prior sentiment knowledge is a promising technique to improve accuracy in cross-domain sentiment classification, it is complementary to our task of distribution prediction across domains. The unsupervised DA setting that we consider does not assume the availability of labeled data for the target"
P14-1058,N09-1032,0,0.085558,"uire any labeled data in either of the two steps. Using two popular multi-domain datasets, we evaluate the proposed method in two prediction tasks: (a) predicting the POS of a word in a target domain, and (b) predicting the sentiment of a review in a target domain. Without requiring any task specific customisations, systems based on our distribution prediction method significantly outperform competitive baselines in both tasks. Because our proposed distribution prediction method is unsupervised and task independent, it is potentially useful for a wide range of DA tasks such entity extraction (Guo et al., 2009) or dependency parsing (McClosky et al., 2010). Our contributions are summarised as follows: The POS of a word is influenced both by its context (contextual bias), and the domain of the document in which it appears (lexical bias). For example, the word signal is predominately used as a noun in MEDLINE, whereas it appears predominantly as an adjective in the Wall Street Journal (WSJ) (Blitzer et al., 2006). Consequently, a tagger trained on WSJ would incorrectly tag signal in MEDLINE. Blitzer et al. (2006) append the source domain labeled data with predicted pivots (i.e. words that appear in bo"
P14-1058,I13-1023,0,0.0944857,"Missing"
P14-1058,P11-1013,0,0.0501642,"10; Socher et al., 2013; Baroni and Lenci, 2010). As we have already discussed, the semantics of a word varies 614 sentence unigrams (surface) unigrams (lemma) unigrams (features) bigrams (lemma) bigrams (features) different domains. The created thesaurus is used to expand feature vectors during train and test stages in a binary classifier. However, unlike our method, SCL, SFA, or SST do not learn a prediction model between word distributions across domains. Prior knowledge of the sentiment of words, such as sentiment lexicons, has been incorporated into cross-domain sentiment classification. He et al. (2011) propose a joint sentiment-topic model that imposes a sentiment-prior depending on the occurrence of a word in a sentiment lexicon. Ponomareva and Thelwall (2012) represent source and target domain reviews as nodes in a graph and apply a label propagation algorithm to predict the sentiment labels for target domain reviews from the sentiment labels in source domain reviews. A sentiment lexicon is used to create features for a document. Although incorporation of prior sentiment knowledge is a promising technique to improve accuracy in cross-domain sentiment classification, it is complementary to"
P14-1058,D13-1170,0,0.00551686,"SST) (Bollegala et al., 2011) groups together words that express similar sentiments in • Using the learnt distribution prediction model, we propose a method to learn a crossdomain POS tagger. • Using the learnt distribution prediction model, we propose a method to learn a crossdomain sentiment classifier. To our knowledge, ours is the first successful attempt to learn a model that predicts the distribution of a word across different domains. 2 Related Work Learning semantic representations for words using documents from a single domain has received much attention lately (Vincent et al., 2010; Socher et al., 2013; Baroni and Lenci, 2010). As we have already discussed, the semantics of a word varies 614 sentence unigrams (surface) unigrams (lemma) unigrams (features) bigrams (lemma) bigrams (features) different domains. The created thesaurus is used to expand feature vectors during train and test stages in a binary classifier. However, unlike our method, SCL, SFA, or SST do not learn a prediction model between word distributions across domains. Prior knowledge of the sentiment of words, such as sentiment lexicons, has been incorporated into cross-domain sentiment classification. He et al. (2011) propos"
P14-1058,D13-1016,0,0.020529,"ain reviews from the sentiment labels in source domain reviews. A sentiment lexicon is used to create features for a document. Although incorporation of prior sentiment knowledge is a promising technique to improve accuracy in cross-domain sentiment classification, it is complementary to our task of distribution prediction across domains. The unsupervised DA setting that we consider does not assume the availability of labeled data for the target domain. However, if a small amount of labeled data is available for the target domain, it can be used to further improve the performance of DA tasks (Xiao et al., 2013; Daum´e III, 2007). 3 3.1 This is an interesting and well researched book this, is, an, interesting, and, well, researched, book this, be, an, interest, and, well, research, book interest, well, research, book this+be, be+an, an+interest, interest+and, and+well, well+research, research+book an+interest, interest+and, and+well, well+research, research+book Table 1: Extracting unigram and bigram features. main, we construct a feature co-occurrence matrix A in which columns correspond to unigram features and rows correspond to either unigram or bigram features. The value of the element aij in th"
P14-1058,D07-1118,0,\N,Missing
P14-1058,P09-1056,0,\N,Missing
P14-1058,C98-2122,0,\N,Missing
P14-1058,D09-1098,0,\N,Missing
P87-1027,E85-1025,1,0.86709,"ated in Figure 4 can clearly be directly mapped into a feature d u s t e r within the features and feature set declarations used by the dictionary and grammar projects. A colnparison of the existing entries for ~oelieve~ in the hand crafted lexicon (Figure 1) and the third word sense for ~believem extracted from LDOCE demonstrates that much of the information available from L D O C E is of direct utility - - for example the SUBCAT values can be derived by an analysis of the T a k e s values and the O R a i e i n g logical type specification above. Indeed, we have demonstrated the feasibility (Alshawi et al., 1985) of driving a parsing system directly from the information av~lable in LDOCE by constructing dictionary entries for the PATR-H system (Shieber, Figure 4: A lexical template derived from LDOCE This resulting structure is a lexical template, designed as a formal representation for the kind of syntacrico-semantic information which can be extracted from the dictionary and which is relevant to a system for automatic morphological and syntactic analysis of English texts. The overall transformation strategy employed by our system attempts to derive both subcategorisation frames relevant to a particul"
P87-1027,J87-3002,1,\N,Missing
P87-1027,J87-3008,0,\N,Missing
P87-1027,E87-1011,1,\N,Missing
P87-1027,C86-1066,0,\N,Missing
P87-1027,P84-1075,0,\N,Missing
P90-1026,1988.tmi-1.12,0,0.292484,"Missing"
P90-1026,E89-1025,0,0.0867367,"yet several plausible grammatical analyses handled by the parser me beyond the capacity of even approach. This paper reports on experience arising from the addition of a generator component to the FLU2 environment; the algorithm is a variant of that proposed in Shieber et al. (1989). We first consider general aspects of adapting unification grammars initially developed for parsing to their use in generation. A brief description of the generator in ELU highlights the differences and improvements we have adopted. We then demonstrate shortcomings 2 &quot;Environnement Linguistique d'Unification&quot;. Cf. Johnson & Rosner (1989) for a description of UD (Unification Device) which includes the parser and facilities such as procedural abswactions and extended data types (lists and trees) and Estival et al. (1989) for a description of the extended ELU system which incorporates the ori~ml UD plus a generation and translation component. of this class of generation algorithms on the basis of two case studies. 2. Generating with Unification Grammars The goal of employing a single, minimally augmented, grammar for both parsing and generation has become more accessible with the introduction of declaratve grammar formalisms (cf"
P90-1026,P85-1018,0,0.0606533,"' restrictorset characterizes a pivot. A restrictorset is also computed for each lexical stem, in order to retrieve words efficiently during generation The generation algorithm uses the distinction between chaining and non-chaining rules as well as 3 Our discussion will therefore assume familiarity with thispaper. 4 Restrictors are attributes selected by the writer of a grammar as being maximally distinctive; when two FSs are to be unified, their respective restrictor values axe first checked for compatibility, so as to eliminate the cost of an attempted nnificaton which is bound to fail. See Shieber (1985). semantic head. A role in which a O~ghter sluues the semantics of the mother can thus be made into a chaining rule or a non-chaining rule, according to whether that daughter is identified as the semantic head, and a rule that would otherwise have multiple semantic heads can be assigned just one. 6 A rule in which there is no such daughter will remain a nonchaining rule, but may nevertheless be annotated with a similar specification. The rationale is twofold: the ability to coerce what would otherwise be a chaining rule to a non-chaining rule grallts the grammar writer more control over genera"
P90-1026,P89-1002,0,0.249579,"Missing"
P90-1026,E87-1029,0,\N,Missing
P90-1026,C88-2150,0,\N,Missing
P90-1026,C88-2128,0,\N,Missing
P91-1028,E89-1025,0,0.0529352,"his information by specifying the 'intransitive' class as one of their superclasses - it then becomes unnecessaw to specify the relevant properties individually for each such verb. The lexicon may be thought of as a tangled hierarchy of classes linked by inheritance paths, with, at the most specific level, lexicai classes and, at the most general, classes for which no superclasses have been defined, and which therefore inherit no information from elsewhere. S ""Environnement Linguistique d'Unlfication"" - see Estival (1990), and, for a description of the earlier UD system on which E~u is based, Johnson and Rosner (1989). 215 Lexical entries are themselves classes, 4 and any information they contain is standardly specific to an individual word; lexical and non-lexical classes differ in that analysis and generation take only the former as entry points to the lexicon. Inheritance of a feature value from a superclass may be overridden by a conflicting value for that feature in a more specific class. This means, for example, that it is possible to place in the class which expresses general properties of verbs an equation such as '<* aux> = no' (i.e. ""typical verbs are not auxiliaries""), while placing the contradi"
P91-1028,C86-1016,0,0.0469393,"and Flickinger (1987) make use of lexical rules - the ELU lexicon does not provide such devices, although some of their functionality may be reproduced by the variant set mechanism. The approach described here differs from some previous proposals for default inheritance in unification-based lexicons in t h a t the process of building FSs is monotonic - classes m a y add information to a FS, but are unable to remove or alter it. Thus, given a C P L ( c i , . . . c . ) , any FS F admitted by a class c~ subsumes every FS that can be created by applying to F the classes (c~+ I , . . . c,~), m n. Karttunen (1986) and Shieber (1986) describe systems in which FSs m a y be modified by default statements in such a way t h a t this property does not automatically hold. These schemes permit default statements to override the effect of earlier statements, whereas default information in the ELU lexicon m a y itself be overridden. We now turn to some examples illustrating the r61e of defeasible inheritance in the lexicon. morpheme only in certain syntactic environments, namely when the verb is untensed or head of a verb-final clause. 9 Members of both classes share morphological, but not necessarily syntactic,"
P91-1028,P90-1021,0,0.258406,"Missing"
P91-1028,E89-1008,0,0.370753,"inder of C, ( c ~ + l , . . . c , ) . The global extension of L is then the yield of the most general class in its C P L - expressed in a slightly different way, the global extension of L is the result of applying to T the C P L of L. It is possible to exert quite fine control over inheritance; one property m a y override another when assigned in a main equation set, but cause failure when assigned in a variant set. Normally, variant sets are defined so as to be mutually exclusive; a FS that unifies with more than one of the variant sets is in effect multiplied, s T h e inheritance systems of Calder (1989) and Flickinger (1987) make use of lexical rules - the ELU lexicon does not provide such devices, although some of their functionality may be reproduced by the variant set mechanism. The approach described here differs from some previous proposals for default inheritance in unification-based lexicons in t h a t the process of building FSs is monotonic - classes m a y add information to a FS, but are unable to remove or alter it. Thus, given a C P L ( c i , . . . c . ) , any FS F admitted by a class c~ subsumes every FS that can be created by applying to F the classes (c~+ I , . . . c,~), m n."
P91-1028,J92-2004,0,\N,Missing
P94-1040,P89-1018,0,0.196166,"Missing"
P94-1040,J93-1002,1,0.9372,"I O N General-purpose natural language (NL) analysis systems have recently started to use declarative unification-based sentence grammar formalisms; systems of this type include SRI's CLARE system (Alshawi et al., 1992) and the A1vey NL Tools (ANLT; Briscoe et al., 1987a). Using a declarative formalism helps ease the task of developing and maintaining the grammar (Kaplan, 1987). In addition to syntactic processing, the systems incorporate lexical, morphological, and semantic processing, and have been applied successfully to the analysis of naturally-occurring texts (e.g. Alshawi et al., 1992; Briscoe & Carroll, 1993). Evaluations of the grammars in these particular systems have shown them to have wide coverage (Alshawi et al., 1992; Taylor, Grover &= Briscoe, 1989) 2. However, although the practical throughput of parsers with such realistic grammars is important, for example when process1This research was supported by SERC/DTI project 4/1/1261 'Extensions to the Alvey Natural Language Tools' and by EC ESPRIT BRA-7315 'ACQUILEX-II'. I am grateful to Ted Briscoe for comments on an earlier version of this paper, to David Weir for valuable discussions, and to Hiyan Alshawi for assistance with the CLARE system"
P94-1040,P81-1022,0,0.076945,"Missing"
P94-1040,W89-0221,0,0.0256818,"e greater than cubic, in the general case. The CF versions implicitly pack identical sequences of sub-analyses, and in all reductions at a given point with rules with the same number of daughters, the packed sequences can be formed into higher-level constituents as they stand without further processing. However, in the unification versions, on each reduce action the daughters of the rule involved have to be unified with every possible alternative sequence of the sub-analyses that are being consumed by the rule The grammar-dependent complexity of the LR parser makes it also appear intractable: Johnson (1989) shows that the number of LR(0) states for certain (pathological) grammars is exponentially related to the size of the grammar, and that there are some inputs which force an LR parser to visit all of these states in the course of a parse. aSchabes describes a table with no lookahead; the successful application of this technique supports Schabes' (1991:109) assertion that ""several other methods (such as LR(k)-like and SLR(k)-like) can also be used for constructing the parsing tables [...]"" aBarton, Berwick & Ristad (1987:221) calculate that GPSG, also with a maximum nesting depth of two, licenc"
P94-1040,W89-0220,0,0.0662614,"Missing"
P94-1040,J93-4001,0,0.0621929,"Missing"
P94-1040,H91-1036,0,0.114623,"Missing"
P94-1040,P91-1014,0,0.13945,"(e.g. Earley, 1970; Lang, 1974; P r a t t , 1975). Section 2 describes three unification-based parsers which are related to polynomial-complexity bottom-up CF parsing algorithms. Although incorporating unification increases their complexity to exponential on grammar size and input length (section 3), this appears to have little impact on practical performance (section 4). Sections 5 and 6 discuss these findings and present conclusions. THE The three parsers in this study are: a bottomup left-corner parser, a (non-deterministic) LR parser, and an LR-like parser based on an algorithm devised by Schabes (1991). All three parsers accept grammars written in the ANLT formalism (Briscoe et al., 1987a), and the first two are distributed as part of the ANLT package. The parsers create parse forests (Tomita, 1987) that incorporate subtree sharing (in which identical sub-analyses are shared between differing superordinate analyses) and node packing (where subanalyses covering the same portion of input whose root categories are in a subsumption relationship are merged into a single node). BOTTOM-UP LR Briscoe & Carroll (1993) describe a methodology for constructing an LR parser for a unificationbased gramma"
P94-1040,E89-1035,0,0.21704,"Missing"
P94-1040,P91-1041,0,0.171956,"Missing"
P94-1040,J87-1004,0,0.0962014,"unification increases their complexity to exponential on grammar size and input length (section 3), this appears to have little impact on practical performance (section 4). Sections 5 and 6 discuss these findings and present conclusions. THE The three parsers in this study are: a bottomup left-corner parser, a (non-deterministic) LR parser, and an LR-like parser based on an algorithm devised by Schabes (1991). All three parsers accept grammars written in the ANLT formalism (Briscoe et al., 1987a), and the first two are distributed as part of the ANLT package. The parsers create parse forests (Tomita, 1987) that incorporate subtree sharing (in which identical sub-analyses are shared between differing superordinate analyses) and node packing (where subanalyses covering the same portion of input whose root categories are in a subsumption relationship are merged into a single node). BOTTOM-UP LR Briscoe & Carroll (1993) describe a methodology for constructing an LR parser for a unificationbased grammar, in which a CF 'backbone' grammar is automatically constructed from the unification grammar, a parse table is constructed from the backbone grammar, and a parser is driven by the table and further co"
P94-1040,W89-0228,0,0.054114,"Missing"
P94-1040,1991.iwpt-1.12,0,0.0562888,"Missing"
P94-1040,E93-1010,0,\N,Missing
P94-1040,1991.iwpt-1.19,0,\N,Missing
P99-1061,C90-2018,0,0.016166,"Missing"
P99-1061,P99-1052,0,0.0251076,"parsing: (i) one can use several start and ~nd vertices (e.g., in case of n-best chains or T h i s approach does not always favor paths with longest edges as the example in figure 2 shows--instead it prefers paths containing no lexical edges (where this is possible) and there might be several such paths having the same cost. Longest (sub)paths, however, can be obtained by employing an exponential estimation function. Other properties, such as prosodic information or probabilistic scores could also be utilized in the estimation function. A detailed description of the approach can be found in (Kasper et al., 1999). P R S Figure 2: Computing best partial analyses. Note that the paths P R and QR are chosen, but not S T , although S is the longest edge. 478 10 Conclusions and Further Work The collection of methods described in this paper has enabled us to unite deep linguistic analysis with speech processing. The overall speedup compared to the original system is about a factor of 10 up to 25. Below we present some absolute timings to give an impression of the current systems' performance. # sentences # words # lex. entries # chart items # results time first time overall German 5106 7 40.9 1024 5.8 1.46 s"
P99-1061,C90-2039,0,0.0356496,"n unsuccessful unification, wasting space and reducing the overall throughput of the system. Tomabechi avoids these problems by simulating non-destructiveness without incurring the overhead necessary to support backtracking. First, it performs a destructive (but reversible) check that the two structures are compatible, and only when that succeeds does it produce an output structure. Thus, no output structures are built until it is certain that the unification will ultimately succeed. While an improvement over simple destructive unification, Tomabechi's approach still suffers from what Kogure (Kogure, 1990) calls redundant copying. The new feature structures produced in the second phase of unification include copies of all the substructures of the input graphs, even when these structures are unchanged. This can be avoided by reusing parts of the input structures in the output structure (Carroll and Malouf, 1999) without introducing significant bookkeeping overhead. To keep things as simple and efficient as possible, the improved unifier also only supports conjunctive feature structures. While disjunctions can be a convenient descriptive tool for writing grammars, they are not absolutely necessar"
P99-1061,1997.iwpt-1.19,0,0.0132806,"mmars for different languages. There is, however, room for further improvements. We intend to generalize to other cases the technique for removing unnecessary lexical items. A detailed investigation of the quickcheck method and its interaction with the rule application filter is planned for the near future. Since almost all failing unifications are avoided through the use of filtering techniques, we will now focus on methods to reduce the number of chart items that do not contribute to any analysis; for instance, by computing context-free or regular approximations of the HPSG grammars (e.g., (Nederhof, 1997)). Acknowledgments The research described in this paper has greatly benefited from a very fruitful collaboration with the HPSG group of CSLI at Stanford University. This cooperation is part of the deep linguistic processing effort within the BMBF project VERBMOBIL. Special thanks are due to Stefem Miiller for discussing the topic of German prefix verbs. Thanks to Dan Flickinger who provided us with several English phenomena. We also want to thank Nicolas Nicolov for reading a version of this paper. Stephan Oepen's and MarkJan Nederhof's fruitful comments have helped us a lot. Finally, we want"
P99-1061,P85-1018,0,0.218395,"the feature structures. Since H P S G requires all relevant information to be contained in the S Y N S E M feature of the mother structure, the unnecessary daughters only increase the size of the overall feature structure without constraining the search space. Due to the Locality Principle of H P S G (Pollard and Sag, 1987, p. 145ff), they can therefore be legally removed in fully instantiated items. The situation is different for active chart items since daughters can affect their siblings. To be independent from a-certain grammatical theory or implementation, we use restrictors similar to (Shieber, 1985) as a flexible and easyto-use specification to perform this deletion. A positive restrictor is an a u t o m a t o n describing the paths in a feature structure t h a t will remain after restriction (the deletion operation), 8 3There are refinements of the technique which we have implemented and which in practice produce additional benefits; we will report these in a subsequent paper. Briefly, they involve an improvement to th e path collection method, and the storage of other information besides types in the vectors. Limiting the N u m b e r of Initial Chart Items Since the number of lexical e"
P99-1061,P91-1041,0,0.361775,"of operations that meet the needs of grammar writers but still can be efficiently implemented. The unifier which was part of the original HPSG grammar development system mentioned in the introduction (described by (Backofen and Krieger, 1993)) provided a number of advanced features, including distributed (or named) disjunctions (D6rre and Eisele, 1990) and support for full backtracking. While these operations were sometimes useful, 474 they also made the unifier much more complex than was really necessary. The unification algorithm used by the current system is a modification of Tomabechi's (Tomabechi, 1991) &quot;quasi-destructive&quot; unification algorithm. Tomabechi's algorithm is based on the insight that unification often fails, and copying should only be performed when the unification is going to succeed. This makes it particularly well suited to chart-based parsing. During parsing, each edge must be built without modifying the edges that contribute to it. With a non-backtracking unifier, one option is to copy the daughter feature structures before performing a destructive unification operation, while the other is to use a non-destructive algorithm that produces a copy of the result up to the point"
P99-1061,C94-1072,1,0.89873,"Missing"
P99-1061,1993.mtsummit-1.11,0,0.0191379,"ns, and speculate on extensions we intend to work on in the near future. Within the different sections, we refer to three corpora we have used to measure the effects of our methods. The reference corpora for English, German, and Japanese consist of 1200-5000 samples. 2 Precompiling the Lexicon Lexicon entries in the development system are small templates that are loaded and expanded on demand by the typed feature structure system. Thereafter, all lexical rules are applied to the expanded feature structures. The results of these two computations form the input of the analysis stage. 1VERBMOBIL(Wahlster, 1993) deals with the translation of spontaneously spoken dialogues, where only a minor part consists of &quot;sentences&quot; in a linguistic sense. Current languages are English, German, and Japanese. Some of the methods were originally developed in the context of another HPSG environment, the LKB (Copestake, 1998). This lends support to our claims of their independence from a particular parser or grammar engine. In order to save space and time in the runtime system, the expansion and the application of lexical rules is now done off-line. In addition, certain parts of the feature structure are deleted, sinc"
P99-1061,1991.iwpt-1.19,0,\N,Missing
P99-1061,C94-2144,1,\N,Missing
R13-1045,N01-1024,0,0.0213292,"hm. 350 Proceedings of Recent Advances in Natural Language Processing, pages 350–356, Hissar, Bulgaria, 7-13 September 2013. (Cruetz and Lagus, 2005, 2007), have brought a theoretical perspective considering input data to be ‘compressed’ into a morphologically analysed representation. This optimization scheme has achieved good results, and is amongst the most effective approaches for unsupervised morphological analysis. Most work on unsupervised learning of morphology has focused on concatenative morphology (De Pauw and Wagacha 2007; Hammarström and Borin 2011). Another perspective adopted by Schone and Jurafsky (2001) incorporates orthographic and phonological features, and induces semantic relatedness between word pairs using Latent Semantic Indexing. Their work shows comparable performance to Goldsmith’s (2000) Linguistica system. Yarowsky and Wicentowski (2000) experiment with learning irregular mnaturaorphology using a lightly supervised technique to align irregular words to their lemmas by estimating the distribution of ratios over part-of-speech classes of inflected words to lemmas. More recently, researchers have addressed nonconcatenative morphology, such as for Semitic languages, using a variety o"
R13-1045,D09-1075,0,0.0320705,"obability value in our clusters as the value for ܲ. Proximity for Pattern Cluster k P(k) yErf 0.99999 yHrf 2.59E-07 ysrf 2.58E-07 ySrf 2.32E-07 yEkf 2.31E-07 tErf 1.10E-09 yErj 4.24E-10 yErD 3.29E-10 yEr$ 2.36E-10 msrf 2.14E-12 zxrf 1.51E-12 … … ܵܮ൫ܲ൯= log ܲ() − log ܲ (Eq. 3) The score is also exponentially Length Adjusted ( )ܣܮfor each pattern,, according to the length of the pattern, ||, in terms of the number of affix charaters in . This boosts the score for lengthier morphemes which are relatively infrequent. The intuition for adjustment formula comes from the work of (Chung and Gildea, 2009) and (Liang and Klein, 2009), who use a exponential Length Penalty measure to adjust their model for morpheme length. Table 3: ME values for the word yErf. 4.4 Dictionary Induction | = )||(ܣܮ| Using the respective word clusters we create dictionaries for two types of morphemes, roots and patterns, such that we score the morphemes thus: Higher scoring morphemes are more plausible and ranked higher in the lexical list than lower ones. The procedure for scoring is adapted and amended from the work of De Pauw and Wagacha (2007). For the pattern lexicon, we score each pattern in the following"
R13-1045,P00-1027,0,0.0718843,"orphologically analysed representation. This optimization scheme has achieved good results, and is amongst the most effective approaches for unsupervised morphological analysis. Most work on unsupervised learning of morphology has focused on concatenative morphology (De Pauw and Wagacha 2007; Hammarström and Borin 2011). Another perspective adopted by Schone and Jurafsky (2001) incorporates orthographic and phonological features, and induces semantic relatedness between word pairs using Latent Semantic Indexing. Their work shows comparable performance to Goldsmith’s (2000) Linguistica system. Yarowsky and Wicentowski (2000) experiment with learning irregular mnaturaorphology using a lightly supervised technique to align irregular words to their lemmas by estimating the distribution of ratios over part-of-speech classes of inflected words to lemmas. More recently, researchers have addressed nonconcatenative morphology, such as for Semitic languages, using a variety of empirical approaches. Daya et al. (2008) learn Semitic roots using supervised learning, building a multi-class classifier for individual root radicals. Clark (2007) uses Arabic as a test-bed to study semi-supervised learning of complex broken plural"
R13-1045,J08-3005,0,0.031521,"ic and phonological features, and induces semantic relatedness between word pairs using Latent Semantic Indexing. Their work shows comparable performance to Goldsmith’s (2000) Linguistica system. Yarowsky and Wicentowski (2000) experiment with learning irregular mnaturaorphology using a lightly supervised technique to align irregular words to their lemmas by estimating the distribution of ratios over part-of-speech classes of inflected words to lemmas. More recently, researchers have addressed nonconcatenative morphology, such as for Semitic languages, using a variety of empirical approaches. Daya et al. (2008) learn Semitic roots using supervised learning, building a multi-class classifier for individual root radicals. Clark (2007) uses Arabic as a test-bed to study semi-supervised learning of complex broken plural structure modelled using memory-based algorithms, with the aim of gaining insights into human language acquisition. Most work on unsupervised learning of morphology has focused on concatenative morphology (Hammarström and Borin 2011). The few studies that have focussed on nonconcatenative morphology, such as for Semitic languages, have not used naturally written text. For example, Rodrig"
R13-1045,J11-2002,0,0.025462,", without referring to application of any clustering algorithm. 350 Proceedings of Recent Advances in Natural Language Processing, pages 350–356, Hissar, Bulgaria, 7-13 September 2013. (Cruetz and Lagus, 2005, 2007), have brought a theoretical perspective considering input data to be ‘compressed’ into a morphologically analysed representation. This optimization scheme has achieved good results, and is amongst the most effective approaches for unsupervised morphological analysis. Most work on unsupervised learning of morphology has focused on concatenative morphology (De Pauw and Wagacha 2007; Hammarström and Borin 2011). Another perspective adopted by Schone and Jurafsky (2001) incorporates orthographic and phonological features, and induces semantic relatedness between word pairs using Latent Semantic Indexing. Their work shows comparable performance to Goldsmith’s (2000) Linguistica system. Yarowsky and Wicentowski (2000) experiment with learning irregular mnaturaorphology using a lightly supervised technique to align irregular words to their lemmas by estimating the distribution of ratios over part-of-speech classes of inflected words to lemmas. More recently, researchers have addressed nonconcatenative m"
R13-1045,N09-1024,0,0.0570327,"Missing"
R13-1045,N09-1069,0,\N,Missing
S01-1029,W96-0209,1,0.870646,"Missing"
S01-1029,A94-1009,0,0.0297692,"essor and parser are used for identifying predicates and argument heads for application of the acquired selectional preferences for disambiguation. Anaphora resolution is used at run-time to make links between antecedents of nouns, where the antecedents or the predicates may be in subject or object relationships. Preprocessor and Parser The preprocessor consists of three modules applied in sequence: a tokeniser, a part-of-speech (PoS) tagger, and a lemmatiser. The tokeniser comprises a small set of manually-developed finite-state rules for identifying word and sentence boundaries. The tagger (Elworthy, 1994) uses a bigram HMM augmented with a statistical unknown word guesser. Vhen applied to the training data for selectional preference acquisition it produces the single highest-ranked tag for each word; at run-time it returns multiple tags whose associated forward-backward probabilities are incorporated into parse probabilities. The lemmatiser ( Minnen et al., 2001) reduces inflected verbs and nouns to their base forms. The parser uses a &apos;shallow&apos; unification-based grammar of English PoS tags, performs .disambiguation using a context-sensitive probabilistic model (Carroll and Briscoe, 1996), and"
S01-1029,C96-1021,0,0.0341865,"Missing"
S01-1029,J98-2002,0,0.0668346,"Missing"
S01-1029,W97-0209,0,0.0431338,"ses when they are not. However, this means we loose out in cases where preferences do not provide the necessary information and other complementary information would help. Another disadvantage of using selectional preferences alone for disambiguation is that the preferences only apply to the grammatical slots for which they have been acquired. In addition, selectional preferences only help disambiguation for slots where there is a strong enough tie between predicate and argument. In this work, we use subject and object relationships, since these appear to work better than other relationships (Resnik, 1997; McCarthy, 2001), and we use argument heads, rather than the entire argument phrase. Our basic system is restricted to using only selectional information, and no other source of disambiguating information. However, we ex119 that is returned from the disambiguation phase. For selectional preference acquisition we applied the analysis system to the 90 million words of the written portion of the British National Corpus (BNC); both in the acquisition phase and at run-time we extracted from the analyser output only subject-verb and verb-direct object dependencies2. Thus we did not use the SENSEVAL"
W00-1427,E99-1042,1,0.5,"peed of the generator on a Sun Ultra 10 workstation. In order to discount program s t a r t u p times (which are anyway only of the order of 0.05 seconds) we used input files of 400K and 800K tokens and recorded the difference in timings; we took the averages of 10 runs. Despite its wide coverage the morphological generator is very fast: it generates at a rate of more t h a n 80,000 words per second. 5 3 The Generator System in an Applied 3.1 T e x t S i m p l i f i c a t i o n The morphological generator forms part of a prototype system for automatic simplification of English newspaper text (Carroll et al., 1999). The goal is to help people with aphasia (a language impairment typically occurring as a result of a stroke or head injury) to better understand English newspaper text. The system comprises two main components: an analysis module which downloads the source newspaper texts from the web and computes syntactic analyses for the sentences in them, and a simplification module which operates on the output of the analyser to improve the comprehensit)ility of the text. Syntactic simplification (Canning and Tait, 1999) operates on the syntax trees produced in the analysis phase, for example converting"
W00-1427,C96-2187,0,0.01743,"he list then the word form generated will still be correct with respect to American English. 2.4 D e r i v i n g t h e G e n e r a t o r The morphological generator comprises a set of of approximately 1,650 rules expressing morphological regularities, subregularities, and exceptions for specific words; also around 350 lines of C/Flex code for program initialisation and defining the functions called by the rule actions. The rule set is in fact obtained by automatically reversing a morphological analyser. This is a much enhanced version of the analyser originally developed for tile GATE system (Cunningham et al., 1996). M i n n e n and Carroll (Under review) describe in detail how the reversal is performed. The generator executable occupies around 700Kb on disc. The analyser--and therefore the generator-includes exception lists derived from WordNet (version 1.5: Miller et al., 1993). In addition. we have incorporated data acquired semiautomatically from the following corpora and machine readable,dictionaries: t h e . . L O B . corpus (Garside et al., 1987), the Penn Treebank (Marcus et al., 1993), the SUSANNE corpus (Sampson, 1995), the Spoken English Corpus (Taylor and Knowles, 1988), the Oxford Psycholing"
W00-1427,J96-2002,0,0.0152047,"Missing"
W00-1427,W96-0501,0,\N,Missing
W00-1427,J93-2004,0,\N,Missing
W00-1427,C94-1066,0,\N,Missing
W00-1427,E83-1027,0,\N,Missing
W00-1427,E93-1012,0,\N,Missing
W00-1427,A97-2017,0,\N,Missing
W00-1601,H91-1036,0,\N,Missing
W00-1601,C96-2120,1,\N,Missing
W00-1601,J97-3004,0,\N,Missing
W00-1601,J87-1004,0,\N,Missing
W00-1601,J93-4001,0,\N,Missing
W00-1601,J93-1002,1,\N,Missing
W00-1601,P94-1040,1,\N,Missing
W00-1601,A92-1022,0,\N,Missing
W00-2007,J96-2002,0,0.0593147,"Missing"
W00-2007,P95-1011,1,0.890936,"Missing"
W00-2007,P98-1061,1,0.892923,"Missing"
W00-2007,W98-0139,1,0.885359,"Missing"
W00-2007,E99-1029,1,\N,Missing
W00-2007,C98-1059,1,\N,Missing
W00-2007,1997.iwpt-1.11,1,\N,Missing
W01-1512,W99-0802,0,0.127485,"been used for teaching. Besides the LKB, typed feature structure environments have been used at many universities, though unlike the systems cited above, most have only been used with small grammars and may not scale up. Hands on courses using various systems have been run at many recent summer schools including ESSLLI 99 (using the Xerox XLE, see Butt et al, 1999) and ESSLLI 97 and the 1999 LSA summer school (both using ConTroll, see Hinrichs and Meurers, 1999). Very little seems to have been formally published describing experiences in teaching with grammar development environments, though Bouma (1999) describes material for teaching a computational linguistics course that includes exercises using the Hdrug unification-based enviroment to extend a grammar. Despite this rich variety of tools, we believe that the LKB system has a combination of features which make it distinctive and give it a useful niche in teaching. The most important points are that its availability as open source, combined with scale and efficiency, allow advanced projects to be supported as well as introductory courses. As far as we are aware, it is the only system freely available with a broad coverage grammar that supp"
W01-1512,copestake-flickinger-2000-open,1,0.684868,"tware University of Groningen, CSLI, Stanford University Ventura Hall, Postbus 716, 9700 AS Groningen, 110 Pioneer Way Stanford, USA The Netherlands Mountain View, USA danf@csli.stanford.edu malouf@let.rug.nl Abstract We demonstrate the open-source LKB system which has been used to teach the fundamentals of constraint-based grammar development to several groups of students. 1 Overview of the LKB system The LKB system is a grammar development environment that is distributed as part of the open source LinGO tools (http://wwwcsli.stanford.edu/˜aac/lkb.html and http://lingo.stanford.edu, see also Copestake and Flickinger, 2000). It is an open-source grammar development environment implemented in Common Lisp, distributed not only as source but also as a standalone application that can be run on Linux, Solaris and Windows (see the website for specific requirements). It will also run under Macintosh Common Lisp, but for this a license is required. The LKB includes a parser, generator, support for large-scale inheritance hierarchies (including the use of defaults), various tools for manipulating semantic representations, a rich set of graphical tools for analyzing and debugging grammars, and extensive on-line documentat"
W02-1304,W02-1304,1,0.0511956,"Missing"
W02-1304,W00-1702,1,0.907606,"Missing"
W02-1304,W01-0703,1,0.824628,"Missing"
W02-1304,W99-0603,0,0.0765567,"Missing"
W02-1304,W00-1322,1,0.899983,"Missing"
W02-1304,J98-1001,0,0.0564481,"Missing"
W02-1304,J98-1006,0,0.0986902,"Missing"
W02-1304,magnini-cavaglia-2000-integrating,1,0.726135,"Missing"
W02-1304,W00-1326,1,0.886817,"Missing"
W02-1304,P98-2247,0,0.048344,"Missing"
W02-1304,S01-1029,1,0.792942,"Missing"
W02-1304,W97-0201,0,0.436936,"Missing"
W02-1304,S01-1017,1,\N,Missing
W02-1304,W00-1325,0,\N,Missing
W02-1304,P00-1064,0,\N,Missing
W02-1304,W00-0706,1,\N,Missing
W02-1304,P95-1026,0,\N,Missing
W02-1304,W02-0801,1,\N,Missing
W02-1304,C98-2242,0,\N,Missing
W02-2229,W98-0108,1,0.862273,"gs of TAG+6 tree can be viewed as invoking some fragment of computation (an elementary computation). Evans and Weir (1998) showed that elementary computations corresponding to bottom-up parsing can be expressed as finite state automata (FSA). All elementary computations for the supertags associated with a word can be combined into a single FSA. By minimizing this automaton (using standard minimization algorithms) sharing of elementary computation is achieved. The hope is that this will lead to significant reductions in parsing time. To date, this proposal has only received limited evaluation. Carroll et al. (1998a) demonstrated that for a large hand-crafted grammar the number of states was significantly reduced by merging and minimizing the FSA associated with a word. For example, the numbers of states in the automaton for the word come (associated with 133 supertags) was reduced from 898 to 50, for break from 1240 to 68, and give from 2494 to 83. This paper improves on this evaluation in two ways: firstly, the grammar used is automatically acquired, so we are not open to the charge that it was designed to make this technique work particularly well; secondly, we measure parse time, not just numbers of"
W02-2229,E99-1025,0,0.0268917,"Missing"
W02-2229,P95-1011,1,0.824869,"Missing"
W02-2229,P98-1061,1,0.936134,"ithm, each elementary  We are extremely grateful to Fei Xia for providing us with the grammar used in these experiments, and to Fei Xia and Anoop Sarkar for the help and advice they have given. 1. Note that the approach described in this section could be combined with supertag filtering.  c 2002 Olga Shaumyan, John Carroll and David Weir. Proceedings of the Sixth International Workshop on Tree Adjoining Grammar and Related Frameworks (TAG+6), pp. 201–205. Universit´a di Venezia. 202 Proceedings of TAG+6 tree can be viewed as invoking some fragment of computation (an elementary computation). Evans and Weir (1998) showed that elementary computations corresponding to bottom-up parsing can be expressed as finite state automata (FSA). All elementary computations for the supertags associated with a word can be combined into a single FSA. By minimizing this automaton (using standard minimization algorithms) sharing of elementary computation is achieved. The hope is that this will lead to significant reductions in parsing time. To date, this proposal has only received limited evaluation. Carroll et al. (1998a) demonstrated that for a large hand-crafted grammar the number of states was significantly reduced b"
W02-2229,C94-1024,0,0.0867669,"Missing"
W02-2229,J93-2004,0,0.0273008,"Missing"
W02-2229,W00-2027,0,0.0292538,"s significantly reduced it is not clear that parse time (as opposed to recognition time) will drop. This is because in order that parse trees be recoverable from the parse table, a considerable amount of book-keeping is required when the table is being completed. This increases both space and time requirements. 4. Experimental evaluation We used a grammar that was automatically induced by Fei Xia (1999) from sections 00–24 of the Wall Street Journal Penn Treebank II corpus (Marcus, Santorini and Marcinkiewicz, 1993). This is very similar to the grammar used by Sarkar, Xia and Joshi (2000) and Sarkar (2000), though slightly larger, containing around around 7,500 elementary trees. We implemented the algorithm described by Evans and Weir (1997) and Evans and Weir (1998), the details of which are not repeated here. Prior to parsing, the grammar is precompiled as follows. For each word, the set of trees that it can anchor is determined. This results in a total of 11,035 distinct tree sets. For each of these tree sets we first build what we refer to as an unmerged FSA. This automaton contains a separate progression of transitions for each of the trees in the set; using these automata for parsing give"
W02-2229,C92-1034,0,0.0621259,"Missing"
W02-2229,1997.iwpt-1.11,1,\N,Missing
W02-2229,C96-1034,0,\N,Missing
W02-2229,C98-1059,1,\N,Missing
W02-2229,W00-1605,0,\N,Missing
W03-1810,pearce-2002-comparative,0,\N,Missing
W03-1810,W01-0513,0,\N,Missing
W03-1810,J90-1003,0,\N,Missing
W03-1810,H94-1020,0,\N,Missing
W03-1810,briscoe-carroll-2002-robust,1,\N,Missing
W03-1810,W03-1812,0,\N,Missing
W03-1810,W03-1809,0,\N,Missing
W03-1810,P98-2127,0,\N,Missing
W03-1810,C98-2122,0,\N,Missing
W03-1810,W02-2001,0,\N,Missing
W03-1810,P99-1041,0,\N,Missing
W03-1810,S01-1029,1,\N,Missing
W04-0837,S01-1020,0,\N,Missing
W04-0837,O97-1002,0,\N,Missing
W04-0837,briscoe-carroll-2002-robust,1,\N,Missing
W04-0837,J04-1003,0,\N,Missing
W04-0837,P98-2127,0,\N,Missing
W04-0837,C98-2122,0,\N,Missing
W04-0837,W04-0861,1,\N,Missing
W05-1517,briscoe-carroll-2002-robust,1,0.820048,"sed parser. The approach allows a node in the forest to be assigned multiple inside and outside probabilities, enabling a set of ‘weighted GRs’ to be computed directly from the forest. The approach improves on previous work which either loses efficiency by unpacking the parse forest before extracting weighted GRs, or places extra constraints on which nodes can be packed, leading to less compact forests. Our experiments demonstrate substantial increases in parser accuracy and throughput for weighted GR output. 1 Introduction RASP is a robust statistical analysis system for English developed by Briscoe and Carroll (2002). It contains a syntactic parser which can output analyses in a number of formats, including (nbest) syntactic trees, robust minimal recursion semantics (Copestake, 2003), grammatical relations (GRs), and weighted GRs. The weighted GRs for a sentence comprise the set of grammatical relations in all parses licensed for that sentence, each GR is weighted based on the probabilities of the parses in which it occurs. This weight is normalised to fall within the range  0,1 where  indicates that all parses contain the GR. Therefore, high precision GR sets can be determined by thresholding on t"
W05-1517,C02-1013,1,0.959465,"a syntactic parser which can output analyses in a number of formats, including (nbest) syntactic trees, robust minimal recursion semantics (Copestake, 2003), grammatical relations (GRs), and weighted GRs. The weighted GRs for a sentence comprise the set of grammatical relations in all parses licensed for that sentence, each GR is weighted based on the probabilities of the parses in which it occurs. This weight is normalised to fall within the range  0,1 where  indicates that all parses contain the GR. Therefore, high precision GR sets can be determined by thresholding on the GR weight (Carroll and Briscoe, 2002). Carroll and Briscoe compute weighted GRs by first unpacking all parses or the n-best subset from the parse forest. Hence, this approach is either (a) inefficient (and for some examples impracticable) if a large number of parses are licensed by the grammar, or (b) inaccurate if the number of parses unpacked is less than the number licensed by the grammar. In this paper, we show how to obviate the need to trade off efficiency and accuracy by extracting weighted GRs directly from the parse forest using a dynamic programming approach based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari"
W05-1517,P04-1014,0,0.0663335,"parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm so that nodes in the packed chart have the same semantic head and ‘unfilled’ GRs. Our ap160 Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 160–170, c Vancouver, October 2005. 2005 Association for Computational Linguistics proach is novel in that while calculating inside probabilities we allow any node in the parse forest to have multiple semantic heads. Clark and Curran (2004) apply Miyao and Tsujii’s (2002) dynamic programming approach to determine weighted GRs. They outline an alternative parse selection method based on th"
W05-1517,P02-1036,0,0.0650185,"amic programming approach based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm so that nodes in the pack"
W05-1517,P01-1042,0,0.0202823,"ectly from the parse forest using a dynamic programming approach based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter"
W05-1517,N04-1013,0,0.253442,"side algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm so that nodes in the packed chart have the same semantic head and ‘unf"
W05-1517,A00-2022,1,0.91779,"Missing"
W05-1517,P01-1060,0,0.0276824,"parse forest using a dynamic programming approach based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm"
W05-1517,W04-3201,0,0.0352823,"(Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm so that nodes in the packed chart have the same semantic head and ‘unfilled’ GRs. Our ap160"
W05-1517,1995.iwpt-1.8,1,\N,Missing
W05-1517,P06-2006,1,\N,Missing
W07-1515,W02-1011,0,0.0122058,"y of an inter-annotator agreement study, based on measures analogous to those used in the MUC-7 evaluation. 1 Introduction The Appraisal framework (Martin and White, 2005) describes a taxonomy of the language employed in communicating evaluation, explaining how users of English convey attitude (emotion, judgement of people and appreciation of objects), engagement (assessment of the evaluations of other people) and how writers may modify the strength of their attitude/engagement. Accurate automatic analysis of these aspects of language will augment existing research in the fields of sentiment (Pang et al., 2002) and subjectivity analysis (Wiebe et al., 2004), but assessing the usefulness of analysis algorithms leveraging the Appraisal framework will require test data. At present there are no machine-readable Appraisal-annotated texts publicly available. Realworld instances of Appraisal in use are limited to example extracts that demonstrate the theory, coming from a wide variety of genres as disparate as news reporting (White, 2002; Martin, 2004) and poetry (Martin and White, 2005). These examples, while useful in demonstrating the various aspects of Appraisal, can only be employed in a qualitative a"
W07-1515,P02-1053,0,0.0067632,"s and who had died an almost unknown. Annotator d believes that the author is communicating the artist’s dissatisfaction with the way he is treated by critics, whereas j believes that the critics are being reproached for their treatment of the artist. This highlights a problem with the coding scheme, which simplifies the task by assuming only one type of Appraisal is conveyed by each unit. 5 Related work Taboada and Grieve (2004) initiated computational experimentation with the Appraisal framework, assigning adjectives into one of the three broad attitude classes. The authors apply SO-PMI-IR (Turney, 2002) to extract and determine the polarity of adjectives. They then use a variant of SO-PMI-IR to determine a ‘potential’ value for affect, judgement and appreciation, calculating the mutual information between the adjective and three pronoun-copular pairs: I was (affect); he was (judgement) and it was (appreciation). While the pairs seem compelling markers of the respective attitude types, they incorrectly assume that appraisals of affect are limited to the first person whilst judgements are made only of the third person. We can expect a high degree of overlap between the sets of documents retrie"
W07-1515,J04-3002,0,0.0190047,"on measures analogous to those used in the MUC-7 evaluation. 1 Introduction The Appraisal framework (Martin and White, 2005) describes a taxonomy of the language employed in communicating evaluation, explaining how users of English convey attitude (emotion, judgement of people and appreciation of objects), engagement (assessment of the evaluations of other people) and how writers may modify the strength of their attitude/engagement. Accurate automatic analysis of these aspects of language will augment existing research in the fields of sentiment (Pang et al., 2002) and subjectivity analysis (Wiebe et al., 2004), but assessing the usefulness of analysis algorithms leveraging the Appraisal framework will require test data. At present there are no machine-readable Appraisal-annotated texts publicly available. Realworld instances of Appraisal in use are limited to example extracts that demonstrate the theory, coming from a wide variety of genres as disparate as news reporting (White, 2002; Martin, 2004) and poetry (Martin and White, 2005). These examples, while useful in demonstrating the various aspects of Appraisal, can only be employed in a qualitative analysis and would bring about inconsistencies i"
W07-1515,S07-1013,0,\N,Missing
W07-1515,P07-2034,0,\N,Missing
W07-1515,P05-2008,1,\N,Missing
W07-1515,J96-2004,0,\N,Missing
W07-1515,day-etal-2004-callisto,0,\N,Missing
W07-1515,W03-2408,0,\N,Missing
W07-2203,P04-1014,0,0.0210531,"nformation is derived from the treebank, it gen23 Proceedings of the 10th Conference on Parsing Technologies, pages 23–32, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics eralizes better to parsers which make different representational assumptions, and it is easier, as Pereira and Schabes did, to map unlabeled bracketings to a format more consistent with the target grammar. Another is that the cost of annotation with unlabeled brackets should be lower than that of developing a representationally richer treebank. More recently, both Riezler et al. (2002) and Clark and Curran (2004) have successfully trained maximum entropy parsing models utilizing all derivations in the model consistent with the annotation of the WSJ PTB, weighting counts by the normalized probability of the associated derivation. In this paper, we extend this line of investigation by utilizing only unlabeled and partial bracketing. We compare the performance of a statistical parsing model trained from a detailed treebank with that of the same model trained with semi-supervised techniques that require only unlabeled partially-bracketed data. We contrast an IOA-based EM method for training a PGLR parser"
W07-2203,A94-1009,0,0.550829,"bracketing. We compare the performance of a statistical parsing model trained from a detailed treebank with that of the same model trained with semi-supervised techniques that require only unlabeled partially-bracketed data. We contrast an IOA-based EM method for training a PGLR parser (Inui et al., 1997), similar to the method applied by Pereira and Schabes to PCFGs, to a range of confidence-based semi-supervised methods described below. The IOA is a generalization of the Baum-Welch or Forward-Backward algorithm, another instance of EM, which can be used to train Hidden Markov Models (HMMs). Elworthy (1994) and Merialdo (1994) demonstrated that Baum-Welch does not necessarily improve the performance of an HMM part-ofspeech tagger when deployed in an unsupervised or semi-supervised setting. These somewhat negative results, in contrast to those of Pereira and Schabes (1992), suggest that EM techniques require fairly determinate training data to yield useful models. Another motivation to explore alternative non-iterative methods is that the derivation space over partiallybracketed data can remain large (&gt;1K) while the confidence-based methods we explore have a total processing overhead equivalent t"
W07-2203,W01-0521,0,0.0221584,"nces (from the PTB) drawn at random from section 23 of the WSJ (the de facto standard test set for statistical parsing). In all the evaluations reported in this paper we test our parser over a gold-standard set of relational dependencies compatible with our parser output derived (Briscoe and Carroll, 2006) from the PARC 700 Dependency Bank (DepBank, henceforth). The Susanne Corpus is a (balanced) subset of the Brown Corpus which consists of 15 broad categories of American English texts. All but one category (reportage text) is drawn from different domains than the WSJ. We therefore, following Gildea (2001) and others, consider S, and also the baseline training data, B, as out-ofdomain training data. 4 The Evaluation Scheme The parser’s output is evaluated using a relational dependency evaluation scheme (Carroll, et al., 1998; Lin, 1998) with standard measures: precision, recall and F1 . Relations are organized into a hierarchy with the root node specifying an unlabeled dependency. The microaveraged precision, recall and F1 scores are calculated from the counts for all relations in the hierarchy which subsume the parser output. The microaveraged F1 score for the baseline system using this evalua"
W07-2203,P99-1010,0,0.0317151,"findings support those of Elworthy (1994) and Merialdo (1994) for POS tagging and suggest that EM is not always the most suitable semi-supervised training method (especially when some in-domain training data is available). The confidence-based methods were successful because the level of noise introduced did not outweigh the benefit of incorporating all derivations compatible with the bracketing in which the derivations contained a high proportion of correct constituents. These findings may not hold if the level of bracketing available does not adequately constrain the parses considered – see Hwa (1999) for a related investigation with EM. In future work we intend to further investigate the problem of tuning to a new domain, given that minimal manual effort is a major priority. We hope to develop methods which required no manual annotation, for example, high precision automatic partial bracketing using phrase chunking and/or named entity recognition techniques might yield enough information to support the training methods developed here. Finally, further experiments on weighting the contribution of each dataset might be beneficial. For instance, Bacchiani et al. (2006) demonstrate imrpovemen"
W07-2203,1997.iwpt-1.16,0,0.702988,"have successfully trained maximum entropy parsing models utilizing all derivations in the model consistent with the annotation of the WSJ PTB, weighting counts by the normalized probability of the associated derivation. In this paper, we extend this line of investigation by utilizing only unlabeled and partial bracketing. We compare the performance of a statistical parsing model trained from a detailed treebank with that of the same model trained with semi-supervised techniques that require only unlabeled partially-bracketed data. We contrast an IOA-based EM method for training a PGLR parser (Inui et al., 1997), similar to the method applied by Pereira and Schabes to PCFGs, to a range of confidence-based semi-supervised methods described below. The IOA is a generalization of the Baum-Welch or Forward-Backward algorithm, another instance of EM, which can be used to train Hidden Markov Models (HMMs). Elworthy (1994) and Merialdo (1994) demonstrated that Baum-Welch does not necessarily improve the performance of an HMM part-ofspeech tagger when deployed in an unsupervised or semi-supervised setting. These somewhat negative results, in contrast to those of Pereira and Schabes (1992), suggest that EM tec"
W07-2203,N06-1020,0,0.0496329,"tive results, in contrast to those of Pereira and Schabes (1992), suggest that EM techniques require fairly determinate training data to yield useful models. Another motivation to explore alternative non-iterative methods is that the derivation space over partiallybracketed data can remain large (&gt;1K) while the confidence-based methods we explore have a total processing overhead equivalent to one iteration of an IOA-based EM algorithm. As we utilize an initial model to annotate additional training data, our methods are closely related to self-training methods described in the literature (e.g. McClosky et al. 2006, Bacchi24 ani et al. 2006). However these methods have been applied to fully-annotated training data to create the initial model, which is then used to annotate further training data derived from unannotated text. Instead, we train entirely from partially-bracketed data, starting from the small proportion of ‘unambiguous’ data whereby a single parse is consistent with the annotation. Therefore, our methods are better described as semi-supervised and the main focus of this work is the flexible re-use of existing treebanks to train a wider variety of statistical parsing models. While many stati"
W07-2203,J94-2001,0,0.493249,"re the performance of a statistical parsing model trained from a detailed treebank with that of the same model trained with semi-supervised techniques that require only unlabeled partially-bracketed data. We contrast an IOA-based EM method for training a PGLR parser (Inui et al., 1997), similar to the method applied by Pereira and Schabes to PCFGs, to a range of confidence-based semi-supervised methods described below. The IOA is a generalization of the Baum-Welch or Forward-Backward algorithm, another instance of EM, which can be used to train Hidden Markov Models (HMMs). Elworthy (1994) and Merialdo (1994) demonstrated that Baum-Welch does not necessarily improve the performance of an HMM part-ofspeech tagger when deployed in an unsupervised or semi-supervised setting. These somewhat negative results, in contrast to those of Pereira and Schabes (1992), suggest that EM techniques require fairly determinate training data to yield useful models. Another motivation to explore alternative non-iterative methods is that the derivation space over partiallybracketed data can remain large (&gt;1K) while the confidence-based methods we explore have a total processing overhead equivalent to one iteration of a"
W07-2203,C02-2025,0,0.0141029,"th EM applied to the same PGLR parse selection model. Indeed, a bracketed corpus provides flexibility as existing treebanks can be utilized despite the incompatibility between the system grammar and the underlying grammar of the treebank. Mapping an incompatible annotated treebank to a compatible partially-bracketed corpus is relatively easy compared to mapping to a compatible fully-annotated corpus. An immediate benefit of this work is that (re)training parsers with incrementally-modified grammars based on different linguistic frameworks should be much more straightforward – see, for example Oepen et al. (2002) for a good discussion of the problem. Furthermore, it suggests that it may be possible to usefully tune a parser to a new domain with less annotation effort. Our findings support those of Elworthy (1994) and Merialdo (1994) for POS tagging and suggest that EM is not always the most suitable semi-supervised training method (especially when some in-domain training data is available). The confidence-based methods were successful because the level of noise introduced did not outweigh the benefit of incorporating all derivations compatible with the bracketing in which the derivations contained a h"
W07-2203,P92-1017,0,0.575714,"trained on the WSJ PTB to the biomedical domain by retraining on the Genia Corpus, augmented with manually corrected derivations in the same format. To make statistical parsing more viable for a range of applications, we need to make more effective and flexible use of extant training data and minimize the cost of annotation for new data created to tune a system to a new domain. Unsupervised methods for training parsers have been relatively unsuccessful to date, including expectation maximization (EM) such as the inside-outside algorithm (IOA) over PCFGs (Baker, 1979; Prescher, 2001). However, Pereira and Schabes (1992) adapted the IOA to apply over semi-supervised data (unlabeled bracketings) extracted from the PTB. They constrain the training data (parses) considered within the IOA to those consistent with the constituent boundaries defined by the bracketing. One advantage of this approach is that, although less information is derived from the treebank, it gen23 Proceedings of the 10th Conference on Parsing Technologies, pages 23–32, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics eralizes better to parsers which make different representational assumptions, and it is eas"
W07-2203,W01-1829,0,0.0497079,"Missing"
W07-2203,P02-1035,0,0.0284737,"h is that, although less information is derived from the treebank, it gen23 Proceedings of the 10th Conference on Parsing Technologies, pages 23–32, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics eralizes better to parsers which make different representational assumptions, and it is easier, as Pereira and Schabes did, to map unlabeled bracketings to a format more consistent with the target grammar. Another is that the cost of annotation with unlabeled brackets should be lower than that of developing a representationally richer treebank. More recently, both Riezler et al. (2002) and Clark and Curran (2004) have successfully trained maximum entropy parsing models utilizing all derivations in the model consistent with the annotation of the WSJ PTB, weighting counts by the normalized probability of the associated derivation. In this paper, we extend this line of investigation by utilizing only unlabeled and partial bracketing. We compare the performance of a statistical parsing model trained from a detailed treebank with that of the same model trained with semi-supervised techniques that require only unlabeled partially-bracketed data. We contrast an IOA-based EM method"
W07-2203,I05-1018,0,0.0552412,"Missing"
W07-2203,J87-1004,0,0.328283,"utilizes a manually written feature-based unification grammar over POS tag sequences. 2.1 The Parse Selection Model A context-free ‘backbone’ is automatically derived from the unification grammar1 and a generalized or non-deterministic LALR(1) table is 1 This backbone is determined by compiling out the values of prespecified attributes. For example, if we compile out the attribute PLURAL which has 2 possible values (plural or not) we will create 2 CFG rules for each rule with categories that contain PLURAL. Therefore, no information is lost during this process. constructed from this backbone (Tomita, 1987). The residue of features not incorporated into the backbone are unified on each reduce action and if unification fails the associated derivation paths also fail. The parser creates a packed parse forest represented as a graph-structured stack.2 The parse selection model ranks complete derivations in the parse forest by computing the product of the probabilities of the (shift/reduce) parse actions (given LR state and lookahead item) which created each derivation (Inui et al., 1997). Estimating action probabilities, consists of a) recording an action history for the correct derivation in the pa"
W07-2203,D07-1130,1,0.813886,"09 |α| 4138 15152 19248 No Match 1322 15749 16946 Timeout 191 1094 1475 Table 1: Corpus split for S, W and SW . eting. However, a preliminary investigation of no matches didn’t yield any clear patterns of inconsistency that we could quickly ameliorate by simple modifications of the PTB bracketing. We leave for the future a more extensive investigation of these cases which, in principle, would allow us to make more use of this training data. An alternative approach that we have also explored is to utilize a similar bootstrapping approach with data partially-annotated for grammatical relations (Watson and Briscoe, 2007). 5.1 Confidence-Based Approaches We use γ to build an initial model. We then utilize this initial model to derive derivations (compatible with the unlabeled partial bracketing) for α from which we select additional training data. We employ two types of selection methods. First, we select the top-ranked derivation only and weight actions which resulted in this derivation equally with those of the initial model (C1 ). This method is similar to ‘Viterbi training’ of HMMs though we do not weight the corresponding actions using the top parse’s probability. Secondly, we select more than one derivat"
W07-2203,W05-1517,1,0.858062,"77.05 76.02 77.05 77.51 77.73 76.45 77.01 76.90 77.85 77.88 77.40 77.09 76.86 77.88 78.01 77.54 Rec 74.22 73.40 74.22 74.80 74.98 73.91 74.31 74.23 75.07 75.04 74.75 74.35 74.21 75.05 75.13 74.95 F1 75.61 74.69 75.61 76.13 76.33 75.16 75.64 75.55 76.43 76.43 76.05 75.70 75.51 76.44 76.54 76.23 P (z)‡ 0.0294 0.4960 0.0655 0.0154 0.2090 0.1038 0.2546 0.0017 0.0011 0.1335 0.1003 0.2483 0.0048 0.0007 0.0618 Table 2: Performance of all models on DepBank. the statistical significance of the system against the baseline model. ‡ represents corresponding normalized inside-outside weight for each node (Watson et al., 2005). We perform EM starting from two initial models; either a uniform probability model, I L (), or from models derived from unambiguous training data, γ. Figure 1 shows the cross entropy decreasing monotonically from iteration 2 (as guaranteed by the EM method) for different corpora and initial models. Some models show an initial increase in cross-entropy from iteration 1 to iteration 2, because the models are initialized from a subset of the data which is used to perform maximisation. Cross-entropy increases, by definition, as we incorporate ambiguous data with more than one consistent derivati"
W07-2203,W03-2401,0,\N,Missing
W07-2203,J03-4003,0,\N,Missing
W07-2203,P06-4020,1,\N,Missing
W07-2203,P06-2006,1,\N,Missing
W07-2207,J97-4005,0,0.122736,"Missing"
W07-2207,P89-1018,0,0.22569,"4), who use an HPSG grammar comparable to the ERG and GG, non-local ME features, and a two-phase parse forest creation and unpacking approach. However, their unpacking phase uses a beam search to find a good (single) candidate for the best parse; in contrast— for ME models containing the types of non-local features that are most important for accurate parse selection—we avoid an approximative search and efficiently identify exactly the n-best parses. When parsing with context free grammars, a (single) parse can be retrieved from a parse forest in time linear in the length of the input string (Billot & Lang, 1989). However, as discussed in Section 2, when parsing with a unification-based grammar and packing under feature structure subsumption, the cross-product of some local ambiguities may not be globally consistent. This means that additional unifications are required at unpacking time. In principle, when parsing with a pathological grammar with a high rate of failure, extracting a single consistent parse from the forest could take exponential time (see Lang (1994) for a discussion of this issue with respect to Indexed Grammars). In the case of GG, a high rate of unification failure in unpacking is d"
W07-2207,N03-1016,0,0.0171498,"properties. This lack of monotonicity in the scores associated with sub-trees, on the one hand, is beneficial, in that performing a greedy best-first search becomes practical: in contrast, with PCFGs and their monotonically decreasing probabilities on larger sub-trees, once the parser finds the first full tree the chart necessarily has been instantiated almost completely. On the other hand, the same property prohibits the application of exact best-first techniques like A∗ search, because there is no reliable future cost estimate; in this respect, our set-up differs fundamentally from that of Klein & Manning (2003) and related PCFG parsing work. Using the unnormalized sum of ME 51 weights on a partial solution as its agenda score, effectively, means that sub-trees with low scores ‘sink’ to the bottom of the agenda; highly-ranked partial constituents, in turn, instigate the immediate creation of larger structures, and ideally the bottom-up agenda-driven search will greedily steer the parser towards full analyses with high scores. Given its heuristic nature, this procedure cannot guarantee that its n-best list of results corresponds to the globally correct rank order, but it may in practice come reasonabl"
W07-2207,J98-2004,0,0.0238923,"ple packed forest: given two ways of decomposing 6 , there will be three candidate ways of instantiating 2 and six for 4 , respectively, for a total of nine full trees. crafted grammars and inputs of average complexity the approach can perform reasonably well. Another mode of operation is to organize the parser’s search according to an agenda (i.e. priority queue) that assigns numeric scores to parsing moves (Erbach, 1991). Each such move is an application of the fundamental rule of chart parsing, combining an active and a passive edge, and the scores represent the expected ‘figure of merit’ (Caraballo & Charniak, 1998) of the resulting structure. Assuming a parse selection model of the type sketched in Section 2, we can determine the agenda priority for a parsing move according to the (unnormalized) ME score of the derivation (sub-)tree that would result from its successful execution. Note that, unlike in probabilistic context-free grammars (PCFGs), ME scores of partial trees do not necessarily decrease as the tree size increases; instead, the distribution of feature weights is in the range (−∞, +∞), centered around 0, where negative weights intuitively correspond to dis-preferred properties. This lack of m"
W07-2207,I05-1015,1,0.317703,"n-best list of results; and (c) a two-phase approach, where a complete packed for48 Proceedings of the 10th Conference on Parsing Technologies, pages 48–59, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics est is created and combined with a specialized graph search procedure to selectively enumerate results in (globally) correct rank order. Although conceptually simple, the second technique has not previously been evaluated for HPSG parsing (to the best of our knowledge). The last of these techniques, which we call selective unpacking, was first proposed by Carroll & Oepen (2005) in the context of chart-based generation. However, they only provide an account of the algorithm for local ME properties and assert that the technique should generalize to larger contexts straightforwardly. This paper describes this generalization of selective unpacking, in its application to parsing, and demonstrates that the move from features that resemble a context-free domain of locality to features of, in principle, arbitrary context size can indeed be based on the same algorithm, but the required extensions are non-trivial. The structure of the paper is as follows. Section 2 summarizes"
W07-2207,P04-1014,0,0.0216039,"algorithm empirically exhibits a linear relationship between processing time and the number of analyses unpacked at all degrees of ME feature nonlocality; in addition, compared with agendadriven best-first parsing and exhaustive parsing with post-hoc parse selection it leads to improved parsing speed, coverage, and accuracy.† 1 Background—Motivation Technology for natural language analysis using linguistically precise grammars has matured to a level of coverage and efficiency that enables parsing of large amounts of running text. Research groups working within grammatical frameworks like CCG (Clark & Curran, 2004), LFG (Riezler et al., 2002), and HPSG (Malouf & van Noord, 2004; Oepen, Flickinger, Toutanova, & Manning, 2004; Miyao, Ninomiya, & Tsujii, 2005) have successfully integrated broad-coverage computational grammars with sophisticated statistical parse selection models. The former delineate the space of possible analyses, while the latter provide a probability distribu† The first author warmly acknowledges the guidance of his PhD advisors, Valia Kordoni and Hans Uszkoreit. We are grateful to Ulrich Callmeier, Berthold Crysmann, Dan Flickinger, and Erik Velldal for many discussions and their suppo"
W07-2207,P02-1036,0,0.0182332,"a parse forest. The algorithm of Carroll & Oepen (2005) and the final one of Huang & Chiang (2005) are essentially equivalent, and turn out to be reformulations of an approach originally described by Jim´enez & Marzal (2000) (although expressed there only for grammars in Chomsky Normal Form). In this paper we have considered ME properties that extend beyond immediate dominance relations, extending up to 4 levels of grandparenting. Previous work has either assumed properties that are restricted to the minimal parse fragments (i.e. subtrees of depth one) that make up the packed representation (Geman & Johnson, 2002), or has taken a more relaxed approach by allowing non-local propConfiguration greedy best-first selective, no caching selective, with cache Unifications (#) 5980 5535 4915 Copies (#) 1447 1523 1522 Hypotheses (#) – 1245 382 Space (kbyte) 9202 27188 27176 Unpack (ms) – 70 10 Total (ms) 400 410 350 Table 5: Efficiency effects of the instantiation failure caching and propagation with GG, without grandparenting. All statistics are averages over the 1941 items that complete within the resource bounds in all three configurations. Unification, Copies, Unpack, and Total have the same interpretation a"
W07-2207,W05-1506,0,0.00687881,"zation of hyper-parameters for individual configurations would moderately improve model performance, especially for higher-order grandparenting levels with large numbers of features. 57 8 Discussion The approach to n-best parsing described in this paper takes as its point of departure recent work of Carroll & Oepen (2005), which describes an efficient algorithm for unpacking n-best trees from a forest produced by a chart-based sentence generator and containing local ME properties with associated weights. In an almost contemporaneous study, but in the context of parsing with treebank grammars, Huang & Chiang (2005) develop a series of increasingly efficient algorithms for unpacking n-best results from a weighted hypergraph representing a parse forest. The algorithm of Carroll & Oepen (2005) and the final one of Huang & Chiang (2005) are essentially equivalent, and turn out to be reformulations of an approach originally described by Jim´enez & Marzal (2000) (although expressed there only for grammars in Chomsky Normal Form). In this paper we have considered ME properties that extend beyond immediate dominance relations, extending up to 4 levels of grandparenting. Previous work has either assumed properti"
W07-2207,A00-2023,0,0.0153214,"number of hypotheses that need to be considered is doubled; as an immediate consequence, there can be up to eight distinct lexicalized variants for the decomposition 1 → h 4 3 i further up in the tree. It may look as if combinatorics will cross-multiply throughout the tree—in the worst case returning us to an exponential number of hypotheses—but this is fortunately not the case: regarding the external bi-grams of 1 , node 6 no longer participates in its left- or rightmost periphery, so variation internal to 6 is not a multiplicative factor at this level. This is essentially the observation of Langkilde (2000), and her bottom-up factoring of n-gram computation is easily incorporated into our top-down selective unpacking control structure. At the point where hypothesizeedge() invokes itself recursively (line 23 in Figure 3), its return value is now a set of lexicalized alternates, and hypothesis creation (in line 26) can take into account the local cross-product of all such alternation. 54 Including additional properties from non-local subtrees (for example higher-order n-grams and head lexicalization) is a straightforward extension of this scheme, replacing our per-edge left- and rightmost peripher"
W07-2207,W02-2018,0,0.0722633,"in “space” between exhaustive and selective unpacking. Also, the difference in “unifications” and “copies” indicates that with our selective unpacking algorithm, these expensive operations on typed feature structures are significantly reduced. In return for increased processing time (and marginal loss in coverage) when using grandparenting features, Table 3 shows some large improvements in parse selection accuracy (although the picture is less clear-cut at higher-order levels of grandparenting5 ). A balance point between efficiency 5 The models were trained using the open-source TADM package (Malouf, 2002), using default hyper-parameters for all configurations, viz. a convergence threshold of 10−8 , variance of the prior of 10−4 , and frequency cut-off of 5. It is likely that ≤ 15 words Configuration GP greedy best-first exhaustive unpacking 0 0 0 1 2 3 4 0 0 0 1 2 3 4 selective unpacking greedy best-first exhaustive unpacking &gt; 15 words selective unpacking Unifications (#) 1845 2287 1912 1913 1914 1914 1914 25233 39095 17489 17493 17493 17495 17495 Copies (#) 527 795 589 589 589 589 589 5602 15685 4422 4421 4421 4422 4422 Space (kbyte) 2328 8907 8109 8109 8109 8110 8110 24646 80832 33326 33318"
W07-2207,P02-1035,0,0.0871292,"ts a linear relationship between processing time and the number of analyses unpacked at all degrees of ME feature nonlocality; in addition, compared with agendadriven best-first parsing and exhaustive parsing with post-hoc parse selection it leads to improved parsing speed, coverage, and accuracy.† 1 Background—Motivation Technology for natural language analysis using linguistically precise grammars has matured to a level of coverage and efficiency that enables parsing of large amounts of running text. Research groups working within grammatical frameworks like CCG (Clark & Curran, 2004), LFG (Riezler et al., 2002), and HPSG (Malouf & van Noord, 2004; Oepen, Flickinger, Toutanova, & Manning, 2004; Miyao, Ninomiya, & Tsujii, 2005) have successfully integrated broad-coverage computational grammars with sophisticated statistical parse selection models. The former delineate the space of possible analyses, while the latter provide a probability distribu† The first author warmly acknowledges the guidance of his PhD advisors, Valia Kordoni and Hans Uszkoreit. We are grateful to Ulrich Callmeier, Berthold Crysmann, Dan Flickinger, and Erik Velldal for many discussions and their support. We thank Ron Kaplan, Mar"
W07-2207,P99-1069,0,0.140483,"t be globally consistent. Assume for example that, in Figure 2, edges 6 and 8 subsume 7 and 9 , respectively; combining 7 and 9 into the same tree during unpacking can in principle fail. Thus, unpacking effectively needs to deterministically replay unifications, but this extra expense in our experience is negligible when compared to the decreased cost of constructing the forest under subsumption. In Section 3 we argue that this very property, in addition to increasing parsing efficiency, interacts beneficially with parse selection and on-demand enumeration of results in rank order. Following (Johnson et al., 1999), a conditional ME model of the probabilities of trees {t1 . . . tn } for a string s, and assuming a set of feature functions {f1 . . . fm } with corresponding weights {λ1 . . . λm }, is defined as: P exp j λj fj (ti ) P p(ti |s) = Pn (1) k=1 exp j λj fj (tk ) 2 This property of parse forests is not a prerequisite of the chart parsing framework. The basic CKY procedure (Kasami, 1965), for example, as well as many unification-based adaptations (e.g. the Core Language Engine; Moore & Alshawi, 1992) merely record the local category of each edge, which is sufficient for the recognition task and si"
W07-2207,J08-1002,0,\N,Missing
W07-2207,J07-4004,0,\N,Missing
W07-2207,P08-1067,0,\N,Missing
W07-2207,W01-1812,0,\N,Missing
W07-2304,N07-1021,1,0.83879,"strictly speaking, according to our model the training parameters are part of the traversal algorithm, not the tree. is considerably more expensive than the greedy modes. 2. Greedy generation: make the single most likely decision at each choice point (rule expansion) in a generation process. This is not guaranteed to result in the most likely generation process, but the computational cost is very low. 3 Examples of this control model 3. Greedy roulette-wheel generation: use a nonuniform random distribution proportional to the likelihoods of alternatives. 3.1 Example 1 – pCRU pCRU (Belz, 2006; Belz, 2007) is a probabilistic language generation framework for creating NLG systems that contain a probabilistic model of the entire generation space, represented by a context-free underspecification grammar. The basic idea is to view all generation rules as context-free rules and to estimate a single probabilistic model from a corpus of texts to guide the generation process. In nonprobabilistic mode, the generator operates by taking any sentential form of the grammar as an input and expanding it using the grammar to all possible fully specified forms, which are the outputs. Thus a pCRU grammar looks r"
W07-2304,W02-2119,1,0.852946,"output gives rise to one source of variation of control. We are not interested in what outputs are, but only how they are constructed, and so we think of them purely in terms of the content operations that give rise to them. Adopting this very abstract view, we can conceptualise a generator as having the following principal components: 2 The control model We start with a very general view of the generation process2 . Generation takes an input and produces an output, which is a ‘more linguistically instantiated’ representation of the input (but we will not say precisely what that means — cf. (Evans et al., 2002; McDonald, 1993). In the process of doing this, the generator makes various decisions about the content of its output — it reaches a choice-point at which several options are possible and selects one to follow, and then reaches another choice point, and so on. In fact, this is all any generation algorithm does: visit choice points one after another and make a decision relating to the content of output at each one. Each decision may be constrained by the input, constrained by other decisions already made, or determined by the generation algorithm itself. These constraints may not reduce the nu"
W07-2304,W02-2103,0,0.0357578,"tional grammar for syntax, except that it is used to model deep generation as well as surface realisation. The probabilistic version of pCRU introduces a probability distribution over the generator decisions. This is achieved by using treebank training, that is, estimating a distribution over the expansion rules that encode the generation space from a corpus using two steps3 : Belz (2006) describes an application of the system to weather forecast generation, and compares the different control techniques with human generation and a more traditional generate-and-test probabilistic architecture (Langkilde-Geary, 2002). pCRU can be interpreted using the model introduce here in the following way (cf. the first example given in section 2.1). The generation tree is defined by all the possible derivations according to the grammar. Each node corresponds to a sentential form and each child node is the result of rewriting a single non-terminal using a grammar rule. Thus the content operations are grammar rules. The content structures are sentences in the grammar. The input is itself a sentential form which identifies where in the complete tree to start generating from, and the input constraint algorithm does nothi"
W07-2304,J93-1009,0,0.0372096,"o one source of variation of control. We are not interested in what outputs are, but only how they are constructed, and so we think of them purely in terms of the content operations that give rise to them. Adopting this very abstract view, we can conceptualise a generator as having the following principal components: 2 The control model We start with a very general view of the generation process2 . Generation takes an input and produces an output, which is a ‘more linguistically instantiated’ representation of the input (but we will not say precisely what that means — cf. (Evans et al., 2002; McDonald, 1993). In the process of doing this, the generator makes various decisions about the content of its output — it reaches a choice-point at which several options are possible and selects one to follow, and then reaches another choice point, and so on. In fact, this is all any generation algorithm does: visit choice points one after another and make a decision relating to the content of output at each one. Each decision may be constrained by the input, constrained by other decisions already made, or determined by the generation algorithm itself. These constraints may not reduce the number of choices a"
W07-2304,P05-1008,1,0.908156,"ration process, and correspondingly of generation systems. The simple pipeline model of Reiter and Dale (2000) actually conceals a wide range of underlying approaches to generation (cf. (Mellish et al., 2006, section 2.1)), and a recent initiative to provide a ‘reference architecture’ for such systems (involving some of the present authors) abandoned any attempt to harmonise control aspects of the systems it studied (Mellish et al., 2006). In such a situation, it is difficult to see how any general statements, results or techniques relating to controlling generation can be developed, although Paiva and Evans (2005) report an approach that has the potential for wider applicability. In the present paper, we introduce a view of the generation process which abstracts away from specific generation systems or architectures, to a point at which it is possible to separate control from content decisions in the generation process. This allows us to explore systematically different control strategies for constructing the same content (mapping from an input to the same output), and examine different approaches (e.g. generative, empirical) to the problem of controlling generation. The approach we develop is quite ab"
W14-3411,P06-4020,1,0.825595,"Missing"
W14-3411,N13-1039,0,0.0386314,"Missing"
W14-3411,W04-1211,0,0.197915,"information for the study of disease and treatment. We present an exploratory study into chunking such text using offthe-shelf language processing tools and pre-trained statistical models. We evaluate chunking accuracy with respect to partof-speech tagging quality, choice of chunk representation, and breadth of context features. Our results indicate that narrow context feature windows give the best results, but that chunk representation and minor differences in tagging quality do not have a significant impact on chunking accuracy. 1 j.cassell@bsms.ac.uk 2 Related Work The Mayo Clinic Corpus (Pakhomov et al., 2004) is a key resource that has been widely used as a gold standard in part-of-speech (POS) tagging of clinical text. Based on that corpus and the Penn TreeBank (Marcus et al., 1993), Coden et al. (2005) present an analysis of the effects of domain data on the performance of POS tagging models, demonstrating significant improvements with models trained entirely on domain data. Savova et al. (2010) use this corpus for the development of cTAKES, Mayo Clinic’s processing pipeline for clinical text. Fan et al. (2011) show that using more diverse clinical data can lead to more accurate POS tagging. The"
W14-3411,W95-0107,0,0.416632,"Missing"
W14-3411,W00-0726,0,0.125749,"ld have the best chance of performing well. We also selected a number of other taggers while trying to diversify their algorithms and train4.2 Chunk Representation The dominant chunk representation standard inside, outside, begin (IOB) introduced by Ramshaw and Marcus (1995) and established with the 79 Feature Set W-1 -W1 , T-1 -T1 , C-1 W-1 -W1 , T-1 -T1 , C-2 -C-1 W-1 -W2 , T-1 -T2 , C-1 W-2 -W1 , T-2 -T1 , C-2 W-1 -W1 , T-1 -T1 , C-2 W-2 -W1 , T-2 -T1 , C-3 -C-1 W-1 -W1 , T-1 -T1 , C-3 -C-1 W-2 -W2 , T-2 -T2 , C-1 W-1 -W1 , T-1 -T1 , C-3 W-3 -W1 , T-3 -T1 , C-2 -C-1 CoNLL-2000 shared task (Sang and Buchholz, 2000) takes a minimalistic approach to the representation problem in order to keep the number of labels low. Note that for chunking representations the total number of labels is the product of the chunk types and the set of representation types plus the outside tag, meaning that for IOB with our set of three chunk types (NP, MV, AP) there are seven labels. Alternative chunk representations, such as begin, end, inside, single, outside (BEISO)3 as used by Kudo and Matsumoto (2001), offer more finegrained tagsets, presumably at a performance cost. That cost is unnecessary unless there is something to"
W14-3411,C08-1106,0,0.0395585,"Missing"
W14-3411,gimenez-marquez-2004-svmtool,0,0.132432,"Missing"
W14-3411,N03-1033,0,0.129879,"Missing"
W14-3411,N01-1025,0,0.124472,", T-1 -T1 , C-3 -C-1 W-2 -W2 , T-2 -T2 , C-1 W-1 -W1 , T-1 -T1 , C-3 W-3 -W1 , T-3 -T1 , C-2 -C-1 CoNLL-2000 shared task (Sang and Buchholz, 2000) takes a minimalistic approach to the representation problem in order to keep the number of labels low. Note that for chunking representations the total number of labels is the product of the chunk types and the set of representation types plus the outside tag, meaning that for IOB with our set of three chunk types (NP, MV, AP) there are seven labels. Alternative chunk representations, such as begin, end, inside, single, outside (BEISO)3 as used by Kudo and Matsumoto (2001), offer more finegrained tagsets, presumably at a performance cost. That cost is unnecessary unless there is something to be gained from a more fine-grained tagset at decoding time, because the two representations are deterministically inter-convertible. For instance, an end tag could be useful for better recognising boundaries between chunks of the same type. The BEISO tagset model looks for the boundary before and after crossing it, while an IOB model only looks after. This should give only a small gain with standard edited text because the chunk type distribution is fairly well balanced and"
W14-3411,P03-1004,0,0.0403251,"Missing"
W14-3411,P10-1052,0,0.170931,"Missing"
W14-3411,J93-2004,0,\N,Missing
W96-0209,1995.iwpt-1.8,1,0.391588,"Missing"
W96-0209,P94-1040,1,0.864533,"which a syntactic analysis should, in 2Briscoe & Carroll (1995) note that &quot;coverage&quot; is a weak measure since discovery of one or more global analyses does not entail that the correct analysis is recovered. 93 principle, be found; for example, in (3), the absence of dashes would mislead a parser into seeking a syntactic relationship between three and the following names, whilst in fact there is only a discourse relation of elaboration between this text adjunct and pronominal three. or build a modular semantics. Our less-tightly integrated g r a m m a r is described in more detail in Briscoe & Carroll (1994). 5. P A R S I N G T H E S U S A N N E SEC CORPORA (3) The three - Miles J. Cooperman, Sheldon Teller, and Richard Austin - and eight other defendants were charged in six indictments with conspiracy to violate federal narcotic law. AND We have used the integrated g r a m m a r to parse the Susanne corpus and the quite distinct Spoken English Corpus (SEC; Taylor ~ Knowles, 1988), a 50K word treebanked corpus of transcribed British radio programmes punctuated by the corpus compilers. Both corpora were retagged using the Acquilex HMM tagger (Elworthy, 1993, 1994) trained on text tagged with a sli"
W96-0209,A88-1019,0,0.0763159,"nced subset of the Brown corpus. Many of the 'failures' are due to the root S(entence) requirement enforced by the parser when dealing with fragments from dialogue and so forth. We have not relaxed this requirement since it increases ambiguity, our primary interest at this point being the extraction of subcategorisation information from full clauses in corpus data. 2. P A R T : O F - S P E E C H TAG SEQUENCE GRAMMAR 3. T E X T GRAMMAR PUNCTUATION We utilised the ANLT metagrammatical formalism to develop a feature-based, declarative description of part-of-speech (PoS) label sequences (see e.g. Church, 1988) for English. This grammar compiles into a DCG-like grammar of approximately 400 rules. It has been designed to enumerate possible valencies for predicates (verbs, adjectives and nouns) by including separate rules for each pattern of possible complementation in English. The distinction between arguments and adjuncts is expressed, following Xbar theory (e.g. Jackendoff, 1977), by Chomskyadjunction of adjuncts to maximal projections (XP ~ XP Adjunct) as opposed to government of arguments (i.e. arguments are sisters within X1 projections; X1 --~ X0 A r g l . . . ArgN). Although the grammar enumer"
W96-0209,P89-1018,0,0.0486341,"Missing"
W96-0209,A94-1009,0,0.268552,"Missing"
W96-0209,C94-1042,0,0.124071,"Missing"
W96-0209,P95-1037,0,0.132203,"Missing"
W96-0209,P90-1031,0,0.0796417,"Missing"
W96-0209,E93-1040,0,0.0788724,"Missing"
W96-0209,E89-1035,1,0.87064,"Missing"
W96-0209,J93-2006,0,0.0457786,"Missing"
W96-0209,A97-1052,1,\N,Missing
W96-0209,P89-1015,0,\N,Missing
W98-0108,1997.iwpt-1.6,1,0.831515,"Missing"
W98-0108,A94-1009,0,0.1648,"Missing"
W98-0108,J96-2002,0,0.221573,"bring together, and evaluate, a variety of current NLP techniques, including the organisation of grammars into inheritance hierarchies for compact representation, exploitation of diverse precompilation techniques for efficient parsing, and use of statistical analysis to disambiguate parse results. In conjunction with this we are using several existing tools and resources, such as the lexicon developed in the Alvey Natural Language Tools project (Briscoe et al., 1987), lexical frequency information from the SPARKLE project 2 , and an established lexical knowledge representation language DATR (Evans and Gazdar, 1996a) to represent the grammar. The overall architecture of LExSvs is shown in Figure 1 and the following sections discuss each of. the system&apos;s main components. 2 The morphological analyser The text is first tokenised and then a sentencesplitter is applied to it to determine likely sentence boundaries. The resulting sentences are tagged with extended part-of-speech (PoS) labels using a first-order HMM tagger (Elworthy, 1994) trained on the SUSANNE corpus (Sam.pson, 1995). The SUSANNE lexicon is augmented with open-class words from tlie LOB corpus and the tagger incorporates a part-of-speech gues"
W98-0108,P98-1061,1,0.583256,"Missing"
W98-0108,P95-1011,1,0.874552,"Missing"
W98-0108,W97-0808,0,0.0448682,"tly increases its disambiguation accuracy. Ve intend also to incorporate this information into the system &lt;lescribe&lt;l in this paper, at the point where lemmas a.re associated with tree families: each lemma / family combination would have a separate probability. Carroll and Weir ( 1997) ou tline other alternative probabilistic models, some of which we also inten&lt;l to investigate. The same shallow phrase-structure parser is also providing data for the acquisition of selectional preferences, at present again just for verbs, and only for NP and PP subject, direct and indirect verbal complements (McCarthy, 1997). The technique uses the WordNet hypernym hierarchy (Fellbaum, 1998) in tandem with Minimum Description Length learning (Rissanen, 1978) to induce semantic classes of nominal heads at an appropriate level of abstraction. We have results of acquisition from a 10 million word extract from the British National Corpus, and will augment the lex.icon with the acquired selectionai frequencies and use them during parsing as a further source of disambiguation information. 5 The parser We have implemented a simple bottom-up parsing algorithm which is being used for grammar development . The parser simul"
W98-0108,P95-1021,1,0.929691,"ny whose probabilities are below a preset factor of the most probable. The thresholding technique allows us to fine-tune the trade-off between the costs of incorrect tagging and processing complexity due to lexical ambiguity. After tagging, a lemmatiser finds the lemma, or base form, corresponding to each word-label pair, using an enhanced version of the GATE project stemmer (Cunningham et al., 1995). Finally, the lemma and PoS label are combined with syntactic information associated with the word &apos;s morphological form ( e.g. number for nouns). 3 The grammar Lexicalized D-Tree Grammar (LDTG) (Rambow et al., 1995) is a variant of LTAG. The primitive elements of LDTG are called elementary d-trees and are combined together to form larger structures during a derivation. Although, for convenience, we present d-trees graphically as though they were conventional trees, they are more correctly thought of as expressions in a tree description logic (Rogers and VijayShanker, 1992). These expressions partially describe trees by asserting various relationships between nodes: parenthood, domination, precedence (indicating that one node is to the left of anoth~r ), equality and inequality. There are two substitution"
W98-0108,P92-1010,0,0.0638642,"Missing"
W98-0108,W98-0139,1,0.780908,"Missing"
W98-0108,W98-1114,1,\N,Missing
W98-1114,P87-1027,1,0.265911,"Missing"
W98-1114,P91-1027,0,0.618493,"Missing"
W98-1114,J93-2002,0,0.465894,"Missing"
W98-1114,A97-1052,1,0.929049,"ernatives for individual verbal predicates. However, the empirical question of whether this type of frequency information can in practice improve the accuracy of a statistical parser has not yet been answered. In this paper we describe an experiment with a widecoverage statistical grammar and parser for English and subcategorisation frequencies acquired from ten million words of text which shows that this information can significantly improve parse accuracy 1. 1 Introduction Recent work on the automatic acquisition of lexical information from substantial amounts of machine-readable text (e.g. Briscoe & Carroll, 1997; Gahl, 1998; Carroll & Rooth, 1998) has opened up the possibility of producing largescale computational lexicons containing data on the relative frequencies of subcategorisation alternatives for individual verbal predicates. However, although Resnik (1992), Schabes (1992), Carroll & Weir (1997) and others have proposed 'lexicalised' probabilistic grammars to improve the accuracy of parse rank~This work was funded by U K E P S R C project GR/L53175 'PSET: Practical Simplification of English Text', C E C Telematics Applications Programme project LE1-2111 'SPARKLE: Shallow PARsing and Knowledge"
W98-1114,1997.iwpt-1.18,0,0.0195461,"divide into clausal, and into non-clausal direct object (dobj), second (non-clausal) complement in ditransitive constructions (obj2), and indirect object complement introduced by a preposition (iobj). In general the parser returns the most specific (leaf) relations in the G R hierarchy, except when it is unable to determine whether clausal s u b j e c t s / o b j e c t s are controlled from within or without (i.e. csubj vs. zsubj, and ccomp vs. zcomp respectively), in which case it 4Shortcomings of this combination of annotation and evaluation scheme have been noted previously by Lin (1996), Carpenter & Manning (1997) and others. Car(3) a ... (VP will hear (NP a greeting) (PP from (NP Gov. Mark garfield))) ... b ... (VP will hear (NP a greeting (PP from ( Y P Gov. Mark Hatfield)))) ... roll, Briscoe & Sanfilippo (1998) summarise the various criticisms that have been made. 122 dependent rood ncmod xmod c arg..mod m o a~ ~ ncsu3Zs~ubbjjcsubj~ a u s a l dobj obj2 iobj xcompccomp Figure 1: Portions of GR hierarchy used. (Relations in italics are not returned by the parser). returns subj or clausal as appropriate. Each relation is parameterised with a head (lemma) and a dependent (lemma)--also optionally a type"
W98-1114,W96-0209,1,0.837679,"ter Science, Tokyo Institute of Technology, and at CSLI, Stanford University; the author wishes to thank researchers at these institutionsfor many stimulating conversations. 118 ing, no wide-coverage parser has yet been constructed which explicitly incorporates probabilities of different subcategorisation alternatives for individual predicates. It is therefore an open question whether this type of information can actually improve parser accuracy in practice. In this paper we address this issue, describing an experiment with an existing wide-coverage statistical grammar and parser for English (Carroll & Briscoe, 1996) in conjunction with subcategorisation frequencies acquired from 10 million words of text from the British National Corpus (BNC; Leech, 1992). Our results show conclusively that this information can improve parse accuracy. 2 Background 2.1 S u b c a t e g o r i s a t i o n A c q u i s i t i o n Several substantial machine-readable subcategorisation dictionaries exist for English, either built semi-automatically from machine-readable versions of conventional learners' dictionaries, or manually by (computational) linguists (e.g. the Alvey NL Tools (ANLT) dictionary, Boguraev et al. (1987); the C"
W98-1114,1997.iwpt-1.6,1,0.757881,"er for English and subcategorisation frequencies acquired from ten million words of text which shows that this information can significantly improve parse accuracy 1. 1 Introduction Recent work on the automatic acquisition of lexical information from substantial amounts of machine-readable text (e.g. Briscoe & Carroll, 1997; Gahl, 1998; Carroll & Rooth, 1998) has opened up the possibility of producing largescale computational lexicons containing data on the relative frequencies of subcategorisation alternatives for individual verbal predicates. However, although Resnik (1992), Schabes (1992), Carroll & Weir (1997) and others have proposed 'lexicalised' probabilistic grammars to improve the accuracy of parse rank~This work was funded by U K E P S R C project GR/L53175 'PSET: Practical Simplification of English Text', C E C Telematics Applications Programme project LE1-2111 'SPARKLE: Shallow PARsing and Knowledge extraction for Language Engineering', and by an E P S R C Advanced Fellowship to the first author. Some of the work was carried out while the firstauthor was a visitor at the Tanaka Laboratory, Department of Computer Science, Tokyo Institute of Technology, and at CSLI, Stanford University; the a"
W98-1114,W98-1505,0,0.055878,"cates. However, the empirical question of whether this type of frequency information can in practice improve the accuracy of a statistical parser has not yet been answered. In this paper we describe an experiment with a widecoverage statistical grammar and parser for English and subcategorisation frequencies acquired from ten million words of text which shows that this information can significantly improve parse accuracy 1. 1 Introduction Recent work on the automatic acquisition of lexical information from substantial amounts of machine-readable text (e.g. Briscoe & Carroll, 1997; Gahl, 1998; Carroll & Rooth, 1998) has opened up the possibility of producing largescale computational lexicons containing data on the relative frequencies of subcategorisation alternatives for individual verbal predicates. However, although Resnik (1992), Schabes (1992), Carroll & Weir (1997) and others have proposed 'lexicalised' probabilistic grammars to improve the accuracy of parse rank~This work was funded by U K E P S R C project GR/L53175 'PSET: Practical Simplification of English Text', C E C Telematics Applications Programme project LE1-2111 'SPARKLE: Shallow PARsing and Knowledge extraction for Language Engineering'"
W98-1114,P96-1025,0,0.152394,"Missing"
W98-1114,A94-1009,0,0.0356313,"Missing"
W98-1114,P98-1071,0,0.0280851,"verbal predicates. However, the empirical question of whether this type of frequency information can in practice improve the accuracy of a statistical parser has not yet been answered. In this paper we describe an experiment with a widecoverage statistical grammar and parser for English and subcategorisation frequencies acquired from ten million words of text which shows that this information can significantly improve parse accuracy 1. 1 Introduction Recent work on the automatic acquisition of lexical information from substantial amounts of machine-readable text (e.g. Briscoe & Carroll, 1997; Gahl, 1998; Carroll & Rooth, 1998) has opened up the possibility of producing largescale computational lexicons containing data on the relative frequencies of subcategorisation alternatives for individual verbal predicates. However, although Resnik (1992), Schabes (1992), Carroll & Weir (1997) and others have proposed 'lexicalised' probabilistic grammars to improve the accuracy of parse rank~This work was funded by U K E P S R C project GR/L53175 'PSET: Practical Simplification of English Text', C E C Telematics Applications Programme project LE1-2111 'SPARKLE: Shallow PARsing and Knowledge extraction f"
W98-1114,C94-1042,0,0.0950826,"Missing"
W98-1114,A92-1022,0,0.0705477,"Missing"
W98-1114,C92-2099,0,0.0514336,"Missing"
W98-1114,1997.iwpt-1.16,0,0.0704025,"Missing"
W98-1114,P95-1037,0,0.0539086,"Missing"
W98-1114,P93-1032,0,0.556183,"Missing"
W98-1114,J93-2004,0,0.0462928,"Missing"
W98-1114,W97-0808,0,0.0568636,"Missing"
W98-1114,W93-0108,0,0.0603925,"Missing"
W98-1114,W97-0301,0,0.0474814,"Missing"
W98-1114,C92-2065,0,0.0443408,"ge statistical grammar and parser for English and subcategorisation frequencies acquired from ten million words of text which shows that this information can significantly improve parse accuracy 1. 1 Introduction Recent work on the automatic acquisition of lexical information from substantial amounts of machine-readable text (e.g. Briscoe & Carroll, 1997; Gahl, 1998; Carroll & Rooth, 1998) has opened up the possibility of producing largescale computational lexicons containing data on the relative frequencies of subcategorisation alternatives for individual verbal predicates. However, although Resnik (1992), Schabes (1992), Carroll & Weir (1997) and others have proposed 'lexicalised' probabilistic grammars to improve the accuracy of parse rank~This work was funded by U K E P S R C project GR/L53175 'PSET: Practical Simplification of English Text', C E C Telematics Applications Programme project LE1-2111 'SPARKLE: Shallow PARsing and Knowledge extraction for Language Engineering', and by an E P S R C Advanced Fellowship to the first author. Some of the work was carried out while the firstauthor was a visitor at the Tanaka Laboratory, Department of Computer Science, Tokyo Institute of Technology,"
W98-1114,C94-2123,0,0.050874,"Missing"
W98-1114,C92-2066,0,0.0607765,"grammar and parser for English and subcategorisation frequencies acquired from ten million words of text which shows that this information can significantly improve parse accuracy 1. 1 Introduction Recent work on the automatic acquisition of lexical information from substantial amounts of machine-readable text (e.g. Briscoe & Carroll, 1997; Gahl, 1998; Carroll & Rooth, 1998) has opened up the possibility of producing largescale computational lexicons containing data on the relative frequencies of subcategorisation alternatives for individual verbal predicates. However, although Resnik (1992), Schabes (1992), Carroll & Weir (1997) and others have proposed 'lexicalised' probabilistic grammars to improve the accuracy of parse rank~This work was funded by U K E P S R C project GR/L53175 'PSET: Practical Simplification of English Text', C E C Telematics Applications Programme project LE1-2111 'SPARKLE: Shallow PARsing and Knowledge extraction for Language Engineering', and by an E P S R C Advanced Fellowship to the first author. Some of the work was carried out while the firstauthor was a visitor at the Tanaka Laboratory, Department of Computer Science, Tokyo Institute of Technology, and at CSLI, Sta"
W98-1114,W93-0109,0,0.185618,"Missing"
W98-1114,C98-1068,0,\N,Missing
