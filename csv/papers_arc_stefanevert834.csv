2021.conll-1.46,{FAST}: A carefully sampled and cognitively motivated dataset for distributional semantic evaluation,2021,-1,-1,1,1,11404,stefan evert,Proceedings of the 25th Conference on Computational Natural Language Learning,0,"What is the first word that comes to your mind when you hear giraffe, or damsel, or freedom? Such free associations contain a huge amount of information on the mental representations of the corresponding concepts, and are thus an extremely valuable testbed for the evaluation of semantic representations extracted from corpora. In this paper, we present FAST (Free ASsociation Tasks), a free association dataset for English rigorously sampled from two standard free association norms collections (the Edinburgh Associative Thesaurus and the University of South Florida Free Association Norms), discuss two evaluation tasks, and provide baseline results. In parallel, we discuss methodological considerations concerning the desiderata for a proper evaluation of semantic representations."
2020.lrec-1.410,{C}orpus {Q}uery {L}ingua {F}ranca part {II}: Ontology,2020,-1,-1,1,1,11404,stefan evert,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The present paper outlines the projected second part of the Corpus Query Lingua Franca (CQLF) family of standards: CQLF Ontology, which is currently in the process of standardization at the International Standards Organization (ISO), in its Technical Committee 37, Subcommittee 4 (TC37SC4) and its national mirrors. The first part of the family, ISO 24623-1 (henceforth CQLF Metamodel), was successfully adopted as an international standard at the beginning of 2018. The present paper reflects the state of the CQLF Ontology at the moment of submission for the Committee Draft ballot. We provide a brief overview of the CQLF Metamodel, present the assumptions and aims of the CQLF Ontology, its basic structure, and its potential extended applications. The full ontology is expected to emerge from a community process, starting from an initial version created by the authors of the present paper."
2020.lrec-1.754,"{E}mpiri{ST} Corpus 2.0: Adding Manual Normalization, Lemmatization and Semantic Tagging to a {G}erman Web and {CMC} Corpus",2020,-1,-1,6,0.757036,18110,thomas proisl,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The EmpiriST corpus (Bei{\ss}wenger et al., 2016) is a manually tokenized and part-of-speech tagged corpus of approximately 23,000 tokens of German Web and CMC (computer-mediated communication) data. We extend the corpus with manually created annotation layers for word form normalization, lemmatization and lexical semantics. All annotations have been independently performed by multiple human annotators. We report inter-annotator agreements and results of baseline systems and state-of-the-art off-the-shelf tools."
W18-6234,{E}moti{KLUE} at {IEST} 2018: Topic-Informed Classification of Implicit Emotions,2018,0,0,4,0.834101,18110,thomas proisl,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"EmotiKLUE is a submission to the Implicit Emotion Shared Task. It is a deep learning system that combines independent representations of the left and right contexts of the emotion word with the topic distribution of an LDA topic model. EmotiKLUE achieves a macro average \textit{Fâ}score of 67.13{\%}, significantly outperforming the baseline produced by a simple ML classifier. Further enhancements after the evaluation period lead to an improved \textit{Fâ}score of 68.10{\%}."
L18-1523,Delta vs. N-Gram Tracing: Evaluating the Robustness of Authorship Attribution Methods,2018,0,0,2,0.834101,18110,thomas proisl,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
E17-2063,Large-scale evaluation of dependency-based {DSM}s: Are they worth the effort?,2017,18,4,2,1,628,gabriella lapesa,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"This paper presents a large-scale evaluation study of dependency-based distributional semantic models. We evaluate dependency-filtered and dependency-structured DSMs in a number of standard semantic similarity tasks, systematically exploring their parameter space in order to give them a {``}fair shot{''} against window-based models. Our results show that properly tuned window-based DSMs still outperform the dependency-based models in most tasks. There appears to be little need for the language-dependent resources and computational cost associated with syntactic analysis."
W16-5309,The {C}og{AL}ex-{V} Shared Task on the Corpus-Based Identification of Semantic Relations,2016,0,3,3,0,181,enrico santus,Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex - V),0,"The shared task of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex-V) aims at providing a common benchmark for testing current corpus-based methods for the identification of lexical semantic relations (synonymy, antonymy, hypernymy, part-whole meronymy) and at gaining a better understanding of their respective strengths and weaknesses. The shared task uses a challenging dataset extracted from EVALution 1.0, which contains word pairs holding the above-mentioned relations as well as semantically unrelated control items (random). The task is split into two subtasks: (i) identification of related word pairs vs. unrelated ones; (ii) classification of the word pairs according to their semantic relation. This paper describes the subtasks, the dataset, the evaluation metrics, the seven participating systems and their results. The best performing system in subtask 1 is GHHH (F1 = 0.790), while the best system in subtask 2 is LexNet (F1 = 0.445). The dataset and the task description are available at \url{https://sites.google.com/site/cogalex2016/home/shared-task}."
W16-5312,{C}og{AL}ex-{V} Shared Task: Mach5 {--} A traditional {DSM} approach to semantic relatedness,2016,0,0,1,1,11404,stefan evert,Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex - V),0,"This contribution provides a strong baseline result for the CogALex-V shared task using a traditional {``}count{''}-type DSM (placed in rank 2 out of 7 in subtask 1 and rank 3 out of 6 in subtask 2). Parameter tuning experiments reveal some surprising effects and suggest that the use of random word pairs as negative examples may be problematic, guiding the parameter optimization in an undesirable direction."
W16-2606,{E}mpiri{ST} 2015: A Shared Task on the Automatic Linguistic Annotation of Computer-Mediated Communication and Web Corpora,2016,18,6,3,0,33865,michael beisswenger,Proceedings of the 10th Web as Corpus Workshop,0,None
W15-0709,Towards a better understanding of Burrows{'}s Delta in literary authorship attribution,2015,14,2,1,1,11404,stefan evert,Proceedings of the Fourth Workshop on Computational Linguistics for Literature,0,"Burrowsxe2x80x99s Delta is the most established measure for stylometric difference in literary authorship attribution. Several improvements on the original Delta have been proposed. However, a recent empirical study showed that none of the proposed variants constitute a major improvement in terms of authorship attribution performance. With this paper, we try to improve our understanding of how and why these text distance measures work for authorship attribution. We evaluate the effects of standardization and vector normalization on the statistical distributions of features and the resulting text clustering quality. Furthermore, we explore supervised selection of discriminant words as a procedure for further improving authorship attribution."
S15-2020,{S}emanti{KLUE}: Semantic Textual Similarity with Maximum Weight Matching,2015,11,0,4,0,37192,nataliia plotnikova,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper describes the SemantiKLUE system (Proisl et al., 2014) used for the SemEval2015 shared task on Semantic Textual Similarity (STS) for English. The system was developed for SemEval-2013 and extended for SemEval-2014, where it participated in three tasks and ranked 13th out of 38 submissions for the English STS task. While this yearxe2x80x99s submission ranks 46th out of 73, further experiments on the selection of training data led to notable improvements showing that the system could have achieved rank 22 out of 73. We report a detailed analysis of those training selection experiments in which we tested different combinations of all the available STS datasets, as well as results of a qualitative analysis conducted on a sample of the sentence pairs for which SemantiKLUE gave wrong STS predictions."
S15-2103,{KLUE}less: Polarity Classification and Association,2015,9,10,4,0,37192,nataliia plotnikova,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper describes the KLUEless system which participated in the SemEval-2015 task on xe2x80x9cSentiment Analysis in Twitterxe2x80x9d. This year the updated system based on the developments for the same task in 2014 (Evert et al., 2014) and 2013 (Proisl et al., 2013) participated in all five subtasks. The paper gives an overview of the core features extended by different additional features and parameters required for individual subtasks. Experiments carried out after the evaluation period on the test dataset 2015 with the gold standard available are integrated into each subtask to explain the submitted feature selection."
W14-4707,{N}a{D}i{R}: Naive Distributional Response Generation,2014,16,0,2,1,628,gabriella lapesa,Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex),0,"This paper describes NaDiR (Naive DIstributional Response generation), a corpus-based system that, from a set of word stimuli as an input, generates a response word relying on association strength and distributional similarity. NaDiR participated in the CogALex 2014 shared task on multiword associations (restricted systems track), operationalizing the task as a ranking problem: candidate words from a large vocabulary are ranked by their average association or similarity to a given set of stimuli. We also report on a number of experiments conducted on the shared task data, comparing first-order models (based on co-occurrence and statistical association) to second-order models (based on distributional similarity)."
S14-2093,{S}emanti{KLUE}: Robust Semantic Similarity at Multiple Levels Using Maximum Weight Matching,2014,20,15,2,1,18110,thomas proisl,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,Being able to quantify the semantic similarity between two texts is important for many practical applications. SemantiKLUE combines unsupervised and supervised techniques into a robust system for measuring semantic similarity. At the core of the system is a word-to-word alignment of two texts using a maximum weight matching algorithm. The system participated in three SemEval-2014 shared tasks and the competitive results are evidence for its usability in that broad field of application.
S14-2096,{S}enti{KLUE}: Updating a Polarity Classifier in 48 Hours,2014,12,12,1,1,11404,stefan evert,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,SentiKLUE is an update of the KLUE polarity classifier xe2x80x93 which achieved good and robust results in SemEval-2013 with a simple feature set xe2x80x93 implemented in 48 hours.
S14-2101,{SNAP}: A Multi-Stage {XML}-Pipeline for Aspect Based Sentiment Analysis,2014,10,1,11,0,39017,clemens wettendorf,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper describes the SNAP system, which participated in Task 4 of SemEval2014: Aspect Based Sentiment Analysis. We use an XML-based pipeline that combines several independent components to perform each subtask. Key resources used by the system are Bing Liuxe2x80x99s sentiment lexicon, Stanford CoreNLP, RFTagger, several machine learning algorithms and WordNet. SNAP achieved satisfactory results in the evaluation, placing in the top half of the field for most subtasks."
S14-1020,Contrasting Syntagmatic and Paradigmatic Relations: Insights from Distributional Semantic Models,2014,30,15,2,1,628,gabriella lapesa,Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*{SEM} 2014),0,"This paper presents a large-scale evaluation of bag-of-words distributional models on two datasets from priming experiments involving syntagmatic and paradigmatic relations. We interpret the variation in performance achieved by different settings of the model parameters as an indication of which aspects of distributional patterns characterize these types of relations. Contrary to what has been argued in the literature (Rapp, 2002; Sahlgren, 2006) xe2x80x90 that bag-of-words models based on secondorder statistics mainly capture paradigmatic relations and that syntagmatic relations need to be gathered from first-order models xe2x80x90 we show that second-order models perform well on both paradigmatic and syntagmatic relations if their parameters are properly tuned. In particular, our results show that size of the context window and dimensionality reduction play a key role in differentiating DSM performance on paradigmatic vs. syntagmatic relations."
Q14-1041,"A Large Scale Evaluation of Distributional Semantic Models: Parameters, Interactions and Model Selection",2014,41,33,2,1,628,gabriella lapesa,Transactions of the Association for Computational Linguistics,0,This paper presents the results of a large-scale evaluation study of window-based Distributional Semantic Models on a wide variety of tasks. Our study combines a broad coverage of model parameters with a model selection methodology that is robust to overfitting and able to capture parameter interactions. We show that our strategy allows us to identify parameter configurations that achieve good performance across different datasets and tasks.
C14-2024,Distributional Semantics in {R} with the wordspace Package,2014,12,5,1,1,11404,stefan evert,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: System Demonstrations",0,"This paper introduces the wordspace package, which turns Gnu R into an interactive laboratory for research in distributional semantics. The package includes highly efficient implementations of a carefully chosen set of key functions, allowing it to scale up to real-life data sets."
W13-2608,Evaluating Neighbor Rank and Distance Measures as Predictors of Semantic Priming,2013,25,21,2,1,628,gabriella lapesa,Proceedings of the Fourth Annual Workshop on Cognitive Modeling and Computational Linguistics ({CMCL}),0,"This paper summarizes the results of a large-scale evaluation study of bag-ofwords distributional models on behavioral data from three semantic priming experiments. The tasks at issue are (i) identification of consistent primes based on their semantic relatedness to the target and (ii) correlation of semantic relatedness with latency times. We also provide an evaluation of the impact of specific model parameters on the prediction of priming. To the best of our knowledge, this is the first systematic evaluation of a wide range of DSM parameters in all possible combinations. An important result of the study is that neighbor rank performs better than distance measures in predicting semantic priming."
S13-2065,{KLUE}: Simple and robust methods for polarity classification,2013,7,19,3,1,18110,thomas proisl,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper describes our approach to the SemEval-2013 task on xe2x80x9cSentiment Analysis in Twitterxe2x80x9d. We use simple bag-of-words models, a freely available sentiment dictionary automatically extended with distributionally similar terms, as well as lists of emoticons and internet slang abbreviations in conjunction with fast and robust machine learning algorithms. The resulting system is resource-lean, making it relatively independent of a specific language. Despite its simplicity, the system achieves competitive accuracies of 0.70xe2x80x900.72 in detecting the sentiment of text messages. We also apply our approach to the task of detecting the contextdependent sentiment of individual words and phrases within a message."
S13-1026,{KLUE}-{CORE}: A regression model of semantic textual similarity,2013,13,1,3,0,39016,paul greiner,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity",0,"This paper describes our system entered for the *SEM 2013 shared task on Semantic Textual Similarity (STS). We focus on the core task of predicting the semantic textual similarity of sentence pairs. The current system utilizes machine learning techniques trained on semantic similarity ratings from the *SEM 2012 shared task; it achieved rank 20 out of 90 submissions from 35 different teams. Given the simple nature of our approach, which uses only WordNet and unannotated corpus data as external resources, we consider this a remarkably good result, making the system an interesting tool for a wide range of practical applications."
W10-1505,{G}oogle Web 1{T} 5-Grams Made Easy (but not for the computer),2010,7,13,1,1,11404,stefan evert,Proceedings of the {NAACL} {HLT} 2010 Sixth Web as Corpus Workshop,0,"This paper introduces Web1T5-Easy, a simple indexing solution that allows interactive searches of the Web 1T 5-gram database and a derived database of quasi-collocations. The latter is validated against co-occurrence data from the BNC and ukWaC on the automatic identification of non-compositional VPC."
N10-4006,Distributional Semantic Models,2010,10,6,1,1,11404,stefan evert,NAACL HLT 2010 Tutorial Abstracts,0,"Distributional semantic models (DSM) -also known as word space or distributional similarity models -are based on the assumption that the meaning of a word can (at least to a certain extent) be inferred from its usage, i.e. its distribution in text. Therefore, these models dynamically build semantic representations -in the form of highdimensional vector spaces -through a statistical analysis of the contexts in which words occur. DSMs are a promising technique for solving the lexical acquisition bottleneck by unsupervised learning, and their distributed representation provides a cognitively plausible, robust and flexible architecture for the organisation and processing of semantic information."
evert-2008-lightweight,A Lightweight and Efficient Tool for Cleaning Web Pages,2008,3,32,1,1,11404,stefan evert,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Originally conceived as a Âna{\""\i}veÂ baseline experiment using traditional n-gram language models as classifiers, the NCleaner system has turned out to be a fast and lightweight tool for cleaning Web pages with state-of-the-art accuracy (based on results from the CLEANEVAL competition held in 2007). Despite its simplicity, the algorithm achieves a significant improvement over the baseline (i.e. plain, uncleaned text dumps), trading off recall for substantially higher precision. NCleaner is available as an open-source software package. It is pre-configured for English Web pages, but can be adapted to other languages with minimal amounts of manually cleaned training data. Since NCleaner does not make use of HTML structure, it can also be applied to existing Web corpora that are only available in plain text format, with a minor loss in classfication accuracy."
P07-2008,zipf{R}: Word Frequency Modeling in {R},2007,0,5,1,1,11404,stefan evert,Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,0,None
P07-1114,Words and Echoes: Assessing and Mitigating the Non-Randomness Problem in Word Frequency Distribution Modeling,2007,5,7,2,0,12129,marco baroni,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"Frequency distribution models tuned to words and other linguistic events can predict the number of distinct types and their frequency distribution in samples of arbitrary sizes. We conduct, for the first time, a rigorous evaluation of these models based on cross-validation and separation of training and test data. Our experiments reveal that the prediction accuracy of the models is marred by serious overfitting problems, due to violations of the random sampling assumption in corpus data. We then propose a simple pre-processing method to alleviate such non-randomness problems. Further evaluation confirms the effectiveness of the method, which compares favourably to more complex correction techniques."
evert-etal-2004-identifying,Identifying Morphosyntactic Preferences in Collocations,2004,8,15,1,1,11404,stefan evert,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"In this paper, we describe research that aims to make evidence on the morphosyntactic preferences of collocations available to lexicographers. Our methods for the extraction of appropriate frequency data and its statistical analysis are applied to the number and case preferences of German adjectivenoun combinations in a small case study."
evert-2004-statistical,The Statistical Analysis of Morphosyntactic Distributions,2004,5,9,1,1,11404,stefan evert,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper describes methods for the statistical analysis of quantitative data on the distribution of morphosyntactic features. A key problem is the large amount of ambiguity in automatically extracted data. In the paper, I argue for a conservative approach that treats ambiguous instances as counter-evidence. It is nonetheless possible to obtain detailed morphosyntactic information from the corpus data with the help of partial disambiguation and by exploiting systematic ambiguity classes."
C04-1136,Significance tests for the evaluation of ranking methods,2004,9,11,1,1,11404,stefan evert,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"This paper presents a statistical model that interprets the evaluation of ranking methods as a random experiment. This model predicts the variability of evaluation results, so that appropriate significance tests for the results can be derived. The paper concludes with an empirical validation of the model on a collocation extraction task."
E03-1080,Experiments on Candidate Data for Collocation Extraction,2003,7,24,1,1,11404,stefan evert,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"The paper describes ongoing work on the evaluation of methods for extracting collocation candidates from large text corpora. Our research is based on a German treebank corpus used as gold standard. Results are available for adjectivenoun pairs, which proved to be a comparatively easy extraction task. We plan to extend the evaluation to other types of collocations (e.g., PPverb pairs)."
kermes-evert-2002-yac,{YAC} - A Recursive Chunker for Unrestricted {G}erman Text,2002,6,17,2,0,32141,hannah kermes,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"YAC is a fully automatic recursive chunker for unrestricted German text. It is especially designed to provide a useful basis for the extraction of linguistic as well as lexicographic information. Consequently, the grammar rules of YAC are implemented such as to make the resulting analysis meet the needs of an ensuing extraction process. The chunks provided by YAC are continuous parts of intra-clausal constituents including recursion but no PP-attachment or sentential elements. The chunks are additionally enriched with information about head lemma, morpho-syntactic features and certain lexical and structural properties."
soria-etal-2002-advanced,Advanced Tools for the Study of Natural Interactivity,2002,4,6,6,0,30233,claudia soria,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"The NITE European project aims at building an integrated best practice workbench for multi-level, cross-level and cross-modality annotation, retrieval and exploitation of multi-party natural interactive human-human and human-machine dialogue data. In this paper we intend to broach the general lines of software development envisaged in NITE, the four prototypes we intend to make available to the scientific community at large and our approach to usability evaluation of the prototypes. Under the aegis of LREC 2002 we plan to encourage conference participants to take active part in usability evaluation and provide early feedback to our software design choices."
P01-1025,Methods for the Qualitative Evaluation of Lexical Association Measures,2001,8,136,1,1,11404,stefan evert,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents methods for a qualitative, unbiased comparison of lexical association measures and the results we have obtained for adjective-noun pairs and preposition-noun-verb triples extracted from German corpora. In our approach, we compare the entire list of candidates, sorted according to the particular measures, to a reference set of manually identified true positives. We also show how estimates for the very large number of hapaxlegomena and double occurrences can be inferred from random samples."
