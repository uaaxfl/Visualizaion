2005.jeptalnrecital-court.8,W02-2233,1,0.893154,"Missing"
2005.jeptalnrecital-court.8,W02-2226,0,0.0637408,"Missing"
2008.jeptalnrecital-long.17,abeille-barrier-2004-enriching,0,0.0656987,"Missing"
2008.jeptalnrecital-long.17,P05-1038,0,0.162403,"Missing"
2008.jeptalnrecital-long.17,A00-1031,0,0.216259,"Missing"
2008.jeptalnrecital-long.17,P05-1022,0,0.0658642,"Missing"
2008.jeptalnrecital-long.17,J03-4003,0,0.0674105,"Missing"
2008.jeptalnrecital-long.17,W01-0521,0,0.0616877,"Missing"
2008.jeptalnrecital-long.17,J98-4004,0,0.223944,"Missing"
2008.jeptalnrecital-long.17,P03-1054,0,0.087619,"Missing"
2008.jeptalnrecital-long.17,P05-1010,0,0.181101,"Missing"
2008.jeptalnrecital-long.17,P06-1055,0,0.187663,"Missing"
2009.jeptalnrecital-court.1,P05-1038,0,0.0413146,"Missing"
2009.jeptalnrecital-court.1,A00-1031,0,0.165214,"Missing"
2009.jeptalnrecital-court.1,P04-1041,0,0.0348247,"Missing"
2009.jeptalnrecital-court.1,A00-2018,0,0.240234,"Missing"
2009.jeptalnrecital-court.1,P00-1058,0,0.0518767,"Missing"
2009.jeptalnrecital-court.1,P03-1013,0,0.0578217,"Missing"
2009.jeptalnrecital-court.1,J98-4004,0,0.172518,"Missing"
2009.jeptalnrecital-court.1,J00-4006,0,0.0159887,"Missing"
2009.jeptalnrecital-court.1,P03-1054,0,0.0322081,"Missing"
2009.jeptalnrecital-court.1,P06-1055,0,0.281177,"Missing"
2009.jeptalnrecital-court.1,D07-1066,0,0.0506424,"Missing"
2009.jeptalnrecital-court.1,schluter-van-genabith-2008-treebank,0,0.257186,"Missing"
2009.jeptalnrecital-long.4,P05-1038,0,0.0779972,"Missing"
2009.jeptalnrecital-long.4,J96-1002,0,0.0126056,"Missing"
2009.jeptalnrecital-long.4,W09-1008,1,0.87588,"Missing"
2009.jeptalnrecital-long.4,de-marneffe-etal-2006-generating,0,0.109659,"Missing"
2009.jeptalnrecital-long.4,A00-2018,0,0.128627,"Missing"
2009.jeptalnrecital-long.4,2001.jeptalnrecital-tutoriel.3,0,0.368197,"Missing"
2009.jeptalnrecital-long.4,W03-2401,0,0.0761601,"Missing"
2009.jeptalnrecital-long.4,P95-1037,0,0.329975,"Missing"
2009.jeptalnrecital-long.4,schluter-van-genabith-2008-treebank,0,0.0611634,"Missing"
2010.jeptalnrecital-long.8,W09-3821,1,0.850096,"Missing"
2010.jeptalnrecital-long.8,chrupala-etal-2008-learning,0,0.0225779,"Missing"
2015.jeptalnrecital-long.25,P14-2133,0,0.0378448,"Missing"
2015.jeptalnrecital-long.25,P14-2131,0,0.0400368,"Missing"
2015.jeptalnrecital-long.25,W09-3821,1,0.847335,"Missing"
2015.jeptalnrecital-long.25,D14-1082,0,0.0628618,"Missing"
2015.jeptalnrecital-long.25,C14-1052,1,0.876883,"Missing"
2015.jeptalnrecital-long.25,P04-1013,0,0.0543676,"Missing"
2015.jeptalnrecital-long.25,P08-1068,0,0.0795963,"Missing"
2015.jeptalnrecital-long.25,P06-1055,0,0.0151221,"Missing"
2015.jeptalnrecital-long.25,P06-2089,0,0.0323646,"Missing"
2015.jeptalnrecital-long.25,W13-4917,0,0.0364094,"Missing"
2015.jeptalnrecital-long.25,P13-1045,0,0.0723748,"Missing"
2015.jeptalnrecital-long.25,P07-1080,0,0.0715634,"Missing"
2015.jeptalnrecital-long.25,P10-1040,0,0.0651207,"Missing"
2015.jeptalnrecital-long.25,I13-1183,0,0.0467716,"Missing"
2015.jeptalnrecital-long.25,W09-3825,0,0.067413,"Missing"
2015.jeptalnrecital-long.25,C12-2136,0,0.292868,"Missing"
2015.jeptalnrecital-long.25,D13-1071,0,0.0270479,"Missing"
2015.jeptalnrecital-long.25,P13-1043,0,0.0525248,"Missing"
2017.jeptalnrecital-long.6,P05-1038,0,0.114874,"Missing"
2017.jeptalnrecital-long.6,F12-2024,0,0.0604719,"Missing"
2017.jeptalnrecital-long.6,D14-1082,0,0.0833254,"Missing"
2017.jeptalnrecital-long.6,E17-1118,1,0.850788,"Missing"
2017.jeptalnrecital-long.6,E17-2053,1,0.860534,"Missing"
2017.jeptalnrecital-long.6,J81-4005,0,0.757708,"Missing"
2017.jeptalnrecital-long.6,P16-2006,0,0.042009,"Missing"
2017.jeptalnrecital-long.6,D16-1001,0,0.0388742,"Missing"
2017.jeptalnrecital-long.6,W11-2913,0,0.0577839,"Missing"
2017.jeptalnrecital-long.6,J13-1006,0,0.0965957,"Missing"
2017.jeptalnrecital-long.6,Q16-1023,0,0.0487651,"Missing"
2017.jeptalnrecital-long.6,P03-1054,0,0.0958761,"Missing"
2017.jeptalnrecital-long.6,P15-1116,0,0.0399677,"Missing"
2017.jeptalnrecital-long.6,J93-2004,0,0.0582368,"Missing"
2017.jeptalnrecital-long.6,C16-1040,0,0.0551228,"Missing"
2017.jeptalnrecital-long.6,P16-2067,0,0.0223115,"Missing"
2017.jeptalnrecital-long.6,L16-1375,0,0.0333758,"Missing"
2017.jeptalnrecital-long.6,W13-4917,0,0.0477458,"Missing"
2017.jeptalnrecital-long.6,A97-1014,0,0.558229,"Missing"
2017.jeptalnrecital-long.6,W14-6104,0,0.0457161,"Missing"
2020.jeptalnrecital-taln.26,D19-1572,0,0.0323304,"Missing"
2020.jeptalnrecital-taln.26,P18-1031,0,0.0541897,"Missing"
2020.jeptalnrecital-taln.26,P19-1340,0,0.0367789,"Missing"
2020.jeptalnrecital-taln.26,P18-1249,0,0.0395933,"Missing"
2020.jeptalnrecital-taln.26,P07-2045,0,0.0108736,"Missing"
2020.jeptalnrecital-taln.26,P10-1023,0,0.119362,"Missing"
2020.jeptalnrecital-taln.26,D14-1162,0,0.0892081,"Missing"
2020.jeptalnrecital-taln.26,N18-1202,0,0.0990203,"Missing"
2020.jeptalnrecital-taln.26,P10-1114,0,0.0829177,"Missing"
2020.jeptalnrecital-taln.26,D17-1039,0,0.0479498,"Missing"
2020.jeptalnrecital-taln.26,W13-4917,0,0.0975746,"112 500 paires de phrases annotées avec les étiquettes entailment, contradiction ou neutre. FLUE intègre la partie française de ce corpus. Analyse syntaxique et étiquetage morphosyntaxique Nous considérons deux tâches d’analyse syntaxique : analyse en constituants et en dépendances, ainsi que l’étiquetage morphosyntaxique. Pour cela, nous utilisons le French Treebank (Abeillé et al., 2003), une collection de phrases du Monde annotées manuellement en constituants et dépendances syntaxiques. Nous utilisons la version de ce corpus de la campagne d’évaluation SPMRL 2014 décrite par Seddah et al. (2013), qui contient 14759, 1235 et 2541 phrases pour respectivement l’entraînement, le développement et l’évaluation. 271 Désambiguïsation lexicale des verbes et des noms La désambiguïsation lexicale consiste à assigner un sens, parmi un inventaire donné, à des mots d’une phrase. Pour la désambiguïsation lexicale de verbes, nous utilisons les données de FrenchSemEval (Segonne et al., 2019). Il s’agit d’un corpus d’évaluation dont les occurrences de verbes ont été annotées manuellement avec les sens de Wiktionary. 10 Pour la désambiguïsation lexicale des noms, nous utilisons la partie française de l"
2020.jeptalnrecital-taln.26,W19-0422,1,0.888597,"Missing"
2020.jeptalnrecital-taln.26,P16-1162,0,0.146858,"Missing"
2020.jeptalnrecital-taln.26,tiedemann-2012-parallel,0,0.0825572,"Missing"
2020.jeptalnrecital-taln.26,2019.gwc-1.14,1,0.893471,"Missing"
2020.jeptalnrecital-taln.26,W18-5446,0,0.0474061,"Missing"
2020.jeptalnrecital-taln.26,N18-1101,0,0.0610743,"Missing"
2020.jeptalnrecital-taln.26,D19-1382,0,0.0395373,"Missing"
2020.jeptalnrecital-taln.26,N19-1131,0,0.0313441,"Missing"
2020.lrec-1.302,2020.osact-1.2,0,0.0214996,"QuAD (Rajpurkar et al., 2018), surpassing previous methods by a large margin. 2.2. Pre-trained Language Models Beyond English Given the impact of pre-trained language models on NLP downstream tasks in English, several works have recently released pre-trained models for other languages. For instance, ELMo exists for Portuguese, Japanese, German and Basque,5 while BERT and variants were specifically trained for simplified and traditional Chinese8 and German.6 A Portuguese version of MultiFiT is also available.7 Recently, more monolingual BERT-based models have been released, such as for Arabic (Antoun et al., 2020), Dutch (de Vries et al., 2019; Delobelle et al., 2020), Finnish (Virtanen et al., 2019), Italian (Polignano et al., 2019), Portuguese (Souza et al., 2019), Russian (Kuratov and Arkhipov, 2019), Spanish (Ca˜nete et al., 2020), and Vietnamese (Nguyen and Nguyen, 2020). For French, besides pre-trained language models using ULMFiT and MultiFiT configurations,7 CamemBERT (Martin et al., 2019) is a French BERT model concurrent to our work. Another trend considers one model estimated for several languages with a shared vocabulary. The release of multilingual BERT for 104 languages pioneered this app"
2020.lrec-1.302,Q19-1038,0,0.0214599,"19), Portuguese (Souza et al., 2019), Russian (Kuratov and Arkhipov, 2019), Spanish (Ca˜nete et al., 2020), and Vietnamese (Nguyen and Nguyen, 2020). For French, besides pre-trained language models using ULMFiT and MultiFiT configurations,7 CamemBERT (Martin et al., 2019) is a French BERT model concurrent to our work. Another trend considers one model estimated for several languages with a shared vocabulary. The release of multilingual BERT for 104 languages pioneered this approach.8 A recent extension of this work leverages parallel data to build a cross-lingual pre-trained version of LASER (Artetxe and Schwenk, 2019) for 93 languages, XLM (Lample and Conneau, 2019) and XLM-R (Conneau et al., 2019) for 100 languages. 2.3. Evaluation Protocol for French NLP Tasks The existence of a multi-task evaluation benchmark such as GLUE (Wang et al., 2018) for English is highly beneficial to facilitate research in the language of interest. The GLUE benchmark has become a prominent framework to evaluate the performance of NLP models in English. The recent contributions based on pre-trained language models have led to remarkable performance across a wide range of Natural Language Understanding (NLU) tasks. The authors o"
2020.lrec-1.302,W06-1615,0,0.0880109,"2 1 985 XNLI-FR Diverse genres 392 702 2 490 5 010 French Treebank Daily newspaper 14 759 1 235 2 541 FrenchSemEval Diverse genres 55 206 - 3 199 Noun Sense Disambiguation Diverse genres 818 262 - 1 445 Table 2: Descriptions of the datasets included in our FLUE benchmark. 4.1. Text Classification CLS The Cross Lingual Sentiment CLS (Prettenhofer and Stein, 2010) dataset consists of Amazon reviews for three product categories: books, DVD, and music in four languages: English, French, German, and Japanese. Each sample contains a review text and the associated rating from 1 to 5 stars. Following Blitzer et al. (2006) and Prettenhofer and Stein (2010), ratings with 3 stars are removed. Positive reviews have ratings higher than 3 and negative reviews are those rated lower than 3. There is one train and test set for each product category. The train and test sets are balanced, including around 1 000 positive and 1 000 negative reviews for a total of 2 000 reviews in each dataset. We take the French portion to create the binary text classification task in FLUE and report the accuracy on the test set. 4.2. Paraphrasing PAWS-X The Cross-lingual Adversarial Dataset for Paraphrase Identification PAWS-X (Yang et al"
2020.lrec-1.302,P17-1152,0,0.0617991,"Missing"
2020.lrec-1.302,D18-1269,0,0.0239485,"gement. The paraphrasing task is to identify whether the sentences in these pairs are semantically equivalent or not. Similar to previous approaches to create multilingual corpora, Yang et al. (2019a) used machine translation to create the training set for each target language in PAWS-X from the English training set in PAWS. The development and test sets for each language are translated by human translators. We take the related datasets for French to perform the paraphrasing task and report the accuracy on the test set. 4.3. Natural Language Inference XNLI The Cross-lingual NLI (XNLI) corpus (Conneau et al., 2018) extends the development and test sets of the Multi-Genre Natural Language Inference corpus (Williams et al., 2018, MultiNLI) to 15 languages. The development and test sets for each language consist of 7 500 humanannotated examples, making up a total of 112 500 sentence pairs annotated with the labels entailment, contradiction, or neutral. Each sentence pair includes a premise (p) and a hypothesis (h). The Natural Language Inference (NLI) task, also known as recognizing textual entailment (RTE), is to determine whether p entails, contradicts or neither entails nor contradicts h. We take the Fr"
2020.lrec-1.302,P19-4007,0,0.0544476,"Missing"
2020.lrec-1.302,W13-4905,0,0.054327,"shared task organizers. Our word representations are a concatenation of word embeddings and tag embeddings learned together with the model parameters on the French Treebank data itself, and at most one of (fastText, CamemBERT, FlauBERTBASE , FlauBERTBASE , mBERT) word vector. As Dozat and Manning (2016), we use word and tag dropout (d = 0.5) on word and tag embeddings but without dropout on BERT representations. We performed a fairly comprehensive grid search on hyperparameters for each model tested. Results The results are reported in Table 7. The best published results in this shared task (Constant et al., 2013) were involving an ensemble of parsers with additional resources for modelling multi word expressions (MWE), typical of the French treebank annotations. The monolingual French BERT models (CamemBERT, FlauBERT) perform better and set the new state of the art on this dataset with a single parser and without specific modelling for MWEs. One can observe that both FlauBERT models perform marginally better than CamemBERT, while all of them outperform mBERT by a large margin. 2484 Model UAS LAS Best published (Constant et al., 2013) 89.19 85.86 No pre-training fastText pre-training mBERT CamemBERT Fl"
2020.lrec-1.302,2020.findings-emnlp.292,0,0.0289963,"ethods by a large margin. 2.2. Pre-trained Language Models Beyond English Given the impact of pre-trained language models on NLP downstream tasks in English, several works have recently released pre-trained models for other languages. For instance, ELMo exists for Portuguese, Japanese, German and Basque,5 while BERT and variants were specifically trained for simplified and traditional Chinese8 and German.6 A Portuguese version of MultiFiT is also available.7 Recently, more monolingual BERT-based models have been released, such as for Arabic (Antoun et al., 2020), Dutch (de Vries et al., 2019; Delobelle et al., 2020), Finnish (Virtanen et al., 2019), Italian (Polignano et al., 2019), Portuguese (Souza et al., 2019), Russian (Kuratov and Arkhipov, 2019), Spanish (Ca˜nete et al., 2020), and Vietnamese (Nguyen and Nguyen, 2020). For French, besides pre-trained language models using ULMFiT and MultiFiT configurations,7 CamemBERT (Martin et al., 2019) is a French BERT model concurrent to our work. Another trend considers one model estimated for several languages with a shared vocabulary. The release of multilingual BERT for 104 languages pioneered this approach.8 A recent extension of this work leverages paral"
2020.lrec-1.302,N19-1423,0,0.620298,"is-diderot.fr, alexandre.allauzen@espci.fr Abstract Language models have become a key step to achieve state-of-the art results in many different Natural Language Processing (NLP) tasks. Leveraging the huge amount of unlabeled texts nowadays available, they provide an efficient way to pre-train continuous word representations that can be fine-tuned for a downstream task, along with their contextualization at the sentence level. This has been widely demonstrated for English using contextualized representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al., 2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and share FlauBERT, a model learned on a very large and heterogeneous French corpus. Models of different sizes are trained using the new CNRS (French National Centre for Scientific Research) Jean Zay supercomputer. We apply our French language models to diverse NLP tasks (text classification, paraphrasing, natural language inference, parsing, word sense disambiguation) and show that most of the time they outperform other pre-training approaches. Different versions of FlauBERT as well as a unified evaluation protocol for the downstream tasks, c"
2020.lrec-1.302,eisele-chen-2010-multiun,0,0.103871,"Missing"
2020.lrec-1.302,D19-1572,0,0.0171919,"architecture, while ELMo adopts a bidirectional LSTM to build the final embedding for each input token from the concatenation of the left-to-right and rightto-left representations. Another fundamental difference lies in how each model can be tuned to different downstream tasks: ELMo delivers different word vectors that can be interpolated, whereas ULMFiT enables robust fine-tuning of the whole network w.r.t. the downstream tasks. The ability of fine-tuning was shown to significantly boost the performance, and thus this approach has been further developed in the recent works such as MultiFiT (Eisenschlos et al., 2019) or most prominently Transformer-based (Vaswani et al., 2017) architectures: GPT (Radford et al., 2018), BERT (Devlin et al., 2019), XLNet (Yang et al., 2019b), XLM (Lample and Conneau, 2019), RoBERTa (Liu et al., 2019), ALBERT (Lan et al., 2019), T5 (Raffel et al., 2019). These methods have one after the other established new state-ofthe-art results on various NLP benchmarks, such as GLUE (Wang et al., 2018) or SQuAD (Rajpurkar et al., 2018), surpassing previous methods by a large margin. 2.2. Pre-trained Language Models Beyond English Given the impact of pre-trained language models on NLP do"
2020.lrec-1.302,P18-1031,0,0.289639,"incent.segonne@etu, bcrabbe@linguist}.univ-paris-diderot.fr, alexandre.allauzen@espci.fr Abstract Language models have become a key step to achieve state-of-the art results in many different Natural Language Processing (NLP) tasks. Leveraging the huge amount of unlabeled texts nowadays available, they provide an efficient way to pre-train continuous word representations that can be fine-tuned for a downstream task, along with their contextualization at the sentence level. This has been widely demonstrated for English using contextualized representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al., 2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and share FlauBERT, a model learned on a very large and heterogeneous French corpus. Models of different sizes are trained using the new CNRS (French National Centre for Scientific Research) Jean Zay supercomputer. We apply our French language models to diverse NLP tasks (text classification, paraphrasing, natural language inference, parsing, word sense disambiguation) and show that most of the time they outperform other pre-training approaches. Different versions of FlauBERT as well as a unified eval"
2020.lrec-1.302,P18-1249,0,0.141589,"Table 5. The results confirm the superiority of the French models compared to the multilingual model mBERT on this task. FlauBERTLARGE performs moderately better than CamemBERT. Both of them clearly outperform XLM-RBASE , while cannot surpass XLM-RLARGE . Model XLM-RLARGE † XLM-RBASE † mBERT‡ CamemBERT ‡ FlauBERTBASE FlauBERTLARGE † ‡ Accuracy 85.2 80.1 76.9 81.2 80.6 83.4 Results reported in (Conneau et al., 2019). Results reported in (Martin et al., 2019). Table 5: Results on the French XNLI dataset. 5.4. Constituency Parsing and POS Tagging Model description We use the parser described by Kitaev and Klein (2018) and Kitaev et al. (2019). It is an openly available19 chart parser based on a self-attentive encoder. We compare (i) a model without any pre-trained parameters, (ii) a model that additionally uses and fine-tunes fastText20 pre-trained embeddings, (iii) models based on pre-trained language models: mBERT, CamemBERT, and FlauBERT. We use the default hyperparameters from Kitaev and Klein (2018) for the first two settings and the hyperparameters from Kitaev et al. (2019) when using pretrained language models, except for FlauBERTLARGE . For this last model, we use a different learning rate (0.00001"
2020.lrec-1.302,P19-1340,0,0.0189308,"m the superiority of the French models compared to the multilingual model mBERT on this task. FlauBERTLARGE performs moderately better than CamemBERT. Both of them clearly outperform XLM-RBASE , while cannot surpass XLM-RLARGE . Model XLM-RLARGE † XLM-RBASE † mBERT‡ CamemBERT ‡ FlauBERTBASE FlauBERTLARGE † ‡ Accuracy 85.2 80.1 76.9 81.2 80.6 83.4 Results reported in (Conneau et al., 2019). Results reported in (Martin et al., 2019). Table 5: Results on the French XNLI dataset. 5.4. Constituency Parsing and POS Tagging Model description We use the parser described by Kitaev and Klein (2018) and Kitaev et al. (2019). It is an openly available19 chart parser based on a self-attentive encoder. We compare (i) a model without any pre-trained parameters, (ii) a model that additionally uses and fine-tunes fastText20 pre-trained embeddings, (iii) models based on pre-trained language models: mBERT, CamemBERT, and FlauBERT. We use the default hyperparameters from Kitaev and Klein (2018) for the first two settings and the hyperparameters from Kitaev et al. (2019) when using pretrained language models, except for FlauBERTLARGE . For this last model, we use a different learning rate (0.00001), batch size (8) and ign"
2020.lrec-1.302,P07-2045,0,0.0134554,"to extract the text or download them directly from their websites. The total size of the uncompressed text before preprocessing is 270 GB. More details can be found in Appendix A.1. Data preprocessing For all sub-corpora, we filtered out very short sentences as well as repetitive and nonmeaningful content such as telephone/fax numbers, email addresses, etc. For Common Crawl, which is our largest sub-corpus with 215 GB of raw text, we applied aggressive cleaning to reduce its size to 43.4 GB. All the data were Unicode-normalized in a consistent way before being tokenized using Moses tokenizer (Koehn et al., 2007). The resulting training corpus is 71 GB in size. Our code for downloading and preprocessing data is made publicly available.13 3.2. Models and Training Configurations Model architecture FlauBERT has the same model architecture as BERT (Devlin et al., 2019), which consists of a multi-layer bidirectional Transformer (Vaswani et al., 2017). Following Devlin et al. (2019), we propose two model sizes: • FlauBERTBASE : L = 12, H = 768, A = 12, • FlauBERTLARGE : L = 24, H = 1024, A = 16, where L, H and A respectively denote the number of Transformer blocks, the hidden size, and the number of selfatt"
2020.lrec-1.302,2005.mtsummit-papers.11,0,0.015061,"Missing"
2020.lrec-1.302,W19-5303,0,0.226301,"ding FlauBERT In this section, we describe the training corpus, the text preprocessing pipeline, the model architecture and training configurations to build FlauBERTBASE and FlauBERTLARGE . 3.1. Training Data Data collection Our French text corpus consists of 24 sub-corpora gathered from different sources, covering diverse topics and writing styles, ranging from formal and well-written text (e.g. Wikipedia and books)10 to random text crawled from the Internet (e.g. Common Crawl).11 The data were collected from three main sources: (1) monolingual data for French provided in WMT19 shared tasks (Li et al., 2019, 4 sub-corpora); (2) French text corpora offered in the OPUS collection (Tiedemann, 2012, 8 sub-corpora); and (3) datasets available in the Wikimedia projects (Meta, 2019, 8 sub-corpora). We used the WikiExtractor tool12 to extract the text from Wikipedia. For the other sub-corpora, we either used our 7 https://github.com/piegu/language-models https://github.com/google-research/bert 9 https://github.com/chineseGLUE/chineseGLUE 10 http://www.gutenberg.org 11 http://data.statmt.org/ngrams/deduped2017 12 https://github.com/attardi/wikiextractor 8 4 It should be noted that learning contextual emb"
2020.lrec-1.302,L16-1147,0,0.0701355,"Missing"
2020.lrec-1.302,H93-1061,0,0.0518853,"rt of the Multilingual WSD task of SemEval 2013 (Navigli et al., 2013), which targets nouns only. We adapted the task to use the WordNet 3.0 sense inventory (Miller, 1995) instead of BabelNet (Navigli and Ponzetto, 2010), by converting the sense keys to WordNet 3.0 if a mapping exists in BabelNet, and removing them otherwise. The result of the conversion process is an evaluation corpus composed of 306 sentences and 1 445 French nouns annotated with WordNet sense keys, and manually verified. For the training data, we followed the method proposed by Hadj Salah (2018), and translated the SemCor (Miller et al., 1993) and the WordNet Gloss Corpus16 into French, using the best English-French Machine Translation system of the fairseq toolkit17 (Ott et al., 2019). Finally, we aligned the WordNet sense annotation from the source English words to the the translated French words, using the alignment provided by the MT system. We rely on WordNet sense keys instead of the original BabelNet annotations for the following two reasons. First, WordNet is a resource that is entirely manually verified, and widely used in WSD research (Navigli, 2009). Second, there is already a large quantity of sense annotated data based"
2020.lrec-1.302,P10-1023,0,0.0572014,"(04-20-2018) openly available via Dbnary (S´erasset, 2012). For a given sense of a target key, the sense inventory offers a definition along with one or more examples. For this task, we considered the examples of the sense inventory as training examples and tested our model on the evaluation dataset. Noun Sense Disambiguation We propose a new challenging task for the WSD of French, based on the French part of the Multilingual WSD task of SemEval 2013 (Navigli et al., 2013), which targets nouns only. We adapted the task to use the WordNet 3.0 sense inventory (Miller, 1995) instead of BabelNet (Navigli and Ponzetto, 2010), by converting the sense keys to WordNet 3.0 if a mapping exists in BabelNet, and removing them otherwise. The result of the conversion process is an evaluation corpus composed of 306 sentences and 1 445 French nouns annotated with WordNet sense keys, and manually verified. For the training data, we followed the method proposed by Hadj Salah (2018), and translated the SemCor (Miller et al., 1993) and the WordNet Gloss Corpus16 into French, using the best English-French Machine Translation system of the fairseq toolkit17 (Ott et al., 2019). Finally, we aligned the WordNet sense annotation from"
2020.lrec-1.302,S13-2040,0,0.0327036,"ated version to French provided in XNLI. Following Conneau et al. (2018), we report the test accuracy. 4.4. Parsing and Part-of-Speech Tagging Syntactic parsing consists in assigning a tree structure to a sentence in natural language. We perform parsing on the French Treebank (Abeill´e et al., 2003), a collection of sentences extracted from French daily newspaper Le Monde, and manually annotated with both constituency and dependency syntactic trees and part-of-speech tags. Specifically, we use the version of the corpus instantiated for the SPMRL 2013 shared task and described by Seddah et al. (2013). This version is provided with a standard split representing 14 759 sentences for the training corpus, and respectively 1 235 and 2 541 sentences for the development and evaluation sets. 4.5. Word Sense Disambiguation Tasks Word Sense Disambiguation (WSD) is a classification task which aims to predict the sense of words in a given context according to a specific sense inventory. We used two French WSD tasks: the FrenchSemEval task (Segonne et al., 2019), which targets verbs only, and a modified version of the French part of the Multilingual WSD task of SemEval 2013 (Navigli et al., 2013), whi"
2020.lrec-1.302,2020.findings-emnlp.92,0,0.0305509,"ls for other languages. For instance, ELMo exists for Portuguese, Japanese, German and Basque,5 while BERT and variants were specifically trained for simplified and traditional Chinese8 and German.6 A Portuguese version of MultiFiT is also available.7 Recently, more monolingual BERT-based models have been released, such as for Arabic (Antoun et al., 2020), Dutch (de Vries et al., 2019; Delobelle et al., 2020), Finnish (Virtanen et al., 2019), Italian (Polignano et al., 2019), Portuguese (Souza et al., 2019), Russian (Kuratov and Arkhipov, 2019), Spanish (Ca˜nete et al., 2020), and Vietnamese (Nguyen and Nguyen, 2020). For French, besides pre-trained language models using ULMFiT and MultiFiT configurations,7 CamemBERT (Martin et al., 2019) is a French BERT model concurrent to our work. Another trend considers one model estimated for several languages with a shared vocabulary. The release of multilingual BERT for 104 languages pioneered this approach.8 A recent extension of this work leverages parallel data to build a cross-lingual pre-trained version of LASER (Artetxe and Schwenk, 2019) for 93 languages, XLM (Lample and Conneau, 2019) and XLM-R (Conneau et al., 2019) for 100 languages. 2.3. Evaluation Prot"
2020.lrec-1.302,N19-4009,0,0.0205028,"nventory (Miller, 1995) instead of BabelNet (Navigli and Ponzetto, 2010), by converting the sense keys to WordNet 3.0 if a mapping exists in BabelNet, and removing them otherwise. The result of the conversion process is an evaluation corpus composed of 306 sentences and 1 445 French nouns annotated with WordNet sense keys, and manually verified. For the training data, we followed the method proposed by Hadj Salah (2018), and translated the SemCor (Miller et al., 1993) and the WordNet Gloss Corpus16 into French, using the best English-French Machine Translation system of the fairseq toolkit17 (Ott et al., 2019). Finally, we aligned the WordNet sense annotation from the source English words to the the translated French words, using the alignment provided by the MT system. We rely on WordNet sense keys instead of the original BabelNet annotations for the following two reasons. First, WordNet is a resource that is entirely manually verified, and widely used in WSD research (Navigli, 2009). Second, there is already a large quantity of sense annotated data based on the sense inventory of WordNet (Vial et al., 2018) that we can use for the training of our system. We publicly release18 both our training da"
2020.lrec-1.302,D14-1162,0,0.0923659,"ding Evaluation), are shared to the research community for further reproducible experiments in French NLP. Keywords: FlauBERT, FLUE, BERT, Transformer, French, language model, pre-training, NLP benchmark, text classification, parsing, word sense disambiguation, natural language inference, paraphrase. 1. Introduction A recent game-changing contribution in Natural Language Processing (NLP) was the introduction of deep unsupervised language representations pre-trained using only plain text corpora. Previous word embedding pre-training approaches, such as word2vec (Mikolov et al., 2013) or GloVe (Pennington et al., 2014), learn a single vector for each wordform. By contrast, these new models are trained to produce contextual embeddings: the output representation depends on the entire input sequence (e.g. each token instance has a vector representation that depends on its left and right context). Initially based on recurrent neural networks (Dai and Le, 2015; Ramachandran et al., 2017; Howard and Ruder, 2018; Peters et al., 2018), these models quickly converged towards the use of the Transformer (Vaswani et al., 2017), such as GPT (Radford et al., 2018), BERT (Devlin et al., 2019), XLNet (Yang et al., 2019b),"
2020.lrec-1.302,N18-1202,0,0.806323,"-grenoble-alpes.fr {vincent.segonne@etu, bcrabbe@linguist}.univ-paris-diderot.fr, alexandre.allauzen@espci.fr Abstract Language models have become a key step to achieve state-of-the art results in many different Natural Language Processing (NLP) tasks. Leveraging the huge amount of unlabeled texts nowadays available, they provide an efficient way to pre-train continuous word representations that can be fine-tuned for a downstream task, along with their contextualization at the sentence level. This has been widely demonstrated for English using contextualized representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al., 2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and share FlauBERT, a model learned on a very large and heterogeneous French corpus. Models of different sizes are trained using the new CNRS (French National Centre for Scientific Research) Jean Zay supercomputer. We apply our French language models to diverse NLP tasks (text classification, paraphrasing, natural language inference, parsing, word sense disambiguation) and show that most of the time they outperform other pre-training approaches. Different versions of FlauBERT a"
2020.lrec-1.302,P10-1114,0,0.0398144,"Missing"
2020.lrec-1.302,P18-2124,0,0.0233078,"f fine-tuning was shown to significantly boost the performance, and thus this approach has been further developed in the recent works such as MultiFiT (Eisenschlos et al., 2019) or most prominently Transformer-based (Vaswani et al., 2017) architectures: GPT (Radford et al., 2018), BERT (Devlin et al., 2019), XLNet (Yang et al., 2019b), XLM (Lample and Conneau, 2019), RoBERTa (Liu et al., 2019), ALBERT (Lan et al., 2019), T5 (Raffel et al., 2019). These methods have one after the other established new state-ofthe-art results on various NLP benchmarks, such as GLUE (Wang et al., 2018) or SQuAD (Rajpurkar et al., 2018), surpassing previous methods by a large margin. 2.2. Pre-trained Language Models Beyond English Given the impact of pre-trained language models on NLP downstream tasks in English, several works have recently released pre-trained models for other languages. For instance, ELMo exists for Portuguese, Japanese, German and Basque,5 while BERT and variants were specifically trained for simplified and traditional Chinese8 and German.6 A Portuguese version of MultiFiT is also available.7 Recently, more monolingual BERT-based models have been released, such as for Arabic (Antoun et al., 2020), Dutch ("
2020.lrec-1.302,D17-1039,0,0.213586,"uage Processing (NLP) was the introduction of deep unsupervised language representations pre-trained using only plain text corpora. Previous word embedding pre-training approaches, such as word2vec (Mikolov et al., 2013) or GloVe (Pennington et al., 2014), learn a single vector for each wordform. By contrast, these new models are trained to produce contextual embeddings: the output representation depends on the entire input sequence (e.g. each token instance has a vector representation that depends on its left and right context). Initially based on recurrent neural networks (Dai and Le, 2015; Ramachandran et al., 2017; Howard and Ruder, 2018; Peters et al., 2018), these models quickly converged towards the use of the Transformer (Vaswani et al., 2017), such as GPT (Radford et al., 2018), BERT (Devlin et al., 2019), XLNet (Yang et al., 2019b), RoBERTa (Liu et al., 2019). Using these pre-trained models in a transfer learning fashion has shown to yield striking improvements across a wide range of NLP tasks. One can easily build state-of-the-art NLP systems thanks to the publicly available pre-trained weights, saving time, energy, and resources. As a consequence, unsupervised language model pre-training has be"
2020.lrec-1.302,W13-4917,0,0.0460081,"Missing"
2020.lrec-1.302,W19-0422,1,0.895578,"Missing"
2020.lrec-1.302,P16-1162,0,0.0200296,"(attention) layers at each training step. Other techniques are also available such as progressive training (Gong et al., 2019), or improving initialization (Zhang et al., 2019a; Xu et al., 2019) and normalization (Nguyen and Salazar, 2019). For training FlauBERTLARGE , we employed pre-norm attention and stochastic depths for their simplicity. We found that these two techniques were sufficient for successful training. We set the rate of layer dropping to 0.2 in all the experiments. Other training details A vocabulary of 50K sub-word units is built using the Byte Pair Encoding (BPE) algorithm (Sennrich et al., 2016). The only difference between our work and RoBERTa is that the training data are preprocessed and tokenized using a basic tokenizer for French (Koehn et al., 2007, Moses), as in XLM (Lample and Conneau, 2019), before the application of BPE. We use fastBPE,15 a very efficient implementation to extract the BPE units and encode the corpora. 15 2481 https://github.com/glample/fastBPE FlauBERTBASE is trained on 32 GPUs Nvidia V100 in 410 hours and FlauBERTLARGE is trained on 128 GPUs in 390 hours, both with the effective batch size of 8192 sequences. Finally, we summarize the differences between Fl"
2020.lrec-1.302,serasset-2012-dbnary,0,0.036519,"Missing"
2020.lrec-1.302,skadins-etal-2014-billions,0,0.0456176,"Missing"
2020.lrec-1.302,tiedemann-2012-parallel,0,0.180846,"peline, the model architecture and training configurations to build FlauBERTBASE and FlauBERTLARGE . 3.1. Training Data Data collection Our French text corpus consists of 24 sub-corpora gathered from different sources, covering diverse topics and writing styles, ranging from formal and well-written text (e.g. Wikipedia and books)10 to random text crawled from the Internet (e.g. Common Crawl).11 The data were collected from three main sources: (1) monolingual data for French provided in WMT19 shared tasks (Li et al., 2019, 4 sub-corpora); (2) French text corpora offered in the OPUS collection (Tiedemann, 2012, 8 sub-corpora); and (3) datasets available in the Wikimedia projects (Meta, 2019, 8 sub-corpora). We used the WikiExtractor tool12 to extract the text from Wikipedia. For the other sub-corpora, we either used our 7 https://github.com/piegu/language-models https://github.com/google-research/bert 9 https://github.com/chineseGLUE/chineseGLUE 10 http://www.gutenberg.org 11 http://data.statmt.org/ngrams/deduped2017 12 https://github.com/attardi/wikiextractor 8 4 It should be noted that learning contextual embeddings was also proposed in (McCann et al., 2017), but in a supervised fashion as they u"
2020.lrec-1.302,W18-1819,0,0.025239,"RTLARGE : warmup steps of 30k, peak learning rate of 3e−4, β1 = 0.9, β2 = 0.98,  = 1e−6 and weight decay of 0.01. Training FlauBERTLARGE Training very deep Transformers is known to be susceptible to instability (Wang et al., 2019b; Nguyen and Salazar, 2019; Xu et al., 2019; Fan et al., 2019). Not surprisingly, we also observed this difficulty when training FlauBERTLARGE using the same configurations as BERTLARGE and RoBERTaLARGE , where divergence happened at an early stage. Several methods have been proposed to tackle this issue. For example, in an updated implementation of the Transformer (Vaswani et al., 2018), layer normalization is applied before each attention layer by default, rather than after each residual block as in the original implementation (Vaswani et al., 2017). These configurations are called pre-norm and post-norm, respectively. It was observed by Vaswani et al. (2018), and again confirmed by later works e.g. (Wang et al., 2019b; Xu et al., 2019; Nguyen and Salazar, 2019), that pre-norm helps stabilize training. Recently, a regularization technique called stochastic depths (Huang et al., 2016) has been demonstrated to be very effective for training deep Transformers, by e.g. Pham et"
2020.lrec-1.302,L18-1166,1,0.830909,"French, using the best English-French Machine Translation system of the fairseq toolkit17 (Ott et al., 2019). Finally, we aligned the WordNet sense annotation from the source English words to the the translated French words, using the alignment provided by the MT system. We rely on WordNet sense keys instead of the original BabelNet annotations for the following two reasons. First, WordNet is a resource that is entirely manually verified, and widely used in WSD research (Navigli, 2009). Second, there is already a large quantity of sense annotated data based on the sense inventory of WordNet (Vial et al., 2018) that we can use for the training of our system. We publicly release18 both our training data and the evaluation data in the UFSAC format (Vial et al., 2018). 5. Experiments and Results In this section, we present FlauBERT fine-tuning results on the FLUE benchmark. We compare the performance of FlauBERT with Multilingual BERT (Devlin et al., 2019, mBERT) and CamemBERT (Martin et al., 2019) on all tasks. In addition, for each task we also include the best non-BERT model for comparison. We made use of the open source libraries (Lample and Conneau, 2019, XLM) and (Wolf et al., 2019, Transformers)"
2020.lrec-1.302,2019.gwc-1.14,1,0.892947,"Missing"
2020.lrec-1.302,W18-5446,0,0.470157,"escribe our methodology to build FlauBERT – French Language Understanding via Bidirectional Encoder Representations from Transformers, a French BERT1 model that outperforms multilingual/cross-lingual models in several downstream NLP tasks, under similar configurations. FlauBERT relies on freely available datasets and is made publicly available in different versions.2 For further reproducible experiments, we also provide the complete processing and training pipeline as well as a general benchmark for evaluating French NLP systems. This evaluation setup is similar to the popular GLUE benchmark (Wang et al., 2018), and is named FLUE (French Language Understanding Evaluation). 2. 2.1. Related Work Pre-trained Language Models Self-supervised3 pre-training on unlabeled text data was first proposed in the task of neural language modeling (Bengio et al., 2003; Collobert and Weston, 2008), where it was shown that a neural network trained to predict next word from prior words can learn useful embedding representations, called word embeddings (each word is represented by a fixed vector). These representations were shown to play an important role in NLP, yielding state-of-the-art performance on multiple tasks ("
2020.lrec-1.302,P19-1176,0,0.104394,"2019) and XLM-R (Conneau et al., 2019) for 100 languages. 2.3. Evaluation Protocol for French NLP Tasks The existence of a multi-task evaluation benchmark such as GLUE (Wang et al., 2018) for English is highly beneficial to facilitate research in the language of interest. The GLUE benchmark has become a prominent framework to evaluate the performance of NLP models in English. The recent contributions based on pre-trained language models have led to remarkable performance across a wide range of Natural Language Understanding (NLU) tasks. The authors of GLUE have therefore introduced SuperGLUE (Wang et al., 2019a): a new benchmark built on the principles of GLUE, including more challenging and diverse set of tasks. A Chinese version of GLUE9 is also developed to evaluate model performance in Chinese NLP tasks. As of now, we have not learned of any such benchmark for French. 3. Building FlauBERT In this section, we describe the training corpus, the text preprocessing pipeline, the model architecture and training configurations to build FlauBERTBASE and FlauBERTLARGE . 3.1. Training Data Data collection Our French text corpus consists of 24 sub-corpora gathered from different sources, covering diverse"
2020.lrec-1.302,N18-1101,0,0.0161936,"ot. Similar to previous approaches to create multilingual corpora, Yang et al. (2019a) used machine translation to create the training set for each target language in PAWS-X from the English training set in PAWS. The development and test sets for each language are translated by human translators. We take the related datasets for French to perform the paraphrasing task and report the accuracy on the test set. 4.3. Natural Language Inference XNLI The Cross-lingual NLI (XNLI) corpus (Conneau et al., 2018) extends the development and test sets of the Multi-Genre Natural Language Inference corpus (Williams et al., 2018, MultiNLI) to 15 languages. The development and test sets for each language consist of 7 500 humanannotated examples, making up a total of 112 500 sentence pairs annotated with the labels entailment, contradiction, or neutral. Each sentence pair includes a premise (p) and a hypothesis (h). The Natural Language Inference (NLI) task, also known as recognizing textual entailment (RTE), is to determine whether p entails, contradicts or neither entails nor contradicts h. We take the French part of the XNLI corpus to form the development and test sets for the NLI task in FLUE. The train set is obta"
2020.lrec-1.302,D19-1382,0,0.0391611,"Missing"
2020.lrec-1.302,N19-1131,0,0.100143,"firmed by later works e.g. (Wang et al., 2019b; Xu et al., 2019; Nguyen and Salazar, 2019), that pre-norm helps stabilize training. Recently, a regularization technique called stochastic depths (Huang et al., 2016) has been demonstrated to be very effective for training deep Transformers, by e.g. Pham et al. (2019) and Fan et al. (2019) who successfully trained architectures of more than 40 layers. The idea is to randomly drop a number of (attention) layers at each training step. Other techniques are also available such as progressive training (Gong et al., 2019), or improving initialization (Zhang et al., 2019a; Xu et al., 2019) and normalization (Nguyen and Salazar, 2019). For training FlauBERTLARGE , we employed pre-norm attention and stochastic depths for their simplicity. We found that these two techniques were sufficient for successful training. We set the rate of layer dropping to 0.2 in all the experiments. Other training details A vocabulary of 50K sub-word units is built using the Byte Pair Encoding (BPE) algorithm (Sennrich et al., 2016). The only difference between our work and RoBERTa is that the training data are preprocessed and tokenized using a basic tokenizer for French (Koehn et a"
2020.lrec-1.724,S14-1001,0,0.026174,"rained lexical distinctions, its hierarchical organization has been seen as different levels of semantic granularity. The top level of WordNet ontology, namely the “Unique Beginners” (UBs) have been taken as coarse-grained categories for both manual and automatic annotation, which has been proved to limit the difficulty of making fine-grained sense distinctions (Palmer et al., 2007; Navigli, 2006; Navigli, 2009). First used by Ciaramita and Johnson (2003) and Ciaramita and Altun (2006) as ”supersenses”, WordNet UBs are adopted in a growing number of studies devoted to coarse semantic tagging (Johannsen et al., 2014; Flekova and Gurevych, 2016). For semantic annotation projects based on WordNet UBs1 , the corpus may or may not be pre-tagged with UBs, depending on whether or not a WordNet lexicon is available with sufficient coverage for the target language. Pretagging was used for instance for Danish in the SemDax project (Pederson et al., 2016), but not used for Arabic in (Schneider et al., 2012)2 . French has a freely availaible Wordnet1 2 See Petrolito and Bond (2014) for an overview. Note that in the former case, UBs are generalizations over like resource, the Wolf, that has been automatically built"
2020.lrec-1.724,2016.gwc-1.30,0,0.0238749,"lso removed the Motive and Shape UBs. The former has 3 All other annotation projects using UBs as tags we know of also had to make adjustments, but to a more limited extent. In Schneider et al. (2012), extended definitions of WordNet UBs are proposed, illustrated by English examples, along with rule decisions such as “all man-made structures (buildings, rooms, bridges, etc.) are to be tagged as Artifact”. Pederson et al. (2016) extend the WordNet UB set by including more specific classes. For instance, they use Vehicle, Building and Container as subclasses of the Artifact supersense (Martinez Alonso et al., 2016). In both projects though, the definition and lexical scope of WordNet UBs are preserved. already been described as problematic in previous supersense annotation projects, and concerns very few words in WordNet. Shape was excluded because of its heterogeneity and fuzzy boundaries, and because its members could be easily dispatched in other existing categories, such as Artifact and Cognition. Novel classes Two supersenses absent from the WordNet inventory were used in the annotation. First, we adopted the Institution tag proposed in the SemDax corpus (Pederson et al., 2016), except that we used"
2020.lrec-1.724,P06-1014,0,0.0641723,"notated corpus of English, occurrences of a word are associated with a predefined list of senses (represented by synsets) from the Princeton WordNet (Miller et al., 1990). WordNet being known to include very fine-grained lexical distinctions, its hierarchical organization has been seen as different levels of semantic granularity. The top level of WordNet ontology, namely the “Unique Beginners” (UBs) have been taken as coarse-grained categories for both manual and automatic annotation, which has been proved to limit the difficulty of making fine-grained sense distinctions (Palmer et al., 2007; Navigli, 2006; Navigli, 2009). First used by Ciaramita and Johnson (2003) and Ciaramita and Altun (2006) as ”supersenses”, WordNet UBs are adopted in a growing number of studies devoted to coarse semantic tagging (Johannsen et al., 2014; Flekova and Gurevych, 2016). For semantic annotation projects based on WordNet UBs1 , the corpus may or may not be pre-tagged with UBs, depending on whether or not a WordNet lexicon is available with sufficient coverage for the target language. Pretagging was used for instance for Danish in the SemDax project (Pederson et al., 2016), but not used for Arabic in (Schneider e"
2020.lrec-1.724,L16-1136,0,0.094348,"-grained sense distinctions (Palmer et al., 2007; Navigli, 2006; Navigli, 2009). First used by Ciaramita and Johnson (2003) and Ciaramita and Altun (2006) as ”supersenses”, WordNet UBs are adopted in a growing number of studies devoted to coarse semantic tagging (Johannsen et al., 2014; Flekova and Gurevych, 2016). For semantic annotation projects based on WordNet UBs1 , the corpus may or may not be pre-tagged with UBs, depending on whether or not a WordNet lexicon is available with sufficient coverage for the target language. Pretagging was used for instance for Danish in the SemDax project (Pederson et al., 2016), but not used for Arabic in (Schneider et al., 2012)2 . French has a freely availaible Wordnet1 2 See Petrolito and Bond (2014) for an overview. Note that in the former case, UBs are generalizations over like resource, the Wolf, that has been automatically built from the Princeton WordNet and other resources, using translation techniques (Sagot and Fiˇser, 2008). We decided not to use it to pre-tag the corpus we annotated, because the Wolf has only been very partly manually validated and the gain of noisy data for speeding up annotation process is not obvious. Instead, following (Schneider et"
2020.lrec-1.724,W14-0132,0,0.0661046,"Missing"
2020.lrec-1.724,P12-2050,0,0.203838,"vigli, 2006; Navigli, 2009). First used by Ciaramita and Johnson (2003) and Ciaramita and Altun (2006) as ”supersenses”, WordNet UBs are adopted in a growing number of studies devoted to coarse semantic tagging (Johannsen et al., 2014; Flekova and Gurevych, 2016). For semantic annotation projects based on WordNet UBs1 , the corpus may or may not be pre-tagged with UBs, depending on whether or not a WordNet lexicon is available with sufficient coverage for the target language. Pretagging was used for instance for Danish in the SemDax project (Pederson et al., 2016), but not used for Arabic in (Schneider et al., 2012)2 . French has a freely availaible Wordnet1 2 See Petrolito and Bond (2014) for an overview. Note that in the former case, UBs are generalizations over like resource, the Wolf, that has been automatically built from the Princeton WordNet and other resources, using translation techniques (Sagot and Fiˇser, 2008). We decided not to use it to pre-tag the corpus we annotated, because the Wolf has only been very partly manually validated and the gain of noisy data for speeding up annotation process is not obvious. Instead, following (Schneider et al., 2012), we used UBs as lexicon-independent seman"
2020.lrec-1.724,W19-0422,1,0.798055,"Missing"
2021.acl-srw.23,P19-1356,0,0.02882,"al., 2019). Yet the role of this over-parametrization is not well understood. In particular, transformers consist of a fixed number of stacked layers, which are suspected to be highly redundant (Liu et al., 2020) and to cause over-fitting (Fan et al., 2020; Zhou et al., 2020). In this paper we provide a study on the role of the multiple layers traditionally used. The mechanism of transformer layers is often compared to intuitive NLP pipelines (Tenney et al., 2019). Starting with the lower layers encoding surface information, middle layers encoding syntax and higher layers encoding semantics (Jawahar et al., 2019; Peters et al., 2018). Transformers progressively refine the features, which become more fine-grained at each iteration (Xin et al., 2020). However, A LBERT (Lan et al., 2020) highlights that it is possible to tie weights across layers and repeat the application of the same function. Consequently, we hypothesize that it is the number Related Work Adapting the transformer depth is an active subject of research. In particular, deep transformer models are suspected to struggle to adapt to different levels of difficulty. While large models correctly predict difficult examples, they over-calculate"
2021.acl-srw.23,P19-1580,0,0.0235753,"the stack of encoder layers iteratively repeats the application of the same transformation function on the input. We interpret the repetition of this application as an iterative process where the token contextualized representations are progressively refined. We analyze this process at the token level during pretraining, fine-tuning, and inference. We show that tokens do not require the same amount of iterations and that difficult or crucial tokens for the task are subject to more iterations. 1 Introduction 2 Transformers are admittedly over-parametrized (Chen et al., 2020; Hou et al., 2020; Voita et al., 2019). Yet the role of this over-parametrization is not well understood. In particular, transformers consist of a fixed number of stacked layers, which are suspected to be highly redundant (Liu et al., 2020) and to cause over-fitting (Fan et al., 2020; Zhou et al., 2020). In this paper we provide a study on the role of the multiple layers traditionally used. The mechanism of transformer layers is often compared to intuitive NLP pipelines (Tenney et al., 2019). Starting with the lower layers encoding surface information, middle layers encoding syntax and higher layers encoding semantics (Jawahar et"
2021.acl-srw.23,2020.acl-main.204,0,0.0210705,"d layers, which are suspected to be highly redundant (Liu et al., 2020) and to cause over-fitting (Fan et al., 2020; Zhou et al., 2020). In this paper we provide a study on the role of the multiple layers traditionally used. The mechanism of transformer layers is often compared to intuitive NLP pipelines (Tenney et al., 2019). Starting with the lower layers encoding surface information, middle layers encoding syntax and higher layers encoding semantics (Jawahar et al., 2019; Peters et al., 2018). Transformers progressively refine the features, which become more fine-grained at each iteration (Xin et al., 2020). However, A LBERT (Lan et al., 2020) highlights that it is possible to tie weights across layers and repeat the application of the same function. Consequently, we hypothesize that it is the number Related Work Adapting the transformer depth is an active subject of research. In particular, deep transformer models are suspected to struggle to adapt to different levels of difficulty. While large models correctly predict difficult examples, they over-calculate simpler inputs (Liu et al., 2020). This issue can be addressed using early-stopping: some samples might be sufficiently simple to classify"
2021.eacl-srw.11,W19-4308,0,0.0437282,"Missing"
2021.eacl-srw.11,S13-1005,0,0.0674134,"Missing"
2021.eacl-srw.11,P19-1442,0,0.128619,"l et al., 2016), discriminating context sentences (Logeswaran and Lee, 2018), predicting specific relations between pairs of sentences (Conneau et al., 2017; Nie et al., 2019). While all these methods propose efficient train71 Proceedings of the 16th Conference of the European Chapter of the Associationfor Computational Linguistics: Student Research Workshop, pages 71–79 April 19 - 23, 2021. ©2021 Association for Computational Linguistics tions. Kong and Zhou (2011) provide a heuristic to combine dependency and constituency analysis for coreference resolution. Zhou et al. (2016); Ahmed et al. (2019) combine Tree LSTM and standard sequential LSTM with a cross-attention method and observe improvements on a semantic textual similarity task. Chen et al. (2017a) combine CNN and Tree LSTM using attention methods and outperform both models taken separately on a sentiment classification task. Finally, Chen et al. (2017b) combine sequential LSTM and Tree LSTM for natural language inference tasks. The novelty here is to combine distinct structured models to build standalone sentence embeddings, which has not yet been explored. This paradigm benefits from several structural advantages. It pairs nic"
2021.eacl-srw.11,N16-1162,0,0.417763,"ros et al., 2015; Hill et al., 2016), discriminating context sentences (Logeswaran and Lee, 2018), predicting specific relations between pairs of sentences (Conneau et al., 2017; Nie et al., 2019). While all these methods propose efficient train71 Proceedings of the 16th Conference of the European Chapter of the Associationfor Computational Linguistics: Student Research Workshop, pages 71–79 April 19 - 23, 2021. ©2021 Association for Computational Linguistics tions. Kong and Zhou (2011) provide a heuristic to combine dependency and constituency analysis for coreference resolution. Zhou et al. (2016); Ahmed et al. (2019) combine Tree LSTM and standard sequential LSTM with a cross-attention method and observe improvements on a semantic textual similarity task. Chen et al. (2017a) combine CNN and Tree LSTM using attention methods and outperform both models taken separately on a sentiment classification task. Finally, Chen et al. (2017b) combine sequential LSTM and Tree LSTM for natural language inference tasks. The novelty here is to combine distinct structured models to build standalone sentence embeddings, which has not yet been explored. This paradigm benefits from several structural adv"
2021.eacl-srw.11,D14-1162,0,0.0987327,"Missing"
2021.eacl-srw.11,P18-1249,0,0.0226754,"dings with pk = W (p) hk + b(p) (2) qj · p|k kqj k2 · kpk k2 (3) αkj = softmaxk (a1j · · · anj ) (4) akj = The embedding at the root of the tree is used as the sentence embedding as the Tree LSTM model computes representations bottom up. Constituency tree (C ONST) Constituent analysis describes the sentence as a nested multi-word 73 3.2 structure. In this framework, words are grouped recursively in constituents. In the resulting tree, only leaf nodes correspond to words, while internal nodes encode recursively word sequences. The structure is obtained using the constituency neural parser from Kitaev and Klein (2018). The framework is associated with the N-Ary Tree LSTM, which is defined in Tai et al. (2015). Similarly to the original article, we binarize the trees to ensure that every node has exactly two dependents. The binarization is performed using a left markovization and unary productions are collapsed in a single node. Again the representation is computed bottomup and the embedding of the tree root node is used as sentence embedding. The equations detailed in Tai et al. (2015) make the distinction between right and left nodes. Therefore we do not propose to enhance the original architecture with a"
2021.eacl-srw.11,D19-1410,0,0.0847379,"relationship between a pair of sentences. The third section reports pre-trained transformers based-models. The last section reports the results from our models. FastSent is reported from Hill et al. (2016). Skipthoughts results from Kiros et al. (2015) Skipthoughts + LN which includes layer normalization method from Ba et al. (2016). We considered the Quickthoughts results (Logeswaran and Lee, 2018) with a pre-training on the bookcorpus dataset. DisSent and Infersent are reported from Nie et al. (2019) and Conneau et al. (2017) respectively. Pre-trained transformers results are reported from Reimers and Gurevych (2019). The Hrs column indicates indicative training time, the Dim column corresponds to the sentence embedding dimension. † indicates models that we had to re-train. Best results in each section are shown in bold, best results overall are underlined. Performance for SICK-R results are reported by convention as ρ and r × 100. 3.3 Results analysis view (S EQ, S EQ) used in Quick-Thought model. It seems that the entanglement of views benefits the sentence embedding properties. In particular, we obtain state-of-the-art results for almost every metric from MRPC and SICK-R tasks, which focus on paraphras"
2021.eacl-srw.11,Y11-1043,0,0.0296239,"sentence embeddings remains an open problem. Many training methods have been explored: generating past and previous sentences (Kiros et al., 2015; Hill et al., 2016), discriminating context sentences (Logeswaran and Lee, 2018), predicting specific relations between pairs of sentences (Conneau et al., 2017; Nie et al., 2019). While all these methods propose efficient train71 Proceedings of the 16th Conference of the European Chapter of the Associationfor Computational Linguistics: Student Research Workshop, pages 71–79 April 19 - 23, 2021. ©2021 Association for Computational Linguistics tions. Kong and Zhou (2011) provide a heuristic to combine dependency and constituency analysis for coreference resolution. Zhou et al. (2016); Ahmed et al. (2019) combine Tree LSTM and standard sequential LSTM with a cross-attention method and observe improvements on a semantic textual similarity task. Chen et al. (2017a) combine CNN and Tree LSTM using attention methods and outperform both models taken separately on a sentiment classification task. Finally, Chen et al. (2017b) combine sequential LSTM and Tree LSTM for natural language inference tasks. The novelty here is to combine distinct structured models to build"
2021.eacl-srw.11,P15-1150,0,0.15667,"Missing"
2021.eacl-srw.11,C16-1274,0,0.123659,"entences (Kiros et al., 2015; Hill et al., 2016), discriminating context sentences (Logeswaran and Lee, 2018), predicting specific relations between pairs of sentences (Conneau et al., 2017; Nie et al., 2019). While all these methods propose efficient train71 Proceedings of the 16th Conference of the European Chapter of the Associationfor Computational Linguistics: Student Research Workshop, pages 71–79 April 19 - 23, 2021. ©2021 Association for Computational Linguistics tions. Kong and Zhou (2011) provide a heuristic to combine dependency and constituency analysis for coreference resolution. Zhou et al. (2016); Ahmed et al. (2019) combine Tree LSTM and standard sequential LSTM with a cross-attention method and observe improvements on a semantic textual similarity task. Chen et al. (2017a) combine CNN and Tree LSTM using attention methods and outperform both models taken separately on a sentiment classification task. Finally, Chen et al. (2017b) combine sequential LSTM and Tree LSTM for natural language inference tasks. The novelty here is to combine distinct structured models to build standalone sentence embeddings, which has not yet been explored. This paradigm benefits from several structural adv"
2021.emnlp-main.377,2021.eacl-main.269,1,0.7122,"ncode syntactic information by observing that neural language models are able to predict the agreement between a verb and its subject. We take a critical look at this line of research by showing that it is possible to achieve high accuracy on this agreement task with simple surface heuristics, indicating a possible flaw in our assessment of neural networks’ syntactic ability. Our fine-grained analyses of results on the long-range French objectverb agreement show that contrary to LSTMs, Transformers are able to capture a non-trivial amount of grammatical structure. 1 Introduction Chaves, 2020; Li and Wisniewski, 2021). Overall, this set of results questions one of the most fundamental assumption in linguistics (Lakretz et al., 2021), namely that a sentence has a recursive structure (Everaert et al., 2015): while LSTMs with proper parametrization can model context-free patterns (Suzgun et al., 2019), Transformers are essentially feed forward models relying on a large number of attention heads. Consequently, they are, in theory, not adapted to model hierarchical syntactic patterns (Hahn, 2020) and explaining their capacity to predict accurately syntactic agreement patterns remains an open issue. We bring new"
2021.emnlp-main.377,Q16-1037,0,0.0179728,"y predict verbal agreement, pushing further the observation of Kuncoro et al. (2018) that a simple rule can provide highly accurate results on the task. Using our extended set of heuristics, we identify sentences for which predicting the correct verb form requires a more abstract representation of the sentence. By comparing models’ performance on these examples, we show that contrary to LSTMs, Transformers perform consistently well in these critical cases. The long distance agreement task is one of the most popular method to assess neural networks (NN) ability to encode syntactic information: Linzen et al. (2016) showed that LSTMs are able to predict the subject-verb agreement in English and has initiated a very active line of research. Since then, many studies have generalized this observation to other languages (Gulordava et al., 2018), other models such as Transformers (Goldberg, 2019; Jawahar 2 Test Set for French Object et al., 2019) or have identified possible confoundPast-Participle Agreement1 ing factors that could distort the stated conclusions (Gulordava et al., 2018; Marvin and Linzen, 2018). We focus on the object-verb agreement (i.e. object All of these studies show that NN are able to le"
2021.emnlp-main.377,D18-1151,0,0.0226438,"s one of the most popular method to assess neural networks (NN) ability to encode syntactic information: Linzen et al. (2016) showed that LSTMs are able to predict the subject-verb agreement in English and has initiated a very active line of research. Since then, many studies have generalized this observation to other languages (Gulordava et al., 2018), other models such as Transformers (Goldberg, 2019; Jawahar 2 Test Set for French Object et al., 2019) or have identified possible confoundPast-Participle Agreement1 ing factors that could distort the stated conclusions (Gulordava et al., 2018; Marvin and Linzen, 2018). We focus on the object-verb agreement (i.e. object All of these studies show that NN are able to learn past-participle agreement) in French: agreement in a ‘substantial amount’ of syntactic information (Be- number and gender occurs between the object and linkov and Glass, 2019). the past participle when the latter is used with the In this work, we propose to take an alterna- auxiliary avoir (to have) and the object is located tive look at these results by studying whether neu- before the verb. As shown in Figure 1, this is, ral networks are able to predict the correct form for instance, the"
2021.jeptalnrecital-taln.24,P18-1082,0,0.060851,"Missing"
2021.jeptalnrecital-taln.24,P07-2045,0,0.00923232,"Missing"
2021.jeptalnrecital-taln.24,D19-1051,0,0.0594263,"Missing"
2021.jeptalnrecital-taln.24,2020.jeptalnrecital-taln.26,1,0.858325,"Missing"
2021.jeptalnrecital-taln.24,2020.lrec-1.302,1,0.852217,"Missing"
2021.jeptalnrecital-taln.24,W19-5303,0,0.0236089,"Missing"
2021.jeptalnrecital-taln.24,W04-1013,0,0.0206503,"Missing"
2021.jeptalnrecital-taln.24,2020.acl-main.645,0,0.0757349,"Missing"
2021.jeptalnrecital-taln.24,P16-1162,0,0.105926,"Missing"
2021.jeptalnrecital-taln.24,tiedemann-2012-parallel,0,0.0189874,"Missing"
2021.jeptalnrecital-taln.9,Q17-1010,0,0.109942,"Missing"
2021.jeptalnrecital-taln.9,F12-2024,0,0.0560287,"Missing"
2021.jeptalnrecital-taln.9,W13-4905,0,0.0546588,"Missing"
2021.jeptalnrecital-taln.9,N19-1423,0,0.0603831,"Missing"
2021.jeptalnrecital-taln.9,lacheret-etal-2014-rhapsodie,0,0.0229571,"Missing"
2021.jeptalnrecital-taln.9,2020.lrec-1.302,1,0.844242,"Missing"
2021.jeptalnrecital-taln.9,2020.acl-main.645,0,0.0866306,"Missing"
2021.jeptalnrecital-taln.9,W17-0411,0,0.0228572,"Missing"
2021.jeptalnrecital-taln.9,2020.acl-demos.14,0,0.0226388,"Missing"
2021.jeptalnrecital-taln.9,W13-4917,0,0.0469866,"Missing"
2021.jeptalnrecital-taln.9,2020.emnlp-demos.6,0,0.0478542,"Missing"
C14-1052,P05-1038,0,0.0611844,"Missing"
C14-1052,P11-1045,0,0.0167861,"++ + + + ++ ++ + ++ + + ++ ++ + + + + + + + ++ ++ ++ + + ++ ++ + ++ ++ +++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ + ++ + ++ ++ ++ ++++ ++ ++ ++ + ++ ++ +++ ++ + ++ +++ ++ + ++ + ++ + + + + ++ ++ + ++ + + ++ + +++ ++ ++ ++++ + ++ ++ ++ +++ ++ ++ ++ ++ ++ ++ ++ ++ ++ +++ ++ ++ +++ + + ++ +++ ++ + ++ ++ ++ ++++++ ++ ++ ++ ++ + ++ + ++ ++ ++ ++++ 0 20 40 60 80 100 + + + + 120 + + 140 Longueur Figure 8: Parsing times We finally observe on English that the LR strategy performs reasonably accurately and faster than the implementation of (Petrov et al., 2006) whereas optimisations of PCFG-LA described by (Bodenstab et al., 2011) are significantly less accurate and not significantly faster. Although it is currently hard to to compare directly on French with the most similar proposal, the Chinese/English parser described by (Zhu et al., 2013), since it does not handle morphology. With respects to speed, their impressive result on English suggests that there is still room for speed improvements without loss of accurracy. 7 Conclusion To our knowledge, this is the first formulation of a discriminative LR-automaton driven parser for natural language. This LR inspired algorithm shares many properties with shift reduce pars"
C14-1052,Q13-1034,0,0.0469682,"Missing"
C14-1052,J93-1002,0,0.437241,"ing 2C FG grammar with respects to temporary symbols. This being said, building an LR(0) automaton for robust treebank grammars raise two issues. The first is inductive, a grammar read off from a treebank is not guaranteed to be robust and to generalize to other text, since a treebank remains a finite sample of language. The second is practical : traditional LR(0) compilation methods involve the determinisation of 542 the LR NFA which is exponential in the number n of states of this NFA. In case of very large ambiguous treebank grammars n is very large and the compilation becomes intractable (Briscoe and Carroll, 1993). These two observations lead us to design this automata by the following construction. First, let Σ be the set of non terminal symbols read off from the treebank, T be the set of temporaries introduced by binarization and N the set of non temporary symbols such that Σ = N ∪ T and N ∩ T = ∅. Second we note W the set of terminal symbols extracted from the treebank and A ∈ N the unique axiom of this grammar. We then partition Σ with the following set of equivalence classes: [a] = {A}, [t] = T and [n] = Σ − (T ∪ A). For convenience we also note [w] = W . Given these equivalence classes, we define"
C14-1052,A00-2018,0,0.705219,"o efficiency issues (Turian and Melamed, 2006; Finkel et al., 2008), we use here several approximations that make the framework not only tractable but also efficient and accurate on a lexically rich language such as French. Despite the successes of dependency grammar, we are interested in phrase structure grammar since it naturally allows to support compositional semantic representations as recently highlighted by (Socher et al., 2012). It remains that most phrase structure parsers have been designed in priority for modelling lexically poor languages such as English or Chinese (Collins, 2003; Charniak, 2000; Zhu et al., 2013). Although highly accurate multilingual parsers exist (Petrov et al., 2006), they remain relatively both slow for wide coverage purposes and their inner formal structure is not designed to handle naturally morphological information. We assume that parsing lexically rich languages benefits from taking into account the structured morphological information that can be extracted from lexical forms. Using French as a case study we show that we can reach both parsing efficiency with an approximative inference method and we can get a state of the art accurracy by generalizing lexic"
C14-1052,W02-1001,0,0.699117,"2), we show that this representation allows us to achieve state of the art accurracy results on a morphologically rich language such as French while achieving more efficient parsing times than the state of the art parsers on the French data set. A comparison with English, a lexically poor language, is also provided. 1 Introduction The paper provides a phrase structure parsing algorithm inspired by LR (Knuth, 1965), GLR (Tomita, 1988) and the recent developments of (Huang and Sagae, 2010) for dependency grammar. The parsing algorithm comes with a discriminative weighting framework inspired by (Collins, 2002). Although discriminative phrase structure parsing has been shown to be challenging when it comes to efficiency issues (Turian and Melamed, 2006; Finkel et al., 2008), we use here several approximations that make the framework not only tractable but also efficient and accurate on a lexically rich language such as French. Despite the successes of dependency grammar, we are interested in phrase structure grammar since it naturally allows to support compositional semantic representations as recently highlighted by (Socher et al., 2012). It remains that most phrase structure parsers have been desi"
C14-1052,J03-4003,0,0.56443,"when it comes to efficiency issues (Turian and Melamed, 2006; Finkel et al., 2008), we use here several approximations that make the framework not only tractable but also efficient and accurate on a lexically rich language such as French. Despite the successes of dependency grammar, we are interested in phrase structure grammar since it naturally allows to support compositional semantic representations as recently highlighted by (Socher et al., 2012). It remains that most phrase structure parsers have been designed in priority for modelling lexically poor languages such as English or Chinese (Collins, 2003; Charniak, 2000; Zhu et al., 2013). Although highly accurate multilingual parsers exist (Petrov et al., 2006), they remain relatively both slow for wide coverage purposes and their inner formal structure is not designed to handle naturally morphological information. We assume that parsing lexically rich languages benefits from taking into account the structured morphological information that can be extracted from lexical forms. Using French as a case study we show that we can reach both parsing efficiency with an approximative inference method and we can get a state of the art accurracy by ge"
C14-1052,de-marneffe-etal-2006-generating,0,0.153388,"Missing"
C14-1052,P08-1109,0,0.028432,"ore efficient parsing times than the state of the art parsers on the French data set. A comparison with English, a lexically poor language, is also provided. 1 Introduction The paper provides a phrase structure parsing algorithm inspired by LR (Knuth, 1965), GLR (Tomita, 1988) and the recent developments of (Huang and Sagae, 2010) for dependency grammar. The parsing algorithm comes with a discriminative weighting framework inspired by (Collins, 2002). Although discriminative phrase structure parsing has been shown to be challenging when it comes to efficiency issues (Turian and Melamed, 2006; Finkel et al., 2008), we use here several approximations that make the framework not only tractable but also efficient and accurate on a lexically rich language such as French. Despite the successes of dependency grammar, we are interested in phrase structure grammar since it naturally allows to support compositional semantic representations as recently highlighted by (Socher et al., 2012). It remains that most phrase structure parsers have been designed in priority for modelling lexically poor languages such as English or Chinese (Collins, 2003; Charniak, 2000; Zhu et al., 2013). Although highly accurate multili"
C14-1052,P12-1110,0,0.0426065,"Missing"
C14-1052,N12-1032,0,0.030125,"mmar should be used with a more robust search strategy than simple beam search. Experiment 4 In experiment 4, we observe that max violation update converges twice as fast as early update but we experienced more overfitting problems explaining the lower scores. It is however harder to achieve fair comparisons since the number of iterations is significantly different. Experiment 5 This last experiment is probably the most significative. We observe that morphology is the variable that allows the parser to improve significantly on French (dev F=81.79). This result thus confirms those observed by (Hohensee and Bender, 2012) on several languages for dependency parsing, yet we had to isolate agreement, refined subcategories and verbal mood to get significant improvements (Figure 6). Final tests In order to compare this proposal with current state of the art parsers, we provide comparative measures of speed and accurracy with the Berkeley parser (Petrov et al., 2006), known to be representative of the state of the art in accurracy and in speed on French and in accurracy on English (Table 3). French Test (gold tags) K=8 Berkeley French Test (predicted tags) K=8 Berkeley French test (raw text) Berkeley English test ("
C14-1052,P10-1110,0,0.366629,"03) by allowing a structured representation of the lexical items. Together with a discriminative weighting component (Collins, 2002), we show that this representation allows us to achieve state of the art accurracy results on a morphologically rich language such as French while achieving more efficient parsing times than the state of the art parsers on the French data set. A comparison with English, a lexically poor language, is also provided. 1 Introduction The paper provides a phrase structure parsing algorithm inspired by LR (Knuth, 1965), GLR (Tomita, 1988) and the recent developments of (Huang and Sagae, 2010) for dependency grammar. The parsing algorithm comes with a discriminative weighting framework inspired by (Collins, 2002). Although discriminative phrase structure parsing has been shown to be challenging when it comes to efficiency issues (Turian and Melamed, 2006; Finkel et al., 2008), we use here several approximations that make the framework not only tractable but also efficient and accurate on a lexically rich language such as French. Despite the successes of dependency grammar, we are interested in phrase structure grammar since it naturally allows to support compositional semantic repr"
C14-1052,N12-1015,0,0.0369864,"G ENK (T )) W (C0⇒k ) where ∆(G ENk−1 (T )) = k−1 S δ(C0⇒k−1 ), Using a beam aims to reduce complexity to O(K|A|(3n − 1)) ≈ O(n) C0⇒k−1 ∈G ENK (T ) k−1 and makes inference computationally tractable in practice. On the other hand it makes inference incomplete (the parser may fail to find a solution even if it exists) and does not guarantee the solution to be optimal. In other words, Equation 1 is replaced by an approximation: C˜ = argmax C0⇒3n−1 ∈G ENK 3n−1 (T ) W (C0⇒3n−1 ) (2) The weight estimation procedure is performed by the averaged percetron algorithm (Collins, 2002). As pointed out by (Huang et al., 2012) using a beam introduces an approximation that can also harm the convergence of the learning procedure since we provide at each training iteration the approximative solution given by equation 2 instead of the exact solution to equation 1 expected in theory by the perceptron algorithm. To overcome the problem we perform updates on subderivation sequences. (r) (0) Let C0⇒k be a subderivation sequence at step k and let C0⇒k = argmaxC0⇒k ∈G ENK (T ) W (C0⇒k ) k be the best subderivation in the beam at step k. In this context the perceptron update has the form: (r) (0) w ← w + Φg (C0⇒k ) − Φg (C0⇒k"
C14-1052,P06-1055,0,0.516158,"approximations that make the framework not only tractable but also efficient and accurate on a lexically rich language such as French. Despite the successes of dependency grammar, we are interested in phrase structure grammar since it naturally allows to support compositional semantic representations as recently highlighted by (Socher et al., 2012). It remains that most phrase structure parsers have been designed in priority for modelling lexically poor languages such as English or Chinese (Collins, 2003; Charniak, 2000; Zhu et al., 2013). Although highly accurate multilingual parsers exist (Petrov et al., 2006), they remain relatively both slow for wide coverage purposes and their inner formal structure is not designed to handle naturally morphological information. We assume that parsing lexically rich languages benefits from taking into account the structured morphological information that can be extracted from lexical forms. Using French as a case study we show that we can reach both parsing efficiency with an approximative inference method and we can get a state of the art accurracy by generalizing lexicalized parsing to handle feature structure-based word representations. Our proposal also diffe"
C14-1052,P06-2089,0,0.655468,"or wide coverage purposes and their inner formal structure is not designed to handle naturally morphological information. We assume that parsing lexically rich languages benefits from taking into account the structured morphological information that can be extracted from lexical forms. Using French as a case study we show that we can reach both parsing efficiency with an approximative inference method and we can get a state of the art accurracy by generalizing lexicalized parsing to handle feature structure-based word representations. Our proposal also differs theoretically from related ones (Sagae and Lavie, 2006; Zhang and Clark, 2011; Zhu et al., 2013) by explicitly using an LR automaton. The explicit introduction of the LR automaton allows us to establish a formal difference between shift reduce phrase structure parsing and shift reduce dependency parsing. It further provides some insights on the nature of the grammar underlying many contemporary parsers. The paper is organized as follows. First, section 2, we set up a formal framework for describing weighted phrase structure parsing as a 2-L CFG (Nederhof and Satta, 2010). Observing that the tree structures are actually constrained in practice we"
C14-1052,D12-1110,0,0.00884354,"orithm comes with a discriminative weighting framework inspired by (Collins, 2002). Although discriminative phrase structure parsing has been shown to be challenging when it comes to efficiency issues (Turian and Melamed, 2006; Finkel et al., 2008), we use here several approximations that make the framework not only tractable but also efficient and accurate on a lexically rich language such as French. Despite the successes of dependency grammar, we are interested in phrase structure grammar since it naturally allows to support compositional semantic representations as recently highlighted by (Socher et al., 2012). It remains that most phrase structure parsers have been designed in priority for modelling lexically poor languages such as English or Chinese (Collins, 2003; Charniak, 2000; Zhu et al., 2013). Although highly accurate multilingual parsers exist (Petrov et al., 2006), they remain relatively both slow for wide coverage purposes and their inner formal structure is not designed to handle naturally morphological information. We assume that parsing lexically rich languages benefits from taking into account the structured morphological information that can be extracted from lexical forms. Using Fr"
C14-1052,P88-1031,0,0.734474,"m generalizes lexicalized parsing (Collins, 2003) by allowing a structured representation of the lexical items. Together with a discriminative weighting component (Collins, 2002), we show that this representation allows us to achieve state of the art accurracy results on a morphologically rich language such as French while achieving more efficient parsing times than the state of the art parsers on the French data set. A comparison with English, a lexically poor language, is also provided. 1 Introduction The paper provides a phrase structure parsing algorithm inspired by LR (Knuth, 1965), GLR (Tomita, 1988) and the recent developments of (Huang and Sagae, 2010) for dependency grammar. The parsing algorithm comes with a discriminative weighting framework inspired by (Collins, 2002). Although discriminative phrase structure parsing has been shown to be challenging when it comes to efficiency issues (Turian and Melamed, 2006; Finkel et al., 2008), we use here several approximations that make the framework not only tractable but also efficient and accurate on a lexically rich language such as French. Despite the successes of dependency grammar, we are interested in phrase structure grammar since it"
C14-1052,P06-1110,0,0.0291642,"s French while achieving more efficient parsing times than the state of the art parsers on the French data set. A comparison with English, a lexically poor language, is also provided. 1 Introduction The paper provides a phrase structure parsing algorithm inspired by LR (Knuth, 1965), GLR (Tomita, 1988) and the recent developments of (Huang and Sagae, 2010) for dependency grammar. The parsing algorithm comes with a discriminative weighting framework inspired by (Collins, 2002). Although discriminative phrase structure parsing has been shown to be challenging when it comes to efficiency issues (Turian and Melamed, 2006; Finkel et al., 2008), we use here several approximations that make the framework not only tractable but also efficient and accurate on a lexically rich language such as French. Despite the successes of dependency grammar, we are interested in phrase structure grammar since it naturally allows to support compositional semantic representations as recently highlighted by (Socher et al., 2012). It remains that most phrase structure parsers have been designed in priority for modelling lexically poor languages such as English or Chinese (Collins, 2003; Charniak, 2000; Zhu et al., 2013). Although h"
C14-1052,J11-1005,0,0.0299844,"es and their inner formal structure is not designed to handle naturally morphological information. We assume that parsing lexically rich languages benefits from taking into account the structured morphological information that can be extracted from lexical forms. Using French as a case study we show that we can reach both parsing efficiency with an approximative inference method and we can get a state of the art accurracy by generalizing lexicalized parsing to handle feature structure-based word representations. Our proposal also differs theoretically from related ones (Sagae and Lavie, 2006; Zhang and Clark, 2011; Zhu et al., 2013) by explicitly using an LR automaton. The explicit introduction of the LR automaton allows us to establish a formal difference between shift reduce phrase structure parsing and shift reduce dependency parsing. It further provides some insights on the nature of the grammar underlying many contemporary parsers. The paper is organized as follows. First, section 2, we set up a formal framework for describing weighted phrase structure parsing as a 2-L CFG (Nederhof and Satta, 2010). Observing that the tree structures are actually constrained in practice we formulate in section 3"
C14-1052,D13-1071,0,0.0881106,"an explicit LR component. The LR automaton allows us to guarantee that the parser generates a viable prefix. We believe the LR framework can also shed light on theoretical, practical and experimental issues related to phrase structure parsing by comparison with dependency parsing. However using the LR automaton to constrain the parsing model 550 for multi-word expressions turns out to be disappointing since it forces the parser to take less local decisions for which the beam approximation is not well suited. This suggests for future work to explore search methods aiming to achieve optimality (Zhao et al., 2013). Mirroring a common practice in dependency parsing, the parser also provides a first support for phrase structure parsing of morphologically rich languages thanks to structured word representations. The richer lexical structure makes morphological information available during the parsing process. For the case of French it enables, among others, to integrate agreement in the parsing model. This simple integration of morphology then allows the parser to achieve state of the art accurracy on French. Since in principle nothing in the algorithm is specific to French, we expect to generalize and ex"
C14-1052,P13-1043,0,\N,Missing
C14-1052,W13-4917,0,\N,Missing
candito-etal-2010-statistical,levy-andrew-2006-tregex,0,\N,Missing
candito-etal-2010-statistical,de-marneffe-etal-2006-generating,0,\N,Missing
candito-etal-2010-statistical,W03-3023,0,\N,Missing
candito-etal-2010-statistical,E06-1011,0,\N,Missing
candito-etal-2010-statistical,W09-3821,1,\N,Missing
candito-etal-2010-statistical,W02-1001,0,\N,Missing
candito-etal-2010-statistical,C96-1058,0,\N,Missing
candito-etal-2010-statistical,J03-4003,0,\N,Missing
candito-etal-2010-statistical,P05-1038,0,\N,Missing
candito-etal-2010-statistical,P05-1012,0,\N,Missing
candito-etal-2010-statistical,Y09-1013,1,\N,Missing
candito-etal-2010-statistical,P06-1055,0,\N,Missing
candito-etal-2010-statistical,W06-2932,0,\N,Missing
candito-etal-2010-statistical,P05-1010,0,\N,Missing
candito-etal-2010-statistical,W07-2416,0,\N,Missing
candito-etal-2010-statistical,P95-1037,0,\N,Missing
candito-etal-2010-statistical,abeille-barrier-2004-enriching,0,\N,Missing
candito-etal-2010-statistical,D07-1096,0,\N,Missing
D15-1212,P05-1038,0,0.0305472,". In our case, we compare the (B+S) model with automated head annotation to the Collins head annotation as implemented in the Standord CORE NLP library (Manning et al., 2014), where we can see that the Collins handcrafted head annotation yields better results than the automated one on English7 . The question is now to which extend c-trees encode meaningful dependencies? As lexicalized c-trees encode unlabeled dependency trees, our parser also directly outputs unlabeled d-trees by 7 This pattern does not seem to be systematic: on French we could also compare with head annotations described in (Arun and Keller, 2005) and we observed a slight improvement when using the automated procedure. 1853 Parser (single) Arabic Basque French German Hebrew Hungarian Korean Polish Swedish Avg Petrov 06 Petrov 06 + tags Hall-Klein 14 Fernandez-Martins 15 This paper (B+S+M) 79.19 78.66 78.75 81.31 70.50 74.74 83.39 85.90 84.94 80.38 79.76 79.70 78.75 80.84 78.30 78.28 78.43 78.66 79.26 86.96 85.42 87.18 88.97 89.65 81.62 85.22 88.25 88.16 90.14 71.42 78.56 80.18 79.28 82.65 79.23 86.75 90.66 91.20 92.66 79.19 80.64 82.00 82.80 83.24 78.45 81.17 83.72 84.22 85.42 Best semi/ensemble 81.32 88.24 82.53 81.66 89.80 91.72 83.8"
D15-1212,E12-2012,0,0.0150881,"ngual framework, the left side of the table shows that the unlabeled dependencies are clearly better than those of genuine dependency parsers. On the right side of the table are languages for which our dependencies are actually worse. This is not a surprise, since these are also the languages for which head annotation was more problematic in the first place. This last observation suggests that a lexicalized c-parser can also provide very accurate dependencies. A way to further gen8 In practice it turns out that these are either DYALOG S R (de La Clergerie, 2013) or sometimes M ALT O PTIMIZER (Ballesteros and Nivre, 2012) eralize this observation to problematic languages would be either to design a less immediate postprocessing conversion scheme or to further normalize the data set to obtain the correct heads from the outset. 6 Conclusion Lexicalized phrase structure parsing of morphologically rich languages used to be difficult since existing implementations targeting essentially English or Chinese do not allow a straightforward integration of morphology. Given multi-view treebanks, we achieve multilingual parsing with a language-agnostic head annotation procedure. Once this procedure has created the required"
D15-1212,W09-3036,0,0.14527,"nguages. This paper shows that a parsing model that can effectively take morphology into account is key for parsing these languages. More specifically, we show that an efficient lexicalized phrase structure parser - modelling both dependencies and morphology - already significantly improves parsing accuracy. But we also show that an additional modelling of spans and constituency provides additional robustness that contributes to yield state of the art results on almost all languages considered, while remaining quite efficient. Moreover, given the availability of existing multi-view treebanks (Bhatt et al., 2009; Seddah et al., 2013; Qiu et al., 2014), our proposed solution only requires a lightweight infrastructure to achieve multilin1847 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1847–1856, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. gual parsing without requiring costly languagedependent modifications such as feature engineering. The paper is organized as follows. We first review the properties of multiview treebanks (Section 2). As these treebanks typically do not provide directly head annotation, an"
D15-1212,W13-4916,0,0.266002,"Missing"
D15-1212,cer-etal-2010-parsing,0,0.180604,"Missing"
D15-1212,A00-2018,0,0.233739,"Alpage – Universit´e Paris Diderot – Inria – IUF Place Paul Ricoeur 75013 Paris benoit.crabbe@univ-paris-diderot.fr Abstract We provide a generalization of discriminative lexicalized shift reduce parsing techniques for phrase structure grammar to a wide range of morphologically rich languages. The model is efficient and outperforms recent strong baselines on almost all languages considered. It takes advantage of a dependency based modelling of morphology and a shallow modelling of constituency boundaries. 1 Introduction Lexicalized phrase structure parsing techniques were first introduced by Charniak (2000) and Collins (2003) as generative probabilistic models. Nowadays most statistical models used in natural language processing are discriminative: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure pars"
D15-1212,P99-1065,0,0.0932429,"more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informative patterns observed on input spans. Hall et al"
D15-1212,J03-4003,0,0.721699,"e Paris Diderot – Inria – IUF Place Paul Ricoeur 75013 Paris benoit.crabbe@univ-paris-diderot.fr Abstract We provide a generalization of discriminative lexicalized shift reduce parsing techniques for phrase structure grammar to a wide range of morphologically rich languages. The model is efficient and outperforms recent strong baselines on almost all languages considered. It takes advantage of a dependency based modelling of morphology and a shallow modelling of constituency boundaries. 1 Introduction Lexicalized phrase structure parsing techniques were first introduced by Charniak (2000) and Collins (2003) as generative probabilistic models. Nowadays most statistical models used in natural language processing are discriminative: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation"
D15-1212,C14-1052,1,0.895276,"Missing"
D15-1212,de-marneffe-etal-2006-generating,0,0.137348,"Missing"
D15-1212,N13-1070,0,0.0174783,"t al. 13 F1 (EVALB) (Toks/sec) 88.6 89.1 89.5 89.7 90.0 90.1 90.2 90.4 12 655 2150  2150  169 957 1290 Alls scores and times except  are measured by Fern´andezGonz´alez and Martins (2015) on an intel Xeon 2.3Ghz.  denotes the use of a different architecture (2.4Ghz intel). Table 5: Penn treebank test (WSJ 23) parison remains indicative, it is clear that the parsing framework described in this paper is not only reasonably accurate on a fixed word order language such as English but it is also quite efficient. Parsing accuracies might be different with other head annotation schemes (See e.g. Elming et al. (2013) for illustrations). In our case, we compare the (B+S) model with automated head annotation to the Collins head annotation as implemented in the Standord CORE NLP library (Manning et al., 2014), where we can see that the Collins handcrafted head annotation yields better results than the automated one on English7 . The question is now to which extend c-trees encode meaningful dependencies? As lexicalized c-trees encode unlabeled dependency trees, our parser also directly outputs unlabeled d-trees by 7 This pattern does not seem to be systematic: on French we could also compare with head annotat"
D15-1212,P15-1147,0,0.168582,"Missing"
D15-1212,P14-1022,0,0.251772,"the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informative patterns observed on input spans. Hall et al. (2014) relies on a similar intuition : the model essentially aims to capture regularities on the spans of constituents and their immediate neighbourhood"
D15-1212,N12-1015,0,0.0259765,"the immediate left and right children of s0 and s1 as well as their left and right corner tokens. This allows us to encode the span models described in Section 5. We also use tuple-structured tokens encoding not only the word-form and the tag but also additional custom lexical features such as those enumerated in Figure 2 (right). This allows us to express the morphological models described in Section 5. Finally, the parameters w are estimated with a parallel averaged structured perceptron designed to cope with inexact inference (beam search): we specifically rely on max-violation updates of Huang et al. (2012) and on minibatches to accelerate and parallelize training (Shalev-Shwartz et al., 2007; Zhao and Huang, 2013). 5 Experiments The experiments aim to compare the contribution of span based features approximating some intuitions of Hall et al. (2014) for shift reduce parsing and morphological features for parsing free word order languages. We start by describing the evaluation protocol and by defining the models used. We use the standard S PMRL data set (Seddah et al., 2013). Part of speech tags are generated with Marmot (M¨uller et al., 2013), a CRF tagger specifically designed to provide tuple"
D15-1212,P04-1061,0,0.0339011,"ield parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informative patterns observed on input spans. Hall et al. (2014) relies on a similar intuition : the model essentially aims to capture regularities on the spans of constituents and their immediate neighbourhood, following earlier intuitions of Klein and Manning (2004). This modelling strategy has two main motivations. First it reduces the burden of feature engineering, making it easier to generalize to multiple languages. Second it avoids modeling explicitly bilexical dependencies for which parameters are notoriously hard to estimate from small data sets such as existing treebanks. On the other hand this strategy becomes less intuitive when it comes to modeling free word order languages where word order and constituency should in principle be less informative. As such, the good results reported by Hall et al. (2014) are surprising. It suggests that word or"
D15-1212,P06-2066,0,0.0178288,"n procedure Lexicalized phrase structure parsers traditionally use hand-crafted heuristics for head annotation (Collins, 2003). Although these heuristics are available for some languages, for others they are non existent or non explicit and typically hidden in conversion procedures. In order to leverage the burden of managing language specific heuristics, we first automate head annotation by taking advantage of the multi-view annotation. We begin by introducing some notation. Assuming a sentence W = w1 . . . wn , the dependency annotation of this sentence is assumed to be a dependency forest (Kuhlmann and Nivre, 2006). A dependency graph G = hV, Ei where V = {1 . . . n} is the set of word indexes or vertices and E ⊆ V × V is a set of dependency links. By convention, a dependency (i, j) means that i governs j. A dependency forest is a dependency graph such that a node has at most a single incoming edge and where there is no cycle. A node with no incoming edge is a root of the dependency forest and a dependency tree is a dependency forest with a single root. For some languages, such as German or Basque, the dependency structures found in the data set are actually dependency forests. Lexicalized parsing relie"
D15-1212,P14-5010,0,0.00371347,"n an intel Xeon 2.3Ghz.  denotes the use of a different architecture (2.4Ghz intel). Table 5: Penn treebank test (WSJ 23) parison remains indicative, it is clear that the parsing framework described in this paper is not only reasonably accurate on a fixed word order language such as English but it is also quite efficient. Parsing accuracies might be different with other head annotation schemes (See e.g. Elming et al. (2013) for illustrations). In our case, we compare the (B+S) model with automated head annotation to the Collins head annotation as implemented in the Standord CORE NLP library (Manning et al., 2014), where we can see that the Collins handcrafted head annotation yields better results than the automated one on English7 . The question is now to which extend c-trees encode meaningful dependencies? As lexicalized c-trees encode unlabeled dependency trees, our parser also directly outputs unlabeled d-trees by 7 This pattern does not seem to be systematic: on French we could also compare with head annotations described in (Arun and Keller, 2005) and we observed a slight improvement when using the automated procedure. 1853 Parser (single) Arabic Basque French German Hebrew Hungarian Korean Polis"
D15-1212,H05-1066,0,0.0924841,"oundaries. 1 Introduction Lexicalized phrase structure parsing techniques were first introduced by Charniak (2000) and Collins (2003) as generative probabilistic models. Nowadays most statistical models used in natural language processing are discriminative: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et a"
D15-1212,P13-2017,0,0.0281428,"al., 2013), which contains multi-view treebanks for a number of morphologically rich languages, for which either constituency or dependency treebanks were available. The same kind of process was applied to the Penn TreeBank using the Stanford conversion system to produce dependency annotations (de Marneffe et al., 2006). In this paper, we use both of these datasets. Although in multi-view treebanks each sentence is annotated both for constituency and dependency, they are not normalized for categories nor lexical features accross languages such as dependencies in the Google Universal Treebank (McDonald et al., 2013). What is more, the dependency and constituency structures may sometimes strongly differ. For some languages, like Hungarian, the conversion has involved some manual reannotation (Vincze et al., 2010). 3 Head annotation procedure Lexicalized phrase structure parsers traditionally use hand-crafted heuristics for head annotation (Collins, 2003). Although these heuristics are available for some languages, for others they are non existent or non explicit and typically hidden in conversion procedures. In order to leverage the burden of managing language specific heuristics, we first automate head a"
D15-1212,N15-1108,0,0.276128,"rectly inferrable from the dependency annotation. Polish uses this restructuration in patterns involving coordination. More surprisingly, non projective patterns, which we expected to be a significant feature of these languages, remain marginal in comparison to annotation related idiosyncrasic problems. 4 Parsing algorithm This section provides an overview of the design of the constituent parsing system. There are three recent proposals for beam-based discriminative shift reduce parsing for phrase structure grammar with a structured perceptron and beam search (Zhu et al., 2013; Crabb´e, 2014; Mi and Huang, 2015). All three proposals point out that for weighted phrase structure parsing, the shift reduce algorithm requires a special treatment of unary rules in order to compare derivations of the same length. They all provide different management schemes for these unaries. The work described here draws on the LR algorithm introduced by Crabb´e (2014), but provides a simpler algorithm, it precisely describes the management of unary rules and clarifies how spans and morphological information is represented (see section 5 ). 2 The constituency conversion of the Basque treebank also contains a recurrent att"
D15-1212,D13-1032,0,0.159988,"Missing"
D15-1212,vincze-etal-2010-hungarian,0,0.0166862,"to the Penn TreeBank using the Stanford conversion system to produce dependency annotations (de Marneffe et al., 2006). In this paper, we use both of these datasets. Although in multi-view treebanks each sentence is annotated both for constituency and dependency, they are not normalized for categories nor lexical features accross languages such as dependencies in the Google Universal Treebank (McDonald et al., 2013). What is more, the dependency and constituency structures may sometimes strongly differ. For some languages, like Hungarian, the conversion has involved some manual reannotation (Vincze et al., 2010). 3 Head annotation procedure Lexicalized phrase structure parsers traditionally use hand-crafted heuristics for head annotation (Collins, 2003). Although these heuristics are available for some languages, for others they are non existent or non explicit and typically hidden in conversion procedures. In order to leverage the burden of managing language specific heuristics, we first automate head annotation by taking advantage of the multi-view annotation. We begin by introducing some notation. Assuming a sentence W = w1 . . . wn , the dependency annotation of this sentence is assumed to be a d"
D15-1212,N13-1038,0,0.0253479,"ws us to encode the span models described in Section 5. We also use tuple-structured tokens encoding not only the word-form and the tag but also additional custom lexical features such as those enumerated in Figure 2 (right). This allows us to express the morphological models described in Section 5. Finally, the parameters w are estimated with a parallel averaged structured perceptron designed to cope with inexact inference (beam search): we specifically rely on max-violation updates of Huang et al. (2012) and on minibatches to accelerate and parallelize training (Shalev-Shwartz et al., 2007; Zhao and Huang, 2013). 5 Experiments The experiments aim to compare the contribution of span based features approximating some intuitions of Hall et al. (2014) for shift reduce parsing and morphological features for parsing free word order languages. We start by describing the evaluation protocol and by defining the models used. We use the standard S PMRL data set (Seddah et al., 2013). Part of speech tags are generated with Marmot (M¨uller et al., 2013), a CRF tagger specifically designed to provide tuple-structured tags. The training and development sets are tagged by 10-fold jackknifing. Head annotation is supp"
D15-1212,P13-1043,0,0.573032,"iscriminative: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informa"
D15-1212,C04-1010,0,0.0158339,"elling of constituency boundaries. 1 Introduction Lexicalized phrase structure parsing techniques were first introduced by Charniak (2000) and Collins (2003) as generative probabilistic models. Nowadays most statistical models used in natural language processing are discriminative: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et a"
D15-1212,P06-1055,0,0.295534,"trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informative patterns observed on input spans. Hall et al. (2014) relies on a similar intuition : the model essentially aims to capture regularities on the spans of con"
D15-1212,C14-1026,0,0.0457046,"model that can effectively take morphology into account is key for parsing these languages. More specifically, we show that an efficient lexicalized phrase structure parser - modelling both dependencies and morphology - already significantly improves parsing accuracy. But we also show that an additional modelling of spans and constituency provides additional robustness that contributes to yield state of the art results on almost all languages considered, while remaining quite efficient. Moreover, given the availability of existing multi-view treebanks (Bhatt et al., 2009; Seddah et al., 2013; Qiu et al., 2014), our proposed solution only requires a lightweight infrastructure to achieve multilin1847 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1847–1856, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. gual parsing without requiring costly languagedependent modifications such as feature engineering. The paper is organized as follows. We first review the properties of multiview treebanks (Section 2). As these treebanks typically do not provide directly head annotation, an information required for lexicalized par"
D15-1212,P06-2089,0,0.305722,"− 1 to 3n − 1. To ensure that a derivation is of length 3n − 1, the parser forces each shift to be followed by either a unary reduction or an alternative dummy Ghost Reduction (GR). Given the pre-processed treebank we infer the set A of actions used by the parser. Let Σ be the set of non-terminal symbols (including temporary symbols) read off from the binary treebank. The set of actions contains one Shift (S), one Ghost Reduction (GR) a set of |Σ |unary reductions (RU-X), one for each symbol, a set of |Σ| binary left reductions (RL-X) and a set of |Σ |binary right reductions (RR-X) (see also Sagae and Lavie (2006) and Figure 3 for details). The parser itself is organized around two data structures: a stack of symbols, S = . . . |s2 |s1 |s0 , whose topmost element is s0 . Symbols are lexicalized non terminals or tokens of the form A[x]. The second structure is a queue statically filled with tokens T = t1 . . . tn . Parsing is performed by sequentially generating configurations C of the form hj, S, ·i where S is a stack and j is the index of the first element of the queue. Given an initial configuration C0 = h1, , ⊥i, a derivation step at−1 Ct−1 ⇒ Ct generates a new configuration Ct by applying an actio"
D15-1212,W13-4906,0,\N,Missing
D19-1106,P15-2142,0,0.181325,"iscriminative parser. Stern et al. (2017) points out that the main difficulty comes from lexical biases using naive beam search. They propose new methods for modifying a classical wordsynchronized beam search for avoiding the lexical bias problem. The paper presents a substantially different search method for parsing in one-step with a neural generative parser, proposing a method inspired by sequential Monte-Carlo sampling and particle Christophe Pallier Cognitive Neuroimaging Lab INSERM - CEA Neurospin bat.145 Gif-sur-Yvette France christophe@pallier.org filtering (Doucet and Johansen, 2011; Buys and Blunsom, 2015). Crucially, the proposed method is naturally not sensitive to problems of lexical biases faced by standard beam search. As a result, the parser is framed as generative and strictly incremental (without lookahead) while remaining quite accurate and generally more efficient than a more traditional beam search method. Not only, the proposed search method is a variable-beam search method, but as such, it naturally provides an additional method to measure the activity required to make the parser progress incrementally and wordby-word that can, in principle, be used for cognitive modelling purposes"
D19-1106,D16-1257,0,0.0219433,"sets (Radford et al., 2019). The perplexities reported as Prince in Table 2 are the perplexities resulting from processing the Little Prince corpus used later in the paper for analyzing neuroimaging data. The table allows to measure the amount of drop in perplexity that can be explained by corpus domain change. We also compare with parsers without strict incrementality restrictions: Dyer et al. (2016) is an RNNG as a reranker with a discriminative first step (that is with lookahead). Stern et al. (2017) are the results reported with a beam of size 2000 using the generative model described by Choe and Charniak (2016) with a substantially different preprocessing of the data than the one used with RNNG (Hale et al., 2018). Finally, Kitaev and Klein (2018) is the current state of the art single parser with a discriminative model. 4 Neuro-imaging and Parsing Models A number of studies observed a positive correlation between behavioural and psycho-linguistic data like reading times and entropy measures derived from probabilistic parsers’ computations (Levy, 2008). Eye-movements (Demberg and Keller, 2008) and Event-Related Potentials (ERPs, Frank et al. (2015) were recorded during reading performance or sentenc"
D19-1106,N16-1024,0,0.156069,"speeding up the computations of direct generative parsing for RNNG. But it also studies the potential cognitive interpretation of the underlying representations built by the search method (beam activity) through analysis of neuro-imaging signal through correlations with the neuro-imaging signal during naturalistic text listening 1 Introduction The paper provides a preliminary investigation of how the improvements in natural language parsing techniques can be used for modelling brain activity during online sentence comprehension. Specifically, we focus on the RNNG generative parsing framework (Dyer et al., 2016), that allows us to extract information-theoretic measures that are relevant for cognitive studies such as surprisal or entropy (Hale, 2016). RNNG is essentially a generative parsing framework but it is not straightforward to design a onestep generative parser. Dyer et al. (2016) achieves generative parsing with RNNG in two steps: by reranking a discriminative parser. Stern et al. (2017) points out that the main difficulty comes from lexical biases using naive beam search. They propose new methods for modifying a classical wordsynchronized beam search for avoiding the lexical bias problem. The"
D19-1106,P18-1254,0,0.419502,"2016): first a discriminative model with lookahead is run on input sentences and then a generative model without lookahead is used to rerank the best hypotheses. However direct generative parsing with R NNG is difficult because word generation transitions have significantly lower probabilities than structural transitions, such as open and close transitions. Thus, inside a beam at the same temporal step, these lexical transitions are likely to be pruned. This situation creates a bias towards parsing with additional spurious structure. Some solutions already described in Stern et al. (2017) and Hale et al. (2018) manage to deal with this problem for direct generative parsing but this solution still requires to use rather large beams to yield accurate results, hence entailing significant computational overhead in time. Among the alternative ways to solve the issue, the two stage architecture (Dyer et al., 2016) is not 1151 an option in our case because it relies on a discriminative model with lookahead that would break the strict incrementality property that we want to preserve for the cognitive perspective. Furthermore, in our scientific context, we have to study two inference problems: (1) the usual"
D19-1106,P18-1249,0,0.0116515,"e corpus used later in the paper for analyzing neuroimaging data. The table allows to measure the amount of drop in perplexity that can be explained by corpus domain change. We also compare with parsers without strict incrementality restrictions: Dyer et al. (2016) is an RNNG as a reranker with a discriminative first step (that is with lookahead). Stern et al. (2017) are the results reported with a beam of size 2000 using the generative model described by Choe and Charniak (2016) with a substantially different preprocessing of the data than the one used with RNNG (Hale et al., 2018). Finally, Kitaev and Klein (2018) is the current state of the art single parser with a discriminative model. 4 Neuro-imaging and Parsing Models A number of studies observed a positive correlation between behavioural and psycho-linguistic data like reading times and entropy measures derived from probabilistic parsers’ computations (Levy, 2008). Eye-movements (Demberg and Keller, 2008) and Event-Related Potentials (ERPs, Frank et al. (2015) were recorded during reading performance or sentence completion tasks have allegedly contributed in giving a cognitive dimension to the Surprisal Theory (Levy, 2008). Parsers Actions and Neu"
D19-1106,E17-1117,0,0.0173397,"Linguistics online parsing process. Section 3 provides empirical measures and quantifies the behaviour of the parser and of the proposed search method. Section 4 describes the relationship between the parsing model and the analysis of neuro-imaging data, section 5 presents the results. 2 2.1 RNNG probability distribution p to the set A of actions given the parsing context: p = S OFTMAX(Wh + b) The parsing context h is itself encoded by a stackLSTM (Dyer et al., 2016): and language modelling h = S TACK -L STM(e1 . . . en ) In-order RNNG We use an in-order variant of RNNG (Liu and Zhang, 2017; Kuncoro et al., 2017) where the set of transitions echoes the one of a left-corner parser. A configuration is a triple hS, B, ni where S is a stack, B is a buffer and n a counter of open brackets. where each ei is either a word eW i , a nonterminal T . Word representations eN , or a tree embedding e i i are pushed on the stack-L STM by the generate action and are the concatenation of a word embedding w and an embedding of the word’s characters c1 . . . cn : eW i = [w; B I -L STM (c1 . . . cn )] Init h∅, x1 . . . xn , 0i T Nonterminal eN i and tree embeddings ei are computed using the same methods as in (Dyer et al"
D19-1106,Q17-1029,0,0.0935026,"ion for Computational Linguistics online parsing process. Section 3 provides empirical measures and quantifies the behaviour of the parser and of the proposed search method. Section 4 describes the relationship between the parsing model and the analysis of neuro-imaging data, section 5 presents the results. 2 2.1 RNNG probability distribution p to the set A of actions given the parsing context: p = S OFTMAX(Wh + b) The parsing context h is itself encoded by a stackLSTM (Dyer et al., 2016): and language modelling h = S TACK -L STM(e1 . . . en ) In-order RNNG We use an in-order variant of RNNG (Liu and Zhang, 2017; Kuncoro et al., 2017) where the set of transitions echoes the one of a left-corner parser. A configuration is a triple hS, B, ni where S is a stack, B is a buffer and n a counter of open brackets. where each ei is either a word eW i , a nonterminal T . Word representations eN , or a tree embedding e i i are pushed on the stack-L STM by the generate action and are the concatenation of a word embedding w and an embedding of the word’s characters c1 . . . cn : eW i = [w; B I -L STM (c1 . . . cn )] Init h∅, x1 . . . xn , 0i T Nonterminal eN i and tree embeddings ei are computed using the same me"
D19-1106,H94-1020,0,0.0711766,"for generative neural parsing that aims to overcome the problems of lexical biases (Stern et al., 2017) by drawing inspiration from particle filtering methods. In section 3 we motivate and study some properties of the method from a computational perspective and we explore in section 5 the potential of the overall beam activity predictors for modelling and analyzing fMRI data (Table 3). 3 Computational experiments We report a few experiments designed to better understand the computational properties of the search method described so far. All the experiments are performed on the Penn-Treebank (Marcus et al., 1994), using sections 2-21 as training, section 22 as development and section 23 as test. 1154 We preprocess the data for numbers replaced by a unique num token and we replace word occurrences with frequency one by the token unk. Our development experiments compare our variable-size beam method with more traditional beam search. As standard naive beam search is not appropriate to generative parsing, we directly compare with the word-synchronous beam search method of Stern et al. (2017), applied to RNNG, with the so-called fast track extension. Our implementation of word synchronous beam search foll"
D19-1106,D17-1178,0,0.564368,"ion of how the improvements in natural language parsing techniques can be used for modelling brain activity during online sentence comprehension. Specifically, we focus on the RNNG generative parsing framework (Dyer et al., 2016), that allows us to extract information-theoretic measures that are relevant for cognitive studies such as surprisal or entropy (Hale, 2016). RNNG is essentially a generative parsing framework but it is not straightforward to design a onestep generative parser. Dyer et al. (2016) achieves generative parsing with RNNG in two steps: by reranking a discriminative parser. Stern et al. (2017) points out that the main difficulty comes from lexical biases using naive beam search. They propose new methods for modifying a classical wordsynchronized beam search for avoiding the lexical bias problem. The paper presents a substantially different search method for parsing in one-step with a neural generative parser, proposing a method inspired by sequential Monte-Carlo sampling and particle Christophe Pallier Cognitive Neuroimaging Lab INSERM - CEA Neurospin bat.145 Gif-sur-Yvette France christophe@pallier.org filtering (Doucet and Johansen, 2011; Buys and Blunsom, 2015). Crucially, the p"
E06-2005,W02-2233,1,0.821185,"Missing"
E06-2005,E03-1030,0,0.0627882,"Missing"
E17-1118,P04-1015,0,0.149252,"abel, its head and the part-of-speech tag of its head. When used as a subscript, l (r) refers to the left (right) index of a node. Finally lo (ro) denotes the token immediately left to the left index (right to the right index). See Figure 4 for a representation of a configuration with these notations. complexity of these algorithms (van Cranenburgh et al., 2016). Unless otherwise indicated, we did experiments with gold part-of-speech tags, following a common practice for discontinuous parsing. 3.2 Classifier We used an averaged structured perceptron (Collins, 2002) with early-update training (Collins and Roark, 2004). We use the hash trick (Shi et al., 2009) to speed up feature hashing. This has no noticeable effect on accuracy and this improves training and parsing speed. The only hyperparameter of the perceptron is the number of training epochs. Features We tested three feature sets described in Table 2 and Figure 4. The BASELINE feature set is the transposition of Maier (2015)’s baseline features to the G AP transition system. It is based on B, on S, and on the top element of D, but does not use information from the rest of D (i.e. the gapped elements). This feature set was designed in order to obtain"
E17-1118,W02-1001,0,0.106465,"des. We use c, w and t to denote a node’s label, its head and the part-of-speech tag of its head. When used as a subscript, l (r) refers to the left (right) index of a node. Finally lo (ro) denotes the token immediately left to the left index (right to the right index). See Figure 4 for a representation of a configuration with these notations. complexity of these algorithms (van Cranenburgh et al., 2016). Unless otherwise indicated, we did experiments with gold part-of-speech tags, following a common practice for discontinuous parsing. 3.2 Classifier We used an averaged structured perceptron (Collins, 2002) with early-update training (Collins and Roark, 2004). We use the hash trick (Shi et al., 2009) to speed up feature hashing. This has no noticeable effect on accuracy and this improves training and parsing speed. The only hyperparameter of the perceptron is the number of training epochs. Features We tested three feature sets described in Table 2 and Figure 4. The BASELINE feature set is the transposition of Maier (2015)’s baseline features to the G AP transition system. It is based on B, on S, and on the top element of D, but does not use information from the rest of D (i.e. the gapped element"
E17-1118,C14-1052,1,0.922411,"Missing"
E17-1118,D15-1212,1,0.895209,"Missing"
E17-1118,P16-2006,0,0.0815386,"Missing"
E17-1118,P03-1013,0,0.212309,"(G´omez-Rodr´ıguez and Fern´andezGonz´alez, 2015). 3 Experiments 3.1 Datasets We evaluated our model on two corpora, namely the Negra corpus (Skut et al., 1997) and the Tiger corpus (Brants, 1998). To ensure comparability with previous work, we carried out experiments on several instantiations of these corpora. We present results on two instantiations of Negra. N EGRA -30 consists of sentences whose length is smaller than, or equal to, 30 words. We used the same split as Maier (2015). A second instantiation, N EGRA -A LL, contains all the sentences of the corpus, and uses the standard split (Dubey and Keller, 2003). For the Tiger corpus, we also use two instantiations. T IGER HN08 is the split used by Hall and Nivre (2008). T IGER M15 is the split of Maier (2015), which corresponds to the SPMRL split (Seddah et al., 2013).2 We refer the reader to Table 8 in Appendix A for further details on the splits used. For both corpora, the first step of preprocessing consists in removing function labels and reattaching the nodes attached to the ROOT and causing artificial discontinuities (these are mainly punctuation terminals).3 Then, corpora are head-annotated using the headrules included in the D ISCO -D OP pac"
E17-1118,W11-2913,0,0.716355,"stituents, e.g. the Tiger corpus (Brants, 1998). From a parsing point of view, discontinuities pose a challenge. Mildly context-sensitive formalisms, that are expressive enough to model discontinuities have high parsing complexity. For example, the CKY algorithm for a binary probabilistic LCFRS is in O(n3k ), where k is the fan-out of the grammar (Kallmeyer, 2010). Recently, there have been several proposals for direct discontinuous parsing. They correspond roughly to three different parsing paradigms. (i) Chart parsers are based on probabilistic LCFRS (Kallmeyer and Maier, 2013; Maier, 2010; Evang and Kallmeyer, 2011), or on the Data-Oriented Parsing (DOP) framework (van Cranenburgh, 2012; van Cranenburgh and Bod, 2013; van Cranenburgh et al., 2016). However, the complexity of inference in this paradigm requires to design elaborate search strategies and heuristics to make parsing run-times reasonable. (ii) Several approaches are based on modified non-projective dependency parsers, for example Hall and Nivre (2008), or more recently Fern´andez-Gonz´alez and Martins (2015) who provided a surprisingly accurate parsing method that can profit from efficient dependency parsers with rich features. (iii) Transitio"
E17-1118,P15-1147,0,0.378207,"Missing"
E17-1118,N10-1118,0,0.020129,"orresponds to the SPMRL split (Seddah et al., 2013).2 We refer the reader to Table 8 in Appendix A for further details on the splits used. For both corpora, the first step of preprocessing consists in removing function labels and reattaching the nodes attached to the ROOT and causing artificial discontinuities (these are mainly punctuation terminals).3 Then, corpora are head-annotated using the headrules included in the D ISCO -D OP package, and binarized by an order-0 head-Markovization (Klein and Manning, 2003). There is a rich literature on binarizing LCFRS (G´omez-Rodr´ıguez et al., 2009; Gildea, 2010), because both the gapdegree and the rank of the resulting trees need to be minimized in order to achieve a reasonable complexity when using chart-based parsers (Kallmeyer and Maier, 2013). However, this seems not to be a problem for transition-based parsing, and the gains of using optimized binarization algorithms do not seem to be worth the 2 As in previous work (Maier, 2015), two sentences (number 46234 and 50224) are excluded from the test set because they contain annotation errors. 3 We used extensively the publicly available software T REE T OOLS and DISCO - DOP for these preprocessing s"
E17-1118,N09-1061,0,0.081113,"Missing"
E17-1118,P14-1022,0,0.227652,"s-diderot.fr S Abstract NP This article introduces a novel transition system for discontinuous lexicalized constituent parsing called SR - GAP. It is an extension of the shift-reduce algorithm with an additional gap transition. Evaluation on two German treebanks shows that SR - GAP outperforms the previous best transitionbased discontinuous parser (Maier, 2015) by a large margin (it is notably twice as accurate on the prediction of discontinuous constituents), and is competitive with the state of the art (Fern´andez-Gonz´alez and Martins, 2015). As a side contribution, we adapt span features (Hall et al., 2014) to discontinuous parsing. 1 NP PPER VVFIN Es ADV ADJA bestunde somit hinreichender ¨ NN Spielraum Figure 1: Discontinuous tree extracted from the Tiger corpus (punctuation removed). Introduction Discontinuous constituent trees can be used to model directly certain specific linguistic phenomena, such as extraposition, or more broadly to describe languages with some degree of word-order freedom. Although these phenomena are sometimes annotated with indexed traces in CFG treebanks, other constituent treebanks are natively annotated with discontinuous constituents, e.g. the Tiger corpus (Brants,"
E17-1118,J13-1006,0,0.886251,"atively annotated with discontinuous constituents, e.g. the Tiger corpus (Brants, 1998). From a parsing point of view, discontinuities pose a challenge. Mildly context-sensitive formalisms, that are expressive enough to model discontinuities have high parsing complexity. For example, the CKY algorithm for a binary probabilistic LCFRS is in O(n3k ), where k is the fan-out of the grammar (Kallmeyer, 2010). Recently, there have been several proposals for direct discontinuous parsing. They correspond roughly to three different parsing paradigms. (i) Chart parsers are based on probabilistic LCFRS (Kallmeyer and Maier, 2013; Maier, 2010; Evang and Kallmeyer, 2011), or on the Data-Oriented Parsing (DOP) framework (van Cranenburgh, 2012; van Cranenburgh and Bod, 2013; van Cranenburgh et al., 2016). However, the complexity of inference in this paradigm requires to design elaborate search strategies and heuristics to make parsing run-times reasonable. (ii) Several approaches are based on modified non-projective dependency parsers, for example Hall and Nivre (2008), or more recently Fern´andez-Gonz´alez and Martins (2015) who provided a surprisingly accurate parsing method that can profit from efficient dependency pa"
E17-1118,N15-1134,0,0.0171024,"ntains one discontinuous tree. The correctness of SR - GAP system holds only for the robust case: that is the full set of labeled discontinuous trees, and not, say, for the set of trees derived by a true LCFRS grammar also able to reject agrammatical sentences. From an empirical point of view, a transition system that overgenerates is necessary for robustness, and is desirable for fast approximate linear-time inference. However, from a formal point of view, the relationship of the SR - GAP transition system with automata explicitly designed for LCFRS parsing (Villemonte de La Clergerie, 2002; Kallmeyer and Maier, 2015) requires further investigations. 2.4 Length of Derivations Any derivation produced by SR - GAP for a sentence of length n will contain exactly n S HIFTS and n − 1 binary reductions. In contrast, the number of unary reductions and G AP actions can vary. Therefore several possible derivations for the same sentence may have different lengths. This is a recurring problem for transition-based parsing because it undermines the comparability of derivation scores. In particular, Crabb´e (2014) observed that the score of a parse item is approximatively linear in the number of previous transitions, whi"
E17-1118,Q16-1023,0,0.0811758,"Missing"
E17-1118,P13-2111,0,0.0267866,"- GAP, SR - CGAP is not complete, as some discontinuous trees whose derivation should contain more than m consecutive G APS cannot be predicted. 2.5 Beam Search with a Tree-structured Stack A naive beam implementation of SR - GAP will copy the whole parsing configuration at each step and for each item in the beam. This causes the parser algorithm to have a practical O(k ·n2 ) complexity, where k is the size of the beam and n the length of a derivation. To overcome this, one can use a tree-structured stack (TSS) to factorize the representations of common prefixes in the stack as described by (Goldberg et al., 2013) for projective dependency parsing. However the discontinuites entail that a limited amount of copying cannot be entirely avoided. When a reduction follows n G AP actions, we need to grow a new branch of size n + 1 in the tree-structured stack to account for reordering. The complexity of the inference becomes O(k · (n + g)) where g is the number of gaps in the derivation. As there are very few gap actions (in proportion) in the dataset, the practical runtime is linear in the length of the derivation. 2.6 Relationship to Dependency Parsing Algorithms The transition system presented in this arti"
E17-1118,P03-1054,0,0.0270902,". T IGER HN08 is the split used by Hall and Nivre (2008). T IGER M15 is the split of Maier (2015), which corresponds to the SPMRL split (Seddah et al., 2013).2 We refer the reader to Table 8 in Appendix A for further details on the splits used. For both corpora, the first step of preprocessing consists in removing function labels and reattaching the nodes attached to the ROOT and causing artificial discontinuities (these are mainly punctuation terminals).3 Then, corpora are head-annotated using the headrules included in the D ISCO -D OP package, and binarized by an order-0 head-Markovization (Klein and Manning, 2003). There is a rich literature on binarizing LCFRS (G´omez-Rodr´ıguez et al., 2009; Gildea, 2010), because both the gapdegree and the rank of the resulting trees need to be minimized in order to achieve a reasonable complexity when using chart-based parsers (Kallmeyer and Maier, 2013). However, this seems not to be a problem for transition-based parsing, and the gains of using optimized binarization algorithms do not seem to be worth the 2 As in previous work (Maier, 2015), two sentences (number 46234 and 50224) are excluded from the test set because they contain annotation errors. 3 We used ext"
E17-1118,P15-2042,0,0.0654424,"Missing"
E17-1118,W10-1407,0,0.0175756,"ontinuous constituents, e.g. the Tiger corpus (Brants, 1998). From a parsing point of view, discontinuities pose a challenge. Mildly context-sensitive formalisms, that are expressive enough to model discontinuities have high parsing complexity. For example, the CKY algorithm for a binary probabilistic LCFRS is in O(n3k ), where k is the fan-out of the grammar (Kallmeyer, 2010). Recently, there have been several proposals for direct discontinuous parsing. They correspond roughly to three different parsing paradigms. (i) Chart parsers are based on probabilistic LCFRS (Kallmeyer and Maier, 2013; Maier, 2010; Evang and Kallmeyer, 2011), or on the Data-Oriented Parsing (DOP) framework (van Cranenburgh, 2012; van Cranenburgh and Bod, 2013; van Cranenburgh et al., 2016). However, the complexity of inference in this paradigm requires to design elaborate search strategies and heuristics to make parsing run-times reasonable. (ii) Several approaches are based on modified non-projective dependency parsers, for example Hall and Nivre (2008), or more recently Fern´andez-Gonz´alez and Martins (2015) who provided a surprisingly accurate parsing method that can profit from efficient dependency parsers with ri"
E17-1118,P15-1116,0,0.102321,"Maximin Coavoux1,2 and Benoˆıt Crabb´e1,2,3 1 Univ. Paris Diderot, Sorbonne Paris Cit´e 2 Laboratoire de linguistique formelle (LLF, CNRS) 3 Institut Universitaire de France maximin.coavoux@etu.univ-paris-diderot.fr benoit.crabbe@linguist.univ-paris-diderot.fr S Abstract NP This article introduces a novel transition system for discontinuous lexicalized constituent parsing called SR - GAP. It is an extension of the shift-reduce algorithm with an additional gap transition. Evaluation on two German treebanks shows that SR - GAP outperforms the previous best transitionbased discontinuous parser (Maier, 2015) by a large margin (it is notably twice as accurate on the prediction of discontinuous constituents), and is competitive with the state of the art (Fern´andez-Gonz´alez and Martins, 2015). As a side contribution, we adapt span features (Hall et al., 2014) to discontinuous parsing. 1 NP PPER VVFIN Es ADV ADJA bestunde somit hinreichender ¨ NN Spielraum Figure 1: Discontinuous tree extracted from the Tiger corpus (punctuation removed). Introduction Discontinuous constituent trees can be used to model directly certain specific linguistic phenomena, such as extraposition, or more broadly to descri"
E17-1118,N15-1108,0,0.0519631,"Missing"
E17-1118,E12-1047,0,0.104673,"Missing"
E17-1118,W14-6104,0,0.333503,"012; van Cranenburgh and Bod, 2013; van Cranenburgh et al., 2016). However, the complexity of inference in this paradigm requires to design elaborate search strategies and heuristics to make parsing run-times reasonable. (ii) Several approaches are based on modified non-projective dependency parsers, for example Hall and Nivre (2008), or more recently Fern´andez-Gonz´alez and Martins (2015) who provided a surprisingly accurate parsing method that can profit from efficient dependency parsers with rich features. (iii) Transition-based discontinuous parsers are based on the easy-first framework (Versley, 2014a) or the shift-reduce algorithm augmented with a swap action (Maier, 2015). In the latter system, which we will refer to as SR - SWAP, a S WAP action pushes the second element of the stack back onto the buffer. Although SR - SWAP is fast and obtained good results, it underperforms Fern´andez-Gonz´alez and Martins (2015)’s parser by a large margin. We believe this result does not indicate a fatal problem for the transition-based framework for discontinuous parsing, but emphasizes several limitations inherent to SR - SWAP, in particular the length of derivations (Section 3.5). 1259 Proceedings"
E17-1118,C02-1028,0,0.0963587,"he forest only contains one discontinuous tree. The correctness of SR - GAP system holds only for the robust case: that is the full set of labeled discontinuous trees, and not, say, for the set of trees derived by a true LCFRS grammar also able to reject agrammatical sentences. From an empirical point of view, a transition system that overgenerates is necessary for robustness, and is desirable for fast approximate linear-time inference. However, from a formal point of view, the relationship of the SR - GAP transition system with automata explicitly designed for LCFRS parsing (Villemonte de La Clergerie, 2002; Kallmeyer and Maier, 2015) requires further investigations. 2.4 Length of Derivations Any derivation produced by SR - GAP for a sentence of length n will contain exactly n S HIFTS and n − 1 binary reductions. In contrast, the number of unary reductions and G AP actions can vary. Therefore several possible derivations for the same sentence may have different lengths. This is a recurring problem for transition-based parsing because it undermines the comparability of derivation scores. In particular, Crabb´e (2014) observed that the score of a parse item is approximatively linear in the number"
E17-1118,P13-1043,0,0.0573025,"xactly n S HIFTS and n − 1 binary reductions. In contrast, the number of unary reductions and G AP actions can vary. Therefore several possible derivations for the same sentence may have different lengths. This is a recurring problem for transition-based parsing because it undermines the comparability of derivation scores. In particular, Crabb´e (2014) observed that the score of a parse item is approximatively linear in the number of previous transitions, which creates a bias towards long derivations. Different strategies have been proposed to ensure that all derivations have the same length (Zhu et al., 2013; Crabb´e, 2014; Mi and Huang, 2015). Following Zhu et al. (2013), we use an additional I DLE action that can only be performed when a parsing item is final. Thus, short derivations are padded until the last parse item in the beam is final. I DLE actions are scored exactly like any other action. SR - CGAP As an alternative strategy to the problem of comparability of hypotheses, we also present a variant of SR - GAP, called SR - CGAP, in which the length of any derivation only depends on the length of the sentence. In SR - CGAP, each 1262 S HIFT action must be followed by either a unary reducti"
E17-1118,W13-5701,0,0.591695,"Missing"
E17-1118,A97-1014,0,0.648407,"s The transition system presented in this article uses two distinct data structures to represent the stack. In this respect, it belongs to the family of algorithms presented by Covington (2001) for dependency parsing. Covington’s algorithm iterates over every possible pair of words in a sentence and decides for each pair whether to attach them – with a left or right arc – or not. This algorithm can be formulated as a transition system with a split stack (G´omez-Rodr´ıguez and Fern´andezGonz´alez, 2015). 3 Experiments 3.1 Datasets We evaluated our model on two corpora, namely the Negra corpus (Skut et al., 1997) and the Tiger corpus (Brants, 1998). To ensure comparability with previous work, we carried out experiments on several instantiations of these corpora. We present results on two instantiations of Negra. N EGRA -30 consists of sentences whose length is smaller than, or equal to, 30 words. We used the same split as Maier (2015). A second instantiation, N EGRA -A LL, contains all the sentences of the corpus, and uses the standard split (Dubey and Keller, 2003). For the Tiger corpus, we also use two instantiations. T IGER HN08 is the split used by Hall and Nivre (2008). T IGER M15 is the split of"
E17-1118,W16-0906,0,\N,Missing
E17-2053,D15-1041,0,0.381493,"and of additional language-specific morphological attributes such as case, tense). We compare the resulting model to a pipeline approach. As the second auxiliary task, we predict the functional label that links each word to its head. Overall, we evaluate to which extent these auxiliary tasks can both improve parsing and enrich the output of the parser. This paper makes the following contributions: We introduce a constituency parser based on a bi-LSTM encoder adapted from recent work (Cross and Huang, 2016b; Kiperwasser and Goldberg, 2016), which can incorporate a lower level character biLSTM (Ballesteros et al., 2015; Plank et al., 2016). We model two important interfaces of constituency parsing with auxiliary tasks supervised at the word level: (i) part-of-speech (POS) and morphological tagging, (ii) functional label prediction. On the SPMRL dataset, our parser obtains above state-of-the-art results on constituency parsing without requiring either predicted POS or morphological tags, and outputs labelled dependency trees. 1 1. We introduce a single greedy parser which does not need predicted POS tags or morphological tags at inference time, and yet outperforms the best published results on the SPMRL data"
E17-2053,Q16-1023,0,0.249521,"a first auxiliary task, we perform morphological analysis (prediction of the POS tags and of additional language-specific morphological attributes such as case, tense). We compare the resulting model to a pipeline approach. As the second auxiliary task, we predict the functional label that links each word to its head. Overall, we evaluate to which extent these auxiliary tasks can both improve parsing and enrich the output of the parser. This paper makes the following contributions: We introduce a constituency parser based on a bi-LSTM encoder adapted from recent work (Cross and Huang, 2016b; Kiperwasser and Goldberg, 2016), which can incorporate a lower level character biLSTM (Ballesteros et al., 2015; Plank et al., 2016). We model two important interfaces of constituency parsing with auxiliary tasks supervised at the word level: (i) part-of-speech (POS) and morphological tagging, (ii) functional label prediction. On the SPMRL dataset, our parser obtains above state-of-the-art results on constituency parsing without requiring either predicted POS or morphological tags, and outputs labelled dependency trees. 1 1. We introduce a single greedy parser which does not need predicted POS tags or morphological tags at"
E17-2053,W13-4916,0,0.426274,"Missing"
E17-2053,D13-1032,0,0.105667,"Missing"
E17-2053,W14-6110,0,0.400562,"Missing"
E17-2053,P16-2067,0,0.314128,"-specific morphological attributes such as case, tense). We compare the resulting model to a pipeline approach. As the second auxiliary task, we predict the functional label that links each word to its head. Overall, we evaluate to which extent these auxiliary tasks can both improve parsing and enrich the output of the parser. This paper makes the following contributions: We introduce a constituency parser based on a bi-LSTM encoder adapted from recent work (Cross and Huang, 2016b; Kiperwasser and Goldberg, 2016), which can incorporate a lower level character biLSTM (Ballesteros et al., 2015; Plank et al., 2016). We model two important interfaces of constituency parsing with auxiliary tasks supervised at the word level: (i) part-of-speech (POS) and morphological tagging, (ii) functional label prediction. On the SPMRL dataset, our parser obtains above state-of-the-art results on constituency parsing without requiring either predicted POS or morphological tags, and outputs labelled dependency trees. 1 1. We introduce a single greedy parser which does not need predicted POS tags or morphological tags at inference time, and yet outperforms the best published results on the SPMRL dataset (Bj¨orkelund et a"
E17-2053,cer-etal-2010-parsing,0,0.0318179,"Missing"
E17-2053,W05-1513,0,0.213942,"s these embeddings as input to score parsing actions. In such architectures, the bi-LSTM component lends itself to auxiliary tasks of sequence prediction at the word level as illustrated for multilingual POS tagging by Plank et al. (2016). In this paper, we present a constituency parsing model based on a bi-LSTM encoder, and use the bi-LSTM component to model two natural interfaces of constituency parsing — morphology and functional labelling — as word-level auxiliary tasks. 2 Constituent Parsing with bi-LSTMs Lexicalized transition-based constituent parsing generally derives from the work of Sagae and Lavie (2005) and subsequent work (Sagae and Lavie, 2006; Zhu et al., 2013, among others). We use the set of parse actions described by Sagae and Lavie (2005). It is a standard shift-reduce transition system which distinguishes left- and right- re1 The code of the parser is available for download at https://github.com/mcoavoux/mtg/. 331 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 331–336, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Parser configuration: s2 CAT Parsing input"
E17-2053,D15-1212,1,0.864862,"Missing"
E17-2053,P06-2089,0,0.112394,"actions. In such architectures, the bi-LSTM component lends itself to auxiliary tasks of sequence prediction at the word level as illustrated for multilingual POS tagging by Plank et al. (2016). In this paper, we present a constituency parsing model based on a bi-LSTM encoder, and use the bi-LSTM component to model two natural interfaces of constituency parsing — morphology and functional labelling — as word-level auxiliary tasks. 2 Constituent Parsing with bi-LSTMs Lexicalized transition-based constituent parsing generally derives from the work of Sagae and Lavie (2005) and subsequent work (Sagae and Lavie, 2006; Zhu et al., 2013, among others). We use the set of parse actions described by Sagae and Lavie (2005). It is a standard shift-reduce transition system which distinguishes left- and right- re1 The code of the parser is available for download at https://github.com/mcoavoux/mtg/. 331 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 331–336, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Parser configuration: s2 CAT Parsing input Aux-task output a1 aj … aA … aj a1 … aA … a"
E17-2053,P16-2006,0,0.19026,"a pipeline approach. As a first auxiliary task, we perform morphological analysis (prediction of the POS tags and of additional language-specific morphological attributes such as case, tense). We compare the resulting model to a pipeline approach. As the second auxiliary task, we predict the functional label that links each word to its head. Overall, we evaluate to which extent these auxiliary tasks can both improve parsing and enrich the output of the parser. This paper makes the following contributions: We introduce a constituency parser based on a bi-LSTM encoder adapted from recent work (Cross and Huang, 2016b; Kiperwasser and Goldberg, 2016), which can incorporate a lower level character biLSTM (Ballesteros et al., 2015; Plank et al., 2016). We model two important interfaces of constituency parsing with auxiliary tasks supervised at the word level: (i) part-of-speech (POS) and morphological tagging, (ii) functional label prediction. On the SPMRL dataset, our parser obtains above state-of-the-art results on constituency parsing without requiring either predicted POS or morphological tags, and outputs labelled dependency trees. 1 1. We introduce a single greedy parser which does not need predicted"
E17-2053,D16-1001,0,0.456282,"a pipeline approach. As a first auxiliary task, we perform morphological analysis (prediction of the POS tags and of additional language-specific morphological attributes such as case, tense). We compare the resulting model to a pipeline approach. As the second auxiliary task, we predict the functional label that links each word to its head. Overall, we evaluate to which extent these auxiliary tasks can both improve parsing and enrich the output of the parser. This paper makes the following contributions: We introduce a constituency parser based on a bi-LSTM encoder adapted from recent work (Cross and Huang, 2016b; Kiperwasser and Goldberg, 2016), which can incorporate a lower level character biLSTM (Ballesteros et al., 2015; Plank et al., 2016). We model two important interfaces of constituency parsing with auxiliary tasks supervised at the word level: (i) part-of-speech (POS) and morphological tagging, (ii) functional label prediction. On the SPMRL dataset, our parser obtains above state-of-the-art results on constituency parsing without requiring either predicted POS or morphological tags, and outputs labelled dependency trees. 1 1. We introduce a single greedy parser which does not need predicted"
E17-2053,P15-1033,0,0.0178363,"eatures are either instantiated with nonterminal embeddings or by the contextual token embedding produced by the bi-LSTM encoder. For example, s0 .L(eft)C(orner) is instantiated by the bi-LSTM output of the left-most token encompassed by the constituent s0 . Bi-LSTM representation of the input The use of a bi-LSTM encoder in parsing was proposed independently by Kiperwasser and Goldberg (2016) and Cross and Huang (2016a). Its role is to provide contextual representations for each token. In transition-based parsing, bi-LSTMs can give a finite representation of the potentially unbounded buffer (Dyer et al., 2015), and model span (Cross and Huang, 2016b). Each token is a tuple of typed symbols, consisting minimally of a word-form. The other types of symbols are POS tags and language-dependent morphological attributes. Each type of symbol has its own embedding look-up table. In our architecture (Figure 1), the input to the bi-LSTM encoder at step i is the concatenation of the embeddings of each typed symbol composing token i. The output for the same token is the concatenation of the forward and backward LSTM 2.3 Auxiliary Tasks We use the bi-LSTM states of the lower layer of the encoder to predict word-"
F13-1013,abeille-barrier-2004-enriching,1,0.835838,"Missing"
F13-1013,blache-etal-2010-otim,0,0.0463402,"Missing"
F13-1013,2009.jeptalnrecital-long.4,1,0.795209,"Missing"
F13-1013,cresti-etal-2004-c,0,0.0440219,"Missing"
F13-1013,W10-1843,0,0.0509728,"Missing"
F13-1013,gravier-etal-2012-etape,0,0.0275884,"Missing"
F13-1013,levy-andrew-2006-tregex,0,0.0734141,"Missing"
F13-1013,J93-2004,0,0.0429192,"Missing"
F13-1013,P06-1055,0,0.170492,"Missing"
F14-1029,A00-2018,0,0.393409,"Missing"
F14-1029,P05-1022,0,0.203143,"Missing"
F14-1029,W02-1001,0,0.176335,"Missing"
F14-1029,J03-4003,0,0.168781,"Missing"
F14-1029,P08-1109,0,0.050766,"Missing"
F14-1029,N12-1015,0,0.0456421,"Missing"
F14-1029,P10-1110,0,0.0512713,"Missing"
F14-1029,N13-1024,0,0.027079,"Missing"
F14-1029,P06-1055,0,0.0541351,"Missing"
F14-1029,P06-2089,0,0.0494046,"Missing"
F14-1029,W10-1410,0,0.0378723,"Missing"
F14-1029,W13-4917,0,0.0341873,"Missing"
F14-1029,D12-1110,0,0.0317111,"Missing"
F14-1029,P88-1031,0,0.722946,"Missing"
F14-1029,W09-3825,0,0.0494653,"Missing"
J13-3005,C96-1034,0,0.376661,"nsider a particular type of computational grammar, namely, tree-based grammars—that is, grammars where the basic units are trees (or tree descriptions) of arbitrary depth, such as Tree-Adjoining Grammar (TAG; Joshi, Levy, and Takahashi 1975), D-Tree Grammar (DTG; Rambow, Vijay-Shanker, and Weir 1995), Tree Description Grammars (TDG; Kallmeyer 1999) or Interaction Grammars (IG; Perrier 2000)— environments sharing all of the listed features are lacking. As we shall see in Section 7 of this article, there have been some proposals for grammar engineering environments for tree-based grammar (e.g., Candito 1996; Xia, Palmer, and Vijay-Shanker 1999, but these lack notational expressivity. This is partly due to the fact that tree-based formalisms offer an extended domain of locality where one can encode constraints between remote syntactic constituents. If one wants to define such constraints while giving a modular and incremental specification of the grammar, one needs a high level of notational expressivity, as we shall see throughout the article (and especially in Section 4). In this article, we present XMG (eXtensible MetaGrammar), a framework for specifying tree-based grammars. Focusing mostly on"
J13-3005,P03-1024,0,0.507858,"Missing"
J13-3005,C69-0101,0,0.536249,"Missing"
J13-3005,J11-1003,0,0.0149523,"s the criticisms leveled by Cohen-Sygal and Wintner (2007, 2009) against non-associative constraints on node unification do not apply. Briefly, in their work, Cohen-Sygal and Wintner (2007, 2009) showed that any polarity-based tree description formalism is not associative. In other words, when describing trees in terms of combinations of polarized structures, the order in which the structures are combined matters (i.e., the output structures depend on the combination order). This feature makes such formalisms not appropriate for a modular and collaborative grammar engineering, such as that of Cohen-Sygal and Wintner (2011) for Unification Grammar. In the XMG case, when using node colors, the tree description solver does not rely on any specific fragment combination order. It computes all possible combination orders. In this context, the grammar designer cannot think in terms of sequences of node identifications. This would lead to tree overgeneration. Again, it is important to remember that tree solving computes any valid tree model, independently of any specific sequence of node identifications (all valid node identifications are computed). In this context, non-associativity of color-based node identification"
J13-3005,copestake-flickinger-2000-open,0,0.0911674,"Missing"
J13-3005,P01-1019,0,0.109092,"Missing"
J13-3005,P95-1011,0,0.232963,"Missing"
J13-3005,W02-2233,1,0.737385,"Missing"
J13-3005,C08-1032,1,0.9499,"a modular account of the syntax/semantics interface in which linking constraints can be stipulated separately and reused to specify the various diatheses. In other words, the DYN feature structure allows us to extend the scope of some specific variables so that they can be unified with variables (or values) introduced in some other classes of the metagrammar. This concept of scope extension can be compared with that of hook in Copestake, Lascarides, and Flickinger (2001). 9 For more details on the interpretation of flat semantics and on its association with a grammar of natural language, see Gardent (2008). 601 Computational Linguistics Volume 39, Number 3 Control language. The linguistic units (named Content here) defined by the linguist can be abstracted and combined as follows: C ,...,C → Class ::= Namex11,...,xnk Content ::= SYN, SEM, DYN |Name |Content ∧ Content |Content ∨ Content Content The first clause states that the linguistic information encoded in Content is abstracted in a class named Name and that this class inherits classes C1 ,..., Ck and exports variables x1 ,..., xn . That is, XMG allows for abstraction, inheritance, and variable exports. By default, variables (referring to no"
J13-3005,P07-1042,1,0.873061,"Missing"
J13-3005,P07-2004,1,0.894592,"Missing"
J13-3005,J05-2003,0,0.0673111,"Missing"
J13-3005,kallmeyer-etal-2008-developing,1,0.809222,"roduce a TAG covering the following frames: intransitive (tree family N0V), transitive with a nominal complement (N0VN1), transitive with a clausal complement (N0VS1), transitive with modal complement (N0V0V1), ditransitive (N0VN1N2), ditransitive with a preposition (N0VN1ON2), ditransitive with a verbal complement (N0V0N1V1), ditransitive with an adjectival complement (N0VN1A), movement verbs with a nominal complement (N0V0V1N1), movement verbs with an adjectival complement (N0V0AV1), and movement ditransitive (N0V0N1V1N2). GerTT. Another XMG-based grammar corresponds to the German MC-TAG of Kallmeyer et al. (2008). This grammar, called GerTT, is in fact an MC-TAG with Tree Tuples (Lichte 2007). This variant of MCTAG has been designed to model free word order phenomena. This is done by imposing node sharing constraints on MCTAG derivations (Kallmeyer 2005). GerTT covers phenomena such as scrambling, coherent constructions, relative clauses, embedded questions, copula verbs, complementized sentences, verbs with various sub-categorization frames, nouns, prepositions, determiners, adjectives, and partly includes semantics. It is made of 103 tree tuples, compiled from 109 classes. 7. Related Work We now com"
J13-3005,W04-3325,0,0.0745752,"Missing"
J13-3005,W04-3321,0,0.0685973,"Missing"
J13-3005,W97-1508,0,0.235579,"he modeling of the tree fragment hierarchies required to specify tree-based grammars and of a syntax/semantics interface between semantic representations and syntactic trees. Finally, we briefly report on several grammars for French, English, and German that were implemented using XMG and compare XMG with other existing grammar specification frameworks for tree-based grammars. 1. Introduction In the late 1980s and early 1990s, many grammar engineering environments were developed to support the specification of large computational grammars for natural language. One may, for instance, cite XLE (Kaplan and Newman 1997) for specifying Lexical-Functional Grammars (LFG), LKB (Copestake and Flickinger 2000) for specifying Head-driven Phrase Structure Grammars (HPSG), and D OT CCG (Baldridge et al. 2007) for specifying Combinatory Categorial Grammars (CCG). Concretely, such environments usually rely on (i) a formal language used to describe a target computational grammar, and (ii) a processor for this language, which aims at generating the actual described grammar (and potentially at checking it, e.g., by feeding it to a parser). Although these environments were tailored for specific grammar formalisms, they sha"
J13-3005,C00-1065,0,0.042807,"c formula can be used to underspecify the meaning of the sentence “Every dog chases a cat”: l0 : ∀(x, h1 , h2 ) ∧ l1 ≤ h1 ∧ l3 : ∃(y, h3 , h4 ) ∧ ∧ l1 : Dog(x) l4 ≤ h3 ∧ ∧ l2 ≤ h2 l4 : Cat(y) ∧ ∧ l2 : Chase(x, y) l2 ≤ h4 (14) This formula denotes the following two first-order logic formulae, thereby describing the two possibles readings of this sentence.9 l0 : ∀(x, l1 , l3 ) ∧ l1 : Dog(x) ∧ l2 : Chase(x, y) ∧ l3 : ∃(y, l4 , l2 ) ∧ l4 : Cat(y) (15) l0 : ∀(x, l1 , l2 ) ∧ l1 : Dog(x) ∧ l2 : Chase(x, y) ∧ l3 : ∃(y, l4 , l0 ) ∧ l4 : Cat(y) (16) DYN. The DYN dimension generalizes Kinyon’s hypertag (Kinyon 2000) which is unified whenever two tree fragments are combined. Similarly, in XMG the DYN dimension is a feature structure that is unified whenever two XMG classes are combined through inheritance or through conjunction (see the discussion on XMG control language, subsequently). For instance, the following constraints ensure a coreference between the index I occurring in the syntactic dimension and the argument X occurring in the semantic dimension (indexsubject and arg1 are feature names, and E, I, X, and V local unification variables). C1 → Node [idx : I] ∧ indexsubject : I (17) C2 → L : P(E) ∧"
J13-3005,W06-1503,0,0.051829,"Missing"
J13-3005,C96-2120,0,0.331007,"Missing"
J13-3005,W98-0129,0,0.099141,"ations are usually called reified constraints. 610 Crabb´e et al. XMG: eXtensible MetaGrammar and if this is the case, we add to the input description a strict precedence constraint on these nodes according to their respective values of the property p:19 bn,m ∧ (pn < pm ) ⇒ n ≺+ m (26) bn,m ∧ (pm < pn ) ⇒ m ≺ n (27) + 5.3.3 Adding Color Constraints to Facilitate Grammar Writing. To further ease grammar development, XMG supports a node coloring mechanism that permits nameless node identification (Crabb´e and Duchier 2004), reminiscent of the polarity-based node identification first proposed by Muskens and Krahmer (1998) and later used by Duchier and Thater (1999) and Perrier (2000). Such a mechanism offers an alternative to explicit node identification using equations between node variables. The idea is to label node variables with a color property, whose value (either red, black, or white) can trigger node identifications. This mechanism is another parameter of the tree solver. When in use, the valid tree models must satisfy some color constraints, namely, they must only have red or black nodes (no remaining white nodes; these have to be identified with some black nodes). As shown in the following table, no"
J13-3005,C02-1153,0,0.164995,"le and second, the Passive meta-rule to the base tree. 596 Crabb´e et al. XMG: eXtensible MetaGrammar Passive meta-rule ⇒ Sr ?1 NP? Sr VP V []  mode Wh-Subject meta-rule 3  ?2 NP? VP ⎡ ⎣ ⎣ 3 ⎤ mode 2 passive 1 ⎡ V ?2NP? ↓  mode ?2 NP? ⇒ Sr  ?1 Sq  ?2NP? ↓  wh + NP↓NA ⎦ 1 + mode 2 ppart ?1  ⎤ passive Sr [] ⎦ PP [] P ?1 NP? by Figure 4 Simplified meta-rules for passive and wh-subject extraction. More generally a meta-rule is a procedural device that, given a tree instance, generates a new tree instance by adding, suppressing (hence possibly substituting) information in grammatical units. Prolo (2002) defines a set of meta-rules that can be used to specify a large FB-LTAG for English. Given an ordered set of meta-rules, however, there is no guarantee that the trees they derive are linguistically appropriate and that the derivation process terminates. Thus, to ensure termination and consistency, Prolo needs to additionally provide rule ordering schemes (expressed as automata). 3.2 XMG: Capturing Diathesis Using Disjunction XMG provides an alternative account for describing tree sets such as that of Figure 2 without lexical rules and without the related ordering constraints. In essence, the"
J13-3005,P95-1021,0,0.701406,"Missing"
J13-3005,P84-1075,0,0.45061,"rase Structure Grammars (HPSG), and D OT CCG (Baldridge et al. 2007) for specifying Combinatory Categorial Grammars (CCG). Concretely, such environments usually rely on (i) a formal language used to describe a target computational grammar, and (ii) a processor for this language, which aims at generating the actual described grammar (and potentially at checking it, e.g., by feeding it to a parser). Although these environments were tailored for specific grammar formalisms, they share a number of features. Firstly, they are expressive enough to characterize subsets of natural language. Following Shieber (1984), we call this feature weak completeness. Secondly, they are notationally expressive enough to relatively easily formalize important theoretical notions. Thirdly, they are rigorous, that is, the semantics of their underlying language is well defined and understood. Additionally, for an environment to be useful in practice, it should be simple to use (by a linguist), and make it possible to detect errors in the described target grammar. If we consider a particular type of computational grammar, namely, tree-based grammars—that is, grammars where the basic units are trees (or tree descriptions)"
J13-3005,C88-2147,0,0.90341,"be the same as that of the root node. Substitution inserts a tree onto a substitution node of some other tree and adjunction inserts an auxiliary tree 593 Computational Linguistics Volume 39, Number 3 S N↓ N Marie Mary vu seen V V V V S N↓ N Jean John ∗ ⇒ N Marie Mary V V N V a vu has seen Jean John a has Figure 1 Sample derivation of Marie a vu Jean ‘Mary has seen John’ in a TAG. into a tree. Figure 1 shows a toy TAG generating the sentence Marie a vu Jean ‘Mary has seen John’ and sketches its derivation.1 Among existing variants of TAG, one commonly used in practice is Lexicalized FB-LTAG (Vijay-Shanker and Joshi 1988). A lexicalized TAG is such that each elementary tree has at least one leaf labeled with a lexical item (word), whereas in an FB-LTAG, tree nodes are additionally decorated with two feature structures (called top and bottom). These feature structures are unified during derivation as follows. On substitution, the top features of the substitution node are unified with the top features of the root node of the tree being substituted in. On adjunction, the top features of the root of the auxiliary tree are unified with the top features of the node where adjunction takes place; and the bottom featur"
J13-3005,C92-1034,0,0.421336,"ng Lexical Rules Following Flickinger (1987), redundancy among grammatical descriptions is often handled using two devices: an inheritance hierarchy and a set of lexical rules. Whereas the inheritance hierarchy permits us to encode the sharing of common substructures, lexical rules (sometimes called meta-rules) permit us to capture relationships between trees by deriving new trees from already specified ones. For instance, passive trees will be derived from active ones. Although Flickinger’s (1987) approach was developed for HPSGs, several similar approaches have been put forward for FB-LTAG (Vijay-Shanker and Schabes 1992; Becker 1993; Evans, Gazdar, and Weir 1995; XTAG Research Group 2001). One important drawback of these approaches, however, is that they are procedural in that the order in which lexical rules apply matters. For instance, consider again the set of trees given in Figure 2. In the meta-rule representation scheme adopted by Becker (1993), the base tree (a) would be specified in the inheritance hierarchy grouping all base trees, and the derived trees (b, c, d) would be generated by applying one or more meta-rules on this base tree. Figure 4 sketches these meta-rules. The left-hand side of the met"
J13-3005,W10-4414,0,0.427943,"Missing"
J13-3005,P06-2032,1,\N,Missing
J13-3005,J15-1003,1,\N,Missing
J13-3005,C00-2087,0,\N,Missing
P15-2078,W06-2920,0,0.353304,"Missing"
P15-2078,K15-1025,1,0.825029,"the external dependency to the noun, since the noun phrase can be entirely predicted based on its left corner. The RightNP factor is significant in the fitted model (βRN P = −0.77, p &lt; 0.001).4 The presence of a noun dependent on the right of the noun favours a prenominal placement, as predicted by DLM (1d). This is a result which, to our knowledge, was not previously observed in the literature, and that clearly answers our initial question, confirming that DLM also applies to very short spans. A much more detailed study of the lexical and structural properties of this effect is developed in (Gulordava and Merlo, 2015). 4 A log-likelihood test of the model including RightAP, LeftAP and RightNP factors compared to the model including only RightAP and LeftAP factors yields χ2 = 107 and p &lt; .001. Douglas Bates, Martin Maechler, Ben Bolker, and Steven Walker, 2014. lme4: Linear mixed-effects models using Eigen and S4. R package version 1.17. 4 Conclusion In this paper, we have developed a model of dependency length minimisation in the noun phrase and shown subtle interactions among its subcomponents. We show that most of DLM predictions are confirmed, and that DLM also apply to short spans. The fact that DLM ef"
P15-2078,W09-1201,0,\N,Missing
P15-2078,petrov-etal-2012-universal,0,\N,Missing
P16-1017,W13-4916,0,0.0782411,"Missing"
P16-1017,W14-6110,0,0.146007,"Missing"
P16-1017,D14-1082,0,0.597699,"tures are very important for MRL parsing (Bj¨orkelund et al., 2013; Crabb´e, 2015). However, traditional linear models (such as the structured perceptron) need to define rather complex feature templates to capture interactions between features. Additional morphological features complicate this task (Crabb´e, 2015). Instead, we propose to rely on a neural network weighting function which uses a non-linear hidden layer to automatically capture interactions between variables, and embeds morphological features in a vector space, as is usual for words and other symbols (Collobert and Weston, 2008; Chen and Manning, 2014). The article is structured as follows. In Section 2, we present neural transition-based parsing. Section 3 motivates learning with a dynamic oracle and presents an algorithm to do so. Section 4 introduces the dynamic oracle. Finally, we present parsing experiments in Section 5 to evaluate our proposal. Dynamic oracle training has shown substantial improvements for dependency parsing in various settings, but has not been explored for constituent parsing. The present article introduces a dynamic oracle for transition-based constituent parsing. Experiments on the 9 languages of the SPMRL dataset"
P16-1017,J03-4003,0,0.0481481,"this work) beam=2 beam=4 beam=8 81.14 81.59 81.80 86.45 86.45 86.48 80.32 80.48 80.56 80.68 80.69 80.74 89.06 89.18 89.24 90.74 90.73 90.76 85.17 85.31 85.33 93.15 93.13 93.13 82.65 82.77 82.80 85.48 85.59 85.64 Table 2: Results on development and test corpora. Metrics are provided by evalb spmrl with spmrl.prm parameters (http://www.spmrl.org/spmrl2013-sharedtask.html). † use clusters or word vectors learned on unannotated data. ∗ Bj¨orkelund et al. (2013). (2015), using the alignment between dependency treebanks and constituent treebanks. For English, we used Collins’ head annotation rules (Collins, 2003). Our system is entirely supervised and uses no external data. Every embedding was initialised randomly (uniformly) in the interval [−0.01, 0.01]. Word embeddings have 32 dimensions, tags and non-terminal embeddings have 16 dimensions. The dimensions of the morphological attributes depend on the number of values they can have (Table 4). The hidden layer has 512 units.4 For the ‘dynamic’ setting, we trained every other k sentence with the dynamic oracle and the other sentences with the static oracle. This method, used by Straka et al. (2015), allows for high values of p, without slowing or prev"
P16-1017,D15-1212,1,0.904626,"Missing"
P16-1017,P06-1055,0,0.0239403,"Missing"
P16-1017,C12-1059,0,0.550082,"ed with a dynamic oracle, leads to accuracies comparable with the best non-reranking and non-ensemble parsers. 1 Introduction Constituent parsing often relies on search methods such as dynamic programming or beam search, because the search space of all possible predictions is prohibitively large. In this article, we present a greedy parsing model. Our main contribution is the design of a dynamic oracle for transitionbased constituent parsing. In NLP, dynamic oracles were first proposed to improve greedy dependency parsing training without involving additional computational costs at test time (Goldberg and Nivre, 2012; Goldberg and Nivre, 2013). The training of a transition-based parser involves an oracle, that is a function mapping a configuration to the best transition. Transition-based parsers usually rely on a static oracle, only welldefined for gold configurations, which transforms trees into sequences of gold actions. Training against a static oracle restricts the exploration of the search space to the gold sequence of actions. At test time, due to error propagation, the parser will be in a very different situation than at training time. It will have to infer good actions from noisy configurations. T"
P16-1017,Q13-1033,0,0.118367,"Oracles Maximin Coavoux1,2 and Benoˆıt Crabb´e1,2,3 1 Univ. Paris Diderot, Sorbonne Paris Cit´e 2 Alpage, Inria 3 Institut Universitaire de France maximin.coavoux@inria.fr benoit.crabbe@linguist.univ-paris-diderot.fr Abstract best action given any configuration, by allowing it to explore a greater part of the search space at train time. Dynamic oracles are non-deterministic oracles well-defined for any configuration. They give the best possible transitions for any configuration. Although dynamic oracles are widely used in dependency parsing and available for most standard transition systems (Goldberg and Nivre, 2013; Goldberg et al., 2014; G´omez-Rodr´ıguez et al., 2014; Straka et al., 2015), no dynamic oracle parsing model has yet been proposed for phrase structure grammars. The model we present aims at parsing morphologically rich languages (MRL). Recent research has shown that morphological features are very important for MRL parsing (Bj¨orkelund et al., 2013; Crabb´e, 2015). However, traditional linear models (such as the structured perceptron) need to define rather complex feature templates to capture interactions between features. Additional morphological features complicate this task (Crabb´e, 201"
P16-1017,Q14-1010,0,0.453141,"2 and Benoˆıt Crabb´e1,2,3 1 Univ. Paris Diderot, Sorbonne Paris Cit´e 2 Alpage, Inria 3 Institut Universitaire de France maximin.coavoux@inria.fr benoit.crabbe@linguist.univ-paris-diderot.fr Abstract best action given any configuration, by allowing it to explore a greater part of the search space at train time. Dynamic oracles are non-deterministic oracles well-defined for any configuration. They give the best possible transitions for any configuration. Although dynamic oracles are widely used in dependency parsing and available for most standard transition systems (Goldberg and Nivre, 2013; Goldberg et al., 2014; G´omez-Rodr´ıguez et al., 2014; Straka et al., 2015), no dynamic oracle parsing model has yet been proposed for phrase structure grammars. The model we present aims at parsing morphologically rich languages (MRL). Recent research has shown that morphological features are very important for MRL parsing (Bj¨orkelund et al., 2013; Crabb´e, 2015). However, traditional linear models (such as the structured perceptron) need to define rather complex feature templates to capture interactions between features. Additional morphological features complicate this task (Crabb´e, 2015). Instead, we propose"
P16-1017,P15-2042,0,0.0315569,"Missing"
P16-1017,W05-1513,0,0.307758,"Missing"
P16-1017,P06-2089,0,0.361589,"Missing"
P16-1017,D14-1099,0,0.0285996,"Missing"
P16-1017,P14-1022,0,0.176691,"e. In dependency parsing, several exact dynamic oracles have been proposed for non arcdecomposable transition systems (Goldberg et al., 2014), including systems for non-projective parsing (G´omez-Rodr´ıguez et al., 2014). These oracles rely on tabular methods to compute the cost of transitions and have (high-degree) polynomial worst case running time. Instead, to avoid resorting to more computationally expensive exact methods, we adapt the algorithm in Figure 6 to the constraints involving temporary symbols using the following heuristics: Dev F1 (E VALB) static (this work) dynamic (this work) Hall et al. (2014) Berkeley (Petrov et al., 2006) Durrett and Klein (2015)† Zhu et al. (2013)† Crabb´e (2015) Sagae and Lavie (2006) static (this work) dynamic (this work) D:m,i Ai,k Bk,j 89.2 90.1 91.1 91.3 90.0 85.1 88.0 88.6 CKY CKY CKY beam=16 beam=8 greedy greedy greedy 12 169 1,290 2,150 3,820 3,950 symbol in the binarized tree corresponds to a constituent in the n-ary tree. Head choice In some cases, namely when reducing two non-temporary symbols to a new constituent (X, i, j), the oracle must determine the head position in the reduction (R EDUCE -R IGHT or R EDUCE -L EFT). We used the following heuris"
P16-1017,J93-2004,0,0.0589606,"DUCE -L EFT). We used the following heuristic: if (X, i, j) is in the gold set, choose the same head position, otherwise, predict both RR(X) and RL(X) to keep the non-determinism. 5 Experiments We conducted parsing experiments to evaluate our proposal. We compare two experimental settings. In the ‘static’ setting, the parser is trained only on gold configurations; in the ‘dynamic’ setting, we use the dynamic oracle and the training method in Figure 5 to explore non-gold configurations. We used both the SPMRL dataset (Seddah et al., 2013) in the ‘predicted tag’ scenario, and the Penn Treebank (Marcus et al., 1993), to compare our proposal to existing systems. The tags and morphological attributes were predicted using Marmot (Mueller et al., 2013), by 10-fold jackknifing for the train and development sets. For the SPMRL dataset, the head annotation was carried out with the procedures described in Crabb´e Gold tree Cm,j C:i,j Ai,k greedy greedy Table 3: Results on the Penn Treebank (Marcus et al., 1993). † use clusters or word vectors learned on unannotated data.  different architecture (2.3Ghz Intel), single processor. • When reductions to both temporary symbols and non-temporary symbols have cost zero"
P16-1017,N15-1108,0,0.0272509,"its direct parent. Table 1 shows a summary of the constraints used to ensure that any predicted tree is a wellformed binarized tree.3 In this table, N is the set of non-terminals and Ntmp ⊂ N is the set of temporary non-terminals. } q1 . . . q4 | {z queue } Thus, θ includes the weights and biases for each layer (W(h) , W(o) , b(h) , b(o) ), and the embedding lookup table for each symbol type. We perform greedy search to infer the bestscoring derivation. Note that this is not an exact inference. Most propositions in phrase structure parsing rely on dynamic programming (Durrett and Klein, 2015; Mi and Huang, 2015) or beam search (Crabb´e, 2015; Watanabe and Sumita, 2015; Zhu et al., 2013). However we found that with a scoring function expressive enough and a rich feature set, greedy decoding can be surprisingly accurate (see Section 5). Weighted Parsing The deductive system is inherently non-deterministic. Determinism is provided by a scoring function τ X stack s0.cl[s0.wl] s0.cr[s0.wr] Figure 4: Schematic representation of local elements in a configuration. Figure 3: Examples of ill-formed binary trees s(C0⇒τ ) = {z fθ (Ci−1 , ai ) i=1 where θ is a set of parameters. The score of a derivation decompos"
P16-1017,P15-1113,0,0.0674325,"onstraints used to ensure that any predicted tree is a wellformed binarized tree.3 In this table, N is the set of non-terminals and Ntmp ⊂ N is the set of temporary non-terminals. } q1 . . . q4 | {z queue } Thus, θ includes the weights and biases for each layer (W(h) , W(o) , b(h) , b(o) ), and the embedding lookup table for each symbol type. We perform greedy search to infer the bestscoring derivation. Note that this is not an exact inference. Most propositions in phrase structure parsing rely on dynamic programming (Durrett and Klein, 2015; Mi and Huang, 2015) or beam search (Crabb´e, 2015; Watanabe and Sumita, 2015; Zhu et al., 2013). However we found that with a scoring function expressive enough and a rich feature set, greedy decoding can be surprisingly accurate (see Section 5). Weighted Parsing The deductive system is inherently non-deterministic. Determinism is provided by a scoring function τ X stack s0.cl[s0.wl] s0.cr[s0.wr] Figure 4: Schematic representation of local elements in a configuration. Figure 3: Examples of ill-formed binary trees s(C0⇒τ ) = {z fθ (Ci−1 , ai ) i=1 where θ is a set of parameters. The score of a derivation decomposes as a sum of scores of actions. In practice, we used a"
P16-1017,W09-3825,0,0.19455,"ations derived by the gold action sequence) and returns the unique gold action. Usually, parsers use a static oracle to transform the set of binarized trees into a set D = {C (i) , a(i) }1≤i≤T of training examples. Training consists in minimizh(0) = [v1 ; v2 ; . . . ; vα ] h(1) = max{0, W(h) · h(0) + b(h) } h(2) = Softmax(W(o) · h(1) + b(o) ) fθ (C, a) = log(h(2) a ) 3 There are additional constraints which are not presented here. For example, S HIFT assumes that the buffer is not empty. A full description of constraints typically used in a slightly different transition system can be found in Zhang and Clark (2009)’s appendix section. 174 function TRAIN O NE S ENTENCE(s, θ, p, o) C ← I NITIAL(s) while C is not a final configuration do A ← o(C, s) . set of best actions a ˆ ← argmaxa fθ (C)a if a ˆ ∈ A then t←a ˆ . t: target else t ← argmaxa∈A fθ (C)a ing the negative log likelihood of these examples. The limitation of this training method is that only gold configurations are seen during training. At test time, due to error propagation, the parser will have to predict good actions from noisy configurations, and will have much difficulty to recover after mistakes. To alleviate this problem, a line of work"
P16-1017,P13-1043,0,0.49527,"the set of constituents constructed so far.1 Constituents are instantiated non-terminals, i.e. tuples (X, i, j) such that X is a non-terminal and (i, j) are two integers denoting its span. Although the content of γ could be retrieved from the stack, we make it explicit because it will be useful for the design of the oracle in Section 4. From an initial configuration C0 = h0, , ⊥, ∅i, the parser incrementally derives new configurations by performing actions until a final configuration is reached. S( HIFT ) pops an element from the 2 This transition system is similar to the extended system of Zhu et al. (2013). The main difference is the strategy used to deal with unary reductions. Our strategy ensures that derivations for a sentence all have the same number of steps, which can have an effect when using beam search. We use a G HOST-R EDUCE action, whereas they use a padding strategy with an I DLE action. 1 The introduction of γ is the main difference with Crabb´e (2015)’s transition system. 173 A[h] A[h] A:[h] C:[c] A:[a] C[h] s2.ct[s2.wt] s1.ct[s1.wt] s0.ct[s0.wt] s1.cl[s1.wl] s1.cr[s1.wr] | rary symbols. In the second one, the head of a temporary symbol is not the head of its direct parent. Table"
P16-1017,P15-1147,0,\N,Missing
P16-1017,P15-1030,0,\N,Missing
P16-1017,D13-1032,0,\N,Missing
Q19-1005,E17-1000,0,0.209719,"Missing"
Q19-1005,W04-3224,0,0.088901,"of the art on English and German discontinuous constituency treebanks. We further provide a per-phenomenon analysis of its errors on discontinuous constituents. 1 VP[saw] −→ VP[saw] PP[telescope]. The probability of such a rule models the likelihood that telescope is a suitable modifier for saw. In contrast, unlexicalized parsing models renounce modeling bilexical statistics, based on the assumptions that they are too sparse to be estimated reliably. Indeed, Gildea (2001) observed that removing bilexical statistics from Collins’ (1997) model lead to at most a 0.5 drop in F-score. Furthermore, Bikel (2004) showed that bilexical statistics were in fact rarely used during decoding, and that when used, they were close to that of backoff distributions used for unknown word pairs. Instead, unlexicalized models may rely on grammar rule refinements to alleviate the strong independence assumptions of PCFGs (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006; Narayan and Cohen, 2016). They sometimes rely on structural information, such as the boundaries of constituents (Hall et al., 2014; Durrett and Klein, 2015; Cross and Huang, 2016b; Stern et al., 2017; Kitaev and Klein, 2018). Alth"
Q19-1005,E17-2053,1,0.903976,"Missing"
Q19-1005,W13-4916,0,0.0443769,"Missing"
Q19-1005,D17-1172,0,0.395174,"Missing"
Q19-1005,N16-1024,0,0.328577,"P that gives access to older elements in the stack and can be performed several times before a reduction. In practice, they made the following modifications over a standard shift-reduce system: Figure 1: Tree from the Discontinuous Penn Treebank (Evang and Kallmeyer, 2011). actions (Zhu et al., 2013; Zhang and Clark, 2011, 2009; Crabb´e, 2014; Wang et al., 2015, among others), including proposals for discontinuous constituency parsing (Versley, 2014a; Maier, 2015; Coavoux and Crabb´e, 2017a). A few recent proposals use an unlexicalized model (Watanabe and Sumita, 2015; Cross and Huang, 2016b; Dyer et al., 2016). Interestingly, these latter models all use recurrent neural networks (RNN) to compute constituent representations. Our contributions are the following. We introduce an unlexicalized discontinuous parsing model, as well as its lexicalized counterpart. We evaluate them in identical experimental conditions. Our main finding is that, in our experiments, unlexicalized models consistently outperform lexicalized models. We assess the robustness of this result by performing the comparison of unlexicalized and lexicalized models with a second pair of transition systems. We further analyze the empiric"
Q19-1005,C14-1052,1,0.935422,"Missing"
Q19-1005,W11-2913,0,0.53595,"Missing"
Q19-1005,W13-5701,0,0.49505,"Missing"
Q19-1005,P15-1147,0,0.689312,"model and identify which types of discontinuous constituents are hard to predict. 2 1. The stack, that stores subtrees being constructed, is split into two parts S and D; 2. reductions are applied to the respective tops of S and D; 3. the GAP action pops an element from S and adds it to D, making the next element of S available for a reduction. Related Work Several approaches to discontinuous constituency parsing have been proposed. Hall and Nivre (2008) reduces the problem to non-projective dependency parsing, via a reversible transformation, a strategy developed by Fern´andez-Gonz´alez and Martins (2015) and Corro et al. (2017). Chart parsers are based on probabilistic Linear Context-Free Rewriting Systems (LCFRS) (Evang and Kallmeyer, 2011; Kallmeyer and Maier, 2010), the DataOriented Parsing (DOP) framework (van Cranenburgh and Bod, 2013; van Cranenburgh et al., 2016), or pseudo-projective parsing (Versley, 2016). 74 Their parser outperforms swap-based systems. However, they only experiment with a linear classifier, and assume access to gold part-of-speech (POS) tags for most of their experiments. All these proposals use a lexicalized model, as defined in the introduction: they assign heads"
Q19-1005,P16-2006,0,0.0895632,"7) model lead to at most a 0.5 drop in F-score. Furthermore, Bikel (2004) showed that bilexical statistics were in fact rarely used during decoding, and that when used, they were close to that of backoff distributions used for unknown word pairs. Instead, unlexicalized models may rely on grammar rule refinements to alleviate the strong independence assumptions of PCFGs (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006; Narayan and Cohen, 2016). They sometimes rely on structural information, such as the boundaries of constituents (Hall et al., 2014; Durrett and Klein, 2015; Cross and Huang, 2016b; Stern et al., 2017; Kitaev and Klein, 2018). Although initially coined for chart parsers, the notion of lexicalization naturally transfers to transition-based parsers. We take lexicalized to denote a model that (i) assigns a lexical head to each constituent and (ii) uses heads of constituents as features to score parsing actions. Head assignment is typically performed with REDUCERIGHT and REDUCE-LEFT actions. Most proposals in transition-based constituency parsing since Sagae and Lavie (2005) have used a lexicalized transition system, and features involving heads to score Introduction This"
Q19-1005,D16-1001,0,0.169647,"7) model lead to at most a 0.5 drop in F-score. Furthermore, Bikel (2004) showed that bilexical statistics were in fact rarely used during decoding, and that when used, they were close to that of backoff distributions used for unknown word pairs. Instead, unlexicalized models may rely on grammar rule refinements to alleviate the strong independence assumptions of PCFGs (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006; Narayan and Cohen, 2016). They sometimes rely on structural information, such as the boundaries of constituents (Hall et al., 2014; Durrett and Klein, 2015; Cross and Huang, 2016b; Stern et al., 2017; Kitaev and Klein, 2018). Although initially coined for chart parsers, the notion of lexicalization naturally transfers to transition-based parsers. We take lexicalized to denote a model that (i) assigns a lexical head to each constituent and (ii) uses heads of constituents as features to score parsing actions. Head assignment is typically performed with REDUCERIGHT and REDUCE-LEFT actions. Most proposals in transition-based constituency parsing since Sagae and Lavie (2005) have used a lexicalized transition system, and features involving heads to score Introduction This"
Q19-1005,N18-1091,0,0.0272766,"2017) 4,700 80 260 ≈7.3 Table 5: Running times on development sets of the Tiger and the DPTB, reported in tokens per second (tok/s) and sentences per second (sent/s). Runtimes are only indicative; they are not comparable with those reported by other authors, since they use different hardware. 5.4.1 Effect of Lexicalization parsing results. A possible interpretation is that the bi-LSTM transducer may implicitly learn latent lexicalization, as suggested by Kuncoro et al. (2017), which is consistent with recent analyses of other types of syntactic information captured by LSTMs in parsing models (Gaddy et al., 2018) or language models (Linzen et al., 2016). Lexicalized vs. Unlexicalized Models We first compare the unlexicalized ML-GAP system with the ML-GAP-LEX system (Table 4). The former consistently obtains higher results. The F-score difference is small on English (0.1 to 0.3) but substantial on the German treebanks (more than 1.0 absolute point) and in general on discontinuous constituents (Disc. F). In order to assess the robustness of the advantage of unlexicalized models, we also compare our implementation of SR-GAP (Coavoux and Crabb´e, 2017a)6 with an unlexicalized variant (SR-GAP-UNLEX) that u"
Q19-1005,P03-1013,0,0.67802,"t al., 1993). For the Tiger corpus, we use the Statistical Parsing of Morphologically Rich Languages (SPMRL) split (Seddah et al., 2013). We obtained the dependency labels and the morphological information for each token from the dependency treebank versions of the SPMRL release. We converted the Negra corpus to labeled dependency trees with the DEPSY tool3 in order to annotate each token with a dependency label. We do not predict morphological attributes for the Negra corpus (only POS tags) since only a small section is annotated with a full morphological analysis. We use the standard split (Dubey and Keller, 2003) for this corpus, and no limit on sentence length. For the Penn Treebank, we use the standard split (sections 2-21 for training, 22 for development and 23 for test). We retrieved the dependency labels from the dependency version of the Penn Treebank (PTB), obtained by the Stanford Parser (de Marneffe et al., 2006). We used the relevant module of discodop4 (van Cranenburgh et al., 2016) for evaluation. It provides an F1 measure on labeled constituents, as well as an F1 score computed only on discontinuous constituents (Disc. F1). Following standard practice, we used the evaluation parameters in"
Q19-1005,C18-1258,0,0.366439,"s on the development sets are the ML-GAP (DPTB, Tiger) and the SR-GAP-UNLEX (Negra) models with BASE features. We report their results on the test sets in Table 7. They are compared with other published results: transition-based parsers using a SWAP action (Maier, 2015; Stanojevi´ c and Garrido Alhama, 2017) or a GAP action (Coavoux and Crabb´e, 2017a), the pseudo-projective parser of Versley (2016), parsers based on non-projective dependency parsing (Fern´andez-Gonz´alez and Martins, 2015; Corro et al., 2017), and finally chart parsers based on probabilistic LCFRS (Evang and Kallmeyer, 2011; Gebhardt, 2018) or dataoriented parsing (van Cranenburgh et al., 2016). Note that some of these publications report results in a gold POS-tag scenario, a much easier experimental setup that is not comparable to ours (bottom part of the table). In Table 7, we also indicate models that use a neural scoring system with a ‘∗ ’. Our models obtain state-of-the-art results and outperform every other system, including the LSTM-based parser of Stanojevi´c and Garrido Alhama (2017) that uses a SWAP action to predict discontinuities. This observation confirms in another setting the results of Coavoux and Crabb´e (2017a"
Q19-1005,W01-0521,0,0.0985809,"empirical evidence that lexicalization is not necessary to achieve strong parsing results. Our best unlexicalized model sets a new state of the art on English and German discontinuous constituency treebanks. We further provide a per-phenomenon analysis of its errors on discontinuous constituents. 1 VP[saw] −→ VP[saw] PP[telescope]. The probability of such a rule models the likelihood that telescope is a suitable modifier for saw. In contrast, unlexicalized parsing models renounce modeling bilexical statistics, based on the assumptions that they are too sparse to be estimated reliably. Indeed, Gildea (2001) observed that removing bilexical statistics from Collins’ (1997) model lead to at most a 0.5 drop in F-score. Furthermore, Bikel (2004) showed that bilexical statistics were in fact rarely used during decoding, and that when used, they were close to that of backoff distributions used for unknown word pairs. Instead, unlexicalized models may rely on grammar rule refinements to alleviate the strong independence assumptions of PCFGs (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006; Narayan and Cohen, 2016). They sometimes rely on structural information, such as the boundarie"
Q19-1005,E17-1117,0,0.0900177,"put to a softmax classifier to output a probability distribution over part-of-speech (POS) tags for each token: P (ti = ·|xn1 ; θ t ) = Softmax(W(t) · h(1,i) + b(t) ), where W(t) , b(t) ∈ θ t are parameters. In addition to predicting POS tags, we also predict other morphosyntactic attributes when they are available (i.e., for the Tiger corpus) such as the case, tense, mood, person, and gender, since the POS tagset does not necessarily contain this information. Finally, we predict the syntactic 2 A more involved strategy would be to rely on Recurrent Neural Network Grammars (Dyer et al., 2016; Kuncoro et al., 2017). However, the adaptation of this model to discontinuous parsing is not straightforward and we leave it to future work. 77 functions of tokens, since this auxiliary task has been shown to be beneficial for constituency parsing (Coavoux and Crabb´e, 2017b). For each type of label l, we use a separate softmax classifier, with its own parameters W(l) and b(l) : Configuration: hS |(Is1 , hs1 )|(Is0 , hs0 ), D|(Id1 , hd1 )|(Id0 , hd0 ), i, C i P (li = ·|xn1 ; θ t ) = Softmax(W(l) · h(1,i) + b(l) ). We decompose the probability of a sequence of n actions am 1 = (a1 , a2 , . . . , am ) for a sentence"
Q19-1005,P14-1022,0,0.0354012,"ving bilexical statistics from Collins’ (1997) model lead to at most a 0.5 drop in F-score. Furthermore, Bikel (2004) showed that bilexical statistics were in fact rarely used during decoding, and that when used, they were close to that of backoff distributions used for unknown word pairs. Instead, unlexicalized models may rely on grammar rule refinements to alleviate the strong independence assumptions of PCFGs (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006; Narayan and Cohen, 2016). They sometimes rely on structural information, such as the boundaries of constituents (Hall et al., 2014; Durrett and Klein, 2015; Cross and Huang, 2016b; Stern et al., 2017; Kitaev and Klein, 2018). Although initially coined for chart parsers, the notion of lexicalization naturally transfers to transition-based parsers. We take lexicalized to denote a model that (i) assigns a lexical head to each constituent and (ii) uses heads of constituents as features to score parsing actions. Head assignment is typically performed with REDUCERIGHT and REDUCE-LEFT actions. Most proposals in transition-based constituency parsing since Sagae and Lavie (2005) have used a lexicalized transition system, and feat"
Q19-1005,Q16-1037,0,0.0323314,"times on development sets of the Tiger and the DPTB, reported in tokens per second (tok/s) and sentences per second (sent/s). Runtimes are only indicative; they are not comparable with those reported by other authors, since they use different hardware. 5.4.1 Effect of Lexicalization parsing results. A possible interpretation is that the bi-LSTM transducer may implicitly learn latent lexicalization, as suggested by Kuncoro et al. (2017), which is consistent with recent analyses of other types of syntactic information captured by LSTMs in parsing models (Gaddy et al., 2018) or language models (Linzen et al., 2016). Lexicalized vs. Unlexicalized Models We first compare the unlexicalized ML-GAP system with the ML-GAP-LEX system (Table 4). The former consistently obtains higher results. The F-score difference is small on English (0.1 to 0.3) but substantial on the German treebanks (more than 1.0 absolute point) and in general on discontinuous constituents (Disc. F). In order to assess the robustness of the advantage of unlexicalized models, we also compare our implementation of SR-GAP (Coavoux and Crabb´e, 2017a)6 with an unlexicalized variant (SR-GAP-UNLEX) that uses a single type of reduction (REDUCE) i"
Q19-1005,C10-1061,0,0.452485,"Missing"
Q19-1005,Q17-1029,0,0.0160162,"ework (van Cranenburgh and Bod, 2013; van Cranenburgh et al., 2016), or pseudo-projective parsing (Versley, 2016). 74 Their parser outperforms swap-based systems. However, they only experiment with a linear classifier, and assume access to gold part-of-speech (POS) tags for most of their experiments. All these proposals use a lexicalized model, as defined in the introduction: they assign heads to new constituents and use them as features to inform parsing decisions. Previous work on unlexicalized transition-based parsing models only focused on projective constituency trees (Dyer et al., 2016; Liu and Zhang, 2017). In particular, Cross and Huang (2016b) introduced a system that does not require explicit binarization. Their system decouples the construction of a tree and the labeling of its nodes by assigning types (structure or label) to each action, and alternating between a structural action for even steps and Structural actions SHIFT MERGE GAP Input hS, D, i, C i hS |Is0 , D|Id0 , i, C i hS |Is0 , D, i, C i Labeling actions LABEL-X NO-LABEL Output ⇒ hS |D, {i + 1}, i + 1, C i ⇒ hS |D, Is0 ∪ Id0 , i, C i ⇒ hS, Is0 |D, i, C i Input Output hS, Id0 , i, C i hS, Id0 , i, C i ⇒ hS, Id0 , i, C ∪ {(X, Id0 )"
Q19-1005,P15-1116,0,0.715632,", 2019. Action Editor: Stephen Clark. Submission batch: 9/2018; Revision batch: 11/2018; Published 4/2019. c 2019 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. S ┌─────────┴────┬───────┐ VP │ │ ┌───────────┴───────────── │ ──┐ │ NP NP │ │ ┌──────┼───────────┬─────────┐ │ │ │ DT JJ JJ NN PRP VBZ . │ │ │ │ │ │ │ An excellent environmental actor he is . Some transition-based discontinuous constituency parsers use the swap action, adapted from dependency parsing (Nivre, 2009) either with an easy-first strategy (Versley, 2014a,b) or with a shift-reduce strategy (Maier, 2015; Maier and Lichte, 2016; Stanojevi´c and Garrido Alhama, 2017). Nevertheless, the swap strategy tends to produce long derivations (in number of actions) to construct discontinuous constituents; as a result, the choice of an oracle that minimizes the number of swap actions has a substantial positive effect in accuracy (Maier and Lichte, 2016; Stanojevi´c and Garrido Alhama, 2017). In contrast, Coavoux and Crabb´e (2017a) extended a shift-reduce transition system to handle discontinuous constituents. Their system allows binary reductions to apply to the top element in the stack, and any other e"
Q19-1005,Q16-1023,0,0.226967,"P-LEX with ML-GAP is that there are two MERGE actions, MERGE-LEFT and MERGE-RIGHT, and that each of them assigns the head of the new set of indexes (and implicitly creates a new directed dependency arc): Eager Oracle For the ML-GAP system, we use an oracle that builds every n-ary constituent in a leftto-right fashion, as illustrated by the derivation in Table 2.1 This implicitly corresponds to a left-branching binarization. 4 The statistical model we used is based on a Long Short-Term Memory network (bi-LSTM) transducer that builds context-aware representations for each token in the sentence (Kiperwasser and Goldberg, 2016; Cross and Huang, 2016a). The token representations are then fed as input to (i) a tagging component for assigning POS tags and (ii) a parsing component for scoring parsing hS |(Is0 , hs0 ), D|(Id0 , hd0 ), i, C i • MERGE-LEFT: ⇒ hS |D, (Is0 ∪ Id0 , hs0 ), i, C i; • 3.3 MERGE-RIGHT: Neural Architecture hS |(Is0 , hs0 ), D|(Id0 , hd0 ), i, C i ⇒ hS |D, (Is0 ∪ Id0 , hd0 ), i, C }i. Oracles In this work, we use deterministic static oracles. We briefly describe an oracle that builds constituents from their head outwards (head-driven 1 The systems exhibit spurious ambiguity for constructing n-ary"
Q19-1005,P18-1249,0,0.38624,"re. Furthermore, Bikel (2004) showed that bilexical statistics were in fact rarely used during decoding, and that when used, they were close to that of backoff distributions used for unknown word pairs. Instead, unlexicalized models may rely on grammar rule refinements to alleviate the strong independence assumptions of PCFGs (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006; Narayan and Cohen, 2016). They sometimes rely on structural information, such as the boundaries of constituents (Hall et al., 2014; Durrett and Klein, 2015; Cross and Huang, 2016b; Stern et al., 2017; Kitaev and Klein, 2018). Although initially coined for chart parsers, the notion of lexicalization naturally transfers to transition-based parsers. We take lexicalized to denote a model that (i) assigns a lexical head to each constituent and (ii) uses heads of constituents as features to score parsing actions. Head assignment is typically performed with REDUCERIGHT and REDUCE-LEFT actions. Most proposals in transition-based constituency parsing since Sagae and Lavie (2005) have used a lexicalized transition system, and features involving heads to score Introduction This paper introduces an unlexicalized parsing mode"
Q19-1005,W16-0906,0,0.45093,"n Editor: Stephen Clark. Submission batch: 9/2018; Revision batch: 11/2018; Published 4/2019. c 2019 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. S ┌─────────┴────┬───────┐ VP │ │ ┌───────────┴───────────── │ ──┐ │ NP NP │ │ ┌──────┼───────────┬─────────┐ │ │ │ DT JJ JJ NN PRP VBZ . │ │ │ │ │ │ │ An excellent environmental actor he is . Some transition-based discontinuous constituency parsers use the swap action, adapted from dependency parsing (Nivre, 2009) either with an easy-first strategy (Versley, 2014a,b) or with a shift-reduce strategy (Maier, 2015; Maier and Lichte, 2016; Stanojevi´c and Garrido Alhama, 2017). Nevertheless, the swap strategy tends to produce long derivations (in number of actions) to construct discontinuous constituents; as a result, the choice of an oracle that minimizes the number of swap actions has a substantial positive effect in accuracy (Maier and Lichte, 2016; Stanojevi´c and Garrido Alhama, 2017). In contrast, Coavoux and Crabb´e (2017a) extended a shift-reduce transition system to handle discontinuous constituents. Their system allows binary reductions to apply to the top element in the stack, and any other element in the stack (ins"
Q19-1005,P03-1054,0,0.0781324,"lexicalized parsing models renounce modeling bilexical statistics, based on the assumptions that they are too sparse to be estimated reliably. Indeed, Gildea (2001) observed that removing bilexical statistics from Collins’ (1997) model lead to at most a 0.5 drop in F-score. Furthermore, Bikel (2004) showed that bilexical statistics were in fact rarely used during decoding, and that when used, they were close to that of backoff distributions used for unknown word pairs. Instead, unlexicalized models may rely on grammar rule refinements to alleviate the strong independence assumptions of PCFGs (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006; Narayan and Cohen, 2016). They sometimes rely on structural information, such as the boundaries of constituents (Hall et al., 2014; Durrett and Klein, 2015; Cross and Huang, 2016b; Stern et al., 2017; Kitaev and Klein, 2018). Although initially coined for chart parsers, the notion of lexicalization naturally transfers to transition-based parsers. We take lexicalized to denote a model that (i) assigns a lexical head to each constituent and (ii) uses heads of constituents as features to score parsing actions. Head assignment is typically performed w"
Q19-1005,J93-2004,0,0.0672087,"Section 5.1) and the optimization protocol (Section 5.2). Then, we discuss empirical runtime efficiency (Section 5.3), before presenting the results of our experiments (Section 5.4). Feature Templates The two feature template sets we used are presented in Table 3. The BASE templates form a minimal set that extracts 78 5.1 • The sentence bi-LSTM has 2 layers, with states of size 128 (in each direction); Data To evaluate our models, we used the Negra corpus (Skut et al., 1997), the Tiger corpus (Brants et al., 2002), and the discontinuous version of the Penn Treebank (Evang and Kallmeyer, 2011; Marcus et al., 1993). For the Tiger corpus, we use the Statistical Parsing of Morphologically Rich Languages (SPMRL) split (Seddah et al., 2013). We obtained the dependency labels and the morphological information for each token from the dependency treebank versions of the SPMRL release. We converted the Negra corpus to labeled dependency trees with the DEPSY tool3 in order to annotate each token with a dependency label. We do not predict morphological attributes for the Negra corpus (only POS tags) since only a small section is annotated with a full morphological analysis. We use the standard split (Dubey and Ke"
Q19-1005,P05-1010,0,0.0773827,"s renounce modeling bilexical statistics, based on the assumptions that they are too sparse to be estimated reliably. Indeed, Gildea (2001) observed that removing bilexical statistics from Collins’ (1997) model lead to at most a 0.5 drop in F-score. Furthermore, Bikel (2004) showed that bilexical statistics were in fact rarely used during decoding, and that when used, they were close to that of backoff distributions used for unknown word pairs. Instead, unlexicalized models may rely on grammar rule refinements to alleviate the strong independence assumptions of PCFGs (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006; Narayan and Cohen, 2016). They sometimes rely on structural information, such as the boundaries of constituents (Hall et al., 2014; Durrett and Klein, 2015; Cross and Huang, 2016b; Stern et al., 2017; Kitaev and Klein, 2018). Although initially coined for chart parsers, the notion of lexicalization naturally transfers to transition-based parsers. We take lexicalized to denote a model that (i) assigns a lexical head to each constituent and (ii) uses heads of constituents as features to score parsing actions. Head assignment is typically performed with REDUCERIGHT and REDU"
Q19-1005,W05-1513,0,0.0660551,"ral information, such as the boundaries of constituents (Hall et al., 2014; Durrett and Klein, 2015; Cross and Huang, 2016b; Stern et al., 2017; Kitaev and Klein, 2018). Although initially coined for chart parsers, the notion of lexicalization naturally transfers to transition-based parsers. We take lexicalized to denote a model that (i) assigns a lexical head to each constituent and (ii) uses heads of constituents as features to score parsing actions. Head assignment is typically performed with REDUCERIGHT and REDUCE-LEFT actions. Most proposals in transition-based constituency parsing since Sagae and Lavie (2005) have used a lexicalized transition system, and features involving heads to score Introduction This paper introduces an unlexicalized parsing model and addresses the question of lexicalization, as a parser design choice, in the context of transition-based discontinuous constituency parsing. Discontinuous constituency trees are constituency trees where crossing arcs are allowed in order to represent long-distance dependencies, and in general phenomena related to word order variations (e.g., the left dislocation in Figure 1). Lexicalized parsing models (Collins, 1997; Charniak, 1997) are based o"
Q19-1005,D13-1032,0,0.0771532,"Missing"
Q19-1005,P16-1146,1,0.903564,"Missing"
Q19-1005,W04-0308,0,0.0309462,"ality than those of ML-GAP-LEX (Section 6.1) and are more economical in terms of number of GAP actions needed to derive discontinuous trees (Section 6.2). Corpus Average length of stack (S+D) ML-GAP-LEX English (DPTB) German (Negra) German (Tiger) ML-GAP 5.62 3.69 3.56 4.86 2.88 2.98 Table 8: Incrementality measured by the average size of the stack during derivations. The average is calculated across all configurations (not across all sentences). the constituent. For example, to construct the following head-final NP, NP[actor] 6.1 Incrementality An We adopt the definition of incrementality of Nivre (2004): an incremental algorithm minimizes the number of connected components in the stack during parsing. An unlexicalized system can construct a new constituent by incorporating each new component immediately, whereas a lexicalized system waits until it has shifted the head of a constituent before starting to build excellent environmental actor a lexicalized system must shift every token before starting reductions in order to be able to predict the dependency arcs between the head actor and its three dependents.7 In contrast, an unlexicalized 7 SH(IFT), SH, SH, SH, SH, M(ERGE)-R(IGHT), M-R, M-R, M"
Q19-1005,P09-1040,0,0.107316,"e Paris Diderot. 73 Transactions of the Association for Computational Linguistics, vol. 7, pp. 73–89, 2019. Action Editor: Stephen Clark. Submission batch: 9/2018; Revision batch: 11/2018; Published 4/2019. c 2019 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. S ┌─────────┴────┬───────┐ VP │ │ ┌───────────┴───────────── │ ──┐ │ NP NP │ │ ┌──────┼───────────┬─────────┐ │ │ │ DT JJ JJ NN PRP VBZ . │ │ │ │ │ │ │ An excellent environmental actor he is . Some transition-based discontinuous constituency parsers use the swap action, adapted from dependency parsing (Nivre, 2009) either with an easy-first strategy (Versley, 2014a,b) or with a shift-reduce strategy (Maier, 2015; Maier and Lichte, 2016; Stanojevi´c and Garrido Alhama, 2017). Nevertheless, the swap strategy tends to produce long derivations (in number of actions) to construct discontinuous constituents; as a result, the choice of an oracle that minimizes the number of swap actions has a substantial positive effect in accuracy (Maier and Lichte, 2016; Stanojevi´c and Garrido Alhama, 2017). In contrast, Coavoux and Crabb´e (2017a) extended a shift-reduce transition system to handle discontinuous constituen"
Q19-1005,A97-1014,0,0.605939,"s The experiments we performed aim at assessing the role of lexicalization in transition-based constituency parsing. We describe the data (Section 5.1) and the optimization protocol (Section 5.2). Then, we discuss empirical runtime efficiency (Section 5.3), before presenting the results of our experiments (Section 5.4). Feature Templates The two feature template sets we used are presented in Table 3. The BASE templates form a minimal set that extracts 78 5.1 • The sentence bi-LSTM has 2 layers, with states of size 128 (in each direction); Data To evaluate our models, we used the Negra corpus (Skut et al., 1997), the Tiger corpus (Brants et al., 2002), and the discontinuous version of the Penn Treebank (Evang and Kallmeyer, 2011; Marcus et al., 1993). For the Tiger corpus, we use the Statistical Parsing of Morphologically Rich Languages (SPMRL) split (Seddah et al., 2013). We obtained the dependency labels and the morphological information for each token from the dependency treebank versions of the SPMRL release. We converted the Negra corpus to labeled dependency trees with the DEPSY tool3 in order to annotate each token with a dependency label. We do not predict morphological attributes for the Neg"
Q19-1005,P06-1055,0,0.293192,"xical statistics, based on the assumptions that they are too sparse to be estimated reliably. Indeed, Gildea (2001) observed that removing bilexical statistics from Collins’ (1997) model lead to at most a 0.5 drop in F-score. Furthermore, Bikel (2004) showed that bilexical statistics were in fact rarely used during decoding, and that when used, they were close to that of backoff distributions used for unknown word pairs. Instead, unlexicalized models may rely on grammar rule refinements to alleviate the strong independence assumptions of PCFGs (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006; Narayan and Cohen, 2016). They sometimes rely on structural information, such as the boundaries of constituents (Hall et al., 2014; Durrett and Klein, 2015; Cross and Huang, 2016b; Stern et al., 2017; Kitaev and Klein, 2018). Although initially coined for chart parsers, the notion of lexicalization naturally transfers to transition-based parsers. We take lexicalized to denote a model that (i) assigns a lexical head to each constituent and (ii) uses heads of constituents as features to score parsing actions. Head assignment is typically performed with REDUCERIGHT and REDUCE-LEFT actions. Most"
Q19-1005,P16-2038,0,0.0124849,"ure is trained end-toend. We illustrate the bi-LSTM and the tagging components in Figure 3. In the following paragraphs, we describe the architecture that builds shared representations (Section 4.1), the tagging component (Section 4.2), the parsing component (Section 4.3), and the objective function (Section 4.4). 4.1 (hx1 , hx2 , . . . , hxn ), to obtain vector representations that depend on the whole sentence: (h(1) , . . . , h(n) ) = bi-LSTM(hx1 , hx2 , . . . , hxn ). In practice, we use a two-layer bi-LSTM in order to supervise parsing and tagging at different layers, following results by Søgaard and Goldberg (2016). In what follows, we denote the ith state of the j th layer with h(j,i) . Building Context-aware Token Representations 4.2 We use a hierarchical bi-LSTM (Plank et al., 2016) to construct context-aware vector representations for each token. A lexical entry x is represented by the concatenation hx = [wx ; cx ], where wx is a standard word embedding and cx = bi-LSTM(x) is the output of a character bi-LSTM encoder, i.e., the concatenation of its last forward and backward states. We run a sentence-level bi-LSTM transducer over the sequence of local embeddings Tagger We use the context-aware repres"
Q19-1005,P81-1022,0,0.643966,"Missing"
Q19-1005,D17-1174,0,0.319409,"Missing"
Q19-1005,P17-1076,0,0.0458544,"a 0.5 drop in F-score. Furthermore, Bikel (2004) showed that bilexical statistics were in fact rarely used during decoding, and that when used, they were close to that of backoff distributions used for unknown word pairs. Instead, unlexicalized models may rely on grammar rule refinements to alleviate the strong independence assumptions of PCFGs (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006; Narayan and Cohen, 2016). They sometimes rely on structural information, such as the boundaries of constituents (Hall et al., 2014; Durrett and Klein, 2015; Cross and Huang, 2016b; Stern et al., 2017; Kitaev and Klein, 2018). Although initially coined for chart parsers, the notion of lexicalization naturally transfers to transition-based parsers. We take lexicalized to denote a model that (i) assigns a lexical head to each constituent and (ii) uses heads of constituents as features to score parsing actions. Head assignment is typically performed with REDUCERIGHT and REDUCE-LEFT actions. Most proposals in transition-based constituency parsing since Sagae and Lavie (2005) have used a lexicalized transition system, and features involving heads to score Introduction This paper introduces an u"
Q19-1005,P15-1113,0,0.039029,"Missing"
Q19-1005,W14-6104,0,0.708559,"on for Computational Linguistics, vol. 7, pp. 73–89, 2019. Action Editor: Stephen Clark. Submission batch: 9/2018; Revision batch: 11/2018; Published 4/2019. c 2019 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. S ┌─────────┴────┬───────┐ VP │ │ ┌───────────┴───────────── │ ──┐ │ NP NP │ │ ┌──────┼───────────┬─────────┐ │ │ │ DT JJ JJ NN PRP VBZ . │ │ │ │ │ │ │ An excellent environmental actor he is . Some transition-based discontinuous constituency parsers use the swap action, adapted from dependency parsing (Nivre, 2009) either with an easy-first strategy (Versley, 2014a,b) or with a shift-reduce strategy (Maier, 2015; Maier and Lichte, 2016; Stanojevi´c and Garrido Alhama, 2017). Nevertheless, the swap strategy tends to produce long derivations (in number of actions) to construct discontinuous constituents; as a result, the choice of an oracle that minimizes the number of swap actions has a substantial positive effect in accuracy (Maier and Lichte, 2016; Stanojevi´c and Garrido Alhama, 2017). In contrast, Coavoux and Crabb´e (2017a) extended a shift-reduce transition system to handle discontinuous constituents. Their system allows binary reductions to apply"
Q19-1005,W09-3825,0,0.19973,"Missing"
Q19-1005,J11-1005,0,0.0143519,"discontinuous constituents. Their system allows binary reductions to apply to the top element in the stack, and any other element in the stack (instead of the two top elements in standard shift-reduce parsing). The second constituent for a reduction is chosen dynamically, with an action called GAP that gives access to older elements in the stack and can be performed several times before a reduction. In practice, they made the following modifications over a standard shift-reduce system: Figure 1: Tree from the Discontinuous Penn Treebank (Evang and Kallmeyer, 2011). actions (Zhu et al., 2013; Zhang and Clark, 2011, 2009; Crabb´e, 2014; Wang et al., 2015, among others), including proposals for discontinuous constituency parsing (Versley, 2014a; Maier, 2015; Coavoux and Crabb´e, 2017a). A few recent proposals use an unlexicalized model (Watanabe and Sumita, 2015; Cross and Huang, 2016b; Dyer et al., 2016). Interestingly, these latter models all use recurrent neural networks (RNN) to compute constituent representations. Our contributions are the following. We introduce an unlexicalized discontinuous parsing model, as well as its lexicalized counterpart. We evaluate them in identical experimental condition"
Q19-1005,W16-0907,0,0.438152,"f S available for a reduction. Related Work Several approaches to discontinuous constituency parsing have been proposed. Hall and Nivre (2008) reduces the problem to non-projective dependency parsing, via a reversible transformation, a strategy developed by Fern´andez-Gonz´alez and Martins (2015) and Corro et al. (2017). Chart parsers are based on probabilistic Linear Context-Free Rewriting Systems (LCFRS) (Evang and Kallmeyer, 2011; Kallmeyer and Maier, 2010), the DataOriented Parsing (DOP) framework (van Cranenburgh and Bod, 2013; van Cranenburgh et al., 2016), or pseudo-projective parsing (Versley, 2016). 74 Their parser outperforms swap-based systems. However, they only experiment with a linear classifier, and assume access to gold part-of-speech (POS) tags for most of their experiments. All these proposals use a lexicalized model, as defined in the introduction: they assign heads to new constituents and use them as features to inform parsing decisions. Previous work on unlexicalized transition-based parsing models only focused on projective constituency trees (Dyer et al., 2016; Liu and Zhang, 2017). In particular, Cross and Huang (2016b) introduced a system that does not require explicit b"
Q19-1005,P13-1043,0,0.0839876,"n system to handle discontinuous constituents. Their system allows binary reductions to apply to the top element in the stack, and any other element in the stack (instead of the two top elements in standard shift-reduce parsing). The second constituent for a reduction is chosen dynamically, with an action called GAP that gives access to older elements in the stack and can be performed several times before a reduction. In practice, they made the following modifications over a standard shift-reduce system: Figure 1: Tree from the Discontinuous Penn Treebank (Evang and Kallmeyer, 2011). actions (Zhu et al., 2013; Zhang and Clark, 2011, 2009; Crabb´e, 2014; Wang et al., 2015, among others), including proposals for discontinuous constituency parsing (Versley, 2014a; Maier, 2015; Coavoux and Crabb´e, 2017a). A few recent proposals use an unlexicalized model (Watanabe and Sumita, 2015; Cross and Huang, 2016b; Dyer et al., 2016). Interestingly, these latter models all use recurrent neural networks (RNN) to compute constituent representations. Our contributions are the following. We introduce an unlexicalized discontinuous parsing model, as well as its lexicalized counterpart. We evaluate them in identical"
Q19-1005,P97-1003,0,\N,Missing
Q19-1005,D16-1257,0,\N,Missing
W02-2233,C94-2149,0,0.0841195,"Missing"
W02-2233,C00-1065,0,0.427079,"Missing"
W02-2233,bonhomme-lopez-2000-resources,0,0.0307854,"Missing"
W02-2233,C92-1034,0,0.416389,"Missing"
W06-1502,W02-2233,1,0.887812,"Missing"
W06-1502,2006.jeptalnrecital-long.12,0,0.101658,"Missing"
W06-3504,A00-2008,0,0.361836,"gates how to extend coverage of a domain independent lexicon tailored for natural language understanding. We introduce two algorithms for adding lexical entries from V ERB N ET to the lexicon of the T RIPS spoken dialogue system. We report results on the efficiency of the method, discussing in particular precision versus coverage issues and implications for mapping to other lexical databases. 1 Introduction This paper explores how different lexicons can be integrated with the goal of extending coverage of a deep parser and semantic interpreter. Lexical semantic databases (Kipper et al., 2000; Johnson and Fillmore, 2000; Dorr, 1997) use a frame-based model of lexical semantics. Each database groups words in classes where predicative words and their arguments are described. The classes are generally organised in an inheritance structure. Each such database can be used, among other things, to perform semantic interpretation. However, their actual structures are quite different, reflecting different underlying methodological approaches to lexical description, and this results in representation that are not directly compatible. Since no such database has full coverage of English, it is worth combining them in or"
W06-3504,P98-1013,0,0.0446515,"ased on a simplified version of F RAME N ET source Grammar (Copestake and Flickinger, 2000) build deep semantic representations which account for scoping and temporal structure, their lexicons do not provide information related to word senses and role labels, in part due to the additional difficulty involved building a wide coverage lexicon with the necessary lexical semantic information. 26 The tourists admired the paintings LSUBJ LOBJ LF::Experiencer-Emotion LF::Experiencer LF::Theme Figure 1: Information in the T RIPS word sense definition for mapping between syntactic and semantic roles. (Baker et al., 1998; Dzikovska et al., 2004), with each LF type describing a particular situation, object or event and its participants. Syntax-Semantics Templates (or templates) capture the linking between the syntax and semantics (LF type and semantic roles) of a word. The semantic properties of an argument are described by means of a semantic role assigned to it and selectional restrictions.2 The T RIPS grammar contains a set of independently described lexical rules, such as the passive or dative shift rules, which are designed to create noncanonical lexical entries automatically, while preserving the linking"
W06-3504,copestake-flickinger-2000-open,0,0.0569589,"ental growth, since the lexical representation is domainindependent and the added words are then re-used in new domains. A graphical representation of the information stored in the TRIPS lexicon and used in parsing is shown in Figure 1. The lexicon is a list of canonical word entries each of which is made of a set of sense definitions comprised of a LF type and a syntax-semantic template. Semantic classes (LF types) in the T RIPS lexicon are organised in a domain-independent ontology (the LF ontology). The LF Ontology was originally based on a simplified version of F RAME N ET source Grammar (Copestake and Flickinger, 2000) build deep semantic representations which account for scoping and temporal structure, their lexicons do not provide information related to word senses and role labels, in part due to the additional difficulty involved building a wide coverage lexicon with the necessary lexical semantic information. 26 The tourists admired the paintings LSUBJ LOBJ LF::Experiencer-Emotion LF::Experiencer LF::Theme Figure 1: Information in the T RIPS word sense definition for mapping between syntactic and semantic roles. (Baker et al., 1998; Dzikovska et al., 2004), with each LF type describing a particular situ"
W06-3504,W04-2604,0,0.0156235,"create noncanonical lexical entries automatically, while preserving the linking properties defined in the canonical entry. In this context adding an entry to the lexicon requires determining both the list of LF types and the list of templates for canonical contexts, that is, the list of mappings between a logical frame and a canonical subcategorization frame. 3 V ERB N ET V ERB N ET (Kipper et al., 2000) provides an actual implementation of the descriptive work carried out by Levin (1993), which has been extended to cover prepositional constructions and corpus-based subcategorization frames (Kipper et al., 2004; Kipper et al., 2006). V ERB N ET is a hierarchical verb lexicon in which verbs are organised in classes. The fundamental assumption underlying the classification is that the members of a given class share a similar syntactic 2 The selectional restrictions are domain independent and specified using features derived from EuroWordNet (Vossen, 1997; Dzikovska et al., to appear). behaviour, that is, they pattern in the same set of alternations, and are further assumed to share common semantic properties.3 V ERB N ET classes are organised in an inheritance hierarchy. Each class includes a set of m"
W06-3504,kipper-etal-2006-extending,0,0.0221897,"Missing"
W06-3504,C04-1100,0,0.0136484,"our experiment. The T RIPS lexicon is used together with a parser to provide a natural language understanding component for several dialogue applications in different domains. It outputs highly detailed semantic representations suitable for complex dialogue tasks such as problem-solving and tutoring dialogue, inter alia. An essential feature of T RIPS is the integration of a detailed lexical semantic representation, semantic classes and theta role assignments in the parsing process. Semantic types and role labelling are helpful in both deep (Tetreault, 2005) and shallow interpretation tasks (Narayanan and Harabagiu, 2004). T RIPS provides a convenient test case because its grammar is already equipped with the formal devices required to build up a frame-based semantic representation including this information.1 1 While wide coverage grammars such as the English ReProceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 25–32, c New York City, June 2006. 2006 Association for Computational Linguistics We chose V ERB N ET to extend the T RIPS lexicon because it includes a detailed syntax-semantic mappings, thus providing a more convenient interface to the syntactic component of the grammar"
W06-3504,C98-1013,0,\N,Missing
W09-1008,schluter-van-genabith-2008-treebank,0,\N,Missing
W09-1008,A00-2018,0,\N,Missing
W09-1008,J98-4004,0,\N,Missing
W09-1008,J04-4004,0,\N,Missing
W09-1008,W01-0521,0,\N,Missing
W09-1008,W06-1614,0,\N,Missing
W09-1008,J03-4003,0,\N,Missing
W09-1008,P03-1054,0,\N,Missing
W09-1008,P05-1038,0,\N,Missing
W09-1008,A00-1031,0,\N,Missing
W09-1008,P06-1055,0,\N,Missing
W09-1008,P05-1010,0,\N,Missing
W09-1008,P03-1013,0,\N,Missing
W09-1008,W04-3224,0,\N,Missing
W09-1008,N06-1020,0,\N,Missing
W09-3821,J92-4003,0,0.385914,"instance among a cluster of infinite verbs, one may find a present participle). The quality of the clusters is more crucial in our case than when clusters are features, whose informativity is discriminatively learnt. This observation led us to append a restricted set of suffixes to the clusters, which gives us the best results for now. token of a sentence, if unknown in the lexicon, the algorithm tries to desinflect the low case corresponding form. This desinflection reduces the number of distinct tokens in the F TB - UC from 27143 to 20268. 4 Unsupervised word clustering We chose to use the (Brown et al., 1992) hard clustering algorithm, which has proven useful for various NLP tasks, such as dependency parsing (Koo et al., 2008) or named entity recognition (Liang, 2005). The algorithm to obtain C clusters is as follows: each of the C most frequent tokens of the corpus is assigned its own distinct cluster. For the (C+1)th most frequent token, create a (C+1)th cluster. Then for each pair among the C+1 resulting clusters, merge the pair that minimizes the loss in the likelihood of the corpus, according to a bigram language model defined on the clusters. Repeat this operation for the (C+2)th most freque"
W09-3821,W09-1008,1,0.880808,"Missing"
W09-3821,W01-0521,0,0.187706,"Missing"
W09-3821,E09-1038,0,0.114879,"Missing"
W09-3821,P08-1068,0,0.747933,"o reported a slight improvement (F1 =88.18) when word forms are clustered on a morphological basis, into lemma+tag clusters. So PCFG-LA uses lexical information, but it is too sparse, hence it benefits from word clustering. Yet the use of lemma+tag terminals supposes tagging prior to parsing. We propose here to apply rather a deterministic supervised morphological clustering that preserves tagging ambiguities, leaving it to the parser to disambiguate POS tags. We also investigate the use of unsupervised word clustering, obtained from unannotated text. It has been proved useful for parsing by (Koo et al., 2008) and their work directly inspired ours. They have shown that parsing improves when cluster information is used as features in a discriminative training method that learns dependency parsers. We investigate in this paper the use of such clusters in a generative approach to probabilistic phrase-structure parsing, simply by replacing each token by its cluster. We present a semi-supervised method to improve statistical parsing performance. We focus on the well-known problem of lexical data sparseness and present experiments of word clustering prior to parsing. We use a combination of lexiconaided"
W09-3821,P98-2127,0,0.130231,"Missing"
W09-3821,P05-1010,0,0.104312,"ation is known crucial in natural language parsing. For probabilistic parsing, one main drawback of the plain PCFG approach is to lack sensitivity to the lexicon. The symbols accessible to context-free rules are part-of-speech tags, which encode generalizations that are too coarse for many parsing decisions (for instance subcategorization information is generally absent from tagsets). The lexicalized models first proposed by Collins reintroduced words at every depth of a parse tree, insuring that attachments receive probabilities that take lexical information into account. On the other hand, (Matsuzaki et al., 2005) have proposed probabilistic CFG learning with latent annotation (hereafter PCFG-LA), as a way to automate symbol splitting in unlexicalized probabilistic parsing (cf. adding latent annotations to a symbol is comparable to splitting this symbol). 138 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 138–141, c Paris, October 2009. 2009 Association for Computational Linguistics 3 Morphological clustering tering using lemmas is not possible, since lemma assignment supposes POS disambiguation. Further, information such as mood on verbs is necessary to capture"
W09-3821,P06-1055,0,0.0199032,"n be identified by its path within this binary tree. Hence, clusters can be used at various levels of granularity. 5 Experiments and discussion For the Brown clustering algorithm, we used Percy Liang’s code3 , run on the L’Est Républicain corpus, a 125 million word journalistic corpus, freely available at CNRTL4. The corpus was tokenised5 , segmented into sentences and desinflected using the process described in section 3. We ran the clustering into 1000 clusters for the desinflected forms appearing at least 20 times. We tested the use of word clusters for parsing with the Berkeley algorithm (Petrov et al., 2006). Clustering words in this case has a double advantage. First, it augments the known vocabulary, which is made of all the forms of all the clusters appearing in the treebank. Second, it reduces sparseness for the latent annotations learning on the lexical rules of the PCFG-LA grammar. 6 Related work We already mentioned that we were inspired by the success of (Koo et al., 2008) in using word clusters as features for the discriminative learning of dependency parsers. Another approach to augment the known vocabulary for a generative prob6 In all metrics punctuation tokens are ignored and all res"
W09-3821,C98-2122,0,\N,Missing
W09-3821,sagot-etal-2006-lefff,0,\N,Missing
W09-3824,abeille-barrier-2004-enriching,0,0.0870136,"this question, this paper reports a set of experiments where five algorithms, first designed for the purpose of parsing English, have been adapted to French: a P CFG parser with latent annotation (Petrov et al., 2006), a Stochastic Tree Adjoining Grammar parser (Chiang, 2003), the Charniak’s lexicalized parser (Charniak, 2000) and the Bikel’s implementation of Collins’ Model 1 and 2 (Collins, 1999) described in (Bikel, 2002). To ease further comparisons, we report results on two versions of the treebank: (1) the last version made available in December 2007, hereafter F TB , and described in (Abeillé and Barrier, 2004) and the (2) L FG inspired version of (Schluter and van Genabith, 2007). The paper is structured as follows : After a brief presentation of the treebanks, we discuss the useThis paper presents preliminary investigations on the statistical parsing of French by bringing a complete evaluation on French data of the main probabilistic lexicalized and unlexicalized parsers first designed on the Penn Treebank. We adapted the parsers on the two existing treebanks of French (Abeillé et al., 2003; Schluter and van Genabith, 2007). To our knowledge, mostly all of the results reported here are state-of-th"
W09-3824,P05-1038,0,0.0683898,"zation for the parsing of French. 1 Introduction The development of large scale symbolic grammars has long been a lively topic in the French NLP community. Surprisingly, the acquisition of probabilistic grammars aiming at stochastic parsing, using either supervised or unsupervised methods, has not attracted much attention despite the availability of large manually syntactic annotated data for French. Nevertheless, the availability of the Paris 7 French Treebank (Abeillé et al., 2003), allowed (Dybro-Johansen, 2004) to carry out the extraction of a Tree Adjoining Grammar (Joshi, 1987) and led (Arun and Keller, 2005) 1 This has been made available in December 2007. 150 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 150–161, c Paris, October 2009. 2009 Association for Computational Linguistics fulness of testing different parsing frameworks over two parsing paradigms before introducing our experimental protocol and presenting our results. Finally, we discuss and compare with related works on cross-language parser adaptation, then we conclude. 2 Treebanks for French This section provides a brief overview to the corpora on which we report results: the French Treebank ("
W09-3824,H91-1060,0,0.121862,"Missing"
W09-3824,P04-1041,0,0.0395878,"Missing"
W09-3824,W08-2102,0,0.0249898,"no substitution node. Moreover, the probability model, being split between lexical anchors and tree templates, allows a very coarse grammar that contains, for example, only 83 tree templates for one treebank instantiation, namely the F TB - CC (cf. section 5). This behavior, although not documented10 , is close to Collins’ model 1, which does not use any argument adjunct distinction information, and led to results interesting enough to be integrated as the “Chiang Spinal” model in our parser set. It should be noted that, recently, the use of similar models has been independently proposed in (Carreras et al., 2008) with the purpose of getting a richer parsing model that can use non local features and in (Sangati and Zuidema, 2009) as a mean of extracting a Lexicalized Tree Substitution Grammar. In their process, the first extracted grammar is actually a spinal STIG. 4 Experimental protocol In this section, we specify the settings of the parsers for French, the evaluation protocol and the different instantiations of the treebanks we used for conducting the experiments. 4.1 Parsers settings Head Propagation table All lexicalized parsers reported in this paper use head propagation tables. Adapting them to"
W09-3824,A00-2018,0,0.849433,"set of trees. This path has the advantage of an easier reproducibility and eases verification of reported results. With the problem of the usability of the data source being solved, the question of finding one or many accurate language models for parsing French raises. Thus, to answer this question, this paper reports a set of experiments where five algorithms, first designed for the purpose of parsing English, have been adapted to French: a P CFG parser with latent annotation (Petrov et al., 2006), a Stochastic Tree Adjoining Grammar parser (Chiang, 2003), the Charniak’s lexicalized parser (Charniak, 2000) and the Bikel’s implementation of Collins’ Model 1 and 2 (Collins, 1999) described in (Bikel, 2002). To ease further comparisons, we report results on two versions of the treebank: (1) the last version made available in December 2007, hereafter F TB , and described in (Abeillé and Barrier, 2004) and the (2) L FG inspired version of (Schluter and van Genabith, 2007). The paper is structured as follows : After a brief presentation of the treebanks, we discuss the useThis paper presents preliminary investigations on the statistical parsing of French by bringing a complete evaluation on French da"
W09-3824,C02-1126,0,0.0564763,"Missing"
W09-3824,N06-1020,0,0.0337046,"as well as (Bikel, 2002)’s implementation of the Collins’ models 1 & 2 (Collins, 1999). Most of the lexicalized parsers we use in this work are well known and since their releases, almost ten years ago, their core parsing models still provide state-of-the-art performance on the standard test set for English.6 We insist on the fact that one of the goals of this work was to evaluate raw performance of well known parsing models on French annotated data. Thus, we have not considered using more complex parsing architectures that makes use of reranking (Charniak and Johnson, 2005) or self-training (McClosky et al., 2006) in order to improve the performance of a raw parsing model. Furthermore, studying and designing a set of features for a reranking parser was beyond the scope of this work. However, we did use some of these models in a non classical way, leading us to explore a Collins’ model 2 variation, named model X, and a Stochastic Tree Adjoining Grammar (Schabes, 1992; Resnik, 1992) variant7 , named Spinal Stochastic Tree Insertion Grammars (hereafter S PINAL S TIG), which was first used to validate the heuristics used by our adaptation of the Bikel’s parser to French. The next two subsections introduce"
W09-3824,P06-1055,0,0.133959,"a new released and corrected version of the treebank1 it was possible to train statistical parsers from the original set of trees. This path has the advantage of an easier reproducibility and eases verification of reported results. With the problem of the usability of the data source being solved, the question of finding one or many accurate language models for parsing French raises. Thus, to answer this question, this paper reports a set of experiments where five algorithms, first designed for the purpose of parsing English, have been adapted to French: a P CFG parser with latent annotation (Petrov et al., 2006), a Stochastic Tree Adjoining Grammar parser (Chiang, 2003), the Charniak’s lexicalized parser (Charniak, 2000) and the Bikel’s implementation of Collins’ Model 1 and 2 (Collins, 1999) described in (Bikel, 2002). To ease further comparisons, we report results on two versions of the treebank: (1) the last version made available in December 2007, hereafter F TB , and described in (Abeillé and Barrier, 2004) and the (2) L FG inspired version of (Schluter and van Genabith, 2007). The paper is structured as follows : After a brief presentation of the treebanks, we discuss the useThis paper presents"
W09-3824,D07-1066,0,0.0373258,"Missing"
W09-3824,P03-1013,0,0.012629,"vercome P CFG’s problems (a) and (b)5 . M FT 4739 28.38 2.11 6944 39 27 3.1 Lexicalized algorithms The first class of algorithms used are lexicalized parsers of (Collins, 1999; Charniak, 2000; Chiang, 2003). The insight underlying the lexicalized algorithms is to model lexical dependencies between a governor and its dependants in order to improve attachment choices. Even though it has been proven numerous times that lexicalization was useful for parsing the Wall Street Journal corpus (Collins, 1999; Charniak, 2000), the question of its relevance for other languages has been raised for German (Dubey and Keller, 2003; Kübler et al., 2006) and for French Table 1: Treebanks Properties 3 F TB A ADV C CL D ET I N P P+D P+PRO PONCT PREF PRO V Parsing Algorithms Although Probabilistic Context Free Grammars (P CFG) are a baseline formalism for probabilistic parsing, it is well known that they suffer from two problems: (a) The independence assumptions made by the model are too strong, and (b) For Natural Language Parsing, they do not take into account lexical probabilities. To date, most of the results on statistical parsing have been reported for English. Here we propose to investigate how to apply these techniq"
W09-3824,E09-1080,0,0.0120162,"lows a very coarse grammar that contains, for example, only 83 tree templates for one treebank instantiation, namely the F TB - CC (cf. section 5). This behavior, although not documented10 , is close to Collins’ model 1, which does not use any argument adjunct distinction information, and led to results interesting enough to be integrated as the “Chiang Spinal” model in our parser set. It should be noted that, recently, the use of similar models has been independently proposed in (Carreras et al., 2008) with the purpose of getting a richer parsing model that can use non local features and in (Sangati and Zuidema, 2009) as a mean of extracting a Lexicalized Tree Substitution Grammar. In their process, the first extracted grammar is actually a spinal STIG. 4 Experimental protocol In this section, we specify the settings of the parsers for French, the evaluation protocol and the different instantiations of the treebanks we used for conducting the experiments. 4.1 Parsers settings Head Propagation table All lexicalized parsers reported in this paper use head propagation tables. Adapting them to the French language requires to design French specific head propagation rules. To this end, we used those described by"
W09-3824,J98-4004,0,0.0648842,"kes advantage of the function labels annotated in the treebank. This is one of the main differences with the experiments described in (Arun and Keller, 2005) and (DybroJohansen, 2004) where the authors had to rely only on the very flat treebank structure without function labels, to annotate the arguments of a head. 3.2 Unlexicalized Parser As an instance of an unlexicalized parser, the last algorithm we use is the Berkeley unlexicalized parser (B KY) of (Petrov et al., 2006). This algorithm is an evolution of treebank transformation principles aimed at reducing P CFG independence assumptions (Johnson, 1998; Klein and Manning, 2003). Treebank transformations may be of two kinds (1) structure transformation and (2) labelling transformations. The Berkeley parser concentrates on (2) by recasting the problem of acquiring an optimal set of non terminal symbols as an semisupervised learning problem by learning a P CFG with Latent annotations (P CFG -L A): given an observed P CFG induced from the treebank, the latent grammar is generated by combining every non terminal of the observed grammar to a predefined set H of latent symbols. The parameters of the latent grammar are estimated from the actual tre"
W09-3824,J95-4002,0,0.210274,"arsing Algorithms Although Probabilistic Context Free Grammars (P CFG) are a baseline formalism for probabilistic parsing, it is well known that they suffer from two problems: (a) The independence assumptions made by the model are too strong, and (b) For Natural Language Parsing, they do not take into account lexical probabilities. To date, most of the results on statistical parsing have been reported for English. Here we propose to investigate how to apply these techniques to another language – French – by testing two distinct enhancements 5 Except (Chiang, 2003) which is indeed a T REE I N (Schabes and Waters, 1995) parser but which must extract a lexicalized grammar from the set of context free rules underlying a treebank. SERTION GRAMMAR 153 a lexicalized PCFG can roughly be described as a set of stochastic rules of the form: P → Ln Ln−1 ..L1 H R1 .. Rm−1 Rm where Li , H, Ri and P are all lexicalized non terminals; P inherits its head from H (Bikel, 2004). The Collins’ model 2 deterministically labels some nodes of a rule to be arguments of a given Head and the remaining nodes are considered to be modifier non terminals (hereafter MNT). In this model, given a left-hand side symbol, the head and its arg"
W09-3824,C92-2066,0,0.129055,"Missing"
W09-3824,P03-1054,0,0.0141452,"f the function labels annotated in the treebank. This is one of the main differences with the experiments described in (Arun and Keller, 2005) and (DybroJohansen, 2004) where the authors had to rely only on the very flat treebank structure without function labels, to annotate the arguments of a head. 3.2 Unlexicalized Parser As an instance of an unlexicalized parser, the last algorithm we use is the Berkeley unlexicalized parser (B KY) of (Petrov et al., 2006). This algorithm is an evolution of treebank transformation principles aimed at reducing P CFG independence assumptions (Johnson, 1998; Klein and Manning, 2003). Treebank transformations may be of two kinds (1) structure transformation and (2) labelling transformations. The Berkeley parser concentrates on (2) by recasting the problem of acquiring an optimal set of non terminal symbols as an semisupervised learning problem by learning a P CFG with Latent annotations (P CFG -L A): given an observed P CFG induced from the treebank, the latent grammar is generated by combining every non terminal of the observed grammar to a predefined set H of latent symbols. The parameters of the latent grammar are estimated from the actual treebank Morphology and typog"
W09-3824,schluter-van-genabith-2008-treebank,0,0.0277974,"Missing"
W09-3824,W06-1614,0,0.0574525,"(a) and (b)5 . M FT 4739 28.38 2.11 6944 39 27 3.1 Lexicalized algorithms The first class of algorithms used are lexicalized parsers of (Collins, 1999; Charniak, 2000; Chiang, 2003). The insight underlying the lexicalized algorithms is to model lexical dependencies between a governor and its dependants in order to improve attachment choices. Even though it has been proven numerous times that lexicalization was useful for parsing the Wall Street Journal corpus (Collins, 1999; Charniak, 2000), the question of its relevance for other languages has been raised for German (Dubey and Keller, 2003; Kübler et al., 2006) and for French Table 1: Treebanks Properties 3 F TB A ADV C CL D ET I N P P+D P+PRO PONCT PREF PRO V Parsing Algorithms Although Probabilistic Context Free Grammars (P CFG) are a baseline formalism for probabilistic parsing, it is well known that they suffer from two problems: (a) The independence assumptions made by the model are too strong, and (b) For Natural Language Parsing, they do not take into account lexical probabilities. To date, most of the results on statistical parsing have been reported for English. Here we propose to investigate how to apply these techniques to another languag"
W09-3824,I08-3008,0,0.0258923,"’ S MODEL 1, S PINAL S TIG, C HAR NIAK and B KY ). For this earlier experiment, our implementation of the C OLLINS MODEL 1 actually corresponds to the MODEL X without an argument adjunct distinction table. More precisely, the absence of argument nodes, used for the acquisition of subcategorization frames features, makes the M ODEL X parsing model consider all the nodes of a rule, ex15 Due to the lack of function annotation labels in this treebank, (Arun and Keller, 2005)’s argument distinction table was used for this experiment. 16 Note that the C HARNIAK’s parser has been adapted for Danish (Zeman and Resnik, 2008) ; the authors report a 80.20 F1 score for a specific instance of the Danish Treebank. PARSER Arun (acl05) Arun (this paper) Schluter (pacling07) Collins (Mx) Collins (M2) Collins (M1) Charniak Chiang (Sp) Bky F TBA RUN 80.45 81.08 81.5 79.36 77.82 82.35 80.94 84.03 M FT S CHLU 79.95 80,96 79,91 82,66 81,86 82.86 Table 6: Labeled bracket scores on Arun’s F TB version and on the M FT In order to favour a “fair” comparison between our work and (Arun and Keller, 2005), we also ran their best adaptation of the C OLLINS MODEL 2 on their treebank version using our own head rules set15 and obtained 8"
W09-3824,J93-2004,0,\N,Missing
W09-3824,J04-4004,0,\N,Missing
W11-0601,W08-2109,0,0.175522,"ons we applied to the phonemic corpora was the increase in the average number of word forms per word. We refer to this quantity, similar to a type-token ratio, as the corpora’s lexical complexity. As allophonic variation is context-dependent, the increase in lexical complexity is, in this condition, limited by the phonotactic constraints of the language: the fewer contexts a phoneme appears in, the fewer contextual allophones it can have. By contrast, the upper limit is much higher in the control condition, as phoneme 1 Some transcription choices made by Brent and Cartwright are questionable (Blanchard and Heinz, 2008). Yet, we used the canonical version of the corpus for the sake of comparability. 3 substitutions are context-free. From a computational point of view, the application of allophonic rules increases both the number of symbols in the alphabet and, as a byproduct, the lexical complexity. Obviously, when any kind of noise or variation is added, there is less information in the data to learn from. We can therefore presume that the probability mass will be scattered, and that as a consequence, statistical models relying on word ngrams statistics will do worse than with phonemic inputs. Yet, we are i"
W11-0601,P08-1016,0,0.408951,"1: Elementary corpus statistics, including number of utterances (U), words (W) and phonemes (P). 2.2 Corpora The three corpora we used were derived from transcribed adult-child verbal interactions collected in the CHILDES database (MacWhinney, 2000). For each sample, elementary textual statistics are presented in Table 1. The English corpus contains 9790 utterances from the Bernstein–Ratner corpus that were automatically transcribed and manually corrected by Brent and Cartwright (1996). It has been used in many word segmentation experiments (Brent, 1999; Venkataraman, 2001; Batchelder, 2002; Fleck, 2008; Goldwater et al., 2009; among others) and can be considered a de facto standard. The French and the Japanese corpora were both made by Le Calvez (2007), the former by automatically transcribing the Champaud, Leveill´e and Rondal corpora, the latter by automatically transcribing the Ishii and Noji corpora from r¯omaji to phonemes. To get samples comparable in size to the English corpus, 10,000 utterances were selected at random in each of Le Calvez’s corpora. All transcription choices made by the authors in terms of phonemic inventory and word segmentation were respected.1 2.3 Variation sourc"
W11-0601,W04-1307,0,0.0346907,"s an incremental approach: when the ith utterance is processed, the model computes the best segmentation of the corpus up to the ith utterance included, assuming the segmentation of the first i − 1 utterances is fixed. 2.1.2 The segmentation task can be summarized as follows: given a corpus of utterances in which word boundaries have been deleted, the model has to put them back. Though we did not challenge the usual idealization that children are able to segment speech into discrete, phoneme-sized units, modeling language acquisition imposes significant constraints on the models (Brent, 1999; Gambell and Yang, 2004): they must generalize to different (if not all) languages, start without any knowledge specific to a particular language, learn in an unsupervised manner and, most importantly, operate incrementally. Online learning is a sound desideratum for any model of language acquisition: indeed, human language-processors do not wait, in Brent’s words, “until the corpus of all utterances they will ever hear becomes available”. Therefore, we favored an ‘infant-plausible’ setting and only considered online word segmentation models, namely MBDP-1 (Brent, 1999) and NGS-u (Venkataraman, 2001). Even if DP (Gol"
W11-0601,W08-0704,0,0.0645085,"Missing"
W11-0601,J01-3002,0,0.601145,"tion: Effects of Linguistic Diversity and Phonetic Variation Luc Boruta1,2 , Sharon Peperkamp2 , Benoˆıt Crabb´e1 , and Emmanuel Dupoux2 1 Univ. Paris Diderot, Sorbonne Paris Cit´e, ALPAGE, UMR-I 001 INRIA, F-75205, Paris, France 2 ´ ´ ´ LSCP–DEC, Ecole des Hautes Etudes en Sciences Sociales, Ecole Normale Sup´erieure, Centre National de la Recherche Scientifique, F-75005, Paris, France luc.boruta@inria.fr, peperkamp@ens.fr, benoit.crabbe@inria.fr, emmanuel.dupoux@gmail.com Abstract information have been proposed, and some of them exhibit satisfactory performance: MBDP-1 (Brent, 1999), NGS-u (Venkataraman, 2001) and DP (Goldwater, Griffiths and Johnson, 2009) can be considered state-of-the-art. Though there is evidence that prosodic, phonotactic and coarticulation cues may count more than statistics (Johnson and Jusczyk, 2001), it is still a matter of interest to know how much can be learned without linguistic cues. To use Venkataraman’s words, we are interested in “the performance of bare-bones statistical models.” Models of the acquisition of word segmentation are typically evaluated using phonemically transcribed corpora. Accordingly, they implicitly assume that children know how to undo phonetic"
W19-0422,abeille-barrier-2004-enriching,0,0.0827286,"Missing"
W19-0422,P17-2094,0,0.0766744,"linguist.univ-paris-diderot.fr benoit.crabbe@linguist.univ-paris-diderot.fr Abstract As opposed to word sense induction, word sense disambiguation (WSD), whether supervised or semi-supervised, has the advantage of using interpretable senses, but requires annotated data, which are quite rare for most languages except English (Miller et al., 1993). In this paper, we investigate which strategy to adopt to achieve WSD for languages lacking data that was annotated specifically for the task, focusing on the particular case of verb disambiguation in French. We first study the usability of Eurosense (Bovi et al. 2017), a multilingual corpus extracted from Europarl (Kohen, 2005) and automatically annotated with BabelNet (Navigli and Ponzetto, 2010) senses. Such a resource opened up the way to supervised and semi-supervised WSD for resourceless languages like French. While this perspective looked promising, our evaluation showed the annotated senses’ quality was not sufficient for supervised WSD on French verbs. Instead, we propose to use Wiktionary, a collaboratively edited, multilingual online dictionary, as a new resource for WSD. Wiktionary provides both sense inventory and manually sense tagged examples"
W19-0422,F12-2024,1,0.87489,"rameNet data (Djemaa et al., 2016), but in such data, only some notional domains were considered, and verb occurrences not pertaining to such domains were not disambiguated. 7 Except for SensEval1 but only the English dataset was given to public domain. 8 The dataset is available here http://www.llf.cnrs.fr/dataset/fse/ 4 Number of sentences Number of annotated verb tokens Number of annotated verb types Mean number of annotations per verb type Mean number of senses per verb type 3121 3199 66 48.47 3.83 Table 2: Statistics for the FrenchSemEval corpus (FSE). and Barrier, 2004) and the Sequoia (Candito and Seddah, 2012) treebank9 ), supplementing the corpus when necessary by occurrences sampled from fr-Wikipedia, in order to reach 50 occurrences per verb. 4.2 Annotation process The annotation has been performed by three students10 for nearly a month. We used WebAnno (Yimam et al., 2014; de Castilho et al., 2016) an open-source adaptable annotation tool. Sentences had already been pre-processed into CoNLL format (Nivre et al., 2007) with the Mind The Gap (MTG) parser (Coavoux and Crabb´e, 2017) and were plugged in WebAnno. We were thus able to provide files (one file per verb) containing sentences in which oc"
W19-0422,E17-1118,1,0.841033,"Missing"
W19-0422,W16-4011,0,0.047586,"Missing"
W19-0422,L16-1601,1,0.859128,"val was built using the following steps: we first selected a vocabulary of verbs based on their frequency in corpus. We selected verbs appearing between 50 and 1000 times in the French Wikipedia (dumped on 2016-12-12 hereafter frWikipedia). Secondly, from this pre-selected list of verbs we extracted those having a number of senses comprised between two and ten in Wiktionary’s sense inventory. For these verbs, we chose to extract 50 occurrences primarily from corpora comprising other annotations (the French TreeBank (FTB) (Abeill´e 6 Verbs are annotated with frames in the French FrameNet data (Djemaa et al., 2016), but in such data, only some notional domains were considered, and verb occurrences not pertaining to such domains were not disambiguated. 7 Except for SensEval1 but only the English dataset was given to public domain. 8 The dataset is available here http://www.llf.cnrs.fr/dataset/fse/ 4 Number of sentences Number of annotated verb tokens Number of annotated verb types Mean number of annotations per verb type Mean number of senses per verb type 3121 3199 66 48.47 3.83 Table 2: Statistics for the FrenchSemEval corpus (FSE). and Barrier, 2004) and the Sequoia (Candito and Seddah, 2012) treebank"
W19-0422,S10-1003,0,0.0491334,"quasiinexistent6 , makes it a serious candidate for a new resource of WSD. To investigate this opportunity for our objective of French verb WSD, we present FrenchSemEval, a new dataset manually annotated for WSD of French verbs which we used to carry out several evaluations, we describe the new resource in the next section. 4 FrenchSemEval : An evaluation corpus for French verb disambiguation Since the first Senseval evaluation serie in 1998 (Kilgarrif, 1998), a various number of evaluation frameworks were proposed to evaluate different WSD tasks, but only a few include French test datasets (Lefever and Hoste, 2010; Navigli et al., 2013) and unfortunately these only focus on nouns7 . In this section we present FrenchSemEval8 a new French dataset in which verb occurrences were manually annotated with Wiktionary senses. Our objective was to evaluate whether Wiktionary’s sense inventory is operational for humans to sense-annotate a corpus, and if so, to use it as evaluation data for WSD experiments. We describe the annotation process along with several statistics about the resulting dataset and the quality of the annotations. 4.1 Data selection To build FrenchSemEval, we chose to focus on moderately freque"
W19-0422,P15-2068,0,0.132793,"type occurring in these sentences is 15,5. More importantly, we could notice that the frontiers of the various senses sometimes appeared difficult to judge, making it difficult to grasp the exact perimeter of a sense.These mixed results led us to investigate other sources of sense-annotated data for French. 3 Wiktionary as data for WSD Wiktionary is a collaboratively edited, open-source multilingual online dictionary, hosted by the Wikimedia Foundation. It provides an interesting open-source resource and several studies already showed its usefulness for various NLP tasks (e.g. lemmatization (Liebeck and Conrad, 2015)), especially in the lexical semantic field, for extracting or improving thesauri (Navarro et al., 2009; Henrich et al., 2011; Miller and Gurevych, 2014). In this section we briefly present Wiktionary’s most interesting features along with our motivations to investigate the use of this resource for WSD on French verbs. Wiktionary’s main advantages is that it is entirely open-source, multilingual and has a good coverage for a substantial number of languages (according to wiktionary statistics4 , 22 languages have more than 50, 000 wiktionary entries each). Each entry consists of a definition an"
W19-0422,K16-1006,0,0.373854,"ased WSD for French verbs, evaluated on FrenchSemEval (FSE), a new dataset of French verbs manually annotated with wiktionary senses. 1 Introduction Word Sense Disambiguation (WSD) is a NLP task aiming at identifying the sense of a word occurrence from its context, given a predefined sense inventory. Although the task emerged almost 70 years ago with the first work on Automatic Machine Translation (Weaver, 1955), it remains unresolved. The recent breakthrough in neural net models allowed a better representation of the context and thus improved the quality of supervised disambiguation systems (Melamud et al., 2016; Yuan et al., 2016; Peters et al., 2018). Nevertheless, although WSD has the advantage of providing interpretable senses (as opposed to the unsupervised task of word sense induction), it also has the drawback of heavily relying on the availability and quality of sense-annotated data, even in the semi-supervised setting. Now, such data is available in English, essentially with SemCor (Miller et al., 1993), a corpus manually sense-annotated with Wordnet (Miller, 1995) senses. But for most languages, sense disambiguated data are very rare or simply don’t exist. This is mainly due to the fact tha"
W19-0422,H93-1061,0,0.791687,", 1955), it remains unresolved. The recent breakthrough in neural net models allowed a better representation of the context and thus improved the quality of supervised disambiguation systems (Melamud et al., 2016; Yuan et al., 2016; Peters et al., 2018). Nevertheless, although WSD has the advantage of providing interpretable senses (as opposed to the unsupervised task of word sense induction), it also has the drawback of heavily relying on the availability and quality of sense-annotated data, even in the semi-supervised setting. Now, such data is available in English, essentially with SemCor (Miller et al., 1993), a corpus manually sense-annotated with Wordnet (Miller, 1995) senses. But for most languages, sense disambiguated data are very rare or simply don’t exist. This is mainly due to the fact that manual semantic annotation is very costly in time and resources (Navigli, 2009). Nevertheless, Bovi et al. (2017) recently presented Eurosense, a multilingual automatically sense-disambiguated corpus extracted from Europarl (Koehn, 2005) and annotated with BabelNet (Navigli and Ponzetto, 2012) senses. In this article, we focus on supervised WSD for French verbs and investigate a way to perform the task"
W19-0422,miller-gurevych-2014-wordnet,0,0.0314455,"udge, making it difficult to grasp the exact perimeter of a sense.These mixed results led us to investigate other sources of sense-annotated data for French. 3 Wiktionary as data for WSD Wiktionary is a collaboratively edited, open-source multilingual online dictionary, hosted by the Wikimedia Foundation. It provides an interesting open-source resource and several studies already showed its usefulness for various NLP tasks (e.g. lemmatization (Liebeck and Conrad, 2015)), especially in the lexical semantic field, for extracting or improving thesauri (Navarro et al., 2009; Henrich et al., 2011; Miller and Gurevych, 2014). In this section we briefly present Wiktionary’s most interesting features along with our motivations to investigate the use of this resource for WSD on French verbs. Wiktionary’s main advantages is that it is entirely open-source, multilingual and has a good coverage for a substantial number of languages (according to wiktionary statistics4 , 22 languages have more than 50, 000 wiktionary entries each). Each entry consists of a definition and one or several examples, either attested or created, each example being a potential sense-annotated example for the lemma at hand. Definitions and exam"
W19-0422,S15-2049,0,0.0667081,"Missing"
W19-0422,Q14-1019,0,0.0708881,"Missing"
W19-0422,S13-2040,0,0.098209,"it a serious candidate for a new resource of WSD. To investigate this opportunity for our objective of French verb WSD, we present FrenchSemEval, a new dataset manually annotated for WSD of French verbs which we used to carry out several evaluations, we describe the new resource in the next section. 4 FrenchSemEval : An evaluation corpus for French verb disambiguation Since the first Senseval evaluation serie in 1998 (Kilgarrif, 1998), a various number of evaluation frameworks were proposed to evaluate different WSD tasks, but only a few include French test datasets (Lefever and Hoste, 2010; Navigli et al., 2013) and unfortunately these only focus on nouns7 . In this section we present FrenchSemEval8 a new French dataset in which verb occurrences were manually annotated with Wiktionary senses. Our objective was to evaluate whether Wiktionary’s sense inventory is operational for humans to sense-annotate a corpus, and if so, to use it as evaluation data for WSD experiments. We describe the annotation process along with several statistics about the resulting dataset and the quality of the annotations. 4.1 Data selection To build FrenchSemEval, we chose to focus on moderately frequent and moderately ambig"
W19-0422,N18-1202,0,0.0184251,"renchSemEval (FSE), a new dataset of French verbs manually annotated with wiktionary senses. 1 Introduction Word Sense Disambiguation (WSD) is a NLP task aiming at identifying the sense of a word occurrence from its context, given a predefined sense inventory. Although the task emerged almost 70 years ago with the first work on Automatic Machine Translation (Weaver, 1955), it remains unresolved. The recent breakthrough in neural net models allowed a better representation of the context and thus improved the quality of supervised disambiguation systems (Melamud et al., 2016; Yuan et al., 2016; Peters et al., 2018). Nevertheless, although WSD has the advantage of providing interpretable senses (as opposed to the unsupervised task of word sense induction), it also has the drawback of heavily relying on the availability and quality of sense-annotated data, even in the semi-supervised setting. Now, such data is available in English, essentially with SemCor (Miller et al., 1993), a corpus manually sense-annotated with Wordnet (Miller, 1995) senses. But for most languages, sense disambiguated data are very rare or simply don’t exist. This is mainly due to the fact that manual semantic annotation is very cost"
W19-0422,E17-1010,0,0.309118,"very costly in time and resources (Navigli, 2009). Nevertheless, Bovi et al. (2017) recently presented Eurosense, a multilingual automatically sense-disambiguated corpus extracted from Europarl (Koehn, 2005) and annotated with BabelNet (Navigli and Ponzetto, 2012) senses. In this article, we focus on supervised WSD for French verbs and investigate a way to perform the task when no manually sense-annotated training data specifically designed for the task are available.We focus on verbs because they are known to be central to understanding tasks, but also known to lead to lower WSD performance (Raganato et al., 2017). In section 2 we report a study on the suitability of using Eurosense as training data for our task. Because the results of our evaluation were inconclusive, we decided to explore Wiktionary, a free collaboratively edited multilingual online dictionary which provides a sense inventory and manually sense tagged examples, as resource for WSD. We give a general description of Wiktionary in section 3. In section 4, we present FrenchSemEval, a new manually sense annotated dataset for French verbs, to serve as evaluation data for WSD experiments using Wiktionary as sense inventory and training exam"
W19-0422,serasset-2012-dbnary,0,0.486383,"Missing"
W19-0422,P14-5016,0,0.0329402,"Missing"
W19-0422,C16-1130,0,0.0783139,"rbs, evaluated on FrenchSemEval (FSE), a new dataset of French verbs manually annotated with wiktionary senses. 1 Introduction Word Sense Disambiguation (WSD) is a NLP task aiming at identifying the sense of a word occurrence from its context, given a predefined sense inventory. Although the task emerged almost 70 years ago with the first work on Automatic Machine Translation (Weaver, 1955), it remains unresolved. The recent breakthrough in neural net models allowed a better representation of the context and thus improved the quality of supervised disambiguation systems (Melamud et al., 2016; Yuan et al., 2016; Peters et al., 2018). Nevertheless, although WSD has the advantage of providing interpretable senses (as opposed to the unsupervised task of word sense induction), it also has the drawback of heavily relying on the availability and quality of sense-annotated data, even in the semi-supervised setting. Now, such data is available in English, essentially with SemCor (Miller et al., 1993), a corpus manually sense-annotated with Wordnet (Miller, 1995) senses. But for most languages, sense disambiguated data are very rare or simply don’t exist. This is mainly due to the fact that manual semantic a"
W19-0422,P10-4014,0,0.10803,"Missing"
