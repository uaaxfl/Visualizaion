1996.amta-1.12,P91-1034,0,0.341452,"efined set. If the set of senses is chosen to be possible translations of the word of interest, the WSD becomes the problem of lexical selection (Dagan et al. 1991; Dagan and Itai 1994) in machine translation (MT) process. WSD methods can be characterized by how word senses are divided and by how WSD knowledge is represented and acquired. Word sense is an abstract concept frequently based on subjective and subtle distinctions in topic, register, dialect, collocation, part-of-speech and valency (McRoy 1992). Researchers have experimented with various knowledge sources for WSD system, including (1) the defining words in every-day dictionaries (Lesk 1986; Cowie et al. 1992; Luk 1995), (2) indicative words in the context of words listed under a thesaurus category acquired from corpus (Yarowsky 1992; Chen and Chang 1994), (3) bilingual corpora or monolingual corpora in the target language (Gale, Church and Yarowsky 1992; Dagan et al. 1991; Dagan  115 and Itai 1994), (4) automatic induced clusters with sublexical representation (Schütze 1992), and (5) handcrafted lexicon containing knowledge from multiple sources (McRoy 1992). This study is motivated by several observations. First, word-ba"
1996.amta-1.12,H92-1046,0,0.3102,"thods can be characterized by how word senses are divided and by how WSD knowledge is represented and acquired. Word sense is an abstract concept frequently based on subjective and subtle distinctions in topic, register, dialect, collocation, part-of-speech and valency (McRoy 1992). Researchers have experimented with various knowledge sources for WSD system, including (1) the defining words in every-day dictionaries (Lesk 1986; Cowie et al. 1992; Luk 1995), (2) indicative words in the context of words listed under a thesaurus category acquired from corpus (Yarowsky 1992; Chen and Chang 1994), (3) bilingual corpora or monolingual corpora in the target language (Gale, Church and Yarowsky 1992; Dagan et al. 1991; Dagan  115 and Itai 1994), (4) automatic induced clusters with sublexical representation (Schütze 1992), and (5) handcrafted lexicon containing knowledge from multiple sources (McRoy 1992). This study is motivated by several observations. First, word-based approaches trained on dictionaries or corpora offer limited coverage for unrestricted text. Lesk (1986) described a word-sense disambiguation technique that is based on the number of overlap between words in a dictionary defi"
1996.amta-1.12,P91-1017,0,0.0721785,"&quot;west&quot;), POSITION (&quot;left,&quot; &quot;right,&quot; and &quot;side&quot;), and ANIMALS (&quot;vole&quot; and &quot;deer&quot;). The data seems to indicate that a class-based approach will be effective for WSD. Second, the translations are quite diversified; six distinct translations for ten instances of &quot;bank&quot; 116 The rest of the paper is organized as follows. We begin by giving the details of material used, including the characteristics of definition sentences in LecDOCE and the organization of words in LLOCE. Next, a set of four algorithms for (1) labeling LecDOCE senses, (2) tagging bilingual corpora, (3) acquisition of WSD rules, and (4) rule-based WSD, are described. Examples demonstrating the effectiveness of the algorithms are given for illustration. After describing the algorithm, the experimental results for a twelve-word test set are presented. Moreover, the proposed method is compared with other approaches in computational linguistics literature. Finally, concluding remarks are made. 2. Labeling dictionary senses The labeling of dictionary definition sentences with a coarse sense distinction like the set labels in LLOCE is a special form of the WSD problem. No simple method can solve the general problem of WSD in unres"
1996.amta-1.12,C94-2113,0,0.143621,"Missing"
1996.amta-1.12,1992.tmi-1.9,0,0.814948,"Missing"
1996.amta-1.12,P95-1025,0,0.2869,"Missing"
1996.amta-1.12,J92-1001,0,0.321849,"Missing"
1996.amta-1.12,C92-2070,0,0.313518,"Missing"
1996.amta-1.12,H93-1052,0,0.0307022,"Missing"
1996.amta-1.12,P95-1026,0,0.116791,"Missing"
2008.amta-papers.20,P07-2045,0,0.0052993,"e accepts a term and domain as input, and transforms the given term into an expanded query. The query is submitted to a search engine to retrieve mixed-code documents. After that, TermMine extracts candidate translations in the returned document snippets and ranks them according to surface patterns, frequency, and distance from the given term. In our prototype, TermMine returns the term translations to the user directly; alternatively, these term translations can be used as additional input to a traditional machine translation system. Some statistical machine translation tools, such as Moses (Koehn et al, 2007), accept the source sentence with preselected word translation candidates. In this way, we may be able to use DSTs to improve the performance of MT systems. The rest of the paper is organized as follows. We review the related work in the next section. Then we present our method for automatically learning to expand a given term into an effective query for a domain (Section 3). We describe the experiments carried out to assess the proposed method. As part of our evaluation, we compare the quality of the translations by TermMine against a state-of-the-art machine translation system and other IR-b"
2008.amta-papers.20,J90-2002,0,0.662487,"Missing"
2008.amta-papers.20,J93-2003,0,0.0221253,"Missing"
2008.amta-papers.20,N04-1034,0,0.0321181,"ased statistical models. While SMT systems establish a general translation model from a parallel corpus, we propose a method for learning to find domain-specific translations via Web search. Parallel corpora are considered better data sources for quality translation information but are limited by lower availability. As an effort to cope with the data sparseness problem, Fung and Yee (1998) advocated using comparable corpora, which are considered more readily available in large quantity. Shao and Ng (2004) described a similar method for extracting new word translations from comparable corpora. Munteanu et al. (2004) also described a system that extracts parallel sentences from comparable corpora as additional training data for SMT systems. Recent research has begun to emphasize phrase translation to improve on word-based SMT approach. Cao and Li (2002) proposed an approach for translating short, base noun phrases based on a bilingual dictionary. The translation candidates for words in a phrase are combined and validated using Web page counts. Koehn and Knight (2003) described a system that builds a noun phrase-based translation subsystem leading to further We present a new terminology translation system,"
2008.amta-papers.20,C02-1011,0,0.0177094,"quality translation information but are limited by lower availability. As an effort to cope with the data sparseness problem, Fung and Yee (1998) advocated using comparable corpora, which are considered more readily available in large quantity. Shao and Ng (2004) described a similar method for extracting new word translations from comparable corpora. Munteanu et al. (2004) also described a system that extracts parallel sentences from comparable corpora as additional training data for SMT systems. Recent research has begun to emphasize phrase translation to improve on word-based SMT approach. Cao and Li (2002) proposed an approach for translating short, base noun phrases based on a bilingual dictionary. The translation candidates for words in a phrase are combined and validated using Web page counts. Koehn and Knight (2003) described a system that builds a noun phrase-based translation subsystem leading to further We present a new terminology translation system, TermMine, that automatically learns to find domain-specific term translations. TermMine uses an unsupervised training method to learn effective query expansions (QE) automatically during training by analyzing a set of terms for each domain"
2008.amta-papers.20,W01-1413,0,0.0162016,"se-to-phrase translations induced from word alignment information. The phrase-based approach significantly improves the translation quality. However, in the situations of single-word noun phrases, phrase-based approach has problem producing correct translation. In contrast, we propose to use domain information, provided by the user or automatically derived from the (sentential or paragraph) context, to help find more appropriate translations. Round the same time, researchers began to turn to the Web and proposed new methods for translating phrases. In a study more closely related to our work, Nagata et al. (2001) introduced a system for extracting the English translations of a given Japanese technical term by collecting and scoring translation candidates co-occurring with the given term in mixed-code Web pages. In addition to using Web texts, Lu et al. (2002) proposed a new method that uses anchor texts and hyperlink structure to find term translations for cross-language information retrieval. More recently, Wu et al. (2005) introduced a method for learning source-target surface patterns to find translation of proper names and technical terms on the Web. Our setting, approach, and evaluation are subst"
2008.amta-papers.20,C04-1089,0,0.0207021,"1993) described how to automatically align words and translations in the parallel sentences and build word-based statistical models. While SMT systems establish a general translation model from a parallel corpus, we propose a method for learning to find domain-specific translations via Web search. Parallel corpora are considered better data sources for quality translation information but are limited by lower availability. As an effort to cope with the data sparseness problem, Fung and Yee (1998) advocated using comparable corpora, which are considered more readily available in large quantity. Shao and Ng (2004) described a similar method for extracting new word translations from comparable corpora. Munteanu et al. (2004) also described a system that extracts parallel sentences from comparable corpora as additional training data for SMT systems. Recent research has begun to emphasize phrase translation to improve on word-based SMT approach. Cao and Li (2002) proposed an approach for translating short, base noun phrases based on a bilingual dictionary. The translation candidates for words in a phrase are combined and validated using Web page counts. Koehn and Knight (2003) described a system that buil"
2008.amta-papers.20,P98-1069,0,0.0595308,"subsequently the word translation ambiguity is resolved by using an n-gram model of the target language. Brown et al. (1993) described how to automatically align words and translations in the parallel sentences and build word-based statistical models. While SMT systems establish a general translation model from a parallel corpus, we propose a method for learning to find domain-specific translations via Web search. Parallel corpora are considered better data sources for quality translation information but are limited by lower availability. As an effort to cope with the data sparseness problem, Fung and Yee (1998) advocated using comparable corpora, which are considered more readily available in large quantity. Shao and Ng (2004) described a similar method for extracting new word translations from comparable corpora. Munteanu et al. (2004) also described a system that extracts parallel sentences from comparable corpora as additional training data for SMT systems. Recent research has begun to emphasize phrase translation to improve on word-based SMT approach. Cao and Li (2002) proposed an approach for translating short, base noun phrases based on a bilingual dictionary. The translation candidates for wo"
2008.amta-papers.20,P05-3010,1,0.89997,"ropriate translations. Round the same time, researchers began to turn to the Web and proposed new methods for translating phrases. In a study more closely related to our work, Nagata et al. (2001) introduced a system for extracting the English translations of a given Japanese technical term by collecting and scoring translation candidates co-occurring with the given term in mixed-code Web pages. In addition to using Web texts, Lu et al. (2002) proposed a new method that uses anchor texts and hyperlink structure to find term translations for cross-language information retrieval. More recently, Wu et al. (2005) introduced a method for learning source-target surface patterns to find translation of proper names and technical terms on the Web. Our setting, approach, and evaluation are substantially different from other Web-based translation approach. More recently, Web-based term translation systems have begun to expand queries to increase the chance of retrieving snippets that contain translations. Huang et al. (2005) proposed a pseudo relevance feedback approach for improving search results by augmenting the second round query with translations of high-frequency words found in the first-round returne"
2008.amta-papers.20,P03-1040,0,0.0134582,"dily available in large quantity. Shao and Ng (2004) described a similar method for extracting new word translations from comparable corpora. Munteanu et al. (2004) also described a system that extracts parallel sentences from comparable corpora as additional training data for SMT systems. Recent research has begun to emphasize phrase translation to improve on word-based SMT approach. Cao and Li (2002) proposed an approach for translating short, base noun phrases based on a bilingual dictionary. The translation candidates for words in a phrase are combined and validated using Web page counts. Koehn and Knight (2003) described a system that builds a noun phrase-based translation subsystem leading to further We present a new terminology translation system, TermMine, that automatically learns to find domain-specific term translations. TermMine uses an unsupervised training method to learn effective query expansions (QE) automatically during training by analyzing a set of terms for each domain of interest, and extracts indicative target words for each individual domain. For example, TermMine learns that “ 市 場 ” and “ 價 格 ” are important TL keywords for the FINANCE domain because it occurs frequently in mixed"
2010.amta-papers.13,C02-1011,0,0.0362544,"rate additional bitexts from comparable, but not parallel, bilingual texts (Fung and Cheung, 2004; Munteanu and Marcu, 2005). Adding more parallel data to MT systems, though may not be always available for some language pairs, tends to reduce the number of OOVs. On the other hand, some work began to extract translations for unknown words from external knowledge sources such as dictionaries and the Web. Unknown words were replaced by their definitions or translations in dictionaries (Vilar et al., 2007; Eck et al., 2008), or by translations mined from large-scale web data (Nagata et al., 2000; Cao and Li, 2002). In our method, translations reside within MT systems’ training corpus not from external knowledge. Recent work has been done on translating different OOV cases: name entities (NE), compounds, and morphological variants. Knight and Graehl (1997) introduced a transliteration model to tackle proper names while Hassan and Sorensen (2005) presented a NE translating approach that combines NE translation and transliteration in a single framework. On the other hand, Cao and Li (2002) and Tanaka and Baldwin (2003) focused on translating compound words, especially noun phrases, via statistical approac"
2010.amta-papers.13,eck-etal-2008-communicating,0,0.0307162,"ces of MT systems via sublexical translations, interesting approaches were presented to generate additional bitexts from comparable, but not parallel, bilingual texts (Fung and Cheung, 2004; Munteanu and Marcu, 2005). Adding more parallel data to MT systems, though may not be always available for some language pairs, tends to reduce the number of OOVs. On the other hand, some work began to extract translations for unknown words from external knowledge sources such as dictionaries and the Web. Unknown words were replaced by their definitions or translations in dictionaries (Vilar et al., 2007; Eck et al., 2008), or by translations mined from large-scale web data (Nagata et al., 2000; Cao and Li, 2002). In our method, translations reside within MT systems’ training corpus not from external knowledge. Recent work has been done on translating different OOV cases: name entities (NE), compounds, and morphological variants. Knight and Graehl (1997) introduced a transliteration model to tackle proper names while Hassan and Sorensen (2005) presented a NE translating approach that combines NE translation and transliteration in a single framework. On the other hand, Cao and Li (2002) and Tanaka and Baldwin (2"
2010.amta-papers.13,W04-3208,0,0.0146153,"t of OOVs on translation quality. 2 Related Work Recently, translating OOV words in the field of machine translation has received much attention. In this paper, we address one aspect of translating OOVs by combining translations of OOVs’ constituents retrieved using wildcard queries and MT system’s existing resources. While this paper focuses on translating the source words with no translation equivalents in the bilingual resources of MT systems via sublexical translations, interesting approaches were presented to generate additional bitexts from comparable, but not parallel, bilingual texts (Fung and Cheung, 2004; Munteanu and Marcu, 2005). Adding more parallel data to MT systems, though may not be always available for some language pairs, tends to reduce the number of OOVs. On the other hand, some work began to extract translations for unknown words from external knowledge sources such as dictionaries and the Web. Unknown words were replaced by their definitions or translations in dictionaries (Vilar et al., 2007; Eck et al., 2008), or by translations mined from large-scale web data (Nagata et al., 2000; Cao and Li, 2002). In our method, translations reside within MT systems’ training corpus not from"
2010.amta-papers.13,W05-0712,0,0.0251386,"known words from external knowledge sources such as dictionaries and the Web. Unknown words were replaced by their definitions or translations in dictionaries (Vilar et al., 2007; Eck et al., 2008), or by translations mined from large-scale web data (Nagata et al., 2000; Cao and Li, 2002). In our method, translations reside within MT systems’ training corpus not from external knowledge. Recent work has been done on translating different OOV cases: name entities (NE), compounds, and morphological variants. Knight and Graehl (1997) introduced a transliteration model to tackle proper names while Hassan and Sorensen (2005) presented a NE translating approach that combines NE translation and transliteration in a single framework. On the other hand, Cao and Li (2002) and Tanaka and Baldwin (2003) focused on translating compound words, especially noun phrases, via statistical approach and translation templates. Furthermore, in languages (e.g., Arabic) where morphological variants are a major cause of OOVs, much work was described to transform these variants into invocabulary word forms (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Arora et al., 2008). In contrast, we focus on translating OOVs resulting from a"
2010.amta-papers.13,huang-etal-2004-sinica,0,0.01938,"(LDC2004T08) and Xinhua News Agency (LDC2007T09). Chinese sentences were word segmented by the CKIP Chinese word segmenter (Ma and Chen, 2003). Common settings were used to run Moses: GIZA++ (Och and Ney, 2003) was used for word alignment, grow-diagonal-final for bidirectional word alignment combination, and phrase extraction heuristics in (Koehn et al., 2003) for bilingual phrase pairs. We exploited English Gigaword Third Edition (LDC2007T07) and SRILM toolkit (Stolcke, 2002) to build trigram language model. In our OOV model, on the other hand, we leveraged WordNet 3.0 and bilingual WordNet (Huang et al., 2004) to filter sublexical translations (Section 3.2). To prune less probable translation candidates of OOVs at run-time (Section 3.3), we used Web 1T 5-gram First Edition (LDC2006T13) for MI calculation. As for the run-time candidate ranking (Section 3.3), we exploited the same parallel corpora and target-language corpus used for Moses to estimate bilingual translation probabilities (Ptrans) and target-language fluency (PTLM), respectively. The OOV handling model was designed to find translations of OOV words from existing bilingual resources that are likely to help human translators or MT systems"
2010.amta-papers.13,P97-1017,0,0.0706502,"uce the number of OOVs. On the other hand, some work began to extract translations for unknown words from external knowledge sources such as dictionaries and the Web. Unknown words were replaced by their definitions or translations in dictionaries (Vilar et al., 2007; Eck et al., 2008), or by translations mined from large-scale web data (Nagata et al., 2000; Cao and Li, 2002). In our method, translations reside within MT systems’ training corpus not from external knowledge. Recent work has been done on translating different OOV cases: name entities (NE), compounds, and morphological variants. Knight and Graehl (1997) introduced a transliteration model to tackle proper names while Hassan and Sorensen (2005) presented a NE translating approach that combines NE translation and transliteration in a single framework. On the other hand, Cao and Li (2002) and Tanaka and Baldwin (2003) focused on translating compound words, especially noun phrases, via statistical approach and translation templates. Furthermore, in languages (e.g., Arabic) where morphological variants are a major cause of OOVs, much work was described to transform these variants into invocabulary word forms (Koehn and Knight, 2003; Yang and Kirch"
2010.amta-papers.13,E03-1076,0,0.0364695,"cal variants. Knight and Graehl (1997) introduced a transliteration model to tackle proper names while Hassan and Sorensen (2005) presented a NE translating approach that combines NE translation and transliteration in a single framework. On the other hand, Cao and Li (2002) and Tanaka and Baldwin (2003) focused on translating compound words, especially noun phrases, via statistical approach and translation templates. Furthermore, in languages (e.g., Arabic) where morphological variants are a major cause of OOVs, much work was described to transform these variants into invocabulary word forms (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Arora et al., 2008). In contrast, we focus on translating OOVs resulting from abbreviations of source phrases or combination forms of common words. These two cover some portion of name entities and nounnoun and adjective-noun compounds (e.g., 邊 貿 border trade (NN), and 新規 new regulations (AN)). In the studies more closely related to our work, Marton et al. (2009) proposed a paraphrase model that replaces OOVs with in-vocabulary equivalents. Paraphrases were learnt based on word alignments computed over a large additional set of bitexts. And Mirkin et al. (2009) para"
2010.amta-papers.13,N03-1017,0,0.00868501,"ging in external knowledge without changing any component such as translation or language model. In this paper, we leveraged the markup language to incorporate OOVs’ translation candidates. To train Moses’ translation model, we used Hong Kong Parallel Text (LDC2004T08) and Xinhua News Agency (LDC2007T09). Chinese sentences were word segmented by the CKIP Chinese word segmenter (Ma and Chen, 2003). Common settings were used to run Moses: GIZA++ (Och and Ney, 2003) was used for word alignment, grow-diagonal-final for bidirectional word alignment combination, and phrase extraction heuristics in (Koehn et al., 2003) for bilingual phrase pairs. We exploited English Gigaword Third Edition (LDC2007T07) and SRILM toolkit (Stolcke, 2002) to build trigram language model. In our OOV model, on the other hand, we leveraged WordNet 3.0 and bilingual WordNet (Huang et al., 2004) to filter sublexical translations (Section 3.2). To prune less probable translation candidates of OOVs at run-time (Section 3.3), we used Web 1T 5-gram First Edition (LDC2006T13) for MI calculation. As for the run-time candidate ranking (Section 3.3), we exploited the same parallel corpora and target-language corpus used for Moses to estima"
2010.amta-papers.13,W04-3250,0,0.0992485,"Missing"
2010.amta-papers.13,P07-2045,0,0.00965846,"Missing"
2010.amta-papers.13,P08-1049,0,0.0174747,"cabulary equivalents. Paraphrases were learnt based on word alignments computed over a large additional set of bitexts. And Mirkin et al. (2009) paraphrased OOV words via entailment rules derived from monolingual corpora and manually compiled synonym thesaurus. These studies are similar in spirit to our work. However, we do not address the problem via paraphrasing. In our model, the wildcard translation searches of OOVs’ constituents might retrieve their source-language paraphrases with translations. Instead of using these source paraphrases, we directly use the target translations. Recently, Li and Yarowsky (2008) presented an unsupervised method for extracting the mappings between full-form phrases and their abbreviations that are OOVs. The main difference from our work is that, in their approach, they need a reverse MT system and they focus on solving OOVs of name entities. Our approach generates translations for OOVs of abbreviations and combinations, which cover common words (e.g., 成名 became famous, 邊貿 border trade and 新規 new regulations) as well as name entities. In addition, our wildcard searches for translations of OOVs’ constituents from existing resources of MT systems can be viewed as finding"
2010.amta-papers.13,W03-1726,0,0.0124391,"ly translations of the given OOV. Notice that θ will be tuned for better translation quality. An example translation of an OOV “上肢” (upper limbs) is shown in Figure 1. i 4 Experimental Setting simple XML markup for plugging in external knowledge without changing any component such as translation or language model. In this paper, we leveraged the markup language to incorporate OOVs’ translation candidates. To train Moses’ translation model, we used Hong Kong Parallel Text (LDC2004T08) and Xinhua News Agency (LDC2007T09). Chinese sentences were word segmented by the CKIP Chinese word segmenter (Ma and Chen, 2003). Common settings were used to run Moses: GIZA++ (Och and Ney, 2003) was used for word alignment, grow-diagonal-final for bidirectional word alignment combination, and phrase extraction heuristics in (Koehn et al., 2003) for bilingual phrase pairs. We exploited English Gigaword Third Edition (LDC2007T07) and SRILM toolkit (Stolcke, 2002) to build trigram language model. In our OOV model, on the other hand, we leveraged WordNet 3.0 and bilingual WordNet (Huang et al., 2004) to filter sublexical translations (Section 3.2). To prune less probable translation candidates of OOVs at run-time (Sectio"
2010.amta-papers.13,J05-4003,0,0.0310817,"n quality. 2 Related Work Recently, translating OOV words in the field of machine translation has received much attention. In this paper, we address one aspect of translating OOVs by combining translations of OOVs’ constituents retrieved using wildcard queries and MT system’s existing resources. While this paper focuses on translating the source words with no translation equivalents in the bilingual resources of MT systems via sublexical translations, interesting approaches were presented to generate additional bitexts from comparable, but not parallel, bilingual texts (Fung and Cheung, 2004; Munteanu and Marcu, 2005). Adding more parallel data to MT systems, though may not be always available for some language pairs, tends to reduce the number of OOVs. On the other hand, some work began to extract translations for unknown words from external knowledge sources such as dictionaries and the Web. Unknown words were replaced by their definitions or translations in dictionaries (Vilar et al., 2007; Eck et al., 2008), or by translations mined from large-scale web data (Nagata et al., 2000; Cao and Li, 2002). In our method, translations reside within MT systems’ training corpus not from external knowledge. Recent"
2010.amta-papers.13,D09-1040,0,0.021936,"nd translation templates. Furthermore, in languages (e.g., Arabic) where morphological variants are a major cause of OOVs, much work was described to transform these variants into invocabulary word forms (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Arora et al., 2008). In contrast, we focus on translating OOVs resulting from abbreviations of source phrases or combination forms of common words. These two cover some portion of name entities and nounnoun and adjective-noun compounds (e.g., 邊 貿 border trade (NN), and 新規 new regulations (AN)). In the studies more closely related to our work, Marton et al. (2009) proposed a paraphrase model that replaces OOVs with in-vocabulary equivalents. Paraphrases were learnt based on word alignments computed over a large additional set of bitexts. And Mirkin et al. (2009) paraphrased OOV words via entailment rules derived from monolingual corpora and manually compiled synonym thesaurus. These studies are similar in spirit to our work. However, we do not address the problem via paraphrasing. In our model, the wildcard translation searches of OOVs’ constituents might retrieve their source-language paraphrases with translations. Instead of using these source paraph"
2010.amta-papers.13,P09-1089,0,0.0141281,"s (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Arora et al., 2008). In contrast, we focus on translating OOVs resulting from abbreviations of source phrases or combination forms of common words. These two cover some portion of name entities and nounnoun and adjective-noun compounds (e.g., 邊 貿 border trade (NN), and 新規 new regulations (AN)). In the studies more closely related to our work, Marton et al. (2009) proposed a paraphrase model that replaces OOVs with in-vocabulary equivalents. Paraphrases were learnt based on word alignments computed over a large additional set of bitexts. And Mirkin et al. (2009) paraphrased OOV words via entailment rules derived from monolingual corpora and manually compiled synonym thesaurus. These studies are similar in spirit to our work. However, we do not address the problem via paraphrasing. In our model, the wildcard translation searches of OOVs’ constituents might retrieve their source-language paraphrases with translations. Instead of using these source paraphrases, we directly use the target translations. Recently, Li and Yarowsky (2008) presented an unsupervised method for extracting the mappings between full-form phrases and their abbreviations that are O"
2010.amta-papers.13,J03-1002,0,0.00437849,"tter translation quality. An example translation of an OOV “上肢” (upper limbs) is shown in Figure 1. i 4 Experimental Setting simple XML markup for plugging in external knowledge without changing any component such as translation or language model. In this paper, we leveraged the markup language to incorporate OOVs’ translation candidates. To train Moses’ translation model, we used Hong Kong Parallel Text (LDC2004T08) and Xinhua News Agency (LDC2007T09). Chinese sentences were word segmented by the CKIP Chinese word segmenter (Ma and Chen, 2003). Common settings were used to run Moses: GIZA++ (Och and Ney, 2003) was used for word alignment, grow-diagonal-final for bidirectional word alignment combination, and phrase extraction heuristics in (Koehn et al., 2003) for bilingual phrase pairs. We exploited English Gigaword Third Edition (LDC2007T07) and SRILM toolkit (Stolcke, 2002) to build trigram language model. In our OOV model, on the other hand, we leveraged WordNet 3.0 and bilingual WordNet (Huang et al., 2004) to filter sublexical translations (Section 3.2). To prune less probable translation candidates of OOVs at run-time (Section 3.3), we used Web 1T 5-gram First Edition (LDC2006T13) for MI calc"
2010.amta-papers.13,P02-1040,0,0.0839862,"r or at least similar translation accuracy compared to the underlying Moses system. System Moses CST BLEU 21.46 21.56 BP 0.928 0.939 # words 41052 41707 Table 5. Performance of two systems (# sentence=1664). System Moses CST BLEU 17.41 17.83 BP 0.912 0.951 # words 10833 11583 Table 6. Performance of two systems (# sentence=351). Figure 5. BLEU scores of different filtering thresholds. 5 Evaluation Results and Discussion We report the experimental results in this section. First, we report the translation performance of the underlying MT system, Moses, with and without our OOV model using BLEU (Papineni et al., 2002). We then show example translations of some OOVs generated by our system and point out the future improvement of our OOV model. 5.1 Experimental Results During the evaluation, we used NIST MT-06 test set, containing 1,664 sentences, for testing. In this test set, there were 933 distinct unknown words scattered in 859 sentences, and its number of OOVs with respect to OOVs’ length was much alike to that of the developing set. In the experiment, out of the 933 OOV words, our model generated translation candidates for the 170 If we look at the performance of the 351 sentences in the test set for w"
2010.amta-papers.13,W07-0705,0,0.0248724,"the bilingual resources of MT systems via sublexical translations, interesting approaches were presented to generate additional bitexts from comparable, but not parallel, bilingual texts (Fung and Cheung, 2004; Munteanu and Marcu, 2005). Adding more parallel data to MT systems, though may not be always available for some language pairs, tends to reduce the number of OOVs. On the other hand, some work began to extract translations for unknown words from external knowledge sources such as dictionaries and the Web. Unknown words were replaced by their definitions or translations in dictionaries (Vilar et al., 2007; Eck et al., 2008), or by translations mined from large-scale web data (Nagata et al., 2000; Cao and Li, 2002). In our method, translations reside within MT systems’ training corpus not from external knowledge. Recent work has been done on translating different OOV cases: name entities (NE), compounds, and morphological variants. Knight and Graehl (1997) introduced a transliteration model to tackle proper names while Hassan and Sorensen (2005) presented a NE translating approach that combines NE translation and transliteration in a single framework. On the other hand, Cao and Li (2002) and Ta"
2010.amta-papers.13,E06-1006,0,0.0272423,"Graehl (1997) introduced a transliteration model to tackle proper names while Hassan and Sorensen (2005) presented a NE translating approach that combines NE translation and transliteration in a single framework. On the other hand, Cao and Li (2002) and Tanaka and Baldwin (2003) focused on translating compound words, especially noun phrases, via statistical approach and translation templates. Furthermore, in languages (e.g., Arabic) where morphological variants are a major cause of OOVs, much work was described to transform these variants into invocabulary word forms (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Arora et al., 2008). In contrast, we focus on translating OOVs resulting from abbreviations of source phrases or combination forms of common words. These two cover some portion of name entities and nounnoun and adjective-noun compounds (e.g., 邊 貿 border trade (NN), and 新規 new regulations (AN)). In the studies more closely related to our work, Marton et al. (2009) proposed a paraphrase model that replaces OOVs with in-vocabulary equivalents. Paraphrases were learnt based on word alignments computed over a large additional set of bitexts. And Mirkin et al. (2009) paraphrased OOV words via enta"
2019.rocling-1.38,W09-2307,0,0.0244943,"Missing"
2019.rocling-1.38,W13-3721,0,0.0734382,"Missing"
2019.rocling-1.38,N13-1070,0,0.0622475,"Missing"
2019.rocling-1.38,de-marneffe-etal-2014-universal,0,0.0400172,"Missing"
2019.rocling-1.38,P13-2017,0,0.0359657,"Missing"
2019.rocling-1.40,J93-2004,0,0.0647064,"Missing"
2019.rocling-1.40,W00-1205,0,0.133279,"Missing"
2019.rocling-1.40,W03-1707,0,0.232937,"Missing"
2020.acl-demos.17,C18-1139,0,0.0383284,"rect and Correct) into a more informative DIRC tag schema (Delete, Insert, Replace, and Correct), with the goal of providing learners more specific suggestions (i.e., the edit type of an error) to revise their essay. We train a GED model based on Bi-LSTM with a Conditional Random Field layer (CRF). To improve the GED model, we add Bidirectional Encoder Representations from Transformers (BERT), which significantly outperforms other embedding schemes in many tasks (Devlin et al., 2018). In addition, we also add a character-based word embedding, Flair, which captures more contextual information (Akbik et al., 2018). Our training process is divided into two steps. In Step (1), we convert sentences with error annotations into unedited sentences and DIRC tags (i.e., &lt;[-,-]&gt; for Delete, tokens preceded by &lt;{+,+}&gt; for Insert, &lt;[-,-]{+,+}&gt; for Replace and tokens with no edit tag for Correct). For example, the sentence “I believe there are {+a+} lot of [-why]{+ways+} enjoy [-the-] shopping.” is converted to “I believe there are lot of why enjoy the shopping .” and “&lt;C C C C I C R C D C C&gt;”. These two sequences are treated as the input and output of a neural GED model respectively. Note that the token to be ins"
2020.acl-demos.17,P13-4024,1,0.901943,"1 (center right). The user can click on an erroneous sentence to demand GED results. LinggleWrite marks suspicious words with orange, red or green, suggesting to insert a word, delete the word, or replace the word respectively, as shown in Section C of Figure 1 (center right). Subsequently, the user can click on an error to display plausible corrective suggestions returned by a n-gram search engine. 2.4 Corrective Feedback We present corrective suggestions according to the context and the edit type (i.e., insertion, deletion, replacement), using an existing linguistic search engine, Linggle (Boisson et al., 2013). An example of corrective suggestions for the sentence “I finished school on June” is shown in Section E in Figure 1 (bottom right). LinggleWrite detects “on” probably requiring a replacement edit. We convert the detected error into a Linggle query to search for more appropriate expressions, and provide the user with the search result “school in June’ for 128 considerations. 3 Method To develop LinggleWrite, we extract the most common grammar patterns from a corpus in order to provide writing suggestions. Additionally, we develop models for AES and GED based on annotated learner corpora. We r"
2020.acl-demos.17,P15-1068,0,0.0209399,"chieve state-of-the-art performance on the FCE test set. Interestingly, we note that the model with word2vec pre-trained word embeddings achieves the highest precision but the lowest recall. As for the DIRC schema, BiLSTM-CRF+BERT+Flair performs the best among all models. Importantly, the DIRC model performs comparably to the binary model while providing more informative feedback (i.e., the edit type) for learners to self-edit their essays. It is also worth noting that for GED and GEC tasks multiple answers are acceptable and there is low inter-annotator agreement (Rozovskaya and Roth, 2010). Bryant and Ng (2015) pointed out even human annotators can only achieve 72.8 F0.5 score at the best against the gold standard annotations of multiple annotators in GEC tasks. Thus, it is fair to say that the performance of our model against one gold standard annotation are underestimated and not far from human annotators, thus acceptable for an application. Table 4 shows results of different network architectures on the AES task. As we can see in Table 4, LSTN-LSTM-ATT achieves the best performance among all models. In addition, we find that sentence-level models perform better than wordlevel ones in general. Fur"
2020.acl-demos.17,K17-1017,0,0.209788,"mputational linguistics and pedagogy. Some existing computer aided writing systems detect and correct grammatical errors, and give an overall score (e.g., Grammarly (www.grammarly.com) and Pigai (www.pigai.org)). Instead of directly correcting users’ essays, Write&Improve (writeandimprove.com) only marks highly-likely incorrect words on the grounds that automated grammatical error correction is still very imprecise. Recently, researchers have begun to apply neural network models to both automated essay scoring (AES) and grammatical error detection (GED), gaining significant improvement (e.g., Dong et al. (2017); Rei and Søgaard (2018)). However, these Web services fall short of providing sufficient “coaching” information (e.g., grammar patterns, collocations, examples) to learners to improve their writing skills. Provide writing suggestions as a user types away or during editing is another emerging approach to coaching the learner. For example, WriteAhead (writeahead.nlpweb.org) provides contextsensitive suggestions, right in the process of writing or self-editing. Google recently released Smart Compose that offers users word or phrase completion suggestions while writing an email (Chen et al., 2019"
2020.acl-demos.17,P15-1120,0,0.0238539,"ing is another emerging approach to coaching the learner. For example, WriteAhead (writeahead.nlpweb.org) provides contextsensitive suggestions, right in the process of writing or self-editing. Google recently released Smart Compose that offers users word or phrase completion suggestions while writing an email (Chen et al., 2019). In line with these systems, we also suggest that feedback on learners’ writings could be more effective if a system not only acts as an editor providing direct corrections, but also a coach performing grammatical error detection and offering interactive suggestions (Hearst, 2015). Moreover, illustrating word usage with bilingual examples can better help non-native English learners. This would enhance learners’ skills of self-editing and pave the way to lifelong language learning. With that in mind, we developed a web-based system LinggleWrite (f.linggle.com) with many assistive writing functions. With LinggleWrite users can write or paste their essays and get informative feedback including just-in-time writing suggestions, essay scoring, error detection, and related word usage information retrieved from Linggle(linggle.com). 2 The LinggleWrite System The system consis"
2020.acl-demos.17,D14-1162,0,0.0822763,"Missing"
2020.acl-demos.17,P16-1112,0,0.0532833,"Missing"
2020.acl-demos.17,W10-1004,0,0.0402919,"n the other GED models and achieve state-of-the-art performance on the FCE test set. Interestingly, we note that the model with word2vec pre-trained word embeddings achieves the highest precision but the lowest recall. As for the DIRC schema, BiLSTM-CRF+BERT+Flair performs the best among all models. Importantly, the DIRC model performs comparably to the binary model while providing more informative feedback (i.e., the edit type) for learners to self-edit their essays. It is also worth noting that for GED and GEC tasks multiple answers are acceptable and there is low inter-annotator agreement (Rozovskaya and Roth, 2010). Bryant and Ng (2015) pointed out even human annotators can only achieve 72.8 F0.5 score at the best against the gold standard annotations of multiple annotators in GEC tasks. Thus, it is fair to say that the performance of our model against one gold standard annotation are underestimated and not far from human annotators, thus acceptable for an application. Table 4 shows results of different network architectures on the AES task. As we can see in Table 4, LSTN-LSTM-ATT achieves the best performance among all models. In addition, we find that sentence-level models perform better than wordleve"
2020.acl-demos.17,D16-1193,0,0.562413,"Step (1). For example, the extracted grammar pattern and collocation from the sentence “Schools play an important role in society” are “V n in n” and “society”. In Step (3), for each keyword, we count and filter out patterns and collocations based on mean and standard deviation. Finally, we use GDEX method (Kilgarriff et al., 2008) to select the best monolingual and bilingual examples from COCA and CAM for each pattern. 3.2 layer, attempting to select the sentences or words to focus on for effective scoring. Our models are similar to other sentence-based and word-based neural AES model (e.g., Taghipour and Ng (2016); Dong et al. (2017)), but we use a different training set, EFCAMDAT (Geertzen et al., 2013) and output format, CEFR levels, to train our model. Scoring an Essay We formulate AES as a regression problem and train a neural model for this task. We investigate two neural network architectures with different input formats: word-based models and sentencebased models, which learn essay representation based on word sequences and sentence sequences respectively. We build our word-based models upon CNN, LSTM and Bi-LSTM (Taghipour and Ng, 2016), while sentence-level models upon the LSTM-LSTM and LSTM-C"
2020.acl-demos.17,P11-1019,0,0.101453,"lanced distribution of levels as shown in Table 2, we randomly selected 1,903 essays from each level and then used 5-fold cross validation for training and evaluation. CEFR Level A1 A2 B1 B2 C1 C2 #Essays 460,614 300,188 166,453 60,844 14,551 1,903 #Training 1,903 1,903 1,903 1,903 1,903 1,903 Table 2: Description of the EFCAMDAT dataset To train the GED model, we use the First Certificate in English dataset (FCE). This dataset contains 1,224 essays written by English learners who took the First Certificate in English (FCE) exam. These essays have been manually tagged based on 77 error types (Yannakoudakis et al., 2011). We used 30,953 sentences from FCE for training, 2,720 for testing, and 2,222 for development. We followed the approach of Rei and Yannakoudakis (2016) in our experiment, but converted the dataset into DIRC format as described in Section 3.3. 130 Model Rei and Søgaard (2018) BiLSTM-CRF + word2vec BiLSTM-CRF + Flair BiLSTM-CRF + BERT BiLSTM-CRF + BERT +Flair Binary Task Incorrect tag Prec. Rec. F0.5 65.5 28.6 52 89 13.8 42.6 68.9 24.6 50.7 71.1 35.7 59.4 72.3 36.7 60.6 Insertion tag Prec. Rec. F0.5 DIRC Task Replacement tag Prec. Rec. F0.5 Deletion tag Prec. Rec. F0.5 57.2 53.8 53.2 54.6 82.9"
2020.ijclclp-1.1,W13-4408,1,0.820078,"Missing"
2020.ijclclp-1.1,E14-3013,0,0.0401491,"Missing"
2020.ijclclp-1.1,P17-4012,0,0.0490072,"Missing"
2020.ijclclp-1.1,W03-1726,0,0.322608,"Missing"
2020.ijclclp-1.1,W15-3106,0,0.042784,"Missing"
2020.ijclclp-1.1,W13-4406,0,0.0505012,"Missing"
2020.ijclclp-1.1,N16-1042,0,0.0191152,"Missing"
2020.ijclclp-1.1,P00-1032,0,0.283688,"Missing"
2020.ijclclp-2.3,P91-1022,0,0.653127,"Missing"
2020.ijclclp-2.3,P93-1002,0,0.641573,"Missing"
2020.ijclclp-2.3,P91-1023,0,0.783031,"Missing"
2020.ijclclp-2.3,J93-1004,0,0.75655,"Missing"
2020.ijclclp-2.3,J99-1003,0,0.484571,"Missing"
2020.ijclclp-2.3,1992.tmi-1.7,0,0.584248,"Missing"
2020.ijclclp-2.3,1994.amta-1.26,0,0.184327,"Missing"
2020.rocling-1.34,N15-3022,1,0.882517,"Missing"
2021.rocling-1.43,P95-1032,0,0.38124,"ion that reflects the similarity and differences between two languages involved, and the user might be interested in multiple ways (structures) of translating a phrase (e.g., consider the phrase “harmful to the ocean” and its translation). More recent researches concentrate on learning word translation and extracting bilingual word translation pairs from bilingual corpus, and then calculate the degree of mutual relationship between word pairs in parallel sentences, thereby deriving the precise translation (Catizone et al. (1989); Brown et al. (1990); Gale and Church (1991); Wu and Xia (1994); Fung (1995); Melamed (1995); Moore (2001)). In our system, we focus on identifying patterns and phrases by a patterns table and a word translation model which are created using statistical methods in bilingual corpora with word alignment. In the area of phrase alignment, Ko (2006) proposed a method for verb phrase translation. For specific verb fragments (e.g. make a report to police), automatic alignment is applied to calculate the collocation relationship across two language (e.g. when make and report appear together, report often corresponds to ȸൔਢȹ), then word and phrase correspondences are generated"
2021.rocling-1.43,H91-1026,0,0.807895,"y not be litateral and may need a presentation that reflects the similarity and differences between two languages involved, and the user might be interested in multiple ways (structures) of translating a phrase (e.g., consider the phrase “harmful to the ocean” and its translation). More recent researches concentrate on learning word translation and extracting bilingual word translation pairs from bilingual corpus, and then calculate the degree of mutual relationship between word pairs in parallel sentences, thereby deriving the precise translation (Catizone et al. (1989); Brown et al. (1990); Gale and Church (1991); Wu and Xia (1994); Fung (1995); Melamed (1995); Moore (2001)). In our system, we focus on identifying patterns and phrases by a patterns table and a word translation model which are created using statistical methods in bilingual corpora with word alignment. In the area of phrase alignment, Ko (2006) proposed a method for verb phrase translation. For specific verb fragments (e.g. make a report to police), automatic alignment is applied to calculate the collocation relationship across two language (e.g. when make and report appear together, report often corresponds to ȸൔਢȹ), then word and phra"
2021.rocling-1.43,W03-1726,0,0.125442,"Missing"
2021.rocling-1.43,W95-0115,0,0.138047,"ects the similarity and differences between two languages involved, and the user might be interested in multiple ways (structures) of translating a phrase (e.g., consider the phrase “harmful to the ocean” and its translation). More recent researches concentrate on learning word translation and extracting bilingual word translation pairs from bilingual corpus, and then calculate the degree of mutual relationship between word pairs in parallel sentences, thereby deriving the precise translation (Catizone et al. (1989); Brown et al. (1990); Gale and Church (1991); Wu and Xia (1994); Fung (1995); Melamed (1995); Moore (2001)). In our system, we focus on identifying patterns and phrases by a patterns table and a word translation model which are created using statistical methods in bilingual corpora with word alignment. In the area of phrase alignment, Ko (2006) proposed a method for verb phrase translation. For specific verb fragments (e.g. make a report to police), automatic alignment is applied to calculate the collocation relationship across two language (e.g. when make and report appear together, report often corresponds to ȸൔਢȹ), then word and phrase correspondences are generated (e.g. make a re"
2021.rocling-1.43,W01-1411,0,0.142121,"ity and differences between two languages involved, and the user might be interested in multiple ways (structures) of translating a phrase (e.g., consider the phrase “harmful to the ocean” and its translation). More recent researches concentrate on learning word translation and extracting bilingual word translation pairs from bilingual corpus, and then calculate the degree of mutual relationship between word pairs in parallel sentences, thereby deriving the precise translation (Catizone et al. (1989); Brown et al. (1990); Gale and Church (1991); Wu and Xia (1994); Fung (1995); Melamed (1995); Moore (2001)). In our system, we focus on identifying patterns and phrases by a patterns table and a word translation model which are created using statistical methods in bilingual corpora with word alignment. In the area of phrase alignment, Ko (2006) proposed a method for verb phrase translation. For specific verb fragments (e.g. make a report to police), automatic alignment is applied to calculate the collocation relationship across two language (e.g. when make and report appear together, report often corresponds to ȸൔਢȹ), then word and phrase correspondences are generated (e.g. make a report to police"
2021.rocling-1.43,J90-2002,0,0.89247,"nslations of nouns and prepositions from bilingual parallel corpora with sentence alignment, and then adjust the translations with additional information of Chinese collocations extracted from a Chinese corpus. 2 3 Related Work Machine Translation is a time-honored and yet active research area. Shifting from the rule-based approach toward data-intensive approach after the seminal paper by Brown et al.,1990, an increasing number of bilingual corpora have made statistical machine translation more and more feasible. In our work we address an aspect of machine translation is not a direct focus of Brown et al. (1990). We also consider on more general linguistic class of units in translation where the translation may not be litateral and may need a presentation that reflects the similarity and differences between two languages involved, and the user might be interested in multiple ways (structures) of translating a phrase (e.g., consider the phrase “harmful to the ocean” and its translation). More recent researches concentrate on learning word translation and extracting bilingual word translation pairs from bilingual corpus, and then calculate the degree of mutual relationship between word pairs in paralle"
2021.rocling-1.43,1994.amta-1.26,0,0.628208,"ay need a presentation that reflects the similarity and differences between two languages involved, and the user might be interested in multiple ways (structures) of translating a phrase (e.g., consider the phrase “harmful to the ocean” and its translation). More recent researches concentrate on learning word translation and extracting bilingual word translation pairs from bilingual corpus, and then calculate the degree of mutual relationship between word pairs in parallel sentences, thereby deriving the precise translation (Catizone et al. (1989); Brown et al. (1990); Gale and Church (1991); Wu and Xia (1994); Fung (1995); Melamed (1995); Moore (2001)). In our system, we focus on identifying patterns and phrases by a patterns table and a word translation model which are created using statistical methods in bilingual corpora with word alignment. In the area of phrase alignment, Ko (2006) proposed a method for verb phrase translation. For specific verb fragments (e.g. make a report to police), automatic alignment is applied to calculate the collocation relationship across two language (e.g. when make and report appear together, report often corresponds to ȸൔਢȹ), then word and phrase correspondences"
C12-3007,W99-0904,0,0.116251,"Missing"
C12-3007,gdaniec-manandise-2002-using,0,0.0846145,". More recently, Schone and Jurafsky (2000) propose to use word semantics from derived Latent Semantic Analysis (LSA) in an attempt to correct errors in morphology induction. Morphological models or morphological segmenters can be used to keep the entries in a dictionary to a minimal by taking advantage of morphological regularity in natural language. Woods (2000) proposes a method that aggressively applies morphology to broaden the coverage a lexicon to make possible more conceptual and effective indexing for information retrieval. The author used around 1,200 morphological rules. Similarly, Gdaniec and Manandise (2002) show that by exploiting affixes, they can extend the lexicon of a machine translation system to cope with OOV words. We use a similar method to expand our seed training data. More recently, Creutz and Lagus (2006) present Morfessor, an unsupervised method for segmenting words into frequent substrings that are similar to morphemes. The method is based on 52 Figure 1: A system screen shot. the principle of minimal description length (MDL), not unlike previous work such as Brent et al. (1995) and Goldsmith (2001). Additionally, Morfessor is enhanced by HMM states of prefix, stems, suffix, and no"
C12-3007,J01-2001,0,0.0952403,"retrieval. The author used around 1,200 morphological rules. Similarly, Gdaniec and Manandise (2002) show that by exploiting affixes, they can extend the lexicon of a machine translation system to cope with OOV words. We use a similar method to expand our seed training data. More recently, Creutz and Lagus (2006) present Morfessor, an unsupervised method for segmenting words into frequent substrings that are similar to morphemes. The method is based on 52 Figure 1: A system screen shot. the principle of minimal description length (MDL), not unlike previous work such as Brent et al. (1995) and Goldsmith (2001). Additionally, Morfessor is enhanced by HMM states of prefix, stems, suffix, and noise based on morpheme length and successor/predecessor perplexity. The system described in this paper differs from previous work in a number of aspects: 1. Previous work has focused mostly on two way splitting into stem and suffix (or amalgam of suffixes), while we attempt to split into Latin/Greek roots often found in English words. 2. We use a small set of words with hand annotation of prefixes, suffixes, and roots. 3. We experimented with several lists of affixes and a comprehensive lexicon (i.e., the Prince"
C12-3007,W00-0712,0,0.109082,"Missing"
C12-3007,A00-1030,0,0.0529725,"training dataset by expanding a small set of seed annotated words (Section 3.1). In Step 2, we describe how to train a CRF model for word part segmentation (Section 3.2). Finally, we use the trained CRF model to construct a web-based system (Section 3.3). 3.1 Generate training data from seed data To achieve reasonable coverage, supervised methods need a large training corpus. However, corpus annotated with fine-grained word parts is hard to come by. Here we describe two strategies that use a small set of annotated words to automatically generate a larger training set. The method is not unlike Woods (2000) or Gdaniec and Manandise (2002). 3.1.1 Expanding training data using prefix and suffix lists Many words in English consist of stem, roots, and affixes. For examples, finite and in+finite, senior and senior+ity, nation and inter+nation+al+ism. Affix lists are not as difficult to come by, 53 comparing to word lists with fine-grained morphological annotations. With a list of affixes, we can iteratively and recursively attach prefixes and suffixes to words in the seed data, potentially forming a new annotated word. Since these expansions from a known word (e.g., danger) can be real words (e.g., d"
C16-2035,P13-4024,1,0.918153,"d preposition or verb, insufficient understanding of grammar, etc. Consequently, people have developed a variety of writing assisting tools to help writing. Oxford Dictionaries contains extensive vocabularies along with explanations and examples. NetSpeak manipulates Google Web 1T 5-gram to provide a way of accessing n-gram information and is capable of filling the blank, reordering the text, choosing a better preposition, etc. Meanwhile, Linggle features better n-gram retrieval performance than NetSpeak and advances some ideas such as query with specific part of speech, and operator nesting (Boisson et al., 2013). Grammarly and Ginger Software check and correct grammatical errors, but only to the extent that is fairly narrow. Write & Improve gives corrective feedback sentence by sentence and assigns an overall grade for a submitted essay. On the other hand, WriteAhead proposed an interactive writing environment which suggests subsequent patterns or collocations while the user is writing away (Yen et al., 2015). Each of the above tools indeed solves some writing problems in somewhat different ways. Yet there is no such an integrated system trying to solve all kinds of problems of writing considerately."
C16-2035,P05-1075,0,0.0134366,"introduce a new strategy for extracting synonyms from large scale monolingual corpus, and then automatic paraphrase generation with corrections. 5.1 Synonyms Extraction We separate this stage into two steps. First, we extract potential synonyms from a larges scale monolingual corpus (e.g., BNC), by exploiting different kinds of surface patterns (i.e., “ADJ and ADJ”, “ADJ or ADJ”, “NOUN but NOUN”, etc.), to the extent of adjective, verb, adverb, and noun. However, these extracted potential synonyms may contain some noise. In order to filter out nonsynonyms, we apply rank ratio (RR) statistics (Deane, 2005) and adjust the overlap coefficients of our strategy. Finally, we tune both the RR and overlap coefficient thresholds to refine extracted synonyms. 5.2 Automatic Paraphrases Generation We exploit Web-scale n-grams and word embedding to automatically generate paraphrases. First, we use large scale monolingual corpora to train a word2vec model (Mikolov et al., 2013a; Mikolov et al., 2013b). Second, we store each word with its corresponding vector, as well as its synonyms mentioned above into a database. At run-time, words in the given query are substituted by their synonyms to derive candidate p"
C16-2035,P15-1120,0,0.0260963,"e word. (i.e., one wanting to determine whether to use the word “to” between listen and music, then one can make the query “listen ?to music.”) Yet another operation “/” is to search for information related to word choice. (i.e., “receive / accept * education” can be used to reveal that receive education is used much more often than accept education.) Finally, a set of PoS symbols is defined to support queries that need more precision than the symbol “ ”. 4 Pattern Grammar Pattern grammar identifies the syntactic information of individual lexical terms (Hunston et al., 1996). As envisioned by(Hearst, 2015), writing software can be more effective if they can facilitate intensive interaction while writing in progress. (e.g., giving feedback for every word entered even with only partially written sentences or incomplete paragraphs). As described in (Yen et al., 2015), grammar patterns can be used to give instantaneous feedback while typing away, and such information can be extracted by generalizing the words nearby a term. In Figure 1, Linggle Knows provides writing suggestions by displaying extracted patterns along with examples. 5 Paraphrases and Corrections Paraphrasing is the action of restati"
C16-2035,P15-4024,1,0.917428,"tter preposition, etc. Meanwhile, Linggle features better n-gram retrieval performance than NetSpeak and advances some ideas such as query with specific part of speech, and operator nesting (Boisson et al., 2013). Grammarly and Ginger Software check and correct grammatical errors, but only to the extent that is fairly narrow. Write & Improve gives corrective feedback sentence by sentence and assigns an overall grade for a submitted essay. On the other hand, WriteAhead proposed an interactive writing environment which suggests subsequent patterns or collocations while the user is writing away (Yen et al., 2015). Each of the above tools indeed solves some writing problems in somewhat different ways. Yet there is no such an integrated system trying to solve all kinds of problems of writing considerately. As a result, we have to switch from one window to the other while trying to solve different kinds of writing problems. It is quite disturbing and sometimes upsetting, since it severely affect the efficiency and reduce the productivity of writing. Our objective is to develop a comprehensive tool which provides essential linguistic knowledge to help people obtain required information immediately and eff"
C18-2018,D16-1195,0,0.0445052,"Missing"
C18-2018,D15-1162,0,0.0178929,"as follows. In section 2, we describe our system implementation. Then, we describe the experiment settings in section 3. We report our system performance and discuss the evaluation results in section 4. Finally, we conclude our paper and explore the future direction of GEC research in section 5. 2 The GEC System In this section, we present GEC Cool English, a web-based system where users can write their essays and get corrective feedback (available at https://nlp-ultron.cs.nthu.edu.tw/gec/). The correction process is divided into three steps. First, we use spaCy1 to tokenize input sentences (Honnibal and Johnson, 2015). Second, the tokenized sentences are converted into lowercase and fed into the NMT model for inference. We then re-capitalize the model predictions using truecaser2 . Finally, to give easyto-read feedback, we convert the result into an informative visual expression instead of the NMT model This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 1 https://spacy.io 2 https://github.com/nreimers/truecaser License details: http:// 82 Proceedings of the 27th International Conference on Computational Linguistics: System Demonstratio"
C18-2018,P17-1070,0,0.150097,"Missing"
C18-2018,P17-4012,0,0.0158088,"n in Figure1). Figure 1: The screenshot of the system GEC Cool English 2.1 Model Implementation We build our NMT model upon the neural sequence-to-sequence (Seq2Seq) framework proposed by Luong et al. (2015), where both encoder and decoder are recurrent neural networks (RNNs). We further extend our NMT model by adding residual connections among the recurrent layers, which has suggested improving the gradient flow during training. To select the best NMT model for our GEC system, we explore word-based model (W ORD) and subword-based model (S UBWORD). Our NMT models are implemented with OpenNMT (Klein et al., 2017), a comprehensive library for training and deploying NMT models. 3 Experiments 3.1 Dataset For training data, we use the EF-Cambridge Open Language Database (EFCAMDAT) (Geertzen et al., 2013), which is currently the largest publicly available learner corpus. EFCAMDAT contains about 1.2 million essays with over 83 million words written by approximately 174 thousand learners with a variety of CEFR levels (A1-C2). We extract parallel sentences from those essays, resulting in about 7 million pairs of parallel sentences and 2.4 million of them contain at least one edit. To the best of our knowledge"
C18-2018,D15-1166,0,0.0269167,"mmons.org/licenses/by/4.0/ 1 https://spacy.io 2 https://github.com/nreimers/truecaser License details: http:// 82 Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations, pages 82–85 Santa Fe, New Mexico, USA, August 20-26, 2018. output directly. Words to be deleted are marked with strikethrough and colored red, while words to be inserted are colored green (as shown in Figure1). Figure 1: The screenshot of the system GEC Cool English 2.1 Model Implementation We build our NMT model upon the neural sequence-to-sequence (Seq2Seq) framework proposed by Luong et al. (2015), where both encoder and decoder are recurrent neural networks (RNNs). We further extend our NMT model by adding residual connections among the recurrent layers, which has suggested improving the gradient flow during training. To select the best NMT model for our GEC system, we explore word-based model (W ORD) and subword-based model (S UBWORD). Our NMT models are implemented with OpenNMT (Klein et al., 2017), a comprehensive library for training and deploying NMT models. 3 Experiments 3.1 Dataset For training data, we use the EF-Cambridge Open Language Database (EFCAMDAT) (Geertzen et al., 20"
C18-2018,E17-2037,0,0.0140831,"s of parallel sentences and 2.4 million of them contain at least one edit. To the best of our knowledge, we are the first group to exploit EFCAMDAT corpus for GEC tasks. To compare our systems with other works, we also use the following frequently used learner corpora: the Lang-8 Corpus of Learner English (L8) 3 , the Cambridge First Certificate English (FCE) exam scripts (Yannakoudakis et al., 2011), which is a subset of proprietary Cambridge Learner Corpus (CLC), and the NUS Corpus of Learner English (NUCLE). For development and test data, we use the JHU FLuency-Extended GUG corpus (JFLEG) (Napoles et al., 2017), which is designed for evaluating fluency and grammaticality. JFLEG corpus consists of 1,501 pairs of erroneous and corrected sentences, in which 754 pairs are development data and 747 pairs test data. 3.2 Preprocessing First, noisy sentences are excluded: sentences with URLs, E-mail, XML-like tags, etc., sentences less than 3 words or more than 50 tokens, and sentences that start with a non alphabetic character or do not end with a punctuation mark. Next, name entities are recognized with spaCy and correct spelling errors on non-name-entity tokens with Enchant. 4 We then re-capitalize senten"
C18-2018,Q14-1033,0,0.0275087,"language is not at all easy, especially in the area of writing. Due to the limited vocabulary and inadequate command of grammar, second language learners are prone to misspelled words and write ungrammatical sentences. The demand for grammatical error correction (GEC) has encouraged researchers to develop technology to support the writing process. Correcting grammatical errors with statistical machine translation (SMT) techniques has gained great success (Brockett et al., 2006). Translating an ungrammatical sentence into a correct one can effectively handle all types of errors simultaneously (Rozovskaya and Roth, 2014). More recently, Rozovskaya and Roth (2016) compares the strength and the weakness of classifier-based and SMT-based approaches, and integrates both of them to build a hybrid GEC system. Recently, Yuan and Briscoe (2016) presents the very first word-based neural machine translation (NMT) model for GEC and proposes a two-step approach to handle the rare word problem. Xie et al. (2016) proposes a character-based NMT model, achieving open vocabulary machine translation. Sennrich et al. (2016) purposes a subword-based model with Byte-Pair Encoding (BPE) algorithm, which only splits rare words and"
C18-2018,P16-1208,0,0.0275739,"the area of writing. Due to the limited vocabulary and inadequate command of grammar, second language learners are prone to misspelled words and write ungrammatical sentences. The demand for grammatical error correction (GEC) has encouraged researchers to develop technology to support the writing process. Correcting grammatical errors with statistical machine translation (SMT) techniques has gained great success (Brockett et al., 2006). Translating an ungrammatical sentence into a correct one can effectively handle all types of errors simultaneously (Rozovskaya and Roth, 2014). More recently, Rozovskaya and Roth (2016) compares the strength and the weakness of classifier-based and SMT-based approaches, and integrates both of them to build a hybrid GEC system. Recently, Yuan and Briscoe (2016) presents the very first word-based neural machine translation (NMT) model for GEC and proposes a two-step approach to handle the rare word problem. Xie et al. (2016) proposes a character-based NMT model, achieving open vocabulary machine translation. Sennrich et al. (2016) purposes a subword-based model with Byte-Pair Encoding (BPE) algorithm, which only splits rare words and leaves frequent words unsegmented. The rema"
C18-2018,I17-2062,0,0.13867,"Missing"
C18-2018,P16-1162,0,0.0202198,"ungrammatical sentence into a correct one can effectively handle all types of errors simultaneously (Rozovskaya and Roth, 2014). More recently, Rozovskaya and Roth (2016) compares the strength and the weakness of classifier-based and SMT-based approaches, and integrates both of them to build a hybrid GEC system. Recently, Yuan and Briscoe (2016) presents the very first word-based neural machine translation (NMT) model for GEC and proposes a two-step approach to handle the rare word problem. Xie et al. (2016) proposes a character-based NMT model, achieving open vocabulary machine translation. Sennrich et al. (2016) purposes a subword-based model with Byte-Pair Encoding (BPE) algorithm, which only splits rare words and leaves frequent words unsegmented. The remainder of this paper is structured as follows. In section 2, we describe our system implementation. Then, we describe the experiment settings in section 3. We report our system performance and discuss the evaluation results in section 4. Finally, we conclude our paper and explore the future direction of GEC research in section 5. 2 The GEC System In this section, we present GEC Cool English, a web-based system where users can write their essays and"
C18-2018,P11-1019,0,0.173778,"ins about 1.2 million essays with over 83 million words written by approximately 174 thousand learners with a variety of CEFR levels (A1-C2). We extract parallel sentences from those essays, resulting in about 7 million pairs of parallel sentences and 2.4 million of them contain at least one edit. To the best of our knowledge, we are the first group to exploit EFCAMDAT corpus for GEC tasks. To compare our systems with other works, we also use the following frequently used learner corpora: the Lang-8 Corpus of Learner English (L8) 3 , the Cambridge First Certificate English (FCE) exam scripts (Yannakoudakis et al., 2011), which is a subset of proprietary Cambridge Learner Corpus (CLC), and the NUS Corpus of Learner English (NUCLE). For development and test data, we use the JHU FLuency-Extended GUG corpus (JFLEG) (Napoles et al., 2017), which is designed for evaluating fluency and grammaticality. JFLEG corpus consists of 1,501 pairs of erroneous and corrected sentences, in which 754 pairs are development data and 747 pairs test data. 3.2 Preprocessing First, noisy sentences are excluded: sentences with URLs, E-mail, XML-like tags, etc., sentences less than 3 words or more than 50 tokens, and sentences that sta"
C18-2018,N16-1042,0,0.0609725,"demand for grammatical error correction (GEC) has encouraged researchers to develop technology to support the writing process. Correcting grammatical errors with statistical machine translation (SMT) techniques has gained great success (Brockett et al., 2006). Translating an ungrammatical sentence into a correct one can effectively handle all types of errors simultaneously (Rozovskaya and Roth, 2014). More recently, Rozovskaya and Roth (2016) compares the strength and the weakness of classifier-based and SMT-based approaches, and integrates both of them to build a hybrid GEC system. Recently, Yuan and Briscoe (2016) presents the very first word-based neural machine translation (NMT) model for GEC and proposes a two-step approach to handle the rare word problem. Xie et al. (2016) proposes a character-based NMT model, achieving open vocabulary machine translation. Sennrich et al. (2016) purposes a subword-based model with Byte-Pair Encoding (BPE) algorithm, which only splits rare words and leaves frequent words unsegmented. The remainder of this paper is structured as follows. In section 2, we describe our system implementation. Then, we describe the experiment settings in section 3. We report our system p"
C18-2022,D14-1110,0,0.0205992,"g “plant”. 2 Related Work Word sense disambiguation (WSD) has been an area of active research. WSD involves predicting the intended sense of a word in context based on a predefined set of senses. (Resnik and Yarowsky, 1999) use translate distinctions in the foreign language to identify sense distinctions in the source language for word sense disambiguation. Recent work (e.g., Guo et al. (2014)), Upadhyay et al. (2017) also use parallel or mutilingual corpora to learn muti-sense vectors and capture different meanings of the same word in word sense disambiguation. In the area of word embedding, Chen et al. (2014) and Iacobacci et al. (2016) propose to use word embeddings instead of surface word as features to improve WSD performance. Yuan et al. (2016) propose to use similarity based on word embedding to identify the intended word sense. 3 Method Problem Statement: We are given a polysemy W . We want to disambiguating the meaning of a word in sentences from a parallel corpus by providing bilingual examples for different senses of a word. Our goal is to find good examples for a given sense in WordNet. For this, we use a word-aligned parallel corpus, and then extract and classify translations for each W"
C18-2022,C14-1048,0,0.0207892,"tails: http:// 99 Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations, pages 99–102 Santa Fe, New Mexico, USA, August 20-26, 2018. Figure 1: Example using LanguageNet typing “plant”. 2 Related Work Word sense disambiguation (WSD) has been an area of active research. WSD involves predicting the intended sense of a word in context based on a predefined set of senses. (Resnik and Yarowsky, 1999) use translate distinctions in the foreign language to identify sense distinctions in the source language for word sense disambiguation. Recent work (e.g., Guo et al. (2014)), Upadhyay et al. (2017) also use parallel or mutilingual corpora to learn muti-sense vectors and capture different meanings of the same word in word sense disambiguation. In the area of word embedding, Chen et al. (2014) and Iacobacci et al. (2016) propose to use word embeddings instead of surface word as features to improve WSD performance. Yuan et al. (2016) propose to use similarity based on word embedding to identify the intended word sense. 3 Method Problem Statement: We are given a polysemy W . We want to disambiguating the meaning of a word in sentences from a parallel corpus by provi"
C18-2022,P16-1085,0,0.0164403,"rk Word sense disambiguation (WSD) has been an area of active research. WSD involves predicting the intended sense of a word in context based on a predefined set of senses. (Resnik and Yarowsky, 1999) use translate distinctions in the foreign language to identify sense distinctions in the source language for word sense disambiguation. Recent work (e.g., Guo et al. (2014)), Upadhyay et al. (2017) also use parallel or mutilingual corpora to learn muti-sense vectors and capture different meanings of the same word in word sense disambiguation. In the area of word embedding, Chen et al. (2014) and Iacobacci et al. (2016) propose to use word embeddings instead of surface word as features to improve WSD performance. Yuan et al. (2016) propose to use similarity based on word embedding to identify the intended word sense. 3 Method Problem Statement: We are given a polysemy W . We want to disambiguating the meaning of a word in sentences from a parallel corpus by providing bilingual examples for different senses of a word. Our goal is to find good examples for a given sense in WordNet. For this, we use a word-aligned parallel corpus, and then extract and classify translations for each W in question. Once the trans"
C18-2022,tian-etal-2014-um,0,0.0316604,"ambiguating the meaning of a word in sentences from a parallel corpus by providing bilingual examples for different senses of a word. Our goal is to find good examples for a given sense in WordNet. For this, we use a word-aligned parallel corpus, and then extract and classify translations for each W in question. Once the translations are classified and sense-tagged, we can then select example sentences for a given word sense. 3.1 Aligning and Extracting Word Translations We use a large English-Chinese parallel corpus, UM-Corpus to obtain diverse kind of translations of a source-language word (Tian et al., 2014). For this, we use a word aligner, fast align (Dyer et al., 2013) to produce word alignments between the source words and translations in a parallel corpus. Then, for every pair of English word and translation, we computes pair similarity based on Dice coefficient and extract and classify translation words which frequently appear together with Dice similarity higher than a threshold. In the final step, we use these pairs of English and Chinese words to select example sentences and generate sense-tagged data. 3.2 Translation Similarity and Sense Labeling In order to classify a given translation"
C18-2022,W17-2613,0,0.0251099,"oceedings of the 27th International Conference on Computational Linguistics: System Demonstrations, pages 99–102 Santa Fe, New Mexico, USA, August 20-26, 2018. Figure 1: Example using LanguageNet typing “plant”. 2 Related Work Word sense disambiguation (WSD) has been an area of active research. WSD involves predicting the intended sense of a word in context based on a predefined set of senses. (Resnik and Yarowsky, 1999) use translate distinctions in the foreign language to identify sense distinctions in the source language for word sense disambiguation. Recent work (e.g., Guo et al. (2014)), Upadhyay et al. (2017) also use parallel or mutilingual corpora to learn muti-sense vectors and capture different meanings of the same word in word sense disambiguation. In the area of word embedding, Chen et al. (2014) and Iacobacci et al. (2016) propose to use word embeddings instead of surface word as features to improve WSD performance. Yuan et al. (2016) propose to use similarity based on word embedding to identify the intended word sense. 3 Method Problem Statement: We are given a polysemy W . We want to disambiguating the meaning of a word in sentences from a parallel corpus by providing bilingual examples f"
C96-1037,J90-2002,0,0.396745,"Missing"
C96-1037,J93-2003,0,0.0331579,"Missing"
C96-1037,W93-0301,0,0.287827,"Missing"
C96-1037,C94-1084,0,0.0538483,"Missing"
C96-1037,H91-1026,0,0.299938,"Missing"
C96-1037,1992.tmi-1.9,0,0.214051,"Missing"
C96-1037,P93-1004,0,0.293829,"Missing"
C96-1037,J96-1001,0,\N,Missing
C96-1037,J93-1004,0,\N,Missing
C96-1037,1994.amta-1.26,0,\N,Missing
C96-1037,J94-4005,0,\N,Missing
C96-1037,C92-2070,0,\N,Missing
C96-1037,C94-2175,0,\N,Missing
C96-1037,C94-2125,0,\N,Missing
C96-1037,C94-2178,0,\N,Missing
C96-1037,C94-2195,0,\N,Missing
C96-1037,P93-1001,0,\N,Missing
C96-1037,P91-1022,0,\N,Missing
C96-1037,J93-1006,0,\N,Missing
C96-1037,P93-1002,0,\N,Missing
C96-1037,Y95-1015,1,\N,Missing
C98-1037,P91-1034,0,0.163168,"Missing"
C98-1037,J98-1003,1,0.849231,"bank~GEOGRAPHY, but certain instances of bank are left untagged for lack of relevant WSD 238 knowledge. For instance, the GEO-bank sense in the context of vole is unresolved since there is no information linking ANIMAL context to GEOGRAPHY sense of bank. The adaptation step adds deer and ANIMAL to the contextual representation for GEO-bank. The enriched CR therefore contains information capable of disambiguating the instance of bank in the context of vole to produce final disambiguation result. 2 Acquiring Conceptual from MRD Knowledge In this section we apply a so-called ?bpSense algorithm (Chen and Chang 1998) to acquire CR for MRD senses. The current implementation of TopSense uses the topical information in Longman Lexicon of Contemporary English (McArthur 1992, LLOCE) to represent WSD knowledge for LDOCE senses. In the following subsections we describe how that is done. 2.1 Contextual MRDs Representation from Dictionary is a text whose subject matter is a language. The purpose of dictionary is to provide definitions of word senses, and in the process it supply knowledge not just about the language, but the world (Wilks et al. 1990). A good-sized dictionary usually has a large vocabulary and good"
C98-1037,J94-4003,0,0.260717,"Missing"
C98-1037,1992.tmi-1.9,0,0.616645,"Missing"
C98-1037,H92-1045,0,0.205507,"Missing"
C98-1037,W93-0303,0,0.0264805,"stems have been developed using word-based model for specific limited domain to disambiguate senses appearing in usually easy context (Leacock, Towell, and Voorlees 1996) with a lot of typical salient words. For unrestricted text, however, the context tends to be very diverse and difficult to capture with a lexicalized model, therefore a corpus-trained system is unlikely to port to new domains and run off the shelf. Generality and adaptiveness are therefore key to a robust and portable WSD system. A concept-based model for WSD requires less parameter and has an element of generality built in (Liddy and Paik 1993). Conceptual classes make it possible to generalize from wordspecific context in order to disambiguate a word sense appearing in a particularly unfamiliar context in term of word recurrences. An adaptive system armed with an initial lexical and conceptual knowledge base extracted from machine-readable dictionaries (MRDs), has two strong advantages over static lexicalized models trained using a corpus. First, the initial 237 knowledge is rich and unbiased such that a substantial portion of text can be disambiguated precisely. Second, based on the result of initial ~_ disambiguated text. Subsequ"
C98-1037,P95-1025,0,0.265323,"Missing"
C98-1037,P95-1026,0,0.291116,"ms proposed in the literature, almost all have the property that the knowledge is fixed when the system completes the training phase. That means the acquired knowledge never expands during the course of disambiguation. Gale, et al. (1992a) report that if one had obtained a set of training materials with errors no more than twenty to thirty percent, one could iterate training materials selection just once or twice and have training sets that had less than ten percent errors. The adaptive approach is somehow similar to their idea of incremental learning and to the bootstrap approach proposed by Yarowsky (1995). However, both approaches are still considered static models which are changed only in the training phase. 242 6 Conclusions We have described a new adaptive approach to word sense disambiguation. Under this learning strategy, first contextual representation for each word sense is built fiom the sense definition in MRD and represented as a weighted-vector of concepts represented as word lists in a thesaurus. Then the knowledge base is applied to the text for WSD in an adaptive fashion to improve on disambiguation precision. We have demonstrated that this approach has the potential of outperfo"
chang-etal-1998-taxonomy,W91-0213,0,\N,Missing
chang-etal-1998-taxonomy,J87-3005,0,\N,Missing
chang-etal-1998-taxonomy,J98-1003,1,\N,Missing
chang-etal-1998-taxonomy,C94-2113,0,\N,Missing
chang-etal-1998-taxonomy,C94-2125,0,\N,Missing
chang-etal-1998-taxonomy,C92-2082,0,\N,Missing
chang-etal-1998-taxonomy,P85-1037,0,\N,Missing
chang-etal-1998-taxonomy,A92-1011,0,\N,Missing
chang-etal-1998-taxonomy,P88-1027,0,\N,Missing
chang-etal-1998-taxonomy,P98-1037,1,\N,Missing
chang-etal-1998-taxonomy,C98-1037,1,\N,Missing
chang-etal-1998-taxonomy,J93-1006,0,\N,Missing
chang-etal-1998-taxonomy,J97-2004,1,\N,Missing
chang-etal-1998-taxonomy,P81-1030,0,\N,Missing
chuang-etal-2002-adaptive,J93-1004,0,\N,Missing
chuang-etal-2002-adaptive,J99-1003,0,\N,Missing
chuang-etal-2002-adaptive,A00-1018,0,\N,Missing
chuang-etal-2002-adaptive,J93-2003,0,\N,Missing
chuang-etal-2002-adaptive,C02-1009,0,\N,Missing
chuang-etal-2002-adaptive,P01-1067,0,\N,Missing
chuang-etal-2002-adaptive,P91-1022,0,\N,Missing
chuang-etal-2002-adaptive,J93-1006,0,\N,Missing
chuang-etal-2002-adaptive,J97-2004,1,\N,Missing
chuang-etal-2002-adaptive,P94-1012,0,\N,Missing
chuang-etal-2002-adaptive,P93-1002,0,\N,Missing
chuang-etal-2002-adaptive,O01-3004,1,\N,Missing
D07-1106,C02-1011,0,0.0200485,"h to perform back transliteration from Japanese to English based on the model. In our work we address an issue of producing transliteration by way of search. Goto et al. (2003), and Li et al. (2004) proposed a grapheme-based transliteration model. Hybrid transliteration models were described by AlOnaizan and Knight (2002), and Oh et al. (2005). Recently, some of the machine transliteration study has begun to consider the problem of extracting names and their transliterations from parallel corpora (Qu and Grefenstette 2004, Lin, Wu and Chang 2004; Lee and Chang 2003, Li and Grefenstette 2005). Cao and Li (2002) described a new method for base noun phrase translation by using Web data. Kwok, et al. (2001) described a system called CHINET for cross language name search. Nagata et al. (2001) described how to exploit proximity and redundancy to extract translation for a given term. Lu, Chien, and Lee (2002) describe a method for name translation based on mining of anchor texts. More recently, Zhang, Huang, and Vogel (2005) proposed to use occurring words to expand queries for searching and extracting transliterations. Oh and Isahara (2006) use phonetic-similarity to recognize transliteration pairs on th"
D07-1106,2003.mtsummit-papers.17,0,0.0306915,"# of correct 263 67 23 answers Applicability 0.60 0.29 0.09 Precision 0.89 0.46 0.52 Recall 0.53 0.13 0.05 F-measure 0.66 0.21 0.08 6 Comparison with Previous Work Machine transliteration has been an area of active research. Most of the machine transliteration method attempts to model the transliteration process of mapping between graphemes and phonemes. Knight and Graehl (1998) proposed a multilayer model and a generate-and-test approach to perform back transliteration from Japanese to English based on the model. In our work we address an issue of producing transliteration by way of search. Goto et al. (2003), and Li et al. (2004) proposed a grapheme-based transliteration model. Hybrid transliteration models were described by AlOnaizan and Knight (2002), and Oh et al. (2005). Recently, some of the machine transliteration study has begun to consider the problem of extracting names and their transliterations from parallel corpora (Qu and Grefenstette 2004, Lin, Wu and Chang 2004; Lee and Chang 2003, Li and Grefenstette 2005). Cao and Li (2002) described a new method for base noun phrase translation by using Web data. Kwok, et al. (2001) described a system called CHINET for cross language name search"
D07-1106,W03-1502,0,0.0326456,"Missing"
D07-1106,J03-3001,0,0.121625,"Missing"
D07-1106,J98-4003,0,0.15155,"ability 0.48 0.60 # Correct Answers 209 263 Precision 0.88 0.89 Recall 0.42 0.53 F-measure 0.57 0.66 Table 11. Performance evaluation of three systems Yahoo! Method TermMine Google QE+ Translate Babelfish Evaluation # of cases done 300 146 44 # of correct 263 67 23 answers Applicability 0.60 0.29 0.09 Precision 0.89 0.46 0.52 Recall 0.53 0.13 0.05 F-measure 0.66 0.21 0.08 6 Comparison with Previous Work Machine transliteration has been an area of active research. Most of the machine transliteration method attempts to model the transliteration process of mapping between graphemes and phonemes. Knight and Graehl (1998) proposed a multilayer model and a generate-and-test approach to perform back transliteration from Japanese to English based on the model. In our work we address an issue of producing transliteration by way of search. Goto et al. (2003), and Li et al. (2004) proposed a grapheme-based transliteration model. Hybrid transliteration models were described by AlOnaizan and Knight (2002), and Oh et al. (2005). Recently, some of the machine transliteration study has begun to consider the problem of extracting names and their transliterations from parallel corpora (Qu and Grefenstette 2004, Lin, Wu and"
D07-1106,P03-1040,0,0.0310623,"Missing"
D07-1106,P93-1003,0,0.154202,"Missing"
D07-1106,W03-0317,1,0.85599,"ultilayer model and a generate-and-test approach to perform back transliteration from Japanese to English based on the model. In our work we address an issue of producing transliteration by way of search. Goto et al. (2003), and Li et al. (2004) proposed a grapheme-based transliteration model. Hybrid transliteration models were described by AlOnaizan and Knight (2002), and Oh et al. (2005). Recently, some of the machine transliteration study has begun to consider the problem of extracting names and their transliterations from parallel corpora (Qu and Grefenstette 2004, Lin, Wu and Chang 2004; Lee and Chang 2003, Li and Grefenstette 2005). Cao and Li (2002) described a new method for base noun phrase translation by using Web data. Kwok, et al. (2001) described a system called CHINET for cross language name search. Nagata et al. (2001) described how to exploit proximity and redundancy to extract translation for a given term. Lu, Chien, and Lee (2002) describe a method for name translation based on mining of anchor texts. More recently, Zhang, Huang, and Vogel (2005) proposed to use occurring words to expand queries for searching and extracting transliterations. Oh and Isahara (2006) use phonetic-simil"
D07-1106,P04-1021,0,0.0338426,"answers Applicability 0.60 0.29 0.09 Precision 0.89 0.46 0.52 Recall 0.53 0.13 0.05 F-measure 0.66 0.21 0.08 6 Comparison with Previous Work Machine transliteration has been an area of active research. Most of the machine transliteration method attempts to model the transliteration process of mapping between graphemes and phonemes. Knight and Graehl (1998) proposed a multilayer model and a generate-and-test approach to perform back transliteration from Japanese to English based on the model. In our work we address an issue of producing transliteration by way of search. Goto et al. (2003), and Li et al. (2004) proposed a grapheme-based transliteration model. Hybrid transliteration models were described by AlOnaizan and Knight (2002), and Oh et al. (2005). Recently, some of the machine transliteration study has begun to consider the problem of extracting names and their transliterations from parallel corpora (Qu and Grefenstette 2004, Lin, Wu and Chang 2004; Lee and Chang 2003, Li and Grefenstette 2005). Cao and Li (2002) described a new method for base noun phrase translation by using Web data. Kwok, et al. (2001) described a system called CHINET for cross language name search. Nagata et al. (2001)"
D07-1106,lin-etal-2004-extraction,1,0.904594,"Missing"
D07-1106,W01-1413,0,0.296795,"and Li et al. (2004) proposed a grapheme-based transliteration model. Hybrid transliteration models were described by AlOnaizan and Knight (2002), and Oh et al. (2005). Recently, some of the machine transliteration study has begun to consider the problem of extracting names and their transliterations from parallel corpora (Qu and Grefenstette 2004, Lin, Wu and Chang 2004; Lee and Chang 2003, Li and Grefenstette 2005). Cao and Li (2002) described a new method for base noun phrase translation by using Web data. Kwok, et al. (2001) described a system called CHINET for cross language name search. Nagata et al. (2001) described how to exploit proximity and redundancy to extract translation for a given term. Lu, Chien, and Lee (2002) describe a method for name translation based on mining of anchor texts. More recently, Zhang, Huang, and Vogel (2005) proposed to use occurring words to expand queries for searching and extracting transliterations. Oh and Isahara (2006) use phonetic-similarity to recognize transliteration pairs on the Web. In contrast to previous work, we propose a simple method for extracting transliterations based on a statistical model trained automatically on a bilingual name list via unsup"
D07-1106,I05-1040,0,0.0238128,"Missing"
D07-1106,P04-1024,0,0.0161031,"nd phonemes. Knight and Graehl (1998) proposed a multilayer model and a generate-and-test approach to perform back transliteration from Japanese to English based on the model. In our work we address an issue of producing transliteration by way of search. Goto et al. (2003), and Li et al. (2004) proposed a grapheme-based transliteration model. Hybrid transliteration models were described by AlOnaizan and Knight (2002), and Oh et al. (2005). Recently, some of the machine transliteration study has begun to consider the problem of extracting names and their transliterations from parallel corpora (Qu and Grefenstette 2004, Lin, Wu and Chang 2004; Lee and Chang 2003, Li and Grefenstette 2005). Cao and Li (2002) described a new method for base noun phrase translation by using Web data. Kwok, et al. (2001) described a system called CHINET for cross language name search. Nagata et al. (2001) described how to exploit proximity and redundancy to extract translation for a given term. Lu, Chien, and Lee (2002) describe a method for name translation based on mining of anchor texts. More recently, Zhang, Huang, and Vogel (2005) proposed to use occurring words to expand queries for searching and extracting transliteratio"
D09-1050,W08-0409,0,0.0115469,"nt based methods, which are highly dependent on the probability information at the lexical level, are not well suited for this type of translation. To address the above problem, some methods have been proposed for extending word alignments to phrase alignments. For example, Och et al. (1999) proposed the so-called grow-diagfinal heuristic method for extending word alignments to phrase alignments. The method is widely used and has achieved good results for phrase-based statistical machine translation. (Och et al., 1999; Koehn et al., 2003; Liang et al., 2006). Instead of using heuristic rules, Ma et al. (2008) showed that syntactic information, e.g., phrase or dependency structures, is useful in extending the word-level alignment. However, the above methods still depend on word-based alignment models, so they are not well suited to extracting the translation equivalences of semantically opaque MWEs due to the lack of word level relations between the translational correspondences. Moreover, the aligned phrases are not precise enough to be used in many NLP applications like dictionary compilation, which require high quality translations. Association-based methods, e.g., the Dice coefficient, are wide"
D09-1050,P00-1056,0,0.408126,"Missing"
D09-1050,W99-0604,0,0.422703,"wan mhbai@sinica.edu.tw, swimming@hp.iis.sinica.edu.tw, kchen@iis.sinica.edu.tw, jschang@cs.nthu.edu.tw Since many concepts are expressed by idiomatic multiword expressions instead of single words, and different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997), word alignment based methods, which are highly dependent on the probability information at the lexical level, are not well suited for this type of translation. To address the above problem, some methods have been proposed for extending word alignments to phrase alignments. For example, Och et al. (1999) proposed the so-called grow-diagfinal heuristic method for extending word alignments to phrase alignments. The method is widely used and has achieved good results for phrase-based statistical machine translation. (Och et al., 1999; Koehn et al., 2003; Liang et al., 2006). Instead of using heuristic rules, Ma et al. (2008) showed that syntactic information, e.g., phrase or dependency structures, is useful in extending the word-level alignment. However, the above methods still depend on word-based alignment models, so they are not well suited to extracting the translation equivalences of semant"
D09-1050,P02-1040,0,0.0937907,"Missing"
D09-1050,J96-1001,0,0.447428,"ndency structures, is useful in extending the word-level alignment. However, the above methods still depend on word-based alignment models, so they are not well suited to extracting the translation equivalences of semantically opaque MWEs due to the lack of word level relations between the translational correspondences. Moreover, the aligned phrases are not precise enough to be used in many NLP applications like dictionary compilation, which require high quality translations. Association-based methods, e.g., the Dice coefficient, are widely used to extract translations of MWEs. (Kupiec, 1993; Smadja et al., 1996; Kitamura and Matsumoto, 1996; Yamamoto and Matsumoto, 2000; Melamed, 2001). The advantage of such methods is that association relations are established at the phrase level instead of the lexical level, so they have the potential to resolve the above-mentioned translation problem. However, when applying association-based methods, we have to consider the following complications. The first complication, which we call the contextual effect, causes the extracted translation to contain noisy words. For Abstract In this paper, we present an algorithm for extracting translations of any given multiwo"
D09-1050,J97-3002,0,0.0648867,"Missing"
D09-1050,P03-1016,0,0.0218972,"eriments show that our approach outperforms the word alignmentbased and other naive association-based methods. We also demonstrate that adopting the extracted translations can significantly improve the performance of the Moses machine translation system. 1 Introduction Translation of multiword expressions (MWEs), such as compound words, phrases, collocations and idioms, is important for many NLP tasks, including the techniques are helpful for dictionary compilation, cross language information retrieval, second language learning, and machine translation. (Smadja et al., 1996; Gao et al., 2002; Wu and Zhou, 2003). However, extracting exact translations of MWEs is still an open problem, possibly because the senses of many MWEs are not compositional (Yamamoto and Matsumoto, 2000), i.e., their translations are not compositions of the translations of individual words. For example, the Chinese idiom 坐視不理 should be translated as “turn a blind eye,” which has no direct relation with respect to the translation of each constituent (i.e., “to sit”, “to see” and “to ignore”) at the word level. Previous SMT systems (e.g., Brown et al., 1993) used a word-based translation model which assumes that a sentence can be"
D09-1050,W96-0107,0,0.220037,"useful in extending the word-level alignment. However, the above methods still depend on word-based alignment models, so they are not well suited to extracting the translation equivalences of semantically opaque MWEs due to the lack of word level relations between the translational correspondences. Moreover, the aligned phrases are not precise enough to be used in many NLP applications like dictionary compilation, which require high quality translations. Association-based methods, e.g., the Dice coefficient, are widely used to extract translations of MWEs. (Kupiec, 1993; Smadja et al., 1996; Kitamura and Matsumoto, 1996; Yamamoto and Matsumoto, 2000; Melamed, 2001). The advantage of such methods is that association relations are established at the phrase level instead of the lexical level, so they have the potential to resolve the above-mentioned translation problem. However, when applying association-based methods, we have to consider the following complications. The first complication, which we call the contextual effect, causes the extracted translation to contain noisy words. For Abstract In this paper, we present an algorithm for extracting translations of any given multiword expression from parallel co"
D09-1050,C00-2135,0,0.625212,"level alignment. However, the above methods still depend on word-based alignment models, so they are not well suited to extracting the translation equivalences of semantically opaque MWEs due to the lack of word level relations between the translational correspondences. Moreover, the aligned phrases are not precise enough to be used in many NLP applications like dictionary compilation, which require high quality translations. Association-based methods, e.g., the Dice coefficient, are widely used to extract translations of MWEs. (Kupiec, 1993; Smadja et al., 1996; Kitamura and Matsumoto, 1996; Yamamoto and Matsumoto, 2000; Melamed, 2001). The advantage of such methods is that association relations are established at the phrase level instead of the lexical level, so they have the potential to resolve the above-mentioned translation problem. However, when applying association-based methods, we have to consider the following complications. The first complication, which we call the contextual effect, causes the extracted translation to contain noisy words. For Abstract In this paper, we present an algorithm for extracting translations of any given multiword expression from parallel corpora. Given a multiword expre"
D09-1050,N03-1017,0,0.177942,"using different numbers of words (Ma et al., 2007; Wu, 1997), word alignment based methods, which are highly dependent on the probability information at the lexical level, are not well suited for this type of translation. To address the above problem, some methods have been proposed for extending word alignments to phrase alignments. For example, Och et al. (1999) proposed the so-called grow-diagfinal heuristic method for extending word alignments to phrase alignments. The method is widely used and has achieved good results for phrase-based statistical machine translation. (Och et al., 1999; Koehn et al., 2003; Liang et al., 2006). Instead of using heuristic rules, Ma et al. (2008) showed that syntactic information, e.g., phrase or dependency structures, is useful in extending the word-level alignment. However, the above methods still depend on word-based alignment models, so they are not well suited to extracting the translation equivalences of semantically opaque MWEs due to the lack of word level relations between the translational correspondences. Moreover, the aligned phrases are not precise enough to be used in many NLP applications like dictionary compilation, which require high quality tran"
D09-1050,W04-3250,0,0.145883,"Missing"
D09-1050,P07-2045,0,0.00646883,"shold 2 . The second type of information is the phrase translation probability and lexical weighting. Computing the phrase translation probability is trivial in the training corpora, but lexical weighting (Koehn et al., 2003) needs lexical-level alignment. For convenience, we assume that each word in an MWE links to each word in the translations. Under this assumption, the lexical weighting is simplified as follows: n p w (f |e, a ) = ∏ i =1 n ≅∏ i =1 1 ∑ p( f i |e j ) |{ j |(i, j ) ∈ a} |∀ ( i , j )∈a 1 ∑ p( fi |e j ) . |e |∀e j ∈e 5 Evaluation Results We trained a model using Moses toolkit (Koehn et al., 2007) on the training data as our baseline system. Table 9 shows the influence of adding the MWE translations to the test data. In the first 2 Conclusions and Future Work We have proposed a high precision algorithm for extracting translations of multiword expressions from parallel corpora. The algorithm can be used to translate any language pair and any type of word sequence, including rigid sequences and discontinuous sequences. Our evaluation results show that the algorithm can cope with the difficulties caused by indirect association and the common subsequence effects, leading to significant imp"
D09-1050,P93-1003,0,0.424216,"phrase or dependency structures, is useful in extending the word-level alignment. However, the above methods still depend on word-based alignment models, so they are not well suited to extracting the translation equivalences of semantically opaque MWEs due to the lack of word level relations between the translational correspondences. Moreover, the aligned phrases are not precise enough to be used in many NLP applications like dictionary compilation, which require high quality translations. Association-based methods, e.g., the Dice coefficient, are widely used to extract translations of MWEs. (Kupiec, 1993; Smadja et al., 1996; Kitamura and Matsumoto, 1996; Yamamoto and Matsumoto, 2000; Melamed, 2001). The advantage of such methods is that association relations are established at the phrase level instead of the lexical level, so they have the potential to resolve the above-mentioned translation problem. However, when applying association-based methods, we have to consider the following complications. The first complication, which we call the contextual effect, causes the extracted translation to contain noisy words. For Abstract In this paper, we present an algorithm for extracting translations"
D09-1050,N06-1014,0,0.0430051,"bers of words (Ma et al., 2007; Wu, 1997), word alignment based methods, which are highly dependent on the probability information at the lexical level, are not well suited for this type of translation. To address the above problem, some methods have been proposed for extending word alignments to phrase alignments. For example, Och et al. (1999) proposed the so-called grow-diagfinal heuristic method for extending word alignments to phrase alignments. The method is widely used and has achieved good results for phrase-based statistical machine translation. (Och et al., 1999; Koehn et al., 2003; Liang et al., 2006). Instead of using heuristic rules, Ma et al. (2008) showed that syntactic information, e.g., phrase or dependency structures, is useful in extending the word-level alignment. However, the above methods still depend on word-based alignment models, so they are not well suited to extracting the translation equivalences of semantically opaque MWEs due to the lack of word level relations between the translational correspondences. Moreover, the aligned phrases are not precise enough to be used in many NLP applications like dictionary compilation, which require high quality translations. Association"
D09-1050,P07-1039,0,0.0255853,"Missing"
D09-1050,J93-2003,0,\N,Missing
D14-1100,I08-1012,0,0.190676,"oncepts in an upper-level ontology. One important characteristic of adjectival verbs is that they have conjunctive morphological structures, i.e., the words are conjunct with two nearly synonymous verbs, e.g., 研/study 究 /search (research), 探 /explore 測 /detect (explore), and 搜/search 尋/find (search). Therefore, we need a morphological classifier that can detect the conjunctive morphological structure of a Related Work Most works on V-N structure identification focus on two types of relation classification: modifierhead relations and predicate-object relations (Wu, 2003; Qiu, 2005; Chen, 2008; Chen et al., 2008; Yu et al., 2008). They exclude the independent structure and conjunctive head-head relation, but the cross-bracket relation does exist between two adjacent words in real language. For example, if “遍佈/all over 世界/world ” was included in the short sentence “遍佈/all over 世界/world 各國 /countries”, it would be an independent structure. A conjunctive head-head relation between a verb and a noun is rare. However, in the sentence “服 務 設備 都 甚 周到” (Both service and equipment are very thoughtful.), there is a conjunctive head-head relation between the verb 服 務 /service and the noun 設備/equipment. Therefor"
D14-1100,O04-1014,1,0.748969,"ghtful.), there is a conjunctive head-head relation between the verb 服 務 /service and the noun 設備/equipment. Therefore, we use four types of relations to describe the VN structures in our experiments. The symbol ‘H/X’ denotes a predicate-object relation; ‘X/H’ denotes a modifier-head relation; ‘H/H’ denotes a conjunctive head-head relation; and ‘X/X’ denotes an independent relation. Feature selection is an important task in V-N disambiguation. Hence, a number of studies have suggested features that may help resolve the ambiguity of V-N structures (Zhao and Huang, 1999; Sun and Jurafsky, 2003; Chiu et al., 2004; Qiu, 2005; Chen, 2008). Zhao and Huang used lexicons, semantic knowledge, and word length in929 formation to increase the accuracy of identification. Although they used the Chinese thesaurus CiLin (Mei et al., 1983) to derive lexical semantic knowledge, the word coverage of CiLin is insufficient. Moreover, none of the above papers tackle the problem of unknown words. Sun and Jurafsky exploit the probabilistic rhythm feature (i.e., the number of syllables in a word or the number of words in a phrase) in their shallow parser. Their results show that the feature improves the parsing performance"
D14-1100,W12-6338,1,0.740419,"Missing"
D14-1100,P06-1055,0,0.0630008,"Missing"
D14-1100,W03-1719,0,0.0865533,"Missing"
D14-1100,W03-1706,0,0.510426,"equipment are very thoughtful.), there is a conjunctive head-head relation between the verb 服 務 /service and the noun 設備/equipment. Therefore, we use four types of relations to describe the VN structures in our experiments. The symbol ‘H/X’ denotes a predicate-object relation; ‘X/H’ denotes a modifier-head relation; ‘H/H’ denotes a conjunctive head-head relation; and ‘X/X’ denotes an independent relation. Feature selection is an important task in V-N disambiguation. Hence, a number of studies have suggested features that may help resolve the ambiguity of V-N structures (Zhao and Huang, 1999; Sun and Jurafsky, 2003; Chiu et al., 2004; Qiu, 2005; Chen, 2008). Zhao and Huang used lexicons, semantic knowledge, and word length in929 formation to increase the accuracy of identification. Although they used the Chinese thesaurus CiLin (Mei et al., 1983) to derive lexical semantic knowledge, the word coverage of CiLin is insufficient. Moreover, none of the above papers tackle the problem of unknown words. Sun and Jurafsky exploit the probabilistic rhythm feature (i.e., the number of syllables in a word or the number of words in a phrase) in their shallow parser. Their results show that the feature improves the"
D14-1100,W12-6335,0,0.118167,"Missing"
D14-1100,W03-1717,0,0.502643,"class of events which that are concepts in an upper-level ontology. One important characteristic of adjectival verbs is that they have conjunctive morphological structures, i.e., the words are conjunct with two nearly synonymous verbs, e.g., 研/study 究 /search (research), 探 /explore 測 /detect (explore), and 搜/search 尋/find (search). Therefore, we need a morphological classifier that can detect the conjunctive morphological structure of a Related Work Most works on V-N structure identification focus on two types of relation classification: modifierhead relations and predicate-object relations (Wu, 2003; Qiu, 2005; Chen, 2008; Chen et al., 2008; Yu et al., 2008). They exclude the independent structure and conjunctive head-head relation, but the cross-bracket relation does exist between two adjacent words in real language. For example, if “遍佈/all over 世界/world ” was included in the short sentence “遍佈/all over 世界/world 各國 /countries”, it would be an independent structure. A conjunctive head-head relation between a verb and a noun is rare. However, in the sentence “服 務 設備 都 甚 周到” (Both service and equipment are very thoughtful.), there is a conjunctive head-head relation between the verb 服 務 /s"
D14-1100,C08-1132,0,0.602334,"-level ontology. One important characteristic of adjectival verbs is that they have conjunctive morphological structures, i.e., the words are conjunct with two nearly synonymous verbs, e.g., 研/study 究 /search (research), 探 /explore 測 /detect (explore), and 搜/search 尋/find (search). Therefore, we need a morphological classifier that can detect the conjunctive morphological structure of a Related Work Most works on V-N structure identification focus on two types of relation classification: modifierhead relations and predicate-object relations (Wu, 2003; Qiu, 2005; Chen, 2008; Chen et al., 2008; Yu et al., 2008). They exclude the independent structure and conjunctive head-head relation, but the cross-bracket relation does exist between two adjacent words in real language. For example, if “遍佈/all over 世界/world ” was included in the short sentence “遍佈/all over 世界/world 各國 /countries”, it would be an independent structure. A conjunctive head-head relation between a verb and a noun is rare. However, in the sentence “服 務 設備 都 甚 周到” (Both service and equipment are very thoughtful.), there is a conjunctive head-head relation between the verb 服 務 /service and the noun 設備/equipment. Therefore, we use four typ"
D14-1100,O00-2004,1,\N,Missing
D14-1100,W03-1726,1,\N,Missing
D19-3040,P17-1074,0,0.0243634,"nation template and fetch reference linguistic information. 3.1 Learning to Provide Feedback We attempt to learn to generate an informative and comprehensive explanation that matches the error and context (in particular, the problem word). Our learning process is shown in Figure 2. In the first stage of the learning process (Step (1) in Figure 2), we analyze sentences with a correction annotated with a problem-causing word which is a word regularly causing the specific error. As we will describe in Section 3.1, we use Turton and Heaton (1996) for training. Based on an existing method, ERRANT (Bryant et al., 2017), we analyze differences between a sentence containing an error and a corrected sentence. Then we produce an error type including an edit type (insert, delete, and replace) and PoS of the edit 236 Table 1: top 10 error codes Code 1. SP 2. RV 3. RT 4. MD 5. R 6. RN 7. FV 8. MT 9. UD 10. UT Gloss Spelling Replace v. Replace prep. Missing det. Replace w. Replace n. Form v. Missing prep. Useless det. Useless prep. Figure 4: Outline of the Smadja’s process words using the EF-Cambridge Open Language Database EFCAMDAT (Geertzen et al. (2013) and Huang et al. (2018)). Then, we use the method proposed"
D19-3040,N15-3022,1,0.698522,"udakis et al., 2011) and associated error types (i.e., extending error types from Top 10, such as from replacing a word, to deleting a word or missing a word) to derive explanation templates. To sum up, we limit ourselves to provide explanation for error types related to editing a verb, adjective, noun, prepositions and function words (e.g., articles). In the second stage of the learning algorithm (Step (2) in Figure 2), we extract reference information. First, we extract grammar patterns from Corpus of Contemporary American English (COCA1 ) using an existing method (in Figure 3) described in Chang and Chang (2015). Subsequently, we store examples corresponded to a keyword’s grammar patterns (e.g., (discuss, V n): issue, topic, matters). Next, we build a collocation dictionary with dependency relation information using triples (e.g., (eat, V:obj:N, bananas)). The relation (e.g., V:obj:N) is produced by a dependency parser using COCA. Finally, we store definitions in Online Cambridge Dictionary to explain word-choice errors (e.g., ‘accept’ education). Additionally, Online Cambridge Dictionary gives a pair of English-Chinese definition and a guide word (e.g., TAKE, APPROVE) for each sense of a polysemous"
D19-3040,J93-1007,0,0.658788,"e analyze differences between a sentence containing an error and a corrected sentence. Then we produce an error type including an edit type (insert, delete, and replace) and PoS of the edit 236 Table 1: top 10 error codes Code 1. SP 2. RV 3. RT 4. MD 5. R 6. RN 7. FV 8. MT 9. UD 10. UT Gloss Spelling Replace v. Replace prep. Missing det. Replace w. Replace n. Form v. Missing prep. Useless det. Useless prep. Figure 4: Outline of the Smadja’s process words using the EF-Cambridge Open Language Database EFCAMDAT (Geertzen et al. (2013) and Huang et al. (2018)). Then, we use the method proposed by Smadja (1993) (in Figure 4) to calculate co-occurrence frequency of pairs of an edit and neighboring words with the goal of selecting the most potential neighboring word triggering the edit. In other words, we assume the problemcausing word as a collocate of the edit. In the fourth and final stage of training (Step (4) in Figure 2), we formulate a feedback template for each error type, classified by ERRANT. For each error type, we observe and exploit the consistent patterns of feedback in Turton and Heaton (1996) to design the templates. For example, we formulate an explanation template for unnecessary pre"
D19-3040,P11-1019,0,0.0800598,"ces of each error type, we develop type-specific templates with slots to be filled with specific information: problem words along with a grammar pattern, collocations and examples. (1) Generating a set of phrase templates in the form of PoS tags (2) Extracting grammar patterns for all keywords in the given corpus annotated by PoS based on phrase templates (3) Extracting exemplary instances for all patterns of all keywords Figure 3: Outline of the pattern extraction process (e.g., (DEL, PREP, about)). For simplicity, we limit ourselves to Top 10 most common error types (in Table 1) in CLE-FCE (Yannakoudakis et al., 2011) and associated error types (i.e., extending error types from Top 10, such as from replacing a word, to deleting a word or missing a word) to derive explanation templates. To sum up, we limit ourselves to provide explanation for error types related to editing a verb, adjective, noun, prepositions and function words (e.g., articles). In the second stage of the learning algorithm (Step (2) in Figure 2), we extract reference information. First, we extract grammar patterns from Corpus of Contemporary American English (COCA1 ) using an existing method (in Figure 3) described in Chang and Chang (201"
D19-3040,W13-1704,0,0.0221836,"or types with an underlying GEC system. Additionally, to provide good explanations, a promising approach is to automatically classify the error and extract a problem word nearby to tailor the explanation to the context of the error. Related Work Corrective feedback on learners’ writing has been an area of active research. Recently, the state-ofthe-art in the research has been represented in Leacock et al. (2010) involving many automated approaches to detect a wide range of error types. To generate explanations, most writing services adopt the approach of canned text with table lookup schemes (Andersen et al., 2013). This approach, despite providing basic explanations, is not optimal, because canned feedback tends to be superficial and context-insensitive. Additionally, canned feedback is limited to common grammatical errors, without covering lexical error types, such as word-choice errors. Providing corrective feedback and explaining how the correction improves grammaticality and adheres to idiomatic principles (Sinclair, 1991) have long been an important research area in Teaching English as Second Language (TESOL). Bitchener et al. (2005) concluded that proper error feedback is significant in improving"
E12-2004,W10-1005,0,0.0306618,"Missing"
E12-2004,W11-1412,1,0.8873,"Missing"
E12-2004,P11-4005,1,0.900825,"Missing"
E12-2004,N03-1017,0,0.0132008,"returns top N predominant syntactic patterns associated with the query. Such patterns characterizing the query’s word usages follow the notion of pattern grammar in (Hunston and Francis, 2000) and are collected across the target language. In the fourth and final stage, we exploit Cst for bilingual phrase acquisition, rather than a manual dictionary, to achieve better translation coverage and variety. We obtain phrase pairs through leveraging IBM models to word-align the bitexts, “smoothing” the directional word alignments via grow-diagonal-final, and extracting translation equivalents using (Koehn et al., 2003). procedure MakePrediction(S,Tp) (1) Assign sliceNgram(S) to {si} (2) Assign sliceNgram(Tp) to {tj} (3) TransOptions=findTranslation({si},Tp) (4) GramOptions=findPattern({tj}) (5) Evaluate translation options in TransOptions and incorporate them into GramOptions (6) Return GramOptions Figure 3. Predicting pattern grammar and translations. In Step (5), we first evaluate and rank the translation candidates using linear combination: λ1 × ( P1 ( t si ) + P1 ( si t ) ) + λ2 × P2 ( t Tp ) where λi is combination weight, P1 and P2 are translation and language model respectively, and t is one of the t"
E12-2004,P09-4005,0,0.0165672,"summarizes the translations for the source’s character-based ngrams. time updating the system’s segmentation /translation options through the user’s word choices. Our intended users are different from those of the previous research focusing on what professional translator can bring for MT systems (e.g., Brown and Nirenburg, 1990). More recently, interactive MT (IMT) systems have begun to shift the user’s role from analyses of the source text to the formation of the target translation. TransType project (Foster et al., 2002) describes such pioneering system that supports next word predictions. Koehn (2009) develops caitra which displays one phrase translation at a time and offers alternative translation options. Both systems are similar in spirit to our work. The main difference is that we do not expect the user to be a professional translator and we provide translation hints along with grammar predictions to avoid the generalization issue facing phrase-based system. Recent work has been done on using fullyfledged statistical MT systems to produce target hypotheses completing user-validated translation prefix in IMT paradigm. Barrachina et al. (2008) investigate the applicability of different M"
E12-2004,P07-1039,0,0.0145222,"d up inverted files of the words in Ct for the next stage (i.e., pattern grammar generation). Apart from sentence and position information, a word’s lemma and part-of-speech (POS) are also recorded. We then leverage the procedure in Figure 2 to generate grammar patterns for any given sequence of words (e.g., contiguous or not). word-level ngrams respectively. Step (3) and (4) retrieve the translations and patterns learned from Section 3.2. Step (3) acquires the active target-language vocabulary that may be used to translate the source text. To alleviate the word boundary issue in MT raised by Ma et al. (2007), TransAhead non-deterministically segments the source text using character ngrams and proceeds with collaborations with the user to obtain the segmentation for MT and to complete the translation. Note that a user vocabulary of preference (due to users’ domain of knowledge or errors of the system) may be exploited for better system performance. On the other hand, Step (4) extracts patterns preceding with the history ngrams of {tj}. procedure PatternFinding(query,N,Ct) (1) interInvList=findInvertedFile(w1 of query) for each word wi in query except for w1 (2) InvList=findInvertedFile(wi) (3a) ne"
E12-2004,W04-3225,0,0.0318764,"one phrase translation at a time and offers alternative translation options. Both systems are similar in spirit to our work. The main difference is that we do not expect the user to be a professional translator and we provide translation hints along with grammar predictions to avoid the generalization issue facing phrase-based system. Recent work has been done on using fullyfledged statistical MT systems to produce target hypotheses completing user-validated translation prefix in IMT paradigm. Barrachina et al. (2008) investigate the applicability of different MT kernels within IMT framework. Nepveu et al. (2004) and Ortiz-Martinez et al. (2011) further exploit user feedbacks for better IMT systems and user experience. Instead of trigged by user correction, our method is triggered by word delimiter and assists in target language learning. In contrast to the previous CAT research, we present a writing assistant that suggests subsequent grammar constructs with translations and interactively collaborates with learners, in view of reducing users’ burden on grammar and word choice and enhancing their writing quality. 17 3. The TransAhead System 3.1 Problem Statement For CAT and CALL, we focus on predicting"
E12-2004,J03-1002,0,0.00762939,"Missing"
E12-2004,P11-4012,0,0.0121682,"a time and offers alternative translation options. Both systems are similar in spirit to our work. The main difference is that we do not expect the user to be a professional translator and we provide translation hints along with grammar predictions to avoid the generalization issue facing phrase-based system. Recent work has been done on using fullyfledged statistical MT systems to produce target hypotheses completing user-validated translation prefix in IMT paradigm. Barrachina et al. (2008) investigate the applicability of different MT kernels within IMT framework. Nepveu et al. (2004) and Ortiz-Martinez et al. (2011) further exploit user feedbacks for better IMT systems and user experience. Instead of trigged by user correction, our method is triggered by word delimiter and assists in target language learning. In contrast to the previous CAT research, we present a writing assistant that suggests subsequent grammar constructs with translations and interactively collaborates with learners, in view of reducing users’ burden on grammar and word choice and enhancing their writing quality. 17 3. The TransAhead System 3.1 Problem Statement For CAT and CALL, we focus on predicting a set of grammar patterns with l"
E12-2004,P02-1040,0,0.0818728,"Missing"
E12-2004,C90-3008,0,\N,Missing
E12-2004,J09-1002,0,\N,Missing
I05-1046,P02-1005,0,0.0262722,"Missing"
I05-1046,N04-1007,0,0.0312177,"g the category of the question. The expanded query is the submitted to a search engine in order to bias the search engine to return passages that are more likely to contain answers to the question. Experimental results indicate the expanded query indeed outperforms the approach of directly using the keywords in the question. 2 Related Work Recent work in Question Answering has attempted to convert the original input question into a query that is more likely to retrieve the answers. Hovy et al. [2] utilized WordNet hypernyms and synonyms to expand queries to increase recall. Hildebrandt et al. [4] looked up in a pre-compiled knowledge base and a dictionary to expand a definition question. However, blindly expanding a word using its synonyms or dictionary gloss may cause undesirable effects. Furthermore, it is difficult to determine which of many related word senses should be considered when expanding the query. Radev et al. [5] proposed a probabilistic algorithm called QASM that learns the best query expansion from a natural language question. The query expansion takes the form of a series of operators, including INSERT, DELETE, REPLACE, etc., to paraphrase a factual question into the"
I05-1046,P97-1063,0,0.0111234,"econd longest river in the world? 3.3 Learning Best Transforms This section describes the procedure for learning transforms Ts which convert the question pattern Qp into bigrams in relevant APs. Word Alignment Across Q and AP We use word alignment techniques developed for statistical machine translation to find out the association between question patterns in Q and bigrams in AP. The reason why we use bigrams in APs instead of unigrams is that bigrams tend to have more unique meaning than single words and are more effective in retrieving relevant passages. We use Competitive Linking Algorithm [8] to align a set of (Q, AP) pairs. The method involves preprocessing steps for each (Q, AP) pair so as to filter useless information: 1. Perform part-of-speech tagging on Q and AP. 2. Replace all instances of A with the tag &lt;ANS> in APs to indicate the location of the answers. 3. Identify the question pattern, Qp and keywords which are not a named entity. We denote the question pattern and keywords as q1, q2, ..., qn. 4. Convert AP into bigrams and eliminate bigrams with low term frequency (tf) or high document frequency (df). Bigrams composed of two function words are also removed, resulting i"
I05-1046,O04-1020,1,0.879638,"Missing"
I08-1033,P06-1002,0,0.0289443,"Missing"
I08-1033,O06-4003,1,0.845107,"are not allowed alignment sequences. The constraint is applied to each possible aligning result. If the alignment violates the constraint, it will be rejected. Since the new alignment algorithm must enumerate all of the possible alignments, the process is very time consuming. Therefore, it is advantageous to use a bilingual terminology bank rather than a parallel corpus. The average length of terminologies is short and much shorter than a typical sentence in a parallel corpus. This makes words to morphemes alignment computationally feasible and the results highly accurate (Chang et al., 2001; Bai et al., 2006). This makes it possible to use the result as pseudo gold standards to evaluate affix rules as described in section 4.3. 1 The bilingual terminology bank was compiled by the National Institute for Compilation and Translation. It is freely download at http://terms.nict.gov.tw by registering your information. 251 resulting in rules R1..Rn . And then for each Ri , we scan R1 to Ri-1, if there is a rule, Rj, have the same English word condition and the affix condition of Ri subsume that of Rj, then we add affix condition of Rj as exception condition of Ri. For example, _ 業 , industry and _工業, indu"
I08-1033,J93-2003,0,0.0301349,"Missing"
I08-1033,O98-3002,1,0.757578,"eriments showed that both of the adjusting methods improve the performance of word alignment significantly. 1 Introduction Word alignment is an important preprocessing task for statistical machine translation. There have been many statistical word alignment methods proposed since the IBM models have been introduced. Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese. In these languages, word segmentation (Chen and Liu, 1992; Chen and Bai, 1998; Chen and Ma, 2002; Ma and Chen, 2003; Gao et al., 2005) is often carried out firstly to identify words before word alignment (Wu and Xia, 1994). However, the differences in lexicalization may degrade word alignment performance, for different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997). For instance, Chinese multi-syllabic words composed of more than one meaningful morpheme which may be translated to several English words. For example, the Chinese word 教育署 is composed of two meaning units, 教育 and 署 , and is translated to Department of Ed"
I08-1033,C02-1049,1,0.804801,"both of the adjusting methods improve the performance of word alignment significantly. 1 Introduction Word alignment is an important preprocessing task for statistical machine translation. There have been many statistical word alignment methods proposed since the IBM models have been introduced. Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese. In these languages, word segmentation (Chen and Liu, 1992; Chen and Bai, 1998; Chen and Ma, 2002; Ma and Chen, 2003; Gao et al., 2005) is often carried out firstly to identify words before word alignment (Wu and Xia, 1994). However, the differences in lexicalization may degrade word alignment performance, for different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997). For instance, Chinese multi-syllabic words composed of more than one meaningful morpheme which may be translated to several English words. For example, the Chinese word 教育署 is composed of two meaning units, 教育 and 署 , and is translated to Department of Education in English."
I08-1033,C92-1019,1,0.71565,"cision tree. Our experiments showed that both of the adjusting methods improve the performance of word alignment significantly. 1 Introduction Word alignment is an important preprocessing task for statistical machine translation. There have been many statistical word alignment methods proposed since the IBM models have been introduced. Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese. In these languages, word segmentation (Chen and Liu, 1992; Chen and Bai, 1998; Chen and Ma, 2002; Ma and Chen, 2003; Gao et al., 2005) is often carried out firstly to identify words before word alignment (Wu and Xia, 1994). However, the differences in lexicalization may degrade word alignment performance, for different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997). For instance, Chinese multi-syllabic words composed of more than one meaningful morpheme which may be translated to several English words. For example, the Chinese word 教育署 is composed of two meaning units, 教育 and 署 , and is translated"
I08-1033,P07-1003,0,0.0248751,"Missing"
I08-1033,H05-1022,0,0.0177728,". The first method is learning affix rules from a bilingual terminology bank. The second method is using the concept of impurity measure motivated by the decision tree. Our experiments showed that both of the adjusting methods improve the performance of word alignment significantly. 1 Introduction Word alignment is an important preprocessing task for statistical machine translation. There have been many statistical word alignment methods proposed since the IBM models have been introduced. Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese. In these languages, word segmentation (Chen and Liu, 1992; Chen and Bai, 1998; Chen and Ma, 2002; Ma and Chen, 2003; Gao et al., 2005) is often carried out firstly to identify words before word alignment (Wu and Xia, 1994). However, the differences in lexicalization may degrade word alignment performance, for different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997). For instance, Chinese multi-syllabic words composed of more than one meaningful mo"
I08-1033,J05-4005,0,0.0303634,"the performance of word alignment significantly. 1 Introduction Word alignment is an important preprocessing task for statistical machine translation. There have been many statistical word alignment methods proposed since the IBM models have been introduced. Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese. In these languages, word segmentation (Chen and Liu, 1992; Chen and Bai, 1998; Chen and Ma, 2002; Ma and Chen, 2003; Gao et al., 2005) is often carried out firstly to identify words before word alignment (Wu and Xia, 1994). However, the differences in lexicalization may degrade word alignment performance, for different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997). For instance, Chinese multi-syllabic words composed of more than one meaningful morpheme which may be translated to several English words. For example, the Chinese word 教育署 is composed of two meaning units, 教育 and 署 , and is translated to Department of Education in English. The morphemes 教育 and 署 have their own"
I08-1033,H05-1085,0,0.0935192,"Missing"
I08-1033,N03-1017,0,0.138776,"rce sentence. In this case, a many-to-one alignment, links a phrase in the source sentence to a single token in the target sentence, is not allowed, forcing most links of a phrase in the source sentence to be abolished. As in the previous example, when aligning from English to Chinese, 教育署 can only be linked to one of the English words, say Education, because of the limitation of the IBM model. However for remedy, many of the current word alignment methods combine the results of both alignment directions, via intersection or 249 grow-diag-final heuristic, to improve the alignment reliability (Koehn et al., 2003; Liang et al., 2006; Ayan et al., 2006; DeNero et al., 2007). However the many-to-one link limitation will undermine the reliability due to the fact that some links are not allowed in one of the directions. In this paper, we propose two novel methods to adjust word segmentation so as to decrease the effect of lexicalization differences to improve word alignment performance. The main idea of our methods is to adjust Chinese word segmentation according to their translation derived from parallel sentences in order to make the tokens compatible to 1-to-1 mapping between the corresponding sentence"
I08-1033,N04-4015,0,0.203541,"he performance of word alignment for several reasons. The first reason is that it will reduce the cooccurrence counts of Chinese and English tokens. Consider the previous example. Since 教育署 is treated as a single unit, it does not contribute to the occurrence counts of Education/ 教育 and Department/署 token pairs. Secondly, the rarely occurring compound word may cause the garbage collectors effect (Moore, 2004; Liang et al., 2006), aligning a rare word in source language to too many words in the target language, due to the frequency imbalance with the corresponding translation words in English (Lee, 2004). Finally, the IBM models (Moore, 2004) impose the limitation that each word in the target sentence can be generated by at most one word in the source sentence. In this case, a many-to-one alignment, links a phrase in the source sentence to a single token in the target sentence, is not allowed, forcing most links of a phrase in the source sentence to be abolished. As in the previous example, when aligning from English to Chinese, 教育署 can only be linked to one of the English words, say Education, because of the limitation of the IBM model. However for remedy, many of the current word alignment"
I08-1033,N06-1014,0,0.0868452,"Education in English. The morphemes 教育 and 署 have their own meanings and are translated to Education and Department respectively. The phenomenon of lexicalization mismatch will degrade the performance of word alignment for several reasons. The first reason is that it will reduce the cooccurrence counts of Chinese and English tokens. Consider the previous example. Since 教育署 is treated as a single unit, it does not contribute to the occurrence counts of Education/ 教育 and Department/署 token pairs. Secondly, the rarely occurring compound word may cause the garbage collectors effect (Moore, 2004; Liang et al., 2006), aligning a rare word in source language to too many words in the target language, due to the frequency imbalance with the corresponding translation words in English (Lee, 2004). Finally, the IBM models (Moore, 2004) impose the limitation that each word in the target sentence can be generated by at most one word in the source sentence. In this case, a many-to-one alignment, links a phrase in the source sentence to a single token in the target sentence, is not allowed, forcing most links of a phrase in the source sentence to be abolished. As in the previous example, when aligning from English"
I08-1033,W03-1705,1,0.843322,"ing methods improve the performance of word alignment significantly. 1 Introduction Word alignment is an important preprocessing task for statistical machine translation. There have been many statistical word alignment methods proposed since the IBM models have been introduced. Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese. In these languages, word segmentation (Chen and Liu, 1992; Chen and Bai, 1998; Chen and Ma, 2002; Ma and Chen, 2003; Gao et al., 2005) is often carried out firstly to identify words before word alignment (Wu and Xia, 1994). However, the differences in lexicalization may degrade word alignment performance, for different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997). For instance, Chinese multi-syllabic words composed of more than one meaningful morpheme which may be translated to several English words. For example, the Chinese word 教育署 is composed of two meaning units, 教育 and 署 , and is translated to Department of Education in English. The morphemes 教育 a"
I08-1033,P07-1039,0,0.0635679,"Missing"
I08-1033,P00-1056,0,0.065896,"lel corpus in three ways: First we use a state-of-the-art word segmenter to tokenize the Chinese part of the corpus. Then, we used the affix rules to adjust word segmentation. Finally, we do the same but by using the impurity measure method. We used the GIZA++ package (Och and Ney, 2003) as the word alignment tool to align tokens on the three copies of preprocessed parallel corpora. We used the first 100,000 sentences of Hong Kong News parallel corpus from LDC as our training data. And 112 randomly selected parallel sentences were aligned manually with sure and possible tags, as described in (Och and Ney, 2000), 4 and we used these annotated data as our gold standard in testing. Because of the modification of Chinese tokens caused by the word segmentation adjustment, a problem has been created when we wanted to compare the results to the copy which did not undergo adjustment. Therefore, after the alignment was done, we merged the alignment links related to tokens that were split up during adjustment. For example, the two links of foreign/外交 minister/部 長 were merged as foreign minister/外交部長. The evaluation of word alignment results are shown in Table 1, including precision-recall and AER evaluation m"
I08-1033,C96-2141,0,0.214769,"responding sentences. The first method is learning affix rules from a bilingual terminology bank. The second method is using the concept of impurity measure motivated by the decision tree. Our experiments showed that both of the adjusting methods improve the performance of word alignment significantly. 1 Introduction Word alignment is an important preprocessing task for statistical machine translation. There have been many statistical word alignment methods proposed since the IBM models have been introduced. Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese. In these languages, word segmentation (Chen and Liu, 1992; Chen and Bai, 1998; Chen and Ma, 2002; Ma and Chen, 2003; Gao et al., 2005) is often carried out firstly to identify words before word alignment (Wu and Xia, 1994). However, the differences in lexicalization may degrade word alignment performance, for different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997). For instance, Chinese multi-syllabic words composed of more"
I08-1033,1994.amta-1.26,0,0.0808119,"portant preprocessing task for statistical machine translation. There have been many statistical word alignment methods proposed since the IBM models have been introduced. Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese. In these languages, word segmentation (Chen and Liu, 1992; Chen and Bai, 1998; Chen and Ma, 2002; Ma and Chen, 2003; Gao et al., 2005) is often carried out firstly to identify words before word alignment (Wu and Xia, 1994). However, the differences in lexicalization may degrade word alignment performance, for different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997). For instance, Chinese multi-syllabic words composed of more than one meaningful morpheme which may be translated to several English words. For example, the Chinese word 教育署 is composed of two meaning units, 教育 and 署 , and is translated to Department of Education in English. The morphemes 教育 and 署 have their own meanings and are translated to Education and Department respectively. The phenomenon of"
I08-1033,J97-3002,0,0.329284,"okens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese. In these languages, word segmentation (Chen and Liu, 1992; Chen and Bai, 1998; Chen and Ma, 2002; Ma and Chen, 2003; Gao et al., 2005) is often carried out firstly to identify words before word alignment (Wu and Xia, 1994). However, the differences in lexicalization may degrade word alignment performance, for different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997). For instance, Chinese multi-syllabic words composed of more than one meaningful morpheme which may be translated to several English words. For example, the Chinese word 教育署 is composed of two meaning units, 教育 and 署 , and is translated to Department of Education in English. The morphemes 教育 and 署 have their own meanings and are translated to Education and Department respectively. The phenomenon of lexicalization mismatch will degrade the performance of word alignment for several reasons. The first reason is that it will reduce the cooccurrence counts of Chinese and English tokens. Consider t"
I08-1033,P03-1051,0,\N,Missing
I08-1033,J03-1002,0,\N,Missing
I13-1083,P05-1074,0,0.627006,"ated factors to optimize the quality of paraphrase extraction. The major contributions of this study lie in the augmentable paraphrasing framework and the three kinds of factors conducive to both semantic and syntactic correctness. A manual evaluation showed that our model achieves more successful results than the state-of-the-art methods. 1. Introduction Paraphrasing provides an alternative way to express an idea using different words. Early work on paraphrase acquisition has been mainly based on either distributional similarity (e.g., Lin and Pantel, 2001) or the pivot-based approach (e.g., Bannard and Callison-Burch, 2005). Both methods have their strengths and limitations. Distributional similarity is capable of extracting syntactically correct paraphrases, but may risk including antonymous phrases as paraphrases. On the other hand, the pivot approach has the advantage of preserving semantic similarity among the generated paraphrases; however, the quality and quantity of the paraphrases closely correlates with the techniques of bilingual phrase alignment. Considering single factors, existing paraphrasing methods could lose some linguistic properties. In view of this, we attempt to differentiate the importance"
I13-1083,P01-1008,0,0.189813,"Missing"
I13-1083,D08-1021,0,0.121974,"ilar contexts. Lin and Pantel (2001) derive 706 International Joint Conference on Natural Language Processing, pages 706–711, Nagoya, Japan, 14-18 October 2013. paraphrases using parse tree paths to compute distributional similarity. Another prominent approach to paraphrase extraction is based on bilingual parallel corpora. For example, Bannard and Callison-Burch (2005) propose the pivot approach to extract phrasal paraphrases from an English-German parallel corpus. With the advantage of its parallel and bilingual natures of such a corpus, the output paraphrases preserve semantic equivalence. Callison-Burch (2008) further places syntactic constraints on extracted paraphrases to improve the quality of the paraphrases. Chan et al. (2011) use monolingual distributional similarity to rank paraphrases generated by the syntactically-constrained pivot method. Recently, some studies take a graphical view of the pivot-based approach. Kok and Brockett (2010) propose the Hitting Time Paraphrase algorithm (HTP) to measure the similarities between phrases. Chen et al. (2012) adopt the PageRank algorithm to find more relevant paraphrases that preserve both meaning and grammaticality for language learners. In this pa"
I13-1083,W11-2504,0,0.0376691,"Missing"
I13-1083,W12-2009,1,0.801651,"el corpus. With the advantage of its parallel and bilingual natures of such a corpus, the output paraphrases preserve semantic equivalence. Callison-Burch (2008) further places syntactic constraints on extracted paraphrases to improve the quality of the paraphrases. Chan et al. (2011) use monolingual distributional similarity to rank paraphrases generated by the syntactically-constrained pivot method. Recently, some studies take a graphical view of the pivot-based approach. Kok and Brockett (2010) propose the Hitting Time Paraphrase algorithm (HTP) to measure the similarities between phrases. Chen et al. (2012) adopt the PageRank algorithm to find more relevant paraphrases that preserve both meaning and grammaticality for language learners. In this paper, we, similarly, present the state-of-the-art approach as a graph. However, unlike Kok and Brockett (2010), we treat English phrases (instead of multilingual phrases) as nodes. On the other hand, different from Chen et al. (2012), our model is augmentable by involving varied linguistic information or domain knowledge. 3. Method Typically, the state-of-the-art paraphrase extraction models only deal with single factors such as distribution similarity o"
I13-1083,N10-1017,0,0.0144578,"Bannard and Callison-Burch (2005) propose the pivot approach to extract phrasal paraphrases from an English-German parallel corpus. With the advantage of its parallel and bilingual natures of such a corpus, the output paraphrases preserve semantic equivalence. Callison-Burch (2008) further places syntactic constraints on extracted paraphrases to improve the quality of the paraphrases. Chan et al. (2011) use monolingual distributional similarity to rank paraphrases generated by the syntactically-constrained pivot method. Recently, some studies take a graphical view of the pivot-based approach. Kok and Brockett (2010) propose the Hitting Time Paraphrase algorithm (HTP) to measure the similarities between phrases. Chen et al. (2012) adopt the PageRank algorithm to find more relevant paraphrases that preserve both meaning and grammaticality for language learners. In this paper, we, similarly, present the state-of-the-art approach as a graph. However, unlike Kok and Brockett (2010), we treat English phrases (instead of multilingual phrases) as nodes. On the other hand, different from Chen et al. (2012), our model is augmentable by involving varied linguistic information or domain knowledge. 3. Method Typicall"
I13-1083,J03-1002,0,0.00933525,"en the vectors of u and q using cosine similarity. ?! ∙ ?!! ℱ! = ! ?!! ?!! where ?!! denotes a vector of u, and ?!! a vector of q, and k ∈ {?, R, ??}. Translation similarity factor Next, we calculate the intrinsic translation similarity which is capable of preserving semantic equivalence. Translation similarity factor for an edge connecting node ? and ? is defined as: ℱ!""#$ = ? ?? ? ?? !∈!(!) where ? is one paraphrase of phrase ? , T(v) denotes a set of the foreign-language alignment of v, and P(.) the translation probability. Both of the alignment and translation probability are described in Och and Ney (2003). 708 3.4 Parameter Optimization Once the factors are selected, we have to determine the weights of the factors, (i.e., ?! in Section 3.2). In other words, we train the weights of factors such that the performance is optimal for a given developing data set. We use Discounted Cumulative Gain (DCG) (Järvelin and Kekäläinen, 2002) to measure the quality of paraphrases. From the top to the bottom of the result list, the DCG score is accumulated with the gain of each result discounted at lower ranks. The DCG score is defined as: ! ??? ?, ? = !!! 2 !""!""#! − 1 ???! (? + 1) where r represents a set of"
I13-1083,P07-1058,0,0.0630643,"odel based on APF with identical weights of factors (APF-avgW). We evaluated the paraphrase quality through a substitution test. We randomly selected 133 most commonly used phrases from 30 research articles. For each phrase, we extracted the corresponding paraphrase candidates and evaluated its top 5 candidates. At the same time, three or less distinct sentences containing the phrase were randomly sampled (a total of 398 sentences were evaluated) from the New York Times section of the English Gigaword (LDC2003T05) to capture the fact that paraphrases are valid in some contexts but not others (Szpektor et al., 2007). Two native speaker judges evaluated whether the candidates are syntactically and semantically appropriate in various contexts. They assigned two values corresponding to the semantic and syntactic considerations to each sentence by score 0, (not acceptable), 1 (“acceptable”) and 2 (“acceptable and correct”). The inter-annotator agreement was 0.67. It is worth noting that we include two measurement schemes for comprehensive analysis. The strict scheme considers a paraphrase as “correct” if and only if both of the two judges scored 2 points, whereas the other one considers a paraphrase as “acce"
I13-1103,N06-1003,0,0.0314116,"to a set of suggested translations. Our experiment results demonstrate that the translations suggested by the unknown word translation template model significantly improve the performance of the Moses machine translation system. 1 Introduction Automatic translation of unknown words is still an open problem. As a result, most statistical machine translation (SMT) systems treat such words as unknown tokens and leave them untranslated. (Koehn et al., 2003; Chiang, 2005; Koehn et al., 2007) The unknown word translation problem has generated considerable interest in recent years. Some works (e.g., Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009) focus on finding in-vocabulary paraphrases, which are then used as bridges to translate target unknown words. Li and Yarowsky (2008) proposed an unsupervised method for extracting the mappings from Chinese abbreviations and their full-forms. The method exploits the full-forms as bridges to translate the abbreviations. A prerequisite of the above methods is that the unknown words must have paraphrases (or full-forms). However, many types of unknown words do not have paraphrases (full-forms) naturally. In contrast to paraphrasing methods, Huang et al."
I13-1103,N03-1017,0,0.0405684,"nknown word is detected during translation, the model applies translation templates to the word to get a set of matched templates, and then translates the word into a set of suggested translations. Our experiment results demonstrate that the translations suggested by the unknown word translation template model significantly improve the performance of the Moses machine translation system. 1 Introduction Automatic translation of unknown words is still an open problem. As a result, most statistical machine translation (SMT) systems treat such words as unknown tokens and leave them untranslated. (Koehn et al., 2003; Chiang, 2005; Koehn et al., 2007) The unknown word translation problem has generated considerable interest in recent years. Some works (e.g., Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009) focus on finding in-vocabulary paraphrases, which are then used as bridges to translate target unknown words. Li and Yarowsky (2008) proposed an unsupervised method for extracting the mappings from Chinese abbreviations and their full-forms. The method exploits the full-forms as bridges to translate the abbreviations. A prerequisite of the above methods is that the unknown words mus"
I13-1103,W04-3250,0,0.0930513,"expansion methods significantly improved the underlying SMT system. To verify the stability of this method, we also rebuilt a baseline system and an unknown word translation model based on the FBIS parallel corpus, as shown in Table 2. Baseline Trans. table Phonetic Numeric All MT06 24.38 24.54 (+0.16) 24.78 (+0.40) 24.64 (+0.26) 25.09 (+0.71) MT08_sub 19.94 20.21 (+0.27) 20.28 (+0.34) 20.09 (+0.15) 20.65 (+0.71) Table 2. Evaluation results based on the FBIS parallel corpus. The improvement in the BLEU score is statistically significant (p < 0.01) under the paired bootstrap re-sampling test (Koehn, 2004). The experimental results show that the proposed translation template model significantly improves the performance of the statistical machine translation system. 5 Conclusion We have proposed a method that utilizes a translation template model to translate Chinese unknown words. The translation templates can be automatically extracted from a word-aligned parallel corpus and evaluated without using extra information. Experimental results show that the model can suggest accurate unknown word translations for an existing SMT system and improve the translation quality. References Berger, Adam L.,"
I13-1103,P07-2045,0,0.0285114,"nslation, the model applies translation templates to the word to get a set of matched templates, and then translates the word into a set of suggested translations. Our experiment results demonstrate that the translations suggested by the unknown word translation template model significantly improve the performance of the Moses machine translation system. 1 Introduction Automatic translation of unknown words is still an open problem. As a result, most statistical machine translation (SMT) systems treat such words as unknown tokens and leave them untranslated. (Koehn et al., 2003; Chiang, 2005; Koehn et al., 2007) The unknown word translation problem has generated considerable interest in recent years. Some works (e.g., Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009) focus on finding in-vocabulary paraphrases, which are then used as bridges to translate target unknown words. Li and Yarowsky (2008) proposed an unsupervised method for extracting the mappings from Chinese abbreviations and their full-forms. The method exploits the full-forms as bridges to translate the abbreviations. A prerequisite of the above methods is that the unknown words must have paraphrases (or full-forms)."
I13-1103,P08-1049,0,0.022749,"rmance of the Moses machine translation system. 1 Introduction Automatic translation of unknown words is still an open problem. As a result, most statistical machine translation (SMT) systems treat such words as unknown tokens and leave them untranslated. (Koehn et al., 2003; Chiang, 2005; Koehn et al., 2007) The unknown word translation problem has generated considerable interest in recent years. Some works (e.g., Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009) focus on finding in-vocabulary paraphrases, which are then used as bridges to translate target unknown words. Li and Yarowsky (2008) proposed an unsupervised method for extracting the mappings from Chinese abbreviations and their full-forms. The method exploits the full-forms as bridges to translate the abbreviations. A prerequisite of the above methods is that the unknown words must have paraphrases (or full-forms). However, many types of unknown words do not have paraphrases (full-forms) naturally. In contrast to paraphrasing methods, Huang et al. (2011) developed a sublexical translation method that translates an unknown word by combining the translations of its sublexicals. However, to deal with the reordering problem,"
I13-1103,W03-1726,1,0.722188,"n rules instead of translation table to generate the translations of morphemes. We use two types of morphological translation rules: numerical and phonetic morphological translation rules. 3 Experimental Setting We evaluate the model on Moses (Koehn et al., 2007) by embedding the translations of the unknown words to test data as suggestion translations. 3.1 Baseline SMT System and Data Sets We used the Hong Kong Parallel Text (LDC2004T08) as the training data for the Moses SMT system and our template model. The Chinese sentences were pre-processed by the CKIP Chinese word segmentation system (Ma and Chen, 2003). The language model was trained on the English Gigaword corpus (LDC2003T05). We randomly selected 340 841 sentences from the NIST MT08 test data as our development set, the NIST MT06 test data and the rest of the NIST MT08 as our test set. 3.2 Training The parallel text was word-aligned by the GIZA++ toolkit (Och and Ney, 2003). Then, we utilized the word-aligned corpus to extract translation templates. This process yielded a set of translation templates and a translation template tagged corpus, which was used to train the fitting probability model. To evaluate the fitting probability model,"
I13-1103,D09-1040,0,0.0151906,"tions. Our experiment results demonstrate that the translations suggested by the unknown word translation template model significantly improve the performance of the Moses machine translation system. 1 Introduction Automatic translation of unknown words is still an open problem. As a result, most statistical machine translation (SMT) systems treat such words as unknown tokens and leave them untranslated. (Koehn et al., 2003; Chiang, 2005; Koehn et al., 2007) The unknown word translation problem has generated considerable interest in recent years. Some works (e.g., Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009) focus on finding in-vocabulary paraphrases, which are then used as bridges to translate target unknown words. Li and Yarowsky (2008) proposed an unsupervised method for extracting the mappings from Chinese abbreviations and their full-forms. The method exploits the full-forms as bridges to translate the abbreviations. A prerequisite of the above methods is that the unknown words must have paraphrases (or full-forms). However, many types of unknown words do not have paraphrases (full-forms) naturally. In contrast to paraphrasing methods, Huang et al. (2011) developed a su"
I13-1103,P09-1089,0,0.0642456,"Missing"
I13-1103,P03-1021,0,0.0147245,"ty model. We also rebuilt the experiments based on the FBIS Parallel Text (LDC2003E14), which contains about 300,000 parallel sentences to verify the stability of our model. The rebuilding process is the same as that for the Hong Kong Parallel Text. 4 Experimental Results We evaluated the translation template model on the NIST MT06 test set and NIST 08 subset. During the evaluation, the test sets were translated by the Moses SMT system with/without the embedded translation suggestions derived by the translation template model. The parameters in Moses were tuned by minimum-error-rate training (Och, 2003) on the development set. Baseline Trans. table Phonetic Numeric All MT06 23.36 23.47 (+0.11) 23.83 (+0.47) 23.43 (+0.07) 23.89 (+0.53) MT08_sub 19.36 19.46 (+0.10) 19.65 (+0.29) 19.44 (+0.08) 19.80 (+0.44) rules. In our experiments, we exploit phonetic and numerical morphological translation rules to generate translations of morphemes. Table 1 shows the performances of the translation results with/without unknown word translation suggestions. As it shows, all of the translation expansion methods significantly improved the underlying SMT system. To verify the stability of this method, we also r"
I13-1103,J03-1002,0,0.0031684,"suggestion translations. 3.1 Baseline SMT System and Data Sets We used the Hong Kong Parallel Text (LDC2004T08) as the training data for the Moses SMT system and our template model. The Chinese sentences were pre-processed by the CKIP Chinese word segmentation system (Ma and Chen, 2003). The language model was trained on the English Gigaword corpus (LDC2003T05). We randomly selected 340 841 sentences from the NIST MT08 test data as our development set, the NIST MT06 test data and the rest of the NIST MT08 as our test set. 3.2 Training The parallel text was word-aligned by the GIZA++ toolkit (Och and Ney, 2003). Then, we utilized the word-aligned corpus to extract translation templates. This process yielded a set of translation templates and a translation template tagged corpus, which was used to train the fitting probability model. To evaluate the fitting probability model, the translation template tagged corpus was randomly split into two parts to obtain a translation template tagged training set (about 1,800,000 sentences) and a translation template tagged test set (about 200,000 sentences). We used the translation template tagged training set to train the rule fitting probability model. Then, we"
I13-1103,J96-1002,0,\N,Missing
I13-1103,P05-1033,0,\N,Missing
I17-3013,E14-1038,0,0.018423,"constructed resources (e,g., (Shei and Pain, 2000; Lee and Seneff, 2008; Liu et al., 2009)). It is not clear whether these manual resources can be easily scaled up and extended to other types of writing error and domains. Classifiers have been used for correcting verb errors. (Wu et al., 2010) describe an approach based on a classifier to predict the verb in the context of a given sentence. The main difference from our current work is that in(Wu et al., 2010), the context alone determine the outcome, the channel model information related to the potentially wrong verb is not used. Similarly, (Rozovskaya et al., 2014) use classifiers with the notion of verb finiteness to identify certain types of verb errors. (Rozovskaya et al., 2014) only address the agreement, tense, and form verb errors related to a small candidate set, while we deal with the verb selection problem with an open candidate set. In a noisy-channel approach closer to our work, (Sawai et al., 2013) use large learner corpus to construct candidate sets. They show that an GEC system that uses learner corpus outperforms systems that use WordNet and roundtrip translations, improving the performance of verb error detection and suggestion. In this"
I17-3013,P13-2124,0,0.0214651,"b in the context of a given sentence. The main difference from our current work is that in(Wu et al., 2010), the context alone determine the outcome, the channel model information related to the potentially wrong verb is not used. Similarly, (Rozovskaya et al., 2014) use classifiers with the notion of verb finiteness to identify certain types of verb errors. (Rozovskaya et al., 2014) only address the agreement, tense, and form verb errors related to a small candidate set, while we deal with the verb selection problem with an open candidate set. In a noisy-channel approach closer to our work, (Sawai et al., 2013) use large learner corpus to construct candidate sets. They show that an GEC system that uses learner corpus outperforms systems that use WordNet and roundtrip translations, improving the performance of verb error detection and suggestion. In this paper, we present a system, Verb Replacer, that uses both learner and web-scale corpora to extract errors to estimate the parameters in a channel model. Our system exploits the regularity of learner errors and a web-scale data set with a goal of maximizing the probability of an GEC system in returning alternatives for correcting misused verbs. An exa"
I17-3013,P10-2021,1,0.790323,"s of a sample of the Cambridge Learner Corpus (CLC) with 1,244 exam scripts for First Certificate English (FCE), verb selection errors (Replace-Verb errors, RV) is the most common error type, not counting spelling errors. In content word (e.g., verb and noun) errors correction, previous systems relied on mostly manually constructed resources (e,g., (Shei and Pain, 2000; Lee and Seneff, 2008; Liu et al., 2009)). It is not clear whether these manual resources can be easily scaled up and extended to other types of writing error and domains. Classifiers have been used for correcting verb errors. (Wu et al., 2010) describe an approach based on a classifier to predict the verb in the context of a given sentence. The main difference from our current work is that in(Wu et al., 2010), the context alone determine the outcome, the channel model information related to the potentially wrong verb is not used. Similarly, (Rozovskaya et al., 2014) use classifiers with the notion of verb finiteness to identify certain types of verb errors. (Rozovskaya et al., 2014) only address the agreement, tense, and form verb errors related to a small candidate set, while we deal with the verb selection problem with an open ca"
I17-3013,W09-2107,0,\N,Missing
I17-3013,P08-1021,0,\N,Missing
I17-3014,W03-1726,0,0.0249647,"te.herokuapp.com 53 The Companion Volume of the IJCNLP 2017 Proceedings: System Demonstrations, pages 53–56, c Taipei, Taiwan, November 27 – December 1, 2017. 2017 AFNLP Word I apologize for my behavior . POS PRP VBP IN PRP$ NN . B-I-O B-NP B-VP B-PP B-NP I-NP O Annotation Pattern V for NP NP (V for n) Table 1: Anchor ’apologize for n’ to a sentence 3.2 After obtaining the target language grammar patterns and instances for each headword, we then proceed to extract the corresponding native language grammar pattern and its example instances. For that, we use a Chinese word segment system, CKIP (Ma and Chen, 2003), to tokenize and tag Chinese sentence with POS information. We also use a word aligner, fast align (Dyer et al., 2013) to explore the crossing-lingual relationship between the target language and native language words (e.g., English and Mandarin words). Finally, we convert the aligned native counterpart instances into grammar patterns. Figure 1: The prototype system, WriteAway 3 Extracting Synchronous Grammar Patterns The extracting process involves recognizing the grammar patterns in the target language, aligning these patterns with their native language counterpart, and finally filtering va"
I17-3014,P15-4024,1,0.75261,"er, fast align (Dyer et al., 2013) to explore the crossing-lingual relationship between the target language and native language words (e.g., English and Mandarin words). Finally, we convert the aligned native counterpart instances into grammar patterns. Figure 1: The prototype system, WriteAway 3 Extracting Synchronous Grammar Patterns The extracting process involves recognizing the grammar patterns in the target language, aligning these patterns with their native language counterpart, and finally filtering valid SGPs with bilingual examples. We use a much simpler approach than previous work (Yen et al., 2015). We rely on a list of English grammar patterns from the HTML version of COLLINS COBUILD GRAMMAR PATTERNS 1: VERBS available at (http://arts-ccr-002.bham.ac.uk/ ccr/patgram/). Therefore, the main focus is to identify the instances of these verb patterns and their counter part and to convert the counterpart instances into patterns. 3.1 Align English Pattern to Chinese Identifying English Grammar Patterns In the identification process, we first use the GENIA Tagger (Tsuruoka et al., 2005) to shallow parse English sentences to obtain part of speech (POS) and chunk information (“B”,“I”,“O” symbols"
J97-2004,J90-2002,0,0.345452,"Missing"
J97-2004,1992.tmi-1.8,0,0.077414,"Missing"
J97-2004,J93-2003,0,0.139843,"Missing"
J97-2004,J92-4003,0,0.0464432,"Missing"
J97-2004,P91-1022,0,0.537908,"Missing"
J97-2004,1994.amta-1.3,0,0.047271,"methods for derived classes (Brown, Della Pietra, deSouza, Lai, and Mercer 1992) are not appropriate, since they also suffer low coverage due to data sparseness. Classes formed from morphologically related words are easy to derive and apply. Morphological classes can be formed, either from words that start with the same five-character prefix as in Gale and Church (1991b), or rigorous analysis as suggested in Brown, Della Pietra, Della Pietra, Lafferty, and Mercer (1992). Although easily applicable, morphological classes are not particularly effective in broadening coverage of word alignment. Chang and Chen (1994) also examine the feasibility of using part-of-speech classes. A potential alternative involves adopting categories available in machine-readable lexicographic resources such as Roget&apos;s thesaurus (Chapman 1977) or hand-crafted computer lexicons (Miller, Beckwith, Fellbaum, Gross, and Miller 1990; McRoy 1992). 3. Algorithms Leading to Class-based Word Alignment This section describes a series of three algorithms leading to a class-based system for word alignment. The first algorithm attempts to obtain reliable connections. The second algorithm generalizes the connections into a list of class-ba"
J97-2004,1996.amta-1.12,1,0.877789,"Missing"
J97-2004,P93-1002,0,0.261921,"Statistical machine translation (SMT) can be understood as a word-by-word model consisting of two submodels: a language model for generating a source text segment S and a translation model for mapping S to its translation T. They recommend using a bilingual corpus to train the parameters of translation probability, Pr(S I T) in the translation model. For MT and other purposes, many methods have been proposed for sentence alignment of the Hansards, an English-French corpus of Canadian parliamentary debates (Brown, Lai, and Mercer 1991; Gale and Church 1991a; Sirnard, Foster, and Isabelle 1992; Chen 1993; Gale and Church 1993), and for other language pairs, including English-German, EnglishChinese, and English-Japanese (Kay and ROscheisen 1993; Church, Dagan, Gale, Fung, Helfman, and Satish 1993; Fung and McKeown 1994; Wu 1994). Alignment at other levels of resolution is obviously useful. A section, paragraph, sentence, phrase, collocation, or word can be aligned to its translation (Kupiec 1993; Smadja, McKeown, and Hatzivassiloglou 1996). Other logical approaches involve aligning parse trees of a sentence and its translation (Matsumoto, Ishimoto, and Utsuro 1993; Meyers, Yangarber, and Grish"
J97-2004,W93-0301,0,0.455558,"Missing"
J97-2004,E93-1015,0,0.036261,"Missing"
J97-2004,1994.amta-1.11,0,0.141822,"its translation T. They recommend using a bilingual corpus to train the parameters of translation probability, Pr(S I T) in the translation model. For MT and other purposes, many methods have been proposed for sentence alignment of the Hansards, an English-French corpus of Canadian parliamentary debates (Brown, Lai, and Mercer 1991; Gale and Church 1991a; Sirnard, Foster, and Isabelle 1992; Chen 1993; Gale and Church 1993), and for other language pairs, including English-German, EnglishChinese, and English-Japanese (Kay and ROscheisen 1993; Church, Dagan, Gale, Fung, Helfman, and Satish 1993; Fung and McKeown 1994; Wu 1994). Alignment at other levels of resolution is obviously useful. A section, paragraph, sentence, phrase, collocation, or word can be aligned to its translation (Kupiec 1993; Smadja, McKeown, and Hatzivassiloglou 1996). Other logical approaches involve aligning parse trees of a sentence and its translation (Matsumoto, Ishimoto, and Utsuro 1993; Meyers, Yangarber, and Grishman 1996), or simultaneously generating parse trees and alignment arrangements (Wu 1995). • Department of Computer Science, National Tsing Hua University, Hsinchu, 30043, Taiwan, ROC. E-mail: ksj@volans.cs.scu.edu.tw;"
J97-2004,P91-1023,0,0.319683,"initiate much of the recent interest in bilingual corpora. Statistical machine translation (SMT) can be understood as a word-by-word model consisting of two submodels: a language model for generating a source text segment S and a translation model for mapping S to its translation T. They recommend using a bilingual corpus to train the parameters of translation probability, Pr(S I T) in the translation model. For MT and other purposes, many methods have been proposed for sentence alignment of the Hansards, an English-French corpus of Canadian parliamentary debates (Brown, Lai, and Mercer 1991; Gale and Church 1991a; Sirnard, Foster, and Isabelle 1992; Chen 1993; Gale and Church 1993), and for other language pairs, including English-German, EnglishChinese, and English-Japanese (Kay and ROscheisen 1993; Church, Dagan, Gale, Fung, Helfman, and Satish 1993; Fung and McKeown 1994; Wu 1994). Alignment at other levels of resolution is obviously useful. A section, paragraph, sentence, phrase, collocation, or word can be aligned to its translation (Kupiec 1993; Smadja, McKeown, and Hatzivassiloglou 1996). Other logical approaches involve aligning parse trees of a sentence and its translation (Matsumoto, Ishimot"
J97-2004,H91-1026,0,0.374817,"initiate much of the recent interest in bilingual corpora. Statistical machine translation (SMT) can be understood as a word-by-word model consisting of two submodels: a language model for generating a source text segment S and a translation model for mapping S to its translation T. They recommend using a bilingual corpus to train the parameters of translation probability, Pr(S I T) in the translation model. For MT and other purposes, many methods have been proposed for sentence alignment of the Hansards, an English-French corpus of Canadian parliamentary debates (Brown, Lai, and Mercer 1991; Gale and Church 1991a; Sirnard, Foster, and Isabelle 1992; Chen 1993; Gale and Church 1993), and for other language pairs, including English-German, EnglishChinese, and English-Japanese (Kay and ROscheisen 1993; Church, Dagan, Gale, Fung, Helfman, and Satish 1993; Fung and McKeown 1994; Wu 1994). Alignment at other levels of resolution is obviously useful. A section, paragraph, sentence, phrase, collocation, or word can be aligned to its translation (Kupiec 1993; Smadja, McKeown, and Hatzivassiloglou 1996). Other logical approaches involve aligning parse trees of a sentence and its translation (Matsumoto, Ishimot"
J97-2004,J93-1004,0,0.278645,"machine translation (SMT) can be understood as a word-by-word model consisting of two submodels: a language model for generating a source text segment S and a translation model for mapping S to its translation T. They recommend using a bilingual corpus to train the parameters of translation probability, Pr(S I T) in the translation model. For MT and other purposes, many methods have been proposed for sentence alignment of the Hansards, an English-French corpus of Canadian parliamentary debates (Brown, Lai, and Mercer 1991; Gale and Church 1991a; Sirnard, Foster, and Isabelle 1992; Chen 1993; Gale and Church 1993), and for other language pairs, including English-German, EnglishChinese, and English-Japanese (Kay and ROscheisen 1993; Church, Dagan, Gale, Fung, Helfman, and Satish 1993; Fung and McKeown 1994; Wu 1994). Alignment at other levels of resolution is obviously useful. A section, paragraph, sentence, phrase, collocation, or word can be aligned to its translation (Kupiec 1993; Smadja, McKeown, and Hatzivassiloglou 1996). Other logical approaches involve aligning parse trees of a sentence and its translation (Matsumoto, Ishimoto, and Utsuro 1993; Meyers, Yangarber, and Grishman 1996), or simultane"
J97-2004,1992.tmi-1.9,0,0.274396,"Missing"
J97-2004,P93-1003,0,0.0173601,"e been proposed for sentence alignment of the Hansards, an English-French corpus of Canadian parliamentary debates (Brown, Lai, and Mercer 1991; Gale and Church 1991a; Sirnard, Foster, and Isabelle 1992; Chen 1993; Gale and Church 1993), and for other language pairs, including English-German, EnglishChinese, and English-Japanese (Kay and ROscheisen 1993; Church, Dagan, Gale, Fung, Helfman, and Satish 1993; Fung and McKeown 1994; Wu 1994). Alignment at other levels of resolution is obviously useful. A section, paragraph, sentence, phrase, collocation, or word can be aligned to its translation (Kupiec 1993; Smadja, McKeown, and Hatzivassiloglou 1996). Other logical approaches involve aligning parse trees of a sentence and its translation (Matsumoto, Ishimoto, and Utsuro 1993; Meyers, Yangarber, and Grishman 1996), or simultaneously generating parse trees and alignment arrangements (Wu 1995). • Department of Computer Science, National Tsing Hua University, Hsinchu, 30043, Taiwan, ROC. E-mail: ksj@volans.cs.scu.edu.tw; jschang@cs.nthu.edu.tw (~) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 2 In addition to machine translation, many applications for al"
J97-2004,1994.amta-1.21,0,0.0598428,"Missing"
J97-2004,P93-1004,0,0.0544031,"Missing"
J97-2004,J92-1001,0,0.0164365,"ame five-character prefix as in Gale and Church (1991b), or rigorous analysis as suggested in Brown, Della Pietra, Della Pietra, Lafferty, and Mercer (1992). Although easily applicable, morphological classes are not particularly effective in broadening coverage of word alignment. Chang and Chen (1994) also examine the feasibility of using part-of-speech classes. A potential alternative involves adopting categories available in machine-readable lexicographic resources such as Roget&apos;s thesaurus (Chapman 1977) or hand-crafted computer lexicons (Miller, Beckwith, Fellbaum, Gross, and Miller 1990; McRoy 1992). 3. Algorithms Leading to Class-based Word Alignment This section describes a series of three algorithms leading to a class-based system for word alignment. The first algorithm attempts to obtain reliable connections. The second algorithm generalizes the connections into a list of class-based rules, which stipulate that a pair of classes of words in the source and target languages are likely mutual translations. The third algorithm performs the actual word alignment based on the acquired rules, in addition to DTs. 319 Computational Linguistics Volume 23, Number 2 3.1 Dictionary-based Word Ali"
J97-2004,C96-1078,0,0.0503976,"Missing"
J97-2004,E93-1054,0,0.0355092,"Missing"
J97-2004,1992.tmi-1.7,0,0.14604,"Missing"
J97-2004,J96-1001,0,0.12018,"Missing"
J97-2004,P94-1012,0,0.138368,"recommend using a bilingual corpus to train the parameters of translation probability, Pr(S I T) in the translation model. For MT and other purposes, many methods have been proposed for sentence alignment of the Hansards, an English-French corpus of Canadian parliamentary debates (Brown, Lai, and Mercer 1991; Gale and Church 1991a; Sirnard, Foster, and Isabelle 1992; Chen 1993; Gale and Church 1993), and for other language pairs, including English-German, EnglishChinese, and English-Japanese (Kay and ROscheisen 1993; Church, Dagan, Gale, Fung, Helfman, and Satish 1993; Fung and McKeown 1994; Wu 1994). Alignment at other levels of resolution is obviously useful. A section, paragraph, sentence, phrase, collocation, or word can be aligned to its translation (Kupiec 1993; Smadja, McKeown, and Hatzivassiloglou 1996). Other logical approaches involve aligning parse trees of a sentence and its translation (Matsumoto, Ishimoto, and Utsuro 1993; Meyers, Yangarber, and Grishman 1996), or simultaneously generating parse trees and alignment arrangements (Wu 1995). • Department of Computer Science, National Tsing Hua University, Hsinchu, 30043, Taiwan, ROC. E-mail: ksj@volans.cs.scu.edu.tw; jschang@cs"
J97-2004,1995.tmi-1.28,0,0.379774,"EnglishChinese, and English-Japanese (Kay and ROscheisen 1993; Church, Dagan, Gale, Fung, Helfman, and Satish 1993; Fung and McKeown 1994; Wu 1994). Alignment at other levels of resolution is obviously useful. A section, paragraph, sentence, phrase, collocation, or word can be aligned to its translation (Kupiec 1993; Smadja, McKeown, and Hatzivassiloglou 1996). Other logical approaches involve aligning parse trees of a sentence and its translation (Matsumoto, Ishimoto, and Utsuro 1993; Meyers, Yangarber, and Grishman 1996), or simultaneously generating parse trees and alignment arrangements (Wu 1995). • Department of Computer Science, National Tsing Hua University, Hsinchu, 30043, Taiwan, ROC. E-mail: ksj@volans.cs.scu.edu.tw; jschang@cs.nthu.edu.tw (~) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 2 In addition to machine translation, many applications for aligned corpora have been suggested, including machine-aided translation (Shemtov 1993), translation assessment and critiquing tools (Isabelle 1992; des Tombe and Armstrong-Warwick 1993; Macklovitch 1994), text generation (Smadja 1992; Smadja, McKeown, and Hatzivassiloglou 1996), bilingual l"
J97-2004,1994.amta-1.26,0,0.156889,"Missing"
J97-2004,C90-3031,0,\N,Missing
J97-2004,C94-1084,0,\N,Missing
J97-2004,J93-1006,0,\N,Missing
J97-2004,1996.amta-1.13,0,\N,Missing
J98-1003,P84-1093,0,0.0562069,"a narrower coverage of word senses. To get the best of both worlds of dictionary and thesaurus, we propose to cluster MRD definitions to yield a broad-coverage sense division with the granularity of a thesaurus. Therefore, a short description of MRDs and thesauri is in order. 2.1 Fine-Grained S e n s e s in an M R D Interest in MRD-based research has increased over the years; in particular, the LDOCE and Webster's Seventh New CollegiateDictionary (W7) (1967) have drawn much attention. Much of the MRD-based research has focused on the analysis and exploitation of the sense definitions in MRDs (Amsler 1984a, 1984b, 1987; Alshawi 1987; Alshawi, Boguraev, and Carter 1989; Vossen, Meijs, and denBroeder 1989). In these works, the definitions are analyzed using either a parser (Montemagni and Vanderwende 1992) or a pattern matcher (Ahlswede and Evens 1988) into semantic relations. These relations are then used for various tasks, ranging from the interpretation of a noun sequence (Vanderwende 1994) or a prepositional phrase (Ravin 1990), to resolving structural ambiguity (Jenson and Binot 1987), to merging dictionary senses for WSD (Dolan 1994). Besides the definition itself, there is an abundance of"
J98-1003,A92-1044,0,0.0663382,"Missing"
J98-1003,P88-1027,0,0.0486569,"ption of MRDs and thesauri is in order. 2.1 Fine-Grained S e n s e s in an M R D Interest in MRD-based research has increased over the years; in particular, the LDOCE and Webster's Seventh New CollegiateDictionary (W7) (1967) have drawn much attention. Much of the MRD-based research has focused on the analysis and exploitation of the sense definitions in MRDs (Amsler 1984a, 1984b, 1987; Alshawi 1987; Alshawi, Boguraev, and Carter 1989; Vossen, Meijs, and denBroeder 1989). In these works, the definitions are analyzed using either a parser (Montemagni and Vanderwende 1992) or a pattern matcher (Ahlswede and Evens 1988) into semantic relations. These relations are then used for various tasks, ranging from the interpretation of a noun sequence (Vanderwende 1994) or a prepositional phrase (Ravin 1990), to resolving structural ambiguity (Jenson and Binot 1987), to merging dictionary senses for WSD (Dolan 1994). Besides the definition itself, there is an abundance of information listed in a dictionary entry, including part of speech, subcategory, examples, collocations, and typical arguments, which is potentially useful for WSD. In this regard, the LDOCE is particularly appropriate since it uses a reduced, contr"
J98-1003,J87-3001,0,0.0330619,"senses. To get the best of both worlds of dictionary and thesaurus, we propose to cluster MRD definitions to yield a broad-coverage sense division with the granularity of a thesaurus. Therefore, a short description of MRDs and thesauri is in order. 2.1 Fine-Grained S e n s e s in an M R D Interest in MRD-based research has increased over the years; in particular, the LDOCE and Webster's Seventh New CollegiateDictionary (W7) (1967) have drawn much attention. Much of the MRD-based research has focused on the analysis and exploitation of the sense definitions in MRDs (Amsler 1984a, 1984b, 1987; Alshawi 1987; Alshawi, Boguraev, and Carter 1989; Vossen, Meijs, and denBroeder 1989). In these works, the definitions are analyzed using either a parser (Montemagni and Vanderwende 1992) or a pattern matcher (Ahlswede and Evens 1988) into semantic relations. These relations are then used for various tasks, ranging from the interpretation of a noun sequence (Vanderwende 1994) or a prepositional phrase (Ravin 1990), to resolving structural ambiguity (Jenson and Binot 1987), to merging dictionary senses for WSD (Dolan 1994). Besides the definition itself, there is an abundance of information listed in a dic"
J98-1003,P91-1034,0,0.372692,". Relatively well-established IR techniques of weighting terms and ranking document relevancy are applied to find the topical clusters that are most relevant to the definition of each M R D sense. Finally, we describe an implemented version of the algorithms for the LDOCE and the LLOCE and assess the performance of the proposed approach in a series of experiments and evaluations. 1. Introduction Word sense disambiguation (WSD) has been found useful in many natural language processing (NLP) applications, including information retrieval (Krovetz and Croft 1992; McRoy 1992), machine translation (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994), and speech synthesis (Yarowsky 1992). WSD has received increasing attention in recent literature on computational linguistics (Lesk 1986; Schi.itze 1992; Gale, Church, and Yarowsky 1992; Yarowsky 1992, 1995; Bruce and Wiebe 1995; Luk 1995; Ng and Lee 1996; Chang et al. 1996). Given a polysemous word in running text, the task of WSD involves examining contextual information to determine the intended sense from a set of predetermined candidates. It is a nontrivial task to divide the senses of a word and determine this set, for word sense is"
J98-1003,1996.amta-1.12,1,0.706319,"approach in a series of experiments and evaluations. 1. Introduction Word sense disambiguation (WSD) has been found useful in many natural language processing (NLP) applications, including information retrieval (Krovetz and Croft 1992; McRoy 1992), machine translation (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994), and speech synthesis (Yarowsky 1992). WSD has received increasing attention in recent literature on computational linguistics (Lesk 1986; Schi.itze 1992; Gale, Church, and Yarowsky 1992; Yarowsky 1992, 1995; Bruce and Wiebe 1995; Luk 1995; Ng and Lee 1996; Chang et al. 1996). Given a polysemous word in running text, the task of WSD involves examining contextual information to determine the intended sense from a set of predetermined candidates. It is a nontrivial task to divide the senses of a word and determine this set, for word sense is an abstract concept frequently based on subjective and subtle distinctions in topic, register, dialect, collocation, part of speech, and valency (McRoy 1992). Various approaches to word sense division have been proposed in the literature on WSD, including (1) sense numbers in every-day dictionaries (Lesk 1986; Cowie, Guthrie, an"
J98-1003,P85-1037,0,0.705218,"Missing"
J98-1003,A88-1019,0,0.0360244,"Missing"
J98-1003,H92-1046,0,0.104344,"Missing"
J98-1003,J94-4003,0,0.443796,"ghting terms and ranking document relevancy are applied to find the topical clusters that are most relevant to the definition of each M R D sense. Finally, we describe an implemented version of the algorithms for the LDOCE and the LLOCE and assess the performance of the proposed approach in a series of experiments and evaluations. 1. Introduction Word sense disambiguation (WSD) has been found useful in many natural language processing (NLP) applications, including information retrieval (Krovetz and Croft 1992; McRoy 1992), machine translation (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994), and speech synthesis (Yarowsky 1992). WSD has received increasing attention in recent literature on computational linguistics (Lesk 1986; Schi.itze 1992; Gale, Church, and Yarowsky 1992; Yarowsky 1992, 1995; Bruce and Wiebe 1995; Luk 1995; Ng and Lee 1996; Chang et al. 1996). Given a polysemous word in running text, the task of WSD involves examining contextual information to determine the intended sense from a set of predetermined candidates. It is a nontrivial task to divide the senses of a word and determine this set, for word sense is an abstract concept frequently based on subjective an"
J98-1003,P91-1017,0,0.109508,"Missing"
J98-1003,C94-2113,0,0.223179,"contextual information to determine the intended sense from a set of predetermined candidates. It is a nontrivial task to divide the senses of a word and determine this set, for word sense is an abstract concept frequently based on subjective and subtle distinctions in topic, register, dialect, collocation, part of speech, and valency (McRoy 1992). Various approaches to word sense division have been proposed in the literature on WSD, including (1) sense numbers in every-day dictionaries (Lesk 1986; Cowie, Guthrie, and Guthrie 1992), (2) automatic or hand-crafted clusters of dictionary senses (Dolan 1994; Bruce and Wiebe 1995; Luk * Department of Computer Science,National Tsing Hua University,Hsinchu 30043,Taiwan, ROC. E-mail: dr818314@cs.nthu.edu.tw; jschang@cs.nthu.edu.tw. (~ 1998Association for Computational Linguistics Computational Linguistics Volume 24, Number 1 1995), (3) thesaurus categories (Yarowsky 1992; Chen and Chang 1994), (4) translation in another language (Gale, Church, and Yarowsky 1992; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994), (5) automatically induced clusters with sublexical representation (Schiitze 1992), and (6) hand-crafted lexicons (McRoy 1992). This paper"
J98-1003,1992.tmi-1.9,0,0.656618,"Missing"
J98-1003,J87-3005,0,0.301698,"tention. Much of the MRD-based research has focused on the analysis and exploitation of the sense definitions in MRDs (Amsler 1984a, 1984b, 1987; Alshawi 1987; Alshawi, Boguraev, and Carter 1989; Vossen, Meijs, and denBroeder 1989). In these works, the definitions are analyzed using either a parser (Montemagni and Vanderwende 1992) or a pattern matcher (Ahlswede and Evens 1988) into semantic relations. These relations are then used for various tasks, ranging from the interpretation of a noun sequence (Vanderwende 1994) or a prepositional phrase (Ravin 1990), to resolving structural ambiguity (Jenson and Binot 1987), to merging dictionary senses for WSD (Dolan 1994). Besides the definition itself, there is an abundance of information listed in a dictionary entry, including part of speech, subcategory, examples, collocations, and typical arguments, which is potentially useful for WSD. In this regard, the LDOCE is particularly appropriate since it uses a reduced, controlled vocabulary of some 2,000 words to define over 60,000 word senses representing a comprehensive vocabulary and broad coverage of word senses. It is arguable that the dictionary division of senses for a given word is too finegrained, thus"
J98-1003,P92-1054,0,0.0536528,"Missing"
J98-1003,P95-1025,0,0.336219,"performance of the proposed approach in a series of experiments and evaluations. 1. Introduction Word sense disambiguation (WSD) has been found useful in many natural language processing (NLP) applications, including information retrieval (Krovetz and Croft 1992; McRoy 1992), machine translation (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994), and speech synthesis (Yarowsky 1992). WSD has received increasing attention in recent literature on computational linguistics (Lesk 1986; Schi.itze 1992; Gale, Church, and Yarowsky 1992; Yarowsky 1992, 1995; Bruce and Wiebe 1995; Luk 1995; Ng and Lee 1996; Chang et al. 1996). Given a polysemous word in running text, the task of WSD involves examining contextual information to determine the intended sense from a set of predetermined candidates. It is a nontrivial task to divide the senses of a word and determine this set, for word sense is an abstract concept frequently based on subjective and subtle distinctions in topic, register, dialect, collocation, part of speech, and valency (McRoy 1992). Various approaches to word sense division have been proposed in the literature on WSD, including (1) sense numbers in every-day dictio"
J98-1003,J92-1001,0,0.73028,"nformation retrieval (IR) research. Relatively well-established IR techniques of weighting terms and ranking document relevancy are applied to find the topical clusters that are most relevant to the definition of each M R D sense. Finally, we describe an implemented version of the algorithms for the LDOCE and the LLOCE and assess the performance of the proposed approach in a series of experiments and evaluations. 1. Introduction Word sense disambiguation (WSD) has been found useful in many natural language processing (NLP) applications, including information retrieval (Krovetz and Croft 1992; McRoy 1992), machine translation (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994), and speech synthesis (Yarowsky 1992). WSD has received increasing attention in recent literature on computational linguistics (Lesk 1986; Schi.itze 1992; Gale, Church, and Yarowsky 1992; Yarowsky 1992, 1995; Bruce and Wiebe 1995; Luk 1995; Ng and Lee 1996; Chang et al. 1996). Given a polysemous word in running text, the task of WSD involves examining contextual information to determine the intended sense from a set of predetermined candidates. It is a nontrivial task to divide the senses of a word an"
J98-1003,P96-1006,0,0.0318847,"e of the proposed approach in a series of experiments and evaluations. 1. Introduction Word sense disambiguation (WSD) has been found useful in many natural language processing (NLP) applications, including information retrieval (Krovetz and Croft 1992; McRoy 1992), machine translation (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994), and speech synthesis (Yarowsky 1992). WSD has received increasing attention in recent literature on computational linguistics (Lesk 1986; Schi.itze 1992; Gale, Church, and Yarowsky 1992; Yarowsky 1992, 1995; Bruce and Wiebe 1995; Luk 1995; Ng and Lee 1996; Chang et al. 1996). Given a polysemous word in running text, the task of WSD involves examining contextual information to determine the intended sense from a set of predetermined candidates. It is a nontrivial task to divide the senses of a word and determine this set, for word sense is an abstract concept frequently based on subjective and subtle distinctions in topic, register, dialect, collocation, part of speech, and valency (McRoy 1992). Various approaches to word sense division have been proposed in the literature on WSD, including (1) sense numbers in every-day dictionaries (Lesk 1986"
J98-1003,1994.amta-1.23,0,0.111535,"Missing"
J98-1003,W91-0208,0,0.0463191,"Missing"
J98-1003,J91-4003,0,0.0648476,"Missing"
J98-1003,C94-2112,0,0.0157498,"ences are systematic intersense relations similar to the abovementioned Food/Plant relation. Indeed, words involved in such intersense relations are frequently underspecified. For instance, chicken is listed under both topic Eb and topic Ad, while duck is listed under Ad but not Eb. By characterizing some 200 cross-references in LLOCE, most systematic sense shifts can be easily identified among the senses across topical clusters. The topical clusters of MRD senses, coupled with the topical description of sense-shift knowledge, can support and realize automatic sense extension, as advocated in Putstejovsky and Bouillon (1994), and prevent a proliferation of senses in the semantic lexicon. For instance, the sense of duck in the Ad cluster can be coerced into an Eb sense, in some context, based on the knowledge of a systematic sense shift from Ad (Birds) to Eb (Food). 6. Other Approaches Sanfilippo and Poznanski (1992) propose a so-called dictionary correlation kit (DCK) in a dialogue-based environment for correlating word senses across a pair of MRDs such as the LDOCE and the LLOCE. The approach taken in DCK is essentially a heuristic one, based on a correlation in the headwords, grammar codes, definition, and exam"
J98-1003,A92-1011,0,0.153108,"ing some 200 cross-references in LLOCE, most systematic sense shifts can be easily identified among the senses across topical clusters. The topical clusters of MRD senses, coupled with the topical description of sense-shift knowledge, can support and realize automatic sense extension, as advocated in Putstejovsky and Bouillon (1994), and prevent a proliferation of senses in the semantic lexicon. For instance, the sense of duck in the Ad cluster can be coerced into an Eb sense, in some context, based on the knowledge of a systematic sense shift from Ad (Birds) to Eb (Food). 6. Other Approaches Sanfilippo and Poznanski (1992) propose a so-called dictionary correlation kit (DCK) in a dialogue-based environment for correlating word senses across a pair of MRDs such as the LDOCE and the LLOCE. The approach taken in DCK is essentially a heuristic one, based on a correlation in the headwords, grammar codes, definition, and examples between the senses in LDOCE and LLOCE. The authors indicate that for the heuristics to yield optimum results, the degree of overlap in the examples should be weighted twice as heavily as all other factors. However, they do not elaborate on how the comparisons are done, or on how effective th"
J98-1003,C92-2070,0,0.50598,"are applied to find the topical clusters that are most relevant to the definition of each M R D sense. Finally, we describe an implemented version of the algorithms for the LDOCE and the LLOCE and assess the performance of the proposed approach in a series of experiments and evaluations. 1. Introduction Word sense disambiguation (WSD) has been found useful in many natural language processing (NLP) applications, including information retrieval (Krovetz and Croft 1992; McRoy 1992), machine translation (Brown et al. 1991; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994), and speech synthesis (Yarowsky 1992). WSD has received increasing attention in recent literature on computational linguistics (Lesk 1986; Schi.itze 1992; Gale, Church, and Yarowsky 1992; Yarowsky 1992, 1995; Bruce and Wiebe 1995; Luk 1995; Ng and Lee 1996; Chang et al. 1996). Given a polysemous word in running text, the task of WSD involves examining contextual information to determine the intended sense from a set of predetermined candidates. It is a nontrivial task to divide the senses of a word and determine this set, for word sense is an abstract concept frequently based on subjective and subtle distinctions in topic, regist"
J98-1003,P95-1026,0,0.29842,"Missing"
J98-1003,C94-2125,0,\N,Missing
J98-1003,C92-2083,0,\N,Missing
J98-1003,T87-1005,0,\N,Missing
J98-1003,P84-1094,0,\N,Missing
J98-1003,P94-1020,0,\N,Missing
J98-1003,P90-1033,0,\N,Missing
J98-1003,C90-3025,0,\N,Missing
lee-etal-2004-alignment,W03-1501,0,\N,Missing
lee-etal-2004-alignment,J93-2003,0,\N,Missing
lee-etal-2004-alignment,W03-0317,1,\N,Missing
lee-etal-2004-alignment,E03-1035,0,\N,Missing
lee-etal-2004-alignment,P97-1063,0,\N,Missing
lee-etal-2004-alignment,P02-1051,0,\N,Missing
lee-etal-2004-alignment,O01-3004,1,\N,Missing
lin-etal-2004-extraction,C02-1099,0,\N,Missing
lin-etal-2004-extraction,W02-2017,0,\N,Missing
lin-etal-2004-extraction,W98-1005,0,\N,Missing
lin-etal-2004-extraction,W03-0317,1,\N,Missing
lin-etal-2004-extraction,P98-1036,0,\N,Missing
lin-etal-2004-extraction,C98-1036,0,\N,Missing
lin-etal-2004-extraction,P02-1051,0,\N,Missing
lin-etal-2004-extraction,O03-1001,1,\N,Missing
lin-etal-2004-extraction,J98-4003,0,\N,Missing
N07-4011,lin-etal-2004-extraction,1,\N,Missing
N07-4011,C02-1011,0,\N,Missing
N07-4011,W01-1413,0,\N,Missing
N07-4011,P03-1040,0,\N,Missing
N07-4011,J98-4003,0,\N,Missing
N09-1029,P05-1033,0,0.0647972,"ifferent circumstances. Therefore, while phrase-based SMT moves from words to phrases as the basic unit of translation, implying effective local reordering within phrases, it suffers when determining phrase reordering, especially when phrases are longer than three words (Koehn et al., 2003). There have been much effort made to improve reordering model in SMT. For example, researchers have been studying CKY parsing over the last decade, which considers translations and orientations of two neighboring block according to grammar rules or context information. In hierarchical phrase-based systems (Chiang, 2005), for example, SCFG rules are automatically learned from aligned bilingual corpus, and are applied in CKY style decoding. As an another application of CKY parsing technique is BTG-based SMT. Xiong et al. (2006) and Xiong et al. (2008a) developed MEBTG systems, in which first or tail words from reordering examples are used as features to train ME-based reordering models. Similarly, Zhang et al. (2007) proposed a model similar to BTG, which uses first/tail words of phrases, and syntactic labels (e.g. NP and VP) from source parse trees as features. In their work, however, inverted rules are allow"
N09-1029,N03-1017,0,0.0268676,"model, since the training data can not possibly cover all such similar cases. In this paper we present an improved reordering model based on BTG, with bilingual linguistic features from neighboring blocks. To avoid data sparseness problem, both source and target words are classified; we perform part-of-speech (POS) tagging on source language, and word classifica255 Related Work In statistical machine translation, reordering model is concerned with predicting correct orders of target language sentence given a source language one and translation pairs. For example, in phrase-based SMT systems (Koehn et al., 2003; Koehn, 2004), distortion model is used, in which reordering probabilities depend on relative positions of target side phrases between adjacent blocks. However, distortion model can not model long-distance reordering, due to the lack of context information, thus is difficult to predict correct orders under different circumstances. Therefore, while phrase-based SMT moves from words to phrases as the basic unit of translation, implying effective local reordering within phrases, it suffers when determining phrase reordering, especially when phrases are longer than three words (Koehn et al., 2003"
N09-1029,koen-2004-pharaoh,0,0.286992,"EBTG, first words of blocks are considered as the features, which are then used to train a ME model 254 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 254–262, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics for predicting orientations of neighboring blocks. Xiong et al. (2008b) proposed a linguistically annotated BTG (LABTG), in which linguistic features such as POS and syntactic labels from source-side parse trees are used. Both MEBTG and LABTG achieved significant improvements over phrase-based Pharaoh (Koehn, 2004) and Moses (Koehn et al., 2007) respectively, on Chinese-to-English translation tasks. 該 項 計劃 Nes Nf Nv the details of 14 49 50 the plan 14 18 的 詳情 DE Na A2 tion on target one, as shown in Figure 2. Additionally, features are extracted and classified depending on lengths of blocks in order to obtain a more informed model. The rest of this paper is organized as follows. Section 2 reviews the related work. Section 3 describes the model used in our BTG-based SMT systems. Section 4 formally describes our bilingual linguistic reordering model. Section 5 and Section 6 explain the implementation of o"
N09-1029,P07-2045,0,0.040628,"cks are considered as the features, which are then used to train a ME model 254 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 254–262, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics for predicting orientations of neighboring blocks. Xiong et al. (2008b) proposed a linguistically annotated BTG (LABTG), in which linguistic features such as POS and syntactic labels from source-side parse trees are used. Both MEBTG and LABTG achieved significant improvements over phrase-based Pharaoh (Koehn, 2004) and Moses (Koehn et al., 2007) respectively, on Chinese-to-English translation tasks. 該 項 計劃 Nes Nf Nv the details of 14 49 50 the plan 14 18 的 詳情 DE Na A2 tion on target one, as shown in Figure 2. Additionally, features are extracted and classified depending on lengths of blocks in order to obtain a more informed model. The rest of this paper is organized as follows. Section 2 reviews the related work. Section 3 describes the model used in our BTG-based SMT systems. Section 4 formally describes our bilingual linguistic reordering model. Section 5 and Section 6 explain the implementation of our systems. We show the experim"
N09-1029,P03-1054,0,0.00277332,", since they focus on syntactic labels. Boundary POS is considered in LABTG only when source phrases are not syntactic phrases. In contrast to the previous works, we present a reordering model for BTG that uses bilingual information including class-level features of POS and word classes. Moreover, our model is dedicated to boundary features and considers different combinations of phrase lengths, rather than only first/tail words. In addition, current state-of-the-art Chinese parsers, including the one used in LABTG (Xiong et al., 2005), lag beyond in inaccuracy, compared with English parsers (Klein and Manning, 2003; Petrov and Klein 2007). In our work, we only use more reliable information such as Chinese word segmentation and POS tagging (Ma and Chen, 2003). 3 Preo ( A1 , A2 , order) reo where order  {straight, inverted}. In MEBTG, a ME reordering model is trained using features extracted from reordering examples of aligned parallel corpus. First words on neighboring blocks are used as features. In reordering example (a), for example, the feature set is {&quot;S1L=three&quot;, &quot;S2L=ago&quot;, &quot;T1L=3&quot;, &quot;T2L=前&quot;} where &quot;S1&quot; and &quot;T1&quot; denote source and target phrases from the block A1. Rule (3) is lexical translation ru"
N09-1029,H05-1021,0,0.0198124,"slation pair drops drastically especially for long sentences, yet it still covers most of the syntactic diversities between two languages. It is common to utilize phrase translation in BTG systems. For example in (Xiong et al., 2006), source sentences are segmented into phrases. Each On the other hand, there are various proposed BTG reordering models to predict correct orientations between neighboring blocks (bilingual phrases). In Figure 1, for example, the role of reordering model is to predict correct orientations of neighboring blocks A1 and A2. In flat model (Wu, 1996; Zens et al., 2004; Kumar and Byrne, 2005), reordering probabilities are assigned uniformly during decoding, and can be tuned depending on different language pairs. It is clear, however, that this kind of model would suffer when the dominant rule is wrongly applied. Predicting orientations in BTG depending on context information can be achieved with lexical features. For example, Xiong et al. (2006) proposed MEBTG, based on maximum entropy (ME) classification with words as features. In MEBTG, first words of blocks are considered as the features, which are then used to train a ME model 254 Human Language Technologies: The 2009 Annual C"
N09-1029,W03-1726,0,0.264274,"ious works, we present a reordering model for BTG that uses bilingual information including class-level features of POS and word classes. Moreover, our model is dedicated to boundary features and considers different combinations of phrase lengths, rather than only first/tail words. In addition, current state-of-the-art Chinese parsers, including the one used in LABTG (Xiong et al., 2005), lag beyond in inaccuracy, compared with English parsers (Klein and Manning, 2003; Petrov and Klein 2007). In our work, we only use more reliable information such as Chinese word segmentation and POS tagging (Ma and Chen, 2003). 3 Preo ( A1 , A2 , order) reo where order  {straight, inverted}. In MEBTG, a ME reordering model is trained using features extracted from reordering examples of aligned parallel corpus. First words on neighboring blocks are used as features. In reordering example (a), for example, the feature set is {&quot;S1L=three&quot;, &quot;S2L=ago&quot;, &quot;T1L=3&quot;, &quot;T2L=前&quot;} where &quot;S1&quot; and &quot;T1&quot; denote source and target phrases from the block A1. Rule (3) is lexical translation rule, which translates source phrase x into target phrase y. We use the same feature functions as typical phrase-based SMT systems (Koehn et al., 20"
N09-1029,E99-1010,0,0.0504779,"Chinese tagset, the CKIP tagset pro257 vides more fine-grained tags, including many tags with semantic information (e.g., Nc for place nouns, Nd for time nouns), and verb transitivity and subcategorization (e.g., VA for intransitive verbs, VC for transitive verbs, VK for verbs that take a clause as object). On the other hand, using the POS features in combination with the lexical features in target language will cause another sparseness problem in the phrase table, since one source phrase would map to multiple target ones with different POS sequences. As an alternative, we use mkcls toolkit (Och, 1999), which uses maximum-likelihood principle to perform classification on target side. After classification, the toolkit produces a many-to-one mapping between English tokens and class numbers. Therefore, there is no ambiguity of word class in target phrases and word class features can be used independently to avoid data sparseness problem and the phrase table remains unchanged. As mentioned in Section 1, features based on words are not representative enough in some cases, and tend to cause sparseness problem. By classifying words we are able to linguistically generalize the features, and hence p"
N09-1029,J03-1002,0,0.00433681,"Missing"
N09-1029,P03-1021,0,0.00477885,"es are applied during decoding: A  A1 A2  (1) A  A1 A2 (2) A x/ y y 6 (3) where A1 and A2 are blocks in source order. Straight rule (1) and inverted rule (2) are reordering rules. They are applied for predicting target-side order when combining two blocks, and form the reordering model with the distributions 256  Plm ( A1 , A2 )lm  Preo ( A1 , A2 , order)reo or P( A)  Plm ( A) lm  Ptrans ( x |y ) where Plm ( A) lm and Plm ( A1 , A2 ) lm are respectively the usual and incremental score of language model. To tune all lambda weights above, we perform minimum error rate training (Och, 2003) on the development set described in Section 7. Let B be the set of all blocks with source side sentence C. Then the best translation of C is the target side of the block A , where A  argmax P( A) AB 4 Bilingual Linguistic Model In this section, we formally describe the problem we want to address and the proposed method. 4.1 Problem Statement We focus on extracting features representative of the two neighboring blocks being considered for reordering by the decoder, as described in Section 3. We define S(A) and T(A) as the information on source and target side of a block A. For two neighborin"
N09-1029,P02-1040,0,0.0836438,"Missing"
N09-1029,N07-1051,0,0.0329957,"tactic labels. Boundary POS is considered in LABTG only when source phrases are not syntactic phrases. In contrast to the previous works, we present a reordering model for BTG that uses bilingual information including class-level features of POS and word classes. Moreover, our model is dedicated to boundary features and considers different combinations of phrase lengths, rather than only first/tail words. In addition, current state-of-the-art Chinese parsers, including the one used in LABTG (Xiong et al., 2005), lag beyond in inaccuracy, compared with English parsers (Klein and Manning, 2003; Petrov and Klein 2007). In our work, we only use more reliable information such as Chinese word segmentation and POS tagging (Ma and Chen, 2003). 3 Preo ( A1 , A2 , order) reo where order  {straight, inverted}. In MEBTG, a ME reordering model is trained using features extracted from reordering examples of aligned parallel corpus. First words on neighboring blocks are used as features. In reordering example (a), for example, the feature set is {&quot;S1L=three&quot;, &quot;S2L=ago&quot;, &quot;T1L=3&quot;, &quot;T2L=前&quot;} where &quot;S1&quot; and &quot;T1&quot; denote source and target phrases from the block A1. Rule (3) is lexical translation rule, which translates sou"
N09-1029,P96-1021,0,0.0439247,"ual linguistic model outperforms the state-of-the-art phrase-based and BTG-based SMT systems by improvements of 2.41 and 1.31 BLEU points respectively. 1 3年 three years 前 three A2 (a) years 後 A2 after A1 ago 3年 A1 (b) Figure 1: Two reordering examples, with straight rule applied in (a), and inverted rule in (b). Introduction Bracketing Transduction Grammar (BTG) is a special case of Synchronous Context Free Grammar (SCFG), with binary branching rules that are either straight or inverted. BTG is widely adopted in SMT systems, because of its good trade-off between efficiency and expressiveness (Wu, 1996). In BTG, the ratio of legal alignments and all possible alignment in a translation pair drops drastically especially for long sentences, yet it still covers most of the syntactic diversities between two languages. It is common to utilize phrase translation in BTG systems. For example in (Xiong et al., 2006), source sentences are segmented into phrases. Each On the other hand, there are various proposed BTG reordering models to predict correct orientations between neighboring blocks (bilingual phrases). In Figure 1, for example, the role of reordering model is to predict correct orientations o"
N09-1029,I05-1007,0,0.0128032,"nformation is used in LABTG and Zhang's work, their models are syntax-oriented, since they focus on syntactic labels. Boundary POS is considered in LABTG only when source phrases are not syntactic phrases. In contrast to the previous works, we present a reordering model for BTG that uses bilingual information including class-level features of POS and word classes. Moreover, our model is dedicated to boundary features and considers different combinations of phrase lengths, rather than only first/tail words. In addition, current state-of-the-art Chinese parsers, including the one used in LABTG (Xiong et al., 2005), lag beyond in inaccuracy, compared with English parsers (Klein and Manning, 2003; Petrov and Klein 2007). In our work, we only use more reliable information such as Chinese word segmentation and POS tagging (Ma and Chen, 2003). 3 Preo ( A1 , A2 , order) reo where order  {straight, inverted}. In MEBTG, a ME reordering model is trained using features extracted from reordering examples of aligned parallel corpus. First words on neighboring blocks are used as features. In reordering example (a), for example, the feature set is {&quot;S1L=three&quot;, &quot;S2L=ago&quot;, &quot;T1L=3&quot;, &quot;T2L=前&quot;} where &quot;S1&quot; and &quot;T1&quot; deno"
N09-1029,P06-1066,0,0.372028,"d rule in (b). Introduction Bracketing Transduction Grammar (BTG) is a special case of Synchronous Context Free Grammar (SCFG), with binary branching rules that are either straight or inverted. BTG is widely adopted in SMT systems, because of its good trade-off between efficiency and expressiveness (Wu, 1996). In BTG, the ratio of legal alignments and all possible alignment in a translation pair drops drastically especially for long sentences, yet it still covers most of the syntactic diversities between two languages. It is common to utilize phrase translation in BTG systems. For example in (Xiong et al., 2006), source sentences are segmented into phrases. Each On the other hand, there are various proposed BTG reordering models to predict correct orientations between neighboring blocks (bilingual phrases). In Figure 1, for example, the role of reordering model is to predict correct orientations of neighboring blocks A1 and A2. In flat model (Wu, 1996; Zens et al., 2004; Kumar and Byrne, 2005), reordering probabilities are assigned uniformly during decoding, and can be tuned depending on different language pairs. It is clear, however, that this kind of model would suffer when the dominant rule is wro"
N09-1029,I08-1066,0,0.101498,"nt rule is wrongly applied. Predicting orientations in BTG depending on context information can be achieved with lexical features. For example, Xiong et al. (2006) proposed MEBTG, based on maximum entropy (ME) classification with words as features. In MEBTG, first words of blocks are considered as the features, which are then used to train a ME model 254 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 254–262, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics for predicting orientations of neighboring blocks. Xiong et al. (2008b) proposed a linguistically annotated BTG (LABTG), in which linguistic features such as POS and syntactic labels from source-side parse trees are used. Both MEBTG and LABTG achieved significant improvements over phrase-based Pharaoh (Koehn, 2004) and Moses (Koehn et al., 2007) respectively, on Chinese-to-English translation tasks. 該 項 計劃 Nes Nf Nv the details of 14 49 50 the plan 14 18 的 詳情 DE Na A2 tion on target one, as shown in Figure 2. Additionally, features are extracted and classified depending on lengths of blocks in order to obtain a more informed model. The rest of this paper is org"
N09-1029,C08-1127,0,0.135827,"nt rule is wrongly applied. Predicting orientations in BTG depending on context information can be achieved with lexical features. For example, Xiong et al. (2006) proposed MEBTG, based on maximum entropy (ME) classification with words as features. In MEBTG, first words of blocks are considered as the features, which are then used to train a ME model 254 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 254–262, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics for predicting orientations of neighboring blocks. Xiong et al. (2008b) proposed a linguistically annotated BTG (LABTG), in which linguistic features such as POS and syntactic labels from source-side parse trees are used. Both MEBTG and LABTG achieved significant improvements over phrase-based Pharaoh (Koehn, 2004) and Moses (Koehn et al., 2007) respectively, on Chinese-to-English translation tasks. 該 項 計劃 Nes Nf Nv the details of 14 49 50 the plan 14 18 的 詳情 DE Na A2 tion on target one, as shown in Figure 2. Additionally, features are extracted and classified depending on lengths of blocks in order to obtain a more informed model. The rest of this paper is org"
N09-1029,C04-1030,0,0.0348825,"Missing"
N09-1029,D07-1056,0,0.0808652,"studying CKY parsing over the last decade, which considers translations and orientations of two neighboring block according to grammar rules or context information. In hierarchical phrase-based systems (Chiang, 2005), for example, SCFG rules are automatically learned from aligned bilingual corpus, and are applied in CKY style decoding. As an another application of CKY parsing technique is BTG-based SMT. Xiong et al. (2006) and Xiong et al. (2008a) developed MEBTG systems, in which first or tail words from reordering examples are used as features to train ME-based reordering models. Similarly, Zhang et al. (2007) proposed a model similar to BTG, which uses first/tail words of phrases, and syntactic labels (e.g. NP and VP) from source parse trees as features. In their work, however, inverted rules are allowed to apply only when source phrases are syntactic; for nonsyntactic ones, blocks are combined straight with a constant score. More recently, Xiong et al. (2008b) proposed LABTG, which incorporates linguistic knowledge by adding features such as syntactic labels and POS from source trees to improve their MEBTG. Different from Zhang's work, their model do not restrict non-syntactic phrases, and applie"
N09-1029,2005.iwslt-1.8,0,\N,Missing
N12-1036,C90-3008,0,0.123876,"(b) are not placed directly under the caret (current input focus) for space limit. (c) and (d) depict predominant grammar constructs which follow and (e) summarizes the confident translations of the source’s character-based ngrams. The frequency of grammar pattern is shown in round brackets while the history (i.e., keyword) based on the user input is shown in shades. emphasis on language learning. Specifically, our goal is to build a translation assistant to help translator (or learner-translator) with inline grammar help and translation. Unlike recent research focusing on professional (e.g., Brown and Nirenburg, 1990), we target on both professional and student translators. More recently, interactive MT (IMT) systems have begun to shift the user’s role from postediting machine output to collaborating with the machine to produce the target text. Foster et al (2000) describe TransType, a pioneering system that supports next word predictions. Along the similar line, Koehn (2009) develops caitra which predicts and displays phrasal translation suggestions one phrase at a time. The main difference between their systems and TransAhead is that we also display grammar patterns to provide the general patterns of pre"
N12-1036,W10-1005,0,0.0149145,"eturns top N predominant 2 syntactic patterns of the query. Such patterns characterizing the query’s word usages in the spirit of pattern grammar in (Hunston and Francis, 2000) and are collected across the target language. In the fourth and final stage, we exploit Cst for bilingual phrase acquisition, rather than a manual dictionary, to achieve better translation coverage and variety. We obtain phrase pairs through a number of steps, namely, leveraging IBM models for bidirectional word alignments, grow-diagonalfinal heuristics to extract phrasal equivalences (Koehn et al., 2003). Inspired by (Gamon and Leacock, 2010). 354 We first slice the source text S into characterlevel ngrams, represented by {si}. We also find the word-level ngrams of the translation prefix Tp. But this time we concentrate on the ngrams, may skipped, ending with the last word of Tp (i.e., pivoted on the last word) since these ngrams are most related to the subsequent grammar patterns. Step (3) and (4) retrieve translations and patterns learned from Section 3.2. Step (3) acquires the target-language active vocabulary that may be used to translate the source. To alleviate the word boundary issue in MT (Ma et al. (2007)), the word bound"
N12-1036,W11-1412,1,0.850846,"es of our working prototype. 4 Preliminary Results In developing TransAhead, we used British National Corpus and Hong Kong Parallel Text as target-language reference corpus and parallel training corpus respectively, and deployed GENIA tagger for lemma and POS analyses. To evaluate TransAhead in CAT and CALL, we introduced it to a class of 34 (Chinese) college freshmen learning English as foreign language. We designed TransAhead to be accessible and intuitive, so the user training tutorial took only one minute. After the tutorial, the participants were asked to translate 15 Chinese texts from (Huang et al., 2011) (half with TransAhead assistance called experimental group, and the other without any system help whatsoever called control group). The evaluation results show that the experimental group achieved much better translation quality than the control group with an average BLEU score (Papineni et al., 2002) of 35.49 vs. 26.46. Admittedly, the MT system Google Translate produced translations with a higher BLEU score of 44.82. Google Translate obviously has much more parallel training data and bilingual translation knowledge. No previous work in CAT uses Google Translate for comparison. Although ther"
N12-1036,N03-1017,0,0.0122139,"the query. The procedure finally returns top N predominant 2 syntactic patterns of the query. Such patterns characterizing the query’s word usages in the spirit of pattern grammar in (Hunston and Francis, 2000) and are collected across the target language. In the fourth and final stage, we exploit Cst for bilingual phrase acquisition, rather than a manual dictionary, to achieve better translation coverage and variety. We obtain phrase pairs through a number of steps, namely, leveraging IBM models for bidirectional word alignments, grow-diagonalfinal heuristics to extract phrasal equivalences (Koehn et al., 2003). Inspired by (Gamon and Leacock, 2010). 354 We first slice the source text S into characterlevel ngrams, represented by {si}. We also find the word-level ngrams of the translation prefix Tp. But this time we concentrate on the ngrams, may skipped, ending with the last word of Tp (i.e., pivoted on the last word) since these ngrams are most related to the subsequent grammar patterns. Step (3) and (4) retrieve translations and patterns learned from Section 3.2. Step (3) acquires the target-language active vocabulary that may be used to translate the source. To alleviate the word boundary issue i"
N12-1036,P09-4005,0,0.135772,"on language learning. Specifically, our goal is to build a translation assistant to help translator (or learner-translator) with inline grammar help and translation. Unlike recent research focusing on professional (e.g., Brown and Nirenburg, 1990), we target on both professional and student translators. More recently, interactive MT (IMT) systems have begun to shift the user’s role from postediting machine output to collaborating with the machine to produce the target text. Foster et al (2000) describe TransType, a pioneering system that supports next word predictions. Along the similar line, Koehn (2009) develops caitra which predicts and displays phrasal translation suggestions one phrase at a time. The main difference between their systems and TransAhead is that we also display grammar patterns to provide the general patterns of predicted translations so a student translator can learn and become more proficient. Recent work has been done on using fullyfledged statistical MT systems to produce target hypotheses completing user-validated translation prefix in IMT paradigm. Barrachina et al. (2008) investigate the applicability of different MT kernels within IMT framework. Nepveu et al. (2004)"
N12-1036,P07-1039,0,0.0192618,"ired by (Gamon and Leacock, 2010). 354 We first slice the source text S into characterlevel ngrams, represented by {si}. We also find the word-level ngrams of the translation prefix Tp. But this time we concentrate on the ngrams, may skipped, ending with the last word of Tp (i.e., pivoted on the last word) since these ngrams are most related to the subsequent grammar patterns. Step (3) and (4) retrieve translations and patterns learned from Section 3.2. Step (3) acquires the target-language active vocabulary that may be used to translate the source. To alleviate the word boundary issue in MT (Ma et al. (2007)), the word boundary in our system is loosely decided. Initially, TransAhead non-deterministically segments the source text using character ngrams for translations and proceeds with collaborations with the user to obtain the segmentation for MT and to complete the translation. Note that Tp may reflect some translated segments, reducing the size of the active vocabulary, and that a user vocabulary of preference (due to users’ domain knowledge or errors of the system) may be exploited for better system performance. In addition, Step (4) extracts patterns preceding with the history ngrams of {tj}"
N12-1036,W04-3225,0,0.0303112,"r line, Koehn (2009) develops caitra which predicts and displays phrasal translation suggestions one phrase at a time. The main difference between their systems and TransAhead is that we also display grammar patterns to provide the general patterns of predicted translations so a student translator can learn and become more proficient. Recent work has been done on using fullyfledged statistical MT systems to produce target hypotheses completing user-validated translation prefix in IMT paradigm. Barrachina et al. (2008) investigate the applicability of different MT kernels within IMT framework. Nepveu et al. (2004) and Ortiz-Martinez et al. (2011) further exploit user feedbacks for better IMT systems and user experience. Instead of triggered by user correction, our method is triggered by word 353 delimiter and assists both translation and learning the target language. In contrast to the previous CAT research, we present a writing assistant that suggests grammar constructs as well as lexical translations following users’ partial translation, aiming to provide users with choice to ease mental burden and enhance performance. 3 The TransAhead System 3.1 Problem Statement We focus on predicting a set of gram"
N12-1036,P11-4012,0,0.0117831,"lops caitra which predicts and displays phrasal translation suggestions one phrase at a time. The main difference between their systems and TransAhead is that we also display grammar patterns to provide the general patterns of predicted translations so a student translator can learn and become more proficient. Recent work has been done on using fullyfledged statistical MT systems to produce target hypotheses completing user-validated translation prefix in IMT paradigm. Barrachina et al. (2008) investigate the applicability of different MT kernels within IMT framework. Nepveu et al. (2004) and Ortiz-Martinez et al. (2011) further exploit user feedbacks for better IMT systems and user experience. Instead of triggered by user correction, our method is triggered by word 353 delimiter and assists both translation and learning the target language. In contrast to the previous CAT research, we present a writing assistant that suggests grammar constructs as well as lexical translations following users’ partial translation, aiming to provide users with choice to ease mental burden and enhance performance. 3 The TransAhead System 3.1 Problem Statement We focus on predicting a set of grammar patterns with lexical transla"
N12-1036,P02-1040,0,0.083121,"and CALL, we introduced it to a class of 34 (Chinese) college freshmen learning English as foreign language. We designed TransAhead to be accessible and intuitive, so the user training tutorial took only one minute. After the tutorial, the participants were asked to translate 15 Chinese texts from (Huang et al., 2011) (half with TransAhead assistance called experimental group, and the other without any system help whatsoever called control group). The evaluation results show that the experimental group achieved much better translation quality than the control group with an average BLEU score (Papineni et al., 2002) of 35.49 vs. 26.46. Admittedly, the MT system Google Translate produced translations with a higher BLEU score of 44.82. Google Translate obviously has much more parallel training data and bilingual translation knowledge. No previous work in CAT uses Google Translate for comparison. Although there is a 355 difference in average translation quality between the experimental TransAhead group and the Google Translate, it is not hard for us to notice the source sentences were better translated by language learners with the help of TransAhead. Take the sentence “我們在完成這筆交易上扮演重要角 色” for example. A tot"
N12-1036,J09-1002,0,\N,Missing
N15-3022,W00-0507,0,0.175678,"Missing"
N19-4005,E17-1084,0,0.0185624,"r representation of lexical semantics and relation between words (Mikolov et al., 2013; Pennington et al., 2014). We consider the specific case of learning word representation of two languages simultaneously, instead of a single language. Previously proposed methods use a rotation matrix to learn the relation between word embeddings of the two languages. Conneau et al. (2017); 24 Proceedings of NAACL-HLT 2019: Demonstrations, pages 24–28 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics Figure 1: The prototype system, x.Linggle Figure 2: x.Linggle Duong et al. (2017) relate cross-lingual information based on a small set of word-translation pairs. Our approach is different in that we use mixedcode data converted from a parallel corpus, to derive directly an embedding space with word tokens in two languages, instead of learning a matrix transforming between two independent language embedding spaces. In a study more closely related to our work, Gouws and Søgaard (2015); Vuli´c and Moens (2015) process a document-aligned comparable corpus as training data while Luong et al. (2015) processes mixed-code sentences for Cross-lingual Document Classification (CLDC)"
N19-4005,N15-1157,0,0.0311333,"L-HLT 2019: Demonstrations, pages 24–28 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics Figure 1: The prototype system, x.Linggle Figure 2: x.Linggle Duong et al. (2017) relate cross-lingual information based on a small set of word-translation pairs. Our approach is different in that we use mixedcode data converted from a parallel corpus, to derive directly an embedding space with word tokens in two languages, instead of learning a matrix transforming between two independent language embedding spaces. In a study more closely related to our work, Gouws and Søgaard (2015); Vuli´c and Moens (2015) process a document-aligned comparable corpus as training data while Luong et al. (2015) processes mixed-code sentences for Cross-lingual Document Classification (CLDC) task. We use a similar training methodology for the different purpose of responding to mixed-code queries by converting mixed-code query into L2 queries based on the bilingual embedding. In area of evaluating embedddings, researchers have typically used Spearman’s rank correlation coefficients and Word Similarity to measure the quality of word embeddings (e.g., Mikolov et al. (2013); Pennington et al. ("
N19-4005,W15-1521,0,0.0264932,"ional Linguistics Figure 1: The prototype system, x.Linggle Figure 2: x.Linggle Duong et al. (2017) relate cross-lingual information based on a small set of word-translation pairs. Our approach is different in that we use mixedcode data converted from a parallel corpus, to derive directly an embedding space with word tokens in two languages, instead of learning a matrix transforming between two independent language embedding spaces. In a study more closely related to our work, Gouws and Søgaard (2015); Vuli´c and Moens (2015) process a document-aligned comparable corpus as training data while Luong et al. (2015) processes mixed-code sentences for Cross-lingual Document Classification (CLDC) task. We use a similar training methodology for the different purpose of responding to mixed-code queries by converting mixed-code query into L2 queries based on the bilingual embedding. In area of evaluating embedddings, researchers have typically used Spearman’s rank correlation coefficients and Word Similarity to measure the quality of word embeddings (e.g., Mikolov et al. (2013); Pennington et al. (2014)). In contrast, we evaluate bilingual embedding by measuring the coverage of appropriate and relevant transl"
N19-4005,D14-1162,0,0.0924373,"ixed-code) texts, and return L2 results. Due to limited L2 vocabulary knowledge, users often submit mix-coded queries, but search engines such as Linguee only retrieve sentences similar to queries without converting them into target language queries. By transforming L1 keywords in the original query into relevant L2 keywords, we can bias 2 Related Work Word representation or word embedding has been an area of active research. It has been shown that predicting instead of counting context words leads to better representation of lexical semantics and relation between words (Mikolov et al., 2013; Pennington et al., 2014). We consider the specific case of learning word representation of two languages simultaneously, instead of a single language. Previously proposed methods use a rotation matrix to learn the relation between word embeddings of the two languages. Conneau et al. (2017); 24 Proceedings of NAACL-HLT 2019: Demonstrations, pages 24–28 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics Figure 1: The prototype system, x.Linggle Figure 2: x.Linggle Duong et al. (2017) relate cross-lingual information based on a small set of word-translation pairs. Our approac"
O01-1013,C88-1016,0,0.1818,"Missing"
O01-1013,J90-2002,0,0.260786,"Missing"
O01-1013,chang-etal-1998-taxonomy,1,0.904718,"Missing"
O01-1013,P99-1028,0,0.0605278,"Missing"
O01-1013,W93-0301,0,0.0283893,"Missing"
O01-1013,1994.amta-1.11,0,0.0273456,"Missing"
O01-1013,H91-1026,0,0.0340343,"Missing"
O01-1013,C88-2142,0,0.0306992,"Missing"
O01-1013,J97-2004,1,0.878381,"Missing"
O01-1013,P97-1017,0,0.0268373,"Missing"
O01-1013,P99-1027,0,0.0763142,"Missing"
O01-1013,1996.amta-1.13,0,0.0821031,"Missing"
O01-1013,P00-1056,0,0.111039,"Missing"
O01-1013,J96-1001,0,0.0684599,"Missing"
O01-1013,C94-2175,0,0.0496826,"Missing"
O01-1013,1994.amta-1.26,0,0.0436294,"Missing"
O01-3004,C88-1016,0,0.130541,"Missing"
O01-3004,chang-etal-1998-taxonomy,1,0.742281,"Missing"
O01-3004,P99-1028,0,0.027526,"Missing"
O01-3004,W93-0301,0,0.0159117,"Missing"
O01-3004,1994.amta-1.11,0,0.0304249,"Missing"
O01-3004,H91-1026,0,0.0547326,"Missing"
O01-3004,C88-2142,0,0.012532,"Missing"
O01-3004,J97-2004,1,0.873966,"Missing"
O01-3004,P97-1017,0,0.0388065,"Missing"
O01-3004,P99-1027,0,0.0597617,"Missing"
O01-3004,1996.amta-1.13,0,0.0489448,"Missing"
O01-3004,J96-1001,0,0.107325,"Missing"
O01-3004,1994.amta-1.26,0,0.0387973,"Missing"
O01-3004,P01-1067,0,0.154305,"Missing"
O01-3004,P00-1056,0,\N,Missing
O01-3004,J93-2003,0,\N,Missing
O01-3004,C94-2175,0,\N,Missing
O01-3004,J90-2002,0,\N,Missing
O01-3004,O99-4002,0,\N,Missing
O01-3004,J93-1006,0,\N,Missing
O03-1001,P98-1036,0,0.114548,"s exacerbated by different systems used for Ramanizing Chinese or Japanese person and place names. For back transliteration task of converting many transliterations back to the unique original name, there is one and only solution. So back transliteration is considered more difficult than transliteration. Knight and Graehl (1998) pioneered the study of machine transliteration and proposed a statistical transliteration model from English to Japanese to experiment on back transliteration of Japanese named entities. Most previous approaches to machine transliteration (Al-Onaizan and Knight, 2002; Chen et al., 1998; Lin and Chen, 2002); English/Japanese (Knight and Graehl, 1998; Lee and Choi, 1997; Oh and Choi, 2002) focused on the tasks of transliteration and back-transliteration. Very little has been touched upon for the issue of aligning and acquiring words and transliterations in a parallel corpus. The alternative to on-the-fly (back) machine transliteration is simple lookup in an extensive list automatically acquired from parallel corpora. Most instances of (back) transliteration of proper names can often be found in a parallel corpus of substantial size and relevant to the task. For instance, fift"
O03-1001,chuang-etal-2002-adaptive,1,0.893719,"Missing"
O03-1001,W93-0301,0,0.180711,"Missing"
O03-1001,W02-2017,0,0.420014,"fferent systems used for Ramanizing Chinese or Japanese person and place names. For back transliteration task of converting many transliterations back to the unique original name, there is one and only solution. So back transliteration is considered more difficult than transliteration. Knight and Graehl (1998) pioneered the study of machine transliteration and proposed a statistical transliteration model from English to Japanese to experiment on back transliteration of Japanese named entities. Most previous approaches to machine transliteration (Al-Onaizan and Knight, 2002; Chen et al., 1998; Lin and Chen, 2002); English/Japanese (Knight and Graehl, 1998; Lee and Choi, 1997; Oh and Choi, 2002) focused on the tasks of transliteration and back-transliteration. Very little has been touched upon for the issue of aligning and acquiring words and transliterations in a parallel corpus. The alternative to on-the-fly (back) machine transliteration is simple lookup in an extensive list automatically acquired from parallel corpora. Most instances of (back) transliteration of proper names can often be found in a parallel corpus of substantial size and relevant to the task. For instance, fifty topics of the CLIR"
O03-1001,C02-1099,0,0.0262604,"back transliteration task of converting many transliterations back to the unique original name, there is one and only solution. So back transliteration is considered more difficult than transliteration. Knight and Graehl (1998) pioneered the study of machine transliteration and proposed a statistical transliteration model from English to Japanese to experiment on back transliteration of Japanese named entities. Most previous approaches to machine transliteration (Al-Onaizan and Knight, 2002; Chen et al., 1998; Lin and Chen, 2002); English/Japanese (Knight and Graehl, 1998; Lee and Choi, 1997; Oh and Choi, 2002) focused on the tasks of transliteration and back-transliteration. Very little has been touched upon for the issue of aligning and acquiring words and transliterations in a parallel corpus. The alternative to on-the-fly (back) machine transliteration is simple lookup in an extensive list automatically acquired from parallel corpora. Most instances of (back) transliteration of proper names can often be found in a parallel corpus of substantial size and relevant to the task. For instance, fifty topics of the CLIR task in the NTCIR 3 evaluation conference contain many named entities (NEs) that re"
O03-1001,W98-1005,0,0.212281,"Missing"
O03-1001,M98-1004,0,\N,Missing
O03-1001,M98-1012,0,\N,Missing
O03-1001,M98-1014,0,\N,Missing
O03-1001,M98-1021,0,\N,Missing
O03-1001,J96-1001,0,\N,Missing
O03-1001,O98-3002,0,\N,Missing
O03-1001,M98-1018,0,\N,Missing
O03-1001,J90-1003,0,\N,Missing
O03-1001,J93-1007,0,\N,Missing
O03-1001,W02-1814,0,\N,Missing
O03-1001,J93-2003,0,\N,Missing
O03-1001,W02-0909,0,\N,Missing
O03-1001,C02-1012,0,\N,Missing
O03-1001,J96-1002,0,\N,Missing
O03-1001,W01-1413,0,\N,Missing
O03-1001,W03-0317,1,\N,Missing
O03-1001,P93-1003,0,\N,Missing
O03-1001,C98-1036,0,\N,Missing
O03-1001,P98-2220,0,\N,Missing
O03-1001,C98-2215,0,\N,Missing
O03-1001,W03-1405,0,\N,Missing
O03-1001,P02-1051,0,\N,Missing
O03-1001,C96-1089,0,\N,Missing
O03-1001,O95-1008,0,\N,Missing
O03-1001,J98-4003,0,\N,Missing
O03-1001,O97-1014,0,\N,Missing
O03-1001,M98-1017,0,\N,Missing
O03-1001,M98-1006,0,\N,Missing
O03-1001,M98-1009,0,\N,Missing
O03-1001,O92-1004,0,\N,Missing
O03-1003,J90-1003,0,0.108714,"Missing"
O03-1003,C96-1089,0,0.462189,"Missing"
O03-1003,P93-1003,0,0.132632,"eval. Hank and Church (1990) pointed out the usefulness of mutual information for identifying monolingual collocations in lexicography. Justeson and Katz (1995) proposed to identify technical terminology based on preferred linguistic patterns and discourse property of repetition. Among many general methods presented by Manning and Schutze (1999), best results can be achieved by filtering based on both linguistic and statistical constraints. Smadja (1993) presented a method called EXTRACT, based on means variance of the distance between two collocates capable of computing elastic collocations. Kupiec (1993) proposed to extract bilingual noun phrases using statistical analysis of co-occurrence of phrases. Smadja, McKeown, and Hatzivassiloglou (1996) extended the EXTRACT approach to handling of bilingual collocation based mainly on the statistical measures of Dice coefficient. Dunning (1993) pointed out the weakness of mutual information and showed that log likelihood ratios are more effective in identifying monolingual collocations especially when the occurrence count is very low. 2 Both Smadja and Kupiec used the statistical association between the whole of collocations in two languages without"
O03-1003,M98-1006,0,0.0736409,"Missing"
O03-1003,J93-1007,0,0.185335,"any applications, including natural language generation, word sense disambiguation, machine translation, lexicography, and cross language information retrieval. Hank and Church (1990) pointed out the usefulness of mutual information for identifying monolingual collocations in lexicography. Justeson and Katz (1995) proposed to identify technical terminology based on preferred linguistic patterns and discourse property of repetition. Among many general methods presented by Manning and Schutze (1999), best results can be achieved by filtering based on both linguistic and statistical constraints. Smadja (1993) presented a method called EXTRACT, based on means variance of the distance between two collocates capable of computing elastic collocations. Kupiec (1993) proposed to extract bilingual noun phrases using statistical analysis of co-occurrence of phrases. Smadja, McKeown, and Hatzivassiloglou (1996) extended the EXTRACT approach to handling of bilingual collocation based mainly on the statistical measures of Dice coefficient. Dunning (1993) pointed out the weakness of mutual information and showed that log likelihood ratios are more effective in identifying monolingual collocations especially w"
O03-3002,J90-1003,0,0.0250974,"Missing"
O03-3002,J96-3004,0,0.0321924,"Missing"
O03-3002,P91-1022,0,0.209184,"Missing"
O03-3002,P93-1002,0,0.0761427,"Missing"
O03-3002,A00-1018,0,0.0530813,"Missing"
O03-3002,J97-2004,1,0.89062,"Missing"
O03-3002,P97-1039,0,0.0526732,"Missing"
O03-3002,J93-1004,0,\N,Missing
O03-3002,chuang-etal-2002-adaptive,1,\N,Missing
O03-3004,P91-1022,0,0.20971,"Missing"
O03-3004,A00-1018,0,0.051269,"Missing"
O03-3004,J97-2004,1,0.898822,"Missing"
O03-3004,P97-1039,0,0.0450179,"Missing"
O03-3004,J93-1004,0,\N,Missing
O03-3004,chuang-etal-2002-adaptive,1,\N,Missing
O03-3004,P93-1002,0,\N,Missing
O03-3005,P91-1023,0,0.118231,"Missing"
O03-3005,macklovitch-etal-2000-transsearch,0,0.0207684,"that each sentence is associated with translation counterpart in a second language. It could be extremely useful for bilingual lexicographers, human translators and second language learners. Pierre Isabelle, in 1993, pointed out: “existing translations contain more solutions to more translation problems than any other existing resource.” It is particularly useful and convenient when the resource of existing translations is made available on the Internet. Web based bilingual concordances have proved to be very useful and popular. For example, the English-French concordance system, TransSearch (Macklovitch et al. 2000), provides a familiar interface for the users who only need to type in the expression in question, a list of citations will come up and it is easy to scroll down until one finds one that is useful. In addition to the similar functionalities provided by TransSearch, TotalRecall comes with an additional feature making the solution more easily recognized: the user not only gets all the citations related to the expression in question, but also gets to see the translation counterpart highlighted. TotalRecall extends the translation memory technology and provide an interactive tool intended for tran"
O03-3005,1992.tmi-1.7,0,0.184354,"Missing"
O03-3005,P94-1012,0,0.0439706,"Missing"
O03-3006,J90-1003,0,0.246409,"Missing"
O03-3006,Y98-1020,0,0.486486,"Missing"
O03-3006,J96-3004,0,0.093113,"Missing"
O03-5003,W99-0603,0,0.0640254,"Missing"
O03-5003,P00-1064,0,0.0748713,"Missing"
O03-5003,P99-1020,0,0.0718714,"artment of Communication Engineering, National Chiao Tung University 1001, University Road, Hsinchu, Taiwan, ROC E-mail: tracylin@mail.nctu.edu.tw ** Department of Information Manangement, National Taichung Institute of Technology San Ming Road, Taichung, Taiwan, ROC E-mail: gny@mail.ntit.edu.tw ++ Dept of Computer Science, Van Nung Institute of Technology 1 Van-Nung Road, Chung-Li, Taiwan, ROC E-mail: tomchuang@cc.vit.edu.tw *** Panasonic Taiwan Laboratories Co., Ltd. (PTL) E-Mail: chingting@ptl.com.tw 62 J. S. Chang et al. such topics as word sense disambiguation [Towell and Voothees, 1998; Mihalcea and Moldovan, 1999], information retrieval [Pasca and Harabagiu, 2001], and computer-assisted language learning [Wible and Liu, 2001]. Thus, there is a universally shared interest in the construction of WordNet in different languages. However, constructing a WordNet for a new language is a formidable task. To exploit the resources of WordNet for other languages, researchers have begun to study ways of speeding up the construction of WordNet for many European languages [Vossen, Diez-Orzas, and Peters, 1997]. One of many ways to build a WordNet for a language other than English is to associate WordNet senses with"
O03-5003,J98-1005,0,\N,Missing
O04-1020,P03-1003,0,0.0355589,"Missing"
O04-1020,P84-1044,0,0.103822,"Missing"
O04-1020,P97-1063,0,0.249938,"Missing"
O04-1027,1999.mtsummit-1.75,0,0.0441745,"Missing"
O04-1027,C00-1019,0,0.0523954,"Missing"
O04-1027,1999.mtsummit-1.37,0,0.0547631,"Missing"
O04-1027,P97-1063,0,0.0275774,"Missing"
O04-1027,J96-1001,0,\N,Missing
O04-1027,J93-1007,0,\N,Missing
O04-1027,P04-1022,0,\N,Missing
O04-1027,P03-1016,0,\N,Missing
O04-1027,P93-1003,0,\N,Missing
O04-1027,2003.mtsummit-papers.14,0,\N,Missing
O04-2001,J90-1003,0,0.0950074,"Missing"
O04-2001,J93-1003,0,0.104077,"Missing"
O04-2001,C96-1089,0,0.0462222,"Missing"
O04-2001,W02-0909,0,0.0303295,"Missing"
O04-2001,P93-1003,0,0.398107,"Missing"
O04-2001,M98-1006,0,0.0655764,"Missing"
O04-2001,P97-1063,0,0.054867,"Missing"
O04-2001,J93-1007,0,0.238174,"Missing"
O04-2001,J96-1001,0,0.250272,"Missing"
O04-2001,O03-2004,0,0.0613975,"Missing"
O04-2001,W93-0305,0,\N,Missing
O04-2001,C94-1088,0,\N,Missing
O04-2001,W00-1219,0,\N,Missing
O04-2001,C02-1021,0,\N,Missing
O04-2001,C02-1101,0,\N,Missing
O04-2001,A94-1006,0,\N,Missing
O04-2001,C02-1012,0,\N,Missing
O04-2001,J96-1002,0,\N,Missing
O04-2001,P94-1033,0,\N,Missing
O04-2001,Y96-1018,0,\N,Missing
O04-2001,O99-1009,0,\N,Missing
O05-1010,W03-0203,0,0.0800068,"Missing"
O05-1020,P00-1056,0,0.0361479,"Missing"
O05-1020,P04-1037,0,0.0222436,"Missing"
O05-1020,P99-1020,0,0.0916688,"Missing"
O05-1020,P02-1033,0,0.0374565,"Missing"
O05-4002,C00-1019,0,0.0386625,"Missing"
O05-4002,1999.mtsummit-1.37,0,0.0626078,"Missing"
O05-4002,2003.mtsummit-papers.14,0,0.029964,"Missing"
O05-4002,P93-1003,0,0.0256529,"Missing"
O05-4002,P97-1063,0,0.0170853,"Missing"
O05-4002,J93-1007,0,0.24023,"Missing"
O05-4002,J96-1001,0,0.207892,"Missing"
O05-4002,P03-1016,0,0.0266709,"Missing"
O06-1021,C96-2141,0,0.0915145,"nother. IBM model 1 can be trained using EM algorithm: starting with a uniform distribution among all translation candidate pairs and ending with convergent probabilities. While IBM model 1 does not utilize position information, the subsequent IBM models take positions into account when modeling for the translation process. (take an English-Chinese sentence pair for example, the first English word more likely translates into the first word in the Chinese sentence) Another model called Hidden Markov model (HMM) is designed to capture localization effect in aligning the words in parallel texts. Vogel et al. (1996), motivated by the idea that words are not distributed arbitrarily over the sentence positions but tend to form clusters, presented a first-order HMM which makes the alignment probabilities explicitly dependent on the alignment position of the previous word. Nonetheless, Toutanova et al. (2002) pointed out that word order variations (large jumps) between languages seem to be a problem. 5 Neither IBM models nor HMMs explicitly utilize any linguistic information. However, other researchers have experimented with incorporation of part of speech (POS) information or context-specific features into"
O06-1021,C02-1010,0,0.057557,"Missing"
O06-1021,W04-3226,0,0.0694144,"Missing"
O06-1021,J97-3002,0,0.497158,"es are used to parse bilingual sentences, simultaneously determining the syntactic structures and word order relationships of languages involved. Thus, the proposed model commits to common linguistic labels for words and phrases found in an English treebank, such as NN (noun), VB (verb), JJ (adjective), NP (noun phrase), VP (verb phrase), ADJP (adjective phrase), PP (prepositional phrase). Furthermore, we assume straight and inverted linguistic phenomena, when projected to the target language, should render a reasonable structural explanation of the target language. We extend ITG productions (Wu 1997) to carry out this process of projection. Take word-aligned sentences in Figure 1 for example. It is possible to match the part of speech information of the source language sentence against the right hand sides of the production rules induced from a tree bank and identify the instances of applying specific rules such as NP ! JJ NN ; JJ ! &quot;positive&quot; and NN ! &quot;role.&quot; Moreover, by exploiting the word alignment information, it is not difficult to infer that such syntactic structure is also present in the target language with similar rules 3 such as NP ! JJ NN ; JJ ! ”積極,” and NN ! ”作用.” By combini"
O06-1021,P01-1067,0,0.046875,"th structural-like, or hierarchical-like rules that specify the constituents and the order of the counterparts in both language is good at resolving the word alignment relations within a sentence pair. However, in their experiments, constituent categories are almost not differentiated, and thus their influences on ordering preferences of the counterparts are not taken into consideration. Consequently, very little syntax information is incorporated into the process of bilingual parsing. In contrast to Wu’s experiment, we use regular context-free grammar rules in our experiments. More recently, Yamada and Knight (2001) suggested the syntax differences in languages are really a better way to model translation. In their work, the English sentence goes through a parser to generate a full parse tree. Subtrees of each node are reordered, function words are inserted and finally the tree is linearized to produce the target sentence. The parse tree of an English sentence is generated independently from the target sentence. Although the monolingual parse might be correct, it may be difficult to project the structures onto the target language. Instead, our model has grammar rules that specify bilingual syntactic info"
O06-1021,C04-1060,0,0.038691,"Missing"
O06-1021,P05-1059,0,0.0238518,"Missing"
O06-1021,W99-0604,0,\N,Missing
O06-1021,W02-1012,0,\N,Missing
O06-1021,W05-1102,0,\N,Missing
O06-1021,P05-1067,0,\N,Missing
O06-1021,P03-1012,0,\N,Missing
O06-1021,P05-1033,0,\N,Missing
O06-1021,P05-1058,0,\N,Missing
O06-1021,P00-1056,0,\N,Missing
O06-1021,N03-1021,0,\N,Missing
O06-4003,P04-1037,0,0.032274,"Missing"
O06-4003,P06-1009,0,0.0254899,"Missing"
O06-4003,O03-5003,1,0.869064,"Missing"
O06-4003,P02-1033,0,0.0376345,"Missing"
O06-4003,C96-2141,0,0.521313,"Missing"
O06-4003,W04-0807,0,\N,Missing
O06-4003,J93-2003,0,\N,Missing
O06-4003,P00-1056,0,\N,Missing
O07-1011,P05-1048,0,0.0193666,"ervised learning. They evaluated an approach to automatically acquire sense-tagged training data from English-Chinese parallel corpora. Pham, Ng, and Lee (2005) have investigated the use of unlabeled training data for WSD, in the framework of semi-supervised learning. Empirical results show that unlabeled data can bring significant improvement in WSD accuracy. We used a bilingual corpus but we do not require sense annotation of the data, because we rely on word alignment tool to annotate translation information of the words in the source sentences. In a study more closely related to our work, Carpuat and Wu (2005) purposed a state-of-the-art Chinese word sense disambiguation model to choose translation candidates for a typical IBM statistical MT system. However, they did not obtain significantly better translation quality than using statistical machine translation system alone. But Cabezas and Resnik (2005) purposed using target language vocabulary directly as “sense,” leading to small improvement in translation performance over a state of the art phrase-based statistical MT system. In previous work, human judgment is required for evaluation of sample word tasks of WSD or WTD. In our research, our goal"
O07-1011,P02-1040,0,0.0722613,"Missing"
O07-1011,A00-2009,0,0.0109334,"xical ambiguities in one language using a statistical data on lexical relationship in another language. Yarowsky (1994) showed that decision list (Rivest, 1987) is a good way to model the relation between the words and their translations. We also use the decision list in our approach for estimating translation probability of the word. Yarowsky (1995) exploited two powerful properties that one sense per collocation and one sense per discourse for WSD. He also presented a bootstrapping approach for word sense disambiguation. We also exploit one sense per dependency relationship in our approach. Pedersen (2000) presented a corpus-based approach to word sense disambiguation that builds an ensemble of Naive Bayesian classifiers, each of which is based on lexical features that represent co-occurring words in varying sized windows of context. Koehn and Knight (2000) present a novel approach to the WTD problem that can be trained using only unrelated monolingual corpora and a lexicon to estimate word translation probabilities using the EM algorithm. Zhou, Ding, and Huang (2001) also proposed an approach to training the translation model by using unrelated monolingual corpora. They parsed a Chinese corpus"
O07-1011,P94-1013,0,0.41373,"tural language processing. This problem is related to the WSD tasks and is one of the difficult issues in machine translation. In our work, we focus on finding the translations of each content word in the given sentence. The contexts would be English and the target words will be their translations in a second language (e.g., consider the word “motion” can be translated as “行 動” or “會議” depending on the sentential content). Dagan, Itai, and Ulrike (1994) presented an approach for resolving lexical ambiguities in one language using a statistical data on lexical relationship in another language. Yarowsky (1994) showed that decision list (Rivest, 1987) is a good way to model the relation between the words and their translations. We also use the decision list in our approach for estimating translation probability of the word. Yarowsky (1995) exploited two powerful properties that one sense per collocation and one sense per discourse for WSD. He also presented a bootstrapping approach for word sense disambiguation. We also exploit one sense per dependency relationship in our approach. Pedersen (2000) presented a corpus-based approach to word sense disambiguation that builds an ensemble of Naive Bayesia"
O07-1011,P95-1026,0,0.0138235,"would be English and the target words will be their translations in a second language (e.g., consider the word “motion” can be translated as “行 動” or “會議” depending on the sentential content). Dagan, Itai, and Ulrike (1994) presented an approach for resolving lexical ambiguities in one language using a statistical data on lexical relationship in another language. Yarowsky (1994) showed that decision list (Rivest, 1987) is a good way to model the relation between the words and their translations. We also use the decision list in our approach for estimating translation probability of the word. Yarowsky (1995) exploited two powerful properties that one sense per collocation and one sense per discourse for WSD. He also presented a bootstrapping approach for word sense disambiguation. We also exploit one sense per dependency relationship in our approach. Pedersen (2000) presented a corpus-based approach to word sense disambiguation that builds an ensemble of Naive Bayesian classifiers, each of which is based on lexical features that represent co-occurring words in varying sized windows of context. Koehn and Knight (2000) present a novel approach to the WTD problem that can be trained using only unrel"
O07-1011,O01-2001,0,0.0627044,"Missing"
O07-1011,P91-1017,0,\N,Missing
O07-1011,P03-1058,0,\N,Missing
O08-1003,W04-3205,0,0.0184503,"However, measures of recognizing collocate similarity are not as well developed as measures of word similarity, the potential applications of semantic classification are not as well known. Nastase and Szpakowicz (2003) presented how to automatically classify a noun-modifier pair, such as “laser printer”, according to the semantic relation between the head noun (printer) and the modifier (laser). Turney (2006) proposed the semantic relations in noun pairs for automatically classifying. As for VerbOcean, a semi-automatic method was used to extract fine-grained semantic relations between verbs (Chklovski & Pantel, 2004). Hatzivassiloglou and McKeown (1993) presented a method towards the automatic identification of adjectival scales. More recently, Wanner et al. (2006) has sought to semi-automatically classify the collocation from corpora by using the lexical functions in dictionary as the semantic typology of collocation elements. Nevertheless, there is still a lack of fine-grained semantically-oriented organization for collocation. 3. Methodology We focus on the preparation step of partitioning collocations into categories: providing each word with a semantic label and thus presenting collocates under thesa"
O08-1003,P93-1023,0,0.104675,"nizing collocate similarity are not as well developed as measures of word similarity, the potential applications of semantic classification are not as well known. Nastase and Szpakowicz (2003) presented how to automatically classify a noun-modifier pair, such as “laser printer”, according to the semantic relation between the head noun (printer) and the modifier (laser). Turney (2006) proposed the semantic relations in noun pairs for automatically classifying. As for VerbOcean, a semi-automatic method was used to extract fine-grained semantic relations between verbs (Chklovski & Pantel, 2004). Hatzivassiloglou and McKeown (1993) presented a method towards the automatic identification of adjectival scales. More recently, Wanner et al. (2006) has sought to semi-automatically classify the collocation from corpora by using the lexical functions in dictionary as the semantic typology of collocation elements. Nevertheless, there is still a lack of fine-grained semantically-oriented organization for collocation. 3. Methodology We focus on the preparation step of partitioning collocations into categories: providing each word with a semantic label and thus presenting collocates under thesaurus categories. The collocations wit"
O08-1003,P90-1034,0,0.280769,"Missing"
O08-1003,P04-3019,1,0.88985,"Missing"
O08-1003,P97-1009,0,0.0196695,"lls. The System “Signposts” of the Longman Dictionary of Contemporary English, 3rd edition, the index “Guide Word” of the Cambridge International Dictionary of English, as well as the “Menus” of the Macmillan English Dictionary for Advanced Learners all value the principle. 2.3 Similarity of Semantic Relations The construction of practical, general word sense classification has been acknowledged to be one of the most ambitious and frustrating tasks in NLP (Nirenburg & Raskin, 1987), even WordNet with more significant contribution of a wide range of lexical-semantic resources (Fellbaum, 1998). Lin (1997) presented an algorithm for word similarity measure by its distributional similarity. Unlike most corpus-based word sense disambiguation (WSD) algorithms where different classifiers are trained for separate words, Lin used the same local context database as the knowledge sources for measuring all word similarities. Distributional similarity allows pair wise word similarity measure to deal with infrequent words or unknown proper nouns. However, compared to distributional similarity measure, our model by random walk algorithm has remarkable feature to deal with any kind of constraints, thus, not"
O08-1003,J87-3007,0,0.155199,"97), menus that summarize or subdivide definitions into groups ahead of entries in dictionaries would help users with limited reference skills. The System “Signposts” of the Longman Dictionary of Contemporary English, 3rd edition, the index “Guide Word” of the Cambridge International Dictionary of English, as well as the “Menus” of the Macmillan English Dictionary for Advanced Learners all value the principle. 2.3 Similarity of Semantic Relations The construction of practical, general word sense classification has been acknowledged to be one of the most ambitious and frustrating tasks in NLP (Nirenburg & Raskin, 1987), even WordNet with more significant contribution of a wide range of lexical-semantic resources (Fellbaum, 1998). Lin (1997) presented an algorithm for word similarity measure by its distributional similarity. Unlike most corpus-based word sense disambiguation (WSD) algorithms where different classifiers are trained for separate words, Lin used the same local context database as the knowledge sources for measuring all word similarities. Distributional similarity allows pair wise word similarity measure to deal with infrequent words or unknown proper nouns. However, compared to distributional s"
O08-1003,J06-3003,0,0.0205851,"ally, the problem is focused on classifying semantic relations. Approaches presented to solve problems on recognizing synonyms in application have been studied (Lesk, 1986; Landauer and Dumais, 1997). However, measures of recognizing collocate similarity are not as well developed as measures of word similarity, the potential applications of semantic classification are not as well known. Nastase and Szpakowicz (2003) presented how to automatically classify a noun-modifier pair, such as “laser printer”, according to the semantic relation between the head noun (printer) and the modifier (laser). Turney (2006) proposed the semantic relations in noun pairs for automatically classifying. As for VerbOcean, a semi-automatic method was used to extract fine-grained semantic relations between verbs (Chklovski & Pantel, 2004). Hatzivassiloglou and McKeown (1993) presented a method towards the automatic identification of adjectival scales. More recently, Wanner et al. (2006) has sought to semi-automatically classify the collocation from corpora by using the lexical functions in dictionary as the semantic typology of collocation elements. Nevertheless, there is still a lack of fine-grained semantically-orien"
O09-3001,H92-1053,0,0.0747903,"Missing"
O09-3001,J93-2003,0,0.0206284,"Missing"
O09-3001,P03-1012,0,0.0545395,"Missing"
O09-3001,P05-1033,0,0.138798,"Missing"
O09-3001,W05-1102,0,0.0325486,"Missing"
O09-3001,N04-1035,0,0.0693356,"Missing"
O09-3001,P06-1121,0,0.0419633,"Missing"
O09-3001,W04-3228,0,0.0367072,"Missing"
O09-3001,P06-1077,0,0.0522533,"Missing"
O09-3001,P00-1056,0,0.209261,"Missing"
O09-3001,J04-4002,0,0.149602,"Missing"
O09-3001,C96-2141,0,0.313837,"Missing"
O09-3001,J97-3002,0,0.307533,"Missing"
O09-3001,P01-1067,0,0.131198,"Missing"
O09-3001,P03-1019,0,0.0461531,"Missing"
O09-3001,C04-1060,0,0.0386785,"Missing"
O09-3001,P05-1059,0,0.0356407,"Missing"
O09-3001,N06-1033,0,0.0489271,"Missing"
O09-3001,N07-1058,0,\N,Missing
O09-3001,W02-1012,0,\N,Missing
O09-3001,J05-3002,0,\N,Missing
O09-3001,J02-4001,0,\N,Missing
O09-3001,P02-1058,0,\N,Missing
O09-3001,P02-1040,0,\N,Missing
O09-3001,W97-0704,0,\N,Missing
O09-3001,P06-1002,0,\N,Missing
O09-3001,W01-0100,0,\N,Missing
O09-3001,O91-1003,0,\N,Missing
O09-3001,I05-7001,0,\N,Missing
O09-3001,N04-3001,0,\N,Missing
O09-5002,W04-3205,0,0.0577308,"Missing"
O09-5002,J98-1003,1,0.799307,"Missing"
O09-5002,P90-1034,0,0.574362,"Missing"
O09-5002,P93-1023,0,0.182868,"Missing"
O09-5002,P97-1009,0,0.0323589,"Missing"
O09-5002,J91-1002,0,0.0484119,"Missing"
O09-5002,J87-3007,0,0.269466,"Missing"
O09-5002,J07-2002,0,0.0293344,"Missing"
O09-5002,P02-1053,0,0.00414297,"Missing"
O09-5002,J06-3003,0,0.0340895,"Missing"
O09-5002,P04-3019,1,\N,Missing
O12-1006,H92-1045,0,0.19597,"Missing"
O12-1006,O97-1002,0,0.143845,"Missing"
O12-1006,H93-1051,0,0.338047,"Missing"
O12-1006,P95-1026,0,0.522317,"Missing"
O12-1006,C92-2070,0,0.420246,"Missing"
O12-1006,P05-1004,0,\N,Missing
O12-1024,J96-1001,0,\N,Missing
O12-1024,koen-2004-pharaoh,0,\N,Missing
O12-1024,C02-1011,0,\N,Missing
O12-1024,A94-1006,0,\N,Missing
O12-1024,P02-1040,0,\N,Missing
O12-1024,P04-1022,0,\N,Missing
O12-1024,P93-1003,0,\N,Missing
O12-1024,P07-2045,0,\N,Missing
O12-1024,P03-1040,0,\N,Missing
O12-1024,P06-4018,0,\N,Missing
O12-1024,N03-1017,0,\N,Missing
O12-1024,O01-2001,0,\N,Missing
O12-1027,C96-1005,0,0.114167,"6. We compute similarity between two link graphs which 8 299 Proceedings of the Twenty-Fourth Conference on Computational Linguistics and Speech Processing (ROCLING 2012) has vertices va, vb as central node respectively using following equations: ܵሺݒ ǡ ݒ ሻ ൌ ȁாೌ תா ȁ (1) ୫୧୬ሺԡாೌ ԡǡԡா ԡሻ In Eq. (1) Ea, Eb denote the edges of va, vb respectively. The interpretation of Eq. (1) is that we compute the number of edges in common with both vertices respectively, and normalize it using edges of smaller graph constructed from va and vb. In order to make range of Eq. (1) lies in [0, 1], we choose to normalize by smaller graph. Thus, bigger value means bigger similarity between two vertices. Given training data, we use Eq. (1) to compute features from training data and use them to train a binary SVM classifier. The procedure is shown in Figure 8. procedure GenerateSVMInput(kb) <Terms, Articles>= RandomTermArticles(kb) (1) (2) for each <term, article> in <Terms, Articles> (3) candidates = GetTermEntity(term) (4) for each <term, entity> in candidates (5) <lp, olinkSim, ilinkSim> = extractFeatures(article, entity) (6) if entity==TargetOf(term) (7) AddToOutput(<1, lp, olinkSim,"
O12-1027,P94-1020,0,0.369719,"Missing"
O12-1027,D07-1007,0,0.0222587,"Missing"
O12-1027,O03-5003,1,0.770168,"Missing"
O12-1027,P02-1033,0,0.0818078,"Missing"
O12-1027,1992.tmi-1.9,0,0.200823,"Missing"
O12-1027,W97-0802,0,0.0471525,"Missing"
O12-1027,O08-1003,1,0.89607,"Missing"
O12-1027,P99-1020,0,0.134221,"Missing"
O12-1027,J98-1005,0,\N,Missing
O12-1027,H93-1051,0,\N,Missing
O12-1027,huang-etal-2004-sinica,0,\N,Missing
O13-1005,C96-2184,0,\N,Missing
O13-1005,J03-1002,0,\N,Missing
O13-1005,W10-4107,0,\N,Missing
O13-1006,N10-1019,0,0.0212302,"nnecessary, and misuse of articles, prepositions, noun number, and verb form. Recently, the state-of-the-art research on GED has been surveyed by Leacock et al. (2010). In our work, we address serial errors in English learners’ writing related to the proposition and verb form, an aspect that has not been dealt with in most GED research. We also consider the issues of broadening the training data for better coverage, and coping with data sparseness when unseen events happen. Researchers have looked at grammatical errors related to the most common prepositions (e.g., De Felice and Pulman, 2007; Gamon 2010). In the research area of detecting verb form errors, methods based on template related to parse tree, maximum entropy with lexical and POS features have been proposed (e.g., Lee and Seneff, 2006; Izumi et al. 2003). The Longman Dictionary of Common Errors, second edition (LDOCE) is the result of analyzing errors encoded in the Longman Learners’ Corpus. The LDOCE shows that 56 Proceedings of the Twenty-Fifth Conference on Computational Linguistics and Speech Processing (ROCLING 2013) grammatical errors in learners’ writing are mostly isolated, but there are certainly a lot of consecutive error"
O13-1006,P03-2026,0,0.0817678,"Missing"
O13-2002,C02-1011,0,0.112429,"Missing"
O13-2002,P12-2026,1,0.133184,"Missing"
O13-2002,W03-1502,0,0.0900638,"Missing"
O13-2002,J98-4003,0,0.298215,"Missing"
O13-2002,P03-1040,0,0.100101,"Missing"
O13-2002,P93-1003,0,0.529693,"Missing"
O13-2002,P08-1113,0,0.0349736,"Missing"
O13-2002,J00-2004,0,0.163957,"Missing"
O13-2002,W01-1413,0,0.0237426,"Missing"
O13-2002,P04-1024,0,0.0484559,"Missing"
O13-2002,J96-1001,0,0.320225,"Missing"
O13-2002,P05-3010,1,0.793328,"Missing"
O13-2002,H91-1026,0,\N,Missing
O13-5002,C96-2184,0,0.0300505,"Missing"
O13-5002,W09-3412,0,0.0355679,"Missing"
O13-5002,W03-1726,0,0.122673,"Missing"
O13-5002,J03-1002,0,0.0127667,"Missing"
O13-5002,W10-4107,0,0.0401607,"Missing"
O13-5003,N10-1019,0,0.0268983,"Missing"
O13-5003,I08-1059,0,0.0698436,"Missing"
O13-5003,P03-2026,0,0.0718537,"Missing"
O13-5003,W09-3010,0,0.0247922,"Missing"
O13-5003,D13-1074,0,0.0240367,"Missing"
O13-5003,P11-1019,0,0.0422916,"Missing"
O13-5003,han-etal-2010-using,0,\N,Missing
O13-5003,E87-1007,0,\N,Missing
O14-5003,I08-1050,0,0.068039,"Missing"
O14-5003,W06-3309,0,0.0795391,"Missing"
O14-5003,J02-4002,0,0.211973,"Missing"
O14-5003,P06-4011,1,0.690405,"Missing"
O15-1009,J02-4002,0,0.217662,"Missing"
O15-1009,P06-4011,1,0.82517,"Missing"
O15-1009,C08-1128,0,0.0184682,"Missing"
O18-1027,P10-1125,0,0.0772691,"Missing"
O97-4004,J94-4005,0,0.0126962,"ased on a word-specific, mutual information-like statistic that select strongly associated word pairs which may have a weak presence in the data. The experimental results confirm the findings of several recent works on terminology extraction and structural disambiguation. Daille (1994) demonstrated that simple criteria related to 88 S. J. Ker, J. S. Chang frequency coupled with a linguistic filter work better than mutual information for terminology extraction. Justeson and Katz (1995) also gave experimental results supporting a similar finding. Recent work involving structural disambiguation (Alshawi and Carter, 1994; Brill and Resnik, 1994) has also indicated that statistics related to frequency outperform mutual information and the X2 statistic. 6. Concluding Remarks This paper has presented an algorithm capable of identifying words and their translations in a bilingual corpus. It is effective for specific linguistic reasons. A significant majority of words in bilingual sentences have diverging translations; those translations are not often found in a bilingual dictionary. However, these deviations are largely limited within the classes defined in thesauri. Therefore, by using a class-based approach, th"
O97-4004,C94-2195,0,0.0557486,", (tongchang) _ (suizhe) Â= (shandian) Ö (er) (lai) POS Reference Code Na Bf06 Dd Ka10 V+Di Hj36 Na Bf06 C Kc02, Kc03, Kc08 V Hj12, Hj63, Jd07 Table 3.2 Tagging results of Example (1c) (1e) Lightening usually accompanies thunder. (1c) &lt; , _ Â= Ö ` leisheng tongchang suizhe shandian er lai thunder usually accompany lightning and come 67 68 S. J. Ker, J. S. Chang 2.3 The Greedy Learner The main mechanism of SenseAlign is the class-based alignment rules. Those rules form a subset of the Cartesian product of the categories in the two thesauri. We were inspired by the revision model proposed by Brill and Resnik (1994) in designing an automatic acquisition procedure for alignment rules. The procedure employs the greedy method to find a set of rules capable of providing optimal alignment in a bilingual corpus. The rule capable of providing the most instances of plausible alignment is preferred and selected first. First, the bilingual example sentences go through some lexical analyses. The lexemes are then looked up in the thesauri to find the possible categories under which they may be listed. At this stage, no information is available regarding what classes of words are likely to align with each other. Seco"
O97-4004,H92-1022,0,0.0363516,"e levels: subjects, titles and sets. In the first level, fourteen major subjects are denoted with reference letters from A to N. For detailed descriptions of CILIN and LLOCE see Appendices A and B. 2.2 Lexical Analyses Two taggers are utilized to resolve part-of-speech ambiguity. Morphological and idiom analyses are also performed to determine the lexical unit and lexeme. Only thesaurus categories consistent with the part-of-speech determined in the analysis are considered in subsequent processes. The part-of-speech taggers for the two languages involved are built using a strategy proposed by Brill (1992). We use the tag set in the Brown Corpus for the English tagger 66 S. J. Ker, J. S. Chang and the part-of-speech system proposed by Chao (1968) for the Chinese tagger. Tables 1.1 and 1.2 present the two tag sets. To eliminate the difficult cases of 0-1 fertility (one target word aligned with nothing in the source sentence), certain morpho-syntactical constructs in Chinese are identified. They are, mainly, Chinese constructions (see Table 2) that have no parallel in English, such as direction or phrase complements (Di, VH, or Ng) following a verb and measure nouns (Nf) following a determinant/q"
O97-4004,P91-1022,0,0.0976485,"Missing"
O97-4004,J90-2002,0,0.150355,"Missing"
O97-4004,J93-2003,0,0.0175987,"Missing"
O97-4004,Y95-1015,1,0.819264,"Missing"
O97-4004,1997.tmi-1.15,1,0.766019,"Missing"
O97-4004,P93-1002,0,0.0607689,"Missing"
O97-4004,P93-1001,0,0.0551517,"Missing"
O97-4004,W93-0301,0,0.0624762,"Missing"
O97-4004,W94-0104,0,0.108749,"erage is not higher than that of other word-based approaches. Focusing on improving coverage, we have chosen to use frequency coupled with simple filtering according to fan-out in the acquisition of class-based rules. Rules that provide the most instances of plausible connection are selected. Our approach differs from those based on a word-specific, mutual information-like statistic that select strongly associated word pairs which may have a weak presence in the data. The experimental results confirm the findings of several recent works on terminology extraction and structural disambiguation. Daille (1994) demonstrated that simple criteria related to 88 S. J. Ker, J. S. Chang frequency coupled with a linguistic filter work better than mutual information for terminology extraction. Justeson and Katz (1995) also gave experimental results supporting a similar finding. Recent work involving structural disambiguation (Alshawi and Carter, 1994; Brill and Resnik, 1994) has also indicated that statistics related to frequency outperform mutual information and the X2 statistic. 6. Concluding Remarks This paper has presented an algorithm capable of identifying words and their translations in a bilingual c"
O97-4004,C94-2178,0,0.0298093,"Missing"
O97-4004,1994.amta-1.11,0,0.0361319,"Missing"
O97-4004,1992.tmi-1.9,0,0.0677433,"Missing"
O97-4004,H91-1026,0,0.552814,"University, Hsin-chu, Taiwan, ROC. ROC. 64 S. J. Ker, J. S. Chang In the context of SMT, Brown et al. (1993) presented a series of five models for estimating translation probability. The first two models have been used in research on word alignment. Model 1 assumes that translation probability depends only on lexical translation probability. Model 2 enhances Model 1 by considering the dependence of translation probability on the distortion probability. There are statistical tools that can help determine the relative association strength of bilingual word pairs with respect to translatability. Gale and Church (1991) used 12 to identify the word correspondence from a bilingual corpus while Fung and Church (1994) proposed a K-vec approach, which is based on a k-way partitioning of the bilingual corpus, to acquire a bilingual lexicon. Such tools usually provide low coverage due to the fact that low frequency words are in the majority and high frequency words tend to have diverse translations. Estimates of word-to-word translation probability based on lexical co-occurrence (Gale and Church, 1991; Kay and R o scheisen, 1993; Fung and Church, 1994; Fung and McKeown, 1994; Utsuro, Ikeda, Yamane, Matsumoto and N"
O97-4004,J93-1006,0,0.0773743,"Missing"
O97-4004,J97-2004,1,0.836046,"is unattainable by statistically trained word-based models. Class-based models obviously offer additional advantages of a smaller storage requirement and higher system Aligning More Words for Small Bilingual Corpora 87 efficiency. Such advantages have their costs, for class-based models may be over-generalized and miss word-specific rules. However, class-based systems have produce results indicating that the advantages outweigh the disadvantages. Obviously, SenseAlign is only one of many possible formulations of the class-based approach to word alignment using both a dictionary and thesaurus. Ker and Chang (1997) described a similar ClassAlign algorithm with a number of differences: 1. ClassAlign does not commit itself to a certain segmentation of Chinese sentences as SenseAlign does. 2. ClassAlign does not identify any morpho-synctical constructions in Chinese sentences as SenseAlign does. 3. Unlike SenseAlign's repeated evaluation of distortion, ClassAlign calculates the distortion, once and for all, relative to anchors cast by the DictAlign algorithm. 4. ClassAlign selects alignment rules by balancing both applicability and specificity; thus, it does not increase coverage at the expense of precisio"
O97-4004,C96-1037,1,0.165665,"Missing"
O97-4004,P93-1004,0,0.0415076,"Missing"
O97-4004,J96-1001,0,0.0875494,"Missing"
O97-4004,C94-2175,0,0.0370175,"Missing"
O97-4004,C94-2169,0,0.057358,"Missing"
O97-4004,C94-2125,0,0.0571763,"Missing"
O97-4004,1994.amta-1.26,0,0.0304857,"Missing"
O97-4004,C92-2070,0,0.036894,"Missing"
P03-2040,P91-1023,0,0.141464,"Missing"
P03-2040,1992.tmi-1.7,0,0.135075,"Missing"
P03-2040,P94-1012,0,0.270359,"Missing"
P03-2040,J93-1004,0,\N,Missing
P03-2040,macklovitch-etal-2000-transsearch,0,\N,Missing
P04-3004,J90-2002,0,0.0491972,"texts offer more answers for the learner than any teacher or reference work do. However, it is important to provide easy access for translators and learning writers alike to find the relevant and informative citations quickly. For instance, the English-French concordance system, TransSearch provides a familiar interface for the users (Macklovitch et al. 2000). The user type in the expression in question, a list of citations will come up and it is easy to scroll down until one finds translation that is useful much like using a search engine. TransSearch exploits sentence alignment techniques (Brown et al 1990; Gale and Church 1990) to facilitate bilingual search at the granularity level of sentences. In this paper, we describe a bilingual concordancer which facilitate search and visualization with fine granularity. TotalRecall exploits subsentential and word alignment to provide a new kind of bilingual concordancer. Through the interactive interface and clustering of short subsentential bi-lingual citations, it helps translators and non-native speakers find ways to translate or express them-selves in a foreign language. 2 Aligning the corpus Central to TotalRecall is a bilingual corpus and a set o"
P04-3004,P91-1023,0,0.467169,"Missing"
P04-3004,1993.tmi-1.17,0,0.0569166,"Missing"
P04-3004,J00-2004,0,0.0461367,"Missing"
P04-3019,J93-1003,0,0.0368109,"est methods for extracting collocations usually take into consideration both linguistic and statistical constraints. Smadja (1993) also detailed techniques for collocation extraction and developed a program called XTRACT, which is capable of computing flexible collocations based Jason S. Chang Department of Computer Science National Tsing Hua University 101, Kuangfu Road, Hsinchu, Taiwan jschang@cs.nthu.edu.tw on elaborated statistical calculation. Moreover, log likelihood ratios are regarded as a more effective method to identify collocations especially when the occurrence count is very low (Dunning, 1993). Smadja’s XTRACT is the pioneering work on extracting collocation types. XTRACT employed three different statistical measures related to how associated a pair to be collocation type. It is complicated to set different thresholds for each statistical measure. We decided to research and develop a new and simple method to extract monolingual collocations. We also provide a web-based user interface capable of searching those collocations and its usage. The concordancer supports language learners to acquire the usage of collocation. In the following section, we give a brief overview of the TANGO c"
P04-3019,J93-1007,0,0.202431,"ike language capability. Collocation extraction is critical to a range of studies and applications, including natural language generation, computer assisted language learning, machine translation, lexicography, word sense disambiguation, cross language information retrieval, and so on. Hanks and Church (1990) proposed using pointwise mutual information to identify collocations in lexicography; however, the method may result in unacceptable collocations for low-count pairs. The best methods for extracting collocations usually take into consideration both linguistic and statistical constraints. Smadja (1993) also detailed techniques for collocation extraction and developed a program called XTRACT, which is capable of computing flexible collocations based Jason S. Chang Department of Computer Science National Tsing Hua University 101, Kuangfu Road, Hsinchu, Taiwan jschang@cs.nthu.edu.tw on elaborated statistical calculation. Moreover, log likelihood ratios are regarded as a more effective method to identify collocations especially when the occurrence count is very low (Dunning, 1993). Smadja’s XTRACT is the pioneering work on extracting collocation types. XTRACT employed three different statistica"
P04-3019,J90-1003,0,\N,Missing
P04-3019,P97-1063,0,\N,Missing
P05-3010,C02-1011,0,0.461963,"Missing"
P05-3010,J98-4003,0,0.353169,"Missing"
P05-3010,P03-1040,0,0.306876,"Missing"
P05-3010,W01-1413,0,0.16275,"Missing"
P05-3010,P91-1036,0,0.0550095,"se E, we assume E is a proper name and evaluate each candidate translation C by the likelihood of C as the transliteration of E using the transliteration model described in (Lin, Wu and Chang 2004). Figure 4. The distribution of distances between source and target terms in Web pages. Pattern FE EF E(F F（E F(E F.E EwF E,F F》（E F」（E 5000 Count 4000 3000 2000 1000 0 Count -4 -3 -2 -1 0 1 2 3 4 63 111 369 2182 4961 2252 718 91 34 Figure 5. The distribution of distances between source and target terms in Web pages. Distance (5) Expanding the tentative translation. Based on a heuristics proposed by Smadja (1991) to expand bigrams to full collocations, we extend the top-ranking candidate with count n on both sides, while keeping the count greater than n/2 (empirically determined). Note that the constant n is set to 10 in the experiment described in Section 4. (6) Final ranking. Rank the expanded versions of candidates by occurrence count and output the ranked list. 4 Experimental results We took the answers of the first 215 questions on a quiz Website (www.quiz-zone.co.uk) and handtranslations as the training data to obtain a of surface patterns. For all but 17 source terms, we are able to find at lea"
P05-3010,lin-etal-2004-extraction,1,\N,Missing
P06-4001,W05-0203,0,0.0552147,"age Processing) has been applied in CAIG to generate tests in multiple-choice format. Mitkov and Ha (2003) established a system which generates reading comprehension tests in a semi-automatic way by using an NLP-based approach to extract key concepts of sentences and obtain semantically alternative terms from WordNet. Coniam (1997) described a process to compose vocabulary test items relying on corpus word frequency data. Recently, Gao (2000) presented a system named AWETS that semiautomatically constructs vocabulary tests based on word frequency and part-of-speech information. Most recently, Hoshino and Nakagawa (2005) established a real-time system which automatically generates vocabulary questions by utilizing machine learning techniques. Brown, Frishkoff, and Eskenazi (2005) also introduced a method on the automatic generation of 6 types of vocabulary questions by employing data from WordNet. 2 Liu, Wang, Gao, and Huang (2005) proposed ways of the automatic composing of English cloze items by applying word sense disambiguation method to choose target words of certain sense and collocation-based approach to select distractors. Previous work emphasizes the automatic generation of reading comprehension, voc"
P06-4001,W03-0203,0,0.060684,"(C) up as (D) as many to Figure 4: An example of generated question. Figure 2: An example of multiple-choice. * X/INFINITIVE * CLAUSE.  * _______* CLAUSE. (A) X/INFINITIVE (B) X/to VBG (C) X/VBG (D) X/VB Although maple trees are among the most colorful (A) varieties in the fall, they lose its leaves (B) (C) sooner than oak trees. (D) Figure 5: An example of surface pattern. Figure 3: An example of error detection. 2 Grammar tests are widely used to assess learners’ grammatical competence, however, it is costly to manually design these questions. In recent years, some attempts (Coniam, 1997; Mitkov and Ha, 2003; Liu et al., 2005) have been made on the automatic generation of language testing. Nevertheless, no attempt has been made to generate English grammar tests. Additionally, previous research merely focuses on generating questions of traditional multiple-choice task, no attempt has been made for the generation of error detection test types. In this paper, we present a novel approach to generate grammar tests of traditional multiplechoice and error detection types. First, by analyzing syntactic structure of English sentences, we constitute a number of patterns for the development of structural te"
P06-4001,W05-0210,0,\N,Missing
P06-4011,P04-3019,1,\N,Missing
P10-2021,W09-2107,0,0.0882658,"Missing"
P11-4005,P06-1032,0,0.0282255,"heckers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. Recent work has been done on incorporating word class information into grammar checkers. For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and partof-speech (PoS) tags, while Sun et al. (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. In an approach similar to our work, Tsao and Wible (2009) use a combined ngrams of words forms, lemmas, and part-of-speech ta"
P11-4005,A00-2019,0,0.0545037,"sting rulebased systems have been proposed. For example, Uria et al. (2009) and Lee et al. (2009) leverage heuristic rules for detecting Basque determiner and Korean particle errors, respectively. Gamon et al. (2009) bases some of the modules in ESL Assistant on rules derived from manually inspecting learner data. Our pattern rules, however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting errors in non-native writing. More recently, statistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. ("
P11-4005,C08-1022,0,0.0602882,"Missing"
P11-4005,W10-1005,0,0.233121,"bases some of the modules in ESL Assistant on rules derived from manually inspecting learner data. Our pattern rules, however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting errors in non-native writing. More recently, statistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. Recent work has been done on incorporating word class information into"
P11-4005,hermet-etal-2008-using,0,0.0309661,"ely. Gamon et al. (2009) bases some of the modules in ESL Assistant on rules derived from manually inspecting learner data. Our pattern rules, however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting errors in non-native writing. More recently, statistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. Recent work has been done on incorporating"
P11-4005,P07-1011,0,0.0190788,"acock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. Recent work has been done on incorporating word class information into grammar checkers. For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and partof-speech (PoS) tags, while Sun et al. (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. In an approach similar to our work, Tsao and Wible (2009) use a combined ngrams of words forms, lemmas, and part-of-speech tags for research int"
P11-4005,P10-2065,0,0.0169083,"tistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. Recent work has been done on incorporating word class information into grammar checkers. For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and partof-speech (PoS) tags, while Sun et al. (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. In an approach similar to our work, Tsa"
P11-4005,W09-2108,0,0.137464,"ecting Basque determiner and Korean particle errors, respectively. Gamon et al. (2009) bases some of the modules in ESL Assistant on rules derived from manually inspecting learner data. Our pattern rules, however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting errors in non-native writing. More recently, statistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without"
P12-2026,C02-1011,0,0.297045,"Missing"
P12-2026,J98-4003,0,0.598858,"age (e.g., Chinese) using the advance search function. Subsequently, we retrieve mixed-code snippets and identify the translations of the given term. The system can potentially be used to assist translators to find the most common translation for a given term, or to supplement a bilingual terminology bank (e.g., adding multilingual titles to existing Wikipedia); alternatively, they can be used as additional training data for a machine translation system, as described in Lin et al. (2008). 2 Related Work Phrase translation and transliteration is important for cross-language tasks. For example, Knight and Graehl (1998) describe and evaluate a multi-stage machine translation method for back transliterating English names into Japanese, while Bian and Chen (2000) describe cross-language information access to multilingual collections on the Internet. Recently, researchers have begun to exploit mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets returned by a search engine. Kwok et al. (2005) focus on named entity transliteration and implemented a cross-language name finder."
P12-2026,P03-1040,0,0.529718,"Missing"
P12-2026,P93-1003,0,0.612894,"runtime, the model is used to extracting translation candidates for a given term. Preliminary experiments and evaluation show our method cleanly combining various features, resulting in a system that outperforms previous work. 1 ... 語言處理技術，如自然語言剖析 (Natural Language Parsing)、問題分類 (Question Classification)、專名辨識 (Named Entity Recognition)等等 ... This snippet contains three technical terms in Chinese (i.e., 自然語言剖析 zhiran yuyan poxi, Introduction The phrase translation problem is critical to machine translation, cross-lingual information retrieval, and multilingual terminology (Bian and Chen 2000, Kupiec 1993). Such systems typically use a parallel corpus. However, the out of vocabulary problem (OOV) is hard to overcome even with a very large training corpus due to the Zipf nature of word distribution, and ever growing new terminology and named entities. Luckily, there are an abundant of webpages consisting mixed-code text, typically written in one language but interspersed with some sentential or phrasal translations in another language. By retrieving and 問題分類 wenti fenlei, 專名辨識 zhuanming bianshi), followed by source terms in brackets (respectively, Natural Language Parsing, Question Classificatio"
P12-2026,P08-1113,0,0.443974,"s a given phrase (e.g., named-entity recognition), and then query a search engine for webpages in the target language (e.g., Chinese) using the advance search function. Subsequently, we retrieve mixed-code snippets and identify the translations of the given term. The system can potentially be used to assist translators to find the most common translation for a given term, or to supplement a bilingual terminology bank (e.g., adding multilingual titles to existing Wikipedia); alternatively, they can be used as additional training data for a machine translation system, as described in Lin et al. (2008). 2 Related Work Phrase translation and transliteration is important for cross-language tasks. For example, Knight and Graehl (1998) describe and evaluate a multi-stage machine translation method for back transliterating English names into Japanese, while Bian and Chen (2000) describe cross-language information access to multilingual collections on the Internet. Recently, researchers have begun to exploit mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets"
P12-2026,W01-1413,0,0.422945,"ikipedia); alternatively, they can be used as additional training data for a machine translation system, as described in Lin et al. (2008). 2 Related Work Phrase translation and transliteration is important for cross-language tasks. For example, Knight and Graehl (1998) describe and evaluate a multi-stage machine translation method for back transliterating English names into Japanese, while Bian and Chen (2000) describe cross-language information access to multilingual collections on the Internet. Recently, researchers have begun to exploit mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets returned by a search engine. Kwok et al. (2005) focus on named entity transliteration and implemented a cross-language name finder. Wu et al. (2005) proposed a method to learn surface patterns to find translations in mixed code snippets. Some researchers exploited the hyperlinks in Webpage to find translations. Lu, et al. (2004) propose a method for mining translations of web queries from anchor texts. Cheng, et al (2004) propose a similar method for translating unknown querie"
P12-2026,P04-1024,0,0.597641,"Missing"
P12-2026,P05-3010,1,0.892117,"describe and evaluate a multi-stage machine translation method for back transliterating English names into Japanese, while Bian and Chen (2000) describe cross-language information access to multilingual collections on the Internet. Recently, researchers have begun to exploit mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets returned by a search engine. Kwok et al. (2005) focus on named entity transliteration and implemented a cross-language name finder. Wu et al. (2005) proposed a method to learn surface patterns to find translations in mixed code snippets. Some researchers exploited the hyperlinks in Webpage to find translations. Lu, et al. (2004) propose a method for mining translations of web queries from anchor texts. Cheng, et al (2004) propose a similar method for translating unknown queries with web corpora for cross-language information retrieval. Gravano (2006) also propose similar methods using anchor texts. In a study more closely related to our work, Lin et al. (2008) proposed a method that performs word alignment between translations and phrases"
P12-2026,W03-1502,0,\N,Missing
P12-3010,P04-3019,1,0.650314,"ents of the query are identified in the target sentences. It helps not only on finding translation equivalents of the query but also presenting various contexts of occurrence. As a result, it is extremely useful for bilingual 1 lexicographers, human translators and second language learners (Bowker and Barlow 2004; Bourdaillet et al., 2010; Gao 2011). Identifying the translation equivalents, translation spotting, is the most challenging part of a bilingual concordancer. Recently, most of the existing bilingual concordancers spot translation equivalents in terms of word alignment-based method. (Jian et al., 2004; Callison-Burch et al., 2005; Bourdaillet et al., 2010). However, word alignment-based translation spotting has some drawbacks. First, aligning a rare (low frequency) term may encounter the garbage collection effect (Moore, 2004; Liang et al., 2006) that cause the term to align to many unrelated words. Second, the statistical word alignment model is not good at many-to-many alignment due to the fact that translation equivalents are not always correlated in lexical level. Unfortunately, the above effects will be intensified in a domain-specific concordancer because the queries are usually doma"
P12-3010,D09-1050,1,0.870206,"Missing"
P12-3010,P04-3031,0,0.0591779,"lnf function is that: when counting the local frequency of t in a sentence pair, if t is a subsequence of H, then the count of t should be reasonably reduced by considering the strength of the correlation between the words in H-t and the query. 3 Experimental Results Experimental Setting We use the Chinese/English web pages of the National Palace Museum 2 as our underlying parallel corpus. It contains about 30,000 sentences in each language. We exploited the Champollion Toolkit (Ma et al., 2006) to align the sentence pairs. The English sentences are tokenized and lemmatized by using the NLTK (Bird and Loper, 2004) and the Chinese sentences are segmented by the CKIP Chinese segmenter (Ma and Chen, 2003). To evaluate the performance of the translation spotting, we selected 12 domain-specific terms to query the concordancer. Then, the returned spotted translation equivalents are evaluated against a manually annotated gold standard in terms of recall and precision metrics. We also build two different translation spotting modules by using the GIZA++ toolkit (Och and Ney, 2000) with the intersection/union of the bidirectional word alignment as baseline systems. To evaluate the performance of the ranking crit"
P12-3010,W04-1408,0,0.0298981,"tion spotting module and the ranking module are evaluated in terms of precision-recall measures and coverage rate respectively. 1 Introduction A bilingual concordancer is a tool that can retrieve aligned sentence pairs in a parallel corpus whose source sentences contain the query and the translation equivalents of the query are identified in the target sentences. It helps not only on finding translation equivalents of the query but also presenting various contexts of occurrence. As a result, it is extremely useful for bilingual 1 lexicographers, human translators and second language learners (Bowker and Barlow 2004; Bourdaillet et al., 2010; Gao 2011). Identifying the translation equivalents, translation spotting, is the most challenging part of a bilingual concordancer. Recently, most of the existing bilingual concordancers spot translation equivalents in terms of word alignment-based method. (Jian et al., 2004; Callison-Burch et al., 2005; Bourdaillet et al., 2010). However, word alignment-based translation spotting has some drawbacks. First, aligning a rare (low frequency) term may encounter the garbage collection effect (Moore, 2004; Liang et al., 2006) that cause the term to align to many unrelated"
P12-3010,2005.eamt-1.9,0,0.0293366,"re identified in the target sentences. It helps not only on finding translation equivalents of the query but also presenting various contexts of occurrence. As a result, it is extremely useful for bilingual 1 lexicographers, human translators and second language learners (Bowker and Barlow 2004; Bourdaillet et al., 2010; Gao 2011). Identifying the translation equivalents, translation spotting, is the most challenging part of a bilingual concordancer. Recently, most of the existing bilingual concordancers spot translation equivalents in terms of word alignment-based method. (Jian et al., 2004; Callison-Burch et al., 2005; Bourdaillet et al., 2010). However, word alignment-based translation spotting has some drawbacks. First, aligning a rare (low frequency) term may encounter the garbage collection effect (Moore, 2004; Liang et al., 2006) that cause the term to align to many unrelated words. Second, the statistical word alignment model is not good at many-to-many alignment due to the fact that translation equivalents are not always correlated in lexical level. Unfortunately, the above effects will be intensified in a domain-specific concordancer because the queries are usually domain-specific terms, which are"
P12-3010,P93-1003,0,0.287529,"until no word add to H ej←left neighbor of H If nc(ej ) θ: add ej to H ek←right neighbor of H If nc( ek ) θ: add ek to H Figure 4: Pseudo-code of translation spotting process. 2.3 Ranking The ranking mechanism of a bilingual concordancer is used to provide the most related translation of the query on the top of the outputs for the user. So, an association metric is needed to evaluate the relations between the query and the spotted translations. The Dice coefficient is a widely used measure for assessing the association strength between a multi-word expression and its translation candidates. (Kupiec, 1993; Smadja et al., 1996; Kitamura and Matsumoto, 1996; Yamamoto and Matsumoto, 2000; Melamed, 2001) The following is the definition of the Dice coefficient: Then, we modify the Dice coefficient by replacing the co-occurrence frequency with normalized frequency as follows: nf_dice(t, q)  (4) where q denotes a multi-word expression to be translated, t denotes a translation candidate of q. However, the Dice coefficient has the common subsequence effect (as mentioned in Section 1) due to the fact that the co-occurrence frequency of the common subsequence is usually larger than that of the full tran"
P12-3010,N06-1014,0,0.0370217,"n translators and second language learners (Bowker and Barlow 2004; Bourdaillet et al., 2010; Gao 2011). Identifying the translation equivalents, translation spotting, is the most challenging part of a bilingual concordancer. Recently, most of the existing bilingual concordancers spot translation equivalents in terms of word alignment-based method. (Jian et al., 2004; Callison-Burch et al., 2005; Bourdaillet et al., 2010). However, word alignment-based translation spotting has some drawbacks. First, aligning a rare (low frequency) term may encounter the garbage collection effect (Moore, 2004; Liang et al., 2006) that cause the term to align to many unrelated words. Second, the statistical word alignment model is not good at many-to-many alignment due to the fact that translation equivalents are not always correlated in lexical level. Unfortunately, the above effects will be intensified in a domain-specific concordancer because the queries are usually domain-specific terms, which are mostly multi-word low-frequency terms and semantically non-compositional terms. Wu et al. (2003) employed a statistical association criterion to spot translation equivalents in their bilingual concordancer. The associatio"
P12-3010,W03-1726,1,0.520862,"bsequence of H, then the count of t should be reasonably reduced by considering the strength of the correlation between the words in H-t and the query. 3 Experimental Results Experimental Setting We use the Chinese/English web pages of the National Palace Museum 2 as our underlying parallel corpus. It contains about 30,000 sentences in each language. We exploited the Champollion Toolkit (Ma et al., 2006) to align the sentence pairs. The English sentences are tokenized and lemmatized by using the NLTK (Bird and Loper, 2004) and the Chinese sentences are segmented by the CKIP Chinese segmenter (Ma and Chen, 2003). To evaluate the performance of the translation spotting, we selected 12 domain-specific terms to query the concordancer. Then, the returned spotted translation equivalents are evaluated against a manually annotated gold standard in terms of recall and precision metrics. We also build two different translation spotting modules by using the GIZA++ toolkit (Och and Ney, 2000) with the intersection/union of the bidirectional word alignment as baseline systems. To evaluate the performance of the ranking criterion, we compiled a reference translation set for each query by collecting the manually a"
P12-3010,ma-2006-champollion,0,0.0709389,"Missing"
P12-3010,P00-1056,0,0.1259,"lion Toolkit (Ma et al., 2006) to align the sentence pairs. The English sentences are tokenized and lemmatized by using the NLTK (Bird and Loper, 2004) and the Chinese sentences are segmented by the CKIP Chinese segmenter (Ma and Chen, 2003). To evaluate the performance of the translation spotting, we selected 12 domain-specific terms to query the concordancer. Then, the returned spotted translation equivalents are evaluated against a manually annotated gold standard in terms of recall and precision metrics. We also build two different translation spotting modules by using the GIZA++ toolkit (Och and Ney, 2000) with the intersection/union of the bidirectional word alignment as baseline systems. To evaluate the performance of the ranking criterion, we compiled a reference translation set for each query by collecting the manually annotated translation spotting set and selecting 1 to 3 frequently used translations. Then, the outputs of each query are ranked by the nf_dice function and evaluated against the reference translation set. We also compared the ranking performance with the Dice coefficient. 3.2 Evaluation of Translation Spotting We evaluate the translation spotting in terms of the Recall and P"
P12-3010,J96-1001,0,0.228554,"add to H ej←left neighbor of H If nc(ej ) θ: add ej to H ek←right neighbor of H If nc( ek ) θ: add ek to H Figure 4: Pseudo-code of translation spotting process. 2.3 Ranking The ranking mechanism of a bilingual concordancer is used to provide the most related translation of the query on the top of the outputs for the user. So, an association metric is needed to evaluate the relations between the query and the spotted translations. The Dice coefficient is a widely used measure for assessing the association strength between a multi-word expression and its translation candidates. (Kupiec, 1993; Smadja et al., 1996; Kitamura and Matsumoto, 1996; Yamamoto and Matsumoto, 2000; Melamed, 2001) The following is the definition of the Dice coefficient: Then, we modify the Dice coefficient by replacing the co-occurrence frequency with normalized frequency as follows: nf_dice(t, q)  (4) where q denotes a multi-word expression to be translated, t denotes a translation candidate of q. However, the Dice coefficient has the common subsequence effect (as mentioned in Section 1) due to the fact that the co-occurrence frequency of the common subsequence is usually larger than that of the full translation; hence, the D"
P12-3010,P03-2040,1,0.65415,"has some drawbacks. First, aligning a rare (low frequency) term may encounter the garbage collection effect (Moore, 2004; Liang et al., 2006) that cause the term to align to many unrelated words. Second, the statistical word alignment model is not good at many-to-many alignment due to the fact that translation equivalents are not always correlated in lexical level. Unfortunately, the above effects will be intensified in a domain-specific concordancer because the queries are usually domain-specific terms, which are mostly multi-word low-frequency terms and semantically non-compositional terms. Wu et al. (2003) employed a statistical association criterion to spot translation equivalents in their bilingual concordancer. The associationbased criterion can avoid the above mentioned effects. However, it has other drawbacks in translation spotting task. First, it will encounter the contextual effect that causes the system incorrectly spot the translations of the strongly collocated context. Second, the association-based translation spotting tends to spot the common subsequence of a set of similar translations instead of the full translations. Figure 1 illustrates an example of contextual effect, in which"
P12-3010,C00-2135,0,0.0541979,"j to H ek←right neighbor of H If nc( ek ) θ: add ek to H Figure 4: Pseudo-code of translation spotting process. 2.3 Ranking The ranking mechanism of a bilingual concordancer is used to provide the most related translation of the query on the top of the outputs for the user. So, an association metric is needed to evaluate the relations between the query and the spotted translations. The Dice coefficient is a widely used measure for assessing the association strength between a multi-word expression and its translation candidates. (Kupiec, 1993; Smadja et al., 1996; Kitamura and Matsumoto, 1996; Yamamoto and Matsumoto, 2000; Melamed, 2001) The following is the definition of the Dice coefficient: Then, we modify the Dice coefficient by replacing the co-occurrence frequency with normalized frequency as follows: nf_dice(t, q)  (4) where q denotes a multi-word expression to be translated, t denotes a translation candidate of q. However, the Dice coefficient has the common subsequence effect (as mentioned in Section 1) due to the fact that the co-occurrence frequency of the common subsequence is usually larger than that of the full translation; hence, the Dice coefficient tends to choose the common subsequence. To r"
P12-3010,J93-2003,0,\N,Missing
P12-3010,P06-4018,0,\N,Missing
P12-3010,W02-0109,0,\N,Missing
P12-3010,W96-0107,0,\N,Missing
P12-3010,P04-1066,0,\N,Missing
P12-3027,P05-1074,0,0.0685221,"r is working on. The context-sensitive feature helps writers find the appropriate phrase while composing and revising. This paper is organized as follows. We review the related work in the next section. In Section 3, we brief our system and method. Section 4 reports the evaluation results. We conclude this paper and point out future directions to research in Section 5. 2. Related Work 2.1 Sub-sentential paraphrases A variety of data-driven paraphrase extraction techniques have been proposed in the literature. One of the most popular methods leveraging bilingual parallel corpora is proposed by Bannard and Callison-Burch (2005). They identify paraphrases using a phrase in another language as a pivot. Using bilingual parallel corpora for 158 paraphrasing demonstrates the strength of semantic equivalence. Another line of research further considers context information to improve the performance. Instead of addressing the issue of local paraphrase acquisition, Max (2009) utilizes the source and target contexts to extract subsentential paraphrases by using pivot SMT systems. 2.2 N-gram suggestions After a survey of several existing writing tools, we focus on reviewing two systems closely related to our study. PENS (Liu e"
P12-3027,D07-1007,0,0.073933,"le to do that mainly by taking a context-sensitive approach. FLOW then inserts the phrase the writer selects into the sentence. 157 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 157–162, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics Figure 1. Screenshot of FLOW In this paper, we propose a context-sensitive disambiguation model which aims to automatically choose the appropriate phrases in different contexts when performing n-gram prediction, paraphrase suggestion and translation tasks. As described in (Carpuat and Wu, 2007), the disambiguation model plays an important role in the machine translation task. Similar to their work, we further integrate the multi-word phrasal lexical disambiguation model to the n-gram prediction model, paraphrase model and translation model of our system. With the phrasal disambiguation model, the output of the system is sensitive to the context the writer is working on. The context-sensitive feature helps writers find the appropriate phrase while composing and revising. This paper is organized as follows. We review the related work in the next section. In Section 3, we brief our sys"
P12-3027,P07-2045,0,0.00340843,"Missing"
P12-3027,W09-2503,0,0.0185967,"5. 2. Related Work 2.1 Sub-sentential paraphrases A variety of data-driven paraphrase extraction techniques have been proposed in the literature. One of the most popular methods leveraging bilingual parallel corpora is proposed by Bannard and Callison-Burch (2005). They identify paraphrases using a phrase in another language as a pivot. Using bilingual parallel corpora for 158 paraphrasing demonstrates the strength of semantic equivalence. Another line of research further considers context information to improve the performance. Instead of addressing the issue of local paraphrase acquisition, Max (2009) utilizes the source and target contexts to extract subsentential paraphrases by using pivot SMT systems. 2.2 N-gram suggestions After a survey of several existing writing tools, we focus on reviewing two systems closely related to our study. PENS (Liu et al, 2000), a machine-aided English writing system, provides translations of the corresponding English words or phrases for writers’ reference. Different from PENS, FLOW further suggests paraphrases to help writers revise their writing tasks. While revising, writers would alter the use of language to express their thoughts. The suggestions of"
P12-3027,P00-1067,0,0.722745,"2005). They identify paraphrases using a phrase in another language as a pivot. Using bilingual parallel corpora for 158 paraphrasing demonstrates the strength of semantic equivalence. Another line of research further considers context information to improve the performance. Instead of addressing the issue of local paraphrase acquisition, Max (2009) utilizes the source and target contexts to extract subsentential paraphrases by using pivot SMT systems. 2.2 N-gram suggestions After a survey of several existing writing tools, we focus on reviewing two systems closely related to our study. PENS (Liu et al, 2000), a machine-aided English writing system, provides translations of the corresponding English words or phrases for writers’ reference. Different from PENS, FLOW further suggests paraphrases to help writers revise their writing tasks. While revising, writers would alter the use of language to express their thoughts. The suggestions of paraphrases could meet their need, and they can reproduce their thoughts more fluently. Another tool, TransType (Foster, 2002), a text editor, provides translators with appropriate translation suggestions utilizing trigram language model. The differences between ou"
P13-4024,J10-4007,0,0.0124859,"013 Association for Computational Linguistics query in cluster display mode will control that two words have been labeled verb-object by a parser. Moreover, n-grams grouped by object topic/domain give the learner an overview of the usage of the verb. For example the verb absorb takes clusters of objects related to the topics liquid, energy, money, knowledge, and population. Figure 1. An example Linggle search for the query “absorb $N.” This tendency of predicates to prefer certain classes of arguments is defined by Wilks (1978) as selectional preferences and widely reported in the literature. Erk and Padó (2010) extend experiments on selectional preference induction to inverse selectional preference, considering the restriction imposed on predicates. Inverse sectional preference is also implemented in linggle (e.g. “$V apple”). Linggle presents clusters of synonymous collocates (adjectives, nouns and verbs) of a query keyword. We obtained the clusters by building on Lin and Pantel’s (2002) large-scale repository of dependencies and word similarity scores. Using the method proposed by Ritter and Etzioni (2010) we induce selectional preference with a Latent Dirichlet Allocation (LDA) model to seed the"
P13-4024,P98-2127,0,0.152522,"ering (e.g., What were the Capitals of ancient China?) . In contrast to the previous research in Web scale linguistic search engines, we present a system that supports queries with keywords, wildcard words, POS, synonyms, and additional regular expression (RE) operators and displays the results according the count, similarity, and topic with clusters of synonyms or conceptually related words. We exploit and combine the power of both LDA analysis and distributional similarity to provide meaningful semantic classes that are constrained with members of high similarity. Distributional similarity (Lin 1998) and LDA topics become two angles of attack to view language usage and corpus patterns. 3 Linggle Functionalities The syntax of Linggle queries involves basic regular expression of keywords enriched with wildcard PoS and synonyms. Linggle queries can be either pattern-based commands or natural language questions. The natural language queries are currently handled by simple string matching based on a limited set of questions and command pairs provided by a native speaker informant. 3.1 Natural language queries The handling of queries formulated in natural language has been implemented with hand"
P13-4024,C02-1144,0,0.0283164,"a system that provides quick access to the Google Web 1T n-gram with RE-like queries (alternator “|”, one arbitrary word “*”, arbitrary number of words between two specified words “…”). In contrast to Linggle, NetSpeak does not support PoS wildcard or conceptual clustering. An important function in both Linggle and NetSpeak is synonym query. NetSpeak uses WordNet (Fellbaum 2010) synsets to support synonym match. But WordNet synsets tend to contain very little synonyms, leading to poor coverage. Alternatively, one can use the distributional approach to similarity based on a very large corpus. Lin and Pantel (2002) report efforts to build a large repository of dependencies extracted from large corpora such as Wikipedia, and provide similarity between words (demo.patrickpantel.com). We use these results both for handling synonym queries and to organize the n-grams into semantic classes. More recently, Ritter and Etzioni (2010) propose to apply an LDA model (Blei et al. 2003) to 140 the problem of inducing selectional preference. The idea is to consider the verbs in a corpus as the documents of a traditional LDA model. The arguments of the verb that are encountered in the corpus are treated as the words c"
P13-4024,lin-etal-2010-new,0,0.0717132,"Missing"
P13-4024,N10-1012,0,0.0533757,"Missing"
P13-4024,P10-1044,0,0.0203934,"Missing"
P13-4024,C98-2122,0,\N,Missing
P15-4024,W10-0405,0,0.0678877,"Missing"
P15-4024,P07-1011,0,0.0540817,"Missing"
P15-4024,W05-1514,0,0.0286156,"sim(A, B) = 4 P if |A |= 6 |B|. word-sim(Ai , Bi ), otherwise. Experiments and Results For training, we used a collection of approximately 3,000 examples for 700 headwords obtained from online Macmillan English Dictionary (Rundel 2007), to develop the templates of patterns. The headwords include nouns, verbs, adjectives, and adverbs. We then proceeded to extract writing grammar patterns and examples from the British National Corpus (BNC, with 100 million words), CiteseerX corpus (with 460 million words) and Taiwan Degree Thesis Corpus (with 10 million words). First, we used Tsujii POS Tagger (Tsuruoka and Tsujii 2005) to generate tagged sentences. We applied the proposed method to generate suggestions for each of the 700 content keywords in Academic Keyword List. 4.1 Technical Architecture WriteAhead was implemented in Python and Flask Web framework. We stored the suggestions in JSON format using PostgreSQL for faster access. WriteAhead server obtains client input from a popular browser (Safari, Chrome, or Firefox) dynamically with AJAX techniques. For uninterrupted service and ease of scaling up, we chose to host WriteAhead on Heroku, a cloud-platform-as-aservice (PaaS) site. 4.2 Demo script Evaluating Wr"
P15-4024,W00-0507,0,0.23966,"Missing"
P15-4024,W11-1422,0,\N,Missing
P15-4024,P96-1010,0,\N,Missing
P19-3033,C16-1198,0,0.0535946,"Missing"
P19-3033,W13-1704,0,0.0308928,"tigated the benefits of using texts from language learning coursebooks to train classifiers for predicting proficiency levels of learners’ texts. Vajjala (2017) and Tack et al. (2017) present methods for identifying the linguistic variables that are indicative of writing quality to evaluate a learner’s proficiency. Their researches and Bartning et al. (2019) all use CEFR to assess proficiency levels. We also utilize CEFR criteria in our research to evaluate essays, but focusing more on grammatical elements laid out in Cambridge EGP. In a study more closely related to our work, Write&Improve1 (Andersen et al., 2013; Yannakoudakis et al., 2018) supports self-assessment and learning by correcting common errors and returning an overall score for an essay. Furthermore, it also indicates potentially worst sentences. In contrast, we focus on providing specific information on raising the proficiency level as the learner writes. Researches have pointed out that supplying suggestions while writing is more helpful than suggesting after the fact (Hearst, 2015). Grammarly tries to correct grammatical errors and provides the explanation while the user is writing. WriteAhead2 (Yen et al., 2015) provides real-time wri"
P19-3033,W18-0500,0,0.13492,"the paper is organized as follows. We review the related work in the next section. Then we present our method for detecting grammatical elements in learners’ essays expected to suggest more advanced elements. In our evaluation, Level-Up can provide useful collocations with levels for learners during writing. 2 Related work English Language Teaching (ELT) has been an area of active research in Applied Linguistics and Computational Linguistics. Recently, the stateof-the-art research in ELT has been represented in the 13th Workshop on Innovative Use of NLP for Building Educational Applications (Tetreault et al., 2018) in the Association for Computational Linguistics (ACL) community. The workshop involves developing applications based on NLP approaches for teachers and learners of English as a Second Language (ESL) in educational settings. For example, Bryant and Briscoe (2018) build a competitive system only requiring minimal annotated data by using a simple Language Model ap208 Regex JJR and JJR too JJ TO VB very JJ Level B1 B1 A1 Statement Can use ’and’ to join a limited range of comparative adjectives. Can use ’too’ before adjectives followed by ’to’-infinitive. Can use ’very’ to modify common gradable"
P19-3033,W14-3509,0,0.0311083,"ollowed by ’to’-infinitive. Can use ’very’ to modify common gradable adjectives. Table 1: Example regular expressions commas and “and” to join more than two adjectives, after “be”.) Moreover, Cambridge University Press organizes a wealth of information related to CEFR, including English Grammar Profile (EGP) and English Vocabulary Profile (EVP). EGP grades learners’ ability in terms of grammatical form and CEFR levels, while EVP defines words and phrases of different CEFR levels. Previous works targeting CEFR level detection of learners’ essays include Hancke and Meurers (2013) for German and Vajjala (2014) for Estonian based on annotated learner data. To cope with high cost of collecting learners’ data, Pil´an et al. (2016) investigated the benefits of using texts from language learning coursebooks to train classifiers for predicting proficiency levels of learners’ texts. Vajjala (2017) and Tack et al. (2017) present methods for identifying the linguistic variables that are indicative of writing quality to evaluate a learner’s proficiency. Their researches and Bartning et al. (2019) all use CEFR to assess proficiency levels. We also utilize CEFR criteria in our research to evaluate essays, but"
P19-3033,W18-0529,0,0.0145355,"cations with levels for learners during writing. 2 Related work English Language Teaching (ELT) has been an area of active research in Applied Linguistics and Computational Linguistics. Recently, the stateof-the-art research in ELT has been represented in the 13th Workshop on Innovative Use of NLP for Building Educational Applications (Tetreault et al., 2018) in the Association for Computational Linguistics (ACL) community. The workshop involves developing applications based on NLP approaches for teachers and learners of English as a Second Language (ESL) in educational settings. For example, Bryant and Briscoe (2018) build a competitive system only requiring minimal annotated data by using a simple Language Model ap208 Regex JJR and JJR too JJ TO VB very JJ Level B1 B1 A1 Statement Can use ’and’ to join a limited range of comparative adjectives. Can use ’too’ before adjectives followed by ’to’-infinitive. Can use ’very’ to modify common gradable adjectives. Table 1: Example regular expressions commas and “and” to join more than two adjectives, after “be”.) Moreover, Cambridge University Press organizes a wealth of information related to CEFR, including English Grammar Profile (EGP) and English Vocabulary"
P19-3033,P15-4024,1,0.725996,"k, Write&Improve1 (Andersen et al., 2013; Yannakoudakis et al., 2018) supports self-assessment and learning by correcting common errors and returning an overall score for an essay. Furthermore, it also indicates potentially worst sentences. In contrast, we focus on providing specific information on raising the proficiency level as the learner writes. Researches have pointed out that supplying suggestions while writing is more helpful than suggesting after the fact (Hearst, 2015). Grammarly tries to correct grammatical errors and provides the explanation while the user is writing. WriteAhead2 (Yen et al., 2015) provides real-time writing suggestions on what to write next in the form of grammar patterns and example sentences. Similarly, ColloCaid3 (Lew et al., 2018) checks if the collocation is used correctly and provides frequent collocates so that writers can choose words that go well together. In contrast to the previous research in English Language Teaching and Grammatical Error Correction, we present a tutoring system, LevelUp, that provides writing assistance, focusing on analyzing grammatical elements and suggesting higher level elements during writing. 3 The Level-Up System To improve learner"
P19-3033,P15-1120,0,0.0253069,"o evaluate essays, but focusing more on grammatical elements laid out in Cambridge EGP. In a study more closely related to our work, Write&Improve1 (Andersen et al., 2013; Yannakoudakis et al., 2018) supports self-assessment and learning by correcting common errors and returning an overall score for an essay. Furthermore, it also indicates potentially worst sentences. In contrast, we focus on providing specific information on raising the proficiency level as the learner writes. Researches have pointed out that supplying suggestions while writing is more helpful than suggesting after the fact (Hearst, 2015). Grammarly tries to correct grammatical errors and provides the explanation while the user is writing. WriteAhead2 (Yen et al., 2015) provides real-time writing suggestions on what to write next in the form of grammar patterns and example sentences. Similarly, ColloCaid3 (Lew et al., 2018) checks if the collocation is used correctly and provides frequent collocates so that writers can choose words that go well together. In contrast to the previous research in English Language Teaching and Grammatical Error Correction, we present a tutoring system, LevelUp, that provides writing assistance, fo"
P19-3034,D17-1277,0,0.0252298,"Missing"
P19-3034,D11-1072,0,0.0161067,"Missing"
P19-3034,K18-1050,0,0.0408624,"ing grammar patterns computationally, Mason (2004) conducted a limited experiment of automatic parsing based on COBUILD grammar patterns with reasonable success. More recently, Yen et al. (2015) introduced a method for inducing grammar patterns to use in an interactive writing environment aimed at assisting language learners in writing. Identifying the intended word sense relevant to the context has long been an active topic of word Wikification of educational materials has been touted as a novel approach to facilitate reading and learning. In this work, we use the existing method proposed by Kolitsas et al. (2018), to identify potentially ambiguous mentions of key phrases in a document and link them to relevant Wikipedia articles. Much of previous work shows that one of the most efficient way to learn a second language is through extensive reading, using engaging extracurricular articles, news or books (e.g., Coady (1997), Pigada and Schmitt (2006)). Inspired by their insights, we present Linggle Booster, an interactive environment which provides helpful information related to input article, to help learners acquiring deeper knowledge while reading. 214 also extract collocations to accompany grammar pa"
P19-3034,H94-1046,0,0.0430229,"ooster session for the user-selected web page 5 , presenting the reformatted article in the left column, where Wikipedia information shown in a pop-up, and we provide the following vocabulary information for the highlighted word, finals: Chinese translations of the word sense, grammar patterns, collocations, and examples in the right column. sense disambiguation (WSD) research. In general, WSD systems typically use supervised learning approach with a sense inventory such as WordNet WSD systems based on dictionary-based sense inventory (e.g., WordNet) and a sense-annotated corpus (e.g., Semcor Miller et al. (1994)). In our work, we adopt BERT introduced by Devlin et al. (2018) to disambiguate words in user-submitted contents to provide correct word definition and appropriate quizzes. describes what language learners can do at six language stages (i.e., A1, A2, B1, B2, C1, and C2), which has a major effect on language exams and course material design. Stemmed from CERF, Cambridge University Press compiles the English Vocabulary Profile which classifies words and phrases by CERF levels. In our system, we perform word sense disambiguation on usersubmitted content and label words with simplified CERF level"
P19-3034,E17-1010,0,0.0134633,"ame design to assist writing in English. Instead of providing supports for reading a user-selected article, the system could take the user’s own writing as input and use grammar patterns and collocations to improve writing quality and correct grammatical errors. Table 2: WSD evaluation and 0.84 respectively. We also performed an experiment on word sense disambiguation based on method proposed in ELMO using SemCor 3.0 Miller et al. (1994) and OMSTI Taghipour and Ng (2015) as training data. After training, we take the average representations for each Wordnet sense. To test our WSD method using (Raganato et al., 2017), we use BERT again to compute word vectors for every target word and take the most similar sense from the training set. If lemma is not in training set, we use the first sense from Wordnet as our word sense. The result of this test is shown in Table 2. 6 References James Coady. 1997. 1 1 l2 vocabulary acquisition through extensive reading. Second language vocabulary acquisition: A rationale for pedagogy, page 225. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.0"
P19-3034,K15-1037,0,0.0130064,"g direction to explore is ranking grammar patterns to match the proficiency level of readers. Yet another direction of research would be using the same design to assist writing in English. Instead of providing supports for reading a user-selected article, the system could take the user’s own writing as input and use grammar patterns and collocations to improve writing quality and correct grammatical errors. Table 2: WSD evaluation and 0.84 respectively. We also performed an experiment on word sense disambiguation based on method proposed in ELMO using SemCor 3.0 Miller et al. (1994) and OMSTI Taghipour and Ng (2015) as training data. After training, we take the average representations for each Wordnet sense. To test our WSD method using (Raganato et al., 2017), we use BERT again to compute word vectors for every target word and take the most similar sense from the training set. If lemma is not in training set, we use the first sense from Wordnet as our word sense. The result of this test is shown in Table 2. 6 References James Coady. 1997. 1 1 l2 vocabulary acquisition through extensive reading. Second language vocabulary acquisition: A rationale for pedagogy, page 225. Jacob Devlin, Ming-Wei Chang, Kent"
P19-3034,P15-4024,1,0.768702,"ictionary and English Vocabulary Profile. In the field of computer-assisted English learning, there have been an increasing interest in helping second language learners acquire the grammatical usage of a target word. Hunston et al. (1996) and Francis et al. (1998) manually mapped out lexical grammar patterns for common verbs, nouns, and adjectives, using the Collins COBUILD corpus. To explore the feasibility of identifying grammar patterns computationally, Mason (2004) conducted a limited experiment of automatic parsing based on COBUILD grammar patterns with reasonable success. More recently, Yen et al. (2015) introduced a method for inducing grammar patterns to use in an interactive writing environment aimed at assisting language learners in writing. Identifying the intended word sense relevant to the context has long been an active topic of word Wikification of educational materials has been touted as a novel approach to facilitate reading and learning. In this work, we use the existing method proposed by Kolitsas et al. (2018), to identify potentially ambiguous mentions of key phrases in a document and link them to relevant Wikipedia articles. Much of previous work shows that one of the most eff"
P97-1038,W93-0300,0,0.231251,"Missing"
P97-1038,C94-1084,0,0.0560804,"Missing"
P97-1038,1994.amta-1.11,0,0.111934,"Missing"
P97-1038,C94-2178,0,0.28428,"Missing"
P97-1038,P91-1023,0,0.286138,"Missing"
P97-1038,H91-1026,0,0.169425,"Missing"
P97-1038,1992.tmi-1.9,0,0.354243,"Missing"
P97-1038,J97-2004,1,0.769456,"Missing"
P97-1038,1992.tmi-1.7,0,0.509871,"Missing"
P97-1038,1996.amta-1.14,0,0.275248,"Missing"
P97-1038,P94-1012,0,0.280462,"Missing"
P97-1038,P91-1022,0,0.62513,"Missing"
P97-1038,P93-1002,0,0.208166,"Missing"
P97-1038,P93-1001,0,0.515825,"Missing"
P97-1038,W93-0301,0,0.156556,"Missing"
P97-1038,J93-1004,0,\N,Missing
P97-1038,J93-2003,0,\N,Missing
P97-1038,J93-1006,0,\N,Missing
P98-1037,P91-1034,0,0.126634,"Missing"
P98-1037,J98-1003,1,0.84718,"bank~GEOGRAPHY, but certain instances of bank are left untagged for lack of relevant WSD 238 knowledge. For instance, the GEO-bank sense in the context of vole is unresolved since there is no information linking ANIMAL context to GEOGRAPHY sense of bank. The adaptation step adds deer and ANIMAL to the contextual representation for GEO-bank. The enriched CR therefore contains information capable of disambiguating the instance of bank in the context of vole to produce final disambiguation result. 2 Acquiring Conceptual Knowledge from MRD In this section we apply a so-called TopSense algorithm (Chen and Chang 1998) to acquire CR for MRD senses. The current implementation of TopSense uses the topical information in Longman Lexicon of Contemporary English (McArthur 1992, LLOCE) to represent WSD knowledge for LDOCE senses. In the following subsections we describe how that is done. 2.1 Contextual MRDs Representation from Dictionary is a text whose subject matter is a language. The purpose of dictionary is to provide definitions of word senses, and in the process it supply knowledge not just about the language, but the world (Wilks et al. 1990). A good-sized dictionary usually has a large vocabulary and good"
P98-1037,J94-4003,0,0.266266,"Missing"
P98-1037,1992.tmi-1.9,0,0.613536,"Missing"
P98-1037,H92-1045,0,0.202549,"Missing"
P98-1037,W93-0303,0,0.028071,"stems have been developed using word-based model for specific limited domain to disambiguate senses appearing in usually easy context (Leacock, Towell, and Voorlees 1996) with a lot of typical salient words. For unrestricted text, however, the context tends to be very diverse and difficult to capture with a lexicalized model, therefore a corpus-trained system is unlikely to port to new domains and run off the shelf. Generality and adaptiveness are therefore key to a robust and portable WSD system. A concept-based model for WSD requires less parameter and has an element of generality built in (Liddy and Paik 1993). Conceptual classes make it possible to generalize from wordspecific context in order to disambiguate a word sense appearing in a particularly unfamiliar context in term of word recurrences. An adaptive system armed with an initial lexical and conceptual knowledge base extracted from machine-readable dictionaries (MRDs), has two strong advantages over static lexicalized models trained using a corpus. First, the initial 237 knowledge is rich and unbiased such that a substantial portion of text can be disambiguated precisely. Second, based on the result of initial disambiguated text. Subsequent"
P98-1037,P95-1025,0,0.231607,"Missing"
P98-1037,P95-1026,0,0.290932,"ms proposed in the literature, almost all have the property that the knowledge is fixed when the system completes the training phase. That means the acquired knowledge never expands during the course of disambiguation. Gale, et al. (1992a) report that if one had obtained a set of training materials with errors no more than twenty to thirty percent, one could iterate training materials selection just once or twice and have training sets that had less than ten percent errors. The adaptive approach is somehow similar to their idea of incremental learning and to the bootstrap approach proposed by Yarowsky (1995). However, both approaches are still considered static models which are changed only in the training phase. 242 6 Conclusions We have described a new adaptive approach to word sense disambiguation. Under this learning strategy, first contextual representation for each word sense is built from the sense definition in MRD and represented as a weighted-vector of concepts represented as word lists in a thesaurus. Then the knowledge base is applied to the text for WSD in an adaptive fashion to improve on disambiguation precision. We have demonstrated that this approach has the potential of outperfo"
W03-0317,P02-1051,0,0.247747,"lingual dictionaries. Thus, it is difficult to handle transliteration only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transl"
W03-0317,P98-1036,0,0.348059,"handle transliteration only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transliteration. In addition, using either"
W03-0317,W93-0301,0,0.173838,"Missing"
W03-0317,P93-1003,0,0.196879,"Missing"
W03-0317,W02-2017,0,0.574452,"ion only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transliteration. In addition, using either a language-dependen"
W03-0317,1996.amta-1.13,0,0.0486863,"Missing"
W03-0317,C02-1099,0,0.354576,"this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transliteration. In addition, using either a language-dependent penalty function to measure the similarity between bilingual word pairs, or handcrafted heuristic mapping rules for translitera"
W03-0317,W98-1005,0,0.174581,"Missing"
W03-0317,J96-1001,0,0.0938054,"Missing"
W03-0317,voorhees-tice-2000-trec,0,0.0257333,", a parallel corpus T2 was prepared to evaluate the performance of proposed methods. T2 consists of 500 bilingual examples from the English-Chinese version of the Longman Dictionary of Contempory English (LDOCE) (Proctor, 1988). 4.2 Evaluation Metric In the first experiment, a set of source words was compared with a given target word, and then was ranked by similarity scores. The source word with the highest similarity score is chosen as the answer to the backtransliteration problem. The performance is evaluated by rates of the Average Rank (AR) and the Average Reciprocal Rank (ARR) following Voorhees and Tice (2000). 1 N AR = ∑ R (i ) N i =1 (15) 1 N ARR = ∑ 1 N i =1 R (i ) (16) where N is the number of testing data, and R(i) is the rank of the i-th testing data. Higher values of ARR indicate better performance. 0.84 3 0.82 Rate of AR 2.5 0.8 2 0.78 1.5 0.76 1 0.74 0.5 0 0.72 1 2 3 4 5 Iteration number AR ARR Rate of ARR 3.5 Figure 7. Performance at each iteration on the validation set T1. In Figure 7, we show the rates of AR and ARR for the validation set T1 by varying the number of iterations of the EM training algorithm from 1 to 6. We note that the rates become saturated at the 2nd iteration, which i"
W03-0317,P98-2220,0,0.556439,"dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transliteration. In addition, using either a language-dependent penalty function to mea"
W03-0317,1994.amta-1.26,0,0.0681629,"Missing"
W03-0317,C98-1036,0,\N,Missing
W03-0317,C98-2215,0,\N,Missing
W03-0317,J98-4003,0,\N,Missing
W03-1702,P91-1017,0,0.107144,"Missing"
W03-1702,P02-1033,0,0.0237623,"one iteration into the next. Li and Huang Another alternative involves using a parallel corpus as a surrogate for tagged data. Gale, Church and Yarowsky (1992) exploited the so-called one sense per translation constraint for WSD. They reported high precision rates of a WSD system for two-way disambiguation of six English nouns based on their translations in an English-French Parallel corpus. However, when working with a particular sense inventory, there is no obvious way to know whether the one sense per translation constraint holds or how to determine the relevant translations automatically. Diab and Resnik (2002) extended the translation-based learning strategy with a weakened constraint that many instances of a word in a parallel corpus often correspond to lexically varied but semantically consistent translations. They proposed to group those translations into a target set, which can be automatically tagged with correct senses based on the hypernym hierarchy of WordNet. Diab and Resnik’s work represents a departure from previous unsupervised approaches in that no seed data is needed and explicit tagged data are produced for a given sense inventory (WordNet in their case). The system trained on the ta"
W03-1702,J93-1003,0,0.0218149,"g Alignment Output c* as the translation; Output the sense of w in L* as the intended sense. i Repeat Steps 2 and 3 until the values of P(d |L) and P(wi,j |i, L) converge; For each i, find the most probable sense wi,j* , j*=argmax j P(wi,j |i, L) ; Output S = { wi,j* |j*=argmax j P(wi,j |i, L)} ; Estimate and output CBSTM for L, To make sense tagging more precise, it is advisable to place constraint on the translation counterpart c of w. SWAT considers only those translations c that has been linked with w based the Competitive Linking Algorithm (Melamed 1997) and logarithmic likelihood ratio (Dunning 1993). “star,” “interest,” “issue,” the adjective “hard,” and the verb “serve.” Table 4. The experimental results of assigning LDOCE senses to classes of LLOCE. Table 5. Evaluation of the MARS Algorithm based on 12 nouns, 1 verb, 1 adjective in LDOCE. Word Bass Bow Cone Duty Galley Mole Sentence Slug Taste Star Interest Issue Serve Hard Avg. Pos #Senses #Done #Correct N N N N N N N N N N N N V A 4 5 3 2 3 3 2 2 6 8 6 7 13 12 4.14 1 2 3 2 3 2 2 2 1 2 4 4 4 2 1.36 1 2 2 2 2 2 2 2 1 2 4 3 2 2 1.29 Prec (LB*) 0.25 0.25 0.33 0.13 0.33 0.33 1.00 0.20 0.17 0.13 0.17 0.14 0.08 0.08 0.26 Prec. 1.00 1.00 0.6"
W03-1702,1992.tmi-1.9,0,0.183894,"Missing"
W03-1702,J98-1005,0,0.0253688,"cks the problem of tagging and data sparseness in a way similar to the Yarowsky approach (1992) based on thesaurus categories. We differ from Yarowsky’s approach, in the following ways: the i. The WSD problem is solved for two languages instead of one within a single sense inventory. Furthermore, an explicit sense tagged corpus is produced in the process. ii. It is possible to work with any number of sense inventories. iii. The method is applicable not only to nouns but also to adjectives and verbs, since it does not rely on topical context, which is effective only for nouns as pointed out by Towell and Voorhees (1998). The approach is very general and modular and can work in conjunction with a number of learning strategies for word sense disambiguation (Yarowsky, 1995; Li and Li, 2002). set of 14 highly ambiguous words showed that very high precision CBSDM and CBSTM can be constructed. High applicability and precision rates were achieved, when applying CBSTM to sense tagging of a Chinese-English parallel corpus. A number of interesting future directions present themselves. First, it would be interesting to see how effectively we can broaden the coverage of CBSTM via backing off smoothing. Second, a CBSTM t"
W03-1702,C92-2070,0,0.215934,"Word sense disambiguation has been an important research area for over 50 years. WSD is crucial for many applications, including machine translation, information retrieval, part of speech tagging, etc. Ide and Veronis (1998) pointed out the two major problems of WSD: sense tagging and data sparseness. On one hand, tagged data are very difficult to come by, since sense tagging is considerably more difficult than other forms of linguistic annotation. On the other hand, although the data sparseness is a common problem, it is especially severe for WSD. The problems were attacked in various ways. Yarowsky (1992) showed a class-based approach under which a very large untagged corpus and thesaurus can be used effectively for unsupervised training for noun homograph disambiguation. However, the method does not offer a method that explicitly produces sense tagged data for any given sense inventory. Li and Huang (1999) described a similar unsupervised approach for Chinese text based on a Chinese thesaurus. As noted in Merialdo (1994), even minimal hand tagging improved on the results of unsupervised methods. Yarowsky (1995) showed that the learning strategy of bootstrapping from small tagged data led to r"
W03-1702,P95-1026,0,0.535804,"blem, it is especially severe for WSD. The problems were attacked in various ways. Yarowsky (1992) showed a class-based approach under which a very large untagged corpus and thesaurus can be used effectively for unsupervised training for noun homograph disambiguation. However, the method does not offer a method that explicitly produces sense tagged data for any given sense inventory. Li and Huang (1999) described a similar unsupervised approach for Chinese text based on a Chinese thesaurus. As noted in Merialdo (1994), even minimal hand tagging improved on the results of unsupervised methods. Yarowsky (1995) showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods. Li and Li (2002) extended the approach by using corpora in two languages to bootstrap the learning process. They showed bilingual bootstrapping is even more effective. The bootstrapping approach is limited by lack of a systematic procedure of preparing seed data for any word in a given sense inventory. The approach also suffers from errors propagating from one iteration into the next. Li and Huang Another alternative involves using a parallel corpus as a surrogate for"
W03-1702,H93-1051,0,0.0874192,"Missing"
W03-1702,P02-1044,0,0.105668,"very large untagged corpus and thesaurus can be used effectively for unsupervised training for noun homograph disambiguation. However, the method does not offer a method that explicitly produces sense tagged data for any given sense inventory. Li and Huang (1999) described a similar unsupervised approach for Chinese text based on a Chinese thesaurus. As noted in Merialdo (1994), even minimal hand tagging improved on the results of unsupervised methods. Yarowsky (1995) showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods. Li and Li (2002) extended the approach by using corpora in two languages to bootstrap the learning process. They showed bilingual bootstrapping is even more effective. The bootstrapping approach is limited by lack of a systematic procedure of preparing seed data for any word in a given sense inventory. The approach also suffers from errors propagating from one iteration into the next. Li and Huang Another alternative involves using a parallel corpus as a surrogate for tagged data. Gale, Church and Yarowsky (1992) exploited the so-called one sense per translation constraint for WSD. They reported high precisio"
W03-1702,O99-4001,0,0.0291855,"On one hand, tagged data are very difficult to come by, since sense tagging is considerably more difficult than other forms of linguistic annotation. On the other hand, although the data sparseness is a common problem, it is especially severe for WSD. The problems were attacked in various ways. Yarowsky (1992) showed a class-based approach under which a very large untagged corpus and thesaurus can be used effectively for unsupervised training for noun homograph disambiguation. However, the method does not offer a method that explicitly produces sense tagged data for any given sense inventory. Li and Huang (1999) described a similar unsupervised approach for Chinese text based on a Chinese thesaurus. As noted in Merialdo (1994), even minimal hand tagging improved on the results of unsupervised methods. Yarowsky (1995) showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods. Li and Li (2002) extended the approach by using corpora in two languages to bootstrap the learning process. They showed bilingual bootstrapping is even more effective. The bootstrapping approach is limited by lack of a systematic procedure of preparing seed data"
W03-1702,J94-2001,0,0.0355105,"ms of linguistic annotation. On the other hand, although the data sparseness is a common problem, it is especially severe for WSD. The problems were attacked in various ways. Yarowsky (1992) showed a class-based approach under which a very large untagged corpus and thesaurus can be used effectively for unsupervised training for noun homograph disambiguation. However, the method does not offer a method that explicitly produces sense tagged data for any given sense inventory. Li and Huang (1999) described a similar unsupervised approach for Chinese text based on a Chinese thesaurus. As noted in Merialdo (1994), even minimal hand tagging improved on the results of unsupervised methods. Yarowsky (1995) showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods. Li and Li (2002) extended the approach by using corpora in two languages to bootstrap the learning process. They showed bilingual bootstrapping is even more effective. The bootstrapping approach is limited by lack of a systematic procedure of preparing seed data for any word in a given sense inventory. The approach also suffers from errors propagating from one iteration into th"
W03-1702,1994.amta-1.18,0,\N,Missing
W03-1702,J98-1001,0,\N,Missing
W03-1702,J04-1001,0,\N,Missing
W03-1702,P97-1063,0,\N,Missing
W11-1412,P06-1032,0,0.0260694,"supervised or unsupervised, to grammar checking have become the recent trend. For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al., 2008) and (Gamon and Leacock, 2010) use Web as a corpus. On the other hand, supervised models, typically treating error detection/correction as a classification problem, utilize the training of well-formed texts ((De Felice and Pulman, 2008) and (Tetreault et al., 2010)), learner texts, or both pairwisely (Brockett et al., 2006). Moreover, (Sun et al., 2007) describes a way to construct a supervised error detection system trained on well-formed and learner texts neither pairwise nor error tagged. In contrast to the previous work in grammar checking, our pattern grammar rules are automatically inferred from a general corpus (as described in Section 3) and helpful for correcting 101 errors resulting from the others (e.g., “to close” in “play ~ role to close”), our pattern grammar lexicalizes on both content and function words and lexical items within may be contiguous (e.g., “look forward to V-ING PRP”) or non-contiguo"
W11-1412,A00-2019,0,0.0550297,"nto an extended Levenshtein algorithm (1966) to provide broad-coverage sentence-level grammatical edits (involving substitution, deletion, and insertion) to inappropriate word usages in learner text. Previously, a number of interesting rule-based error detection/correction systems have been proposed for some specific error types such as article and preposition error (e.g., (Uria et al., 2009), (Lee et al., 2009), and some modules in (Gamon et al., 2009)). Statistical approaches, supervised or unsupervised, to grammar checking have become the recent trend. For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al., 2008) and (Gamon and Leacock, 2010) use Web as a corpus. On the other hand, supervised models, typically treating error detection/correction as a classification problem, utilize the training of well-formed texts ((De Felice and Pulman, 2008) and (Tetreault et al., 2010)), learner texts, or both pairwisely (Brockett et al., 2006). Moreover, (Sun et al., 2007) describes a way to construct a supervised error detection system trained on well-formed and"
W11-1412,C08-1022,0,0.0496488,"Missing"
W11-1412,W10-1005,0,0.280638,". As such, GRASP will be evaluated over CALL. In this section, we first present the setting of GRASP (Section 4.1) and report the results of different consulting systems on language learning in Section 4.2. 4.1 Experimental Setting We used British National Corpus (BNC) as our underlying reference corpus C. It is a British English text collection. We exploited GENIA tagger to obtain the lemmas and POS tags of C’s sentences. After lemmatizing and syntactic analyses, all sentences in BNC were used to build up inverted files and used as examples for grammar pattern extraction. 3 5 99 Inspired by (Gamon and Leacock, 2010). English (E) sentence with corresponding Chinese (C) translation C: 環境保護對地球有深遠的影響 E: Environmental protection has ___ impact ___. C: 房屋仲介商在賣屋上大賺一筆 E: The real estate agent ___ record profit ___. C: 他們打算在不久將來推出新專輯 E: They plan to release their new album in ___ future C: 他為了再見她一面等了很久 E: He waited for her for a long time in ___ attempt ___ again. 4.2 Results of Constrained Experiments In our experiments, we showed GRASP 6 to two classes of Chinese EFL (first-year) college students. 32 and 86 students participated, and were trained to use GRASP and instructed to perform a sentence translation/com"
W11-1412,hermet-etal-2008-using,0,0.0281455,"ppropriate word usages in learner text. Previously, a number of interesting rule-based error detection/correction systems have been proposed for some specific error types such as article and preposition error (e.g., (Uria et al., 2009), (Lee et al., 2009), and some modules in (Gamon et al., 2009)). Statistical approaches, supervised or unsupervised, to grammar checking have become the recent trend. For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al., 2008) and (Gamon and Leacock, 2010) use Web as a corpus. On the other hand, supervised models, typically treating error detection/correction as a classification problem, utilize the training of well-formed texts ((De Felice and Pulman, 2008) and (Tetreault et al., 2010)), learner texts, or both pairwisely (Brockett et al., 2006). Moreover, (Sun et al., 2007) describes a way to construct a supervised error detection system trained on well-formed and learner texts neither pairwise nor error tagged. In contrast to the previous work in grammar checking, our pattern grammar rules are automatically infer"
W11-1412,J93-1007,0,0.500771,"Missing"
W11-1412,P07-1011,0,0.0174044,"mmar checking have become the recent trend. For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al., 2008) and (Gamon and Leacock, 2010) use Web as a corpus. On the other hand, supervised models, typically treating error detection/correction as a classification problem, utilize the training of well-formed texts ((De Felice and Pulman, 2008) and (Tetreault et al., 2010)), learner texts, or both pairwisely (Brockett et al., 2006). Moreover, (Sun et al., 2007) describes a way to construct a supervised error detection system trained on well-formed and learner texts neither pairwise nor error tagged. In contrast to the previous work in grammar checking, our pattern grammar rules are automatically inferred from a general corpus (as described in Section 3) and helpful for correcting 101 errors resulting from the others (e.g., “to close” in “play ~ role to close”), our pattern grammar lexicalizes on both content and function words and lexical items within may be contiguous (e.g., “look forward to V-ING PRP”) or non-contiguous (e.g., “play ~ role In V-IN"
W11-1412,P10-2065,0,0.0140506,"ome modules in (Gamon et al., 2009)). Statistical approaches, supervised or unsupervised, to grammar checking have become the recent trend. For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al., 2008) and (Gamon and Leacock, 2010) use Web as a corpus. On the other hand, supervised models, typically treating error detection/correction as a classification problem, utilize the training of well-formed texts ((De Felice and Pulman, 2008) and (Tetreault et al., 2010)), learner texts, or both pairwisely (Brockett et al., 2006). Moreover, (Sun et al., 2007) describes a way to construct a supervised error detection system trained on well-formed and learner texts neither pairwise nor error tagged. In contrast to the previous work in grammar checking, our pattern grammar rules are automatically inferred from a general corpus (as described in Section 3) and helpful for correcting 101 errors resulting from the others (e.g., “to close” in “play ~ role to close”), our pattern grammar lexicalizes on both content and function words and lexical items within may be co"
W11-1412,W09-2108,0,0.102324,"provide more information in a way similar what is provided in learner dictionaries. 3 3.1 The GRASP System Problem Statement We focus on constructing a usage summary likely to explain the contexts of a given linguistic search. The usage summary, consisting of the query’s predominant attendant phraseology ranging from pattern grammar to lexical phrases, is then returned as the output of the system. The returned summary, or a set of patterns pivoted with both content and function words, can be used for learners’ benefits directly, or passed on to an error detection and correction system (e.g., (Tsao and Wible, 2009) and some modules in (Gamon et al., 2009) as rules. Therefore, our goal is to return a reasonable-sized set of lexical and grammatical patterns characterizing the contexts of the query. We now formally state the problem that we are addressing. Problem Statement: We are given a reference corpus C from a wide range of sources and a learner search query Q. Our goal is to construct a summary of word usages based on C that is likely to represent the lexical or grammatical preferences on Q’s contexts. For this, we transform the words in Q into sets of (word position, sentence record) pairs such that"
W11-1412,W10-0804,0,0.0477183,"Missing"
W11-1412,P04-3019,1,0.880858,"Missing"
W11-1412,P95-1026,0,0.0391388,"n Figure 2. In Step (1) we reformulate the user query into new ones, queries, if necessary. The first type of query reformulation concerns the language used in query. If it is not in the same language as C, we translate query and append the translations to queries as if they were submitted by the user. The second concerns the length of the query. Since single words may be ambiguous in senses and contexts or grammar patterns are closely associated with words’ meanings (Hunston and Francis, 2000), we transform single-word queries into their collocations, particularly focusing on one word sense (Yarowsky, 1995), as stepping stones to GRASP patterns. Notice that, in implementation, users may be allowed to choose their own interested translation or collocation of the query for usage learning. The prototypes for firstlanguage (i.e., Chinese) queries and English queries of any length are at A2 and B3 respectively. The goal of cross-lingual GRASP is to assist EFL users even when they do not know the words of their searches and to avoid incorrect queries largely because of miscollocation, misapplication, and misgeneralization. Afterwards, we initialize GRASPresponses to collect usage summaries for queries"
W12-2009,C08-1013,0,0.0438714,"Missing"
W12-2009,P05-1074,0,0.654314,"techniques in language learning and teaching. In this paper, we treat the paraphrase generation problem as a graph-related problem. We adopt the PageRank algorithm (Page et al., 1999) to generate paraphrases based on the assumption that a page with more incoming links is likely to receive a higher rank. Meanwhile, a page which is linked by a higher ranked page should transitively be ranked higher. We take advantage of transitivity of relevance to rank and filter the paraphrases generated by the pivot-based method (i.e., phrase are treated as paraphrases if they share the same translations) of Bannard and Callison-Burch (2005). The advantage of the pivot approach is that the generated paraphrases are exactly semantically equivalent to the query phrase. However, its 80 The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 80–85, c Montr´eal, Canada, June 3-8, 2012. 2012 Association for Computational Linguistics quality of the paraphrases highly correlates with that of the techniques of bilingual alignment. To overcome such limitation, we use the PageRank algorithm to refine the generated paraphrases. In other words, we leverage the PageRank algorithm to find more relevant paraphr"
W12-2009,D08-1021,0,0.71803,"} from a bilingual parallel section, we focus on reviewing the methods related corpus B for a query phrase q. Each phrase in cP is to our work. also represented as a node in G. Note that the One prominent approach to paraphrase query phrase q is excluded from cP. generation is based on bilingual parallel corpora. For example, Bannard and Callison-Burch (2005) propose the pivot approach to generate phrasal q paraphrases from an English-German parallel corpus. With the advantage of its parallel and cP bilingual natures of such a corpus, the output paraphrases do preserve semantic similarity. ?? Callison-Burch (2008) further places syntactic ?? constraints on generated paraphrases to improve the quality of the paraphrases. In this paper, we generate paraphrases adopting the pivot-based ?? ?? method proposed by Bannard and Callison-Burch (2005) in the first round. Then we use a graph-based approach to further ensure paraphrase Figure 1. A simple graph G. Note that the cp1 and candidates preserve both meaning and will be linked iff is the paraphrase of q grammaticality. and is also the paraphrase of In a study more closely related to our work, Kok and Brockett (2010) take a graphical view of 81 Graph G only"
W12-2009,W11-2504,0,0.152854,"Missing"
W12-2009,N10-1017,0,0.0558195,"hrases do preserve semantic similarity. ?? Callison-Burch (2008) further places syntactic ?? constraints on generated paraphrases to improve the quality of the paraphrases. In this paper, we generate paraphrases adopting the pivot-based ?? ?? method proposed by Bannard and Callison-Burch (2005) in the first round. Then we use a graph-based approach to further ensure paraphrase Figure 1. A simple graph G. Note that the cp1 and candidates preserve both meaning and will be linked iff is the paraphrase of q grammaticality. and is also the paraphrase of In a study more closely related to our work, Kok and Brockett (2010) take a graphical view of 81 Graph G only contains the paraphrases cpi whose probabilities are higher than a certain threshold ε 2 as nodes. In addition, each cpi is linked to the query phrase q with edge e which is weighted by the probability ( |). Furthermore, we establish the edges among the phrases in cP. An example graph is shown in Figure 1. By repeating the previous steps, for each phrase cp1, cp2,... in cP, we find their corresponding paraphrases, and …., and discard the paraphrases that are not in cP. Once the phrases are linked with their paraphrases, the graph G is created. In this"
W12-2009,J10-3003,0,0.028125,"how we use the have problems in paraphrasing. In view of this, we PageRank algorithm to rank and filter the develop PREFER, a paraphrase reference tool, for paraphrases generated by the pivot-based method. helping English learners with their writing. Paraphrase generation, on the other hand, has 3.1 Graph Construction been an area of active research and the related We first exploit the pivot-based method proposed work has been thoroughly surveyed in by Bannard and Callison-Burch (2005) to populate Androutsopoulos and Malakasiotis (2010) as well our graph G using of candidate paraphrases as in Madnani and Dorr (2010). In the rest of this cP={ } from a bilingual parallel section, we focus on reviewing the methods related corpus B for a query phrase q. Each phrase in cP is to our work. also represented as a node in G. Note that the One prominent approach to paraphrase query phrase q is excluded from cP. generation is based on bilingual parallel corpora. For example, Bannard and Callison-Burch (2005) propose the pivot approach to generate phrasal q paraphrases from an English-German parallel corpus. With the advantage of its parallel and cP bilingual natures of such a corpus, the output paraphrases do preser"
W12-2009,J03-1002,0,0.00382819,"weight the edges based on the paraphrase probability in the pivot-based approach using 3.2 Graph-Based Paraphrase Generation 4.1 Experimental Setting We then refine the generated paraphrases adopting the PageRank algorithm proposed by Page et al. (1999). Consider a graph consisting of a set of webpages on the Web V and a set of hyperlinks E. The PageRank algorithm assigns a value PR to each webpage as their importance measurement. The PR value of a certain page u is defined iteratively as the following equation: ( ) ( ) ∑ ( ) ( ) In this paper, word alignments were produced by Giza++ toolkit (Och and Ney, 2003) over a set of Danish-English section (containing 1,236,427 sentences) of the Europarl corpus, version 2 (Koehn, 2002). We compared our graph-based approach with a strong baseline, the pivot-based method with syntactic constraint (SBP) (Callison-Burch, 2008) utilizing the same Danish-English corpus. We also investigate the contribution of adding the edge weights to the PageRank algorithm by building two models, PR representing the method of the PageRank algorithm without weights and PRw representing the method of the weighted PageRank algorithm, for comparison. To assess the performance of our"
W12-2035,W07-1604,0,0.0823599,"Missing"
W12-2035,W12-2006,0,0.0292011,"Missing"
W12-2035,W07-1607,0,0.0629018,"Missing"
W12-2035,W97-0301,0,0.0464826,"aining and testing of the preposition error detection and correction modules. Input sentence Tagger & Parser Determiner Error Detection Determiner Determiner Choice Preposition Error Detection Preposition Preposition Error Choice Output Figure 1. System Architecture (Run-Time) 296 Word This virus affects the defence system Base form This virus affect the defence system POS DT NN VBZ DT NN NN Chunk B-NP I-NP B-VP B-NP I-NP I-NP NE O O O O O O . . . O O Table 1. The tag result of sample sentence. 2.2 Determiners In this section, we investigate the performance of two maximum entropy classifiers (Ratnaparkhi, 1997), one for determining whether a noun phrase has a determiner or not and the other for selecting the appropriate determiner if one is needed. From the British National Corpus (BNC), we extract 22,552,979 noun phrases (NPs). For determining which features are useful for this task, all NPs are divided into two sets, 20 million cases as a training set and the others as a validation set. For the classifier (named the DetClassifier hereafter) trained for predicting whether a NP has a determiner or not, the label set contains two labels: “Zero” and “DET.” On the other hand, for the classifier (named"
W12-2035,W10-4236,0,\N,Missing
W12-6338,W00-1205,1,0.66075,"ter. The training scale is 407 outcomes, 2438366 parameters and 1593985 predicates. Experiments and Results In this section, we describe the experiment design, and then evaluate the proposed models based on Sinica Treebank. We also analyze the results, and compare them with the results derived by the open source Berkeley statistical parser on the same test set. 4.1 4.2 Experimental Settings Treebank: We employ Sinica Treebank as our experimental corpus. It contains 61,087 syntactic tree structures and 361,834 words. The syntactic theory of Sinica Treebank is based on the HeadDriven Principle (Huang et al., 2000); that is, a sentence or phrase is composed of a phrasal head and its arguments or adjuncts. We divide the treebank into four parts: the training data (55,888 sentences), the development set (1,068 sentences), the test data T06 (867 sentences), and the test data T07 (689 sentences). The test datasets (T06, T07) were used in CoNLL06 and CoNLL07 dependent parsing evaluation individually. The main difference between Sinica Treebank data and CoNLL data is that the CoNLL is in dependency format. Word Sense: With regard to semantic features, we use the head senses of words expressed in EHowNet (http"
W12-6338,P03-1054,0,0.0249263,"to their structural evaluation scores, which may be an accumulated score of rule probabilities and featurebased scores. In general, the evaluation functions are derived from very limited and biased resources, such as treebanks. Therefore we need to find a way to improve the evaluation functions under the constraint of very limited resources. Suppose that the parsing environment is a model of probabilistic context-free grammar (PCFG). Several researchers are attaching many useful features to the grammar rules to improve the precision of the grammar rules (Johnson, 1998; Sun and Jurafsky, 2003; Klein and Manning, 2003; Hsieh et al., 2005). In this paper, we follow grammar representation in Hsieh et al. (2005), and propose a context-dependent probability re-estimation model (CDM) to enhance the performance of the original PCFG model. CDM combines rule probabilities and machine learning techniques in structure evaluation. Similar to other machine learning methods (Ratnaparkhi, 1999; Charniak, 2000; Wang et al., 2006), the CDM has the flexibility to adjust the features, and to obtain better re-estimated structure probabilities. The remainder of this paper is organized as follows. Section 2 provides background"
W12-6338,A00-2018,0,0.404183,"probabilistic context-free grammar (PCFG). Several researchers are attaching many useful features to the grammar rules to improve the precision of the grammar rules (Johnson, 1998; Sun and Jurafsky, 2003; Klein and Manning, 2003; Hsieh et al., 2005). In this paper, we follow grammar representation in Hsieh et al. (2005), and propose a context-dependent probability re-estimation model (CDM) to enhance the performance of the original PCFG model. CDM combines rule probabilities and machine learning techniques in structure evaluation. Similar to other machine learning methods (Ratnaparkhi, 1999; Charniak, 2000; Wang et al., 2006), the CDM has the flexibility to adjust the features, and to obtain better re-estimated structure probabilities. The remainder of this paper is organized as follows. Section 2 provides background on PCFG parsing with grammar rule representation. Section 3 describes the proposed CDM and our selected features. The experimental evaluation and results are in Section 4. The last section contains some concluding remarks. 216 Proceedings of the Second CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 216–221, Tianjin, China, 20-21 DEC. 2012 2 Background 2.1 The ba"
W12-6338,W03-1706,0,0.40213,"uld be ranked according to their structural evaluation scores, which may be an accumulated score of rule probabilities and featurebased scores. In general, the evaluation functions are derived from very limited and biased resources, such as treebanks. Therefore we need to find a way to improve the evaluation functions under the constraint of very limited resources. Suppose that the parsing environment is a model of probabilistic context-free grammar (PCFG). Several researchers are attaching many useful features to the grammar rules to improve the precision of the grammar rules (Johnson, 1998; Sun and Jurafsky, 2003; Klein and Manning, 2003; Hsieh et al., 2005). In this paper, we follow grammar representation in Hsieh et al. (2005), and propose a context-dependent probability re-estimation model (CDM) to enhance the performance of the original PCFG model. CDM combines rule probabilities and machine learning techniques in structure evaluation. Similar to other machine learning methods (Ratnaparkhi, 1999; Charniak, 2000; Wang et al., 2006), the CDM has the flexibility to adjust the features, and to obtain better re-estimated structure probabilities. The remainder of this paper is organized as follows. Sect"
W12-6338,W04-1116,1,0.731418,"Missing"
W12-6338,P10-1113,0,0.0233934,"hinese. Suppose we need to calculate CDPi based on the related features, while the i-th rule is applied for covering a span of words [L…R]. The used context and contextual features are as follows: tion to derive the rule probabilities from transformed Sinica Treebank (http://TreeBank.sinica.edu.tw). 3 Context-Dependent Probability Reestimation Model Many works try to improve rule probability estimation by using context-dependent probabilities in PCFG model, and show that rules with dependent context features perform better than PCFG alone (Ratnaparkhi, 1999; Charniak, 2000; Wang et al., 2006; Li et al., 2010). Charniak (2000) presented a maximum-entropy-inspired model to estimate probabilities in Markov grammar. The model uses a standard bottom-up best-first probabilistic chart parser to generate possible candidate parses in the first pass, and then evaluates the candidates with the proposed probabilistic model in the second pass. Therefore Charniak’s method (2000) generates possible candidate parses first and then evaluates these candidates without early pruning. We adopt the maximum entropy method for structure evaluation, and integrate it into present PCFG model, called as CDM. CDM integrates t"
W12-6338,P06-1054,0,0.77856,"ontext-free grammar (PCFG). Several researchers are attaching many useful features to the grammar rules to improve the precision of the grammar rules (Johnson, 1998; Sun and Jurafsky, 2003; Klein and Manning, 2003; Hsieh et al., 2005). In this paper, we follow grammar representation in Hsieh et al. (2005), and propose a context-dependent probability re-estimation model (CDM) to enhance the performance of the original PCFG model. CDM combines rule probabilities and machine learning techniques in structure evaluation. Similar to other machine learning methods (Ratnaparkhi, 1999; Charniak, 2000; Wang et al., 2006), the CDM has the flexibility to adjust the features, and to obtain better re-estimated structure probabilities. The remainder of this paper is organized as follows. Section 2 provides background on PCFG parsing with grammar rule representation. Section 3 describes the proposed CDM and our selected features. The experimental evaluation and results are in Section 4. The last section contains some concluding remarks. 216 Proceedings of the Second CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 216–221, Tianjin, China, 20-21 DEC. 2012 2 Background 2.1 The baseline model, PCFG P"
W12-6338,P06-1055,0,0.109175,"Missing"
W12-6338,O04-2005,1,0.802886,"Berkeley’s parser are closed to F-PCFG model in Table 2. Either Berkely’s parser or F-PCFG represents the ceiling results of a general method, and they both outperform the naïve PCFG model. 4.4 Experiments for Task4 of CLP2012 Task 4 of CLP2012 includes two sub-tasks: sentence parsing and semantic role labeling task. For each sub-task, the testing data are complete Chinese sentence with gold standard word segmentation. Therefore, a pipeline process is needed to solve the POS tagging, syntactic parsing and semantic role assignment in our experiment. We adopt the context-rule tagger proposed by Tsai and Chen (2004) for the POS tagging. For syntactic parsing, we use the CDM parser with same training data in Section 4.1. For semantic role labeling, we follow You and Chen’s (2004) method to assignment semantic role automatically. The detail parsing results of our systems on the test set can be found on the official evaluation report. Our system obtains acceptable results on both sentence parsing and semantic role labeling tasks. F1-Score Task 4-1 Task 4-2 MicroAveraging 0.7287 0.6034 MacroAveraging 0.7448 0.6249 Table 4. Official scores of sentence parsing (task4-1) and semantic role labeling (task4-2). Ta"
W12-6338,I05-1016,1,0.949763,"ation scores, which may be an accumulated score of rule probabilities and featurebased scores. In general, the evaluation functions are derived from very limited and biased resources, such as treebanks. Therefore we need to find a way to improve the evaluation functions under the constraint of very limited resources. Suppose that the parsing environment is a model of probabilistic context-free grammar (PCFG). Several researchers are attaching many useful features to the grammar rules to improve the precision of the grammar rules (Johnson, 1998; Sun and Jurafsky, 2003; Klein and Manning, 2003; Hsieh et al., 2005). In this paper, we follow grammar representation in Hsieh et al. (2005), and propose a context-dependent probability re-estimation model (CDM) to enhance the performance of the original PCFG model. CDM combines rule probabilities and machine learning techniques in structure evaluation. Similar to other machine learning methods (Ratnaparkhi, 1999; Charniak, 2000; Wang et al., 2006), the CDM has the flexibility to adjust the features, and to obtain better re-estimated structure probabilities. The remainder of this paper is organized as follows. Section 2 provides background on PCFG parsing with"
W12-6338,H91-1060,0,0.0289007,"皮球 ball] by the maximal entropy model. Some examples of con218 textual features are “LW0=李四, RW0=皮球, LW1=叫, LW1=撿, RW-1=撿, RW1=X, LW-1&LW0= 叫&李四, LW0&LW1=李四&撿, RW-1&RW0=撿 & 皮 球 , RW0&RW1= 皮 球 &X, RhsW1= 李 四 , RhsW2= 撿 , RhsC1=Nb, RhsC2=VC, RHS=NPHead:Nb_VP-Head:VC, …”, etc. Afterwards, we integrate and calculate the evaluation score by Formula 2. 車:quantity={mass|眾}}, and its head sense is “LandVehicle|車”. For detailed description about E-HowNet, readers may refer to Huang et al. (2008). Estimate Parsing Performance: To evaluate a model, we compare the parsing results with the gold standard. Black et al. (1991) proposed a structural evaluation system is called PARSEVAL. In all the experiments, we used the bracketed f-score (BF) as the parsing performance metric. S'-Head:VF+0+NP NP-Head:Nb Bracketed F - score (BF)  VP-Head:VC NP-Head:Na Head:Nb Head:VC 他 He 叫 ask 李四 Li-si LW0 撿 pick Bracketed Precision (BP)  # bracket correct consitituents in parser's parse of testing data # bracket constituents in parser's of testing data Head:Na 皮球 ball RW0 Bracketed Recall (BR)  # bracket correct consitituents in parser' s parse of testing data # bracket constituents in treebank' s of testing data Figure 3. A p"
W12-6338,J03-4003,0,\N,Missing
W13-3603,P13-4024,1,0.737636,"tion on the location of the location of cell location of cell phone on the location the location of location of cell the location location of MW4 MW3 MW2 Table 2. Trigram information of ‘location’ and ‘locations’ in back-off model MW3 n-gram location on the location the location of location of cell on the locations the locations of locations of cell locations Freq. S3 304,400 3,794,400 1,400 18,200 374,000 200 4M 0.04 M then measure the ratio of the counts of the original and replaced n-grams in a corpus. The frequency counts are obtained by querying a linguistic search engine Linggle (Joanne Boisson et al. 2013), a web-scale linguistic search engine based on Google Web1T (Brants and Franz, 2006). The sum of n-gram counts, Sk with the word w (original or replacement) in the ith position is defined as 2.1 Overview In this section, we give an overview of our system. Figure 1 shows the architecture of the error correction system. In this study, we focus on five different grammatical error types, including the improper usage of Determiner (ArtOrDet), Noun Number (Nn), Verb-Tenses (Vform), Subject-Verb Agreement (SVA), and Preposition (Prep). In order to deal with these different types of errors systematic"
W13-3603,W13-1703,0,0.127097,"Missing"
W13-3603,N12-1067,0,0.189797,"Missing"
W13-3603,D10-1094,0,0.0516178,"Missing"
W13-3603,J90-1003,0,\N,Missing
W13-3603,W13-3601,0,\N,Missing
W13-4408,W03-1726,0,0.0929847,"lected by comparing the original text and its OCR results. Similarly, Zhuang et al. (2004) proposed an effective approach using OCR to recognize possible confusion set. In addition, Zhuang et al. (2004) also used a multiknowledge based statistical language model, the n-gram language model, and Latent Semantic Analysis. However, the experiments by Zhuang et al. (2004) seem to show that the simple n-gram model performs the best. In recent years, Chinese spelling checkers have incorporated word segmentation. The method proposed by Huang et al. (2007) incorporates Sinica Word Segmentation System (Ma and Chen, 2003) to detect typos. With a characterbased bigram language model and the rule-based methods of dictionary knowledge and confusion set, the method determines whether the word is a typo or not. There are many more systems that use word segmentation to detect errors. For example, in Hung and Wu (2009), the given sentence is segmented using a bigram language model. In addition, the method also uses confusion set and common error templates manually edited and provided by Ministry of Education in Taiwan. Chen and Wu (2010) modified the system proposed by Hung and Wu (2009), by combining statistic-based"
W13-4408,J03-1002,0,0.00804178,"wo translations are possible for this candidate: “氣憤 qi fen” and “氣氛 qi fen”. We use a simple, publicly available decoder written in Python to correct potential spelling errors found in the detection module. The decoder reads in a Chinese sentence at a time and attempts to “translate” the sentence into a correctly spelled one. The decoder translates monotonically without reordering the Chinese words and phrases using two models — translation probability model and the language model. These two models read from a data directory containing two text files containing a translation model in GIZA++ (Och and Ney, 2003) format, and a language model in SRILM (Stolcke et al., 2011) format. These two models are stored in memory for quick access. The decoder invokes the two modules to load the translation and language models and decodes the input sentences, storing the result in output. The decoder computes the probability of the output sentences according to the models. It works by summing over all possible ways that the model could have generated the corrected sentence from the input sentence. Although in general covering all possible corrections in the translation and language models is intractable, but a maj"
W13-4408,W10-4107,0,0.0430754,"statistical methods (Hung and Wu, 2009; Chen and Wu, 2010). Rule-based methods use knowledge resources such as a dictionary to identify a word as a typo if the word is not in the dictionary, and provide similar words in the dictionary as sug49 Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing (SIGHAN-7), pages 49–53, Nagoya, Japan, 14 October 2013. and Section 5 present the experimental data and evaluation results. And we conclude in Section 6. 2 matching module generated automatically to detect and correct typos based on language model. In a work closer to our method, Wu et al. (2010) adopts the noise channel model, a framework used both in spell checkers and machine translation systems. The system combined statistic-based method and template matching with the help of a dictionary and a confusion set. They also used word segmentation to detect errors, but they did not use an existing word segmentation as Huang et al. (2007) did, because it might regard a typo as a new word. They used a backward longest first approach to segment sentences with an online dictionary sponsored by MOE, and a templates with a confusion set. The system also treat Chinese spelling check as a kind"
W13-4408,C96-2184,0,0.123418,"are considered as strongly similar and are retained. For example, the code of “徵 zheng” and “微 wei” are strongly similar in shape, since in their corresponding codes “竹人 山土大” and “竹人山山大”, differ only in one place. Experimental Setting To train our model, we used several corpora including Sinica Chinese Balanced Corpus, TWWaC (Taiwan Web as Corpus), a Chinese dictionary, and a confusion set. We describe the data sets in more detail below. Sinica Corpus ""Academia Sinica Balanced Corpus of Modern Chinese"", or Sinica Corpus for short, is the first balanced Chinese corpus with part-of-speech tags (Huang et al., 1996). Current size of the corpus is about 5 million words. Texts are segmented according to the word segmentation standard proposed by the ROC Computational Linguistic Society. We use the corpus to generate the frequency of bigram, trigram and 4-gram for training translation model and to train the n-gram language model. TWWaC (Taiwan Web as Corpus) We use TWWaC for obtaining more language information. TWWaC is a corpus gathered from the Web under the .tw domain, containing 1,817,260 Web pages, 30 billions Chinese characters. We use the corpus to generate the frequency of all character n-grams for"
W13-4411,N03-1028,0,0.0139232,"Missing"
W13-4411,P00-1032,0,0.0622192,"Missing"
W13-4411,W03-0430,0,0.253178,"Missing"
W13-4411,W09-3412,0,0.0537182,"Missing"
W13-4411,P02-1006,0,\N,Missing
W14-1712,W12-2025,0,0.0329696,"Missing"
W14-1712,N12-1067,0,0.0775705,"Missing"
W14-1712,W13-1703,0,0.0562161,"Missing"
W14-1712,N12-1029,0,0.061715,"Missing"
W14-1712,P03-1054,0,\N,Missing
W14-1712,S13-1035,0,\N,Missing
W14-6832,W13-4408,1,0.578764,"Missing"
W14-6832,W13-4406,0,0.0620612,"Missing"
W14-6832,O13-1005,1,\N,Missing
W96-0305,P91-1034,0,0.113773,"in Longman Lexicon of Contemporary English (LLOCE) are used in this work. Quantitative results for a 12-word test set are reported. Our discussion entails how the availability of these labels provides the means for treating such problems as: acquisition of a lexicon capable of providing broad coverage, systematic word sense shifts, lexical underspecification, and acquisition of zero-derivatives. 1. Introduction Treatment of lexical ambiguity such as WSD has been found useful in many NLP applications, including information retrieval (McRoy 1992; Krovetz and Croft 1992) and machine translation (Brown et al. 1991; Dagan et al. 1991; Dagan and Itai 1994). Recently, various approaches (Dolan 1994; Luk 1995; Yarowsky 1992; Dagan et al. 1991 ;Dagan and Itai 1994) to word sense division have been used in WSD research. Directly using dictionary senses as the sense division has several advantages. First, sense distinction according to a dictionary is readily available from MRDs such as the LDOCE (Longman 1992). Second, indicative words and concepts for each sense are directly available in numbered definitions and examples. Lesk (1986) demonstated that dictionary entries can be used to generate signatures of"
W96-0305,A88-1019,0,0.10715,"Missing"
W96-0305,P91-1017,0,0.0355771,"of Contemporary English (LLOCE) are used in this work. Quantitative results for a 12-word test set are reported. Our discussion entails how the availability of these labels provides the means for treating such problems as: acquisition of a lexicon capable of providing broad coverage, systematic word sense shifts, lexical underspecification, and acquisition of zero-derivatives. 1. Introduction Treatment of lexical ambiguity such as WSD has been found useful in many NLP applications, including information retrieval (McRoy 1992; Krovetz and Croft 1992) and machine translation (Brown et al. 1991; Dagan et al. 1991; Dagan and Itai 1994). Recently, various approaches (Dolan 1994; Luk 1995; Yarowsky 1992; Dagan et al. 1991 ;Dagan and Itai 1994) to word sense division have been used in WSD research. Directly using dictionary senses as the sense division has several advantages. First, sense distinction according to a dictionary is readily available from MRDs such as the LDOCE (Longman 1992). Second, indicative words and concepts for each sense are directly available in numbered definitions and examples. Lesk (1986) demonstated that dictionary entries can be used to generate signatures of senses for WSD. How"
W96-0305,C94-2113,0,0.0698592,"ults for a 12-word test set are reported. Our discussion entails how the availability of these labels provides the means for treating such problems as: acquisition of a lexicon capable of providing broad coverage, systematic word sense shifts, lexical underspecification, and acquisition of zero-derivatives. 1. Introduction Treatment of lexical ambiguity such as WSD has been found useful in many NLP applications, including information retrieval (McRoy 1992; Krovetz and Croft 1992) and machine translation (Brown et al. 1991; Dagan et al. 1991; Dagan and Itai 1994). Recently, various approaches (Dolan 1994; Luk 1995; Yarowsky 1992; Dagan et al. 1991 ;Dagan and Itai 1994) to word sense division have been used in WSD research. Directly using dictionary senses as the sense division has several advantages. First, sense distinction according to a dictionary is readily available from MRDs such as the LDOCE (Longman 1992). Second, indicative words and concepts for each sense are directly available in numbered definitions and examples. Lesk (1986) demonstated that dictionary entries can be used to generate signatures of senses for WSD. However, using MRD as the knowledge source for sense division and d"
W96-0305,P92-1054,0,0.0187198,"isted under both topics Eb and topic Ad, while &quot;duck&quot; is listed under Ad but not Eb. By characterizing of some 200 cross references in LLOCE, most systematic inter-sense relations can be easily identiffed among the labeled senses. The labels attached to senses in the MRD, coupled with these inter-sense relations, can then support and realize automatic sense shifts advocated in Putstejovsky and Bouillon (1994). For instance, the sense of &quot;duck&quot; label with topic Ad can be coerced into an Eb sense when necessary, with the availability of the lexical rule stipulating a sense shift from Ad and Eb. Krovetz (1992) observed that LDOCE indicates sense shifts via direct reference (links indicated by a capitalized word with a sense number) and deictic reference (implicit links to the previous sense created by this, these, that, those, its, itself, such a, such an). Sense shifts indicated through a deictic reference are also present in our 12-word test set. For instance, the first 2 senses of &quot;issue&quot; are 1. the act of coming out. 2. an example of this. The definition of the 2nd senses indicates an A ctionNoun-CountNoun sense shifts from issue.n.1 to issue.n.2 through a deictic reference of &quot;this.&quot; Since tho"
W96-0305,P95-1025,0,0.0122202,"2-word test set are reported. Our discussion entails how the availability of these labels provides the means for treating such problems as: acquisition of a lexicon capable of providing broad coverage, systematic word sense shifts, lexical underspecification, and acquisition of zero-derivatives. 1. Introduction Treatment of lexical ambiguity such as WSD has been found useful in many NLP applications, including information retrieval (McRoy 1992; Krovetz and Croft 1992) and machine translation (Brown et al. 1991; Dagan et al. 1991; Dagan and Itai 1994). Recently, various approaches (Dolan 1994; Luk 1995; Yarowsky 1992; Dagan et al. 1991 ;Dagan and Itai 1994) to word sense division have been used in WSD research. Directly using dictionary senses as the sense division has several advantages. First, sense distinction according to a dictionary is readily available from MRDs such as the LDOCE (Longman 1992). Second, indicative words and concepts for each sense are directly available in numbered definitions and examples. Lesk (1986) demonstated that dictionary entries can be used to generate signatures of senses for WSD. However, using MRD as the knowledge source for sense division and disambiguat"
W96-0305,C92-2070,0,0.0325617,"t set are reported. Our discussion entails how the availability of these labels provides the means for treating such problems as: acquisition of a lexicon capable of providing broad coverage, systematic word sense shifts, lexical underspecification, and acquisition of zero-derivatives. 1. Introduction Treatment of lexical ambiguity such as WSD has been found useful in many NLP applications, including information retrieval (McRoy 1992; Krovetz and Croft 1992) and machine translation (Brown et al. 1991; Dagan et al. 1991; Dagan and Itai 1994). Recently, various approaches (Dolan 1994; Luk 1995; Yarowsky 1992; Dagan et al. 1991 ;Dagan and Itai 1994) to word sense division have been used in WSD research. Directly using dictionary senses as the sense division has several advantages. First, sense distinction according to a dictionary is readily available from MRDs such as the LDOCE (Longman 1992). Second, indicative words and concepts for each sense are directly available in numbered definitions and examples. Lesk (1986) demonstated that dictionary entries can be used to generate signatures of senses for WSD. However, using MRD as the knowledge source for sense division and disambiguation encounters"
W96-0305,C94-2112,0,\N,Missing
W96-0305,J94-4003,0,\N,Missing
W96-0305,A92-1011,0,\N,Missing
W96-0305,J92-1001,0,\N,Missing
Y02-1026,C88-1016,0,0.0703446,"develop the call router. One of the problems with this approach is the difference between user&apos; s colloquial vocabulary and written formal style of the material to develop the routing algorithm. In order to bridge the gap, we used an English thesaurus and bilingual dictionary to find synonyms related to the domain of telecommunication regulation. The words appearing in the organization profile written in English were extracted. Sets of English synonyms of those words were obtained in the thesaurus, Longman Lexicon of Contemporary English. Based on class-based probabilistic translation model (Brown et al. 1988), we experimented with a new approach to find compatible and appropriate translations for a group of synonymous words. Those sets (Table 3) of translations were subsequently used to expand keywords for more robust call routing. Under the statistical machine translation model (Brown et al. 1988), translation probability P(CIE) is the probability an English word E is translated into a Chinese word C. We extended the basic definition of P(CIE) to include the consideration of translation probability for a class of words. For this, we tie together the probability P(CIE) for a set of word E in a cla"
Y02-1026,O98-1007,1,0.706082,"perate the call router via a speech interface. The system transforms the natural speech, matches the information related to directory, and finally determines the routing destination. The output is then displayed on the screen for the operator to carry out the actual routing action. The goal is to assist the operator in selecting the desired destination that matches caller&apos; s intension. This will expedite operator&apos;s response since there is no need to search a printed directory or enter the query in Chinese text. Numerous previous works on call routing has been reported (Riccardi et. al., 1997; Lee et al., 1998; Chu-Carroll and Carpenter, 1999). Most approaches in the literature require a corpus of routed calls to train a routing matrix or language model. Such corpora of dialog are sometimes difficult to obtain due to the concerns over invasion of privacy right. In addition to the acoustic module, a call router also needs to classify caller&apos; s request according to routing destination. This task of classification is similar to text categorization (Lewis et al., 1996) in IR or topic identification (McDonough et al., 1994) in speech research. When a corpus of calls is available, researchers tend to ado"
Y02-1026,H91-1014,0,0.0367513,"to the concerns over invasion of privacy right. In addition to the acoustic module, a call router also needs to classify caller&apos; s request according to routing destination. This task of classification is similar to text categorization (Lewis et al., 1996) in IR or topic identification (McDonough et al., 1994) in speech research. When a corpus of calls is available, researchers tend to adopt a vector space model, under which terms in the corpus is weighted statistically and treated as independent. Many systems adopted a form-based approach that is commonly used in spoken understanding system (Seneff, Glass, and Goddeau, 1991; Lamel, 1998; Chu-Carroll, 1999; Papineni, Roukos, and Ward, 1999). A form consists of a set of keywords all (or most) of which need to be present in the caller&apos; s request in order for the destination to be activated. This idea amounts to formulating an AND query of many independent keywords. There are problems with adopting a form-based approach. Firstly, the acoustic module produces incorrect output, which may cause the IR module to fail. If we set the precision of the acoustic output too high, there could be insufficient information for the IR module to produce a destination. On the other"
Y03-1035,P02-1051,0,0.0505236,"ation (MT), cross-language information retrieval (CLIR), and bilingual lexicon construction. Proper nouns are often domain specific and frequently created. It is difficult to handle transliteration using existing bilingual dictionaries. Unfamiliar personal names, place names, and technical terms are especially difficult for human translators to transliterate correctly. In CLIR, the accuracy of transliteration greatly affects the retrieval performance. Recent studies have made great strides toward machine transliteration for many language pairs, such as English/Arabic (Stalls and Knight, 1998; Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Wan and Verspoor, 1998; Lin and Chen, 2002), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Machine transliteration is classified into two types based on transliteration direction. Transliteration, forward-direction, is the process that converts an original word in the source language into an approximate phonetic equivalent word in the target language, whereas back-transliteration, backward-direction, is the reverse process that converts the transliterated word back into its original word. Most of th"
Y03-1035,P98-1036,0,0.15261,"l (CLIR), and bilingual lexicon construction. Proper nouns are often domain specific and frequently created. It is difficult to handle transliteration using existing bilingual dictionaries. Unfamiliar personal names, place names, and technical terms are especially difficult for human translators to transliterate correctly. In CLIR, the accuracy of transliteration greatly affects the retrieval performance. Recent studies have made great strides toward machine transliteration for many language pairs, such as English/Arabic (Stalls and Knight, 1998; Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Wan and Verspoor, 1998; Lin and Chen, 2002), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Machine transliteration is classified into two types based on transliteration direction. Transliteration, forward-direction, is the process that converts an original word in the source language into an approximate phonetic equivalent word in the target language, whereas back-transliteration, backward-direction, is the reverse process that converts the transliterated word back into its original word. Most of the previous approaches require a pron"
Y03-1035,W03-0317,1,0.552583,"1 11,EAM mmaxP(CI M, E)P(M I E) maxP(C I M , E)P(M) (4) We approximate P(CIER(M) as follows: I unP(mi , m2 ,... ,m N) P(C I M, E)P(M) = f i). lP(vi u; )P(m 1 (5) Therefore, we have logP(C1 E) maxi(logP(vi 1 + logP(m)). (6) 1=1 Then, for a given C, the best source stringE can be efficiently obtained by using a dynamic programming algorithm. Using the Expectation Maximization (EM) algorithm (Dempster et al., 1977) with Viterbi decoding (Forney, 1973), we adopt the iterative parameter estimation procedure to solve the maximum likelihood estimation (MLE) problem. For more details, please refer to Lee and Chang (2003). 3 Back-transliteration The proposed transliteration model can be applied to back-transliteration. The complexity of the task increases for language pairs with different sound systems, such as Chinese/English, Japanese/English, and Arabic/English. 3.1 Similarity-based Framework There are several approaches to back-transliteration, such as the generative framework, similarity-based framework, and rule-based framework. As stated by Lin and Chen (2002), the similarity-based approach works better because it directly addresses the problem of similarity measurement between the source word and the t"
Y03-1035,W02-2017,0,0.662963,"n. Proper nouns are often domain specific and frequently created. It is difficult to handle transliteration using existing bilingual dictionaries. Unfamiliar personal names, place names, and technical terms are especially difficult for human translators to transliterate correctly. In CLIR, the accuracy of transliteration greatly affects the retrieval performance. Recent studies have made great strides toward machine transliteration for many language pairs, such as English/Arabic (Stalls and Knight, 1998; Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Wan and Verspoor, 1998; Lin and Chen, 2002), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Machine transliteration is classified into two types based on transliteration direction. Transliteration, forward-direction, is the process that converts an original word in the source language into an approximate phonetic equivalent word in the target language, whereas back-transliteration, backward-direction, is the reverse process that converts the transliterated word back into its original word. Most of the previous approaches require a pronunciation dictionary to convert a source word"
Y03-1035,C02-1099,0,0.0713324,"on using existing bilingual dictionaries. Unfamiliar personal names, place names, and technical terms are especially difficult for human translators to transliterate correctly. In CLIR, the accuracy of transliteration greatly affects the retrieval performance. Recent studies have made great strides toward machine transliteration for many language pairs, such as English/Arabic (Stalls and Knight, 1998; Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Wan and Verspoor, 1998; Lin and Chen, 2002), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Machine transliteration is classified into two types based on transliteration direction. Transliteration, forward-direction, is the process that converts an original word in the source language into an approximate phonetic equivalent word in the target language, whereas back-transliteration, backward-direction, is the reverse process that converts the transliterated word back into its original word. Most of the previous approaches require a pronunciation dictionary to convert a source word into its corresponding pronunciation sequence. Words with unknown pronunciations may cause problem for"
Y03-1035,W98-1005,0,0.111887,"g, such as machine translation (MT), cross-language information retrieval (CLIR), and bilingual lexicon construction. Proper nouns are often domain specific and frequently created. It is difficult to handle transliteration using existing bilingual dictionaries. Unfamiliar personal names, place names, and technical terms are especially difficult for human translators to transliterate correctly. In CLIR, the accuracy of transliteration greatly affects the retrieval performance. Recent studies have made great strides toward machine transliteration for many language pairs, such as English/Arabic (Stalls and Knight, 1998; Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Wan and Verspoor, 1998; Lin and Chen, 2002), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Machine transliteration is classified into two types based on transliteration direction. Transliteration, forward-direction, is the process that converts an original word in the source language into an approximate phonetic equivalent word in the target language, whereas back-transliteration, backward-direction, is the reverse process that converts the transliterated word back into"
Y03-1035,voorhees-tice-2000-trec,0,0.0198087,"Missing"
Y03-1035,P98-2220,0,0.130367,"gual lexicon construction. Proper nouns are often domain specific and frequently created. It is difficult to handle transliteration using existing bilingual dictionaries. Unfamiliar personal names, place names, and technical terms are especially difficult for human translators to transliterate correctly. In CLIR, the accuracy of transliteration greatly affects the retrieval performance. Recent studies have made great strides toward machine transliteration for many language pairs, such as English/Arabic (Stalls and Knight, 1998; Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Wan and Verspoor, 1998; Lin and Chen, 2002), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Machine transliteration is classified into two types based on transliteration direction. Transliteration, forward-direction, is the process that converts an original word in the source language into an approximate phonetic equivalent word in the target language, whereas back-transliteration, backward-direction, is the reverse process that converts the transliterated word back into its original word. Most of the previous approaches require a pronunciation dictionary to"
Y03-1035,C98-1036,0,\N,Missing
Y03-1035,C98-2215,0,\N,Missing
Y03-1035,J98-4003,0,\N,Missing
Y09-1009,E06-1002,0,0.0522272,"ized in Medelyan et al. (2009), a survey paper that provides an in-depth description of the creation process and textual structure of Wikipedia pages, and review diverse effort that exploits Wikipedia in many research areas: word sense disambiguation (Mihalcea and Csomai, 2007; Ruiz-Casado et al., 2005; Wu and Weld, 2007), bilingual lexicography (Erdmann et al., 2008; Tyers and Pienaar, 2008), multilingual information retrieval (Potthast et al., 2008), information extraction and question answering (Banko et al., 2007; Toral and Muñoz, 2007; Ferrández et al., 2007), named entities recognition (Bunescu and Paşca, 2006; Cimiano and Volker, 2005; Dakka and Cucerzan, 2007), and ontology construction (Auer et al. 2007; Ponzetto and Strube, 2007; Suchanek et al., 2007). In our work we address a specific knowledge mining problem of identifying and categorizing named entities that appear as the titles in Wikipedia (e.g., identifying and categorizing John Updike and Terrorist as named entities of the types PERSON and COMMUNICATION). In the work on mining meaning from Wikipedia, the most closely related body of research to our work focuses on word sense disambiguation of Wikipedia titles, words and phrases. 75 Miha"
Y09-1009,D07-1074,0,0.0309835,"an in-depth description of the creation process and textual structure of Wikipedia pages, and review diverse effort that exploits Wikipedia in many research areas: word sense disambiguation (Mihalcea and Csomai, 2007; Ruiz-Casado et al., 2005; Wu and Weld, 2007), bilingual lexicography (Erdmann et al., 2008; Tyers and Pienaar, 2008), multilingual information retrieval (Potthast et al., 2008), information extraction and question answering (Banko et al., 2007; Toral and Muñoz, 2007; Ferrández et al., 2007), named entities recognition (Bunescu and Paşca, 2006; Cimiano and Volker, 2005; Dakka and Cucerzan, 2007), and ontology construction (Auer et al. 2007; Ponzetto and Strube, 2007; Suchanek et al., 2007). In our work we address a specific knowledge mining problem of identifying and categorizing named entities that appear as the titles in Wikipedia (e.g., identifying and categorizing John Updike and Terrorist as named entities of the types PERSON and COMMUNICATION). In the work on mining meaning from Wikipedia, the most closely related body of research to our work focuses on word sense disambiguation of Wikipedia titles, words and phrases. 75 Mihalcea (2007) considers the same title (e.g., bar) with"
Y09-1009,I08-1071,0,0.384982,"Missing"
Y09-1009,H05-1059,0,0.0373418,"Missing"
Y09-1022,P97-1023,0,0.0790702,"Missing"
Y09-1022,W02-1011,0,0.0580528,"words (in terms of polarity directions and intensities), especially adjectives, which are good indicators of subjective statements (Hatzivassiloglou and Mckeown, 1997; Hatzivassiloglou and Wiebe, 2000; Wiebe, 2000; Turney and Littman, 2003). Some, however, focuses on identifying the sentiments of collocations (Wiebe et al., 2001), of phrases containing adjectives and adverbs (Turney, 2002), and of phrases marked with polarity (Wilson et al., 2005). Past research utilizes lexicons (hand crafted in (Huettner and Subasic, 2000) and automatically mined in (Yang et al., 2007a)) or n-gram features (Pang et al., 2002) in automatic 201 analysis on documents’ sentiments, such as sentiment categorization of reviews or mood classification of Web blogs. The sentiment classification of documents may be approached by first analyzing their sentences’ semantic orientations (Yang et al., 2007b) or sequential sentiments of their sentences (Mao and Lebanon, 2006) or by treating the sentences within as a whole (Mishne, 2005). In this paper, the goal of our model is to automatically classify reviews into five sentiment ratings using article-level surface n-gram and semantic word-class features. At run-time, we further l"
Y09-1022,P02-1053,0,0.0623809,"l favorability or unfavorability for them. In terms of marketing, damage control, and risk management, it is of great importance. Some of the research on sentiment analysis focuses on predicting semantic orientations for words (in terms of polarity directions and intensities), especially adjectives, which are good indicators of subjective statements (Hatzivassiloglou and Mckeown, 1997; Hatzivassiloglou and Wiebe, 2000; Wiebe, 2000; Turney and Littman, 2003). Some, however, focuses on identifying the sentiments of collocations (Wiebe et al., 2001), of phrases containing adjectives and adverbs (Turney, 2002), and of phrases marked with polarity (Wilson et al., 2005). Past research utilizes lexicons (hand crafted in (Huettner and Subasic, 2000) and automatically mined in (Yang et al., 2007a)) or n-gram features (Pang et al., 2002) in automatic 201 analysis on documents’ sentiments, such as sentiment categorization of reviews or mood classification of Web blogs. The sentiment classification of documents may be approached by first analyzing their sentences’ semantic orientations (Yang et al., 2007b) or sequential sentiments of their sentences (Mao and Lebanon, 2006) or by treating the sentences with"
Y09-1022,H05-1044,0,0.0192465,"of marketing, damage control, and risk management, it is of great importance. Some of the research on sentiment analysis focuses on predicting semantic orientations for words (in terms of polarity directions and intensities), especially adjectives, which are good indicators of subjective statements (Hatzivassiloglou and Mckeown, 1997; Hatzivassiloglou and Wiebe, 2000; Wiebe, 2000; Turney and Littman, 2003). Some, however, focuses on identifying the sentiments of collocations (Wiebe et al., 2001), of phrases containing adjectives and adverbs (Turney, 2002), and of phrases marked with polarity (Wilson et al., 2005). Past research utilizes lexicons (hand crafted in (Huettner and Subasic, 2000) and automatically mined in (Yang et al., 2007a)) or n-gram features (Pang et al., 2002) in automatic 201 analysis on documents’ sentiments, such as sentiment categorization of reviews or mood classification of Web blogs. The sentiment classification of documents may be approached by first analyzing their sentences’ semantic orientations (Yang et al., 2007b) or sequential sentiments of their sentences (Mao and Lebanon, 2006) or by treating the sentences within as a whole (Mishne, 2005). In this paper, the goal of ou"
Y09-1022,P07-2034,0,0.154814,"on predicting semantic orientations for words (in terms of polarity directions and intensities), especially adjectives, which are good indicators of subjective statements (Hatzivassiloglou and Mckeown, 1997; Hatzivassiloglou and Wiebe, 2000; Wiebe, 2000; Turney and Littman, 2003). Some, however, focuses on identifying the sentiments of collocations (Wiebe et al., 2001), of phrases containing adjectives and adverbs (Turney, 2002), and of phrases marked with polarity (Wilson et al., 2005). Past research utilizes lexicons (hand crafted in (Huettner and Subasic, 2000) and automatically mined in (Yang et al., 2007a)) or n-gram features (Pang et al., 2002) in automatic 201 analysis on documents’ sentiments, such as sentiment categorization of reviews or mood classification of Web blogs. The sentiment classification of documents may be approached by first analyzing their sentences’ semantic orientations (Yang et al., 2007b) or sequential sentiments of their sentences (Mao and Lebanon, 2006) or by treating the sentences within as a whole (Mishne, 2005). In this paper, the goal of our model is to automatically classify reviews into five sentiment ratings using article-level surface n-gram and semantic word"
Y09-1022,C00-1044,0,\N,Missing
Y09-1040,P94-1020,0,0.0975969,"del can be used to broaden the scope of an existing bilingual WordNet. Alternatively, our model can be embedded into machine translation (MT) systems in order to help choose more appropriate word translations. 2 Related Work Word Sense Disambiguation (WSD) has been an area of active research. WSD is to determine the meaning of a word in current context, which is an important component in language understanding or MT systems. WSD models have been developed using machine learning techniques. They may train on sets of sense-annotated data for predefined words (Hearst, 1991; Leacock et al., 1993; Bruce and Wiebe, 1994). To avoid the labor-intensive and time-consuming process of sense-tagging, Yarowsky (1995) propose a semi-supervised model to bootstrap from raw data based on some confident and unambiguous seeds. 1 With respect to the sense disambiguation task. 376 Another direction is to base WSD models on dictionaries or lexical semantic knowledge resources. Lesk (1986) is the first to leverage the definitions of words in machine readable dictionaries to predict word senses. On the other hand, WordNet, a valuable knowledge source encoded with hyponym, hypernym, and synonym semantic relations, is used to me"
Y09-1040,O03-5003,1,0.67706,"disambiguation (WTD), aimed at improving word selection in MT, has been proved to have positive influence on bilingual application like statistical MT systems (Chan et al., 2007; Carpuat and Wu, 2007). In our work, word senses are assigned to given translations, which is the opposite of WTD, choosing translations for senses, in view of extending the translation coverage of an existing bilingual WordNet such as Sinica Bilingual Ontological WordNet (Huang et al., 2004), Sinica BOW for short. Such bilingual WordNet may be constructed manually by translation (Huang et al., 2004) or automatically (Chang et al., 2003). Our work can be thought of as (Chang et al., 2003)’s follow-up research which enriches the translations in bilingual WordNet. 3 3.1 Hierarchical Word Translation Classification Problem Statement We focus on the essential step of extending bilingual WordNet: determining the appropriate word senses for unseen translation pairs from bilingual knowledge resources (e.g., dictionaries or phrase tables). Using bilingual WordNet which provides a hierarchical structure on tree nodes (i.e., synsets) and translations, we train a classifier at each branching node that estimates associations between give"
Y09-1040,P02-1033,0,0.0326223,"se disambiguation (Agirre and Rigau, 1996; Galley and McKeown, 2003). An interesting approach presented by Mihalcea (2005) describes how to apply a graph-based algorithm (i.e., random walk algorithm) and WordNet semantic relations to solve all-word WSD task. Recently, WSD not only has been approached from bilingual perspective, but has been applied to bilingual applications. Li and Li (2002) introduce “bilingual bootstrapping” making use of a small number of sense-annotated data to further bootstrap two languages’ discerning or effective context words in disambiguation. Gale et al. (1992) and Diab and Resnik (2002) also leverage bilingual information in WSD. WSD or word translation disambiguation (WTD), aimed at improving word selection in MT, has been proved to have positive influence on bilingual application like statistical MT systems (Chan et al., 2007; Carpuat and Wu, 2007). In our work, word senses are assigned to given translations, which is the opposite of WTD, choosing translations for senses, in view of extending the translation coverage of an existing bilingual WordNet such as Sinica Bilingual Ontological WordNet (Huang et al., 2004), Sinica BOW for short. Such bilingual WordNet may be constr"
Y09-1040,H93-1051,0,0.0179883,"ses provided by our model can be used to broaden the scope of an existing bilingual WordNet. Alternatively, our model can be embedded into machine translation (MT) systems in order to help choose more appropriate word translations. 2 Related Work Word Sense Disambiguation (WSD) has been an area of active research. WSD is to determine the meaning of a word in current context, which is an important component in language understanding or MT systems. WSD models have been developed using machine learning techniques. They may train on sets of sense-annotated data for predefined words (Hearst, 1991; Leacock et al., 1993; Bruce and Wiebe, 1994). To avoid the labor-intensive and time-consuming process of sense-tagging, Yarowsky (1995) propose a semi-supervised model to bootstrap from raw data based on some confident and unambiguous seeds. 1 With respect to the sense disambiguation task. 376 Another direction is to base WSD models on dictionaries or lexical semantic knowledge resources. Lesk (1986) is the first to leverage the definitions of words in machine readable dictionaries to predict word senses. On the other hand, WordNet, a valuable knowledge source encoded with hyponym, hypernym, and synonym semantic"
Y09-1040,P02-1044,0,0.0236572,"ctionaries to predict word senses. On the other hand, WordNet, a valuable knowledge source encoded with hyponym, hypernym, and synonym semantic relations, is used to measure semantic distances among word senses to help sense disambiguation (Agirre and Rigau, 1996; Galley and McKeown, 2003). An interesting approach presented by Mihalcea (2005) describes how to apply a graph-based algorithm (i.e., random walk algorithm) and WordNet semantic relations to solve all-word WSD task. Recently, WSD not only has been approached from bilingual perspective, but has been applied to bilingual applications. Li and Li (2002) introduce “bilingual bootstrapping” making use of a small number of sense-annotated data to further bootstrap two languages’ discerning or effective context words in disambiguation. Gale et al. (1992) and Diab and Resnik (2002) also leverage bilingual information in WSD. WSD or word translation disambiguation (WTD), aimed at improving word selection in MT, has been proved to have positive influence on bilingual application like statistical MT systems (Chan et al., 2007; Carpuat and Wu, 2007). In our work, word senses are assigned to given translations, which is the opposite of WTD, choosing t"
Y09-1040,H05-1052,0,0.0127682,"ome confident and unambiguous seeds. 1 With respect to the sense disambiguation task. 376 Another direction is to base WSD models on dictionaries or lexical semantic knowledge resources. Lesk (1986) is the first to leverage the definitions of words in machine readable dictionaries to predict word senses. On the other hand, WordNet, a valuable knowledge source encoded with hyponym, hypernym, and synonym semantic relations, is used to measure semantic distances among word senses to help sense disambiguation (Agirre and Rigau, 1996; Galley and McKeown, 2003). An interesting approach presented by Mihalcea (2005) describes how to apply a graph-based algorithm (i.e., random walk algorithm) and WordNet semantic relations to solve all-word WSD task. Recently, WSD not only has been approached from bilingual perspective, but has been applied to bilingual applications. Li and Li (2002) introduce “bilingual bootstrapping” making use of a small number of sense-annotated data to further bootstrap two languages’ discerning or effective context words in disambiguation. Gale et al. (1992) and Diab and Resnik (2002) also leverage bilingual information in WSD. WSD or word translation disambiguation (WTD), aimed at"
Y09-1040,P95-1026,0,0.0793378,"n be embedded into machine translation (MT) systems in order to help choose more appropriate word translations. 2 Related Work Word Sense Disambiguation (WSD) has been an area of active research. WSD is to determine the meaning of a word in current context, which is an important component in language understanding or MT systems. WSD models have been developed using machine learning techniques. They may train on sets of sense-annotated data for predefined words (Hearst, 1991; Leacock et al., 1993; Bruce and Wiebe, 1994). To avoid the labor-intensive and time-consuming process of sense-tagging, Yarowsky (1995) propose a semi-supervised model to bootstrap from raw data based on some confident and unambiguous seeds. 1 With respect to the sense disambiguation task. 376 Another direction is to base WSD models on dictionaries or lexical semantic knowledge resources. Lesk (1986) is the first to leverage the definitions of words in machine readable dictionaries to predict word senses. On the other hand, WordNet, a valuable knowledge source encoded with hyponym, hypernym, and synonym semantic relations, is used to measure semantic distances among word senses to help sense disambiguation (Agirre and Rigau,"
Y09-1040,C96-1005,0,\N,Missing
Y09-1040,D07-1007,0,\N,Missing
Y09-1040,P07-1005,0,\N,Missing
Y10-1040,H05-1098,0,0.012239,"ond language learners have difficulties choosing the right prepositions, we would like to include prepositional words into grammatical patterns. For queries “play role”, “have impact”, and “exert influence”, the patterns lexicalized on prepositional PoS tags look like “play role+IN(in) DT”, “have impact+IN(on) NN”, and “exert influence+IN(on) NN” where collocating prepositions are shown in parentheses. Such lexicalized grammar patterns if accompanied with target-language translations may be helpful not only for language learners but for syntax-based machine translation systems, such as Hiero (Chiang et al., 2005). 9 Include the 15 test items. The “B” stands for the beginning of a phrase constituent. 10 363 364 Poster Papers We would also like to construct a cross-lingual GRASP system in which it accepts query terms in second language learners’ mother tongue and returns grammatical patterns of their suitable translations. For example, for the first-language query “打擊 犯罪” (fight crime), the cross-lingual GRASP would provide organized grammatical patterns (as described in this paper) of its English translations such as “fight crimes”, “combat crimes”, “crack down on crimes” and etc. Language learners may"
Y10-1040,P04-3019,1,0.71347,"onal behavior by displaying example sentences. Word Sketch Engine (Kilgarriff et al., 2004), a famous concordancer, has been used in language learning and in the production of the Macmillan English Dictionary. On the other hand, concordancers may be implemented with cross-lingual information (e.g., translations3). Researchers have long considered collocations essential and helpful in language learning and sentence composition (Benson, 1985; Benson et al., 1986; Lewis, 2000; Nation, 2001; Liu, 2002; Nesselhauf, 2003; Chen, 2009; Chen and Lin, 2009; Durrant, 2009). While services such as TANGO (Jian et al., 2004) and MUST (Chang et al., 2008) assist learners in collocation finding and collocation correcting, learners may still have problems putting a collocation or a phrase in sentences. In this paper, rather than solely returning an overwhelming chuck of sentences with the query collocation/phrase (Cheng et al., 2006), we impose an grammatically-motivated thesaurus structure on its context in view of speeding up the process of language learning and lexicography. 3 3.1 The GRASP System Problem Statement We focus on providing language learners a means to quickly grasp representative usage of their sear"
Y10-1040,N03-1017,0,0.0270509,"Missing"
Y10-1040,P95-1026,0,0.203312,"NGO typically accept only one querying word and retrieve sentences with it or words it co-occurring probabilistically more frequently than usual. However, learners may attempt to learn the usage of a certain word sense of the query word. Consider the polysemy “play”. In WordNet, it has a myriad of senses including ‘participating in games or sport’, ‘act or having an effect in a specified way’ and ‘play on an instrument’. Learners may be aware of its senses but intend to acquire more knowledge on the context or usage of the word sense ‘act or having an effect in a specified way’. Suggested by (Yarowsky, 1995), accompanying “play” with its collocate “role” is a good way to narrow down 1 2 candle.fl.nthu.edu.tw/collocation/webform2.aspx candle.fl.nthu.edu.tw/vntango/ 357 358 Poster Papers the senses of “play” (and vice versa). Therefore, multi-word query might be as important in language learning. However, the best response to the multi-word query “play role” is probably not an overwhelming set of sentences with it which may be returned by general-purpose concordancers and search engines (e.g., Google). A good response might indicate that the collocation “play role” is frequently followed by the gra"
Y14-1034,P03-1012,0,0.0481514,"ent dotplot (see figure on the right) 抵達 德黑蘭 Note that the dark cells represent links in the 後 intersection of two alignments, while the gray 發表 cells represent links in the rest of the union 這 項 談話 。 . Figure 2: An example TakeTwo session and results IBM models, which has since become the tool of choice for developing SMT systems. As an alternative to the EM algorithm, researchers have been exploring various knowledge sources for word alignment, using automatically derived lexicons or handcrafted dictionaries (Gale and Church, 1991; Ker and Chang, 1997), or syntactic structure (Gildea, 2003; Cherry and Lin, 2003; Wang and Zong, 2013). There has been work on translating phrases using mixed-code web-pages (e.g., (Nagata et al., 2001; Wu and Chang, 2007)). Similarly, (Lin et al., 2008) propose a method that performs word alignment for parenthetic translation phrases to improve the performance of SMT systems. Researchers have also studied sublexical models for machine transliteration (Knight and Graehl, 1998). More recently, (Chang et al., 2012) introduce a method for learning a CRF model to find translations and transliterations of technical terms on the Web. We use similar transliteration-based feature"
Y14-1034,J90-2002,0,0.478876,"keTwo with those produced by Giza++ with GDFA (Section 4 and Section 5) over a set of parallel sentences with hand-annotated word alignment. 2 Related Work Machine translation (MT) has been an area of active research. (Dorr, 1993) summarizes various approaches to MT, while (Lopez, 2007) surveys recent work on statistical machine translation (SMT). We focus on the first part of developing an SMT system, namely, aligning words in a given parallel corpus. The state of the art in word alignment focuses on automatically learning generative translation models via Expectation Maximization algorithm (Brown et al., 1990; Brown et al., 1993). (Och and Ney, 2003) describe Giza++, an implementation of the !283 PACLIC 28 Input: ... He made this remark after Heinonen arrived in Tehran. ÷ / ( w˛Á µT ∑—- å |h ⇡ ⇧ «q ⇥ ... Initial word alignments in two directions (En-Ch and Ch-En): he(÷) made this remark(/) after(( å) heinonen(w˛Á |h ⇧ «q) arrived(µT) in tehran(∑—-) ÷(he) / ( w˛Á(remark heinonen) µT(arrive in) ∑—-(tehran) å(after) |h(made) ⇡(this) ⇧ «q Crosslingual relatedness: ra n a rk s th i he(÷) made(|h) this(⇡) remark(«q) ma he de Output: = .25 . = sim(remark, talk) te h x-sim(remark, «q) in o ne n a rr ive d"
Y14-1034,J93-2003,0,0.0501737,"duced by Giza++ with GDFA (Section 4 and Section 5) over a set of parallel sentences with hand-annotated word alignment. 2 Related Work Machine translation (MT) has been an area of active research. (Dorr, 1993) summarizes various approaches to MT, while (Lopez, 2007) surveys recent work on statistical machine translation (SMT). We focus on the first part of developing an SMT system, namely, aligning words in a given parallel corpus. The state of the art in word alignment focuses on automatically learning generative translation models via Expectation Maximization algorithm (Brown et al., 1990; Brown et al., 1993). (Och and Ney, 2003) describe Giza++, an implementation of the !283 PACLIC 28 Input: ... He made this remark after Heinonen arrived in Tehran. ÷ / ( w˛Á µT ∑—- å |h ⇡ ⇧ «q ⇥ ... Initial word alignments in two directions (En-Ch and Ch-En): he(÷) made this remark(/) after(( å) heinonen(w˛Á |h ⇧ «q) arrived(µT) in tehran(∑—-) ÷(he) / ( w˛Á(remark heinonen) µT(arrive in) ∑—-(tehran) å(after) |h(made) ⇡(this) ⇧ «q Crosslingual relatedness: ra n a rk s th i he(÷) made(|h) this(⇡) remark(«q) ma he de Output: = .25 . = sim(remark, talk) te h x-sim(remark, «q) in o ne n a rr ive d in = sim(make, publi"
Y14-1034,P12-2026,1,0.857078,"alignment, using automatically derived lexicons or handcrafted dictionaries (Gale and Church, 1991; Ker and Chang, 1997), or syntactic structure (Gildea, 2003; Cherry and Lin, 2003; Wang and Zong, 2013). There has been work on translating phrases using mixed-code web-pages (e.g., (Nagata et al., 2001; Wu and Chang, 2007)). Similarly, (Lin et al., 2008) propose a method that performs word alignment for parenthetic translation phrases to improve the performance of SMT systems. Researchers have also studied sublexical models for machine transliteration (Knight and Graehl, 1998). More recently, (Chang et al., 2012) introduce a method for learning a CRF model to find translations and transliterations of technical terms on the Web. We use similar transliteration-based features derived from transliteration model in a different setting. Word alignment is closely related to measuring word similarity, and especially in the form of crosslingual relatedness. Much work has been done on word similarity and crosslingual relatedness. Early research efforts have been devoted to design the knowledge-based measures, based, in particular, on WordNet (Fellbaum, 1999). Researchers have extensively investigated WordNet an"
Y14-1034,P06-2014,0,0.0227388,"is that previous methods use manually labeled data (typically hundreds sentences with thousands of word-translation relations) to train a word alignment model. In contrast, we take a self learning approach and automatically generate labelled training data. More specifically, We train our model based on a much larger training set (hundred of thousand of word-translation instances in partially labeled sentences) based on self learning. Recently, some researchers have begun using syntax in word alignment, by incorporating features such as inversion transduction grammar or parse tree. Supervised (Cherry and Lin, 2006; Setiawan et al., 2010) and unsupervised (Pauls et al., 2010) methods have been proposed, showing that syntax can improve alignment performance. All these features can be used to training the classifier used in TakeTwo. In a word alignment approach closer to our method, (Deng and Zhou, 2009) propose a method to optimize word alignment combination to derive a more effective phrase table. Similarly, (Nakov and Tiedemann, 2012) propose combining word-level and character-Level alignment models for improving machine translation between two closely-related languages. In contrast to the previous res"
Y14-1034,P09-2058,0,0.0148143,"l based on a much larger training set (hundred of thousand of word-translation instances in partially labeled sentences) based on self learning. Recently, some researchers have begun using syntax in word alignment, by incorporating features such as inversion transduction grammar or parse tree. Supervised (Cherry and Lin, 2006; Setiawan et al., 2010) and unsupervised (Pauls et al., 2010) methods have been proposed, showing that syntax can improve alignment performance. All these features can be used to training the classifier used in TakeTwo. In a word alignment approach closer to our method, (Deng and Zhou, 2009) propose a method to optimize word alignment combination to derive a more effective phrase table. Similarly, (Nakov and Tiedemann, 2012) propose combining word-level and character-Level alignment models for improving machine translation between two closely-related languages. In contrast to the previous research in word alignment, we present a system that automatically generates instances of word-translation relations based on self learning, with the goal of training a model to estimate translation probability for effective word alignment. We exploit the inherent crosslingual regularity in para"
Y14-1034,H91-1026,0,0.540468,"rk, /) 他 after(å) heinonen(w˛Á) arrived(µT) in(µT) 是 tehran(∑—-) . (⇥) 在 海諾寧 Alignment dotplot (see figure on the right) 抵達 德黑蘭 Note that the dark cells represent links in the 後 intersection of two alignments, while the gray 發表 cells represent links in the rest of the union 這 項 談話 。 . Figure 2: An example TakeTwo session and results IBM models, which has since become the tool of choice for developing SMT systems. As an alternative to the EM algorithm, researchers have been exploring various knowledge sources for word alignment, using automatically derived lexicons or handcrafted dictionaries (Gale and Church, 1991; Ker and Chang, 1997), or syntactic structure (Gildea, 2003; Cherry and Lin, 2003; Wang and Zong, 2013). There has been work on translating phrases using mixed-code web-pages (e.g., (Nagata et al., 2001; Wu and Chang, 2007)). Similarly, (Lin et al., 2008) propose a method that performs word alignment for parenthetic translation phrases to improve the performance of SMT systems. Researchers have also studied sublexical models for machine transliteration (Knight and Graehl, 1998). More recently, (Chang et al., 2012) introduce a method for learning a CRF model to find translations and transliter"
Y14-1034,P03-1011,0,0.0537433,") 在 海諾寧 Alignment dotplot (see figure on the right) 抵達 德黑蘭 Note that the dark cells represent links in the 後 intersection of two alignments, while the gray 發表 cells represent links in the rest of the union 這 項 談話 。 . Figure 2: An example TakeTwo session and results IBM models, which has since become the tool of choice for developing SMT systems. As an alternative to the EM algorithm, researchers have been exploring various knowledge sources for word alignment, using automatically derived lexicons or handcrafted dictionaries (Gale and Church, 1991; Ker and Chang, 1997), or syntactic structure (Gildea, 2003; Cherry and Lin, 2003; Wang and Zong, 2013). There has been work on translating phrases using mixed-code web-pages (e.g., (Nagata et al., 2001; Wu and Chang, 2007)). Similarly, (Lin et al., 2008) propose a method that performs word alignment for parenthetic translation phrases to improve the performance of SMT systems. Researchers have also studied sublexical models for machine transliteration (Knight and Graehl, 1998). More recently, (Chang et al., 2012) introduce a method for learning a CRF model to find translations and transliterations of technical terms on the Web. We use similar transli"
Y14-1034,J97-2004,1,0.619041,"nen(w˛Á) arrived(µT) in(µT) 是 tehran(∑—-) . (⇥) 在 海諾寧 Alignment dotplot (see figure on the right) 抵達 德黑蘭 Note that the dark cells represent links in the 後 intersection of two alignments, while the gray 發表 cells represent links in the rest of the union 這 項 談話 。 . Figure 2: An example TakeTwo session and results IBM models, which has since become the tool of choice for developing SMT systems. As an alternative to the EM algorithm, researchers have been exploring various knowledge sources for word alignment, using automatically derived lexicons or handcrafted dictionaries (Gale and Church, 1991; Ker and Chang, 1997), or syntactic structure (Gildea, 2003; Cherry and Lin, 2003; Wang and Zong, 2013). There has been work on translating phrases using mixed-code web-pages (e.g., (Nagata et al., 2001; Wu and Chang, 2007)). Similarly, (Lin et al., 2008) propose a method that performs word alignment for parenthetic translation phrases to improve the performance of SMT systems. Researchers have also studied sublexical models for machine transliteration (Knight and Graehl, 1998). More recently, (Chang et al., 2012) introduce a method for learning a CRF model to find translations and transliterations of technical te"
Y14-1034,P08-1113,0,0.0391384,"Missing"
Y14-1034,P98-2127,0,0.0241249,"the Web. We use similar transliteration-based features derived from transliteration model in a different setting. Word alignment is closely related to measuring word similarity, and especially in the form of crosslingual relatedness. Much work has been done on word similarity and crosslingual relatedness. Early research efforts have been devoted to design the knowledge-based measures, based, in particular, on WordNet (Fellbaum, 1999). Researchers have extensively investigated WordNet and other taxonomic structure in an attempt to calculate the word similarity by counting conceptual distance (Lin, 1998b). On the other hand, there has been much work on distributional word similarity, for example, (Lin, !284 PACLIC 28 1998a). In the area of cross-lingual relatedness, (Michelbacher et al., 2010) present a graph-based method for building a a cross-lingual thesaurus. The method uses two monolingual corpora and a basic dictionary to build two monolingual word graphs, with nodes representing words and edges representing linguistic relations between words. In the research area of supervised training for word alignment, (Moore, 2005) demonstrates that a discriminative model with the main feature of"
Y14-1034,P05-1057,0,0.0229715,"present a graph-based method for building a a cross-lingual thesaurus. The method uses two monolingual corpora and a basic dictionary to build two monolingual word graphs, with nodes representing words and edges representing linguistic relations between words. In the research area of supervised training for word alignment, (Moore, 2005) demonstrates that a discriminative model with the main feature of Log Likelihood Ratio (LLR) could result in a smaller model comparable to more complex generative EM models in alignment accuracy. (Taskar et al., 2005) independently propose a similar approach. (Liu et al., 2005) also propose a log-linear model incorporating features (alignment probability, POS correspondence and bilingual dictionary coverage). The main difference from our current work is that previous methods use manually labeled data (typically hundreds sentences with thousands of word-translation relations) to train a word alignment model. In contrast, we take a self learning approach and automatically generate labelled training data. More specifically, We train our model based on a much larger training set (hundred of thousand of word-translation instances in partially labeled sentences) based on"
Y14-1034,2007.mtsummit-tutorials.1,0,0.0290391,"and fill in valid links [made, |h] and [remark, «q], leading to an improved alignment. The rest of the paper is organized as follows. We review the related work in the next section. Then we present our method for TakeTwo (Section 3). To evaluate the performance of TakeTwo, we compare the quality of alignments produced by TakeTwo with those produced by Giza++ with GDFA (Section 4 and Section 5) over a set of parallel sentences with hand-annotated word alignment. 2 Related Work Machine translation (MT) has been an area of active research. (Dorr, 1993) summarizes various approaches to MT, while (Lopez, 2007) surveys recent work on statistical machine translation (SMT). We focus on the first part of developing an SMT system, namely, aligning words in a given parallel corpus. The state of the art in word alignment focuses on automatically learning generative translation models via Expectation Maximization algorithm (Brown et al., 1990; Brown et al., 1993). (Och and Ney, 2003) describe Giza++, an implementation of the !283 PACLIC 28 Input: ... He made this remark after Heinonen arrived in Tehran. ÷ / ( w˛Á µT ∑—- å |h ⇡ ⇧ «q ⇥ ... Initial word alignments in two directions (En-Ch and Ch-En): he(÷) ma"
Y14-1034,H05-1011,0,0.0219792,"mpt to calculate the word similarity by counting conceptual distance (Lin, 1998b). On the other hand, there has been much work on distributional word similarity, for example, (Lin, !284 PACLIC 28 1998a). In the area of cross-lingual relatedness, (Michelbacher et al., 2010) present a graph-based method for building a a cross-lingual thesaurus. The method uses two monolingual corpora and a basic dictionary to build two monolingual word graphs, with nodes representing words and edges representing linguistic relations between words. In the research area of supervised training for word alignment, (Moore, 2005) demonstrates that a discriminative model with the main feature of Log Likelihood Ratio (LLR) could result in a smaller model comparable to more complex generative EM models in alignment accuracy. (Taskar et al., 2005) independently propose a similar approach. (Liu et al., 2005) also propose a log-linear model incorporating features (alignment probability, POS correspondence and bilingual dictionary coverage). The main difference from our current work is that previous methods use manually labeled data (typically hundreds sentences with thousands of word-translation relations) to train a word a"
Y14-1034,W01-1413,0,0.0103124,"nts, while the gray 發表 cells represent links in the rest of the union 這 項 談話 。 . Figure 2: An example TakeTwo session and results IBM models, which has since become the tool of choice for developing SMT systems. As an alternative to the EM algorithm, researchers have been exploring various knowledge sources for word alignment, using automatically derived lexicons or handcrafted dictionaries (Gale and Church, 1991; Ker and Chang, 1997), or syntactic structure (Gildea, 2003; Cherry and Lin, 2003; Wang and Zong, 2013). There has been work on translating phrases using mixed-code web-pages (e.g., (Nagata et al., 2001; Wu and Chang, 2007)). Similarly, (Lin et al., 2008) propose a method that performs word alignment for parenthetic translation phrases to improve the performance of SMT systems. Researchers have also studied sublexical models for machine transliteration (Knight and Graehl, 1998). More recently, (Chang et al., 2012) introduce a method for learning a CRF model to find translations and transliterations of technical terms on the Web. We use similar transliteration-based features derived from transliteration model in a different setting. Word alignment is closely related to measuring word similari"
Y14-1034,P12-2059,0,0.0241581,"self learning. Recently, some researchers have begun using syntax in word alignment, by incorporating features such as inversion transduction grammar or parse tree. Supervised (Cherry and Lin, 2006; Setiawan et al., 2010) and unsupervised (Pauls et al., 2010) methods have been proposed, showing that syntax can improve alignment performance. All these features can be used to training the classifier used in TakeTwo. In a word alignment approach closer to our method, (Deng and Zhou, 2009) propose a method to optimize word alignment combination to derive a more effective phrase table. Similarly, (Nakov and Tiedemann, 2012) propose combining word-level and character-Level alignment models for improving machine translation between two closely-related languages. In contrast to the previous research in word alignment, we present a system that automatically generates instances of word-translation relations based on self learning, with the goal of training a model to estimate translation probability for effective word alignment. We exploit the inherent crosslingual regularity in parallel corpora and use automatically annotated data for training a discriminative model. 3 The TakeTwo Aligner Aligning words and translat"
Y14-1034,J03-1002,0,0.0191785,"DFA (Section 4 and Section 5) over a set of parallel sentences with hand-annotated word alignment. 2 Related Work Machine translation (MT) has been an area of active research. (Dorr, 1993) summarizes various approaches to MT, while (Lopez, 2007) surveys recent work on statistical machine translation (SMT). We focus on the first part of developing an SMT system, namely, aligning words in a given parallel corpus. The state of the art in word alignment focuses on automatically learning generative translation models via Expectation Maximization algorithm (Brown et al., 1990; Brown et al., 1993). (Och and Ney, 2003) describe Giza++, an implementation of the !283 PACLIC 28 Input: ... He made this remark after Heinonen arrived in Tehran. ÷ / ( w˛Á µT ∑—- å |h ⇡ ⇧ «q ⇥ ... Initial word alignments in two directions (En-Ch and Ch-En): he(÷) made this remark(/) after(( å) heinonen(w˛Á |h ⇧ «q) arrived(µT) in tehran(∑—-) ÷(he) / ( w˛Á(remark heinonen) µT(arrive in) ∑—-(tehran) å(after) |h(made) ⇡(this) ⇧ «q Crosslingual relatedness: ra n a rk s th i he(÷) made(|h) this(⇡) remark(«q) ma he de Output: = .25 . = sim(remark, talk) te h x-sim(remark, «q) in o ne n a rr ive d in = sim(make, publish) = .32, he x-sim(m"
Y14-1034,J04-4002,0,0.0303385,"with high predicted probabiliy, are added to the results. In Step (4), we attempt to fill in links which are probably wordtranslation pairs, if the link is not in conflict with the current alignment. In Step (5), we execute the FINAL-AND step the same way as in GDFA. Experiments and Evaluation TakeTwo. TakeTwo (no fill-in). Giza++: grow-diag-final-and. Giza++: intersection. Giza++: union. We manually aligned 300 random selected sentences with English and Chinese words as the reference answers. For simplicity, we do not distinguished between sure and uncertain alignment links as described in (Och and Ney, 2004). For preprocessing and generating syntactic features, we used the Genia Tagger and CKIP Word Segmenter to generate tokens and parts of speech. We also used the Wikipedia Dump (English) to build distributional word similarity measure. In order to train a classifier for word-translation relation, we used SVM classifier with the tool libsvm. We used lexical, morphological, transliteration, and syntactic features, as described in Section 3.2.2. For simplicity, we used an empirically determined values for the thresholds of similarity constraint in T akeT wo. 4.2 Evaluation Metrics Each word-transl"
Y14-1034,N10-1014,0,0.0158535,"undreds sentences with thousands of word-translation relations) to train a word alignment model. In contrast, we take a self learning approach and automatically generate labelled training data. More specifically, We train our model based on a much larger training set (hundred of thousand of word-translation instances in partially labeled sentences) based on self learning. Recently, some researchers have begun using syntax in word alignment, by incorporating features such as inversion transduction grammar or parse tree. Supervised (Cherry and Lin, 2006; Setiawan et al., 2010) and unsupervised (Pauls et al., 2010) methods have been proposed, showing that syntax can improve alignment performance. All these features can be used to training the classifier used in TakeTwo. In a word alignment approach closer to our method, (Deng and Zhou, 2009) propose a method to optimize word alignment combination to derive a more effective phrase table. Similarly, (Nakov and Tiedemann, 2012) propose combining word-level and character-Level alignment models for improving machine translation between two closely-related languages. In contrast to the previous research in word alignment, we present a system that automaticall"
Y14-1034,D10-1052,0,0.0374544,"Missing"
Y14-1034,H05-1010,0,0.0399836,"area of cross-lingual relatedness, (Michelbacher et al., 2010) present a graph-based method for building a a cross-lingual thesaurus. The method uses two monolingual corpora and a basic dictionary to build two monolingual word graphs, with nodes representing words and edges representing linguistic relations between words. In the research area of supervised training for word alignment, (Moore, 2005) demonstrates that a discriminative model with the main feature of Log Likelihood Ratio (LLR) could result in a smaller model comparable to more complex generative EM models in alignment accuracy. (Taskar et al., 2005) independently propose a similar approach. (Liu et al., 2005) also propose a log-linear model incorporating features (alignment probability, POS correspondence and bilingual dictionary coverage). The main difference from our current work is that previous methods use manually labeled data (typically hundreds sentences with thousands of word-translation relations) to train a word alignment model. In contrast, we take a self learning approach and automatically generate labelled training data. More specifically, We train our model based on a much larger training set (hundred of thousand of word-tr"
Y14-1034,Q13-1024,0,0.011739,"e on the right) 抵達 德黑蘭 Note that the dark cells represent links in the 後 intersection of two alignments, while the gray 發表 cells represent links in the rest of the union 這 項 談話 。 . Figure 2: An example TakeTwo session and results IBM models, which has since become the tool of choice for developing SMT systems. As an alternative to the EM algorithm, researchers have been exploring various knowledge sources for word alignment, using automatically derived lexicons or handcrafted dictionaries (Gale and Church, 1991; Ker and Chang, 1997), or syntactic structure (Gildea, 2003; Cherry and Lin, 2003; Wang and Zong, 2013). There has been work on translating phrases using mixed-code web-pages (e.g., (Nagata et al., 2001; Wu and Chang, 2007)). Similarly, (Lin et al., 2008) propose a method that performs word alignment for parenthetic translation phrases to improve the performance of SMT systems. Researchers have also studied sublexical models for machine transliteration (Knight and Graehl, 1998). More recently, (Chang et al., 2012) introduce a method for learning a CRF model to find translations and transliterations of technical terms on the Web. We use similar transliteration-based features derived from transli"
Y14-1034,D07-1106,1,0.833193,"表 cells represent links in the rest of the union 這 項 談話 。 . Figure 2: An example TakeTwo session and results IBM models, which has since become the tool of choice for developing SMT systems. As an alternative to the EM algorithm, researchers have been exploring various knowledge sources for word alignment, using automatically derived lexicons or handcrafted dictionaries (Gale and Church, 1991; Ker and Chang, 1997), or syntactic structure (Gildea, 2003; Cherry and Lin, 2003; Wang and Zong, 2013). There has been work on translating phrases using mixed-code web-pages (e.g., (Nagata et al., 2001; Wu and Chang, 2007)). Similarly, (Lin et al., 2008) propose a method that performs word alignment for parenthetic translation phrases to improve the performance of SMT systems. Researchers have also studied sublexical models for machine transliteration (Knight and Graehl, 1998). More recently, (Chang et al., 2012) introduce a method for learning a CRF model to find translations and transliterations of technical terms on the Web. We use similar transliteration-based features derived from transliteration model in a different setting. Word alignment is closely related to measuring word similarity, and especially in"
Y14-1034,C98-2122,0,\N,Missing
Y14-1034,J98-4003,0,\N,Missing
Y14-1034,michelbacher-etal-2010-building,0,\N,Missing
Y15-2005,I08-1050,0,0.0218436,"t to analyze the result section while others applied it to investigate the discussion section (e.g. Hopkins and Dudley-Evans, 1994). More researches have been done to study RAs in recent years. 2.2 Identifying Moves for Text Classification In the search area of automatic analysis of the discourse structure of research articles, in recent years, much work has been done viewing the task as a text classification problem that determines a label (move name) for each sentence. Various classiPACLIC 29 with features of unigram, subject-verb, verb tense, relative sentence location, and sentence score. Hirohata et al (2008) presented another system for Medline abstracts into four moves. They trained a CRF classifier with features of n-grams, sentence location, and features from previous/next sentences. 3 Figure 3: Structure of research article introduction (Swales, 1990) fiers were applied to text categorization, including Naive Bayesian Model (NBM) (Teufel and Moens, 2002, 2004, 2006; Anthony 2003), Support Vector Machines (SVM) (McKnight and Arinivasan, 2003; Shimbo et al., 2003; Yamamoto and Takagi, 2005), Hidden Markov Model (HMM) (Lin et al., 2006), and Conditional Random Fields (CRFs) (Hirohata et al. 2008"
Y15-2005,E99-1015,0,0.159627,"Missing"
Y15-2005,J02-4002,0,0.234666,"Missing"
Y18-1042,Y18-1000,0,0.256227,"e spelling errors, and correct the errors using SMT model built from a large corpus. More recently, Neural Machine Translation (NMT) has been adopted in error correction task and achieved state-of-the-art performance. Yuan and Briscoe (2016) presented the very first NMT model for grammatical error correction of English. However, word-based NMT models usually suffer from rare word problem and infrequent words are substituted for a “UNK” token. Then, a character-based NMT approach was proposed by Xie et al. (2016) to avoid the problem of out-of-vocabulary words. Subsequently, Chollampatt and Ng (2018) proposed a multilayer convolutional encoder-decoder neural network to correct grammatical, orthographic, and collocation errors. Until now, most work on error correction using NMT model aimed at correction for English text. In contrast, we focus on correcting Chinese spelling errors. Building an error correction system using machine learning techniques typically requires a considerable amount of error-annotated data. Unfortunately, limited availability of error-annotated data is holding back progress in the area of automatic er368 32nd Pacific Asia Conference on Language, Information and Comp"
Y18-1042,W13-4408,1,0.827198,"d a similar approach using confusing word substitution and trigram language model to extend the method proposed by Chang (1995). In recent years, Statistical Machine Translation (SMT) has been applied to Chinese spelling check. Wu et al. (2010) presented a system using a new error model and a common error template generation method to detect and correct Chinese character errors, which reduce the false alarm rate significantly. The idea of the error model is adopted from the noisy channel model, a framework of SMT, which is used in many NLP tasks such as spelling check and machine translation. Chiu et al. (2013) proposed a datadriven method that detects and corrects Chinese errors based on phrasal statistical machine translation framework. They used word segmentation and dictionary to detect possible spelling errors, and correct the errors using SMT model built from a large corpus. More recently, Neural Machine Translation (NMT) has been adopted in error correction task and achieved state-of-the-art performance. Yuan and Briscoe (2016) presented the very first NMT model for grammatical error correction of English. However, word-based NMT models usually suffer from rare word problem and infrequent wor"
Y18-1042,E14-3013,0,0.0184417,"rthographic, and collocation errors. Until now, most work on error correction using NMT model aimed at correction for English text. In contrast, we focus on correcting Chinese spelling errors. Building an error correction system using machine learning techniques typically requires a considerable amount of error-annotated data. Unfortunately, limited availability of error-annotated data is holding back progress in the area of automatic er368 32nd Pacific Asia Conference on Language, Information and Computation Hong Kong, 1-3 December 2018 Copyright 2018 by the authors PACLIC 32 ror correction. Felice and Yuan (2014) presented a method of generating artificial errors for training, and improved NMT models for correcting mistakes made by English as a second language. Rei et al. (2017) investigated two alternative approaches for artificially generating all types of writing errors. They extracted error patterns from an annotated corpus and transplanting them into error-free text. In addition, they built a phrase-based SMT error generator to translate the grammatically correct text into incorrect one. In a study closer to our work, Gu and Lang (2017) applied sequence-to-sequence (seq2seq) model to construct a"
Y18-1042,P17-4012,0,0.0327984,"p(yj |y1 , y2 , ..., yj−1 ; c) = (6) where g is a nonlinear function, and h0j is the hidden state vector of the RNN decoder at time j. We use a attention-based RNN decoder that focuses on the most relevant information in the source sentence rather than the entire source sentence. Thus, the conditional probability in Equation 5 is redefined as: p(yj |y1 , y2 , ..., yj−1 ; e) = g(yj−1 , h0j , cj ) cj = (7) I X aji hi (8) (9) i=1 aji = PI exp(score(h0j , hi )) 0 i0 =1 exp(score(hj , hi0 )) T score(h0j , hi ) = h0j Wa hi (10) (11) Instead of implementing an NMT model from scratch, we use OpenNMT (Klein et al., 2017), an open source toolkit for neural machine translation and sequence modeling, to train the model. The training details and hyper-parameters of our model will be described in Section 4.2 4 Experimental Setting In this section, we first give a brief description of the datasets used in the experiments in Section 4.1, and describe the hyper-parameters for the NMT model in Section 4.2. Then several NMT models with different experimental setting for comparing performance are described in Section 4.3. Finally in Section 4.4, we introduce the evaluation metrics for evaluating the performance of these"
Y18-1042,W03-1726,0,0.109256,"n (e.g., “[-佈-]{+布+}” or “{+布+}[-佈-]”) as spelling correction, and extract the sentences containing such edit pairs. Finally, we obtain a set of sentences with spelling errors annotated using simple edit tags, as shown in Figure 3. 3.2 Generating Artificially Misspelled Sentences To make our Chinese spelling check system more effective, we create a set of artificial misspelled sentences for expanding our training data. The input to this stage are a set of presumably error-free sentences from news articles with word segmentation done using a word segmentation tool provided by the CKIP Project (Ma and Chen, 2003). Artificially misspelled sentences are generated by injecting errors into these error-free sentences. Although a correct word could be misspelled as any other Chinese word, some right-and-wrong word pairs are more likely to happen than others. In order to generate realistic spelling errors, we use a confusion set consisting of commonly confused right-andwrong word pairs (see Table 1). The wrong words in confusion set are used to replace counterpart correct words in the sentences. For example, we use error-free sentence “也 跟 患者 賠罪 了 十 分鐘” to generate three misspelled sentences, as shown in Tab"
Y18-1042,W17-5032,0,0.0210929,"e spelling errors. Building an error correction system using machine learning techniques typically requires a considerable amount of error-annotated data. Unfortunately, limited availability of error-annotated data is holding back progress in the area of automatic er368 32nd Pacific Asia Conference on Language, Information and Computation Hong Kong, 1-3 December 2018 Copyright 2018 by the authors PACLIC 32 ror correction. Felice and Yuan (2014) presented a method of generating artificial errors for training, and improved NMT models for correcting mistakes made by English as a second language. Rei et al. (2017) investigated two alternative approaches for artificially generating all types of writing errors. They extracted error patterns from an annotated corpus and transplanting them into error-free text. In addition, they built a phrase-based SMT error generator to translate the grammatically correct text into incorrect one. In a study closer to our work, Gu and Lang (2017) applied sequence-to-sequence (seq2seq) model to construct a word-based Chinese spelling error corrector. They established their own error corpus for training and evaluation by transplanting errors into an error-free news corpus."
Y18-1042,W15-3106,0,0.0157639,"on different combinations of UDN Edit Logs and artificially generated data. In addition, we use the pronunciation and shape of a character as additional features for both the source and target sides to train another model. For example, for the character “詣”, the pronunciation feature is “ㄧ” (without considering the tone) and the shape features are “言” and “旨”. There are totally seven models trained for comparing, and only last one was trained with features, as shown in Table 4. 4.4 Evaluation Metrics We use the metrics provided by SIGHAN-8 Bakeoff 2015 for Chinese spelling check shared task (Tseng et al., 2015), which include False Positive Rate (FPR), Accuracy, Precision, Recall, and F1, to evaluate our systems. 5 Results and Discussion Table 5 shows the evaluation results of the two test sets we used. For UDN Edit Logs test set, as we can see, all models trained on edit logs plus artificially generated data perform better than the one trained on only edit logs. Moreover, UDN-only performs slightly worse, while ART-only performs the worst on all metrics. Though the model trained with sound and shape features has a relatively bad FPR, it has the best performance on accuracy, precision, recall, and F"
Y18-1042,W10-4107,0,0.0357229,"statistical method to automatically correct Chinese spelling errors. The approach involves a confusing character substitution mechanism and bigram language model. Later, Zhang et al. (2000) pointed out that the method proposed by Chang (1995) only address character substitution errors, other kinds of errors such as deletion and insertion can not be handled. They proposed a similar approach using confusing word substitution and trigram language model to extend the method proposed by Chang (1995). In recent years, Statistical Machine Translation (SMT) has been applied to Chinese spelling check. Wu et al. (2010) presented a system using a new error model and a common error template generation method to detect and correct Chinese character errors, which reduce the false alarm rate significantly. The idea of the error model is adopted from the noisy channel model, a framework of SMT, which is used in many NLP tasks such as spelling check and machine translation. Chiu et al. (2013) proposed a datadriven method that detects and corrects Chinese errors based on phrasal statistical machine translation framework. They used word segmentation and dictionary to detect possible spelling errors, and correct the"
Y18-1042,W13-4406,0,0.0480999,"Missing"
Y18-1042,N16-1042,0,0.0418596,"ethod for automatically learning to correct typos in a given sentence. Section 4 describes resources and datasets we used in the experiment. In our evaluation, over two test sets, we compare the performance of several models in Section 5. Finally, we summarize and point out the future work in Section 6. 2 Related Work Error Correction has been an area of active research, which involves Grammatical Error Correction (GEC) and Spelling Error Correction (SEC). Recently, researchers have begun applying neural machine translation models to both GEC and SEC, and gained significant improvement (e.g., Yuan and Briscoe (2016) and Xie et al. (2016)). However, compared to English, relatively little work has been done on Chinese error correction. In our work, we address the Chinese spelling error correction task on text written by native speakers, and an improved model by generating artificial typos. Early works on Chinese spelling check typically focused on rule-based and statistical approaches. Rule-based approaches usually use dictionary to identify typos and confusion set to find possible corrections, while statistical methods use the noisy channel model to find candidates of correction for a typo, and language m"
Y18-1042,P00-1032,0,0.163617,"g check typically focused on rule-based and statistical approaches. Rule-based approaches usually use dictionary to identify typos and confusion set to find possible corrections, while statistical methods use the noisy channel model to find candidates of correction for a typo, and language model to calculate the likelihood of the corrected sentences. Chang (1995) proposed an approach that integrates both rule-based method and statistical method to automatically correct Chinese spelling errors. The approach involves a confusing character substitution mechanism and bigram language model. Later, Zhang et al. (2000) pointed out that the method proposed by Chang (1995) only address character substitution errors, other kinds of errors such as deletion and insertion can not be handled. They proposed a similar approach using confusing word substitution and trigram language model to extend the method proposed by Chang (1995). In recent years, Statistical Machine Translation (SMT) has been applied to Chinese spelling check. Wu et al. (2010) presented a system using a new error model and a common error template generation method to detect and correct Chinese character errors, which reduce the false alarm rate s"
Y18-1062,W09-2307,0,0.0592908,"Missing"
Y18-1062,C10-3004,0,0.0146774,"ting collocations (i.e., word sketches), and to build a concordance and thesaurus. Specifically, they extract grammatical relations of a lexicon using hand-crafted rules, count the frequency of a word which is connected to another word by a specific grammatical relation (e.g., SUBJ OF, OBJ OF) (Lin, 1998), and weigh its collocations by logDice (Rychly, 2008). Also, Hu et al. (2016) presents a system searching for the collocations of a Chinese word with a certain grammar relations, online Chinese Collocation Assistant (COCA) (http://occa.xingtanlu. cn). Sentences are preprocessed by LTP-Cloud (Che et al., 2010), including word segmentation, POS tagging and dependency parsing, collocations are extracted based on dependency relations by 37 hand-crafted rules and classified into nine types of grammatical relations. Finally, they try to filter out parsing errors and inappropriate collocations by frequency. Other systems (e.g., Baisa and Suchomel (2014) and Wu and Witten (2016)) also use collocations as the top-level structure to organize examples. Developing from the traditional system of concordances and collocations, some of the previous researches integrate grammatical relations into collocations (Ki"
Y18-1062,C16-1307,0,0.015507,". See (Flowerdew, 2009) Recent concordance systems has begun to organize examples according to the grammatical relations and collocations. Kilgarriff et al. (2014; Kilgarriff et al. (2004) describe an interesting approach for extracting collocations (i.e., word sketches), and to build a concordance and thesaurus. Specifically, they extract grammatical relations of a lexicon using hand-crafted rules, count the frequency of a word which is connected to another word by a specific grammatical relation (e.g., SUBJ OF, OBJ OF) (Lin, 1998), and weigh its collocations by logDice (Rychly, 2008). Also, Hu et al. (2016) presents a system searching for the collocations of a Chinese word with a certain grammar relations, online Chinese Collocation Assistant (COCA) (http://occa.xingtanlu. cn). Sentences are preprocessed by LTP-Cloud (Che et al., 2010), including word segmentation, POS tagging and dependency parsing, collocations are extracted based on dependency relations by 37 hand-crafted rules and classified into nine types of grammatical relations. Finally, they try to filter out parsing errors and inappropriate collocations by frequency. Other systems (e.g., Baisa and Suchomel (2014) and Wu and Witten (201"
Y18-1062,Y18-1000,0,0.223248,"Missing"
Y18-1062,P98-2127,0,0.360626,"g discovery of patterns bottomup a slow and ineffective learning process. See (Flowerdew, 2009) Recent concordance systems has begun to organize examples according to the grammatical relations and collocations. Kilgarriff et al. (2014; Kilgarriff et al. (2004) describe an interesting approach for extracting collocations (i.e., word sketches), and to build a concordance and thesaurus. Specifically, they extract grammatical relations of a lexicon using hand-crafted rules, count the frequency of a word which is connected to another word by a specific grammatical relation (e.g., SUBJ OF, OBJ OF) (Lin, 1998), and weigh its collocations by logDice (Rychly, 2008). Also, Hu et al. (2016) presents a system searching for the collocations of a Chinese word with a certain grammar relations, online Chinese Collocation Assistant (COCA) (http://occa.xingtanlu. cn). Sentences are preprocessed by LTP-Cloud (Che et al., 2010), including word segmentation, POS tagging and dependency parsing, collocations are extracted based on dependency relations by 37 hand-crafted rules and classified into nine types of grammatical relations. Finally, they try to filter out parsing errors and inappropriate collocations by fr"
Y18-1062,P15-4024,1,0.922982,"examples. Developing from the traditional system of concordances and collocations, some of the previous researches integrate grammatical relations into collocations (Kilgarriff et al., 2014; Hu et al., 2016) . However, this approach still limits writing assisting to the lexical level, which is helpful but not enough to describe the whole picture of word usage. To provide more useful assistance for learners, a writing-assisted system should also provide the structural information and the interaction between possible grammatical relations of a word . In a study more closely related to our work, Yen et al. (2015) proposes an interactive writing environment, WriteAhead, which provides the automatically derived English grammar patterns and examples to assist learners to write fluently and avoid making writing errors. The main difference from our current work is that in (Yen et al., 2015), the grammar patterns are derived using all English sentences with contain high degree of parsing errors, while we use the active learning approach to select a small sample of representative Chinese sentences to cope with parsing errors. In contrast to the previous research in using corpora and concordance for lexicogra"
Y95-1015,C94-2195,0,0.147899,"Missing"
Y95-1015,W95-0103,0,0.0242637,"Missing"
Y95-1015,J87-3005,0,0.0883801,"Missing"
Y95-1015,J93-2005,0,0.0432067,"Missing"
Y95-1015,H94-1048,0,0.0749454,"Missing"
Y95-1015,W93-0307,0,0.0281971,"Missing"
Y95-1015,1995.tmi-1.22,0,0.0281229,"Missing"
Y95-1017,W95-0104,0,0.09571,"Missing"
Y95-1017,C94-2198,0,0.056635,"Missing"
Y95-1017,J93-1007,0,0.11321,"Missing"
Y95-1017,C90-2036,0,0.060584,"Missing"
Y95-1017,C88-2157,0,0.0688825,"Missing"
Y95-1017,W93-0308,0,0.0446456,"Missing"
Y95-1017,P94-1049,0,0.0222792,"Missing"
Y95-1017,A94-1031,0,0.0287158,"Missing"
Y95-1017,A94-1039,0,0.0354675,"Missing"
Y95-1017,A94-1033,0,\N,Missing
Y95-1023,H92-1022,0,0.0495313,"Missing"
Y95-1023,J90-2002,0,0.149276,"Missing"
Y95-1023,P91-1034,0,0.0624164,"Missing"
Y95-1023,1992.tmi-1.8,0,0.0315625,"Missing"
Y95-1023,1994.amta-1.3,0,0.0668897,"Missing"
Y95-1023,W93-0301,0,0.0591022,"Missing"
Y95-1023,C94-1084,0,0.0470307,"Missing"
Y95-1023,E93-1015,0,0.0399696,"Missing"
Y95-1023,H91-1026,0,0.0781452,"Missing"
Y95-1023,P93-1003,0,0.0520194,"Missing"
Y95-1023,P93-1004,0,0.0414258,"Missing"
Y95-1023,J93-2003,0,\N,Missing
