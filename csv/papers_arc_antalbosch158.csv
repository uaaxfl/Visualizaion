2020.lrec-1.756,Optimising {T}witter-based Political Election Prediction with Relevance and{S}entiment Filters,2020,-1,-1,2,0.57045,18115,eric sanders,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We study the relation between the number of mentions of political parties in the last weeks before the elections and the election results.In this paper we focus on the Dutch elections of the parliament in 2012 and for the provinces (and the senate) in 2011 and 2015. With raw counts, without adaptations, we achieve a mean absolute error (MAE) of 2.71{\%} for 2011, 2.02{\%} for 2012 and 2.89{\%} for 2015. A set of over 17,000 tweets containing political party names were annotated by at least three annotators per tweet on ten features denoting communicative intent (including the presence of sarcasm, the message{'}s polarity, the presence of an explicit voting endorsement or explicit voting advice, etc.). The annotations were used to create oracle (gold-standard) filters. Tweets with or without a certain majority annotation are held out from the tweet counts, with the goal of attaining lower MAEs. With a grid search we tested all combinations of filters and their responding MAE to find the best filter ensemble. It appeared that the filters show markedly different behaviour for the three elections and only a small MAE improvement is possible when optimizing on all three elections. Larger improvements for one election are possible, but result in deterioration of the MAE for the other elections."
2020.cogalex-1.4,Less is Better: A cognitively inspired unsupervised model for language segmentation,2020,-1,-1,3,0,21789,jinbiao yang,Proceedings of the Workshop on the Cognitive Aspects of the Lexicon,0,"Language users process utterances by segmenting them into many cognitive units, which vary in their sizes and linguistic levels. Although we can do such unitization/segmentation easily, its cognitive mechanism is still not clear. This paper proposes an unsupervised model, Less-is-Better (LiB), to simulate the human cognitive process with respect to language unitization/segmentation. LiB follows the principle of least effort and aims to build a lexicon which minimizes the number of unit tokens (alleviating the effort of analysis) and number of unit types (alleviating the effort of storage) at the same time on any given corpus. LiB{'}s workflow is inspired by empirical cognitive phenomena. The design makes the mechanism of LiB cognitively plausible and the computational requirement light-weight. The lexicon generated by LiB performs the best among different types of lexicons (e.g. ground-truth words) both from an information-theoretical view and a cognitive view, which suggests that the LiB lexicon may be a plausible proxy of the mental lexicon."
W19-3503,Detecting harassment in real-time as conversations develop,2019,0,0,3,0,24426,wessel stoop,Proceedings of the Third Workshop on Abusive Language Online,0,"We developed a machine-learning-based method to detect video game players that harass teammates or opponents in chat earlier in the conversation. This real-time technology would allow gaming companies to intervene during games, such as issue warnings or muting or banning a player. In a proof-of-concept experiment on League of Legends data we compute and visualize evaluation metrics for a machine learning classifier as conversations unfold, and observe that the optimal precision and recall of detecting toxic players at each moment in the conversation depends on the confidence threshold of the classifier: the threshold should start low, and increase as the conversation unfolds. How fast this sliding threshold should increase depends on the training set size."
W19-2903,Simulating {S}panish-{E}nglish Code-Switching: El Modelo Est{\\'a} Generating Code-Switches,2019,0,0,3,0,24609,chara tsoukala,Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics,0,"Multilingual speakers are able to switch from one language to the other ({``}code-switch{''}) between or within sentences. Because the underlying cognitive mechanisms are not well understood, in this study we use computational cognitive modeling to shed light on the process of code-switching. We employed the Bilingual Dual-path model, a Recurrent Neural Network of bilingual sentence production (Tsoukala et al., 2017), and simulated sentence production in simultaneous Spanish-English bilinguals. Our first goal was to investigate whether the model would code-switch without being exposed to code-switched training input. The model indeed produced code-switches even without any exposure to such input and the patterns of code-switches are in line with earlier linguistic work (Poplack,1980). The second goal of this study was to investigate an auxiliary phrase asymmetry that exists in Spanish-English code-switched production. Using this cognitive model, we examined a possible cause for this asymmetry. To our knowledge, this is the first computational cognitive model that aims to simulate code-switched sentence production."
W19-2909,Dependency Parsing with your Eyes: Dependency Structure Predicts Eye Regressions During Reading,2019,0,2,3,0,24621,alessandro lopopolo,Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics,0,"Backward saccades during reading have been hypothesized to be involved in structural reanalysis, or to be related to the level of text difficulty. We test the hypothesis that backward saccades are involved in online syntactic analysis. If this is the case we expect that saccades will coincide, at least partially, with the edges of the relations computed by a dependency parser. In order to test this, we analyzed a large eye-tracking dataset collected while 102 participants read three short narrative texts. Our results show a relation between backward saccades and the syntactic structure of sentences."
R19-1070,Question Similarity in Community Question Answering: A Systematic Exploration of Preprocessing Methods and Models,2019,0,0,4,1,24427,florian kunneman,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"Community Question Answering forums are popular among Internet users, and a basic problem they encounter is trying to find out if their question has already been posed before. To address this issue, NLP researchers have developed methods to automatically detect question-similarity, which was one of the shared tasks in SemEval. The best performing systems for this task made use of Syntactic Tree Kernels or the SoftCosine metric. However, it remains unclear why these methods seem to work, whether their performance can be improved by better preprocessing methods and what kinds of errors they (and other methods) make. In this paper, we therefore systematically combine and compare these two approaches with the more traditional BM25 and translation-based models. Moreover, we analyze the impact of preprocessing steps (lowercasing, suppression of punctuation and stop words removal) and word meaning similarity based on different distributions (word translation probability, Word2Vec, fastText and ELMo) on the performance of the task. We conduct an error analysis to gain insight into the differences in performance between the system set-ups. The implementation is made publicly available from https://github.com/fkunneman/DiscoSumo/tree/master/ranlp."
W18-3901,Language Identification and Morphosyntactic Tagging: The Second {V}ar{D}ial Evaluation Campaign,2018,0,13,15,0,622,marcos zampieri,"Proceedings of the Fifth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial 2018)",0,"We present the results and the findings of the Second VarDial Evaluation Campaign on Natural Language Processing (NLP) for Similar Languages, Varieties and Dialects. The campaign was organized as part of the fifth edition of the VarDial workshop, collocated with COLING{'}2018. This year, the campaign included five shared tasks, including two task re-runs {--} Arabic Dialect Identification (ADI) and German Dialect Identification (GDI) {--}, and three new tasks {--} Morphosyntactic Tagging of Tweets (MTT), Discriminating between Dutch and Flemish in Subtitles (DFS), and Indo-Aryan Language Identification (ILI). A total of 24 teams submitted runs across the five shared tasks, and contributed 22 system description papers, which were included in the VarDial workshop proceedings and are referred to in this report."
L18-1073,A Multilingual Wikified Data Set of Educational Material,2018,0,0,13,0,16715,iris hendrickx,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1521,Discovering the Language of Wine Reviews: A Text Mining Account,2018,0,0,4,0,2023,els lefever,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"It is widely held that smells and flavors are impossible to put into words. In this paper we test this claim by seeking predictive patterns in wine reviews, which ostensibly aim to provide guides to perceptual content. Wine reviews have previously been critiqued as random and meaningless. We collected an English corpus of wine reviews with their structured metadata, and applied machine learning techniques to automatically predict the wine's color, grape variety, and country of origin. To train the three supervised classifiers, three different information sources were incorporated: lexical bag-of-words features, domain-specific terminology features, and semantic word embedding features. In addition, using regression analysis we investigated basic review properties, i.e., review length, average word length, and their relationship to the scalar values of price and review score. Our results show that wine experts do share a common vocabulary to describe wines and they use this in a consistent way, which makes it possible to automatically predict wine characteristics based on the review text alone. This means that odors and flavors may be more expressible in language than typically acknowledged."
C18-1188,Aspect-based summarization of pros and cons in unstructured product reviews,2018,0,0,3,1,24427,florian kunneman,Proceedings of the 27th International Conference on Computational Linguistics,0,"We developed three systems for generating pros and cons summaries of product reviews. Automating this task eases the writing of product reviews, and offers readers quick access to the most important information. We compared SynPat, a system based on syntactic phrases selected on the basis of valence scores, against a neural-network-based system trained to map bag-of-words representations of reviews directly to pros and cons, and the same neural system trained on clusters of word-embedding encodings of similar pros and cons. We evaluated the systems in two ways: first on held-out reviews with gold-standard pros and cons, and second by asking human annotators to rate the systems{'} output on relevance and completeness. In the second evaluation, the gold-standard pros and cons were assessed along with the system output. We find that the human-generated summaries are not deemed as significantly more relevant or complete than the SynPat systems; the latter are scored higher than the human-generated summaries on a precision metric. The neural approaches yield a lower performance in the human assessment, and are outperformed by the baseline."
W17-1224,Exploring Lexical and Syntactic Features for Language Variety Identification,2017,8,3,2,0,3388,chris lee,"Proceedings of the Fourth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial)",0,"We present a method to discriminate between texts written in either the Netherlandic or the Flemish variant of the Dutch language. The method draws on a feature bundle representing text statistics, syntactic features, and word $n$-grams. Text statistics include average word length and sentence length, while syntactic features include ratios of function words and part-of-speech $n$-grams. The effectiveness of the classifier was measured by classifying Dutch subtitles developed for either Dutch or Flemish television. Several machine learning algorithms were compared as well as feature combination methods in order to find the optimal generalization performance. A machine-learning meta classifier based on AdaBoost attained the best F-score of 0.92."
W16-6608,Abstractive Compression of Captions with Attentive Recurrent Neural Networks,2016,32,0,3,1,19006,sander wubben,Proceedings of the 9th International Natural Language Generation conference,0,"INLG 2016 : The 9th International Natural Language Generation conference, Edinburgh, Scotland, September 5-8, 2016"
P16-2023,Improving cross-domain n-gram language modelling with skipgrams,2016,16,1,2,0,34403,louis onrust,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"In this paper we improve over the hierarchical Pitman-Yor processes language model in a cross-domain setting by adding skipgrams as features. We find that adding skipgram features reduces the perplexity. This reduction is substantial when models are trained on a generic corpus and tested on domain-specific corpora. We also find that within-domain testing and cross-domain testing require different backoff strategies. We observe a 30-40% reduction in perplexity in a cross-domain language modelling task, and up to 6% reduction in a within-domain experiment, for both English and Flemish-Dutch."
P16-2050,Very quaffable and great fun: Applying {NLP} to wine reviews,2016,25,6,5,0,16715,iris hendrickx,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We automatically predict properties of wines on the basis of smell and flavor descriptions from experts' wine reviews. We show wine experts are capable of describing their smell and flavor experiences in wine reviews in a sufficiently consistent manner, such that we can use their descriptions to predict properties of a wine based solely on language. The experimental results show promising F-scores when using lexical and semantic information to predict the color, grape variety, country of origin, and price of a wine. This demonstrates, contrary to popular opinion, that wine experts' reviews really are informative."
L16-1003,Enhancing Access to Online Education: Quality Machine Translation of {MOOC} Content,2016,19,1,2,0,12066,valia kordoni,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The present work is an overview of the TraMOOC (Translation for Massive Open Online Courses) research and innovation project, a machine translation approach for online educational content. More specifically, videolectures, assignments, and MOOC forum text is automatically translated from English into eleven European and BRIC languages. Unlike previous approaches to machine translation, the output quality in TraMOOC relies on a multimodal evaluation schema that involves crowdsourcing, error type markup, an error taxonomy for translation model comparison, and implicit evaluation via text mining, i.e. entity recognition and its performance comparison between the source and the translated text, and sentiment analysis on the students{'} forum posts. Finally, the evaluation output will result in more and better quality in-domain parallel data that will be fed back to the translation engine for higher quality output. The translation service will be incorporated into the Iversity MOOC platform and into the VideoLectures.net digital library portal."
L16-1203,{N}ederlab: Towards a Single Portal and Research Environment for Diachronic {D}utch Text Corpora,2016,9,3,6,0,34922,hennie brugman,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The Nederlab project aims to bring together all digitized texts relevant to the Dutch national heritage, the history of the Dutch language and culture (circa 800 {--} present) in one user friendly and tool enriched open access web interface. This paper describes Nederlab halfway through the project period and discusses the collections incorporated, back-office processes, system back-end as well as the Nederlab Research Portal end-user web application."
L16-1473,Can Tweets Predict {TV} Ratings?,2016,7,0,3,0,35193,bridget sommerdijk,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We set out to investigate whether TV ratings and mentions of TV programmes on the Twitter social media platform are correlated. If such a correlation exists, Twitter may be used as an alternative source for estimating viewer popularity. Moreover, the Twitter-based rating estimates may be generated during the programme, or even before. We count the occurrences of programme-specific hashtags in an archive of Dutch tweets of eleven popular TV shows broadcast in the Netherlands in one season, and perform correlation tests. Overall we find a strong correlation of 0.82; the correlation remains strong, 0.79, if tweets are counted a half hour before broadcast time. However, the two most popular TV shows account for most of the positive effect; if we leave out the single and second most popular TV shows, the correlation drops to being moderate to weak. Also, within a TV show, correlations between ratings and tweet counts are mostly weak, while correlations between TV ratings of the previous and next shows are strong. In absence of information on previous shows, Twitter-based counts may be a viable alternative to classic estimation methods for TV ratings. Estimates are more reliable with more popular TV shows."
2016.lilt-14.7,Sarcastic Soulmates: Intimacy and irony markers in social media messaging,2016,19,3,4,0,35904,koen hallmann,"Linguistic Issues in Language Technology, Volume 14, 2016 - Modality: Logic, Semantics, Annotation, and Machine Learning",0,"Verbal irony, or sarcasm, presents a significant technical and conceptual challenge when it comes to automatic detection. Moreover, it can be a disruptive factor in sentiment analysis and opinion mining, because it changes the polarity of a message implicitly. Extant methods for automatic detection are mostly based on overt clues to ironic intent such as hashtags, also known as irony markers. In this paper, we investigate whether people who know each other make use of irony markers less often than people who do not know each other. We trained a machinelearning classifier to detect sarcasm in Twitter messages (tweets) that were addressed to specific users, and in tweets that were not addressed to a particular user. Human coders analyzed the top-1000 features found to be most discriminative into ten categories of irony markers. The classifier was also tested within and across the two categories. We find that tweets with a user mention contain fewer irony markers than tweets not addressed to a particular user. Classification experiments confirm that the irony in the two types of tweets is signaled differently. The within-category performance of the classifier is about 91{\%} for both categories, while cross-category experiments yield substantially lower generalization performance scores of 75{\%} and 71{\%}. We conclude that irony markers are used more often when there is less mutual knowledge between sender and receiver. Senders addressing other Twitter users less often use irony markers, relying on mutual knowledge which should lead the receiver to infer ironic intent from more implicit clues. With regard to automatic detection, we conclude that our classifier is able to detect ironic tweets addressed at another user as reliably as tweets that are not addressed at at a particular person."
2016.eamt-2.20,{T}ra{MOOC} (Translation for Massive Open Online Courses): providing reliable {MT} for {MOOC}s,2016,0,1,19,0,12066,valia kordoni,Proceedings of the 19th Annual Conference of the European Association for Machine Translation: Projects/Products,0,None
W15-4935,{T}ra{MOOC}: Translation for Massive Open Online Courses,2015,0,0,9,0,12066,valia kordoni,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W15-2414,Modeling dative alternations of individual children,2015,23,3,1,1,18116,antal bosch,Proceedings of the Sixth Workshop on Cognitive Aspects of Computational Language Learning,0,"We address the question whether children can acquire mature use of higher-level grammatical choices from the linguistic input, given only general prior knowledge and learning biases. We do so on the basis of a case study with the dative alternation in English, building on a study by de Marneffe et al. (2012) who model the production of the dative alternation by seven young children, using data from the Child Language Data Exchange System corpus. Using mixed-effects logistic modelling on the aggregated data of these children, De Marneffe et al. report that the childrenxe2x80x99s choices can be predicted both by their own utterances and by child-directed speech. Here we bring the computational modeling down to the individual child, using memory-based learning and incremental learning curve studies. We observe that for all children, their dative choices are best predicted by a model trained on child-directed speech. Yet, models trained on two individual children for which sufficient data is available are about as accurate. Furthermore, models trained on the dative alternations of these children provide approximations of dative alternations in caregiver speech that are about as accurate as training and testing on caregiver data only."
R15-1043,Automatically Identifying Periodic Social Events from {T}witter,2015,25,2,2,1,24427,florian kunneman,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"Many events referred to on Twitter are of a periodic nature, characterized by roughlyn constant time intervals in between occurrences. Examples are annual music festivals,n weekly television programs, and the full moon cycle. We propose a system that can automatically identify periodic events from Twitter in an unsupervised and open-domain fashion. We first extract events from the Twitter stream by associating terms that have a high probability of denoting an event to the exact date of the event. We compare a timeline-based and a calendar-based approach to detecting periodic patterns from the event dates that are connected to these terms. After applying event extraction on over four years of Dutch tweets and scanning the resulting events for periodic patterns, the calendar-based approach yields a precision of 0.76 on the 500 top-ranked periodic events, while the timeline-based approach scores 0.63."
2015.eamt-1.36,{T}ra{MOOC}: Translation for Massive Open Online Courses,2015,0,0,9,0,12066,valia kordoni,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,None
W14-1302,Estimating Time to Event from Tweets Using Temporal Expressions,2014,16,6,3,0,38762,ali hurriyetovglu,Proceedings of the 5th Workshop on Language Analysis for Social Media ({LASM}),0,"Given a stream of Twitter messages about an event, we investigate the predictive power of temporal expressions in the messages to estimate the time to event (TTE). From labeled training data we learn average TTE estimates of temporal expressions and combinations thereof, and define basic rules to compute the time to event from temporal expressions, so that when they occur in a tweet that mentions an event we can generate a prediction. We show in a case study on soccer matches that our estimations are off by about eight hours on average in terms of mean absolute error."
W14-1304,The (Un)Predictability of Emotional Hashtags in {T}witter,2014,28,19,3,1,24427,florian kunneman,Proceedings of the 5th Workshop on Language Analysis for Social Media ({LASM}),0,"Hashtags in Twitter posts may carry different semantic payloads. Their dual form (word and label) may serve to categorize the tweet, but may also add content to the message, or strengthen it. Some hashtags are related to emotions. In a study on emotional hashtags in Dutch Twitter posts we employ machine learning classifiers to test to what extent tweets that are stripped from their hashtag could be reassigned to this hashtag. About half of the 24 tested hashtags can be predicted with AUC scores of .80 or higher. However, when we apply the three best-performing classifiers to unseen tweets that do not carry the hashtag but might have carried it according to human annotators, the classifiers manage to attain a precision-at-250 of .7 for only two of the hashtags. We observe that some hashtags are predictable from their tweets, and strengthen the emotion already expressed in the tweets. Other hashtags are added to messages that do not predict them, presumably to provide emotional information that was not yet in the tweet."
S14-2005,{S}em{E}val 2014 Task 5 - {L}2 Writing Assistant,2014,10,3,3,1,38941,maarten gompel,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"We present a new cross-lingual task for SemEval concerning the translation of L1 fragments in an L2 context. The task is at the boundary of Cross-Lingual Word Sense Disambiguation and Machine Translation. It finds its application in the field of computer-assisted translation, particularly in the context of second language learning. Translating L1 fragments in an L2 context allows language learners when writing in a target language (L2) to fall back to their native language (L1) whenever they are uncertain of the right word or phrase."
P14-1082,Translation Assistance by Translation of {L}1 Fragments in an {L}2 Context,2014,18,3,2,1,38941,maarten gompel,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"52nd Annual Meeting of the Association for Computational Linguistics (ACL-2014), 23 juni 2014"
wubben-etal-2014-creating,Creating and using large monolingual parallel corpora for sentential paraphrase generation,2014,42,4,2,1,19006,sander wubben,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper we investigate the automatic generation of paraphrases by using machine translation techniques. Three contributions we make are the construction of a large paraphrase corpus for English and Dutch, a re-ranking heuristic to use machine translation for paraphrase generation and a proper evaluation methodology. A large parallel corpus is constructed by aligning clustered headlines that are scraped from a news aggregator site. To generate sentential paraphrases we use a standard phrase-based machine translation (PBMT) framework modified with a re-ranking component (henceforth PBMT-R). We demonstrate this approach for Dutch and English and evaluate by using human judgements collected from 76 participants. The judgments are compared to two automatic machine translation evaluation metrics. We observe that as the paraphrases deviate more from the source sentence, the performance of the PBMT-R system degrades less than that of the word substitution baseline system."
E14-1034,Using idiolects and sociolects to improve word prediction,2014,20,6,2,0,24426,wessel stoop,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"14th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2014), 26 april 2014"
W13-3614,Memory-based Grammatical Error Correction,2013,6,4,1,1,18116,antal bosch,Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task,0,"We describe the xe2x80x99TILBxe2x80x99 team entry for the CONLL-2013 Shared Task. Our system consists of five memory-based classifiers that generate correction suggestions for center positions in small text windows of two words to the left and to the right. Trained on the Google Web 1T corpus, the first two classifiers determine the presence of a determiner or a preposition between all words in a text. The second pair of classifiers determine which is the most likely correction of an occurring determiner or preposition. The fifth classifier is a general word predictor which is used to suggest noun and verb form corrections. We report on the scores attained and errors corrected and missed. We point out a number of obvious improvements to boost the scores obtained by the system."
W13-2702,Using character overlap to improve language transformation,2013,21,0,3,1,19006,sander wubben,"Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities",0,Language transformation can be defined as translating between diachronically distinct language variants. We investigate the transformation of Middle Dutch into Modern Dutch by means of machine translation. We demonstrate that by using character overlap the performance of the machine translation process can be improved for this task.
W13-1605,The perfect solution for detecting sarcasm in tweets {\\#}not,2013,39,126,3,0,35905,christine liebrecht,"Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"To avoid a sarcastic message being understood in its unintended literal meaning, in microtexts such as messages on Twitter.com sarcasm is often explicitly marked with the hashtag xe2x80x98#sarcasmxe2x80x99. We collected a training corpus of about 78 thousand Dutch tweets with this hashtag. Assuming that the human labeling is correct (annotation of a sample indicates that about 85% of these tweets are indeed sarcastic), we train a machine learning classifier on the harvested examples, and apply it to a test set of a dayxe2x80x99s stream of 3.3 million Dutch tweets. Of the 135 explicitly marked tweets on this day, we detect 101 (75%) when we remove the hashtag. We annotate the top of the ranked list of tweets most likely to be sarcastic that do not have the explicit hashtag. 30% of the top-250 ranked tweets are indeed sarcastic. Analysis shows that sarcasm is often signalled by hyperbole, using intensifiers and exclamations; in contrast, non-hyperbolic sarcastic messages often receive an explicit marker. We hypothesize that explicit markers such as hashtags are the digital extralinguistic equivalent of nonverbal expressions that people employ in live interaction when conveying sarcasm."
S13-2033,{WSD}2: Parameter optimisation for Memory-based Cross-Lingual Word-Sense Disambiguation,2013,14,5,2,1,38941,maarten gompel,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"We present our system WSD2 which participated in the Cross-Lingual Word-Sense Disambiguation task for SemEval 2013 (Lefever and Hoste, 2013). The system closely resembles our winning system for the same task in SemEval 2010. It is based on k-nearest neighbour classifiers which map words with local and global context features onto their translation, i.e. their cross-lingual sense. The system participated in the task for all five languages and obtained winning scores for four of them when asked to predict the best translation(s). We tested various configurations of our system, focusing on various levels of hyperparameter optimisation and feature selection. Our final results indicate that hyperparameter optimisation did not lead to the best results, indicating overfitting by our optimisation method in this aspect. Feature selection does have a modest positive impact."
W12-2034,Memory-based text correction for preposition and determiner errors,2012,6,2,1,1,18116,antal bosch,Proceedings of the Seventh Workshop on Building Educational Applications Using {NLP},0,"We describe the Valkuil.net team entry for the HOO 2012 Shared Task. Our systems consists of four memory-based classifiers that generate correction suggestions for middle positions in small text windows of two words to the left and to the right. Trained on the Google 1TB 5-gram corpus, the first two classifiers determine the presence of a determiner or a preposition between all words in a text in which the actual determiners and prepositions are masked. The second pair of classifiers determines which is the most likely correction given a masked determiner or preposition. The hyperparameters that govern the classifiers are optimized on the shared task training data. We point out a number of obvious improvements to boost the medium-level scores attained by the system."
P12-1107,Sentence Simplification by Monolingual Machine Translation,2012,33,94,2,1,19006,sander wubben,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"In this paper we describe a method for simplifying sentences using Phrase Based Machine Translation, augmented with a re-ranking heuristic based on dissimilarity, and trained on a monolingual parallel corpus. We compare our system to a word-substitution baseline and two state-of-the-art systems, all trained and tested on paired sentences from the English part of Wikipedia and Simple Wikipedia. Human test subjects judge the output of the different systems. Analysing the judgements shows that by relatively careful phrase-based paraphrasing our model achieves similar simplification results to state-of-the-art systems, while generating better formed output. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems."
vossen-etal-2012-dutchsemcor,{D}utch{S}em{C}or: Targeting the ideal sense-tagged corpus,2012,18,5,4,0,5469,piek vossen,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Word Sense Disambiguation (WSD) systems require large sense-tagged corpora along with lexical databases to reach satisfactory results. The number of English language resources for developed WSD increased in the past years while most other languages are still under-resourced. The situation is no different for Dutch. In order to overcome this data bottleneck, the DutchSemCor project will deliver a Dutch corpus that is sense-tagged with senses from the Cornetto lexical database. In this paper, we discuss the different conflicting requirements for a sense-tagged corpus and our strategies to fulfill them. We report on a first series of experiments to sup- port our semi-automatic approach to build the corpus."
E12-1057,The effect of domain and text type on text prediction quality,2012,11,3,2,0,2840,suzan verberne,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Text prediction is the task of suggesting text while the user is typing. Its main aim is to reduce the number of keystrokes that are needed to type a text. In this paper, we address the influence of text type and domain differences on text prediction quality.n n By training and testing our text prediction algorithm on four different text types (Wikipedia, Twitter, transcriptions of conversational speech and FAQ) with equal corpus sizes, we found that there is a clear effect of text type on text prediction quality: training and testing on the same text type gave percentages of saved keystrokes between 27 and 34%; training on a different text type caused the scores to drop to percentages between 16 and 28%.n n In our case study, we compared a number of training corpora for a specific data set for which training data is sparse: questions about neurological issues. We found that both text type and topic domain play a role in text prediction quality. The best performing training corpus was a set of medical pages from Wikipedia. The second-best result was obtained by leave-one-out experiments on the test questions, even though this training corpus was much smaller (2,672 words) than the other corpora (1.5 Million words)."
W11-1708,A Link to the Past: Constructing Historical Social Networks,2011,15,10,2,0,40209,matje camp,Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis ({WASSA} 2.011),0,"To assist in the research of social networks in history, we develop machine-learning-based tools for the identification and classification of personal relationships. Our case study focuses on the Dutch social movement between 1870 and 1940, and is based on biographical texts describing the lives of notable people in this movement. We treat the identification and the labeling of relations between two persons into positive, neutral, and negative both as a sequence of two tasks and as a single task. We observe that our machine-learning classifiers, support vector machines, produce better generalization performance on the single task. We show how a complete social network can be built from these classifications, and provide a qualitative analysis of the induced network using expert judgements on samples of the network."
W11-1604,Comparing Phrase-based and Syntax-based Paraphrase Generation,2011,33,2,3,1,19006,sander wubben,Proceedings of the Workshop on Monolingual Text-To-Text Generation,0,"Paraphrase generation can be regarded as machine translation where source and target language are the same. We use the Moses statistical machine translation toolkit for paraphrasing, comparing phrase-based to syntax-based approaches. Data is derived from a recently released, large scale (2.1M tokens) paraphrase corpus for Dutch. Preliminary results indicate that the phrase-based approach performs better in terms of NIST scores and produces paraphrases at a greater distance from the source."
W11-1507,Enrichment and Structuring of Archival Description Metadata,2011,18,5,3,0,25346,kalliopi zervanou,"Proceedings of the 5th {ACL}-{HLT} Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities",0,"Cultural heritage institutions are making their digital content available and searchable online. Digital metadata descriptions play an important role in this endeavour. This metadata is mostly manually created and often lacks detailed annotation, consistency and, most importantly, explicit semantic content descriptors which would facilitate online browsing and exploration of available information. This paper proposes the enrichment of existing cultural heritage metadata with automatically generated semantic content descriptors. In particular, it is concerned with metadata encoding archival descriptions (EAD) and proposes to use automatic term recognition and term clustering techniques for knowledge acquisition and content-based document classification purposes."
W10-4223,Paraphrase Generation as Monolingual Translation: Data and Evaluation,2010,22,30,2,1,19006,sander wubben,Proceedings of the 6th International Natural Language Generation Conference,0,In this paper we investigate the automatic generation and evaluation of sentential paraphrases. We describe a method for generating sentential paraphrases by using a large aligned monolingual corpus of news headlines acquired automatically from Google News and a standard Phrase-Based Machine Translation (PBMT) framework. The output of this system is compared to a word substitution baseline. Human judges prefer the PBMT paraphrasing system over the word substitution system. We demonstrate that BLEU correlates well with human judgements provided that the generated paraphrased sentence is sufficiently different from the source sentence.
2010.amta-papers.23,Supertags as Source Language Context in Hierarchical Phrase-Based {SMT},2010,31,16,3,0.606061,5016,rejwanul haque,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"Statistical machine translation (SMT) models have recently begun to include source context modeling, under the assumption that the proper lexical choice of the translation for an ambiguous word can be determined from the context in which it appears. Various types of lexical and syntactic features have been explored as effective source context to improve phrase selection in SMT. In the present work, we introduce lexico-syntactic descriptions in the form of supertags as source-side context features in the state-of-the-art hierarchical phrase-based SMT (HPB) model. These features enable us to exploit source similarity in addition to target similarity, as modelled by the language model. In our experiments two kinds of supertags are employed: those from lexicalized tree-adjoining grammar (LTAG) and combinatory categorial grammar (CCG). We use a memory-based classification framework that enables the efficient estimation of these features. Despite the differences between the two supertagging approaches, they give similar improvements. We evaluate the performance of our approach on an English-to-Dutch translation task, and report statistically significant improvements of 4.48{\%} and 6.3{\%} BLEU scores in translation quality when adding CCG and LTAG supertags, respectively, as context-informed features."
Y09-1019,Dependency Relations as Source Context in Phrase-Based {SMT},2009,31,9,3,0.606061,5016,rejwanul haque,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 1",0,"The Phrase-Based Statistical Machine Translation (PB-SMT) model has recently begun to include source context modeling, under the assumption that the proper lexicaln choice of an ambiguous word can be determined from the context in which it appears. Various types of lexical and syntactic features such as words, parts-of-speech, andn supertags have been explored as effective source context in SMT. In this paper, we show that position-independent syntactic dependency relations of the head of a source phrase can be modeled as useful source context to improve target phrase selection and thereby improve overall performance of PB-SMT. On a Dutchxe2x80x94English translation task, by combining dependency relations and syntactic contextual features (part-of-speech), we achieved a 1.0 BLEU (Papineni et al., 2002) point improvement (3.1% relative) over the baseline."
W09-3728,Comparing Alternative Data-Driven Ontological Vistas of Natural History (short paper),2009,4,0,3,1,17171,marieke erp,Proceedings of the Eight International Conference on Computational Semantics,0,"Traditionally, domain ontologies are created manually, based on human experts' views on the classes and relations of the domain at hand. We present ongoing work on two approaches to the automatic construction of ontologies from a flat database of records, and compare them to a manually constructed ontology. The latter CIDOC-CRM ontology focusses on the organisation of classes and relations. In contrast, the first automatic method, based on machine learning, focuses on the mutual predictiveness between classes, while the second automatic method, created with the aid of Wikipedia, stresses meaningful relations between classes. The three ontologies show little overlap; their differences illustrate that a different focus during ontology construction can lead to radically different ontologies. We discuss the implications of these differences, and argue that the two alternative ontologies may be useful in higher-level information systems such as search engines."
W09-3743,A semantic relatedness metric based on free link structure (short paper),2009,7,0,2,1,19006,sander wubben,Proceedings of the Eight International Conference on Computational Semantics,0,"While shortest paths in WordNet are known to correlate well with semantic similarity, an is-a hierarchy is less suited for estimating semantic relatedness. We demonstrate this by comparing two free scale networks ( ConceptNet and Wikipedia) to WordNet. Using the Finkelstein353 dataset we show that a shortest path metric run on Wikipedia attains a better correlation than WordNet-based metrics. ConceptNet attains a good correlation as well, but suffers from a low concept coverage."
W09-1203,Joint Memory-Based Learning of Syntactic and Semantic Dependencies in Multiple Languages,2009,8,11,3,0.384615,5465,roser morante,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL} 2009): Shared Task,0,"In this paper we present a system submitted to the CoNLL Shared Task 2009 performing the identification and labeling of syntactic and semantic dependencies in multiple languages. Dependencies are truly jointly learned, i.e. as if they were a single task. The system works in two phases: a classification phase in which three classifiers predict different types of information, and a ranking phase in which the output of the classifiers is combined."
W09-0621,Clustering and Matching Headlines for Automatic Paraphrase Acquisition,2009,12,26,2,1,19006,sander wubben,Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009),0,"For developing a data-driven text rewriting algorithm for paraphrasing, it is essential to have a monolingual corpus of aligned paraphrased sentences. News article headlines are a rich source of paraphrases; they tend to describe the same event in various different ways, and can easily be obtained from the web. We compare two methods of aligning headlines to construct such an aligned corpus of paraphrases, one based on clustering, and the other on pairwise similarity-based matching. We show that the latter performs best on the task of aligning paraphrastic headlines."
W09-0308,Instance-Driven Discovery of Ontological Relation Labels,2009,17,2,2,1,17171,marieke erp,"Proceedings of the {EACL} 2009 Workshop on Language Technology and Resources for Cultural Heritage, Social Sciences, Humanities, and Education ({L}a{T}e{CH} {--} {SHELT}{\\&}R 2009)",0,"An approach is presented to the automatic discovery of labels of relations between pairs of ontological classes. Using a hyperlinked encyclopaedic resource, we gather evidence for likely predicative labels by searching for sentences that describe relations between terms. The terms are instances of the pair of ontological classes under consideration, drawn from a populated knowledge base. Verbs or verb phrases are automatically extracted, yielding a ranked list of candidate relations. Human judges rate the extracted relations. The extracted relations provide a basis for automatic ontology discovery from a non-relational database. The approach is demonstrated on a database from the natural history domain."
R09-1051,Dependency Parsing and Semantic Role Labeling as a Single Task,2009,17,2,3,0.384615,5465,roser morante,Proceedings of the International Conference {RANLP}-2009,0,"We present a comparison between two systems for establishing syntactic and semantic dependencies: one that performs dependency parsing and semantic role labeling as a single task, and another that performs the two tasks in isolation. The systems are based on local memorybased classiers predicting syntactic and semantic dependency relations between pairs of words. In a second global phase, the systems perform a deterministic ranking procedure in which the output of the local classiers is combined per sentence into a dependency graph and semantic role labeling assignments for all predicates. The comparison shows that in the learning phase a joint approach produces better-scoring classiers, while after the ranking phase the isolated approach produces the most accurate syntactic dependencies, while the joint approach yields the most accurate semantic role assignments."
2009.eamt-1.25,A Constraint Satisfaction Approach to Machine Translation,2009,17,5,2,0.972222,47609,sander canisius,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"Constraint satisfaction inference is presented as a generic, theory-neutral inference engine for machine translation. The approach enables the integration of many different solutions to aspects of the output space, including classification-based translation models that take source-side context into account, as well as stochastic components such as target language models. The approach is contrasted with a word-based SMT system using the same decoding algorithm, but optimising a different objective function. The incorporation of sourceside context models in our model filters out many irrelevant candidate translations, leading to superior translation scores."
S07-1039,{ILK}: Machine learning of semantic relations with shallow features and almost no data,2007,14,8,4,1,16715,iris hendrickx,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper summarizes our approach to the Semeval 2007 shared task on Classification of Semantic Relations between Nominals. Our overall strategy is to develop machine-learning classifiers making use of a few easily computable and effective features, selected independently for each classifier in wrapper experiments. We train two types of classifiers for each of the seven relations: with and without WordNet information."
J07-1001,Letter to the Editor,2007,0,1,2,0,444,walter daelemans,Computational Linguistics,0,None
2007.tmi-papers.28,Exploiting source similarity for {SMT} using context-informed features,2007,29,59,2,0,49191,nicolas stroppa,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,"In this paper, we introduce context informed features in a log-linear phrase-based SMT framework; these features enable us to exploit source similarity in addition to target similarity modeled by the language model. Wen present a memory-based classification framework that enables the estimation of these features while avoidingn sparseness problems. We evaluate the performance of our approach on Italian-to-English and Chinese-to-English translation tasks using a state-of-the-art phrase-based SMTn system, and report significant improvements for both BLEU and NIST scores when adding the context-informed features."
W06-3604,All-word Prediction as the Ultimate Confusible Disambiguation,2006,17,6,1,1,18116,antal bosch,Proceedings of the Workshop on Computationally Hard Problems and Joint Inference in Speech and Language Processing,0,"We present a classification-based word prediction model based on IGTree, a decision-tree induction algorithm with favorable scaling abilities and a functional equivalence to n-gram models with back-off smoothing. Through a first series of experiments, in which we train on Reuters newswire text and test either on the same type of data or on general or fictional text, we demonstrate that the system exhibits log-linear increases in prediction accuracy with increasing numbers of training examples. Trained on 30 million words of newswire text, prediction accuracies range between 12.6% on fictional text and 42.2% on newswire text. In a second series of experiments we compare all-words prediction with confusable prediction, i.e., the same task, but specialized to predicting among limited sets of words. Confusable prediction yields high accuracies on nine example confusable sets in all genres of text. The confusable approach outperforms the all-words-prediction approach, but with more data the difference decreases."
W06-3206,Improved morpho-phonological sequence processing with constraint satisfaction inference,2006,17,12,1,1,18116,antal bosch,Proceedings of the Eighth Meeting of the {ACL} Special Interest Group on Computational Phonology and Morphology at {HLT}-{NAACL} 2006,0,"In performing morpho-phonological sequence processing tasks, such as letter-phoneme conversion or morphological analysis, it is typically not enough to base the output sequence on local decisions that map local-context input windows to single output tokens. We present a global sequence-processing method that repairs inconsistent local decisions. The approach is based on local predictions of overlapping trigrams of output tokens, which open up a space of possible sequences; a data-driven constraint satisfaction inference step then searches for the optimal output sequence. We demonstrate significant improvements in terms of word accuracy on English and Dutch letter-phoneme conversion and morphological segmentation, and we provide qualitative analyses of error types prevented by the constraint satisfaction inference method."
W06-2924,Dependency Parsing by Inference over High-recall Dependency Predictions,2006,14,18,3,1,47609,sander canisius,Proceedings of the Tenth Conference on Computational Natural Language Learning ({C}o{NLL}-X),0,"As more and more syntactically-annotated corpora become available for a wide variety of languages, machine learning approaches to parsing gain interest as a means of developing parsers without having to repeat some of the labor-intensive and language-specific activities required for traditional parser development, such as manual grammar engineering, for each new language. The CoNLL-X shared task on multi-lingual dependency parsing (Buchholz et al., 2006) aims to evaluate and advance the state-of-the-art in machine learning-based dependency parsing by providing a standard benchmark set comprising thirteen languages. In this paper, we describe two different machine learning approaches to the CoNLL-X shared task."
W06-2602,Constraint Satisfaction Inference: Non-probabilistic Global Inference for Sequence Labelling,2006,0,0,2,1,47609,sander canisius,Proceedings of the Workshop on Learning Structured Information in Natural Language Applications,0,None
W06-2206,Spotting the {`}Odd-one-out{'}: Data-Driven Error Detection and Correction in Textual Databases,2006,11,8,4,1,33924,caroline sporleder,Proceedings of the Workshop on Adaptive Text Extraction and Mining ({ATEM} 2006),0,"We present two methods for semiautomatic detection and correction of errors in textual databases. The first method (horizontal correction) aims at correcting inconsistent values within a database record, while the second (vertical correction) focuses on values which were entered in the wrong column. Both methods are data-driven and language-independent. We utilise supervised machine learning, but the training data is obtained automatically from the database; no manual annotation is required. Our experiments show that a significant proportion of errors can be detected by the two methods. Furthermore, both methods were found to lead to a precision that is high enough to make semi-automatic error correction feasible."
van-den-bosch-etal-2006-transferring,Transferring {P}o{S}-tagging and lemmatization tools from spoken to written {D}utch corpus development,2006,8,16,1,1,18116,antal bosch,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"We describe a case study in the reuse and transfer of tools in language resource development, from a corpus of spoken Dutch to a corpus of written Dutch. Once tools for a particular language have been developed, it is logical, but not trivial to reuse them for other types or registers of the language than the tools were originally designed for. This paper reviews the decisions and adaptations necessary to make this particular transfer from spoken to written language, focusing on a part-of-speech tagger and a lemmatizer. While the lemmatizer can be transferred fairly straightforwardly, the tagger needs to be adaptated considerably. We show how it can be adapted without starting from scratch. We describe how the part-of-speech tagset was adapted and how the tagger was retrained to deal with written-text phenomena it had not been trained on earlier."
sporleder-etal-2006-identifying,Identifying Named Entities in Text Databases from the Natural History Domain,2006,15,10,4,1,33924,caroline sporleder,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In this paper, we investigate whether it is possible to bootstrap a named entity tagger for textual databases by exploiting the database structure to automatically generate domain and database-specific gazetteer lists. We compare three tagging strategies: (i) using the extracted gazetteers in a look-up tagger, (ii) using the gazetteers to automatically extract training data to train a database-specific tagger, and (iii) using a generic named entity tagger. Our results suggest that automatically built gazetteers in combination with a look-up tagger lead to a relatively good performance and that generic taggers do not perform particularly well on this type of data."
W05-0701,Memory-Based Morphological Analysis Generation and Part-of-Speech Tagging of {A}rabic,2005,14,25,2,0.833333,32380,erwin marsi,Proceedings of the {ACL} Workshop on Computational Approaches to {S}emitic Languages,0,"We explore the application of memory-based learning to morphological analysis and part-of-speech tagging of written Arabic, based on data from the Arabic Treebank. Morphological analysis -- the construction of all possible analyses of isolated unvoweled wordforms -- is performed as a letter-by-letter operation prediction task, where the operation encodes segmentation, part-of-speech, character changes, and vocalization. Part-of-speech tagging is carried out by a bi-modular tagger that has a subtagger for known words and one for unknown words. We report on the performance of the morphological analyzer and part-of-speech tagger. We observe that the tagger, which has an accuracy of 91.9% on new data, can be used to select the appropriate morphological analysis of words in context at a precision of 64.0 and a recall of 89.7."
W05-0611,Improving Sequence Segmentation Learning by Predicting Trigrams,2005,23,12,1,1,18116,antal bosch,Proceedings of the Ninth Conference on Computational Natural Language Learning ({C}o{NLL}-2005),0,"Symbolic machine-learning classifiers are known to suffer from near-sightedness when performing sequence segmentation (chunking) tasks in natural language processing: without special architectural additions they are oblivious of the decisions they made earlier when making new ones. We introduce a new pointwise-prediction single-classifier method that predicts trigrams of class labels on the basis of windowed input sequences, and uses a simple voting mechanism to decide on the labels in the final output sequence. We apply the method to maximum-entropy, sparse-winnow, and memory-based classifiers using three different sentence-level chunking tasks, and show that the method is able to boost generalization performance in most experiments, attaining error reductions of up to 51%. We compare and combine the method with two known alternative methods to combat near-sightedness, viz. a feedback-loop method and a stacking method, using the memory-based classifier. The combination with a feedback loop suffers from the label bias problem, while the combination with a stacking method produces the best overall results."
W05-0637,Applying Spelling Error Correction Techniques for Improving Semantic Role Labelling,2005,9,22,3,0,16268,erik sang,Proceedings of the Ninth Conference on Computational Natural Language Learning ({C}o{NLL}-2005),0,"This paper describes our approach to the CoNLL-2005 shared task: semantic role labelling. We do many of the obvious things that can be found in the other submissions as well. We use syntactic trees for deriving instances, partly at the constituent level and partly at the word level. On both levels we edit the data down to only the predicted positive cases of verb-constituent or verb-word pairs exhibiting a verb-argument relation, and we train two next-level classifiers that assign the appropriate labels to the positively classified cases. Each classifier is trained on data in which the features have been selected to optimize generalization performance on the particular task. We apply different machine learning algorithms and combine their predictions."
W04-2414,"Memory-based semantic role labeling: Optimizing features, algorithm, and output",2004,11,22,1,1,18116,antal bosch,Proceedings of the Eighth Conference on Computational Natural Language Learning ({C}o{NLL}-2004) at {HLT}-{NAACL} 2004,0,None
W04-0827,"{GAMBL}, genetic algorithm optimization of memory-based {WSD}",2004,7,81,4,0,51636,bart decadt,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"GAMBL is a word expert approach to WSD in which each word expert is trained using memory based learning. Joint feature selection and algorithm parameter optimization are achieved with a genetic algorithm (GA). We use a cascaded classifier approach in which the GA optimizes local context features and the output of a separate keyword classifier (rather than also optimizing the keyword features together with the local context features). A further innovation on earlier versions of memory based WSD is the use of grammatical relation and chunk features. This paper presents the architecture of the system briefly, and discusses its performance on the English lexical sample and all words tasks in SENSEVAL-3."
W03-2710,Machine Learning for Shallow Interpretation of User Utterances in Spoken Dialogue Systems,2003,17,21,2,0.454545,17846,piroska lendvai,"Proceedings of the 2003 {EACL} Workshop on Dialogue Systems: interaction, adaptation and styes of management",0,"We investigate to what extent automatic learning techniques can be used for shallow interpretation of user utterances in spoken dialogue systems. This task involves dialogue act classification, shallow understanding and problem detection simultaneously. For this purpose we train both a rule-induction and a memory-based learning algorithm on a large set of surface features obtained by affordable means from an annotated corpus of human-machine dialogues. Using a pseudo-exhaustive search, the parameters of both algorithms are optimized. The shallow interpretation task turns out to be a difficult one, partly since there are 94 types of user answers. The best overall accuracy (exact match) obtained was 73.5%, which is a significant improvement over the baseline. The best average precision and recall for dialogue act classification was 91.2%, for classifying slot types 86.8% and for detecting communication problems 91.0%."
W03-0427,"Memory-based one-step named-entity recognition: Effects of seed list features, classifier stacking, and unannotated data",2003,11,17,2,1,16715,iris hendrickx,Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003,0,"We present a memory-based named-entity recognition system that chunks and labels named entities in a oneshot task. Training and testing on CoNLL-2003 shared task data, we measure the effects of three extensions. First, we incorporate features that signal the presence of wordforms in external, language-specific seed (gazetteer) lists. Second, we build a second-stage stacked classifier that corrects first-stage output errors. Third, we add selected instances from classified unannotated data to the training material. The system that incorporates all attains an overall F-rate on the final test set of 78.20 on English and 63.02 on German."
P03-1062,Learning to Predict Pitch Accents and Prosodic Boundaries in {D}utch,2003,22,21,3,0.833333,32380,erwin marsi,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"We train a decision tree inducer (CART) and a memory-based classifier (MBL) on predicting prosodic pitch accents and breaks in Dutch text, on the basis of shallow, easy-to-compute features. We train the algorithms on both tasks individually and on the two tasks simultaneously. The parameters of both algorithms and the selection of features are optimized per task with iterative deepening, an efficient wrapper procedure that uses progressive sampling of training data. Results show a consistent significant advantage of MBL over CART, and also indicate that task combination can be done at the cost of little generalization score loss. Tests on cross-validated data and on held-out data yield F-scores of MBL on accent placement of 84 and 87, respectively, and on breaks of 88 and 91, respectively. Accent placement is shown to outperform an informed baseline rule; reliably predicting breaks other than those already indicated by intra-sentential punctuation, however, appears to be more challenging."
E03-1051,Learning {PP} attachment for filtering prosodic phrasing,2003,25,8,3,0,50233,olga herwijnen,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We explore learning prepositional-phrase attachment in Dutch, to use it as a filter in prosodic phrasing. From a syntactic treebank of spoken Dutch we extract instances of the attachment of prepositional phrases to either a governing verb or noun. Using cross-validated parameter and feature selection, we train two learning algorithms, IB 1 and RIPPER, on making this distinction, based on unigram and bigram lexical features and a cooccurrence feature derived from WWW counts. We optimize the learning on noun attachment, since in a second stage we use the attachment decision for blocking the incorrect placement of phrase boundaries before prepositional phrases attached to the preceding noun. On noun attachment, IB 1 attains an F-score of 82; RIPPER an F-score of 78. When used as a filter for prosodic phrasing, using attachment decisions from IB 1 yields the best improvement on precision (by six points to 71) on phrase boundary placement."
W02-0809,{D}utch Word Sense Disambiguation: Optimizing the Localness of Context,2002,14,4,1,1,18116,antal bosch,Proceedings of the {ACL}-02 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions,0,"We describe a new version of the Dutch word sense disambiguation system trained and tested on a corrected version of the SENSEVAL-2 data. The system is an ensemble of word experts; each word expert is a memory-based classifier of which the parameters are automatically determined through cross-validation on training material. The original best-performing system, which used only local context features for disambiguation, is further refined by performing additional parallel cross-validation experiments for optimizing algorithmic parameters and the amount of local context available to each of the word experts' memory-based kernels. This procedure produces an accuracy of 84.8% on test material, improving on a baseline score of 77.2% and the previous SENSEVAL-2 score of 84.2%. We show that cross-validation overfits; had the local context been held constant at two left and right neighbouring words, the system would have scored 85.0%."
W02-0814,Evaluating the results of a memory-based word-expert approach to unrestricted word sense disambiguation,2002,35,18,4,1,441,veronique hoste,Proceedings of the {ACL}-02 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions,0,"In this paper, we evaluate the results of the Antwerp University word sense disambiguation system in the English all words task of SENSEVAL-2. In this approach, specialized memory-based word-experts were trained per word-POS combination. Through optimization by cross-validation of the individual component classifiers and the voting scheme for combining them, the best possible word-expert was determined. In the competition, this word-expert architecture resulted in accuracies of 63.6% (fine-grained) and 64.5% (coarse-grained) on the SENSEVAL-2 test data.In order to better understand these results, we investigated whether classifiers trained on different information sources performed differently on the different part-of-speech categories. Furthermore, the results were evaluated in terms of the available number of training items, the number of senses, and the sense distributions in the data set. We conclude that there is no information source which is optimal over all word-experts. Selecting the optimal classifier/voter for each single word-expert, however, leads to major accuracy improvements. We furthermore show that accuracies do not so much depend on the available number of training items, but largely on polysemy and sense distributions."
P02-1055,Shallow Parsing on the Basis of Words Only: A Case Study,2002,35,23,1,1,18116,antal bosch,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"We describe a case study in which a memory-based learning algorithm is trained to simultaneously chunk sentences and assign grammatical function tags to these chunks. We compare the algorithm's performance on this parsing task with varying training set sizes (yielding learning curves) and different input representations. In particular we compare input consisting of words only, a variant that includes word form information for low-frequency words, gold-standard POS only, and combinations of these. The word-based shallow parser displays an apparently log-linear increase in performance, and surpasses the flatter POS-based curve at about 50,000 sentences of training data. The low-frequency variant performs even better, and the combinations is best. Comparative experiments with a real POS tagger produce lower results. We argue that we might not need an explicit intermediate POS-tagging step for parsing when a sufficient amount of training material is available and word form information is used for low-frequency words."
S01-1003,{D}utch Word Sense Disambiguation: Data and Preliminary Results,2001,5,8,2,1,16715,iris hendrickx,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"We describe the Dutch word sense disambiguation data submitted to SENSEVAL-2, and give preliminary results on the data using a WSD system based on memory-based learning and statistical keyword selection."
P01-1012,Detecting Problematic Turns in Human-Machine Interactions: Rule-induction Versus Memory-based Learning Approaches,2001,15,26,1,1,18116,antal bosch,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"We address the issue of on-line detection of communication problems in spoken dialogue systems. The usefulness is investigated of the sequence of system question types and the word graphs corresponding to the respective user utterances. By applying both rule-induction and memory-based learning techniques to data obtained with a Dutch train time-table information system, the current paper demonstrates that the aforementioned features indeed lead to a method for problem detection that performs significantly above baseline. The results are interesting from a dialogue perspective since they employ features that are present in the majority of spoken dialogue systems and can be obtained with little or no computational overhead. The results are interesting from a machine learning perspective, since they show that the rule-based method performs significantly better than the memory-based method, because the former is better capable of representing interactions between features."
W00-0713,Using Induced Rules as Complex Features in Memory-Based Language Learning,2000,24,5,1,1,18116,antal bosch,Fourth Conference on Computational Natural Language Learning and the Second Learning Language in Logic Workshop,0,"An extension to memory-based learning is described in which automatically induced rules are used as binary features. These features have an active value when the left-hand side of the underlying rule applies to the instance. The RIPPER rule induction algorithm is adopted for the selection of the underlying rules. The similarity of a memory instance to a new instance is measured by taking the sum of the weights of the matching rules both instances share. We report on experiments that indicate that (i) the method works equally well or better than RIPPER on various language learning and other benchmark datasets; (ii) the method does not necessarily perform better than default memory-based learning, but (iii) when multi-valued features are combined with the rule-based features, some slight to significant improvements are observed."
W00-0735,Single-Classifier Memory-Based Phrase Chunking,2000,11,22,2,0,53136,jorn veenstra,Fourth Conference on Computational Natural Language Learning and the Second Learning Language in Logic Workshop,0,"In the shared task for CoNLL-2000, words and tags form the basic multi-valued features for predicting a rich phrase segmentation code. While the tag features, containing WSJ part-of-speech tags (Marcus et al., 1993), have about 45 values, the word features have more than 10,000 values. In our study we have looked at how memory-based learning, as implemented in the TiMBL software system (Daelemans et al., 2000), can handle such features. We have limited our search to single classifiers, thereby explicitly ignoring the possibility to build a meta-learning classifier architecture that could be expected to improve accuracy. Given this restriction we have explored the following:1. The generalization accuracy of TiMBL with default settings (multi-valued features, overlap metric, feature weighting).2. The usage of MVDM (Stanfill and Waltz, 1986; Cost and Salzberg, 1993) (Section 2), which should work well on word value pairs with a medium or high frequency, but may work badly on word value pairs with low frequency.3. The straightforward unpacking of feature values into binary features. On some tasks we have found that splitting multi-valued features into several binary features can enhance performance of the classifier.4. A heuristic search for complex features on the basis of all unpacked feature values, and using these complex features for the classification task."
buchholz-van-den-bosch-2000-integrating,Integrating Seed Names and ngrams for a Named Entity List and Classifier,2000,4,27,2,0,46220,sabine buchholz,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"We present a method for building a named-entity list and machine-learned named-entity classifier from a corpus of Dutch n ewspaper text, a rule-based named entity recognizer, and labeled seed name lists taken from the internet. The seed names, labeled either as PERSON, LOCATION, ORGANIZATION, or ADJECTIVAL name, are looked up i n a 83-million word corpus, and their immediate contexts are stored as instances of their label. The latter 8-grams are us ed by a decision-tree learning algorithm that, after traini ng, (i) can produce high-precision labeling of instances to be added to the seed lists, and (ii) more generally labels new, unseen names. Unlabeled namedentity types are labeled with a precision of 61% and a recall of 56%; aiming at optimizing precision, an overall precision of 83% can be obtained (a top precision of 88% on PERSON). On free text, named-entity token labeling accuracy is 71%."
P99-1037,Memory-Based Morphological Analysis,1999,17,102,1,1,18116,antal bosch,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,"We present a general architecture for efficient and deterministic morphological analysis based on memory-based learning, and apply it to morphological analysis of Dutch. The system makes direct mappings from letters in context to rich categories that encode morphological boundaries, syntactic class labels, and spelling changes. Both precision and recall of labeled morphemes are over 84% on held-out dictionary test words and estimated to be over 93% in free text."
W98-1223,Modularity in Inductively-Learned Word Pronunciation Systems,1998,25,6,1,1,18116,antal bosch,New Methods in Language Processing and Computational Natural Language Learning,0,"In leading morpho-phonological theories and state-of-the-art text-to-speech systems it is assumed that word pronunciation cannot be learned or performed without in-between analyses at several abstraction levels (e.g., morphological, graphemic, phonemic, syllabic, and stress levels). We challenge this assumption for the case of English word pronunciation. Using igtree, an inductive-learning decision-tree algorithms, we train and test three word-pronunciation systems in which the number of abstraction levels (implemented as sequenced modules) is reduced from five, via three, to one. The latter system, classifying letter strings directly as mapping to phonemes with stress markers, yields significantly better generalisation accuracies than the two multi-module systems. Analyses of empirical results indicate that positive utility effects of sequencing modules are outweighed by cascading errors passed on between modules."
W98-1224,Do Not Forget: Full Memory in Memory-Based Learning of Word Pronunciation,1998,29,16,1,1,18116,antal bosch,New Methods in Language Processing and Computational Natural Language Learning,0,"Memory-based learning, keeping full memory of learning material, appears a viable approach to learning NLP tasks, and is often superior in generalisation accuracy to eager learning approaches that abstract from learning material. Here we investigate three partial memory-based learning approaches which remove from memory specific task instance types estimated to be exceptional. The three approaches each implement one heuristic function for estimating exceptionality of instance types: (i) typicality, (ii) class prediction strength, and (iii) friendly-neighbourhood size. Experiments are performed with the memory-based learning algorithm IB1-IG trained on English word pronunciation. We find that removing instance types with low prediction strength (ii) is the only tested method which does not seriously harm generalisation accuracy. We conclude that keeping full memory of types rather than tokens, and excluding minority ambiguities appear to be the only performance-preserving optimisations of memory-based learning."
E93-1007,Data-Oriented Methods for Grapheme-to-Phoneme Conversion,1993,19,81,1,1,18116,antal bosch,Sixth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"It is traditionally assumed that various sources of linguistic knowledge and their interaction should be formalised in order to be able to convert words into their phonemic representations with reasonable accuracy. We show that using supervised learning techniques, based on a corpus of transcribed words, the same and even better performance can be achieved, without explicit modeling of linguistic knowledge.In this paper we present two instances of this approach. A first model implements a variant of instance-based learning, in which a weighed similarity metric and a database of prototypical exemplars are used to predict new mappings. In the second model, grapheme-to-phoneme mappings are looked up in a compressed text-to-speech lexicon (table lookup) enriched with default mappings. We compare performance and accuracy of these approaches to a connectionist (backpropagation) approach and to the linguistic knowledge-based approach."
