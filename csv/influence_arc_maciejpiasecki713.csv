2016.gwc-1.41,J14-1003,0,0.0605544,"Missing"
2016.gwc-1.41,broda-etal-2012-kpwr,0,0.359727,"Missing"
2016.gwc-1.41,hajnicz-2014-procedure,0,0.0302827,"Missing"
2016.gwc-1.41,W14-0104,0,0.0379266,"Missing"
2016.gwc-1.41,W99-0501,0,0.276107,"Missing"
2016.gwc-1.41,R13-1058,1,0.931879,"gn any sense stored in a wordnet to words in text. So, in spite of their lower precision they seem to be noteworthy as a potentially practical solution. Most wordnet-based weakly supervised WSD methods are based on the idea of spreading activation in the wordnet graph, where the initial activation comes from the words in a textual context. Several methods based on this general scheme were proposed. A short overview is presented in Section 2. Most such methods were developed and tested on Princeton WordNet (PWN) (Fellbaum, 1998) that is slightly different than plWordNet (Piasecki et al., 2009, Maziarz et al., 2013a), currently the world largest wordnet. First attempts to transfer the methods with good performance on PWN to plWordNet (K˛edzia et al., 2015) were encouraging; the performance is relatively close to the performance of the supervised methods observed for Polish on limited test sets (Ba´s et al., 2008, Młodzki and Przepiórkowski, 2009). In addition to the differences between both wordnets, PWN has been enriched with various other resources in order to obtain better performance of unsupervised WSD. First of all, additional links between synsets were created on the basis of the manually disambi"
2016.gwc-1.41,P04-1036,0,0.140456,"Missing"
2016.gwc-1.41,C04-1162,0,0.0966645,"Missing"
2016.gwc-1.41,H93-1061,0,0.629639,"Missing"
2016.gwc-1.42,W97-0802,0,0.610878,"Missing"
2016.gwc-1.42,kedzia-piasecki-2014-ruled,1,0.856536,"Missing"
2016.gwc-1.42,R13-1058,1,0.886126,"Missing"
2016.gwc-1.42,W14-0142,1,0.872788,"Missing"
2016.gwc-1.42,R15-1056,1,0.885123,"Missing"
2016.gwc-1.42,mititelu-2012-adding,0,0.0251846,"Missing"
2016.gwc-1.42,R13-1073,1,0.864579,"Missing"
2016.gwc-1.42,C12-2101,1,0.90159,"Missing"
2016.gwc-1.42,R15-1092,1,0.894692,"Missing"
2018.gwc-1.14,C16-1213,1,0.853121,"Missing"
2018.gwc-1.14,2016.gwc-1.31,0,0.240894,"., 2009) and is not a constitutive relation (Maziarz et al., 2013). PWN verb relations link only verbs (Fellbaum, 1998b), in similar way to GermaNet (Kunze, 1999). In plWN, following EuroWordNet (Vossen 2002) verb LUs can be linked to all PoS. Modification of the verb part of plWN 4.0 model 7 8 I.e. A verb lemma encodes its aspect, it is not inflected with respect to aspect. However, more precisely, we should say that they do not significantly differ in their meanings beyond the information expressed by the aspect change. was inspired by relations for adjectives and adverbs from plWN 3.0, cf (Maziarz et al., 2016a, 2016b). The verb relations expanded to cross-categorial relations include: processuality (e.g. anarchizować się ‘to becomeImp anarchic’ → anarchista ‘anarchist’ / anarchiczny ‘anarchic’ / anarchicznie ‘anarchically’), causality (e.g. zmienić ‘to change’ → zmiana ‘a change’ / inny ‘different’ / inaczej ‘other’,), presupossition (e.g. całość ‘a whole’ / cały ‘whole’ ← podzielić się `to divide itself’; jasno ‘brightly’ ← ściemnić ‘to dim’), preceding (e.g. dobry ‘goodadj’ / zły ‘badadj’ / dobrze ‘goodadv’ / źle ‘badadv’ ← pogorszyć się ‘to worsen’; mąż ‘a husband’, żona ‘a wife’ ← rozwieść się"
2018.gwc-1.18,baccianella-etal-2010-sentiwordnet,0,0.224517,"Missing"
2018.gwc-1.18,de-albornoz-etal-2012-sentisense,0,0.0510434,"Missing"
2018.gwc-1.18,P14-2063,0,0.031889,"Missing"
2018.gwc-1.18,W10-3208,0,0.0693614,"Missing"
2018.gwc-1.18,esuli-sebastiani-2006-sentiwordnet,0,0.399767,"Missing"
2018.gwc-1.18,C16-1213,1,0.90781,"Missing"
2018.gwc-1.18,strapparava-valitutti-2004-wordnet,0,0.285725,"Missing"
2018.gwc-1.18,W11-1710,0,0.0384531,"Missing"
2018.gwc-1.18,R15-1092,1,0.527301,"Missing"
2018.gwc-1.22,P09-4002,1,0.667287,"allows for adding new types of lexicographic files and annotation with semantic domains. The former facilitates wordnet editing (e.g. the extension includes verb classes used in plWordNet), while the latter supports applications. The domains are based on WordNet Domains (Bentivogli et al., 2004), but we plan to manually modify and expand this classification. 6.2 Portuguese Wordnet As WordnetLoom is getting consolidated, it can be used to help the construction of wordnets other than just plWordNet. This is what is happening with the MultiWordnet of Portuguese, a quality wordnet for Portuguese (Branco et al., 2009). This Portuguese wordnet is a project started in 2004 as a branch of Multi-WordNet (Pianta et al., 2002), which until now gathered seven different languages (English, Hebrew, Italian, Latin, Portuguese, Romanian and Spanish), and was one of the first consistent initiatives pursuing the goal of establishing a multilingual wordnet that remains open for further languages. The wordnets in these languages, were transitively aligned with each other by resorting to its alignment to Princeton WordNet, whose format all are following, and thus having English as the pivot language. This pilot applicatio"
2018.gwc-1.22,E12-1059,0,0.0602801,"Missing"
2018.gwc-1.22,henrich-hinrichs-2010-gernedit,0,0.0319185,"). A web-based system sloWTool (Fišer and Novak, 2011, Fišer and Sagot, 2015) offers good UI and visual wordnet browsing and editing. However, presentation is always limited to a small fragment of the wordnet graph (up to two links distance) and there is no means for neither viewing larger parts, nor comparing different parts. Visualisation of wordnet graphs in most tools follows a radial pattern: a synset in focus is presented in the middle and all links, irrespectively of their types are placed radially around the central element, e.g. sloWTool or WordTies (Pedersen et al., 2012). GernEdiT (Henrich and Hinrichs, 2010) offers visualisation of the wordnet structure in the range selected by the user, but it is hierarchical and focused mainly on hypernymy. Moreover the visual presentation does not allow for direct editing of the structures. WordnetLoom introduced elaborated presentation of the relation graph and direct visual editing (Piasecki et al., 2013). As it is an open tool, it was used as a basis for the solution presented in this paper. 3 Basic Assumptions WordnetLoom 1.0 has been used for plWordNet development since 2005 and proved to be a generally useful system. Thus, although software architecture"
2018.gwc-1.22,R13-1058,1,0.838614,"inning of the plWordNet project in the year 2005, we developed a wordnet editing system, called WordnetLoom in order to avoid problems with manual editing of wordnet representation. It was based on a database and Graphical User Interface (GUI), and separated users from the internal representation of the wordnet. As plWordNet was developed by a team of linguists, it was important to provide distributed access to the system. WordnetLoom has been constructed in a way providing support for the corpus-based wordnet de1 A triple: lemma, Part of Speech, sense id. velopment method used for plWordNet (Maziarz et al., 2013); i.e. enabling close association between editors’ decisions and language data, the use of substitution tests and application of semiautomatic methods as tools for editors. An unique feature of WordnetLoom is the possibility to simultaneously browse and edit wordnet graphs directly on the screen. Nevertheless, WordnetLoom was based on a quite inefficient thick client model, as well as it had restricted expressiveness of the applied wordnet representation and limited possibilities to adapt UI to the format extensions. Moreover, WordnetLoom was initially designed to support a monolingual wordnet"
2018.gwc-1.22,P15-4013,0,0.0311776,"Missing"
2018.gwc-1.24,W14-0142,1,0.803292,"systems between English and Polish e.g. {big fishn:1 , ...} linked by Domain Usage relation to {colloquialismn:1 } and via I-partial synonymy relation to the Polish synset {gruba ryban:1 ‘big fish’, wa˙zniakn:2 ‘VIP’} with both its LUs marked for the colloquial register. However, such simple cases are rare. Both in Princeton WordNet and in plWordNet, LUs of different registers can co-occur in the same synset. However, in the latter only LUs of compatible register can be grouped in one synset or linked by some relation, e.g. hypernymy. A set of rules was defined for this purpose in plWordNet (Maziarz et al., 2014), while this aspect is largely unconstrained in Princeton WordNet. General, specialist, literary, and official registers can co-occur in one synset; the same holds for general and colloquial ones (provided that that specialist, literary and official are not found in the same synset). Colloquial, common and vulgar can also come together. On the other hand, regional, obsolete, slang/argot and non-normative always come on their own. An example is the Polish synset {okularyn:1 ‘glasses’: general register, patrzałkin:1 , szkłan:1 ‘specs’: colloquial register, binoklen:2 ‘eyeglasses’: colloquial reg"
2018.gwc-1.24,C16-1213,1,0.878716,"Missing"
2018.gwc-1.24,P13-1133,1,0.827848,"on and supplements them with (parallel) corpus frequency and translatability. Three types of equivalence are distinguished, namely strong, regular and weak depending on the conformity with the proposed features. The presented solutions are languageneutral and they can be easily applied to language pairs other than Polish and English. Sense-level mapping is a more finegrained mapping than the existing synset mappings and is thus of great potential to human and machine translation. 1 Introduction Currently, bi- and multilingual wordnets are most commonly inter-linked on the synset level, (e.g., Bond and Foster, 2013). Synsets can be composed of one or more lexical units (lemma-PoS-synset triples, also called senses; henceforth, LUs), so such inter-wordnet links may be of three types: 1-to-1 sense link (between two synsets each built of a single LU); 1-to-many sense link (between two synsets, one built of a single LU, the other of more than one); and many-to-many sense link (between two multiple-LU synsets). The (large) majority of inter-linked wordnets use one simple equivalence relation to connect their synsets (effectively synonymy). If, due to substantial differences between languages, such a link cann"
2018.gwc-1.24,W99-0603,0,0.255854,"are already partially mapped on the synset level, and, eventually, to verbs after some mapping between verb synsets is accomplished. It may well be that additional features will need to be introduced while some of the ones proposed for nouns might be dismissed as irrelevant. The proposed strategy is designed for manual mapping, but we plan to develop an automatic system of prompts that will support lexicographers’ work. The new system will be an extension of an earlier system of automatic prompts for mapping of noun synsets and based on a modification of the Relaxation Labelling algorithm of Daudé et al. (1999) joined with lemma-pair checking and filtering by a large Polish-English cascade dictionary K˛edzia et al. (2013) and translation probabilities from bilingual corpora. As regards future avenues, this study may be continued in a number of possible ways. Firstly, the strategy of sense-level mapping described in this paper should be further tested on a structured and balanced sample of concrete and abstract nouns representing the whole variety of semantic domains (lexicographers’ files). We plan to extract the lists of Polish-English lexical unit pairs from the Polish-English pairs of synsets lin"
2018.gwc-1.24,C12-2101,1,0.838454,"treated as ‘given’. The interlingual relations that will be taken into consideration include I-synonymy, I-partial synonymy, Ihyponymy and I-hypernymy, all of which hold between the same part of speech synsets. Our focus will be the relations between nouns. The more interesting formal features are number and countability. For regular, countable nouns, agreement in these features is usually also given, because both in plWordNet and in Princeton WordNet lemmas appear in singular form. Still, some cases of ‘mixed’ Princeton WordNetsynsets were already tracked e.g. {dumplingn:1 , dumplingsn:1 } (Rudnicka et al., 2012, 2016). Such mixed synsets currently serve as inter-lingual hypernyms for both singular and plural Polish synsets e.g.{pierógn:2 , pierogn:1 } ‘dumpling’ or {pierogi ruskien:1 } ‘Russian dumplings’. Still, sense level mapping will allow to resolve such inconsistencies in the synset built-up. In regular cases, the agreement in number will always be observed in the mapping. A different case are pluralia and singularia tantum that have regular countable nouns as equivalents in another language such as, for instance, {drzwin:1 } ‘doorpl ’ I-syn {doorn:1 }, {grabien:1 } ‘rakepl ’ I-syn {raken:1 },"
2018.gwc-1.24,2016.gwc-1.49,1,0.769409,"one language there should not exist two different forms that share identical function and meaning, so there have to be slight differences between component LUs of a given synset, and even larger differences between the LUs from two synsets representing two different languages (even if those synsets are linked by I-synonymy). Existing research on interwordnet mapping between plWordNet (Maziarz et al., 2016) and Princeton WordNet (Fellbaum, 1998), especially 1-to-many and many-to many sense links, has shown the potential for creating stronger links between some LUs from a given pair of synsets (Rudnicka et al., 2016). To give an example, in the pair of synsets: {złoton:3 , Aun:1 }P L I-syn {goldn:3 , Aun:1 , atomic number 79n:1 }EN — złoton:3 P L and goldn:3 EN and Aun:1 P L and Aun:1 EN seem the best-fitted equivalents due to the agreement not only in sense, but also in register. The words from the first pair belong to the general register, while the ones from the second pair are from the specialist register. Biand multilingual wordnets are used by translators who would certainly appreciate such a more detailed mapping. 2 Background Equivalence is a popular concept used in, among others, translation stud"
2018.gwc-1.26,W17-5304,0,0.0188913,"nstein and Goodenough, 1965), WS353 (Finkelstein et al., 2002) and most of the all 10 data sets discussed in (Faruqui and Dyer, 2014), where only two of them include ≈2000 and ≈3000 word pairs. They were used in many tests, in fact overused. Small sizes of these datasets make performing proper evaluation more difficult, e.g. because of the lack of the common partitioning into training, tuning and testing parts. Datasets for MSR evaluation are often collected during experiments based on testing human judgement in reaction to some prompting signal, which is close to reaction to a stimuli, e.g. (Auguste et al., 2017) measured the correlation between the reaction times in the context of priming with ranking based on word embeddings. However, this is slightly different situation than analysis of lexical meanings during language utterance interpretation, especially a textual utterance. MSR is extracted from a text corpus, and it is more natural to evaluate it against language resources. Moreover, (Faruqui et al., 2016) noticed that the distinction between similarity and relatedness is not well defined and consistently expressed in most popular test datasets. (Schnabel et al., 2015) evaluated systematically d"
2018.gwc-1.26,P14-5004,0,0.0197235,"to publishing word embedding models of known properties built on the basis of a very large corpus of Polish. 2 Related Works MSR evaluation methods can be roughly divided into intrinsic and extrinsic. The former are based on the direct evaluation of the MSR properties, e.g. by assessment by humans or comparison with a gold standard. The latter is based on applying an MSR as knowledge source in some NLP application. Typical datasets used in the intrinsic evaluation are small, e.g. (Rubenstein and Goodenough, 1965), WS353 (Finkelstein et al., 2002) and most of the all 10 data sets discussed in (Faruqui and Dyer, 2014), where only two of them include ≈2000 and ≈3000 word pairs. They were used in many tests, in fact overused. Small sizes of these datasets make performing proper evaluation more difficult, e.g. because of the lack of the common partitioning into training, tuning and testing parts. Datasets for MSR evaluation are often collected during experiments based on testing human judgement in reaction to some prompting signal, which is close to reaction to a stimuli, e.g. (Auguste et al., 2017) measured the correlation between the reaction times in the context of priming with ranking based on word embedd"
2018.gwc-1.26,W16-2506,0,0.0190526,"parts. Datasets for MSR evaluation are often collected during experiments based on testing human judgement in reaction to some prompting signal, which is close to reaction to a stimuli, e.g. (Auguste et al., 2017) measured the correlation between the reaction times in the context of priming with ranking based on word embeddings. However, this is slightly different situation than analysis of lexical meanings during language utterance interpretation, especially a textual utterance. MSR is extracted from a text corpus, and it is more natural to evaluate it against language resources. Moreover, (Faruqui et al., 2016) noticed that the distinction between similarity and relatedness is not well defined and consistently expressed in most popular test datasets. (Schnabel et al., 2015) evaluated systematically different DS models, but finally all tests were based on data collected during crowdsourcing experiments using Amazon Turk. (Jastrzebski et al., 2017) performed “evaluation focused on data efficiency&quot; with respect to 4 categories, namely: “Similarity, Analogy, Sentence and Single word”. In the case of similarity, which is most interesting for us, they used only well known data sets for English. For each t"
2018.gwc-1.26,W05-0604,0,0.0585022,"between it and an MSR, e.g. (Lin, 1998). It was assumed that similarity rankings generated by the two measures should be similar. However, there are many wordnet-based similarity measures of different properties and some of them depend on additional knowledge like information about the frequency of word senses. Thus, the result of the comparison can be different depending on the wordnetbased similarity measure applied and in all cases is not straightforward in interpretation. We want to follow a different approach and to explore two methods that are free of these problems. 3.1 Synonymy tests (Freitag et al., 2005) proposed a wordnet-based synonymy test (WBST) in which for a question word x an n-tuple is automatically generated: D = hd1 , . . . dn i, such that one the elements: di is the correct answer, i.e. it is synonymous with x and belongs to the same synset as x, and all other dj 6= di are detractors, i.e. false answers that are not synonymous with x. Elements of D and the position of the correct answer are randomly selected. MSR is tested by using its values in selecting a possible answer for the problem word x. In the case of some wordnets, including plWordNet, many synsets are singletons and inc"
2018.gwc-1.26,W17-6615,0,0.020436,"17) performed “evaluation focused on data efficiency&quot; with respect to 4 categories, namely: “Similarity, Analogy, Sentence and Single word”. In the case of similarity, which is most interesting for us, they used only well known data sets for English. For each type of dataset different combinations of preprocessing and classification algorithms were applied. It is worth to notice, that the cost of preparing larger datasets for another language than English is quite substantial. This is one of the reasons that it is hard to find such approaches for other languages, with notable exceptions e.g. (Hartmann et al., 2017) for Portuguese. In our case we want to explore the possibility of constructing of large test datasets on the basis of an already existing wordnet. As the primary application we focused on is support for wordnet development, so comparison with data collected in experiments with humans is not necessarily the best solution for us. 3 Wordnet-based Evaluation In many approaches a wordnet was used to generate a wordnet-based measure of semantic similarity that was next used to assess the correlation between it and an MSR, e.g. (Lin, 1998). It was assumed that similarity rankings generated by the tw"
2018.gwc-1.26,P12-1092,0,0.161838,"Missing"
2018.gwc-1.26,kurc-etal-2012-constraint,1,0.77959,"erged to single tokens. This simple test is meaningful only for large, comprehensive wordnets or wordnets describing well some selected domains. However, WBCR has very simple interpretation and can be easily tuned to different subsets or domains of words and senses. plWNC-multi was prepared with the help of Liner2 tool (Marci´nczuk et al., 2013) for recognition and classification of PNs. plWordNet 3.1 includes almost 60,000 Polish MWEs represented as lexical units and described by lexicalised morpho-syntactic constraints that allow for their efficient and accurate recognition in tagged texts (Kurc et al., 2012). We represent Proper Names (one and multiword, including many common words) and multiword expressions as single tokens in plWNC-multi in order to block the interpretation of their components as individual words. Components of PNs and MWEs can have very specific meanings (e.g. in non-compositional MWEs) that can influence the resulting word embeddings. Corpora created from the Polish Wikipedia data alone (of ≈ 600M words) were used in two experiments reported in the literature. We evaluated these published word embedding models against our tests, too, see Sec. 5 4 4.2 1. for the problem word x"
2018.gwc-1.26,P98-2127,0,0.52711,"r other languages, with notable exceptions e.g. (Hartmann et al., 2017) for Portuguese. In our case we want to explore the possibility of constructing of large test datasets on the basis of an already existing wordnet. As the primary application we focused on is support for wordnet development, so comparison with data collected in experiments with humans is not necessarily the best solution for us. 3 Wordnet-based Evaluation In many approaches a wordnet was used to generate a wordnet-based measure of semantic similarity that was next used to assess the correlation between it and an MSR, e.g. (Lin, 1998). It was assumed that similarity rankings generated by the two measures should be similar. However, there are many wordnet-based similarity measures of different properties and some of them depend on additional knowledge like information about the frequency of word senses. Thus, the result of the comparison can be different depending on the wordnetbased similarity measure applied and in all cases is not straightforward in interpretation. We want to follow a different approach and to explore two methods that are free of these problems. 3.1 Synonymy tests (Freitag et al., 2005) proposed a wordne"
2018.gwc-1.26,R13-1058,1,0.86735,"word embeddings models from the largest corpus of Polish available. Next we evaluated them in several tests based on plWordNet 3.1 (i.e. the most contemporary version) and compared with other word embedding models for Polish extracted from smaller corpora and published in the web. 4.1 Corpora and preprocessing As a basis for the experiments we selected plWordNet 3.1 – a very large wordnet of Polish including ≈190,500 different words, described by ≈282,500 senses, more than 217,000 synsets and more than 750,000 relation links. plWordNet has been built by corpus-based wordnet developed method (Maziarz et al., 2013) and expresses very good coverage of words in large corpora (Maziarz et al., 2016). We calculated our word embeddings model on the basis of plWordNet Corpus 10.0 (plWNC) of Polish, Word embedding models tested For the generation of word2vec models Gensim library ˇ uˇrek and Sojka, 2010). On the basis was used (Reh˚ of the set of 6 parameters, we selected during preexperiments 9 different types of models to be evaluated experimentally, i.e. the following combinations: 1. vector size: 100, 300 and 1000, 2. algorithm type: Skip-gram, CBOW ns (with negative subsampling) and CBOW hs (with hierarchi"
2018.gwc-1.26,D15-1036,0,0.0186496,"eaction to a stimuli, e.g. (Auguste et al., 2017) measured the correlation between the reaction times in the context of priming with ranking based on word embeddings. However, this is slightly different situation than analysis of lexical meanings during language utterance interpretation, especially a textual utterance. MSR is extracted from a text corpus, and it is more natural to evaluate it against language resources. Moreover, (Faruqui et al., 2016) noticed that the distinction between similarity and relatedness is not well defined and consistently expressed in most popular test datasets. (Schnabel et al., 2015) evaluated systematically different DS models, but finally all tests were based on data collected during crowdsourcing experiments using Amazon Turk. (Jastrzebski et al., 2017) performed “evaluation focused on data efficiency&quot; with respect to 4 categories, namely: “Similarity, Analogy, Sentence and Single word”. In the case of similarity, which is most interesting for us, they used only well known data sets for English. For each type of dataset different combinations of preprocessing and classification algorithms were applied. It is worth to notice, that the cost of preparing larger datasets f"
2018.gwc-1.26,wolinski-2014-morfeusz,0,0.0357077,"Missing"
2018.gwc-1.29,P14-1113,0,0.144322,"proper representation of less frequent words (even words with frequency 100–200 per 1G can be erroneously 1 Lexical units here are triples: lemma, Part of Speech and sense id. described, not mentioning those &lt; 100). So, the question is whether we can successfully recognise among the associations suggested by word embeddings those that correspond to lexico-semantic relations, i.e. whether we can interpret word embeddings in a meaningful way for humans. The works presented for English are contradictory even in the case of hypernymy – the relatively simplest relation: from successful extraction (Fu et al., 2014) till denial of the feasibility of such a method (Levy et al., 2015). We want to re-approach this intriguing issues, first checking the contradictory points of the view on large corpora and comprehensive wordnet for Polish, second by expanding this research with one more relation, a more difficult one, namely meronymy. This is a part of a broader work on the automated extraction of lexico-semantic relations that are under-represented in wordnets, e.g. in order to improve wordnet-based WSD. 2 Related Works ClassHyp system of (Piasecki et al., 2008) used a measure of semantic relatedness based o"
2018.gwc-1.29,N15-1098,0,0.0751857,"uency 100–200 per 1G can be erroneously 1 Lexical units here are triples: lemma, Part of Speech and sense id. described, not mentioning those &lt; 100). So, the question is whether we can successfully recognise among the associations suggested by word embeddings those that correspond to lexico-semantic relations, i.e. whether we can interpret word embeddings in a meaningful way for humans. The works presented for English are contradictory even in the case of hypernymy – the relatively simplest relation: from successful extraction (Fu et al., 2014) till denial of the feasibility of such a method (Levy et al., 2015). We want to re-approach this intriguing issues, first checking the contradictory points of the view on large corpora and comprehensive wordnet for Polish, second by expanding this research with one more relation, a more difficult one, namely meronymy. This is a part of a broader work on the automated extraction of lexico-semantic relations that are under-represented in wordnets, e.g. in order to improve wordnet-based WSD. 2 Related Works ClassHyp system of (Piasecki et al., 2008) used a measure of semantic relatedness based on Distributional Semantics together with several statistical knowled"
2018.gwc-1.29,W14-0142,1,0.828834,"in fact. In our work we verified both claims using a very large wordnet of Polish as a gold standard for lexico-semantic relations and word embeddings extracted from a very large corpus of Polish. We showed that a hyponymy extraction method based on linear regression classifiers trained on clusters of vectors can be successfully applied on large scale. We presented also a possible explanation for contradictory findings in the literature. Moreover, in order to show the feasibility of the method we extended it to the recognition of meronymy. 1 Introduction A very large wordnet, e.g. plWordNet (Maziarz et al., 2014) describes many lexico-semantic relations, linking lexical units1 (or word senses) by thousands of relation instances. However, even in a very large wordnet some relation instances can be omitted and typically wordnets are very biased towards only a few relations, e.g. hypernymy/hyponymy for nouns, with much smaller coverage for the other. Measures of semantic relatedness constructed on the basis of word embeddings (Mikolov et al., 2013b) are known to express many different lexico-semantic relations, e.g. on a list of the k most related words to a word x we can typically find words associated"
2018.gwc-1.29,C16-1213,1,0.820821,"beddings The method proposed by (Fu et al., 2014) intuitively seems to be correct: elements of the word embeddings are derived from the occurrence contexts and correspond to the semantic features of words, while the similarity of features of two words correspond to the amount of overlapping in the values. This inspired us to revisit the method of (Fu et al., 2014) in a new setting and confront it once again with the objections of (Levy et al., 2015). 3.1 Corpora and Vector-based Representation As a gold standard for lexico-semantic relations we used plWordNet – a very large wordnet of Polish (Maziarz et al., 2016). It is substantially bigger then Princeton WordNet (Fellbaum, 1998), and was constructed from scratch using a corpus-based wordnet development method. As a result plWordNet has much better coverage of words in large corpora than other wordnets including Princeton WordNet. As a source of text data, we utilised plWordNet Corpus (henceforth plWNC) which includes ≈4 billion words and combines all publicly available Polish corpora, and a very large number of Polish texts collected from the Web2 . Using word2vec tool (Mikolov et al., 2013a) we built embedding vectors as representations for all word"
2018.gwc-1.29,P16-1226,0,0.0903929,"ures might lack the necessary information to deduce how one word relates to another”. However, it is worth to notice that the reported results for supervised approaches based on two vectors were in fact in the most cases slightly but significantly better than single-vector results, and (Levy et al., 2015) did not apply the original approach of (Fu et al., 2014) in their key tests (sic!). Moreover, all evaluations were done only for English and for quite limited test data. However, there are also many other works that report on successful extraction of hypernymy from contextual features, e.g. (Shwartz et al., 2016). 3 Search for Relations in Word Embeddings The method proposed by (Fu et al., 2014) intuitively seems to be correct: elements of the word embeddings are derived from the occurrence contexts and correspond to the semantic features of words, while the similarity of features of two words correspond to the amount of overlapping in the values. This inspired us to revisit the method of (Fu et al., 2014) in a new setting and confront it once again with the objections of (Levy et al., 2015). 3.1 Corpora and Vector-based Representation As a gold standard for lexico-semantic relations we used plWordNet"
2018.gwc-1.29,wolinski-2014-morfeusz,0,0.0213525,"(e.g. polysemy, differences in contexts of occurrences etc.) and the set of additional features introduced by a hyponym. So the difference can 2 It consists of IPI PAN Corpus (Przepiórkowski, 2004), the first annotated corpus of Polish, National Corpus of Polish (Przepiórkowski et al., 2012), Polish Wikipedia (from 2016), Rzeczpospolita Corpus (Weiss, 2008) – a corpus of electronic editions of a Polish newspaper from the years 1993-2003, supplemented with text acquired from the Web – only text with small percentage of words unknown to a very comprehensive morphological analyser Morfeusz 2.0 (Woliński, 2014) were included; duplicates were automatically eliminated from the merged corpus. be biased beyond the capabilities of a representation by a single common hypernymy projection. In order to obtain a more regular picture, difference vectors for the training hyponymy instances are automatically clustered and for each cluster a different classifier is trained. The k-means algorithm was used for clustering and for each cluster a separated classifier was trained by the linear regression method. In a similar way, negative examples of non-hyponymic pairs constructed on the basis of plWordNet are cluste"
2018.gwc-1.39,baccianella-etal-2010-sentiwordnet,0,0.297316,"Missing"
2018.gwc-1.39,esuli-sebastiani-2006-sentiwordnet,0,0.242103,"Missing"
2018.gwc-1.39,maks-etal-2014-generating,0,0.0350517,"Missing"
2018.gwc-1.39,C16-1213,1,0.892377,"Missing"
2018.gwc-1.39,vossen-etal-2008-integrating,0,0.0291171,"Missing"
2018.gwc-1.39,strapparava-valitutti-2004-wordnet,0,0.435109,"Missing"
2018.gwc-1.39,R15-1092,1,0.895039,"Missing"
2018.gwc-1.6,R13-1058,1,0.807177,"Missing"
2018.gwc-1.6,R15-1056,1,0.887855,"Missing"
2018.gwc-1.6,C16-1213,1,0.926399,"Missing"
2018.gwc-1.6,R15-1092,1,0.862065,"Missing"
2019.gwc-1.45,C96-1005,0,0.475666,"ordnet development. In plWordNet 3.0 (Maziarz et al., 2016) LUs located in the lower parts of the hypernymy hierarchy were often described by only a few relation links, if not just one. Thus, their meaning descriptions were limited, especially those described by single hyponymy links connecting to the same hypernym. There was no meaning distinction between such LUs. Diversity and density of relation links is crucial for many applications of a wordnet, e.g. comparison of meanings, analysis of selectional preferences (McCarthy and Carroll, 2003, Hajnicz et al., 2016), Word Sense Disambiguation (Agirre and Rigau, 1996, Kędzia et al., 2015), texts semantic indexing (Scott and Matwin, 1998), query expansion in Information Retrieval (Voorhees, 1998, Varelas et al., 2005), or construction of topic descriptors for media monitoring (Johansson et al., 2012). Taking the above into account, we have proposed an expansion of the plWordNet model by several new relations, described in the next section. In sum, we will have 33 types of synset relations (52 when counting subtypes) and 20 types of LU relations, i.e. not shared among LUs (56 including subtypes). 2.1 Nouns The system of noun relations in plWordNet 4.1 is ba"
2019.gwc-1.45,broda-etal-2012-kpwr,0,0.0278867,"l research in the lexical system and its disfunction of patients suffering from dementia and Alzheimer disease. It was also utilised in Social Sciences, including an analysis of the language in Polish social media (digital trace, speaker intention, content of blog posts) (Haniewicz et al., 2014, Wawer and Sarzyńska, 2018), analysis of personal self-descriptions (structure and content), and analysis of commercials in media IwińskaKnop and Krystyańczuk (2016). plWordNet was used to construct new resources, e.g. the system of Polish National Library descriptors was mapped on it, and KPWr Corpus (Broda et al., 2012), Składnica Corpus (Woliński et al., 2011) were annotated by the selected LUs. The most numerous group are applications in Natural Language Engineering, e.g. evaluation of word embedding models on the basis of synonymy tests automatically generated from plWordNet (Piasecki et al., 2018), named entity recognition, text mining and semantic search (Maciołek and Dobrowolski, 2013), text classification and text relation recognition (Brzeski and Boiński, 2014), semantic indexing of text (Karwowski et al., 2018), assignment of descriptive keywords to text documents (as knowledge basis and keyword rep"
2019.gwc-1.45,2018.gwc-1.14,1,0.594984,"Missing"
2019.gwc-1.45,L16-1418,0,0.121956,"via substitution tests that are then used in the wordnet development. In plWordNet 3.0 (Maziarz et al., 2016) LUs located in the lower parts of the hypernymy hierarchy were often described by only a few relation links, if not just one. Thus, their meaning descriptions were limited, especially those described by single hyponymy links connecting to the same hypernym. There was no meaning distinction between such LUs. Diversity and density of relation links is crucial for many applications of a wordnet, e.g. comparison of meanings, analysis of selectional preferences (McCarthy and Carroll, 2003, Hajnicz et al., 2016), Word Sense Disambiguation (Agirre and Rigau, 1996, Kędzia et al., 2015), texts semantic indexing (Scott and Matwin, 1998), query expansion in Information Retrieval (Voorhees, 1998, Varelas et al., 2005), or construction of topic descriptors for media monitoring (Johansson et al., 2012). Taking the above into account, we have proposed an expansion of the plWordNet model by several new relations, described in the next section. In sum, we will have 33 types of synset relations (52 when counting subtypes) and 20 types of LU relations, i.e. not shared among LUs (56 including subtypes). 2.1 Nouns"
2019.gwc-1.45,L18-1291,0,0.0593431,"Missing"
2019.gwc-1.45,J98-1006,0,0.345683,"tions almost identical to adjective relations – with the exclusion of modifier – and a set of LU relations including: antonymy (complementary and gradable), and cross-categorial synonymy to adjectives. Similarly to the adjective relations, we keep the adverb relations unchanged. Collocation A large wordnet can be successfully used as a knowledge base for Word Sense Disambiguation, but the quality of the resulting system depends a lot on the richness of a network of connections between words from texts via their senses, especially between senses that are likely to co-occur in similar contexts (Leacock et al., 1998). Unfortunately, the coverage of such associations is limited by typical wordnet relations. Following the above observation, we introduce a collocation relation for LUs that links lexical meanings, not words. In contrast to the definitional feature relation, which is based on a semantically motivated, paradigmatic feature, collocation follows the corpus supported language data and indicates frequent meaning co-occurrences. It can link two LUs of any of part of speech, if they co-occur often enough in corpora. So far we have added 16 979 instances of the collocation relation for all parts of sp"
2019.gwc-1.45,lis-2012-polish,0,0.0249124,"ered users (both individual and institutional). It has also had a quite large number of non-registered users and tens of thousands of users of the on-line browser2 . On the basis of citations, questionnaires of the registered users, and direct co-operation with users within CLARIN, we can attempt an overview of plWordNet 4.1 applications. First, it was applied in linguistics for an analysis of lexico-semantic fields (Stanulewicz, 2010), analysis of word-forming nests (Lango et al., 2018), derivational processes (Kyjánek, 2018), 2 http://plwordnet.pwr.edu.pl identification of semantic classes (Lis, 2012), study on multi-word expressions (support for their extraction, recognition, classification) (Mykowiecka and Marciniak, 2012), and measuring semantic similarity of words (on the basis of their relation structure) (Siemiński, 2012). It found several applications in bilingual lexicography, e.g. in the study on partial equivalences in bilingual dictionaries (Liu, 2018), building a multilingual dictionary of the Yiddish language, as well as development of several bilingual and multilingual dictionaries (Sosnowski and Koseska-Toszewa, 2015). plWordNet was used in applied linguistics, e.g. in studi"
2019.gwc-1.45,2018.gwc-1.6,1,0.754863,"on may suggest that it is. However, this is misleading. In the case of a very large wordnet, the focus shifts from mere growth to the improvement of the amount and quality of information expressed for different lexical meanings. We plan to continue the work on increasing the density of relations (especially for LUs described so far by a few, if not single links), continuous maintenance of the wordnet quality by encompassing new lemmas and LUs in a corpus-based way. Instead of incorporating more and more specialist vocabulary, we plan to develop a system of crossresource mappings envisaged in (Maziarz and Piasecki, 2018) in order to build a system of terminological, ontological and knowledge resources around plWordNet and make it an interface between them and the natural language lexicon. In addition, we also plan to further expand the relation structure towards better support for Word Sense Disambiguation. Moreover, we are going to continue the works on sense-level mappings. While proceeding with manual mapping, we are also going to develop a semi-automatic prompt system. Acknowledgements The work co-financed as part of the investment in the CLARIN-PL research infrastructure funded by the Polish Ministry of"
2019.gwc-1.45,R13-1058,1,0.927426,"Missing"
2019.gwc-1.45,C16-1213,1,0.82814,"Missing"
2019.gwc-1.45,J03-4004,0,0.154774,"ctly refer to language data via substitution tests that are then used in the wordnet development. In plWordNet 3.0 (Maziarz et al., 2016) LUs located in the lower parts of the hypernymy hierarchy were often described by only a few relation links, if not just one. Thus, their meaning descriptions were limited, especially those described by single hyponymy links connecting to the same hypernym. There was no meaning distinction between such LUs. Diversity and density of relation links is crucial for many applications of a wordnet, e.g. comparison of meanings, analysis of selectional preferences (McCarthy and Carroll, 2003, Hajnicz et al., 2016), Word Sense Disambiguation (Agirre and Rigau, 1996, Kędzia et al., 2015), texts semantic indexing (Scott and Matwin, 1998), query expansion in Information Retrieval (Voorhees, 1998, Varelas et al., 2005), or construction of topic descriptors for media monitoring (Johansson et al., 2012). Taking the above into account, we have proposed an expansion of the plWordNet model by several new relations, described in the next section. In sum, we will have 33 types of synset relations (52 when counting subtypes) and 20 types of LU relations, i.e. not shared among LUs (56 includin"
2019.gwc-1.45,C12-1119,0,0.540488,"Missing"
2019.gwc-1.45,2018.gwc-1.22,1,0.663498,"bulary. We include these units in plWordNet only when we can confirm their use in texts, for example in freely available old literature. For this reason and because of the presence of modern vocabulary in our corpora that we write about in Sec. 3., the quantity of inter-register synonymy linking synsets with LUs of divergent registers is increasing (in 4.1 version it amounts to 12 223 instances for all parts of speech, of which most for nouns – 7 171). We expect that this process will advance. 3.2 Non-relational Elements and Verification In 2017 a wordnet editor system called WordnetLoom 2.0 (Naskręt et al., 2018) was enriched with the ability to record comments concerning the correctness of a given LU and synset. Information that has been collected by this system is one of the inputs to the plWordNet verification process started by us. We use also data collected from the diagnostic tools (Piasecki et al., 2016). The verification of plWordNet is performed on the two levels of LUs and synsets. Both are described by an additional status feature whose value is set by a lexicographer after each operation: verified, partially processed, new, meaning, erroneous and not processed, with the last one as a defau"
2019.gwc-1.45,2018.gwc-1.26,1,0.759164,"t al., 2014, Wawer and Sarzyńska, 2018), analysis of personal self-descriptions (structure and content), and analysis of commercials in media IwińskaKnop and Krystyańczuk (2016). plWordNet was used to construct new resources, e.g. the system of Polish National Library descriptors was mapped on it, and KPWr Corpus (Broda et al., 2012), Składnica Corpus (Woliński et al., 2011) were annotated by the selected LUs. The most numerous group are applications in Natural Language Engineering, e.g. evaluation of word embedding models on the basis of synonymy tests automatically generated from plWordNet (Piasecki et al., 2018), named entity recognition, text mining and semantic search (Maciołek and Dobrowolski, 2013), text classification and text relation recognition (Brzeski and Boiński, 2014), semantic indexing of text (Karwowski et al., 2018), assignment of descriptive keywords to text documents (as knowledge basis and keyword repository) (Kaleta, 2014), automated structuring of text data (Maciołek and Dobrowolski, 2010), text interpretation in chat bots, text semantic similarity calculation (Siemiński, 2012), antiplagiarism systems (Szmit, 2017), generation of semantically related families/sets of words for Inf"
2019.gwc-1.45,przepiorkowski-etal-2014-walenty,0,0.394518,"Missing"
2019.gwc-1.45,C12-2101,1,0.772725,"1365 Adj pl 4338 1493 95 0 375 44389 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1067 946 22697 75401 en 4339 1430 92 0 44373 374 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 50608 Total pl 45991 7625 2195 10785 31302 140032 7945 7724 623 40 157 21 12 451 102 126 6 34 64 313 37 6 18 80 1069 947 22795 280502 en 45990 7439 2195 7945 140032 31305 10785 623 7724 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 254038 Table 3: Interlingual relation counts It took the form of manual mapping that is aligning wordnet nodes (synsets) corresponding in meanings and relation structures via a rich set of interlingual relations, (Rudnicka et al., 2012). It quickly turned out that interlingual synonymy (representing Simple Equivalence, cf. Vossen (2002)) is not enough to link two independently built resources for two quite different languages. English is an analytical Germanic language, while Polish a synthetic Slavic one. Therefore, other Complex Equivalence relations had to be resorted to. In Tab. 3, we present the full list of interlingual relations with their respective counts. The most frequent one is interlingual hyponymy and this tendency occurs across all parts of speech. In the latest 4.1 version of plWordNet, we have expanded the s"
2019.gwc-1.45,W09-1127,0,0.0423883,"et, but with a lot of cooperation between the two teams. This resulted in its schema referring to plWordNet LUs and semantic selectional preferences often annotated with plWordNet synsets (Hajnicz et al., 2016). Unfortunately, the old, 2.1 version of plWordNet was used for this purpose. Our goal was to automatically map the semantic roles of Walenty onto plWordNet in order to increase the density of its relations. In contrast to FrameNet (Ruppenhofer et al., 2006), automatically linked to Princeton WordNet on the basis of similarity of paraphrases of its units and Princeton WordNet relations (Tonelli and Pighin, 2009), the linking between plWordNet and Walenty was done semi-automatically, with a lot of manual verification. First, we compared 2.1 and 3.0 versions of plWordNet and generated a list of plWordNet synsets whose content differed between the two versions. Next, two rounds of correction were carried out: automatic (based on the comparison of synset content and LU properties) and manual (for synsets which represented too big discrepancies between the two versions). In the latter case, we corrected the discrepancies. The differences between 2.1 and 4.0 synsets were mainly due to the introduction of n"
2019.gwc-1.45,R15-1092,1,0.852381,"indexing of text (Karwowski et al., 2018), assignment of descriptive keywords to text documents (as knowledge basis and keyword repository) (Kaleta, 2014), automated structuring of text data (Maciołek and Dobrowolski, 2010), text interpretation in chat bots, text semantic similarity calculation (Siemiński, 2012), antiplagiarism systems (Szmit, 2017), generation of semantically related families/sets of words for Information Retrieval and Internet monitoring and text normalisation, e.g. in the legal domain (Pełech-Pilichowski et al., 2014). As plWordNet is expanded with emotive annotation, cf (Zaśko-Zielińska et al., 2015), it has been applied several times in sentiment analysis and development of sentiment lexicons (Rybiński, 2017). Finally, it was used in Jasnopis system for the analysis of text difficulty to extract synonyms and hypernyms of words classified as too difficult for the intended text difficulty level (Dębowski et al., 2015). 6 Further Works Is it ever possible to complete a wordnet? plWordNet 4.1 size and coverage, as well as its growth since 3.0 version may suggest that it is. However, this is misleading. In the case of a very large wordnet, the focus shifts from mere growth to the improvement"
2019.gwc-1.46,baccianella-etal-2010-sentiwordnet,0,0.601331,"nz♢ and Maciej Piasecki♢ ♠ Nanyang Technological University, Singapore ♢ Wrocław University of Science and Technology, Poland bond@ieee.org, {arkadius.janz|maciej.piasecki}@pwr.edu.pl Abstract In this paper, we compare a variety of sense-tagged sentiment resources, including SentiWordNet, ML-Senticon, plWordNet emo and the NTU Multilingual Corpus. The goal is to investigate the quality of the resources and see how well the sentiment polarity annotation maps across languages. 1 Introduction There are several semantic resources with senses annotated by sentiment polarity, e.g. SentiWordNet 3.0 (Baccianella et al., 2010) and even emotions, e.g. WordNet-Affect (Strapparava and Valitutti, 2004; Torii et al., 2011). However, most of them were built on the basis of automated expansion of a small subset of senses described manually. In addition the majority of them were built for a single language, namely English, with MLSentiCon (Cruz et al., 2014) a notable exception. This paper present the results of comparing two very different sense-level sentiment resources: a very large semantic lexicon annotated manually for Polish, i.e. plWordNet (Maziarz et al., 2016) expanded with manual emotive annotations (ZaśkoZieliń"
2019.gwc-1.46,P13-1133,1,0.804304,"nd Bond, 2012) has a variety of texts and their translations, many of which are sense annotated.2 Two stories from the Sherlock Holmes Canon (The Adventure of the Speckled Band and The Adventure of the Dancing Men) have been both sense tagged with wordnet senses and annotated for sentiment (Bond et al., 2016a). Princeton Wordnet (Fellbaum, 1998) was used for English, the Chinese Open Wordnet for Chinese (Wang and Bond, 2013) and the Japanese wordnet for Japanese (Bond et al., 2009). These are linked through Princeton WordNet 3.0 (Fellbaum, 1998) with the help of the open multilingual wordnet (Bond and Foster, 2013). In addition, pronouns (Seah and Bond, 2014) and new concepts that were discovered in the corpus during the annotation have been added. A continuous scale was used for tagging sentiment, with scores from -100 to 100. The tagging tool splits these into seven values by default (-95, -64, -34, 0, 34, 64, 95), and there are keyboard shortcuts to select these values. Three values were chosen for each polarity, in order to be able to show the changes in chunks: quite good is less positive than good and this is less positive than very good. Annotators could select different, more fine-grained values"
2019.gwc-1.46,2016.gwc-1.9,1,0.842256,"ly. In addition the majority of them were built for a single language, namely English, with MLSentiCon (Cruz et al., 2014) a notable exception. This paper present the results of comparing two very different sense-level sentiment resources: a very large semantic lexicon annotated manually for Polish, i.e. plWordNet (Maziarz et al., 2016) expanded with manual emotive annotations (ZaśkoZielińska et al., 2015); the annotation of two English short stories (The Adventure of the Speckled Band and The Adventure of the Dancing Men (Conan Doyle, 1892, 1905)) and their Chinese and Japanese translations (Bond et al., 2016a). As the stories have been annotated on the basis of senses, not words – i.e. all words were assigned Princeton WordNet synsets – this opens an unique possibility of cross-lingual comparison of manual sentiment annotation at the level of word senses. These are then compared with SentiWordNet and MLSentiCon and finally they are all compared to a small gold standard sample Micro-WNOp Corpus (Cerini et al., 2007). Our technical goal is to analyse the feasibility and technical means of correlation between independently created resources as the first step towards cross-lingual applications. Takin"
2019.gwc-1.46,W13-2319,1,0.807562,"nses. When we compare across languages, if a synset appears in the corpus multiple times, we add it to the comparison set as often as the least frequent language. Thus for example, if between Chinese and English, 02433000-a “showing the wearing effects of overwork or care or suffering” appeared three times in Chinese (as 憔悴 qiáo cuì) with an average score of -48.5 and twice in English with a score of −64 (as haggard and drawn), we would count this as two occurrences of −48.5 (in Chinese) and −64 (in English). In general, fewer than half of the concepts align directly across any two languages (Bond et al., 2013). Even though we have over 12,000 occurences concepts in English and more in Chinese and Japanese (Table 2) fewer than 7,000 appear in both (Table 4). Pair Chinese-English Chinese-Japanese English-Japanese ρ .73 .77 .76 # samples 6,843 4,099 4,163 Table 4: Correlation between the different language pairs For most concepts, the agreement across languages was high, although rarely identical. There was high agreement for the polarity but not necessarily in intensity/magnitude. For example, for the concept 02433000-a “haggard”, the English words drawn and haggard were given scores of −64, while Ch"
2019.gwc-1.46,esuli-sebastiani-2006-sentiwordnet,0,0.22212,"Missing"
2019.gwc-1.46,C16-1213,1,0.932383,"ted by sentiment polarity, e.g. SentiWordNet 3.0 (Baccianella et al., 2010) and even emotions, e.g. WordNet-Affect (Strapparava and Valitutti, 2004; Torii et al., 2011). However, most of them were built on the basis of automated expansion of a small subset of senses described manually. In addition the majority of them were built for a single language, namely English, with MLSentiCon (Cruz et al., 2014) a notable exception. This paper present the results of comparing two very different sense-level sentiment resources: a very large semantic lexicon annotated manually for Polish, i.e. plWordNet (Maziarz et al., 2016) expanded with manual emotive annotations (ZaśkoZielińska et al., 2015); the annotation of two English short stories (The Adventure of the Speckled Band and The Adventure of the Dancing Men (Conan Doyle, 1892, 1905)) and their Chinese and Japanese translations (Bond et al., 2016a). As the stories have been annotated on the basis of senses, not words – i.e. all words were assigned Princeton WordNet synsets – this opens an unique possibility of cross-lingual comparison of manual sentiment annotation at the level of word senses. These are then compared with SentiWordNet and MLSentiCon and finally"
2019.gwc-1.46,P10-1114,0,0.0234995,"http://www.globalwordnet.org/ili/ixxx. 2.5 The Micro-WNOp Corpus We evaluated the Micro-WNOp Corpus (Cerini et al., 2007) as it is the only sense-tagged sentiment lexicon we could find.4 It was used to evaluate SentiWordNet and build ML-SentiCon, and consists of 1,105 Wordnet synsets chosen from the General Inquirer lexicon (Stone et al., 1966) and annotated by 1–3 annotators. There are many corpora tagged for sentiment, for example the Stanford Sentiment Treebank (Socher et al., 2013), but few multilingual (Balahur and Turchi, 2014) and no multilingual sentiment corpora for Asian languages. (Prettenhofer and Stein, 2010) contains English, French, German and Japanese product reviews, but they are comparable (reviews of the same product) or machine translated, not translated text, so while useful it is not suitable for studying close correspondences. 3 Comparisons We are going to compare four languages and two types of resources: a corpus and a lexicon from the perspective of sentiment polarity annotation. In order to make the comparison feasible, we focus on word senses – that can be represented by concepts – and their mappings across languages, as links between the different resources. There are both manually"
2019.gwc-1.46,D13-1170,0,0.00719287,"e over all the lemmas in all the languages. The concepts are identified with the Interlingual Index (Bond et al., 2016b).3 3 LOD: http://www.globalwordnet.org/ili/ixxx. 2.5 The Micro-WNOp Corpus We evaluated the Micro-WNOp Corpus (Cerini et al., 2007) as it is the only sense-tagged sentiment lexicon we could find.4 It was used to evaluate SentiWordNet and build ML-SentiCon, and consists of 1,105 Wordnet synsets chosen from the General Inquirer lexicon (Stone et al., 1966) and annotated by 1–3 annotators. There are many corpora tagged for sentiment, for example the Stanford Sentiment Treebank (Socher et al., 2013), but few multilingual (Balahur and Turchi, 2014) and no multilingual sentiment corpora for Asian languages. (Prettenhofer and Stein, 2010) contains English, French, German and Japanese product reviews, but they are comparable (reviews of the same product) or machine translated, not translated text, so while useful it is not suitable for studying close correspondences. 3 Comparisons We are going to compare four languages and two types of resources: a corpus and a lexicon from the perspective of sentiment polarity annotation. In order to make the comparison feasible, we focus on word senses – t"
2019.gwc-1.46,strapparava-valitutti-2004-wordnet,0,0.513871,"Missing"
2019.gwc-1.46,W11-1710,0,0.0210103,"nce and Technology, Poland bond@ieee.org, {arkadius.janz|maciej.piasecki}@pwr.edu.pl Abstract In this paper, we compare a variety of sense-tagged sentiment resources, including SentiWordNet, ML-Senticon, plWordNet emo and the NTU Multilingual Corpus. The goal is to investigate the quality of the resources and see how well the sentiment polarity annotation maps across languages. 1 Introduction There are several semantic resources with senses annotated by sentiment polarity, e.g. SentiWordNet 3.0 (Baccianella et al., 2010) and even emotions, e.g. WordNet-Affect (Strapparava and Valitutti, 2004; Torii et al., 2011). However, most of them were built on the basis of automated expansion of a small subset of senses described manually. In addition the majority of them were built for a single language, namely English, with MLSentiCon (Cruz et al., 2014) a notable exception. This paper present the results of comparing two very different sense-level sentiment resources: a very large semantic lexicon annotated manually for Polish, i.e. plWordNet (Maziarz et al., 2016) expanded with manual emotive annotations (ZaśkoZielińska et al., 2015); the annotation of two English short stories (The Adventure of the Speckled"
2019.gwc-1.46,W13-4302,1,0.897056,"comparison we aim for is limited only to sentiment polarity, both emotions and fundamental values will be ignored in comparison. 2.4 NTU Multilingual Corpus The NTU Multilingual Corpus (Tan and Bond, 2012) has a variety of texts and their translations, many of which are sense annotated.2 Two stories from the Sherlock Holmes Canon (The Adventure of the Speckled Band and The Adventure of the Dancing Men) have been both sense tagged with wordnet senses and annotated for sentiment (Bond et al., 2016a). Princeton Wordnet (Fellbaum, 1998) was used for English, the Chinese Open Wordnet for Chinese (Wang and Bond, 2013) and the Japanese wordnet for Japanese (Bond et al., 2009). These are linked through Princeton WordNet 3.0 (Fellbaum, 1998) with the help of the open multilingual wordnet (Bond and Foster, 2013). In addition, pronouns (Seah and Bond, 2014) and new concepts that were discovered in the corpus during the annotation have been added. A continuous scale was used for tagging sentiment, with scores from -100 to 100. The tagging tool splits these into seven values by default (-95, -64, -34, 0, 34, 64, 95), and there are keyboard shortcuts to select these values. Three values were chosen for each polari"
2019.gwc-1.46,R15-1092,1,0.837705,"ation, basic emotions and fundamental human values. The latter two provide additional characteristics and help annotators to determine the sentiment polarity and its intensity expressed in the 5 grade scale: strong or weak vs negative and positive. Each annotator’s decision for polarised senses is supported by use examples – a sentence including the given sense and illustrating the postulated sentiment polarity and its strength. Concerning emotions, due to the compatibility with other wordnet-based annotations, the set of eight basic emotions recognised by Plutchik (Plutchik, 1980) were used (Zaśko-Zielińska et al., 2015). It contains Ekman’s six basic emotions (Ekman, 1992): joy , fear, surprise, sadness, disgust, anger, complemented by Plutchik’s trust and anticipation. As a result, negative emotions do not prevail in the set. One sense can be assigned more than one emotion and, as a result, complex emotions can be represented by using the same eightelement set, following the observations of Plutchik (1980). However, as the comparison we aim for is limited only to sentiment polarity, both emotions and fundamental values will be ignored in comparison. 2.4 NTU Multilingual Corpus The NTU Multilingual Corpus (T"
2020.lrec-1.233,P18-2057,0,0.0142542,"small annotated seed of already known word pairs linked by hyponymy relation). However, such approaches are limited to relations expressed by relatively stable and specific patterns and may result in good precision but mostly low recall, that is not acceptable for the construction of monitoring search queries. With the progress of neural representation learning (word embeddings, contextual embeddings) and neural classification methods (bidirectional recurrent models, convolutional networks, and finally transformers) new approaches have emerged e.g. (Shwartz et al., 2016; Nguyen et al., 2017; Roller et al., 2018; Qu et al., 2018; Eberts and Ulges, 2019). They improved generalisation of the relation models by mapping context onto vector spaces. New contextualised text representations such as deep bidirectional language models e.g. ELMo(Peters et al., 2018), transformer networks e.g. BERT(Devlin et al., 2018), RoBERTa(Liu et al., 2019), TransformerXL(Dai et al., 2019) have been proposed to significantly improve the performance across a range of natural language processing tasks. 1895 The solutions to the task of relation extraction for namedentities usually follow the pipeline approach where the subtas"
2020.lrec-1.233,P16-1226,0,0.0235402,"irectly from the text (Snow, 2004) (given a small annotated seed of already known word pairs linked by hyponymy relation). However, such approaches are limited to relations expressed by relatively stable and specific patterns and may result in good precision but mostly low recall, that is not acceptable for the construction of monitoring search queries. With the progress of neural representation learning (word embeddings, contextual embeddings) and neural classification methods (bidirectional recurrent models, convolutional networks, and finally transformers) new approaches have emerged e.g. (Shwartz et al., 2016; Nguyen et al., 2017; Roller et al., 2018; Qu et al., 2018; Eberts and Ulges, 2019). They improved generalisation of the relation models by mapping context onto vector spaces. New contextualised text representations such as deep bidirectional language models e.g. ELMo(Peters et al., 2018), transformer networks e.g. BERT(Devlin et al., 2018), RoBERTa(Liu et al., 2019), TransformerXL(Dai et al., 2019) have been proposed to significantly improve the performance across a range of natural language processing tasks. 1895 The solutions to the task of relation extraction for namedentities usually fol"
2020.lrec-1.233,P19-1285,0,0.0139755,"g (word embeddings, contextual embeddings) and neural classification methods (bidirectional recurrent models, convolutional networks, and finally transformers) new approaches have emerged e.g. (Shwartz et al., 2016; Nguyen et al., 2017; Roller et al., 2018; Qu et al., 2018; Eberts and Ulges, 2019). They improved generalisation of the relation models by mapping context onto vector spaces. New contextualised text representations such as deep bidirectional language models e.g. ELMo(Peters et al., 2018), transformer networks e.g. BERT(Devlin et al., 2018), RoBERTa(Liu et al., 2019), TransformerXL(Dai et al., 2019) have been proposed to significantly improve the performance across a range of natural language processing tasks. 1895 The solutions to the task of relation extraction for namedentities usually follow the pipeline approach where the subtasks of entity detection and relation recognition are solved separately. These kind of approaches train two separate models and combine their results to extract semantic relations linking entities in text. However, in the case of a pipeline approach different components can be trained on different datasets. As datasets are often created in different projects, a"
2020.lrec-1.233,N15-1098,0,0.0783067,"Missing"
2020.lrec-1.233,N19-1308,0,0.0187298,"es in text. However, in the case of a pipeline approach different components can be trained on different datasets. As datasets are often created in different projects, a situation in which there are separate trainingtesting sets, e.g. for named-entities (a large, rich one) and relations (much smaller and focused on representing relations) is quite frequent. The tasks of entity detection and relation extraction may benefit from each other when they are combined within the same model and solved together (Figure 3). Recently the joint approaches have become more popular also in other NLP areas. (Luan et al., 2019) has introduced a general framework for relation extraction that is capable of detecting the entities, resolving coreferences and identifying relations between detected entities. The framework was based on the idea of multitask learning paradigm where the loss function was a combination of the log-likelihood values of entity recognition task, relation recognition and coreference resolution. (Eberts and Ulges, 2019) has proposed a joint model for entity identification and relation extraction based on BERT transformer. The architecture of the model consisted of three subtask-oriented layers: i)"
2020.lrec-1.233,E17-1008,0,0.0207052,"(Snow, 2004) (given a small annotated seed of already known word pairs linked by hyponymy relation). However, such approaches are limited to relations expressed by relatively stable and specific patterns and may result in good precision but mostly low recall, that is not acceptable for the construction of monitoring search queries. With the progress of neural representation learning (word embeddings, contextual embeddings) and neural classification methods (bidirectional recurrent models, convolutional networks, and finally transformers) new approaches have emerged e.g. (Shwartz et al., 2016; Nguyen et al., 2017; Roller et al., 2018; Qu et al., 2018; Eberts and Ulges, 2019). They improved generalisation of the relation models by mapping context onto vector spaces. New contextualised text representations such as deep bidirectional language models e.g. ELMo(Peters et al., 2018), transformer networks e.g. BERT(Devlin et al., 2018), RoBERTa(Liu et al., 2019), TransformerXL(Dai et al., 2019) have been proposed to significantly improve the performance across a range of natural language processing tasks. 1895 The solutions to the task of relation extraction for namedentities usually follow the pipeline appr"
2020.lrec-1.233,N18-1202,0,0.140628,"not acceptable for the construction of monitoring search queries. With the progress of neural representation learning (word embeddings, contextual embeddings) and neural classification methods (bidirectional recurrent models, convolutional networks, and finally transformers) new approaches have emerged e.g. (Shwartz et al., 2016; Nguyen et al., 2017; Roller et al., 2018; Qu et al., 2018; Eberts and Ulges, 2019). They improved generalisation of the relation models by mapping context onto vector spaces. New contextualised text representations such as deep bidirectional language models e.g. ELMo(Peters et al., 2018), transformer networks e.g. BERT(Devlin et al., 2018), RoBERTa(Liu et al., 2019), TransformerXL(Dai et al., 2019) have been proposed to significantly improve the performance across a range of natural language processing tasks. 1895 The solutions to the task of relation extraction for namedentities usually follow the pipeline approach where the subtasks of entity detection and relation recognition are solved separately. These kind of approaches train two separate models and combine their results to extract semantic relations linking entities in text. However, in the case of a pipeline approach"
2021.gwc-1.16,P13-1133,0,0.0351653,"the current statistics of interlingual synset relations. 2 Related works WordNet started off as a lexico-semantic network for English (Fellbaum, 1998). With a quickly manifested potential both for linguistics and NLP research, it soon found its followers for other languages, e.g. GermaNet for German, (Hamp and Feldweg, 1997). Since crosslinguistic applications are always welcome, the idea of linking monolingual wordnets into a multilingual network naturally arose. It was put into practice in the EuroWordNet project (Vossen, 1998, 2002) and more recently in the OpenMultilingualWordnet project (Bond and Foster, 2013). Even before the start of EuroWordNet project, it was clear that constructing a wordnet from scratch and later linking it to similar resources is time and moneyconsuming. Few teams could afford it. On the other hand, taking Princeton WordNet as a basic template and expanding on it proved much more economical in terms of the investment needed. The two approaches were called merge and expand, respectively. Yet, science does not operate on a simple winlose model. The expand approach rests on a long-abandoned assumption of the universality of mental lexicon (von Fintel and Matthewson, 2008). Thus"
2021.gwc-1.16,W99-0603,0,0.585069,"Missing"
2021.gwc-1.16,2019.gwc-1.45,1,0.86399,"Missing"
2021.gwc-1.16,W97-0802,0,0.771233,"of the bilingual Polish-English wordnet. In the paper we describe the systems of interlingual relations proposed and implemented for noun, adjective, adverb and verb synsets, presented in a chronological order motivated by the increasing difficulty of the milestones of the project. We close with the current statistics of interlingual synset relations. 2 Related works WordNet started off as a lexico-semantic network for English (Fellbaum, 1998). With a quickly manifested potential both for linguistics and NLP research, it soon found its followers for other languages, e.g. GermaNet for German, (Hamp and Feldweg, 1997). Since crosslinguistic applications are always welcome, the idea of linking monolingual wordnets into a multilingual network naturally arose. It was put into practice in the EuroWordNet project (Vossen, 1998, 2002) and more recently in the OpenMultilingualWordnet project (Bond and Foster, 2013). Even before the start of EuroWordNet project, it was clear that constructing a wordnet from scratch and later linking it to similar resources is time and moneyconsuming. Few teams could afford it. On the other hand, taking Princeton WordNet as a basic template and expanding on it proved much more econ"
2021.gwc-1.16,R13-1058,1,0.859718,"Missing"
2021.gwc-1.16,C16-1213,1,0.89716,"Missing"
2021.gwc-1.16,2016.gwc-1.43,0,0.0242443,"Missing"
2021.gwc-1.16,2020.lrec-1.398,1,0.800424,"Missing"
2021.gwc-1.16,C12-2101,1,0.821481,"ept. In addition, PWN provided short definitions called glosses, sometimes followed by examples, for every synset, while plWN started adding glosses for lexical units (not for synsets) only at a later stage2 of its development around the 3.0 version. With the above challenges in mind, the guiding idea of the mapping was to link nodes of wordnet graphs that would mainly correspond in terms of relation structures (and possibly also with respect to glosses). This turned out a non-trivial task. Often, even for closely related concepts, their relation structures were partially or wholly different (Rudnicka et al., 2012). This explains the use of different types of interlingual relations (I-relations) going far beyond interlingual synonymy defined as Simple Equivalence by (Vossen, 2002). Most of Vossen’s Complex Equivalence relations were adopted (e.g. I-hypo/hypernymy, Inear-synonymy, or I-mero/holonymy). Some new ones were added too, such as, for instance, interlingual inter-register synonymy. Of the four parts of speech described by plWN and PWN, nouns share the most in terms of the fundamentals of their internal synset relation structure (Maziarz et al., 2013a). The basic relation is hypo/hypernymy, follo"
2021.gwc-1.16,L16-1382,1,0.876827,"Missing"
2021.gwc-1.26,C18-1048,0,0.0220405,"n evaluation of supervised CST relation recognition The applied features included: sentence length difference, ratio of shared words, sentence position in text, differences in word numbers across PoSs, and the number of shared synonyms between sentences. The J48-based classifier achieved the best average score of 0.403. In similar task of implicit discourse relation recognition (Cianflone and Kosseim, 2018) used encoder- decoder (RNN) trained directly on character-level data from a large training corpus of annotated relations (reported F1 between 0.3 and 0.8, depending on the relation type). (Bai and Zhao, 2018) used ELMo (Gardner et al., 2017) and subword-level encoding as an input to a stack of a convolutional encoder, and a recurrent encoder and a multiple layer perceptron with softmax layer as the classifier – F1 between 0.36 and 0.51 was obtained. (Guo et al., 2018) represented input data by pre-trained word embeddings and next trained a neural tensor network on a large corpus of annotated sentences obtaining F1: 0.38 – 0.72. However, (Ponti and Korhonen, 2017) used topic model word vectors as representation, but also enriched it with features extracted by dependency parser to recognise causal r"
2021.gwc-1.26,broda-etal-2012-kpwr,0,0.0150012,"ormer-based language models and prepare baseline solutions for CST task. To prepare our baseline solutions we decided to choose ELMo and BERT (Devlin et al., 2019) pre-trained language models as it has been shown that they express good performance in Natural Language Inference (NLI) tasks e.g. Textual Entailment (TE). This choice was motivated by the fact that NLI tasks and CST theory are strongly interconnected. Dataset For comparison, we utilised exactly the same dataset as in (Kędzia et al., 2017; Janz et al., 2018), i.e. of sentence pairs annotated with CST relations from the KPWr Corpus (Broda et al., 2012), henceforth WUT CST. The underlying corpus used to build the dataset contained 11 949 complete documents that were clustered and split into groups of 3 news, each including the most similar and potentially related documents. A set of bundles for manual annotation process was prepared – every one with 10 triples {D1 , D2 , D3 } of most similar documents, that were randomly assigned to the annotators. Finally, 96 bundles covering more than 2800 documents were analysed in order to discover new instances of CST relations. The imposed similarity structure facilitated searching for sentence pairs l"
2021.gwc-1.26,L18-1306,0,0.0353928,"Missing"
2021.gwc-1.26,C18-1046,0,0.0455203,"Missing"
2021.gwc-1.26,R13-1044,0,0.134627,"e-processing of analysed data. As it was proposed by Janz et al. (2018) we applied the following pre-processing steps: text lemmatisation and morphosyntactic tagging (Radziszewski, 2013), dependency parsing (Wróblewska and Woliński, 2012; Wróblewska, 2014) in parallel with chunking (Radziszewski and Pawlaczek, 2013), named entity recognition (Marcińczuk et al., 2013), multi-word expression recognition (Radziszewski et al., 2011), and word sense disambiguation (Kędzia et al., 2015; Piasecki et al., 2016). Selected semantic relations inside nominal phrases were recognised by hand-crafted rules (Kedzia and Maziarz, 2013). The output from word sense disambiguation tool was used to map words to the appropriate synsets of plWordNet 3.0. As plWordNet 3.0 synsets were semi-automatically mapped onto concepts from SUMO ontology (Pease, 2011), thus, the words could be also mapped to their corresponding concepts. We used the metadata obtained by applying aforementioned pre-processing steps to reproduce graph-based representations of the sentences from WUT CST dataset. 5.2 Graph-based Representation The graph-based representation proposed by Janz et al. (2018) represents a single sentence as a collection of graphs wher"
2021.gwc-1.26,kedzia-etal-2017-graph,1,0.773604,"ul pushing the limits in many different natural language tasks we decided to start off with the most popular transformer-based language models and prepare baseline solutions for CST task. To prepare our baseline solutions we decided to choose ELMo and BERT (Devlin et al., 2019) pre-trained language models as it has been shown that they express good performance in Natural Language Inference (NLI) tasks e.g. Textual Entailment (TE). This choice was motivated by the fact that NLI tasks and CST theory are strongly interconnected. Dataset For comparison, we utilised exactly the same dataset as in (Kędzia et al., 2017; Janz et al., 2018), i.e. of sentence pairs annotated with CST relations from the KPWr Corpus (Broda et al., 2012), henceforth WUT CST. The underlying corpus used to build the dataset contained 11 949 complete documents that were clustered and split into groups of 3 news, each including the most similar and potentially related documents. A set of bundles for manual annotation process was prepared – every one with 10 triples {D1 , D2 , D3 } of most similar documents, that were randomly assigned to the annotators. Finally, 96 bundles covering more than 2800 documents were analysed in order to d"
2021.gwc-1.26,N19-1423,0,0.00987256,"ed setting. The updated dataset is available at https:// clarin-pl.eu/dspace/handle/11321/781. 3 Successful applications of transformer-based language models in many NLP tasks seem to be grounded in transfer learning methods and intensive model pre-training on large textual corpora. As pre-trained neural language models became very successful pushing the limits in many different natural language tasks we decided to start off with the most popular transformer-based language models and prepare baseline solutions for CST task. To prepare our baseline solutions we decided to choose ELMo and BERT (Devlin et al., 2019) pre-trained language models as it has been shown that they express good performance in Natural Language Inference (NLI) tasks e.g. Textual Entailment (TE). This choice was motivated by the fact that NLI tasks and CST theory are strongly interconnected. Dataset For comparison, we utilised exactly the same dataset as in (Kędzia et al., 2017; Janz et al., 2018), i.e. of sentence pairs annotated with CST relations from the KPWr Corpus (Broda et al., 2012), henceforth WUT CST. The underlying corpus used to build the dataset contained 11 949 complete documents that were clustered and split into gro"
2021.gwc-1.26,2016.gwc-1.41,1,0.643863,"irs: words plus their frequencies. This basic idea was expanded to bags of diverse elements resulting from rich pre-processing of analysed data. As it was proposed by Janz et al. (2018) we applied the following pre-processing steps: text lemmatisation and morphosyntactic tagging (Radziszewski, 2013), dependency parsing (Wróblewska and Woliński, 2012; Wróblewska, 2014) in parallel with chunking (Radziszewski and Pawlaczek, 2013), named entity recognition (Marcińczuk et al., 2013), multi-word expression recognition (Radziszewski et al., 2011), and word sense disambiguation (Kędzia et al., 2015; Piasecki et al., 2016). Selected semantic relations inside nominal phrases were recognised by hand-crafted rules (Kedzia and Maziarz, 2013). The output from word sense disambiguation tool was used to map words to the appropriate synsets of plWordNet 3.0. As plWordNet 3.0 synsets were semi-automatically mapped onto concepts from SUMO ontology (Pease, 2011), thus, the words could be also mapped to their corresponding concepts. We used the metadata obtained by applying aforementioned pre-processing steps to reproduce graph-based representations of the sentences from WUT CST dataset. 5.2 Graph-based Representation The"
2021.gwc-1.26,W17-0903,0,0.0282491,"n character-level data from a large training corpus of annotated relations (reported F1 between 0.3 and 0.8, depending on the relation type). (Bai and Zhao, 2018) used ELMo (Gardner et al., 2017) and subword-level encoding as an input to a stack of a convolutional encoder, and a recurrent encoder and a multiple layer perceptron with softmax layer as the classifier – F1 between 0.36 and 0.51 was obtained. (Guo et al., 2018) represented input data by pre-trained word embeddings and next trained a neural tensor network on a large corpus of annotated sentences obtaining F1: 0.38 – 0.72. However, (Ponti and Korhonen, 2017) used topic model word vectors as representation, but also enriched it with features extracted by dependency parser to recognise causal relations between events – a similar task to ours, but narrower. redundancy and improve its quality by removing noisy sentence pairs. To deal with highly imbalanced class distribution we decided to completely remove specific minor classes as their sample size was too small to prepare a robust and effective supervised model in a supervised setting. The updated dataset is available at https:// clarin-pl.eu/dspace/handle/11321/781. 3 Successful applications of tr"
2021.gwc-1.26,W00-1009,0,0.252918,"n in Polish. The representation describes selected levels of the sentence structure including description of lexical meanings on the basis of the wordnet (plWordNet) synsets and connected SUMO concepts. The obtained results show that in the case of diﬀicult relations and medium size training corpus semantically enriched text representation leads to significantly better results. 1 Introduction Recognition of semantic relations linking text fragments may provide insight into the semanticpragmatic structure of text or be a basis for humanlike reasoning. The Cross-document Structure Theory (CST) (Radev, 2000) defines a system of semantic relations connecting topically related texts. However, due to the large number of relations and often subtle differences between them, CST relation recognition is known to be much harder than Textual Entailment (TE) recognition. TE depends on a binary decision whether one piece of text semantically entails another one due to their content, while CST is a model of more general use, but more diﬀicult to achieve good results, especially when a classifier is trained on a domain different than the domain of its application. CST relations are based on relations between"
2021.gwc-1.26,radev-etal-2004-cst,0,0.245106,"useful in such cases. 2 Related Work In Zhang et al. (2003) CST relations were recognised by a supervised approach with boosting on the basis of lexical, syntactic and semantic features extracted from sentence pairs. The evaluation was performed in two steps: binary classification for relationship detection, and multi-class classification for relationship recognition. (Zhang and Radev, 2005), in addition to labelled data, exploited also unlabelled instances that improved the performance. Boosting technique was used in combination with the same set of features to classify the data in CSTBank (Radev et al., 2004). Relation detection was significantly improved to F1score = 0.8839. However, recognition of the relation type was still unsatisfactory. (Aleixo and Pardo, 2008) is one of few works that address the problem of CST relations recognition for languages other than English. They utilised CST in search for topically related Portuguese documents. They applied a supervised approach based on similarity measures calculated for sentence pairs from different documents: cosine similarity and a variant of the Jaccard index. Cut-off thresholds for the similarity were studied in combination with the performan"
2021.gwc-1.26,2020.acl-main.111,0,0.0122825,"sumption 161 147 Unrelated 143 Fulfilment 96 Elaboration Summary 45 Identity 45 Paraphrase 44 Source 40 Figure 2: Relations distribution in WUT CST. 4.3 Polish BERT-based Models As it was stated in previous section, the quality of pre-trained language models is mainly dependent on the quality of training corpora. A large part of Polish NLP community in the last few years was focused on adopting well-known language models and training them on publicly available Polish corpora due to the insuﬀicient performance of models trained on Polish Wikipedia only. HerBERT2 is a new Polish language model (Rybak et al., 2020) pre-trained on multiple open Polish corpora. The model itself is mainly based on BERT architecture but it also uses dynamic masking as it was originally proposed in RoBERTa (Liu 2 et al., 2019) language model. 316 https://huggingface.co/allegro/herbert-klej-cased-v1 4.4 Polish ELMo ELMo is a language model based on stacked bidirectional LSTM architecture with character-level convolutions. We decided to choose a publicly available model 3 trained on KGR10 corpora as it was the only one model of this kind fully pretrained on large Polish data from scratch. The KGR10 (Kocoń and Gawor, 2019) is o"
broda-etal-2008-corpus,J05-4002,0,\N,Missing
broda-etal-2008-corpus,C04-1161,0,\N,Missing
broda-etal-2008-corpus,N01-1009,0,\N,Missing
broda-etal-2008-corpus,C04-1036,0,\N,Missing
broda-etal-2008-corpus,W05-0604,0,\N,Missing
broda-etal-2008-corpus,P97-1009,0,\N,Missing
broda-etal-2008-corpus,P98-2127,0,\N,Missing
broda-etal-2008-corpus,C98-2122,0,\N,Missing
broda-etal-2008-corpus,P93-1023,0,\N,Missing
broda-etal-2010-building,varadi-etal-2008-clarin,0,\N,Missing
broda-etal-2010-building,przepiorkowski-etal-2008-towards,0,\N,Missing
broda-etal-2010-building,tufis-etal-2008-racais,0,\N,Missing
broda-etal-2010-building,P93-1016,0,\N,Missing
broda-etal-2010-building,P10-4005,0,\N,Missing
C12-2101,bentivogli-etal-2000-coping,0,0.333981,"lexical unit SŁOWA KLUCZOWE: wordnet, wordnet dwujęzyczny, rzutowanie wordnetów, synset, jednostka leksykalna + Work financed by the EU, the European Innovative Economy Programme Project POIG.01.01.02-14-013/09 Proceedings of COLING 2012: Posters, pages 1039–1048, COLING 2012, Mumbai, December 2012. 1039 1 Introduction We present a strategy and the preliminary results of the mapping of Polish WordNet [plWordNet] onto Princeton WordNet [PWN] (Fellbaum 1998). There have been many attempts to build such mappings for wordnets, including EuroWordNet [EWN] (Vossen 1998, Vossen 2002), MultiWordNet (Bentivogli, et al. 2000; Bentivogli & Pianta 2000), AsianWordNet (Robkop et al. 2010) and IndoWordNet (Sinha, et al. 2006, Bhattacharyya 2010). Those projects usually took advantage of EWN’s transfer-and-merge method, which largely consisted in the translation of most of PWN’s structure and content into the target language. In contrast with this, plWordNet’s design and construction are independent of EWN or PWN, though inevitably substantially influenced by both. A unique corpus-based method was employed (Maziarz et al. 2012, Piasecki et al. 2009). Synsets in plWordNet are merely groups of similarly interconnected l"
C12-2101,P00-1064,0,0.122466,"ediate hypernyms/hyponyms and meronyms and holonyms, if there are any. These are strefa and świat (zone, world). In case of doubts or difficulties with determining the synset sense, the editor considers the direct and indirect hypernyms (or other relations). Once the sense of the analysed synset has been established (‘area located beyond the borders of a given country’), the editor can move to the 1040 next stage: seek the equivalent target synset in PWN. First, automatic prompts are checked if they are present. We re-implemented an automated mapping algorithm described in (Daudé et al. 2003, Daudé et al. 2000). If there is no prompt, the editor’s language intuitions help select among target-language LUs one or two candidates which share the sense of the source-language synset (‘foreign country’). These candidate LUs are located in PWN and their synsets are analysed with respect to their sense and position in the wordnet structure (hypernym state). Special attention must be paid to their immediate hypernym(s) and hyponyms (or other relations if there are any), since these are going to be juxtaposed with the equivalent relations of the target synset. The editor must check if there already exist, or a"
C12-2101,W97-0802,0,0.574431,"Missing"
C16-1213,P13-1133,0,0.1167,"al dictionary: Web-based (http://plwordnet.pwr.edu.pl) via an Android application, and via WordnetLoom (Piasecki et al., 2013) (http://ws.clarin-pl.eu/public/WordnetLoom-Viewer.zip) a wordnet editor which offers advanced visual, graph-based browsing. plWordNet has also been included in a very large and popular Polish multilingual dictionary Lingo (http://ling.pl). Access to plWordNet as a dictionary amounts to tens of thousand of visits a month. In addition to monolingual resources, plWordNet is part of multilingual resources, e.g., WordTies (Pedersen et al., 2012), Open Multilingual WordNet (Bond and Foster, 2013) and multimodal resources, e.g., the classification of gestures based on the verb categorisation in plWordNet (Lis and Navarretta, 2014). plWordNet was referred to in the resource for textual entailment (Przepiórkowski, 2015) and utilised for ontology mapping and linking ontology to lexicon (Jastrząb et al., 2016). Assorted applications of plWordNet include language correction, relation extraction (Mykowiecka and Marciniak, 2014), text indexing (Kaleta, 2014), Text Mining (Maciołek and Dobrowolski, 2013), text classification (Wróbel et al., 2016; Mirończuk and Protasiewicz, 2016), Open Domain"
C16-1213,2016.gwc-1.14,0,0.0176512,"formed by a group separate from the plWordNet editors, so it also served as a form of verification of the plWordNet content. The newest release of plWordNet, version 3.0, complements the preceding versions. After version 2.3, the work concentrated on a modified system of relations for adjectives (Maziarz et al., 2012) and on the expansion of the adjective sub-database; the construction of the adverb subnetwork,7 supported by a semi-automated method based on adjective-adverb derivational relations (Maziarz et al., 2016); and a major increase of the number of lexicalised multi-word expressions (Dziob and Wendelberger, 2016). 3 3.1 Comparative analysis The lexical net A wordnet is a lexical net, so it can be evaluated with statistical measures suitable for graphs (Lewis, 2009). We consider graph size, network volume, average graph density, corpus coverage, clustering coefficient, distance measure and connectivity. A wordnet of good quality ought to have a large, dense network, covering contemporary corpora well, and showing traits of “small-worldness”. Network volume and density. Table 2 shows the number of synsets, lemmas and LUs in three manually and independently constructed wordnets: Princeton WordNet, plWord"
C16-1213,W14-0104,0,0.023116,"and Piasecki, 2014), 10 R is a registered trademark. We cannot use it. The symbol WordNet 2265 • NELexion2, a very large lexicon of Polish Proper Names (PNs), ≈1.5 million, manually linked at the level of fine-grained semantic PN classes (Marcińczuk, 2016), • a lexicon of ≈60,000 multiword expressions with syntactic structures described, linked to plWordNet’s LUs by lemmas (Maziarz et al., 2015; Dziob et al., 2016), • a syntactic-semantic lexicon of Polish valency frames (≈15,000 lemmas described) linked to plWordNet at the LU level and semantic restrictions of frame arguments (Kotsyba, 2014; Hajnicz, 2014). The system is a very large network, linking knowledge elements to lexical meaning and descriptions of local syntactic-semantic structures. Given the mapping to WordNet, the system can be an anchor to a global Linked Data network,11 a powerful cloud of heterogenous data webs. Manually crafted lexicalsemantic resources could serve as a skeleton for the cloud, notably with plWordNet’s comprehensive coverage. Lexical item descriptions therein would be the means of anchoring webs to text clouds. plWordNet has become an important reference for research on the development of wordnets; (Fišer and Sa"
C16-1213,kedzia-piasecki-2014-ruled,1,0.832533,"s where a link from the Polish side would have been inaccurate. The result, enWordNet 1.0,10 is also part of this release, which ought to encourage comparative studies and cross-lingual research. 4 Applications of plWordNet Language resources are developed for applications: the higher the uptake, the better the perceived quality. plWordNet is a pivotal element of a system of language and knowledge resources; plWordNet’s wide coverage helps a lot. The system has several layers, with plWordNet in the middle: • top- and medium-level ontology SUMO with plWordNet semi-automatically mapped onto it (Kędzia and Piasecki, 2014), 10 R is a registered trademark. We cannot use it. The symbol WordNet 2265 • NELexion2, a very large lexicon of Polish Proper Names (PNs), ≈1.5 million, manually linked at the level of fine-grained semantic PN classes (Marcińczuk, 2016), • a lexicon of ≈60,000 multiword expressions with syntactic structures described, linked to plWordNet’s LUs by lemmas (Maziarz et al., 2015; Dziob et al., 2016), • a syntactic-semantic lexicon of Polish valency frames (≈15,000 lemmas described) linked to plWordNet at the LU level and semantic restrictions of frame arguments (Kotsyba, 2014; Hajnicz, 2014). The"
C16-1213,R15-1056,1,0.740008,"ge and knowledge resources; plWordNet’s wide coverage helps a lot. The system has several layers, with plWordNet in the middle: • top- and medium-level ontology SUMO with plWordNet semi-automatically mapped onto it (Kędzia and Piasecki, 2014), 10 R is a registered trademark. We cannot use it. The symbol WordNet 2265 • NELexion2, a very large lexicon of Polish Proper Names (PNs), ≈1.5 million, manually linked at the level of fine-grained semantic PN classes (Marcińczuk, 2016), • a lexicon of ≈60,000 multiword expressions with syntactic structures described, linked to plWordNet’s LUs by lemmas (Maziarz et al., 2015; Dziob et al., 2016), • a syntactic-semantic lexicon of Polish valency frames (≈15,000 lemmas described) linked to plWordNet at the LU level and semantic restrictions of frame arguments (Kotsyba, 2014; Hajnicz, 2014). The system is a very large network, linking knowledge elements to lexical meaning and descriptions of local syntactic-semantic structures. Given the mapping to WordNet, the system can be an anchor to a global Linked Data network,11 a powerful cloud of heterogenous data webs. Manually crafted lexicalsemantic resources could serve as a skeleton for the cloud, notably with plWordNe"
C16-1213,2016.gwc-1.31,1,0.747333,"LUs are the object of linguistic tests or are included in usage examples. The annotation was performed by a group separate from the plWordNet editors, so it also served as a form of verification of the plWordNet content. The newest release of plWordNet, version 3.0, complements the preceding versions. After version 2.3, the work concentrated on a modified system of relations for adjectives (Maziarz et al., 2012) and on the expansion of the adjective sub-database; the construction of the adverb subnetwork,7 supported by a semi-automated method based on adjective-adverb derivational relations (Maziarz et al., 2016); and a major increase of the number of lexicalised multi-word expressions (Dziob and Wendelberger, 2016). 3 3.1 Comparative analysis The lexical net A wordnet is a lexical net, so it can be evaluated with statistical measures suitable for graphs (Lewis, 2009). We consider graph size, network volume, average graph density, corpus coverage, clustering coefficient, distance measure and connectivity. A wordnet of good quality ought to have a large, dense network, covering contemporary corpora well, and showing traits of “small-worldness”. Network volume and density. Table 2 shows the number of sy"
C16-1213,P13-3014,0,0.0147475,"urces, e.g., the classification of gestures based on the verb categorisation in plWordNet (Lis and Navarretta, 2014). plWordNet was referred to in the resource for textual entailment (Przepiórkowski, 2015) and utilised for ontology mapping and linking ontology to lexicon (Jastrząb et al., 2016). Assorted applications of plWordNet include language correction, relation extraction (Mykowiecka and Marciniak, 2014), text indexing (Kaleta, 2014), Text Mining (Maciołek and Dobrowolski, 2013), text classification (Wróbel et al., 2016; Mirończuk and Protasiewicz, 2016), Open Domain Question Answering (Przybyła, 2013), and use as a quasi-ontology in document structure recognition (Kamola et al., 2015). Registered users of plWordNet declare its applications. Here is a selection of such declaration: education (at different levels) including Polish language teaching, building dictionaries, extraction of synonyms and semantically related words, detection of loanwords, cross-linguistic study on phonesthemes, classification of metaphorical expressions, corpus studies, grammar development, comparative and contrastive studies, language recognition, parsing disambiguation, semantic analysis of text, document simila"
C16-1213,C12-2101,1,0.820266,"larger than for plWordNet 3.0) and shortest path lengths. The conglomerate has small-world behaviour more than its separate parts. It seems that linking independently built resources creates a new quality. 3.2 Comparison by mapping As noted, plWordNet has been developed independently from WordNet, without any transfer of structures between the two resources, thus avoiding any bias towards WordNet. Even so, the alignment of plWordNet and WordNet was needed for a variety of (bilingual and multilingual) applications and research tasks. We have designed a strategy of mapping plWordNet to WordNet (Rudnicka et al., 2012). The key element 2263 I-relation I-Synonymy I-Hyponymy I-Hypernymy I-Meronymy I-Holonymy I-Partial synonymy I-Inter-register synonymy I-Cross-categorial synonymy Total Noun 36,367 74,394 4,121 6,982 3,471 4,339 1,672 131,346 Adjective 4,077 29,216 167 1,544 54 19,286 54,344 Adverb 448 781 51 4 22 1,306 Total 40,892 104,391 4,339 6,982 3,471 5,887 1,748 19,286 186,996 Table 4: Interlingual relation counts of the strategy was a comparison of the two relation structures in order to find the corresponding nodes of synset graph structures and link them via one of eight interlingual relations (hier"
C16-1213,R15-1092,1,0.614174,"Missing"
kedzia-piasecki-2014-ruled,P00-1064,0,\N,Missing
kedzia-piasecki-2014-ruled,C12-2101,1,\N,Missing
kedzia-piasecki-2014-ruled,R13-1058,1,\N,Missing
kurc-etal-2012-constraint,copestake-etal-2002-multiword,0,\N,Missing
kurc-etal-2012-constraint,W04-0411,0,\N,Missing
kurc-etal-2012-constraint,2003.mtsummit-papers.39,0,\N,Missing
L18-1665,esuli-sebastiani-2006-sentiwordnet,0,0.0220759,"r network context of a word sense, but also a richer set of lexical relations to propagate the sentiment polarity. Yet another problem with the existing approaches is that many solutions depend on handcrafted propagation rules that cannot be easily transferred to a wordnet built for another language. Here we propose a method which allows for automated discovery of propagation rules by using the wordnet structure in a more extensive way to recognise the sentiment polarity of senses. 2. Related Works SentiWordNet, one of the most commonly used sentiment resources for English, was introduced in (Esuli and Sebastiani, 2006). The main goal of the authors was to construct a large lexical resource with sentiment polarity assigned to meanings, rather than words2 . There were many attempts to construct sense-level sentiment lexicons, but most of them were evaluated only for English. The easiest way to create a sense-level sentiment lexicon for another languages is simply to map SentiWordNet annotations to a non-English wordnet via existing mappings between the two wordnet or even translating first Princeton WordNet (Fellbaum, 1998) into another language. However, wordnets for different languages may differ significan"
L18-1665,maks-etal-2014-generating,0,0.0160225,"es. 4212 three datasets of different quality: high-quality, low-quality and mixed. The best results were achieved using the largest dataset of mixed quality, derived from the General Inquirer (Stone, 1966) – a sentiment lexicon. The conclusion was, that the size is the most important factor. The authors also proposed a third approach combining this transfer method with label propagation, with almost the same result. The results may also suggest, that simple transfer methods are not perfect, but combining multiple approaches with transfer methods may bring us promising results. The authors of (Maks et al., 2014) expanded research on the sentiment propagation to non-English wordnets. They applied the same propagation method to five wordnets of different languages. Words and their polarity were acquired from the well-known sentiment lexicon – the General Inquirer Lexicon, and then translated with a machine translation service to five languages. The words were manually mapped to their corresponding synsets in particular wordnets, and used as a seed for propagation. The resulting lexicons varied significantly with respect to their size and precision. The authors concluded, that the way a given wordnet ha"
L18-1665,C16-1213,1,0.891515,"Missing"
L18-1665,P17-1154,0,0.359108,"r each method and configuration we performed 10-fold cross-validation. Annotated synsets were divided into 10 parts, where 9 parts (about 40,400 synsets in total) were treated as a seed for the baseline (or a training set for CPP) and the 10th part (about 3,600 synsets) as a test set. We implemented a simple rule-based seed-driven propagation method described in (Maks and Vossen, 2011) to obtain a baseline (henceforth BASE). Then we compared results of its application with the CPP method in two variants, described in Section 4.: naive (CPP-N) and sorted (CPP-S). 5.2. Task-based Evaluation In (Qian et al., 2017) the authors proposed a simple, yet effective solution to recognize sentiment polarity of sentences using Bidirectional LSTM network. The proposed yˆi log yi + α i XX i Lt,i + βkθk2 (1) t The authors called their solution Linguistically Regularized LSTM (henceforth LR-LSTM) which is a model of LSTM network but expanded with a set of regularizers to better reflect the linguistic role of sentiment, negation and intensity of words (Qian et al., 2017). Here we have applied all four proposed regularization terms namely non-sentiment regularizer (NSR), sentiment regularizer (SR), negation regularize"
L18-1665,vossen-etal-2008-integrating,0,0.0198951,"Missing"
L18-1665,2018.gwc-1.18,1,0.789748,"Missing"
L18-1665,R15-1092,1,0.553698,"Missing"
piasecki-etal-2012-recognition,J01-1003,0,\N,Missing
piasecki-etal-2012-recognition,N01-1024,0,\N,Missing
piasecki-etal-2012-recognition,P99-1037,0,\N,Missing
R13-1056,broda-etal-2012-kpwr,1,0.885592,"Missing"
R13-1056,C12-1084,0,0.0541495,"Missing"
R13-1056,H93-1012,0,0.430485,"Missing"
R13-1058,broda-etal-2012-kpwr,1,0.766015,"Missing"
R13-1058,broda-etal-2012-tools,1,0.859555,"owa´c ‘rule’ – władca ‘ruler’); AGENT (spawacz ‘welder’ – spawa´c ‘weld’); IN STRUMENT (nadajnik ‘transmitter’ – nadawa´c ‘transmit’); DIMINUTIVE (córeczka ‘little daughter’ – córka ‘daughter’).9 2.2 The construction process • whether a given lemma is correct in Polish (e.g., tagger mistakes are weeded out); • how many LUs should be distinguished – whether all existing senses appear in usage examples or WordnetWeaver’s suggestions; • how to describe a given LU by plWordNet relations – what relation types should be used. Wordnet construction is rather like writing a dictionary (Fellbaum, 1998; Broda et al., 2012b). Lexicography distinguishes four phases: data collection, selection, analysis and presentation (Svensén, 2009). In the plWordNet project, language technologies support all four phases. Professional linguists under the supervision of senior coordinators work with WordnetLoom, a Web application. This graph-based wordnet editor allows visual browsing and concurrent editing. Many semiautomatic tools are integrated into WordnetLoom. In the data collection phase, a large corpus is essential (Wynne, 2005). A multi-source corpus with 1.8 billion tokens, the foundation of plWordNet’s systematic grow"
R13-1058,lis-2012-polish,0,0.0619675,"ear perfectly usable in linking other wordnets. The Ihyponymy links are now a clear sign of gaps which can be repaired in the further stages of the development of the networks. Mapping plWordNet to PWN also opens up the possibility of establishing links to other wordnets already linked to PWN. 5 Applications Freely available for any purpose on a licence identical to the PWN licence, plWordNet has already proven its value in at least 16 research applications and in many publication which cite it. The verb portion of plWordNet was used in semantic annotation in a corpus of referential gestures (Lis, 2012) and in a lexicon of semantic valency frames (Hajnicz, 2011; Hajnicz, 2012). In the latter, plWordNet domains were also used in algorithms of verb classification. In (Maciołek, 2010; Maciołek and Dobrowolski, 2013) plWordNet is used to extend a set of features for text mining from Web pages. In (Wróblewska et al., 2013) 20 Glosses for all synsets are a relatively late addition to PWN. We have only recently begun to introduce them into plWordNet. 449 study on phonesthemes.”), Affect Analysis (multilingual systems), humour analysis, development of Polish Link Grammar, and plWordNet as an object"
R13-1058,mititelu-2012-adding,0,0.0341853,"), terminology extraction and clustering (Mykowiecka and Marciniak, 2012), automated extraction of opinion attribute lexicons from product descriptions (Wawer and Gołuchowski, 2012), named entity recognition, word-sense disambiguation, extraction of semantic relations (Gołuchowski and Przepiórkowski, 2012), temporal information (Jarz˛ebowski and Przepiórkowski, 2012) and anaphora resolution. Open Multilingual Wordnet (Bond, 2013) now includes plWordNet. It is referred to in other work on wordnets and semantic lexicons (Pedersen et al., 2009; Lindén and Carlson, 2010; Borin and Forsberg, 2010; Mititelu, 2012; Zafar et al., 2012; Šojat et al., 2012). 6 The resource has attracted about 450 registered individual and institutional users (registration upon download is not mandatory). The plWordNet Web page and Web service have had tens of thousands of visitors (hundreds of thousands of searches). The intended use includes 70 commercial applications, and 50 scientific and educational applications (at all levels: university, high school and primary school). The declared topics of scientific applications include semantic word similarity calculation, multilingual wordsense disambiguation, text classificat"
R13-1058,C12-1119,0,0.0587364,"nguistics and even as an illustration of linguistic notions in education in primary and secondary schools. plWordNet was the basis for building a mapping between a lexicon and an ontology. Miłkowski (2010) included plWordNet in a set of dictionaries in his proofreading tool. There are applications of plWordNet in word-to-word similarity measures utilised in research on ontologies (Lula and Paliwoda-P˛ekosz, 2009) or in calculating text similarity (Siemi´nski, 2012). As a semantic lexicon, plWordNet has been useful in text classification (Maciołek, 2010), terminology extraction and clustering (Mykowiecka and Marciniak, 2012), automated extraction of opinion attribute lexicons from product descriptions (Wawer and Gołuchowski, 2012), named entity recognition, word-sense disambiguation, extraction of semantic relations (Gołuchowski and Przepiórkowski, 2012), temporal information (Jarz˛ebowski and Przepiórkowski, 2012) and anaphora resolution. Open Multilingual Wordnet (Bond, 2013) now includes plWordNet. It is referred to in other work on wordnets and semantic lexicons (Pedersen et al., 2009; Lindén and Carlson, 2010; Borin and Forsberg, 2010; Mititelu, 2012; Zafar et al., 2012; Šojat et al., 2012). 6 The resource h"
R13-1058,C12-2101,1,0.360293,"umber of instances of I-relations in plWordNet 2.0 and in GermaNet 8.0, another partially manually constructed and mapped wordnet.19 I-synonymy, a primary relation in both wordnets has a comparable number of instances. It is the most frequent relation in GermaNet, while in plWordNet it has been overtaken by I-hyponymy. The latter statistic can be explained by profound differences in the struc18 Two LUs mean roughly the same but belong to different stylistic registers. 19 We thank Verena Henrich for providing us with the relevant GermaNet data. A partial mapping of plWordNet onto PWN is ready (Rudnicka et al., 2012). A hierarchically 448 Relation type I-synonymy I-hyponymy I-hypernymy I-meronymy I-holonymy I-near synonymy I-inter-register synonymy plWordNet 2.0 14240 22873 3329 1732 394 923 GermaNet 8.0 15259 1397 760 126 52 3389 522 — Table 8: Inter-lingual relation count (instances) in plWordNet and in GermaNet. ture and content of plWordNet and PWN, discovered during mapping and discussed below. In GermaNet, I-hyponymy has quite few instances. On the other hand, the second largest relation in GermaNet is I-near synonymy. There are lexico-semantic and lexicogrammatical differences between English and P"
R13-1073,W97-0802,0,0.465407,"attern-based and Distributional Semantics approaches can be used. The algorithm is based on a general spreading activation model. Support for word-to-word semantic associations is first mapped on the existing wordnet structure. Next, the support is spread over the wordnet network in order to find attachment areas for a new word. Evaluation and comparison with other approaches in experiments on Princeton WordNet 3.0 is presented. 1 Introduction Wordnets became important large scale language resources providing relational description of lexical meanings. e.g. WordNet (Fellbaum, 1998), GermaNet (Hamp and Feldweg, 1997) or plWordNet (Maziarz et al., 2012). The required large amount of work on wordnet construction can be lessened by supporting manual work with automated tools for the extraction of lexico-semantic relations and wordnet expansion. A scheme for lexico-semantic network extraction from corpus includes, e.g. (Yang and Callan, 2009; Navigli et al., 2011): term extraction, extraction of term associations and taxonomy induction. A taxonomy structure is mostly a subset of the whole wordnet hyper/hyponynymy structure. Thus, a more general task, for the last phase, is extraction of 2 Related works (Alfon"
R13-1073,P06-1101,0,0.261425,"ypernymic levels are already built manually, and what is needed is to expand the wordnet structure towards the lower levels. Our goal is to develop a method of automated expansion of wordnet hypernymy structure based on both lexico-semantic associations extracted automatically from a large text corpus and the prior partial wordnet structure. We do not assume the existence of any kind of semantic annotation or document structure, to make the proposed method general. Most taxonomy induction methods use only the existing hypernymy structure as a basis for the incremental wordnet expansion, e.g. (Snow et al., 2006; Piasecki et al., 2009b). We explore all different types of wordnet links to identify the appropriate location for a new lemma sense. The paper presents a wordnet expansion algorithm, which is based on lexicosemantic relations extracted from large text corpora. We do not assume that the extracted relation instances (i.e. word pairs) are described by probabilities. Thus, results produced by any method, including pattern-based and Distributional Semantics approaches can be used. The algorithm is based on a general spreading activation model. Support for word-to-word semantic associations is fir"
R13-1073,D10-1108,0,0.016258,"e taxonomy, the whole taxonomy must be (locally) searched for an attachment place that maximises probabilities of all the implied relations. The attachment of new elements transforms the structure T into a new T’. The appropriate T’ maximises the probability of the change in relation to the evidence at hand. Multiplicative change computation is based on all added relation links, including the links implied by hyponymy. Multiplicative change depends on the inverse odds of the prior k which is a constant independent of words and taxonomy T. (Snow et al., 2006) have not provided any value of k. (Kozareva and Hovy, 2010) presented two step taxonomy induction. First, hyponym-hypernym pairs are extracted from Internet and ranked. The extraction mechanism is exclusively based on “doubly-anchored lexico-syntactic patterns” and a heuristic iterative algorithm. The process is weakly controlled by a root and seed lemmas. (Navigli et al., 2011) divided taxonomy induction into four steps. Three initial ones are devoted to the extraction of hypernymy instances. The process is focused on ontology learning, identification of overt definitions in text and the extraction of hypernymy instances from them. However, definitio"
R13-1073,P93-1016,0,0.0676484,"Missing"
R13-1073,N03-1036,0,0.0379339,"the extraction of lexico-semantic relations and wordnet expansion. A scheme for lexico-semantic network extraction from corpus includes, e.g. (Yang and Callan, 2009; Navigli et al., 2011): term extraction, extraction of term associations and taxonomy induction. A taxonomy structure is mostly a subset of the whole wordnet hyper/hyponynymy structure. Thus, a more general task, for the last phase, is extraction of 2 Related works (Alfonseca and Manandhar, 2002) and (Witschel, 2005) treat wordnet hypernymy as a kind of decision tree applied to word meanings described by Distributional Semantics. (Widdows, 2003) attaches words on the basis of their semantic neighbours – k most similar words according to their co-occurrence with the most frequent words. (Snow et al., 2006) proposed Probabilistic Wordnet Expansion (PWE) method, which is based on a probabilistic model of the taxonomy 553 Proceedings of Recent Advances in Natural Language Processing, pages 553–561, Hissar, Bulgaria, 7-13 September 2013. sion is controlled by Minimum Evolution Assumption and Abstractness Assumption principles. The first results in minimising “the overall semantic distance among the terms” but also avoiding “dramatic chang"
R13-1073,P09-1031,0,0.301025,". Evaluation and comparison with other approaches in experiments on Princeton WordNet 3.0 is presented. 1 Introduction Wordnets became important large scale language resources providing relational description of lexical meanings. e.g. WordNet (Fellbaum, 1998), GermaNet (Hamp and Feldweg, 1997) or plWordNet (Maziarz et al., 2012). The required large amount of work on wordnet construction can be lessened by supporting manual work with automated tools for the extraction of lexico-semantic relations and wordnet expansion. A scheme for lexico-semantic network extraction from corpus includes, e.g. (Yang and Callan, 2009; Navigli et al., 2011): term extraction, extraction of term associations and taxonomy induction. A taxonomy structure is mostly a subset of the whole wordnet hyper/hyponynymy structure. Thus, a more general task, for the last phase, is extraction of 2 Related works (Alfonseca and Manandhar, 2002) and (Witschel, 2005) treat wordnet hypernymy as a kind of decision tree applied to word meanings described by Distributional Semantics. (Widdows, 2003) attaches words on the basis of their semantic neighbours – k most similar words according to their co-occurrence with the most frequent words. (Snow"
R15-1056,J08-4004,0,0.0329758,"Missing"
R15-1056,J08-3001,0,0.0416163,"Missing"
R15-1067,R15-1056,1,0.91738,"ompleted with texts collected from the internet. All texts from the internet were filtered: only larger texts with a relatively small number of words not recognised by the morphological analyser Morfeusz (Woli´nski, 2006) have been included in the corpus. • What method should we select if we need to extract MWEs of different subtypes? • How effective are different methods in helping lexicographers who use a complex but 512 Proceedings of Recent Advances in Natural Language Processing, pages 512–520, Hissar, Bulgaria, Sep 7–9 2015. 2 Background icality of a given MLU candidate is presented in (Maziarz et al., 2015b) and (Maziarz et al., 2015a) in this volume. Summarising, it is based on a decision tree guiding linguists. Every extracted collocation is analysed in a sequence of tests before it is rejected or accepted as a plWordNet MLU. The application of with the guidelines tree improved consistency of lexicographers’ decisions. In order to check trustworhtiness of plWordNet as a gold-standard lexical resource we asked 5 linguists to intuitively assess lexicality of 200 MLUs randomly taken from plWordNet 2.1. They were given a definition pointing to the notion of LU being the part of our mental lexicon"
R15-1067,W09-2905,0,0.355853,"le measures. However, (Paradowski, 2015) showed that many of them are correlated and even can be obtained from the same basic equation by changing its parameters. Such correlated measures are redundant attributes from the Machine Learning point of view and should not be used together. P M I(x, y) = log2 p(x, y) p(x)p(y) (1) PMI was modified in different ways to cope with this problem, e.g. one possibility is to refer to the ‘full’ Mutual Information in which the logarithm is multiplied by p(x, y) probability. Applying this analogy to PMI, we obtain W Specific Correlation in Eq. 2 proposed in (Hoang et al., 2009a). Our approach differs significantly from the previous ones by the scale of the evaluation tests in terms of the size of: corpora used for the extraction and the MWE lexicon used for the comparison. Concerning the former we used the Merged Corpus of Polish described in Sec. 1, concerning the latter we used MLUs for plWordNet 2.2 as the gold set that includes almost 50 000 MWEs. W _SC(x, y) = p(x, y)log2 p(x, y) p(x)p(y) (2) Mutual Dependency in Eq. 3 is another modification of PMI in which the x and y joint frequency is emphasised inside the logarithm: In (Peˇcina, 2010) the evaluation was p"
R15-1067,kurc-etal-2012-constraint,1,0.842402,"of the statistical measures to word forms would not be feasible for the extraction of MWE candidates. There are too many word forms and each candidate has several inflectional forms on average. Thus, both corpora were first preprocessed by the morphosyntactic tagger WCRFT2 (Radziszewski, 2013) that maps words on their lemmas8 . Next, the extraction process was performed on the level of lemmas annotated with morphosyntactic information. MLUs in plWordNet are described with complex information including: multi-word lemmas, partial description of the syntactic structure and syntactic heads, cf (Kurc et al., 2012). The partial description of a MLU is expressed in the WCCL language of morpho-syntactic constraints (Radziszewski et al., 2011). Each MLU is assigned a minimal set of constraints that refer to its lemma and enable recognition of its occurrences in text, e.g. the constraints define the order of constituents (if it is fixed) and morphosyntactic agreements between them. plWordNet editors tried to use the same single constraint set for the description of many MLUs. As a result a limited set of structural classes of MWEs was defined. About 100 MWE structural classes are used in plWordNet, but most"
R15-1067,W11-1303,0,0.0732381,"Missing"
R15-1092,baccianella-etal-2010-sentiwordnet,0,0.535765,"Missing"
R15-1092,de-albornoz-etal-2012-sentisense,0,0.0912499,"Missing"
R15-1092,P14-2063,0,0.0774922,"Missing"
R15-1092,W10-3208,0,0.0837259,"Missing"
R15-1092,C12-1119,0,0.102611,"Missing"
R15-1092,esuli-sebastiani-2006-sentiwordnet,0,0.731205,"nnotation process, and introduces the resulting resource, plWordNetemo. We discuss the selection of the material for the pilot study, show the distribution of annotations across the wordnet, and consider the statistics, including interannotator agreement and the resolution of disagreement. 1 Introduction The Polish wordnet, plWordNet (Piasecki et al., 2009; Maziarz et al., 2013), is very large and comprehensive, with well over 150,000 synsets 1 The term lexical unit will be abbreviated to LU throughout this paper. 2 This annotation is already on a scale several times larger than SentiWordNet (Esuli and Sebastiani, 2006). 721 Proceedings of Recent Advances in Natural Language Processing, pages 721–730, Hissar, Bulgaria, Sep 7–9 2015. 2 Sentiment and Affect Annotations in Wordnets relations. The authors’ visualisation and editing tools, designed to allow relatively easy expansion and adaptation, did not add much to the resource, so every user must enlarge it further to make it really applicable. Several sentiment lexicons are available for English, but hardly any for most other languages. Chen and Skiena (2014) have found 12 publicly available sentiment lexicons for 5 languages; there are none for Polish. Some"
R15-1092,C12-2101,1,0.811373,"y equal across different types of polarity. A possible explanation: it is harder to read the meaning of adjectival LUs from plWordNet, and the annotators were more careful in reading the wordnet structures exactly. 6 on sentiment polarity propagation along the wordnet graph. The development of plWordNet has been independent of PWN, and the amount of sentiment annotation in our pilot project exceeds that in SentiWordNet and WordNet-Affect. It might therefore be interesting to compare our annotation with the automatic annotation in those wordnets, using the manual mapping of plWordNet onto PWN (Rudnicka et al., 2012). Acknowledgments Work financed by the Polish Ministry of Science and Higher Education, a program in support of scientific units involved in the development of a European research infrastructure for the humanities and social sciences in the scope of the consortia CLARIN ERIC and ESS-ERIC, 2015-2016. Heartfelt thanks to our annotators: Ada Zajaczkowska, ˛ Anna Nizi´nska, Kamil Wabnic, Monika Górka, Amelia Kiełbawska and Joanna Wieczorek. Conclusions The resource we have constructed is a first, important step towards sentiment annotation of the whole plWordNet. That is because the achieved size"
R15-1092,strapparava-valitutti-2004-wordnet,0,0.320501,"Missing"
R15-1092,W11-1710,0,0.68128,"Missing"
R19-1048,E17-2043,0,0.0136357,"oceedings of Recent Advances in Natural Language Processing, pages 409–417, Varna, Bulgaria, Sep 2–4, 2019. https://doi.org/10.26615/978-954-452-056-4_048 cluding 95 435 564 characters in total) obtained through Twitter API1 by applying Polish language filter (automatic Twitter filter that can produce some noise) and in addition tracking the top 100 words from the frequency list generated for the Polish language (Kazojć, 2009) in the search query, (Sapkota et al., 2015). There were a couple of attempts to classify tweets based on their character n-gram representations (Schwartz et al., 2013) (Sari et al., 2017) (Zhang et al., 2015) with different approaches to extracting a subset of meaningful characters (Plakias and Stamatatos, 2008) (Sapkota et al., 2015). In terms of a classifier used for such a task, CNNs have been recently widely explored and proved successful for text analysis (Sierra et al., 2017) (Ruder et al., 2016). A combination of the two approaches appears in (Shrestha et al., 2017) where a text is classified based on a sequence of input characters. The method uses straightforward sequences of characters and their n-grams which are then embedded and processed in a CNN classifier. Anothe"
R19-1048,E17-2106,0,0.110394,"ted for the Polish language (Kazojć, 2009) in the search query, (Sapkota et al., 2015). There were a couple of attempts to classify tweets based on their character n-gram representations (Schwartz et al., 2013) (Sari et al., 2017) (Zhang et al., 2015) with different approaches to extracting a subset of meaningful characters (Plakias and Stamatatos, 2008) (Sapkota et al., 2015). In terms of a classifier used for such a task, CNNs have been recently widely explored and proved successful for text analysis (Sierra et al., 2017) (Ruder et al., 2016). A combination of the two approaches appears in (Shrestha et al., 2017) where a text is classified based on a sequence of input characters. The method uses straightforward sequences of characters and their n-grams which are then embedded and processed in a CNN classifier. Another approach which is using a byte pair encoding algorithm for text encoding together with the application of the same CNN classifier, proves that the method is comparable to the state-of-the-art despite another level of text compression (Wang, 2018). The latter, however, uses a limited range of characters with at least punctuation and white space characters ignored. Additionally, in both wo"
R19-1048,D18-2012,0,0.0194777,"). The topic-related groups are extrated as one of the goals of the experiments was to verify whether the subject on which particular users tweet is a strong distinguishing factor which affects obtained results. As the activity of different authors is diversified, the Influencer Set is highly unbalanced with the number of tweets per author deviating from 314 to 18 204 tweets per account. This problem was mediated by subsampling during the experiments. Contribution In our work we extend the solution presented in (Shrestha et al., 2017) by using SentencePiece with Byte-Pair Encoding algorithms (Kudo and Richardson, 2018), without exclusion of any characters. Moreover, instead of using a data-specific text embedding trained simultaneously with the classifier, we teach a separate distributional language model on a corpus of Polish tweets. We also test robustness of our solution by alternating topics in the training and testing corpora, as well as using disjunctive time windows for texts in both corpora. 4 5 Text Representation Tweets are very short texts and do not include many repeated occurrences of typical stylometry markers like functional words. We can observe prevalence of the information content over typ"
R19-1048,N15-1010,0,0.134042,"ig chunks of texts, where the sample of author’s writing is relatively big (Gollub et al., 2013), (Frantzeskou et al., 2007), (Koppel et al., 2011). Recently, a lot of work has been done regarding authorship attribution of short texts, especially tweets due to their accessibility. The problem is challenging in comparison to the classification of longer texts as it is harder to maintain the classification accuracy along with the input pruning (Koppel and Winter, 2014). Some methods are based on stylistic features (Macleod and Grant, 2011) or word and character n-grams (Schwartz et al., 2013), (Sapkota et al., 2015). Considering the fact that tweets may be of highly varying character with usage of multiple special characters, notorious misspellings and mixes of languages, character n-grams seem to be intuitively best-fit for the problem. Moreover, such approach appears to hold both topic-specific and morphology-specific information on the text (Koppel et al., 2011) Introduction The problem of authorship attribution is one of the major areas of text classification. However, the issue is usually undertaken in the context of longer texts, such as book fragments, journal articles or emails. In recent years,"
R19-1061,W99-0501,0,0.0537209,"row semantic context. More formally, a lexical knowledge base is a graph G(V, E) consisting of nodes and edges, where V = {v1 , v2 , ..., vN } represents a set of concepts (modelling lexical meanings) and E = {e1 , e2 , ..., eM } a set of edges corresponding to lexico-semantic associations linking these concepts. 3.1 Existing Knowledge Bases In literature, we can find many attempts to combine Princeton WordNet with resources of many types to obtain a better knowledge base for WSD. UKB lexical knowledge base, e.g. (Agirre and Soroa, 2009), consists of Princeton WordNet 3.0 or eXtended WordNet (Harabagiu et al., 1999) which was expanded by introducing links extracted from SemCor, manually disambiguated glosses from Princeton WordNet Gloss Corpus, and Wikipedia. BabelNet (Navigli and Ponzetto, 2012) was initially created by linking the largest multilingual Web encyclopedia, i.e. Wikipedia, with the most popular computational semantic lexicon, i.e., 518 3.3 WordNet. Later it was expanded with a number of resources: The initial performance of the algorithms can be moderate when the knowledge-base is limited only to the plain wordnet structure. We can significantly improve the overall performance by introducin"
R19-1061,kedzia-piasecki-2014-ruled,1,0.825055,"Missing"
R19-1061,W18-2505,0,0.0264756,"Missing"
R19-1061,E09-1005,0,0.638893,"association between “hot” areas and senses to be selected. Various methods following this scheme were proposed. Weakly supervised WSD methods are mostly based on the recursive PageRank algorithm (Page et al., 1998) for spreading activation. Mihalcea et al. (2004) proposed application of the original PageRank to WSD called Static PageRank. PageRank algorithm (henceforth PR) is an iterative method for ranking nodes in the graph G. In WSD the nodes in G represent synsets and the edges of G correspond to wordnet relations (linking synsets, and in some wordnets also linking specific word senses). (Agirre and Soroa, 2009; Agirre et al., 2014) proposed a modified version called Personalised PageRank (PPR) in which the values in v, called personalised vector, depend on the textual context of the disambiguated word. The non-zero score values are assigned to those nodes which are contextually supported. In PPR all words from the context are disambiguated at once. The v values tially good compromise. Such methods can cover, at least potentially, all word senses described in a lexical knowledge base. Very large wordnets describing more than 100,000 words (lemmas) and their senses by hundreds of lexico-semantic rela"
R19-1061,C16-1213,1,0.901524,"Missing"
R19-1061,W10-4001,0,0.0649601,"Missing"
R19-1061,C04-1162,0,0.0624005,"formation in some “hot” areas and identify word senses located in them or close to them. The identified synsets should be the most likely senses for words in the text. There are several parameters to set in this general scheme: the initial activation (coming from the text words), spreading activation algorithm (topology and relations) and identification of association between “hot” areas and senses to be selected. Various methods following this scheme were proposed. Weakly supervised WSD methods are mostly based on the recursive PageRank algorithm (Page et al., 1998) for spreading activation. Mihalcea et al. (2004) proposed application of the original PageRank to WSD called Static PageRank. PageRank algorithm (henceforth PR) is an iterative method for ranking nodes in the graph G. In WSD the nodes in G represent synsets and the edges of G correspond to wordnet relations (linking synsets, and in some wordnets also linking specific word senses). (Agirre and Soroa, 2009; Agirre et al., 2014) proposed a modified version called Personalised PageRank (PPR) in which the values in v, called personalised vector, depend on the textual context of the disambiguated word. The non-zero score values are assigned to th"
R19-1061,P13-1133,0,0.0235109,"pendium of sourced quotations from notable people and creative works in every language (March 2015 dump); • VerbNet (Kippera et al., 2006), a Class-Based Verb Lexicon (version 3.2); • Microsoft Terminology, a collection of terminologies that can be used to develop localised versions of applications (July 2015 dumps); • GeoNames, a free geographical database covering all countries and containing over eight million place names (April 2015 dump); • FrameNet (Ruppenhofer et al., 2016), a lexical database of English that is both humanand machine-readable (version 1.6); • Open Multilingual WordNet (Bond and Foster, 2013), a collection of wordnets available in different languages. The mappings provided by BabelNet (especially the links between synsets and Wikipedia pages) were built semi-automatically. We chose to manually map synsets of plWordNet by lexicographers instead of use the semi-automatic mappings provided by BabelNet to have more control over the accuracy of our results. 3.2 Expansions Presented Knowledge Base For the work presented here, two knowledge graphs were built on the basis of the two largest wordnets, namely plWordNet 3.2 (Maziarz et al., 2016) for Polish, and Princeton WordNet 3.1 (Fellba"
R19-1061,Q14-1019,0,0.259252,"Net (Navigli and Ponzetto, 2012) was initially created by linking the largest multilingual Web encyclopedia, i.e. Wikipedia, with the most popular computational semantic lexicon, i.e., 518 3.3 WordNet. Later it was expanded with a number of resources: The initial performance of the algorithms can be moderate when the knowledge-base is limited only to the plain wordnet structure. We can significantly improve the overall performance by introducing new semantic links to the basis knowledge graph. In this work we expanded the ideas presented in (Agirre and Soroa, 2009), (Agirre et al., 2018) and (Moro et al., 2014). Following the procedure presented in (Agirre et al., 2018) we extended the structure of our knowledge graph by including the links extracted from the the Princeton WordNet Gloss Corpus2 including manually disambiguated glosses. The Suggested Upper Merged Ontology (SUMO) (Pease, 2011) is a formal representation of concepts, organised into hierarchies of classes and subclasses, which is widely used for semantic analysis in NLP. The lexical senses of PWN 3.0 and plWordNet 3.2 have been mapped onto their equivalent concepts of SUMO. The mapping procedure for plWordNet was based on interlingual l"
R19-1061,N15-1026,0,0.0484358,"Missing"
R19-1061,E17-1010,0,0.0218903,"adapted a following set of parameters for our experimental part: the transition probability c = 0.3, the overall number of random walks per node rw_iter = 1000, the importance of sense frequencies on the final score α = 0.5, and (1−α) for the importance of random walk-based scores. For a Polish dataset we did not use sense frequencies since there are no sense-tagged corpora available to compute the frequencies. The resultant performance (tables tab. 1 and tab. 2) was computed 10 times and averaged. Datasets In the experimental part we evaluate our methods on the English dataset described in (Raganato et al., 2017) and the Polish dataset presented in (K˛edzia et al., 2015). The former dataset consists of the five standard English texts prepared for Senseval and SemEval competitions for all-words WSD task. A sense inventory for the gold standard annotations was built on a basis of Princeton WordNet 3.0 which makes it approximately compatible with our knowledge-base, i.e. built on extended Princeton WordNet 3.1 in the case of English and plWordNet 3.2 (mapped to WordNet 3.1 and via it to SUMO) in the case of Polish. As we use WordNet 3.1 some small discrepancies can influence the results of the comparison"
R19-1148,Q17-1010,0,0.0199104,"much information as possible from the text structure which can be helpful in next stages of processing like sentiment recognition. Many of the methods proposed in literature are based on a process: normalisation followed by tagger application. Thus, a comparison of our solution with them is difficult, as the text tagged is different. Therefore we do not handle segmentation problems in our tagging system. To deal with typos and lack of diacritics we focus on character representation together with suffix representation and choose to use the fastText 1 http://hdl.handle.net/11321/637 embedding (Bojanowski et al., 2017), because it is based on the n-gram based subword word representation. In addition, we obtained cluster information to get better representation of contexts for similar words. We applied the Brown Clustering algorithm (Brown et al., 1992) to group words on the basis of the one million subcorpus of NCP (Przepiórkowski et al., 2012) (this is the same data set which is used as training data). The Brown Clustering is a method of hierarchical clustering of words based on their contexts. We assumed that words belonging to the same clusters have the same probability of the contextual occurrence under"
R19-1148,J92-4003,0,0.236085,". Thus, a comparison of our solution with them is difficult, as the text tagged is different. Therefore we do not handle segmentation problems in our tagging system. To deal with typos and lack of diacritics we focus on character representation together with suffix representation and choose to use the fastText 1 http://hdl.handle.net/11321/637 embedding (Bojanowski et al., 2017), because it is based on the n-gram based subword word representation. In addition, we obtained cluster information to get better representation of contexts for similar words. We applied the Brown Clustering algorithm (Brown et al., 1992) to group words on the basis of the one million subcorpus of NCP (Przepiórkowski et al., 2012) (this is the same data set which is used as training data). The Brown Clustering is a method of hierarchical clustering of words based on their contexts. We assumed that words belonging to the same clusters have the same probability of the contextual occurrence under the condition of the occurrence of preceding and following words. In principle, we want to achieve good results in spite of processing noisy textual data, due to the knowledge of their structure on the coarse-grained description level ba"
R19-1148,W18-3917,0,0.0258826,"Missing"
R19-1148,W17-1410,0,0.0359938,"Missing"
R19-1148,P16-2067,0,0.0134698,"t type of a recursive network (Silfverberg and Drobac, 2018) for this purpose. The way the network is trained ensures that a tag that has never occurred in the training data is not generated. Such a manner of getting replies from networks allows also words, which are concatenated together from several morphemes, to have a ‘multi-part’ tag, i.e. a cluster of several tags per se. This solution was inspired by the Sequence-toSequence architecture. It also shows the positive effect of combining embedding vectors for words and characters, which is confirmed by other works from this genre, such as (Plank et al., 2016). Another work in this field is (Ljubeši´c, 2018), which compares a tagger model based on Conditional Random Fields with a model based on a recursive neural network in disambiguation of Slovene, Serbian and Croatian CMC texts. The differences between the two models are small (about 0.02), which leads to the conclusion that both methods are worth considering in further research. However, a comparative study in (Östling, 2018) shows that better results are achieved with good manual processing of features than with extending and deepening the architecture. Apart from CRF-based models, the other m"
R19-1148,K18-2004,0,0.0283879,"the encoding of the input text and features generated for it. Toygger uses text encoded as a sequence of embedding vectors in combination with information from the morphological analysis performed with the morpho-syntactic analyser Morfeusz2 (Kiera´s and Woli´nski, 2017), and KRNNT uses information from the morphological analysis ´ from Maca (Radziszewski and Sniatowski, 2011) (that is also employing Morfeusz inside) in combination with predetermined features based on a set of features from the Concraft (Waszczuk, 2012) tool. In a similar way, complex systems such as dependency parser COMBO (Rybak and Wróblewska, 2018), in their internal taggers began to use LSTM networks with similar architecture to the stand-alone taggers mentioned above. Inside the COMBO system the tagger component obtains the features extracted from a bidirectional LSTM layer and passes them through a fully connected network with one hidden layer with a softmax activation function. That network predicts a universal part-of-speech tag and a tagset specific tag (for instance a grammatical class in the case of a tagset for Polish). The morphological features have similar networks for each feature type. Apart from the systems created for th"
R19-1148,W18-3904,0,0.0135571,"l class in the case of a tagset for Polish). The morphological features have similar networks for each feature type. Apart from the systems created for the Polish language, several solutions were proposed for other Slavic languages or even highly inflected languages in general. The winning solution of the competition organised at the VarDial 2018 conference (Zampieri et al., 2018) was a system based on a bidirectional LSTM network, which instead of classifying words with morpho-syntactic tags generates the tags in a character per character way and uses a different type of a recursive network (Silfverberg and Drobac, 2018) for this purpose. The way the network is trained ensures that a tag that has never occurred in the training data is not generated. Such a manner of getting replies from networks allows also words, which are concatenated together from several morphemes, to have a ‘multi-part’ tag, i.e. a cluster of several tags per se. This solution was inspired by the Sequence-toSequence architecture. It also shows the positive effect of combining embedding vectors for words and characters, which is confirmed by other works from this genre, such as (Plank et al., 2016). Another work in this field is (Ljubeši´"
R19-1148,C12-1170,0,0.367547,"ved very good results in the PolEval contest. The main difference between these two is in the encoding of the input text and features generated for it. Toygger uses text encoded as a sequence of embedding vectors in combination with information from the morphological analysis performed with the morpho-syntactic analyser Morfeusz2 (Kiera´s and Woli´nski, 2017), and KRNNT uses information from the morphological analysis ´ from Maca (Radziszewski and Sniatowski, 2011) (that is also employing Morfeusz inside) in combination with predetermined features based on a set of features from the Concraft (Waszczuk, 2012) tool. In a similar way, complex systems such as dependency parser COMBO (Rybak and Wróblewska, 2018), in their internal taggers began to use LSTM networks with similar architecture to the stand-alone taggers mentioned above. Inside the COMBO system the tagger component obtains the features extracted from a bidirectional LSTM layer and passes them through a fully connected network with one hidden layer with a softmax activation function. That network predicts a universal part-of-speech tag and a tagset specific tag (for instance a grammatical class in the case of a tagset for Polish). The morp"
R19-1148,W18-3901,0,0.0605409,"Missing"
W14-0142,C12-2101,1,\N,Missing
W14-0142,R13-1058,1,\N,Missing
W14-0142,kurc-etal-2012-constraint,1,\N,Missing
W14-0142,P13-1133,0,\N,Missing
W14-0146,J08-4004,0,0.0801973,"substantial. It is commonly assumed that only κ ≥ 0.8 guarantees reliable results in computational linguistics, and κ in 0.67-0.8 is tolerable. Reidsma and Carletta (2007) show that this rule of thumb does not always work. Sometimes lower κ makes the results reliable, sometimes even κ ≥ 0.8 does not suffice. The authors recommend checking whether differences between annotators are systematic or random,11 so we have decided also to put our data 10 The confidence interval was calculated by simple percentile bootstrap (DiCiccio and Efron, 1996; DiCiccio and Romano, 1988) suitable for Cohen’s κ (Artstein and Poesio, 2008). 11 The former is a real problem for computational methods, label system 10 labels 5 labels Cohen’s κ 0.645 0.722 confidence interval of κ 0.586-0.722 0.657-0.785 p-value of χ2 test 0.03962 0.02686 Table 1: Inter-rater agreement of two annotators assigning marking labels to nouns from plWordNet. Confidence intervals are calculated by the percentile bootstrap method, n = 10000 resamplings, α = 0.05. P-values are calculated for the χ2 tests of independence. The 10-label system was described in Section 4. The 5-label system equates compatible labels, as described in this section. through a non-p"
W14-0146,J08-3001,0,\N,Missing
