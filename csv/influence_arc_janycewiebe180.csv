2007.sigdial-1.5,reidsma-etal-2006-annotating,0,0.072425,"Missing"
2007.sigdial-1.5,P04-1085,0,0.0839832,"Missing"
2007.sigdial-1.5,W06-1639,0,0.133431,"Missing"
2007.sigdial-1.5,W05-0308,1,0.769752,"Missing"
2007.sigdial-1.5,H05-1044,1,0.118163,"of work on the Sentiment category. By contrast, little work has been done on the Arguing category. We first define and annotate these opinion types in AMI meetings. We then perform inter-annotator agreement studies to verify if the two categories can be reliably detected. We develop an Arguing lexicon as a new knowl26 Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue, pages 26–34, c Antwerp, September 2007. 2007 Association for Computational Linguistics edge source for automatically recognizing the Arguing category. We use previously developed lexicons for Sentiment detection (Wilson et al., 2005; Stone et al., 1966) to evaluate their portability to multi-party meetings. Previous efforts in recognizing opinions (or subjectivity) in monologic texts have focussed on knowledge from lexico-syntactic sources. While these have proven useful, we believe that in the conversational genre, reliably recognizing opinion expressions in utterances is a complex discourse task. Thus, we explore the novel use of dialog features for opinion recognition in combination with a lexicon. We find that this combination of knowledge sources shows promising results. The rest of the paper is organized as follows"
A97-1056,P94-1020,1,0.960352,"by the results of an extensive disambiguation experiment involving 12 ambiguous 388 words (in sections 5 and 6). We discuss related work (in section 7) and close with recommendations for search strategy and evaluation criterion when selecting models for word-sense disambiguation. 2 Decomposable Models Decomposable models are a subset of the class of graphical models (Whittaker, 1990) which are in turn a subset of the class of log-linear models (Bishop et al., 1975). Familiar examples of decomposable models are Naive Bayes and n-gram models. They are characterized by the following properties (Bruce and Wiebe, 1994b): 1. In a graphical model, variables are either interdependent or conditionally independent of one another. 1 All graphical models have a graphical representation such that each variable in the model is mapped to a node in the graph, and there is an undirected edge between each pair of nodes corresponding to interdependent variables. The sets of completely connected nodes (i.e., cliques) correspond to sets of interdependent variables. Any two nodes that are not directly connected by an edge are conditionally independent given the values of the nodes on the path that connects them. 2. Decompo"
A97-1056,W96-0210,1,0.46849,"Evaluation criteria fall into two broad classes, significance tests and information criteria. This paper considers two significance tests, the exact conditional test (Kreiner, 1987) and the Log-likelihood ratio statistic G 2 (Bishop et al., 1975), and two information criteria, Akaike&apos;s Information Criterion (AIC) (Akaike, 1974) and the Bayesian Information Criterion (BIC) (Schwarz, 1978). 4.1 Significance tests The Log-likelihood ratio statistic G 2 is defined as: q = F_,.f, × logei (3) (2) 5 Experimental Data The sense-tagged text and feature set used in these experiments are the same as in (Bruce et al., 1996). The text consists of every sentence from the A C L / D C I Wall Street Journal corpus that contains any of the nouns interest, bill, concern, and drug, any of the verbs close, help, agree, and include, or any of the adjectives chief, public, last, and common. The extracted sentences have been hand-tagged with senses defined in the Longman Dictionary of Contemporary English (LDOCE). There are between 800 and 3,000 sense-tagged sentences for each of the 12 words. This data was randomly divided into training and test samples at a 10:1 ratio. A sentence with an ambiguous word is represented by a"
A97-1056,P91-1017,0,0.029491,"on. However, the Naive Bayes classifier has been found to perform well for word-sense disambiguation both here and in a variety of other works (e.g., (Bruce and Wiebe, 1994a), (Gale et al., 1992), (Leacock et al., 1993), and (Mooney, 1996)). In order to utilize models with more complicated interactions among feature variables, (Bruce and Wiebe, 1994b) introduce the use of sequential model selection and decomposable models for word-sense disambiguation. ~ Alternative probabilistic approaches have involved using a single contextual feature to perform disambiguation (e.g., (Brown et al., 1991), (Dagan et al., 1991), and (Yarowsky, 1993) present techniques for identifying the optimal feature to use in disambiguation). M a x i m u m Entropy models have been used to express the interactions among multiple feature variables (e.g., (Berger et al., 1996)), but within this framework no systematic study of interactions has been proposed. Decision tree induction has been applied to word-sense disambiguation (e.g. (Black, 1988) and (Mooney, 1996)) but, while it is a type of model selection, the models are not parametric. SThey recommended a model selection procedure using BSS and the exact conditional test in com"
A97-1056,H93-1051,0,0.197003,"FSS is clearly ilStatistical analysis of NLP d a t a has often been limited to the application of standard models, such as n-gram (Markov chain) models and the Naive Bayes model. While n-grams perform well in p a r t of-speech tagging and speech processing, they require a fixed interdependency structure that is inappropriate for the broad class of contextual features used in word-sense disambiguation. However, the Naive Bayes classifier has been found to perform well for word-sense disambiguation both here and in a variety of other works (e.g., (Bruce and Wiebe, 1994a), (Gale et al., 1992), (Leacock et al., 1993), and (Mooney, 1996)). In order to utilize models with more complicated interactions among feature variables, (Bruce and Wiebe, 1994b) introduce the use of sequential model selection and decomposable models for word-sense disambiguation. ~ Alternative probabilistic approaches have involved using a single contextual feature to perform disambiguation (e.g., (Brown et al., 1991), (Dagan et al., 1991), and (Yarowsky, 1993) present techniques for identifying the optimal feature to use in disambiguation). M a x i m u m Entropy models have been used to express the interactions among multiple feature"
A97-1056,W96-0208,0,0.212431,"l analysis of NLP d a t a has often been limited to the application of standard models, such as n-gram (Markov chain) models and the Naive Bayes model. While n-grams perform well in p a r t of-speech tagging and speech processing, they require a fixed interdependency structure that is inappropriate for the broad class of contextual features used in word-sense disambiguation. However, the Naive Bayes classifier has been found to perform well for word-sense disambiguation both here and in a variety of other works (e.g., (Bruce and Wiebe, 1994a), (Gale et al., 1992), (Leacock et al., 1993), and (Mooney, 1996)). In order to utilize models with more complicated interactions among feature variables, (Bruce and Wiebe, 1994b) introduce the use of sequential model selection and decomposable models for word-sense disambiguation. ~ Alternative probabilistic approaches have involved using a single contextual feature to perform disambiguation (e.g., (Brown et al., 1991), (Dagan et al., 1991), and (Yarowsky, 1993) present techniques for identifying the optimal feature to use in disambiguation). M a x i m u m Entropy models have been used to express the interactions among multiple feature variables (e.g., (Be"
A97-1056,J96-1002,0,0.0330623,"n the path that connects them. 2. Decomposable models are those graphical models that express the joint distribution as the product of the marginal distributions of the variables in the maximal cliques of the graphical representation, scaled by the marginal distributions of variables common to two or more of these maximal sets. Because their joint distributions have such closed-form expressions, the parameters can be estimated directly from the training data without the need for an iterative fitting procedure (as is required, for example, to estimate the parameters of maximum entropy models; (Berger et al., 1996)). 3. Although there are far fewer decomposable models than log-linear models for a given set of feature variables, it has been shown that they have substantially the same expressive power (Whittaker, 1990). The joint parameter estimate ""d]~,]~..f3,~, Fl&apos;F2&apos;F3&apos;s is the probability that the feature vector (fl, f~., .1:3,si) will be observed in a training sample where each observation is represented by the feature variables (F1, F~, F3, S). Suppose that the graphical representation of a decomposable model is defined by the two cliques (i.e., marginals) (F1, S) and (F2, F3, S). The frequencies of"
A97-1056,P96-1006,0,0.0898132,"BSS, some pre-determined cutoff, a. An alternative to using a X2 approximation is to define the exact conditional distribution of G 2. The exact conditional distribution of G 2 is the distribu: tion of G ~ values that would be observed for comparable data samples randomly generated from the model being tested. The significance of G 2 based on the exact conditional distribution does not rely on an asymptotic approximation and is accurate for sparse and skewed data samples (Pedersen et al., 1996) 2An alternative feature set for this data is utilized with an exemplar-based learning algorithm in (Ng and Lee, 1996). 390 The sparse nature of our data can be illustrated by interest. There are 6 possible values for the sense variable. Combined with the other feature variables this results in 37,500,000 possible feature vectors (or joint parameters). However, we have a training sample of only 2,100 instances. 6 Experimental Results In total, eight different decomposable models were selected via a model search for each of the 12 words. Each of the eight models is due to a different combination of search strategy and evaluation criterion. Two additional classifiers were evaluated to serve as benchmarks. The d"
A97-1056,H94-1047,1,0.850766,"by the results of an extensive disambiguation experiment involving 12 ambiguous 388 words (in sections 5 and 6). We discuss related work (in section 7) and close with recommendations for search strategy and evaluation criterion when selecting models for word-sense disambiguation. 2 Decomposable Models Decomposable models are a subset of the class of graphical models (Whittaker, 1990) which are in turn a subset of the class of log-linear models (Bishop et al., 1975). Familiar examples of decomposable models are Naive Bayes and n-gram models. They are characterized by the following properties (Bruce and Wiebe, 1994b): 1. In a graphical model, variables are either interdependent or conditionally independent of one another. 1 All graphical models have a graphical representation such that each variable in the model is mapped to a node in the graph, and there is an undirected edge between each pair of nodes corresponding to interdependent variables. The sets of completely connected nodes (i.e., cliques) correspond to sets of interdependent variables. Any two nodes that are not directly connected by an edge are conditionally independent given the values of the nodes on the path that connects them. 2. Decompo"
A97-1056,H93-1052,0,\N,Missing
A97-1056,P91-1034,0,\N,Missing
banea-etal-2008-bootstrapping,E06-1026,0,\N,Missing
banea-etal-2008-bootstrapping,E06-1025,0,\N,Missing
banea-etal-2008-bootstrapping,E06-1027,0,\N,Missing
banea-etal-2008-bootstrapping,N06-1026,0,\N,Missing
banea-etal-2008-bootstrapping,H05-1044,1,\N,Missing
banea-etal-2008-bootstrapping,H93-1061,0,\N,Missing
banea-etal-2008-bootstrapping,W03-1017,0,\N,Missing
banea-etal-2008-bootstrapping,W03-1014,1,\N,Missing
banea-etal-2008-bootstrapping,P07-1123,1,\N,Missing
banea-etal-2008-bootstrapping,P02-1053,0,\N,Missing
banea-etal-2008-bootstrapping,esuli-sebastiani-2006-sentiwordnet,0,\N,Missing
C00-1044,A88-1019,0,0.0212769,"r emphasis, and redder and redder (as in “her face became redder and redder”) can be used to indicate a progression of coloring. To distinguish between truly gradable adjectives and non-gradable adjectives in these exceptional contexts, we have developed a trainable log-linear statistical model that takes into account the number of times an adjective has been observed in a form or context indicating gradability relative to the number of times it has been seen in non-gradable contexts. We use a shallow parser to retrieve from a large corpus tagged for part-of-speech with Church’s PARTS tagger (Church, 1988) all adjectives and their modifiers. Although the most common use of an adverb modifying an adjective is to function as an intensifier or diminisher (Quirk et al., 1985, p. 445), adverbs can also add to the semantic content of the adjectival phrase instead of providing a grading effect (e.g., immediately available, politically vulnerable), or function as emphasizers, adding to the force of the base adjective and not to its degree (e.g., virtually impossible; compare *very impossible). Therefore, we compiled by hand a list of 73 adverbs and noun phrases (such as a little, exceedingly, somewhat,"
C00-1044,P97-1023,1,0.486415,"tologies are useful for many NLP tasks, such as machine translation, word-sense disambiguation, and generation. Some subjective features are included in existing ontologies (for example, Mikrokosmos (Mahesh and Nirenburg, 1995) includes attitude slots). Our corpusbased methods could help in identifying more or extending their coverage. To be able to use automatic subjectivity recognition in text-processing applications, good clues of subjectivity must be found. The features developed in this paper are not only good clues of subjectivity, they can be identified automatically from corpora (see (Hatzivassiloglou and McKeown, 1997), and Section 3 in the present paper). In fact, the results in Table 3 show that the predictability of the automatically determined gradability and polarity sets is better than or at least comparable to the predictability of the manually determined sets. Thus, the oriented and gradable adjectives in the particular application genre can be identified for use in subjectivity recognition. Our efforts in this paper are largely exploratory, aiming to establish correlations among the various features examined. In related work, we have begun to incorporate the features developed here into systems for"
C00-1044,J93-2004,0,0.0765266,"Missing"
C00-1044,P99-1032,1,0.487023,"Missing"
C08-1101,H05-1043,0,0.0189711,"iloff et al., 2003; Pang and Lee, 2004) and adjacency pair information has been used to predict congressional votes (Thomas et al., 2006). However, these methods do not explicitly model the relations between opinions. An application of the idea of alternative targets can be seen in Kim and Hovy’s (2007) work on election prediction. They assume that if a speaker expresses support for one party, all mentions of the competing parties have negative polarity, thus creating automatically labeled training data. In the field of product review mining, sentiments and features (aspects) have been mined (Popescu and Etzioni, 2005), where the aspects correspond to our definition of targets. However, the aspects themselves are not related to each other in any fashion. Polanyi and Zaenen (2006), in their discussion on contextual valence shifters, have also observed the phenomena described in this work - namely that a central topic may be divided into subtopics in order to perform evaluations, and that discourse structure can influence the overall interpretation of valence. Snyder and Barzilay (2007) combine an agreement model based on contrastive RST relations with a local aspect model to make a more informed overall deci"
C08-1101,W03-0404,1,0.298262,"e baseline which has comparable accuracy, namely Distribution, we see that our system improves in f-measure by 24 percentage points. Our results are encouraging - even using simple features to capture target relations achieves considerable improvement over the baselines. However, there is much room for improvement. Using more detailed target and discourse information promises to further improve system performance. These are avenues for future work. 6 Related work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (Riloff et al., 2003; Pang and Lee, 2004) and adjacency pair information has been used to predict congressional votes (Thomas et al., 2006). However, these methods do not explicitly model the relations between opinions. An application of the idea of alternative targets can be seen in Kim and Hovy’s (2007) work on election prediction. They assume that if a speaker expresses support for one party, all mentions of the competing parties have negative polarity, thus creating automatically labeled training data. In the field of product review mining, sentiments and features (aspects) have been mined (Popescu and Etzion"
C08-1101,N07-1038,0,0.0460476,"tomatically labeled training data. In the field of product review mining, sentiments and features (aspects) have been mined (Popescu and Etzioni, 2005), where the aspects correspond to our definition of targets. However, the aspects themselves are not related to each other in any fashion. Polanyi and Zaenen (2006), in their discussion on contextual valence shifters, have also observed the phenomena described in this work - namely that a central topic may be divided into subtopics in order to perform evaluations, and that discourse structure can influence the overall interpretation of valence. Snyder and Barzilay (2007) combine an agreement model based on contrastive RST relations with a local aspect model to make a more informed overall decision for sentiment classification. In our scheme, their aspects would be related as same and their high contrast relations would correspond to the non-reinforcing frames SPSNsame, SNSPsame. Additionally, our frame relations would link the sentiments across nonadjacent clauses, and make connections via alt target relations. With regard to meetings, the most closely related work includes the dialog-related annotation 807 schemes for various available corpora of conversatio"
C08-1101,2007.sigdial-1.5,1,0.931162,"on and polarity information. Our experiments thus focus on the new question: “Given two opinion sentences, determine if they participate in any frame relation.” Here, an opinion sentence is a sentence containing one or more sentiment or arguing expression. In this work, we consider frame detection only between sentence pairs belonging to the same speaker. 5.1 Annotation of Gold Standard Creating gold-standard opinion-frame data is accomplished by annotating frame components and then building the frames from those underlying annotations. We began with annotations created by Somasundaran et al. (2007), namely four meetings of the AMI meeting corpus annotated for sentiment and arguing opinions (text anchor and type). Following that annotation scheme, we annotated an additional meeting. This gave us a corpus of 4436 sentences or 2942 segments (utterances). We added attributes to the existing opinion annotations, namely polarity and target-id. The targetid attribute links the opinion to its local target span. Relations between targets were then annotated. When a newly annotated target is similar (or opposed) to a set of targets already participating in same relations, then the same (or alt) l"
C08-1101,W08-0122,1,0.75346,"n annotated. When a newly annotated target is similar (or opposed) to a set of targets already participating in same relations, then the same (or alt) link is made only to one of them - the one that seems most natural. This is often the one that is physically closest. Table 3: Features for Opinion Frame detection Link transitivity is then used to connect targets that are not explicitly linked by the annotators. All annotations were performed by two of the co-authors of this paper by consensus labeling. The details of our annotation scheme and interannotator agreement studies are presented in (Somasundaran et al., 2008). Once the individual frame components are annotated, conceptually, a frame exists for a pair of opinions if their polarities are either positive or negative and their targets are in a same or alt relation. For our experiments, if a path exists between two targets, then their opinions are considered to be participating in an opinion-frame relation. The experimental data consists of pairs of opinion sentences and the gold-standard information whether there exists a frame between them. We approximate continuous discourse by only pairing sentences that are not more than 10 sentences apart. We als"
C08-1101,W06-1639,0,0.0206321,"entage points. Our results are encouraging - even using simple features to capture target relations achieves considerable improvement over the baselines. However, there is much room for improvement. Using more detailed target and discourse information promises to further improve system performance. These are avenues for future work. 6 Related work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (Riloff et al., 2003; Pang and Lee, 2004) and adjacency pair information has been used to predict congressional votes (Thomas et al., 2006). However, these methods do not explicitly model the relations between opinions. An application of the idea of alternative targets can be seen in Kim and Hovy’s (2007) work on election prediction. They assume that if a speaker expresses support for one party, all mentions of the competing parties have negative polarity, thus creating automatically labeled training data. In the field of product review mining, sentiments and features (aspects) have been mined (Popescu and Etzioni, 2005), where the aspects correspond to our definition of targets. However, the aspects themselves are not related to"
C08-1101,J00-4003,0,0.0129342,"ish relations between targets, in the process relating their respective opinions. We address two types of relations, same and alternative. The same relation holds between targets that refer to the same entity, property, or proposition. Observing the relations marked by annotators, we found that same covers not only identity, but also part-whole, synonymy, generalization, specialization, entity-attribute, instantiation, cause-effect, epithets and implicit background topic, i.e., relations that have been studied by many researchers in the context of anaphora and co-reference (e.g. (Clark, 1975; Vieira and Poesio, 2000; Mueller and Strube, 2001)). Actually, same relations holding between entities often involve co-reference (where co-reference is broadly conceived to include relations such as part-whole listed above). However, there are no morphosyntactic constraints on what targets may be. Thus, same relations may also hold between adjective phrases, verb phrases, and clauses. An instance of this is Example 1, where the same target relation holds between the adjectives edgy and computery. 1 Polarity can also be neutral or both (Wilson and Wiebe, 2005), but these values are not significant for our opinion fr"
C08-1101,W05-0308,1,0.911842,"lt, ANSNalt ment (turn/utterance) information for each speaker. Each utterance consists of one or more sentences. We also use some of the accompanying manual annotations (like adjacency pairs) as features in our machine learning experiments. 3 Opinion Frames Table 1: Opinion Frames In this section, we lay out definitions relating to opinion frames, illustrate with examples how these are manifested in our data, and consider them in the context of discourse relations. 3.1 Definitions The components of opinion frames are individual opinions and the relationships between their targets. Following (Wilson and Wiebe, 2005; Somasundaran et al., 2007), we address two types of opinions, sentiment and arguing. Sentiment includes positive and negative evaluations, emotions, and judgments. Arguing includes arguing for or against something, and arguing that something should or should not be done. Opinions have a polarity that can be positive or negative. 1 The target of an opinion is the entity or proposition that the opinion is about. We establish relations between targets, in the process relating their respective opinions. We address two types of relations, same and alternative. The same relation holds between targ"
C08-1101,T75-2000,0,0.843069,"ut. We establish relations between targets, in the process relating their respective opinions. We address two types of relations, same and alternative. The same relation holds between targets that refer to the same entity, property, or proposition. Observing the relations marked by annotators, we found that same covers not only identity, but also part-whole, synonymy, generalization, specialization, entity-attribute, instantiation, cause-effect, epithets and implicit background topic, i.e., relations that have been studied by many researchers in the context of anaphora and co-reference (e.g. (Clark, 1975; Vieira and Poesio, 2000; Mueller and Strube, 2001)). Actually, same relations holding between entities often involve co-reference (where co-reference is broadly conceived to include relations such as part-whole listed above). However, there are no morphosyntactic constraints on what targets may be. Thus, same relations may also hold between adjective phrases, verb phrases, and clauses. An instance of this is Example 1, where the same target relation holds between the adjectives edgy and computery. 1 Polarity can also be neutral or both (Wilson and Wiebe, 2005), but these values are not signi"
C08-1101,D07-1113,0,0.0978778,"Missing"
C08-1101,W01-1612,0,0.018633,"gets, in the process relating their respective opinions. We address two types of relations, same and alternative. The same relation holds between targets that refer to the same entity, property, or proposition. Observing the relations marked by annotators, we found that same covers not only identity, but also part-whole, synonymy, generalization, specialization, entity-attribute, instantiation, cause-effect, epithets and implicit background topic, i.e., relations that have been studied by many researchers in the context of anaphora and co-reference (e.g. (Clark, 1975; Vieira and Poesio, 2000; Mueller and Strube, 2001)). Actually, same relations holding between entities often involve co-reference (where co-reference is broadly conceived to include relations such as part-whole listed above). However, there are no morphosyntactic constraints on what targets may be. Thus, same relations may also hold between adjective phrases, verb phrases, and clauses. An instance of this is Example 1, where the same target relation holds between the adjectives edgy and computery. 1 Polarity can also be neutral or both (Wilson and Wiebe, 2005), but these values are not significant for our opinion frames. The alternative relat"
C08-1101,P04-1035,0,0.0375306,"comparable accuracy, namely Distribution, we see that our system improves in f-measure by 24 percentage points. Our results are encouraging - even using simple features to capture target relations achieves considerable improvement over the baselines. However, there is much room for improvement. Using more detailed target and discourse information promises to further improve system performance. These are avenues for future work. 6 Related work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (Riloff et al., 2003; Pang and Lee, 2004) and adjacency pair information has been used to predict congressional votes (Thomas et al., 2006). However, these methods do not explicitly model the relations between opinions. An application of the idea of alternative targets can be seen in Kim and Hovy’s (2007) work on election prediction. They assume that if a speaker expresses support for one party, all mentions of the competing parties have negative polarity, thus creating automatically labeled training data. In the field of product review mining, sentiments and features (aspects) have been mined (Popescu and Etzioni, 2005), where the a"
C08-1101,H05-2017,0,\N,Missing
C10-1004,E06-2031,0,0.0482677,"Missing"
C10-1004,W03-1014,1,0.521582,"Missing"
C10-1004,D08-1014,1,0.778312,"rtment of Computer Science University of Pittsburgh wiebe@cs.pitt.edu Carmen Banea, Rada Mihalcea Department of Computer Science University of North Texas carmenbanea@my.unt.edu rada@cs.unt.edu Abstract generate more viable data. Research that benefited from this additional layering ranges from question answering (Yu and Hatzivassiloglou, 2003), to conversation summarization (Carenini et al., 2008), and text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006a). Although subjectivity tends to be preserved across languages – see the manual study in (Mihalcea et al., 2007), (Banea et al., 2008) hypothesize that subjectivity is expressed differently in various languages due to lexicalization, formal versus informal markers, etc. Based on this observation, our research seeks to answer the following questions. First, can we reliably predict sentencelevel subjectivity in languages other than English, by leveraging on a manually annotated English dataset? Second, can we improve the English subjectivity classification by expanding the feature space through the use of multilingual data? Similarly, can we also improve the classifiers in the other target languages? Finally, third, can we ben"
C10-1004,P09-1027,0,0.410042,"Missing"
C10-1004,P07-1056,0,0.0108534,"Missing"
C10-1004,P06-1134,1,0.910603,"Missing"
C10-1004,P08-1041,0,0.0443809,"Missing"
C10-1004,E06-1025,0,0.0568889,"Missing"
C10-1004,esuli-sebastiani-2006-sentiwordnet,0,0.011988,"Missing"
C10-1004,W03-1017,0,0.0904504,"Missing"
C10-1004,esuli-etal-2008-annotating,0,0.115023,"Missing"
C10-1004,P07-1123,1,0.828014,"Missing"
C10-1004,H05-1073,0,\N,Missing
C14-1009,D09-1020,1,0.908201,"Missing"
C14-1009,D08-1083,0,0.11253,"oss in accuracy for other two components. 2 Related Work Most work in sentiment analysis focuses on classifying explicit sentiments and extracting explicit opinion expressions, holders and targets (Wiebe et al., 2005; Johansson and Moschitti, 2013; Yang and Cardie, 2013). There is some work investigating features that directly indicate implicit sentiments (Zhang and Liu, 2011; Feng et al., 2013). In contrast, we focus on how we can bridge between explicit and implicit sentiments via inference. To infer the implicit sentiments related to gfbf events, some work mines various syntactic patterns (Choi and Cardie, 2008), proposes linguistic templates (Zhang and Liu, 2011; Anand and Reschke, 2010; Reschke and Anand, 2011), or generates a lexicon of patient polarity verbs (Goyal et al., 2013). Different from their work, which do not cover all cases relevant to gfbf events, (Deng and Wiebe, 2014) defines a generalized set of implicature rules and proposes a graph-based model to achieve sentiment propagation between the agents and themes of gfbf events. However, that system requires all of the gfbf information (Q1)-(Q4) to be input from the manual annotations; the only ambiguity it resolves is sentiments toward"
C14-1009,W06-1651,0,0.0859129,"the current method is greater than that by the previous method, even though it operates over the noisy output of local components automatically. Different from pipeline architectures, where each step is computed independently, joint inference has often achieved better results. Roth and Yih (2004) formulate the task of information extraction using Integer Linear Programming (ILP). Since then, ILP has been widely used in various tasks in NLP, including semantic role labeling (Punyakanok et al., 2004; Punyakanok et al., 2008; Das et al., 2012), joint extraction of opinion entities and relations (Choi et al., 2006; Yang and Cardie, 2013), co-reference resolution (Denis and Baldridge, 2007), and summarization (Martins and Smith, 2009). The most similar ILP model to ours is (Somasundaran and Wiebe, 2009), which improves opinion polarity classification using discourse constraints in an ILP model. However, their work addresses discourse relations among explicit opinions in different sentences. 3 GoodFor/BadFor Event and Implicature This work addresses sentiments toward, in general, states and events which positively or negatively affect entities. Deng et al. (2013) (hereafter DCW) identify a clear case tha"
C14-1009,W14-2618,1,0.789281,"Missing"
C14-1009,J81-4005,0,0.760217,"Missing"
C14-1009,S12-1029,0,0.0270282,"ll see below in Section 6, the improvement over the local detectors by the current method is greater than that by the previous method, even though it operates over the noisy output of local components automatically. Different from pipeline architectures, where each step is computed independently, joint inference has often achieved better results. Roth and Yih (2004) formulate the task of information extraction using Integer Linear Programming (ILP). Since then, ILP has been widely used in various tasks in NLP, including semantic role labeling (Punyakanok et al., 2004; Punyakanok et al., 2008; Das et al., 2012), joint extraction of opinion entities and relations (Choi et al., 2006; Yang and Cardie, 2013), co-reference resolution (Denis and Baldridge, 2007), and summarization (Martins and Smith, 2009). The most similar ILP model to ours is (Somasundaran and Wiebe, 2009), which improves opinion polarity classification using discourse constraints in an ILP model. However, their work addresses discourse relations among explicit opinions in different sentences. 3 GoodFor/BadFor Event and Implicature This work addresses sentiments toward, in general, states and events which positively or negatively affect"
C14-1009,E14-1040,1,0.788127,"ver explicit sentiments and events that positively/negatively affect entities (goodFor/badFor, gfbf events). We incorporate the inferences developed by implicature rules into an optimization framework, to jointly improve sentiment detection toward entities and disambiguate components of gfbf events. The framework simultaneously beats the baselines by more than 10 points in F-measure on sentiment detection and more than 7 points in accuracy on gfbf polarity disambiguation. 1 Introduction Previous work in NLP on sentiment analysis has mainly focused on explicit sentiments. However, as noted in (Deng and Wiebe, 2014), many opinions are expressed implicitly, as shown by this example: Ex(1) The reform would lower health care costs, which would be a tremendous positive change across the entire health-care system. There is an explicit positive sentiment toward the event of “reform lower costs”. However, in expressing this sentiment, the writer also implies he is negative toward the “costs”, since he’s happy to see the costs being decreased. Moreover, the writer may be positive toward “reform” since it contributes to the “lower” event. Such inferences may be seen as opinion-oriented implicatures (i.e., defeasi"
C14-1009,P13-2022,1,0.734062,"tire health-care system. There is an explicit positive sentiment toward the event of “reform lower costs”. However, in expressing this sentiment, the writer also implies he is negative toward the “costs”, since he’s happy to see the costs being decreased. Moreover, the writer may be positive toward “reform” since it contributes to the “lower” event. Such inferences may be seen as opinion-oriented implicatures (i.e., defeasible inferences)1 . We develop a set of rules for inferring and detecting implicit sentiments from explicit sentiments and events such as “lower” (Wiebe and Deng, 2014). In (Deng et al., 2013), we investigate such events, defining a badFor (bf) event to be an event that negatively affects the theme and a goodFor (gf) event to be an event that positively affects the theme of the event.2 Here, “lower” is a bf event. According to their annotation scheme, goodFor/badFor (gfbf) events have NP agents and themes (though the agent may be implicit), and the polarity of a gf event may be changed to bf by a reverser (and vice versa). The ultimate goal of this work is to utilize gfbf information to improve detection of the writer’s sentiments toward entities mentioned in the text. However, thi"
C14-1009,N07-1030,0,0.0648824,"though it operates over the noisy output of local components automatically. Different from pipeline architectures, where each step is computed independently, joint inference has often achieved better results. Roth and Yih (2004) formulate the task of information extraction using Integer Linear Programming (ILP). Since then, ILP has been widely used in various tasks in NLP, including semantic role labeling (Punyakanok et al., 2004; Punyakanok et al., 2008; Das et al., 2012), joint extraction of opinion entities and relations (Choi et al., 2006; Yang and Cardie, 2013), co-reference resolution (Denis and Baldridge, 2007), and summarization (Martins and Smith, 2009). The most similar ILP model to ours is (Somasundaran and Wiebe, 2009), which improves opinion polarity classification using discourse constraints in an ILP model. However, their work addresses discourse relations among explicit opinions in different sentences. 3 GoodFor/BadFor Event and Implicature This work addresses sentiments toward, in general, states and events which positively or negatively affect entities. Deng et al. (2013) (hereafter DCW) identify a clear case that occurs frequently in opinion sentences, namely the gfbf events mentioned ab"
C14-1009,P13-1174,0,0.389712,"results show that, compared to the local detectors, the ILP framework improves sentiment detection by more than 10 points in F-measure and disambiguating gfbf polarity by more than 7 points in the accuracy, without any loss in accuracy for other two components. 2 Related Work Most work in sentiment analysis focuses on classifying explicit sentiments and extracting explicit opinion expressions, holders and targets (Wiebe et al., 2005; Johansson and Moschitti, 2013; Yang and Cardie, 2013). There is some work investigating features that directly indicate implicit sentiments (Zhang and Liu, 2011; Feng et al., 2013). In contrast, we focus on how we can bridge between explicit and implicit sentiments via inference. To infer the implicit sentiments related to gfbf events, some work mines various syntactic patterns (Choi and Cardie, 2008), proposes linguistic templates (Zhang and Liu, 2011; Anand and Reschke, 2010; Reschke and Anand, 2011), or generates a lexicon of patient polarity verbs (Goyal et al., 2013). Different from their work, which do not cover all cases relevant to gfbf events, (Deng and Wiebe, 2014) defines a generalized set of implicature rules and proposes a graph-based model to achieve senti"
C14-1009,J13-3002,0,0.167403,"vents. We are only able to evaluate true hits of gfbf events. Thus, the input to the system is the set of the text spans marked as gfbf events in the corpus. The results show that, compared to the local detectors, the ILP framework improves sentiment detection by more than 10 points in F-measure and disambiguating gfbf polarity by more than 7 points in the accuracy, without any loss in accuracy for other two components. 2 Related Work Most work in sentiment analysis focuses on classifying explicit sentiments and extracting explicit opinion expressions, holders and targets (Wiebe et al., 2005; Johansson and Moschitti, 2013; Yang and Cardie, 2013). There is some work investigating features that directly indicate implicit sentiments (Zhang and Liu, 2011; Feng et al., 2013). In contrast, we focus on how we can bridge between explicit and implicit sentiments via inference. To infer the implicit sentiments related to gfbf events, some work mines various syntactic patterns (Choi and Cardie, 2008), proposes linguistic templates (Zhang and Liu, 2011; Anand and Reschke, 2010; Reschke and Anand, 2011), or generates a lexicon of patient polarity verbs (Goyal et al., 2013). Different from their work, which do not cover all"
C14-1009,W09-1801,0,0.0298487,"cal components automatically. Different from pipeline architectures, where each step is computed independently, joint inference has often achieved better results. Roth and Yih (2004) formulate the task of information extraction using Integer Linear Programming (ILP). Since then, ILP has been widely used in various tasks in NLP, including semantic role labeling (Punyakanok et al., 2004; Punyakanok et al., 2008; Das et al., 2012), joint extraction of opinion entities and relations (Choi et al., 2006; Yang and Cardie, 2013), co-reference resolution (Denis and Baldridge, 2007), and summarization (Martins and Smith, 2009). The most similar ILP model to ours is (Somasundaran and Wiebe, 2009), which improves opinion polarity classification using discourse constraints in an ILP model. However, their work addresses discourse relations among explicit opinions in different sentences. 3 GoodFor/BadFor Event and Implicature This work addresses sentiments toward, in general, states and events which positively or negatively affect entities. Deng et al. (2013) (hereafter DCW) identify a clear case that occurs frequently in opinion sentences, namely the gfbf events mentioned above. As defined in DCW, a gf event is an even"
C14-1009,C04-1197,0,0.032024,"four ambiguities simultaneously. Further, as we will see below in Section 6, the improvement over the local detectors by the current method is greater than that by the previous method, even though it operates over the noisy output of local components automatically. Different from pipeline architectures, where each step is computed independently, joint inference has often achieved better results. Roth and Yih (2004) formulate the task of information extraction using Integer Linear Programming (ILP). Since then, ILP has been widely used in various tasks in NLP, including semantic role labeling (Punyakanok et al., 2004; Punyakanok et al., 2008; Das et al., 2012), joint extraction of opinion entities and relations (Choi et al., 2006; Yang and Cardie, 2013), co-reference resolution (Denis and Baldridge, 2007), and summarization (Martins and Smith, 2009). The most similar ILP model to ours is (Somasundaran and Wiebe, 2009), which improves opinion polarity classification using discourse constraints in an ILP model. However, their work addresses discourse relations among explicit opinions in different sentences. 3 GoodFor/BadFor Event and Implicature This work addresses sentiments toward, in general, states and"
C14-1009,J08-2005,0,0.0175543,"eously. Further, as we will see below in Section 6, the improvement over the local detectors by the current method is greater than that by the previous method, even though it operates over the noisy output of local components automatically. Different from pipeline architectures, where each step is computed independently, joint inference has often achieved better results. Roth and Yih (2004) formulate the task of information extraction using Integer Linear Programming (ILP). Since then, ILP has been widely used in various tasks in NLP, including semantic role labeling (Punyakanok et al., 2004; Punyakanok et al., 2008; Das et al., 2012), joint extraction of opinion entities and relations (Choi et al., 2006; Yang and Cardie, 2013), co-reference resolution (Denis and Baldridge, 2007), and summarization (Martins and Smith, 2009). The most similar ILP model to ours is (Somasundaran and Wiebe, 2009), which improves opinion polarity classification using discourse constraints in an ILP model. However, their work addresses discourse relations among explicit opinions in different sentences. 3 GoodFor/BadFor Event and Implicature This work addresses sentiments toward, in general, states and events which positively o"
C14-1009,W11-0145,0,0.112074,"lassifying explicit sentiments and extracting explicit opinion expressions, holders and targets (Wiebe et al., 2005; Johansson and Moschitti, 2013; Yang and Cardie, 2013). There is some work investigating features that directly indicate implicit sentiments (Zhang and Liu, 2011; Feng et al., 2013). In contrast, we focus on how we can bridge between explicit and implicit sentiments via inference. To infer the implicit sentiments related to gfbf events, some work mines various syntactic patterns (Choi and Cardie, 2008), proposes linguistic templates (Zhang and Liu, 2011; Anand and Reschke, 2010; Reschke and Anand, 2011), or generates a lexicon of patient polarity verbs (Goyal et al., 2013). Different from their work, which do not cover all cases relevant to gfbf events, (Deng and Wiebe, 2014) defines a generalized set of implicature rules and proposes a graph-based model to achieve sentiment propagation between the agents and themes of gfbf events. However, that system requires all of the gfbf information (Q1)-(Q4) to be input from the manual annotations; the only ambiguity it resolves is sentiments toward entities. In contrast, the method in this paper tackles four ambiguities simultaneously. Further, as we"
C14-1009,W04-2401,0,0.0739394,"stem requires all of the gfbf information (Q1)-(Q4) to be input from the manual annotations; the only ambiguity it resolves is sentiments toward entities. In contrast, the method in this paper tackles four ambiguities simultaneously. Further, as we will see below in Section 6, the improvement over the local detectors by the current method is greater than that by the previous method, even though it operates over the noisy output of local components automatically. Different from pipeline architectures, where each step is computed independently, joint inference has often achieved better results. Roth and Yih (2004) formulate the task of information extraction using Integer Linear Programming (ILP). Since then, ILP has been widely used in various tasks in NLP, including semantic role labeling (Punyakanok et al., 2004; Punyakanok et al., 2008; Das et al., 2012), joint extraction of opinion entities and relations (Choi et al., 2006; Yang and Cardie, 2013), co-reference resolution (Denis and Baldridge, 2007), and summarization (Martins and Smith, 2009). The most similar ILP model to ours is (Somasundaran and Wiebe, 2009), which improves opinion polarity classification using discourse constraints in an ILP m"
C14-1009,P09-1026,1,0.0836519,"es, where each step is computed independently, joint inference has often achieved better results. Roth and Yih (2004) formulate the task of information extraction using Integer Linear Programming (ILP). Since then, ILP has been widely used in various tasks in NLP, including semantic role labeling (Punyakanok et al., 2004; Punyakanok et al., 2008; Das et al., 2012), joint extraction of opinion entities and relations (Choi et al., 2006; Yang and Cardie, 2013), co-reference resolution (Denis and Baldridge, 2007), and summarization (Martins and Smith, 2009). The most similar ILP model to ours is (Somasundaran and Wiebe, 2009), which improves opinion polarity classification using discourse constraints in an ILP model. However, their work addresses discourse relations among explicit opinions in different sentences. 3 GoodFor/BadFor Event and Implicature This work addresses sentiments toward, in general, states and events which positively or negatively affect entities. Deng et al. (2013) (hereafter DCW) identify a clear case that occurs frequently in opinion sentences, namely the gfbf events mentioned above. As defined in DCW, a gf event is an event that positively affects the theme of the event and a bf event is an"
C14-1009,P10-2029,0,0.0138141,"but it does not change the polarity between “companies” and “patients”. 6 We use Opinion Extractor (Johansson and Moschitti, 2013) , opinionFinder (Wilson et al., 2005), MPQA subjectivity lexicon (Wilson et al., 2005), General Inquirer (Stone et al., 1966) and a connotation lexicon (Feng et al., 2013), to detect writer’s sentiments toward all agent and theme candidates, and all gfbf events. We adopt Rule 1 and Rule 3 to infer from the sentiment toward event to the sentiment toward theme. Then we conduct a majority voting based on the results. 7 We use the co-reference resolution system from (Stoyanov et al., 2010). 84 6.1 Experiment Data We use the “Affordable Care Act” corpus of DCW, consisting of 134 online editorials and blogs. In total, there are 1,762 annotated triples, out of which 692 are gf or retainers and 1,070 are bf or reversers. From the writer’s perspective, 1,495 noun phrases are annotated positive, 1,114 noun phrases are negative and the remaining 8 are neutral. This indicates that there are many opinions in the corpus. Out of 134 documents in the corpus, 3 do not have any annotation. 6 are used as a development set to develop the heuristics in Sections 4 and 5. We use the remaining 125"
C14-1009,H05-1044,1,0.0959411,"Missing"
C14-1009,P13-1161,0,0.312257,"uate true hits of gfbf events. Thus, the input to the system is the set of the text spans marked as gfbf events in the corpus. The results show that, compared to the local detectors, the ILP framework improves sentiment detection by more than 10 points in F-measure and disambiguating gfbf polarity by more than 7 points in the accuracy, without any loss in accuracy for other two components. 2 Related Work Most work in sentiment analysis focuses on classifying explicit sentiments and extracting explicit opinion expressions, holders and targets (Wiebe et al., 2005; Johansson and Moschitti, 2013; Yang and Cardie, 2013). There is some work investigating features that directly indicate implicit sentiments (Zhang and Liu, 2011; Feng et al., 2013). In contrast, we focus on how we can bridge between explicit and implicit sentiments via inference. To infer the implicit sentiments related to gfbf events, some work mines various syntactic patterns (Choi and Cardie, 2008), proposes linguistic templates (Zhang and Liu, 2011; Anand and Reschke, 2010; Reschke and Anand, 2011), or generates a lexicon of patient polarity verbs (Goyal et al., 2013). Different from their work, which do not cover all cases relevant to gfbf"
C14-1009,P11-2101,0,0.132444,"s in the corpus. The results show that, compared to the local detectors, the ILP framework improves sentiment detection by more than 10 points in F-measure and disambiguating gfbf polarity by more than 7 points in the accuracy, without any loss in accuracy for other two components. 2 Related Work Most work in sentiment analysis focuses on classifying explicit sentiments and extracting explicit opinion expressions, holders and targets (Wiebe et al., 2005; Johansson and Moschitti, 2013; Yang and Cardie, 2013). There is some work investigating features that directly indicate implicit sentiments (Zhang and Liu, 2011; Feng et al., 2013). In contrast, we focus on how we can bridge between explicit and implicit sentiments via inference. To infer the implicit sentiments related to gfbf events, some work mines various syntactic patterns (Choi and Cardie, 2008), proposes linguistic templates (Zhang and Liu, 2011; Anand and Reschke, 2010; Reschke and Anand, 2011), or generates a lexicon of patient polarity verbs (Goyal et al., 2013). Different from their work, which do not cover all cases relevant to gfbf events, (Deng and Wiebe, 2014) defines a generalized set of implicature rules and proposes a graph-based mo"
C90-2069,J88-2004,0,0.0243029,"Missing"
C90-2069,C88-2099,0,0.0879734,"ified to be an expected subjective character (as discussed in Section 3.2). Before we address the effect of subjective elements on identifying the subjective character of a private-state sentence, we need to consider interpretations of private-state sentences. There Subjective elements do this, as in tile following passage; at the start of the passage, Sandy and Dennys are (collectively) the last subjective character: ""13 s This observation is predicted by Nakhimovsky&apos;s work on the discourse structure of narrative text, in which it is suggested that paragraph breaks accompany discontinuities (Nakhimovsky & Rapaport 1988; Naldaimovsky 1988). 9 Actually, the algorithm allows for a broadeningor narrowing of point of view upon a private-state sentence. This can occur because, as shown by Banfield 1982, a subjective sentence can be attributed to a set of characters. 10 We borrow this term from Bantield 1982, but redefine it; Banfield uses it to refer to linguistic elements that always indicate that a sentence is subjective. 404 What nice eyes he had, small, but such a dark blue! [Mansfield, ""The Garden Party""] n There is also an objective interpretation (see Wiebe 1990). tz Cohn 1978 does not acknowledge this amb"
C90-2069,P88-1016,1,0.915615,"short stories, in the ways that texts initiate, continue, and resume a character&apos;s point of view. The rules of the algorithm were checked, by hand, on over four hundred pages from seven novels. We were able to categorize most exceptions according to particular problems that remain to be addressed, such as the effect of certain spatial and temporal discontinuities on the psychological point of view. These classes of exceptions, together with complete descriptions of the current algorithm and its implementation, can be found in Wiebe 1990. A preliminary version of the algorithm was presented by Wiebe & Rapaport 1988. 3. IDENTIFYING THE SUBJECTIVE CHARACTER. 3.1. Introduction. Black, Turner, & Bower (1979) claim the following result of their empirical investigation of point of view in narrative: ""Merely making a character the subject of the narrative statement sufficed to establish his as the dominant point of view"" (p. 187). However, their stimulus materials were short, artificially constructed narratives. For extended texts (i.e., novels and short stories), this simple rule is inadequate. The subjective character of a subjective sentenee is sometimes identifiable from the sentence itself. This is the ca"
C90-2069,J86-3001,0,0.00683419,"last subjective character else SC is the last active character end if else if there is an expected subjective character then SC is the expected subjective character else SC is unidentified end if 5. CONCLUSION. We am extending this work along two avenues. First, we are developing psychological experiments to test whether the regularities on which the algorithm is based influence the reader&apos;s recognition of subjective sentences and identification of subjective characters. Second, we are extending the algorithm to make connections with work on focus of attention and discom&apos;se structure (such as Grosz & Sidner 1986); in particular, we are investigating how resolving anaphora and tracking the current point of view are related (Stark 1987, Hewitt 1988). An important direction for future research is reasoning about the plausibility of a suggested interpretation, that is, whether it is plausible that the con° tent of a subjective sentence is a particular character&apos;s thought or perception. We lmve presented part of an algorithm for identifying subjective characters that is based on regularities in the ways that texts initiate, resume, and continue a character&apos;s point of view. When faced with a subjective sent"
D08-1014,H05-1073,0,0.0266035,"guages (Romanian and Spanish), we show that automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language. 1 Samer Hassan University of North Texas samer@unt.edu Introduction We have seen a surge in interest towards the application of automatic tools and techniques for the extraction of opinions, emotions, and sentiments in text (subjectivity). A large number of text processing applications have already employed techniques for automatic subjectivity analysis, including automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), tracking sentiment timelines in on-line forums and news (Lloyd et al., 2005; Balog et al., 2006), mining opinions from product reviews (Hu and Liu, 2004), and question answering (Yu and Hatzivassiloglou, 2003). First, assuming an English corpus manually annotated for subjectivity, can we use machine translation to generate a subjectivity-annotated corpus in the target language? Second, assuming the availability of a tool for automatic subjectivity analysis in English, can we generate a corpus annotated for subject"
D08-1014,E06-2031,0,0.0371117,"Missing"
D08-1014,E06-1025,0,0.0456582,"a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language. 1 Samer Hassan University of North Texas samer@unt.edu Introduction We have seen a surge in interest towards the application of automatic tools and techniques for the extraction of opinions, emotions, and sentiments in text (subjectivity). A large number of text processing applications have already employed techniques for automatic subjectivity analysis, including automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), tracking sentiment timelines in on-line forums and news (Lloyd et al., 2005; Balog et al., 2006), mining opinions from product reviews (Hu and Liu, 2004), and question answering (Yu and Hatzivassiloglou, 2003). First, assuming an English corpus manually annotated for subjectivity, can we use machine translation to generate a subjectivity-annotated corpus in the target language? Second, assuming the availability of a tool for automatic subjectivity analysis in English, can we generate a corpus annotated for subjectivity in the target language by using automatic subjectivity annotations of Eng"
D08-1014,I05-1001,0,0.0244171,"Work Research in sentiment and subjectivity analysis has received increasingly growing interest from the natural language processing community, particularly motivated by the widespread need for opinion-based applications, including product and movie reviews, entity tracking and analysis, opinion summarization, and others. Much of the work in subjectivity analysis has been applied to English data, though work on other languages is growing: e.g., Japanese data are used in (Kobayashi et al., 2004; Suzuki et al., 2006; Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006). In addition, several participants in the Chinese and Japanese Opinion Extraction tasks of NTCIR6 (Kando and Evans, 2007) performed subjectivity and sentiment analysis in languages other than English. In general, efforts on building subjectivity analysis tools for other languages have been hampered by the high cost involved in creating corpora and lexical resources for a new language. To address this gap, we focus on leveraging resources already developed for one language to derive subjectivity analysis tools for a new language. This motivates"
D08-1014,W06-1642,0,0.0166009,"8 Association for Computational Linguistics 2 3 Related Work Research in sentiment and subjectivity analysis has received increasingly growing interest from the natural language processing community, particularly motivated by the widespread need for opinion-based applications, including product and movie reviews, entity tracking and analysis, opinion summarization, and others. Much of the work in subjectivity analysis has been applied to English data, though work on other languages is growing: e.g., Japanese data are used in (Kobayashi et al., 2004; Suzuki et al., 2006; Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006). In addition, several participants in the Chinese and Japanese Opinion Extraction tasks of NTCIR6 (Kando and Evans, 2007) performed subjectivity and sentiment analysis in languages other than English. In general, efforts on building subjectivity analysis tools for other languages have been hampered by the high cost involved in creating corpora and lexical resources for a new language. To address this gap, we focus on leveraging resources already developed for one language to derive subjectivity analy"
D08-1014,N06-1026,0,0.0672819,"lysis has received increasingly growing interest from the natural language processing community, particularly motivated by the widespread need for opinion-based applications, including product and movie reviews, entity tracking and analysis, opinion summarization, and others. Much of the work in subjectivity analysis has been applied to English data, though work on other languages is growing: e.g., Japanese data are used in (Kobayashi et al., 2004; Suzuki et al., 2006; Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006). In addition, several participants in the Chinese and Japanese Opinion Extraction tasks of NTCIR6 (Kando and Evans, 2007) performed subjectivity and sentiment analysis in languages other than English. In general, efforts on building subjectivity analysis tools for other languages have been hampered by the high cost involved in creating corpora and lexical resources for a new language. To address this gap, we focus on leveraging resources already developed for one language to derive subjectivity analysis tools for a new language. This motivates the direction of our research, in which we use ma"
D08-1014,P07-1123,1,0.683406,"building subjectivity analysis tools for other languages have been hampered by the high cost involved in creating corpora and lexical resources for a new language. To address this gap, we focus on leveraging resources already developed for one language to derive subjectivity analysis tools for a new language. This motivates the direction of our research, in which we use machine translation coupled with cross-lingual annotation projections to generate the resources and tools required to perform subjectivity classification in the target language. The work closest to ours is the one reported in (Mihalcea et al., 2007), where a bilingual lexicon and a manually translated parallel text are used to generate the resources required to build a subjectivity classifier in a new language. In that work, we found that the projection of annotations across parallel texts can be successfully used to build a corpus annotated for subjectivity in the target language. However, parallel texts are not always available for a given language pair. Therefore, in this paper we explore a different approach where, instead of relying on manually translated parallel corpora, we use machine translation to produce a corpus in the new la"
D08-1014,H93-1061,0,0.0139269,"ize of the lexicon and the coverage of the classifier. For most of our experiments we use the high-coverage classifier. 129 Figure 2: Experiment two: machine translation of raw training data from source language into target language Table 1 shows the performance of the two OpinionFinder classifiers as measured on the MPQA corpus (Wiebe and Riloff, 2005). high-precision high-coverage P 86.7 79.4 R 32.6 70.6 F 47.4 74.7 Table 1: Precision (P), Recall (R) and F-measure (F) for the two OpinionFinder classifiers, as measured on the MPQA corpus As a raw corpus, we use a subset of the SemCor corpus (Miller et al., 1993), consisting of 107 documents with roughly 11,000 sentences. This is a balanced corpus covering a number of topics in sports, politics, fashion, education, and others. The reason for working with this collection is the fact that we also have a manual translation of the SemCor documents from English into one of the target languages used in the experiments (Romanian), which enables comparative evaluations of different scenarios (see Section 4). Note that in this experiment the annotation of subjectivity is carried out on the original source language text, and thus expected to be more accurate th"
D08-1014,E06-1026,0,0.0128137,"lulu, October 2008. 2008 Association for Computational Linguistics 2 3 Related Work Research in sentiment and subjectivity analysis has received increasingly growing interest from the natural language processing community, particularly motivated by the widespread need for opinion-based applications, including product and movie reviews, entity tracking and analysis, opinion summarization, and others. Much of the work in subjectivity analysis has been applied to English data, though work on other languages is growing: e.g., Japanese data are used in (Kobayashi et al., 2004; Suzuki et al., 2006; Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006). In addition, several participants in the Chinese and Japanese Opinion Extraction tasks of NTCIR6 (Kando and Evans, 2007) performed subjectivity and sentiment analysis in languages other than English. In general, efforts on building subjectivity analysis tools for other languages have been hampered by the high cost involved in creating corpora and lexical resources for a new language. To address this gap, we focus on leveraging resources already developed for one languag"
D08-1014,P06-1134,1,0.545202,"automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language. 1 Samer Hassan University of North Texas samer@unt.edu Introduction We have seen a surge in interest towards the application of automatic tools and techniques for the extraction of opinions, emotions, and sentiments in text (subjectivity). A large number of text processing applications have already employed techniques for automatic subjectivity analysis, including automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), tracking sentiment timelines in on-line forums and news (Lloyd et al., 2005; Balog et al., 2006), mining opinions from product reviews (Hu and Liu, 2004), and question answering (Yu and Hatzivassiloglou, 2003). First, assuming an English corpus manually annotated for subjectivity, can we use machine translation to generate a subjectivity-annotated corpus in the target language? Second, assuming the availability of a tool for automatic subjectivity analysis in English, can we generate a corpus annotated for subjectivity in the target language by using automatic su"
D08-1014,W03-1017,0,0.0317556,"interest towards the application of automatic tools and techniques for the extraction of opinions, emotions, and sentiments in text (subjectivity). A large number of text processing applications have already employed techniques for automatic subjectivity analysis, including automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), tracking sentiment timelines in on-line forums and news (Lloyd et al., 2005; Balog et al., 2006), mining opinions from product reviews (Hu and Liu, 2004), and question answering (Yu and Hatzivassiloglou, 2003). First, assuming an English corpus manually annotated for subjectivity, can we use machine translation to generate a subjectivity-annotated corpus in the target language? Second, assuming the availability of a tool for automatic subjectivity analysis in English, can we generate a corpus annotated for subjectivity in the target language by using automatic subjectivity annotations of English text and machine translation? Finally, third, can these automatically generated resources be used to effectively train tools for subjectivity analysis in the target language? Since our methods are particula"
D09-1018,W06-1651,0,0.103089,"ation (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. (1) There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. DA-1: ... this kind of rubbery material, DA-2: it’s a bit more bouncy, DA-3: like you said they get chucked around a lot. DA-4: A bit more durable and that can also be ergonomic and DA-5: it kind of feels a bit different from all the other remote controls. In the example, the individual opinion expressions (shown in bold) are essentially regarding the same thing – the rubbery material. Thus, the explicit targets (shown in italics), it’s, that, and it, and the implicit target of a"
D09-1018,N07-1030,0,0.0215381,"guistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. (1) There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. DA-1: ... this kind of rubbery material, DA-2: it’s a bit more bouncy, DA-3: like you said they get chucked around a lot. DA-4: A bit more durable and that can also be ergonomic and DA-5: it kind of feels a bit different from all the other remote controls. In the example, the individual opinion expressions (shown in bold) are essentially regarding the same thing – the rubbery material. Thus, the explicit targets (shown in italics), it’s, that, and it, and the im"
D09-1018,P07-1124,0,0.017294,"8), which was developed to support a global, interdependent polarity interpretation. To achieve discourse-based global inference, we explore two different frameworks. The first is a supervised framework that learns interdependent opinion interpretations from training data. The second is an unsupervised optimization framework which uses constraints to express the ideas of coherent opinion interpretation embodied in the 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, c Singapore, 6-7 August 2009. 2009 ACL and AFNLP 3 tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate how automatic methods"
D09-1018,W06-3808,0,0.0207626,"emote. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (So"
D09-1018,W06-1642,0,0.00908126,"from Somasundaran et al. (2008), which was developed to support a global, interdependent polarity interpretation. To achieve discourse-based global inference, we explore two different frameworks. The first is a supervised framework that learns interdependent opinion interpretations from training data. The second is an unsupervised optimization framework which uses constraints to express the ideas of coherent opinion interpretation embodied in the 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, c Singapore, 6-7 August 2009. 2009 ACL and AFNLP 3 tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstra"
D09-1018,C08-2002,0,0.188107,"s, two diverse global inference paradigms are used: a supervised collective classification framework and an unsupervised optimization framework. Both approaches perform substantially better than baseline approaches, establishing the efficacy of the methods and the underlying discourse scheme. We also present quantitative and qualitative analyses showing how the improvements are achieved. 1 Introduction The importance of discourse in opinion analysis is being increasingly recognized (Polanyi and Zaenen, 2006). Motivated by the need to enable discourse-based opinion analysis, previous research (Asher et al., 2008; Somasundaran et al., 2008) developed discourse schemes and created manually annotated corpora. However, it was not known whether and how well these linguistic ideas and schemes can be translated into effective computational implementations. In this paper, we first investigate ways in which an opinion discourse scheme can be computationally modeled, and then how it can be utilized to improve polarity classification. Specifically, the discourse scheme we use is from Somasundaran et al. (2008), which was developed to support a global, interdependent polarity interpretation. To achieve discourse"
D09-1018,C08-2004,0,0.0137935,"Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. (1) There are sev"
D09-1018,W06-2909,0,0.0131139,"on, the label is transferred upwards to the containing DA. When a DA contains multiple opinion annotations, each with a different polarity, one of them is randomly chosen as the label for the DA. The discourse relations existing between opinions are also transferred upwards, between the DAs containing each of these annotations. We recreate an example from Somasundaran et al. (2008) using DA segmentation in Example 1. Here, the speaker has a positive opinion towards the rubbery material for the TV remote. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (T"
D09-1018,E09-1066,0,0.011278,"rred upwards to the containing DA. When a DA contains multiple opinion annotations, each with a different polarity, one of them is randomly chosen as the label for the DA. The discourse relations existing between opinions are also transferred upwards, between the DAs containing each of these annotations. We recreate an example from Somasundaran et al. (2008) using DA segmentation in Example 1. Here, the speaker has a positive opinion towards the rubbery material for the TV remote. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006"
D09-1018,W98-0801,0,0.0207417,"Missing"
D09-1018,P04-1035,0,0.146992,"her NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on har"
D09-1018,H05-1043,0,0.0369536,"as a positive opinion towards the rubbery material for the TV remote. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et"
D09-1018,D08-1049,0,0.00635378,"Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. (1) There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih,"
D09-1018,W04-2401,0,0.0274539,"et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. (1) There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. DA-1: ... this kind of rubbery material, DA-2: it’s a bit more bouncy, DA-3: like you said they get chucked around a lot. DA-4: A bit more durable and that can also be ergonomic and DA-5: it kind of feels a bit different from all the other remote controls. In the example, the individual opinion expressions (shown in bold) are essentially regarding the same thing – the rubbery material. Thus, the explicit targets (shown in italics), it’s, that, and it, and the implicit target of a bit more durable are"
D09-1018,sadamitsu-etal-2008-sentiment,0,0.0606562,"to support a global, interdependent polarity interpretation. To achieve discourse-based global inference, we explore two different frameworks. The first is a supervised framework that learns interdependent opinion interpretations from training data. The second is an unsupervised optimization framework which uses constraints to express the ideas of coherent opinion interpretation embodied in the 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, c Singapore, 6-7 August 2009. 2009 ACL and AFNLP 3 tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate how automatic methods can use their ideas to i"
D09-1018,2007.sigdial-1.5,1,0.908295,"Missing"
D09-1018,C08-1101,1,0.913435,"006). Motivated by the need to enable discourse-based opinion analysis, previous research (Asher et al., 2008; Somasundaran et al., 2008) developed discourse schemes and created manually annotated corpora. However, it was not known whether and how well these linguistic ideas and schemes can be translated into effective computational implementations. In this paper, we first investigate ways in which an opinion discourse scheme can be computationally modeled, and then how it can be utilized to improve polarity classification. Specifically, the discourse scheme we use is from Somasundaran et al. (2008), which was developed to support a global, interdependent polarity interpretation. To achieve discourse-based global inference, we explore two different frameworks. The first is a supervised framework that learns interdependent opinion interpretations from training data. The second is an unsupervised optimization framework which uses constraints to express the ideas of coherent opinion interpretation embodied in the 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; De"
D09-1018,N07-1037,0,0.0105351,"sing DA segmentation in Example 1. Here, the speaker has a positive opinion towards the rubbery material for the TV remote. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), com"
D09-1018,W06-1639,0,0.0260272,"6; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent infere"
D09-1018,H05-1044,1,0.138976,". Specifically, the discourse scheme we use is from Somasundaran et al. (2008), which was developed to support a global, interdependent polarity interpretation. To achieve discourse-based global inference, we explore two different frameworks. The first is a supervised framework that learns interdependent opinion interpretations from training data. The second is an unsupervised optimization framework which uses constraints to express the ideas of coherent opinion interpretation embodied in the 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, c Singapore, 6-7 August 2009. 2009 ACL and AFNLP 3 tion schemes for interpreting opinions with discours"
D09-1018,W05-0623,0,\N,Missing
D09-1018,H05-2017,0,\N,Missing
D09-1020,N06-2015,0,0.038926,"ity is a property that can be associated with word senses. We show that it is a natural grouping of word senses and that it provides a principled way for clustering senses. They also demonstrate that subjectivity helps with WSD. We show that a coarse-grained WSD variant (SWSD) helps with subjectivity and sentiment analysis. Both (Wiebe and Mihalcea, 2006) and (Su and Markert, 2008) show that even reliable subjectivity clues have objective senses. We demonstrate that this ambiguity is also prevalent in a corpus. Several researchers (e.g., (Palmer et al., 2004; Navigli, 2006; Snow et al., 2007; Hovy et al., 2006)) work on reducing the granularity of sense inventories for WSD. They aim for a more coarsegrained sense inventory to overcome performance shortcomings related to fine-grained sense distinctions. Our work is similar in the sense that we reduce all senses of a word to two senses (S/O). The difference is the criterion driving the grouping. Related work concentrates on syntactic and semantic similarity between senses to group them. In contrast, our grouping is driven by subjectivity with a specific application area in mind, namely subjectivity and sentiment analysis. Table 4: Effect of SWSD on th"
D09-1020,C04-1200,0,0.115446,"report results using 0.0008, though the accuracy using the other thresholds is statistically significantly better than the accuracy of the original classifier at the same level. 196 Acc NP NR NF NgP NgR NgF PsP PsR PsF OP s/N g/N 77.6 80.9 94.6 87.2 60.4 29.4 39.5 52.2 32.4 40.0 R4 80.6 81.2 98.7 89.1 82.1 29.4 43.2 68.6 32.4 44.0 Table 5: Effect of SWSD on the contextual polarity classifier ON/P R3 R4 Acc NP NR NF PP PR PF 79.0 81.5 92.5 86.7 65.8 40.7 50.3 70.0 83.7 73.8 78.4 44.4 59.3 50.8 81.6 81.7 96.8 88.6 81.1 38.6 52.3 tional information as well (e.g., (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Wilson et al., 2005a)). We apply SWSD to some of those systems to show the effect of SWSD on contextual subjectivity and sentiment analysis. Another set of related work is on subjectivity and polarity labeling of word senses (e.g. (Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Wiebe and Mihalcea, 2006; Su and Markert, 2008)). They label senses of words in a dictionary. In comparison, we label senses of word instances in a corpus. Moreover, our work extends findings in (Wiebe and Mihalcea, 2006) and (Su and Markert, 2008). (Wiebe and Mihalcea, 2006) demonstra"
D09-1020,N06-1026,0,0.00935933,"e subjective but not have any particular polarity. An example given by (Wilson et al., 2005a) is Jerome says the hospital feels no different than a hospital in the states. An NLP application system may want to find a wide range of private states attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. Second, benefits for sentiment analysis can be realized by decomposing the problem into S/O (or neutral versus polar) and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005a; Kim and Hovy, 2006). We will see further evidence of this in Section 4.2.3 in this paper. The contextual subjectivity analysis experiments in Section 4 include both S/O and polarity classifications. The data used in those experiments is from the MPQA Corpus (Wiebe et al., 2005; Wilson, 2008),1 which consists of texts from the world press annotated for subjective expressions. 1 His alarm grew. alarm, dismay, consternation – (fear resulting from the awareness of danger) =&gt; fear, fearfulness, fright – (an emotion experienced in anticipation of some specific pain or danger (usually accompanied by a desire to flee or"
D09-1020,C02-1039,1,0.792672,"-tagged data). The subjectivity sense labels are used to collapse the sense labels in the sense-tagged data into the two new senses, S and O. His alarm grew. Will someone shut that darn alarm off? The alarm went off. We use a supervised approach to SWSD. We train a different classifier for each lexicon entry for which we have training data. Thus, our approach is like targeted WSD (in contrast to allwords WSD), with two labels: S and O. We borrow machine learning features which have been successfully used in WSD. Specifically, given an ambiguous target word, we use the following features from (Mihalcea, 2002): Our sense-tagged data are the lexical sample corpora (training and test data) from S ENSEVAL1 (Kilgarriff and Palmer, 2000), S ENSEVAL2 (Preiss and Yarowsky, 2001), and S ENSEVAL3 (Mihalcea and Edmonds, 2004). We selected all of the S ENSEVAL words that are also in the subjectivity lexicon, and labeled their dictionary senses as S, O, or B according to the annotation scheme described above in Section 2. We did this subjectivity sense labeling according to the sense inventory of the underlying corpus (Hector for S ENSEVAL1; WordNet1.7 for S ENSEVAL2; and WordNet1.7.1 for S ENSEVAL3). CW : the"
D09-1020,P06-1014,0,0.0109781,"2006) demonstrates that subjectivity is a property that can be associated with word senses. We show that it is a natural grouping of word senses and that it provides a principled way for clustering senses. They also demonstrate that subjectivity helps with WSD. We show that a coarse-grained WSD variant (SWSD) helps with subjectivity and sentiment analysis. Both (Wiebe and Mihalcea, 2006) and (Su and Markert, 2008) show that even reliable subjectivity clues have objective senses. We demonstrate that this ambiguity is also prevalent in a corpus. Several researchers (e.g., (Palmer et al., 2004; Navigli, 2006; Snow et al., 2007; Hovy et al., 2006)) work on reducing the granularity of sense inventories for WSD. They aim for a more coarsegrained sense inventory to overcome performance shortcomings related to fine-grained sense distinctions. Our work is similar in the sense that we reduce all senses of a word to two senses (S/O). The difference is the criterion driving the grouping. Related work concentrates on syntactic and semantic similarity between senses to group them. In contrast, our grouping is driven by subjectivity with a specific application area in mind, namely subjectivity and sentiment"
D09-1020,W04-2807,0,0.0103097,"Missing"
D09-1020,P04-1035,0,0.0560716,") classification. First, expressions may be subjective but not have any particular polarity. An example given by (Wilson et al., 2005a) is Jerome says the hospital feels no different than a hospital in the states. An NLP application system may want to find a wide range of private states attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. Second, benefits for sentiment analysis can be realized by decomposing the problem into S/O (or neutral versus polar) and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005a; Kim and Hovy, 2006). We will see further evidence of this in Section 4.2.3 in this paper. The contextual subjectivity analysis experiments in Section 4 include both S/O and polarity classifications. The data used in those experiments is from the MPQA Corpus (Wiebe et al., 2005; Wilson, 2008),1 which consists of texts from the world press annotated for subjective expressions. 1 His alarm grew. alarm, dismay, consternation – (fear resulting from the awareness of danger) =&gt; fear, fearfulness, fright – (an emotion experienced in anticipation of some specific pain or danger"
D09-1020,W03-1014,1,0.19976,"d negative classes. Negative precision goes from 60.4 to 82.1 and positive precision goes from 52.2 to 68.6, with no loss in recall. This is evidence that the SWSD system is doing a good job of removing some false hits of subjectivity clues that harm the original version of the system. 5 Comparisons to Previous Work Several researchers exploit lexical resources for contextual subjectivity and sentiment analysis. These systems typically look for the presence of subjective or sentiment-bearing words in the text. They may rely only on this information (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003)), or they may combine it with addi6 Conclusions and Future Work We introduced the task of subjectivity word sense disambiguation (SWSD), and evaluated a supervised method inspired by research in WSD. The 197 system achieves high accuracy, especially on highly ambiguous words, and substantially outperforms WSD on the same data. The positive results provide evidence that SWSD is a feasible variant of WSD, and that the S/O sense groupings are natural ones. We also explored the promise of SWSD for contextual subjectivity analysis. We showed that a subjectivity lexicon can have substantial coverag"
D09-1020,D07-1107,0,0.0177048,"ates that subjectivity is a property that can be associated with word senses. We show that it is a natural grouping of word senses and that it provides a principled way for clustering senses. They also demonstrate that subjectivity helps with WSD. We show that a coarse-grained WSD variant (SWSD) helps with subjectivity and sentiment analysis. Both (Wiebe and Mihalcea, 2006) and (Su and Markert, 2008) show that even reliable subjectivity clues have objective senses. We demonstrate that this ambiguity is also prevalent in a corpus. Several researchers (e.g., (Palmer et al., 2004; Navigli, 2006; Snow et al., 2007; Hovy et al., 2006)) work on reducing the granularity of sense inventories for WSD. They aim for a more coarsegrained sense inventory to overcome performance shortcomings related to fine-grained sense distinctions. Our work is similar in the sense that we reduce all senses of a word to two senses (S/O). The difference is the criterion driving the grouping. Related work concentrates on syntactic and semantic similarity between senses to group them. In contrast, our grouping is driven by subjectivity with a specific application area in mind, namely subjectivity and sentiment analysis. Table 4:"
D09-1020,E06-1027,0,0.0925621,"9.1 82.1 29.4 43.2 68.6 32.4 44.0 Table 5: Effect of SWSD on the contextual polarity classifier ON/P R3 R4 Acc NP NR NF PP PR PF 79.0 81.5 92.5 86.7 65.8 40.7 50.3 70.0 83.7 73.8 78.4 44.4 59.3 50.8 81.6 81.7 96.8 88.6 81.1 38.6 52.3 tional information as well (e.g., (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Wilson et al., 2005a)). We apply SWSD to some of those systems to show the effect of SWSD on contextual subjectivity and sentiment analysis. Another set of related work is on subjectivity and polarity labeling of word senses (e.g. (Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Wiebe and Mihalcea, 2006; Su and Markert, 2008)). They label senses of words in a dictionary. In comparison, we label senses of word instances in a corpus. Moreover, our work extends findings in (Wiebe and Mihalcea, 2006) and (Su and Markert, 2008). (Wiebe and Mihalcea, 2006) demonstrates that subjectivity is a property that can be associated with word senses. We show that it is a natural grouping of word senses and that it provides a principled way for clustering senses. They also demonstrate that subjectivity helps with WSD. We show that a coarse-grained WSD variant (SWSD) helps with subje"
D09-1020,N07-1039,0,0.0911988,"g 0.0008, though the accuracy using the other thresholds is statistically significantly better than the accuracy of the original classifier at the same level. 196 Acc NP NR NF NgP NgR NgF PsP PsR PsF OP s/N g/N 77.6 80.9 94.6 87.2 60.4 29.4 39.5 52.2 32.4 40.0 R4 80.6 81.2 98.7 89.1 82.1 29.4 43.2 68.6 32.4 44.0 Table 5: Effect of SWSD on the contextual polarity classifier ON/P R3 R4 Acc NP NR NF PP PR PF 79.0 81.5 92.5 86.7 65.8 40.7 50.3 70.0 83.7 73.8 78.4 44.4 59.3 50.8 81.6 81.7 96.8 88.6 81.1 38.6 52.3 tional information as well (e.g., (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Wilson et al., 2005a)). We apply SWSD to some of those systems to show the effect of SWSD on contextual subjectivity and sentiment analysis. Another set of related work is on subjectivity and polarity labeling of word senses (e.g. (Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Wiebe and Mihalcea, 2006; Su and Markert, 2008)). They label senses of words in a dictionary. In comparison, we label senses of word instances in a corpus. Moreover, our work extends findings in (Wiebe and Mihalcea, 2006) and (Su and Markert, 2008). (Wiebe and Mihalcea, 2006) demonstrates that subjectivit"
D09-1020,esuli-sebastiani-2006-sentiwordnet,0,0.0602843,"2.4 40.0 R4 80.6 81.2 98.7 89.1 82.1 29.4 43.2 68.6 32.4 44.0 Table 5: Effect of SWSD on the contextual polarity classifier ON/P R3 R4 Acc NP NR NF PP PR PF 79.0 81.5 92.5 86.7 65.8 40.7 50.3 70.0 83.7 73.8 78.4 44.4 59.3 50.8 81.6 81.7 96.8 88.6 81.1 38.6 52.3 tional information as well (e.g., (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Wilson et al., 2005a)). We apply SWSD to some of those systems to show the effect of SWSD on contextual subjectivity and sentiment analysis. Another set of related work is on subjectivity and polarity labeling of word senses (e.g. (Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Wiebe and Mihalcea, 2006; Su and Markert, 2008)). They label senses of words in a dictionary. In comparison, we label senses of word instances in a corpus. Moreover, our work extends findings in (Wiebe and Mihalcea, 2006) and (Su and Markert, 2008). (Wiebe and Mihalcea, 2006) demonstrates that subjectivity is a property that can be associated with word senses. We show that it is a natural grouping of word senses and that it provides a principled way for clustering senses. They also demonstrate that subjectivity helps with WSD. We show that a coarse-grained WSD"
D09-1020,P02-1053,0,0.0108887,"k at the precision of the positive and negative classes. Negative precision goes from 60.4 to 82.1 and positive precision goes from 52.2 to 68.6, with no loss in recall. This is evidence that the SWSD system is doing a good job of removing some false hits of subjectivity clues that harm the original version of the system. 5 Comparisons to Previous Work Several researchers exploit lexical resources for contextual subjectivity and sentiment analysis. These systems typically look for the presence of subjective or sentiment-bearing words in the text. They may rely only on this information (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003)), or they may combine it with addi6 Conclusions and Future Work We introduced the task of subjectivity word sense disambiguation (SWSD), and evaluated a supervised method inspired by research in WSD. The 197 system achieves high accuracy, especially on highly ambiguous words, and substantially outperforms WSD on the same data. The positive results provide evidence that SWSD is a feasible variant of WSD, and that the S/O sense groupings are natural ones. We also explored the promise of SWSD for contextual subjectivity analysis. We showed that a s"
D09-1020,P06-1134,1,0.965016,"ins all of the negative keywords 190 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 190–199, c Singapore, 6-7 August 2009. 2009 ACL and AFNLP first attempt to explicitly use sense-level subjectivity tags in contextual subjectivity and sentiment analysis. 2 In the MPQA Corpus, subjective expressions of varying lengths are marked, from single words to long phrases. In addition, other properties are annotated, including polarity. For SWSD, we need the notions of subjective and objective senses of words in a dictionary. We adopt the definitions from (Wiebe and Mihalcea, 2006), who describe the annotation scheme as follows. Classifying a sense as S means that, when the sense is used in a text or conversation, one expects it to express subjectivity, and also that the phrase or sentence containing it expresses subjectivity. As noted in (Wiebe and Mihalcea, 2006), sentences containing objective senses may not be objective. Thus, objective senses are defined as follows: Classifying a sense as O means that, when the sense is used in a text or conversation, one does not expect it to express subjectivity and, if the phrase or sentence containing it is subjective, the subj"
D09-1020,H05-1044,1,0.565807,"m grew. He absorbed the information quickly. UCC/Disciples leaders roundly condemned the Iranian President’s verbal assault on Israel. What’s the catch? Polarity (also called semantic orientation) is also important to NLP applications. In review mining, for example, we want to know whether an opinion about a product is positive or negative. Nonetheless, as argued by (Wiebe and Mihalcea, 2006; Su and Markert, 2008), there are also motivations for a separate subjective/objective (S/O) classification. First, expressions may be subjective but not have any particular polarity. An example given by (Wilson et al., 2005a) is Jerome says the hospital feels no different than a hospital in the states. An NLP application system may want to find a wide range of private states attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. Second, benefits for sentiment analysis can be realized by decomposing the problem into S/O (or neutral versus polar) and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005a; Kim and Hovy, 2006). We will see further evidence of this in Section 4.2.3 in this paper. T"
D09-1020,H05-2018,1,0.580955,"m grew. He absorbed the information quickly. UCC/Disciples leaders roundly condemned the Iranian President’s verbal assault on Israel. What’s the catch? Polarity (also called semantic orientation) is also important to NLP applications. In review mining, for example, we want to know whether an opinion about a product is positive or negative. Nonetheless, as argued by (Wiebe and Mihalcea, 2006; Su and Markert, 2008), there are also motivations for a separate subjective/objective (S/O) classification. First, expressions may be subjective but not have any particular polarity. An example given by (Wilson et al., 2005a) is Jerome says the hospital feels no different than a hospital in the states. An NLP application system may want to find a wide range of private states attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. Second, benefits for sentiment analysis can be realized by decomposing the problem into S/O (or neutral versus polar) and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005a; Kim and Hovy, 2006). We will see further evidence of this in Section 4.2.3 in this paper. T"
D09-1020,W03-1017,0,0.669166,"arate subjective/objective (S/O) classification. First, expressions may be subjective but not have any particular polarity. An example given by (Wilson et al., 2005a) is Jerome says the hospital feels no different than a hospital in the states. An NLP application system may want to find a wide range of private states attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. Second, benefits for sentiment analysis can be realized by decomposing the problem into S/O (or neutral versus polar) and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005a; Kim and Hovy, 2006). We will see further evidence of this in Section 4.2.3 in this paper. The contextual subjectivity analysis experiments in Section 4 include both S/O and polarity classifications. The data used in those experiments is from the MPQA Corpus (Wiebe et al., 2005; Wilson, 2008),1 which consists of texts from the world press annotated for subjective expressions. 1 His alarm grew. alarm, dismay, consternation – (fear resulting from the awareness of danger) =&gt; fear, fearfulness, fright – (an emotion experienced in anticipation of some spec"
D09-1020,C08-1104,0,\N,Missing
D14-1125,D09-1020,1,0.891328,"Missing"
D14-1125,W11-0311,1,0.890536,"Missing"
D14-1125,J08-4004,0,0.0250475,"fect (-effect) if it has +effect (-effect) on an entity, which may be the agent, the theme, or some other entity. In a previous paper (Choi et al., 2014), we conducted a study of the sense-level +/-effect property. For the evaluation, two annotators (who are co-authors of that paper) independently annotated senses of selected words, where some are from pure +effect (-effect) words (i.e., all senses of the words are classified into the same class) and some are from mixed words (i.e., the words have both +effect and -effect senses). In the agreement study, we calculated percent agreement and κ (Artstein and Poesio, 2008), and achieved 0.84 percent agreement and 0.75 κ value. For a seed set and an evaluation set in this paper, we need annotated sense-level +/-effect data. Mappings between FrameNet and WordNet are not perfect. Thus, we opted to manually annotate the senses of the words in the word-level lexicon. We first extracted all words from 736 +effect LUs and 601 -effect LUs; this extracts 606 +effect words and 537 -effect words (the number of words is smaller than the number of LUs because one word can have more than one LU). Among them, 14 words (e.g., crush, order, etc.) are in both the +effect word se"
D14-1125,baccianella-etal-2010-sentiwordnet,0,0.0506463,"ain two classifiers, one for positive and another for negative. As features, a vectorial representation of glosses is adopted. These classifiers were applied to all WordNet senses to measure positive, negative, and objective scores. In extending their work (Esuli and Sebastiani, 2007), the PageRank algorithm is applied to rank senses in terms of how strongly they are positive or negative. In the graph, each sense is one node, and two nodes are connected when they contain the same words in their WordNet glosses. Moreover, a random-walk step is adopted to refine the scores in their recent work (Baccianella et al., 2010). In contrast, our approach uses WordNet relations and graph propagation in addition to gloss classification. Kang et al. (2014) present a unified model that assigns connotation polarities to both words and senses. They formulate the induction process as collective inference over pairwise-Markov Random Fields, and apply loopy belief propagation for inference. Their approach relies on selectional preferences of connotative predicates; the polarity of a connotation predicate suggests the polarity of its arguments. We have not discovered an analogous type of predicate for the problem we address."
D14-1125,W14-2618,1,0.556274,"them and picked out the LUs which he judged to be +effect or -effect. In total, 736 +effect LUs and 601 -effect LUs were selected from 463 semantic frames. While Deng et al. (2013) and Deng and Wiebe (2014) specifically focus on events affecting objects (i.e., themes), we do not want to limit the lexicon to only that case. Sometimes, events have positive or negative effects on agents or other entities as well. Thus, in this paper, we consider a sense to be +effect (-effect) if it has +effect (-effect) on an entity, which may be the agent, the theme, or some other entity. In a previous paper (Choi et al., 2014), we conducted a study of the sense-level +/-effect property. For the evaluation, two annotators (who are co-authors of that paper) independently annotated senses of selected words, where some are from pure +effect (-effect) words (i.e., all senses of the words are classified into the same class) and some are from mixed words (i.e., the words have both +effect and -effect senses). In the agreement study, we calculated percent agreement and κ (Artstein and Poesio, 2008), and achieved 0.84 percent agreement and 0.75 κ value. For a seed set and an evaluation set in this paper, we need annotated s"
D14-1125,E14-1040,1,0.603867,"in the seed set. 1 (1) The bill would curb skyrocketing health care costs. Introduction Opinion mining (or sentiment analysis) identifies positive or negative opinions in many kinds of texts such as reviews, blogs, and news articles. It has been exploited in many application areas such as review mining, election analysis, and information extraction. While most previous research focusses on explicit opinion expressions, recent work addresses a type of opinion inference that arises when opinions are expressed toward events which have positive or negative effects on entities (Deng et al., 2013; Deng and Wiebe, 2014). We call such events +/-effect events.2 Deng and Wiebe (2014) show how sentiments toward one 1 WordNet 3.0, http://wordnet.princeton.edu/ While the term goodFor/badFor is used in previous papers (Deng et al., 2013; Deng and Wiebe, 2014; Deng et al., 2014), we have since decided that +/-effect is a better term. 2 The writer expresses an explicit negative sentiment (by skyrocketing) toward the object (health care costs). The event, curb, has a negative effect on costs, since they are reduced. We can reason that the writer is positive toward the event because it has a negative effect on costs, t"
D14-1125,P13-2022,1,0.643795,"senses that are not in the seed set. 1 (1) The bill would curb skyrocketing health care costs. Introduction Opinion mining (or sentiment analysis) identifies positive or negative opinions in many kinds of texts such as reviews, blogs, and news articles. It has been exploited in many application areas such as review mining, election analysis, and information extraction. While most previous research focusses on explicit opinion expressions, recent work addresses a type of opinion inference that arises when opinions are expressed toward events which have positive or negative effects on entities (Deng et al., 2013; Deng and Wiebe, 2014). We call such events +/-effect events.2 Deng and Wiebe (2014) show how sentiments toward one 1 WordNet 3.0, http://wordnet.princeton.edu/ While the term goodFor/badFor is used in previous papers (Deng et al., 2013; Deng and Wiebe, 2014; Deng et al., 2014), we have since decided that +/-effect is a better term. 2 The writer expresses an explicit negative sentiment (by skyrocketing) toward the object (health care costs). The event, curb, has a negative effect on costs, since they are reduced. We can reason that the writer is positive toward the event because it has a nega"
D14-1125,C14-1009,1,0.332055,"many application areas such as review mining, election analysis, and information extraction. While most previous research focusses on explicit opinion expressions, recent work addresses a type of opinion inference that arises when opinions are expressed toward events which have positive or negative effects on entities (Deng et al., 2013; Deng and Wiebe, 2014). We call such events +/-effect events.2 Deng and Wiebe (2014) show how sentiments toward one 1 WordNet 3.0, http://wordnet.princeton.edu/ While the term goodFor/badFor is used in previous papers (Deng et al., 2013; Deng and Wiebe, 2014; Deng et al., 2014), we have since decided that +/-effect is a better term. 2 The writer expresses an explicit negative sentiment (by skyrocketing) toward the object (health care costs). The event, curb, has a negative effect on costs, since they are reduced. We can reason that the writer is positive toward the event because it has a negative effect on costs, toward which the writer is negative. From there, we can reason that the writer is positive toward the bill, since it is the agent of the positive event. Deng and Wiebe (2014) show that such inferences may be exploited to significantly improve explicit senti"
D14-1125,N09-1001,0,0.10092,"jury (Anand and Reschke, 2010; Deng et al., 2013). The creation, gain, and benefit classes are +effect events. For example, baking a cake has a positive effect on the cake because it is created;3 increasing the tax rate has a positive effect on the tax rate; and comforting the child has a positive effect on the child. The antonymous classes of each are -effect events: destroying the building has a negative effect on the building; demand decreasing has a negative effect on demand; and killing Bill has a negative effect on Bill.4 While sentiment (Esuli and Sebastiani, 2006; Wilson et al., 2005; Su and Markert, 2009) and connotation lexicons (Feng et al., 2011; Kang et al., 2014) are related, sentiment, connotation, and +/-effects are not the same; a single event may have different sentiment and +/-effect polarities, for example. Consider the following example: perpetrate: S: (v) perpetrate, commit, pull (perform an act, usually with a negative connotation) “perpetrate a crime”; “pull a bank robbery” This sense of perpetuate has a negative connotation, and is an objective term in SentiWordNet. However, it has a positive effect on the object, a crime, since performing a crime brings it into existence. 3 De"
D14-1125,esuli-sebastiani-2006-sentiwordnet,0,0.596505,"s in states involving possession), and benefit/injury (Anand and Reschke, 2010; Deng et al., 2013). The creation, gain, and benefit classes are +effect events. For example, baking a cake has a positive effect on the cake because it is created;3 increasing the tax rate has a positive effect on the tax rate; and comforting the child has a positive effect on the child. The antonymous classes of each are -effect events: destroying the building has a negative effect on the building; demand decreasing has a negative effect on demand; and killing Bill has a negative effect on Bill.4 While sentiment (Esuli and Sebastiani, 2006; Wilson et al., 2005; Su and Markert, 2009) and connotation lexicons (Feng et al., 2011; Kang et al., 2014) are related, sentiment, connotation, and +/-effects are not the same; a single event may have different sentiment and +/-effect polarities, for example. Consider the following example: perpetrate: S: (v) perpetrate, commit, pull (perform an act, usually with a negative connotation) “perpetrate a crime”; “pull a bank robbery” This sense of perpetuate has a negative connotation, and is an objective term in SentiWordNet. However, it has a positive effect on the object, a crime, since perfo"
D14-1125,P07-1054,0,0.0106517,"ity, sentiment and connotation lexicons, some do take a sense-level approach. Esuli and Sebastiani (2006) construct SentiWordNet. They assume that terms with the same polarity tend to have similar glosses. So, they first expand a manually selected seed set of senses using WordNet lexical relations such as also-see and direct antonymy and train two classifiers, one for positive and another for negative. As features, a vectorial representation of glosses is adopted. These classifiers were applied to all WordNet senses to measure positive, negative, and objective scores. In extending their work (Esuli and Sebastiani, 2007), the PageRank algorithm is applied to rank senses in terms of how strongly they are positive or negative. In the graph, each sense is one node, and two nodes are connected when they contain the same words in their WordNet glosses. Moreover, a random-walk step is adopted to refine the scores in their recent work (Baccianella et al., 2010). In contrast, our approach uses WordNet relations and graph propagation in addition to gloss classification. Kang et al. (2014) present a unified model that assigns connotation polarities to both words and senses. They formulate the induction process as colle"
D14-1125,D11-1101,0,0.0159154,"). The creation, gain, and benefit classes are +effect events. For example, baking a cake has a positive effect on the cake because it is created;3 increasing the tax rate has a positive effect on the tax rate; and comforting the child has a positive effect on the child. The antonymous classes of each are -effect events: destroying the building has a negative effect on the building; demand decreasing has a negative effect on demand; and killing Bill has a negative effect on Bill.4 While sentiment (Esuli and Sebastiani, 2006; Wilson et al., 2005; Su and Markert, 2009) and connotation lexicons (Feng et al., 2011; Kang et al., 2014) are related, sentiment, connotation, and +/-effects are not the same; a single event may have different sentiment and +/-effect polarities, for example. Consider the following example: perpetrate: S: (v) perpetrate, commit, pull (perform an act, usually with a negative connotation) “perpetrate a crime”; “pull a bank robbery” This sense of perpetuate has a negative connotation, and is an objective term in SentiWordNet. However, it has a positive effect on the object, a crime, since performing a crime brings it into existence. 3 Deng et al. (2013) point out that +/-effect ob"
D14-1125,D10-1008,0,0.063747,". In contrast, our approach uses WordNet relations and graph propagation in addition to gloss classification. Kang et al. (2014) present a unified model that assigns connotation polarities to both words and senses. They formulate the induction process as collective inference over pairwise-Markov Random Fields, and apply loopy belief propagation for inference. Their approach relies on selectional preferences of connotative predicates; the polarity of a connotation predicate suggests the polarity of its arguments. We have not discovered an analogous type of predicate for the problem we address. Goyal et al. (2010) generate a lexicon of patient polarity verbs (PPVs) that impart positive or negative states on their patients. They harvest PPVs from a Web corpus by co-occurance with Kind and Evil agents and by bootstrapping over conjunctions of verbs. Riloff et al. (2013) learn positive sentiment phrases and negative situation phrases from a corpus of tweets with hashtag “sarcasm”. However, both of these methods are word-level rather than sense-level. Ours is the first NLP research into developing a sense-level lexicon for events that have negative or positive effects on entities. Gyamfi et al. (2009) cons"
D14-1125,N09-1002,1,0.962027,"ress. Goyal et al. (2010) generate a lexicon of patient polarity verbs (PPVs) that impart positive or negative states on their patients. They harvest PPVs from a Web corpus by co-occurance with Kind and Evil agents and by bootstrapping over conjunctions of verbs. Riloff et al. (2013) learn positive sentiment phrases and negative situation phrases from a corpus of tweets with hashtag “sarcasm”. However, both of these methods are word-level rather than sense-level. Ours is the first NLP research into developing a sense-level lexicon for events that have negative or positive effects on entities. Gyamfi et al. (2009) construct a classifier to label the subjectivity of word senses. The hierarchical structure and domain information in WordNet are exploited to define features in terms of similarity (using the LCS metric in Resnik (1995)) of target senses and a seed set of senses. Also, the similarity of glosses in WordNet is considered. Even though they investigated the hierarchical structure by LCS values, WordNet relations are not exploited directly. 4 Su and Markert (2009) adopt a semi-supervised mincut method to recognize the subjectivity of word senses. To construct a graph, each node corresponds to one"
D14-1125,H05-1044,1,0.137673,"Missing"
D14-1125,P97-1023,0,0.166409,"ied” +effect S: (v) purge (rid of impurities) “purge the water”; “purge your mind” +effect This is part of the WordNet output for the word purge. In the first sense, the polarity is -effect since it has a negative effect on the object, Deng Xizo Ping. However, the other cases have positive effect on the object. Moreover, although a word may not have both +effect and -effect senses, it may have mixtures of ((+effect or -effect) and Null). A purely word-based approach is blind to these cases. 3 Related Work Lexicons are widely used in sentiment analysis and opinion mining. Several works such as Hatzivassiloglou and McKeown (1997), Turney and Littman (2003), Kim and Hovy (2004), Strapparava and Valitutti (2004), and Peng and Park (2011) have tackled automatic lexicon expansion or acquistion. However, in most such work, the lexicons are word-level rather than sense-level. 1182 5 Called the goodFor/badFor corpus in that paper. For the related (but different) tasks of developing subjectivity, sentiment and connotation lexicons, some do take a sense-level approach. Esuli and Sebastiani (2006) construct SentiWordNet. They assume that terms with the same polarity tend to have similar glosses. So, they first expand a manually"
D14-1125,P14-1145,0,0.377257,"in, and benefit classes are +effect events. For example, baking a cake has a positive effect on the cake because it is created;3 increasing the tax rate has a positive effect on the tax rate; and comforting the child has a positive effect on the child. The antonymous classes of each are -effect events: destroying the building has a negative effect on the building; demand decreasing has a negative effect on demand; and killing Bill has a negative effect on Bill.4 While sentiment (Esuli and Sebastiani, 2006; Wilson et al., 2005; Su and Markert, 2009) and connotation lexicons (Feng et al., 2011; Kang et al., 2014) are related, sentiment, connotation, and +/-effects are not the same; a single event may have different sentiment and +/-effect polarities, for example. Consider the following example: perpetrate: S: (v) perpetrate, commit, pull (perform an act, usually with a negative connotation) “perpetrate a crime”; “pull a bank robbery” This sense of perpetuate has a negative connotation, and is an objective term in SentiWordNet. However, it has a positive effect on the object, a crime, since performing a crime brings it into existence. 3 Deng et al. (2013) point out that +/-effect objects are not equiva"
D14-1125,C04-1200,0,0.0650726,"“purge your mind” +effect This is part of the WordNet output for the word purge. In the first sense, the polarity is -effect since it has a negative effect on the object, Deng Xizo Ping. However, the other cases have positive effect on the object. Moreover, although a word may not have both +effect and -effect senses, it may have mixtures of ((+effect or -effect) and Null). A purely word-based approach is blind to these cases. 3 Related Work Lexicons are widely used in sentiment analysis and opinion mining. Several works such as Hatzivassiloglou and McKeown (1997), Turney and Littman (2003), Kim and Hovy (2004), Strapparava and Valitutti (2004), and Peng and Park (2011) have tackled automatic lexicon expansion or acquistion. However, in most such work, the lexicons are word-level rather than sense-level. 1182 5 Called the goodFor/badFor corpus in that paper. For the related (but different) tasks of developing subjectivity, sentiment and connotation lexicons, some do take a sense-level approach. Esuli and Sebastiani (2006) construct SentiWordNet. They assume that terms with the same polarity tend to have similar glosses. So, they first expand a manually selected seed set of senses using WordNet lexic"
D14-1125,D13-1066,0,0.0346395,"Missing"
D14-1125,strapparava-valitutti-2004-wordnet,0,0.0816086,"ffect This is part of the WordNet output for the word purge. In the first sense, the polarity is -effect since it has a negative effect on the object, Deng Xizo Ping. However, the other cases have positive effect on the object. Moreover, although a word may not have both +effect and -effect senses, it may have mixtures of ((+effect or -effect) and Null). A purely word-based approach is blind to these cases. 3 Related Work Lexicons are widely used in sentiment analysis and opinion mining. Several works such as Hatzivassiloglou and McKeown (1997), Turney and Littman (2003), Kim and Hovy (2004), Strapparava and Valitutti (2004), and Peng and Park (2011) have tackled automatic lexicon expansion or acquistion. However, in most such work, the lexicons are word-level rather than sense-level. 1182 5 Called the goodFor/badFor corpus in that paper. For the related (but different) tasks of developing subjectivity, sentiment and connotation lexicons, some do take a sense-level approach. Esuli and Sebastiani (2006) construct SentiWordNet. They assume that terms with the same polarity tend to have similar glosses. So, they first expand a manually selected seed set of senses using WordNet lexical relations such as also-see and"
D15-1018,P05-1045,0,0.0338954,"N EG PAIR(s,t): a negative pair from s toward t Probabilistic Soft Logic PSL (Bach et al., 2015) uses logical representations to compactly define large graphical models with continuous variables, and includes methods for performing efficient probabilistic inference for the resulting models (Beltagy et al., 2014). As 182 ground atom S OURCE(y,s) is created with score 1.0. Otherwise, if S3 extracts opinion y, a ground atom S OURCE(y,writer) is created with score 1.0 (since S3 assumes the source is always the writer). Otherwise, we run the Stanford named entity recognizer (Manning et al., 2014; Finkel et al., 2005) to extract named entities in the sentence. The nearest named entity to the opinion span on the dependency parse graph will be treated as the source. The score is the reciprocal of the length of the path between the opinion span and the source span in the dependency parse. E TARGET(y,t): Though each eTarget is an entity or event, it is difficult to determine which nouns and verbs should be considered. Taking into consideration the trade-off between precision and recall, we experimented with three methods to select eTarget candidates. For each opinion y, a ground atom E TARGET(y,t) is created f"
D15-1018,P14-1114,0,0.0476347,"also propose a set of sentiment inference rules and develop a rule-based system to infer sentiments (Wiebe and Deng, 2014). However, the rule-based system requires all information regarding explicit sentiments and +/-effect events to be provided as oracle information by manual annotations. Probabilistic Soft Logic. Probabilistic Soft Logic (PSL) is a variation of Markov Logic Networks, which is a framework for probabilistic logic that employs weighted formulas in firstorder logic to compactly encode complex undirected probabilistic graphical models (i.e., Markov networks) (Bach et al., 2015; Beltagy et al., 2014). PSL is a new statistical relational learning method that has been applied to many NLP and other machine learning tasks in recent years (Beltagy et al., 2014; London et al., 2013; Pujara et al., 2013; Bach et al., 2013; Huang et al., 2013; Memory et al., 2012). Previously, PSL has not been applied to entity/event-level sentiment analysis. 4 181 Available at http://mpqa.cs.pitt.edu/corpora/ mentioned above, a PSL model is defined using a set of atoms to be grounded, and a set of weighted if-then rules in first-order logic. For example, friend(x,y) ∧ votesFor(y,z) ⇒ votesFor(x,z) means that a p"
D15-1018,D14-1125,1,0.835959,"Missing"
D15-1018,J13-4004,0,0.0261485,"xtracted by systems S1, S2 and S3. We hypothesized that ET2 would be useful because most of the eTargets in MPQA 3.0 appear within the opinion or the target spans of MPQA 2.0. ET3 considers the heads of the target and opinion spans that are automatically extracted by systems S1, S2 and S3.5 ET3 also considers the heads of siblings of target spans and opinion spans. Among the three methods, ET3 has the lowest recall but the highest precision. In addition, for the eTarget candidate set extracted by ET2, or ET3, we run the Stanford coreference system (Manning et al., 2014; Recasens et al., 2013; Lee et al., 2013) to expand the set in two ways. First, for each eTarget candidate t, the co-reference system extracts the entities that co-refer with t. We add the referring entities into the candidate set. Second, the co-reference system extracts words which the Stanford system judges to be entities, regardless of whether they have any referent or not. We add this set of entities to the candidate set as well. We train an SVM classifier (Cortes and Vapnik, 1995) to assign a score to the ground atom E TARGET(y,t). Syntactic features describing the Both s and t are chosen from the set E. The values of ground at"
D15-1018,E14-1040,1,0.601508,"ive pairs. The goal of this work is to automatically recognize a set of positive pairs (Pauto ) and a set of negative pairs (Nauto ). We compare the system output (Pauto ∪ Nauto ) against the gold standard (Pgold ∪ Ngold ) for each sentence. Sentiment Inference. There is some recent work investigating features that directly indicate implicit sentiments (Zhang and Liu, 2011; Feng et al., 2013). That work assumes the source is only the writer. Further, as it uses features to directly extract implicit sentiments, it does not perform general sentiment inference. Previously, we (Deng et al., 2013; Deng and Wiebe, 2014; Deng et al., 2014) develop rules and models to infer sentiments related to +/-effect events, events that positively or negatively affect entities. That work assumes that the source is only the writer, and the targets are limited to entities that participate in +/-effect events. Further, our previous models all require certain manual (oracle) annotations to be input. In this work we use an expanded set of more general rules. We allow sources other than the writer, and targets that may be any entity or event. In fact, under our new rules, the targets of sentiments may be other sentiments; we m"
D15-1018,P14-5010,0,0.0525728,"ir from s toward t (2) N EG PAIR(s,t): a negative pair from s toward t Probabilistic Soft Logic PSL (Bach et al., 2015) uses logical representations to compactly define large graphical models with continuous variables, and includes methods for performing efficient probabilistic inference for the resulting models (Beltagy et al., 2014). As 182 ground atom S OURCE(y,s) is created with score 1.0. Otherwise, if S3 extracts opinion y, a ground atom S OURCE(y,writer) is created with score 1.0 (since S3 assumes the source is always the writer). Otherwise, we run the Stanford named entity recognizer (Manning et al., 2014; Finkel et al., 2005) to extract named entities in the sentence. The nearest named entity to the opinion span on the dependency parse graph will be treated as the source. The score is the reciprocal of the length of the path between the opinion span and the source span in the dependency parse. E TARGET(y,t): Though each eTarget is an entity or event, it is difficult to determine which nouns and verbs should be considered. Taking into consideration the trade-off between precision and recall, we experimented with three methods to select eTarget candidates. For each opinion y, a ground atom E TA"
D15-1018,N15-1146,1,0.902095,"he target (what is the sentiment toward). Much fine-grained analysis is span or aspect based (Yang and Cardie, 2014; Pontiki et al., 2014). In contrast, this work contributes to entity/event-level sentiment analysis. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Who is negative/positive toward X?” (Stoyanov et al., 2005), where X could be any entity or event. Let us consider an example from the MPQA opinion annotated corpus (Wiebe et al., 2005a; Wilson, 2007; Deng and Wiebe, 2015). 1 Sources in MPQA are nested, having the form hwriteri or hwriter, S1 , . . . , Sn i. This work only deals with the rightmost source, writer or Sn . Also, actions like issuing a fatwa are treated the same as private states. Please see (Wiebe et al., 2005a). 179 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 179–189, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. work, we propose a more general set of inference rules and encode them in a probabilistic soft logic (PSL) framework (Bach et al., 2015). We ch"
D15-1018,P13-2022,1,0.889345,"nding set for negative pairs. The goal of this work is to automatically recognize a set of positive pairs (Pauto ) and a set of negative pairs (Nauto ). We compare the system output (Pauto ∪ Nauto ) against the gold standard (Pgold ∪ Ngold ) for each sentence. Sentiment Inference. There is some recent work investigating features that directly indicate implicit sentiments (Zhang and Liu, 2011; Feng et al., 2013). That work assumes the source is only the writer. Further, as it uses features to directly extract implicit sentiments, it does not perform general sentiment inference. Previously, we (Deng et al., 2013; Deng and Wiebe, 2014; Deng et al., 2014) develop rules and models to infer sentiments related to +/-effect events, events that positively or negatively affect entities. That work assumes that the source is only the writer, and the targets are limited to entities that participate in +/-effect events. Further, our previous models all require certain manual (oracle) annotations to be input. In this work we use an expanded set of more general rules. We allow sources other than the writer, and targets that may be any entity or event. In fact, under our new rules, the targets of sentiments may be"
D15-1018,S14-2004,0,0.0326208,"t, because Rushdie insults the Prophet and Imam is angry that he does Introduction There are increasing numbers of opinions expressed in various genres, including reviews, newswire, editorials, and forums. While much early work was at the document or sentence level, to fully understand and utilize opinions, researchers are increasingly carrying out more finegrained sentiment analysis to extract components of opinion frames: the source (whose sentiment is it), the polarity, and the target (what is the sentiment toward). Much fine-grained analysis is span or aspect based (Yang and Cardie, 2014; Pontiki et al., 2014). In contrast, this work contributes to entity/event-level sentiment analysis. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Who is negative/positive toward X?” (Stoyanov et al., 2005), where X could be any entity or event. Let us consider an example from the MPQA opinion annotated corpus (Wiebe et al., 2005a; Wilson, 2007; Deng and Wiebe, 2015). 1 Sources in MPQA are nested, having the form hwriteri or hwriter, S1 , . . . , Sn i. This work only deals with the"
D15-1018,C14-1009,1,0.720399,"n P and N , where the sources are entities (or the writer) and the targets are entities and events. Previous work in sentiment analysis mainly focuses on detecting explicit opinions. Recently there is emerging focus on sentiment inference, which recognizes implicit sentiments by inferring them from explicit sentiments via inference rules. Current works in sentiment inference differ on how the sentiment inference rules are defined and how they are expressed. For example, Zhang and Liu (2011) define linguistic templates to recognize phrases that express implicit sentiments, while previously we (Deng et al., 2014) represent a few simple rules as (in)equality constraints in Integer Linear Programming. In contrast to previous 2 Related Work Fined-grained sentiment analysis. Most finegrained sentiment analysis is span or aspect based. Previous work differs from the entity/event-level sentiment analysis task we address in terms of targets and sources. In terms of targets, in a spanbased sentiment analysis system, the target is a span instead of the exact head of the phrase referring to the target. The target in a span-based system is evaluated by measuring the overlapping proportion of an extracted span ag"
D15-1018,P13-1174,0,0.0151273,"ositive pair of two entities, (e1 , e2 ) where e1 , e2 ∈ E, and e1 is positive toward e2 . A positive pair (e1 ,e2 ) aggregates all the positive sentiments from e1 to e2 in the sentence. N is the corresponding set for negative pairs. The goal of this work is to automatically recognize a set of positive pairs (Pauto ) and a set of negative pairs (Nauto ). We compare the system output (Pauto ∪ Nauto ) against the gold standard (Pgold ∪ Ngold ) for each sentence. Sentiment Inference. There is some recent work investigating features that directly indicate implicit sentiments (Zhang and Liu, 2011; Feng et al., 2013). That work assumes the source is only the writer. Further, as it uses features to directly extract implicit sentiments, it does not perform general sentiment inference. Previously, we (Deng et al., 2013; Deng and Wiebe, 2014; Deng et al., 2014) develop rules and models to infer sentiments related to +/-effect events, events that positively or negatively affect entities. That work assumes that the source is only the writer, and the targets are limited to entities that participate in +/-effect events. Further, our previous models all require certain manual (oracle) annotations to be input. In t"
D15-1018,N13-1071,0,0.0449836,"Missing"
D15-1018,D13-1170,0,0.00377254,"entities and events (P OS PAIR(s,t) and N EG PAIR(s,t)) in the sentence. Next, we turn to assigning local scores to ground atoms (3)-(6). P OS(y) and N EG(y): We build upon three spanbased sentiment analysis systems. The first, S1 (Yang and Cardie, 2013), and the second, S2 (Yang and Cardie, 2014), are both trained on MPQA 2.0, which does not contain any eTarget annotations. S1 extracts triples of hsource span, opinion span, target spani, but does not extract opinion polarities. S2 extracts opinion spans and opinion polarities, but it does not extract sources or targets. The third system, S3 (Socher et al., 2013), is trained on movie review data. It extracts opinion spans and polarities. The source is always assumed to be the writer. We take the union set of opinions extracted by S1, S2 and S3. For each opinion y, a ground atom is created, depending on the polarity (P OS(y) if y is positive and N EG(y) is y is negative). The polarity is determined as follows. If S2 assigns a polarity to y, then that polarity is used. If S3 but not S2 assigns a polarity to y, then S3’s polarity is used. In both cases, the score assigned to the ground atom is 1.0. If neither S2 nor S3 assigns a polarity to y, we use the"
D15-1018,H05-1116,1,0.72829,"s are increasingly carrying out more finegrained sentiment analysis to extract components of opinion frames: the source (whose sentiment is it), the polarity, and the target (what is the sentiment toward). Much fine-grained analysis is span or aspect based (Yang and Cardie, 2014; Pontiki et al., 2014). In contrast, this work contributes to entity/event-level sentiment analysis. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Who is negative/positive toward X?” (Stoyanov et al., 2005), where X could be any entity or event. Let us consider an example from the MPQA opinion annotated corpus (Wiebe et al., 2005a; Wilson, 2007; Deng and Wiebe, 2015). 1 Sources in MPQA are nested, having the form hwriteri or hwriter, S1 , . . . , Sn i. This work only deals with the rightmost source, writer or Sn . Also, actions like issuing a fatwa are treated the same as private states. Please see (Wiebe et al., 2005a). 179 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 179–189, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computa"
D15-1018,P08-1036,0,0.0606178,"acted span against the gold standard phrase (Yang and Cardie, 2013), while the eTarget in an entity/event-level system is evaluated against the exact word (i.e., head of NP/VP) in the gold standard. It is a stricter evaluation. While the targets in aspect-based sentiment analysis are often entity targets, they are mainly product aspects, which are a predefined set.3 In contrast, the target in the entity/event-level task may be any noun or verb. In terms of sources, previous work in sentiment analysis trained on review data assumes that the source is the writer of the review (Hu and Liu, 2004; Titov and McDonald, 2008). 2 Note that the inferences are conversational implicatures; they are defeasible and may not go through in context (Deng et al., 2014; Wiebe and Deng, 2014). 3 As stated in SemEval-2014: “we annotate only aspect terms naming particular aspects”. 180 3 Our work is rare in that it allows sources other than the writer and finds sentiments toward eTargets which may be any entity or event. Task Definition In this section, we introduce the definition of the entity/event-level sentiment analysis task, followed by a description of the gold standard corpus. For each sentence s, we define a set E consi"
D15-1018,P13-1161,0,0.572976,"(in)equality constraints in Integer Linear Programming. In contrast to previous 2 Related Work Fined-grained sentiment analysis. Most finegrained sentiment analysis is span or aspect based. Previous work differs from the entity/event-level sentiment analysis task we address in terms of targets and sources. In terms of targets, in a spanbased sentiment analysis system, the target is a span instead of the exact head of the phrase referring to the target. The target in a span-based system is evaluated by measuring the overlapping proportion of an extracted span against the gold standard phrase (Yang and Cardie, 2013), while the eTarget in an entity/event-level system is evaluated against the exact word (i.e., head of NP/VP) in the gold standard. It is a stricter evaluation. While the targets in aspect-based sentiment analysis are often entity targets, they are mainly product aspects, which are a predefined set.3 In contrast, the target in the entity/event-level task may be any noun or verb. In terms of sources, previous work in sentiment analysis trained on review data assumes that the source is the writer of the review (Hu and Liu, 2004; Titov and McDonald, 2008). 2 Note that the inferences are conversat"
D15-1018,P14-1031,0,0.169208,"itive toward the Prophet, because Rushdie insults the Prophet and Imam is angry that he does Introduction There are increasing numbers of opinions expressed in various genres, including reviews, newswire, editorials, and forums. While much early work was at the document or sentence level, to fully understand and utilize opinions, researchers are increasingly carrying out more finegrained sentiment analysis to extract components of opinion frames: the source (whose sentiment is it), the polarity, and the target (what is the sentiment toward). Much fine-grained analysis is span or aspect based (Yang and Cardie, 2014; Pontiki et al., 2014). In contrast, this work contributes to entity/event-level sentiment analysis. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Who is negative/positive toward X?” (Stoyanov et al., 2005), where X could be any entity or event. Let us consider an example from the MPQA opinion annotated corpus (Wiebe et al., 2005a; Wilson, 2007; Deng and Wiebe, 2015). 1 Sources in MPQA are nested, having the form hwriteri or hwriter, S1 , . . . , Sn i. This w"
D15-1018,P11-2101,0,0.437281,"ines are explicit sentiments and the dashed lines are implicit sentiments. In this work, we detect sentiments such as those in P and N , where the sources are entities (or the writer) and the targets are entities and events. Previous work in sentiment analysis mainly focuses on detecting explicit opinions. Recently there is emerging focus on sentiment inference, which recognizes implicit sentiments by inferring them from explicit sentiments via inference rules. Current works in sentiment inference differ on how the sentiment inference rules are defined and how they are expressed. For example, Zhang and Liu (2011) define linguistic templates to recognize phrases that express implicit sentiments, while previously we (Deng et al., 2014) represent a few simple rules as (in)equality constraints in Integer Linear Programming. In contrast to previous 2 Related Work Fined-grained sentiment analysis. Most finegrained sentiment analysis is span or aspect based. Previous work differs from the entity/event-level sentiment analysis task we address in terms of targets and sources. In terms of targets, in a spanbased sentiment analysis system, the target is a span instead of the exact head of the phrase referring to"
E14-1029,E09-1004,0,0.0182455,"iting scalability. As a countermeasure, in (Akkaya et al., 2011), we showed that non-expert annotations collected through Amazon Mechanical Turk (MTurk) can replace expert annotations successfully and might be used to apply SWSD on a large scale. Although non-expert annotations are cheap and fast, they still incur some cost. In this work, we aim to reduce the human annotation effort needed Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) A new treatment based on training T-cells to attack cancerous cells ... He was attacked by Milosevic for attempting to carve out a new"
E14-1029,D09-1020,1,0.906521,"notations successfully and might be used to apply SWSD on a large scale. Although non-expert annotations are cheap and fast, they still incur some cost. In this work, we aim to reduce the human annotation effort needed Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) A new treatment based on training T-cells to attack cancerous cells ... He was attacked by Milosevic for attempting to carve out a new party from the Socialists. 269 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 269–278, c Gothenburg, Swe"
E14-1029,J04-3001,0,0.0516427,"Missing"
E14-1029,W11-0311,1,0.87743,"d sentiment analysis resulting in substantial improvement for both subjectivity and sentiment analysis by avoiding false hits. Although SWSD is a promising tool, it suffers from the knowledge acquisition bottleneck. SWSD is defined as a supervised task, and follows a targeted approach common in the WSD literature for performance reasons. This means, for each target clue, a different classifier is trained requiring separate training data for each target clue. It is expensive and time-consuming to obtain annotated datasets to train SWSD classifiers limiting scalability. As a countermeasure, in (Akkaya et al., 2011), we showed that non-expert annotations collected through Amazon Mechanical Turk (MTurk) can replace expert annotations successfully and might be used to apply SWSD on a large scale. Although non-expert annotations are cheap and fast, they still incur some cost. In this work, we aim to reduce the human annotation effort needed Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentim"
E14-1029,W02-0811,0,0.130092,"an be different usages, both having a subjective meaning. On the other hand, if two instances are labeled having opposing labels, we do not want them to be in the same cluster. Thus, we utilize cannot-links but not must-links. Constraints can be obtained from domain knowledge or from available instance labels. In our work, constraints are generated from instance labels. Each instance pair with opposing labels is considered to be cannot-linked. There are two general strategies to incorporate constraints into clustering. The first is to adapt the similarity between instances (Xing et al., 2002; Klein et al., 2002) by adjusting the underlying distance metric. The main idea is to make the distance between must-linked instances – their neighbourhoods – smaller and the distance between cannot-linked instances – their neighbourhoods – larger. The second strategy is modifying the clustering algorithm itself so that search is biased towards a partitioning for which the constraints hold (Wagstaff and Cardie, 2000; Basu et al., 2002; Demiriz et al., 1999). Our proposed constrained clustering method relies on some ideas from (Klein et al., 2002). Thus, we explain it in more detail. (Klein et al., 2002) utilizes"
E14-1029,C04-1200,0,0.0249805,"ime-consuming to obtain annotated datasets to train SWSD classifiers limiting scalability. As a countermeasure, in (Akkaya et al., 2011), we showed that non-expert annotations collected through Amazon Mechanical Turk (MTurk) can replace expert annotations successfully and might be used to apply SWSD on a large scale. Although non-expert annotations are cheap and fast, they still incur some cost. In this work, we aim to reduce the human annotation effort needed Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) A new treatment based on training T-cells to attack cancero"
E14-1029,P08-1034,0,0.0284671,"ts to train SWSD classifiers limiting scalability. As a countermeasure, in (Akkaya et al., 2011), we showed that non-expert annotations collected through Amazon Mechanical Turk (MTurk) can replace expert annotations successfully and might be used to apply SWSD on a large scale. Although non-expert annotations are cheap and fast, they still incur some cost. In this work, we aim to reduce the human annotation effort needed Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) A new treatment based on training T-cells to attack cancerous cells ... He was attacked by Milosevic for attemp"
E14-1029,C02-1039,1,0.645235,"equent lemmas). We do not filter out stop words, since they have been shown to be useful for various semantic similarity tasks in (Bullinaria and Levy, 2007). We use positive point-wise mutual information to compute values of the vector components, which has also been shown to be favourable in (Bullinaria and Levy, 2007). Purandere and Pedersen is the prominent representative of feature-based models. (Purandare and Pedersen, 2004) creates context vectors from local feature representations similar to the feature vectors found in supervised WSD. In this work, we use the following features from (Mihalcea, 2002) to build the local feature representation: (1) the target word itself and its part of speech, (2) surrounding context of 3 words and their part of speech, (3) the head of the noun phrase, (4) the first noun and verb before the target word, (5) the first noun and verb after the target word. average appear-v fine-a interest-n restraint-n skew local dsm add dsm mul mix rep 79.90 80.50 80.50 83.53 85.23 53.83 54.85 54.85 57.40 69.39 70.07 72.26 70.07 74.45 75.18 54.41 54.78 55.88 81.62 81.62 70.45 71.97 75.00 71.21 81.82 Table 1: Evaluation of Various Context Representations 3.1 Evaluation of Con"
E14-1029,W04-2406,0,0.256427,"respond to word lemmas present in the corpus. We adopt the parameters for our semantic space from (Mitchell and Lapata, 2010): window size of 10 and dimension size of 2000 (i.e., the 2000 most frequent lemmas). We do not filter out stop words, since they have been shown to be useful for various semantic similarity tasks in (Bullinaria and Levy, 2007). We use positive point-wise mutual information to compute values of the vector components, which has also been shown to be favourable in (Bullinaria and Levy, 2007). Purandere and Pedersen is the prominent representative of feature-based models. (Purandare and Pedersen, 2004) creates context vectors from local feature representations similar to the feature vectors found in supervised WSD. In this work, we use the following features from (Mihalcea, 2002) to build the local feature representation: (1) the target word itself and its part of speech, (2) surrounding context of 3 words and their part of speech, (3) the head of the noun phrase, (4) the first noun and verb before the target word, (5) the first noun and verb after the target word. average appear-v fine-a interest-n restraint-n skew local dsm add dsm mul mix rep 79.90 80.50 80.50 83.53 85.23 53.83 54.85 54."
E14-1029,N07-1039,0,0.0158411,"ain annotated datasets to train SWSD classifiers limiting scalability. As a countermeasure, in (Akkaya et al., 2011), we showed that non-expert annotations collected through Amazon Mechanical Turk (MTurk) can replace expert annotations successfully and might be used to apply SWSD on a large scale. Although non-expert annotations are cheap and fast, they still incur some cost. In this work, we aim to reduce the human annotation effort needed Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) A new treatment based on training T-cells to attack cancerous cells ... He was"
E14-1029,W03-1014,1,0.601385,"aining data for each target clue. It is expensive and time-consuming to obtain annotated datasets to train SWSD classifiers limiting scalability. As a countermeasure, in (Akkaya et al., 2011), we showed that non-expert annotations collected through Amazon Mechanical Turk (MTurk) can replace expert annotations successfully and might be used to apply SWSD on a large scale. Although non-expert annotations are cheap and fast, they still incur some cost. In this work, we aim to reduce the human annotation effort needed Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) A new tr"
E14-1029,J98-1004,0,0.77205,"ubjectivity sense tagged data). We train a different SWSD classifier for each target word as in (Akkaya et al., 2009). Thus, we need a different training dataset for each target word. Our ultimate 3 Context Representations There has been much work on context representations of words for various NLP tasks. Clustering word instances in order to discriminate senses of a word is called Word Sense Discrimination. Context representations for this task rely on two main types of models: distributional semantic models (DSM) and feature-based models. 1 Available corpora 270 at http://mpqa.cs.pitt.edu/ (Schutze, 1998), which is still a competitive model for word-sense discrimination by context clustering, relies on a distributional semantic model (DSM) (Turney and Pantel, 2010; Sahlgren, 2006; Bullinaria and Levy, 2007). A DSM is usually a word-to-word co-occurrence matrix – also called semantic space – such that each row represents the distribution of a target word in a large text corpus. Each row gives the semantic signature of a word, which is basically a high dimensional numeric vector. Note that this high dimensional vector represents word types, not word tokens. Thus, it cannot model a word instance"
E14-1029,D08-1112,0,0.0349391,"Missing"
E14-1029,P02-1053,0,0.0112679,"fier is trained requiring separate training data for each target clue. It is expensive and time-consuming to obtain annotated datasets to train SWSD classifiers limiting scalability. As a countermeasure, in (Akkaya et al., 2011), we showed that non-expert annotations collected through Amazon Mechanical Turk (MTurk) can replace expert annotations successfully and might be used to apply SWSD on a large scale. Although non-expert annotations are cheap and fast, they still incur some cost. In this work, we aim to reduce the human annotation effort needed Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sent"
E14-1029,W03-1017,0,0.0555593,"get clue. It is expensive and time-consuming to obtain annotated datasets to train SWSD classifiers limiting scalability. As a countermeasure, in (Akkaya et al., 2011), we showed that non-expert annotations collected through Amazon Mechanical Turk (MTurk) can replace expert annotations successfully and might be used to apply SWSD on a large scale. Although non-expert annotations are cheap and fast, they still incur some cost. In this work, we aim to reduce the human annotation effort needed Introduction Subjectivity lexicons (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)) play an important role in opinion, sentiment, and subjectivity analysis. These systems typically look for the presence of clues in text. Recently, in (Akkaya et al., 2009), we showed that subjectivity clues are fairly ambiguous as to whether they express subjectivity or not – words in such lexicons may have both subjective and objective usages. We call this problem subjectivity sense ambiguity. Consider the following sentence containing the clue “attack”: (1) A new treatment based on training T-cel"
E14-1029,W12-3702,1,\N,Missing
E14-1029,S01-1021,0,\N,Missing
E14-1040,W11-0145,0,0.789596,"Missing"
E14-1040,D08-1083,0,0.631387,"e idea of lowering them, then, presumably, she is negative toward the costs themselves (specifically, how high they are). The only explicit sentiment expression, tremendous positive change, is positive, yet we can infer a negative attitude toward the object of the event itself (i.e., health care costs). 377 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 377–385, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics not entirely new. For example, two papers mentioned above (Zhang and Liu, 2011; Choi and Cardie, 2008) include linguistic patterns for the tasks that they address that include gfbf events, but they don’t define general implicature rules relating sentiments and gfbf events, agents, and objects as we do. Recently, in linguistics, Anand and Reschke (2010; 2011) identify classes of gfbf terms, and carry out studies involving artificially constructed gfbf triples and corpus examples matching fixed linguistic templates. Our work focuses on gfbf triples in naturally-occurring data and uses generalized implicature rules. Goyal et al. (2012) generate a lexicon of patient polarity verbs, which correspon"
E14-1040,D13-1066,0,0.149959,"Missing"
E14-1040,P12-2013,0,0.0452067,"y-automatic systems evaluated on the MPQA corpus (Wiebe et al., 2005), for example, a recent paper (Johansson and Moschitti, 2013) reports results that improve over previous work, yet the Fmeasures are in the 40s and 50s. Most work in NLP addresses explicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Several papers apply compositional semantics to determine polarity (e.g., (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Moilanen et al., 2010); see (Liu, 2012) for an overview). The goal of such work is to determine one overall polarity of an expression or sentence. In contrast, our framework commits to a holder having sentiments toward various events and entities in the sentence, possibly of different polarities. The idea of gfbf events in sentiment analysis is 3 Opinion Implicatures"
E14-1040,P13-2022,1,0.610604,"ork is to determine one overall polarity of an expression or sentence. In contrast, our framework commits to a holder having sentiments toward various events and entities in the sentence, possibly of different polarities. The idea of gfbf events in sentiment analysis is 3 Opinion Implicatures This section describes the opinion-implicature framework motivating the design of the graphbased method for sentiment analysis proposed below. The components of the framework are gfbf events, explicit sentiments, and rules operating over gfbf events and sentiments. The definition of a gfbf event is from (Deng et al., 2013). A GOOD F OR event is an event that positively affects an entity (similarly, for BAD F OR events). (Deng et al., 2013) point out that gfbf objects are not equivalent to benefactive/malefactive semantic roles. An example they give is She baked a cake for me: a cake is the object of GOOD F OR event baked (creating something is good for it (Anand and Reschke, 2010)), while me is the filler of its benefactive semantic role (Z´un˜ iga and Kittil¨a, 2010). Four implicature rule schemas are relevant for this paper.1 Four individual rules are covered by 1 Implicatures “normally accompany the utteranc"
E14-1040,P13-1174,0,0.480277,"sed toward different entities in a document, fine-grained analysis may be more informative for applications. However, fine-grained sentiment analysis remains a challenging task for NLP systems. For fully-automatic systems evaluated on the MPQA corpus (Wiebe et al., 2005), for example, a recent paper (Johansson and Moschitti, 2013) reports results that improve over previous work, yet the Fmeasures are in the 40s and 50s. Most work in NLP addresses explicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Several papers apply compositional semantics to determine polarity (e.g., (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Moilanen et al., 2010); see (Liu, 2012) for an overview). The goal of such work is to determine one overall polarity of an expression or sentence. In contrast, our fr"
E14-1040,H05-1044,1,0.0710056,"by the writer toward that entity in the document. Since y ranges over (pos, neg), each node has a positive and a negative score; the scores sum to 1. If it is a positive node, then its positive value ranges from 0.5 to 1, and its negative value ranges from 0 to 0.5 (similarly for negative nodes). For any node without explicit sentiment, both the positive and negative values are 0.5, indicating a neutral node. Thus, we build a sentiment classifier that takes a node as input and outputs a positive and a negative score. It is built from widely-used, freely available resources: the OpinionFinder (Wilson et al., 2005) and General Inquirer (Stone et al., 1966) lexicons and the OpinionFinder system.5 We also use a new Opinion Extraction system (Johansson and Moschitti, 2013) that shows better performance than previous work on fine-grained sentiment analysis,6 and a new automatically developed connotation lexicon (Feng et al., 2013).7 We implement a weighted voting method among these various sentiment resources. After that, for nodes that have not yet been assigned polar values (positive or negative), we implement a simple local discourse heuristic to try to assign them polar values. The particular strategies"
E14-1040,J13-3002,0,0.400565,"we use manually annotated gfbf information to build the graph. Thus, the evaluations in this paper are able to demonstrate the promise of the overall framework itself. 2 Related Work Much work in sentiment analysis has been on document-level classification. Since different sentiments may be expressed toward different entities in a document, fine-grained analysis may be more informative for applications. However, fine-grained sentiment analysis remains a challenging task for NLP systems. For fully-automatic systems evaluated on the MPQA corpus (Wiebe et al., 2005), for example, a recent paper (Johansson and Moschitti, 2013) reports results that improve over previous work, yet the Fmeasures are in the 40s and 50s. Most work in NLP addresses explicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Sever"
E14-1040,P11-2101,0,0.555149,"is positive toward the idea of lowering them, then, presumably, she is negative toward the costs themselves (specifically, how high they are). The only explicit sentiment expression, tremendous positive change, is positive, yet we can infer a negative attitude toward the object of the event itself (i.e., health care costs). 377 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 377–385, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics not entirely new. For example, two papers mentioned above (Zhang and Liu, 2011; Choi and Cardie, 2008) include linguistic patterns for the tasks that they address that include gfbf events, but they don’t define general implicature rules relating sentiments and gfbf events, agents, and objects as we do. Recently, in linguistics, Anand and Reschke (2010; 2011) identify classes of gfbf terms, and carry out studies involving artificially constructed gfbf triples and corpus examples matching fixed linguistic templates. Our work focuses on gfbf triples in naturally-occurring data and uses generalized implicature rules. Goyal et al. (2012) generate a lexicon of patient polarit"
H05-1044,P97-1023,0,0.20439,"iments show that the combination of features is needed to achieve significant results over baseline for polarity classification. 353 7 Related Work Much work on sentiment analysis classifies documents by their overall sentiment, for example determining whether a review is positive or negative (e.g., (Turney, 2002; Dave et al., 2003; Pang and Lee, 2004; Beineke et al., 2004)). In contrast, our experiments classify individual words and phrases. A number of researchers have explored learning words and phrases with prior positive or negative polarity (another term is semantic orientation) (e.g., (Hatzivassiloglou and McKeown, 1997; Kamps and Marx, 2002; Turney, 2002)). In contrast, we begin with a lexicon of words with established prior polarities, and identify the contextual polarity of phrases in which instances of those words appear in the corpus. To make the relationship between that task and ours clearer, note that some word lists used to evaluate methods for recognizing prior polarity are included in our prior-polarity lexicon (General Inquirer lists (General-Inquirer, 2000) used for evaluation by Turney, and lists of manually identified positive and negative adjectives, used for evaluation by Hatzivassiloglou an"
H05-1044,C04-1200,0,0.216699,"shed prior polarities, and identify the contextual polarity of phrases in which instances of those words appear in the corpus. To make the relationship between that task and ours clearer, note that some word lists used to evaluate methods for recognizing prior polarity are included in our prior-polarity lexicon (General Inquirer lists (General-Inquirer, 2000) used for evaluation by Turney, and lists of manually identified positive and negative adjectives, used for evaluation by Hatzivassiloglou and McKeown). Some research classifies the sentiments of sentences. Yu and Hatzivassiloglou (2003), Kim and Hovy (2004), Hu and Liu (2004), and Grefenstette et al. (2001)4 all begin by first creating prior-polarity lexicons. Yu and Hatzivassiloglou then assign a sentiment to a sentence by averaging the prior semantic orientations of instances of lexicon words in the sentence. Thus, they do not identify the contextual polarity of individual phrases containing clues, as we 4 In (Grefenstette et al., 2001), the units that are classified are fixed windows around named entities rather than sentences. do in this paper. Kim and Hovy, Hu and Liu, and Grefenstette et al. multiply or count the prior polarities of clue i"
H05-1044,P04-1035,0,0.14181,"y classifier is retrained and evaluated. Table 7 lists the features that are removed for each experiment. The only significant difference in performance in these experiments is neutral F-measure when the modification features (AB2) are removed. These ablation experiments show that the combination of features is needed to achieve significant results over baseline for polarity classification. 353 7 Related Work Much work on sentiment analysis classifies documents by their overall sentiment, for example determining whether a review is positive or negative (e.g., (Turney, 2002; Dave et al., 2003; Pang and Lee, 2004; Beineke et al., 2004)). In contrast, our experiments classify individual words and phrases. A number of researchers have explored learning words and phrases with prior positive or negative polarity (another term is semantic orientation) (e.g., (Hatzivassiloglou and McKeown, 1997; Kamps and Marx, 2002; Turney, 2002)). In contrast, we begin with a lexicon of words with established prior polarities, and identify the contextual polarity of phrases in which instances of those words appear in the corpus. To make the relationship between that task and ours clearer, note that some word lists used to"
H05-1044,W03-1014,1,0.254211,"Missing"
H05-1044,P02-1053,0,0.187322,"ures is excluded, and the polarity classifier is retrained and evaluated. Table 7 lists the features that are removed for each experiment. The only significant difference in performance in these experiments is neutral F-measure when the modification features (AB2) are removed. These ablation experiments show that the combination of features is needed to achieve significant results over baseline for polarity classification. 353 7 Related Work Much work on sentiment analysis classifies documents by their overall sentiment, for example determining whether a review is positive or negative (e.g., (Turney, 2002; Dave et al., 2003; Pang and Lee, 2004; Beineke et al., 2004)). In contrast, our experiments classify individual words and phrases. A number of researchers have explored learning words and phrases with prior positive or negative polarity (another term is semantic orientation) (e.g., (Hatzivassiloglou and McKeown, 1997; Kamps and Marx, 2002; Turney, 2002)). In contrast, we begin with a lexicon of words with established prior polarities, and identify the contextual polarity of phrases in which instances of those words appear in the corpus. To make the relationship between that task and ours cle"
H05-1044,H01-1014,0,0.102463,"rd immediately before or after: if the word is a noun preceded by an adjective, if the preceding word is an adverb other than not, if the preceding word is an intensifier, and if the word itself is an intensifier. A word is considered an intensifier if it appears in a list of intensifiers and if it precedes a word of the appropriate part-of-speech (e.g., an intensifier adjective must come before a noun). The modify features involve the dependency parse tree for the sentence, obtained by first parsing the sentence (Collins, 1997) and then converting the tree into its dependency representation (Xia and Palmer, 2001). In a dependency representation, every node in the tree structure is a surface word (i.e., there are no abstract nodes such as NP or VP). The edge between a parent and a child specifies the grammatical relationship between the two words. Figure 1 shows Word Features word token word part-of-speech word context prior polarity: positive, negative, both, neutral reliability class: strongsubj or weaksubj Modification Features preceeded by adjective: binary preceeded by adverb (other than not): binary preceeded by intensifier: binary is intensifier: binary modifies strongsubj: binary modifies weaks"
H05-1044,P04-1034,0,0.0908993,"ained and evaluated. Table 7 lists the features that are removed for each experiment. The only significant difference in performance in these experiments is neutral F-measure when the modification features (AB2) are removed. These ablation experiments show that the combination of features is needed to achieve significant results over baseline for polarity classification. 353 7 Related Work Much work on sentiment analysis classifies documents by their overall sentiment, for example determining whether a review is positive or negative (e.g., (Turney, 2002; Dave et al., 2003; Pang and Lee, 2004; Beineke et al., 2004)). In contrast, our experiments classify individual words and phrases. A number of researchers have explored learning words and phrases with prior positive or negative polarity (another term is semantic orientation) (e.g., (Hatzivassiloglou and McKeown, 1997; Kamps and Marx, 2002; Turney, 2002)). In contrast, we begin with a lexicon of words with established prior polarities, and identify the contextual polarity of phrases in which instances of those words appear in the corpus. To make the relationship between that task and ours clearer, note that some word lists used to evaluate methods for r"
H05-1044,P97-1003,0,0.134778,"e binary relationship features. The first four involve relationships with the word immediately before or after: if the word is a noun preceded by an adjective, if the preceding word is an adverb other than not, if the preceding word is an intensifier, and if the word itself is an intensifier. A word is considered an intensifier if it appears in a list of intensifiers and if it precedes a word of the appropriate part-of-speech (e.g., an intensifier adjective must come before a noun). The modify features involve the dependency parse tree for the sentence, obtained by first parsing the sentence (Collins, 1997) and then converting the tree into its dependency representation (Xia and Palmer, 2001). In a dependency representation, every node in the tree structure is a surface word (i.e., there are no abstract nodes such as NP or VP). The edge between a parent and a child specifies the grammatical relationship between the two words. Figure 1 shows Word Features word token word part-of-speech word context prior polarity: positive, negative, both, neutral reliability class: strongsubj or weaksubj Modification Features preceeded by adjective: binary preceeded by adverb (other than not): binary preceeded b"
H05-1044,W03-1017,0,0.198608,"a lexicon of words with established prior polarities, and identify the contextual polarity of phrases in which instances of those words appear in the corpus. To make the relationship between that task and ours clearer, note that some word lists used to evaluate methods for recognizing prior polarity are included in our prior-polarity lexicon (General Inquirer lists (General-Inquirer, 2000) used for evaluation by Turney, and lists of manually identified positive and negative adjectives, used for evaluation by Hatzivassiloglou and McKeown). Some research classifies the sentiments of sentences. Yu and Hatzivassiloglou (2003), Kim and Hovy (2004), Hu and Liu (2004), and Grefenstette et al. (2001)4 all begin by first creating prior-polarity lexicons. Yu and Hatzivassiloglou then assign a sentiment to a sentence by averaging the prior semantic orientations of instances of lexicon words in the sentence. Thus, they do not identify the contextual polarity of individual phrases containing clues, as we 4 In (Grefenstette et al., 2001), the units that are classified are fixed windows around named entities rather than sentences. do in this paper. Kim and Hovy, Hu and Liu, and Grefenstette et al. multiply or count the prior"
H05-1116,P04-1035,0,0.241773,"ion 5 briefly describes an opinion annotation scheme used in the experiments. Sections 6 and 7 explore the use of opinion information in the design of MPQA systems. 2 Related Work There is a growing interest in methods for the automatic identification and extraction of opinions, emotions, and sentiments in text. Much of the relevant research explores sentiment classification, a text categorization task in which the goal is to assign to a document either positive (“thumbs up”) or negative (“thumbs down”) polarity (e.g. Das and Chen (2001), Pang et al. (2002), Turney (2002), Dave et al. (2003), Pang and Lee (2004)). Other research has concentrated on analyzing opinions at, or below, the sentence level. Recent work, for example, indicates that systems can be trained to recognize opinions, their polarity, their source, and their strength to a reasonable degree of accuracy (e.g. Dave et al. (2003), Riloff and Wiebe (2003), Bethard et al. (2004), Pang and Lee (2004), Wilson et al. (2004), Yu and Hatzivassiloglou (2003), Wiebe and Riloff (2005)). Related work in the area of corpus development includes Wiebe et al.’s (2005) opinion annotation scheme to identify subjective expressions — expressions used to ex"
H05-1116,W02-1011,0,0.028931,"ic issues for handling opinion vs. fact questions. Section 5 briefly describes an opinion annotation scheme used in the experiments. Sections 6 and 7 explore the use of opinion information in the design of MPQA systems. 2 Related Work There is a growing interest in methods for the automatic identification and extraction of opinions, emotions, and sentiments in text. Much of the relevant research explores sentiment classification, a text categorization task in which the goal is to assign to a document either positive (“thumbs up”) or negative (“thumbs down”) polarity (e.g. Das and Chen (2001), Pang et al. (2002), Turney (2002), Dave et al. (2003), Pang and Lee (2004)). Other research has concentrated on analyzing opinions at, or below, the sentence level. Recent work, for example, indicates that systems can be trained to recognize opinions, their polarity, their source, and their strength to a reasonable degree of accuracy (e.g. Dave et al. (2003), Riloff and Wiebe (2003), Bethard et al. (2004), Pang and Lee (2004), Wilson et al. (2004), Yu and Hatzivassiloglou (2003), Wiebe and Riloff (2005)). Related work in the area of corpus development includes Wiebe et al.’s (2005) opinion annotation scheme to"
H05-1116,W03-1014,1,0.458677,"text. Much of the relevant research explores sentiment classification, a text categorization task in which the goal is to assign to a document either positive (“thumbs up”) or negative (“thumbs down”) polarity (e.g. Das and Chen (2001), Pang et al. (2002), Turney (2002), Dave et al. (2003), Pang and Lee (2004)). Other research has concentrated on analyzing opinions at, or below, the sentence level. Recent work, for example, indicates that systems can be trained to recognize opinions, their polarity, their source, and their strength to a reasonable degree of accuracy (e.g. Dave et al. (2003), Riloff and Wiebe (2003), Bethard et al. (2004), Pang and Lee (2004), Wilson et al. (2004), Yu and Hatzivassiloglou (2003), Wiebe and Riloff (2005)). Related work in the area of corpus development includes Wiebe et al.’s (2005) opinion annotation scheme to identify subjective expressions — expressions used to express opinions, emotions, sentiments and other private states in text. Wiebe et al. have applied the annotation scheme to create the MPQA corpus consisting of 535 documents manually annotated for phrase-level expressions of opinion. In addition, the NIST-sponsored TREC evaluation has begun to develop data focu"
H05-1116,P02-1053,0,0.00514181,"ng opinion vs. fact questions. Section 5 briefly describes an opinion annotation scheme used in the experiments. Sections 6 and 7 explore the use of opinion information in the design of MPQA systems. 2 Related Work There is a growing interest in methods for the automatic identification and extraction of opinions, emotions, and sentiments in text. Much of the relevant research explores sentiment classification, a text categorization task in which the goal is to assign to a document either positive (“thumbs up”) or negative (“thumbs down”) polarity (e.g. Das and Chen (2001), Pang et al. (2002), Turney (2002), Dave et al. (2003), Pang and Lee (2004)). Other research has concentrated on analyzing opinions at, or below, the sentence level. Recent work, for example, indicates that systems can be trained to recognize opinions, their polarity, their source, and their strength to a reasonable degree of accuracy (e.g. Dave et al. (2003), Riloff and Wiebe (2003), Bethard et al. (2004), Pang and Lee (2004), Wilson et al. (2004), Yu and Hatzivassiloglou (2003), Wiebe and Riloff (2005)). Related work in the area of corpus development includes Wiebe et al.’s (2005) opinion annotation scheme to identify subjec"
H05-1116,W03-1017,0,0.728753,"on task in which the goal is to assign to a document either positive (“thumbs up”) or negative (“thumbs down”) polarity (e.g. Das and Chen (2001), Pang et al. (2002), Turney (2002), Dave et al. (2003), Pang and Lee (2004)). Other research has concentrated on analyzing opinions at, or below, the sentence level. Recent work, for example, indicates that systems can be trained to recognize opinions, their polarity, their source, and their strength to a reasonable degree of accuracy (e.g. Dave et al. (2003), Riloff and Wiebe (2003), Bethard et al. (2004), Pang and Lee (2004), Wilson et al. (2004), Yu and Hatzivassiloglou (2003), Wiebe and Riloff (2005)). Related work in the area of corpus development includes Wiebe et al.’s (2005) opinion annotation scheme to identify subjective expressions — expressions used to express opinions, emotions, sentiments and other private states in text. Wiebe et al. have applied the annotation scheme to create the MPQA corpus consisting of 535 documents manually annotated for phrase-level expressions of opinion. In addition, the NIST-sponsored TREC evaluation has begun to develop data focusing on opinions — the 2003 Novelty Track features a task that requires sys924 tems to identify op"
H05-1116,W03-2102,1,\N,Missing
H05-2018,H05-1045,1,0.340187,"generated from a large corpus of unannotated data by two high-precision, rule-based classifiers. Speech Events and Direct Subjective Expression Classification The second component identifies speech events (e.g., “said,” “according to”) and direct subjective expressions (e.g., “fears,” “is happy”). Speech events include both speaking and writing events. Direct subjective expressions are words or phrases where an opinion, emotion, sentiment, etc. is directly described. A high-precision, rule-based classifier is used to identify these expressions. Related Work Please see (Wiebe and Riloff, 2005; Choi et al., 2005; Wilson et al., 2005) for discussions of related work in automatic opinion and sentiment analysis. 4 Acknowledgments This work was supported by the Advanced Research and Development Activity (ARDA), by the NSF under grants IIS-0208028, IIS-0208798 and IIS0208985, and by the Xerox Foundation. 2.3.2 2.3.3 Opinion Source Identification The third component is a source identifier that combines a Conditional Random Field sequence tagging model (Lafferty et al., 2001) and extraction pattern learning (Riloff, 1996) to identify the sources of speech events and subjective expressions (Choi et al., 2005"
H05-2018,P97-1003,0,0.0192817,"tering out opinionated sentences (Riloff et al., 2005). System Architecture Overview Document Processing For general document processing, OpinionFinder first runs the Sundance partial parser (Riloff and Phillips, 2004) to provide semantic class tags, identify Named Entities, and match extraction patterns that correspond to subjective language (Riloff and Wiebe, 2003). Next, OpenNLP1 1.1.0 is used to tokenize, sentence split, and part-of-speech tag the data, and the Abney stemmer2 is used to stem. In batch mode, OpinionFinder parses the data again, this time to obtain constituency parse trees (Collins, 1997), which are then converted to dependency parse trees (Xia and Palmer, 2001). Currently, this stage is only 1 2 http://opennlp.sourceforge.net/ SCOL version 1g available at http://www.vinartus.net/spa/ 34 Proceedings of HLT/EMNLP 2005 Demonstration Abstracts, pages 34–35, Vancouver, October 2005. available for batch mode processing due to the time required for parsing. Finally, a clue-finder is run to identify words and phrases from a large subjective language lexicon. 2.3 Subjectivity Analysis The subjectivity analysis has four components. The first classifier focuses on identifying sentiment"
H05-2018,W03-1014,1,0.673444,"from knowledge of subjective language include systems that summarize the various viewpoints in a document or that mine product reviews. Even typical fact-oriented applications, such as information extraction, can benefit from subjectivity analysis by filtering out opinionated sentences (Riloff et al., 2005). System Architecture Overview Document Processing For general document processing, OpinionFinder first runs the Sundance partial parser (Riloff and Phillips, 2004) to provide semantic class tags, identify Named Entities, and match extraction patterns that correspond to subjective language (Riloff and Wiebe, 2003). Next, OpenNLP1 1.1.0 is used to tokenize, sentence split, and part-of-speech tag the data, and the Abney stemmer2 is used to stem. In batch mode, OpinionFinder parses the data again, this time to obtain constituency parse trees (Collins, 1997), which are then converted to dependency parse trees (Xia and Palmer, 2001). Currently, this stage is only 1 2 http://opennlp.sourceforge.net/ SCOL version 1g available at http://www.vinartus.net/spa/ 34 Proceedings of HLT/EMNLP 2005 Demonstration Abstracts, pages 34–35, Vancouver, October 2005. available for batch mode processing due to the time requir"
H05-2018,H05-1044,1,0.169551,"rge corpus of unannotated data by two high-precision, rule-based classifiers. Speech Events and Direct Subjective Expression Classification The second component identifies speech events (e.g., “said,” “according to”) and direct subjective expressions (e.g., “fears,” “is happy”). Speech events include both speaking and writing events. Direct subjective expressions are words or phrases where an opinion, emotion, sentiment, etc. is directly described. A high-precision, rule-based classifier is used to identify these expressions. Related Work Please see (Wiebe and Riloff, 2005; Choi et al., 2005; Wilson et al., 2005) for discussions of related work in automatic opinion and sentiment analysis. 4 Acknowledgments This work was supported by the Advanced Research and Development Activity (ARDA), by the NSF under grants IIS-0208028, IIS-0208798 and IIS0208985, and by the Xerox Foundation. 2.3.2 2.3.3 Opinion Source Identification The third component is a source identifier that combines a Conditional Random Field sequence tagging model (Lafferty et al., 2001) and extraction pattern learning (Riloff, 1996) to identify the sources of speech events and subjective expressions (Choi et al., 2005). The source of a spe"
H05-2018,H01-1014,0,0.0113786,"tecture Overview Document Processing For general document processing, OpinionFinder first runs the Sundance partial parser (Riloff and Phillips, 2004) to provide semantic class tags, identify Named Entities, and match extraction patterns that correspond to subjective language (Riloff and Wiebe, 2003). Next, OpenNLP1 1.1.0 is used to tokenize, sentence split, and part-of-speech tag the data, and the Abney stemmer2 is used to stem. In batch mode, OpinionFinder parses the data again, this time to obtain constituency parse trees (Collins, 1997), which are then converted to dependency parse trees (Xia and Palmer, 2001). Currently, this stage is only 1 2 http://opennlp.sourceforge.net/ SCOL version 1g available at http://www.vinartus.net/spa/ 34 Proceedings of HLT/EMNLP 2005 Demonstration Abstracts, pages 34–35, Vancouver, October 2005. available for batch mode processing due to the time required for parsing. Finally, a clue-finder is run to identify words and phrases from a large subjective language lexicon. 2.3 Subjectivity Analysis The subjectivity analysis has four components. The first classifier focuses on identifying sentiment expressions. The second classifier takes the sentiment expressions and iden"
H94-1047,C92-2070,0,0.125654,"nt distribution of the values of the contextual features and object classes. Most previous efforts to formulate a probabilistic classifier for word-sense disambiguation did not a t t e m p t to systematically identify the interdependencies among contextual features that can be used to classify the meaning of an ambiguous word. Many researchers have performed disambiguation on the basis of only a single feature ([61, [15], [2]), while others who do consider multiple contextual features assume t h a t all contextual features are either conditionally independent given the sense of the word (Is], [14]) o r fuRRy independent ([10], [16]). In earlier work, we describe a method for identifying an uppropriate model for use in disambiguating a word given a set of contextual features. We chose a particular set of contextual features and, using this method, identified a model incorporating these features for use in disambiguating the noun interest. These features, which are assigned automatically, are of three types: morphological, collocation-specific, and class-based, with part-of-speech (POS) categories serving as the word classes (see [3] for how the features were chosen). The results of usin"
H94-1047,H93-1052,0,0.709176,"erned with the selection of individually informative features ([2], [5]), with relatively little attention directed toward the identification of an optimum approximation to the joint distribution of the values of the contextual features and object classes. Most previous efforts to formulate a probabilistic classifier for word-sense disambiguation did not a t t e m p t to systematically identify the interdependencies among contextual features that can be used to classify the meaning of an ambiguous word. Many researchers have performed disambiguation on the basis of only a single feature ([61, [15], [2]), while others who do consider multiple contextual features assume t h a t all contextual features are either conditionally independent given the sense of the word (Is], [14]) o r fuRRy independent ([10], [16]). In earlier work, we describe a method for identifying an uppropriate model for use in disambiguating a word given a set of contextual features. We chose a particular set of contextual features and, using this method, identified a model incorporating these features for use in disambiguating the noun interest. These features, which are assigned automatically, are of three types: mo"
H94-1047,J90-1003,0,\N,Missing
H94-1047,P94-1020,1,\N,Missing
H94-1047,P91-1034,0,\N,Missing
H94-1047,P91-1017,0,\N,Missing
J04-3002,J93-3004,0,0.0205942,", the focus of our work is on learning features of subjectivity. We perform opinion piece recognition in order to assess the usefulness of the various features when used together. Other previous NLP research has used features similar to ours for other NLP tasks. Low-frequency words have been used as features in information extraction (Weeber, Vos, and Baayen 2000) and text categorization (Copeck et al. 2000). A number of researchers have worked on mining collocations from text to extend lexicographic resources for machine translation and word sense disambiguation (e.g., Smajda 1993; Lin 1999; Biber 1993). In Samuel, Carberry, and Vijay-Shanker’s (1998) work on identifying collocations for dialog-act recognition, a filter similar to ours was used to eliminate redundant n-gram features: n-grams were eliminated if they contained substrings with the same entropy score as or a better entropy score than the n-gram. 302 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language While it is common in studies of collocations to omit low-frequency words and expressions from analysis, because they give rise to invalid or unrealistic statistical measures (Church and Hanks, 1990), we are able to"
J04-3002,H92-1022,0,0.0152031,"Missing"
J04-3002,W01-1605,0,0.378999,"Missing"
J04-3002,J90-1003,0,0.0763575,"Missing"
J04-3002,P94-1038,0,0.0171372,"Missing"
J04-3002,P03-1027,0,0.03017,"Missing"
J04-3002,P97-1023,0,0.683243,"Missing"
J04-3002,P90-1034,0,0.183988,"Missing"
J04-3002,C94-2174,0,0.0168176,"Missing"
J04-3002,P97-1005,0,0.00751626,"to assess consistency of performance by cross-validating between our manual annotations and the existing document-level annotations. Because the document-level data are not annotated at the sentence level, sentence-level classification is not highlighted in this article. The new sentence annotation study to evaluate sentences with high-density features (Section 4.5) uses different data from WSJ-SE, because some of the features (n-grams and density parameters) were identified using WSJ-SE as training data. Other previous work in NLP has addressed related document-level classifications. Spertus (1997) developed a system for recognizing inflammatory messages. As mentioned earlier in the article, inflammatory language is a type of subjective language, so the task she addresses is closely related to ours. She uses machine learning to select among manually developed features. In contrast, the focus in our work is on automatically identifying features from the data. A number of projects investigating genre detection include editorials as one of the targeted genres. For example, in Karlgren and Cutting (1994), editorials are one of fifteen categories, and in Kessler, Nunberg, and Schutze ¨ (1997"
J04-3002,P99-1004,0,0.619789,"hat the unique generalized collocations were learned from the training data by their matching different unique words from the ones they match in the test data. 3.4 Generating Features from Document-Level Annotations Using Distributional Similarity In this section, we identify adjective and verb PSEs using distributional similarity. Opinion-piece data are used for training, and (a different set of) opinion-piece data and the subjective-element data are used for testing. With distributional similarity, words are judged to be more or less similar based on their distributional patterning in text (Lee 1999; Lee and Pereira 1999). Our Table 5 Random sample of fixed-3-gram collocations in OP1. one-noun of-prep his-det worst-adj of-prep all-det quality-noun of-prep the-det to-prep do-verb so-adverb in-prep the-det company-noun you-pronoun and-conj your-pronoun have-verb taken-verb the-det rest-noun of-prep us-pronoun are-verb at-prep least-adj but-conj if-prep you-pronoun as-prep a-det weapon-noun continue-verb to-to do-verb purpose-noun of-prep the-det could-modal have-verb be-verb it-pronoun seem-verb to-prep to-pronoun continue-verb to-prep have-verb be-verb the-det do-verb something-noun about"
J04-3002,P99-1005,0,0.0615072,"ique generalized collocations were learned from the training data by their matching different unique words from the ones they match in the test data. 3.4 Generating Features from Document-Level Annotations Using Distributional Similarity In this section, we identify adjective and verb PSEs using distributional similarity. Opinion-piece data are used for training, and (a different set of) opinion-piece data and the subjective-element data are used for testing. With distributional similarity, words are judged to be more or less similar based on their distributional patterning in text (Lee 1999; Lee and Pereira 1999). Our Table 5 Random sample of fixed-3-gram collocations in OP1. one-noun of-prep his-det worst-adj of-prep all-det quality-noun of-prep the-det to-prep do-verb so-adverb in-prep the-det company-noun you-pronoun and-conj your-pronoun have-verb taken-verb the-det rest-noun of-prep us-pronoun are-verb at-prep least-adj but-conj if-prep you-pronoun as-prep a-det weapon-noun continue-verb to-to do-verb purpose-noun of-prep the-det could-modal have-verb be-verb it-pronoun seem-verb to-prep to-pronoun continue-verb to-prep have-verb be-verb the-det do-verb something-noun about-prep cause-verb you-pr"
J04-3002,P98-2127,0,0.685398,"78 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language ingly, many include noncontent words that are typically on stop lists of NLP systems (e.g., of, the, get, out, here in the above examples). The method is then used to identify an unusual form of collocation: One or more positions in the collocation may be filled by any word (of an appropriate part of speech) that is unique in the test data. The third type of subjectivity clue we examine here are adjective and verb features identified using the results of a method for clustering words according to distributional similarity (Lin 1998) (Section 3.4). We hypothesized that two words may be distributionally similar because they are both potentially subjective (e.g., tragic, sad, and poignant are identified from bizarre). In addition, we use distributional similarity to improve estimates of unseen events: A word is selected or discarded based on the precision of it together with its n most similar neighbors. We show that the various subjectivity clues perform better and worse on the same data sets, exhibiting an important consistency in performance (Section 4.2). In addition to learning and evaluating clues associated with subj"
J04-3002,P99-1041,0,0.0102576,"ve studies, the focus of our work is on learning features of subjectivity. We perform opinion piece recognition in order to assess the usefulness of the various features when used together. Other previous NLP research has used features similar to ours for other NLP tasks. Low-frequency words have been used as features in information extraction (Weeber, Vos, and Baayen 2000) and text categorization (Copeck et al. 2000). A number of researchers have worked on mining collocations from text to extend lexicographic resources for machine translation and word sense disambiguation (e.g., Smajda 1993; Lin 1999; Biber 1993). In Samuel, Carberry, and Vijay-Shanker’s (1998) work on identifying collocations for dialog-act recognition, a filter similar to ours was used to eliminate redundant n-gram features: n-grams were eliminated if they contained substrings with the same entropy score as or a better entropy score than the n-gram. 302 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language While it is common in studies of collocations to omit low-frequency words and expressions from analysis, because they give rise to invalid or unrealistic statistical measures (Church and Hanks, 1990), we"
J04-3002,P95-1015,0,0.0603072,"Missing"
J04-3002,J93-2004,0,0.0453146,"Missing"
J04-3002,W02-1011,0,0.0506747,"Missing"
J04-3002,W03-1014,1,0.580218,"Missing"
J04-3002,W03-0404,1,0.586125,"Missing"
J04-3002,P98-2188,0,0.00659051,"Missing"
J04-3002,J93-1007,0,0.0153923,"st to the above studies, the focus of our work is on learning features of subjectivity. We perform opinion piece recognition in order to assess the usefulness of the various features when used together. Other previous NLP research has used features similar to ours for other NLP tasks. Low-frequency words have been used as features in information extraction (Weeber, Vos, and Baayen 2000) and text categorization (Copeck et al. 2000). A number of researchers have worked on mining collocations from text to extend lexicographic resources for machine translation and word sense disambiguation (e.g., Smajda 1993; Lin 1999; Biber 1993). In Samuel, Carberry, and Vijay-Shanker’s (1998) work on identifying collocations for dialog-act recognition, a filter similar to ours was used to eliminate redundant n-gram features: n-grams were eliminated if they contained substrings with the same entropy score as or a better entropy score than the n-gram. 302 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language While it is common in studies of collocations to omit low-frequency words and expressions from analysis, because they give rise to invalid or unrealistic statistical measures (Church and Hanks,"
J04-3002,W00-1302,0,0.0167587,"Missing"
J04-3002,P02-1053,0,0.132495,"to present multiple answers to the user based upon speculation or opinions derived from different sources (Carbonell 1979; Wiebe et al. 2003). Multidocument summarization systems should summarize different opinions and perspectives. Automatic subjectivity analysis would also be useful to perform flame recognition (Spertus 1997; Kaufer 2000), e-mail classification (Aone, Ramos-Santacruze, and Niehaus 2000), intellectual attribution in text (Teufel and Moens 2000), recognition of speaker role in radio broadcasts (Barzialy et al. 2000), review mining (Terveen et al. 1997), review classification (Turney 2002; Pang, Lee, and Vaithyanathan 2002), style in generation (Hovy 1987), and clustering documents by ideological point of view (Sack 1995). In general, nearly any information-seeking system could benefit from knowledge of how opinionated a text is and whether or not the writer purports to objectively present factual material. To perform automatic subjectivity analysis, good clues must be found. A huge variety of words and phrases have subjective usages, and while some manually developed resources exist, such as dictionaries of affective language (General-Inquirer 2000; Heise 2000) and subjective"
J04-3002,J00-3001,0,0.0186492,"Missing"
J04-3002,W02-2034,1,0.518762,"Missing"
J04-3002,J94-2004,1,0.542838,"s article shows that the density of subjectivity clues in the surrounding context strongly affects how likely it is that a word is subjective, and it provides the results of an annotation study assessing the subjectivity of sentences with high-density features. Finally, the clues are used to perform opinion piece recognition (a type of text categorization and genre detection) to demonstrate the utility of the knowledge acquired in this article. 1. Introduction Subjectivity in natural language refers to aspects of language used to express opinions, evaluations, and speculations (Banfield 1982; Wiebe 1994). Many natural language processing (NLP) applications could benefit from being able to distinguish subjective language from language used to objectively present factual information. Current extraction and retrieval technology focuses almost exclusively on the subject matter of documents. However, additional aspects of a document influence its relevance, including evidential status and attitude (Kessler, Nunberg, Schutze ¨ 1997). Information extraction systems should be able to distinguish between factual information (which should be extracted) and nonfactual information (which should be ∗ Depa"
J04-3002,W01-1626,1,0.354477,"med for the expression-level task. A single round of tagging was performed, with no communication between annotators. There are techniques for analyzing agreement when annotations involve segment boundaries (Litman and Passonneau 1995; Marcu, Romera, and Amorortu 1999), but our focus in this article is on words. Thus, our analyses are at the word level: Each word is classified as either appearing in a subjective element or not. Punctuation and numbers are excluded from the analyses. The kappa value for word agreement in this study is 0.42. Another two-level annotation project was performed in Wiebe et al. (2001), this time involving document-level and expression-level annotations of newsgroup data (NG-FE in Table 1). In that project, we were interested in annotating flames, inflammatory messages in newsgroups or listservs. Note that inflammatory language is a kind of subjective language. The annotators were instructed to mark a message as a flame if the main intention of the message is a personal attack and the message contains insulting or abusive language. After multiple rounds of training, three annotators independently annotated a fresh test set of 88 messages from NG-FE. The average pairwise per"
J04-3002,P99-1032,1,0.701309,"Missing"
J04-3002,W98-1126,1,0.28225,"Missing"
J04-3002,P88-1016,1,0.372378,"Missing"
J04-3002,W03-1017,0,0.598142,"Missing"
J04-3002,C92-3145,0,\N,Missing
J04-3002,C98-2122,0,\N,Missing
J04-3002,C98-2183,0,\N,Missing
J04-3002,W03-2102,1,\N,Missing
J09-2002,W04-2608,0,0.218431,"Missing"
J09-2002,A00-2031,0,0.0395297,"Missing"
J09-2002,J99-2002,1,0.824565,"Missing"
J09-2002,W04-2412,0,0.101345,"Missing"
J09-2002,W05-0620,0,0.0903727,"Missing"
J09-2002,Y01-1001,0,0.0700515,"Missing"
J09-2002,J02-3001,0,0.43876,"onverted into a common inventory, and a separate relation classiﬁer induced over the resulting data. This has the advantage that the target relation-type inventory remains stable whenever new sources of relation annotations are introduced. In addition, the classiﬁer will likely be more accurate as there are more examples per relation type on average. The drawback, however, is that annotations from new resources must ﬁrst be mapped into the common inventory before incorporation. The latter approach is employed here. The common inventory incorporates some of the general relation types deﬁned by Gildea and Jurafsky (2002) for their experiments in classifying semantic relations in FrameNet using a reduced relation inventory. They deﬁned 18 relations (including a special-case null role for expletives), as shown in Table 7. These roles served as the starting point for the common relation inventory we developed to support deﬁnition analysis (O’Hara 2005), with half of the roles used as is and a few others mapped into similar roles. In total, twenty-six relations are deﬁned, including a few roles based on the PTB, Cyc, and Conceptual Graphs invenTable 7 Abstract roles deﬁned by Gildea and Jurafsky based on FrameNet"
J09-2002,W04-0831,0,0.0314671,"Missing"
J09-2002,W05-0625,0,0.0532924,"Missing"
J09-2002,W02-0802,0,0.289013,"Missing"
J09-2002,W04-0803,0,0.0538865,"Missing"
J09-2002,W06-2106,0,0.376705,"on. 1. Introduction English prepositions convey important relations in text. When used as verbal adjuncts, they are the principal means of conveying semantic roles for the supporting entities described by the predicate. Preposition disambiguation is a challenging problem. First, prepositions are highly polysemous. A typical collegiate dictionary has dozens of senses for each of the common prepositions. Second, the senses of prepositions tend to be closely related to one another. For instance, there are three duplicate role assignments among the twenty senses for of in The Preposition Project (Litkowski and Hargraves 2006), a resource containing semantic annotations for common prepositions. ∗ Institute for Language and Information Technologies, Baltimore, MD 21250. E-mail: tomohara@umbc.edu. ∗∗ Department of Computer Science, Pittsburgh, PA 15260. E-mail: wiebe@cs.pitt.edu. Submission received: 7 August 2006; accepted for publication: 21 February 2007. © 2008 Association for Computational Linguistics Computational Linguistics Volume 35, Number 2 Consider the disambiguation of the usages of on in the following sentences: (1) The cut should be blocked on procedural grounds. (2) The industry already operates on ve"
J09-2002,S07-1005,0,0.445495,"Missing"
J09-2002,P93-1033,0,0.219442,"Missing"
J09-2002,H94-1020,0,0.377896,"address such coverage problems in lexicons, we have developed an empirical approach to lexical acquisition, building upon earlier knowledge-based approaches in dictionary deﬁnition analysis (Wilks, Slator, and Guthrie 1996). This involves a two-step process: Deﬁnitions are ﬁrst analyzed with a broad-coverage parser, and then the resulting syntactic relationships are disambiguated using statistical classiﬁcation. A crucial part of this process is the disambiguation of prepositions, exploiting online resources with semantic role usage information. The main resources are the Penn Treebank (PTB; Marcus et al. 1994) and FrameNet (Fillmore, Wooters, and Baker 2001), two popular corpora providing rich annotations on English text, such as the semantic roles associated with prepositional phrases in context. In addition to the semantic role annotations from PTB and FrameNet, traditional knowledge bases (KBs) are utilized to provide training data for the relation classiﬁcation. In particular, the Factotum KB (Cassidy 2000) is used to provide additional training data for prepositions that are used to convey particular relationships. Information on preposition usage is not explicitly encoded in Factotum, so a ne"
J09-2002,J93-2004,0,0.031833,"Missing"
J09-2002,C02-1039,0,0.0707028,"Missing"
J09-2002,W04-0807,0,0.0855353,"Missing"
J09-2002,N03-2022,0,0.0253917,"Missing"
J09-2002,W04-0849,1,0.902702,"Missing"
J09-2002,J05-1004,0,0.364025,"Missing"
J09-2002,W98-0706,0,0.101273,"Missing"
J09-2002,W98-1126,1,0.740813,"Missing"
J09-2002,S07-1051,0,0.132044,"Missing"
J09-2002,J09-2001,0,\N,Missing
J09-2002,A00-1034,0,\N,Missing
J09-3003,E06-1027,0,0.372482,"Missing"
J09-3003,P04-1034,0,0.0409757,"Missing"
J09-3003,P97-1003,0,0.017649,"e is true if the clue instance itself is an intensiﬁer. A word is considered to be an intensiﬁer if it appears in a list of intensiﬁers and if it precedes a word of the appropriate part of speech (e.g., an intensiﬁer adjective must come before a noun). The list of intensiﬁers is a compilation of those listed in Quirk et al. (1985), intensiﬁers identiﬁed from existing entries in the subjectivity lexicon, and intensiﬁers identiﬁed during explorations of the development data. The modiﬁes/modifed by features involve the dependency parse tree of the sentence, obtained by ﬁrst parsing the sentence (Collins 1997) and then converting the tree into its dependency representation (Xia and Palmer 2001). In a dependency representation, every node in the tree structure is a surface word (i.e., there are no abstract nodes such as NP or VP). The parent word is called the head, and its children are its modiﬁers. The 410 Wilson, Wiebe, and Hoffmann Recognizing Contextual Polarity Table 7 Features for neutral–polar classiﬁcation. Word Features word token word part of speech previous word part of speech next word part of speech prior polarity: positive, negative, both, neutral reliability class: strongsubj or weak"
J09-3003,E06-1025,0,0.0226763,"Missing"
J09-3003,esuli-sebastiani-2006-sentiwordnet,0,0.145478,"ing constraints on the co-occurrence in conjunctions of words with similar or opposite polarity (Hatzivassiloglou and McKeown 1997) and statistical measures of word association (Turney and Littman 2003), as well as techniques that exploit information about lexical relationships (Kamps and Marx 2002; Kim and Hovy 2004) and glosses (Esuli and Sebastiani 2005; Andreevskaia and Bergler 2006) in resources such as WordNet. Acquiring the polarity of words and phrases is undeniably important, and there are still open research challenges, such as addressing the sentiments of different senses of words (Esuli and Sebastiani 2006b; Wiebe and Mihalcea 2006), and so on. However, what the polarity of a given word or phrase is when it is used in a particular context is another problem entirely. Consider, for example, the underlined positive and negative words in the following sentence. (3) Philip Clapp, president of the National Environment Trust, sums up well the general thrust of the reaction of environmental movements: “There is no reason at all to believe that the polluters are suddenly going to become reasonable.” The ﬁrst underlined word is Trust. Although many senses of the word trust express a positive sentiment,"
J09-3003,C04-1121,0,0.394693,"Missing"
J09-3003,P97-1023,0,0.909432,"rnments denounced (negative) it. (2) Gavin Elementary School was condemned in April 2004. A common approach to sentiment analysis is to use a lexicon with information about which words and phrases are positive and which are negative. This lexicon may be manually compiled, as is the case with the General Inquirer (Stone et al. 1966), a resource often used in sentiment analysis. Alternatively, the information in the lexicon may be acquired automatically. Acquiring the polarity of words and phrases is itself an active line of research in the sentiment analysis community, pioneered by the work of Hatzivassiloglou and McKeown (1997) on predicting the polarity or semantic orientation of adjectives. Various techniques have been proposed for learning the polarity of words. They include corpus-based techniques, such as using constraints on the co-occurrence in conjunctions of words with similar or opposite polarity (Hatzivassiloglou and McKeown 1997) and statistical measures of word association (Turney and Littman 2003), as well as techniques that exploit information about lexical relationships (Kamps and Marx 2002; Kim and Hovy 2004) and glosses (Esuli and Sebastiani 2005; Andreevskaia and Bergler 2006) in resources such as"
J09-3003,P06-2059,0,0.0160849,"Missing"
J09-3003,W06-1642,0,0.51892,"Missing"
J09-3003,C04-1200,0,0.747408,"of research in the sentiment analysis community, pioneered by the work of Hatzivassiloglou and McKeown (1997) on predicting the polarity or semantic orientation of adjectives. Various techniques have been proposed for learning the polarity of words. They include corpus-based techniques, such as using constraints on the co-occurrence in conjunctions of words with similar or opposite polarity (Hatzivassiloglou and McKeown 1997) and statistical measures of word association (Turney and Littman 2003), as well as techniques that exploit information about lexical relationships (Kamps and Marx 2002; Kim and Hovy 2004) and glosses (Esuli and Sebastiani 2005; Andreevskaia and Bergler 2006) in resources such as WordNet. Acquiring the polarity of words and phrases is undeniably important, and there are still open research challenges, such as addressing the sentiments of different senses of words (Esuli and Sebastiani 2006b; Wiebe and Mihalcea 2006), and so on. However, what the polarity of a given word or phrase is when it is used in a particular context is another problem entirely. Consider, for example, the underlined positive and negative words in the following sentence. (3) Philip Clapp, president of the N"
J09-3003,W04-3253,0,0.506352,"Missing"
J09-3003,W02-1011,0,0.0395442,"Missing"
J09-3003,H05-1043,0,0.616227,"Missing"
J09-3003,W03-1014,1,0.501021,"Missing"
J09-3003,H05-1116,1,0.419475,"Missing"
J09-3003,P02-1053,0,0.0265178,"from recognizing ∗ School of Informatics, Edinburgh EH8 9LW, U.K. E-mail: twilson@inf.ed.ac.uk. ∗∗ Department of Computer Science, Pittsburgh, PA 15260, USA. E-mail: {wiebe,hoffmanp}@cs.pitt.edu. Submission received: 14 November 2006; revised submission received: 8 March 2008; accepted for publication: 16 April 2008. © 2009 Association for Computational Linguistics Computational Linguistics Volume 35, Number 3 inﬂammatory messages (Spertus 1997), to tracking sentiments over time in online discussions (Tong 2001), to classifying positive and negative reviews (Pang, Lee, and Vaithyanathan 2002; Turney 2002). Although a great deal of work in sentiment analysis has targeted documents, applications such as opinion question answering (Yu and Hatzivassiloglou 2003; Maybury 2004; Stoyanov, Cardie, and Wiebe 2005) and review mining to extract opinions about companies and products (Morinaga et al. 2002; Nasukawa and Yi 2003) require sentence-level or even phrase-level analysis. For example, if a question answering system is to successfully answer questions about people’s opinions, it must be able not only to pinpoint expressions of positive and negative sentiments, such as we ﬁnd in sentence (1), but al"
J09-3003,J94-2004,1,0.387341,"s except one, the combination of all features together gives the best performance. Another facet of the evaluation considers how the presence of neutral instances affects the performance of features for distinguishing between positive and negative polarity. These experiments show that the presence of neutral instances greatly degrades the performance of these features, and that perhaps the best way to improve performance across all polarity classes is to improve the system’s ability to identify when an instance is neutral. 1. Introduction Sentiment analysis is a type of subjectivity analysis (Wiebe 1994) that focuses on identifying positive and negative opinions, emotions, and evaluations expressed in natural language. It has been a central component in applications ranging from recognizing ∗ School of Informatics, Edinburgh EH8 9LW, U.K. E-mail: twilson@inf.ed.ac.uk. ∗∗ Department of Computer Science, Pittsburgh, PA 15260, USA. E-mail: {wiebe,hoffmanp}@cs.pitt.edu. Submission received: 14 November 2006; revised submission received: 8 March 2008; accepted for publication: 16 April 2008. © 2009 Association for Computational Linguistics Computational Linguistics Volume 35, Number 3 inﬂammatory"
J09-3003,P99-1032,1,0.456498,"Missing"
J09-3003,H05-1044,1,0.364355,"Missing"
J09-3003,H01-1014,0,0.00585022,"Missing"
J09-3003,W03-1017,0,0.321342,"gh, PA 15260, USA. E-mail: {wiebe,hoffmanp}@cs.pitt.edu. Submission received: 14 November 2006; revised submission received: 8 March 2008; accepted for publication: 16 April 2008. © 2009 Association for Computational Linguistics Computational Linguistics Volume 35, Number 3 inﬂammatory messages (Spertus 1997), to tracking sentiments over time in online discussions (Tong 2001), to classifying positive and negative reviews (Pang, Lee, and Vaithyanathan 2002; Turney 2002). Although a great deal of work in sentiment analysis has targeted documents, applications such as opinion question answering (Yu and Hatzivassiloglou 2003; Maybury 2004; Stoyanov, Cardie, and Wiebe 2005) and review mining to extract opinions about companies and products (Morinaga et al. 2002; Nasukawa and Yi 2003) require sentence-level or even phrase-level analysis. For example, if a question answering system is to successfully answer questions about people’s opinions, it must be able not only to pinpoint expressions of positive and negative sentiments, such as we ﬁnd in sentence (1), but also to determine when an opinion is not being expressed by a word or phrase that typically does evoke one, such as condemned in sentence (2). (1) African ob"
J09-3003,H05-2017,0,\N,Missing
J09-3003,P06-1134,1,\N,Missing
J09-3003,P05-1017,0,\N,Missing
J92-3012,J87-1002,0,0.0291843,"such as contrast and parallel to be valuable in discourse processing. With his relation definitions, Hobbs addresses the question of how domain knowledge is involved in recognizing such relations. In addition, fulfilling the requirements of a relation yields inferences to be drawn in the discourse context, as well as recognition of the relation itself. However, his focus on inference is at the expense of other aspects of discourse processing addressed by other researchers, for example using &quot;surface&quot; information such as cue words to constrain possible interpretations (as in Reichman 1985 and Cohen 1987, for example). The recognition of coherence relations is just one of the discourse problems included in Hobbs&apos;s subtheory 5. Solving the other discourse problems, producing the candidate interpretations, choosing the best interpretation, and the rest of the subtheories are black boxes that are assumed to exist but are not specified here, being outside the scope of the book. The justification for assuming these black boxes is that this is &quot;a way of isolating the problem of interest&quot; (p. 43). People working in NLU, especially those working on discourse, must often make such assumptions. Otherwi"
J94-2004,J88-2004,0,0.0224152,"tigate linguistic aspects of subjective sentences. The present work greatly benefited from their investigations, most directly from Dole~el (1973), Uspensky (1973), Kuroda (1973, 1976), Fillmore (1974), Cohn (1978), and especially Banfield (1982). However, the relevant work in the above fields is descriptive only; it describes characteristics of subjective sentences, but does not address the problem of tracking POV. An exception is work on POV and aspect that shows that aspect is only a context-sensitive marker of subjectivity (Ehrlich [1987, 1990] and Caenepeel [1989]; see Section 9). In AI, Nakhimovsky (1988) suggests a discourse-processing approach to tracking POV, but does not develop it in any depth. Also, Reiser (1981) simply suggests that POV may be established by syntactic clues, and by including &quot;more episodes and internal information&quot; about a character (p. 209). 239 Computational Linguistics Volume 20, Number 2 con text ~ l{ }, { }, {}, presubjective-nonactive / loop if ~SENTENCE(ITEM( text, i) ) then context ~- NEW-CONTEXT'(ITEM(text, i), context) else interpretation ~ POV (FEATURES(ITEM( text, i) ),context) context ~ NEw-CONTEXT(interpretation, context) end if i~i+l end loop n ~e.nl~ce ~"
J94-2004,C88-2099,0,0.0196845,"rather than initiating Y's. W h e n a private-state sentence appears in the continuing-subjective situation, therefore, the algorithm identifies the SC to be the last SC rather than the experiencer of the private state. The question of whether there is a psychological link between paragraph breaks and tracking POV has not been previously investigated. Stark (1987, 1988) performed psychological experiments that showed that there is a significant correlation between paragraph breaks and discourse discontinuities, but the sorts of discontinuities she investigated did not include changes in POV. Nakhimovsky and Rapaport (1988) suggest that in narrative, paragraph breaks accompany changes in POV, but they did not investigate this hypothesis experimentally. In fact, we have performed psychological experiments (Bruder and Wiebe 1990 and in press) that did establish such a link. Specifically, through manipulation of paragraph breaks in naturally occurring passages, the experiments showed that readers' interpretations of private-state sentences are influenced by paragraph breaks as we predicted on the basis of the algorithm. 8.3.2 Subjective Elements. Private-state sentences are pragmatically ambiguous as to whether the"
J94-2004,P88-1016,1,0.8452,"entence (21): (21) John knew Mary had the key. Sentence (21) is about a private state: &quot;John knew ps(pl,experiencerl, attitude1, Mary had the key.&quot; objectl) 4 A private-state sentence may also be objective.An example is a simple-past sentence with a negated factive term and a propositional object, such as &quot;John did not know that Mary was in the next room.&quot; This sentence cannot be John's subjectivesentence; it is either objective or the subjective sentence of someone else. Becauseof space limitations, how the algorithm recognizes and processes such sentences is not discussed in this paper; see Wiebe and Rapaport (1988) and Wiebe (1990). 253 Computational Linguistics Volume 20, Number 2 Under a private-state report interpretation of (21), pl is not itself the object of some other private state. But under a represented thought interpretation of (21), pl is the object of some other private state P2, the experiencer and attitude of which are implicit: &quot;John knew Mary had the key.&quot; ps (P2, experiencer2, attitude2, object2 = pl ) To m y knowledge, this ambiguity in the interpretation of private-state sentences and its importance in tracking POV have not been previously discussed in linguistics or literary theory."
J94-2004,J89-2001,0,\N,Missing
J94-2004,J87-1002,0,\N,Missing
J94-2004,J82-1002,0,\N,Missing
J94-2004,P83-1007,0,\N,Missing
J94-2004,J86-3001,0,\N,Missing
J99-2002,J96-1002,0,0.0229023,"Missing"
J99-2002,P94-1020,1,0.631984,"used in NLP. The class of models, decomposable models, is large and expressive, yet there are computationally feasible model search procedures defined for them. They can include any kind of discrete variable, and the formality of the method supports evaluation. In this paper, our goal is to make this model selection framework accessible to researchers in NLP, by providing a concise explanation of the underlying theor~ pointing * Department of Computer Science, Asheville, NC 28804-3299. Department of Computer Science, Las Cruces, NM 88003. 1 This framework was originally introduced into NLP in Bruce and Wiebe (1994). (~) 1999 Association for Computational Linguistics Computational Linguistics Volume 25, Number 2 out relationships to existing NLP research, and providing pointers to available software and important references. In addition, we describe how the quality of the three determinants of classifier performance (the features, the form of the m o d e l and the parameter estimates) can be separately evaluated. We also demonstrate the classification performance of these models in a largescale experiment involving the disambiguation of 34 words taken from the HECTOR word sense corpus (Atkins 1993; Hanks"
J99-2002,W96-0210,1,0.874289,"Missing"
J99-2002,W97-1005,1,0.883221,"Missing"
J99-2002,H93-1051,0,0.0537048,"Missing"
J99-2002,W96-0208,0,0.111683,"atures, the form of the m o d e l and the parameter estimates) can be separately evaluated. We also demonstrate the classification performance of these models in a largescale experiment involving the disambiguation of 34 words taken from the HECTOR word sense corpus (Atkins 1993; Hanks 1996). We compare the performance of classifiers based on models selected by this algorithm with the performance of naive Bayes classifiers (classifiers based on the naive Bayes model). Naive Bayes classifiers have been found to be remarkably successful in many applications, including word sense disambiguation (Mooney 1996). In 10-fold cross-validations, the model search procedure achieves an overall 1.4 percentage point improvement over naive Bayes, and is significantly better on 6 of the words without being significantly worse on any of them. 2. Probabilistic Modeling We will use word sense disambiguation of the word interest as a concrete example in this section. For simplicity, we will use only two contextual features, the part of speech of the word to the left and the part of speech of the word to the right. Assume that there are 8 senses of interest and 20 part of speech tags. We will map the features to f"
J99-2002,A97-1056,1,0.776162,"Missing"
J99-2002,W97-0301,0,0.0125468,"iables are the class assigned to the current object and the classes assigned to the previous N - 1 objects, and there are edges between all pairs of variables. A naive Bayes model includes edges between the classification variable and each feature variable (and contains no other edges). Because n-gram and naive Bayes models are decomposable, they are possible candidates during model selection. However, they would be selected only if they appear to be the most appropriate models for the particular data. In maximum entropy modeling as applied to NLP (Berger, Della Pietra, and Della Pietra 1996; Ratnaparkhi 1997), feature selection and model search are typically combined, but the procedure differs from that described here. It is important to note that decomposable models are a subset of maximum entropy models. Even so, no effort is made to select for decomposable models (and take advantage of their benefits), or to demonstrate the need for a broader class of models. Bayesian networks are extensively used in artificial intelligence. They are popular because of their graphical representations and because there are probability propagation algorithms for computing the joint and conditional distributions o"
N03-4017,W02-1028,0,0.0193568,"Missing"
N03-4017,P99-1032,1,\N,Missing
N09-1002,E06-1027,0,0.515121,"e hospital feels no different than a hospital in the states. An NLP application system may want to find a wide range 11 of private states attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. Second, distinguishing S and O instances has often proven more difficult than subsequent polarity classification. Researchers have found this at various levels of analysis, including the manual annotation of phrases (Takamura et al., 2006), sentiment classification of phrases (Wilson et al., 2005), sentiment tagging of words (Andreevskaia and Bergler, 2006b), and sentiment tagging of word senses (Esuli and Sebastiani, 2006a). Thus, effective methods for S/O classification promise to improve performance for sentiment classification. In fact, researchers in sentiment analysis have realized benefits by decomposing the problem into S/O and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). One reason is that different features may be relevant for the two subproblems. For example, negation features are more important for polarity classification than for subjectivity classification. N"
N09-1002,E06-1025,0,0.0528476,"ication system may want to find a wide range 11 of private states attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. Second, distinguishing S and O instances has often proven more difficult than subsequent polarity classification. Researchers have found this at various levels of analysis, including the manual annotation of phrases (Takamura et al., 2006), sentiment classification of phrases (Wilson et al., 2005), sentiment tagging of words (Andreevskaia and Bergler, 2006b), and sentiment tagging of word senses (Esuli and Sebastiani, 2006a). Thus, effective methods for S/O classification promise to improve performance for sentiment classification. In fact, researchers in sentiment analysis have realized benefits by decomposing the problem into S/O and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). One reason is that different features may be relevant for the two subproblems. For example, negation features are more important for polarity classification than for subjectivity classification. Note that some of our features require vertical links that are presen"
N09-1002,esuli-sebastiani-2006-sentiwordnet,0,0.163404,"ication system may want to find a wide range 11 of private states attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. Second, distinguishing S and O instances has often proven more difficult than subsequent polarity classification. Researchers have found this at various levels of analysis, including the manual annotation of phrases (Takamura et al., 2006), sentiment classification of phrases (Wilson et al., 2005), sentiment tagging of words (Andreevskaia and Bergler, 2006b), and sentiment tagging of word senses (Esuli and Sebastiani, 2006a). Thus, effective methods for S/O classification promise to improve performance for sentiment classification. In fact, researchers in sentiment analysis have realized benefits by decomposing the problem into S/O and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). One reason is that different features may be relevant for the two subproblems. For example, negation features are more important for polarity classification than for subjectivity classification. Note that some of our features require vertical links that are presen"
N09-1002,P07-1054,0,0.220206,"isting resources that do not require manually annotated data; they also implement a supervised system for comparison, which we will call SMsup. The other three groups start with positive and negative seed sets and expand them by adding synonyms and antonyms, and traversing horizontal links in WordNet. AB, ES, and SMsup additionally use information contained in glosses; AB also use hyponyms; SMsup also uses relation and POS features. AB perform multiple runs of their system to assign fuzzy categories to senses. ES use a semi-supervised, multiple-classifier learning approach. In a later paper, (Esuli and Sebastiani, 2007), ES again use information in glosses, applying a random walk ranking algorithm to a graph in which synsets are linked if a member of the first synset appears in the gloss of the second. Like ES and SMsup, we use machine learning, but with more diverse sources of knowledge. Further, several of our features are novel for the task. The LCS features (Section 6.1) detect subjectivity by measuring the similarity of a candidate word sense with a seed set. WM also use a similarity measure, but as a way to filter the output of a measure of distributional similarity (selecting words for a given word se"
N09-1002,C04-1200,0,0.377964,"ntended to conserve water”) He sold his catch at the market. catch, haul – (the quantity that was caught; “the catch was only 10 fish”) =&gt; indefinite quantity – (an estimated quantity) WM performed an agreement study and report that good agreement (κ=0.74) can be achieved between human annotators labeling the subjectivity of senses. For a similar task, (Su and Markert, 2008) also report good agreement. 3 Related Work Many methods have been developed for automatically identifying subjective (opinion, sentiment, attitude, affect-bearing, etc.) words, e.g., (Turney, 2002; Riloff and Wiebe, 2003; Kim and Hovy, 2004; Taboada et al., 2006; Takamura et al., 2006). Five groups have worked on subjectivity sense labeling. WM and Su and Markert (2008) (hereafter SM) assign S/O labels to senses, while Esuli and Sebastiani (hereafter ES) (2006a; 2007), Andreevskaia and Bergler (hereafter AB) (2006b; 2006a), and (Valitutti et al., 2004) assign polarity labels. WM, SM, and ES have evaluated their systems against manually annotated word-sense data. WM’s annotations are described above; SM’s are similar. In the scheme ES use (Cerini et al., 2007), senses are assigned three scores, for positivity, negativity, 12 and"
N09-1002,N06-1026,0,0.0492454,"at various levels of analysis, including the manual annotation of phrases (Takamura et al., 2006), sentiment classification of phrases (Wilson et al., 2005), sentiment tagging of words (Andreevskaia and Bergler, 2006b), and sentiment tagging of word senses (Esuli and Sebastiani, 2006a). Thus, effective methods for S/O classification promise to improve performance for sentiment classification. In fact, researchers in sentiment analysis have realized benefits by decomposing the problem into S/O and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). One reason is that different features may be relevant for the two subproblems. For example, negation features are more important for polarity classification than for subjectivity classification. Note that some of our features require vertical links that are present in WordNet for nouns and verbs but not for other parts of speech. Thus we address nouns (leaving verbs to future work). There are other motivations for focusing on nouns. Relatively little work in subjectivity and sentiment analysis has focused on subjective nouns. Also, a study (Bruce and Wiebe, 1999) showed that, of the major pa"
N09-1002,P04-1035,0,0.0182573,"assification. Researchers have found this at various levels of analysis, including the manual annotation of phrases (Takamura et al., 2006), sentiment classification of phrases (Wilson et al., 2005), sentiment tagging of words (Andreevskaia and Bergler, 2006b), and sentiment tagging of word senses (Esuli and Sebastiani, 2006a). Thus, effective methods for S/O classification promise to improve performance for sentiment classification. In fact, researchers in sentiment analysis have realized benefits by decomposing the problem into S/O and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). One reason is that different features may be relevant for the two subproblems. For example, negation features are more important for polarity classification than for subjectivity classification. Note that some of our features require vertical links that are present in WordNet for nouns and verbs but not for other parts of speech. Thus we address nouns (leaving verbs to future work). There are other motivations for focusing on nouns. Relatively little work in subjectivity and sentiment analysis has focused on subjective nouns. Also, a study (Bruce and"
N09-1002,W03-1014,1,0.63668,"your wrist”; “a device intended to conserve water”) He sold his catch at the market. catch, haul – (the quantity that was caught; “the catch was only 10 fish”) =&gt; indefinite quantity – (an estimated quantity) WM performed an agreement study and report that good agreement (κ=0.74) can be achieved between human annotators labeling the subjectivity of senses. For a similar task, (Su and Markert, 2008) also report good agreement. 3 Related Work Many methods have been developed for automatically identifying subjective (opinion, sentiment, attitude, affect-bearing, etc.) words, e.g., (Turney, 2002; Riloff and Wiebe, 2003; Kim and Hovy, 2004; Taboada et al., 2006; Takamura et al., 2006). Five groups have worked on subjectivity sense labeling. WM and Su and Markert (2008) (hereafter SM) assign S/O labels to senses, while Esuli and Sebastiani (hereafter ES) (2006a; 2007), Andreevskaia and Bergler (hereafter AB) (2006b; 2006a), and (Valitutti et al., 2004) assign polarity labels. WM, SM, and ES have evaluated their systems against manually annotated word-sense data. WM’s annotations are described above; SM’s are similar. In the scheme ES use (Cerini et al., 2007), senses are assigned three scores, for positivity,"
N09-1002,E06-1026,0,0.11017,"be subjective but not have any particular polarity. An example given by (Wilson et al., 2005) is Jerome says the hospital feels no different than a hospital in the states. An NLP application system may want to find a wide range 11 of private states attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. Second, distinguishing S and O instances has often proven more difficult than subsequent polarity classification. Researchers have found this at various levels of analysis, including the manual annotation of phrases (Takamura et al., 2006), sentiment classification of phrases (Wilson et al., 2005), sentiment tagging of words (Andreevskaia and Bergler, 2006b), and sentiment tagging of word senses (Esuli and Sebastiani, 2006a). Thus, effective methods for S/O classification promise to improve performance for sentiment classification. In fact, researchers in sentiment analysis have realized benefits by decomposing the problem into S/O and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). One reason is that different features may be relevant for the two subproblems"
N09-1002,P02-1053,0,0.00471185,"gh to wear on your wrist”; “a device intended to conserve water”) He sold his catch at the market. catch, haul – (the quantity that was caught; “the catch was only 10 fish”) =&gt; indefinite quantity – (an estimated quantity) WM performed an agreement study and report that good agreement (κ=0.74) can be achieved between human annotators labeling the subjectivity of senses. For a similar task, (Su and Markert, 2008) also report good agreement. 3 Related Work Many methods have been developed for automatically identifying subjective (opinion, sentiment, attitude, affect-bearing, etc.) words, e.g., (Turney, 2002; Riloff and Wiebe, 2003; Kim and Hovy, 2004; Taboada et al., 2006; Takamura et al., 2006). Five groups have worked on subjectivity sense labeling. WM and Su and Markert (2008) (hereafter SM) assign S/O labels to senses, while Esuli and Sebastiani (hereafter ES) (2006a; 2007), Andreevskaia and Bergler (hereafter AB) (2006b; 2006a), and (Valitutti et al., 2004) assign polarity labels. WM, SM, and ES have evaluated their systems against manually annotated word-sense data. WM’s annotations are described above; SM’s are similar. In the scheme ES use (Cerini et al., 2007), senses are assigned three"
N09-1002,P06-1134,1,0.900403,"nding subjective words, if it would make sense for word- and sense-level approaches to work in tandem, or should we best view them as competing approaches? We give evidence suggesting that first identifying subjective words and then disambiguating their senses would be an effective approach to subjectivity sense labeling. 10 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 10–18, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics There are several motivations for assigning subjectivity labels to senses. First, (Wiebe and Mihalcea, 2006) provide evidence that word sense labels, together with contextual subjectivity analysis, can be exploited to improve performance in word sense disambiguation. Similarly, given subjectivity sense labels, word-sense disambiguation may potentially help contextual subjectivity analysis. In addition, as lexical resources such as WordNet are developed further, subjectivity labels would provide principled criteria for refining word senses, as well as for clustering similar meanings to create more coursegrained sense inventories. For many opinion mining applications, polarity (positive, negative) is"
N09-1002,H05-1044,1,0.269656,"rm grew. He absorbed the information quickly. UCC/Disciples leaders roundly condemned the Iranian President’s verbal assault on Israel. What’s the catch? Polarity (also called semantic orientation) is also important to NLP applications in sentiment analysis and opinion extraction. In review mining, for example, we want to know whether an opinion about a product is positive or negative. Even so, we believe there are strong motivations for a separate subjective/objective (S/O) classification as well. First, expressions may be subjective but not have any particular polarity. An example given by (Wilson et al., 2005) is Jerome says the hospital feels no different than a hospital in the states. An NLP application system may want to find a wide range 11 of private states attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. Second, distinguishing S and O instances has often proven more difficult than subsequent polarity classification. Researchers have found this at various levels of analysis, including the manual annotation of phrases (Takamura et al., 2006), sentiment classification of phrases (Wilson et al., 2005), sentiment"
N09-1002,W03-1017,0,0.020249,"ult than subsequent polarity classification. Researchers have found this at various levels of analysis, including the manual annotation of phrases (Takamura et al., 2006), sentiment classification of phrases (Wilson et al., 2005), sentiment tagging of words (Andreevskaia and Bergler, 2006b), and sentiment tagging of word senses (Esuli and Sebastiani, 2006a). Thus, effective methods for S/O classification promise to improve performance for sentiment classification. In fact, researchers in sentiment analysis have realized benefits by decomposing the problem into S/O and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). One reason is that different features may be relevant for the two subproblems. For example, negation features are more important for polarity classification than for subjectivity classification. Note that some of our features require vertical links that are present in WordNet for nouns and verbs but not for other parts of speech. Thus we address nouns (leaving verbs to future work). There are other motivations for focusing on nouns. Relatively little work in subjectivity and sentiment analysis has focused on subjective nouns. Also"
N09-1002,C08-1104,0,\N,Missing
N09-1002,andreevskaia-bergler-2006-semantic,0,\N,Missing
N15-1146,D08-1083,0,0.0232455,"a valuable new resource for developing systems for entity/event-level sentiment analysis. Such systems, in turn, would be valuable in NLP applications such as Automatic Question Answering. We introduce the idea of entity and event targets (eTargets), describe the annotation scheme, and present the results of an agreement study. 1 Introduction Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002; Turney, 2002). There is increasing interest in more fine-grained levels - sentence-level (Yu and Hatzivassiloglou, 2003; McDonald et al., 2007), phrase-level (Choi and Cardie, 2008), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. We specifically address sentiments toward entities and events (i.e., eTargets) expressed in data such as blogs, newswire, and editorials. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). Or, to augment an automatic wikification system (Ratinov et al., 2011) – in addition to relationships such as"
N15-1146,P13-2022,1,0.648655,"nclude target annotations. Such targets are often aspects or features of products or services, and as such are somewhat limited.2 Recently, to create the Sentiment Treebank (Socher et al., 2013), researchers crowdsourced annotations of movie review data and then overlaid the annotations onto syntax trees. Thus, the targets are not limited to aspects of products/services. However, annotators were asked to annotate small and then increasingly larger segments of the sentence. Thus, the annotations are mixed in the degree to which context was considered when making the judgements. Previously, we (Deng et al., 2013) annotated a corpus of non-review data with sentiments toward entities, but only for those that participate in certain types of events. In all of the above corpora, the only sentiments considered are those of the writer, excluding sentiments attributed to other entities. The MPQA opinion annotated corpus (Wiebe et al., 2005; Wilson, 2007) is entirely span-based, and contains no eTarget annotations. However, it provides an infrastructure for sentiment annotation that is not provided by other sentiment NLP corpora, and 1 http://www.nist.gov/tac/2014/KBP/Sentiment/index.html For example, as state"
N15-1146,J13-3002,0,0.0183563,"he formal agreement study, one document was randomly selected from each of the four topics of the OPQA subset (Stoyanov et al., 2005) of the MPQA corpus. They were not any of the documents used to develop the manual. We then independently annotated the four documents. There are 292 eTargets in the four documents in total. To evaluate the results, the same agreement measure is used for both attitude and ESE eTargets. Given an attitude or ESE, let set A be the set of eTargets annotated by annotator X, and set B be the set of eTargets annotated by annotator Y . Following (Wilson and Wiebe, 2003; Johansson and Moschitti, 2013), which treat each set A and B in turn as the gold-standard, we calculate the average F-measure, denoted agr(A, B). The agr(A, B) is 0.82 on average over the four documents, showing good agreement: agr(A, B) = (|A∩B|/|B|+|A∩B|/|A|)/2. 4 Disagreement Analysis One issue is whether an attitude toward an entity or event is indeed communicated in the sentence. Consider this sentence: “President Mugabe’s reelection has been praised by OAU.” The OAU is positive toward “reelection,” which is an eTarget both annotators mark. The question is whether it is also communicated in this sentence that the OAU"
N15-1146,P07-1055,0,0.0723618,"corpus. The new corpus promises to be a valuable new resource for developing systems for entity/event-level sentiment analysis. Such systems, in turn, would be valuable in NLP applications such as Automatic Question Answering. We introduce the idea of entity and event targets (eTargets), describe the annotation scheme, and present the results of an agreement study. 1 Introduction Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002; Turney, 2002). There is increasing interest in more fine-grained levels - sentence-level (Yu and Hatzivassiloglou, 2003; McDonald et al., 2007), phrase-level (Choi and Cardie, 2008), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. We specifically address sentiments toward entities and events (i.e., eTargets) expressed in data such as blogs, newswire, and editorials. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). Or, to augment an automatic wikification system (Ratinov et al., 2011) –"
N15-1146,W02-1011,0,0.0160017,"t This paper presents an annotation scheme for adding entity and event target annotations to the MPQA corpus, a rich span-annotated opinion corpus. The new corpus promises to be a valuable new resource for developing systems for entity/event-level sentiment analysis. Such systems, in turn, would be valuable in NLP applications such as Automatic Question Answering. We introduce the idea of entity and event targets (eTargets), describe the annotation scheme, and present the results of an agreement study. 1 Introduction Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002; Turney, 2002). There is increasing interest in more fine-grained levels - sentence-level (Yu and Hatzivassiloglou, 2003; McDonald et al., 2007), phrase-level (Choi and Cardie, 2008), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. We specifically address sentiments toward entities and events (i.e., eTargets) expressed in data such as blogs, newswire, and editorials. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/"
N15-1146,P11-1138,0,0.0152689,"McDonald et al., 2007), phrase-level (Choi and Cardie, 2008), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. We specifically address sentiments toward entities and events (i.e., eTargets) expressed in data such as blogs, newswire, and editorials. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). Or, to augment an automatic wikification system (Ratinov et al., 2011) – in addition to relationships such as spouse and parents, the system could include information about whom or what the subject supports or opposes. A recent NIST evaluation – The Knowledge Base Population (KBP) Sentiment track1 — aims at using corpora to collect information regarding sentiments expressed toward or by named entities. Annotated corpora of reviews (e.g., (Hu and Liu, 2004; Titov and McDonald, 2008)), widely used in NLP, often include target annotations. Such targets are often aspects or features of products or services, and as such are somewhat limited.2 Recently, to create the"
N15-1146,D13-1170,0,0.00559474,"lationships such as spouse and parents, the system could include information about whom or what the subject supports or opposes. A recent NIST evaluation – The Knowledge Base Population (KBP) Sentiment track1 — aims at using corpora to collect information regarding sentiments expressed toward or by named entities. Annotated corpora of reviews (e.g., (Hu and Liu, 2004; Titov and McDonald, 2008)), widely used in NLP, often include target annotations. Such targets are often aspects or features of products or services, and as such are somewhat limited.2 Recently, to create the Sentiment Treebank (Socher et al., 2013), researchers crowdsourced annotations of movie review data and then overlaid the annotations onto syntax trees. Thus, the targets are not limited to aspects of products/services. However, annotators were asked to annotate small and then increasingly larger segments of the sentence. Thus, the annotations are mixed in the degree to which context was considered when making the judgements. Previously, we (Deng et al., 2013) annotated a corpus of non-review data with sentiments toward entities, but only for those that participate in certain types of events. In all of the above corpora, the only se"
N15-1146,H05-1116,1,0.763823,"more fine-grained levels - sentence-level (Yu and Hatzivassiloglou, 2003; McDonald et al., 2007), phrase-level (Choi and Cardie, 2008), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. We specifically address sentiments toward entities and events (i.e., eTargets) expressed in data such as blogs, newswire, and editorials. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). Or, to augment an automatic wikification system (Ratinov et al., 2011) – in addition to relationships such as spouse and parents, the system could include information about whom or what the subject supports or opposes. A recent NIST evaluation – The Knowledge Base Population (KBP) Sentiment track1 — aims at using corpora to collect information regarding sentiments expressed toward or by named entities. Annotated corpora of reviews (e.g., (Hu and Liu, 2004; Titov and McDonald, 2008)), widely used in NLP, often include target annotations. Such targets are often aspects or features of products"
N15-1146,P08-1036,0,0.126059,"y/event-level sentiment analysis. Such systems, in turn, would be valuable in NLP applications such as Automatic Question Answering. We introduce the idea of entity and event targets (eTargets), describe the annotation scheme, and present the results of an agreement study. 1 Introduction Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002; Turney, 2002). There is increasing interest in more fine-grained levels - sentence-level (Yu and Hatzivassiloglou, 2003; McDonald et al., 2007), phrase-level (Choi and Cardie, 2008), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. We specifically address sentiments toward entities and events (i.e., eTargets) expressed in data such as blogs, newswire, and editorials. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). Or, to augment an automatic wikification system (Ratinov et al., 2011) – in addition to relationships such as spouse and parents, the system could include information ab"
N15-1146,P02-1053,0,0.0200679,"ts an annotation scheme for adding entity and event target annotations to the MPQA corpus, a rich span-annotated opinion corpus. The new corpus promises to be a valuable new resource for developing systems for entity/event-level sentiment analysis. Such systems, in turn, would be valuable in NLP applications such as Automatic Question Answering. We introduce the idea of entity and event targets (eTargets), describe the annotation scheme, and present the results of an agreement study. 1 Introduction Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002; Turney, 2002). There is increasing interest in more fine-grained levels - sentence-level (Yu and Hatzivassiloglou, 2003; McDonald et al., 2007), phrase-level (Choi and Cardie, 2008), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. We specifically address sentiments toward entities and events (i.e., eTargets) expressed in data such as blogs, newswire, and editorials. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who"
N15-1146,W03-2102,1,0.737723,"n agreement study. For the formal agreement study, one document was randomly selected from each of the four topics of the OPQA subset (Stoyanov et al., 2005) of the MPQA corpus. They were not any of the documents used to develop the manual. We then independently annotated the four documents. There are 292 eTargets in the four documents in total. To evaluate the results, the same agreement measure is used for both attitude and ESE eTargets. Given an attitude or ESE, let set A be the set of eTargets annotated by annotator X, and set B be the set of eTargets annotated by annotator Y . Following (Wilson and Wiebe, 2003; Johansson and Moschitti, 2013), which treat each set A and B in turn as the gold-standard, we calculate the average F-measure, denoted agr(A, B). The agr(A, B) is 0.82 on average over the four documents, showing good agreement: agr(A, B) = (|A∩B|/|B|+|A∩B|/|A|)/2. 4 Disagreement Analysis One issue is whether an attitude toward an entity or event is indeed communicated in the sentence. Consider this sentence: “President Mugabe’s reelection has been praised by OAU.” The OAU is positive toward “reelection,” which is an eTarget both annotators mark. The question is whether it is also communicate"
N15-1146,W03-1017,0,0.123728,"a rich span-annotated opinion corpus. The new corpus promises to be a valuable new resource for developing systems for entity/event-level sentiment analysis. Such systems, in turn, would be valuable in NLP applications such as Automatic Question Answering. We introduce the idea of entity and event targets (eTargets), describe the annotation scheme, and present the results of an agreement study. 1 Introduction Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002; Turney, 2002). There is increasing interest in more fine-grained levels - sentence-level (Yu and Hatzivassiloglou, 2003; McDonald et al., 2007), phrase-level (Choi and Cardie, 2008), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. We specifically address sentiments toward entities and events (i.e., eTargets) expressed in data such as blogs, newswire, and editorials. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). Or, to augment an automatic wikification system"
P06-1134,P97-1023,0,0.531349,"es to speech (or writing) events expressing private states: UCC/Disciples leaders roundly condemned the Iranian President’s verbal assault on Israel. The editors of the left-leaning paper attacked the new House Speaker. (3) expressive subjective elements: He would be quite a catch. What’s the catch? That doctor is a quack. Work on automatic subjectivity analysis falls into three main areas. The first is identifying words and phrases that are associated with subjectivity, for example, that think is associated with private states and that beautiful is associated with positive sentiments (e.g., (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Kamps and Marx, 2002; Turney, 2002; Esuli and Sebastiani, 2005)). Such judgments are made for words. In contrast, our end task (in Section 4) is to assign subjectivity labels to word senses. The second is subjectivity classification of sentences, clauses, phrases, or word instances in the context of a particular text or conversation, either subjective/objective classifications or positive/negative sentiment classifications (e.g.,(Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Dave et al., 2003; Hu and Liu, 2004)). The third exploits automatic subjectivity analysis in app"
P06-1134,O97-1002,0,0.0146293,". Starting with a given ambiguous word w, we first find the distributionally similar words using the method of (Lin, 1998) applied to the automatically parsed texts of the British National Corpus. Let DSW = dsw1 , dsw2 , ..., dswn be the list of top-ranked distributionally similar words, sorted in decreasing order of their similarity. Next, for each sense wsi of the word w, we determine the similarity with each of the words in the list DSW , using a WordNet-based measure of semantic similarity (wnss). Although a large number of such word-to-word similarity measures exist, we chose to use the (Jiang and Conrath, 1997) measure, since it was found both to be efficient and to provide the best results in previous experiments involving word sense ranking (McCarthy et al., 2004)5 . For distributionally similar words 5 Note that unlike the above measure of distributional simAlgorithm 1 Word Sense Subjectivity Score Input: Word sense wi Input: Distributionally similar words DSW = {dswj |j = 1..n} Output: Subjectivity score subj(wi ) 1: subj(wi ) = 0 2: totalsim = 0 3: for j = 1 to n do 4: Instsj = all instances of dswj in the MPQA corpus 5: for k in Instsj do 6: if k is in a subj. expr. in MPQA corpus then 7: subj"
P06-1134,C04-1200,0,0.866003,"econd is subjectivity classification of sentences, clauses, phrases, or word instances in the context of a particular text or conversation, either subjective/objective classifications or positive/negative sentiment classifications (e.g.,(Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Dave et al., 2003; Hu and Liu, 2004)). The third exploits automatic subjectivity analysis in applications such as review classification (e.g., (Turney, 2002; Pang and Lee, 2004)), mining texts for product reviews (e.g., (Yi et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005)), summarization (e.g., (Kim and Hovy, 2004)), information extraction (e.g., (Riloff et al., 2005)), 1 Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation. 2 These distinctions are not strictly needed for this paper, but may help the reader appreciate the examples given below. and question answering (e.g., (Yu and Hatzivassiloglou, 2003; Stoyanov et al., 2005)). Most manual subjectivity annotation research has focused on annotating words, out of context (e.g., (Heise, 2001)), or sentences and phrases in the context of a tex"
P06-1134,W02-1006,0,0.0253206,"gh sense-specific keywords determined as a list of at most five words occurring at least three times in the contexts defining a certain word sense. This feature set is similar to the one used by (Ng and Lee, 1996), as well as by a number of S ENSEVAL systems. The parameters for sense-specific keyword selection were determined through cross-fold validation on the training set. The features are integrated in a Naive Bayes classifier, which was selected mainly for its performance in previous work showing that it can lead to a state-of-the-art disambiguation system given the features we consider (Lee and Ng, 2002). The experiments are performed on the set of ambiguous nouns from the S ENSEVAL -3 English lexical sample evaluation (Mihalcea et al., 2004). We use the rule-based subjective sentence classifier of (Riloff and Wiebe, 2003) to assign an S, O, or B label to all the training and test examples pertaining to these ambiguous words. This subjectivity annotation tool targets sentences, rather than words or paragraphs, and therefore the tool is fed with sentences. We also include a surrounding context of two additional sentences, because the classifier considers some contextual information. Our hypoth"
P06-1134,P98-2127,0,0.0185016,"e can derive information about a word sense based on information drawn from words that are distributionally similar to the given word sense. This idea relates to the unsupervised word sense ranking algorithm described in (McCarthy et al., 2004). Note, however, that (McCarthy et al., 2004) used the information about distributionally similar words to approximate corpus frequencies for word senses, whereas we target the estimation of a property of a given word sense (the “subjectivity”). Starting with a given ambiguous word w, we first find the distributionally similar words using the method of (Lin, 1998) applied to the automatically parsed texts of the British National Corpus. Let DSW = dsw1 , dsw2 , ..., dswn be the list of top-ranked distributionally similar words, sorted in decreasing order of their similarity. Next, for each sense wsi of the word w, we determine the similarity with each of the words in the list DSW , using a WordNet-based measure of semantic similarity (wnss). Although a large number of such word-to-word similarity measures exist, we chose to use the (Jiang and Conrath, 1997) measure, since it was found both to be efficient and to provide the best results in previous expe"
P06-1134,P04-1036,0,0.104809,"ve reactions to the condition. One annotator judged only the sense (giving tag O), while the second considered the hypernym as well (giving tag UB). 4 Automatic Assessment of Word Sense Subjectivity Encouraged by the results of the agreement study, we devised a method targeting the automatic annotation of word senses for subjectivity. The main idea behind our method is that we can derive information about a word sense based on information drawn from words that are distributionally similar to the given word sense. This idea relates to the unsupervised word sense ranking algorithm described in (McCarthy et al., 2004). Note, however, that (McCarthy et al., 2004) used the information about distributionally similar words to approximate corpus frequencies for word senses, whereas we target the estimation of a property of a given word sense (the “subjectivity”). Starting with a given ambiguous word w, we first find the distributionally similar words using the method of (Lin, 1998) applied to the automatically parsed texts of the British National Corpus. Let DSW = dsw1 , dsw2 , ..., dswn be the list of top-ranked distributionally similar words, sorted in decreasing order of their similarity. Next, for each sens"
P06-1134,W04-0807,1,0.308658,"word sense. This feature set is similar to the one used by (Ng and Lee, 1996), as well as by a number of S ENSEVAL systems. The parameters for sense-specific keyword selection were determined through cross-fold validation on the training set. The features are integrated in a Naive Bayes classifier, which was selected mainly for its performance in previous work showing that it can lead to a state-of-the-art disambiguation system given the features we consider (Lee and Ng, 2002). The experiments are performed on the set of ambiguous nouns from the S ENSEVAL -3 English lexical sample evaluation (Mihalcea et al., 2004). We use the rule-based subjective sentence classifier of (Riloff and Wiebe, 2003) to assign an S, O, or B label to all the training and test examples pertaining to these ambiguous words. This subjectivity annotation tool targets sentences, rather than words or paragraphs, and therefore the tool is fed with sentences. We also include a surrounding context of two additional sentences, because the classifier considers some contextual information. Our hypothesis motivating the use of a sentence-level subjectivity classifier is that instances of subjective senses are more likely to be in subjectiv"
P06-1134,P96-1006,0,0.0609969,"res. 9 The break-even point (Lewis, 1992) is a standard measure used in conjunction with precision-recall evaluations. It represents the value where precision and recall become equal. Specifically, we use the current word and its partof-speech, a local context of three words to the left and right of the ambiguous word, the parts-ofspeech of the surrounding words, and a global context implemented through sense-specific keywords determined as a list of at most five words occurring at least three times in the contexts defining a certain word sense. This feature set is similar to the one used by (Ng and Lee, 1996), as well as by a number of S ENSEVAL systems. The parameters for sense-specific keyword selection were determined through cross-fold validation on the training set. The features are integrated in a Naive Bayes classifier, which was selected mainly for its performance in previous work showing that it can lead to a state-of-the-art disambiguation system given the features we consider (Lee and Ng, 2002). The experiments are performed on the set of ambiguous nouns from the S ENSEVAL -3 English lexical sample evaluation (Mihalcea et al., 2004). We use the rule-based subjective sentence classifier"
P06-1134,P04-1035,0,0.205261,"ebastiani, 2005)). Such judgments are made for words. In contrast, our end task (in Section 4) is to assign subjectivity labels to word senses. The second is subjectivity classification of sentences, clauses, phrases, or word instances in the context of a particular text or conversation, either subjective/objective classifications or positive/negative sentiment classifications (e.g.,(Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Dave et al., 2003; Hu and Liu, 2004)). The third exploits automatic subjectivity analysis in applications such as review classification (e.g., (Turney, 2002; Pang and Lee, 2004)), mining texts for product reviews (e.g., (Yi et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005)), summarization (e.g., (Kim and Hovy, 2004)), information extraction (e.g., (Riloff et al., 2005)), 1 Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation. 2 These distinctions are not strictly needed for this paper, but may help the reader appreciate the examples given below. and question answering (e.g., (Yu and Hatzivassiloglou, 2003; Stoyanov et al., 2005)). Most manual sub"
P06-1134,H05-1043,0,0.0577035,"to assign subjectivity labels to word senses. The second is subjectivity classification of sentences, clauses, phrases, or word instances in the context of a particular text or conversation, either subjective/objective classifications or positive/negative sentiment classifications (e.g.,(Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Dave et al., 2003; Hu and Liu, 2004)). The third exploits automatic subjectivity analysis in applications such as review classification (e.g., (Turney, 2002; Pang and Lee, 2004)), mining texts for product reviews (e.g., (Yi et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005)), summarization (e.g., (Kim and Hovy, 2004)), information extraction (e.g., (Riloff et al., 2005)), 1 Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation. 2 These distinctions are not strictly needed for this paper, but may help the reader appreciate the examples given below. and question answering (e.g., (Yu and Hatzivassiloglou, 2003; Stoyanov et al., 2005)). Most manual subjectivity annotation research has focused on annotating words, out of context (e.g., (Heise, 2001)), or s"
P06-1134,W03-1014,1,0.344348,"mple, that think is associated with private states and that beautiful is associated with positive sentiments (e.g., (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Kamps and Marx, 2002; Turney, 2002; Esuli and Sebastiani, 2005)). Such judgments are made for words. In contrast, our end task (in Section 4) is to assign subjectivity labels to word senses. The second is subjectivity classification of sentences, clauses, phrases, or word instances in the context of a particular text or conversation, either subjective/objective classifications or positive/negative sentiment classifications (e.g.,(Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Dave et al., 2003; Hu and Liu, 2004)). The third exploits automatic subjectivity analysis in applications such as review classification (e.g., (Turney, 2002; Pang and Lee, 2004)), mining texts for product reviews (e.g., (Yi et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005)), summarization (e.g., (Kim and Hovy, 2004)), information extraction (e.g., (Riloff et al., 2005)), 1 Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation. 2 These distin"
P06-1134,H05-1116,1,0.754642,"e.g., (Turney, 2002; Pang and Lee, 2004)), mining texts for product reviews (e.g., (Yi et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005)), summarization (e.g., (Kim and Hovy, 2004)), information extraction (e.g., (Riloff et al., 2005)), 1 Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation. 2 These distinctions are not strictly needed for this paper, but may help the reader appreciate the examples given below. and question answering (e.g., (Yu and Hatzivassiloglou, 2003; Stoyanov et al., 2005)). Most manual subjectivity annotation research has focused on annotating words, out of context (e.g., (Heise, 2001)), or sentences and phrases in the context of a text or conversation (e.g., (Wiebe et al., 2005)). The new annotations in this paper are instead targeting the annotation of word senses. 3 Human Judgment of Word Sense Subjectivity To explore our hypothesis that subjectivity may be associated with word senses, we developed a manual annotation scheme for assigning subjectivity labels to WordNet senses,3 and performed an inter-annotator agreement study to assess its reliability. Sens"
P06-1134,P02-1053,0,0.0172673,"es leaders roundly condemned the Iranian President’s verbal assault on Israel. The editors of the left-leaning paper attacked the new House Speaker. (3) expressive subjective elements: He would be quite a catch. What’s the catch? That doctor is a quack. Work on automatic subjectivity analysis falls into three main areas. The first is identifying words and phrases that are associated with subjectivity, for example, that think is associated with private states and that beautiful is associated with positive sentiments (e.g., (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Kamps and Marx, 2002; Turney, 2002; Esuli and Sebastiani, 2005)). Such judgments are made for words. In contrast, our end task (in Section 4) is to assign subjectivity labels to word senses. The second is subjectivity classification of sentences, clauses, phrases, or word instances in the context of a particular text or conversation, either subjective/objective classifications or positive/negative sentiment classifications (e.g.,(Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Dave et al., 2003; Hu and Liu, 2004)). The third exploits automatic subjectivity analysis in applications such as review classification (e.g., (T"
P06-1134,W03-1017,0,0.893463,"ciated with private states and that beautiful is associated with positive sentiments (e.g., (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Kamps and Marx, 2002; Turney, 2002; Esuli and Sebastiani, 2005)). Such judgments are made for words. In contrast, our end task (in Section 4) is to assign subjectivity labels to word senses. The second is subjectivity classification of sentences, clauses, phrases, or word instances in the context of a particular text or conversation, either subjective/objective classifications or positive/negative sentiment classifications (e.g.,(Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Dave et al., 2003; Hu and Liu, 2004)). The third exploits automatic subjectivity analysis in applications such as review classification (e.g., (Turney, 2002; Pang and Lee, 2004)), mining texts for product reviews (e.g., (Yi et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005)), summarization (e.g., (Kim and Hovy, 2004)), information extraction (e.g., (Riloff et al., 2005)), 1 Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation. 2 These distinctions are not strictly needed"
P06-1134,H05-2017,0,\N,Missing
P06-1134,C98-2122,0,\N,Missing
P07-1123,E06-1027,0,0.0591854,"are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may seek a wide range of types of subjectivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on sentiment. There is world-wide interest in text analysis applications. While work on subjectivity analysis in other languages is growing (e.g., Japanese"
P07-1123,H05-1073,0,0.33515,"Missing"
P07-1123,E06-2031,0,0.0863299,"Missing"
P07-1123,E06-1025,0,0.568579,"nd uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage appro"
P07-1123,I05-1001,0,0.040085,"tivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on sentiment. There is world-wide interest in text analysis applications. While work on subjectivity analysis in other languages is growing (e.g., Japanese data are used in (Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006)), much of the work in subjectivity analysis has been applied to English data. Creating corpora and lexical resources for a new language is very time consuming. In general, we would like to leverage resources already developed for one language to more rapidly create subjectivity analysis tools for a new one. This motivates our exploration and use of cross-lingual lexicon translations and annotation projections. Most if not all work on subjectivity analysis has been carried out in a monolingual framework. We 977 are not aware of multi-lingual wo"
P07-1123,W06-1642,0,0.099884,"NLP application may seek a wide range of types of subjectivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on sentiment. There is world-wide interest in text analysis applications. While work on subjectivity analysis in other languages is growing (e.g., Japanese data are used in (Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006)), much of the work in subjectivity analysis has been applied to English data. Creating corpora and lexical resources for a new language is very time consuming. In general, we would like to leverage resources already developed for one language to more rapidly create subjectivity analysis tools for a new one. This motivates our exploration and use of cross-lingual lexicon translations and annotation projections. Most if not all work on subjectivity analysis has been carried out in a monolingual framewo"
P07-1123,N06-1026,0,0.452624,"cs While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may seek a wide range of types of subjectivity at"
P07-1123,H93-1061,0,0.0228724,"bjectivity or sentiment classification, e.g., (Pang et al., 2002; Yu and Hatzivassiloglou, 2003)). The hypothesis is that we can eliminate some of the ambiguities (and consequent loss of subjectivity) observed during the lexicon translation by accounting for the context of the ambiguous words, which is possible in a corpus-based approach. Additionally, we also hope to improve the recall of the classifier, by addressing those cases not covered by the lexicon-based approach. In the experiments reported in this section, we use a parallel corpus consisting of 107 documents from the SemCor corpus (Miller et al., 1993) and their manual translations into Romanian.3 The corpus consists of roughly 11,000 sentences, with approximately 250,000 tokens on each side. It is a balanced corpus covering a number of topics in sports, politics, fashion, education, and others. 3 The translation was carried out by a Romanian native speaker, student in a department of “Foreign Languages and Translations” in Romania. 980 Annotation Study. We start by performing an agreement study meant to determine the extent to which subjectivity is preserved by the cross-lingual projections. In the study, three annotators – one native Engl"
P07-1123,P04-1035,0,0.124897,"7 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may see"
P07-1123,W02-1011,0,0.024939,"Missing"
P07-1123,W03-1014,1,0.425604,"s for a new one. This motivates our exploration and use of cross-lingual lexicon translations and annotation projections. Most if not all work on subjectivity analysis has been carried out in a monolingual framework. We 977 are not aware of multi-lingual work in subjectivity analysis such as that proposed here, in which subjectivity analysis resources developed for one language are used to support developing resources in another. 3 A Lexicon-Based Approach Many subjectivity and sentiment analysis tools rely on manually or semi-automatically constructed lexicons (Yu and Hatzivassiloglou, 2003; Riloff and Wiebe, 2003; Kim and Hovy, 2006). Given the success of such techniques, the first approach we take to generating a target-language subjectivity classifier is to create a subjectivity lexicon by translating an existing source language lexicon, and then build a classifier that relies on the resulting lexicon. Below, we describe the translation process and discuss the results of an annotation study to assess the quality of the translated lexicon. We then describe and evaluate a lexicon-based target-language classifier. 3.1 Translating a Subjectivity Lexicon The subjectivity lexicon we use is from OpinionFin"
P07-1123,E06-1026,0,0.0307306,"wo-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may seek a wide range of types of subjectivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on se"
P07-1123,P02-1053,0,0.0118121,"roviding motivations, we present two approaches to developing sentence-level subjectivity classifiers for a new target language. The first uses a subjectivity lexicon translated from an English one. The second uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotio"
P07-1123,P06-1134,1,0.726219,"m an English one. The second uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have"
P07-1123,H05-1044,1,0.132207,"Missing"
P07-1123,W03-1017,0,0.862182,"llel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances a"
P09-1026,C08-2002,0,0.012611,"o not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. Pragmatic opinions. Some of the errors are due to the fact that the opinions expressed in the post are pragmatic. This becomes a problem especially when the debate post is small, and we have few other lexical clue"
P09-1026,C08-2004,0,0.0327329,"ns between topics and aspects alone. The system that implements this information, mined from the web, outperforms the web PMI-based baseline. Our hypothesis that addressing concessionary opinions is useful is also corroborated by improved performance. 6 Related Work Several researchers have worked on similar tasks. Kim and Hovy (2007) predict the results of an election by analyzing forums discussing the elections. Theirs is a supervised bag-of-words system using unigrams, bigrams, and trigrams as features. In contrast, our approach is unsupervised, and exploits different types of information. Bansal et al. (2008) predict the vote from congressional floor debates using agreement/disagreement features. We do not model inter-personal exchanges; instead, we model factors that influence stance taking. Lin at al (2006) identify opposing perspectives. Though apparently related at the task level, perspectives as they define them are not the same as opinions. Their approach does not involve any opinion analysis. Fujii and Ishikawa (2006) also work with arguments. However, their focus is on argument visualization rather than on recognizing stances. Other researchers have also mined data to learn associations am"
P09-1026,N07-1039,0,0.00986641,"2005); however, in our work, we need to find Table 4: Performance of the systems on the test data 232 information in the other direction – that is, given the opinion, what is the opinion about. Stoyanov and Cardie (2008) work on opinion co-reference; however, we need to identify the specific target. user preferences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual"
P09-1026,W06-0303,0,0.0333837,"Missing"
P09-1026,C08-1031,0,0.0442457,"Missing"
P09-1026,I08-1039,0,0.0101091,"ever, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. Pragmatic opinions. Some of the errors are due to the fact that the opinions expressed in the post are pragmatic. This becomes a problem especially when the debate post is small, and we have few other lexical clues in the post. The following post is an example: (4) The blackberry is something like $150 and the iPhone is $500. I don’t think it’s worth it. You could buy a iPod separate and have a boatload of extra money left over. In this example, the participant mentions the difference in the prices in the first sentenc"
P09-1026,D07-1113,0,0.0234193,"unsupervised method for classifying the side taken by a post, which also accounts for concessionary opinions. Our results corroborate our hypothesis that finding relations between aspects associated with a topic, but particularized to polarity, is more effective than finding relations between topics and aspects alone. The system that implements this information, mined from the web, outperforms the web PMI-based baseline. Our hypothesis that addressing concessionary opinions is useful is also corroborated by improved performance. 6 Related Work Several researchers have worked on similar tasks. Kim and Hovy (2007) predict the results of an election by analyzing forums discussing the elections. Theirs is a supervised bag-of-words system using unigrams, bigrams, and trigrams as features. In contrast, our approach is unsupervised, and exploits different types of information. Bansal et al. (2008) predict the vote from congressional floor debates using agreement/disagreement features. We do not model inter-personal exchanges; instead, we model factors that influence stance taking. Lin at al (2006) identify opposing perspectives. Though apparently related at the task level, perspectives as they define them a"
P09-1026,H05-2017,0,0.885217,"information. The dependency parses are obtained using 2 3.2 Learning aspects and preferences from the web We observed in our development data that people highlight the aspects of topics that are the bases for their stances, both positive opinions toward aspects of the preferred topic, and negative opinions toward aspects of the dispreferred one. Thus, we decided to mine the web for aspects associated with a side in the debate, and then use that information to recognize the stances expressed in individual posts. Previous work mined web data for aspects associated with topics (Hu and Liu, 2004; Popescu et al., 2005). In our work, we search for aspects associated with a topic, but particularized to polarity. Not all aspects associated with a topic are 3 Available at http://www.cs.pitt.edu/mpqa. 228 http://nlp.stanford.edu/software/lex-parser.shtml. termp storm+ storm− phone+ e-mail+ ipod+ battery − network− keyboard+ keyboard− side1 (pro-iPhone) P (iP hone+ |termp ) P (blackberry −|termp ) 0.227 0.068 0.062 0.843 0.333 0.176 0 0.333 0.5 0 0 0 0.333 0 0.09 0.12 0.25 0.25 side2 (pro-blackberry) P (iP hone− |termp ) P (blackberry + |termp ) 0.022 0.613 0.06 0.03 0.137 0.313 0.166 0.5 0.33 0 0.666 0.333 0.666"
P09-1026,sadamitsu-etal-2008-sentiment,0,0.0115781,"ative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. Pragmatic opinions. Some of the errors are due to the fact that the opinions expressed in the post are pragmatic. This becomes a problem especially when the debate post is small, and we have few other lexical clues in the post. The follow"
P09-1026,N07-1038,0,0.0174188,"rences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. Pragmatic opinions. Some of the errors are due to the fact that the opinions expressed in the post are pragmatic. This becomes a problem especially when the debate po"
P09-1026,C08-1101,1,0.43507,"atures over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. Pragmatic opinions. Some of the errors are due to the fact that the opinions expressed in the post are pragmatic. This becomes a problem especially when the debate post is small, and we have fe"
P09-1026,C08-1103,0,0.00797451,"er to analyze why OpPr outperforms OpPMI, we need to compare Tables 2 and 3. Table 2 reports the conditional probaOpinion-target pairing. The syntactic rulebased opinion-target pairing system is a large source of errors in the OpPr as well as the baseline systems. Product review mining work has explored finding opinions with respect to, or in conjunction with, aspects (Hu and Liu, 2004; Popescu et al., 2005); however, in our work, we need to find Table 4: Performance of the systems on the test data 232 information in the other direction – that is, given the opinion, what is the opinion about. Stoyanov and Cardie (2008) work on opinion co-reference; however, we need to identify the specific target. user preferences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have re"
P09-1026,P06-1134,1,0.363199,"c 33.87 53.23 64.52 66.13 Prec 67.74 60.0 64.52 66.13 Rec 33.87 53.23 64.52 66.13 F1 45.16 56.41 64.52 66.13 Windows vs. Mac (15 posts) Acc 13.33 46.67 66.67 66.67 Prec 40.0 53.85 66.67 66.67 Rec 13.33 46.67 66.67 66.67 F1 20.0 50.00 66.67 66.67 SonyPs3 vs. Wii (36 posts) Acc 33.33 33.33 56.25 61.11 Prec 80.0 46.15 56.25 68.75 Rec 33.33 33.33 50.0 61.11 F1 47.06 38.71 52.94 64.71 Opera vs. Firefox (4 posts) Acc 25.0 50.0 75.0 100.0 Prec 33.33 100 75.0 100.0 Rec 25.0 50 75.0 100.0 F1 28.57 66.67 75.0 100.0 5.1 Errors 5 Discussion False lexicon hits. The lexicon is word based, but, as shown by (Wiebe and Mihalcea, 2006; Su and Markert, 2008), many subjective words have both objective and subjective senses. Thus, one major source of errors is a false hit of a word in the lexicon. In this section, we discuss the results from the previous section and describe the sources of errors. As reported in the previous section, the OpPr system outperforms both the OpTopic and the OpPMI systems. In order to analyze why OpPr outperforms OpPMI, we need to compare Tables 2 and 3. Table 2 reports the conditional probaOpinion-target pairing. The syntactic rulebased opinion-target pairing system is a large source of errors in"
P09-1026,I05-2030,0,0.0297107,"u, 2004; Popescu et al., 2005); however, in our work, we need to find Table 4: Performance of the systems on the test data 232 information in the other direction – that is, given the opinion, what is the opinion about. Stoyanov and Cardie (2008) work on opinion co-reference; however, we need to identify the specific target. user preferences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recogniz"
P09-1026,W06-2915,1,0.9047,"Missing"
P09-1026,H05-1044,1,0.0399215,"them with targets, both to mine the web for general preferences and to classify the stance of a debate post. We use straightforward methods, as these tasks are not the focus of this paper. To find opinions, we look up words in a subjectivity lexicon: all instances of those words are treated as opinions. An opinion is assigned the prior polarity that is listed for that word in the lexicon, except that, if the prior polarity is positive or negative, and the instance is modified by a negation word (e.g., “not”), then the polarity of that instance is reversed. We use the subjectivity lexicon of (Wilson et al., 2005),2 which contains approximately 8000 words which may be used to express opinions. Each entry consists of a subjective word, its prior polarity (positive (+ ), negative (− ), neutral (∗ )), morphological information, and part of speech information. To pair opinions with targets, we built a rulebased system based on dependency parse information. The dependency parses are obtained using 2 3.2 Learning aspects and preferences from the web We observed in our development data that people highlight the aspects of topics that are the bases for their stances, both positive opinions toward aspects of th"
P09-1026,C08-1104,0,\N,Missing
P09-1026,H05-1043,0,\N,Missing
P12-4004,banea-etal-2008-bootstrapping,1,0.892304,"Missing"
P13-2022,W05-0308,1,0.721647,"toward their agents and objects. Work on opinion and sentiment tends to focus on explicit expressions of opinions. However, many attitudes are conveyed implicitly, and benefactive/malefactive events are important for inferring implicit attitudes. We describe an annotation scheme and give the results of an inter-annotator agreement study. The annotated corpus is available online. 1 Introduction Work in NLP on opinion mining and sentiment analysis tends to focus on explicit expressions of opinions. Consider, however, the following sentence from the MPQA corpus (Wiebe et al., 2005) discussed by (Wilson and Wiebe, 2005): 2 Overview For ease of communication, we use the terms goodFor and badFor for benefactive and malefactive events, respectively, and use the abbreviation gfbf for an event that is one or the other. There are many varieties of gfbf events, including destruction (as in kill Bill, which is bad for Bill), creation (as in bake a cake, which is good for the cake), gain or loss (as in increasing costs, which is good for the costs), and benefit or injury (as in comforted the child, which is good for the child) (Anand and Reschke, 2010). The scheme targets clear cases of gfbf events. The event must be"
P13-2022,J08-4004,0,0.108735,"as the goldstandard, we calculate the average F-measure, denoted agr(A, B). agr(A, B) is calculated twice, once with c = c1 and once with c = c2 . match(A, B) = agent Table 1: Span overlapping agreement agr(A, B) in agreement study and consensus study. Numerical: (Johansson and Moschitti, 2013) propose, for the pairs that are counted as 1 by c1 , a measure of the percentage of overlapping tokens, c2 (a, b) = c1 c2 c1 c2 c1 c2 gfbf & influencer 0.70 0.69 0.75 0.72 0.85 0.81 match(A, B) |B| agr(A||B) + agr(B||A) 2 Now that we have the sets of annotations on which the annotators agree, we use κ (Artstein and Poesio, 2008) to measure agreement for the attributes. We report two κ values: one for the polarities of the gfbf events, together with the effects of the influencers, and one for the writer’s agr(A, B) = 4.4 Consensus Analysis Following (Medlock and Briscoe, 2007), we examined what percentage of disagreement is due to negligence on behalf of one or the other annotator (i.e., cases of clear gfbfs or influencers that were missed), though we conducted our consensus 123 back to creating [jobs]. (a) Creating is goodFor jobs; the agent is Obama and the Democrats. (b) The phrase to get back to is a retainer infl"
P13-2022,W12-3810,1,0.295128,"ond-step consensus study to further analyze the disagreement. 4.1 Agreement Study Evaluation The two annotators do agree on the hObama, helped, reformi triple, the first one marking helped as a retainer and the other marking it as a goodFor event. To take such cases into consideration in our evaluation of agreement, if two spans overlap and one is marked as gfbf and the other as influencer, we use the following rules to match up their agents and objects: Data and Agreement Study Design For this study, we want to use data that is rich in opinions and implicatures. Thus we used the corpus from (Conrad et al., 2012), which consists of 134 documents from blogs and editorials about a controversial topic, “the Affordable Care Act”. • for a gfbf event, consider its agent and object as annotated; 122 • for an influencer, assign the agent of the influencer’s object to be the influencer’s object, and consider its agent as annotated and the newly-assigned object. In (9), Ann 2’s annotations remain the same and Ann 1’s become hObama, helped, reformi and hreform, curb, costsi. all annotations only certain consensus study We use the same measurement for agreement for all types of spans. Suppose A is a set of annota"
P13-2022,J13-3002,0,0.063408,"|is the number of tokens in span a, and ∩ gives the tokens that two spans have in common. As (Breck et al., 2007) point out, c2 avoids the problem of c1 , namely that c1 does not penalize a span covering the whole sentence, so it potentially inflates the results. Following (Wilson and Wiebe, 2003), treating each set A and B in turn as the goldstandard, we calculate the average F-measure, denoted agr(A, B). agr(A, B) is calculated twice, once with c = c1 and once with c = c2 . match(A, B) = agent Table 1: Span overlapping agreement agr(A, B) in agreement study and consensus study. Numerical: (Johansson and Moschitti, 2013) propose, for the pairs that are counted as 1 by c1 , a measure of the percentage of overlapping tokens, c2 (a, b) = c1 c2 c1 c2 c1 c2 gfbf & influencer 0.70 0.69 0.75 0.72 0.85 0.81 match(A, B) |B| agr(A||B) + agr(B||A) 2 Now that we have the sets of annotations on which the annotators agree, we use κ (Artstein and Poesio, 2008) to measure agreement for the attributes. We report two κ values: one for the polarities of the gfbf events, together with the effects of the influencers, and one for the writer’s agr(A, B) = 4.4 Consensus Analysis Following (Medlock and Briscoe, 2007), we examined wha"
P13-2022,P07-1125,0,0.0355527,"Numerical: (Johansson and Moschitti, 2013) propose, for the pairs that are counted as 1 by c1 , a measure of the percentage of overlapping tokens, c2 (a, b) = c1 c2 c1 c2 c1 c2 gfbf & influencer 0.70 0.69 0.75 0.72 0.85 0.81 match(A, B) |B| agr(A||B) + agr(B||A) 2 Now that we have the sets of annotations on which the annotators agree, we use κ (Artstein and Poesio, 2008) to measure agreement for the attributes. We report two κ values: one for the polarities of the gfbf events, together with the effects of the influencers, and one for the writer’s agr(A, B) = 4.4 Consensus Analysis Following (Medlock and Briscoe, 2007), we examined what percentage of disagreement is due to negligence on behalf of one or the other annotator (i.e., cases of clear gfbfs or influencers that were missed), though we conducted our consensus 123 back to creating [jobs]. (a) Creating is goodFor jobs; the agent is Obama and the Democrats. (b) The phrase to get back to is a retainer influencer. But, the agent span is also Obama and the Democrats, as the same with the goodFor, so we don’t have to give an annotation for it. (c) The phrase enable is a retainer influencer. Since its agent span is different (namely, it), we do create an an"
P13-2022,C10-1091,0,0.0120108,"nd agent must be determined compositionally. For example, the structure of Jack stopped Mary from trying to kill Bill is a reverser influencer (stopped) whose object is a retainer influencer (trying) whose object is, in turn, a badFor event (kill). The ultimate polarity of this event is goodFor and the “highest level” agent is Jack. In our scheme, all such chains of length N are treated as N − 1 influencers followed by a single gfbf event. It will be up to an automatic system to calculate the ultimate polarity and agent using rules such as those presented in, e.g., (Moilanen and Pulman, 2007; Neviarouskaya et al., 2010). To save some effort, the annotators are not asked to mark retainer influencers which do not introduce new agents. For example, for Jack stopped trying to kill Bill, there is no need to mark “trying.” Of course, all reverser influencers must be marked. 4 4.2 We annotate four types of items (gfbf event, influencer, agent, and object) and their corresponding attributes. As noted above in Section 2, influencers can also be viewed as gfbf events. Also, the two may be combined together in chains. Thus, we measure agreement for gfbf and influencer spans together, treating them as one type. Then we"
P13-2022,W03-2102,1,0.633758,"ct to be the influencer’s object, and consider its agent as annotated and the newly-assigned object. In (9), Ann 2’s annotations remain the same and Ann 1’s become hObama, helped, reformi and hreform, curb, costsi. all annotations only certain consensus study We use the same measurement for agreement for all types of spans. Suppose A is a set of annotations of a particular type and B is the set of annotations of the same type from the other annotator. For any text span a ∈ A and b ∈ B, the span coverage c measures the overlap between a and b. Two measures of c are adopted here. Binary: As in (Wilson and Wiebe, 2003), if two spans a and b overlap, the pair is counted as 1, otherwise 0. c1 (a, b) = 1 if all certain |a ∩ b |> 0 4.3 1.00 0.97 1.00 0.98 0.99 0.98 polarity & effect 0.97 0.97 attitude 0.89 0.89 Agreement Study Results Recall that the annotator could choose whether (s)he is certain about the annotation. Thus, we evaluate two sets: all annotations and only those annotations that both annotators are certain about. The results are shown in the top four rows in Table 1. The results for agents and objects in Table 1 are all quite good, indicating that, given a gfbf or influencer, the annotators are a"
P15-5003,E09-1004,0,0.0116512,"some time, most research using it does not make use of many of its features. We believe this is because the MPQA annotation is quite complex and requires a deeper understanding of the phenomenon of “private state”, which is what the annotation is 1.2 Current Work on Annotating Sentiment To date, the computational analyses of sentiment are often fairly superficial. Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002). There is increasing interest in more fine-grained levels: sentence-level (McDonald et al., 2007), phrase-level (Choi and Cardie, 2008; Agarwal et al., 2009), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. Sentiments toward entities and events (“eTargets”) expressed in blogs, newswire, editorials, etc. are particularly important. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). 7 Proceedings of the Tutorials of the 53rd Annual Meeting of the ACL and the 7th IJCNLP, pages 7–11, c Beijing, China, Jul"
P15-5003,D08-1083,0,0.0160594,"07) has been around for some time, most research using it does not make use of many of its features. We believe this is because the MPQA annotation is quite complex and requires a deeper understanding of the phenomenon of “private state”, which is what the annotation is 1.2 Current Work on Annotating Sentiment To date, the computational analyses of sentiment are often fairly superficial. Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002). There is increasing interest in more fine-grained levels: sentence-level (McDonald et al., 2007), phrase-level (Choi and Cardie, 2008; Agarwal et al., 2009), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. Sentiments toward entities and events (“eTargets”) expressed in blogs, newswire, editorials, etc. are particularly important. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). 7 Proceedings of the Tutorials of the 53rd Annual Meeting of the ACL and the 7th IJCNLP, pages 7–11"
P15-5003,E14-1040,1,0.840074,"rsity of Pittsburgh. She has worked on issues related to private states for some time, originally in the context of tracking point of view in narrative (Wiebe, 1994), and later in the context of recognizing sentiment in other genres such as news articles (Wilson et al., 2005). She has approached the area from the perspective of corpus annotation (Wiebe et al., 2005; Deng et al., 2013), lexical semantics (Wiebe and Mihalcea, 2006), and discourse (Somasundaran et al., 2009). In addition to continuing these lines of research, she has recently begun investigating implicatures in opinion analysis (Deng and Wiebe, 2014). She has received funding for her research from NSF, NIH, DARPA, ONR, NSA, ARDA, and Homeland Security. She was Program Chair of NAACL 2000 and Program Co-Chair of ACL-IJCNLP 2009. She has been on the editorial board of Computational Linguistics and is currently an action editor for Transactions of the ACL. http://people. cs.pitt.edu/˜wiebe/ 3. Break (15 minutes) 4. Representing belief: a presentation of FactBank, the LU corpus, and the ongoing LDC annotation under the DARPA DEFT program. (30 minutes) 5. Integration and looking forward: a discussion of how sentiment and belief interact, and h"
P15-5003,P13-2022,1,0.835708,"Missing"
P15-5003,W09-3012,1,0.867045,"tes with other types of attitudes. This tutorial will present the original MPQA annotation scheme (V2) and its recent extension to include eTarget annotations (V3), which we believe is a valuable new resource for the community. Pustejovsky, 2009), which represents the source of the belief, the target, the strength, and the polarity (using a system of 10 tags which cover strength and polarity). Following (Wiebe et al., 2005), the sources are nested, reflecting the same nesting of private states we also observe for sentiment. FactBank is a rich and complex annotation; the so-called LU corpus of Diab et al. (2009) was created independently, and represents a subset of the annotations of FactBank. The LU corpus annotates only the writer’s belief in the propositions in the text, only distinguishes 3 types of belief, but does clearly represent the target. Unlike FactBank, which is annotated on top of the Penn Treebank, the LU corpus represents a diverse set of texts. The recent annotations at the LDC for the DARPA DEFT project follow the simplicity of the LU corpus annotations, but extend the tagset of the LU corpus to four tags. An annotation effort in the spring of 2015 will include the source of the bel"
P15-5003,P07-1055,0,0.0253856,"corpus (Wiebe et al., 2005; Wilson, 2007) has been around for some time, most research using it does not make use of many of its features. We believe this is because the MPQA annotation is quite complex and requires a deeper understanding of the phenomenon of “private state”, which is what the annotation is 1.2 Current Work on Annotating Sentiment To date, the computational analyses of sentiment are often fairly superficial. Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002). There is increasing interest in more fine-grained levels: sentence-level (McDonald et al., 2007), phrase-level (Choi and Cardie, 2008; Agarwal et al., 2009), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. Sentiments toward entities and events (“eTargets”) expressed in blogs, newswire, editorials, etc. are particularly important. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). 7 Proceedings of the Tutorials of the 53rd Annual Meeting of t"
P15-5003,W02-1011,0,0.0165495,"ns that have been made. The issue of annotation is crucial for private states: while the MPQA corpus (Wiebe et al., 2005; Wilson, 2007) has been around for some time, most research using it does not make use of many of its features. We believe this is because the MPQA annotation is quite complex and requires a deeper understanding of the phenomenon of “private state”, which is what the annotation is 1.2 Current Work on Annotating Sentiment To date, the computational analyses of sentiment are often fairly superficial. Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002). There is increasing interest in more fine-grained levels: sentence-level (McDonald et al., 2007), phrase-level (Choi and Cardie, 2008; Agarwal et al., 2009), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. Sentiments toward entities and events (“eTargets”) expressed in blogs, newswire, editorials, etc. are particularly important. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive"
P15-5003,C10-2117,1,0.895857,"Missing"
P15-5003,W12-3807,1,0.909088,"Missing"
P15-5003,W93-0227,1,0.549478,"Missing"
P15-5003,P11-1138,0,0.0641946,"Missing"
P15-5003,D09-1018,1,0.795945,"argets). (45 minutes) Janyce Wiebe Janyce Wiebe is Professor of Computer Science and Professor and Co-Director of the Intelligent Systems at the University of Pittsburgh. She has worked on issues related to private states for some time, originally in the context of tracking point of view in narrative (Wiebe, 1994), and later in the context of recognizing sentiment in other genres such as news articles (Wilson et al., 2005). She has approached the area from the perspective of corpus annotation (Wiebe et al., 2005; Deng et al., 2013), lexical semantics (Wiebe and Mihalcea, 2006), and discourse (Somasundaran et al., 2009). In addition to continuing these lines of research, she has recently begun investigating implicatures in opinion analysis (Deng and Wiebe, 2014). She has received funding for her research from NSF, NIH, DARPA, ONR, NSA, ARDA, and Homeland Security. She was Program Chair of NAACL 2000 and Program Co-Chair of ACL-IJCNLP 2009. She has been on the editorial board of Computational Linguistics and is currently an action editor for Transactions of the ACL. http://people. cs.pitt.edu/˜wiebe/ 3. Break (15 minutes) 4. Representing belief: a presentation of FactBank, the LU corpus, and the ongoing LDC a"
P15-5003,H05-1116,1,0.62816,"ncreasing interest in more fine-grained levels: sentence-level (McDonald et al., 2007), phrase-level (Choi and Cardie, 2008; Agarwal et al., 2009), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. Sentiments toward entities and events (“eTargets”) expressed in blogs, newswire, editorials, etc. are particularly important. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). 7 Proceedings of the Tutorials of the 53rd Annual Meeting of the ACL and the 7th IJCNLP, pages 7–11, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Or, to augment an automatic wikification system (Ratinov et al., 2011), which could include information about whom or what the subject supports or opposes. A recent NIST evaluation – The Knowledge Base Population (KBP) Sentiment track1 — aims at using corpora to collect information regarding sentiments expressed toward or by named entities. Annotated corpora of reviews (Hu and Liu, 2004; Titov and McDonald, 200"
P15-5003,P08-1036,0,0.0201005,"many of its features. We believe this is because the MPQA annotation is quite complex and requires a deeper understanding of the phenomenon of “private state”, which is what the annotation is 1.2 Current Work on Annotating Sentiment To date, the computational analyses of sentiment are often fairly superficial. Much work in sentiment analysis and opinion mining is at the document level (Pang et al., 2002). There is increasing interest in more fine-grained levels: sentence-level (McDonald et al., 2007), phrase-level (Choi and Cardie, 2008; Agarwal et al., 2009), aspect-level (Hu and Liu, 2004; Titov and McDonald, 2008), etc. Sentiments toward entities and events (“eTargets”) expressed in blogs, newswire, editorials, etc. are particularly important. A system that could recognize sentiments toward entities and events would be valuable in an application such as Automatic Question Answering, to support answering questions such as “Toward whom/what is X negative/positive?” “Who is negative/positive toward X?” (Stoyanov et al., 2005). 7 Proceedings of the Tutorials of the 53rd Annual Meeting of the ACL and the 7th IJCNLP, pages 7–11, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguisti"
P15-5003,W94-0320,1,0.593979,"Missing"
P15-5003,P06-1134,1,0.736603,"MPQA Version 3 (extension of MPQA V2 to eTargets). (45 minutes) Janyce Wiebe Janyce Wiebe is Professor of Computer Science and Professor and Co-Director of the Intelligent Systems at the University of Pittsburgh. She has worked on issues related to private states for some time, originally in the context of tracking point of view in narrative (Wiebe, 1994), and later in the context of recognizing sentiment in other genres such as news articles (Wilson et al., 2005). She has approached the area from the perspective of corpus annotation (Wiebe et al., 2005; Deng et al., 2013), lexical semantics (Wiebe and Mihalcea, 2006), and discourse (Somasundaran et al., 2009). In addition to continuing these lines of research, she has recently begun investigating implicatures in opinion analysis (Deng and Wiebe, 2014). She has received funding for her research from NSF, NIH, DARPA, ONR, NSA, ARDA, and Homeland Security. She was Program Chair of NAACL 2000 and Program Co-Chair of ACL-IJCNLP 2009. She has been on the editorial board of Computational Linguistics and is currently an action editor for Transactions of the ACL. http://people. cs.pitt.edu/˜wiebe/ 3. Break (15 minutes) 4. Representing belief: a presentation of Fac"
P15-5003,C90-2069,1,0.440593,"larger goal) and the technical details of the annotations (achieving the immediate goal). 1.1 Introduction Over the last ten years, there has been an explosion in interest in sentiment analysis, with many interesting and impressive results. For example, the first twenty publications on Google Scholar returned for the Query “sentiment analysis” all date from 2003 or later, and have a total citation count of 12,140. The total number of publications is in the thousands. Partly, this interest is driven by the immediate commercial applications of sentiment analysis. Sentiment is a “private state” (Wiebe, 1990). However, it is not the only private state that has received attention in the computational literature; others include belief and intention. In this tutorial, we propose to provide a deeper understanding of what a private state is. We will concentrate on sentiment and belief. We will provide background that will allow the tutorial participants to understand the notion of a private state as a cognitive phenomenon, which can be manifested linguistically in communication in various ways. We will explain the formalization in terms of a triple of state, source, and target. We will discuss how to m"
P15-5003,J94-2004,1,0.272914,"eridicity (Karttunen, 1971) and modality), and cognitive science. (45 minutes) 3.2 2. Representing sentiment: a presentation of early work, of MPQA V2 (with nested sources, and attitude, expressive-subjective element, and target span annotations), and of MPQA Version 3 (extension of MPQA V2 to eTargets). (45 minutes) Janyce Wiebe Janyce Wiebe is Professor of Computer Science and Professor and Co-Director of the Intelligent Systems at the University of Pittsburgh. She has worked on issues related to private states for some time, originally in the context of tracking point of view in narrative (Wiebe, 1994), and later in the context of recognizing sentiment in other genres such as news articles (Wilson et al., 2005). She has approached the area from the perspective of corpus annotation (Wiebe et al., 2005; Deng et al., 2013), lexical semantics (Wiebe and Mihalcea, 2006), and discourse (Somasundaran et al., 2009). In addition to continuing these lines of research, she has recently begun investigating implicatures in opinion analysis (Deng and Wiebe, 2014). She has received funding for her research from NSF, NIH, DARPA, ONR, NSA, ARDA, and Homeland Security. She was Program Chair of NAACL 2000 and"
P15-5003,H05-1044,1,0.0357036,"iment: a presentation of early work, of MPQA V2 (with nested sources, and attitude, expressive-subjective element, and target span annotations), and of MPQA Version 3 (extension of MPQA V2 to eTargets). (45 minutes) Janyce Wiebe Janyce Wiebe is Professor of Computer Science and Professor and Co-Director of the Intelligent Systems at the University of Pittsburgh. She has worked on issues related to private states for some time, originally in the context of tracking point of view in narrative (Wiebe, 1994), and later in the context of recognizing sentiment in other genres such as news articles (Wilson et al., 2005). She has approached the area from the perspective of corpus annotation (Wiebe et al., 2005; Deng et al., 2013), lexical semantics (Wiebe and Mihalcea, 2006), and discourse (Somasundaran et al., 2009). In addition to continuing these lines of research, she has recently begun investigating implicatures in opinion analysis (Deng and Wiebe, 2014). She has received funding for her research from NSF, NIH, DARPA, ONR, NSA, ARDA, and Homeland Security. She was Program Chair of NAACL 2000 and Program Co-Chair of ACL-IJCNLP 2009. She has been on the editorial board of Computational Linguistics and is c"
P88-1016,J87-1002,0,0.0671453,"Missing"
P88-1016,P84-1016,1,0.880755,"Missing"
P88-1016,J86-3001,0,\N,Missing
P91-1020,C90-3053,0,0.0512998,"Missing"
P94-1020,P91-1017,0,0.0934139,"appear to be too good, indicating that the model is in fact over constrained for the data available. In this work, we have limited ourselves to considering only those models with sufficient statistics that are not sparse, where the significance of the reference X 2 is not unreasonable; most such models have sufficient statistics that are lower-order marginal distributions. In the future, we will investigate other goodness-of-fit tests ([18], [1], [22]) that are perhaps more appropriate for sparse data. The Experiment Unlike several previous approaches to word sense disambiguation ([29], [5], [7], [10]), nothing in this approach limits the selection of sense tags to a particular number or type of meaning distinctions. In this study, our goal was to address a non-trivial case of ambiguity, but one that would allow some comparison of results with previous work. As a result of these considerations, the word interest was chosen as a test case, and the six non-idiomatic noun senses of interest defined in LDOCE were selected as the tag set. The only restriction limiting the choice of corpus is the need for large amounts of on-line data. Due to availability, the Penn Treebank Wall Street Jou"
P94-1020,J93-1003,0,0.011494,"ly selected and set aside to serve as the test set. The distribution of sense tags in the data set is presented in Table 1. We now turn to the selection of individually informative contextual features. In our approach to disambiguation, a contextual feature is judged to be informative (i.e., correlated with the sense tag of the ambiguous word) if the model for independence between that feature and the sense tag is judged to have an extremely poor fit using the test described in Section 2. The worse the fit, the more informative the feature is judged to be (similar to the approach suggested in [9]). Only features whose values can be automatically determined were considered, and preference was given to features that intuitively are not specific to interest (but see the discussion of collocational features below). An additional criterion was that the features not have too many possible values, in order to curtail sparsity in the resulting data matrix. We considered three different types of contextual features: morphological, collocation-specific, and classbased, with part-of-speech (POS) categories serving as the word classes. Within these classes, we choose a number of specific features"
P94-1020,P92-1032,0,0.119199,"he domain, such as public interest group. Because our sense distinctions are not merely between two or three clearly defined core senses of a word, the task of hand-tagging the tokens of interest required subtle judgments, a point that has also been observed by other researchers disambiguating with respect to the full set of LDOCE senses ([6], [28]). Although this undoubtedly degraded the accuracy of the manually assigned sense tags (and thus the accuracy of the study as well), this problem seems unavoidable when making semantic distinctions beyond clearly defined core senses of a word ([17], [11], [14], [15]). Of the 2,369 sentences containing the sense-tagged usages of interest, 600 were randomly selected and set aside to serve as the test set. The distribution of sense tags in the data set is presented in Table 1. We now turn to the selection of individually informative contextual features. In our approach to disambiguation, a contextual feature is judged to be informative (i.e., correlated with the sense tag of the ambiguous word) if the model for independence between that feature and the sense tag is judged to have an extremely poor fit using the test described in Section 2. The w"
P94-1020,H93-1021,0,0.0158549,"us word. The tree construction process used by Black partitions the data according to the values of one contextual feature before considering the values of the next, thereby treating all features incorporated in the tree as interdependent. The method presented here for using information from multiple contextual features is more flexible and makes better use of a small data set by eliminating the need to treat all features as interdependent. The work that bears the closest resemblance to the work presented here is the maximum entropy approach to developing language models ([24], [25], [19] and [20]). Conclusions and Future Work • In this paper, we presented a method for formulating probabilistic models that use multiple contextual features for word-sense disambiguation without requiring untested assumptions regarding the form of the model. In this approach, the joint distribution of all variables is described by only the most systematic variable interactions, thereby limiting the number of parameters to be estimated, supporting computational efficiency, and providing an understanding of the data. Further, different types of variables, such as class-based and collocation-specific ones, c"
P94-1020,H94-1048,0,0.00917875,"se tags of an ambiguous word. The tree construction process used by Black partitions the data according to the values of one contextual feature before considering the values of the next, thereby treating all features incorporated in the tree as interdependent. The method presented here for using information from multiple contextual features is more flexible and makes better use of a small data set by eliminating the need to treat all features as interdependent. The work that bears the closest resemblance to the work presented here is the maximum entropy approach to developing language models ([24], [25], [19] and [20]). Conclusions and Future Work • In this paper, we presented a method for formulating probabilistic models that use multiple contextual features for word-sense disambiguation without requiring untested assumptions regarding the form of the model. In this approach, the joint distribution of all variables is described by only the most systematic variable interactions, thereby limiting the number of parameters to be estimated, supporting computational efficiency, and providing an understanding of the data. Further, different types of variables, such as class-based and colloca"
P94-1020,H94-1013,0,0.00691599,"s of an ambiguous word. The tree construction process used by Black partitions the data according to the values of one contextual feature before considering the values of the next, thereby treating all features incorporated in the tree as interdependent. The method presented here for using information from multiple contextual features is more flexible and makes better use of a small data set by eliminating the need to treat all features as interdependent. The work that bears the closest resemblance to the work presented here is the maximum entropy approach to developing language models ([24], [25], [19] and [20]). Conclusions and Future Work • In this paper, we presented a method for formulating probabilistic models that use multiple contextual features for word-sense disambiguation without requiring untested assumptions regarding the form of the model. In this approach, the joint distribution of all variables is described by only the most systematic variable interactions, thereby limiting the number of parameters to be estimated, supporting computational efficiency, and providing an understanding of the data. Further, different types of variables, such as class-based and collocation-s"
P94-1020,C92-2070,0,0.680462,"model will appear to be too good, indicating that the model is in fact over constrained for the data available. In this work, we have limited ourselves to considering only those models with sufficient statistics that are not sparse, where the significance of the reference X 2 is not unreasonable; most such models have sufficient statistics that are lower-order marginal distributions. In the future, we will investigate other goodness-of-fit tests ([18], [1], [22]) that are perhaps more appropriate for sparse data. The Experiment Unlike several previous approaches to word sense disambiguation ([29], [5], [7], [10]), nothing in this approach limits the selection of sense tags to a particular number or type of meaning distinctions. In this study, our goal was to address a non-trivial case of ambiguity, but one that would allow some comparison of results with previous work. As a result of these considerations, the word interest was chosen as a test case, and the six non-idiomatic noun senses of interest defined in LDOCE were selected as the tag set. The only restriction limiting the choice of corpus is the need for large amounts of on-line data. Due to availability, the Penn Treebank Wall"
P94-1020,H93-1052,0,\N,Missing
P94-1020,P91-1034,0,\N,Missing
P99-1032,W98-1507,1,0.664278,"~Department of C o m p u t e r Science University of North Carolina at Asheville Asheville, NC 28804-8511 wiebe, tomohara@cs, nmsu. edu, bruce@cs, unca. edu Abstract This paper presents a case study of analyzing and improving intercoder reliability in discourse tagging using statistical techniques. Biascorrected tags are formulated and successfully used to guide a revision of the coding manual and develop an automatic classifier. 1 Introduction This paper presents a case study of analyzing and improving intercoder reliability in discourse tagging using the statistical techniques presented in (Bruce and Wiebe, 1998; Bruce and Wiebe, to appear). Our approach is data driven: we refine our understanding and presentation of the classification scheme guided by the results of the intercoder analysis. We also present the results of a probabilistic classifier developed on the resulting annotations. Much research in discourse processing has focused on task-oriented and instructional dialogs. The task addressed here comes to the fore in other genres, especially news reporting. The task is to distinguish sentences used to objectively present factual information from sentences used to present opinions and evaluatio"
P99-1032,J99-2002,1,0.433371,"he two-category latent class model produces the most consistent clusters across the d a t a configurations. Thus, it is used to define the bias-corrected tags for the second data set as well. 5 Machine Learning Results Recently, there have been many successful applications of machine learning to discourse processing, such as (Litman, 1996; Samuel et al., 1998). In this section, we report the results of machine learning experiments, in which we develop probablistic classifiers to automatically perform the subjective and objective classification. In the method we use for developing classifters (Bruce and Wiebe, 1999), a search is performed to find a probability model that captures important interdependencies among features. Because features can be dropped and added during search, the method also performs feature selection. In these experiments, the system considers naive Bayes, full independence, full interdependence, and models generated from those using forward and backward search. The model selected is the one with the highest accuracy on a held-out portion of the training data. 10-fold cross validation is performed. The data is partitioned randomly into 10 different SFor the analysis in Table 3, certa"
P99-1032,J96-2004,0,0.174701,"ent factual information from sentences used to present opinions and evaluations. There are many applications for which this distinction promises to be important, including text categorization and summarization. This research takes a large step toward developing a reliably annotated gold standard to support experimenting with such applications. This research is also a case study of analyzing and improving manual tagging that is applicable to any tagging task. We perform a statistical analysis that provides information that complements the information provided by 246 Cohen's Kappa (Cohen, 1960; Carletta, 1996). In particular, we analyze patterns of agreement to identify systematic disagreements that result from relative bias among judges, because they can potentially be corrected automatically. The corrected tags serve two purposes in this work. They are used to guide the revision of the coding manual, resulting in improved Kappa scores, and they serve as a gold standard for developing a probabilistic classifier. Using bias-corrected tags as gold-standard tags is one way to define a single best tag when there are multiple judges who disagree. The coding manual and data from our experiments are avai"
P99-1032,J93-1003,0,0.0141586,"e judges' observations. The remainder of this section describes these models in more detail. All models can be evaluated using the freeware package CoCo, which 248 was developed by Badsberg (1995) and is available at: http://web.math.auc.dk/-jhb/CoCo. 3.1 P a t t e r n s of D i s a g r e e m e n t A probability model enforces constraints on the counts in the data. The degree to which the counts in the data conform to the constraints is called the fit of the model. In this work, model fit is reported in terms of the likelihood ratio statistic, G 2, and its significance (Read and Cressie, 1988; Dunning, 1993). The higher the G 2 value, the poorer the fit. We will consider model fit to be acceptable if its reference significance level is greater than 0.01 (i.e., if there is greater than a 0.01 probability that the data sample was randomly selected from a population described by the model). Bias of one judge relative to another is evidenced as a discrepancy between the marginal totals for the two judges (i.e., ni+ and n+j in Table 1). Bias is measured by testing the fit of the model for marginal homogeneity: ~i+ = P+i for all i. The larger the G 2 value, the greater the bias. The fit of the model ca"
P99-1032,P97-1023,0,0.229594,"Missing"
P99-1032,W98-1123,0,0.0111655,"the bias-corrected tags (in section 3), the case study of improving intercoder agreement (in section 4), and the results of the classifter for automatic subjectivity tagging (in section 5). 2 T h e Subjective a n d Objective Categories We address evidentiality in text (Chafe, 1986), which concerns issues such as what is the source of information, and whether information is being presented as fact or opinion. These questions are particularly important in news reporting, in which segments presenting opinions and verbal reactions are mixed with segments presenting objective fact (van Dijk, 1988; Kan et al., 1998). The definitions of the categories in our coding manual are intention-based: ""If the primary intention of a sentence is objective presentation of material that is factual to the reporter, the sentence is objective. Otherwise, the sentence is subjective."" 1 We focus on sentences about private states, such as belief, knowledge, emotions, etc. (Quirk et al., 1985), and sentences about speech events, such as speaking and writing. Such sentences may be either subjective or objective. From the coding manual: ""Subjective speech-event (and private-state) sentences are used to communicate the speaker'"
P99-1032,J93-2004,0,0.0513326,"arguing for his or her own tag in some cases. Based on the judges' feedback, 22 of the 504 bias-corrected tags are changed, and a second draft of the coding manual is written. 5. A second corpus is annotated by the same four judges according to the new coding manual. Each spends about five hours. 6. The results of the second tagging experiment are analyzed using the methods described in section 3, and bias-corrected tags are produced for the second data set. Two disjoint corpora are used in steps 2 and 5, both consisting of complete articles taken from the Wall Street Journal Treebank Corpus (Marcus et al., 1993). In both corpora, judges assign tags to each non-compound sentence and to each conjunct of each compound sentence, 504 in the first corpus and 500 in the second. The segmentation of compound sentences was performed manually before the judges received the data. Judges J and B, the first two authors of this paper, are NLP researchers. Judge M is an undergraduate computer science student, and judge D has no background in computer science or linguistics. Judge J, with help from M, developed the original coding instructions, and Judge J directed the process in step 4. The analysis performed in ste"
P99-1032,P98-2188,0,0.00896436,"n step 6, as in step 3, there is strong evidence of relative bias among judges D, J and M. Each pairwise comparison of judges also shows a strong pattern of symmetric disagreement. The results of this analysis are presented in Table 3. 3 Also as in step 3, the two-category latent class model produces the most consistent clusters across the d a t a configurations. Thus, it is used to define the bias-corrected tags for the second data set as well. 5 Machine Learning Results Recently, there have been many successful applications of machine learning to discourse processing, such as (Litman, 1996; Samuel et al., 1998). In this section, we report the results of machine learning experiments, in which we develop probablistic classifiers to automatically perform the subjective and objective classification. In the method we use for developing classifters (Bruce and Wiebe, 1999), a search is performed to find a probability model that captures important interdependencies among features. Because features can be dropped and added during search, the method also performs feature selection. In these experiments, the system considers naive Bayes, full independence, full interdependence, and models generated from those"
P99-1032,W98-1126,1,0.586667,"Missing"
P99-1032,J94-2004,1,0.217425,"Freedom Now"" was ""undesirable for broadcasting."" Subjective speech-event sentence. In sentence 4, there is no uncertainty or evaluation expressed toward the speaking event. Thus, from one point of view, one might have considered this sentence to be objective. However, the object of the sentence is not presented as material that is factual to the reporter, so the sentence is classified as subjective. Linguistic categorizations usually do not cover all instances perfectly. For example, sen1The category specifications in the coding manual axe based on our previous work on tracking point of view (Wiebe, 1994), which builds on Banfield's (1982) linguistic theory of subjectivity. 247 tences may fall on the borderline between two categories. To allow for uncertainty in the annotation process, the specific tags used in this work include certainty ratings, ranging from 0, for least certain, to 3, for most certain. As discussed below in section 3.2, the certainty ratings allow us to investigate whether a model positing additional categories provides a better description of the judges' annotations than a binary model does. Subjective and objective categories are potentially important for many text proces"
P99-1032,C98-2183,0,\N,Missing
ruppenhofer-etal-2008-finding,E06-1025,0,\N,Missing
ruppenhofer-etal-2008-finding,N07-1037,0,\N,Missing
ruppenhofer-etal-2008-finding,W05-0308,1,\N,Missing
ruppenhofer-etal-2008-finding,W06-0305,0,\N,Missing
ruppenhofer-etal-2008-finding,W06-0301,0,\N,Missing
ruppenhofer-etal-2008-finding,H05-2017,0,\N,Missing
ruppenhofer-etal-2008-finding,H05-1043,0,\N,Missing
ruppenhofer-etal-2008-finding,W03-1014,1,\N,Missing
ruppenhofer-etal-2008-finding,W06-1651,0,\N,Missing
ruppenhofer-etal-2008-finding,P04-1035,0,\N,Missing
ruppenhofer-etal-2008-finding,P98-1013,0,\N,Missing
ruppenhofer-etal-2008-finding,C98-1013,0,\N,Missing
ruppenhofer-etal-2008-finding,N07-1039,0,\N,Missing
ruppenhofer-etal-2008-finding,P02-1053,0,\N,Missing
ruppenhofer-etal-2008-finding,J05-1004,0,\N,Missing
ruppenhofer-etal-2008-finding,P97-1023,0,\N,Missing
ruppenhofer-etal-2008-finding,andreevskaia-bergler-2006-semantic,0,\N,Missing
S14-2010,S14-2085,0,0.0392393,"Missing"
S14-2010,S14-2069,0,0.0326403,"Missing"
S14-2010,S14-2128,0,0.0328229,"Missing"
S14-2010,P13-1024,1,0.0618966,"data set is a subset of the PASCAL VOC-2008 data set (Rashtchian et al., 2010), which consists of 1,000 images and has been used by a number of image description systems. It was also sampled from string similarity values between 0.6 and 1. Deft-forum and Deft-news are from DEFT data.2 Deft-forum contains the forum post sentences, and Deft-news are news summaries. We selected 450 pairs for Deft-forum and 300 pairs for Deft-news. They are sampled evenly from string similarities falling in the interval 0.6 to 1. The Tweets data set contains tweet-news pairs selected from the corpus released in (Guo et al., 2013), where each pair contains a sentence that pertains to the news title, while the other one represents a Twitter comment on that particular news. They are evenly sampled from string similarity values between 0.5 and 1. Table 1 shows the explanations and values associated with each score between 5 and 0. As in prior years, we used Amazon Mechanical Turk (AMT)3 to crowdsource the annotation of the English pairs.4 Annotators are presented with the Table 2: English subtask: Summary of train (2012 and 2013) and test (2014) datasets. a DARPA sponsored workshop at Columbia University.1 In 2013, STS wa"
S14-2010,S14-2112,0,0.0317369,"Missing"
S14-2010,N06-2015,0,0.0715746,"ferent similarity ranges, hence we built two sets of headline pairs: (i) a set where the pairs come from the same EMM cluster, (ii) and another set where the headlines come from a different EMM cluster, then we computed the string similarity between those pairs. Accordingly, we sampled 375 headline pairs of headlines that occur in the same EMM cluster, aiming for pairs equally distributed between minimal and maximal similarity using simple string similarity. We sampled other 375 pairs from the different EMM cluster in the same manner. For OnWN, we used the sense definition pairs of OntoNotes (Hovy et al., 2006) and WordNet (Fellbaum, 1998). Different from previous tasks, the two definition sentences in a pair belong to different senses. We sampled 750 pairs based on a string similarity ranging from 0.5 to 1. The Images data set is a subset of the PASCAL VOC-2008 data set (Rashtchian et al., 2010), which consists of 1,000 images and has been used by a number of image description systems. It was also sampled from string similarity values between 0.6 and 1. Deft-forum and Deft-news are from DEFT data.2 Deft-forum contains the forum post sentences, and Deft-news are news summaries. We selected 450 pairs"
S14-2010,S12-1051,1,0.623306,"r as both tasks have been defined to date in the literature) in that, rather than being a binary yes/no decision (e.g. a vehicle is not a car), we define STS to be a graded similarity notion (e.g. a vehicle and a car are more similar than a wave and a car). A quantifiable graded bidirectional notion of textual similarity is useful for a myriad of NLP tasks such as MT evaluation, information extraction, question answering, summarization, etc. In 2012 we held the first pilot task at SemEval 2012, as part of the *SEM 2012 conference, with great success: 35 teams participated with 88 system runs (Agirre et al., 2012). In addition, we held In Semantic Textual Similarity, systems rate the degree of semantic equivalence between two text snippets. This year, the participants were challenged with new data sets for English, as well as the introduction of Spanish, as a new language in which to assess semantic similarity. For the English subtask, we exposed the systems to a diversity of testing scenarios, by preparing additional OntoNotesWordNet sense mappings and news headlines, as well as introducing new genres, including image descriptions, DEFT discussion forums, DEFT newswire, and tweet-newswire headline map"
S14-2010,S14-2131,0,0.0336314,"Missing"
S14-2010,S14-2072,0,0.0817436,"Missing"
S14-2010,Q14-1018,0,0.0731,"Missing"
S14-2010,S14-2039,0,0.0993932,"Missing"
S14-2010,S14-2078,0,0.101731,"Missing"
S14-2010,S14-2022,0,0.0306687,"Missing"
S14-2010,S14-2046,0,0.022257,"Missing"
S14-2010,D13-1179,0,0.0175763,"Missing"
S14-2010,S12-1060,0,0.0199826,"Missing"
S14-2010,S14-2093,0,0.0281526,"Missing"
S14-2010,W10-0721,0,0.050451,"d 375 headline pairs of headlines that occur in the same EMM cluster, aiming for pairs equally distributed between minimal and maximal similarity using simple string similarity. We sampled other 375 pairs from the different EMM cluster in the same manner. For OnWN, we used the sense definition pairs of OntoNotes (Hovy et al., 2006) and WordNet (Fellbaum, 1998). Different from previous tasks, the two definition sentences in a pair belong to different senses. We sampled 750 pairs based on a string similarity ranging from 0.5 to 1. The Images data set is a subset of the PASCAL VOC-2008 data set (Rashtchian et al., 2010), which consists of 1,000 images and has been used by a number of image description systems. It was also sampled from string similarity values between 0.6 and 1. Deft-forum and Deft-news are from DEFT data.2 Deft-forum contains the forum post sentences, and Deft-news are news summaries. We selected 450 pairs for Deft-forum and 300 pairs for Deft-news. They are sampled evenly from string similarities falling in the interval 0.6 to 1. The Tweets data set contains tweet-news pairs selected from the corpus released in (Guo et al., 2013), where each pair contains a sentence that pertains to the new"
S14-2010,W10-0707,0,\N,Missing
S14-2010,P94-1019,0,\N,Missing
S14-2010,Q14-1017,0,\N,Missing
S14-2010,S14-2138,0,\N,Missing
S14-2098,O97-1002,0,0.055036,"Abstract 2 Related Work Over the past years, the research community has focused on computing semantic relatedness using methods that are either knowledge-based or corpus-based. Knowledge-based methods derive a measure of relatedness by utilizing lexical resources and ontologies such as WordNet (Miller, 1995) or Roget (Rog, 1995) to measure definitional overlap, term distance within a graphical taxonomy, or term depth in the taxonomy as a measure of specificity. There are many knowledge-based measures that were proposed in the past, e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Resnik, 1995; Jiang and Conrath, 1997; Lin, 1998; Jarmasz and Szpakowicz, 2003; Hughes and Ramage, 2007). On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer and Dumais, 1997), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. T"
S14-2098,S12-1051,0,0.0213281,"l language processing applications, such as information retrieval (Salton and Lesk, 1971), relevance feedback and text classification (Rocchio, 1971), word sense disambiguation (Lesk, 1986; Schutze, 1998), summarization (Salton et al., 1997; Lin and Hovy, 2003), automatic evaluation of machine translation (Papineni et al., 2002), plagiarism detection (Nawab et al., 2011), and more. To date, semantic similarity research has primarily focused on comparing text snippets of similar length (see the semantic textual similarity tasks organized during *Sem 2013 (Agirre et al., 2013) and SemEval 2012 (Agirre et al., 2012)). Yet, as new challenges emerge, such as augmenting a knowledge-base with textual evidence, assessing similarity across different context granularities is gaining traction. The SemEval Cross-level semantic similarity task is aimed at this latter scenario, and is described in more details in the task paper (Jurgens et al., 2014). 3 ∗ {carmennb,chenditc,mihalcea}@umich.edu This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 3.1 System De"
S14-2098,S14-2003,0,0.0210175,"), plagiarism detection (Nawab et al., 2011), and more. To date, semantic similarity research has primarily focused on comparing text snippets of similar length (see the semantic textual similarity tasks organized during *Sem 2013 (Agirre et al., 2013) and SemEval 2012 (Agirre et al., 2012)). Yet, as new challenges emerge, such as augmenting a knowledge-base with textual evidence, assessing similarity across different context granularities is gaining traction. The SemEval Cross-level semantic similarity task is aimed at this latter scenario, and is described in more details in the task paper (Jurgens et al., 2014). 3 ∗ {carmennb,chenditc,mihalcea}@umich.edu This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 3.1 System Description Generic Features Our system employs both knowledge and corpusbased measures as detailed below. 560 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 560–565, Dublin, Ireland, August 23-24, 2014. Knowledge-based features Knowledge-based metrics were shown to provide high correlat"
S14-2098,P13-4021,0,0.0236756,"Missing"
S14-2098,N03-1020,0,0.0569777,"ovel corpusbased measures based on deep learning paradigms, paired with varying degrees of context expansion. The framework enabled us to reach the highest overall performance among all competing systems. 1 Janyce Wiebe University of Pittsburgh Pittsburgh, PA Introduction Semantic textual similarity is one of the key components behind a multitude of natural language processing applications, such as information retrieval (Salton and Lesk, 1971), relevance feedback and text classification (Rocchio, 1971), word sense disambiguation (Lesk, 1986; Schutze, 1998), summarization (Salton et al., 1997; Lin and Hovy, 2003), automatic evaluation of machine translation (Papineni et al., 2002), plagiarism detection (Nawab et al., 2011), and more. To date, semantic similarity research has primarily focused on comparing text snippets of similar length (see the semantic textual similarity tasks organized during *Sem 2013 (Agirre et al., 2013) and SemEval 2012 (Agirre et al., 2012)). Yet, as new challenges emerge, such as augmenting a knowledge-base with textual evidence, assessing similarity across different context granularities is gaining traction. The SemEval Cross-level semantic similarity task is aimed at this l"
S14-2098,J90-1003,0,0.0840197,"rm distance within a graphical taxonomy, or term depth in the taxonomy as a measure of specificity. There are many knowledge-based measures that were proposed in the past, e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Resnik, 1995; Jiang and Conrath, 1997; Lin, 1998; Jarmasz and Szpakowicz, 2003; Hughes and Ramage, 2007). On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer and Dumais, 1997), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words. Unlike knowledge-based methods, which suffer from limited coverage, corpus-based measures are able to induce the similarity between any two words, as long as they appear in the corpus used for training. This article pres"
S14-2098,D07-1061,0,0.00911978,"ty has focused on computing semantic relatedness using methods that are either knowledge-based or corpus-based. Knowledge-based methods derive a measure of relatedness by utilizing lexical resources and ontologies such as WordNet (Miller, 1995) or Roget (Rog, 1995) to measure definitional overlap, term distance within a graphical taxonomy, or term depth in the taxonomy as a measure of specificity. There are many knowledge-based measures that were proposed in the past, e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Resnik, 1995; Jiang and Conrath, 1997; Lin, 1998; Jarmasz and Szpakowicz, 2003; Hughes and Ramage, 2007). On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer and Dumais, 1997), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual inf"
S14-2098,N13-1090,0,0.00492088,"and obtain metrics W T V 1 (by applying Align) and W T V 2 (using VectorSum). paragraph2sentence. At this level, due to the long context that entails one-to-many mappings between the words in the sentence and those in the paragraph, we use a text clustering technique prior to calculating the features’ weights. Corpus based features Our corpus based features are derived from a deep learning vector space model that is able to “understand” word meaning without human input. Distributed word embeddings are learned using a skip-gram recurrent neural net architecture running over a large raw corpus (Mikolov et al., 2013b; Mikolov et al., 2013a). A primary advantage of such a model is that, by breaking away from the typical n-gram model that sees individual units with no relationship to each other, it is able to generalize and produce word vectors that are similar for related words, thus encoding linguistic regularities and patterns (Mikolov et al., 2013b). For example, vec(Madrid)-vec(Spain)+vec(France) is closer to vec(Paris) than any other word vector (Mikolov et al., 2013a). We used the pretrained Google News word2vec model (W T V ) built over a 100 billion words corpus, and containing 3 million 300-dimen"
S14-2098,islam-inkpen-2006-second,0,0.0105473,"nomy as a measure of specificity. There are many knowledge-based measures that were proposed in the past, e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Resnik, 1995; Jiang and Conrath, 1997; Lin, 1998; Jarmasz and Szpakowicz, 2003; Hughes and Ramage, 2007). On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer and Dumais, 1997), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words. Unlike knowledge-based methods, which suffer from limited coverage, corpus-based measures are able to induce the similarity between any two words, as long as they appear in the corpus used for training. This article presents our team’s participating system at SemEval-2014 Task 3. Using"
S14-2098,P02-1040,0,0.0914881,"with varying degrees of context expansion. The framework enabled us to reach the highest overall performance among all competing systems. 1 Janyce Wiebe University of Pittsburgh Pittsburgh, PA Introduction Semantic textual similarity is one of the key components behind a multitude of natural language processing applications, such as information retrieval (Salton and Lesk, 1971), relevance feedback and text classification (Rocchio, 1971), word sense disambiguation (Lesk, 1986; Schutze, 1998), summarization (Salton et al., 1997; Lin and Hovy, 2003), automatic evaluation of machine translation (Papineni et al., 2002), plagiarism detection (Nawab et al., 2011), and more. To date, semantic similarity research has primarily focused on comparing text snippets of similar length (see the semantic textual similarity tasks organized during *Sem 2013 (Agirre et al., 2013) and SemEval 2012 (Agirre et al., 2012)). Yet, as new challenges emerge, such as augmenting a knowledge-base with textual evidence, assessing similarity across different context granularities is gaining traction. The SemEval Cross-level semantic similarity task is aimed at this latter scenario, and is described in more details in the task paper (J"
S14-2098,J98-1004,0,0.0351393,"ith traditional knowledgebased metrics, as well as novel corpusbased measures based on deep learning paradigms, paired with varying degrees of context expansion. The framework enabled us to reach the highest overall performance among all competing systems. 1 Janyce Wiebe University of Pittsburgh Pittsburgh, PA Introduction Semantic textual similarity is one of the key components behind a multitude of natural language processing applications, such as information retrieval (Salton and Lesk, 1971), relevance feedback and text classification (Rocchio, 1971), word sense disambiguation (Lesk, 1986; Schutze, 1998), summarization (Salton et al., 1997; Lin and Hovy, 2003), automatic evaluation of machine translation (Papineni et al., 2002), plagiarism detection (Nawab et al., 2011), and more. To date, semantic similarity research has primarily focused on comparing text snippets of similar length (see the semantic textual similarity tasks organized during *Sem 2013 (Agirre et al., 2013) and SemEval 2012 (Agirre et al., 2012)). Yet, as new challenges emerge, such as augmenting a knowledge-base with textual evidence, assessing similarity across different context granularities is gaining traction. The SemEva"
S14-2098,S13-1004,0,\N,Missing
S15-1009,P98-1013,0,0.149614,"the syntactic head of the text passage describing the proposition). We do not propose to develop our own semantic representation, but instead we will look to using existing relation and event representations based on the ACE program (Doddington et al., 2004). These have the advantage that there are offthe-shelf computational tools available for detecting ACE relations and events; they have the disadvantage that they do not cover all propositions we may be interested in. An alternative would be the use of a shallower semantic representation such as PropBank (Kingsbury et al., 2002), FrameNet (Baker et al., 1998), or AMR (Banarescu et al., 2013). 7.3 Entities as Targets In Section 6, we discussed an initial evaluation of a belief being about an entity. In this section we discuss further guidelines for identifying belief targets, i.e., when one can say that someone’s belief is about 89 a certain entity. In general, the notion of belief “aboutness” is fairly fuzzy and it may be difficult to circumscribe precisely without some additional constraints. Suppose then that one of the ultimate objectives of belief extraction is to populate a knowledge base with beliefs held about specific entities: individuals"
S15-1009,baker-etal-2010-modality,0,0.0482113,"Missing"
S15-1009,W13-2322,0,0.0158937,"xt passage describing the proposition). We do not propose to develop our own semantic representation, but instead we will look to using existing relation and event representations based on the ACE program (Doddington et al., 2004). These have the advantage that there are offthe-shelf computational tools available for detecting ACE relations and events; they have the disadvantage that they do not cover all propositions we may be interested in. An alternative would be the use of a shallower semantic representation such as PropBank (Kingsbury et al., 2002), FrameNet (Baker et al., 1998), or AMR (Banarescu et al., 2013). 7.3 Entities as Targets In Section 6, we discussed an initial evaluation of a belief being about an entity. In this section we discuss further guidelines for identifying belief targets, i.e., when one can say that someone’s belief is about 89 a certain entity. In general, the notion of belief “aboutness” is fairly fuzzy and it may be difficult to circumscribe precisely without some additional constraints. Suppose then that one of the ultimate objectives of belief extraction is to populate a knowledge base with beliefs held about specific entities: individuals, groups, artifacts, etc., which"
S15-1009,W09-3012,1,0.690346,"space we do not provide an overview over all definitions. While at first the terms “belief” and “factuality” appear to relate to rather different things (a subjective state versus truth), in the NLP community they in fact refer to the same phenomenon, while having rather different connotations. The phenomenon is the communicative intention of a writer1 to present propositional content as something that she firmly believes is true, weakly believes is true, or has some other attitude towards, namely a wish or a reported belief. The term “belief” here describes the cognitive state of the writer (Diab et al., 2009), and comes from artificial intelligence and cognitive science, as in the Belief-Desire-Intention model of Bratman (1999 1987). The term “factuality” describes the communicative intention of the writer (Saur´ı and Pustejovsky, 2012, p. 263) (our emphasis): The fact that an eventuality is depicted as holding or not does not mean that this is the case in the world, but that this is how it is characterized by its informant. Similarly, it does not mean that this is the real knowledge that informant has (his true cognitive state regarding that event) but what he wants us to believe it is. We would"
S15-1009,doddington-etal-2004-automatic,1,0.834711,"sity/George Washington University, the Florida Institute for Human and Machine Cognition, and the University of Albany. The goal of our research project is not linguistic annotation, but the identification of meaning which is expressed in a non-linguistic manner. Such a meaning representation is useful for many applications; in our project we are specifically interested in knowledge base population. A different part of the DEFT program is concerned with the representation of propositional meaning, following the tradition of the ACE program in representing entities, relations and events (ERE) (Doddington et al., 2004). The work presented here is concerned with the attitude of agents towards propositional content: do the agents express a committed belief or a non-committed belief in the propositional content? Our work has several characteristics that set it apart from other work: we are interested in annotation which can be done fairly quickly; we are not interested in annotating linguistic elements (such as trigger words); and we are planning an integration with sentiment annotation. The structure of the paper is as follows: we start out by situating our notion of “belief” with respect to other notions of"
S15-1009,W10-3001,0,0.293703,"Missing"
S15-1009,P11-2102,0,0.0364363,"rotates around the earth, as was his (presumably) honest communicative intention. Therefore, to us as researchers interested in describing how language 2 Sarcasm and irony differ from lying in that the communicative intention and the cognitive state are aligned, but they do not align with the standard interpretation of the utterance. Here, the intention is that the reader recognizes that the form of the utterance does not literally express the cognitive state. We leave aside sarcasm and irony in this paper; for current computational work on sarcasm detection, see for example (Gonz´alez-Ib´an˜ ez et al., 2011). is used to communicate, it does not matter that astronomers now believe that Ptolemy was wrong, it does not change our account of communication and it does not change the communication that happened two millennia ago. And since we do not need to make the assumption that the writer knows what she is talking about, we choose not to make this assumption. In the case of Ptolemy, we leave this determination – what is actually true – to astronomers. In other cases, we typically have models of trustworthiness: if a writer sends her spouse a text message saying she is hungry, the spouse has no reaso"
S15-1009,P09-2078,0,0.0256017,"d, we could assume that the writer knows what is true (assumption of truth). In this paper, we do not make this second assumption. We discuss these two assumptions in turn. We start with the assumption of truthfulness. In the quote above, Saur´ı and Pustejovsky (2012) (apart from distinguishing factuality from truth) also make the point that the writer’s communicative intention of making the reader believe she has a specific belief state does not mean that she actually has that cognitive state, since she may be lying. Lying is clearly an important phenomenon that researchers have looked into (Mihalcea and Strapparava, 2009; Ott et al., 2011).2 However, we (as linguists interested in understanding how language enables communication) feel that assuming the writer is truthful is a standard assumption about communication which we should in general make. This is because if we do not make this assumption, we cannot explain why communication is possible at all, since discourse participants would have no motivation to ever adopt another discourse participant’s belief as their own. We therefore do claim that we can infer belief from utterances, while assuming that the writer is not lying, and knowing that this assumptio"
S15-1009,P11-1032,0,0.0145471,"er knows what is true (assumption of truth). In this paper, we do not make this second assumption. We discuss these two assumptions in turn. We start with the assumption of truthfulness. In the quote above, Saur´ı and Pustejovsky (2012) (apart from distinguishing factuality from truth) also make the point that the writer’s communicative intention of making the reader believe she has a specific belief state does not mean that she actually has that cognitive state, since she may be lying. Lying is clearly an important phenomenon that researchers have looked into (Mihalcea and Strapparava, 2009; Ott et al., 2011).2 However, we (as linguists interested in understanding how language enables communication) feel that assuming the writer is truthful is a standard assumption about communication which we should in general make. This is because if we do not make this assumption, we cannot explain why communication is possible at all, since discourse participants would have no motivation to ever adopt another discourse participant’s belief as their own. We therefore do claim that we can infer belief from utterances, while assuming that the writer is not lying, and knowing that this assumption may be false in c"
S15-1009,C10-2117,1,0.747479,"on-committed belief in the annotations, the heuristic rules (mainly based on the presence of modal auxiliaries) that we added for the purpose of classifying the beliefs (CB, NCB, ROB, NA) did not work reliably in all cases. 4.3 System C System C uses a supervised learning approach to identify tokens denoting the heads of propositions that denote author’s expressed beliefs. It approaches this problem as a 5-way (CB, NCB, ROB, NA, nil) multi-class classification task at the word level. System C is adapted from a previous system which uses an earlier, simpler definition and annotation of belief (Prabhakaran et al., 2010). The system uses lexical and syntactic features for this task, which are extracted using the part-of-speech tags and dependency parses obtained from the Stanford CoreNLP system. In addition to the features described in (Prabhakaran et al., 2010), System C uses a set of new features including features based on a dictionary of hedge-words (Prokofieva and Hirschberg, 2014). The hedge features improved the NCB Fmeasure by around 2.2 percentage points (an overall F-measure improvement of 0.25 percentage points) in experiments conducted on a separate development set. It uses a quadratic kernel SVM"
S15-1009,W12-3807,1,0.915772,"Missing"
S15-1009,J12-2002,0,0.157236,"Missing"
S15-1009,W15-1304,1,0.70443,"ore, the FactBank annotation is basically compatible with ours. Our annotation is much simpler than that of FactBank in order to allow for a quicker annotation. We summarize the main points of simplification here. • We have taken the source always to be the writer. As we will discuss in Section 7.1, we will adopt the FactBank annotation in the next iteration of our annotation. • We do not distinguish between possible and probable; this distinction may be hard to annotate and not too valuable. • We ignore negation. If present, we simply assume it is part of the proposition which is the target. Werner et al. (2015) study the relation between belief and factuality in more detail. They provide an automatic way of mapping the annotations in FactBank to the 4-way distinction of speaker/writer’s belief that we present in this paper. 3.3 Corpus and Annotation Results The annotation effort for this phase of belief annotation for DEFT produced a training corpus of 852,836 words and an evaluation corpus of 100,037 words. All annotated data consisted of English text from discussion forum threads. The discussion forum threads were originally collected for the DARPA BOLT program, and were harvested from a wide vari"
S15-1009,C98-1013,0,\N,Missing
S15-2045,agerri-etal-2014-ixa,1,0.57453,"onal and knowledge-based similarity are widely used, and also syntactic analysis and named entity recognition. Most teams add a machine learning algorithm to learn the output scores, but note that Samsung team did not use it in their best run. 4 3.6 The baseline system used for the interpretable subtask consists of a cascade concatenation of several procedures. First, we undertake a brief NLP step in which input sentences are tokenized using simple regular expressions. Additionally, this step collects chunk regions coming either from gold standard or from the chunking done by ixa-pipes-chunk (Agerri et al., 2014). This is followed by a lowercased token aligning phase, which consists of aligning (or linking) identical tokens across the input sentences. Then we use chunk boundaries as token regions to group individual tokens into groups, and compute all links across groups. The weight of the link across groups is proportional to the number of links counted between within-group tokens. The next phase consists of an optimization step in which groups x,y that have the highest link weight are identified, as well as the chunks that are linked to either x or y but not with a maximum alignment weight (thus ena"
S15-2045,S12-1051,1,0.519741,"TS also differs from both TE and paraphrasing (in as far as both tasks have been defined to date in the literature) in that rather than being a binary yes/no decision (e.g. a vehicle is not a car), we define STS to be a graded similarity notion (e.g. a vehicle and a car are more similar than a wave and a car). A quantifiable graded bidirectional notion of textual similarity is useful for many NLP tasks such as MT evaluation, information extraction, question answering, summarization. In 2012, we held the first pilot task at SemEval 2012, as part of the *SEM 2012 conference, with great success (Agirre et al., 2012). In addition, we 252 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 252–263, c Denver, Colorado, June 4-5, 2015. 2015 Association for Computational Linguistics held a DARPA sponsored workshop at Columbia University.1 In 2013, STS was selected as the official shared task of the *SEM 2013 conference, with two subtasks: a core task, which was similar to the 2012 task, and a pilot task on typed-similarity between semi-structured records. In 2014, new datasets including new genres were used, and we expanded the evaluations to address sentence similarity"
S15-2045,S14-2010,1,0.800447,"f the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 252–263, c Denver, Colorado, June 4-5, 2015. 2015 Association for Computational Linguistics held a DARPA sponsored workshop at Columbia University.1 In 2013, STS was selected as the official shared task of the *SEM 2013 conference, with two subtasks: a core task, which was similar to the 2012 task, and a pilot task on typed-similarity between semi-structured records. In 2014, new datasets including new genres were used, and we expanded the evaluations to address sentence similarity in a new language, namely Spanish (Agirre et al., 2014). This year we presented three subtasks: the English subtask, the Spanish subtask and the interpretable pilot subtask. The English subtask comprised pairs from headlines and image descriptions, and it also introduced new genres, including answer pairs from a tutorial dialogue system and from Q&A websites, and pairs from a dataset tagged with committed belief annotations. For the Spanish subtask, additional pairs from news and Wikipedia articles were selected. The annotations for both tasks leveraged crowdsourcing. Finally, with the interpretable STS pilot subtask, we wanted to start exploring"
S15-2045,P14-1023,0,0.0115737,"7070 0.7251 0.7311 0.7250 0.7422 0.6364 0.7775 0.7032 0.7130 0.7189 0.4616 0.7533 0.6111 0.5379 0.5424 0.5672 0.6558 0.4919 0.5912 0.6964 0.7114 0.6364 Table 3: Task 2a: English evaluation results in terms of Pearson correlation. 259 Rank 61 42 29 63 56 57 70 69 71 62 44 49 43 74 72 73 34 28 26 1 3 5 19 18 16 8 9 2 12 13 23 41 59 20 47 22 11 15 33 45 55 24 10 17 50 51 52 4 7 6 46 36 27 39 31 30 32 25 53 14 40 37 35 68 21 58 66 65 64 48 67 60 42 38 54 approach for the top three participants (DLS@CU, ExBThemis, Samsung). They use WordNet (Miller, 1995), Mikolov Embeddings (Mikolov et al., 2013; Baroni et al., 2014) and PPDB (Ganitkevitch et al., 2013). In general, generic NLP tools such as lemmatization, PoS tagging, distributional word embeddings, distributional and knowledge-based similarity are widely used, and also syntactic analysis and named entity recognition. Most teams add a machine learning algorithm to learn the output scores, but note that Samsung team did not use it in their best run. 4 3.6 The baseline system used for the interpretable subtask consists of a cascade concatenation of several procedures. First, we undertake a brief NLP step in which input sentences are tokenized using simple"
S15-2045,N13-1092,0,0.0796576,"the mentioned works, we first identified the segments (chunks in our case) in each sentence separately, and then aligned them. In a different strand of work, Nielsen et al. (2009) defined a textual entailment model where the “facets” (words under some syntactic/semantic relation) in the response of a student were linked to the concepts in the reference answer. The link would signal whether each facet in the response was entailed by the reference answer or not, but would not explicitly mark which parts of the reference answer caused the entailment. This model was later followed by Levy et al. (2013). Our task was different in that we identified the corresponding chunks in both sentences. We think that, in the future, the aligned facets could provide complementary information to chunks. For interpretable STS the similarity scores range from 0 to 5, as in the English subtask. With respect to the relation between the aligned chunks, the present pilot only allowed 1:1 alignments. As a consequence, we had to include a special alignment context tag (ALIC) to simulate those chunks which had some semantic similarity or relatedness in the other sentence, but could not have been aligned because of"
S15-2045,P13-2080,0,0.0179598,"Contrary to the mentioned works, we first identified the segments (chunks in our case) in each sentence separately, and then aligned them. In a different strand of work, Nielsen et al. (2009) defined a textual entailment model where the “facets” (words under some syntactic/semantic relation) in the response of a student were linked to the concepts in the reference answer. The link would signal whether each facet in the response was entailed by the reference answer or not, but would not explicitly mark which parts of the reference answer caused the entailment. This model was later followed by Levy et al. (2013). Our task was different in that we identified the corresponding chunks in both sentences. We think that, in the future, the aligned facets could provide complementary information to chunks. For interpretable STS the similarity scores range from 0 to 5, as in the English subtask. With respect to the relation between the aligned chunks, the present pilot only allowed 1:1 alignments. As a consequence, we had to include a special alignment context tag (ALIC) to simulate those chunks which had some semantic similarity or relatedness in the other sentence, but could not have been aligned because of"
S15-2045,W10-0721,0,0.0157602,"ns student answers Q&A forum answers commited belief Table 2: English subtask: Summary of train (2012, 2013, 2014) and test (2015) datasets. lines come from a different EMM cluster. Then, we computed the string similarity between those pairs. Accordingly, we sampled 1000 headline pairs of headlines that occur in the same EMM cluster, aiming for pairs equally distributed between minimal and maximal similarity using simple string similarity as a metric. We sampled another 1000 pairs from the different EMM cluster in the same manner. The Images dataset is a subset of the PASCAL VOC-2008 dataset (Rashtchian et al., 2010), which consists of 1000 images with around 10 descriptions each, and has been used by a number of image description systems. It was also sampled using string similarity, discarding those that had been used in previous years. We organized two bins with 1000 pairs each: one with pairs of descriptions from the same image, and the other one with pairs of descriptions from different images. The source of the Answers-student pairs is the BEETLE corpus (Dzikovska et al., 2010), which is a question-answer dataset collected and annotated during the evaluation of the BEETLE II tutorial dialogue system."
S15-2045,W00-0726,0,0.313421,"Missing"
S15-2045,S12-1060,0,0.211502,"Missing"
S15-2045,W10-0707,0,\N,Missing
S16-1081,S16-1103,0,0.0432732,"n of Sultan et al. (2015)’s very successful STS model enhanced with additional features found to work well in the literature. The team in second place overall, UWB, combines a large number of diverse similarity models and features (Brychcin and Svoboda, 2016). Similar to Samsung, UWB includes both manually engineered NLP features (e.g., character n-gram overlap) with sophisticated models from deep learning (e.g., Tree LSTMs). The third place team, MayoNLPTeam, also achieves their best results using a combination of a more traditionally engineered NLP pipeline with a deep learning based model (Afzal et al., 2016). Specifically, MayoNLPTeam combines a pipeline that makes use of linguistic resources such as WordNet and well understood concepts such as the information content of a word (Resnik, 1995) with a deep learning method known as Deep Structured Semantic Model (DSSM) (Huang et al., 2013). The next two teams in overall performance, ECNU and NaCTeM, make use of large feature sets, including features based on word embeddings. However, they did not incorporate the more sophisticated deep learning based models explored by Samsung, UWB and MayoNLPTeam (Tian and Lan, 2016; Przybyła et al., 2016). The nex"
S16-1081,S12-1051,1,0.454212,"for replicating human judgements regarding the degree to which a translation generated by an machine translation system corresponds to a reference translation produced by a human translator. STS systems plausibly could be used as a drop-in replacement for existing translation evaluation metrics (e.g., BLEU, MEANT, ME498 TEOR, TER).1 The cross-lingual STS subtask that is newly introduced this year is similarly related to machine translation quality estimation. The STS shared task has been held annually since 2012, providing a venue for the evaluation of state-of-the-art algorithms and models (Agirre et al., 2012; Agirre et al., 2013; Agirre et al., 2014; Agirre et al., 2015). During this time, a diverse set of genres and data sources have been explored (i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Christiane Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion forums, and Q&A data sets). This year’s 1 Both monolingual and cross-lingual STS score what is referred to in the machine translation literature as adequacy and ignore fluency unless it obscures meaning. While popular machine translat"
S16-1081,S13-1004,1,0.536348,"n judgements regarding the degree to which a translation generated by an machine translation system corresponds to a reference translation produced by a human translator. STS systems plausibly could be used as a drop-in replacement for existing translation evaluation metrics (e.g., BLEU, MEANT, ME498 TEOR, TER).1 The cross-lingual STS subtask that is newly introduced this year is similarly related to machine translation quality estimation. The STS shared task has been held annually since 2012, providing a venue for the evaluation of state-of-the-art algorithms and models (Agirre et al., 2012; Agirre et al., 2013; Agirre et al., 2014; Agirre et al., 2015). During this time, a diverse set of genres and data sources have been explored (i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Christiane Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion forums, and Q&A data sets). This year’s 1 Both monolingual and cross-lingual STS score what is referred to in the machine translation literature as adequacy and ignore fluency unless it obscures meaning. While popular machine translation evaluation techni"
S16-1081,S14-2010,1,0.564132,"g the degree to which a translation generated by an machine translation system corresponds to a reference translation produced by a human translator. STS systems plausibly could be used as a drop-in replacement for existing translation evaluation metrics (e.g., BLEU, MEANT, ME498 TEOR, TER).1 The cross-lingual STS subtask that is newly introduced this year is similarly related to machine translation quality estimation. The STS shared task has been held annually since 2012, providing a venue for the evaluation of state-of-the-art algorithms and models (Agirre et al., 2012; Agirre et al., 2013; Agirre et al., 2014; Agirre et al., 2015). During this time, a diverse set of genres and data sources have been explored (i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Christiane Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion forums, and Q&A data sets). This year’s 1 Both monolingual and cross-lingual STS score what is referred to in the machine translation literature as adequacy and ignore fluency unless it obscures meaning. While popular machine translation evaluation techniques do not assess fl"
S16-1081,S16-1101,1,0.859309,"Missing"
S16-1081,S16-1086,0,0.0343004,"Missing"
S16-1081,P98-1013,0,0.0704238,"E498 TEOR, TER).1 The cross-lingual STS subtask that is newly introduced this year is similarly related to machine translation quality estimation. The STS shared task has been held annually since 2012, providing a venue for the evaluation of state-of-the-art algorithms and models (Agirre et al., 2012; Agirre et al., 2013; Agirre et al., 2014; Agirre et al., 2015). During this time, a diverse set of genres and data sources have been explored (i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Christiane Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion forums, and Q&A data sets). This year’s 1 Both monolingual and cross-lingual STS score what is referred to in the machine translation literature as adequacy and ignore fluency unless it obscures meaning. While popular machine translation evaluation techniques do not assess fluency independent from adequacy, it is possible that the deeper semantic assessment being performed by STS systems could benefit from being paired with a separate fluency module. evaluation adds new data sets drawn from plagiarism detection and post-edited machine translation"
S16-1081,S16-1117,0,0.0317832,"Missing"
S16-1081,S16-1089,0,0.463664,"STS. The overall winner, Samsung Poland NLP Team, proposes a textual similarity model that is a novel hybrid of recursive auto-encoders from deep learning with penalty and reward signals extracted from WordNet (Rychalska et al., 2016). To obtain even better performance, this model is combined in an ensemble with a number of other similarity models including a version of Sultan et al. (2015)’s very successful STS model enhanced with additional features found to work well in the literature. The team in second place overall, UWB, combines a large number of diverse similarity models and features (Brychcin and Svoboda, 2016). Similar to Samsung, UWB includes both manually engineered NLP features (e.g., character n-gram overlap) with sophisticated models from deep learning (e.g., Tree LSTMs). The third place team, MayoNLPTeam, also achieves their best results using a combination of a more traditionally engineered NLP pipeline with a deep learning based model (Afzal et al., 2016). Specifically, MayoNLPTeam combines a pipeline that makes use of linguistic resources such as WordNet and well understood concepts such as the information content of a word (Resnik, 1995) with a deep learning method known as Deep Structure"
S16-1081,D15-1181,0,0.0283646,"nik, 1995) with a deep learning method known as Deep Structured Semantic Model (DSSM) (Huang et al., 2013). The next two teams in overall performance, ECNU and NaCTeM, make use of large feature sets, including features based on word embeddings. However, they did not incorporate the more sophisticated deep learning based models explored by Samsung, UWB and MayoNLPTeam (Tian and Lan, 2016; Przybyła et al., 2016). The next team in the rankings, UMD-TTIC-UW, only makes use of a single deep learning model (He et al., 2016). The team extends a multi-perspective convolutional neural network (MPCNN) (He et al., 2015) with a simple word level attentional mecha17 To see how much of this is related to the Q&A domain in particular, we will investigate including difficult non-Q&A evaluation data in future STS competitions. nism based on the aggregate cosine similarity of a word in one text with all of the words in a paired text. The submission is notable for how well it performs without any manual feature engineering. Finally, the best performing system on the postediting data, RICOH’s Run-n, introduces a novel IRbased approach for textual similarity that incorporates word alignment information (Itoh, 2016). 6"
S16-1081,S16-1170,0,0.023392,"s such as WordNet and well understood concepts such as the information content of a word (Resnik, 1995) with a deep learning method known as Deep Structured Semantic Model (DSSM) (Huang et al., 2013). The next two teams in overall performance, ECNU and NaCTeM, make use of large feature sets, including features based on word embeddings. However, they did not incorporate the more sophisticated deep learning based models explored by Samsung, UWB and MayoNLPTeam (Tian and Lan, 2016; Przybyła et al., 2016). The next team in the rankings, UMD-TTIC-UW, only makes use of a single deep learning model (He et al., 2016). The team extends a multi-perspective convolutional neural network (MPCNN) (He et al., 2015) with a simple word level attentional mecha17 To see how much of this is related to the Q&A domain in particular, we will investigate including difficult non-Q&A evaluation data in future STS competitions. nism based on the aggregate cosine similarity of a word in one text with all of the words in a paired text. The submission is notable for how well it performs without any manual feature engineering. Finally, the best performing system on the postediting data, RICOH’s Run-n, introduces a novel IRbased"
S16-1081,N06-2015,0,0.0113871,"ual STS subtask that is newly introduced this year is similarly related to machine translation quality estimation. The STS shared task has been held annually since 2012, providing a venue for the evaluation of state-of-the-art algorithms and models (Agirre et al., 2012; Agirre et al., 2013; Agirre et al., 2014; Agirre et al., 2015). During this time, a diverse set of genres and data sources have been explored (i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Christiane Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion forums, and Q&A data sets). This year’s 1 Both monolingual and cross-lingual STS score what is referred to in the machine translation literature as adequacy and ignore fluency unless it obscures meaning. While popular machine translation evaluation techniques do not assess fluency independent from adequacy, it is possible that the deeper semantic assessment being performed by STS systems could benefit from being paired with a separate fluency module. evaluation adds new data sets drawn from plagiarism detection and post-edited machine translations. We also introduce an evaluat"
S16-1081,S16-1106,0,0.0956972,"ween the best and median scores to highlight the extent to which top scoring systems outperformed the typical level of performance achieved on each data set. The best overall performance is obtained by Samsung Poland NLP Team’s EN1 system, which achieves an overall correlation of 0.778 (Rychalska et al., 2016). This system also performs best on three out of the five individual evaluation sets: answer-answer, headlines, plagiarism. The EN1 system achieves competitive performance on the postediting data with a correlation score of 0.83516. The best system on the postediting data, RICOH’s Run-n (Itoh, 2016), obtains a score of 0.867. Like all systems, EN1 struggles on the question-question data, achieving a correlation of 0.687. Another system submitted by the Samsung Poland NLP Team named 15 The median scores reported here do not include late or corrected systems. The median scores for the on-time systems without corrections are: ALL 0.68923; plagiarism 0.78949; answer-answer 0.48018; postediting 0.81241; headlines 0.76439; question-question 0.57140. Team Run ALL Ans.-Ans. HDL Plagiarism Postediting Ques.-Ques. Samsung Poland NLP Team UWB MayoNLPTeam Samsung Poland NLP Team NaCTeM ECNU UMD-TTIC"
S16-1081,P14-2124,0,0.0245172,"roximately 0.25 drop in correlation on the news data as compare to the multi-source setting; 2) systems performing evenly on both data sets. 6.5.1 Methods In terms of approaches, most runs rely on a monolingual framework. They automatically translate the Spanish member of a sentence pair into English and then compute monolingual semantic similarity using a system developed for English. In contrast, the CNRC team (Lo et al., 2016) provides a true crosslingual system that makes use of embedding space phrase similarity, the score from XMEANT, a crosslingual machine translation evaluation metric (Lo et al., 2014), and precision and recall features for material filling aligned cross-lingual semantic roles (e.g., action, agent, patient). The FBK HLT team (Ataman et al., 2016) proposes a model combining cross-lingual word embeddings with features from QuEst (Specia et al., 2013), a tool for machine translation quality estimation. The RTM system (Bic¸ici, 2016) also builds on methods developed for machine translation quality estimation and is applicable to both cross-lingual and monolingual similarity. The GWU NLP team (Aldarmaki and Diab, 2016) uses a shared cross-lingual vector space to directly assess"
S16-1081,S16-1102,0,0.0363344,"Missing"
S16-1081,P14-5010,0,0.0120217,"data sources we use for the evaluation sets. 3.1.1 Selection Heuristics Unless otherwise noted, pairs are heuristically selected using a combination of lexical surface form and word embedding similarity between a candidate pair of text snippets. The heuristics are used to find pairs sharing some minimal level of either surface or embedding space similarity. An approximately equal number of candidate sentence pairs are produced using our lexical surface form and word embedding selection heuristics. Both heuristics make use of a Penn Treebank style tokenization of the text provided by CoreNLP (Manning et al., 2014). 500 year 2016 2016 2016 dataset Trial News Multi-source pairs 103 301 294 source Sampled ≤ 2015 STS en-es news articles en news headlines, short-answer plag., MT postedits, Q&A forum answers, Q&A forum questions Table 3: Spanish-English subtask: Trial and test data sets. Surface Lexical Similarity Our surface form selection heuristic uses an information theoretic measure based on unigram overlap (Lin, 1998). As shown in equation (1), surface level lexical similarity between two snippets s1 and s2 is computed as a log probability weighted sum of the words common to both snippets divided by a"
S16-1081,D14-1162,0,0.109685,"Missing"
S16-1081,S16-1093,0,0.0144173,"ased model (Afzal et al., 2016). Specifically, MayoNLPTeam combines a pipeline that makes use of linguistic resources such as WordNet and well understood concepts such as the information content of a word (Resnik, 1995) with a deep learning method known as Deep Structured Semantic Model (DSSM) (Huang et al., 2013). The next two teams in overall performance, ECNU and NaCTeM, make use of large feature sets, including features based on word embeddings. However, they did not incorporate the more sophisticated deep learning based models explored by Samsung, UWB and MayoNLPTeam (Tian and Lan, 2016; Przybyła et al., 2016). The next team in the rankings, UMD-TTIC-UW, only makes use of a single deep learning model (He et al., 2016). The team extends a multi-perspective convolutional neural network (MPCNN) (He et al., 2015) with a simple word level attentional mecha17 To see how much of this is related to the Q&A domain in particular, we will investigate including difficult non-Q&A evaluation data in future STS competitions. nism based on the aggregate cosine similarity of a word in one text with all of the words in a paired text. The submission is notable for how well it performs without any manual feature engin"
S16-1081,S16-1091,0,0.0291873,"representations of the two snippets. 6.4 English Subtask The rankings for the English STS subtask are given in Tables 4 and 5. The baseline system ranked 100th. Table 6 provides the best and median scores for each of the individual evaluation sets as well as overall.15 The table also provides the difference between the best and median scores to highlight the extent to which top scoring systems outperformed the typical level of performance achieved on each data set. The best overall performance is obtained by Samsung Poland NLP Team’s EN1 system, which achieves an overall correlation of 0.778 (Rychalska et al., 2016). This system also performs best on three out of the five individual evaluation sets: answer-answer, headlines, plagiarism. The EN1 system achieves competitive performance on the postediting data with a correlation score of 0.83516. The best system on the postediting data, RICOH’s Run-n (Itoh, 2016), obtains a score of 0.867. Like all systems, EN1 struggles on the question-question data, achieving a correlation of 0.687. Another system submitted by the Samsung Poland NLP Team named 15 The median scores reported here do not include late or corrected systems. The median scores for the on-time sy"
S16-1081,P13-4014,0,0.0272301,"Missing"
S16-1081,2011.eamt-1.12,0,0.00782041,"swers. This corpus provides a collection of short answers to computer science questions that exhibit varying degrees of plagiarism from related Wikipedia articles.4 The short answers include text that was constructed by each of the following four strategies: 1) copying and pasting individual sentences from Wikipedia; 2) light revision of material copied from Wikipedia; 3) heavy revision of material from Wikipedia; 4) non-plagiarised answers produced without even looking at Wikipedia. This corpus is segmented into individual sentences using CoreNLP (Manning et al., 2014). 3.1.4 Postediting The Specia (2011) EAMT 2011 corpus provides machine translations of French news data using the Moses machine translation system (Koehn et al., 2007) paired with postedited corrections of those translations.5 The corrections were provided by human translators instructed to perform the minimum useful for finding semantically similar text snippets that differ in surface form. 4 Questions: A. What is inheritance in object orientated programming?, B. Explain the PageRank algorithm that is used by the Google search engine, C. Explain the Vector Space Model that is used for Information Retrieval., D. Explain Bayes Th"
S16-1081,S15-2027,0,0.0111195,"r to be significantly worse than the monolingual submissions even though the systems are being asked to perform the more challenging problem of evaluating crosslingual sentence pairs. While the correlations are not directly comparable, they do seem to motivate a more direct comparison between cross-lingual and monolingual STS systems. In terms of performance on the manually culled news data set, the highest overall rank is achieved by an unsupervised system submitted by team UWB (Brychcin and Svoboda, 2016). The unsupervised UWB system builds on the word alignment based STS method proposed by Sultan et al. (2015). However, when calculating the final similarity score, it weights both the aligned and unaligned words by their inverse document frequency. This system is able to attain a 0.912 correlation on the news data, while ranking second on the multi-source data set. For the multi-source test set, the highest scoring submission is a supervised system from the UWB team that combines multiple signals originating from lexical, syntactic and semantic similarity approaches in a regression-based model, achieving a 0.819 correlation. This is modestly better than the second place unsupervised approach that ac"
S16-1081,S16-1094,0,0.00995156,"th a deep learning based model (Afzal et al., 2016). Specifically, MayoNLPTeam combines a pipeline that makes use of linguistic resources such as WordNet and well understood concepts such as the information content of a word (Resnik, 1995) with a deep learning method known as Deep Structured Semantic Model (DSSM) (Huang et al., 2013). The next two teams in overall performance, ECNU and NaCTeM, make use of large feature sets, including features based on word embeddings. However, they did not incorporate the more sophisticated deep learning based models explored by Samsung, UWB and MayoNLPTeam (Tian and Lan, 2016; Przybyła et al., 2016). The next team in the rankings, UMD-TTIC-UW, only makes use of a single deep learning model (He et al., 2016). The team extends a multi-perspective convolutional neural network (MPCNN) (He et al., 2015) with a simple word level attentional mecha17 To see how much of this is related to the Q&A domain in particular, we will investigate including difficult non-Q&A evaluation data in future STS competitions. nism based on the aggregate cosine similarity of a word in one text with all of the words in a paired text. The submission is notable for how well it performs without"
S16-1081,C98-1013,0,\N,Missing
S16-1081,P07-2045,0,\N,Missing
W01-1626,H92-1022,0,0.0431275,"phrases express the main intent of the message). In addition to the above annotations, tagger M performed subjective-element tagging on a di erent set of Usenet newsgroup messages, corpus NGSE. The size of this corpus is 15413 words. In datasets WSJ-SE and NG-SE, the taggers were also asked to specify one of ve subjective element types: e+ (positive evaluative), e; (negative evaluative), e? (some other type of evaluation), u (uncertainty), and o (none of the above), with the option to assign multiple types to an instance. All corpora were stemmed (Karp et al., 1992) and part-of-speech tagged (Brill, 1992). 6.2 Agreement Among Taggers There are techniques for analyzing agreement when annotations involve segment boundaries (Litman and Passonneau, 1995; Marcu et al., 1999), but our focus in this paper is on words. Thus, our analyses are at the word level: each word is classi ed as either appearing in a subjective element or not. Punctuation is excluded from our analyses. The WSJ data is divided into two subsets in this section, Exp1 and Exp2. As mentioned above, in WSJ-SE Exp1 and Exp2, the taggers also classi ed subjective elements with respect to the type of subjectivity being expressed. Subjec"
W01-1626,C92-3145,0,0.0159273,"cases, the tagger does not believe that these phrases express the main intent of the message). In addition to the above annotations, tagger M performed subjective-element tagging on a di erent set of Usenet newsgroup messages, corpus NGSE. The size of this corpus is 15413 words. In datasets WSJ-SE and NG-SE, the taggers were also asked to specify one of ve subjective element types: e+ (positive evaluative), e; (negative evaluative), e? (some other type of evaluation), u (uncertainty), and o (none of the above), with the option to assign multiple types to an instance. All corpora were stemmed (Karp et al., 1992) and part-of-speech tagged (Brill, 1992). 6.2 Agreement Among Taggers There are techniques for analyzing agreement when annotations involve segment boundaries (Litman and Passonneau, 1995; Marcu et al., 1999), but our focus in this paper is on words. Thus, our analyses are at the word level: each word is classi ed as either appearing in a subjective element or not. Punctuation is excluded from our analyses. The WSJ data is divided into two subsets in this section, Exp1 and Exp2. As mentioned above, in WSJ-SE Exp1 and Exp2, the taggers also classi ed subjective elements with respect to the type"
W01-1626,P97-1005,0,0.117135,"ively present factual information (objective sentences ). This task is especially relevant for news reporting and Internet forums, in which opinions of various agents are expressed. There are numerous applications for which subjectivity tagging is relevant. Two are information retrieval and information extraction. Current extraction and retrieval technology focuses almost exclusively on the subject matter of documents. However, additional aspects of a document in uence its relevance, including, e.g., the evidential status of the material presented, and the attitudes expressed about the topic (Kessler et al., 1997). Knowledge of subjective language would also be useful in ame recognition (Spertus, 1997; Kaufer, 2000), email classi cation (Aone et al., 2000), intellectual attribution in text (Teufel and Moens, 2000), recognizing speaker role in radio broadcasts (Barzilay et al., 2000), review mining (Terveen et al., 1997), generation and style (Hovy, 1987), clustering documents by ideological point of view (Sack, 1995), and any other application that would bene t from knowledge of how opinionated the language is, and whether or not the writer purports to objectively present factual material. To use subje"
W01-1626,P98-2127,0,0.0764198,"Missing"
W01-1626,P95-1015,0,0.0121898,"on a di erent set of Usenet newsgroup messages, corpus NGSE. The size of this corpus is 15413 words. In datasets WSJ-SE and NG-SE, the taggers were also asked to specify one of ve subjective element types: e+ (positive evaluative), e; (negative evaluative), e? (some other type of evaluation), u (uncertainty), and o (none of the above), with the option to assign multiple types to an instance. All corpora were stemmed (Karp et al., 1992) and part-of-speech tagged (Brill, 1992). 6.2 Agreement Among Taggers There are techniques for analyzing agreement when annotations involve segment boundaries (Litman and Passonneau, 1995; Marcu et al., 1999), but our focus in this paper is on words. Thus, our analyses are at the word level: each word is classi ed as either appearing in a subjective element or not. Punctuation is excluded from our analyses. The WSJ data is divided into two subsets in this section, Exp1 and Exp2. As mentioned above, in WSJ-SE Exp1 and Exp2, the taggers also classi ed subjective elements with respect to the type of subjectivity being expressed. Subjectivity type agreement is again analyzed at the word level, but, in this analysis, only the words classi ed as belonging to subjective elements by b"
W01-1626,J93-2004,0,0.0398538,"individual subjective elements were annotated as part of this work, re ning previous work on sentence-level annotations. Finally, PSEs may be complex expressions such as `village idiot', `powers that be', `You' NP, and `What a' NP. There is a great variety of such expressions, including many studied under the rubric of idioms (see, for example, (Nunberg et al., 1994)). We address learning such expressions in another project. 3 Previous Work on Subjectivity Tagging In previous work (Wiebe et al., 1999; Bruce and Wiebe, 1999), a corpus of sentences from the Wall Street Journal Treebank Corpus (Marcus et al., 1993) was manually annotated with subjectivity classi cations by multiple judges. The judges were instructed to consider a sentence to be subjective if they perceived any signi cant expression of subjectivity (of any source) in the sentence, and to consider the sentence to be objective, otherwise. Agreement was summarized in terms of Cohen's  (Cohen, 1960), which compares the total probability of agreement to that expected if the taggers' classi cations were statistically independent (i.e., chance agreement&quot;). After two rounds of tagging by three judges, an average pairwise  value of .69 was ach"
W01-1626,W00-1302,0,0.0909327,"pplications for which subjectivity tagging is relevant. Two are information retrieval and information extraction. Current extraction and retrieval technology focuses almost exclusively on the subject matter of documents. However, additional aspects of a document in uence its relevance, including, e.g., the evidential status of the material presented, and the attitudes expressed about the topic (Kessler et al., 1997). Knowledge of subjective language would also be useful in ame recognition (Spertus, 1997; Kaufer, 2000), email classi cation (Aone et al., 2000), intellectual attribution in text (Teufel and Moens, 2000), recognizing speaker role in radio broadcasts (Barzilay et al., 2000), review mining (Terveen et al., 1997), generation and style (Hovy, 1987), clustering documents by ideological point of view (Sack, 1995), and any other application that would bene t from knowledge of how opinionated the language is, and whether or not the writer purports to objectively present factual material. To use subjectivity tagging in applications, good linguistic clues must be found. As with many pragmatic and discourse distinctions, existing lexical resources are not comprehensively coded for subjectivity. The goal"
W01-1626,W98-1126,1,0.853628,"sagreement in the assignment of the original type tags. Surprisingly, the taggers appear to act independently when they disagree in assigning the compressed type tags (i.e., tags e, u and o). This shift in the pattern of disagreement between taggers again suggests that the compression of the evaluative tags was inappropriate. Additionally, these ndings suggest that it may be possible to automatically correct the type biases expressed by the taggers using the technique described in (Bruce and Wiebe, 1999), a topic that will be investigated in future work. 6.3 Uniqueness Based on previous work (Wiebe et al., 1998), we hypothesized that low-frequency words are associated with subjectivity. Table 6 provides evidence that the number of unique words (words that appear just once) in subjective elements is higher than expected. The rst row gives information for all words and the second gives information for words that appear just once. The gures in the Num columns are total counts, and the gures in the P columns give the proportion that appear in subjective elements. The Agree columns give inExp1 Full Match Partial Match Exp2 Full Match Partial Match All Words 0:4216 0:5156 0:3041 0:4209 Nouns 0:4228 0:4570"
W01-1626,P99-1032,1,0.884827,"ith itself). In addition, subjectivity of the writer is expressed (e.g., `we stand in awe'). As described below, individual subjective elements were annotated as part of this work, re ning previous work on sentence-level annotations. Finally, PSEs may be complex expressions such as `village idiot', `powers that be', `You' NP, and `What a' NP. There is a great variety of such expressions, including many studied under the rubric of idioms (see, for example, (Nunberg et al., 1994)). We address learning such expressions in another project. 3 Previous Work on Subjectivity Tagging In previous work (Wiebe et al., 1999; Bruce and Wiebe, 1999), a corpus of sentences from the Wall Street Journal Treebank Corpus (Marcus et al., 1993) was manually annotated with subjectivity classi cations by multiple judges. The judges were instructed to consider a sentence to be subjective if they perceived any signi cant expression of subjectivity (of any source) in the sentence, and to consider the sentence to be objective, otherwise. Agreement was summarized in terms of Cohen's  (Cohen, 1960), which compares the total probability of agreement to that expected if the taggers' classi cations were statistically independent ("
W01-1626,J94-2004,1,0.914246,"twilson@cs.pitt.edu, bruce@cs.unca.edu, mmartin@cs.nmsu.edu Abstract This paper presents a corpus study of evaluative and speculative language. Knowledge of such language would be useful in many applications, such as text categorization and summarization. Analyses of annotator agreement and of characteristics of subjective language are performed. This study yields knowledge needed to design e ective machine learning systems for identifying subjective language. 1 Introduction Subjectivity in natural language refers to aspects of language used to express opinions and evaluations (Ban eld, 1982; Wiebe, 1994). Subjectivity tagging is distinguishing sentences used to present opinions and other forms of subjectivity (subjective sentences ) from sentences used to objectively present factual information (objective sentences ). This task is especially relevant for news reporting and Internet forums, in which opinions of various agents are expressed. There are numerous applications for which subjectivity tagging is relevant. Two are information retrieval and information extraction. Current extraction and retrieval technology focuses almost exclusively on the subject matter of documents. However, additio"
W01-1626,C98-2122,0,\N,Missing
W02-2034,J94-2004,1,\N,Missing
W02-2034,W00-1302,0,\N,Missing
W02-2034,W01-1605,0,\N,Missing
W02-2034,W01-1626,1,\N,Missing
W02-2034,P97-1005,0,\N,Missing
W02-2034,P99-1032,1,\N,Missing
W02-2034,P98-2127,0,\N,Missing
W02-2034,C98-2122,0,\N,Missing
W03-0404,P99-1016,0,0.0739636,"Missing"
W03-0404,P97-1023,0,0.80925,"Missing"
W03-0404,C92-2082,0,0.023385,"Missing"
W03-0404,C94-2174,0,0.0211935,"Missing"
W03-0404,P97-1005,0,0.0184628,"Missing"
W03-0404,W02-1011,0,0.0665331,"Missing"
W03-0404,W97-0313,1,0.377646,"Missing"
W03-0404,P98-2182,0,0.0178579,"Missing"
W03-0404,P98-1013,0,0.0179181,"Missing"
W03-0404,P02-1053,0,0.0353155,"Missing"
W03-0404,P99-1032,1,0.642678,"Missing"
W03-0404,C98-1013,0,\N,Missing
W03-0404,W02-1028,1,\N,Missing
W03-0404,C98-2177,0,\N,Missing
W03-0411,A00-2031,0,0.0182579,"Missing"
W03-0411,J99-2002,1,0.825672,"on would be to use standard WSD features, such as the parts-of-speech of surrounding words and, more importantly, collocations (e.g., lexical associations). Although this can be highly accurate, it will likely overfit the data and generalize poorly. To overcome these problems, a class-based approach is used for the collocations, with WordNet high-level synsets as the source of the word classes. Therefore, in addition to using collocations in the form of other words, this uses collocations in the form of semantic categories. A supervised approach for word-sense disambiguation is used following Bruce and Wiebe (1999). The results described here were obtained using the settings in Figure 1. These are similar to the settings used by O’Hara et al. (2000) in the first S ENSEVAL competition, with the exception of the hypernym collocations. This shows that for the hypernym associations, only those words that occur within 5 words of the target prepositions are considered.2 The main difference from that of a standard WSD approach is that, during the determination of the class-based collocations, each word token is replaced by synset tokens for its hypernyms in WordNet, several of which might occur more than once."
W03-0411,P02-1055,0,0.0405697,"Missing"
W03-0411,Y01-1001,0,0.0204293,"Missing"
W03-0411,J02-3001,0,0.15002,"Missing"
W03-0411,H94-1020,0,0.0329199,"ed fine-grained roles, often specific to particular domains. For example, in the Cyc KB there are close to 200 different types of semantic roles. These range from high-level roles (e.g., beneficiaries) through medium-level roles (e.g., exchanges) to highly specialized roles (e.g., catalyst).1 Preposition classification using two different semantic role inventories are investigated in this paper, taking advantage of large annotated corpora. After providing background to the work in Section 2, experiments over the semantic role annotations are discussed in Section 3. The results over T REEBANK (Marcus et al., 1994) are covered first. Treebank include about a dozen high-level roles similar to Fillmore’s. Next, experiments using the finer-grained semantic role annotations in F RAME N ET version 0.75 (Fillmore et al., 2001) are 1 Part of the Cyc KB is freely available at www.opencyc.org. presented. FrameNet includes over 140 roles, approaching but not quite as specialized as Cyc’s inventory. Section 4 follows with a comparison to related work, emphasizing work in broad-coverage preposition disambiguation. 2 Background 2.1 Semantic roles in the P ENN T REEBANK The second version of the Penn Treebank (Marcus"
W03-0411,1992.tmi-1.2,0,0.0192586,"Missing"
W03-0411,W98-1126,1,0.883135,"Missing"
W03-0411,J93-2004,0,\N,Missing
W03-0411,J93-1005,0,\N,Missing
W03-0411,W02-0802,0,\N,Missing
W03-0411,P91-1020,1,\N,Missing
W03-0411,A00-1034,0,\N,Missing
W03-1014,P98-1013,0,0.104127,"Missing"
W03-1014,P98-1067,0,0.0158561,"example, you can say that a comedian bombed last night, which is a subjective statement, but you can’t express this sentiment with the passive voice of bombed. In Section 3.2, we will show examples of extraction patterns representing subjective expressions which do in fact exhibit both of these phenomena. A variety of algorithms have been developed to automatically learn extraction patterns. Most of these algorithms require special training resources, such as texts annotated with domain-specific tags (e.g., AutoSlog (Riloff, 1993), CRYSTAL (Soderland et al., 1995), RAPIER (Califf, 1998), SRV (Freitag, 1998), WHISK (Soderland, 1999)) or manually defined keywords, frames, or object recognizers (e.g., PALKA (Kim and Moldovan, 1993) and LIEP (Huffman, 1996)). AutoSlog-TS (Riloff, 1996) takes a different approach, requiring only a corpus of unannotated texts that have been separated into those that are related to the target domain (the “relevant” texts) and those that are not (the “irrelevant” texts). Most recently, two bootstrapping algorithms have been used to learn extraction patterns. Metabootstrapping (Riloff and Jones, 1999) learns both extraction patterns and a semantic lexicon using unannotat"
W03-1014,P97-1023,0,0.928172,"IMA, and NRO. Janyce Wiebe Department of Computer Science University of Pittsburgh Pittsburgh, PA 15260 wiebe@cs.pitt.edu must recognize rants and emotional tirades, among other things. In general, nearly any system that seeks to identify information could benefit from being able to separate factual and subjective information. Some existing resources contain lists of subjective words (e.g., Levin’s desire verbs (1993)), and some empirical methods in NLP have automatically identified adjectives, verbs, and N-grams that are statistically associated with subjective language (e.g., (Turney, 2002; Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Wiebe et al., 2001)). However, subjective language can be exhibited by a staggering variety of words and phrases. In addition, many subjective terms occur infrequently, such as strongly subjective adjectives (e.g., preposterous, unseemly) and metaphorical or idiomatic phrases (e.g., dealt a blow, swept off one’s feet). Consequently, we believe that subjectivity learning systems must be trained on extremely large text collections before they will acquire a subjective vocabulary that is truly broad and comprehensive in scope. To address this issue, we have been exploring the use o"
W03-1014,C94-2174,0,0.0157234,"Missing"
W03-1014,P02-1053,0,0.130923,"A, DIA, NSA, NIMA, and NRO. Janyce Wiebe Department of Computer Science University of Pittsburgh Pittsburgh, PA 15260 wiebe@cs.pitt.edu must recognize rants and emotional tirades, among other things. In general, nearly any system that seeks to identify information could benefit from being able to separate factual and subjective information. Some existing resources contain lists of subjective words (e.g., Levin’s desire verbs (1993)), and some empirical methods in NLP have automatically identified adjectives, verbs, and N-grams that are statistically associated with subjective language (e.g., (Turney, 2002; Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Wiebe et al., 2001)). However, subjective language can be exhibited by a staggering variety of words and phrases. In addition, many subjective terms occur infrequently, such as strongly subjective adjectives (e.g., preposterous, unseemly) and metaphorical or idiomatic phrases (e.g., dealt a blow, swept off one’s feet). Consequently, we believe that subjectivity learning systems must be trained on extremely large text collections before they will acquire a subjective vocabulary that is truly broad and comprehensive in scope. To address this iss"
W03-1014,P97-1005,0,0.0140973,"Missing"
W03-1014,P99-1032,1,0.511368,"Missing"
W03-1014,W02-1011,0,0.0681785,"Missing"
W03-1014,W03-0404,1,0.378518,"Missing"
W03-1014,W03-2102,1,0.146689,"seem subjective to a person intuitively, but that are reliable indicators of subjectivity. 4 Experimental Results 4.1 Subjectivity Data The text collection that we used consists of Englishlanguage versions of foreign news documents from FBIS, the U.S. Foreign Broadcast Information Service. The data is from a variety of countries. Our system takes unannotated data as input, but we needed annotated data to evaluate its performance. We briefly describe the manual annotation scheme used to create the gold-standard, and give interannotator agreement results. In 2002, a detailed annotation scheme (Wilson and Wiebe, 2003) was developed for a government-sponsored project. We only mention aspects of the annotation scheme relevant to this paper. The scheme was inspired by work in linguistics and literary theory on subjectivity, which focuses on how opinions, emotions, etc. are expressed linguistically in context (Banfield, 1982). The goal is to identify and characterize expressions of private states in a sentence. Private state is a general covering term for opinions, evaluations, emotions, and speculations (Quirk et al., 1985). For example, in sentence (1) the writer is expressing a negative evaluation. (1) “The"
W03-1014,C00-2136,0,0.0441251,"ned keywords, frames, or object recognizers (e.g., PALKA (Kim and Moldovan, 1993) and LIEP (Huffman, 1996)). AutoSlog-TS (Riloff, 1996) takes a different approach, requiring only a corpus of unannotated texts that have been separated into those that are related to the target domain (the “relevant” texts) and those that are not (the “irrelevant” texts). Most recently, two bootstrapping algorithms have been used to learn extraction patterns. Metabootstrapping (Riloff and Jones, 1999) learns both extraction patterns and a semantic lexicon using unannotated texts and seed words as input. ExDisco (Yangarber et al., 2000) uses a bootstrapping mechanism to find new extraction patterns using unannotated texts and some seed patterns as the initial input. For our research, we adopted a learning process very similar to that used by AutoSlog-TS, which requires only relevant texts and irrelevant texts as its input. We describe this learning process in more detail in the next section. 3 Learning and Bootstrapping Extraction Patterns for Subjectivity We have developed a bootstrapping process for subjectivity classification that explores three ideas: (1) highprecision classifiers can be used to automatically identify su"
W03-1014,C98-1013,0,\N,Missing
W03-1014,C98-1064,0,\N,Missing
W03-2102,J93-2004,0,0.026194,"Missing"
W03-2102,P99-1032,1,0.874748,"Missing"
W03-2102,J94-2004,1,0.905038,"l subjective sentence annotations. 1 Introduction In this paper we present a detailed scheme for annotating expressions of opinions, beliefs, emotions, sentiment, speculation and other private states in newspaper articles. Private state is a general term that covers mental and emotional states, which cannot be directly observed or verified (Quirk et al., 1985). For example, we can observe evidence of someone else being happy, but we cannot directly observe their happiness. In natural language, opinions, emotions and other private states are expressed using subjective language (Banfield, 1982; Wiebe, 1994). Articles in the news are composed of a mixture of factual and subjective material. Writers of editorials frequently include facts to support their arguments, and news reports often mix segments presenting objective facts with segments presenting opinions and verbal reactions (van Dijk, 1988). However, natural language processing applications that retrieve or extract information from or that summarize or answer quesJanyce Wiebe Department of Computer Science University of Pittsburgh Pittsburgh, PA 15260, USA wiebe@cs.pitt.edu tions about news and other discourse have focused primarily on fact"
W04-0849,J98-1001,0,0.0770343,"Missing"
W04-0849,P98-2127,0,0.05235,"cation variable HyperColls for each sense s is binary, corresponding to the absence or presence of any hypernym in the set chosen for s. This set of hypernyms is chosen using the ratio of conditional probability to prior probability as described for the WordColls feature above. In contrast, HyperColl∗,i selects nonsense-speciﬁc hypernym collocations: 10 separate binary features are used based on the G2 selection criteria. (More of these features could be used, but they are limited for tractability.) For more details on hypernym collocations, see (O’Hara, forthcoming). Word-similarity classes (Lin, 1998) derived from clustering are also used to expand the pool of potential collocations; this type of semantic relatedness among words is expressed in the SimilarColl feature. For the DictColl features, deﬁnition analysis (O’Hara, forthcoming) is used to determine the semantic relatedness of the deﬁning words. Diﬀerences between these two sources of word relations are illustrated by looking at the information they provide for ‘ballerina’: word-clusters: dancer:0.115 baryshnikov:0.072 pianist:0.056 choreographer:0.049 ... [18 other words] nicole:0.041 wrestler:0.040 tibetans:0.040 clown:0.040 defin"
W04-0849,C02-1039,0,0.126802,"ing semantic class-based collocations to augment traditional word-based collocations. Three separate sources of word relatedness are used for these collocations: 1) WordNet hypernym relations; 2) cluster-based word similarity classes; and 3) dictionary deﬁnition analysis. 1 Introduction Supervised systems for word-sense disambiguation (WSD) often rely upon word collocations (i.e., sense-speciﬁc keywords) to provide clues on the most likely sense for a word given the context. In the second Senseval competition, these features ﬁgured predominantly among the feature sets for the leading systems (Mihalcea, 2002; Yarowsky et al., 2001; Seo et al., 2001). A limitation of such features is that the words selected must occur in the test data in order for the features to apply. To alleviate this problem, class-based approaches augment word-level features with category-level ones (Ide and V´eronis, 1998; Jurafsky and Martin, 2000). When applied to collocational features, this approach effectively uses class labels rather than wordforms in deriving the collocational features. This research focuses on the determination of class-based collocations to improve wordsense disambiguation. We do not address reﬁneme"
W04-0849,S01-1036,0,0.0179511,"o augment traditional word-based collocations. Three separate sources of word relatedness are used for these collocations: 1) WordNet hypernym relations; 2) cluster-based word similarity classes; and 3) dictionary deﬁnition analysis. 1 Introduction Supervised systems for word-sense disambiguation (WSD) often rely upon word collocations (i.e., sense-speciﬁc keywords) to provide clues on the most likely sense for a word given the context. In the second Senseval competition, these features ﬁgured predominantly among the feature sets for the leading systems (Mihalcea, 2002; Yarowsky et al., 2001; Seo et al., 2001). A limitation of such features is that the words selected must occur in the test data in order for the features to apply. To alleviate this problem, class-based approaches augment word-level features with category-level ones (Ide and V´eronis, 1998; Jurafsky and Martin, 2000). When applied to collocational features, this approach effectively uses class labels rather than wordforms in deriving the collocational features. This research focuses on the determination of class-based collocations to improve wordsense disambiguation. We do not address reﬁnement of existing algorithms for machine lear"
W04-0849,W98-1126,1,0.872747,"Missing"
W04-0849,S01-1040,0,0.0274567,"ss-based collocations to augment traditional word-based collocations. Three separate sources of word relatedness are used for these collocations: 1) WordNet hypernym relations; 2) cluster-based word similarity classes; and 3) dictionary deﬁnition analysis. 1 Introduction Supervised systems for word-sense disambiguation (WSD) often rely upon word collocations (i.e., sense-speciﬁc keywords) to provide clues on the most likely sense for a word given the context. In the second Senseval competition, these features ﬁgured predominantly among the feature sets for the leading systems (Mihalcea, 2002; Yarowsky et al., 2001; Seo et al., 2001). A limitation of such features is that the words selected must occur in the test data in order for the features to apply. To alleviate this problem, class-based approaches augment word-level features with category-level ones (Ide and V´eronis, 1998; Jurafsky and Martin, 2000). When applied to collocational features, this approach effectively uses class labels rather than wordforms in deriving the collocational features. This research focuses on the determination of class-based collocations to improve wordsense disambiguation. We do not address reﬁnement of existing algorith"
W04-0849,C98-2122,0,\N,Missing
W04-2116,J02-2001,0,0.0255363,"th examples. This allows for better coverage at the expense of precision. Note that relation disambiguation is not yet addressed in Extended WordNet (Rus, 2002); for example, prepositions are treated as predicates in the logical form representation. Their extraction process is also closely tied into the speciﬁcs of the parser, as a transformation rule is developed for each grammar rule. This work addresses the acquisition of conceptual distinctions. In principle, it can handle any level of granularity given suﬃcient training data; however, addressing distinctions at the level of nearsynonyms (Edmonds and Hirst, 2002) might require customized analysis for each cluster of nearly synonymous words. Inkpen and Hirst (2001) discuss how this can be automated by analyzing specialized synonymy dictionaries. Decision lists of indicative keywords are learned for the broad types of pragmatic distinctions, and these are then manually split into decision lists for more-speciﬁc distinctions. 6 Conclusion We have presented an empirical methodology for extracting information from dictionary deﬁnitions. This diﬀers from previous approaches by using datadriven relation disambiguation, using FrameNet semantic roles annotatio"
W04-2116,Y01-1001,0,0.0139764,"ries, use of traditional word-sense disambiguation algorithms would be required. With the emphasis on corpus analysis in computational linguistics, there has been shift away from relying on explicitly coded knowledge towards the use of knowledge inferred from naturally occurring text, in particular text that has been annotated by humans to indicate phenomena of interest. The Penn Treebank version II (Marcus et al., 1994) provided the ﬁrst large-scale set of case role annotations for general-purpose text. These are very general roles akin to Fillmore’s (1968) case roles. The Berkeley FrameNet (Fillmore et al., 2001) project provides the most recent large-scale annotation of semantic roles. These are at a much ﬁner granularity than those in Treebank, so they should prove quite useful for applications learning detailed semantics from corpora. O’Hara and Wiebe (2003) explain how both inventories can be used for preposition disambiguation. The goal of relation disambiguation is to determine the underlying semantic role indicated by particular words in a phrase or by word order. For relations indicated directly by function words, the disambiguation can be seen as a special case of wordsense disambiguation (WS"
W04-2116,J02-3001,0,0.00772386,"incorporated, making the diﬀerentia disambiguation system less predictable. Alternatively, the annotations can be converted into a common inventory, and a separate relation classiﬁer induced over the resulting data. This has the advantage that the target relation-type inventory remains stable whenever new sources of relation annotations are introduced. The drawback however is that annotations from new resources must ﬁrst be mapped into the common inventory before incorporation. The latter approach is employed here. The common inventory incorporates some of the general relation types deﬁned by Gildea and Jurafsky (2002) for their experiments in classifying semantic relations in FrameNet using a reduced inventory. Frequency 0.316 0.116 0.080 0.069 0.069 0.061 0.058 0.053 0.039 0.022 0.021 0.021 0.019 0.017 0.017 0.011 0.010 0.001 Table 1: Frequency of relations extracted. 4 Evaluation The evaluation discussed here assesses the quality of the information that would be added to the lexicons with respect to relation disambiguation, which is the focus of the research. An application-oriented evaluation is discussed in (O’Hara, forthcoming), showing how using the extracted information improves wordsense disambigua"
W04-2116,W99-0501,0,0.0381362,"Missing"
W04-2116,H94-1020,0,0.0177802,"both the source and target terms. The WordNet deﬁnitions have recently been sense-tagged as part of the Extended WordNet (Novischi, 2002), so these annotations are incorporated. For other dictionaries, use of traditional word-sense disambiguation algorithms would be required. With the emphasis on corpus analysis in computational linguistics, there has been shift away from relying on explicitly coded knowledge towards the use of knowledge inferred from naturally occurring text, in particular text that has been annotated by humans to indicate phenomena of interest. The Penn Treebank version II (Marcus et al., 1994) provided the ﬁrst large-scale set of case role annotations for general-purpose text. These are very general roles akin to Fillmore’s (1968) case roles. The Berkeley FrameNet (Fillmore et al., 2001) project provides the most recent large-scale annotation of semantic roles. These are at a much ﬁner granularity than those in Treebank, so they should prove quite useful for applications learning detailed semantics from corpora. O’Hara and Wiebe (2003) explain how both inventories can be used for preposition disambiguation. The goal of relation disambiguation is to determine the underlying semantic"
W04-2116,H94-1046,0,0.0377651,"m the most-informative ancestor will be used instead of the parent. This is determined by selecting the ancestor that best balances frequency of occurrence in a tagged corpus with speciﬁcity. This is similar to Resnik’s (1995) notion of most-informative subsumer for a pair of concepts. In his approach, estimated frequencies for synsets are percolated up the hierarchy, so that the frequency always increases as one proceeds up the hierarchy. Therefore the ﬁrst common ancestor for a pair is the most-informative subsumer (i.e., has most information content). Here attested frequencies from SemCor (Miller et al., 1994) are used, so all ancestors are considered. Speciﬁcity is accounted for by applying a scaling factor to the frequencies that decreases as one proceeds up the hierarchy. Thus, ‘informative’ is used more in an intuitive sense rather than technical. More details on the extraction process and the subsequent disambiguation can be found in (O’Hara, forthcoming). 3 Diﬀerentia Disambiguation After the diﬀerentia properties have been extracted from a deﬁnition, the words for the relation source and object terms are disambiguated to order to reduce vagueness in the relationships. In addition, the relati"
W04-2116,W03-0411,1,0.866097,"Missing"
W04-2116,W95-0105,0,0.0906694,"Missing"
W04-2116,1993.iwpt-1.22,0,0.00882778,"can be incorporated without having to rework the disambiguation process. This paper is organized as follows: Section 2 details the steps in extracting the initial relations from the deﬁnition parse. Section 3 illustrates the disambiguation process, the crucial part of this approach. Section 4 presents an evaluation of the relations that are extracted from the WordNet deﬁnitions. Lastly, Section 5 compares the approach to previous approaches that have been tried. 2 Diﬀerentia Extraction The approach to diﬀerentia extraction is entirely automated. This starts with using the Link Grammar Parser (Sleator and Temperley, 1993), a dependency parser, to determine the syntactic lexical relations that occur in the sentence. Dictionary deﬁnitions are often given in the form of sentence fragments with the headword omitted. For example, the deﬁnition for the beverage sense of ‘wine’ is “fermented juice (of grapes especially).” Therefore, prior to running the deﬁnition analysis, the deﬁnitions are converted into complete sentences, using simple templates for each part of speech. After parsing, a series of postprocessing steps is performed prior to the extraction of the lexical relations. For the Link Parser, this mainly in"
W05-0308,J04-3002,1,0.619878,"Missing"
W05-0308,W03-2102,1,0.723148,"and other private states in text. We first give an overview of the core scheme. We then describe recent extensions to the scheme, namely refined annotations of attitudes and targets, or objects, of private states. Finally, we discuss related items from the “Pie in the Sky” Check List of Desirable Semantic Information for Annotation, and related work. We believe our scheme would provide a foundation for adding private state annotations to other layers of semantic and pragmatic meaning. 2 The Core Scheme This section overviews the core of the annotation scheme. Further details may be found in (Wilson and Wiebe, 2003; Wiebe et al., 2005). 2.1 Means of Expressing Private States The goals of the annotation scheme are to represent internal mental and emotional states, and to distinguish subjective information from material presented as fact. As a result, the annotation scheme is centered on the notion of private state, a general term that covers opinions, beliefs, thoughts, feelings, emotions, goals, evaluations, and judgments. As Quirk et al. (1985) define it, a private state is a state that is not open to objective observation or verification: “a person may be observed to assert that God exists, but not to"
W05-0308,W03-1017,0,0.0272348,"Missing"
W06-0607,W05-0308,1,\N,Missing
W06-0607,P96-1038,0,\N,Missing
W06-1652,C04-1200,0,0.0976101,"Missing"
W06-1652,J93-2004,0,0.0384676,"Missing"
W06-1652,W04-3253,0,0.0510384,"Missing"
W06-1652,P04-1035,0,0.17754,"ence (i.e., A is good enough that we are comfortable discarding B in favor of the more general feature A). Note that based on the subsumption hierarchy shown in Figure 2, all 1Grams will always survive the subsumption process because they cannot be subsumed by any other types of features. Our goal is to identify complex features that are worth adding to a set of unigram features. 3 4 Using the Subsumption Hierarchy for Analysis Data Sets We used three opinion-related data sets for our analyses and experiments: the OP data set created by (Wiebe et al., 2004), the Polarity data set5 created by (Pang and Lee, 2004), and the MPQA data set created by (Wiebe et al., 2005).6 The OP and Polarity data sets involve document-level opinion classification, while the MPQA data set involves 5 Version v2.0, which is available at: http://www.cs.cornell.edu/people/pabo/movie-review-data/ 6 Available at http://www.cs.pitt.edu/mpqa/databaserelease/ 444 In this section, we illustrate how the subsumption hierarchy can be used as an analytic tool to automatically identify features that substantially outperform simpler counterparts. These features represent specialized usages and expressions that would be good candidates fo"
W06-1652,W02-1011,0,0.0182856,"a method to automatically identify features that are representationally subsumed by a simpler feature but that are better opinion indicators. These subjective expressions could then be added to a subjectivity lexicon (Esuli and Sebastiani, 2005), and used to gain understanding about which types of complex features capture meaningful expressions that are important for opinion recognition. Many opinion classifiers are created by adopting a “kitchen sink” approach that throws together a variety of features. But in many cases adding new types of features does not improve performance. For example, Pang et al. (2002) found that unigrams outperformed bigrams, and unigrams outperformed the combination of unigrams plus bigrams. Our second goal is to automatically identify features that are unnecessary because similar features provide equal or better coverage and discriminatory value. Our hypothesis is that a reduced feature set, which selectively combines unigrams with only the most valuable complex features, will perform better than a larger feature set that includes the entire “kitchen sink” of features. In this paper, we explore the use of a subsumption hierarchy to formally define the subsumption relatio"
W06-1652,H05-1043,0,0.0716947,"Missing"
W06-1652,W03-1014,1,0.127302,"&lt;np> &lt;possessive> NP The Subsumption Hierarchy 2.1 Text Representations We analyze two feature representations that have been used for opinion analysis: Ngrams and Extraction Patterns. Information extraction (IE) patterns are lexico-syntactic patterns that represent expressions which identify role relationships. For example, the pattern “&lt;subj> ActVP(recommended)” extracts the subject of active-voice instances of the verb “recommended” as the recommender. The pattern “&lt;subj> PassVP(recommended)” extracts the subject of passive-voice instances of “recommended” as the object being recommended. (Riloff and Wiebe, 2003) explored the idea of using extraction patterns to represent more complex subjective expressions that have noncompositional meanings. For example, the expression “drive (someone) up the wall” expresses the feeling of being annoyed, but the meanings of the words “drive”, “up”, and “wall” have no emotional connotations individually. Furthermore, this expression is not a fixed word sequence that can be adequately modeled by Ngrams. Any noun phrase can appear between the words “drive’ and “up”, so a flexible representation is needed to capture the general pattern “drives &lt;NP> up the wall”. This ex"
W06-1652,P02-1053,0,0.00825848,"Missing"
W06-1652,J04-3002,1,0.073394,"hat is considered to be an acceptable performance difference (i.e., A is good enough that we are comfortable discarding B in favor of the more general feature A). Note that based on the subsumption hierarchy shown in Figure 2, all 1Grams will always survive the subsumption process because they cannot be subsumed by any other types of features. Our goal is to identify complex features that are worth adding to a set of unigram features. 3 4 Using the Subsumption Hierarchy for Analysis Data Sets We used three opinion-related data sets for our analyses and experiments: the OP data set created by (Wiebe et al., 2004), the Polarity data set5 created by (Pang and Lee, 2004), and the MPQA data set created by (Wiebe et al., 2005).6 The OP and Polarity data sets involve document-level opinion classification, while the MPQA data set involves 5 Version v2.0, which is available at: http://www.cs.cornell.edu/people/pabo/movie-review-data/ 6 Available at http://www.cs.pitt.edu/mpqa/databaserelease/ 444 In this section, we illustrate how the subsumption hierarchy can be used as an analytic tool to automatically identify features that substantially outperform simpler counterparts. These features represent specialized"
W06-1652,W03-1017,0,0.170187,"Missing"
W06-1652,H05-2017,0,\N,Missing
W06-2915,P04-1034,0,0.0161556,"Missing"
W06-2915,W02-1011,0,0.0150654,"written with high accuracy. 2 Related Work Identifying the perspective from which a document is written is a subtask in the growing area of automatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and 110 Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005). While by its very nature we expect much of the language that is used when presenting a perspective or point-of-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Moreover, the ideology and beliefs authors possess are often expressed in ways other than positive or negative language toward specific targets. Research on the automatic cl"
W06-2915,H05-1043,0,0.0276617,"atic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and 110 Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005). While by its very nature we expect much of the language that is used when presenting a perspective or point-of-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Moreover, the ideology and beliefs authors possess are often expressed in ways other than positive or negative language toward specific targets. Research on the automatic classification of movie or product reviews as positive or negative (e.g., (Pang et al., 2002; Morinaga et al., 2002; Turney and Littman, 2003; Nasukawa and"
W06-2915,W03-1014,1,0.071132,"Missing"
W06-2915,W03-0404,1,0.249577,"Missing"
W06-2915,J04-3002,1,0.119165,"earning the perspective of sentences. We propose a novel statistical model to overcome this problem. The experimental results show that the proposed statistical models can successfully identify the perspective from which a document is written with high accuracy. 2 Related Work Identifying the perspective from which a document is written is a subtask in the growing area of automatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and 110 Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005). While by its very nature we expect much of the language that is used when presenting a perspective or point-of-view to be subjective, labeling a document or a sentence as subjective is not"
W06-2915,H05-1044,1,0.0324732,"d extraction. Subjective language is used to express opinions, emotions, and sentiments. So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and 110 Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005). While by its very nature we expect much of the language that is used when presenting a perspective or point-of-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Moreover, the ideology and beliefs authors possess are often expressed in ways other than positive or negative language toward specific targets. Research on the automatic classification of movie or product reviews as positive or negative (e.g., (Pang et al., 2002; Morinaga et al., 2002; Turney and Littman, 2003; Nasukawa and Yi, 2003; Mullen and"
W06-2915,W03-1017,0,0.0797858,"overcome this problem. The experimental results show that the proposed statistical models can successfully identify the perspective from which a document is written with high accuracy. 2 Related Work Identifying the perspective from which a document is written is a subtask in the growing area of automatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and 110 Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005). While by its very nature we expect much of the language that is used when presenting a perspective or point-of-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Moreover, the ideology and b"
W06-2915,W04-3253,0,\N,Missing
W06-2915,H05-2017,0,\N,Missing
W07-1530,W05-0305,1,0.887762,"Missing"
W07-1530,J93-2004,0,0.0279621,"Missing"
W07-1530,W04-2703,1,0.832896,"Missing"
W07-1530,W04-0212,1,0.90064,"Missing"
W07-1530,J05-2005,0,0.0850358,"Missing"
W07-1530,W04-0213,1,0.81694,"d projects/muc/. 2 The Automated Content Extraction program, www.nist.gov/speech/tests/ace/. 192 genre-specific corpus of German newspaper commentaries, taken from the daily papers M¨arkische Allgemeine Zeitung and Tagesspiegel. One central aim is to provide a tool for studying mechanisms of argumentation and how they are reflected on the linguistic surface. The corpus on the one hand is a collection of “raw” data, which is used for genreoriented statistical explorations. On the other hand, we have identified two sub-corpora that are subject to a rich multi-level annotation (MLA). The PCC176 (Stede, 2004) is a sub-corpus that is available upon request for research purposes. It consists of 176 relatively short commentaries (1215 sentences), with 33.000 tokens in total. The sentences have been PoS-tagged automatically (and manually checked); sentence syntax was annotated semi-automatically using the TIGER scheme (Brants et al., 2002) and Annotate3 tool. In addition, we annotated coreference (PoCos (Krasavina and Chiarcos, 2007)) and rhetorical structure according to RST (Mann and Thompson, 1988). Our annotation software architecture consists of a variety of standard, external tools that can be u"
W07-1530,J02-4002,1,0.73024,"a single, very complex annotation step; • end up with less ambiguity in the annotations, since the reasons for specific decisions can be made explicit (by annotations on “simpler” levels); • be more explicit than a single tree can be: if a discourse fulfills, for example, a function both for thematic development and for the writer’s intention, they can both be accounted for; • provide the central information that a “traditional” rhetorical tree conveys, without loosing essential information. 5 AZ Corpus (Simone Teufel, Cambridge) The Argumentative Zoning (AZ) annotation scheme (Teufel, 2000; Teufel and Moens, 2002) is concerned with marking argumentation steps in scientific articles. One example for an argumentation step is the description of the research goal, another an overt comparison of the authors’ work with rival approaches. In our scheme, these argumentation steps have to be associated with text spans (sentences or sequences of sentences). AZ–Annotation is the labelling of each sentence in the text with one of these labels (7 in the original scheme in (Teufel, 2000)). The AZ labels are seen as relations holding between the meanings of these spans, and the rhetorical act of the entire paper. (Teu"
W07-1530,E99-1015,1,0.662031,"02) is concerned with marking argumentation steps in scientific articles. One example for an argumentation step is the description of the research goal, another an overt comparison of the authors’ work with rival approaches. In our scheme, these argumentation steps have to be associated with text spans (sentences or sequences of sentences). AZ–Annotation is the labelling of each sentence in the text with one of these labels (7 in the original scheme in (Teufel, 2000)). The AZ labels are seen as relations holding between the meanings of these spans, and the rhetorical act of the entire paper. (Teufel et al., 1999) reports on interannotator agreement studies with this scheme. There is a strong interrelationship between the argumentation in a paper, and the citations writers use to support their argument. Therefore, a part of the computational linguistics corpus has a second layer of annotation, called CFC (Teufel et al., 2006) or Citation Function Classification. CFC– annotation records for each citation which rhetorical function it plays in the argument. This is following the spirit of research in citation content analysis (e.g., (Moravcsik and Murugesan, 1975)). An example for a ci193 tation function"
W07-1530,W06-1312,1,0.772883,"sequences of sentences). AZ–Annotation is the labelling of each sentence in the text with one of these labels (7 in the original scheme in (Teufel, 2000)). The AZ labels are seen as relations holding between the meanings of these spans, and the rhetorical act of the entire paper. (Teufel et al., 1999) reports on interannotator agreement studies with this scheme. There is a strong interrelationship between the argumentation in a paper, and the citations writers use to support their argument. Therefore, a part of the computational linguistics corpus has a second layer of annotation, called CFC (Teufel et al., 2006) or Citation Function Classification. CFC– annotation records for each citation which rhetorical function it plays in the argument. This is following the spirit of research in citation content analysis (e.g., (Moravcsik and Murugesan, 1975)). An example for a ci193 tation function would be “motivate that the method used is sound”. The annotation scheme contains 12 functions, clustered into “superiority”, “neutral comparison/contrast”, “praise or usage” and “neutral”. One type of research we hope to do in the future is to study the relationship between these rhetorical phonemena with more tradi"
W08-0122,P04-1035,0,0.0146039,"a target respects the co-reference but it also results in incorrect conclusions: the speech recognition is an alternative to having both speech recognition and buttons. (7) A:: One thing is interesting is talking about speech recognition in a remote control... D:: ... So that we don’t need any button on the remote control it would be all based on speech. A:: ... I think that would not work so well. You wanna have both options. 5 Related Work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (Riloff et al., 2003; Pang and Lee, 2004)) and adjacency pair information has been used to predict congressional votes (Thomas et al., 2006). However, these methods do not explicitly model the relations between opinions. Additionally, in our scheme opinions that are not in the immediate context may be allowed to influence the interpretation of a given opinion via target chains. Polanyi and Zaenen (2006), in their discussion on contextual valence shifters, have also observed the phenomena described in this work - namely that a central topic may be divided into subtopics in order to perform evaluations, and that discourse structure can"
W08-0122,passonneau-2004-computing,0,0.0444751,"ging is very high. This confirms our hypothesis that Sentiment and Arguing can be reliably distinguished once the opinion spans are known. Our polarity detection task shows an improvement in κ over a similar polarity assignment task by Wilson et al. (2005) for the news corpus (κ of 0.72). We believe this improvement can partly be attributed to the target information available to our annotators. 4.4 Target Linking As an intuitive first step in evaluating target linking, we treat target links in the discourse similarly to anaphoric chains and apply methods developed for co-reference resolution (Passonneau, 2004) for our evaluation. Passonneau’s method is based on Krippendorf’s α metric (Krippendorff, 2004) and allows for partial matches between anaphoric chains. In addition to this, we evaluate links identified by both annotators for the type (same / alternative) labeling task with the help of the κ metric. Passonneau (2004) reports that in her co-reference task on spoken monologs, α varies with the difficulty of the corpus (from 0.46 to 0.74). This is true in our case too. Table 6 shows our agreement for the four types of meetings in the AMI corpus: the kickoff meeting (a), the functional design (b)"
W08-0122,W06-0305,0,0.0127562,"nce. Snyder and Barzilay (2007) combine an agreement model based on contrastive RST relations with a local aspect (or target) model to make a more informed overall decision for sentiment classification. The contrastive cue indicates a change in the sentiment polarity. In our scheme, their aspects would be related as same and their high contrast relations would result in frames such as SPSNsame, SNSPsame. Additionally, our frame relations would link sentiments across non-adjacent clauses, and make connections via alt target relations. Considering the discourse relation annotations in the PDTB (Prasad et al., 2006), there can be alignment between discourse relations (like contrast) and our opinion frames when the frames represent dominant relations between two clauses. However, when the relation between opinions is not the most prominent one between two clauses, the discourse relation may not align with the opinion frames. And when an opinion frame is between two opinions in the same clause, there would be no discourse relation counterpart at all. Further, opinion frames assume particular intentions that are not necessary for the establishment of ostensibly similar discourse relations. For example, we m"
W08-0122,W03-0404,1,0.716835,"speech recognition as a target respects the co-reference but it also results in incorrect conclusions: the speech recognition is an alternative to having both speech recognition and buttons. (7) A:: One thing is interesting is talking about speech recognition in a remote control... D:: ... So that we don’t need any button on the remote control it would be all based on speech. A:: ... I think that would not work so well. You wanna have both options. 5 Related Work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (Riloff et al., 2003; Pang and Lee, 2004)) and adjacency pair information has been used to predict congressional votes (Thomas et al., 2006). However, these methods do not explicitly model the relations between opinions. Additionally, in our scheme opinions that are not in the immediate context may be allowed to influence the interpretation of a given opinion via target chains. Polanyi and Zaenen (2006), in their discussion on contextual valence shifters, have also observed the phenomena described in this work - namely that a central topic may be divided into subtopics in order to perform evaluations, and that di"
W08-0122,N07-1038,0,0.0392226,"predict congressional votes (Thomas et al., 2006). However, these methods do not explicitly model the relations between opinions. Additionally, in our scheme opinions that are not in the immediate context may be allowed to influence the interpretation of a given opinion via target chains. Polanyi and Zaenen (2006), in their discussion on contextual valence shifters, have also observed the phenomena described in this work - namely that a central topic may be divided into subtopics in order to perform evaluations, and that discourse structure can influence the overall interpretation of valence. Snyder and Barzilay (2007) combine an agreement model based on contrastive RST relations with a local aspect (or target) model to make a more informed overall decision for sentiment classification. The contrastive cue indicates a change in the sentiment polarity. In our scheme, their aspects would be related as same and their high contrast relations would result in frames such as SPSNsame, SNSPsame. Additionally, our frame relations would link sentiments across non-adjacent clauses, and make connections via alt target relations. Considering the discourse relation annotations in the PDTB (Prasad et al., 2006), there can"
W08-0122,2007.sigdial-1.5,1,0.928388,"l votes (Thomas et al., 2006). However, these methods do not explicitly model the relations between opinions. Additionally, in our scheme opinions that are not in the immediate context may be allowed to influence the interpretation of a given opinion via target chains. Polanyi and Zaenen (2006), in their discussion on contextual valence shifters, have also observed the phenomena described in this work - namely that a central topic may be divided into subtopics in order to perform evaluations, and that discourse structure can influence the overall interpretation of valence. Snyder and Barzilay (2007) combine an agreement model based on contrastive RST relations with a local aspect (or target) model to make a more informed overall decision for sentiment classification. The contrastive cue indicates a change in the sentiment polarity. In our scheme, their aspects would be related as same and their high contrast relations would result in frames such as SPSNsame, SNSPsame. Additionally, our frame relations would link sentiments across non-adjacent clauses, and make connections via alt target relations. Considering the discourse relation annotations in the PDTB (Prasad et al., 2006), there can"
W08-0122,W06-1639,0,0.0256134,"nition is an alternative to having both speech recognition and buttons. (7) A:: One thing is interesting is talking about speech recognition in a remote control... D:: ... So that we don’t need any button on the remote control it would be all based on speech. A:: ... I think that would not work so well. You wanna have both options. 5 Related Work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (Riloff et al., 2003; Pang and Lee, 2004)) and adjacency pair information has been used to predict congressional votes (Thomas et al., 2006). However, these methods do not explicitly model the relations between opinions. Additionally, in our scheme opinions that are not in the immediate context may be allowed to influence the interpretation of a given opinion via target chains. Polanyi and Zaenen (2006), in their discussion on contextual valence shifters, have also observed the phenomena described in this work - namely that a central topic may be divided into subtopics in order to perform evaluations, and that discourse structure can influence the overall interpretation of valence. Snyder and Barzilay (2007) combine an agreement m"
W08-0122,W05-0308,1,0.928307,"SNSPsame, APANsame, ANAPsame, SPANsame, APSNsame, SNAPsame, ANSPsame, SPSPalt, SNSNalt, APAPalt, ANANalt, SPAPalt, SNANalt, APSPalt, ANSNalt Opinion frames are presented in Section 2, our annotation scheme is described in Section 3, the interannotator agreement studies are presented in Section 4, related work is discussed in Section 5, and conclusions are in Section 6. 2 Opinion Frames 2.1 Table 1: Opinion Frames Introduction The components of opinion frames are individual opinions and the relationships between their targets. We address two types of opinions, sentiment and arguing. Following (Wilson and Wiebe, 2005; Somasundaran et al., 2007), sentiment includes positive and negative evaluations, emotions, and judgments, while arguing includes arguing for or against something, and arguing that something should or should not be done. In our examples, the lexical anchors revealing the opinion type (as the words are interpreted in context) are indicated in bold face. In addition, the text span capturing the target of the opinion (again, as interpreted in context) is indicated in italics. (2) D:: . . . this kind of rubbery material, it’s a bit more bouncy, like you said they get chucked around a lot. A bit"
W08-0122,H05-1044,1,0.0655995,"Missing"
W09-3210,C08-2002,0,0.0173397,"ille and Jensen (2000), Lu and Getoor (2003), Taskar et al. (2004), Richardson and Domingos (2006)). In this paper, we use an approach proposed by (Bilgic et al., 2007) which iteratively predicts class and link existence using local classifiers. Other joint models used in sentiment classification include the spin model (Takamura et al., 2007), relaxation labeling (Popescu and Etzioni, 2005), and label propagation (Goldberg and Zhu, 2006). Polanyi and Zaenen (2006) observe that a central topic may be divided into subtopics in order to perform evaluations. Similar to Somasundaran et al. (2008), Asher et al. (2008) advocate a discourse-level analysis in order to get a deeper understanding of contextual polarity and the strength of opinions. However, these works do not provide an implementation for their insights. In this work we demonstrate a concrete way that discourse-level interpretation can improve recognition of individual opinions and their polarities. Graph-based approaches for joint inference in sentiment analysis have been explored previously by many researchers. The biggest difference between this work and theirs is in what the links represent linguistically. Some of these are not related to d"
W09-3210,C08-2004,0,0.0151175,"dual opinions and their polarities. Graph-based approaches for joint inference in sentiment analysis have been explored previously by many researchers. The biggest difference between this work and theirs is in what the links represent linguistically. Some of these are not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word based measures like TF-IDF (Goldberg and Zhu, 2006)). Some of these work on sentence cohesion (Pang and Lee, 2004) or agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008). Our model is not based on sentence cohesion or structural adjacency. The relations due to the opinion frames are based on relationships between targets and discourse-level functions of opinions being mutually reinforcing or non-reinforcing. Adjacent instances need not be related via opinion frames, while long distant relations can be present if opinion targets are same or alternatives. Also, previous efforts in graph-based joint inference in opinion analysis has been textbased, while our work is over multi-party conversations. 7 Conclusion This work uses an opinion graph framework, DLOG, to"
W09-3210,H05-1043,0,0.023437,"h their genre is different, we plan to experiment with their full feature set for improving our TLC system. Turning to collective classification, there have been various collective classification frameworks proposed (for example, Neville and Jensen (2000), Lu and Getoor (2003), Taskar et al. (2004), Richardson and Domingos (2006)). In this paper, we use an approach proposed by (Bilgic et al., 2007) which iteratively predicts class and link existence using local classifiers. Other joint models used in sentiment classification include the spin model (Takamura et al., 2007), relaxation labeling (Popescu and Etzioni, 2005), and label propagation (Goldberg and Zhu, 2006). Polanyi and Zaenen (2006) observe that a central topic may be divided into subtopics in order to perform evaluations. Similar to Somasundaran et al. (2008), Asher et al. (2008) advocate a discourse-level analysis in order to get a deeper understanding of contextual polarity and the strength of opinions. However, these works do not provide an implementation for their insights. In this work we demonstrate a concrete way that discourse-level interpretation can improve recognition of individual opinions and their polarities. Graph-based approaches"
W09-3210,sadamitsu-etal-2008-sentiment,0,0.028618,"fier performs substantially better than the Local classifier for all metrics and all classes. The accuracy improves by 10 percentage points, while the Fmeasure improves by about 15 percentage points for the minority (positive and negative) classes. This result confirms that our discourse-level opinion graphs are useful and discourse-level information is non-redundant with lexical and dialog-act 6 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. 72 summaries. We do not model topics; instead we directly model the relations between targets. The focus of our work is to jointly model opinion polarities via target relations. The task of finding coreferent opinion topics by (Stoyanov and Cardie, 2008) is similar to our target link classification task, and we use somewhat similar features. Even though their genre is different, we plan to experiment with their full feature set for improving our TLC system. Turning to collective classification, there have been various collective classi"
W09-3210,N07-1038,0,0.103265,"Missing"
W09-3210,P07-1124,0,0.0241535,"the ICA-LinkNeigh classifier performs substantially better than the Local classifier for all metrics and all classes. The accuracy improves by 10 percentage points, while the Fmeasure improves by about 15 percentage points for the minority (positive and negative) classes. This result confirms that our discourse-level opinion graphs are useful and discourse-level information is non-redundant with lexical and dialog-act 6 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. 72 summaries. We do not model topics; instead we directly model the relations between targets. The focus of our work is to jointly model opinion polarities via target relations. The task of finding coreferent opinion topics by (Stoyanov and Cardie, 2008) is similar to our target link classification task, and we use somewhat similar features. Even though their genre is different, we plan to experiment with their full feature set for improving our TLC system. Turning to collective classification, there have been"
W09-3210,2007.sigdial-1.5,1,0.929828,". Thus the reinforcing frame link emerges as being the most likely candidate. This in turn disambiguates the polarity of a bit different. Thus, by establishing target links and frame links between the opinion instances, we are able to perform a joint interpretation of the opinions. The interdependent framework of this example is iterative and dynamic — the information in the nodes can be used to change the structure (i.e., 4 Collective Classification Framework For our collective classification framework, we use a variant of the iterative classification algorithm (ICA) proposed by Bilgic et al (2007). It combines several common prediction tasks in graphs: object classification (predicting the label of an object) and link prediction (predicting the existence and class of a link between objects). For our tasks, object classification directly corresponds to predicting opinion polarity and the link prediction corresponds to predicting the existence of a same or alternative target link or a reinforcing or non-reinforcing frame link between opinions. We note that given the nature of our problem formulation and approach, we use the terms link prediction and link classification interchangeably. I"
W09-3210,W06-3808,0,0.0679889,"ith their full feature set for improving our TLC system. Turning to collective classification, there have been various collective classification frameworks proposed (for example, Neville and Jensen (2000), Lu and Getoor (2003), Taskar et al. (2004), Richardson and Domingos (2006)). In this paper, we use an approach proposed by (Bilgic et al., 2007) which iteratively predicts class and link existence using local classifiers. Other joint models used in sentiment classification include the spin model (Takamura et al., 2007), relaxation labeling (Popescu and Etzioni, 2005), and label propagation (Goldberg and Zhu, 2006). Polanyi and Zaenen (2006) observe that a central topic may be divided into subtopics in order to perform evaluations. Similar to Somasundaran et al. (2008), Asher et al. (2008) advocate a discourse-level analysis in order to get a deeper understanding of contextual polarity and the strength of opinions. However, these works do not provide an implementation for their insights. In this work we demonstrate a concrete way that discourse-level interpretation can improve recognition of individual opinions and their polarities. Graph-based approaches for joint inference in sentiment analysis have b"
W09-3210,C08-1101,1,0.908683,"from the details (type and polarity) of the opinions it relates and the target relation involved. Even though the different combinations of opinion type (sentiment and arguing), polarity (positive and negative) and target links (same and alternative) result in many distinct frames types (32 in total), they can be grouped, according to their discourse-level characteristics, into the two categories reinforcing and non-reinforcing. In this work, we only make this category distinction for opinion frames and the corresponding frame links. The next example (Example 2, also from Somasundaran et al. (2008)) illustrates an alternative target relation. In the domain of TV remote controls, the set of all shapes are alternatives to one another, since a remote control may have only one shape at a time. In such scenarios, a positive opinion regarding one choice may imply a negative opinion toward competing choices, and vice versa. In this passage, speaker C’s positive stance towards the curved shape is brought out even more strongly with his negative opinions toward the alternative, square-like, shapes. In this section, we describe these graphs and illustrate their applicability to goal-oriented mult"
W09-3210,C08-1103,0,0.0199362,"are useful and discourse-level information is non-redundant with lexical and dialog-act 6 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. 72 summaries. We do not model topics; instead we directly model the relations between targets. The focus of our work is to jointly model opinion polarities via target relations. The task of finding coreferent opinion topics by (Stoyanov and Cardie, 2008) is similar to our target link classification task, and we use somewhat similar features. Even though their genre is different, we plan to experiment with their full feature set for improving our TLC system. Turning to collective classification, there have been various collective classification frameworks proposed (for example, Neville and Jensen (2000), Lu and Getoor (2003), Taskar et al. (2004), Richardson and Domingos (2006)). In this paper, we use an approach proposed by (Bilgic et al., 2007) which iteratively predicts class and link existence using local classifiers. Other joint models us"
W09-3210,N07-1037,0,0.0439036,"we use somewhat similar features. Even though their genre is different, we plan to experiment with their full feature set for improving our TLC system. Turning to collective classification, there have been various collective classification frameworks proposed (for example, Neville and Jensen (2000), Lu and Getoor (2003), Taskar et al. (2004), Richardson and Domingos (2006)). In this paper, we use an approach proposed by (Bilgic et al., 2007) which iteratively predicts class and link existence using local classifiers. Other joint models used in sentiment classification include the spin model (Takamura et al., 2007), relaxation labeling (Popescu and Etzioni, 2005), and label propagation (Goldberg and Zhu, 2006). Polanyi and Zaenen (2006) observe that a central topic may be divided into subtopics in order to perform evaluations. Similar to Somasundaran et al. (2008), Asher et al. (2008) advocate a discourse-level analysis in order to get a deeper understanding of contextual polarity and the strength of opinions. However, these works do not provide an implementation for their insights. In this work we demonstrate a concrete way that discourse-level interpretation can improve recognition of individual opini"
W09-3210,W06-1642,0,0.0734569,"iterion is met. For our experiments, we use a fixed number of 30 iterations which was sufficient, in most of our datasets, for ICA to converge to a solution. The pseudocode for the algorithm is shown in Algorithm 4.1. Table 1: Features and the classification task it is used for; TLC = target-link classification, FLC = Frame-link classification tures. We use lexicons that have been successfully used in previous work (the polarity lexicon from (Wilson et al., 2005) and the arguing lexicon (Somasundaran et al., 2007)). Previous work used features based on parse trees, e.g., (Wilson et al., 2005; Kanayama and Nasukawa, 2006), but our data has very different characteristics from monologic texts – the utterances and sentences are much shorter, and there are frequent disfluencies, restarts, hedging and repetitions. Because of this, we cannot rely on parsing features. On the other hand, in this data, we have dialog act information1 (Dialog Acts), which we can exploit. Note that the IPC uses only the Dialog Act tags (instance level tags like Inform, Suggest) and not the dialog structure information. Opinion frame detection between sentences has been previously attempted (Somasundaran et al., 2008) by using features th"
W09-3210,W06-1639,0,0.0602779,"recognition of individual opinions and their polarities. Graph-based approaches for joint inference in sentiment analysis have been explored previously by many researchers. The biggest difference between this work and theirs is in what the links represent linguistically. Some of these are not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word based measures like TF-IDF (Goldberg and Zhu, 2006)). Some of these work on sentence cohesion (Pang and Lee, 2004) or agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008). Our model is not based on sentence cohesion or structural adjacency. The relations due to the opinion frames are based on relationships between targets and discourse-level functions of opinions being mutually reinforcing or non-reinforcing. Adjacent instances need not be related via opinion frames, while long distant relations can be present if opinion targets are same or alternatives. Also, previous efforts in graph-based joint inference in opinion analysis has been textbased, while our work is over multi-party conversations. 7 Conclusion This work uses an opinion grap"
W09-3210,P08-1036,0,0.0911941,"Missing"
W09-3210,P07-1055,0,0.0364669,"olarity classification, even with partial neighborhood information. Our experiments showed three to five percentage points improvement in F-measure with link information, and 15 percentage point improvement with full neighborhood information. These results show that lexical and discourse information are non-redundant for polarity classification, and our DLOG, that employs both, improves performance. We discovered that link classification is a difficult problem. Here again, we found that by using the DLOG framework, and using even partial neighborhood information, improvements can be achieved. McDonald et al. (2007) propose a joint model for sentiment classification based on relations defined by granularity (sentence and document). Snyder and Barzilay (2007) combine an agreement model based on contrastive RST relations with a local aspect (topic) model. Their aspects would be related as same and their high contrast relations would correspond to (a subset of) the non-reinforcing frames. In the field of product review mining, sentiments and features (aspects or targets) have been mined (for example, Yi et al. (2003), Popescu and Etzioni (2005), and Hu and Liu (2006)). More recently there has been work on c"
W09-3210,H05-1044,1,0.189141,"ing the local features and the values of the currently predicted relational features based on previous predictions. We repeat this until some stopping criterion is met. For our experiments, we use a fixed number of 30 iterations which was sufficient, in most of our datasets, for ICA to converge to a solution. The pseudocode for the algorithm is shown in Algorithm 4.1. Table 1: Features and the classification task it is used for; TLC = target-link classification, FLC = Frame-link classification tures. We use lexicons that have been successfully used in previous work (the polarity lexicon from (Wilson et al., 2005) and the arguing lexicon (Somasundaran et al., 2007)). Previous work used features based on parse trees, e.g., (Wilson et al., 2005; Kanayama and Nasukawa, 2006), but our data has very different characteristics from monologic texts – the utterances and sentences are much shorter, and there are frequent disfluencies, restarts, hedging and repetitions. Because of this, we cannot rely on parsing features. On the other hand, in this data, we have dialog act information1 (Dialog Acts), which we can exploit. Note that the IPC uses only the Dialog Act tags (instance level tags like Inform, Suggest) a"
W09-3210,P04-1035,0,0.0395443,"a concrete way that discourse-level interpretation can improve recognition of individual opinions and their polarities. Graph-based approaches for joint inference in sentiment analysis have been explored previously by many researchers. The biggest difference between this work and theirs is in what the links represent linguistically. Some of these are not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word based measures like TF-IDF (Goldberg and Zhu, 2006)). Some of these work on sentence cohesion (Pang and Lee, 2004) or agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008). Our model is not based on sentence cohesion or structural adjacency. The relations due to the opinion frames are based on relationships between targets and discourse-level functions of opinions being mutually reinforcing or non-reinforcing. Adjacent instances need not be related via opinion frames, while long distant relations can be present if opinion targets are same or alternatives. Also, previous efforts in graph-based joint inference in opinion analysis has been textbased, while our work is over multi-"
W09-3210,H05-2017,0,\N,Missing
W10-0214,C08-2004,0,0.136299,"Missing"
W10-0214,D09-1062,0,0.0186604,"ated independent of arguing features. In order to detect sentiment opinions, we use a sentiment lexicon (Wilson et al., 2005). In addition to positive (+ ) and negative (− ) words, this lexicon also contains subjective words that are themselves neutral (= ) with respect to polarity. Examples of neutral entries are “absolutely”, “amplify”, “believe”, and “think”. We find the sentiment polarity of the entire sentence and assign this polarity to each content word in the sentence (denoted, for example, as target+ ). In order to detect the sentence polarity, we use the Vote and Flip algorithm from Choi and Cardie (2009). This algorithm essentially counts the number of positive, negative and neutral lexicon hits in a given expression and accounts for negator words. The algorithm is used as is, except for the default polarity assignment (as we do not know the most prominent polarity in the corpus). Note that the Vote and Flip algorithm has been developed for expressions but we employ it on sentences. Once the polarity of a sentence is determined, we create sentiment features for the sentence. This is done for all sentences in the post. 5 Experiments Experiments are carried out on debate posts from the followin"
W10-0214,N09-1057,0,0.0294865,"ords in differing frequencies. On similar lines, Kim and Hovy (2007) use unigrams, bigrams and trigrams for election prediction from forum posts. In contrast, our work specifically employs sentiment-based and arguing-based features to perform stance classification in political debates. Our experiments are focused on determining how different opinion expressions reinforce an overall political stance. Our results indicate that while unigram information is reliable, further improvements can be achieved in certain domains using our opinion-based approach. Our work is also complementary to that by Greene and Resnik (2009), which focuses on syntactic packaging for recognizing perspectives. For Gay Rights Against Gay Rights Unigram Features constitution, fundamental, rights, suffrage, pursuit, discrimina- pervert, hormone, liberty, fidelity, naval, retarded, orientation, prition, government, happiness, shame, wed, gay, heterosexual- vate, partner, kingdom, bible, sin, bigot ity, chromosome, evolution, genetic, christianity, mormonism, corinthians, procreate, adopt Arguing Features from Arg+Sent ap-constitution, ap-fundamental, ap-rights, ap-hormone, an-constitution, an-fundamental, an-rights, an-hormone, ap-libe"
W10-0214,D07-1113,0,0.0182875,"explicitly encode these fine-grained distinctions in this work). Interestingly, we found that sentiment features in Arg+Sent are not as informative as the arguing features discussed above. 6 Related Work Generally, research in identifying political viewpoints has employed information from words in the document (Malouf and Mullen, 2008; Mullen and Malouf, 2006; Grefenstette et al., 2004; Laver et al., 2003; Martin and Vanberg, 2008; Lin et al., 2006; Lin, 2006). Specifically, Lin et al. observe that people from opposing perspectives seem to use words in differing frequencies. On similar lines, Kim and Hovy (2007) use unigrams, bigrams and trigrams for election prediction from forum posts. In contrast, our work specifically employs sentiment-based and arguing-based features to perform stance classification in political debates. Our experiments are focused on determining how different opinion expressions reinforce an overall political stance. Our results indicate that while unigram information is reliable, further improvements can be achieved in certain domains using our opinion-based approach. Our work is also complementary to that by Greene and Resnik (2009), which focuses on syntactic packaging for r"
W10-0214,W06-2915,1,0.764557,"e the choice of topics with the stances, while the arguing features can capture the concerns, defenses, appeals or denials that signify each side (though we do not explicitly encode these fine-grained distinctions in this work). Interestingly, we found that sentiment features in Arg+Sent are not as informative as the arguing features discussed above. 6 Related Work Generally, research in identifying political viewpoints has employed information from words in the document (Malouf and Mullen, 2008; Mullen and Malouf, 2006; Grefenstette et al., 2004; Laver et al., 2003; Martin and Vanberg, 2008; Lin et al., 2006; Lin, 2006). Specifically, Lin et al. observe that people from opposing perspectives seem to use words in differing frequencies. On similar lines, Kim and Hovy (2007) use unigrams, bigrams and trigrams for election prediction from forum posts. In contrast, our work specifically employs sentiment-based and arguing-based features to perform stance classification in political debates. Our experiments are focused on determining how different opinion expressions reinforce an overall political stance. Our results indicate that while unigram information is reliable, further improvements can be achie"
W10-0214,N06-3005,0,0.0179873,"pics with the stances, while the arguing features can capture the concerns, defenses, appeals or denials that signify each side (though we do not explicitly encode these fine-grained distinctions in this work). Interestingly, we found that sentiment features in Arg+Sent are not as informative as the arguing features discussed above. 6 Related Work Generally, research in identifying political viewpoints has employed information from words in the document (Malouf and Mullen, 2008; Mullen and Malouf, 2006; Grefenstette et al., 2004; Laver et al., 2003; Martin and Vanberg, 2008; Lin et al., 2006; Lin, 2006). Specifically, Lin et al. observe that people from opposing perspectives seem to use words in differing frequencies. On similar lines, Kim and Hovy (2007) use unigrams, bigrams and trigrams for election prediction from forum posts. In contrast, our work specifically employs sentiment-based and arguing-based features to perform stance classification in political debates. Our experiments are focused on determining how different opinion expressions reinforce an overall political stance. Our results indicate that while unigram information is reliable, further improvements can be achieved in certa"
W10-0214,P09-1026,1,0.760047,"ng stances in ideological debates. In order to capture arguing opinions in ideological stance taking, we construct an arguing lexicon automatically from a manually annotated corpus. We build supervised systems employing sentiment and arguing opinions and their targets as features. Our systems perform substantially better than a distribution-based baseline. Additionally, by employing both types of opinion features, we are able to perform better than a unigrambased system. 1 Introduction In this work, we explore if and how ideological stances can be recognized using opinion analysis. Following (Somasundaran and Wiebe, 2009), stance, as used in this work, refers to an overall position held by a person toward an object, idea or proposition. For example, in a debate “Do you believe in the existence of God?,” a person may take a for-existence of God stance or an against existence of God stance. Similarly, being pro-choice, believing in creationism, and supporting universal healthcare are all examples of ideological stances. Online web forums discussing ideological and political hot-topics are popular.1 In this work, we are 1 http://www.opposingviews.com, http://wiki.idebate.org, http://www.createdebate.com and http:"
W10-0214,2007.sigdial-1.5,1,0.571386,"-adopt Table 5: Examples of features associated with the stances in Gay Rights domain Discourse-level participant relation, that is, whether participants agree/disagree has been found useful for determining political side-taking (Thomas et al., 2006; Bansal et al., 2008; Agrawal et al., 2003; Malouf and Mullen, 2008). Agreement/disagreement relations are not the main focus of our work. Other work in the area of polarizing political discourse analyze co-citations (Efron, 2004) and linking patterns (Adamic and Glance, 2005). In contrast, our focus is on document content and opinion expressions. Somasundaran et al. (2007b) have noted the usefulness of the arguing category for opinion QA. Our tasks are different; they use arguing to retrieve relevant answers, but not distinguish stances. Our work is also different from related work in the domain of product debates (Somasundaran and Wiebe, 2009) in terms of the methodology. Wilson (2007) manually adds positive/negative arguing information to entries in a sentiment lexicon from (Wilson et al., 2005) and uses these as arguing features. Our arguing trigger expressions are separate from the sentiment lexicon entries and are derived from a corpus. Our n-gram trigger"
W10-0214,C08-1101,1,0.837612,"r of universal healthcare. This negative opinion reveals his against-healthcare stance. We observed that arguing, a less well explored type of subjectivity, is prominently manifested in ideological debates. As used in this work, arguing is a type of linguistic subjectivity, where a person is arguing for or against something or expressing a belief about what is true, should be true or should be done 2 As used in this work, sentiment is a type of linguistic subjectivity, specifically positive and negative expressions of emotions, judgments, and evaluations (Wilson and Wiebe, 2005; Wilson, 2007; Somasundaran et al., 2008). 116 Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 116–124, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics in his or her view of the world (Wilson and Wiebe, 2005; Wilson, 2007; Somasundaran et al., 2008). For instance, let us consider the following snippet from a post supporting an against-existence of God stance. (2) Obviously that hasn’t happened, and to be completely objective (as all scientists should be) we must lean on the side of greatest evidence which at the present ti"
W10-0214,W06-1639,0,0.670961,", ap-partner, an-private, an-wed, an-gay, ap-heterosexuality, an-partner, ap-chromosome, ap-evolution, ap-genetic, an-kingdom, an- an-chromosome, an-evolution, an-genetic, ap-kingdom, apchristianity, an-mormonism, an-corinthians, an-bible, an-sin, christianity, ap-mormonism, ap-corinthians, ap-bible, ap-sin, an-bigot, an-procreate, ap-adopt, ap-bigot, ap-procreate, an-adopt Table 5: Examples of features associated with the stances in Gay Rights domain Discourse-level participant relation, that is, whether participants agree/disagree has been found useful for determining political side-taking (Thomas et al., 2006; Bansal et al., 2008; Agrawal et al., 2003; Malouf and Mullen, 2008). Agreement/disagreement relations are not the main focus of our work. Other work in the area of polarizing political discourse analyze co-citations (Efron, 2004) and linking patterns (Adamic and Glance, 2005). In contrast, our focus is on document content and opinion expressions. Somasundaran et al. (2007b) have noted the usefulness of the arguing category for opinion QA. Our tasks are different; they use arguing to retrieve relevant answers, but not distinguish stances. Our work is also different from related work in the do"
W10-0214,W05-0308,1,0.676554,"ed toward the government, the initiator of universal healthcare. This negative opinion reveals his against-healthcare stance. We observed that arguing, a less well explored type of subjectivity, is prominently manifested in ideological debates. As used in this work, arguing is a type of linguistic subjectivity, where a person is arguing for or against something or expressing a belief about what is true, should be true or should be done 2 As used in this work, sentiment is a type of linguistic subjectivity, specifically positive and negative expressions of emotions, judgments, and evaluations (Wilson and Wiebe, 2005; Wilson, 2007; Somasundaran et al., 2008). 116 Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 116–124, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics in his or her view of the world (Wilson and Wiebe, 2005; Wilson, 2007; Somasundaran et al., 2008). For instance, let us consider the following snippet from a post supporting an against-existence of God stance. (2) Obviously that hasn’t happened, and to be completely objective (as all scientists should be) we must lean on the side of"
W10-0214,H05-1044,1,0.360997,"e, people not only express their sentiments, but they also argue about what is true (e.g., this is prominent in the existence of God debate) and about what should or should not be done (e.g., this is prominent in the healthcare debate). In this work, we investigate whether sentiment and arguing expressions of opinion are useful for ideological stance classification. For this, we explore ways to capture relevant opinion information as machine learning features into a supervised stance classifier. While there is a large body of resources for sentiment analysis (e.g., the sentiment lexicon from (Wilson et al., 2005)), arguing analysis does not seem to have a well established lexical resource. In order to remedy this, using a simple automatic approach and a manually annotated corpus,3 we construct an arguing lexicon. We create features called opinion-target pairs, which encode not just the opinion information, but also what the opinion is about, its target. Systems employing sentiment-based and arguing-based features alone, or both in combination, are analyzed. We also take a qualitative look at features used by the learners to get insights about the information captured by them. We perform experiments on"
W10-0731,D09-1020,1,0.782035,"P systems subject to a so-called knowledge acquisition bottleneck. For example, (Ng, 1997) estimates an effort of 16 person years to construct training data for a highaccuracy domain independent Word Sense Disambiguation (WSD) system. Recently researchers have been investigating Amazon Mechanical Turk (MTurk) as a source of non-expert natural language annotation, which is a cheap and quick alternative to expert annotations (Kaisser and Lowe, 2008; Mrozinski et al., 2008). In this paper, we utilize MTurk to obtain training data for Subjectivity Word Sense Disambiguation (SWSD) as described in (Akkaya et al., 2009). The goal of SWSD is to automatically determine which word instances in a corpus are being used with subjective senses, and which are being used with objective senses. SWSD is a new task which suffers from the absence of a substantial amount of annotated data and thus can only be applied on a small scale. SWSD has strong connections to WSD. Like supervised WSD, it requires training data where target word instances – words which need to be disambiguated by the system – are labeled as having an objective sense or a subjective sense. (Akkaya et al., 2009) show that SWSD may bring substantial imp"
W10-0731,D09-1030,0,0.447101,"scale. The good news is that training data for 80 selected keywords is enough to make a substantial difference (Akkaya et al., 2009). Thus, large scale SWSD is feasible. We hypothesize that annotations for SWSD can be provided by non-experts reliably if the annotation task is presented in a simple way. The annotations obtained from MTurk workers are noisy by nature, because MTurk workers are not trained for the underlying annotation task. That is why previous work explored methods to assess annotation quality and to aggregate multiple noisy annotations for high reliability (Snow et al., 2008; Callison-Burch, 2009). It is understandable that not every worker will provide high-quality annotations, 195 Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 195–203, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics depending on their background and interest. Unfortunately, some MTurk workers do not follow the annotation guidelines and carelessly submit annotations in order to gain economic benefits with only minimal effort. We define this group of workers as spammers. We believe it is essential to distinguish b"
W10-0731,W09-1904,0,0.0326961,"ing data (in our case for SWSD). Several studies have concentrated specifically on the quality aspect of the MTurk annotations. They investigated methods to assess annotation quality and to aggregate multiple noisy annotations for high reliability. (Snow et al., 2008) report MTurk annotation quality on various NLP tasks (e.g. WSD, Textual Entailment, Word Similarity) and define a bias correction method for non-expert annotators. (Callison-Burch, 2009) uses MTurk workers for manual evaluation of automatic translation quality and experiments with weighed voting to combine multiple annotations. (Hsueh et al., 2009) define various annotation quality measures and show that they are useful for selecting annotations leading to more accurate classifiers. Our work investigates the effect of built-in qualifications on the quality of MTurk annotations. (Hsueh et al., 2009) applies MTurk to get sentiment annotations on political blog snippets. (Snow et al., 2008) utilizes MTurk for affective text annotation task. In both works, MTurk workers annotated larger entities but on a more detailed scale than we 202 do. (Snow et al., 2008) also provides a WSD annotation task which is similar to our annotation task. The d"
W10-0731,kaisser-lowe-2008-creating,0,0.0933232,"ounts of manually annotated data that is collected from domain experts. The annotation process to obtain this data is very laborious and expensive. This makes supervised NLP systems subject to a so-called knowledge acquisition bottleneck. For example, (Ng, 1997) estimates an effort of 16 person years to construct training data for a highaccuracy domain independent Word Sense Disambiguation (WSD) system. Recently researchers have been investigating Amazon Mechanical Turk (MTurk) as a source of non-expert natural language annotation, which is a cheap and quick alternative to expert annotations (Kaisser and Lowe, 2008; Mrozinski et al., 2008). In this paper, we utilize MTurk to obtain training data for Subjectivity Word Sense Disambiguation (SWSD) as described in (Akkaya et al., 2009). The goal of SWSD is to automatically determine which word instances in a corpus are being used with subjective senses, and which are being used with objective senses. SWSD is a new task which suffers from the absence of a substantial amount of annotated data and thus can only be applied on a small scale. SWSD has strong connections to WSD. Like supervised WSD, it requires training data where target word instances – words whi"
W10-0731,P08-1051,0,0.121127,"ted data that is collected from domain experts. The annotation process to obtain this data is very laborious and expensive. This makes supervised NLP systems subject to a so-called knowledge acquisition bottleneck. For example, (Ng, 1997) estimates an effort of 16 person years to construct training data for a highaccuracy domain independent Word Sense Disambiguation (WSD) system. Recently researchers have been investigating Amazon Mechanical Turk (MTurk) as a source of non-expert natural language annotation, which is a cheap and quick alternative to expert annotations (Kaisser and Lowe, 2008; Mrozinski et al., 2008). In this paper, we utilize MTurk to obtain training data for Subjectivity Word Sense Disambiguation (SWSD) as described in (Akkaya et al., 2009). The goal of SWSD is to automatically determine which word instances in a corpus are being used with subjective senses, and which are being used with objective senses. SWSD is a new task which suffers from the absence of a substantial amount of annotated data and thus can only be applied on a small scale. SWSD has strong connections to WSD. Like supervised WSD, it requires training data where target word instances – words which need to be disambiguat"
W10-0731,W97-0201,0,0.110822,"conclusive, we are able to obtain high-quality annotations for the SWSD task. These results suggest a greater role for MTurk with respect to constructing a large scale SWSD system in the future, promising substantial improvement in subjectivity and sentiment analysis. 1 Introduction Many Natural Language Processing (NLP) systems rely on large amounts of manually annotated data that is collected from domain experts. The annotation process to obtain this data is very laborious and expensive. This makes supervised NLP systems subject to a so-called knowledge acquisition bottleneck. For example, (Ng, 1997) estimates an effort of 16 person years to construct training data for a highaccuracy domain independent Word Sense Disambiguation (WSD) system. Recently researchers have been investigating Amazon Mechanical Turk (MTurk) as a source of non-expert natural language annotation, which is a cheap and quick alternative to expert annotations (Kaisser and Lowe, 2008; Mrozinski et al., 2008). In this paper, we utilize MTurk to obtain training data for Subjectivity Word Sense Disambiguation (SWSD) as described in (Akkaya et al., 2009). The goal of SWSD is to automatically determine which word instances"
W10-0731,D08-1027,0,0.567301,"Missing"
W10-0731,P06-1134,1,0.203751,"small enough to wear on your wrist”; “a device intended to conserve water”) He sold his catch at the market. catch, haul – (the quantity that was caught; “the catch was only 10 fish”) =&gt; indefinite quantity – (an estimated quantity) Figure 1: Subjective and objective word sense examples. techniques such as majority voting among the submissions can be used to aggregate the results for some types of HITs, resulting in a higher-quality final answer. Previous work (Snow et al., 2008) demonstrates that aggregating worker submissions often leads to an increase in quality. 3 Word Sense Subjectivity (Wiebe and Mihalcea, 2006) define subjective expressions as words and phrases being used to express mental and emotional states, such as speculations, evaluations, sentiments, and beliefs. Many approaches to sentiment and subjectivity analysis rely on lexicons of such words (subjectivity clues). However, such clues often have both subjective and objective senses, as illustrated by (Wiebe and Mihalcea, 2006). Figure 1 provides subjective and objective examples of senses. (Akkaya et al., 2009) points out that most subjectivity lexicons are compiled as lists of keywords, rather than word meanings (senses). Thus, subjectiv"
W10-0731,passonneau-etal-2006-inter,0,\N,Missing
W11-0311,E09-1004,0,0.109842,"a annotated by non-expert annotators. Further, by improving the method for integrating SWSD into contextual opinion analysis, even greater benefits from SWSD are achieved than in previous work. We thus more firmly demonstrate the potential of SWSD to improve contextual opinion analysis. 1 (2) Introduction Often, methods for opinion, sentiment, and subjectivity analysis rely on lexicons of subjective (opinion-carrying) words (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)). Examples of such words are the following (in bold): (1) Rada Mihalcea University of North Texas Denton TX, 76207, USA rada@cs.unt.edu He is a disease to every team he has gone to. Converting to SMF is a headache. The concert left me cold. That guy is such a pain. Early symptoms of the disease include severe headaches, red eyes, fevers and cold chills, body pain, and vomiting. Recently, in (Akkaya et al., 2009), we introduced the task of subjectivity word sense disambiguation (SWSD), which is to automatically determine which word instances in a corpus are being used with subjective senses, a"
W11-0311,D09-1020,1,0.811735,"Missing"
W11-0311,W10-0731,1,0.946719,"tive) { attack } – begin to injure; ”The cancer cells are attacking his liver”; ”Rust is attacking the metal” { attack, aggress } – take the initiative and go on the offensive; ”The visiting team started to attack” Figure 1: Sense sets for target word “attack” (abridged). of the subjectivity lexicon of (Wilson et al., 2005; Wilson, 2007).3 There are 39 such words. (Akkaya et al., 2009) chose words from a subjectivity lexicon because such words are known to have subjective usages. For this paper, subjectivity sense-tagged data was obtained from the MTurk workers using the annotation scheme of (Akkaya et al., 2010). A goal is to keep the annotation task as simple as possible. Thus, the workers are not directly asked if the instance of a target word has a subjective or an objective sense, because the concept of subjectivity would be difficult to explain in this setting. Instead the workers are shown two sets of senses – one subjective set and one objective set – for a specific target word and a text passage in which the target word appears. Their job is to select the set that best reflects the meaning of the target word in the text passage. The set they choose gives us the subjectivity label of the insta"
W11-0311,E06-1027,0,0.014381,"tion is statistically significant at the p &lt; .01 level with McNemar’s test. More importantly, the F-measure for all the labels improves. This indicates that non-expert MTurk annotations can replace expert annotations for our end-goal – improving contextual opinion analysis – while reducing time and cost requirements by a large margin. Moreover, we see that the improvements in (Akkaya et al., 2009) scale up to new subjectivity clues. 4 Related Work One related line of research is to automatically assign subjectivity and/or polarity labels to word senses in a dictionary (Valitutti et al., 2004; Andreevskaia and Bergler, 2006; Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2007; Su and Markert, 2009). In contrast, the task in our paper is to automatically assign labels to word instances in a corpus. Recently, some researchers have exploited full word sense disambiguation in methods for opinionrelated tasks. For example, (Mart´ın-Wanton et al., 2010) exploit WSD for recognizing quotation polarities, and (Rentoumi et al., 2009; Mart´ın-Wanton et al., 2010) exploit WSD for recognizing headline polarities. None of this previous work investigates performing a coarse-grained variation of WSD such as SWSD to improve the"
W11-0311,P08-1034,0,0.122996,"e, by successfully gathering data annotated by non-expert annotators. Further, by improving the method for integrating SWSD into contextual opinion analysis, even greater benefits from SWSD are achieved than in previous work. We thus more firmly demonstrate the potential of SWSD to improve contextual opinion analysis. 1 (2) Introduction Often, methods for opinion, sentiment, and subjectivity analysis rely on lexicons of subjective (opinion-carrying) words (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)). Examples of such words are the following (in bold): (1) Rada Mihalcea University of North Texas Denton TX, 76207, USA rada@cs.unt.edu He is a disease to every team he has gone to. Converting to SMF is a headache. The concert left me cold. That guy is such a pain. Early symptoms of the disease include severe headaches, red eyes, fevers and cold chills, body pain, and vomiting. Recently, in (Akkaya et al., 2009), we introduced the task of subjectivity word sense disambiguation (SWSD), which is to automatically determine which word instances in a corpus are being used wi"
W11-0311,N07-1039,0,0.21355,"ements in performance, by successfully gathering data annotated by non-expert annotators. Further, by improving the method for integrating SWSD into contextual opinion analysis, even greater benefits from SWSD are achieved than in previous work. We thus more firmly demonstrate the potential of SWSD to improve contextual opinion analysis. 1 (2) Introduction Often, methods for opinion, sentiment, and subjectivity analysis rely on lexicons of subjective (opinion-carrying) words (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)). Examples of such words are the following (in bold): (1) Rada Mihalcea University of North Texas Denton TX, 76207, USA rada@cs.unt.edu He is a disease to every team he has gone to. Converting to SMF is a headache. The concert left me cold. That guy is such a pain. Early symptoms of the disease include severe headaches, red eyes, fevers and cold chills, body pain, and vomiting. Recently, in (Akkaya et al., 2009), we introduced the task of subjectivity word sense disambiguation (SWSD), which is to automatically determine which word instanc"
W11-0311,P07-1054,0,0.0630713,"h McNemar’s test. More importantly, the F-measure for all the labels improves. This indicates that non-expert MTurk annotations can replace expert annotations for our end-goal – improving contextual opinion analysis – while reducing time and cost requirements by a large margin. Moreover, we see that the improvements in (Akkaya et al., 2009) scale up to new subjectivity clues. 4 Related Work One related line of research is to automatically assign subjectivity and/or polarity labels to word senses in a dictionary (Valitutti et al., 2004; Andreevskaia and Bergler, 2006; Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2007; Su and Markert, 2009). In contrast, the task in our paper is to automatically assign labels to word instances in a corpus. Recently, some researchers have exploited full word sense disambiguation in methods for opinionrelated tasks. For example, (Mart´ın-Wanton et al., 2010) exploit WSD for recognizing quotation polarities, and (Rentoumi et al., 2009; Mart´ın-Wanton et al., 2010) exploit WSD for recognizing headline polarities. None of this previous work investigates performing a coarse-grained variation of WSD such as SWSD to improve their application results, as we do in this work. A notab"
W11-0311,N09-1002,1,0.91279,"Missing"
W11-0311,N06-2015,0,0.0415888,"SWSD to improve the performance on a contextual NLP task, as we do. While the task in our paper is subjectivity and sentiment analysis, their task is English-Chinese lexical substitution. As (Akkaya et al., 2009) did, they anno94 tated word senses, and exploited SENSEVAL data as training data for SWSD. They did not directly annotate words in context with S/O labels, as we do in our work. Further, they did not separately evaluate a SWSD system component. Many researchers work on reducing the granularity of sense inventories for WSD (e.g., (Palmer et al., 2004; Navigli, 2006; Snow et al., 2007; Hovy et al., 2006)). Their criteria for grouping senses are syntactic and semantic similarities, while the groupings in work on SWSD are driven by the goals to improve contextual subjectivity and sentiment analysis. 5 Conclusions and Future Work In this paper, we utilized a large pool of non-expert annotators (MTurk) to collect subjectivity sensetagged data for SWSD. We showed that non-expert annotations are as good as expert annotations for training SWSD classifiers. Moreover, we demonstrated that SWSD classifiers trained on non-expert annotations can be exploited to improve contextual opinion analysis. The ad"
W11-0311,C04-1200,0,0.759913,"still obtain improvements in performance, by successfully gathering data annotated by non-expert annotators. Further, by improving the method for integrating SWSD into contextual opinion analysis, even greater benefits from SWSD are achieved than in previous work. We thus more firmly demonstrate the potential of SWSD to improve contextual opinion analysis. 1 (2) Introduction Often, methods for opinion, sentiment, and subjectivity analysis rely on lexicons of subjective (opinion-carrying) words (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)). Examples of such words are the following (in bold): (1) Rada Mihalcea University of North Texas Denton TX, 76207, USA rada@cs.unt.edu He is a disease to every team he has gone to. Converting to SMF is a headache. The concert left me cold. That guy is such a pain. Early symptoms of the disease include severe headaches, red eyes, fevers and cold chills, body pain, and vomiting. Recently, in (Akkaya et al., 2009), we introduced the task of subjectivity word sense disambiguation (SWSD), which is to automatically determin"
W11-0311,P06-1014,0,0.0335572,"u and Markert, 2010), who exploit SWSD to improve the performance on a contextual NLP task, as we do. While the task in our paper is subjectivity and sentiment analysis, their task is English-Chinese lexical substitution. As (Akkaya et al., 2009) did, they anno94 tated word senses, and exploited SENSEVAL data as training data for SWSD. They did not directly annotate words in context with S/O labels, as we do in our work. Further, they did not separately evaluate a SWSD system component. Many researchers work on reducing the granularity of sense inventories for WSD (e.g., (Palmer et al., 2004; Navigli, 2006; Snow et al., 2007; Hovy et al., 2006)). Their criteria for grouping senses are syntactic and semantic similarities, while the groupings in work on SWSD are driven by the goals to improve contextual subjectivity and sentiment analysis. 5 Conclusions and Future Work In this paper, we utilized a large pool of non-expert annotators (MTurk) to collect subjectivity sensetagged data for SWSD. We showed that non-expert annotations are as good as expert annotations for training SWSD classifiers. Moreover, we demonstrated that SWSD classifiers trained on non-expert annotations can be exploited to impr"
W11-0311,W04-2807,0,0.0327808,"table exception is (Su and Markert, 2010), who exploit SWSD to improve the performance on a contextual NLP task, as we do. While the task in our paper is subjectivity and sentiment analysis, their task is English-Chinese lexical substitution. As (Akkaya et al., 2009) did, they anno94 tated word senses, and exploited SENSEVAL data as training data for SWSD. They did not directly annotate words in context with S/O labels, as we do in our work. Further, they did not separately evaluate a SWSD system component. Many researchers work on reducing the granularity of sense inventories for WSD (e.g., (Palmer et al., 2004; Navigli, 2006; Snow et al., 2007; Hovy et al., 2006)). Their criteria for grouping senses are syntactic and semantic similarities, while the groupings in work on SWSD are driven by the goals to improve contextual subjectivity and sentiment analysis. 5 Conclusions and Future Work In this paper, we utilized a large pool of non-expert annotators (MTurk) to collect subjectivity sensetagged data for SWSD. We showed that non-expert annotations are as good as expert annotations for training SWSD classifiers. Moreover, we demonstrated that SWSD classifiers trained on non-expert annotations can be ex"
W11-0311,R09-1067,0,0.0625514,"subjectivity clues. 4 Related Work One related line of research is to automatically assign subjectivity and/or polarity labels to word senses in a dictionary (Valitutti et al., 2004; Andreevskaia and Bergler, 2006; Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2007; Su and Markert, 2009). In contrast, the task in our paper is to automatically assign labels to word instances in a corpus. Recently, some researchers have exploited full word sense disambiguation in methods for opinionrelated tasks. For example, (Mart´ın-Wanton et al., 2010) exploit WSD for recognizing quotation polarities, and (Rentoumi et al., 2009; Mart´ın-Wanton et al., 2010) exploit WSD for recognizing headline polarities. None of this previous work investigates performing a coarse-grained variation of WSD such as SWSD to improve their application results, as we do in this work. A notable exception is (Su and Markert, 2010), who exploit SWSD to improve the performance on a contextual NLP task, as we do. While the task in our paper is subjectivity and sentiment analysis, their task is English-Chinese lexical substitution. As (Akkaya et al., 2009) did, they anno94 tated word senses, and exploited SENSEVAL data as training data for SWSD"
W11-0311,W03-1014,1,0.777946,"ntegration of SWSD into contextual opinion analysis and still obtain improvements in performance, by successfully gathering data annotated by non-expert annotators. Further, by improving the method for integrating SWSD into contextual opinion analysis, even greater benefits from SWSD are achieved than in previous work. We thus more firmly demonstrate the potential of SWSD to improve contextual opinion analysis. 1 (2) Introduction Often, methods for opinion, sentiment, and subjectivity analysis rely on lexicons of subjective (opinion-carrying) words (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)). Examples of such words are the following (in bold): (1) Rada Mihalcea University of North Texas Denton TX, 76207, USA rada@cs.unt.edu He is a disease to every team he has gone to. Converting to SMF is a headache. The concert left me cold. That guy is such a pain. Early symptoms of the disease include severe headaches, red eyes, fevers and cold chills, body pain, and vomiting. Recently, in (Akkaya et al., 2009), we introduced the task of subjectivity word sense disamb"
W11-0311,D07-1107,0,0.0197717,"2010), who exploit SWSD to improve the performance on a contextual NLP task, as we do. While the task in our paper is subjectivity and sentiment analysis, their task is English-Chinese lexical substitution. As (Akkaya et al., 2009) did, they anno94 tated word senses, and exploited SENSEVAL data as training data for SWSD. They did not directly annotate words in context with S/O labels, as we do in our work. Further, they did not separately evaluate a SWSD system component. Many researchers work on reducing the granularity of sense inventories for WSD (e.g., (Palmer et al., 2004; Navigli, 2006; Snow et al., 2007; Hovy et al., 2006)). Their criteria for grouping senses are syntactic and semantic similarities, while the groupings in work on SWSD are driven by the goals to improve contextual subjectivity and sentiment analysis. 5 Conclusions and Future Work In this paper, we utilized a large pool of non-expert annotators (MTurk) to collect subjectivity sensetagged data for SWSD. We showed that non-expert annotations are as good as expert annotations for training SWSD classifiers. Moreover, we demonstrated that SWSD classifiers trained on non-expert annotations can be exploited to improve contextual opin"
W11-0311,N09-1001,0,0.0772355,"tantly, the F-measure for all the labels improves. This indicates that non-expert MTurk annotations can replace expert annotations for our end-goal – improving contextual opinion analysis – while reducing time and cost requirements by a large margin. Moreover, we see that the improvements in (Akkaya et al., 2009) scale up to new subjectivity clues. 4 Related Work One related line of research is to automatically assign subjectivity and/or polarity labels to word senses in a dictionary (Valitutti et al., 2004; Andreevskaia and Bergler, 2006; Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2007; Su and Markert, 2009). In contrast, the task in our paper is to automatically assign labels to word instances in a corpus. Recently, some researchers have exploited full word sense disambiguation in methods for opinionrelated tasks. For example, (Mart´ın-Wanton et al., 2010) exploit WSD for recognizing quotation polarities, and (Rentoumi et al., 2009; Mart´ın-Wanton et al., 2010) exploit WSD for recognizing headline polarities. None of this previous work investigates performing a coarse-grained variation of WSD such as SWSD to improve their application results, as we do in this work. A notable exception is (Su and"
W11-0311,N10-1054,0,0.0167085,"2009). In contrast, the task in our paper is to automatically assign labels to word instances in a corpus. Recently, some researchers have exploited full word sense disambiguation in methods for opinionrelated tasks. For example, (Mart´ın-Wanton et al., 2010) exploit WSD for recognizing quotation polarities, and (Rentoumi et al., 2009; Mart´ın-Wanton et al., 2010) exploit WSD for recognizing headline polarities. None of this previous work investigates performing a coarse-grained variation of WSD such as SWSD to improve their application results, as we do in this work. A notable exception is (Su and Markert, 2010), who exploit SWSD to improve the performance on a contextual NLP task, as we do. While the task in our paper is subjectivity and sentiment analysis, their task is English-Chinese lexical substitution. As (Akkaya et al., 2009) did, they anno94 tated word senses, and exploited SENSEVAL data as training data for SWSD. They did not directly annotate words in context with S/O labels, as we do in our work. Further, they did not separately evaluate a SWSD system component. Many researchers work on reducing the granularity of sense inventories for WSD (e.g., (Palmer et al., 2004; Navigli, 2006; Snow"
W11-0311,P02-1053,0,0.00653987,"les. In this paper, we scale up the integration of SWSD into contextual opinion analysis and still obtain improvements in performance, by successfully gathering data annotated by non-expert annotators. Further, by improving the method for integrating SWSD into contextual opinion analysis, even greater benefits from SWSD are achieved than in previous work. We thus more firmly demonstrate the potential of SWSD to improve contextual opinion analysis. 1 (2) Introduction Often, methods for opinion, sentiment, and subjectivity analysis rely on lexicons of subjective (opinion-carrying) words (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)). Examples of such words are the following (in bold): (1) Rada Mihalcea University of North Texas Denton TX, 76207, USA rada@cs.unt.edu He is a disease to every team he has gone to. Converting to SMF is a headache. The concert left me cold. That guy is such a pain. Early symptoms of the disease include severe headaches, red eyes, fevers and cold chills, body pain, and vomiting. Recently, in (Akkaya et al., 2009), we introd"
W11-0311,P06-1134,1,0.959197,"omings, in this paper, we investigate (1) the feasibility of obtaining a substantial amount of annotated data, (2) whether performance improvements on contextual opinion analysis can be realized on a larger scale, and (3) whether those improvements can be realized with subjectivity sense tagged data that is not built on expert fullinventory sense annotations. In addition, we explore better methods for applying SWSD to contextual opinion analysis. 2 Subjectivity Word Sense Disambiguation 2.1 Annotation Tasks We adopt the definitions of subjective (S) and objective (O) from (Wiebe et al., 2005; Wiebe and Mihalcea, 2006; Wilson, 2007). Subjective expressions are words and phrases being used to express mental and emotional states, such as speculations, evaluations, sentiments, and beliefs. A general covering term for such states is private state (Quirk et al., 1985), an internal state that cannot be directly observed or verified by others. Objective expressions instead are words and phrases that lack subjectivity. The contextual opinion analysis experiments described in Section 3 include both S/O and polarity (positive,negative, neutral) classifications. The opinion-annotated data used in those experiments is"
W11-0311,H05-1044,1,0.626848,"p://www.cs.pitt.edu/mpqa 88 Sense Set1 (Subjective) { attack, round, assail, lash out, snipe, assault } – attack in speech or writing; ”The editors attacked the House Speaker” { assail, assault, set on, attack } – attack someone emotionally; ”Nightmares assailed him regularly” Sense Set2 (Objective) { attack } – begin to injure; ”The cancer cells are attacking his liver”; ”Rust is attacking the metal” { attack, aggress } – take the initiative and go on the offensive; ”The visiting team started to attack” Figure 1: Sense sets for target word “attack” (abridged). of the subjectivity lexicon of (Wilson et al., 2005; Wilson, 2007).3 There are 39 such words. (Akkaya et al., 2009) chose words from a subjectivity lexicon because such words are known to have subjective usages. For this paper, subjectivity sense-tagged data was obtained from the MTurk workers using the annotation scheme of (Akkaya et al., 2010). A goal is to keep the annotation task as simple as possible. Thus, the workers are not directly asked if the instance of a target word has a subjective or an objective sense, because the concept of subjectivity would be difficult to explain in this setting. Instead the workers are shown two sets of se"
W11-0311,W03-1017,0,0.119389,"contextual opinion analysis and still obtain improvements in performance, by successfully gathering data annotated by non-expert annotators. Further, by improving the method for integrating SWSD into contextual opinion analysis, even greater benefits from SWSD are achieved than in previous work. We thus more firmly demonstrate the potential of SWSD to improve contextual opinion analysis. 1 (2) Introduction Often, methods for opinion, sentiment, and subjectivity analysis rely on lexicons of subjective (opinion-carrying) words (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003; Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Andreevskaia and Bergler, 2008; Agarwal et al., 2009)). Examples of such words are the following (in bold): (1) Rada Mihalcea University of North Texas Denton TX, 76207, USA rada@cs.unt.edu He is a disease to every team he has gone to. Converting to SMF is a headache. The concert left me cold. That guy is such a pain. Early symptoms of the disease include severe headaches, red eyes, fevers and cold chills, body pain, and vomiting. Recently, in (Akkaya et al., 2009), we introduced the task of subjectivity word sense disambiguation (SWSD), which is to au"
W11-0311,C08-1104,0,\N,Missing
W11-3707,D09-1020,1,0.880556,"Missing"
W11-3707,E06-2031,0,0.0438856,"Missing"
W11-3707,banea-etal-2008-bootstrapping,1,0.841995,"10) in Dutch. Sentiment and subjectivity lexicons such as the one included with the OpinionFinder distribution (Wiebe and Riloff, 2005), the General Inquirer (Stone et al., 1967), or the SentiWordNet (Esuli and Sebastiani, 2006b) were transferred into Chinese (Ku et al., 2006; Wu, 2008) and into Romanian (Mihalcea et al., 2007). English corpora manually annotated for subjectivity or sentiment such as MPQA (Wiebe et al., 2005), or the multi-domain sentiment classification corpus (Blitzer et al., 2007) were subjected to experiments in Spanish, Romanian, or Chinese upon automatic translation by (Banea et al., 2008b; Wan, 2009). Furthermore, tools developed for English were used to determine sentiment 44 Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP), IJCNLP 2011, pages 44–50, Chiang Mai, Thailand, November 13, 2011. or subjectivity labeling for a given target language by transferring the text to English and applying an English classifier on the resulting data. The labels were then transferred back into the target language (Bautin et al., 2008; Banea et al., 2008b). These experiments are carried out in Arabic, Chinese, French, German, Japanese, Spanish, Romanian. We"
W11-3707,D08-1014,1,0.83571,"10) in Dutch. Sentiment and subjectivity lexicons such as the one included with the OpinionFinder distribution (Wiebe and Riloff, 2005), the General Inquirer (Stone et al., 1967), or the SentiWordNet (Esuli and Sebastiani, 2006b) were transferred into Chinese (Ku et al., 2006; Wu, 2008) and into Romanian (Mihalcea et al., 2007). English corpora manually annotated for subjectivity or sentiment such as MPQA (Wiebe et al., 2005), or the multi-domain sentiment classification corpus (Blitzer et al., 2007) were subjected to experiments in Spanish, Romanian, or Chinese upon automatic translation by (Banea et al., 2008b; Wan, 2009). Furthermore, tools developed for English were used to determine sentiment 44 Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP), IJCNLP 2011, pages 44–50, Chiang Mai, Thailand, November 13, 2011. or subjectivity labeling for a given target language by transferring the text to English and applying an English classifier on the resulting data. The labels were then transferred back into the target language (Bautin et al., 2008; Banea et al., 2008b). These experiments are carried out in Arabic, Chinese, French, German, Japanese, Spanish, Romanian. We"
W11-3707,C10-1004,1,0.647963,"Missing"
W11-3707,P07-1056,0,0.00609238,"rried out by (Esuli et al., 2008) when annotating expressions of private state in Italian or by (Maks and Vossen, 2010) in Dutch. Sentiment and subjectivity lexicons such as the one included with the OpinionFinder distribution (Wiebe and Riloff, 2005), the General Inquirer (Stone et al., 1967), or the SentiWordNet (Esuli and Sebastiani, 2006b) were transferred into Chinese (Ku et al., 2006; Wu, 2008) and into Romanian (Mihalcea et al., 2007). English corpora manually annotated for subjectivity or sentiment such as MPQA (Wiebe et al., 2005), or the multi-domain sentiment classification corpus (Blitzer et al., 2007) were subjected to experiments in Spanish, Romanian, or Chinese upon automatic translation by (Banea et al., 2008b; Wan, 2009). Furthermore, tools developed for English were used to determine sentiment 44 Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP), IJCNLP 2011, pages 44–50, Chiang Mai, Thailand, November 13, 2011. or subjectivity labeling for a given target language by transferring the text to English and applying an English classifier on the resulting data. The labels were then transferred back into the target language (Bautin et al., 2008; Banea et al"
W11-3707,P08-1041,0,0.0183951,"chniques for automatic sentiment and subjectivity analysis, including automatic expressive text-to-speech synthesis (Alm et al., 1990), tracking sentiment timelines in on-line forums and news (Balog et al., 2006; Lloyd et al., 2005), and mining opinions from product reviews (Hu and Liu, 2004). In many natural language processing tasks, subjectivity and sentiment classification has been used as a first phase filtering to generate more viable data. Research that benefited from this additional layering ranges from question answering (Yu and Hatzivassiloglou, 2003), to conversation summarization (Carenini et al., 2008), text semantic analysis (Wiebe and MihalRelated Work Recently, resources and tools for sentiment analysis developed for English have been used as a starting point to build resources in other languages, via cross-lingual projections or monolingual and multilingual bootstrapping. Several directions were followed, focused on leveraging annotation schemes, lexicons, corpora and automated annotation systems. English annotation schemes developed for opinionated text lays the groundwork for research carried out by (Esuli et al., 2008) when annotating expressions of private state in Italian or by (Ma"
W11-3707,E06-1025,0,0.0226646,"al projections or monolingual and multilingual bootstrapping. Several directions were followed, focused on leveraging annotation schemes, lexicons, corpora and automated annotation systems. English annotation schemes developed for opinionated text lays the groundwork for research carried out by (Esuli et al., 2008) when annotating expressions of private state in Italian or by (Maks and Vossen, 2010) in Dutch. Sentiment and subjectivity lexicons such as the one included with the OpinionFinder distribution (Wiebe and Riloff, 2005), the General Inquirer (Stone et al., 1967), or the SentiWordNet (Esuli and Sebastiani, 2006b) were transferred into Chinese (Ku et al., 2006; Wu, 2008) and into Romanian (Mihalcea et al., 2007). English corpora manually annotated for subjectivity or sentiment such as MPQA (Wiebe et al., 2005), or the multi-domain sentiment classification corpus (Blitzer et al., 2007) were subjected to experiments in Spanish, Romanian, or Chinese upon automatic translation by (Banea et al., 2008b; Wan, 2009). Furthermore, tools developed for English were used to determine sentiment 44 Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP), IJCNLP 2011, pages 44–50, Chiang"
W11-3707,esuli-sebastiani-2006-sentiwordnet,0,0.0203499,"al projections or monolingual and multilingual bootstrapping. Several directions were followed, focused on leveraging annotation schemes, lexicons, corpora and automated annotation systems. English annotation schemes developed for opinionated text lays the groundwork for research carried out by (Esuli et al., 2008) when annotating expressions of private state in Italian or by (Maks and Vossen, 2010) in Dutch. Sentiment and subjectivity lexicons such as the one included with the OpinionFinder distribution (Wiebe and Riloff, 2005), the General Inquirer (Stone et al., 1967), or the SentiWordNet (Esuli and Sebastiani, 2006b) were transferred into Chinese (Ku et al., 2006; Wu, 2008) and into Romanian (Mihalcea et al., 2007). English corpora manually annotated for subjectivity or sentiment such as MPQA (Wiebe et al., 2005), or the multi-domain sentiment classification corpus (Blitzer et al., 2007) were subjected to experiments in Spanish, Romanian, or Chinese upon automatic translation by (Banea et al., 2008b; Wan, 2009). Furthermore, tools developed for English were used to determine sentiment 44 Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP), IJCNLP 2011, pages 44–50, Chiang"
W11-3707,esuli-etal-2008-annotating,0,0.025217,"Yu and Hatzivassiloglou, 2003), to conversation summarization (Carenini et al., 2008), text semantic analysis (Wiebe and MihalRelated Work Recently, resources and tools for sentiment analysis developed for English have been used as a starting point to build resources in other languages, via cross-lingual projections or monolingual and multilingual bootstrapping. Several directions were followed, focused on leveraging annotation schemes, lexicons, corpora and automated annotation systems. English annotation schemes developed for opinionated text lays the groundwork for research carried out by (Esuli et al., 2008) when annotating expressions of private state in Italian or by (Maks and Vossen, 2010) in Dutch. Sentiment and subjectivity lexicons such as the one included with the OpinionFinder distribution (Wiebe and Riloff, 2005), the General Inquirer (Stone et al., 1967), or the SentiWordNet (Esuli and Sebastiani, 2006b) were transferred into Chinese (Ku et al., 2006; Wu, 2008) and into Romanian (Mihalcea et al., 2007). English corpora manually annotated for subjectivity or sentiment such as MPQA (Wiebe et al., 2005), or the multi-domain sentiment classification corpus (Blitzer et al., 2007) were subjec"
W11-3707,maks-vossen-2010-annotation,0,0.0146337,"8), text semantic analysis (Wiebe and MihalRelated Work Recently, resources and tools for sentiment analysis developed for English have been used as a starting point to build resources in other languages, via cross-lingual projections or monolingual and multilingual bootstrapping. Several directions were followed, focused on leveraging annotation schemes, lexicons, corpora and automated annotation systems. English annotation schemes developed for opinionated text lays the groundwork for research carried out by (Esuli et al., 2008) when annotating expressions of private state in Italian or by (Maks and Vossen, 2010) in Dutch. Sentiment and subjectivity lexicons such as the one included with the OpinionFinder distribution (Wiebe and Riloff, 2005), the General Inquirer (Stone et al., 1967), or the SentiWordNet (Esuli and Sebastiani, 2006b) were transferred into Chinese (Ku et al., 2006; Wu, 2008) and into Romanian (Mihalcea et al., 2007). English corpora manually annotated for subjectivity or sentiment such as MPQA (Wiebe et al., 2005), or the multi-domain sentiment classification corpus (Blitzer et al., 2007) were subjected to experiments in Spanish, Romanian, or Chinese upon automatic translation by (Ban"
W11-3707,P07-1123,1,0.831231,"leveraging annotation schemes, lexicons, corpora and automated annotation systems. English annotation schemes developed for opinionated text lays the groundwork for research carried out by (Esuli et al., 2008) when annotating expressions of private state in Italian or by (Maks and Vossen, 2010) in Dutch. Sentiment and subjectivity lexicons such as the one included with the OpinionFinder distribution (Wiebe and Riloff, 2005), the General Inquirer (Stone et al., 1967), or the SentiWordNet (Esuli and Sebastiani, 2006b) were transferred into Chinese (Ku et al., 2006; Wu, 2008) and into Romanian (Mihalcea et al., 2007). English corpora manually annotated for subjectivity or sentiment such as MPQA (Wiebe et al., 2005), or the multi-domain sentiment classification corpus (Blitzer et al., 2007) were subjected to experiments in Spanish, Romanian, or Chinese upon automatic translation by (Banea et al., 2008b; Wan, 2009). Furthermore, tools developed for English were used to determine sentiment 44 Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP), IJCNLP 2011, pages 44–50, Chiang Mai, Thailand, November 13, 2011. or subjectivity labeling for a given target language by transferrin"
W11-3707,N10-1054,0,0.0382252,"Missing"
W11-3707,P09-1027,0,0.378731,"nt and subjectivity lexicons such as the one included with the OpinionFinder distribution (Wiebe and Riloff, 2005), the General Inquirer (Stone et al., 1967), or the SentiWordNet (Esuli and Sebastiani, 2006b) were transferred into Chinese (Ku et al., 2006; Wu, 2008) and into Romanian (Mihalcea et al., 2007). English corpora manually annotated for subjectivity or sentiment such as MPQA (Wiebe et al., 2005), or the multi-domain sentiment classification corpus (Blitzer et al., 2007) were subjected to experiments in Spanish, Romanian, or Chinese upon automatic translation by (Banea et al., 2008b; Wan, 2009). Furthermore, tools developed for English were used to determine sentiment 44 Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP), IJCNLP 2011, pages 44–50, Chiang Mai, Thailand, November 13, 2011. or subjectivity labeling for a given target language by transferring the text to English and applying an English classifier on the resulting data. The labels were then transferred back into the target language (Bautin et al., 2008; Banea et al., 2008b). These experiments are carried out in Arabic, Chinese, French, German, Japanese, Spanish, Romanian. We are not aware"
W11-3707,P06-1134,1,0.839338,"Missing"
W11-3707,W03-1017,0,0.0337717,"te, a large number of text processing applications have used techniques for automatic sentiment and subjectivity analysis, including automatic expressive text-to-speech synthesis (Alm et al., 1990), tracking sentiment timelines in on-line forums and news (Balog et al., 2006; Lloyd et al., 2005), and mining opinions from product reviews (Hu and Liu, 2004). In many natural language processing tasks, subjectivity and sentiment classification has been used as a first phase filtering to generate more viable data. Research that benefited from this additional layering ranges from question answering (Yu and Hatzivassiloglou, 2003), to conversation summarization (Carenini et al., 2008), text semantic analysis (Wiebe and MihalRelated Work Recently, resources and tools for sentiment analysis developed for English have been used as a starting point to build resources in other languages, via cross-lingual projections or monolingual and multilingual bootstrapping. Several directions were followed, focused on leveraging annotation schemes, lexicons, corpora and automated annotation systems. English annotation schemes developed for opinionated text lays the groundwork for research carried out by (Esuli et al., 2008) when annot"
W11-3707,W11-0104,1,\N,Missing
W11-3707,W08-1207,0,\N,Missing
W11-3707,H05-1073,0,\N,Missing
W11-3707,andreevskaia-bergler-2006-semantic,0,\N,Missing
W12-3810,W11-1701,0,0.380067,"ent 683 130 104 75 54 52 51 43 79 Table 2: Arguing and argument label statistics for the “pro” stance. subjectivity and arguments. We collected documents written both before and after the passage of the final “Patient Protection and Affordable Care Act” bill using the “Google Blog Search”3 and “Daily Op Ed”4 search portals. By choosing a relatively broad time window, from early 2009 to late 2011, we aimed to capture a wide range of arguments expressed throughout the debate. The focus of this paper is on sentence-level argument detection rather than document-level stance classification (e.g., (Anand et al., 2011), (Park et al., 2011), (Somasundaran and Wiebe, 2010), (Burfoot et al., 2011)). We treat stance classification as a separate step preceding arguing subjectivity detection, and thus provide oracle stance labels for our data. We treat documents written from the “pro” 3 4 http://www.google.com/blogsearch http://www.dailyoped.com/ arguing subjectivity objective subjective 913 575 argument labels no label diminishes quality of care too expensive unpopular hurts economy expands govt bill is politically motivated other reforms more appropriate other argument 913 122 67 60 55 52 44 35 140 Table 3: Arg"
W12-3810,P11-1151,0,0.0270021,"stics for the “pro” stance. subjectivity and arguments. We collected documents written both before and after the passage of the final “Patient Protection and Affordable Care Act” bill using the “Google Blog Search”3 and “Daily Op Ed”4 search portals. By choosing a relatively broad time window, from early 2009 to late 2011, we aimed to capture a wide range of arguments expressed throughout the debate. The focus of this paper is on sentence-level argument detection rather than document-level stance classification (e.g., (Anand et al., 2011), (Park et al., 2011), (Somasundaran and Wiebe, 2010), (Burfoot et al., 2011)). We treat stance classification as a separate step preceding arguing subjectivity detection, and thus provide oracle stance labels for our data. We treat documents written from the “pro” 3 4 http://www.google.com/blogsearch http://www.dailyoped.com/ arguing subjectivity objective subjective 913 575 argument labels no label diminishes quality of care too expensive unpopular hurts economy expands govt bill is politically motivated other reforms more appropriate other argument 913 122 67 60 55 52 44 35 140 Table 3: Arguing and argument label statistics for the “anti” stance. stance and document"
W12-3810,P11-1013,0,0.0269265,"discourse parser, and semantic similarity measures with respect to recognizing arguments. By incorporating information gained from these resources, we outperform a unigram baseline by a significant margin. In addition, we explore a two-phase approach to recognizing arguments, with promising results. 1 Introduction Subjectivity analysis is a thriving field within natural language processing. However, most research into subjectivity has focused on sentiment with respect to concrete things such as product debates (e.g., (Somasundaran and Wiebe, 2009), (Yu et al., 2011)) and movie reviews (e.g., (He et al., 2011), (Maas et al., 2011), (Pang and Lee, 2004)). Analysis often follows the opinion-target paradigm, in which expressions of sentiment are assessed with respect to the aspects of the object(s) under consideration towards which they are targeted. For example, (1) Almost everyone knows that we must start holding insurance companies accountable and give Americans a greater sense of stability and security when it comes to their health care. In a traditional opinion-target or sentimenttopic paradigm, perhaps this sentence could be labeled as containing a negative sentiment towards a topic representing"
W12-3810,P11-1016,0,0.0042768,"ecific actions may be referenced, as illustrated in Examples (2-4) from Section 1. To address this problem, we investigate expanding each instance with terms that are most similar, according to a distributional model generated from Wikipedia articles, to the nouns and verbs present within the instance (Pantel et al., 2009). We refer to these features as “expn”, where n is the number of most-similar terms with which to expand the instance for each noun or verb. We experiment with values of n = 5 and n = 10. Subjectivity classification of small units of text, such as individual microblog posts (Jiang et al., 2011) and sentences (Riloff et al., 2003), has been shown to benefit from additional context. Thus, we augment the feature representation of each target sentence with features from the two preceding and two following sentences. These additional features are modified so that they do not fall within the same feature space 5 downloaded from http://www.cs.pitt.edu/mpqa/ subj_lexicon.html feat. abbrev. unigram senti rels exp5 exp10 elaboration 2 binary features indicating positive or negative sentiment based on presence of lexicon clues 15 binary features indicating kinds of discourse relationships and"
W12-3810,W06-2915,1,0.698866,"s from Table 7. While all of the hierarchical configurations beat the best “combined” classifier, none beats the top combined classifier by a significant margin, although the best configurations approach significance (0.05 &lt; p &lt; 0.1). 7 Related Work Much recent work in ideological subjectivity detection has focused on detecting a writer’s stance in domains of varying formality, such as online forums, debating websites, and op-eds. (Anand et al., 2011) demonstrates the usefulness of dependency relations, LIWC counts (Pennebaker et al., 2001), and information about related posts for this task. (Lin et al., 2006) explores relationships between sentence-level and document-level classification for a stance-like prediction task. Among the literature on ideological subjectivity, perhaps most similar to our work is (Somasundaran and Wiebe, 2010). This paper investigates the impact of incorporating arguing-based 87 and sentiment-based features into binary stance prediction for debate posts. Also closely related to our work is (Somasundaran et al., 2007). To support answering of opinion-based questions, this work investigates the use of high-precision sentiment and arguing clues for sentence-level sentiment"
W12-3810,P11-1100,0,0.010642,"Missing"
W12-3810,P11-1015,0,0.0208271,"nd semantic similarity measures with respect to recognizing arguments. By incorporating information gained from these resources, we outperform a unigram baseline by a significant margin. In addition, we explore a two-phase approach to recognizing arguments, with promising results. 1 Introduction Subjectivity analysis is a thriving field within natural language processing. However, most research into subjectivity has focused on sentiment with respect to concrete things such as product debates (e.g., (Somasundaran and Wiebe, 2009), (Yu et al., 2011)) and movie reviews (e.g., (He et al., 2011), (Maas et al., 2011), (Pang and Lee, 2004)). Analysis often follows the opinion-target paradigm, in which expressions of sentiment are assessed with respect to the aspects of the object(s) under consideration towards which they are targeted. For example, (1) Almost everyone knows that we must start holding insurance companies accountable and give Americans a greater sense of stability and security when it comes to their health care. In a traditional opinion-target or sentimenttopic paradigm, perhaps this sentence could be labeled as containing a negative sentiment towards a topic representing “insurance companies"
W12-3810,P04-1035,0,0.00260051,"y measures with respect to recognizing arguments. By incorporating information gained from these resources, we outperform a unigram baseline by a significant margin. In addition, we explore a two-phase approach to recognizing arguments, with promising results. 1 Introduction Subjectivity analysis is a thriving field within natural language processing. However, most research into subjectivity has focused on sentiment with respect to concrete things such as product debates (e.g., (Somasundaran and Wiebe, 2009), (Yu et al., 2011)) and movie reviews (e.g., (He et al., 2011), (Maas et al., 2011), (Pang and Lee, 2004)). Analysis often follows the opinion-target paradigm, in which expressions of sentiment are assessed with respect to the aspects of the object(s) under consideration towards which they are targeted. For example, (1) Almost everyone knows that we must start holding insurance companies accountable and give Americans a greater sense of stability and security when it comes to their health care. In a traditional opinion-target or sentimenttopic paradigm, perhaps this sentence could be labeled as containing a negative sentiment towards a topic representing “insurance companies”, or a positive senti"
W12-3810,P11-1035,0,0.143022,"52 51 43 79 Table 2: Arguing and argument label statistics for the “pro” stance. subjectivity and arguments. We collected documents written both before and after the passage of the final “Patient Protection and Affordable Care Act” bill using the “Google Blog Search”3 and “Daily Op Ed”4 search portals. By choosing a relatively broad time window, from early 2009 to late 2011, we aimed to capture a wide range of arguments expressed throughout the debate. The focus of this paper is on sentence-level argument detection rather than document-level stance classification (e.g., (Anand et al., 2011), (Park et al., 2011), (Somasundaran and Wiebe, 2010), (Burfoot et al., 2011)). We treat stance classification as a separate step preceding arguing subjectivity detection, and thus provide oracle stance labels for our data. We treat documents written from the “pro” 3 4 http://www.google.com/blogsearch http://www.dailyoped.com/ arguing subjectivity objective subjective 913 575 argument labels no label diminishes quality of care too expensive unpopular hurts economy expands govt bill is politically motivated other reforms more appropriate other argument 913 122 67 60 55 52 44 35 140 Table 3: Arguing and argument lab"
W12-3810,prasad-etal-2008-penn,0,0.0370597,"Missing"
W12-3810,W03-0404,1,0.399392,"s illustrated in Examples (2-4) from Section 1. To address this problem, we investigate expanding each instance with terms that are most similar, according to a distributional model generated from Wikipedia articles, to the nouns and verbs present within the instance (Pantel et al., 2009). We refer to these features as “expn”, where n is the number of most-similar terms with which to expand the instance for each noun or verb. We experiment with values of n = 5 and n = 10. Subjectivity classification of small units of text, such as individual microblog posts (Jiang et al., 2011) and sentences (Riloff et al., 2003), has been shown to benefit from additional context. Thus, we augment the feature representation of each target sentence with features from the two preceding and two following sentences. These additional features are modified so that they do not fall within the same feature space 5 downloaded from http://www.cs.pitt.edu/mpqa/ subj_lexicon.html feat. abbrev. unigram senti rels exp5 exp10 elaboration 2 binary features indicating positive or negative sentiment based on presence of lexicon clues 15 binary features indicating kinds of discourse relationships and how they connect instance to surroun"
W12-3810,P09-1026,1,0.255916,"ne learning experiments, we investigate the utility of a sentiment lexicon, discourse parser, and semantic similarity measures with respect to recognizing arguments. By incorporating information gained from these resources, we outperform a unigram baseline by a significant margin. In addition, we explore a two-phase approach to recognizing arguments, with promising results. 1 Introduction Subjectivity analysis is a thriving field within natural language processing. However, most research into subjectivity has focused on sentiment with respect to concrete things such as product debates (e.g., (Somasundaran and Wiebe, 2009), (Yu et al., 2011)) and movie reviews (e.g., (He et al., 2011), (Maas et al., 2011), (Pang and Lee, 2004)). Analysis often follows the opinion-target paradigm, in which expressions of sentiment are assessed with respect to the aspects of the object(s) under consideration towards which they are targeted. For example, (1) Almost everyone knows that we must start holding insurance companies accountable and give Americans a greater sense of stability and security when it comes to their health care. In a traditional opinion-target or sentimenttopic paradigm, perhaps this sentence could be labeled"
W12-3810,W10-0214,1,0.935419,"nizing Arguing Subjectivity and Argument Tags Alexander Conrad, Janyce Wiebe, and Rebecca Hwa Department of Computer Science University of Pittsburgh Pittsburgh PA, 15260, USA {conrada,wiebe,hwa}@cs.pitt.edu Abstract in the domain of smartphone reviews, aspects could include product features such as the keyboard, screen quality, and battery life. Although sentiment analysis is interesting and important in its own right, this paradigm does not seem to be the best match for finegrained analysis of ideological domains. While sentiment is also present in documents from this domain, previous work (Somasundaran and Wiebe, 2010) has found that arguing subjectivity, a less-studied form of subjectivity, is more frequently employed and more relevant for a robust assessment of ideological positions. Whereas sentiment conveys the polarity of a writer’s affect towards a topic, arguing subjectivity is a type of linguistic subjectivity in which a person expresses a controversial belief about what is true or what action ought to be taken regarding a central contentious issue (Somasundaran, 2010). For example, consider this sentence about health care reform: In this paper we investigate two distinct tasks. The first task invol"
W12-3810,W03-2102,1,0.484806,"Inter-annotator span agr (top) and argument label kappa on overlapping spans (bottom). In assessing inter-annotator agreement on this subset of the corpus, we must address two levels of agreement, arguing spans and argument tags. At first glance, how to assess agreement of annotated arguing spans is not obvious. Because our annotation scheme did not enforce strict boundaries, we hypothesized that both annotators would both frequently see an instance of arguing subjectivity within a local region of text, but would disagree with respect to where the arguing begins and ends. Thus, we adopt from (Wilson and Wiebe, 2003) the agr directional agreement metric to measure the degree of annotation overlap. Given two sets of spans A and B annotated by two different annotators, this metric measures the fraction of spans in A which at least partially overlap with any spans in B. Specifically, agreement is computed as: agr (A B) = A matching B A When A is the gold standard set of annotations, agr is equivalent to recall. Similarly, when B is the gold standard, agr is equivalent to precision. For this evaluation, we treat the dataset annotated by our primary annotator as the gold standard. Table 5 presents these agr sc"
W12-3810,H05-1044,1,0.0101733,"inferred by the discourse parser with the parent top-level PDTB 85 discourse relationship class. We arrive at a total of 15 binary discourse relationship features: (4 top-level classes + “other”) x (connects to previous + connects to following + internal connection) = 15. We refer to these features as “rels”. As illustrated in our earlier examples, while arguing subjectivity is different from sentiment, the two types of subjectivity are often related. Thus, we investigate incorporating sentiment information based on the presence of unigram clues from a publically-available sentiment lexicon5 (Wilson, 2005). Each clue in the lexicon is marked as being either “strong” or “weak”. We found that this lexicon was producing many false hits for positive sentiment. Thus, a span containing a minimum of two positive clues of which at least one is marked as “strong”, or three positive “weak” clues, is augmented with a feature indicating positive sentiment. For negative sentiment the threshold is slightly lower, at one “strong” clue or two “weak” clues. These features are referred to as “senti”. A challenge to argument tag assignment is the broad diversity of language through which individual entities or sp"
W12-3810,P11-1150,0,0.0390719,"stigate the utility of a sentiment lexicon, discourse parser, and semantic similarity measures with respect to recognizing arguments. By incorporating information gained from these resources, we outperform a unigram baseline by a significant margin. In addition, we explore a two-phase approach to recognizing arguments, with promising results. 1 Introduction Subjectivity analysis is a thriving field within natural language processing. However, most research into subjectivity has focused on sentiment with respect to concrete things such as product debates (e.g., (Somasundaran and Wiebe, 2009), (Yu et al., 2011)) and movie reviews (e.g., (He et al., 2011), (Maas et al., 2011), (Pang and Lee, 2004)). Analysis often follows the opinion-target paradigm, in which expressions of sentiment are assessed with respect to the aspects of the object(s) under consideration towards which they are targeted. For example, (1) Almost everyone knows that we must start holding insurance companies accountable and give Americans a greater sense of stability and security when it comes to their health care. In a traditional opinion-target or sentimenttopic paradigm, perhaps this sentence could be labeled as containing a neg"
W12-3810,D09-1098,0,\N,Missing
W14-2603,J13-3002,0,0.122263,"supporting evidences for detecting Chinese gfbf events. In the disagreement analysis, we have observed interesting cases which are gfbf events in semantics but are triggered by Chinese own syntax. We explain the cases in Section 3.3. Further, we analyze gfbf words and syntax of agents/objects in Chinese. Our analysis shows that it is feasible to extract components of Chinese gfbf events utilizing the existing resources. In the last section we briefly talk bout the Chinese explicit sentiment analysis. 2 Related Work In addition to researches focusing on explicit sentiments (Wiebe et al., 2005; Johansson and Moschitti, 2013; Yang and Cardie, 2013), recently there are work investigating features that directly indicate implicit sentiments (Zhang and Liu, 2011; Feng et al., 2013), or working on inferring implicit opinions (Choi and Cardie, 2008; Zhang and Liu, 2011; Anand and Reschke, 2010; Reschke and Anand, 2011; Goyal et al., 2013). Different from their work, which do not cover all the inferences of implicit opinions over explicit opinions and gfbf events, we define a generalized set of inference rules and incorporate the rules into a graph-based model to achieve sentiment propagation between the agents and obje"
W14-2603,P13-1117,0,0.0149013,"e gfbf event and the object is the entity that the gfbf event affects. This definition is very similar to subject and (in)direct object in semantic role labeling. Xue and Palmer (2004) investigate the Chinese semantic role labeling. They utilize the PropBank and the constituency parser. However, from a preliminary analysis of constituency parse, we cannot distinguish the agent and object merely from the parse tree, because the sentences in the editorials are usually complicated and it is difficult to classify whether a noun phrase (NP) constituency is agent or object in terms of its position. Kozhevnikov and Titov (2013) adopt a model transfer between different languages using dependency parser. In our case, the dependency parser has labels such Chinese Reversers The polarity of a gfbf event could be changed by a reverser (Deng et al., 2013). A common class of reversers is negation. For example, in the sentence, “the bill will not increase the costs”, the gf increase is changed to be bf via the negation not. In this section, we analyze the Chinese reversers. All of the reversers in the Chinese gfbf corpus happen to be negations. In the English sentences, 14 translators tend to break down a long English senten"
W14-2603,J08-4004,0,0.0222777,"gfbf, agent, or object). Suppose A is a set of annotations of a particular type and B is the set of annotations of the same type from the other annotator. For any text span a ∈ A and b ∈ B, the span coverage c counts the percentage of overlapping Chinese characters between a and b, |a ∩ b| |b| agent 0.9091 0.9524 agent attitude 0.7830 0.5913 Table 1: Results for Agreement Study Analysis. Agreement Study Evaluation and Result c(a, b) = gfbf 0.7929 0.7044 gfbf polarity 0.9385 0.8966 (2) agr(A||B) + agr(B||A) (3) 2 Now that we have the sets of annotations on which the annotators agree, we use κ (Artstein and Poesio, 2008) to measure agreement for the attributes. We report three κ values: one for the polarities of the gfbf events, and the other two for the writer’s attitudes toward the agents and objects. Three annotator participate in the agreement study. All of them are Chinese graduate students studying in US. One of them is the co-author of this work (Anno 1), while the other two do agr(A, B) = 10 Table 1 Polar Eng Anno 1 & 2 agent object 0.783 0.723 0.875 0.915 0.738 0.652 Anno 1& 3 agent object 0.591 0.848 1 0.88 0.4633 0.8734 marked. Some annotators view from pragmatics and read as a passive voice. Since"
W14-2603,D10-1005,0,0.0581118,"Missing"
W14-2603,W09-2307,0,0.0365219,"Missing"
W14-2603,P11-1033,0,0.042992,"Missing"
W14-2603,D08-1083,0,0.0608387,"Missing"
W14-2603,E14-1040,1,0.826005,"(denoted DCW corpus) (Deng et al., 2013)2 and generalizes such events, defining a badFor (bf) event to be an event that negatively affects the object and a goodFor (gf) event to be an event that positively affects the object of the event. Here, lower is a bf event. According to the annotation scheme, goodFor/badFor (hereafter gfbf ) events have NP agents and objects (though the agent may be implicit), and the polarity of a gf event may be changed to bf by a reverser (and vice versa). We have developed a set of rules for inferring implicit sentiments, from explicit sentiments and gfbf events (Deng and Wiebe, 2014). We incorporate the rules into a graph-based model, which significantly improves classifying the sentiments toward agents and objects in the gfbf events. The contribution of this work is investigating implicatures in a second language, specifically in Chinese. People in different languages may express implicit opinions in different ways, so it is better to first assess similarity of implicatures in the two languages, rather than to directly utilize the English resources. In this work we conduct an agreement study for gfbf information in Chinese. The good agreement scores provide evidence for"
W14-2603,P13-2022,1,0.89719,"res “normally accompany the utterances of a given sentence unless special factors exclude that possibility (p. 39).” (Huddleston and Pullum, 2002) 2 Available at: http://mpqa.cs.pitt.edu/ 8 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 8–17, c Baltimore, Maryland, USA. June 27, 2014. 2014 Association for Computational Linguistics positively affects an entity (similarly, for badFor (bf) events). A gfbf triple has the structure of h agent, gfbf, objecti, though the agent can be implicit. For example, in the sentence from (Deng et al., 2013), “Repealing the Affordable Care Act (ACA) would hurt our economy.”, there are two gfbf triples. One is hRepealing the ACA, hurt, families, our economyi, which is a bf. The other is himplicit, Repealing, the ACAi, which is bf and the agent is implicit. The DCW corpus contains manually annotated gfbf events, the gfbf polarities, the corresponding agents and objects and the writer’s attitudes toward the agents and objects. Because people in different languages may express their opinions in different ways. In this section, we conduct an agreement study for Chinese gfbf information in Section 3.1"
W14-2603,W11-0145,0,0.0665002,"Missing"
W14-2603,P13-1174,0,0.0488423,"Missing"
W14-2603,D08-1058,0,0.0860848,"Missing"
W14-2603,P09-1027,0,0.0490287,"Missing"
W14-2603,W03-2102,1,0.846349,"al and several Chinese gfbf examples. Then, the annotators label several paragraphs and discuss their disagreements to reconcile their differences. For the formal agreement study, we randomly selected 60 paragraphs, which have a total of 253 Chinese sentences. These paragraphs are different from the paragraphs discussed during training. The annotators then independently annotated the 60 selected paragraphs. 3.2 κ Anno 1 & 2 Anno 1 & 3 (1) where |a |is the number of characters in span a, and ∩ gives the set of characters that two spans have in common (Johansson and Moschitti, 2013). Following (Wilson and Wiebe, 2003), we treat each set A and B in turn as the gold-standard and calculate the average F-measure (agr(A, B)). P a∈A,b∈B, c(a, b) agr(A||B) = |a∩b|>0 |B| object 0.9091 1.0 object attitude 0.7238 0.8478 not know details of gfbf and implicature before (Anno2, Anno3). Since Anno1 is familiar with this work, we compare the other two’s annotations to Anno1’s. In Table 1, the upper half is the agreement for span overlapping (agr(A, B)), and the lower half is the agreement for attribute (κ). The result have shown that the annotators have good agreement scores, though our training period is not long and ou"
W14-2603,W04-3212,0,0.0298579,"Missing"
W14-2603,P13-1161,0,0.0610296,"Missing"
W14-2603,P11-2101,0,0.0440101,"Missing"
W14-2618,W10-0204,0,0.0284656,"n, makes us hopeful that gfbf information may be practically exploited to improve sentiment analysis in the future. baseline 0.37 0.44 Table 2: Results against sense-annotated data Anno1 Anno2 gf accuracy 0.74 0.68 bf accuracy 0.83 0.74 baseline 0.37 0.44 Table 3: Accuracy broken down for gfbf 5 Conclusion and Future Work Related Work Lexicons are widely used in sentiment analysis and opinion extraction. There are several previous works to acquire or expand sentiment lexicons such as (Kim and Hovy, 2004), (Strapparava and Valitutti, 2004), (Esuli and Sebastiani, 2006), (Gyamfi et al., 2009), (Mohammad and Turney, 2010) and (Peng and Park, 2011). Such sentiment lexicons are helpful for detecting explicitly stated opinions, but are not sufficient for recognizing implicit opinions. Inferred opinions often have opposite polarities from the explicit sentiment expressions in the sentence; explicit sentiments must be combined with benefactive, malefactive state and event information to detect implicit sentiments. There are few previous works closest to ours. (Feng et al., 2011) build connotation lexicons that list words with connotative polarity and connotative predicates. Goyal et al. (2010) generate a lexicon of"
W14-2618,D09-1020,1,0.899625,"kers judge the entries in which we have least confidence. This would be much more time- and cost-effective. The seed sets we used are small - only 400 total senses. We believe it will be worth the effort to create larger seed sets, with the hope to mine many additional gfbf senses from WordNet. To exploit the lexicon to recognize sentiments in a corpus, the word-sense ambiguity we discovered needs to be addressed. There is evidence that the performance of word-sense disambiguation systems using a similar coarse-grained sense inventory is much better than when the full sense inventory is used (Akkaya et al., 2009; Akkaya et al., 2011). That, coupled with the fact that our study suggests that many words are unambiguous with respect to the gfbf distinction, makes us hopeful that gfbf information may be practically exploited to improve sentiment analysis in the future. baseline 0.37 0.44 Table 2: Results against sense-annotated data Anno1 Anno2 gf accuracy 0.74 0.68 bf accuracy 0.83 0.74 baseline 0.37 0.44 Table 3: Accuracy broken down for gfbf 5 Conclusion and Future Work Related Work Lexicons are widely used in sentiment analysis and opinion extraction. There are several previous works to acquire or ex"
W14-2618,W10-0731,1,0.882076,"ources are promising for expanding such sense-level lexicons. Even though the seed set is completely independent from the corpus, the expanded lexicon’s coverage of the corpus is not small. The accuracy of the expanded lexicon is substantially higher than baseline accuracy. Also, the results of the agreement study are positive, providing evidence that the annotation task is feasible and that the concept of gfbf gives us a natural coarse-grained grouping of senses. However, there is still room for improvement. We believe that gf/bf judgements of word senses could be effectively crowd-sourced; (Akkaya et al., 2010), for example, effectively used Amazon Mechanical Turk (AMT) for similar coarsegrained judgements. The idea would be to use automatic expansion methods to create a sense-level lexicon, and then have AMT workers judge the entries in which we have least confidence. This would be much more time- and cost-effective. The seed sets we used are small - only 400 total senses. We believe it will be worth the effort to create larger seed sets, with the hope to mine many additional gfbf senses from WordNet. To exploit the lexicon to recognize sentiments in a corpus, the word-sense ambiguity we discovered"
W14-2618,W11-0311,1,0.892606,"s in which we have least confidence. This would be much more time- and cost-effective. The seed sets we used are small - only 400 total senses. We believe it will be worth the effort to create larger seed sets, with the hope to mine many additional gfbf senses from WordNet. To exploit the lexicon to recognize sentiments in a corpus, the word-sense ambiguity we discovered needs to be addressed. There is evidence that the performance of word-sense disambiguation systems using a similar coarse-grained sense inventory is much better than when the full sense inventory is used (Akkaya et al., 2009; Akkaya et al., 2011). That, coupled with the fact that our study suggests that many words are unambiguous with respect to the gfbf distinction, makes us hopeful that gfbf information may be practically exploited to improve sentiment analysis in the future. baseline 0.37 0.44 Table 2: Results against sense-annotated data Anno1 Anno2 gf accuracy 0.74 0.68 bf accuracy 0.83 0.74 baseline 0.37 0.44 Table 3: Accuracy broken down for gfbf 5 Conclusion and Future Work Related Work Lexicons are widely used in sentiment analysis and opinion extraction. There are several previous works to acquire or expand sentiment lexicon"
W14-2618,J08-4004,0,0.0537863,"Missing"
W14-2618,D13-1066,0,0.162557,"Missing"
W14-2618,E14-1040,1,0.687348,"ed senses culled from FrameNet and expand the lexicon using WordNet relationships. The evaluations show that the accuracy of the approach is well above baseline accuracy. 1 Introduction Opinions are commonly expressed in many kinds of written and spoken text such as blogs, reviews, new articles, and conversation. Recently, there have been a surge in reserach in opinion analysis (sentiment analysis) research (Liu, 2012; Pang and Lee, 2008). While most past researches have mainly addressed explicit opinion expressions, there are a few researches for implicit opinions expressed via implicatures. Deng and Wiebe (2014) showed how sentiments toward one entity may be propagated to other entities via opinion implicature rules. Consider The bill would curb skyrocketing health care costs. Note that curb costs is bad for the object costs since the costs are reduced. We can reason that the writer is positive toward the event curb since the event is bad for the object health care costs which the writer expresses an explicit negative sentiment (skyrocketing). We can reason from there that the writer is positive toward the bill, since it is the agent of the positive event. 107 Proceedings of the 5th Workshop on Compu"
W14-2618,strapparava-valitutti-2004-wordnet,0,0.101721,"t our study suggests that many words are unambiguous with respect to the gfbf distinction, makes us hopeful that gfbf information may be practically exploited to improve sentiment analysis in the future. baseline 0.37 0.44 Table 2: Results against sense-annotated data Anno1 Anno2 gf accuracy 0.74 0.68 bf accuracy 0.83 0.74 baseline 0.37 0.44 Table 3: Accuracy broken down for gfbf 5 Conclusion and Future Work Related Work Lexicons are widely used in sentiment analysis and opinion extraction. There are several previous works to acquire or expand sentiment lexicons such as (Kim and Hovy, 2004), (Strapparava and Valitutti, 2004), (Esuli and Sebastiani, 2006), (Gyamfi et al., 2009), (Mohammad and Turney, 2010) and (Peng and Park, 2011). Such sentiment lexicons are helpful for detecting explicitly stated opinions, but are not sufficient for recognizing implicit opinions. Inferred opinions often have opposite polarities from the explicit sentiment expressions in the sentence; explicit sentiments must be combined with benefactive, malefactive state and event information to detect implicit sentiments. There are few previous works closest to ours. (Feng et al., 2011) build connotation lexicons that list words with connotat"
W14-2618,P13-2022,1,0.443356,"is positive toward the bill, since it is the agent of the positive event. 107 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 107–112, c Baltimore, Maryland, USA. June 27, 2014. 2014 Association for Computational Linguistics 2 The GFBF Corpus (bad for); that is, word-level approaches can work well. However, word-level approaches are not applicable for all the words. Consider the following: A corpus of blogs and editorials about the Affordable Care Act, a controversial topic, was manually annotated with gfbf information by Deng et al. (2013)1 . This corpus provides annotated gfbf events and the agents and objects of the events. It consists of 134 blog posts and editorials. Because the Affordable Health Care Act is a controversial topic, the data is full of opinions. In this corpus, 1,411 gfbf instances are annotated, each including a gfbf event, its agent, and its object (615 gf instances and 796 bf instances). 196 different words appear in gf instances and 286 different words appear in bf instances; 10 words appear in both. 3 • A word with gf and neutral senses: inspire S3: (v) prompt, inspire, instigate (serve as the inciting c"
W14-2618,esuli-sebastiani-2006-sentiwordnet,0,0.0239804,"s are unambiguous with respect to the gfbf distinction, makes us hopeful that gfbf information may be practically exploited to improve sentiment analysis in the future. baseline 0.37 0.44 Table 2: Results against sense-annotated data Anno1 Anno2 gf accuracy 0.74 0.68 bf accuracy 0.83 0.74 baseline 0.37 0.44 Table 3: Accuracy broken down for gfbf 5 Conclusion and Future Work Related Work Lexicons are widely used in sentiment analysis and opinion extraction. There are several previous works to acquire or expand sentiment lexicons such as (Kim and Hovy, 2004), (Strapparava and Valitutti, 2004), (Esuli and Sebastiani, 2006), (Gyamfi et al., 2009), (Mohammad and Turney, 2010) and (Peng and Park, 2011). Such sentiment lexicons are helpful for detecting explicitly stated opinions, but are not sufficient for recognizing implicit opinions. Inferred opinions often have opposite polarities from the explicit sentiment expressions in the sentence; explicit sentiments must be combined with benefactive, malefactive state and event information to detect implicit sentiments. There are few previous works closest to ours. (Feng et al., 2011) build connotation lexicons that list words with connotative polarity and connotative p"
W14-2618,D11-1101,0,0.233676,"Missing"
W14-2618,D10-1008,0,0.0839149,"Missing"
W14-2618,N09-1002,1,0.771558,"to the gfbf distinction, makes us hopeful that gfbf information may be practically exploited to improve sentiment analysis in the future. baseline 0.37 0.44 Table 2: Results against sense-annotated data Anno1 Anno2 gf accuracy 0.74 0.68 bf accuracy 0.83 0.74 baseline 0.37 0.44 Table 3: Accuracy broken down for gfbf 5 Conclusion and Future Work Related Work Lexicons are widely used in sentiment analysis and opinion extraction. There are several previous works to acquire or expand sentiment lexicons such as (Kim and Hovy, 2004), (Strapparava and Valitutti, 2004), (Esuli and Sebastiani, 2006), (Gyamfi et al., 2009), (Mohammad and Turney, 2010) and (Peng and Park, 2011). Such sentiment lexicons are helpful for detecting explicitly stated opinions, but are not sufficient for recognizing implicit opinions. Inferred opinions often have opposite polarities from the explicit sentiment expressions in the sentence; explicit sentiments must be combined with benefactive, malefactive state and event information to detect implicit sentiments. There are few previous works closest to ours. (Feng et al., 2011) build connotation lexicons that list words with connotative polarity and connotative predicates. Goyal et al."
W14-2618,O97-1002,0,0.0273278,"Missing"
W14-2618,C04-1200,0,0.152208,"pled with the fact that our study suggests that many words are unambiguous with respect to the gfbf distinction, makes us hopeful that gfbf information may be practically exploited to improve sentiment analysis in the future. baseline 0.37 0.44 Table 2: Results against sense-annotated data Anno1 Anno2 gf accuracy 0.74 0.68 bf accuracy 0.83 0.74 baseline 0.37 0.44 Table 3: Accuracy broken down for gfbf 5 Conclusion and Future Work Related Work Lexicons are widely used in sentiment analysis and opinion extraction. There are several previous works to acquire or expand sentiment lexicons such as (Kim and Hovy, 2004), (Strapparava and Valitutti, 2004), (Esuli and Sebastiani, 2006), (Gyamfi et al., 2009), (Mohammad and Turney, 2010) and (Peng and Park, 2011). Such sentiment lexicons are helpful for detecting explicitly stated opinions, but are not sufficient for recognizing implicit opinions. Inferred opinions often have opposite polarities from the explicit sentiment expressions in the sentence; explicit sentiments must be combined with benefactive, malefactive state and event information to detect implicit sentiments. There are few previous works closest to ours. (Feng et al., 2011) build connotation lex"
W14-2618,W12-3702,1,\N,Missing
W14-2625,E14-1040,1,0.83805,"Intelligent Systems Program University of Pittsburgh lid29@pitt.edu Abstract Below, we give terminology, overview the rulebased system, and then present the rule schemas. Finally, via discussion of an example from the MPQA opinion-annotated corpus (Wiebe et al., 2005)1 , we illustrate the potential of the framework for recognizing implicit sentiments and writer-level sentiments that are not anchored on clear sentiment words, and for capturing interdependencies among explicit and implicit sentiments. We have developed a graph-based computational model implementing some rules introduced below (Deng and Wiebe, 2014). Moreover, in ongoing work, we have proposed an optimization framework to jointly extract and resolve the input ambiguities. While previous sentiment analysis research has concentrated on the interpretation of explicitly stated opinions and attitudes, this work addresses a type of opinion implicature (i.e., opinion-oriented default inference) in real-world text. This work describes a rule-based conceptual framework for representing and analyzing opinion implicatures. In the course of understanding implicatures, the system recognizes implicit sentiments (and beliefs) toward various events and"
W14-2625,P06-1134,1,0.762051,"pinion implicature, to provide a blueprint for realizing fully automatic systems in the future. 1 Available at http://mpqa.cs.pitt.edu 154 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 154–159, c Baltimore, Maryland, USA. June 27, 2014. 2014 Association for Computational Linguistics 3 private state is sentiment. There are many types of linguistic clues that contribute to recognizing subjective expressions (Wiebe, 1994). In the clearest case, some word senses give rise to subjectivity whenever they are used in discourse (Wiebe and Mihalcea, 2006). Other clues are not as definitive. For example, researchers in NLP have begun to develop lexicons of connotations (Feng et al., 2011), i.e., words associated with polarities out of context (e.g., war has negative connotation and sunshine has positive connotation (Feng et al., 2013)). However, words may be used in context with polarities opposite to their connotations, as in Ghenghis Kan likes war. Inferred Private States and Opinion Implicatures. We address private states inferred from other private states, where the attitude type of both is sentiment. Inference is initiated by explicit sent"
W14-2625,P13-2022,1,0.691112,"ted vs. what is said (Doran et al., 2012). Generalized conversational implicatures are cancellable, or defeasible. Analogously, we can treat subjectivity as part of what is said,2 and the private-state inferences we address to be part of what is implicated. Opinion implicatures are default inferences that may not go through in context. Benefactive/Malefactive Events and States. This work addresses sentiments toward, in general, states and events which positively or negatively affect entities. Various lexical items and semantic roles evoke such situations. We adopt one clear case in this work (Deng et al., 2013): hagent, event, objecti triples, where event negatively (badFor) or positively (goodFor) affects the object. An event that is goodFor or badFor is a gfbf event. Note that we have annotated a corpus with gfbf information and the speaker’s sentiment toward the agents and objects of gfbf events (Deng et al., 2013).3 Overview In this section, we give an overview of the rulebased system to provide an intuitive big picture of what it can infer, instead of elaborating specific rules, which will be introduced in Section 4. The system includes default inference rules which apply if there is no evidenc"
W14-2625,J94-2004,1,0.456555,"-world text. This work describes a rule-based conceptual framework for representing and analyzing opinion implicatures. In the course of understanding implicatures, the system recognizes implicit sentiments (and beliefs) toward various events and entities in the sentence, often of mixed polarities; thus, it produces a richer interpretation than is typical in opinion analysis. 1 2 Introduction Terminology The building blocks of our opinion implicature framework are subjectivity, inferred private states, and benefactive/malefactive events and states. Subjectivity. Following (Wiebe et al., 2005; Wiebe, 1994), subjectivity is defined as the expression of private states in language, where private states are mental and emotional states such as speculations, sentiments, and beliefs (Quirk et al., 1985). Subjective expressions (i.e., opinions) have sources (or holders): the entity or entities whose private states are being expressed. Again following (Wiebe et al., 2005; Wiebe, 1994), a private state is an attitude held by a source toward (optionally) a target. Sentiment and belief are types of attitudes. Subjectivity is the linguistic expression of private states. Subjectivity is a pragmatic notion: a"
W14-2625,D11-1101,0,0.029625,"ceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 154–159, c Baltimore, Maryland, USA. June 27, 2014. 2014 Association for Computational Linguistics 3 private state is sentiment. There are many types of linguistic clues that contribute to recognizing subjective expressions (Wiebe, 1994). In the clearest case, some word senses give rise to subjectivity whenever they are used in discourse (Wiebe and Mihalcea, 2006). Other clues are not as definitive. For example, researchers in NLP have begun to develop lexicons of connotations (Feng et al., 2011), i.e., words associated with polarities out of context (e.g., war has negative connotation and sunshine has positive connotation (Feng et al., 2013)). However, words may be used in context with polarities opposite to their connotations, as in Ghenghis Kan likes war. Inferred Private States and Opinion Implicatures. We address private states inferred from other private states, where the attitude type of both is sentiment. Inference is initiated by explicit sentiment subjectivity. We borrow the term implicature from linguistics, specifically generalized conversational implicature. Grice (1967;"
W14-2625,P13-1174,0,0.0199864,"USA. June 27, 2014. 2014 Association for Computational Linguistics 3 private state is sentiment. There are many types of linguistic clues that contribute to recognizing subjective expressions (Wiebe, 1994). In the clearest case, some word senses give rise to subjectivity whenever they are used in discourse (Wiebe and Mihalcea, 2006). Other clues are not as definitive. For example, researchers in NLP have begun to develop lexicons of connotations (Feng et al., 2011), i.e., words associated with polarities out of context (e.g., war has negative connotation and sunshine has positive connotation (Feng et al., 2013)). However, words may be used in context with polarities opposite to their connotations, as in Ghenghis Kan likes war. Inferred Private States and Opinion Implicatures. We address private states inferred from other private states, where the attitude type of both is sentiment. Inference is initiated by explicit sentiment subjectivity. We borrow the term implicature from linguistics, specifically generalized conversational implicature. Grice (1967; 1989) introduced the notion to account for how more can be pragmatically communicated than what is strictly said - what is implicated vs. what is sai"
W14-3408,W12-2416,1,0.875314,"Missing"
W16-0411,W11-0702,0,0.0523523,"Missing"
W16-0411,P12-1042,0,0.0214305,"sentiments non-reinforcing(X,Y) X and Y are non-reinforcing sentiments ideology(X,I) X holds ideology I aspect(X,Y) an aspect (feature) of X is Y Table 1: Atoms in the Rules. word him refers to Obama. The instantiated rule is: (R2) posExternal(writer,him) ∧ sameEntity(him,Obama) ⇒ pos(writer,Obama) Agree. We may also infer that the writer has the same sentiments as sources with whom he or she agrees. While much previous work detects agreement at the turn level in conversation (Michel Galley, 2004; Wang et al., 2011), or identifies participants who agree with one another (Hassan et al., 2012; Abu-Jbara et al., 2012; Park et al., 2011), there is recent work on detecting agreement within documents (Wang and Cardie, 2014; Abbott et al., 2011; Misra and Walker, 2013). Consider, I agree with Paul. ... The plan is a brilliant idea. The writer (I) agree with Paul, and the writer is positive toward the plan. Then we infer that probably Paul is positive toward the plan. (R3) agree(writer,Paul) ∧ posExternal(writer,plan) ⇒ pos(Paul,plan) Opinion-oriented Discourse Models. Furthermore, previous work have developed opinionoriented discourse models (OODMs) (Somasundaran, 2010). The OODM models recognize toward 55 wh"
W16-0411,D15-1263,0,0.0218125,"products and sentiments toward different aspects (Liu, 2012). (Non-)Reinforcing Sentiment Analysis. In the other case, people may be ambivalent, or change their minds in the course of a document. Two sentiments may be in reinforcing or non-reinforcing discourse scenarios. Reinforcing relations exist between opinions when they contribute to the same overall stance. Non-reinforcing relations exist between opinions that show ambivalence, which represents a discourse scenario in which inconsistent sentiments are expressed with respect to a stance (Somasundaran, 2010; Trivedi and Eisenstein, 2013; Bhatia et al., 2015). Consider, It is expensive. ... However, I think it is worth a try if I loan to buy the phone. Previous work (Somasundaran, 2010) may recognize that two non-reinforcing sentiments occur (indicated by the word However). S1 represents the negative opinion in the first sentence expressed toward it, and S2 represents the positive opinion in the second sentence expressed toward the phone. (R7) non-reinforcing(S1,S2) ∧ source(S1,writer) ∧ source(S2,writer) ∧ target(S1,It) ∧ target(S2,the phone) ∧ sameEntity(It, the phone) ∧ negExternal(writer,It) ⇒ pos(writer,the phone) 56 Rules of Extra-Document K"
W16-0411,T75-2000,0,0.691625,"urthermore, previous work have developed opinionoriented discourse models (OODMs) (Somasundaran, 2010). The OODM models recognize toward 55 which entities the writer’s sentiments are the same (sameEntity), and toward which entities the writer’s sentiments are opposite (altEntity). The discourse sameEntity relation covers not only identity, but also part-whole, synonymy, generalization, specialization, entity-attribute/aspect, instantiation, cause-effect, and implicit background topic, i.e., relations that have been studied by many researchers in the context of anaphora and co-reference (e.g. (Clark, 1975; Vieira and Poesio, 2000; Mueller and Strube, 2001)). Two entities are in an altEntity relation if they are mutually exclusive options in the context of the discourse. For example, in a debate about mobile phones, the iPhone and iOS are considered as sameEntity, while the Android and iPhone are considered as altEntity. In OODM models, same sentiments toward same entities express the same stance, and opposite sentiments toward alternative targets express the same overall stance (Somasundaran, 2010). (R4) posExternal(writer,iOS) ∧ sameEntity(iOS,iPhone) ⇒ pos(writer,iPhone) (R5) posExternal(wri"
W16-0411,D15-1018,1,0.868622,"ction Opinions are ubiquitous in language. Existing opinion analysis techniques rely on the clues in the sentence that focus on the sentiment analysis task itself. Consider, for example, (Ex1) Oh no, the voters defeated the bill. The sentiment lexicons are used to recognize Oh no as a negative opinion, the semantic role labeling features are used to recognize the target is the defeating event (Yang and Cardie, 2013), and the implicatures are used to recognize the writer is positive toward the bill since the writer is negative toward the defeating event which harms the bill (Deng et al., 2014; Deng and Wiebe, 2015). These work mainly 53 Janyce Wiebe Intelligent Systems Program Department of Computer Science University of Pittsburgh wiebe@cs.pitt.edu rely on the clues that directly indicate opinions (e.g., recognizing On no as a negative opinion), or indicate components of opinions (e.g., recognizng the target being defeating), or indicate other opinions based on the information within the sentence (e.g., recognizing a positive opinion toward the bill). They do not exploit the vast amount of knowledge outside the sentence, which are outputs from many NLP tasks. But the task of sentiment analysis may bene"
W16-0411,P13-2022,1,0.900238,"Missing"
W16-0411,C14-1009,1,0.906084,"Missing"
W16-0411,N13-1092,0,0.0259636,"Missing"
W16-0411,N09-1057,0,0.0369269,"Ex(5A) John deleted the file I need. Ex(5B) John accidentally deleted the file I need. the rules imply a negative sentiment toward John. However, this inference is weakened in the variation (Ex5B). To recognize these cases, lexical clues are important, such as unintentionally, involuntary. Given a list of seed words, resources such as WordNet, word embeddings (Mikolov et al., 2013) and paraphrase databases (e.g., PPDB (Ganitkevitch et al., 2013)) can be utilized to find semantically similar words and phrases. 2 We realized these cases from the study of implicit sentiment in Greene and Resnik (Greene and Resnik, 2009). 57 5 Conclusion Sentiment analysis is not isolated from other NLP tasks. The conceptual framework in this paper aims at improving sentiment analysis by introducing dependency rules between sentiments and various knowledge provided from various NLP tasks including co-reference resolution, opinion discourse analysis, entity linking and ideology, etc. The framework uses dependency rules as constraints in the joint models. Further, the framework can block a rule in context by recognizing evidences against the instantiated rule. Though it is a conceptual framework, it bridges different tasks of s"
W16-0411,D12-1006,0,0.0164979,"and Y are reinforcing sentiments non-reinforcing(X,Y) X and Y are non-reinforcing sentiments ideology(X,I) X holds ideology I aspect(X,Y) an aspect (feature) of X is Y Table 1: Atoms in the Rules. word him refers to Obama. The instantiated rule is: (R2) posExternal(writer,him) ∧ sameEntity(him,Obama) ⇒ pos(writer,Obama) Agree. We may also infer that the writer has the same sentiments as sources with whom he or she agrees. While much previous work detects agreement at the turn level in conversation (Michel Galley, 2004; Wang et al., 2011), or identifies participants who agree with one another (Hassan et al., 2012; Abu-Jbara et al., 2012; Park et al., 2011), there is recent work on detecting agreement within documents (Wang and Cardie, 2014; Abbott et al., 2011; Misra and Walker, 2013). Consider, I agree with Paul. ... The plan is a brilliant idea. The writer (I) agree with Paul, and the writer is positive toward the plan. Then we infer that probably Paul is positive toward the plan. (R3) agree(writer,Paul) ∧ posExternal(writer,plan) ⇒ pos(Paul,plan) Opinion-oriented Discourse Models. Furthermore, previous work have developed opinionoriented discourse models (OODMs) (Somasundaran, 2010). The OODM model"
W16-0411,P14-1105,0,0.022594,"uppose we have known that Donald Trump is conservative, and a conservative ideology is against the concept of gun control, then we probably infer that he is opposed to gun control in the context. (R10) ideology(Donald Trump,C ONSERVATIVE) ∧ negExternal(C ONSERVATIVE,G UN C ONTROL) ∧ sameEntity(G UN C ONTROL, gun control) ⇒ neg(Donald Trump,gun control) Rather than attempt to computationally define a general notion of ideology, people in NLP tend to use data for which specific ideologies have been defined. Previous work have studied recognizing ideologies including political party affiliation (Iyyer et al., 2014), or labels such as left, right, and center (Sim et al., 2013), or use a proxy for ideology such as voting record (Gerrish and Blei, 2011). 4 Integrating Evidence Against Rules The framework allows exceptions to the rules. The joint models implemented in the previous work (Deng et al., 2014; Deng and Wiebe, 2015) use implicature rules as soft constraints. However, previous work didn’t investigate when the rules are blocked. In this section we introduce two types of evidences against the rules. 2 The first case is when the event is involuntarily conducted. Consider Ex(4A) below. (Ex4A) The insu"
W16-0411,P11-1115,0,0.0257996,"e negative opinion in the first sentence expressed toward it, and S2 represents the positive opinion in the second sentence expressed toward the phone. (R7) non-reinforcing(S1,S2) ∧ source(S1,writer) ∧ source(S2,writer) ∧ target(S1,It) ∧ target(S2,the phone) ∧ sameEntity(It, the phone) ∧ negExternal(writer,It) ⇒ pos(writer,the phone) 56 Rules of Extra-Document Knowledge Entity Linking. Knowledge from outside the document is also important. For example, the work in entity linking maps entity mentions (e.g.,Obama, US President) in the text to entries in the knowledge base (e.g., BARACK O BAMA) (Ji and Grishman, 2011; Rao et al., 2013). Such information can be exploited to recognize sameEntity, as shown below. (R9) sameEntity(Obama, BARACK O BAMA) ∧ sameEntity(US President, BARACK O BAMA) ⇒ sameEntity(Obama, US President) Thus, we can use the knowledge base to enrich the recognition of sameEntity and help recognize more sentiments. Ideology. Groups of people sharing the same ideology tend to have the same opinions about certain things. Suppose we have known that Donald Trump is conservative, and a conservative ideology is against the concept of gun control, then we probably infer that he is opposed to gun"
W16-0411,P04-1085,0,0.0578083,"Missing"
W16-0411,W13-4006,0,0.0148857,"le 1: Atoms in the Rules. word him refers to Obama. The instantiated rule is: (R2) posExternal(writer,him) ∧ sameEntity(him,Obama) ⇒ pos(writer,Obama) Agree. We may also infer that the writer has the same sentiments as sources with whom he or she agrees. While much previous work detects agreement at the turn level in conversation (Michel Galley, 2004; Wang et al., 2011), or identifies participants who agree with one another (Hassan et al., 2012; Abu-Jbara et al., 2012; Park et al., 2011), there is recent work on detecting agreement within documents (Wang and Cardie, 2014; Abbott et al., 2011; Misra and Walker, 2013). Consider, I agree with Paul. ... The plan is a brilliant idea. The writer (I) agree with Paul, and the writer is positive toward the plan. Then we infer that probably Paul is positive toward the plan. (R3) agree(writer,Paul) ∧ posExternal(writer,plan) ⇒ pos(Paul,plan) Opinion-oriented Discourse Models. Furthermore, previous work have developed opinionoriented discourse models (OODMs) (Somasundaran, 2010). The OODM models recognize toward 55 which entities the writer’s sentiments are the same (sameEntity), and toward which entities the writer’s sentiments are opposite (altEntity). The discour"
W16-0411,W01-1612,0,0.0942482,"ed opinionoriented discourse models (OODMs) (Somasundaran, 2010). The OODM models recognize toward 55 which entities the writer’s sentiments are the same (sameEntity), and toward which entities the writer’s sentiments are opposite (altEntity). The discourse sameEntity relation covers not only identity, but also part-whole, synonymy, generalization, specialization, entity-attribute/aspect, instantiation, cause-effect, and implicit background topic, i.e., relations that have been studied by many researchers in the context of anaphora and co-reference (e.g. (Clark, 1975; Vieira and Poesio, 2000; Mueller and Strube, 2001)). Two entities are in an altEntity relation if they are mutually exclusive options in the context of the discourse. For example, in a debate about mobile phones, the iPhone and iOS are considered as sameEntity, while the Android and iPhone are considered as altEntity. In OODM models, same sentiments toward same entities express the same stance, and opposite sentiments toward alternative targets express the same overall stance (Somasundaran, 2010). (R4) posExternal(writer,iOS) ∧ sameEntity(iOS,iPhone) ⇒ pos(writer,iPhone) (R5) posExternal(writer,iOS) ∧ altEntity(iOS,Android) ⇒ neg(writer,Andro"
W16-0411,P11-1035,0,0.0163165,"ing(X,Y) X and Y are non-reinforcing sentiments ideology(X,I) X holds ideology I aspect(X,Y) an aspect (feature) of X is Y Table 1: Atoms in the Rules. word him refers to Obama. The instantiated rule is: (R2) posExternal(writer,him) ∧ sameEntity(him,Obama) ⇒ pos(writer,Obama) Agree. We may also infer that the writer has the same sentiments as sources with whom he or she agrees. While much previous work detects agreement at the turn level in conversation (Michel Galley, 2004; Wang et al., 2011), or identifies participants who agree with one another (Hassan et al., 2012; Abu-Jbara et al., 2012; Park et al., 2011), there is recent work on detecting agreement within documents (Wang and Cardie, 2014; Abbott et al., 2011; Misra and Walker, 2013). Consider, I agree with Paul. ... The plan is a brilliant idea. The writer (I) agree with Paul, and the writer is positive toward the plan. Then we infer that probably Paul is positive toward the plan. (R3) agree(writer,Paul) ∧ posExternal(writer,plan) ⇒ pos(Paul,plan) Opinion-oriented Discourse Models. Furthermore, previous work have developed opinionoriented discourse models (OODMs) (Somasundaran, 2010). The OODM models recognize toward 55 which entities the wri"
W16-0411,D13-1010,0,0.0142798,"nservative ideology is against the concept of gun control, then we probably infer that he is opposed to gun control in the context. (R10) ideology(Donald Trump,C ONSERVATIVE) ∧ negExternal(C ONSERVATIVE,G UN C ONTROL) ∧ sameEntity(G UN C ONTROL, gun control) ⇒ neg(Donald Trump,gun control) Rather than attempt to computationally define a general notion of ideology, people in NLP tend to use data for which specific ideologies have been defined. Previous work have studied recognizing ideologies including political party affiliation (Iyyer et al., 2014), or labels such as left, right, and center (Sim et al., 2013), or use a proxy for ideology such as voting record (Gerrish and Blei, 2011). 4 Integrating Evidence Against Rules The framework allows exceptions to the rules. The joint models implemented in the previous work (Deng et al., 2014; Deng and Wiebe, 2015) use implicature rules as soft constraints. However, previous work didn’t investigate when the rules are blocked. In this section we introduce two types of evidences against the rules. 2 The first case is when the event is involuntarily conducted. Consider Ex(4A) below. (Ex4A) The insurance companies will increase their spending on health care im"
W16-0411,N13-1100,0,0.0316352,"g data to discover aspects of products and sentiments toward different aspects (Liu, 2012). (Non-)Reinforcing Sentiment Analysis. In the other case, people may be ambivalent, or change their minds in the course of a document. Two sentiments may be in reinforcing or non-reinforcing discourse scenarios. Reinforcing relations exist between opinions when they contribute to the same overall stance. Non-reinforcing relations exist between opinions that show ambivalence, which represents a discourse scenario in which inconsistent sentiments are expressed with respect to a stance (Somasundaran, 2010; Trivedi and Eisenstein, 2013; Bhatia et al., 2015). Consider, It is expensive. ... However, I think it is worth a try if I loan to buy the phone. Previous work (Somasundaran, 2010) may recognize that two non-reinforcing sentiments occur (indicated by the word However). S1 represents the negative opinion in the first sentence expressed toward it, and S2 represents the positive opinion in the second sentence expressed toward the phone. (R7) non-reinforcing(S1,S2) ∧ source(S1,writer) ∧ source(S2,writer) ∧ target(S1,It) ∧ target(S2,the phone) ∧ sameEntity(It, the phone) ∧ negExternal(writer,It) ⇒ pos(writer,the phone) 56 Rul"
W16-0411,J00-4003,0,0.0264286,"revious work have developed opinionoriented discourse models (OODMs) (Somasundaran, 2010). The OODM models recognize toward 55 which entities the writer’s sentiments are the same (sameEntity), and toward which entities the writer’s sentiments are opposite (altEntity). The discourse sameEntity relation covers not only identity, but also part-whole, synonymy, generalization, specialization, entity-attribute/aspect, instantiation, cause-effect, and implicit background topic, i.e., relations that have been studied by many researchers in the context of anaphora and co-reference (e.g. (Clark, 1975; Vieira and Poesio, 2000; Mueller and Strube, 2001)). Two entities are in an altEntity relation if they are mutually exclusive options in the context of the discourse. For example, in a debate about mobile phones, the iPhone and iOS are considered as sameEntity, while the Android and iPhone are considered as altEntity. In OODM models, same sentiments toward same entities express the same stance, and opposite sentiments toward alternative targets express the same overall stance (Somasundaran, 2010). (R4) posExternal(writer,iOS) ∧ sameEntity(iOS,iPhone) ⇒ pos(writer,iPhone) (R5) posExternal(writer,iOS) ∧ altEntity(iOS,"
W16-0411,W14-2617,0,0.0129815,"spect(X,Y) an aspect (feature) of X is Y Table 1: Atoms in the Rules. word him refers to Obama. The instantiated rule is: (R2) posExternal(writer,him) ∧ sameEntity(him,Obama) ⇒ pos(writer,Obama) Agree. We may also infer that the writer has the same sentiments as sources with whom he or she agrees. While much previous work detects agreement at the turn level in conversation (Michel Galley, 2004; Wang et al., 2011), or identifies participants who agree with one another (Hassan et al., 2012; Abu-Jbara et al., 2012; Park et al., 2011), there is recent work on detecting agreement within documents (Wang and Cardie, 2014; Abbott et al., 2011; Misra and Walker, 2013). Consider, I agree with Paul. ... The plan is a brilliant idea. The writer (I) agree with Paul, and the writer is positive toward the plan. Then we infer that probably Paul is positive toward the plan. (R3) agree(writer,Paul) ∧ posExternal(writer,plan) ⇒ pos(Paul,plan) Opinion-oriented Discourse Models. Furthermore, previous work have developed opinionoriented discourse models (OODMs) (Somasundaran, 2010). The OODM models recognize toward 55 which entities the writer’s sentiments are the same (sameEntity), and toward which entities the writer’s se"
W16-0411,P11-2065,0,0.0126193,"ative entities agree(X,Y) X and Y agree with each other reinforcing(X,Y) X and Y are reinforcing sentiments non-reinforcing(X,Y) X and Y are non-reinforcing sentiments ideology(X,I) X holds ideology I aspect(X,Y) an aspect (feature) of X is Y Table 1: Atoms in the Rules. word him refers to Obama. The instantiated rule is: (R2) posExternal(writer,him) ∧ sameEntity(him,Obama) ⇒ pos(writer,Obama) Agree. We may also infer that the writer has the same sentiments as sources with whom he or she agrees. While much previous work detects agreement at the turn level in conversation (Michel Galley, 2004; Wang et al., 2011), or identifies participants who agree with one another (Hassan et al., 2012; Abu-Jbara et al., 2012; Park et al., 2011), there is recent work on detecting agreement within documents (Wang and Cardie, 2014; Abbott et al., 2011; Misra and Walker, 2013). Consider, I agree with Paul. ... The plan is a brilliant idea. The writer (I) agree with Paul, and the writer is positive toward the plan. Then we infer that probably Paul is positive toward the plan. (R3) agree(writer,Paul) ∧ posExternal(writer,plan) ⇒ pos(Paul,plan) Opinion-oriented Discourse Models. Furthermore, previous work have developed o"
W16-0411,W14-2625,1,0.933062,"way: first order logic rules. In summary, this paper presents a conceptual framework using the newly defined dependency rules as constraints of joint models to exploit various kinds of knowledge to make progress toward a deeper interpretation of subjective language. The background of joint models is given in Section 2. The dependency rules and corresponding NLP tasks are given in Section 3. Furthermore, the framework allows exceptions to the rules, which will be discussed in Section 4. Finally we give the conclusion. according to local scores only. However, the previous conceptual framework (Wiebe and Deng, 2014b) only defines rules over the Implicature Knowledge atoms to only consider the information within the sentence. And they are limited to a particular type of event: +/-effect event. Instead, this paper introduces rules defined over the External Knowledge atoms to exploit knowledge outside the sentence and outside the document. Further, the atoms defined in this paper are general so that people can use these atoms to design more rules. 2 Different from the rules defined in (Wiebe and Deng, 2014a), we define new rules depicting the dependencies between sentiments (e.g., pos(X,Y)) and external kn"
W16-0411,P13-1161,0,0.034138,"dependency rules as constraints aims at exploiting information outside the sentence and outside the document to improve sentiment analysis. Further, the framework allows exception to the rules. 1 Introduction Opinions are ubiquitous in language. Existing opinion analysis techniques rely on the clues in the sentence that focus on the sentiment analysis task itself. Consider, for example, (Ex1) Oh no, the voters defeated the bill. The sentiment lexicons are used to recognize Oh no as a negative opinion, the semantic role labeling features are used to recognize the target is the defeating event (Yang and Cardie, 2013), and the implicatures are used to recognize the writer is positive toward the bill since the writer is negative toward the defeating event which harms the bill (Deng et al., 2014; Deng and Wiebe, 2015). These work mainly 53 Janyce Wiebe Intelligent Systems Program Department of Computer Science University of Pittsburgh wiebe@cs.pitt.edu rely on the clues that directly indicate opinions (e.g., recognizing On no as a negative opinion), or indicate components of opinions (e.g., recognizng the target being defeating), or indicate other opinions based on the information within the sentence (e.g.,"
W93-0239,P93-1020,0,0.0657826,"Missing"
W96-0210,C92-2099,0,0.0693075,"Missing"
W96-0210,J93-3003,0,0.0402987,"Missing"
W96-0210,J93-2004,0,0.0406796,"Missing"
W96-0210,H94-1048,0,0.074479,"Missing"
W97-0202,H92-1022,0,0.0902467,"Missing"
W97-0202,J93-2004,0,0.0257617,"esmanual annotation, because it is easier to fix a moderate number of errors than to tag the verbs completely from scratch. The preprocessor performs other miscellaneous tasks to aide in the tagging task, such as separating out punctuation marks and contractions. At the end of the paper, we share some strategies from our coding instructions for recognizing idioms, and show some challenging ambiguities we found in the data. Introduction 2 This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus (Marcus et al. 1993). The purpose of this work is to support related work in automatic word-sense disambiguation. The verbs are tagged with respect to senses in WordNet (Miller 1990), which has become widely used, for example in corpus-annotation projects (Miller et al. 1994, Ng & Hian 1996, and Grishman et al. 1994) and for performing disambiguation (Resnik 1995 and Leacock et ai. 1993). The verbs to tag were chosen on the basis of how frequently they occur in the text, how wide their range of senses, and how distinguishable the senses are from one another. In related work, we have begun to tag nouns and adjecti"
W97-0202,H94-1046,0,0.108598,"ctions. At the end of the paper, we share some strategies from our coding instructions for recognizing idioms, and show some challenging ambiguities we found in the data. Introduction 2 This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus (Marcus et al. 1993). The purpose of this work is to support related work in automatic word-sense disambiguation. The verbs are tagged with respect to senses in WordNet (Miller 1990), which has become widely used, for example in corpus-annotation projects (Miller et al. 1994, Ng & Hian 1996, and Grishman et al. 1994) and for performing disambiguation (Resnik 1995 and Leacock et ai. 1993). The verbs to tag were chosen on the basis of how frequently they occur in the text, how wide their range of senses, and how distinguishable the senses are from one another. In related work, we have begun to tag nouns and adjectives as well. These are being chosen additionally on the basis of co-occurrence with the verbs already tagged, to support approaches such as (Hirst 1987), in which word-sense ambiguities are resolved with respect to one another. T h e Verbs and the Basic T"
W97-0202,W95-0105,0,0.126211,"izing idioms, and show some challenging ambiguities we found in the data. Introduction 2 This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus (Marcus et al. 1993). The purpose of this work is to support related work in automatic word-sense disambiguation. The verbs are tagged with respect to senses in WordNet (Miller 1990), which has become widely used, for example in corpus-annotation projects (Miller et al. 1994, Ng & Hian 1996, and Grishman et al. 1994) and for performing disambiguation (Resnik 1995 and Leacock et ai. 1993). The verbs to tag were chosen on the basis of how frequently they occur in the text, how wide their range of senses, and how distinguishable the senses are from one another. In related work, we have begun to tag nouns and adjectives as well. These are being chosen additionally on the basis of co-occurrence with the verbs already tagged, to support approaches such as (Hirst 1987), in which word-sense ambiguities are resolved with respect to one another. T h e Verbs and the Basic Tag Format The following are the verbs that were tagged. The total number of occurrences is"
W97-0202,P80-1030,0,0.0262109,"erm used in Quirk et al. (1985; pp. 138-148), defined as an occurrence &quot;whose status is in some degree intermediate between auxiliaries and main verbs.&quot; Quirk et al. arrange verbs on a scale ranging from modal auxiliaries to main verbs, and &quot;many of the intermediate verbs, WordNet does not provide entries for all idioms, and the entries it does provide do not always include a sense for the occurrences observed in the corpus. It is important to recognize idioms, because interpreting their constituent words separately would often change the meaning of the sentence (cf., e.g., 9 m Wilks 1977 and Wilensky & Arens 1980). Our coding instructions specify that the tagger should attempt to identify idioms even if WordNet does not provide an entry for it. The preprocessor assistsin this task, by identifyingpotential idioms. The following axe strategies we found useful in dealing with the difficultproblem of manually identifying idioms. 1. Does the word following the verb cease to have any of its usual or literalmeanings as supplied by WordNet when used with that verb? If America can keep_(keep.up verb 1) up the present situation ... the economies of these countries would be totally restructured to be able to almo"
W97-0202,C94-1042,0,\N,Missing
W97-0320,A97-1007,0,0.0266357,"tion, we annotated the seen training dialogs for anaphoric chains, to support analysis of the data. A fully automatic system has been developed that takes as input the ambiguous output of a semantic parser (Lavie ~ Tomita 1993, Levin et al. 1995). The system performance on unseen, held-out test data is good, especially on the CMU data, showing the usefulness of our straightforward approach. The performance on the NMSU data is worse but surprisingly comparable, given the greater complexity of the data and the fact that the system was primarily developed on the simpler data. Rose et al. (1995), Alexandersson et al. (1997), and Busemann et al. (1997) describe other recent NLP systems that resolve temporal expressions in scheduling dialogs as part of their overall processing, but they do not give results of system performance on any temporal interpretation tasks. Kamp & Reyle (1993) address many representational and processing issues in the interpretation of temporal expressions, but they do not attempt coverage of a data set or present results of a working system. To our knowledge, there are no other published results on unseen test data of systems performing the same temporal resolution tasks. The specific con"
W97-0320,A97-1006,0,0.168242,"ing dialogs for anaphoric chains, to support analysis of the data. A fully automatic system has been developed that takes as input the ambiguous output of a semantic parser (Lavie ~ Tomita 1993, Levin et al. 1995). The system performance on unseen, held-out test data is good, especially on the CMU data, showing the usefulness of our straightforward approach. The performance on the NMSU data is worse but surprisingly comparable, given the greater complexity of the data and the fact that the system was primarily developed on the simpler data. Rose et al. (1995), Alexandersson et al. (1997), and Busemann et al. (1997) describe other recent NLP systems that resolve temporal expressions in scheduling dialogs as part of their overall processing, but they do not give results of system performance on any temporal interpretation tasks. Kamp & Reyle (1993) address many representational and processing issues in the interpretation of temporal expressions, but they do not attempt coverage of a data set or present results of a working system. To our knowledge, there are no other published results on unseen test data of systems performing the same temporal resolution tasks. The specific contributions of this paper are"
W97-0320,J96-2004,0,0.0207919,"Missing"
W97-0320,J95-2003,0,0.164862,"on in scheduling dialogs (i.e., dialogs in which participants schedule a meeting with one another). This work thus describes how to identify temporal information that is missing due to ellipsis or anaphora, and it shows how to determine the times evoked by deictic expressions. In developing the algorithm, our approach was to start with a straightforward, recencybased approach and add complexity as needed to address problems encountered in the data. The algorithm does not include a mechanism for handling global focus (Grosz & Sidner 1986), for centering within a discourse segment (Sidner 1979; Grosz et al. 1995), or for performing tense and aspect interpretation. Instead, the algorithm processes anaphoric references with respect to an Attentional State (Grosz & Sidner 1986) structured as a linear list of all times mentioned so far in the current dialog. The list is ordered by recency, no entries are ever deleted from the list, and there is no restriction on access. The algorithm decides among candidate antecedents based on a combined score reflecting recency, a priori preferences for the type Of anaphoric relation(s) established, and plausibility of the resulting temporal reference. In determining th"
W97-0320,J86-3001,0,0.0393889,"ents the results of an empirical investigation of temporal reference resolution in scheduling dialogs (i.e., dialogs in which participants schedule a meeting with one another). This work thus describes how to identify temporal information that is missing due to ellipsis or anaphora, and it shows how to determine the times evoked by deictic expressions. In developing the algorithm, our approach was to start with a straightforward, recencybased approach and add complexity as needed to address problems encountered in the data. The algorithm does not include a mechanism for handling global focus (Grosz & Sidner 1986), for centering within a discourse segment (Sidner 1979; Grosz et al. 1995), or for performing tense and aspect interpretation. Instead, the algorithm processes anaphoric references with respect to an Attentional State (Grosz & Sidner 1986) structured as a linear list of all times mentioned so far in the current dialog. The list is ordered by recency, no entries are ever deleted from the list, and there is no restriction on access. The algorithm decides among candidate antecedents based on a combined score reflecting recency, a priori preferences for the type Of anaphoric relation(s) establish"
W97-0320,P96-1038,0,0.027066,"utterances that do not contain temporal information. In the case of an utterance that refers to multiple, distinct intervals, the representation is a list of Temporal Units. A Temporal Unit is also the representation used in the evaluation of the system. That is, the system&apos;s answers are mapped from its more complex internal representation (an I L T , see section 4.1) into this simpler vector representation before evaluation is performed. As in much recent empirical work in discourse processing (e.g., Arhenberg et al. 1995; Isard & Carletta 1995; Litman & Passonneau 1995; Moser & Moore 1995; Hirschberg & Nakatani 1996), we performed an intercoder reliability study investigating agreement in annotating the times. The goal in developing the annotation instructions is that they can be used reliably by non-experts after a reasonable amount of training (cf. Passonneau & Litman 1993, Condon & Cech 1995, and Hirschberg & Nakatani 1996), where reliability is measured in terms of the amount of agreement among annotators. High reliability indicates that the encoding scheme is reproducible given multiple labelers. In addition, the instructions serve to document the annotations. The subjects were three people with no p"
W97-0320,P93-1010,0,0.0201364,"om the corpus (translated into English): Preceding time: Thursday 19 August sl s2 1 2 3 4 5 sl 6 7 On Thursday I can only meet after two pm From two to four Or two thirty to four thirty Or three to five Then how does from two thirty to four thirty seem to you On Thursday Thursday the thirtieth of September An example of temporal reference resolution is that (2) refers to 2-4pm Thursday 19 August. Although related, this problem is distinct from tense and aspect interpretation in discourse (as addressed in, e.g., Webber 1988, Song & Cohen 1991, Hwang & Schubert 1992, Lascarides et al. 1992, and Kameyama et al. 1993). Because the dialogs are centrally concerned with negotiating an interval of time in which to hold a meeting, our representations are geared toward such intervals. Our basic representational unit is given in figure 1. To avoid confusion, we refer to this basic unit throughout as a Temporal Unit (TU). The time referred to in, for example, &quot;From 2 to 4, on Wednesday the 19th of August&quot; is represented as: ((August, 19th, Wednesday, 2, pm) (August, 19th, Wednesday, 4, pm)) Thus, the information from multiple noun phrases is often merged into a single representation of the underlying interval evok"
W97-0320,P92-1001,0,0.0167556,"udy Consider this passage from the corpus (translated into English): Preceding time: Thursday 19 August sl s2 1 2 3 4 5 sl 6 7 On Thursday I can only meet after two pm From two to four Or two thirty to four thirty Or three to five Then how does from two thirty to four thirty seem to you On Thursday Thursday the thirtieth of September An example of temporal reference resolution is that (2) refers to 2-4pm Thursday 19 August. Although related, this problem is distinct from tense and aspect interpretation in discourse (as addressed in, e.g., Webber 1988, Song & Cohen 1991, Hwang & Schubert 1992, Lascarides et al. 1992, and Kameyama et al. 1993). Because the dialogs are centrally concerned with negotiating an interval of time in which to hold a meeting, our representations are geared toward such intervals. Our basic representational unit is given in figure 1. To avoid confusion, we refer to this basic unit throughout as a Temporal Unit (TU). The time referred to in, for example, &quot;From 2 to 4, on Wednesday the 19th of August&quot; is represented as: ((August, 19th, Wednesday, 2, pm) (August, 19th, Wednesday, 4, pm)) Thus, the information from multiple noun phrases is often merged into a single representation of t"
W97-0320,1993.iwpt-1.12,0,0.029393,"ral reference resolution. After a brief overview, the rule-application architecture is described and then the rules composing the algorithm are given. As mentioned earlier, this is a high-level algorithm. Description of the complete algorithm, 178 Architecture Following (Qu et al. 1996) and (Shum et al. 1994), the representation of a single utterance is called an ILT (for InterLingual Text). An ILT, once it has been augmented by our system with temporal (and speech-act) information, is called an augmented ILT (an AILT). The input to our system, produced by a semantic parser (Shum et al. 1994; Lavie & Tomita 1993), consists of multiple alternative ILT representations of utterances. To produce one ILT, the parser maps the main event and its participants into one of a small set of case frames (for example, a meet frame or an is busy frame) and produces a surface representation of any temporal information, which is faithful to the input utterance. Although the events and states discussed in the NMSU data are often outside the coverage of this parser, the temporal information generally is not. Thus, the parser provides us with a sufficient input representation for our purposes on both sets of data. This pa"
W97-0320,1995.tmi-1.13,0,0.0598624,"Missing"
W97-0320,P95-1015,0,0.0326867,"null. And, of course, all fields are null for utterances that do not contain temporal information. In the case of an utterance that refers to multiple, distinct intervals, the representation is a list of Temporal Units. A Temporal Unit is also the representation used in the evaluation of the system. That is, the system&apos;s answers are mapped from its more complex internal representation (an I L T , see section 4.1) into this simpler vector representation before evaluation is performed. As in much recent empirical work in discourse processing (e.g., Arhenberg et al. 1995; Isard & Carletta 1995; Litman & Passonneau 1995; Moser & Moore 1995; Hirschberg & Nakatani 1996), we performed an intercoder reliability study investigating agreement in annotating the times. The goal in developing the annotation instructions is that they can be used reliably by non-experts after a reasonable amount of training (cf. Passonneau & Litman 1993, Condon & Cech 1995, and Hirschberg & Nakatani 1996), where reliability is measured in terms of the amount of agreement among annotators. High reliability indicates that the encoding scheme is reproducible given multiple labelers. In addition, the instructions serve to document the anno"
W97-0320,P95-1018,0,0.0308188,"fields are null for utterances that do not contain temporal information. In the case of an utterance that refers to multiple, distinct intervals, the representation is a list of Temporal Units. A Temporal Unit is also the representation used in the evaluation of the system. That is, the system&apos;s answers are mapped from its more complex internal representation (an I L T , see section 4.1) into this simpler vector representation before evaluation is performed. As in much recent empirical work in discourse processing (e.g., Arhenberg et al. 1995; Isard & Carletta 1995; Litman & Passonneau 1995; Moser & Moore 1995; Hirschberg & Nakatani 1996), we performed an intercoder reliability study investigating agreement in annotating the times. The goal in developing the annotation instructions is that they can be used reliably by non-experts after a reasonable amount of training (cf. Passonneau & Litman 1993, Condon & Cech 1995, and Hirschberg & Nakatani 1996), where reliability is measured in terms of the amount of agreement among annotators. High reliability indicates that the encoding scheme is reproducible given multiple labelers. In addition, the instructions serve to document the annotations. The subject"
W97-0320,J88-2004,0,0.0718035,"Missing"
W97-0320,P93-1020,0,0.018016,"he system&apos;s answers are mapped from its more complex internal representation (an I L T , see section 4.1) into this simpler vector representation before evaluation is performed. As in much recent empirical work in discourse processing (e.g., Arhenberg et al. 1995; Isard & Carletta 1995; Litman & Passonneau 1995; Moser & Moore 1995; Hirschberg & Nakatani 1996), we performed an intercoder reliability study investigating agreement in annotating the times. The goal in developing the annotation instructions is that they can be used reliably by non-experts after a reasonable amount of training (cf. Passonneau & Litman 1993, Condon & Cech 1995, and Hirschberg & Nakatani 1996), where reliability is measured in terms of the amount of agreement among annotators. High reliability indicates that the encoding scheme is reproducible given multiple labelers. In addition, the instructions serve to document the annotations. The subjects were three people with no previous involvement in the project. They were given the original Spanish and the English translations. How176 ever, as they have limited knowledge of Spanish, in essence they annotated the English translations. The subjects annotated two training dialogs accordin"
W97-0320,P95-1005,0,0.026077,"Missing"
W97-0320,J96-2005,0,0.0124701,"in applying the rules, errors in mistaking anaphoric references for deictic references (and vice versa), and errors in choosing the wrong anaphoric relation. As will be shown in the next section, very few errors can be attributed to the wrong entities being in focus due to not handling subdialogs or &quot;multiple threads&quot; (Ros6 et al. 1995). 6 Global Focus The algorithm is conspicuously lacking in any mechanism for recognizing the global structure of the discourse, such as in Grosz ~ Sidner (1986), Mann & Thompson (1988), Allen & Perranlt (1980), and their descendants. Recently in the literature, Walker (1996) has argued for a more linear-recency based model of Attentional State (though not that discourse structure need not be recognized), while Rosd et al. (1995) argue for a more complex model of Attentional State than is represented in most current computational theories of discourse. Many theories that address how Attentional State should be modeled have the goal of performing inten183 tion recognition as well. We investigate performing temporal reference resolution directly, without also attempting to recognize discourse structure or intentions. We assess the challenges the data present to our"
W97-0320,J88-2006,0,0.0535762,"challenges. 2 The Corpus and Intercoder Reliability Study Consider this passage from the corpus (translated into English): Preceding time: Thursday 19 August sl s2 1 2 3 4 5 sl 6 7 On Thursday I can only meet after two pm From two to four Or two thirty to four thirty Or three to five Then how does from two thirty to four thirty seem to you On Thursday Thursday the thirtieth of September An example of temporal reference resolution is that (2) refers to 2-4pm Thursday 19 August. Although related, this problem is distinct from tense and aspect interpretation in discourse (as addressed in, e.g., Webber 1988, Song & Cohen 1991, Hwang & Schubert 1992, Lascarides et al. 1992, and Kameyama et al. 1993). Because the dialogs are centrally concerned with negotiating an interval of time in which to hold a meeting, our representations are geared toward such intervals. Our basic representational unit is given in figure 1. To avoid confusion, we refer to this basic unit throughout as a Temporal Unit (TU). The time referred to in, for example, &quot;From 2 to 4, on Wednesday the 19th of August&quot; is represented as: ((August, 19th, Wednesday, 2, pm) (August, 19th, Wednesday, 4, pm)) Thus, the information from multi"
W98-1126,W96-0210,1,0.873789,"Missing"
W98-1126,P94-1020,1,0.768264,"there is also a value for the absence of any of them. (The verb feature is analogous.) Table 1: Mean Accuracy Across Algorithms CO SP The Machine Learning Algorithms The algorithms included in this study are representative of the major types suggested by Michie et al. (1994) of the StatLog project comparing machine learning algorithms. (1) PEBLS, a K-Nearest Neighbor algorithm (Cost and Salzberg 1993); (2) C4.5, a decision tree algorithm (Quinlan 1994); (3) Ripper, an inductive rule based classifier (Cohen 1996); (4) the Naive Bayes classifier; and (5), a probabilistic model search procedure (Bruce & Wiebe 1994) using the public domain software CoCo (Badsberg 1995). Linear discriminant classifiers are omitted because they are not appropriate for categorical data. Neural network classifiers are omitted as well. 6 ORb .719 .710 PCb .584 .737 PCe .607 .746 fications of Wiebe et al. (1997a) were made to facilitate the comparisons at issue here. First, nouns were originally included in the CO but not the SP collocational property. Here, they are not included in either. Second, a weakness in the method for selecting the collocation sets is changed so that, for each collocational property, the words in the"
W98-1126,C92-2082,0,0.0030096,"ment. The improvement we see when moving from the over-range to the per-class organizations of the SP collocations is largely due to inclusion of additional high quality collocations; the PC organizations allow them to be included without adding complexity. Various methods have been proposed for reducing the complex feature space associated with large numbers of low frequency properties. For example, one can ignore infrequent collocations entirely (e.g., Ng & Lee), consider only the single best property (e.g., Yarowsky 1993), or ignore negative evidence, i.e., the absence of a property (e.g., Hearst 1992). Another is to retain the high quality collocations, grouping them per-class. Cohen (1996) and Goldberg (1995) propose similar methods for text categorization tasks, although they do not address the comparative issues investigated here. 8 9 Acknowledgements This research was supported in part by the Office of Naval Research under grant number N00014-95-1-0776. We thank Julie Maples for her work developing the annotation instructions and manually annotating the data, and Lei Duan for his work implementing the original experiments. 10 References Badsberg, J. 1995. An Environment for Graphical M"
W98-1126,J93-3003,0,0.0195395,"& Lee 1996 and Bruce & Wiebe 1994); the actual collocations would be words that occur there. We need to untie the notion of collocation from wordsense disambiguation, and consider collocations to be words that co-occur (more than chance) with whatever classes are being targeted (such as the event categories presented above). Viewed in this way, collocations are also important for many event categorization and discourse processing tasks. Examples are openclass words that suggest dialog acts; words that help disambiguate cue words (e.g., is now being used temporally, or as a discourse marker? (Hirschberg & Litman 1993)); and words that suggest states versus events (Siegel 1997). The work reported here is relevant when there are m a n ) potential collocations to choose from, and we are automatically sifting through the various possibilities for good ones. For wordsense disambiguation, many different words cooccur in the corpus with the target word; we want to choose a subset that are good indicators of the sense of the target word. For dialog act recognition, we could search through the adjectives in the corpus, for example, for some that suggest a rejection dialog act (e.g., busy, occupied, committed, tied"
W98-1126,P96-1006,0,0.0433762,"represented by a vector (F1,...,Fn_l,C). The Fi&apos;s are input features and C is the targeted classification. Our task is to induce a classifier that will predict the value of C given an untagged sentence represented by the Fi&apos;s. This section addresses selecting collocations and representing them as such features. 4.1 Selecting Collocations Following are two methods for selecting collocation words of a given collocational property (Wiebe et al. 1997a). Assume there are c classes, C1 ... Cc, and s subproperties, $1 ... Ss. 4.1.1 P e r - C l a s s M e t h o d In the per-class method (also used by Ng and Lee 1996), a set of words, WordsCiSj, is selected for each combination of Class Ci and subproperty Sj. They are selected to be words that, when they satisfy a constraint in Sj, are correlated with class Ci. Specifically: WordsCiS) = {W[ P(Cilw satisfies a constraint in Sj) &gt; k}. We use k = 0.5. We experimented with some 228 other values of k and other criteria, but did not find any that consistently yield better results. A more thorough investigation is planned. 4.1.2 O v e r - R a n g e M e t h o d In the over-range method, a set of words, l¥ordsSj, is selected for each subproperty Sj, such that, when"
W98-1126,W97-0318,0,0.0216108,"ds that occur there. We need to untie the notion of collocation from wordsense disambiguation, and consider collocations to be words that co-occur (more than chance) with whatever classes are being targeted (such as the event categories presented above). Viewed in this way, collocations are also important for many event categorization and discourse processing tasks. Examples are openclass words that suggest dialog acts; words that help disambiguate cue words (e.g., is now being used temporally, or as a discourse marker? (Hirschberg & Litman 1993)); and words that suggest states versus events (Siegel 1997). The work reported here is relevant when there are m a n ) potential collocations to choose from, and we are automatically sifting through the various possibilities for good ones. For wordsense disambiguation, many different words cooccur in the corpus with the target word; we want to choose a subset that are good indicators of the sense of the target word. For dialog act recognition, we could search through the adjectives in the corpus, for example, for some that suggest a rejection dialog act (e.g., busy, occupied, committed, tied up, ...) in the scheduling domain (Wiebe et. al 1997b)). For"
W98-1126,W97-0320,1,0.202265,"n e t h J. M c K e e v e r t and R e b e c c a F . B r u c e $ D e p a r t m e n t of C o m p u t e r Science and the C o m p u t i n g Research L a b o r a t o r y New Mexico State University Las Cruces, NM 88003 e-mail: wiebe, kmckeeve@cs.nmsu.edu S D e p a r t m e n t of C o m p u t e r Science University of N o r t h Carolina at Asheville Asheville, NC 28804-3299 e-mail: bruce@cs.unca.edu Abstract This paper investigates interactions between collocational properties and methods for organizing them into features for machine learning. In experiments performing an event categorization task, Wiebe et al. (1997a) found that different organizations are best for different properties. This paper presents a statistical analysis of the results across different machine learning algorithms. In the experiments, the relationship between property and organization was strikingly consistent across algorithms. This prompted further analysis of this relationship, and an investigation of criteria for recognizing beneficial ways to include collocational properties in machine learning experiments. While many types of collocational properties and methods of organizing them into features have been used in NLP, systema"
W98-1126,H93-1052,0,0.0102813,"-class organizations to existing collocations will not result in significant improvement. The improvement we see when moving from the over-range to the per-class organizations of the SP collocations is largely due to inclusion of additional high quality collocations; the PC organizations allow them to be included without adding complexity. Various methods have been proposed for reducing the complex feature space associated with large numbers of low frequency properties. For example, one can ignore infrequent collocations entirely (e.g., Ng & Lee), consider only the single best property (e.g., Yarowsky 1993), or ignore negative evidence, i.e., the absence of a property (e.g., Hearst 1992). Another is to retain the high quality collocations, grouping them per-class. Cohen (1996) and Goldberg (1995) propose similar methods for text categorization tasks, although they do not address the comparative issues investigated here. 8 9 Acknowledgements This research was supported in part by the Office of Naval Research under grant number N00014-95-1-0776. We thank Julie Maples for her work developing the annotation instructions and manually annotating the data, and Lei Duan for his work implementing the ori"
W98-1126,J93-2004,0,0.027245,"Missing"
W98-1507,W97-0211,0,0.0307552,"Missing"
W98-1507,P95-1015,0,0.0723365,"Missing"
W98-1507,J93-2004,0,0.0231676,"Missing"
W98-1507,P95-1018,0,0.0636626,"Missing"
W98-1507,W97-0322,1,0.874704,"Missing"
W98-1507,W97-0320,1,0.883211,"Missing"
W98-1507,C92-2070,0,\N,Missing
W98-1507,P96-1038,0,\N,Missing
