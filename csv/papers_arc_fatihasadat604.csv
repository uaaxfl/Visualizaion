2021.jeptalnrecital-taln.29,Revitalisation des langues autochtones via le pr{\\'e}traitement et la traduction automatique neuronale: le cas de l{'}inuktitut (Revitalization and Preservation of Indigenous Languages through Natural Language Processing ),2021,-1,-1,2,0,5646,tan ngoc,Actes de la 28e Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 1 : conf{\\'e}rence principale,0,"Nous pr{\'e}sentons des r{\'e}sum{\'e}s en fran{\c{c}}ais et en anglais de l{'}article (Tan Le {\&} Sadat, 2020) pr{\'e}sent{\'e} {\`a} la 28{\`e}me conf{\'e}rence internationale sur les linguistiques computationnelles (the 28th International Conference on Computational Linguistics) en 2020."
2021.americasnlp-1.17,Towards a First Automatic Unsupervised Morphological Segmentation for {I}nuinnaqtun,2021,-1,-1,2,1,12335,ngoc le,Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas,0,"Low-resource polysynthetic languages pose many challenges in NLP tasks, such as morphological analysis and Machine Translation, due to available resources and tools, and the morphologically complex languages. This research focuses on the morphological segmentation while adapting an unsupervised approach based on Adaptor Grammars in low-resource setting. Experiments and evaluations on Inuinnaqtun, one of Inuit language family in Northern Canada, considered a language that will be extinct in less than two generations, have shown promising results."
2021.adaptnlp-1.14,On the Hidden Negative Transfer in Sequential Transfer Learning for Domain Adaptation from News to Tweets,2021,-1,-1,5,1,12382,sara meftah,Proceedings of the Second Workshop on Domain Adaptation for NLP,0,"Transfer Learning has been shown to be a powerful tool for Natural Language Processing (NLP) and has outperformed the standard supervised learning paradigm, as it takes benefit from the pre-learned knowledge. Nevertheless, when transfer is performed between less related domains, it brings a negative transfer, i.e. hurts the transfer performance. In this research, we shed light on the hidden negative transfer occurring when transferring from the News domain to the Tweets domain, through quantitative and qualitative analysis. Our experiments on three NLP taks: Part-Of-Speech tagging, Chunking and Named Entity recognition, reveal interesting insights."
2020.wildre-1.6,Multilingual Neural Machine Translation involving {I}ndian Languages,2020,-1,-1,2,0,14045,pulkit madaan,Proceedings of the WILDRE5{--} 5th Workshop on Indian Language Data: Resources and Evaluation,0,"Neural Machine Translations (NMT) models are capable of translating a single bilingual pair and require a new model for each new language pair. Multilingual Neural Machine Translation models are capable of translating multiple language pairs, even pairs which it hasn{'}t seen before in training. Availability of parallel sentences is a known problem in machine translation. Multilingual NMT model leverages information from all the languages to improve itself and performs better. We propose a data augmentation technique that further improves this model profoundly. The technique helps achieve a jump of more than 15 points in BLEU score from the multilingual NMT model. A BLEU score of 36.2 was achieved for Sindhi{--}English translation, which is higher than any score on the leaderboard of the LoResMT SharedTask at MT Summit 2019, which provided the data for the experiments."
2020.socialnlp-1.8,Multi-Task Supervised Pretraining for Neural Domain Adaptation,2020,-1,-1,6,1,12382,sara meftah,Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media,0,"Two prevalent transfer learning approaches are used in recent works to improve neural networks performance for domains with small amounts of annotated data: Multi-task learning which involves training the task of interest with related auxiliary tasks to exploit their underlying similarities, and Mono-task fine-tuning, where the weights of the model are initialized with the pretrained weights of a large-scale labeled source domain and then fine-tuned with labeled data of the target domain (domain of interest). In this paper, we propose a new approach which takes advantage from both approaches by learning a hierarchical model trained across multiple tasks from a source domain, and is then fine-tuned on multiple tasks of the target domain. Our experiments on four tasks applied to the social media domain show that our proposed approach leads to significant improvements on all tasks compared to both approaches."
2020.lincr-1.7,Towards a Multi-Dataset for Complex Emotions Learning Based on Deep Neural Networks,2020,-1,-1,2,0,18476,billal belainine,Proceedings of the Second Workshop on Linguistic and Neurocognitive Resources,0,"In sentiment analysis, several researchers have used emoji and hashtags as specific forms of training and supervision. Some emotions, such as fear and disgust, are underrepresented in the text of social media. Others, such as anticipation, are absent. This research paper proposes a new dataset for complex emotion detection using a combination of several existing corpora in order to represent and interpret complex emotions based on the Plutchik{'}s theory. Our experiments and evaluations confirm that using Transfer Learning (TL) with a rich emotional corpus, facilitates the detection of complex emotions in a four-dimensional space. In addition, the incorporation of the rule on the reverse emotions in the model{'}s architecture brings a significant improvement in terms of precision, recall, and F-score."
2020.coling-main.410,Revitalization of Indigenous Languages through Pre-processing and Neural Machine Translation: The case of {I}nuktitut,2020,-1,-1,2,1,21502,tan le,Proceedings of the 28th International Conference on Computational Linguistics,0,"Indigenous languages have been very challenging when dealing with NLP tasks and applications because of multiple reasons. These languages, in linguistic typology, are polysynthetic and highly inflected with rich morphophonemics and variable dialectal-dependent spellings; which affected studies on any NLP task in the recent years. Moreover, Indigenous languages have been considered as low-resource and/or endangered; which poses a great challenge for research related to Artificial Intelligence and its fields, such as NLP and machine learning. In this paper, we propose a study on the Inuktitut language through pre-processing and neural machine translation, in order to revitalize the language which belongs to the Inuit family, a type of polysynthetic languages spoken in Northern Canada. Our focus is concentrated on: (1) the preprocessing phase, and (2) applications on specific NLP tasks such as morphological analysis and neural machine translation, both for Indigenous languages of Canada. Our evaluations in the context of lowresource Inuktitut-English Neural Machine Translation, showed significant improvements of the proposed approach compared to the state-of-the-art."
2020.amta-research.15,Low-Resource {NMT}: an Empirical Study on the Effect of Rich Morphological Word Segmentation on {I}nuktitut,2020,-1,-1,2,1,21502,tan le,Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Track),0,None
W19-3644,Augmenting Named Entity Recognition with Commonsense Knowledge,2019,-1,-1,3,0,24411,gaith dekhili,Proceedings of the 2019 Workshop on Widening NLP,0,"Commonsense can be vital in some applications like Natural Language Understanding (NLU), where it is often required to resolve ambiguity arising from implicit knowledge and underspecification. In spite of the remarkable success of neural network approaches on a variety of Natural Language Processing tasks, many of them struggle to react effectively in cases that require commonsense knowledge. In the present research, we take advantage of the availability of the open multilingual knowledge graph ConceptNet, by using it as an additional external resource in Named Entity Recognition (NER). Our proposed architecture involves BiLSTM layers combined with a CRF layer that was augmented with some features such as pre-trained word embedding layers and dropout layers. Moreover, apart from using word representations, we used also character-based representation to capture the morphological and the orthographic information. Our experiments and evaluations showed an improvement in the overall performance with +2.86 in the F1-measure. Commonsense reasonnig has been employed in other studies and NLP tasks but to the best of our knowledge, there is no study relating the integration of a commonsense knowledge base in NER."
N19-1416,Joint Learning of Pre-Trained and Random Units for Domain Adaptation in Part-of-Speech Tagging,2019,17,0,5,1,12382,sara meftah,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Fine-tuning neural networks is widely used to transfer valuable knowledge from high-resource to low-resource domains. In a standard fine-tuning scheme, source and target problems are trained using the same architecture. Although capable of adapting to new domains, pre-trained units struggle with learning uncommon target-specific patterns. In this paper, we propose to augment the target-network with normalised, weighted and randomly initialised units that beget a better adaptation while maintaining the valuable source knowledge. Our experiments on POS tagging of social media texts (Tweets domain) demonstrate that our method achieves state-of-the-art performances on 3 commonly used datasets."
2019.jeptalnrecital-court.15,Exploration de l{'}apprentissage par transfert pour l{'}analyse de textes des r{\\'e}seaux sociaux (Exploring neural transfer learning for social media text analysis ),2019,-1,-1,5,1,12382,sara meftah,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume II : Articles courts,0,"L{'}apprentissage par transfert repr{\'e}sente la capacit{\'e} qu{'}un mod{\`e}le neuronal entra{\^\i}n{\'e} sur une t{\^a}che {\`a} g{\'e}n{\'e}raliser suffisamment et correctement pour produire des r{\'e}sultats pertinents sur une autre t{\^a}che proche mais diff{\'e}rente. Nous pr{\'e}sentons dans cet article une approche fond{\'e}e sur l{'}apprentissage par transfert pour construire automatiquement des outils d{'}analyse de textes des r{\'e}seaux sociaux en exploitant les similarit{\'e}s entre les textes d{'}une langue bien dot{\'e}e (forme standard d{'}une langue) et les textes d{'}une langue peu dot{\'e}e (langue utilis{\'e}e en r{\'e}seaux sociaux). Nous avons exp{\'e}riment{\'e} notre approche sur plusieurs langues ainsi que sur trois t{\^a}ches d{'}annotation linguistique ({\'e}tiquetage morpho-syntaxique, annotation en parties du discours et reconnaissance d{'}entit{\'e}s nomm{\'e}es). Les r{\'e}sultats obtenus sont tr{\`e}s satisfaisants et montrent l{'}int{\'e}r{\^e}t de l{'}apprentissage par transfert pour tirer profit des mod{\`e}les neuronaux profonds sans la contrainte d{'}avoir {\`a} disposition une quantit{\'e} de donn{\'e}es importante n{\'e}cessaire pour avoir une performance acceptable."
Y18-1038,Improving the neural network-based machine transliteration for low-resourced language pair,2018,0,0,2,1,12335,ngoc le,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation",0,None
W18-3927,Using Neural Transfer Learning for Morpho-syntactic Tagging of {S}outh-{S}lavic Languages Tweets,2018,0,0,3,1,12382,sara meftah,"Proceedings of the Fifth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial 2018)",0,"In this paper, we describe a morpho-syntactic tagger of tweets, an important component of the CEA List DeepLIMA tool which is a multilingual text analysis platform based on deep learning. This tagger is built for the Morpho-syntactic Tagging of Tweets (MTT) Shared task of the 2018 VarDial Evaluation Campaign. The MTT task focuses on morpho-syntactic annotation of non-canonical Twitter varieties of three South-Slavic languages: Slovene, Croatian and Serbian. We propose to use a neural network model trained in an end-to-end manner for the three languages without any need for task or domain specific features engineering. The proposed approach combines both character and word level representations. Considering the lack of annotated data in the social media domain for South-Slavic languages, we have also implemented a cross-domain Transfer Learning (TL) approach to exploit any available related out-of-domain annotated data."
W18-2414,Low-Resource Machine Transliteration Using Recurrent Neural Networks of {A}sian Languages,2018,0,2,2,1,12335,ngoc le,Proceedings of the Seventh Named Entities Workshop,0,"Grapheme-to-phoneme models are key components in automatic speech recognition and text-to-speech systems. With low-resource language pairs that do not have available and well-developed pronunciation lexicons, grapheme-to-phoneme models are particularly useful. These models are based on initial alignments between grapheme source and phoneme target sequences. Inspired by sequence-to-sequence recurrent neural network-based translation methods, the current research presents an approach that applies an alignment representation for input sequences and pre-trained source and target embeddings to overcome the transliteration problem for a low-resource languages pair. We participated in the NEWS 2018 shared task for the English-Vietnamese transliteration task."
L18-1698,Retrieving Information from the {F}rench Lexical Network in {RDF}/{OWL} Format,2018,0,1,2,1,30300,alexsandro fonseca,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
2017.jeptalnrecital-demo.13,Translitt{\\'e}ration automatique pour une paire de langues peu dot{\\'e}e (),2017,-1,-1,2,1,12335,ngoc le,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 3 - D{\\'e}monstrations,0,"La translitt{\'e}ration convertit phon{\'e}tiquement les mots dans une langue source (i.e. fran{\c{c}}ais) en mots {\'e}quivalents dans une langue cible (i.e. vietnamien). Cette conversion n{\'e}cessite un nombre consid{\'e}rable de r{\`e}gles d{\'e}finies par les experts linguistes pour d{\'e}terminer comment les phon{\`e}mes sont align{\'e}s ainsi que prendre en compte le syst{\`e}me de phonologie de la langue cible. La probl{\'e}matique pour les paires de langues peu dot{\'e}es lie {\`a} la p{\'e}nurie des ressources linguistiques. Dans ce travail de recherche, nous pr{\'e}sentons une d{\'e}monstration de conversion de graph{\`e}me en phon{\`e}me pour pallier au probl{\`e}me de translitt{\'e}ration pour une paire de langues peu dot{\'e}e, avec une application sur fran{\c{c}}ais-vietnamien. Notre syst{\`e}me n{\'e}cessite un petit corpus d{'}apprentissage phon{\'e}tique bilingue. Nous avons obtenu des r{\'e}sultats prometteurs, avec un gain de +4,40{\%} de score BLEU, par rapport au syst{\`e}me de base utilisant l{'}approche de traduction automatique statistique."
W16-5320,{L}exfom: a lexical functions ontology model,2016,0,3,2,1,30300,alexsandro fonseca,Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex - V),0,"A lexical function represents a type of relation that exists between lexical units (words or expressions) in any language. For example, the antonymy is a type of relation that is represented by the lexical function Anti: Anti(big) = small. Those relations include both paradigmatic relations, i.e. vertical relations, such as synonymy, antonymy and meronymy and syntagmatic relations, i.e. horizontal relations, such as objective qualification (legitimate demand), subjective qualification (fruitful analysis), positive evaluation (good review) and support verbs (pay a visit, subject to an interrogation). In this paper, we present the Lexical Functions Ontology Model (lexfom) to represent lexical functions and the relation among lexical units. Lexfom is divided in four modules: lexical function representation (lfrep), lexical function family (lffam), lexical function semantic perspective (lfsem) and lexical function relations (lfrel). Moreover, we show how it combines to Lexical Model for Ontologies (lemon), for the transformation of lexical networks into the semantic web formats. So far, we have implemented 100 simple and 500 complex lexical functions, and encoded about 8,000 syntagmatic and 46,000 paradigmatic relations, for the French language."
W16-3915,Named Entity Recognition and Hashtag Decomposition to Improve the Classification of Tweets,2016,0,7,3,0,18476,billal belainine,Proceedings of the 2nd Workshop on Noisy User-generated Text ({WNUT}),0,"In social networks services like Twitter, users are overwhelmed with huge amount of social data, most of which are short, unstructured and highly noisy. Identifying accurate information from this huge amount of data is indeed a hard task. Classification of tweets into organized form will help the user to easily access these required information. Our first contribution relates to filtering parts of speech and preprocessing this kind of highly noisy and short data. Our second contribution concerns the named entity recognition (NER) in tweets. Thus, the adaptation of existing language tools for natural languages, noisy and not accurate language tweets, is necessary. Our third contribution involves segmentation of hashtags and a semantic enrichment using a combination of relations from WordNet, which helps the performance of our classification system, including disambiguation of named entities, abbreviations and acronyms. Graph theory is used to cluster the words extracted from WordNet and tweets, based on the idea of connected components. We test our automatic classification system with four categories: politics, economy, sports and the medical field. We evaluate and compare several automatic classification systems using part or all of the items described in our contributions and found that filtering by part of speech and named entity recognition dramatically increase the classification precision to 77.3 {\%}. Moreover, a classification system incorporating segmentation of hashtags and semantic enrichment by two relations from WordNet, synonymy and hyperonymy, increase classification precision up to 83.4 {\%}."
W16-3926,{UQAM}-{NTL}: Named entity recognition in {T}witter messages,2016,7,3,3,1,12335,ngoc le,Proceedings of the 2nd Workshop on Noisy User-generated Text ({WNUT}),0,"This paper describes our system used in the 2nd Workshop on Noisy User-generated Text (WNUT) shared task for Named Entity Recognition (NER) in Twitter, in conjunction with Coling 2016. Our system is based on supervised machine learning by applying Conditional Random Fields (CRF) to train two classifiers for two evaluations. The first evaluation aims at predicting the 10 fine-grained types of named entities; while the second evaluation aims at predicting no type of named entities. The experimental results show that our method has significantly improved Twitter NER performance."
W15-4943,Multi-Dialect Machine Translation ({M}u{DM}at),2015,0,1,1,1,5647,fatiha sadat,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,None
2015.jeptalnrecital-demonstration.6,Building a Bilingual {V}ietnamese-{F}rench Named Entity Annotated Corpus through Cross-Linguistic Projection,2015,-1,-1,2,1,12335,ngoc le,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,"The creation of high-quality named entity annotated resources is time-consuming and an expensive process. Most of the gold standard corpora are available for English but not for less-resourced languages such as Vietnamese. In Asian languages, this task is remained problematic. This paper focuses on an automatic construction of named entity annotated corpora for Vietnamese-French, a less-resourced pair of languages. We incrementally apply different cross-projection methods using parallel corpora, such as perfect string matching and edit distance similarity. Evaluations on Vietnamese {--}French pair of languages show a good accuracy (F-score of 94.90{\%}) when identifying named entities pairs and building a named entity annotated parallel corpus."
2015.eamt-1.44,Multi-Dialect Machine Translation ({M}u{DM}at),2015,0,1,1,1,5647,fatiha sadat,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,None
W14-5904,Automatic Identification of {A}rabic Language Varieties and Dialects in Social Media,2014,18,30,1,1,5647,fatiha sadat,Proceedings of the Second Workshop on Natural Language Processing for Social Media ({S}ocial{NLP}),0,"Modern Standard Arabic (MSA) is the formal language in most Arabic countries. Arabic Dialects (AD) or daily language differs from MSA especially in social media communication. However, most Arabic social media texts have mixed forms and many variations especially between MSA and AD. This paper aims to bridge the gap between MSA and AD by providing a framework for AD classification using probabilistic models across social media datasets. We present a set of experiments using the character n-gram Markov language model and Naive Bayes classifiers with detailed examination of what models perform best under different conditions in social media context. Experimental results show that Naive Bayes classifier based on character bi-gram model can identify the 18 different Arabic dialects with a considerable overall accuracy of 98%."
W14-5813,Collaboratively Constructed Linguistic Resources for Language Variants and their Exploitation in {NLP} Application {--} the case of {T}unisian {A}rabic and the Social Media,2014,19,11,1,1,5647,fatiha sadat,Proceedings of Workshop on Lexical and Grammatical Resources for Language Processing,0,"Modern Standard Arabic (MSA) is the formal language in most Arabic countries. Arabic Dialects (AD) or daily language differs from MSA especially in social media communication. However, most Arabic social media texts have mixed forms and many variations especially between MSA and AD. This paper aims to bridge the gap between MSA and AD by providing a framework for the translation of texts of social media. More precisely, this paper focuses on the Tunisian Dialect of Arabic (TAD) with an application on automatic machine translation for a social media text into MSA and any other target language. Linguistic tools such as a bilingual TAD-MSA lexicon and a set of grammatical mapping rules are collaboratively constructed and exploited in addition to a language model to produce MSA sentences of Tunisian dialectal sentences. This work is a first-step towards collaboratively constructed semantic and lexical resources for Arabic Social Media within the ASMAT (Arabic Social Media Analysis Tools) project."
W14-5706,A Comparative Study of Different Classification Methods for the Identification of {B}razilian {P}ortuguese Multiword Expressions,2014,19,0,2,1,30300,alexsandro fonseca,Proceedings of the First Workshop on Computational Approaches to Compound Analysis ({C}om{AC}om{A} 2014),0,"This paper presents a comparative study of different methods for the identification of multiword expressions, applied to a Brazilian Portuguese corpus. First, we selected the candidates based on the frequency of bigrams. Second, we used the linguistic information based on the grammatical classes of the words forming the bigrams, together with the frequency information in order to compare the performance of different classification algorithms. The focus of this study is related to different classification techniques such as support-vector machines (SVM), multi-layer perceptron, naive Bayesian nets, decision trees and random forest. Third, we evaluated three different multi-layer perceptron training functions in the task of classifying different patterns of multiword expressions. Finally, our study compared two different tools, MWEtoolkit and Text-NSP, for the extraction of multiword expression candidates using different association measures."
W14-4813,Identifying {P}ortuguese Multiword Expressions using Different Classification Algorithms - A Comparative Analysis,2014,19,0,2,1,30300,alexsandro fonseca,Proceedings of the 4th International Workshop on Computational Terminology (Computerm),0,"This paper presents a comparative analysis based on different classification algorithms and tools for the identification of Portuguese multiword expressions. Our focus is on two-word expressions formed by nouns, adjectives and verbs. The candidates are selected on the basis of the frequency of the bigrams; then on the basis of the grammatical class of each bigramxe2x80x99s constituent words. This analysis compares the performance of three different multi-layer perceptron training functions in the task of extracting different patterns of multiword expressions, using and comparing nine different classification algorithms, including decision trees, multilayer perceptron and SVM. Moreover, this analysis compares two different tools, Text-NSP and Termostat for the identification of multiword expressions using different association measures."
R13-1076,Towards a Hybrid Rule-based and Statistical {A}rabic-{F}rench Machine Translation System,2013,12,2,1,1,5647,fatiha sadat,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"Arabic is a morphologically rich and complex language, which presents significant challenges for natural language processing and machine translation. In this paper, we describe an ongoing effort to build our first Arabic-French phrasexe2x80x90 based machine translation system using the Moses decoder among other linguistic tools. The results show an improvement in the quality of translation and a gain in terms of Bleu score after introducing a pre-processing scheme for Arabic and applying some rules based on morphological variations of the source language. The proposed approach is completed without increasing the amount of training data or changing radically the algorithms that can affect the translation or training engines."
F13-2015,Pre-processing and Language Analysis for {A}rabic to {F}rench Statistical Machine Translation (Traduction automatique statistique pour l{'}arabe-fran{\\c{c}}ais am{\\'e}lior{\\'e}e par le pr{\\'e}traitement et l{'}analyse de la langue) [in {F}rench],2013,-1,-1,1,1,5647,fatiha sadat,Proceedings of TALN 2013 (Volume 2: Short Papers),0,None
2013.mtsummit-wpt.5,Exploiting multiple resources for {J}apanese to {E}nglish patent translation,2013,-1,-1,2,1,38216,rahma sellami,Proceedings of the 5th Workshop on Patent Translation,0,None
W12-1310,Extraction de lexiques bilingues {\\`a} partir de Wikip{\\'e}dia (Bilingual lexicon extraction from {W}ikipedia) [in {F}rench],2012,0,0,2,1,38216,rahma sellami,"{JEP}-{TALN}-{RECITAL} 2012, Workshop {TALA}f 2012: Traitement Automatique des Langues Africaines ({TALA}f 2012: {A}frican Language Processing)",0,None
2012.amta-caas14.10,Exploiting {W}ikipedia as a Knowledge Base for the Extraction of Linguistic Resources: Application on {A}rabic-{F}rench Comparable Corpora and Bilingual Lexicons,2012,-1,-1,2,1,38216,rahma sellami,Fourth Workshop on Computational Approaches to Arabic-Script-based Languages,0,We present simple and effective methods for extracting comparable corpora and bilingual lexicons from Wikipedia. We shall exploit the large scale and the structure of Wikipedia articles to extract two resources that will be very useful for natural language applications. We build a comparable corpus from Wikipedia using categories as topic restrictions and we extract bilingual lexicons from inter-language links aligned with statistical method or a combined statistical and linguistic method.
Y10-1060,Exploiting a Multilingual Web-based Encyclopedia for Bilingual Terminology Extraction,2010,18,1,1,1,5647,fatiha sadat,"Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation",0,"Multilingual linguistic resources are usually constructed from parallel corpora, but since these corpora are available only for selected text domains and language pairs, the potential of other resources is being explored as well. This article seeks to explore and to exploit the idea of using multilingual web-based encyclopedias such as Wikipedia as comparable corpora for bilingual terminology extraction. We propose an approach to extract terms and their translations from different types of Wikipedia link information and data. The next step will be using a linguistic-based infouflation to re-rank and filter the extracted term candidates in the target language. Preliminary evaluations using the combined statistics-based and linguistic-based approaches were applied on different pairs of languages including Japanese, French and English. These evaluations showed a real open improvement and a good quality of the extracted term candidates for building or enriching multilingual ontology, dictionaries or feeding a cross-language information retrieval system with the related expansion terms of the source query."
2010.jeptalnrecital-demonstration.6,Exploitation de Wikip{\\'e}dia pour l{'}Enrichissement et la Construction des Ressources Linguistiques,2010,-1,-1,1,1,5647,fatiha sadat,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,"Cet article pr{\'e}sente une approche et des r{\'e}sultats utilisant l{'}encyclop{\'e}die en ligne Wikip{\'e}dia comme ressource semi-structur{\'e}e de connaissances linguistiques et en particulier comme un corpus comparable pour l{'}extraction de terminologie bilingue. Cette approche tend {\`a} extraire d{'}abord des paires de terme et traduction {\`a} partir de types des informations, liens et textes de Wikip{\'e}dia. L{'}{\'e}tape suivante consiste {\`a} l{'}utilisation de l{'}information linguistique afin de r{\'e}-ordonner les termes et leurs traductions pertinentes et ainsi {\'e}liminer les termes cibles inutiles. Les {\'e}valuations pr{\'e}liminaires utilisant les paires de langues fran{\c{c}}ais-anglais, japonais-fran{\c{c}}ais et japonais-anglais ont montr{\'e} une bonne qualit{\'e} des paires de termes extraits. Cette {\'e}tude est tr{\`e}s favorable pour la construction et l{'}enrichissement des ressources linguistiques tels que les dictionnaires et ontologies multilingues. Aussi, elle est tr{\`e}s utile pour un syst{\`e}me de recherche d{'}information translinguistique (RIT)."
W06-3118,{PORTAGE}: with Smoothed Phrase Tables and Segment Choice Models,2006,7,10,2,0,43880,howard johnson,Proceedings on the Workshop on Statistical Machine Translation,0,Improvements to Portage and its participation in the shared task of NAACL 2006 Workshop on Statistical Machine Translation are described. Promising ideas in phrase table smoothing and global distortion using feature-rich models are discussed as well as numerous improvements in the software base.
P06-1001,Combination of {A}rabic Preprocessing Schemes for Statistical Machine Translation,2006,21,63,1,1,5647,fatiha sadat,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Statistical machine translation is quite robust when it comes to the choice of input representation. It only requires consistency between training and testing. As a result, there is a wide range of possible preprocessing choices for data used in statistical machine translation. This is even more so for morphologically rich languages such as Arabic. In this paper, we study the effect of different word-level preprocessing schemes for Arabic on the quality of phrase-based statistical machine translation. We also present and evaluate different methods for combining preprocessing schemes resulting in improved translation quality."
N06-2013,{A}rabic Preprocessing Schemes for Statistical Machine Translation,2006,12,195,2,0,517,nizar habash,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Short Papers",0,"In this paper, we study the effect of different word-level preprocessing decisions for Arabic on SMT quality. Our results show that given large amounts of training data, splitting off only proclitics performs best. However, for small amounts of training data, it is best to apply English-like to-kenization using part-of-speech tags, and sophisticated morphological analysis and disambiguation. Moreover, choosing the appropriate preprocessing produces a significant increase in BLEU score if there is a change in genre between training and test data."
2006.jeptalnrecital-poster.23,Syst{\\`e}me de traduction automatique statistique combinant diff{\\'e}rentes ressources,2006,-1,-1,1,1,5647,fatiha sadat,Actes de la 13{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Cet article d{\'e}crit une approche combinant diff{\'e}rents mod{\`e}les statistiques pour la traduction automatique bas{\'e}e sur les segments. Pour ce faire, diff{\'e}rentes ressources sont utilis{\'e}es, dont deux corpus parall{\`e}les aux caract{\'e}ristiques diff{\'e}rentes et un dictionnaire de terminologie bilingue et ce, afin d{'}am{\'e}liorer la performance quantitative et qualitative du syst{\`e}me de traduction. Nous {\'e}valuons notre approche sur la paire de langues fran{\c{c}}ais-anglais et montrons comment la combinaison des ressources propos{\'e}es am{\'e}liore de fa{\c{c}}on significative les r{\'e}sultats."
2006.bcs-1.7,Automatic Transliteration of Proper Nouns from {A}rabic to {E}nglish,2006,-1,-1,3,0,49040,mehdi kashani,Proceedings of the International Conference on the Challenge of Arabic for NLP/MT,0,"After providing a brief introduction to the transliteration problem, and highlighting some issues specific to Arabic to English translation, a three phase algorithm is introduced as a computational solution to the problem. The algorithm is based on a Hidden Markov Model approach, but also leverages information available in on-line databases. The algorithm is then evaluated, and shown to achieve accuracy approaching .80{\%}"
W05-0822,{PORTAGE}: A Phrase-Based Machine Translation System,2005,7,31,1,1,5647,fatiha sadat,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"This paper describes the participation of the Portage team at NRC Canada in the shared task of ACL 2005 Workshop on Building and Using Parallel Texts. We discuss Portage, a statistical phrase-based machine translation system, and present experimental results on the four language pairs of the shared task. First, we focus on the French-English task using multiple resources and techniques. Then we describe our contribution on the Finnish-English, Spanish-English and German-English language pairs using the provided data for the shared task."
W03-1108,Learning Bilingual Translations from Comparable Corpora to Cross-Language Information Retrieval: Hybrid Statistics-based and Linguistics-based Approach,2003,21,31,1,1,5647,fatiha sadat,Proceedings of the Sixth International Workshop on Information Retrieval with {A}sian Languages,0,"Recent years saw an increased interest in the use and the construction of large corpora. With this increased interest and awareness has come an expansion in the application to knowledge acquisition and bilingual terminology extraction. The present paper will seek to present an approach to bilingual lexicon extraction from non-aligned comparable corpora, combination to linguistics-based pruning and evaluations on Cross-Language Information Retrieval. We propose and explore a two-stages translation model for the acquisition of bilingual terminology from comparable corpora, disambiguation and selection of best translation alternatives on the basis of their morphological knowledge. Evaluations using a large-scale test collection on Japanese-English and different weighting schemes of SMART retrieval system confirmed the effectiveness of the proposed combination of two-stages comparable corpora and linguistics-based pruning on Cross-Language Information Retrieval."
P03-2025,Bilingual Terminology Acquisition from Comparable Corpora and Phrasal Translation to Cross-Language Information Retrieval,2003,9,22,1,1,5647,fatiha sadat,The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics,0,"The present paper will seek to present an approach to bilingual lexicon extraction from non-aligned comparable corpora, phrasal translation as well as evaluations on Cross-Language Information Retrieval. A two-stages translation model is proposed for the acquisition of bilingual terminology from comparable corpora, disambiguation and selection of best translation alternatives according to their linguistics-based knowledge. Different rescoring techniques are proposed and evaluated in order to select best phrasal translation alternatives. Results demonstrate that the proposed translation model yields better translations and retrieval effectiveness could be achieved across Japanese-English language pair."
C02-1166,An Approach Based on Multilingual Thesauri and Model Combination for Bilingual Lexicon Extraction,2002,9,84,3,0,18523,herve dejean,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper focuses on exploiting different models and methods in bilingual lexicon extraction, either from parallel or comparable corpora, in specialized domains. First, a special attention is given to the use of multilingual thesauri, and different search strategies based on such thesauri are investigated. Then, a method to combine the different models for bilingual lexicon extraction is presented. Our results show that the combination of the models significantly improves results, and that the use of the hierarchical information contained in our thesaurus, UMLS/MeSH, is of primary importance. Lastly, methods for bilingual terminology extraction and thesaurus enrichment are discussed."
