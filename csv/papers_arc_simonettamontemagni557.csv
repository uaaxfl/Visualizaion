2020.lrec-1.114,{``}Voices of the Great War{''}: A Richly Annotated Corpus of {I}talian Texts on the First World War,2020,-1,-1,12,0,16843,federico boschetti,Proceedings of the 12th Language Resources and Evaluation Conference,0,"{``}Voices of the Great War{''} is the first large corpus of Italian historical texts dating back to the period of First World War. This corpus differs from other existing resources in several respects. First, from the linguistic point of view it gives account of the wide range of varieties in which Italian was articulated in that period, namely from a diastratic (educated vs. uneducated writers), diaphasic (low/informal vs. high/formal registers) and diatopic (regional varieties, dialects) points of view. From the historical perspective, through a collection of texts belonging to different genres it represents different views on the war and the various styles of narrating war events and experiences. The final corpus is balanced along various dimensions, corresponding to the textual genre, the language variety used, the author type and the typology of conveyed contents. The corpus is fully annotated with lemmas, part-of-speech, terminology, and named entities. Significant corpus samples representative of the different {``}voices{''} have also been enriched with meta-linguistic and syntactic information. The layer of syntactic annotation forms the first nucleus of an Italian historical treebank complying with the Universal Dependencies standard. The paper illustrates the final resource, the methodology and tools used to build it, and the Web Interface for navigating it."
2020.lrec-1.883,Profiling-{UD}: a Tool for Linguistic Profiling of Texts,2020,-1,-1,5,0.571429,11248,dominique brunato,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this paper, we introduce Profiling{--}UD, a new text analysis tool inspired to the principles of linguistic profiling that can support language variation research from different perspectives. It allows the extraction of more than 130 features, spanning across different levels of linguistic description. Beyond the large number of features that can be monitored, a main novelty of Profiling{--}UD is that it has been specifically devised to be multilingual since it is based on the Universal Dependencies framework. In the second part of the paper, we demonstrate the effectiveness of these features in a number of theoretical and applicative studies in which they were successfully used for text and author profiling."
W18-6001,Assessing the Impact of Incremental Error Detection and Correction. A Case Study on the {I}talian {U}niversal {D}ependency Treebank,2018,0,0,3,1,24180,chiara alzetta,Proceedings of the Second Workshop on Universal Dependencies ({UDW} 2018),0,"Detection and correction of errors and inconsistencies in {``}gold treebanks{''} are becoming more and more central topics of corpus annotation. The paper illustrates a new incremental method for enhancing treebanks, with particular emphasis on the extension of error patterns across different textual genres and registers. Impact and role of corrections have been assessed in a dependency parsing experiment carried out with four different parsers, whose results are promising. For both evaluation datasets, the performance of parsers increases, in terms of the standard LAS and UAS measures and of a more focused measure taking into account only relations involved in error patterns, and at the level of individual dependencies."
W18-6012,Enhancing {U}niversal {D}ependency Treebanks: A Case Study,2018,0,4,5,0,10682,joakim nivre,Proceedings of the Second Workshop on Universal Dependencies ({UDW} 2018),0,"We evaluate two cross-lingual techniques for adding enhanced dependencies to existing treebanks in Universal Dependencies. We apply a rule-based system developed for English and a data-driven system trained on Finnish to Swedish and Italian. We find that both systems are accurate enough to bootstrap enhanced dependencies in existing UD treebanks. In the case of Italian, results are even on par with those of a prototype language-specific system."
L18-1719,{U}niversal {D}ependencies and Quantitative Typological Trends. A Case Study on Word Order,2018,0,0,3,1,24180,chiara alzetta,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-7624,Dangerous Relations in Dependency Treebanks,2017,0,0,3,1,24180,chiara alzetta,Proceedings of the 16th International Workshop on Treebanks and Linguistic Theories,0,None
L16-1014,{CI}t{A}: an {L}1 {I}talian Learners Corpus to Study the Development of Writing Competence,2016,0,1,4,0,34747,alessia barbagli,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, we present the CItA corpus (Corpus Italiano di Apprendenti L1), a collection of essays written by Italian L1 learners collected during the first and second year of lower secondary school. The corpus was built in the framework of an interdisciplinary study jointly carried out by computational linguistics and experimental pedagogists and aimed at tracking the development of written language competence over the years and students{'} background information."
L16-1520,{ALT} Explored: Integrating an Online Dialectometric Tool and an Online Dialect Atlas,2016,6,0,4,0.833333,8503,martijn wieling,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, we illustrate the integration of an online dialectometric tool, Gabmap, together with an online dialect atlas, the Atlante Lessicale Toscano (ALT-Web). By using a newly created url-based interface to Gabmap, ALT-Web is able to take advantage of the sophisticated dialect visualization and exploration options incorporated in Gabmap. For example, distribution maps showing the distribution in the Tuscan dialect area of a specific dialectal form (selected via the ALT-Web website) are easily obtainable. Furthermore, the complete ALT-Web dataset as well as subsets of the data (selected via the ALT-Web website) can be automatically uploaded and explored in Gabmap. By combining these two online applications, macro- and micro-analyses of dialectal data (respectively offered by Gabmap and ALT-Web) are effectively and dynamically combined."
W15-2618,{NLP}{--}Based Readability Assessment of Health{--}Related Texts: a Case Study on {I}talian Informed Consent Forms,2015,31,2,4,1,11249,giulia venturi,Proceedings of the Sixth International Workshop on Health Text Mining and Information Analysis,0,"The paper illustrates the results of a case study aimed at investigating and enhancing the accessibility of Italian healthxe2x80x93 related documents by relying on advanced NLP techniques, with particular attention to informed consent forms. Results achieved show that the features automatically extracted from the linguistically annotated text and ranging across different levels of linguistic description have a high discriminative power in order to guarantee a reliable readability assessment."
W15-1604,Design and Annotation of the First {I}talian Corpus for Text Simplification,2015,31,3,4,0.571429,11248,dominique brunato,Proceedings of The 9th Linguistic Annotation Workshop,0,"In this paper, we present design and construction of the first Italian corpus for automatic and semixe2x80x90automatic text simplification. In line with current approaches, we propose a new annotation scheme specifically conceived to identify the typology of changes an original sentence undergoes when it is manually simplified. Such a scheme has been applied to two aligned Italian corpora, containing original texts with corresponding simplified versions, selected as representative of two different manual simplification strategies and addressing different target reader populations. Each corpus was annotated with the operations foreseen in the annotation scheme, covering different levels of linguistic description. Annotation results were analysed with the final aim of capturing peculiarities and differences of the different simplification strategies pursued in the two corpora."
W14-1820,Assessing the Readability of Sentences: Which Corpora and Features?,2014,37,10,5,1,6236,felice dellorletta,Proceedings of the Ninth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"The paper investigates the problem of sentence readability assessment, which is modelled as a classification task, with a specific view to text simplification. In particular, it addresses two open issues connected with it, i.e. the corpora to be used for training, and the identification of the most effective features to determine sentence readability. An existing readability assessment tool developed for Italian was specialized at the level of training corpus and learning algorithm. A maximum entropyxe2x80x93based feature selection and ranking algorithm (grafting) was used to identify to the most relevant features: it turned out that assessing the readability of sentences is a complex task, requiring a high number of features, mainly syntactic ones."
dellorletta-etal-2014-t2k,{T}2{K}{\\textasciicircum}2: a System for Automatically Extracting and Organizing Knowledge from Texts,2014,21,14,4,1,6236,felice dellorletta,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we present T2K{\textasciicircum}2, a suite of tools for automatically extracting domainâspecific knowledge from collections of Italian and English texts. T2K{\textasciicircum}2 (TextâToâKnowledge v2) relies on a battery of tools for Natural Language Processing (NLP), statistical text analysis and machine learning which are dynamically integrated to provide an accurate and incremental representation of the content of vast repositories of unstructured documents. Extracted knowledge ranges from domainâspecific entities and named entities to the relations connecting them and can be used for indexing document collections with respect to different information types. T2K{\textasciicircum}2 also includes Âlinguistic profilingÂ functionalities aimed at supporting the user in constructing the acquisition corpus, e.g. in selecting texts belonging to the same genre or characterized by the same degree of specialization or in monitoring the Âadded valueÂ of newly inserted documents. T2K{\textasciicircum}2 is a web application which can be accessed from any browser through a personal account which has been tested in a wide range of domains."
simi-etal-2014-less,Less is More? Towards a Reduced Inventory of Categories for Training a Parser for the {I}talian {S}tanford Dependencies,2014,14,9,3,0,5835,maria simi,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Stanford Dependencies (SD) represent nowadays a de facto standard as far as dependency annotation is concerned. The goal of this paper is to explore pros and cons of different strategies for generating SD annotated Italian texts to enrich the existing Italian Stanford Dependency Treebank (ISDT). This is done by comparing the performance of a statistical parser (DeSR) trained on a simpler resource (the augmented version of the Merged Italian Dependency Treebank or MIDT+) and whose output was automatically converted to SD, with the results of the parser directly trained on ISDT. Experiments carried out to test reliability and effectiveness of the two strategies show that the performance of a parser trained on the reduced dependencies repertoire, whose output can be easily converted to SD, is slightly higher than the performance of a parser directly trained on ISDT. A non-negligible advantage of the first strategy for generating SD annotated texts is that semi-automatic extensions of the training resource are more easily and consistently carried out with respect to a reduced dependency tag set. Preliminary experiments carried out for generating the collapsed and propagated SD representation are also reported."
W13-2308,Converting {I}talian Treebanks: Towards an {I}talian {S}tanford Dependency Treebank,2013,21,26,2,0.555556,17906,cristina bosco,Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,0,"The paper addresses the challenge of converting MIDT, an existing dependencyxe2x80x93 based Italian treebank resulting from the harmonization and merging of smaller resources, into the Stanford Dependencies annotation formalism, with the final aim of constructing a standardxe2x80x93compliant resource for the Italian language. Achieved results include a methodology for converting treebank annotations belonging to the same dependencyxe2x80x93based family, the Italian Stanford Dependency Treebank (ISDT), and an Italian localization of the Stanford Dependency scheme."
W13-1906,Unsupervised Linguistically-Driven Reliable Dependency Parses Detection and Self-Training for Adaptation to the Biomedical Domain,2013,23,3,3,1,6236,felice dellorletta,Proceedings of the 2013 Workshop on Biomedical Natural Language Processing,0,"In this paper, a new selfxe2x80x90training method for domain adaptation is illustrated, where the selection of reliable parses is carried out by an unsupervised linguisticallyxe2x80x90 driven algorithm, ULISSE. The method has been tested on biomedical texts with results showing a significant improvement with respect to considered baselines, which demonstrates its ability to capture both reliability of parses and domainxe2x80x90 specificity of linguistic constructions."
W13-1727,Linguistic Profiling based on General{--}purpose Features and Native Language Identification,2013,24,6,4,0.916667,18355,andrea cimino,Proceedings of the Eighth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"In this paper, we describe our approach to native language identification and discuss the results we submitted as participants to the First NLI Shared Task. By resorting to a wide set of generalxe2x80x90purpose features qualifying the lexical and grammatical structure of a text, rather than to ad hoc features specifically selected for the NLI task, we achieved encouraging results, which show that the proposed approach is generalxe2x80x90purpose and portable across different tasks, domains and languages."
R13-1025,Linguistic Profiling of Texts Across Textual Genres and Readability Levels. An Exploratory Study on {I}talian Fictional Prose,2013,29,2,2,1,6236,felice dellorletta,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"In this paper we present a case study focusing on the literature genre, in particular on Italian fictional prose, aimed at identifying the features characterizing this text type. Identified features were tested in two classification tasks, i.e. by genre and by readability, with promising results. Interestingly, the same multixe2x80x93level set of linguistic features turned out to reliably capture variation within and across textual genres."
W12-5812,Genre-oriented Readability Assessment: a Case Study,2012,-1,-1,3,1,6236,felice dellorletta,Proceedings of the Workshop on Speech and Language Processing Tools in Education,0,None
lenci-etal-2012-enriching,Enriching the {ISST}-{TANL} Corpus with Semantic Frames,2012,16,4,2,0,928,alessandro lenci,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The paper describes the design and the results of a manual annotation methodology devoted to enrich the ISST--TANL Corpus, derived from the Italian Syntactic--Semantic Treebank (ISST), with Semantic Frames information. The main issues encountered in applying the English FrameNet annotation criteria to a corpus of Italian language are discussed together with the choice of anchoring the semantic annotation layer to the underlying dependency syntactic structure. The results of a case study aimed at extending and specialising this methodology for the annotation of a corpus of legislative texts are also discussed."
W11-2308,{READ}{--}{IT}: Assessing Readability of {I}talian Texts with a View to Text Simplification,2011,32,54,2,1,6236,felice dellorletta,Proceedings of the Second Workshop on Speech and Language Processing for Assistive Technologies,0,"In this paper, we propose a new approach to readability assessment with a specific view to the task of text simplification: the intended audience includes people with low literacy skills and/or with mild cognitive impairment. READ-IT represents the first advanced readability assessment tool for what concerns Italian, which combines traditional raw text features with lexical, morpho-syntactic and syntactic information. In READ-IT readability assessment is carried out with respect to both documents and sentences where the latter represents an important novelty of the proposed approach creating the prerequisites for aligning the readability assessment step with the text simplification process. READ-IT shows a high accuracy in the document classification task and promising results in the sentence classification scenario."
W11-0314,{ULISSE}: an Unsupervised Algorithm for Detecting Reliable Dependency Parses,2011,28,10,3,1,6236,felice dellorletta,Proceedings of the Fifteenth Conference on Computational Natural Language Learning,0,"In this paper we present ULISSE, an unsupervised linguistically--driven algorithm to select reliable parses from the output of a dependency parser. Different experiments were devised to show that the algorithm is robust enough to deal with the output of different parsers and with different languages, as well as to be used across different domains. In all cases, ULISSE appears to outperform the baseline algorithms."
W10-3711,Contrastive Filtering of Domain-Specific Multi-Word Terms from Different Types of Corpora,2010,4,10,4,0,10600,francesca bonin,Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications,0,In this paper we tackle the challenging task of Multi-word term (MWT) extraction from different types of specialized corpora. Contrastive filtering of previously extracted MWTs results in a considerable increment of acquired domainspecific terms.
bosco-etal-2010-comparing,Comparing the Influence of Different Treebank Annotations on Dependency Parsing,2010,11,16,2,0.555556,17906,cristina bosco,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"As the interest of the NLP community grows to develop several treebanks also for languages other than English, we observe efforts towards evaluating the impact of different annotation strategies used to represent particular languages or with reference to particular tasks. This paper contributes to the debate on the influence of resources used for the training and development on the performance of parsing systems. It presents a comparative analysis of the results achieved by three different dependency parsers developed and tested with respect to two treebanks for the Italian language, namely TUT and ISST--TANL, which differ significantly at the level of both corpus composition and adopted dependency representations."
attardi-etal-2010-resource,A Resource and Tool for Super-sense Tagging of {I}talian Texts,2010,16,10,5,0,5833,giuseppe attardi,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"A SuperSense Tagger is a tool for the automatic analysis of texts that associates to each noun, verb, adjective and adverb a semantic category within a general taxonomy. The developed tagger, based on a statistical model (Maximum Entropy), required the creation of an Italian annotated corpus, to be used as a training set, and the improvement of various existing tools. The obtained results significantly improved the current state-of-the art for this particular task."
bonin-etal-2010-contrastive,A Contrastive Approach to Multi-word Extraction from Domain-specific Corpora,2010,0,21,3,0,10600,francesca bonin,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper, we present a novel approach to multi-word terminology extraction combining a well-known automatic term recognition approach, the C--NC value method, with a contrastive ranking technique, aimed at refining obtained results either by filtering noise due to common words or by discerning between semantically different types of terms within heterogeneous terminologies. Differently from other contrastive methods proposed in the literature that focus on single terms to overcome the multi-word terms' sparsity problem, the proposed contrastive function is able to handle variation in low frequency events by directly operating on pre-selected multi-word terms. This methodology has been tested in two case studies carried out in the History of Art and Legal domains. Evaluation of achieved results showed that the proposed two--stage approach improves significantly multi--word term extraction results. In particular, for what concerns the legal domain it provides an answer to a well-known problem in the semi--automatic construction of legal ontologies, namely that of singling out law terms from terms of the specific domain being regulated."
lenci-etal-2008-unsupervised,Unsupervised Acquisition of Verb Subcategorization Frames from Shallow-Parsed Corpora,2008,21,13,3,0.718122,928,alessandro lenci,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper, we reported experiments of unsupervised automatic acquisition of Italian and English verb subcategorization frames (SCFs) from general and domain corpora. The proposed technique operates on syntactically shallow-parsed corpora on the basis of a limited number of search heuristics not relying on any previous lexico-syntactic knowledge about SCFs. Although preliminary, reported results are in line with state-of-the-art lexical acquisition systems. The issue of whether verbs sharing similar SCFs distributions happen to share similar semantic properties as well was also explored by clustering verbs that share frames with the same distribution using the Minimum Description Length Principle (MDL). First experiments in this direction were carried out on Italian verbs with encouraging results."
giovannetti-etal-2008-ontology,Ontology Learning and Semantic Annotation: a Necessary Symbiosis,2008,6,3,3,0,18490,emiliano giovannetti,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Semantic annotation of text requires the dynamic merging of linguistically structured information and a Âworld modelÂ, usually represented as a domain-specific ontology. On the other hand, the process of engineering a domain-ontology through semi-automatic ontology learning system requires the availability of a considerable amount of semantically annotated documents. Facing this bootstrapping paradox requires an incremental process of annotation-acquisition-annotation, whereby domain-specific knowledge is acquired from linguistically-annotated texts and then projected back onto texts for extra linguistic information to be annotated and further knowledge layers to be extracted. The presented methodology is a first step in the direction of a full ÂvirtuousÂ circle where the semantic annotation platform and the evolving ontology interact in symbiosis. As a case study we have chosen the semantic annotation of product catalogues. We propose a hybrid approach, combining pattern matching techniques to exploit the regular structure of product descriptions in catalogues, and Natural Language Processing techniques which are resorted to analyze natural language descriptions. The semantic annotation involves the access to the ontology, semi-automatically bootstrapped with an ontology learning tool from annotated collections of catalogues."
thompson-etal-2008-building,Building a Bio-Event Annotated Corpus for the Acquisition of Semantic Frames from Biomedical Corpora,2008,16,9,5,0,17111,paul thompson,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper reports on the design and construction of a bio-event annotated corpus which was developed with a specific view to the acquisition of semantic frames from biomedical corpora. We describe the adopted annotation scheme and the annotation process, which is supported by a dedicated annotation tool. The annotated corpus contains 677 abstracts of biomedical research articles."
W06-0604,Probing the Space of Grammatical Variation: Induction of Cross-Lingual Grammatical Constraints from Treebanks,2006,11,2,3,1,6236,felice dellorletta,Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006,0,"The paper reports on a detailed quantitative analysis of distributional language data of both Italian and Czech, highlighting the relative contribution of a number of distributed grammatical factors to sentence-based identification of subjects and direct objects. The work uses a Maximum Entropy model of stochastic resolution of conflicting grammatical constraints and is demonstrably capable of putting explanatory theoretical accounts to the test of usage-based empirical verification."
dellorletta-etal-2006-searching,Searching treebanks for functional constraints: cross-lingual experiments in grammatical relation assignment,2006,12,0,3,1,6236,felice dellorletta,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The paper reports on a detailed quantitative analysis of distributional language data of both Italian and Czech, highlighting the relative contribution of a number of distributed grammatical factors to sentence-based identification of subjects and direct objects. The work is based on a Maximum Entropy model of stochastic resolution of grammatical conflicting constraints, and is demonstrably capable of putting explanatory theoretical accounts to the challenging test of an extensive, usage-based empirical verification."
cucurullo-etal-2006-dialectal,Dialectal resources on-line: the {ALT}-Web experience,2006,3,5,2,0,50555,nella cucurullo,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The paper presents an on-line dialectal resource, ALT-Web, which gives access to the linguistic data of the Atlante Lessicale Toscano, a specially designed linguistic atlas in which lexical data have both a diatopic and diastratic characterisation. The paper focuses on: the dialectal data representation model; the access modalities to the ALT dialectal corpus; ontology-based search."
W05-0509,Climbing the Path to Grammar: A Maximum Entropy Model of Subject/Object Learning,2005,21,14,3,1,6236,felice dellorletta,Proceedings of the Workshop on Psychocomputational Models of Human Language Acquisition,0,"In this paper, we discuss an application of Maximum Entropy to modeling the acquisition of subject and object processing in Italian. The model is able to learn from corpus data a set of experimentally and theoretically well-motivated linguistic constraints, as well as their relative salience in Italian grammar development and processing. The model is also shown to acquire robust syntactic generalizations by relying on the evidence provided by a small number of high token frequency verbs only. These results are consistent with current research focusing on the role of high frequency verbs in allowing children to converge on the most salient constraints in the grammar."
bartolini-etal-2004-semantic,Semantic Mark-up of {I}talian Legal Texts Through {NLP}-based Techniques,2004,4,6,3,1,29604,roberto bartolini,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"In this paper we illustrate an approach to information extraction from legal texts using SALEM. SALEM is an NLP architecture for semantic annotation and indexing of Italian legislative texts, developed by ILC in close collaboration with ITTIG-CNR, Florence. Results of SALEM performance on a test sample of about 500 Italian law paragraphs are provided."
bartolini-etal-2004-hybrid,Hybrid Constraints for Robust Parsing: First Experiments and Evaluation,2004,5,12,3,1,29604,roberto bartolini,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"In this paper we present IDEAL, a parsing architecture for Italian, which pursues the goal of pairing robustness with deep linguistic analysis by extending a shallow processing kernel with a pool of hybrid constraints for the incremental identification of grammatical relations. The parsing output takes the form of dependency structures representing the full range of instantiated functional relations (e.g. subject, object, modifier, complement, etc.). The paper focuses on nature and interaction of the battery of hybrid constraints and evaluates their joint impact against a gold standard of more than 700 manually annotated sentences."
hepple-etal-2004-nlp,{NLP}-enhanced Content Filtering Within the {POESIA} Project,2004,7,7,5,0,28213,mark hepple,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper introduces the POESIA internet filtering system, which is open-source, and which combines standard filtering methods, such as positive/negative URL lists, with more advanced techniques, such as image processing and NLP-enhanced text filtering. The description here focusses on components providing textual content filtering for three European languages (English, Italian and Spanish), employing NLP methods to enhance performance. We address also the acquisition of language data needed to develop these filters, and the evaluation of the system and its components."
W02-1501,"Grammar and Lexicon in the Robust Parsing of {I}talian towards a Non-Na{\\\\\i}ve Interplay""",2002,15,12,3,1,29604,roberto bartolini,{COLING}-02: Grammar Engineering and Evaluation,0,In the paper we report a qualitative evaluation of the performance of a dependency analyser of Italian that runs in both a non-lexicalised and a lexicalised mode. Results shed light on the contribution of types of lexical information to parsing.
bartolini-etal-2002-lexicon,The Lexicon-Grammar Balance in Robust Parsing of {I}talian,2002,5,7,3,1,29604,roberto bartolini,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"What is the role of lexical information in robust parsing of unrestricted texts? In this paper we provide experimental evidence showing that, in order to strike the balance between robustness and coverage needed for practical NLP applications, judicious use of positive lexical evidence given a text should be complemented with a battery of dynamic parsing strategies aimed at solving local constraint conflicts. Likewise, negative lexical evidence should not blindly override grammatical information. Unlike fully lexicalised approaches to parsing where cross-categorial constraints on lexicon usage apply freely, optimal results can be obtained by modulating the way subcategorisation information is brought to bear in identifying dependency relations in context."
lenci-etal-2000-opposites,Where Opposites Meet. A Syntactic Meta-scheme for Corpus Annotation and Parsing Evaluation,2000,15,12,2,1,928,alessandro lenci,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"The paper describes the use of FAME, a functional annotation metaxe2x80x93scheme for comparison and evaluation of syntactic annotation schemes, i) as a flexible yardstick in multixe2x80x93lingual and multixe2x80x93modal parser evaluation campaigns and ii) for corpus annotation. We show that FAME complies with a variety of nonxe2x80x93trivial methodological requirements, and has the potential for being effectively used as an xe2x80x9cinterlinguaxe2x80x9d between different syntactic representation formats. 1. Motivation and background"
allegrini-etal-2000-controlled,Controlled Bootstrapping of Lexico-semantic Classes as a Bridge between Paradigmatic and Syntagmatic Knowledge: Methodology and Evaluation,2000,14,1,2,1,52316,paolo allegrini,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"Semantic classification of words is a highly context sensitive and somewhat moving target, hard to deal with and even harder to evaluate on an objective basis. In this paper we suggest a stepxe2x80x93wise methodology for automatic acquisition of lexicoxe2x80x93semantic classes and delve into the non trivial issue of how results should be evaluated against a topxe2x80x93down reference standard."
C00-1002,Learning Word Clusters from Data Types,2000,14,9,2,1,52316,paolo allegrini,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"The paper illustrates a linguistic knowledge acquisition model making use of data types, infinite memory, and an inferential mechanism for inducing new information from known data. The model is compared with standard stochastic methods applied to data tokens, and tested on a task of lexico-semantic classification."
W99-0407,{FAME}: a Functional Annotation Meta-scheme for multi-modal and multi-lingual Parsing Evaluation,1999,14,9,2,1,928,alessandro lenci,Computer Mediated Language Assessment and Evaluation in Natural Language Processing,0,"The paper describes FAME, a functional annotation meta-scheme for comparison and evaluation of existing syntactic annotation schemes, intended to be used as a flexible yardstick in multi-lingual and multi-modal parser evaluation campaigns. We show that FAME complies with a variety of non-trivial methodological requirements, and has the potential for being effectively used as an interlingua between different syntactic representation formats."
W98-0712,Augmenting {W}ord{N}et-like lexical resources with distributional evidence. An application-oriented perspective,1998,13,9,1,1,16849,simonetta montemagni,Usage of {W}ord{N}et in Natural Language Processing Systems,0,The paper deals with the issue of how and to what extent WordNet-like resources provide the necessary information for an assessment of semantic similarity which is useful for practical applications. The general point is made that taxonomical information should be complemented with distributional evidence. The claim is substantiated through experimental data and an illustration of a word sense disambiguation system (SENSE) capable of using contextually-relevant semantic similarity.
W97-0813,Inferring Semantic Similarity from Distributional Evidence: an Analogy-based Approach to Word Sense Disambiguation,1997,6,14,2,0,55551,stefano federici,Automatic Information Extraction and Building of Lexical Semantic Resources for {NLP} Applications,0,None
C96-1064,Resolving syntactic ambiguities with lexico-semantic patterns: an analogy-based approach,1996,9,6,1,1,16849,simonetta montemagni,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,A system for the resolution of syntactic ambiguities is illustrated which operates on morpho-syntactically ambiguous subject-object assignments in Italian and tries to find the most likely analysis on the basis of the evidence contained in a knowledge base of linguistic data automatically extracted from on-line resources. The system works on the basis of a set of straighforward analogy-based principles. Its performance on a substantial corpus of test data extracted from real texts is described.
C92-2083,Structural Patterns vs. String Patterns for Extracting Semantic Information from Dictionaries,1992,11,54,1,1,16849,simonetta montemagni,{COLING} 1992 Volume 2: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"This chapter presents evidence for preferring to extract semantic information from a syntactic analysis of a dictionary definition rather than directly from the definition string itself when the information to be extracted is found in the differentiae. We present examples of how very complex information can be extracted from the differentiae of the definition using structural analysis patterns, and why string patterns would fail to do the same."
