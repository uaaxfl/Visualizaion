2021.smm4h-1.18,Classification of Tweets Self-reporting Adverse Pregnancy Outcomes and Potential {COVID}-19 Cases Using {R}o{BERT}a Transformers,2021,-1,-1,1,1,1205,lunghao lee,Proceedings of the Sixth Social Media Mining for Health ({\\#}SMM4H) Workshop and Shared Task,0,"This study describes our proposed model design for SMM4H 2021 shared tasks. We fine-tune the language model of RoBERTa transformers and their connecting classifier to complete the classification tasks of tweets for adverse pregnancy outcomes (Task 4) and potential COVID-19 cases (Task 5). The evaluation metric is F1-score of the positive class for both tasks. For Task 4, our best score of 0.93 exceeded the mean score of 0.925. For Task 5, our best of 0.75 exceeded the mean score of 0.745."
2021.rocling-1.33,Multi-Label Classification of {C}hinese Humor Texts Using Hypergraph Attention Networks,2021,-1,-1,3,0,2390,haochuan kao,Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing (ROCLING 2021),0,"We use Hypergraph Attention Networks (HyperGAT) to recognize multiple labels of Chinese humor texts. We firstly represent a joke as a hypergraph. The sequential hyperedge and semantic hyperedge structures are used to construct hyperedges. Then, attention mechanisms are adopted to aggregate context information embedded in nodes and hyperedges. Finally, we use trained HyperGAT to complete the multi-label classification task. Experimental results on the Chinese humor multi-label dataset showed that HyperGAT model outperforms previous sequence-based (CNN, BiLSTM, FastText) and graph-based (Graph-CNN, TextGCN, Text Level GNN) deep learning models."
2021.rocling-1.34,Incorporating Domain Knowledge into Language Transformers for Multi-Label Classification of {C}hinese Medical Questions,2021,-1,-1,3,0,2392,pohan chen,Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing (ROCLING 2021),0,"In this paper, we propose a knowledge infusion mechanism to incorporate domain knowledge into language transformers. Weakly supervised data is regarded as the main source for knowledge acquisition. We pre-train the language models to capture masked knowledge of focuses and aspects and then fine-tune them to obtain better performance on the downstream tasks. Due to the lack of publicly available datasets for multi-label classification of Chinese medical questions, we crawled questions from medical question/answer forums and manually annotated them using eight predefined classes: persons and organizations, symptom, cause, examination, disease, information, ingredient, and treatment. Finally, a total of 1,814 questions with 2,340 labels. Each question contains an average of 1.29 labels. We used Baidu Medical Encyclopedia as the knowledge resource. Two transformers BERT and RoBERTa were implemented to compare performance on our constructed datasets. Experimental results showed that our proposed model with knowledge infusion mechanism can achieve better performance, no matter which evaluation metric including Macro F1, Micro F1, Weighted F1 or Subset Accuracy were considered."
2021.rocling-1.36,Generative Adversarial Networks based on Mixed-Attentions for Citation Intent Classification in Scientific Publications,2021,-1,-1,3,0,2403,yuhshyang wang,Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing (ROCLING 2021),0,"We propose the mixed-attention-based Generative Adversarial Network (named maGAN), and apply it for citation intent classification in scientific publication. We select domain-specific training data, propose a mixed-attention mechanism, and employ generative adversarial network architecture for pre-training language model and fine-tuning to the downstream multi-class classification task. Experiments were conducted on the SciCite datasets to compare model performance. Our proposed maGAN model achieved the best Macro-F1 of 0.8532."
2021.rocling-1.50,{NCU}-{NLP} at {ROCLING}-2021 Shared Task: Using {M}ac{BERT} Transformers for Dimensional Sentiment Analysis,2021,-1,-1,4,0,1206,manchen hung,Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing (ROCLING 2021),0,"We use the MacBERT transformers and fine-tune them to ROCLING-2021 shared tasks using the CVAT and CVAS data. We compare the performance of MacBERT with the other two transformers BERT and RoBERTa in the valence and arousal dimensions, respectively. MAE and correlation coefficient (r) were used as evaluation metrics. On ROCLING-2021 test set, our used MacBERT model achieves 0.611 of MAE and 0.904 of r in the valence dimensions; and 0.938 of MAE and 0.549 of r in the arousal dimension."
2021.bionlp-1.30,{NCUEE}-{NLP} at {MEDIQA} 2021: Health Question Summarization Using {PEGASUS} Transformers,2021,-1,-1,1,1,1205,lunghao lee,Proceedings of the 20th Workshop on Biomedical Language Processing,0,"This study describes the model design of the NCUEE-NLP system for the MEDIQA challenge at the BioNLP 2021 workshop. We use the PEGASUS transformers and fine-tune the downstream summarization task using our collected and processed datasets. A total of 22 teams participated in the consumer health question summarization task of MEDIQA 2021. Each participating team was allowed to submit a maximum of ten runs. Our best submission, achieving a ROUGE2-F1 score of 0.1597, ranked third among all 128 submissions."
2020.smm4h-1.23,Medication Mention Detection in Tweets Using {ELECTRA} Transformers and Decision Trees,2020,-1,-1,1,1,1205,lunghao lee,Proceedings of the Fifth Social Media Mining for Health Applications Workshop {\\&} Shared Task,0,"This study describes our proposed model design for the SMM4H 2020 Task 1. We fine-tune ELECTRA transformers using our trained SVM filter for data augmentation, along with decision trees to detect medication mentions in tweets. Our best F1-score of 0.7578 exceeded the mean score 0.6646 of all 15 submitting teams."
2020.rocling-1.2,Gated Graph Sequence Neural Networks for {C}hinese Healthcare Named Entity Recognition,2020,-1,-1,2,0,3546,yi lu,Proceedings of the 32nd Conference on Computational Linguistics and Speech Processing (ROCLING 2020),0,None
2020.rocling-1.32,Scientific Writing Evaluation Using Ensemble Multi-channel Neural Networks,2020,-1,-1,2,0,2403,yuhshyang wang,Proceedings of the 32nd Conference on Computational Linguistics and Speech Processing (ROCLING 2020),0,None
2020.ijclclp-2.2,"åºæ¼åç¥ç¶ç¶²è·¯ä¹ä¸­æå¥åº·ç\
§è­·å½åå¯¦é«è¾¨è­ ({C}hinese Healthcare Named Entity Recognition Based on Graph Neural Networks)",2020,-1,-1,2,0,3546,yi lu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 25, Number 2, December 2020",0,None
W19-5058,{NCUEE} at {MEDIQA} 2019: Medical Text Inference Using Ensemble {BERT}-{B}i{LSTM}-Attention Model,2019,0,3,1,1,1205,lunghao lee,Proceedings of the 18th BioNLP Workshop and Shared Task,0,This study describes the model design of the NCUEE system for the MEDIQA challenge at the ACL-BioNLP 2019 workshop. We use the BERT (Bidirectional Encoder Representations from Transformers) as the word embedding method to integrate the BiLSTM (Bidirectional Long Short-Term Memory) network with an attention mechanism for medical text inferences. A total of 42 teams participated in natural language inference task at MEDIQA 2019. Our best accuracy score of 0.84 ranked the top-third among all submissions in the leaderboard.
W18-3723,Multilingual Short Text Responses Clustering for Mobile Educational Activities: a Preliminary Exploration,2018,0,1,2,0.966834,2391,yuenhsien tseng,Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications,0,"Text clustering is a powerful technique to detect topics from document corpora, so as to provide information browsing, analysis, and organization. On the other hand, the Instant Response System (IRS) has been widely used in recent years to enhance student engagement in class and thus improve their learning effectiveness. However, the lack of functions to process short text responses from the IRS prevents the further application of IRS in classes. Therefore, this study aims to propose a proper short text clustering module for the IRS, and demonstrate our implemented techniques through real-world examples, so as to provide experiences and insights for further study. In particular, we have compared three clustering methods and the result shows that theoretically better methods need not lead to better results, as there are various factors that may affect the final performance."
L18-1363,Building a {TOCFL} Learner Corpus for {C}hinese Grammatical Error Diagnosis,2018,-1,-1,1,1,1205,lunghao lee,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
S17-2165,The {NTNU} System at {S}em{E}val-2017 Task 10: Extracting Keyphrases and Relations from Scientific Publications Using Multiple Conditional Random Fields,2017,0,2,1,1,1205,lunghao lee,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This study describes the design of the NTNU system for the ScienceIE task at the SemEval 2017 workshop. We use self-defined feature templates and multiple conditional random fields with extracted features to identify keyphrases along with categorized labels and their relations from scientific publications. A total of 16 teams participated in evaluation scenario 1 (subtasks A, B, and C), with only 7 teams competing in all sub-tasks. Our best micro-averaging F1 across the three subtasks is 0.23, ranking in the middle among all 16 submissions."
I17-4001,{IJCNLP}-2017 Task 1: {C}hinese Grammatical Error Diagnosis,2017,0,4,4,0,11752,gaoqi rao,"Proceedings of the {IJCNLP} 2017, Shared Tasks",0,"This paper presents the IJCNLP 2017 shared task for Chinese grammatical error diagnosis (CGED) which seeks to identify grammatical error types and their range of occurrence within sentences written by learners of Chinese as foreign language. We describe the task definition, data preparation, performance metrics, and evaluation results. Of the 13 teams registered for this shared task, 5 teams developed the system and submitted a total of 13 runs. We expected this evaluation campaign could lead to the development of more advanced NLP techniques for educational applications, especially for Chinese error detection. All data sets with gold standards and scoring scripts are made publicly available to researchers."
I17-4002,{IJCNLP}-2017 Task 2: Dimensional Sentiment Analysis for {C}hinese Phrases,2017,0,0,2,0,2441,liangchih yu,"Proceedings of the {IJCNLP} 2017, Shared Tasks",0,"This paper presents the IJCNLP 2017 shared task on Dimensional Sentiment Analysis for Chinese Phrases (DSAP) which seeks to identify a real-value sentiment score of Chinese single words and multi-word phrases in the both valence and arousal dimensions. Valence represents the degree of pleasant and unpleasant (or positive and negative) feelings, and arousal represents the degree of excitement and calm. Of the 19 teams registered for this shared task for two-dimensional sentiment analysis, 13 submitted results. We expected that this evaluation campaign could produce more advanced dimensional sentiment analysis techniques, especially for Chinese affective computing. All data sets with gold standards and scoring script are made publicly available to researchers."
W16-4906,Overview of {NLP}-{TEA} 2016 Shared Task for {C}hinese Grammatical Error Diagnosis,2016,0,3,1,1,1205,lunghao lee,Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications ({NLPTEA}2016),0,"This paper presents the NLP-TEA 2016 shared task for Chinese grammatical error diagnosis which seeks to identify grammatical error types and their range of occurrence within sentences written by learners of Chinese as foreign language. We describe the task definition, data preparation, performance metrics, and evaluation results. Of the 15 teams registered for this shared task, 9 teams developed the system and submitted a total of 36 runs. We expected this evaluation campaign could lead to the development of more advanced NLP techniques for educational applications, especially for Chinese error detection. All data sets with gold standards and scoring scripts are made publicly available to researchers."
W16-0513,The {NTNU}-{YZU} System in the {AESW} Shared Task: Automated Evaluation of Scientific Writing Using a Convolutional Neural Network,2016,26,1,1,1,1205,lunghao lee,Proceedings of the 11th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"This study describes the design of the NTNU-YZU system for the automated evaluation of scientific writing shared task. We employ a convolutional neural network with the Word2Vec/GloVe embedding representation to predict whether a sentence needs language editing. For the Boolean prediction track, our best F-score of 0.6108 ranked second among the ten submissions. Our system also achieved an F-score of 0.7419 for the probabilistic estimation track, ranking fourth among the nine submissions."
N16-1066,Building {C}hinese Affective Resources in Valence-Arousal Dimensions,2016,17,48,2,0,2441,liangchih yu,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
W15-4401,Overview of the {NLP}-{TEA} 2015 Shared Task for {C}hinese Grammatical Error Diagnosis,2015,1,10,1,1,1205,lunghao lee,Proceedings of the 2nd Workshop on Natural Language Processing Techniques for Educational Applications,0,"This paper introduces the NLP-TEA 2015 shared task for Chinese grammatical error diagnosis. We describe the task, data preparation, performance metrics, and evaluation results. The hope is that such an evaluation campaign may produce more advanced Chinese grammatical error diagnosis techniques. All data sets with gold standards and evaluation tools are publicly available for research purposes."
W15-3106,Introduction to {SIGHAN} 2015 Bake-off for {C}hinese Spelling Check,2015,4,9,2,1,2391,yuenhsien tseng,Proceedings of the Eighth {SIGHAN} Workshop on {C}hinese Language Processing,0,"This paper introduces the SIGHAN 2015 Bake-off for Chinese Spelling Check, including task description, data preparation, performance metrics, and evaluation results. The competition reveals current state-of-the-art NLP techniques in dealing with Chinese spelling checking. All data sets with gold standards and evaluation tool used in this bake-off are publicly available for future research."
O15-2001,Guest Editoral: Special Issue on {C}hinese as a Foreign Language,2015,10,1,1,1,1205,lunghao lee,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 20, Number 1, June 2015-Special Issue on {C}hinese as a Foreign Language",0,"This introduction paper describes the research trends of Chinese as a second/foreign language along with related studies. We also overview the research papers included in this special issue. Finally, we conclude the findings and offer the suggestions."
W14-6820,Overview of {SIGHAN} 2014 Bake-off for {C}hinese Spelling Check,2014,4,16,2,0,2441,liangchih yu,Proceedings of The Third {CIPS}-{SIGHAN} Joint Conference on {C}hinese Language Processing,0,"This paper introduces a Chinese Spelling Check campaign organized for the SIGHAN 2014 bake-off, including task description, data preparation, performance metrics, and evaluation results based on essays written by Chinese as a foreign language learners. The hope is that such evaluations can produce more advanced Chinese spelling check techniques."
E14-4003,{C}hinese Open Relation Extraction for Knowledge Acquisition,2014,15,19,2,1,2391,yuenhsien tseng,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"This study presents the Chinese Open Relation Extraction (CORE) system that is able to extract entity-relation triples from Chinese free texts based on a series of NLP techniques, i.e., word segmentation, POS tagging, syntactic parsing, and extraction rules. We employ the proposed CORE techniques to extract more than 13 million entity-relations for an open domain question answering application. To our best knowledge, CORE is the first Chinese Open IE system for knowledge acquisition."
C14-2015,A Sentence Judgment System for Grammatical Error Detection,2014,7,11,1,1,1205,lunghao lee,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: System Demonstrations",0,"This study develops a sentence judgment system using both rule-based and n-gram statistical methods to detect grammatical errors in Chinese sentences. The rule-based method provides 142 rules developed by linguistic experts to identify potential rule violations in input sentences. The n-gram statistical method relies on the n-gram scores of both correct and incorrect training sentences to determine the correctness of the input sentences, providing learners with improved understanding of linguistic rules and n-gram frequencies."
W13-4406,{C}hinese Spelling Check Evaluation at {SIGHAN} Bake-off 2013,2013,6,34,3,0,2436,shihhung wu,Proceedings of the Seventh {SIGHAN} Workshop on {C}hinese Language Processing,0,"This paper introduces an overview of Chinese Spelling Check task at SIGHAN Bake-off 2013. We describe all aspects of the task for Chinese spelling check, consisting of task description, data preparation, performance metrics, and evaluation results. This bake-off contains two subtasks, i.e., error detection and error correction. We evaluate the systems that can automatically point out the spelling errors and provide the corresponding corrections in studentsxe2x80x99 essays, summarize the performance of all participantsxe2x80x99 submitted results, and discuss some advanced issues. The hope is that through such evaluation campaigns, more advanced Chinese spelling check techniques will be emerged."
W12-6335,Traditional {C}hinese Parsing Evaluation at {SIGHAN} Bake-offs 2012,2012,8,4,2,1,2391,yuenhsien tseng,Proceedings of the Second {CIPS}-{SIGHAN} Joint Conference on {C}hinese Language Processing,0,"This paper presents the overview of traditional Chinese parsing task at SIGHAN Bake-offs 2012. On behalf of task organizers, we describe all aspects of the task for traditional Chinese parsing, i.e., task description, data preparation, performance metrics, and evaluation results. We summarize the performance results of all participant teams in this evaluation, in the hope to encourage more future studies on traditional Chinese parsing"
wang-etal-2012-ntusocialrec,{NTUS}ocial{R}ec: An Evaluation Dataset Constructed from Microblogs for Recommendation Applications in Social Networks,2012,8,0,3,0,37581,chiehjen wang,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper proposes a method to construct an evaluation dataset from microblogs for the development of recommendation systems. We extract the relationships among three main entities in a recommendation event, i.e., who recommends what to whom. User-to-user friend relationships and user-to-resource interesting relationships in social media and resource-to-metadata descriptions in an external ontology are employed. In the experiments, the resources are restricted to visual entertainment media, movies in particular. A sequence of ground truths varying with time is generated. That reflects the dynamic of real world."
Y09-1031,{C}hinese {W}ord{N}et Domains: Bootstrapping {C}hinese {W}ord{N}et with Semantic Domain Labels,2009,18,2,1,1,1205,lunghao lee,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 1",0,"We bootstrapped Chinese WordNet with semantic domain labels of WordNet Domains for constructing a language resource called Chinese WordNet Domains. The bootstrapping methods work from three aspects: 1) Princeton WordNet alignment, 2) lexical semantic relations and 3) domain taxonomy mapping. Experimental results of our proposed bootstrapping based domain predication achieve satisfying effects. We believe the resulting Chinese WordNet Domains will be the first oriental language resource, which can be used to interoperate with the existing WordNet Domains of several languages and benefits for cross-language and domain-specific researches and applications. In addition, we also plan to release resulting Chinese WordNet Domains to the community for research purposes."
W09-3418,{CWN}-{LMF}: {C}hinese {W}ord{N}et in the {L}exical {M}arkup {F}ramework,2009,17,8,1,1,1205,lunghao lee,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"Lexical Markup Framework (LMF, ISO-24613) is the ISO standard which provides a common standardized framework for the construction of natural language processing lexicons. LMF facilitates data exchange among computational linguistic resources, and also promises a convenient uniformity for future application. This study describes the design and implementation of the WordNet-LMF used to represent lexical semantics in Chinese WordNet. The compiled CWN-LMF will be released to the community for linguistic researches."
Y08-1042,Contrastive Approach towards Text Source Classification based on Top-Bag-of-Word Similarity,2008,19,20,2,0,1504,churen huang,"Proceedings of the 22nd Pacific Asia Conference on Language, Information and Computation",0,"This paper proposes a method to automatically classify texts from different varieties of the same language. We show that similarity measure is a robust tool for studying comparable corpora of language variations. We take LDCxe2x80x99s Chinese Gigaword Corpus composed of three varieties of Chinese from Mainland China, Singapore, and Taiwan, as the comparable corpora. Top-bag-of-word similarity measures reflect distances among the three varieties of the same language. A Top-bag-of-word similarity based contrastive approach was taken to solve the text source classification problem. Our results show that a contrastive approach using similarity to rule out identity of source and to arrive actual source by inference is more robust that directly confirmation of source by similarity. We show that this approach is robust when applied to other texts."
huang-etal-2008-quality,Quality Assurance of Automatic Annotation of Very Large Corpora: a Study based on heterogeneous Tagging System,2008,9,7,2,0,1504,churen huang,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,We propose a set of heuristics for improving annotation quality of very large corpora efficiently. The Xinhua News portion of the Chinese Gigaword Corpus was tagged independently with both the Peking University ICL tagset and the Academia Sinica CKIP tagset. The corpus-based POS tags mapping will serve as the basis of the possible contrast in grammatical systems between PRC and Taiwan. And it can serve as the basic model for mapping between the CKIP and ICL tagging systems for any data.
