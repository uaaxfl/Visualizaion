2020.lrec-1.86,2020.scil-1.31,1,0.786792,"l. and Lindemann et al. parsers to obtain the standard AMR for manual corrections, as each correctly captured several of the extremely frequent aspects of the corpus, including the mode :imperative marker. 4.2.2. Graph-to-Graph Transformation for Dialogue-AMR In order to automatically generate Dialogue-AMRs with the tense, aspect, and illocutionary force information critical to the navigation domain, we developed a graph-tograph transformation system that converts standard AMRs into our Dialogue-AMRs through a mixed-methods approach that leverages both rule-based and classifier-based systems (Abrams et al., 2020). Both the standard AMR and original natural language utterance are required as input to the graph-to-graph transformer. From the utterance, the speech act and tense are determined by employing classifiers. From the standard AMR, the relations (e.g., go-02, turn-01) corresponding to robot concepts are determined by matching the standard AMR root relation against a dictionary of keywords associated with a particular robot concept (see Table 2). Next, the aspectual information is extracted based upon speech act and tense patterns (e.g., present-tense assertions are complete ongoing +). Finally,"
2020.lrec-1.86,W13-2322,1,0.888934,"nly the content of an utterance, but the illocutionary force behind it, as well as tense and aspect. To showcase the coverage of the schema, we use both manual and automatic methods to construct the “DialAMR” corpus—a corpus of human-robot dialogue annotated with standard AMR and our enriched Dialogue-AMR schema. Our automated methods can be used to incorporate AMR into a larger NLU pipeline supporting human-robot dialogue. Keywords: Dialogue, Abstract Meaning Representation, Illocutionary Force 1. Introduction This paper describes a schema that enriches Abstract Meaning Representation (AMR) (Banarescu et al., 2013) to support Natural Language Understanding (NLU) in humanrobot dialogue systems. AMR is a formalism for sentence semantics that abstracts away many syntactic idiosyncrasies and represents sentences with rooted directed acyclic graphs (Figure 1a shows the PENMAN notation of the graph). Although AMR provides a suitable level of abstraction for representing the content of sentences in our domain, it lacks a level of representation for speaker intent, which would capture the pragmatic effect of an utterance in dialogue. Pragmatic information is critical in dialogue with a conversational agent. For"
2020.lrec-1.86,bastianelli-etal-2014-huric,0,0.0191406,"taxonomies often have to be fine-tuned to the domain of interest to be fully useful. While we adopt many of the categories of Searle’s taxonomy for our own speech act inventory, we integrate distinctions from the ISO standard and, following Traum (1999) and Poesio and Traum (1998), define our speech acts according to the effects of an utterance relating to the beliefs and obligations of the interlocutors (see Section 3.1). Our work forms part of a larger, growing interest in representing various levels of interpretation in existing meaning representation frameworks, and in AMR in particular. Bastianelli et al. (2014) present their Human Robot Interaction Corpus (HuRIC) following the format of AMR. This corpus is comprised of paired audio interactions and transcriptions. Though all text is annotated in the format of AMR, AMR is significantly altered by incorporating detailed spatial relations, frame semantics (Fillmore, 1985), and morphosyntactic information. Shen (2018) further presents a small corpus of manually annotated AMRs for spoken language to help the parsing task. The study presents similar findings to our own: while AMR offers a clean framework for the concepts and relations used in spoken langu"
2020.lrec-1.86,W19-3322,1,0.813505,"d and robust schema for representing illocutionary force in AMR called “Dialogue-AMR” (Figure 1b). This expands and refines previous work which proposed basic modifications for (a) (d / drive-01 :mode imperative :ARG0 (y / you) :destination (d2 / door)) (b) (c / command-SA :ARG0 (c2 / commander) :ARG2 (r / robot) :ARG1 (g / go-02 :completable + :ARG0 r :ARG3 (h / here) :ARG4 (d/ door) :time (a2 / after :op1 (n / now)))) Figure 1: The utterance Drive to the door represented in (a) standard AMR form, (b) Dialogue-AMR form. how to annotate speech acts and tense and aspect information within AMR (Bonial et al., 2019a). The contributions of the present research are: i) a set of speech acts finalized and situated in a taxonomy (Section 3.1); ii) the refinement of the Dialogue-AMR annotation schema to provide coverage of novel language (Sections 3.2 and 3.3); and iii) the creation of the “DialAMR” corpus, a collection of human-robot dialogues to which the new Dialogue-AMR schema has been applied (Section 4).1 DialAMR has additionally been annotated with standard AMR, thus constituting one of the first corpora of dialogue annotated with AMR (see related work in Section 5) and allowing for comparison of both"
2020.lrec-1.86,W19-0124,1,0.862276,"d and robust schema for representing illocutionary force in AMR called “Dialogue-AMR” (Figure 1b). This expands and refines previous work which proposed basic modifications for (a) (d / drive-01 :mode imperative :ARG0 (y / you) :destination (d2 / door)) (b) (c / command-SA :ARG0 (c2 / commander) :ARG2 (r / robot) :ARG1 (g / go-02 :completable + :ARG0 r :ARG3 (h / here) :ARG4 (d/ door) :time (a2 / after :op1 (n / now)))) Figure 1: The utterance Drive to the door represented in (a) standard AMR form, (b) Dialogue-AMR form. how to annotate speech acts and tense and aspect information within AMR (Bonial et al., 2019a). The contributions of the present research are: i) a set of speech acts finalized and situated in a taxonomy (Section 3.1); ii) the refinement of the Dialogue-AMR annotation schema to provide coverage of novel language (Sections 3.2 and 3.3); and iii) the creation of the “DialAMR” corpus, a collection of human-robot dialogues to which the new Dialogue-AMR schema has been applied (Section 4).1 DialAMR has additionally been annotated with standard AMR, thus constituting one of the first corpora of dialogue annotated with AMR (see related work in Section 5) and allowing for comparison of both"
2020.lrec-1.86,T75-2014,0,0.329028,"ialogue, an interlocutor must interpret the meaning of a speaker’s utterance on at least two levels, as first suggested by Austin (1962): (i) its propositional content and (ii) its illocutionary force. While semantic representations have traditionally sought to represent propositional content, speech act theory has sought to delineate and explicate the relationship between an utter690 ance and its effects on the mental and interactional states of the conversational participants. Speech acts have been used as part of the meaning representation of task-oriented dialogue systems since the 1970s (Bruce, 1975; Cohen and Perrault, 1979; Allen and Perrault, 1980). For a summary of some of the earlier work in this area, see Traum (1999). Although the refinement and extension of Austin’s (1962) hypothesized speech acts by Searle (1969) remains a canonical work on this topic, there have since been a number of widely used speech act taxonomies that differ from or augment this work, including an ISO standard (Bunt et al., 2012). Nevertheless, these taxonomies often have to be fine-tuned to the domain of interest to be fully useful. While we adopt many of the categories of Searle’s taxonomy for our own sp"
2020.lrec-1.86,bunt-etal-2012-iso,1,0.899784,"ng those same concepts. Thus, the AMR formalism smooths away many syntactic and lexical features that are unimportant to the robot. Existing AMR parsers can be utilized to obtain an initial interpretation of a user utterance, making the interpretation process easier than parsing natural language Development of Dialogue-AMR Speech Act Inventory We embrace much of the higher-level categorization and labeling of speech acts outlined by Searle (1969), including the basic categories of Assertions (termed “representatives” by Searle), Commissives, Directives, and Expressives. Additionally, based on Bunt et al. (2012), we introduce an early distinction in classifying our speech acts between Information Transfer Functions and Action-Discussion Functions (see Figure 3). In terms of dialogue function, this division allows us to monitor the status of distinct dialogue contexts. For Information Transfer Types, we can monitor the quantity and quality of general-purpose information exchanged in the dialogue that is relevant to the larger task at hand. For example, Robot, do you speak any foreign languages? may not directly impact a current task, but it introduces information into the dialogue that may be useful a"
2020.lrec-1.86,P13-2131,0,0.260444,"Missing"
2020.lrec-1.86,N15-1119,0,0.0330163,"use a lexicon (shared with PropBank (Palmer et al., 2005) comprised of numbered senses of a relation, each of which lists a set of numbered participant roles (Arg0-5). For ease of creation and manipulation, annotators work with notation from the PENMAN project (Penman Natural Language Group, 1989), which is the notation used in this paper (e.g., Figure 1a). AMR has been used to support NLU, generation, and summarization (Liu et al., 2015; Pourdamghani et al., 2016), as well as machine translation (Langkilde and Knight, 1998), question answering (Mitra and Baral, 2016), information extraction (Pan et al., 2015), and biomedical text mining (Garg et al., 2016; Rao et al., 2017; Wang et al., 2017). text directly into a robot-oriented representation. Standard AMR nevertheless omits certain semantic information essential to our domain. Specifically, AMR omits both tense and aspect information, assuming that some of this information may be gleaned from morphosyntactic information already well-represented in syntactic treebanks. The formalism also lacks illocutionary force, considering it distinct from core contentful meaning. We therefore add these properties to the robot’s semantic representation (Sectio"
2020.lrec-1.86,W16-6603,0,0.0140873,"r graph nodes) are introduced for entities, events, properties, and states. Leaves are labeled with concepts (e.g., (r / robot)). Relational concepts in AMR use a lexicon (shared with PropBank (Palmer et al., 2005) comprised of numbered senses of a relation, each of which lists a set of numbered participant roles (Arg0-5). For ease of creation and manipulation, annotators work with notation from the PENMAN project (Penman Natural Language Group, 1989), which is the notation used in this paper (e.g., Figure 1a). AMR has been used to support NLU, generation, and summarization (Liu et al., 2015; Pourdamghani et al., 2016), as well as machine translation (Langkilde and Knight, 1998), question answering (Mitra and Baral, 2016), information extraction (Pan et al., 2015), and biomedical text mining (Garg et al., 2016; Rao et al., 2017; Wang et al., 2017). text directly into a robot-oriented representation. Standard AMR nevertheless omits certain semantic information essential to our domain. Specifically, AMR omits both tense and aspect information, assuming that some of this information may be gleaned from morphosyntactic information already well-represented in syntactic treebanks. The formalism also lacks illocut"
2020.lrec-1.86,W17-2315,0,0.484277,"Missing"
2020.lrec-1.86,L18-1017,1,0.835141,"by the DM. SCOUT also includes annotations of dialogue structure 685 Left Conversational Floor # Participant 1 2 3 4 5 6 7 8 9 proceed to the doorway ahead Right Conversational Floor DM → Participant DM → RN RN I see more than one doorway. Which doorway? the doorway closest to you processing move into Kitchen moving... done done Table 1: Navigation instruction initiated by the participant (#1), its clarification (#2-4), subsequent translation to a simplified form (Dialogue Manager (DM) to Robot Navigator (RN), #6), and acknowledgement of instructions (#5, 7, 9) and execution by the RN (#8). (Traum et al., 2018) that allow for the characterization of distinct information states (Traum and Larsson, 2003). However, this dialogue structure annotation schema does not provide a markup of the semantic content in participant instructions. 2.2. AMR AMR is a formalism for sentence semantics that abstracts away from some syntactic idiosyncrasies (Banarescu et al., 2013). Each sentence is represented by a rooted directed acyclic graph (DAG) in which variables (or graph nodes) are introduced for entities, events, properties, and states. Leaves are labeled with concepts (e.g., (r / robot)). Relational concepts in"
2020.lrec-1.86,N15-1040,0,0.0218702,"lease data, which, as mentioned previously, does not include natural dialogue, nor does it include much instruction-giving or commands. Nonetheless, we applied parsers to the SCOUT corpus to determine which could achieve the best performance with the least manually annotated in-domain training data. These experiments are ongoing, and full results will be reported in a future paper. Here, we limit our description to what is relevant for the automatic annotation pass used to efficiently create the DialAMR corpus. First, we tested two long-standing parsers, JAMR (Flanigan et al., 2014) and CAMR (Wang et al., 2015), on the Random-Commander set of gold-standard, manually annotated standard AMRs. Performance was far below reported f-scores on LDC AMR test data (Bonial et al., 2019b). Particularly problematic areas included missing mode :imperative markers on all imperative utterances, failure to include implicit subjects (e.g., the Arg0-mover in utterances such as Moving...), and failure to correctly represent the photographing semantics of the common light verb construction take a photo/picture (instead representing this as a taking event in the sense of grasping/moving). Next, we evaluated more recent s"
2020.lrec-1.86,W00-0309,0,0.46237,"guage generation, and robot concept specification. The DialogueAMR relations classify speaker intention, while the argument roles allow for flexible representation of previously unseen values (e.g., Turn left 100 degrees compared to a more typical number of degrees, such as 90) and compositional construction of referring expressions. Furthermore, the completable annotation attached to goal-oriented Dialogue-AMRs allow a dialogue management system to determine if all the arguments required for execution of the instruction are present, and, if not, the system can follow up with a clarification (Xu and Rudnicky, 2000). This structured approach is expected to be less brittle than the statistical similarity and retrieval model implemented in Lukin et al.’s (2018) NLU component in this human-robot dialogue domain, which has difficulty generalizing to novel, unseen commands. We expect promising results from integrating DialogueAMR into our human-robot dialogue architecture. Furthermore, our annotation schema and corpus will contribute to a growing set of resources supporting meaning representation that goes beyond propositional content to model speaker intention in the conversational context. Acknowledgments W"
aggarwal-etal-2012-twins,H92-1073,0,\N,Missing
gratch-etal-2014-distress,W13-4032,1,\N,Missing
gratch-etal-2014-distress,brugman-russel-2004-annotating,0,\N,Missing
J08-4004,W98-1507,0,0.0780676,"Castellan. Submission received: 26 August 2005; revised submission received: 21 December 2007; accepted for publication: 28 January 2008. © 2008 Association for Computational Linguistics Computational Linguistics Volume 34, Number 4 were enormously inﬂuential, and K quickly became the de facto standard for measuring agreement in computational linguistics not only in work on discourse (Carletta et al. 1997; Core and Allen 1997; Hearst 1997; Poesio and Vieira 1998; Di Eugenio 2000; Stolcke et al. 2000; Carlson, Marcu, and Okurowski 2003) but also for other annotation tasks (e.g., V´eronis 1998; Bruce and Wiebe 1998; Stevenson and Gaizauskas 2000; Craggs and McGee Wood 2004; Mieskes and Strube 2006). During this period, however, a number of questions have also been raised about K and similar coefﬁcients—some already in Carletta’s own work (Carletta et al. 1997)—ranging from simple questions about the way the coefﬁcient is computed (e.g., whether it is really applicable when more than two coders are used), to debates about which levels of agreement can be considered ‘acceptable’ (Di Eugenio 2000; Craggs and McGee Wood 2005), to the realization that K is not appropriate for all types of agreement (Poesio a"
J08-4004,J96-2004,0,0.857273,"r areas of computational linguistics (CL). This soon led to worries about the subjectivity of the judgments required to create annotated resources, much greater for semantics and pragmatics than for the aspects of language interpretation of concern in the creation of early resources such as the Brown corpus (Francis and Kucera 1982), the British National Corpus (Leech, Garside, and Bryant 1994), or the Penn Treebank (Marcus, Marcinkiewicz, and Santorini 1993). Problems with early proposals for assessing coders’ agreement on discourse segmentation tasks (such as Passonneau and Litman 1993) led Carletta (1996) to suggest the adoption of the K coefﬁcient of agreement, a variant of Cohen’s κ (Cohen 1960), as this had already been used for similar purposes in content analysis for a long time.1 Carletta’s proposals ∗ Now at the Institute for Creative Technologies, University of Southern California, 13274 Fiji Way, Marina Del Rey, CA 90292. ∗∗ At the University of Essex: Department of Computing and Electronic Systems, University of Essex, Wivenhoe Park, Colchester, CO4 3SQ, UK. E-mail: poesio@essex.ac.uk. At the University of Trento: CIMeC, Universit`a degli Studi di Trento, Palazzo Fedrigotti, Corso Be"
J08-4004,J97-1002,0,0.0265824,"Missing"
J08-4004,J05-3001,0,0.0471299,"Missing"
J08-4004,di-eugenio-2000-usage,0,0.0200079,"Missing"
J08-4004,P98-1052,0,0.0727297,"Missing"
J08-4004,W01-1607,0,0.0268042,"barczy, Carroll, and Sampson 2006), let alone for discourse coding tasks such as dialogue act coding. We concentrate here on this latter type of coding, but a discussion of issues raised for POS, named entity, and prosodic coding can be found in the extended version of the article. Dialogue act tagging is a type of linguistic annotation with which by now the CL community has had extensive experience: Several dialogue-act-annotated spoken language corpora now exist, such as MapTask (Carletta et al. 1997), Switchboard (Stolcke et al. 2000), Verbmobil (Jekat et al. 1995), and Communicator (e.g., Doran et al. 2001), among others. Historically, dialogue act annotation was also one of the types of annotation that motivated the introduction in CL of chance-corrected coefﬁcients of agreement (Carletta et al. 1997) and, as we will see, it has been the type of annotation that has generated the most discussion concerning annotation methodology and measuring agreement. A number of coding schemes for dialogue acts have achieved values of K over 0.8 and have therefore been assumed to be reliable: For example, K = 0.83 for the 577 Computational Linguistics Volume 34, Number 4 13-tag MapTask coding scheme (Carletta"
J08-4004,W06-1318,0,0.0328439,"n to be performed by the addressee. At least in principle, an organization of this type opens up the possibility for coders to mark an utterance with the superclass (IAFA) in case they do not feel conﬁdent that the utterance satisﬁes the additional requirements for Open-option or Directive. This, in turn, would do away with the need to make a choice between these two options. This possibility wasn’t pursued in the studies using the original DAMSL that we are aware of (Core and Allen 1997; Di Eugenio 2000; Stent 2001), but was tested by Shriberg et al. (2004) and subsequent work, in particular Geertzen and Bunt (2006), who were speciﬁcally interested in the idea of using hierarchical schemes to measure partial agreement, and in addition experimented with weighted coefﬁcients of agreement for their hierarchical tagging scheme, speciﬁcally κ w . Geertzen and Bunt tested intercoder agreement with Bunt’s DIT++ (Bunt 2005), a scheme with 11 dimensions that builds on ideas from DAMSL and from Dynamic Interpretation Theory (Bunt 2000). In DIT++, tags can be hierarchically related: For example, the class information-seeking is viewed as consisting of two classes, yesno question (ynq) and wh-question (whq). The hie"
J08-4004,J86-3001,0,0.179667,"Missing"
J08-4004,J97-1003,0,0.197477,"by K. In what follows, we use κ to indicate Cohen’s original coefﬁcient and its generalization to more than two coders, and K for the coefﬁcient discussed by Siegel and Castellan. Submission received: 26 August 2005; revised submission received: 21 December 2007; accepted for publication: 28 January 2008. © 2008 Association for Computational Linguistics Computational Linguistics Volume 34, Number 4 were enormously inﬂuential, and K quickly became the de facto standard for measuring agreement in computational linguistics not only in work on discourse (Carletta et al. 1997; Core and Allen 1997; Hearst 1997; Poesio and Vieira 1998; Di Eugenio 2000; Stolcke et al. 2000; Carlson, Marcu, and Okurowski 2003) but also for other annotation tasks (e.g., V´eronis 1998; Bruce and Wiebe 1998; Stevenson and Gaizauskas 2000; Craggs and McGee Wood 2004; Mieskes and Strube 2006). During this period, however, a number of questions have also been raised about K and similar coefﬁcients—some already in Carletta’s own work (Carletta et al. 1997)—ranging from simple questions about the way the coefﬁcient is computed (e.g., whether it is really applicable when more than two coders are used), to debates about which l"
J08-4004,N06-2015,0,0.177165,"main headings: methodology, choice of coefﬁcients, and interpretation of coefﬁcients. 589 Computational Linguistics Volume 34, Number 4 5.1 Methodology Our ﬁrst recommendation is that annotation efforts should perform and report rigorous reliability testing. The last decade has already seen considerable improvement, from the absence of any tests for the Penn Treebank (Marcus, Marcinkiewicz, and Santorini 1993) or the British National Corpus (Leech, Garside, and Bryant 1994) to the central role played by reliability testing in the Penn Discourse Treebank (Miltsakaki et al. 2004) and OntoNotes (Hovy et al. 2006). But even the latter efforts only measure and report percent agreement. We believe that part of the reluctance to report chance-corrected measures is the difﬁculty in interpreting them. However, our experience is that chancecorrected coefﬁcients of agreement do provide a better indication of the quality of the resulting annotation than simple percent agreement, and moreover, the detailed calculations leading to the coefﬁcients can be very revealing as to where the disagreements are located and what their sources may be. A rigorous methodology for reliability testing does not, in our opinion,"
J08-4004,E99-1046,0,0.0728621,"enough to be useful (cf. Krippendorff 2004a, pages 213–214). In content analysis, conclusions are drawn directly from annotated corpora, so the emphasis is more on replicability; whereas in CL, corpora constitute a resource which is used by other processes, so the emphasis is more towards usefulness. There is also a tradeoff between the sophistication of judgments and the availability of coders who can make such judgments. Consequently, annotation by experts is often the only practical way to get useful corpora for CL. Current practice achieves high reliability either by using professionals (Kilgarriff 1999) or through intensive training (Hovy et al. 2006; Carlson, Marcu, and Okurowski 2003); this means that results are not replicable across sites, and are therefore less reliable than annotation by naive coders adhering to written instructions. We feel that inter-annotator agreement studies should still be carried out, as they serve as an assurance that the results are replicable when the annotators are chosen from the same population as the original annotators. An important additional assurance should be provided in the form of an independent evaluation of the task for which the corpus is used ("
J08-4004,C94-1103,0,0.107243,"Missing"
J08-4004,J93-2004,0,0.0623642,"Missing"
J08-4004,mieskes-strube-2006-part,0,0.0384854,"ecember 2007; accepted for publication: 28 January 2008. © 2008 Association for Computational Linguistics Computational Linguistics Volume 34, Number 4 were enormously inﬂuential, and K quickly became the de facto standard for measuring agreement in computational linguistics not only in work on discourse (Carletta et al. 1997; Core and Allen 1997; Hearst 1997; Poesio and Vieira 1998; Di Eugenio 2000; Stolcke et al. 2000; Carlson, Marcu, and Okurowski 2003) but also for other annotation tasks (e.g., V´eronis 1998; Bruce and Wiebe 1998; Stevenson and Gaizauskas 2000; Craggs and McGee Wood 2004; Mieskes and Strube 2006). During this period, however, a number of questions have also been raised about K and similar coefﬁcients—some already in Carletta’s own work (Carletta et al. 1997)—ranging from simple questions about the way the coefﬁcient is computed (e.g., whether it is really applicable when more than two coders are used), to debates about which levels of agreement can be considered ‘acceptable’ (Di Eugenio 2000; Craggs and McGee Wood 2005), to the realization that K is not appropriate for all types of agreement (Poesio and Vieira 1998; Marcu, Romera, and Amorrortu 1999; Di Eugenio 2000; Stevenson and Gai"
J08-4004,W04-0807,0,0.0167724,"Missing"
J08-4004,W04-2703,0,0.00940122,"ment. These can be grouped under three main headings: methodology, choice of coefﬁcients, and interpretation of coefﬁcients. 589 Computational Linguistics Volume 34, Number 4 5.1 Methodology Our ﬁrst recommendation is that annotation efforts should perform and report rigorous reliability testing. The last decade has already seen considerable improvement, from the absence of any tests for the Penn Treebank (Marcus, Marcinkiewicz, and Santorini 1993) or the British National Corpus (Leech, Garside, and Bryant 1994) to the central role played by reliability testing in the Penn Discourse Treebank (Miltsakaki et al. 2004) and OntoNotes (Hovy et al. 2006). But even the latter efforts only measure and report percent agreement. We believe that part of the reluctance to report chance-corrected measures is the difﬁculty in interpreting them. However, our experience is that chancecorrected coefﬁcients of agreement do provide a better indication of the quality of the resulting annotation than simple percent agreement, and moreover, the detailed calculations leading to the coefﬁcients can be very revealing as to where the disagreements are located and what their sources may be. A rigorous methodology for reliability t"
J08-4004,W00-1007,0,0.0214899,"d next. 4.4.3 Discourse Deixis. A second annotation study we carried out (Artstein and Poesio 2006) shows even more clearly the possible side effects of using weighted coefﬁcients. This study was concerned with the annotation of the antecedents of references to abstract objects, such as the example of the pronoun that in utterance 7.6 (TRAINS 1991, dialogue d91-2.2). 7.3 7.4 7.5 7.6 : : : : so we ship one boxcar of oranges to Elmira and that takes another 2 hours Previous studies of discourse deixis annotation showed that these are extremely difﬁcult judgments to make (Eckert and Strube 2000; Navarretta 2000; Byron 2002), except perhaps for identifying the type of object (Poesio and Modjeska 2005), so we simpliﬁed the task by only requiring our participants to identify the boundaries of the area of text in which the antecedent was introduced. Even so, we found a great variety in how these boundaries were marked: Exactly as in the case of discourse segmentation discussed earlier, our participants broadly agreed on the area of text, but disagreed on 0.7 Chain K α None Partial Full 0.628 0.563 0.480 0.656 0.677 0.691 α K α α 0.6 K 0.5 0.4 K no chain partial chain full chain Figure 3 A comparison of"
J08-4004,N04-1019,0,0.00655755,"t by using individual coder marginals (κ) or pooled distributions (K) can lead to reliability values falling on different sides of the accepted 0.67 threshold, and recommended reporting both values. Craggs and McGee Wood argued, following Krippendorff (2004a,b), that measures like Cohen’s κ are inappropriate for measuring agreement. Finally, Passonneau has been advocating the use of Krippendorff’s α (Krippendorff 1980, 2004a) for coding tasks in CL which do not involve nominal and disjoint categories, including anaphoric annotation, wordsense tagging, and summarization (Passonneau 2004, 2006; Nenkova and Passonneau 2004; Passonneau, Habash, and Rambow 2006). Now that more than ten years have passed since Carletta’s original presentation at the workshop on Empirical Methods in Discourse, it is time to reconsider the use of coefﬁcients of agreement in CL in a systematic way. In this article, a survey of coefﬁcients of agreement and their use in CL, we have three main goals. First, we discuss in some detail the mathematics and underlying assumptions of the coefﬁcients used or mentioned in the CL and content analysis literatures. Second, we also cover in some detail Krippendorff’s α, often mentioned but never re"
J08-4004,passonneau-2004-computing,0,0.0606495,"ulating chance agreement by using individual coder marginals (κ) or pooled distributions (K) can lead to reliability values falling on different sides of the accepted 0.67 threshold, and recommended reporting both values. Craggs and McGee Wood argued, following Krippendorff (2004a,b), that measures like Cohen’s κ are inappropriate for measuring agreement. Finally, Passonneau has been advocating the use of Krippendorff’s α (Krippendorff 1980, 2004a) for coding tasks in CL which do not involve nominal and disjoint categories, including anaphoric annotation, wordsense tagging, and summarization (Passonneau 2004, 2006; Nenkova and Passonneau 2004; Passonneau, Habash, and Rambow 2006). Now that more than ten years have passed since Carletta’s original presentation at the workshop on Empirical Methods in Discourse, it is time to reconsider the use of coefﬁcients of agreement in CL in a systematic way. In this article, a survey of coefﬁcients of agreement and their use in CL, we have three main goals. First, we discuss in some detail the mathematics and underlying assumptions of the coefﬁcients used or mentioned in the CL and content analysis literatures. Second, we also cover in some detail Krippendorf"
J08-4004,passonneau-2006-measuring,0,0.431865,"et relation are closer (less distant) than ones that merely intersect. This leads to the following distance metric between two sets A and B.  0 if   1 /3 if dP = 2 / if    3 1 if A=B A ⊂ B or B ⊂ A A ∩ B = ∅, but A ⊂ B and B ⊂ A A∩B = ∅ Alternative distance metrics take the size of the anaphoric chain into account, based on measures used to compare sets in Information Retrieval, such as the coefﬁcient of community of Jaccard (1912) and the coincidence index of Dice (1945) (Manning and ¨ Schutze 1999). Jaccard: d J = 1 − |A ∩ B| |A ∪ B| Dice: d D = 1 − 2 |A ∩ B| |A |+ |B| In later work, Passonneau (2006) offers a reﬁned distance metric which she called MASI (Measuring Agreement on Set-valued Items), obtained by multiplying Passonneau’s original metric d P by the metric derived from Jaccard d J . d M = dP × d J 4.4.2 Experience with α for Anaphoric Annotation. In the experiment mentioned previously (Poesio and Artstein 2005) we used 18 coders to test α and K under a variety of conditions. We found that even though our coders by and large agreed on the interpretation of anaphoric expressions, virtually no coder ever identiﬁed all the mentions of a discourse entity. As a result, even though the"
J08-4004,passonneau-etal-2006-inter,0,0.142739,"Missing"
J08-4004,P93-1020,0,0.0570518,"e same empirical footing as other areas of computational linguistics (CL). This soon led to worries about the subjectivity of the judgments required to create annotated resources, much greater for semantics and pragmatics than for the aspects of language interpretation of concern in the creation of early resources such as the Brown corpus (Francis and Kucera 1982), the British National Corpus (Leech, Garside, and Bryant 1994), or the Penn Treebank (Marcus, Marcinkiewicz, and Santorini 1993). Problems with early proposals for assessing coders’ agreement on discourse segmentation tasks (such as Passonneau and Litman 1993) led Carletta (1996) to suggest the adoption of the K coefﬁcient of agreement, a variant of Cohen’s κ (Cohen 1960), as this had already been used for similar purposes in content analysis for a long time.1 Carletta’s proposals ∗ Now at the Institute for Creative Technologies, University of Southern California, 13274 Fiji Way, Marina Del Rey, CA 90292. ∗∗ At the University of Essex: Department of Computing and Electronic Systems, University of Essex, Wivenhoe Park, Colchester, CO4 3SQ, UK. E-mail: poesio@essex.ac.uk. At the University of Trento: CIMeC, Universit`a degli Studi di Trento, Palazzo"
J08-4004,J97-1005,0,0.0215495,"Missing"
J08-4004,J02-1002,0,0.0336925,"ng several units, as done in the methods proposed to evaluate the performance of topic detection algorithms such as 581 Computational Linguistics Volume 34, Number 4 Table 8 Fewer boundaries, higher expected agreement. Case 1: Broad segments Ao = 0.96, Ae = 0.89, K = 0.65 C ODER A C ODER B B OUNDARY N O B OUNDARY T OTAL B OUNDARY N O B OUNDARY T OTAL 2 1 3 1 46 47 3 47 50 Case 2: Fine discourse units Ao = 0.88, Ae = 0.53, K = 0.75 C ODER A C ODER B B OUNDARY N O B OUNDARY T OTAL B OUNDARY N O B OUNDARY T OTAL 16 3 19 3 28 31 19 31 50 Pk (Beeferman, Berger, and Lafferty 1999) or W INDOW D IFF (Pevzner and Hearst 2002) (which are, however, raw agreement scores not corrected for chance). 4.3.2 Unitizing (Or, Agreement on Markable Identiﬁcation). It is often assumed in CL annotation practice that the units of analysis are “natural” linguistic objects, and therefore there is no need to check agreement on their identiﬁcation. As a result, agreement is usually measured on the labeling of units rather than on the process of identifying them (unitizing, Krippendorff 1995). We have just seen, however, two coding tasks for which the reliability of unit identiﬁcation is a crucial part of the overall reliability, and"
J08-4004,W04-0210,1,0.0907393,"ies and Unitizing Before labeling can take place, the units of annotation, or markables, need to be identiﬁed—a process Krippendorff (1995, 2004a) calls unitizing. The practice in CL for the forms of annotation discussed in the previous section is to assume that the units are linguistic constituents which can be easily identiﬁed, such as words, utterances, or noun phrases, and therefore there is no need to check the reliability of this process. We are aware of few exceptions to this assumption, such as Carletta et al. (1997) on unitization for move coding and our own work on the GNOME corpus (Poesio 2004b). In cases such as text segmentation, however, the identiﬁcation of units is as important as their labeling, if not more important, and therefore checking agreement on unit identiﬁcation is essential. In this section we discuss current CL practice with reliability testing of these types of annotation, before brieﬂy summarizing Krippendorff’s proposals concerning measuring reliability for unitizing. 4.3.1 Segmentation and Topic Marking. Discourse segments are portions of text that constitute a unit either because they are about the same “topic” (Hearst 1997; Reynar 1998) or because they have"
J08-4004,W04-2327,1,0.116185,"ies and Unitizing Before labeling can take place, the units of annotation, or markables, need to be identiﬁed—a process Krippendorff (1995, 2004a) calls unitizing. The practice in CL for the forms of annotation discussed in the previous section is to assume that the units are linguistic constituents which can be easily identiﬁed, such as words, utterances, or noun phrases, and therefore there is no need to check the reliability of this process. We are aware of few exceptions to this assumption, such as Carletta et al. (1997) on unitization for move coding and our own work on the GNOME corpus (Poesio 2004b). In cases such as text segmentation, however, the identiﬁcation of units is as important as their labeling, if not more important, and therefore checking agreement on unit identiﬁcation is essential. In this section we discuss current CL practice with reliability testing of these types of annotation, before brieﬂy summarizing Krippendorff’s proposals concerning measuring reliability for unitizing. 4.3.1 Segmentation and Topic Marking. Discourse segments are portions of text that constitute a unit either because they are about the same “topic” (Hearst 1997; Reynar 1998) or because they have"
J08-4004,W05-0311,1,0.212648,"ly that multiple coders increase reliability: The variance of the individual coders’ distributions can be just as large with many coders as with few coders, but its effect on the value of κ decreases as the number of coders grows, and becomes more similar to random noise. The same holds for weighted measures too; see the extended version of this article for deﬁnitions and proof. In an annotation study with 18 subjects, we compared α with a variant which uses individual coder distributions to calculate expected agreement, and found that the values never differed beyond the third decimal point (Poesio and Artstein 2005). We conclude with a summary of our views concerning the difference between πstyle and κ-style coefﬁcients. First of all, keep in mind that empirically the difference is small, and gets smaller as the number of annotators increases. Then instead of reporting two coefﬁcients, as suggested by Di Eugenio and Glass (2004), the appropriate coefﬁcient should be chosen based on the task (not on the observed differences between coder marginals). When the coefﬁcient is used to assess reliability, a single-distribution coefﬁcient like π or α should be used; this is indeed already the practice in CL, bec"
J08-4004,J98-2001,1,0.107964,"follows, we use κ to indicate Cohen’s original coefﬁcient and its generalization to more than two coders, and K for the coefﬁcient discussed by Siegel and Castellan. Submission received: 26 August 2005; revised submission received: 21 December 2007; accepted for publication: 28 January 2008. © 2008 Association for Computational Linguistics Computational Linguistics Volume 34, Number 4 were enormously inﬂuential, and K quickly became the de facto standard for measuring agreement in computational linguistics not only in work on discourse (Carletta et al. 1997; Core and Allen 1997; Hearst 1997; Poesio and Vieira 1998; Di Eugenio 2000; Stolcke et al. 2000; Carlson, Marcu, and Okurowski 2003) but also for other annotation tasks (e.g., V´eronis 1998; Bruce and Wiebe 1998; Stevenson and Gaizauskas 2000; Craggs and McGee Wood 2004; Mieskes and Strube 2006). During this period, however, a number of questions have also been raised about K and similar coefﬁcients—some already in Carletta’s own work (Carletta et al. 1997)—ranging from simple questions about the way the coefﬁcient is computed (e.g., whether it is really applicable when more than two coders are used), to debates about which levels of agreement can b"
J08-4004,J08-3001,0,0.233261,"re appropriate for many annotation tasks, make the issue of deciding when the value of a coefﬁcient indicates sufﬁcient agreement even K= 0.0 Poor 0.2 Slight 0.4 Fair 0.6 Moderate 0.8 Substantial Figure 1 Kappa values and strength of agreement according to Landis and Koch (1977). 576 1.0 Perfect Artstein and Poesio Inter-Coder Agreement for CL more complicated because of the problem of determining appropriate weights (see Section 4.4). We will return to the issue of interpreting the value of the coefﬁcients at the end of this article. 4.1.4 Agreement and Machine Learning. In a recent article, Reidsma and Carletta (2008) point out that the goals of annotation in CL differ from those of content analysis, where agreement coefﬁcients originate. A common use of an annotated corpus in CL is not to conﬁrm or reject a hypothesis, but to generalize the patterns using machine-learning algorithms. Through a series of simulations, Reidsma and Carletta demonstrate that agreement coefﬁcients are poor predictors of machine-learning success: Even highly reproducible annotations are difﬁcult to generalize when the disagreements contain patterns that can be learned, whereas highly noisy and unreliable data can be generalized"
J08-4004,N04-4020,0,0.0258176,"computing agreement proposed here could could also be used to allow coders to choose either a more speciﬁc label or one of Palmer, Dang, and Fellbaum’s superlabels. For example, suppose A sticks to WN1, but B decides to mark the use above using Palmer, Dang, and Fellbaum’s LABEL category, then we would still ﬁnd a distance d = 1/3. An alternative way of using α for word sense annotation was developed and tested by Passonneau, Habash, and Rambow (2006). Their approach is to allow coders to assign multiple labels (WordNet synsets) for wordsenses, as done by V´eronis (1998) and more recently by Rosenberg and Binkowski (2004) for text classiﬁcation labels and by Poesio and Artstein (2005) for anaphora. These multi-label sets can then be compared using the MASI distance metric for α (Passonneau 2006). 5. Conclusions The purpose of this article has been to expose the reader to the mathematics of chancecorrected coefﬁcients of agreement as well as the current state of the art of using these coefﬁcients in CL. Our hope is that readers come to view agreement studies not as an additional chore or hurdle for publication, but as a tool for analysis which offers new insights into the annotation process. We conclude by summ"
J08-4004,W04-2319,0,0.0265492,"erg, and Biasca (1997), which incorporates many ideas from the “multi-dimensional” theories of dialogue acts, but does not allow marking an utterance as both an acknowledgment and a statement; a choice has to be made. This tagset results in overall agreement of K = 0.80. Interestingly, subsequent developments of SWITCHBOARD-DAMSL backtracked on some of these decisions. For instance, the ICSI-MRDA tagset developed for the annotation of the ICSI Meeting Recorder corpus reintroduces some of the DAMSL ideas, in that annotators are allowed to assign multiple SWITCHBOARD-DAMSL labels to utterances (Shriberg et al. 2004). Shriberg et al. achieved a comparable reliability to that obtained with SWITCHBOARD-DAMSL, but only when using a tagset of just ﬁve “class-maps”. Shriberg et al. (2004) also introduced a hierarchical organization of tags to improve reliability. The dimensions of the DAMSL scheme can be viewed as “superclasses” of dialogue acts which share some aspect of their meaning. For instance, the dimension of Influencing-Addressee-Future-Action (IAFA) includes the two dialogue acts Open-option (used to mark suggestions) and Directive, both of which bring into 578 Artstein and Poesio Inter-Coder Agreeme"
J08-4004,A00-1012,0,0.00727323,"received: 26 August 2005; revised submission received: 21 December 2007; accepted for publication: 28 January 2008. © 2008 Association for Computational Linguistics Computational Linguistics Volume 34, Number 4 were enormously inﬂuential, and K quickly became the de facto standard for measuring agreement in computational linguistics not only in work on discourse (Carletta et al. 1997; Core and Allen 1997; Hearst 1997; Poesio and Vieira 1998; Di Eugenio 2000; Stolcke et al. 2000; Carlson, Marcu, and Okurowski 2003) but also for other annotation tasks (e.g., V´eronis 1998; Bruce and Wiebe 1998; Stevenson and Gaizauskas 2000; Craggs and McGee Wood 2004; Mieskes and Strube 2006). During this period, however, a number of questions have also been raised about K and similar coefﬁcients—some already in Carletta’s own work (Carletta et al. 1997)—ranging from simple questions about the way the coefﬁcient is computed (e.g., whether it is really applicable when more than two coders are used), to debates about which levels of agreement can be considered ‘acceptable’ (Di Eugenio 2000; Craggs and McGee Wood 2005), to the realization that K is not appropriate for all types of agreement (Poesio and Vieira 1998; Marcu, Romera,"
J08-4004,J00-3003,0,0.109726,"Missing"
J08-4004,E99-1015,0,0.0753719,"Missing"
J08-4004,J02-4002,0,0.0397052,"Missing"
J08-4004,M95-1005,0,0.0295577,"ent on such sets, and 8 ftp://ftp.cs.rochester.edu/pub/papers/ai/92.tn1.trains 91 dialogues.txt. 583 Computational Linguistics Volume 34, Number 4 consequently it raises serious questions about weighted measures—in particular, about the interpretability of the results, as we will see shortly. 4.4.1 Passonneau’s Proposal. Passonneau (2004) recommends measuring agreement on anaphoric annotation by using sets of mentions of discourse entities as labels, that is, the emerging anaphoric/coreference chains. This proposal is in line with the methods developed to evaluate anaphora resolution systems (Vilain et al. 1995). But using anaphoric chains as labels would not make unweighted measures such as K a good measure for agreement. Practical experience suggests that, except when a text is very short, few annotators will catch all mentions of a discourse entity: Most will forget to mark a few, with the result that the chains (that is, category labels) differ from coder to coder and agreement as measured with K is always very low. What is needed is a coefﬁcient that also allows for partial disagreement between judgments, when two annotators agree on part of the coreference chain but not on all of it. Passonneau"
J08-4004,J96-3006,0,\N,Missing
J08-4004,brants-plaehn-2000-interactive,0,\N,Missing
J08-4004,sekine-etal-2002-extended,0,\N,Missing
J08-4004,W03-1903,0,\N,Missing
J08-4004,W01-1605,0,\N,Missing
J08-4004,P02-1011,0,\N,Missing
J08-4004,P03-1048,0,\N,Missing
J08-4004,doddington-etal-2004-automatic,0,\N,Missing
J08-4004,buhmann-etal-2002-annotation,0,\N,Missing
J08-4004,wayne-2000-multilingual,0,\N,Missing
J08-4004,J09-4005,0,\N,Missing
L16-1326,doddington-etal-2004-automatic,0,0.117394,"e can not participate in a coreference chain. In a few cases, these constraints revealed intriguing cases of anaphoric expressions. Mostly, however, they have helped us identify and eliminate clear annotation errors. We will provide more details on our approach in Section 4. below. 3. ARRAU and other coreferentially annotated corpora The ARRAU guidelines focus on more detailed representation of linguistic phenomena related to anaphora and coreference. In this section, we highlight the main differences between ARRAU and two other commonly used corpora annotated for coreference in English, ACE (Doddington et al., 2004) and OntoNotes (Pradhan et al., 2011; Pradhan et al., 2012). Table 2 provides a summary of the most distinctive features of ARRAU as opposed to ACE and OntoNotes. The most prominent feature of ARRAU is its rich linguistically motivated annotation of markables. To start with, each nominal markables is shown with its minimal and maximal span. This solution is in line with the ACE annotation guidelines and has unfortunately been discarded for the OntoNotes dataset in order to decrease the annotation price and thus augment the corpus size. The maximal span corresponds to the full noun phrase, wher"
L16-1326,W11-1916,0,0.0174322,"nts with head-finding rules, one might expect to extract the minimal span for each NP rather reliably. It has been shown, however, that naive parsing-based heuristics do not lead to the best performance and a coreference resolver might benefit considerably from explicit or latent identification of minimal spans or heads (Zhekova and K¨ubler, 2013; Peng et al., 2015). Moreover, explicitly annotated minimal spans allow for better lenient matching that has been shown to improve the training procedure of coreference resolvers through better alignment of automatically extracted and gold markables (Kummerfeld et al., 2011). We believe therefore that the combination of minimal and maximal spans is the most reliable way of annotating markable boundaries for coreference. In the second release of ARRAU, we provide minimal and maximal spans for all the domains. In ARRAU, we focus on different types of noun phrases. In particular, we label markables that do not participate in coreference chains: singletons and non-referentials. The ACE guidelines restrict the annotation scope to referentials1 , whereas OntoNotes only marks co-referential (no singletons) markables. As Table 3 shows, non-referentials and singletons acc"
L16-1326,K15-1002,0,0.0525315,"rresponds to the head noun or to the bare named entity for complex NE-nominals. With the latest development in the parsing technology, it might seem redundant to include minimal spans in the manual annotation directly: using dependencies or constituents with head-finding rules, one might expect to extract the minimal span for each NP rather reliably. It has been shown, however, that naive parsing-based heuristics do not lead to the best performance and a coreference resolver might benefit considerably from explicit or latent identification of minimal spans or heads (Zhekova and K¨ubler, 2013; Peng et al., 2015). Moreover, explicitly annotated minimal spans allow for better lenient matching that has been shown to improve the training procedure of coreference resolvers through better alignment of automatically extracted and gold markables (Kummerfeld et al., 2011). We believe therefore that the combination of minimal and maximal spans is the most reliable way of annotating markable boundaries for coreference. In the second release of ARRAU, we provide minimal and maximal spans for all the domains. In ARRAU, we focus on different types of noun phrases. In particular, we label markables that do not part"
L16-1326,poesio-artstein-2008-anaphoric,1,0.83521,"task achieve robust performance on relatively easy cases of coreference, especially since the vast model optimization efforts have been undertaken by various research groups for the recent SemEval and CoNLL coreference resolution tracks (Recasens et al., 2010; Pradhan et al., 2011; Pradhan et al., 2012). More complex cases have been identified and investigated since the first years of research on coreference resolution, however, they have been out of the scope of the mainstream community till very recently. One of the main reasons is the lack of appropriate datasets. Since its first release (Poesio and Artstein, 2008), the ARRAU corpus has been used, on one hand, for research on more complex coreference phenomena, and, on the other hand, as a reference point for annotating coreference corpora in other languages. The current paper presents the second release of ARRAU. For the second release we have not only focused on augmenting the number of covered documents, but also invested a considerable effort into improving the data quality. This involved annotating more attributes and designing a methodology for cleaning up the annotations. The former allows to use ARRAU for a variety of coreference-related problem"
L16-1326,W11-1901,0,0.116866,"ywords: Discourse, Anaphora, Coreference 1. Introduction Coreference resolution is a crucial step in deep text understanding and as such is a vital prerequisite for a variety of high-level natural processing tasks, ranging from information extraction to summarization or machine translation. State-of-the-art statistical approaches to the task achieve robust performance on relatively easy cases of coreference, especially since the vast model optimization efforts have been undertaken by various research groups for the recent SemEval and CoNLL coreference resolution tracks (Recasens et al., 2010; Pradhan et al., 2011; Pradhan et al., 2012). More complex cases have been identified and investigated since the first years of research on coreference resolution, however, they have been out of the scope of the mainstream community till very recently. One of the main reasons is the lack of appropriate datasets. Since its first release (Poesio and Artstein, 2008), the ARRAU corpus has been used, on one hand, for research on more complex coreference phenomena, and, on the other hand, as a reference point for annotating coreference corpora in other languages. The current paper presents the second release of ARRAU. F"
L16-1326,W12-4501,1,0.90767,"phora, Coreference 1. Introduction Coreference resolution is a crucial step in deep text understanding and as such is a vital prerequisite for a variety of high-level natural processing tasks, ranging from information extraction to summarization or machine translation. State-of-the-art statistical approaches to the task achieve robust performance on relatively easy cases of coreference, especially since the vast model optimization efforts have been undertaken by various research groups for the recent SemEval and CoNLL coreference resolution tracks (Recasens et al., 2010; Pradhan et al., 2011; Pradhan et al., 2012). More complex cases have been identified and investigated since the first years of research on coreference resolution, however, they have been out of the scope of the mainstream community till very recently. One of the main reasons is the lack of appropriate datasets. Since its first release (Poesio and Artstein, 2008), the ARRAU corpus has been used, on one hand, for research on more complex coreference phenomena, and, on the other hand, as a reference point for annotating coreference corpora in other languages. The current paper presents the second release of ARRAU. For the second release w"
L16-1326,S10-1001,1,0.894033,"Missing"
L16-1326,R13-1097,0,0.0359572,"Missing"
L16-1501,C14-2023,0,0.026127,"Missing"
L16-1501,passonneau-2006-measuring,0,0.0343287,"was done using Synchronous Context-Free Grammar (SCFG) (Aho and Ullman, 1972), where we defined the SCFG rules for both the natural language and the semantic language.6 Then, in real-time, the NLG used a quick look-up in this mapping to translate the agent’s outputs. 3.5. Annotation Once dialogue collection was completed, two independent annotators annotated the corpus following the annotation guidelines7 . Disagreements were resolved by the WOZ person as the arbitrator. As a metric of inter-annotator agreement we used Krippendorff’s α with MASI distance that supports multi-label annotation (Passonneau, 2006), as implemented in the DKPro Agreement package (Meyer et al., 2014).8 The inter-annotator agreement before reconciliation was 0.89 and after reconciliation became 0.95. The annotators were instructed to take the context of the dialogue into account while annotating each utterance. For example, the annotation of the following utterance could depend on the context of the dialogue: OK, let’s move to pension fund If this utterance is a reply to some Offer, then it would most likely be annotated as Accept, referring to the previous Offer, along with Query(Offer=Pension Fund). However, if 6 The scr"
L18-1017,bunt-etal-2012-iso,1,0.79484,"pplications of these annotations are introduced. Keywords: dialogue structure annotation, human-robot interaction, multiparty dialogue 1. Introduction We present an annotation scheme for meso-level dialogue structure (Traum and Nakatani, 1999), specifically designed for multi-floor dialogue. The scheme includes both a transaction unit for clustering utterances from multiple participants and floors that contribute to realization of an initiating participant’s intent, and relations between individual utterances within the unit. While there are standard annotation schemes for both dialogue acts (Bunt et al., 2012) and discourse relations (Prasad and Bunt, 2015), these schemes do not fully address the issues of dialogue structure. Of particular interest to us, and not previously addressed in other schemes, are cases in which the units and relations span across multiple conversational floors. Dialogues can be characterized by distinct information states (Traum and Larsson, 2003). These include sets of participants, participant roles (e.g. active, ratified participant vs. overhearer), turn-taking or floor-holding, expectation of how many participants will make substantial contributions at a time (Edelsky,"
L18-1017,J86-3001,0,0.827712,"ferent kinds of multi-party, multi-floor contributions. This is addressed by analysis of dialogue annotated with this scheme and the kinds of patterns of interaction that are observed (see section 5). Second, we use data from the corpus annotated with this scheme to serve as training and evaluation data for creating automated multicommunicators (see section 6). 2. Annotation Scheme We annotate two aspects of Dialogue Structure at the mesolevel (bigger than a single speaker-turn, but smaller than a complete dialogue activity) (Traum and Nakatani, 1999). First, we look at intentional structure (Grosz and Sidner, 1986), consisting of units of dialogue utterances that all have a role in explicating and addressing an initiating participant’s intention. Second, we look at the relations between different utterances within this unit, which reveal 104 Expansions Responses Translations processing: relate utterances that are produced by the same participant within the same floor. relate utterances by different participants within the same floor. relate utterances in different floors. acknowledgement: Table 1: Top Level Corpus Relations how the information state of participants in the dialogue is updated as the unit"
L18-1017,W17-2808,1,0.455485,"t apply this annotation scheme to a corpus of humanrobot interaction, taken from a project with a long-term goal to create an autonomous robot intelligence that can collaborate with remotely located human participants on exploration and navigation tasks. In the initial versions, a human “Commander” tasks the robot verbally, and gets feedback via multiple modalities, including text messages, a live 2Dmap built from the robot’s LIDAR scanner, and still photos captured from the robot’s front-facing camera. In order to collect sufficient information about the type of language used by a Commander (Marge et al., 2017), and provide training data to support development of appropriate language processing components, the development of the autonomous human-robot interaction begins with a series of “Wizard of Oz” experiments (Marge et al., 2016; Bonial et al., 2017), where the robot is controlled by two wizards, with an internal communication floor, distinct from the floor used by the Commander to communicate with the robot. The wizards include a Dialogue Manager (DMWizard, or DM) who handles communication to the Commander and “speaks” via text messages (Bonial et al., 2017) and a Robot Navigator (RN-Wizard, or"
L18-1017,passonneau-2006-measuring,0,0.130273,"Missing"
L18-1017,W15-0210,0,0.0252823,"ced. Keywords: dialogue structure annotation, human-robot interaction, multiparty dialogue 1. Introduction We present an annotation scheme for meso-level dialogue structure (Traum and Nakatani, 1999), specifically designed for multi-floor dialogue. The scheme includes both a transaction unit for clustering utterances from multiple participants and floors that contribute to realization of an initiating participant’s intent, and relations between individual utterances within the unit. While there are standard annotation schemes for both dialogue acts (Bunt et al., 2012) and discourse relations (Prasad and Bunt, 2015), these schemes do not fully address the issues of dialogue structure. Of particular interest to us, and not previously addressed in other schemes, are cases in which the units and relations span across multiple conversational floors. Dialogues can be characterized by distinct information states (Traum and Larsson, 2003). These include sets of participants, participant roles (e.g. active, ratified participant vs. overhearer), turn-taking or floor-holding, expectation of how many participants will make substantial contributions at a time (Edelsky, 1981), and other factors. Often distinct dialog"
L18-1017,W99-0313,1,0.538189,"ation of an initiator’s intent, and relations between individual utterances within the unit. We apply this scheme to annotate a corpus of multi-floor human-robot interaction dialogues. We examine the patterns of structure observed in these dialogues and present inter-annotator statistics and relative frequencies of types of relations and transaction units. Finally, some example applications of these annotations are introduced. Keywords: dialogue structure annotation, human-robot interaction, multiparty dialogue 1. Introduction We present an annotation scheme for meso-level dialogue structure (Traum and Nakatani, 1999), specifically designed for multi-floor dialogue. The scheme includes both a transaction unit for clustering utterances from multiple participants and floors that contribute to realization of an initiating participant’s intent, and relations between individual utterances within the unit. While there are standard annotation schemes for both dialogue acts (Bunt et al., 2012) and discourse relations (Prasad and Bunt, 2015), these schemes do not fully address the issues of dialogue structure. Of particular interest to us, and not previously addressed in other schemes, are cases in which the units"
L18-1463,brugman-russel-2004-annotating,0,0.183201,"Missing"
L18-1532,W17-5544,1,0.816389,"s and responses: for our agent, the questions are requests for particular stories, and the responses are the stories themselves. For example, a user might ask Do you know a story about foxes? and the classifier will find the most appropriate response. The agent can also make statements about itself, as well as greetings and closings to maintain dialogue flow. Some previous applications using NPCEditor include virtual museum guides (Swartout et al., 2010), a system for coversation with Holocaust survivors (Traum et al., 2015), and a Facebook Messenger chatbot to answer sexual health questions (Brixey et al., 2017) Finally, the corpus serves as a repository for teaching and learning the language. As nearly all of the text entries are bilingual, learners and teachers alike can benefit from the translations. 6. Discussion and Conclusions This paper introduced a multimodal data set of the low resource American indigenous language Choctaw. This data set comprises more than 50,000 word tokens in text, many with English translation, and 400 minutes of oral examples from audio and video. Future work aims to continuously develop the data set as new publications are released. Future work will also include unpubl"
L18-1532,L16-1467,0,0.0189017,"As the data set includes both audio and their transcriptions, an automatic speech recognition system could be developed. One potential NLP use case is machine translation (MT). The majority of the data in our corpus is translated in English, creating a well-formed parallel data set. The language presents interesting challenges in this domain, as morphologically rich languages pose problems for MT systems from errors in word-alignment and multiple affixes. Current alignment models at word-level do not distinguish words and morphemes, and produce low-quality end translation due to misalignment (Li et al., 2016). The small size of the data set would encourage novel approaches for a MT model, as there is not enough data to use many machine learning techniques. However, as no system yet exists, a MT system would assist in generating new texts in Choctaw from English. Cultural immersion is another use case for the corpus. Storytelling is an important means for sharing cultural norms and beliefs. We built an interactive bilingual textbased conversational agent that shares stories and parables about animals from the corpus. The agent was built using NPCEditor, a response classifier and dialogue management"
L18-1683,P16-1170,0,0.0764105,"rovide a crowd-sourcing methodology to offload complex annotation between expert users and novice users and evaluate them. This is particularly useful for creating a sizable corpus. 2. Related Work Recently, there has been a lot of work on applications that combine vision and language, e.g., understanding and generating image descriptions (Kulkarni et al., 2013), identifying visual reference in the presence of distractors (Paetzel et al., 2015; de Vries et al., 2016), visual question answering (Antol et al., 2015), visual storytelling (Huang et al., 2016), generating questions about an image (Mostafazadeh et al., 2016), and question-answer interactions grounded on information shown in an image (Mostafazadeh et al., 2017). Current image and language corpora typically consist of digital photographs paired with crowd-sourced captions (Lin et al., 2014; Krishna et al., 2017), or in some cases with questions related to those images (Mostafazadeh et al., 2016). Much of the work above is relevant to the problem at hand. For example, understanding image descriptions is crucial for interpreting the requests quoted above, as all of them contain image descriptions (my wedding dress; my dog’s eyes; the people in the ba"
L18-1683,I17-1047,0,0.0714646,"and evaluate them. This is particularly useful for creating a sizable corpus. 2. Related Work Recently, there has been a lot of work on applications that combine vision and language, e.g., understanding and generating image descriptions (Kulkarni et al., 2013), identifying visual reference in the presence of distractors (Paetzel et al., 2015; de Vries et al., 2016), visual question answering (Antol et al., 2015), visual storytelling (Huang et al., 2016), generating questions about an image (Mostafazadeh et al., 2016), and question-answer interactions grounded on information shown in an image (Mostafazadeh et al., 2017). Current image and language corpora typically consist of digital photographs paired with crowd-sourced captions (Lin et al., 2014; Krishna et al., 2017), or in some cases with questions related to those images (Mostafazadeh et al., 2016). Much of the work above is relevant to the problem at hand. For example, understanding image descriptions is crucial for interpreting the requests quoted above, as all of them contain image descriptions (my wedding dress; my dog’s eyes; the people in the background; my ex). However, to our knowledge, no work has yet attempted to tackle the specific task of au"
L18-1683,W15-4610,1,0.637423,"reference to objects in the images. Second, a framework for understanding these natural language instructions and mapping them to actionable computer commands. Finally, we provide a crowd-sourcing methodology to offload complex annotation between expert users and novice users and evaluate them. This is particularly useful for creating a sizable corpus. 2. Related Work Recently, there has been a lot of work on applications that combine vision and language, e.g., understanding and generating image descriptions (Kulkarni et al., 2013), identifying visual reference in the presence of distractors (Paetzel et al., 2015; de Vries et al., 2016), visual question answering (Antol et al., 2015), visual storytelling (Huang et al., 2016), generating questions about an image (Mostafazadeh et al., 2016), and question-answer interactions grounded on information shown in an image (Mostafazadeh et al., 2017). Current image and language corpora typically consist of digital photographs paired with crowd-sourced captions (Lin et al., 2014; Krishna et al., 2017), or in some cases with questions related to those images (Mostafazadeh et al., 2016). Much of the work above is relevant to the problem at hand. For example, under"
L18-1683,W15-4622,0,0.098124,"Missing"
N16-3007,2005.sigdial-1.14,0,0.0452554,"The dialogue management logic is designed to deal with instances where the classifier cannot identify a good direct response. During training, NPCEditor calculates a response threshold based on the classifier’s confidence in the appropriateness of selected responses; at runtime, if the confidence for a selected response falls below the predetermined threshold, that response is replaced with an “off-topic” utterance that asks the user to repeat the question or takes initiative and changes the topic (Leuski et al., 2006); such failure to return a direct response, also called non-understanding (Bohus and Rudnicky, 2005), is usually preferred over returning an inappropriate one (misunderstanding). The current system uses a five-stage off-topic selection algorithm which is an extension of that presented in Artstein et al. (2009). Figure 1 shows a sample dialogue illustrating the handling of nonunderstanding. 33 User Hello Pinchas, how are you? Las Vegas how are you Pinchas Can you just repeat that? User Hello Pinchas, can you hear me? how thick is can you hear me Pinchas I can hear you, yeah. User Pinchas, can you tell me how old you are? Vegas can you tell me how old you are Pinchas I was born in nineteen thi"
N16-3007,W06-1303,1,0.539718,"tion-response pairs, which identifies the most appropriate response to new (unseen) user input. The dialogue management logic is designed to deal with instances where the classifier cannot identify a good direct response. During training, NPCEditor calculates a response threshold based on the classifier’s confidence in the appropriateness of selected responses; at runtime, if the confidence for a selected response falls below the predetermined threshold, that response is replaced with an “off-topic” utterance that asks the user to repeat the question or takes initiative and changes the topic (Leuski et al., 2006); such failure to return a direct response, also called non-understanding (Bohus and Rudnicky, 2005), is usually preferred over returning an inappropriate one (misunderstanding). The current system uses a five-stage off-topic selection algorithm which is an extension of that presented in Artstein et al. (2009). Figure 1 shows a sample dialogue illustrating the handling of nonunderstanding. 33 User Hello Pinchas, how are you? Las Vegas how are you Pinchas Can you just repeat that? User Hello Pinchas, can you hear me? how thick is can you hear me Pinchas I can hear you, yeah. User Pinchas, can y"
N16-3007,W15-4629,1,0.824999,"ciation for Computational Linguistics 2 Technical details In the New Dimensions in Testimony prototype, users talk to a persistent representation of a Holocaust survivor presented on a video screen, and a computer algorithm selects and plays individual video clips of the survivor in response to user utterances. The result is much like an ordinary conversation between the user and the survivor. The system has been described in detail in previous publications, covering the proof of concept (Artstein et al., 2014), the content elicitation process (Artstein et al., 2015), the language processing (Traum et al., 2015a), the full prototype (Traum et al., 2015b), and ethical considerations (Artstein and Silver, 2016). Here we give a brief description of the language processing technology and the system’s runtime components. 2.1 Language processing At the heart of the runtime computer system is a response classifier and dialogue management component called NPCEditor (Leuski and Traum, 2011), which selects a response to each user utterance. NPCEditor combines the functions of Natural Language Understanding (NLU) and Dialogue Management – understanding the utterance text and selecting an appropriate response."
poesio-artstein-2008-anaphoric,J98-2001,1,\N,Missing
poesio-artstein-2008-anaphoric,A00-2018,0,\N,Missing
poesio-artstein-2008-anaphoric,J93-2004,0,\N,Missing
poesio-artstein-2008-anaphoric,W01-1605,0,\N,Missing
poesio-artstein-2008-anaphoric,W04-0210,1,\N,Missing
poesio-artstein-2008-anaphoric,W05-0311,1,\N,Missing
poesio-artstein-2008-anaphoric,N06-2015,0,\N,Missing
poesio-artstein-2008-anaphoric,W04-2327,1,\N,Missing
poesio-artstein-2008-anaphoric,M98-1029,0,\N,Missing
poesio-artstein-2008-anaphoric,J06-4012,0,\N,Missing
W05-0311,M98-1029,0,0.0956869,"United Kingdom Abstract We report the results of a study of the reliability of anaphoric annotation which (i) involved a substantial number of naive subjects, (ii) used Krippendorff’s α instead of K to measure agreement, as recently proposed by Passonneau, and (iii) allowed annotators to mark anaphoric expressions as ambiguous. 1 INTRODUCTION We tackle three limitations with the current state of the art in the annotation of anaphoric relations. The first problem is the lack of a truly systematic study of agreement on anaphoric annotation in the literature: none of the studies we are aware of (Hirschman, 1998; Poesio and Vieira, 1998; Byron, 2003; Poesio, 2004) is completely satisfactory, either because only a small number of coders was involved, or because agreement beyond chance couldn’t be assessed for lack of an appropriate statistic, a situation recently corrected by Passonneau (2004). The second limitation, which is particularly serious when working on dialogue, is our still limited understanding of the degree of agreement on references to abstract objects, as in discourse deixis (Webber, 1991; Eckert and Strube, 2001). The third shortcoming is a problem that affects all types of semantic an"
W05-0311,W03-2117,0,0.0588724,"Missing"
W05-0311,passonneau-2004-computing,0,0.578984,"s to mark anaphoric expressions as ambiguous. 1 INTRODUCTION We tackle three limitations with the current state of the art in the annotation of anaphoric relations. The first problem is the lack of a truly systematic study of agreement on anaphoric annotation in the literature: none of the studies we are aware of (Hirschman, 1998; Poesio and Vieira, 1998; Byron, 2003; Poesio, 2004) is completely satisfactory, either because only a small number of coders was involved, or because agreement beyond chance couldn’t be assessed for lack of an appropriate statistic, a situation recently corrected by Passonneau (2004). The second limitation, which is particularly serious when working on dialogue, is our still limited understanding of the degree of agreement on references to abstract objects, as in discourse deixis (Webber, 1991; Eckert and Strube, 2001). The third shortcoming is a problem that affects all types of semantic annotation. In all annotation studies we are aware of,1 the fact that an expression may not have a unique interpretation in the context of its 1 The one exception is Rosenberg and Binkowski (2004). occurrence is viewed as a problem with the annotation scheme, to be fixed by, e.g., develo"
W05-0311,J98-2001,1,0.54707,"stract We report the results of a study of the reliability of anaphoric annotation which (i) involved a substantial number of naive subjects, (ii) used Krippendorff’s α instead of K to measure agreement, as recently proposed by Passonneau, and (iii) allowed annotators to mark anaphoric expressions as ambiguous. 1 INTRODUCTION We tackle three limitations with the current state of the art in the annotation of anaphoric relations. The first problem is the lack of a truly systematic study of agreement on anaphoric annotation in the literature: none of the studies we are aware of (Hirschman, 1998; Poesio and Vieira, 1998; Byron, 2003; Poesio, 2004) is completely satisfactory, either because only a small number of coders was involved, or because agreement beyond chance couldn’t be assessed for lack of an appropriate statistic, a situation recently corrected by Passonneau (2004). The second limitation, which is particularly serious when working on dialogue, is our still limited understanding of the degree of agreement on references to abstract objects, as in discourse deixis (Webber, 1991; Eckert and Strube, 2001). The third shortcoming is a problem that affects all types of semantic annotation. In all annotati"
W05-0311,W99-0309,0,0.0165983,"r, even better, to develop methods to identify genuinely ambiguous expressions–the ultimate goal of this work. The paper is organized as follows. We first briefly review previous work on anaphoric annotation and on reliability indices. We then discuss our experiment with anaphoric annotation, and its results. Finally, we discuss the implications of this work. 2 ANNOTATING ANAPHORA It is not our goal at this stage to propose a new scheme for annotating anaphora. For this study we simply developed a coding manual for the purposes of our experiment, broadly based on the approach adopted in MATE (Poesio et al., 1999) and GNOME (Poesio, 2004), but introducing new types of annotation (ambiguous anaphora, and a simple form of discourse deixis) while simplifying other aspects (e.g., by not annotating bridging references). The task of ‘anaphoric annotation’ discussed here is related, although different from, the task of annotating ‘coreference’ in the sense of the so-called MUCSS scheme for the MUC -7 initiative (Hirschman, 1998). This scheme, while often criticized, is still widely used, and has been the basis of coreference annotation for the ACE initiative in the past two years. It suffers however from a nu"
W05-0311,N04-4020,0,0.0305547,"yond chance couldn’t be assessed for lack of an appropriate statistic, a situation recently corrected by Passonneau (2004). The second limitation, which is particularly serious when working on dialogue, is our still limited understanding of the degree of agreement on references to abstract objects, as in discourse deixis (Webber, 1991; Eckert and Strube, 2001). The third shortcoming is a problem that affects all types of semantic annotation. In all annotation studies we are aware of,1 the fact that an expression may not have a unique interpretation in the context of its 1 The one exception is Rosenberg and Binkowski (2004). occurrence is viewed as a problem with the annotation scheme, to be fixed by, e.g., developing suitably underspecified representations, as done particularly in work on wordsense annotation (Buitelaar, 1998; Palmer et al., 2005), but also on dialogue act tagging. Unfortunately, the underspecification solution only genuinely applies to cases of polysemy, not homonymy (Poesio, 1996), and anaphoric ambiguity is not a case of polysemy. Consider the dialogue excerpt in (1):2 it’s not clear to us (nor was to our annotators, as we’ll see below) whether the demonstrative that in utterance unit 18.1 r"
W05-0311,J00-4005,0,0.0736232,"Missing"
W05-0311,W04-2327,1,\N,Missing
W08-0130,W98-1425,0,0.246218,"mar (or language model) for free. However, it is harder to tailor output to the desired wording and style for a specific dialogue system, and these generators demand a specific input format that is otherwise foreign to an existing dialogue system. Unfortunately, in our experience, the development burden of implementing the translation between the system’s available meaning representations and the generator’s required input format is quite substantial. Indeed, implementing the translation might require as much effort as would be required to build a simple custom generator; cf. (Callaway, 2003; Busemann and Horacek, 1998). This development cost is exacerbated when a dialogue system’s native meaning representation scheme is under revision. In this paper, we survey a new example-based approach (DeVault et al., 2008) that we have developed in order to mitigate these difficulties, so that grammar-based generation can be deployed more widely in implemented dialogue systems. Our development pipeline requires a system developer to create a set of training examples which directly connect desired output texts to available application semantic forms. This is achieved through a streamlined authoring task that does not re"
W08-0130,P01-1017,0,0.0291106,"polarity = negative speech-act.content.attribute = resourceAttribute speech-act.content.value = medical-supplies speech-act.content.object-id = market  addressee = captain-kirk dialogue-act.addressee = captain-kirk  speech-act.addressee = captain-kirk Figure 3: A generation training example for Doctor Perez. suggests the output utterance u = we don’t have medical supplies here captain. Each utterance u is accompanied by syntax(u), a syntactic analysis in Penn Treebank format (Marcus et al., 1994). In this example, the syntax is a hand-corrected version of the output of the Charniak parser (Charniak, 2001; Charniak, 2005) on this sentence; we discuss this hand correction in Section 4. To represent the meaning of utterances, our approach assumes that the system provides some set M = {m1 , ..., mj } of semantic representations. The meaning of any individual utterance is then identified with some subset of M . For Doctor Perez, M comprises the 232 distinct key-value pairs that appear in the system’s various generation frames. In this example, the utterance’s meaning is captured by the 8 key-value pairs indicated in the figure. Our approach requires the generation content author to link these 8 ke"
W08-0130,J05-1003,0,0.0397406,"st applications. The second step of automated processing, then, uses the training examples to learn an effective search policy so that good output sentences can be found in a reasonable time frame. The solution we have developed employs a beam search strategy that uses weighted features to rank alternative grammatical expansions at each step. Our algorithm for selecting features and weights is based on the search optimization algorithm of (Daumé and Marcu, 2005), which decides to update feature weights when mistakes are made during search on training examples. We use the boosting approach of (Collins and Koo, 2005) to perform feature selection and identify good weight values. 4 Empirical Evaluation In the introduction, we identified run-time speed, adequacy of coverage, authoring burdens, and NLG re202 quest specification as important factors in the selection of a technology for a dialogue system’s NLG component. In this section, we evaluate our technique along these four dimensions. Hand-authored utterances. We collected a sample of 220 instances of frames that Doctor Perez’s dialogue manager had requested of the generation component in previous dialogues with users. Some frames occurred more than once"
W08-0130,W08-1111,1,0.718471,"rwise foreign to an existing dialogue system. Unfortunately, in our experience, the development burden of implementing the translation between the system’s available meaning representations and the generator’s required input format is quite substantial. Indeed, implementing the translation might require as much effort as would be required to build a simple custom generator; cf. (Callaway, 2003; Busemann and Horacek, 1998). This development cost is exacerbated when a dialogue system’s native meaning representation scheme is under revision. In this paper, we survey a new example-based approach (DeVault et al., 2008) that we have developed in order to mitigate these difficulties, so that grammar-based generation can be deployed more widely in implemented dialogue systems. Our development pipeline requires a system developer to create a set of training examples which directly connect desired output texts to available application semantic forms. This is achieved through a streamlined authoring task that does not require detailed linguistic knowledge. Our approach then processes these training examples to automatically construct all the resources needed for a fast, highquality, run-time grammar-based generat"
W08-0130,P98-1116,0,0.0604384,"2003). One strategy is to hand-build an applicationspecific grammar. However, in our experience, this process requires a painstaking, time-consuming effort by a developer who has detailed linguistic knowledge as well as detailed domain knowledge, and the resulting coverage is inevitably limited. Wide-coverage generators that aim for applicabil198 Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 198–207, c Columbus, June 2008. 2008 Association for Computational Linguistics ity across application domains (White et al., 2007; Zhong and Stent, 2005; Langkilde-Geary, 2002; Langkilde and Knight, 1998; Elhadad, 1991) provide a grammar (or language model) for free. However, it is harder to tailor output to the desired wording and style for a specific dialogue system, and these generators demand a specific input format that is otherwise foreign to an existing dialogue system. Unfortunately, in our experience, the development burden of implementing the translation between the system’s available meaning representations and the generator’s required input format is quite substantial. Indeed, implementing the translation might require as much effort as would be required to build a simple custom g"
W08-0130,W02-2103,0,0.0412378,"t exist (Reiter et al., 2003). One strategy is to hand-build an applicationspecific grammar. However, in our experience, this process requires a painstaking, time-consuming effort by a developer who has detailed linguistic knowledge as well as detailed domain knowledge, and the resulting coverage is inevitably limited. Wide-coverage generators that aim for applicabil198 Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 198–207, c Columbus, June 2008. 2008 Association for Computational Linguistics ity across application domains (White et al., 2007; Zhong and Stent, 2005; Langkilde-Geary, 2002; Langkilde and Knight, 1998; Elhadad, 1991) provide a grammar (or language model) for free. However, it is harder to tailor output to the desired wording and style for a specific dialogue system, and these generators demand a specific input format that is otherwise foreign to an existing dialogue system. Unfortunately, in our experience, the development burden of implementing the translation between the system’s available meaning representations and the generator’s required input format is quite substantial. Indeed, implementing the translation might require as much effort as would be require"
W08-0130,W06-1303,1,0.85619,"Missing"
W08-0130,2007.mtsummit-ucnlg.4,0,0.162385,"or which attractive methodologies do not yet exist (Reiter et al., 2003). One strategy is to hand-build an applicationspecific grammar. However, in our experience, this process requires a painstaking, time-consuming effort by a developer who has detailed linguistic knowledge as well as detailed domain knowledge, and the resulting coverage is inevitably limited. Wide-coverage generators that aim for applicabil198 Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 198–207, c Columbus, June 2008. 2008 Association for Computational Linguistics ity across application domains (White et al., 2007; Zhong and Stent, 2005; Langkilde-Geary, 2002; Langkilde and Knight, 1998; Elhadad, 1991) provide a grammar (or language model) for free. However, it is harder to tailor output to the desired wording and style for a specific dialogue system, and these generators demand a specific input format that is otherwise foreign to an existing dialogue system. Unfortunately, in our experience, the development burden of implementing the translation between the system’s available meaning representations and the generator’s required input format is quite substantial. Indeed, implementing the translation mi"
W08-0130,J93-2004,0,\N,Missing
W08-0130,C98-1112,0,\N,Missing
W08-0130,P00-1058,0,\N,Missing
W08-0130,2005.sigdial-1.25,1,\N,Missing
W08-1111,P04-1011,0,0.0549318,"99; Chiang, 2000; Chiang, 2003) to induce a probabilistic, lexicalized tree-adjoining grammar that supports the derivation of all the suggested output sentences, and many others besides. The final step is to use the training examples to learn an effective search policy so that our run-time generation component can find good output sentences in a reasonable time frame. In particular, we use variants of existing search optimization (Daumé and Marcu, 2005) and ranking algorithms (Collins and Koo, 2005) to train our run-time component to find good outputs within a specified time window; see also (Stent et al., 2004; Walker et al., 2001). The result is a run-time component that treats generation as an anytime search problem, and is thus suitable for applications in which a time/performance tradeoff is necessary (such as real-time dialogue). 3.1 Specification of Training Examples Each training example in our approach specifies a target output utterance (string), its syntax, and a set of links between substrings within the utterance and system semantic representations. Formally, a training example takes the form (u, syntax(u), semantics(u)). We will illustrate this format using the training example in Figu"
W08-1111,W02-0111,0,0.0171852,"rees, (2) enforcing consistency in the finiteness of VP and S complements, and (3) restricting subject/direct object/indirect object complements to play the same grammatical role in derived trees. Automatic Grammar Induction We adopt essentially the probabilistic tree-adjoining grammar (PTAG) formalism and grammar induction technique of (Chiang, 2003). Our approach makes three modifications, however. First, while Chiang’s model includes both full adjunction and sister adjunction operations, our grammar has only sister adjunction (left and right), exactly as in the TAGLET grammar formalism of (Stone, 2002). Second, to support lexicalization at an arbitrary granularity, we allow Chiang’s tree templates to be associated with more than one lexical anchor. Third, to unify syntactic and semantic reasoning in search, we augment lexical anchors with semantic information. Formally, wherever Chiang’s model has a lexical anchor w, ours has a pair (hw1 , ..., wn i, M ′ ), where M ′ ⊆ M is connected to lexical anchors hw1 , ..., wn i by the generation content author, as in Figure 1. The result is that the derivation probabiliIn the second stage, the complements and adjuncts in the decorated trees are incre"
W08-1111,N01-1001,0,0.226182,"generation component into an existing application. We believe this approach will broaden the class of applications in which grammarbased generation may feasibly be deployed. In principle, grammar-based generation offers significant advantages for many applications, when compared with simpler template-based or canned text output solutions, by providing productive coverage and greater output variety. However, realizing these advantages can require significant development costs (Busemann and Horacek, 1998). A third strategy is to use an example-based approach (Wong and Mooney, 2007; Stone, 2003; Varges and Mellish, 2001) in which the connection 77 paper is the generation of output utterances for a particular virtual human, Doctor Perez, who is designed to teach negotiation skills in a multi-modal, multi-party, non-team dialogue setting (Traum et al., 2008). The human trainee who talks to the doctor plays the role of a U.S. Army captain named Captain Kirk. The design goals for Doctor Perez create a number of requirements for a practical NLG component. We briefly summarize these requirements here; see (DeVault et al., 2008) for more details. Doctor Perez has a relatively rich internal mental state including bel"
W08-1111,N01-1003,0,0.0213809,"iang, 2003) to induce a probabilistic, lexicalized tree-adjoining grammar that supports the derivation of all the suggested output sentences, and many others besides. The final step is to use the training examples to learn an effective search policy so that our run-time generation component can find good output sentences in a reasonable time frame. In particular, we use variants of existing search optimization (Daumé and Marcu, 2005) and ranking algorithms (Collins and Koo, 2005) to train our run-time component to find good outputs within a specified time window; see also (Stent et al., 2004; Walker et al., 2001). The result is a run-time component that treats generation as an anytime search problem, and is thus suitable for applications in which a time/performance tradeoff is necessary (such as real-time dialogue). 3.1 Specification of Training Examples Each training example in our approach specifies a target output utterance (string), its syntax, and a set of links between substrings within the utterance and system semantic representations. Formally, a training example takes the form (u, syntax(u), semantics(u)). We will illustrate this format using the training example in Figure 1. In this example,"
W08-1111,2007.mtsummit-ucnlg.4,0,0.337341,"Missing"
W08-1111,N07-1022,0,0.145547,"needed to integrate a grammar-based generation component into an existing application. We believe this approach will broaden the class of applications in which grammarbased generation may feasibly be deployed. In principle, grammar-based generation offers significant advantages for many applications, when compared with simpler template-based or canned text output solutions, by providing productive coverage and greater output variety. However, realizing these advantages can require significant development costs (Busemann and Horacek, 1998). A third strategy is to use an example-based approach (Wong and Mooney, 2007; Stone, 2003; Varges and Mellish, 2001) in which the connection 77 paper is the generation of output utterances for a particular virtual human, Doctor Perez, who is designed to teach negotiation skills in a multi-modal, multi-party, non-team dialogue setting (Traum et al., 2008). The human trainee who talks to the doctor plays the role of a U.S. Army captain named Captain Kirk. The design goals for Doctor Perez create a number of requirements for a practical NLG component. We briefly summarize these requirements here; see (DeVault et al., 2008) for more details. Doctor Perez has a relatively"
W08-1111,W98-1425,0,0.642771,"widecoverage realizer that aims for applicability in multiple application domains (White et al., 2007; Cahill and van Genabith, 2006; Zhong and Stent, 2005; Langkilde-Geary, 2002; Langkilde and Knight, 1998; Elhadad, 1991). These realizers provide a sound wide-coverage grammar (or robust widecoverage language model) for free, but demand a specific input format that is otherwise foreign to an existing application. Unfortunately, the development burden of implementing the translation between the system’s available semantic representations and the required input format can be quite substantial (Busemann and Horacek, 1998). Indeed, implementing the translation might require as much effort as would be required to build a simple custom generator; cf. (Callaway, 2003). Thus, there currently are many applications where using a widecoverage generator remains impractical. We present a technique that opens up grammar-based generation to a wider range of practical applications by dramatically reducing the development costs and linguistic expertise that are required. Our method infers the grammatical resources needed for generation from a set of declarative examples that link surface expressions directly to the applicat"
W08-1111,P06-1130,0,0.170417,"Missing"
W08-1111,P01-1017,0,0.0292359,"l representations that would be necessary to specify semantics down to the lexers a bug or disfluency in the NLG output, it is better if she can fix it directly rather than requiring a (computational) linguist to do so. 3 Technical Approach Our approach builds on recently developed techniques in statistical parsing, lexicalized syntax modeling, generation with lexicalized grammars, and search optimization to automatically construct all the resources needed for a high-quality run-time generation component. In particular, we leverage the increasing availability of off-the-shelf parsers such as (Charniak, 2001; Charniak, 2005) to automatically (or semi-automatically) assign syntactic analyses to a set of suggested output sentences. We then draw on lexicalization techniques for statistical language models (Magerman, 1995; Collins, 1999; Chiang, 2000; Chiang, 2003) to induce a probabilistic, lexicalized tree-adjoining grammar that supports the derivation of all the suggested output sentences, and many others besides. The final step is to use the training examples to learn an effective search policy so that our run-time generation component can find good output sentences in a reasonable time frame. In"
W08-1111,P00-1058,0,0.0445926,"approach builds on recently developed techniques in statistical parsing, lexicalized syntax modeling, generation with lexicalized grammars, and search optimization to automatically construct all the resources needed for a high-quality run-time generation component. In particular, we leverage the increasing availability of off-the-shelf parsers such as (Charniak, 2001; Charniak, 2005) to automatically (or semi-automatically) assign syntactic analyses to a set of suggested output sentences. We then draw on lexicalization techniques for statistical language models (Magerman, 1995; Collins, 1999; Chiang, 2000; Chiang, 2003) to induce a probabilistic, lexicalized tree-adjoining grammar that supports the derivation of all the suggested output sentences, and many others besides. The final step is to use the training examples to learn an effective search policy so that our run-time generation component can find good output sentences in a reasonable time frame. In particular, we use variants of existing search optimization (Daumé and Marcu, 2005) and ranking algorithms (Collins and Koo, 2005) to train our run-time component to find good outputs within a specified time window; see also (Stent et al., 20"
W08-1111,J05-1003,0,0.219574,"tput sentences. We then draw on lexicalization techniques for statistical language models (Magerman, 1995; Collins, 1999; Chiang, 2000; Chiang, 2003) to induce a probabilistic, lexicalized tree-adjoining grammar that supports the derivation of all the suggested output sentences, and many others besides. The final step is to use the training examples to learn an effective search policy so that our run-time generation component can find good output sentences in a reasonable time frame. In particular, we use variants of existing search optimization (Daumé and Marcu, 2005) and ranking algorithms (Collins and Koo, 2005) to train our run-time component to find good outputs within a specified time window; see also (Stent et al., 2004; Walker et al., 2001). The result is a run-time component that treats generation as an anytime search problem, and is thus suitable for applications in which a time/performance tradeoff is necessary (such as real-time dialogue). 3.1 Specification of Training Examples Each training example in our approach specifies a target output utterance (string), its syntax, and a set of links between substrings within the utterance and system semantic representations. Formally, a training exam"
W08-1111,W08-0130,1,0.734384,"rd strategy is to use an example-based approach (Wong and Mooney, 2007; Stone, 2003; Varges and Mellish, 2001) in which the connection 77 paper is the generation of output utterances for a particular virtual human, Doctor Perez, who is designed to teach negotiation skills in a multi-modal, multi-party, non-team dialogue setting (Traum et al., 2008). The human trainee who talks to the doctor plays the role of a U.S. Army captain named Captain Kirk. The design goals for Doctor Perez create a number of requirements for a practical NLG component. We briefly summarize these requirements here; see (DeVault et al., 2008) for more details. Doctor Perez has a relatively rich internal mental state including beliefs, goals, plans, and emotions. He uses an attribute-value matrix (AVM) semantic representation to describe an utterance as a set of core speech acts and other dialogue acts. Speech acts generally have semantic contents that describe propositions and questions about states and actions in the domain. To facilitate interprocess communication, and statistical processing, this AVM structure is linearized into a “frame” of key values in which each non-recursive terminal value is paired with a path from the ro"
W08-1111,P98-1116,0,0.379699,"Missing"
W08-1111,W02-2103,0,0.226409,"Missing"
W08-1111,P95-1037,0,0.205764,"o so. 3 Technical Approach Our approach builds on recently developed techniques in statistical parsing, lexicalized syntax modeling, generation with lexicalized grammars, and search optimization to automatically construct all the resources needed for a high-quality run-time generation component. In particular, we leverage the increasing availability of off-the-shelf parsers such as (Charniak, 2001; Charniak, 2005) to automatically (or semi-automatically) assign syntactic analyses to a set of suggested output sentences. We then draw on lexicalization techniques for statistical language models (Magerman, 1995; Collins, 1999; Chiang, 2000; Chiang, 2003) to induce a probabilistic, lexicalized tree-adjoining grammar that supports the derivation of all the suggested output sentences, and many others besides. The final step is to use the training examples to learn an effective search policy so that our run-time generation component can find good output sentences in a reasonable time frame. In particular, we use variants of existing search optimization (Daumé and Marcu, 2005) and ranking algorithms (Collins and Koo, 2005) to train our run-time component to find good outputs within a specified time windo"
W08-1111,J93-2004,0,\N,Missing
W08-1111,J03-4003,0,\N,Missing
W08-1111,C98-1112,0,\N,Missing
W11-2030,bunt-2006-dimensions,0,0.0317849,"r arguments that appeal to emotions. On the other hand, people from Eastern collectivistic cultures are more likely to use arguments in which the beneficiary is not themselves. Furthermore, Arab cultures tend to favor more indirect ways of argumentation and expression (Koch, 1983; Zaharna, 1995). ∗ Now at the University of Texas at San Antonio. In order to analyze negotiation in detail, including aspects such as persuasion, negotiation, and crosscultural differences, we have developed a novel annotation scheme. General purpose annotation schemes such as DAMSL (Core and Allen, 1997) and DIT++ (Bunt, 2006) represent moves in the dialogue but do not capture enough details of the interaction to distinguish between different styles of persuasion and argumentation, especially cross-cultural differences. Our goal for developing this coding scheme is two-fold. First, we aim to fill the gap in the literature of cross-cultural argumentation and persuasion. To our knowledge this is the first annotation scheme designed specifically for coding cross-cultural argumentation and persuasion strategies. Previous work on cross-cultural negotiation, e.g. Brett and Gelfand (2006), has not focused on argumentation"
W11-2030,J87-1002,0,0.173196,"science (Sidner, 1994; Ros´e and Torrey, 2004). Our specific focus is on the role of argumentation and per272 Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 272–278, c Portland, Oregon, June 17-18, 2011. 2011 Association for Computational Linguistics suasion. Sycara (1990) studied the role of argumentation in negotiation with regard to the role of arguments in changing the decision process of the interlocutor. Most attempts have focused on studying the structure of argumentation and persuasion, often using formal logic (Cohen, 1987; Prakken, 2008). Dung (1995) showed that argumentation can be viewed as a special form of logic programming with negation as failure. An argumentation scheme is defined as a structure or template for forming an argument. Schemes are necessary for identifying arguments, finding missing premises, analyzing arguments, and evaluating arguments (Pollock, 1995; Katzav and Reed, 2004; Walton et al., 2008). Recently, there has been some work on using machine learning techniques for automatically interpreting (George et al., 2007) and generating arguments (Zukerman, 2001). Note also the work of Piwek"
W11-2037,2005.sigdial-1.14,0,\N,Missing
W13-4032,baccianella-etal-2010-sentiwordnet,0,0.0040804,"tuting a single turn. While this simple scheme does not provide a detailed treatment of relevant phenomena such as overlapping speech, backchannels, and the interactive process of negotiating the turn in dialogue (Yang and Heeman, 2010), it provides a conceptually simple model for the definition of features for aggregate statistical analysis. 4.2 Valence features for user speech Features (e)(g) are meant to explore the idea that distressed users might use more negative or less positive vocabulary than non-distressed subjects. As an exploratory approach to this topic, we used SentiWordNet 3.0 (Baccianella and Sebastiani, 2010), a lexical sentiment dictionary, to assign valence to individual words spoken by users in our study. The dictionary contains approximately 117,000 entries. In general, each word w may appear in multiple entries, corresponding to different parts of speech and word senses. To assign a single valence score v(w) to each word in the dictionary, in our features we compute the average score across all parts of speech and word senses: Context-independent feature analysis We begin by analyzing a set of shallow features which we describe as context-independent, as they apply to user speech segments ind"
W13-4032,D12-1004,0,0.0145618,"3–202, c Metz, France, 22-24 August 2013. 2013 Association for Computational Linguistics Heeman et al. (2010) observed differences in children with autism in how long they pause before speaking and in their use of fillers, acknowledgments, and discourse markers. Some of these features are similar to those studied here, but looked at children communicating with clinicians rather than a virtual human dialogue system. Recent work on machine classification has demonstrated the ability to discriminate between schizophrenic patients and healthy controls based on transcriptions of spoken narratives (Hong et al., 2012), and to predict patient adherence to medical treatment from word-level features of dialogue transcripts (Howes et al., 2012). Automatic speech recognition and word alignment has also been shown to give good results in scoring narrative recall tests for identification of cognitive impairment (Prud’hommeaux and Roark, 2011; Lehr et al., 2012). Figure 1: Ellie. communicative behavior of patients with specific psychological disorders such as depression. In this section, we briefly summarize some closely related work. Most work has observed the behavior of patients in human-human interactions, suc"
W13-4032,W12-1610,0,0.0311906,"rences in children with autism in how long they pause before speaking and in their use of fillers, acknowledgments, and discourse markers. Some of these features are similar to those studied here, but looked at children communicating with clinicians rather than a virtual human dialogue system. Recent work on machine classification has demonstrated the ability to discriminate between schizophrenic patients and healthy controls based on transcriptions of spoken narratives (Hong et al., 2012), and to predict patient adherence to medical treatment from word-level features of dialogue transcripts (Howes et al., 2012). Automatic speech recognition and word alignment has also been shown to give good results in scoring narrative recall tests for identification of cognitive impairment (Prud’hommeaux and Roark, 2011; Lehr et al., 2012). Figure 1: Ellie. communicative behavior of patients with specific psychological disorders such as depression. In this section, we briefly summarize some closely related work. Most work has observed the behavior of patients in human-human interactions, such as clinical interviews and doctor-patient interactions. PTSD is generally less well studied than depression. Examples of th"
W13-4032,J11-2001,0,0.0104219,"context-independent, as they apply to user speech segments independently of what the system has recently said. Most of these are features that apply to many or all user speech segments. We describe our context-independent features in Section 4.2.1, and present our results for these features in Section 4.2.2. 4.2.1 v(w) = P e∈E(w) PosScoree (w) |E(w)| − NegScoree (w) where E(w) is the set of entries for the word w, PosScoree (w) is the positive score for w in entry e, and NegScoree (w) is the negative score for w in entry e. This is similar to the “averaging across senses” method described in Taboada et al. (2011). We use several different measures of the valence of each speech segment with transcript t = hw1 , ..., wn i. We compute the min, mean, and max valence of each transcript: Context-independent features We summarize our context-independent features in Figure 2. Speaking rate and onset times Based on previous clinical observations related to slowed speech and increased onset time for depressed individuals (Section 2), we defined features for speaking rate and onset time of user speech segments. We quantify the speaking rate of a user speech segment hs, e, ti, where t = hw1 , ..., wN i, as N/(e −"
W13-4032,W10-4346,0,\N,Missing
W13-4032,wittenburg-etal-2006-elan,0,\N,Missing
W13-4064,aggarwal-etal-2012-twins,1,0.766178,"d new hires, who acted as test subjects. This dataset has 4K audio files each annotated with one of the 117 different NLU semantic classes. answering characters, but unlike SGTs Blackwell and Star, the response is a whole dialogue sequence, potentially involving interchange from both characters, rather than a single character turn. There are two types of users for the Twins: demonstrators, who are museum staff members, using head-mounted microphones, and museum visitors, who use a Shure 522 table-top mounted microphone (Traum et al., 2012). More on analysis of the museum data can be found in (Aggarwal et al., 2012). We also investigated speech recognition and NLU performance in this domain in Morbini et al. (2012). This dataset contains 14K audio files each annotated with one of the 168 possible response sequences. The division in training development and test is the same used in Morbini et al. (2012) (10K for training, the rest equally divided between development and test). Amani (Artstein et al., 2009b; Artstein et al., 2011) is an advanced question-answering character used as a prototype for systems meant to train soldiers to perform tactical questioning. The users are in between real users and test"
W13-4064,W11-2037,1,0.821297,"nstructed from known parts using a generative approach. A second issue is that even though we can cast the problem as multi-class classification, classification accuracy is not always the most appropriate metric of NLU quality. For question-answering characters, getting an appropriate and relevant reply is more important than picking the exact reply selected by a human domain designer or annotator: there might be multiple good answers, or even the best available answer might not be very good. For that reason, the question-answering characters allow an “off-topic” answer and Errorreturn plots (Artstein, 2011) might be necessary to choose an optimal threshold. For the SASO-EN system, slot-filler metrics such as precision, recall, and f-score are more appropriate than frame accu400 conventional ASR scale and use word accuracy, so that higher numbers signify better performance on both scales.13 Figure 1 shows the results obtained in the 3 dialogue systems by the various ASR systems. The figures plot ASR performance against NLU performance; NLU results on manual transcriptions are included for comparison. There are too few data points for the correlations between ASR and NLU performance to be signific"
W13-4064,2007.sigdial-1.23,0,0.036582,"derstand or react well to, even when an alternative formulation is known to work. ASR performance as well. One important aspect is the broad physical differences among speakers, such as male vs female, adult vs child (e.g. Bell and Gustafson, 2003), or language proficiency/accent, that will have implications for the acoustics of what is said, and ASR results. Other aspects of users have implications for what will be said, and how successful the interface may be, overall. Many (e.g. Hassel and Hagen, 2006; Jokinen and Kanto, 2004) have looked at the differences between novice and expert users. Ai et al. (2007a) also points out a difference between real users and recruited subjects. Real users also come in many different flavors, depending on their purposes. E.g. are they interacting with the system for fun, to do a specific task that they need to get done, to learn something (specific or general), or with some other purpose in mind? We considered the following classes of users, ordered from easiest to hardest to get to acceptable performance and robustness levels: 3.2 Types of Dialogue System Genres Dialogue Genres can be distinguished along many lines, e.g. the number and relationship of particip"
W13-4064,N03-1001,0,0.0442742,"Missing"
W13-4064,robinson-etal-2008-ask,1,0.689243,"ring character, with no internal semantic representation and the primary NLU task merged with Dialogue management as selecting the best response. The original users were ICT demonstrators. However, there were also some experiments with recruited participants (Leuski et al., 2006a; Leuski et al., 2006b). Later SGT Blackwell became a part of the “best design in America” triennial at the Cooper-Hewitt Museum in New York City, and the data set here is from visitors to the museum, who are mostly casual users, but range from expert to red-team. Users spoke into a mounted directional microphone (see Robinson et al., 2008 for more details). Slot-filling Probably the most common type of dialogue system (at least in the research community) is slot-filling. Here the dialogue is fairly structured, with an initial greeting phase, then one or more tasks, which all start with the user selecting the task, and the system taking over initiative to “fill” and possibly confirm the needed slots, before retrieving some information from a database, or performing a simple service.11 This genre also requires a semantic representation, at least of the slots and acceptable values. Generally, the set of possible values is large e"
W13-4064,P04-1012,0,0.0133144,"ak” the system, or show it as not-competent, and may try to do things the system can’t understand or react well to, even when an alternative formulation is known to work. ASR performance as well. One important aspect is the broad physical differences among speakers, such as male vs female, adult vs child (e.g. Bell and Gustafson, 2003), or language proficiency/accent, that will have implications for the acoustics of what is said, and ASR results. Other aspects of users have implications for what will be said, and how successful the interface may be, overall. Many (e.g. Hassel and Hagen, 2006; Jokinen and Kanto, 2004) have looked at the differences between novice and expert users. Ai et al. (2007a) also points out a difference between real users and recruited subjects. Real users also come in many different flavors, depending on their purposes. E.g. are they interacting with the system for fun, to do a specific task that they need to get done, to learn something (specific or general), or with some other purpose in mind? We considered the following classes of users, ordered from easiest to hardest to get to acceptable performance and robustness levels: 3.2 Types of Dialogue System Genres Dialogue Genres can"
W13-4064,W06-1303,1,0.719162,"s on the size of the training and development sets may be found in Yao et al. (2010), here we report only the numbers relevant to the Twins domain and to the NLU analysis, which are not in Yao et al. (2010). SGT Blackwell was created as a virtual human technology demonstration for the 2004 Army Science Conference. This is a question-answering character, with no internal semantic representation and the primary NLU task merged with Dialogue management as selecting the best response. The original users were ICT demonstrators. However, there were also some experiments with recruited participants (Leuski et al., 2006a; Leuski et al., 2006b). Later SGT Blackwell became a part of the “best design in America” triennial at the Cooper-Hewitt Museum in New York City, and the data set here is from visitors to the museum, who are mostly casual users, but range from expert to red-team. Users spoke into a mounted directional microphone (see Robinson et al., 2008 for more details). Slot-filling Probably the most common type of dialogue system (at least in the research community) is slot-filling. Here the dialogue is fairly structured, with an initial greeting phase, then one or more tasks, which all start with the u"
W13-4064,yao-etal-2010-practical,1,0.963582,"du Abstract While this increased choice of quality recognizers is of great benefit to dialogue system developers, it also creates a dilemma – which recognizer to use? Unfortunately, the answer is not simple – it depends on a number of issues, including the type of dialogue domain, availability and amount of training data, availability of internet connectivity for the runtime system, and speed of response needed. In this paper we assess several freely available speech recognition engines, and examine their suitability and performance in several dialogue systems. Here we extend the work done in Yao et al. (2010) focusing in particular on cloud based freely available ASR systems. We include 2 local ASRs for reference, one of which was also used in the earlier work for easy comparison. We present an analysis of several publicly available automatic speech recognizers (ASRs) in terms of their suitability for use in different types of dialogue systems. We focus in particular on cloud based ASRs that recently have become available to the community. We include features of ASR systems and desiderata and requirements for different dialogue systems, taking into account the dialogue genre, type of user, and oth"
W14-4334,baccianella-etal-2010-sentiwordnet,0,0.00639605,"understanding of user speech. SimSensei Kiosk currently uses 4 statistically trained utterance classifiers to capture different aspects of user utterance meaning. The first NLU classifier identifies generic dialogue act types, including statements, yes-no questions, wh-questions, yes and no answers, and several others. This classifier is trained using the Switchboard DAMSL corpus (Jurafsky et al., 1997) using a maximum entropy model. The second NLU classifier assigns positive, negative, or neutral valence to utterances, in order to guide Ellie’s expression of empathy. We use SentiWordNet 3.0 (Baccianella et al., 2010), a lexical sentiment dictionary, to assign valence to individual words spoken by users (as recognized by the ASR); the valence assigned to an utterance is based primarily on the mean valence scores of Opening Rapport Building Phase What are some things you really like about LA? (top level question) I love the weather, I love the palm trees, I love the beaches, there’s a lot to do here. Ellie Diagnostic Phase Have you noticed any changes in your behavior or thoughts lately? (top level question) User Yes. Ellie Can you tell me about that? (continuation prompt) User I’m having a lot more nightma"
W14-4334,W13-4032,1,0.849274,"ss conditions such as depression, anxiety, and post-traumatic stress disorder (PTSD) (DeVault et al., 2014). SimSensei Kiosk has two main functions – a virtual human called Ellie (pictured in Figure 1), who converses with a user in a spoken, semi-structured interview, and a multimodal perception system which analyzes the user’s behavior in real time to identify indicators of psychological distress. The system has been designed and developed over two years using a series of face-toface, Wizard-of-Oz, and automated system studies involving more than 350 human participants (Scherer et al., 2013; DeVault et al., 2013; DeVault et al., 2014). Agent design has been guided by two overarching goals: (1) the agent should make 254 Proceedings of the SIGDIAL 2014 Conference, pages 254–256, c Philadelphia, U.S.A., 18-20 June 2014. 2014 Association for Computational Linguistics gine. The perception system analyzes audio and video in real time to identify features such as head position, gaze direction, smile intensity, and voice quality. DeVault et al. (2014) provides details on all the agent’s modules. 2 2.1 Ellie User Overview of Dialogue Processing ASR and NLU components Unlike many task-oriented dialogue domains"
W15-4629,W11-2037,1,0.936015,"Missing"
W15-4629,2005.sigdial-1.14,0,0.146605,"sed on the classifier’s confidence in the appropriateness of selected responses: this threshold finds an optimal balance between false positives (inappropriate responses above threshold) and false negatives (appropriate responses below threshold) in the training data. At runtime, if the confidence for a selected response falls below the predetermined threshold, that response is replaced with an “off-topic” utterance that asks the user to repeat the question or takes initiative and changes the topic (Leuski et al., 2006); such failure to return a direct response, also called non-understanding (Bohus and Rudnicky, 2005), is usually preferred over returning an inappropriate one (misunderstanding). is also above the threshold, Pinchas will respond with the lower ranked response. If the only responses above threshold are among the recently used then Pinchas will choose one of them, since repetition is considered preferable to responding with an off-topic or inappropriate statement. 3.5 Data collection The development process consisted of several stages: preliminary planning and question gathering, initial recording of survivor statements, Wizard of Oz studies using the recorded statements to identify gaps in th"
W15-4629,W06-1303,1,\N,Missing
W15-4629,W10-4345,1,\N,Missing
W16-3614,W11-2037,1,0.868313,"Missing"
W16-3614,W15-4629,1,0.798411,"that separates tokens by whitespace and removes periods, exclamation marks, question marks and quotation marks. The same simple tokenizer was used as a second option for the English text. Method 2.1 Tokenization Materials 2.3 Our English data come from the New Dimensions in Testimony system, which allows people to ask questions in conversation with a representation of Holocaust Survivor Pinchas Gutter; this system had undergone an extensive process of user testing, so the linked questions and responses contain many actual user questions that are relevant to the domain (Artstein et al., 2015; Traum et al., 2015). The New Dimensions in Testimony system has more than 1700 responses, almost 7000 training questions, and 400 test questions, with a manyto-many linking between questions and responses (Traum et al., 2015). To get a dataset that is large enough to yield meaningful results yet small Stemming Tamil is an agglutinative language where stems can take many affixes (Lehmann, 1989), so we experimented with a stemmer (Rajalingam, 2013).2 For comparison, we also ran the English experiments with the SnowballStemmer(&quot;english&quot;) routine from NLTK.3 2.4 Response ranking We reimplemented parts of the respons"
W16-3614,W06-1303,0,0.36073,"ems: Translating a Question-Answering System from English into Tamil Satheesh Ravi1 and Ron Artstein1,2 University of Southern California 1 Department of Computer Science, 941 Bloom Walk, Los Angeles, CA 90089-0781, USA 2 Institute for Creative Technologies, 12015 Waterfront Drive, Playa Vista CA 90094, USA satheesr@usc.edu, artstein@ict.usc.edu Abstract ponent, using off-the-shelf rather than domainadapted machine translation, and with languages that are not as closely related. Question-answering characters are designed to sustain a conversation driven primarily by the user asking questions. Leuski et al. (2006) developed algorithms for training such characters using linked questions and responses in the form of unstructured natural language text. Given a novel user question, the character finds an appropriate response from a list of available responses, and when a direct answer is not available, the character selects an “off-topic” response according to a set policy, ensuring that the conversation remains coherent even with a finite number of responses. The response selection algorithms are languageindependent, also allowing the questions and responses to be in separate languages. These algorithms h"
W17-2808,Q13-1016,0,0.0662557,"the methodology of corpus-based robotics (Bugmann et al., 2004), where some natural language, primarily route instructions, is collected. Route instruction interpreters dating back to M ARCO (MacMahon, 2006), and more recently the robotic forklift (Tellex et al., 2011) and Tactical Behavior Specification grammar (Hemachandra et al., 2015; Boularias et al., 2016), rely on these initial route instructions to learn mappings to robot-executable procedures like path planning. Additionally, some use semantic parsers (e.g., (Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013; Matuszek et al., 2013; Krishnamurthy and Kollar, 2013)) or translation (Matuszek et al., 2010) to map natural language to actions. A gap in these works is bi-directional dialogue interaction, specifically cases where initial instructions are not well-formed and need additional clarification, or when participants grow to better grasp the robot’s capabilities, varying instruction strategies over time. Our work collected instructions to a robot, but also included the dialogue and followon responses needed to establish or build common ground. This paper focused on analyzing initial robot-directed instructions, leaving analysis of responses during the"
W17-2808,Q13-1005,0,0.0154904,"to natural language interpretation for robots follow the methodology of corpus-based robotics (Bugmann et al., 2004), where some natural language, primarily route instructions, is collected. Route instruction interpreters dating back to M ARCO (MacMahon, 2006), and more recently the robotic forklift (Tellex et al., 2011) and Tactical Behavior Specification grammar (Hemachandra et al., 2015; Boularias et al., 2016), rely on these initial route instructions to learn mappings to robot-executable procedures like path planning. Additionally, some use semantic parsers (e.g., (Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013; Matuszek et al., 2013; Krishnamurthy and Kollar, 2013)) or translation (Matuszek et al., 2010) to map natural language to actions. A gap in these works is bi-directional dialogue interaction, specifically cases where initial instructions are not well-formed and need additional clarification, or when participants grow to better grasp the robot’s capabilities, varying instruction strategies over time. Our work collected instructions to a robot, but also included the dialogue and followon responses needed to establish or build common ground. This paper focused on analyzing initial robot-directe"
W17-2808,W10-4328,1,0.77268,"s shown in Figure 5. command:send-image. Others require additional parameters to fully specify the complete action. Of particular interest to us is the information that participants chose to include in robot-directed motion requests. We focused on command:drive and command:rotate for variation in how participants communicated. We annotated motion-command parameters for their usage of metric (e.g., move forward 2 feet; turn left 90 degrees) and landmarkbased points of reference (e.g., move to the table; turn to face the doorway) similar to absolute and relative steps in route instructions from Marge and Rudnicky (2010). 3.2.3 Dialogue-Moves To analyze internal IU structure, we annotated Commander-issued lower-level dialogue-moves. This annotation scheme is inspired by a prior approach to military dialogue that identified dialogue-moves in calls for artillery fire (Roque et al., 2006). Examples of a command type request are command:drive or command:rotate, that instruct the robot to perform certain motions. A dialogue-move list is provided in Appendix B. Three annotators independently validated the dialogue-move set on 99 dialogue turns in our human-robot dialogue corpus. Annotators had high agreement (α = 0"
W17-2808,J97-1002,0,0.437754,"ial1 , Ashley Foots1 , Cory Hayes1 , Cassidy Henry1 , Kimberly A. Pollard1 , Ron Artstein2 , Clare R. Voss1 , and David Traum2 1 U.S. 2 USC Army Research Laboratory, Adelphi, MD 20783 Institute for Creative Technologies, Playa Vista, CA 90094 matthew.r.marge.civ@mail.mil Abstract ulate robot intelligence and actions without participant awareness. With ten participants, we collected ten hours of human-robot dialogue. We are currently undertaking corpus curation and plan to make the data freely available in the next year. In this experiment, a human and robot engage in a series of transactions (Carletta et al., 1997) where an instruction is issued, and wizards acting on behalf of the robot either perform a task or prompt for clarification until the requested task is completed or abandoned. We propose a new term, instruction unit (IU), to identify all commands within a transaction issued before the robot generates a response. IUs were analyzed both in structure and variation. Our findings suggest a general, initial preference for including metric information over landmarks in motion commands, but this decreased over time. Results will assist in future work adapting robot responses to varied instruction sty"
W17-2808,passonneau-2006-measuring,0,0.0754703,"e, we annotated Commander-issued lower-level dialogue-moves. This annotation scheme is inspired by a prior approach to military dialogue that identified dialogue-moves in calls for artillery fire (Roque et al., 2006). Examples of a command type request are command:drive or command:rotate, that instruct the robot to perform certain motions. A dialogue-move list is provided in Appendix B. Three annotators independently validated the dialogue-move set on 99 dialogue turns in our human-robot dialogue corpus. Annotators had high agreement (α = 0.92; Krippendorf’s α using the MASI distance measure (Passonneau, 2006)). 3.3 Participants This study recruited ten participants: two female, eight male. Ages ranged from 28 to 58 (mean = 44, s.d. = 10.6). Two participants reported one year or less of robotics research; others reported none.1 1 We collected measures that were included in our statistical analysis but not presented in this paper. The Spatial Orientation Survey, part of the Guilford-Zimmerman Aptitude Survey (Guilford and Zimmerman, 1948), assesses spatial orientation perception. The HRI Trust Survey (Schaefer, 2013) measures subjective trust of the robot, based upon personal belief of the robot’s c"
W17-2808,P08-1073,0,0.0405719,"angement), the environment is sparsely filled with objects and is not in a finished state. These were practical limitations of laboratory resources, but in future work we plan to explore the effects of the environment further by varying it in a fully simulated version of the experiment. 5.2 6.1 By far the WOz method’s most common use has been for handling natural language (Riek, 2012). Many studies use a wizard in automated dialogue system development (e.g., in virtual agent negotiation (Gandhe and Traum, 2007), time-offset storytelling (Artstein et al., 2015), and in-car personal assistants (Rieser and Lemon, 2008)). Some researchers have considered a multiwizard setup for multimodal interfaces. The SimSensei project (DeVault et al., 2014) used a twowizard setup during the development stage; one controlling the virtual agent’s verbal behaviors and another the non-verbal behaviors. Green et al. (2004) investigated using multiple wizards for dialogue processing and navigation capabilities for a robot in a home touring scenario, finding the multi-wizard approach effective when the robot and human were co-present. Dialogue-Move Types We found that most IUs contained command dialogue-moves, but with some exc"
W17-2808,eberhard-etal-2010-indiana,0,0.0441354,"Missing"
W17-2808,stoia-etal-2008-scare,0,0.324368,"Missing"
W17-2808,gargett-etal-2010-give,0,\N,Missing
W17-5541,W13-4064,1,0.841205,"5-17 August 2017. 2017 Association for Computational Linguistics The NDT system listens to the user’s audio streaming from a microphone. Two components handle the audio stream: AcquireSpeech (1) records the user’s audio to a file for later analysis, and the Google Web ASR webapp (2) sends the audio to Google speech recognition services, receives the speech transcription, and forwards the text to the language understanding module. The webapp is loaded from a web server (8) running in the background. We chose the Google speech service because it has been shown to be highly effective and robust (Morbini et al., 2013). At the time of the system development, the only way to access the Google ASR was to use the Web Speech API in the Chrome web browser1 ; we thus had to include Chrome as an additional component of the NDT system (the ninth component, not explicitly shown on Figure 1). The language understanding and dialogue management are handled by NPCEditor (3) (Leuski and Traum, 2011). It uses a statistical classifier to analyze the speech transcript and selects the appropriate response from a collection of Mr. Gutter’s video clips. It passes the clip identifier to a custom Video Player (4), which handles"
W17-5541,W15-4629,1,0.930402,"ue system in an environment where deep technical expertise might not be readily available. The initial version was created using a collection of research tools. We summarize a number of challenges with its deployment at two museums and describe a new system that simplifies the installation and user interface; reduces reliance on 3rd-party software; and provides a robust data collection mechanism. 1 2. Google Web ASR webapp G 7. ActvieMQ server 3. NPCEditor 4. Video Player Audio Video Google ASR Service 1. AcquireSpeech 5. Launcher 6. Logger Figure 1: The initial NDT system architecture. ence (Traum et al., 2015b). However, we discovered a number of issues with the system maintenance and support: system installation was a delicate process, there were issues maintaining the 3rd party system dependencies, the system user interface tended to overwhelm and confuse the operators, and reliable data collection proved to be a challenge. The lessons we learned from the deployment of the NDT system led us back to the drawing board. We created a new version of the NDT system that we call Alfred. Our goal was to make the system easier to install and maintain. We looked to simplify and streamline the user interfa"
W17-5544,N16-3007,1,0.834225,"will repeat or elaborate, based on the topic annotation of the responses. A counter keeps track of the number of consecutive times the chatbot has failed to provide a direct answer, and on the 3rd instance, an “alternative” response is given to suggest returning to the HIV/AIDS domain. The counter restarts after giving an “alternative” response. Previous applications of NPCEditor have been used to drive interactive characters in various domains such as interactive museum guides (Swartout et al., 2010), entertainment experiences (Hartholt et al., 2009), and interviews with Holocaust survivors (Artstein et al., 2016). NPCEditor was applied to the HIV/AIDS domain in the development of a virtual reality application designed for HIV positive young men who have sex with men (YMSM) to practice disclosing their status to intimate partners in an immersive, nonjudgmental environment (Knudtson et al., 2016). While NPCEditor has been used for custom chat applications, this is the first deployment of NPCEditor with Facebook Messenger. 4.2 Facebook API Facebook launched the Messenger platform supporting chatbots, as well as sending and receiving APIs in 2016.6 SHIHbot is the first deployment of a Facebook bot using N"
W18-4701,E09-1022,0,0.0174719,"lso involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 2013). With this interface a user can for example select a person’s hat in an image and say “this is a hat”. Then the system learns to associate the tag “hat” with the selected region of the image. Fin"
W18-4701,N16-1147,0,0.0178558,"nvolving dialogue and vision has been in the context of answering factual questions on images (Das et al., 2017; Antol et al., 2015) using the MSCOCO data set (Lin et al., 2014). The task may also involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 201"
W18-4701,P10-1128,0,0.0270435,"rlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 2013). With this interface a user can for example select a person’s hat in an image and say “this is a hat”. Then the system learns to associate the tag “hat” with the selected region of the image. Finally, Manuvinakurike et al. (2018a) re"
W18-4701,P02-1048,0,0.161474,"is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 2013). With this interface a user can for example select a person’s hat in an image and say “this is a hat”. Then the system learns to associate the tag “hat” with the selected region of the image. Finally, Manuvinakurike et al. (2018a) recently introduced a corpus containing one-shot image editing instructions. 3 Data The task of image editing"
W18-4701,D14-1086,0,0.0765644,"ersation in the context of visual information has been studied for a long time. Clark and WilkesGibbs (1986) studied reference resolution of simple figures called tangrams. Kennington and Schlangen (2015) and Manuvinakurike et al. (2016) performed incremental understanding and incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied using virtual reality technologies and spatial constraints (Stoia et al., 2008; Das et al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has"
W18-4701,P15-1029,0,0.0167866,"the role of a future dialogue system). We introduce a novel annotation scheme for this task, and discuss challenging sub-tasks in this domain. Conversational image editing combines spoken language, dialogue, and computer vision, and our real-world domain extends the literature on domains that are at the intersection of language and computer vision. We will publicly release our corpus in the near future. 2 Related Work Conversation in the context of visual information has been studied for a long time. Clark and WilkesGibbs (1986) studied reference resolution of simple figures called tangrams. Kennington and Schlangen (2015) and Manuvinakurike et al. (2016) performed incremental understanding and incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whe"
W18-4701,W16-3630,0,0.0131278,"m). We introduce a novel annotation scheme for this task, and discuss challenging sub-tasks in this domain. Conversational image editing combines spoken language, dialogue, and computer vision, and our real-world domain extends the literature on domains that are at the intersection of language and computer vision. We will publicly release our corpus in the near future. 2 Related Work Conversation in the context of visual information has been studied for a long time. Clark and WilkesGibbs (1986) studied reference resolution of simple figures called tangrams. Kennington and Schlangen (2015) and Manuvinakurike et al. (2016) performed incremental understanding and incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond im"
W18-4701,W17-5539,1,0.843575,"resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied using virtual reality technologies and spatial constraints (Stoia et al., 2008; Das et al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has been in the context of answering factual questions on images (Das et al., 2017; Antol et al., 2015) using the MSCOCO data set (Lin et al., 2014). The task may also involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the fo"
W18-4701,L18-1683,1,0.883106,"Missing"
W18-4701,W18-5033,1,0.93435,"le completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 2013). With this interface a user can for example select a person’s hat in an image and say “this is a hat”. Then the system learns to associate the tag “hat” with the selected region of the image. Finally, Manuvinakurike et al. (2018a) recently introduced a corpus containing one-shot image editing instructions. 3 Data The task of image editing is challenging for the following reasons: (i) The user needs to understand whether changes applied to a given image fit the target narrative or not. (ii) Image editing is a time consuming task. The user typically experiments with various features often undoing, redoing, altering in increments, or even completely removing previously performed edits before settling on the final image edit. (iii) The users may know at an abstract level what changes they want to perform, but be unaware"
W18-4701,I17-1047,0,0.0261199,"al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has been in the context of answering factual questions on images (Das et al., 2017; Antol et al., 2015) using the MSCOCO data set (Lin et al., 2014). The task may also involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal inter"
W18-4701,paetzel-etal-2014-multimodal,0,0.0225781,"f visual information has been studied for a long time. Clark and WilkesGibbs (1986) studied reference resolution of simple figures called tangrams. Kennington and Schlangen (2015) and Manuvinakurike et al. (2016) performed incremental understanding and incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied using virtual reality technologies and spatial constraints (Stoia et al., 2008; Das et al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has been in the context o"
W18-4701,W15-4610,0,0.0243606,"incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied using virtual reality technologies and spatial constraints (Stoia et al., 2008; Das et al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has been in the context of answering factual questions on images (Das et al., 2017; Antol et al., 2015) using the MSCOCO data set (Lin et al., 2014). The task may also involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al."
W18-4701,P16-1115,0,0.0126772,"logue, and computer vision, and our real-world domain extends the literature on domains that are at the intersection of language and computer vision. We will publicly release our corpus in the near future. 2 Related Work Conversation in the context of visual information has been studied for a long time. Clark and WilkesGibbs (1986) studied reference resolution of simple figures called tangrams. Kennington and Schlangen (2015) and Manuvinakurike et al. (2016) performed incremental understanding and incremental reference resolution respectively in a domain of geometric shape descriptions, while Schlangen et al. (2016) resolved references to objects in real-world example images. Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied"
W18-4701,stoia-etal-2008-scare,0,0.0374439,"Much work has been done in the context of gamified scenarios where the interlocutors interact and resolve references to real-world objects (Kazemzadeh et al., 2014; Paetzel et al., 2014; Manuvinakurike and DeVault, 2015). Also, such gamified scenarios have served as platforms for developing/learning incremental dialogue policies regarding whether the system should respond immediately or wait for more information (Paetzel et al., 2015; Manuvinakurike et al., 2017). Referential domains in the context of dialogue have also been studied using virtual reality technologies and spatial constraints (Stoia et al., 2008; Das et al., 2018) as well as robots (Whitney et al., 2016; Skantze, 2017). A more recent direction of research involving dialogue and vision has been in the context of answering factual questions on images (Das et al., 2017; Antol et al., 2015) using the MSCOCO data set (Lin et al., 2014). The task may also involve a gamified scenario with the interlocutors playing a yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the im"
W18-4701,tokunaga-etal-2012-rex,0,0.0131817,"yes-no questionanswer game as in de Vries et al. (2017). In these works the focus is less on the dialogue aspects and more on the factual aspects of the images, i.e., if an object is present or what a certain component of the image is. Mostafazadeh et al. (2017) extended this line of work with conversations grounded on images. Furthermore, Huang et al. (2016) built a data set of images with corresponding descriptions in sequence, for the task of visual storytelling. Other gamified real-world scenarios involve object arrangement (DeVault and Stone, 2009), puzzle completion (Iida et al., 2010; Takenobu et al., 2012), map navigation (Anderson et al., 1991; Lemon et al., 2001; Johnston et al., 2002), furniture-buying scenarios (Di Eugenio et al., 2000), and treasure-hunt tasks in a virtual environment (Byron and Fosler-Lussier, 2006). A multi-modal interface for image editing combining speech and direct manipulation was developed by (Laput et al., 2013). With this interface a user can for example select a person’s hat in an image and say “this is a hat”. Then the system learns to associate the tag “hat” with the selected region of the image. Finally, Manuvinakurike et al. (2018a) recently introduced a corp"
W18-4701,W15-4622,0,0.0162603,"Update requests (IER-U) are refinements to a previous request (users often request updates until the target is achieved). Revert requests (IER-R) occur when users want to undo the changes done to the image until a certain point. Compare requests (IER-C) occur when users want to compare the current version of the image to a previous version (before the most recent changes took place). The image edit requests IER-N and IER-U are labeled further with action and entity labels, which specify the nature of the edit request (the use of actions and entities is inspired by the intents and entities of Williams et al. (2015)). These labels serve as an intermediary language to map a user’s utterance to executable commands that can be carried out in an image editing program. Actions are a predefined list of 18 functions common to most 4 Segments Dialogue Act Action Attribute Loc/Obj Mod/Val uh make the tree brighter like a 100 nope too much O IER-N IER-U COM-D Adjust Adjust - brightness brightness - tree tree - 100 - perfect let’s work on sharpness COM-L IER-N Adjust sharpness - - Table 2: Example annotations of dialogue acts, actions, and entities. Dialogue Act IER-N IER-U IER-R IER-C COM-L COM-D COM-I RQR QF QIA"
W18-5012,W15-4611,0,0.0604603,"Missing"
W18-5012,stoia-etal-2008-scare,0,0.18304,"contains more than one intent (Dialogue 4). Understanding stylistic differences can support the development of dialogue systems with strategies that tailor system responses to the user’s style, rather than constrain the user’s style to the expected input. The taxonomy is described in more detail in Section 3. We observe and analyze these stylistic differences in a corpus of human-robot direction-giving dialogue from Marge et al. (2017). These styles are not unique to this corpus; they emerge in other human-robot and human-human dialogue, such as TeamTalk (Marge and Rudnicky, 2011) and SCARE (Stoia et al., 2008). The corpus contains 60 dialogues from 20 participants (Section 4). The robot dialogue management in the corpus is controlled by a Wizard-of-Oz experimenter, allowing for the study of users’ style with a fluent and naturalistic partner (i.e., with an approximation of an idealized automated system). In Section 5, we investigate possible consequences and implications of these categorized styles in this corpus. We examine the relationship of style and miscommunication frequency, applying an existing taxonomy for miscommunication in human-agent conversational dialogue (Higashinaka et al., 2015a)"
W18-5012,D15-1268,0,0.319779,"z for dialogue management. This allowed us specifically to isolate the style usage and miscommunication errors of the human partner (because the Wizard makes very few errors on the robot’s end). Studies of human-robot automated systems tend to focus on the miscommunication errors of the dialogue system (i.e., the robot itself), rather than the miscommunication or style of the human partner. In conversational agents, the research focus is also primarily to categorize errors made by the agent, not the human, including errors in ASR, surface realization, or appropriateness of the response (e.g., Higashinaka et al. (2015b); Paek and Horvitz (2000)). The more generic task-oriented and agent-based response-level errors from Higashinaka et al. (2015a) map well to the user miscommunication in the corpus we examine, including excess/lack of information, nonunderstanding, unclear intention, and misunderstanding. Works that focus specifically on miscommunication from the user when interacting with a robot include those categorizing referential ambiguity and impossible-to-execute commands (Marge and Rudnicky, 2015). These categories are common in the data we examine as well. In this analysis, we predict that trust wi"
W18-5012,L16-1504,0,0.0301679,"ed dialogue management strategies and offer concluding remarks on future work (Sections 7 and 8). 2 3 Stylistic Differences We describe two classes of stylistic differences for instruction-giving: differences in the verbosity of an instruction, and in the structure of the instruction. These styles emerge when decomposing a high-level plan or intent (e.g., exploring a physical space) into (potentially, but not necessarily) lowlevel instructions (e.g., how to explore the space, where to move, how to turn). Related Work A number of human-human direction-giving corpora exist, among them, ArtWalk (Liu et al., 2016), CReST (Eberhard et al., 2010), SCARE (Stoia et al., 2008), and SaGA (L¨ucking et al., 2010). The majority of existing analyses on these 111 3.1 Verbosity while looking at a live 2D-map built from the robot’s LIDAR scanner. A low bandwidth environment was simulated by disabling video streaming; instead, photos could be captured on-demand from the robot’s front-facing camera. To allow full natural language use, users were not provided example commands to the robot, though they were provided with a list of the robot’s capabilities which they could reference throughout the trials. Well-formed in"
W18-5012,L18-1017,1,0.612951,"plan of the user. In Dialogue 3, the user issues a single instruction “go through the other door” and waits until the instruction has been completed. Upon receiving completion feedback from the robot (“executing” and “done” responses), the next instruction, “take a picture”, is issued. Compare this with Dialogue 4, where the intents “face your starting position” and “send a picture” are compounded together and issued at the same time. This is classified as an Extended intent structure: instructions that have more than one expressed intent. These structural definitions were first described in Traum et al. (2018) to classify the composition of an instruction. In this work, we use these definitions to classify the style of the user. 4 4.1 Corpus Statistics The corpus contains 3,573 utterances from 20 users, totaling 18,336 words. 1,981 instructions were issued. The least verbose instruction observed is 1 word (“stop”), and the most verbose is 59 words (mean 7.3, SD 5.8). Of the total instructions, 1,383 are of the Minimal style, and 598, Extended. A moderate, positive correlation exists between higher verbosity and the Extended style in this corpus (rs (1969) = .613, p < .001)), supporting an intuition"
W18-5012,W17-2808,1,0.679528,"uman-robot collaboration has been studied with respect to engagement with the robot, and memory of information from the robot (Powers et al., 2007). two Minimal) or Extended if it contains more than one intent (Dialogue 4). Understanding stylistic differences can support the development of dialogue systems with strategies that tailor system responses to the user’s style, rather than constrain the user’s style to the expected input. The taxonomy is described in more detail in Section 3. We observe and analyze these stylistic differences in a corpus of human-robot direction-giving dialogue from Marge et al. (2017). These styles are not unique to this corpus; they emerge in other human-robot and human-human dialogue, such as TeamTalk (Marge and Rudnicky, 2011) and SCARE (Stoia et al., 2008). The corpus contains 60 dialogues from 20 participants (Section 4). The robot dialogue management in the corpus is controlled by a Wizard-of-Oz experimenter, allowing for the study of users’ style with a fluent and naturalistic partner (i.e., with an approximation of an idealized automated system). In Section 5, we investigate possible consequences and implications of these categorized styles in this corpus. We exami"
W18-5012,W15-4604,1,0.853954,", not the human, including errors in ASR, surface realization, or appropriateness of the response (e.g., Higashinaka et al. (2015b); Paek and Horvitz (2000)). The more generic task-oriented and agent-based response-level errors from Higashinaka et al. (2015a) map well to the user miscommunication in the corpus we examine, including excess/lack of information, nonunderstanding, unclear intention, and misunderstanding. Works that focus specifically on miscommunication from the user when interacting with a robot include those categorizing referential ambiguity and impossible-to-execute commands (Marge and Rudnicky, 2015). These categories are common in the data we examine as well. In this analysis, we predict that trust will have an effect on stylistic variations. Factors of trust in co-present and remote human-robot collaboration has been studied with respect to engagement with the robot, and memory of information from the robot (Powers et al., 2007). two Minimal) or Extended if it contains more than one intent (Dialogue 4). Understanding stylistic differences can support the development of dialogue systems with strategies that tailor system responses to the user’s style, rather than constrain the user’s sty"
W19-3322,W18-4912,1,0.829047,"e assertions. We found that more fine-grained speech act information is needed for human-robot dialogue. 5 Tense & Aspect AMR currently lacks information that specifies when an action occurs relative to speech time and whether or not this action is completed (if a past event) or able to be completed (if a future event). This information is essential for situated humanrobot dialogue, where successful collaboration depends on bridging the gap between differing perceptions of the shared environment and creating common ground (Chai et al., 2014). Our tense and aspect annotation scheme is based on Donatelli et al. (2018), who propose a four-way division of temporal annotation and three multi-valued categories for aspectual annotation that fits seamlessly into existing AMR annotation practice. We reduced the authors’ proposed temporal categories to three, to capture temporal relations before, during, and after the speech time. In addition to the aspectual categories proposed by Donatelli et al. (2018), we added the category :completable +/- to signal whether or not a hypothetical event has an end-goal that is executable for the robot (described further in Section 5.3). Our annotation categories for tense and a"
W19-3322,P13-1023,0,0.0277445,"systems for NLU. However, for many of these representations, there are no existing automatic parsers, limiting their feasibility for largerscale implementation. An exception is combinatory categorical grammar (CCG) (Steedman and Baldridge, 2011); CCG parsers have been incorporated in some current dialogue systems (Chai et al., 2014). Although promising, CCG parses closely mirror the input language, so systems making use of CCG parses still face the challenge of a great deal of linguistic variability that can be associated with a single intent. Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013), which also abstracts away from syntactic idiosyncrasies, and its corresponding parser (Hershcovich et al., 2017) merits future investigation. 7.2 7.3 Speech Act Taxonomies for Dialogue Speech acts have been used as part of the meaning representation of task-oriented dialogue systems since the 1970s (e.g., Bruce, 1975; Cohen and Perrault, 1979; Allen and Perrault, 1980). For a summary of some of the earlier work in this area, see Traum (1999). There have been a number of widely used speech act taxonomies, including an ISO standard (Bunt et al., 2012), however these often have to be particular"
W19-3322,P14-1134,0,0.0835122,"ture, a declarative statement that the instruction is being carried out, and an acknowledgment that it has been carried out are critical for conveying the robot’s current status in a live system. (m / move-01 :ARG0 (i / i) :direction (f / forward) :extent (d / distance-quantity :quant 10 :unit (f2 / foot))) Figure 2: Identical AMR for I will move / I am moving / I moved forward...10 feet. Although the imperative Move forward 10 feet should receive an AMR marker :mode imperative, our evaluation of the existing 1 https://github.com/amrisi/amr-guidelines/blob/master/ amr.md 201 5.1 parsers JAMR (Flanigan et al., 2014) and CAMR (Wang et al., 2015) showed that parser output does not include this marker as it is rare if not entirely missing from the AMR 1.0 or 2.0 training corpora (Section 6).2 As a result, the command to move forward also received the identical above AMR (Figure 2) in parser output. While this suggests that additional training data is needed that includes imperatives, this speaks to a larger issue of AMR: the existing representation is very limited with respect to speech act information. Current AMR includes :mode imperative and represents questions through the presence of amr-unknown standi"
W19-3322,W00-1015,0,0.0512794,"ch acts have been used as part of the meaning representation of task-oriented dialogue systems since the 1970s (e.g., Bruce, 1975; Cohen and Perrault, 1979; Allen and Perrault, 1980). For a summary of some of the earlier work in this area, see Traum (1999). There have been a number of widely used speech act taxonomies, including an ISO standard (Bunt et al., 2012), however these often have to be particularized to the domain of interest to be fully useful. Our approach with speech act types and subtypes representing a kind of semantic frame is perhaps most similar to the dialogue primitives of Hagen and Popowich (2000). Combining these types with fully compositional AMRs will allow flexible expressiveness, inferential power and tractable connection to robot action. 8 Conclusions This paper has proposed refinements for AMR to encode information necessary for situated humanrobot dialogue. Specifically, we elaborate 36 templates specific to situated dialogue that capture i) tense and aspect information; ii) speech acts; and iii) spatial parameters for robot execution. These refinements come after evaluating the coverage of existing AMR for a corpus of human-robot dialogue elicited from tasks related to search-"
W19-3322,W13-2322,1,0.855315,"by the participant. The RN then tele-operates the robot to complete the participant’s instructions. Finally, the RN provides spoken feedback to the DM of completed actions or problems that arose, which are relayed by the DM to the participant. A sample interaction can be seen in Table 1. The corpus contains dialogues from a total of 82 participants across three separate phased data collections. The participants’ speech and the RN’s speech are transcribed and time-aligned with text messages generated by the DM and sent either to the participant or the RN. 2.2 3 Background: AMR The AMR project (Banarescu et al., 2013) has created a manually annotated semantics bank of text drawn from a variety of genres. Each sentence is represented by a rooted directed acyclic graph in which variables (or graph nodes) are introduced for entities, events, properties, and states; leaves are labeled with concepts (e.g., (d / dog)). For ease of creation and manipulation, annotators work with the PENMAN representation of the same information (Penman Natural Language Group, 1989), as in Figure 1. Dialogue Structure Annotations (w / want-01 :ARG0 (d / dog) :ARG1 (p / pet-01 :ARG0 (g / girl) :ARG1 d)) The corpus also includes ann"
W19-3322,P17-1104,0,0.0184341,"r feasibility for largerscale implementation. An exception is combinatory categorical grammar (CCG) (Steedman and Baldridge, 2011); CCG parsers have been incorporated in some current dialogue systems (Chai et al., 2014). Although promising, CCG parses closely mirror the input language, so systems making use of CCG parses still face the challenge of a great deal of linguistic variability that can be associated with a single intent. Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013), which also abstracts away from syntactic idiosyncrasies, and its corresponding parser (Hershcovich et al., 2017) merits future investigation. 7.2 7.3 Speech Act Taxonomies for Dialogue Speech acts have been used as part of the meaning representation of task-oriented dialogue systems since the 1970s (e.g., Bruce, 1975; Cohen and Perrault, 1979; Allen and Perrault, 1980). For a summary of some of the earlier work in this area, see Traum (1999). There have been a number of widely used speech act taxonomies, including an ISO standard (Bunt et al., 2012), however these often have to be particularized to the domain of interest to be fully useful. Our approach with speech act types and subtypes representing a"
W19-3322,T75-2014,0,0.588771,"Although promising, CCG parses closely mirror the input language, so systems making use of CCG parses still face the challenge of a great deal of linguistic variability that can be associated with a single intent. Universal Conceptual Cognitive Annotation (UCCA) (Abend and Rappoport, 2013), which also abstracts away from syntactic idiosyncrasies, and its corresponding parser (Hershcovich et al., 2017) merits future investigation. 7.2 7.3 Speech Act Taxonomies for Dialogue Speech acts have been used as part of the meaning representation of task-oriented dialogue systems since the 1970s (e.g., Bruce, 1975; Cohen and Perrault, 1979; Allen and Perrault, 1980). For a summary of some of the earlier work in this area, see Traum (1999). There have been a number of widely used speech act taxonomies, including an ISO standard (Bunt et al., 2012), however these often have to be particularized to the domain of interest to be fully useful. Our approach with speech act types and subtypes representing a kind of semantic frame is perhaps most similar to the dialogue primitives of Hagen and Popowich (2000). Combining these types with fully compositional AMRs will allow flexible expressiveness, inferential po"
W19-3322,P13-2131,0,0.121004,"ection of communication. 204 Figure 7: Planned pipeline for implementing AMRs into our human-robot dialogue system: natural language instructions are parsed using AMR parsers into existing AMR, which is then converted via graph-to-graph transformation into one of our augmented AMR templates. If all required parameters in the template are complete and the instruction executable, it will be mapped onto one of the robot’s action specifications for execution. Clarifications and feedback from the robot are generated from the AMR templates. quate scores of .82, .82, and .91 using the Smatch metric (Cai and Knight, 2013). According to AMR development group communication, 2014, IAA Smatch scores on AMRs are generally between .7 and .8, depending on the complexity of the data. Having created a gold standard sample of our data, we ran both JAMR4 (Flanigan et al., 2014) and CAMR5 (Wang et al., 2015) on the same sample and obtained the Smatch scores when compared to the gold standard. We selected these two parsers to explore because JAMR was one of the first AMR parsers and uses a two-part algorithm to first identify concepts and then to build the maximum spanning connected subgraph of those concepts, adding in th"
W19-3322,N15-1114,0,0.046006,"ser-output AMRs to our set of in-domain AMRs. Rather than train parsers to parse directly into the augmented AMRs described here, a graph-to-graph transformation allows us to maintain the parser output as a representation of the sentence meanings themselves as input, while the output captures our contextual domain-specific layer and includes speaker intent on top of the sentence meaning. To create training data for graphto-graph transformation algorithms and to evaluate the coverage and quality of the set of in-domain 7 We plan to eventually model our graph-to-graph transformation on work by (Liu et al., 2015) for abstractive summarization with AMR, though in the opposite direction. 206 (Hakkani-T¨ur et al., 2016; Chen et al., 2016), the latter of which allows the system to take advantage of information from the discourse context to achieve improved NLU. Substantial challenges to these systems include working in domains with intents that have a large number of possible values for each slot and accommodation of out-ofvocabulary slot values (i.e. operating in a domain with a great deal of linguistic variability). able to perform slot-filling dialogue (Xu and Rudnicky, 2000) including clarification of"
W19-3322,P18-4016,1,0.891986,"Missing"
W19-3322,P18-1037,0,0.0227543,"Missing"
W19-3322,P14-5010,0,0.0028211,"of the data. Having created a gold standard sample of our data, we ran both JAMR4 (Flanigan et al., 2014) and CAMR5 (Wang et al., 2015) on the same sample and obtained the Smatch scores when compared to the gold standard. We selected these two parsers to explore because JAMR was one of the first AMR parsers and uses a two-part algorithm to first identify concepts and then to build the maximum spanning connected subgraph of those concepts, adding in the relations. CAMR, in contrast, starts by obtaining the dependency tree— in this case, using the Charniak parser6 and Stanford CoreNLP toolkit (Manning et al., 2014)—and then applies a series of transformations to the dependency tree, ultimately transforming it into an AMR graph. As seen in Table 3, CAMR performs better on both precision and recall when trained on AMR 1.0, thus obtaining the higher F-score. However, compared to their self-reported F-scores (0.58 for JAMR and 0.63 for CAMR) on other corpora, both under-perform on the human-robot dialogue data. Given the relatively poor performance of both parsers on the human-robot dialogue data and erParser Data Precision Recall F-score CAMR JAMR JAMR JAMR 1.0 1.0 2.0 2.0+D 0.33 0.27 0.46 0.56 0.51 0.44 0"
W19-3322,N15-1040,0,0.293404,"t the instruction is being carried out, and an acknowledgment that it has been carried out are critical for conveying the robot’s current status in a live system. (m / move-01 :ARG0 (i / i) :direction (f / forward) :extent (d / distance-quantity :quant 10 :unit (f2 / foot))) Figure 2: Identical AMR for I will move / I am moving / I moved forward...10 feet. Although the imperative Move forward 10 feet should receive an AMR marker :mode imperative, our evaluation of the existing 1 https://github.com/amrisi/amr-guidelines/blob/master/ amr.md 201 5.1 parsers JAMR (Flanigan et al., 2014) and CAMR (Wang et al., 2015) showed that parser output does not include this marker as it is rare if not entirely missing from the AMR 1.0 or 2.0 training corpora (Section 6).2 As a result, the command to move forward also received the identical above AMR (Figure 2) in parser output. While this suggests that additional training data is needed that includes imperatives, this speaks to a larger issue of AMR: the existing representation is very limited with respect to speech act information. Current AMR includes :mode imperative and represents questions through the presence of amr-unknown standing in for the concept or pola"
W19-3322,W17-2808,1,0.930987,"(provided by one senior and two recently trained AMR annotators), based on existing guidelines.1 We then examined how effectively these gold, guideline-based AMRs can capture the distinctions of interest for humanrobot dialogue and how accurately two available AMR parsers generate those gold annotations. Common instructions in the corpus include Move forward 10 feet, Take a picture, and Turn right 45 degrees. People also used landmarkbased instructions such as Move to face the yellow cone, and Go to the doorway to your right, although these were less common than the metricbased instructions (Marge et al., 2017). In response to these instructions from the DM to the participant, common feedback would be indications that an instruction will be carried out (I will move forward 10 feet), is in progress (Moving. . . ), or completed (I moved forward 10 feet). Given that current AMR guidelines do not make tense/aspect distinctions, these three types of feedback from the robot are represented identically under the current guidelines (see Figure 2). The distinctions between a promise to carry out an instruction in the future, a declarative statement that the instruction is being carried out, and an acknowledg"
W19-3322,W00-0309,0,0.772256,"raph transformation on work by (Liu et al., 2015) for abstractive summarization with AMR, though in the opposite direction. 206 (Hakkani-T¨ur et al., 2016; Chen et al., 2016), the latter of which allows the system to take advantage of information from the discourse context to achieve improved NLU. Substantial challenges to these systems include working in domains with intents that have a large number of possible values for each slot and accommodation of out-ofvocabulary slot values (i.e. operating in a domain with a great deal of linguistic variability). able to perform slot-filling dialogue (Xu and Rudnicky, 2000) including clarification of missing or vague descriptions and, if all required parameters are present, will use the domain-specific AMR for robot execution. 7 7.1 Related Work Semantic Representation There is a long-standing tradition of research in semantic representation within NLP, AI, as well as theoretical linguistics and philosophy (see Schubert (2015) for an overview). Thus, there are a variety of options that could be used within dialogue systems for NLU. However, for many of these representations, there are no existing automatic parsers, limiting their feasibility for largerscale impl"
W19-3322,C18-1313,0,0.0293395,"Missing"
W19-3322,J05-1004,0,0.105239,"ch acts work such as Austin (1975) and Searle (1969). To capture the range of speech acts present in the corpus, we arrived at an inventory of 36 unique speech acts specific to human-robot dialogue, inspired loosely by the dialogue move annotation of Marge et al. (2017). These 36 speech acts are classified into 5 types. In Figure 4, these are listed with the number of their subtypes in parentheses, along with a list of example subtypes for the type command. A full listing of subtypes and can be found in the Appendix. To integrate speech acts into AMR design, we selected existing AMR/PropBank (Palmer et al., 2005) rolesets corresponding to each speech act (e.g., command-02, assert-02, request-01, etc.) 5.3 Spatial Information A key component of successful human-robot collaboration is whether or not robot-directed commands are executable. In the dialogues represented in the corpus, for a command to be effectively executable by the robot, it must have a clear beginning and endpoint and comprise a basic action. For example, Move forward is not executable, since it lacks a clear endpoint; Move forward two feet, which identifies an endpoint, is executable. Additionally, a command such as Explore this room i"
yao-etal-2010-practical,W06-1303,1,\N,Missing
yao-etal-2010-practical,burger-etal-2006-competitive,0,\N,Missing
yao-etal-2010-practical,robinson-etal-2008-ask,1,\N,Missing
