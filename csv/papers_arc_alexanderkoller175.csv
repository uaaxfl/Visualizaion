2021.starsem-1.18,Script Parsing with Hierarchical Sequence Modelling,2021,-1,-1,3,1,985,fangzhou zhai,Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics,0,"Scripts capture commonsense knowledge about everyday activities and their participants. Script knowledge proved useful in a number of NLP tasks, such as referent prediction, discourse classification, and story generation. A crucial step for the exploitation of script knowledge is script parsing, the task of tagging a text with the events and participants from a certain activity. This task is challenging: it requires information both about the ways events and participants are usually uttered in surface language as well as the order in which they occur in the world. We show how to do accurate script parsing with a hierarchical sequence model and transfer learning. Our model improves the state of the art of event parsing by over 16 points F-score and, for the first time, accurately tags script participants."
2021.spnlp-1.3,Learning compositional structures for semantic graph parsing,2021,-1,-1,3,1,1025,jonas groschwitz,Proceedings of the 5th Workshop on Structured Prediction for NLP (SPNLP 2021),0,"AM dependency parsing is a method for neural semantic graph parsing that exploits the principle of compositionality. While AM dependency parsers have been shown to be fast and accurate across several graphbanks, they require explicit annotations of the compositional tree structures for training. In the past, these were obtained using complex graphbank-specific heuristics written by experts. Here we show how they can instead be trained directly on the graphs with a neural latent-variable model, drastically reducing the amount and complexity of manual heuristics. We demonstrate that our model picks up on several linguistic phenomena on its own and achieves comparable accuracy to supervised training, greatly facilitating the use of AM dependency parsing for new sembanks."
2021.emnlp-main.554,Aligning Actions Across Recipe Graphs,2021,-1,-1,6,0.731707,5431,lucia donatelli,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Recipe texts are an idiosyncratic form of instructional language that pose unique challenges for automatic understanding. One challenge is that a cooking step in one recipe can be explained in another recipe in different words, at a different level of abstraction, or not at all. Previous work has annotated correspondences between recipe instructions at the sentence level, often glossing over important correspondences between cooking steps across recipes. We present a novel and fully-parsed English recipe corpus, ARA (Aligned Recipe Actions), which annotates correspondences between individual actions across similar recipes with the goal of capturing information implicit for accurate recipe understanding. We represent this information in the form of recipe graphs, and we train a neural model for predicting correspondences on ARA. We find that substantial gains in accuracy can be obtained by taking fine-grained structural information about the recipes into account."
2020.sigdial-1.7,{MC}-Saar-Instruct: a Platform for {M}inecraft Instruction Giving Agents,2020,-1,-1,6,0.776172,9779,arne kohn,Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We present a comprehensive platform to run human-computer experiments where an agent instructs a human in Minecraft, a 3D blocksworld environment. This platform enables comparisons between different agents by matching users to agents. It performs extensive logging and takes care of all boilerplate, allowing to easily incorporate new agents to evaluate them. Our environment is prepared to evaluate any kind of instruction giving system, recording the interaction and all actions of the user. We provide example architects, a Wizard-of-Oz architect and set-up scripts to automatically download, build and start the platform."
2020.emnlp-main.323,Fast semantic parsing with well-typedness guarantees,2020,-1,-1,3,1,20360,matthias lindemann,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"AM dependency parsing is a linguistically principled method for neural semantic parsing with high accuracy across multiple graphbanks. It relies on a type system that models semantic valency but makes existing parsers slow. We describe an A* parser and a transition-based parser for AM dependency parsing which guarantee well-typedness and improve parsing speed by up to 3 orders of magnitude, while maintaining or improving accuracy."
2020.crac-1.4,Predicting Coreference in {A}bstract {M}eaning {R}epresentations,2020,-1,-1,2,0,11450,tatiana anikina,"Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference",0,"This work addresses coreference resolution in Abstract Meaning Representation (AMR) graphs, a popular formalism for semantic parsing. We evaluate several current coreference resolution techniques on a recently published AMR coreference corpus, establishing baselines for future work. We also demonstrate that coreference resolution can improve the accuracy of a state-of-the-art semantic parser on this corpus."
2020.coling-main.212,Story Generation with Rich Details,2020,-1,-1,3,1,985,fangzhou zhai,Proceedings of the 28th International Conference on Computational Linguistics,0,"Automatically generated stories need to be not only coherent, but also interesting. Apart from realizing a story line, the text also needs to include rich details to engage the readers. We propose a model that features two different generation components: an outliner, which proceeds the main story line to realize global coherence; a detailer, which supplies relevant details to the story in a locally coherent manner. Human evaluations show our model substantially improves the informativeness of generated text while retaining its coherence, outperforming various baselines."
2020.coling-main.252,Generating Instructions at Different Levels of Abstraction,2020,-1,-1,6,0.776172,9779,arne kohn,Proceedings of the 28th International Conference on Computational Linguistics,0,"When generating technical instructions, it is often convenient to describe complex objects in the world at different levels of abstraction. A novice user might need an object explained piece by piece, while for an expert, talking about the complex object (e.g. a wall or railing) directly may be more succinct and efficient. We show how to generate building instructions at different levels of abstraction in Minecraft. We introduce the use of hierarchical planning to this end, a method from AI planning which can capture the structure of complex objects neatly. A crowdsourcing evaluation shows that the choice of abstraction level matters to users, and that an abstraction strategy which balances low-level and high-level object descriptions compares favorably to ones which don{'}t."
2020.coling-main.267,Normalizing Compositional Structures Across Graphbanks,2020,12,0,4,0.731707,5431,lucia donatelli,Proceedings of the 28th International Conference on Computational Linguistics,0,"The emergence of a variety of graph-based meaning representations (MRs) has sparked an important conversation about how to adequately represent semantic structure. MRs exhibit structural differences that reflect different theoretical and design considerations, presenting challenges to uniform linguistic analysis and cross-framework semantic parsing. Here, we ask the question of which design differences between MRs are meaningful and semantically-rooted, and which are superficial. We present a methodology for normalizing discrepancies between MRs at the compositional level (Lindemann et al., 2019), finding that we can normalize the majority of divergent phenomena using linguistically-grounded rules. Our work significantly increases the match in compositional structure between MRs and improves multi-task learning (MTL) in a low-resource setting, serving as a proof of concept for future broad-scale cross-MR normalization."
2020.acl-main.463,"Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data",2020,-1,-1,2,0,11448,emily bender,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as {``}understanding{''} language or capturing {``}meaning{''}. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of {``}Taking Stock of Where We{'}ve Been and Where We{'}re Going{''}, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding."
W19-8601,Talking about what is not there: Generating indefinite referring expressions in {M}inecraft,2019,0,0,2,0.776172,9779,arne kohn,Proceedings of the 12th International Conference on Natural Language Generation,0,"When generating technical instructions, it is often necessary to describe an object that does not exist yet. For example, an NLG system which explains how to build a house needs to generate sentences like {``}build *a wall of height five to your left*{''} and {``}now build *a wall on the other side*.{''} Generating (indefinite) referring expressions to objects that do not exist yet is fundamentally different from generating the usual definite referring expressions, because the new object must be distinguished from an infinite set of possible alternatives. We formalize this problem and present an algorithm for generating such expressions, in the context of generating building instructions within the Minecraft video game."
P19-4002,Graph-Based Meaning Representations: Design and Processing,2019,0,0,1,1,987,alexander koller,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts,0,This tutorial is on representing and processing sentence meaning in the form of labeled directed graphs. The tutorial will (a) briefly review relevant background in formal and linguistic semantics; (b) semi-formally define a unified abstract view on different flavors of semantic graphs and associated terminology; (c) survey common frameworks for graph-based meaning representation and available graph banks; and (d) offer a technical overview of a representative selection of different parsing approaches.
P19-1008,Semantic Expressive Capacity with Bounded Memory,2019,25,0,2,0,5809,antoine venant,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"We investigate the capacity of mechanisms for compositional semantic parsing to describe relations between sentences and semantic representations. We prove that in order to represent certain relations, mechanisms which are syntactically projective must be able to remember an unbounded number of locations in the semantic representations, where nonprojective mechanisms need not. This is the first result of this kind, and has consequences both for grammar-based and for neural systems."
P19-1450,Compositional Semantic Parsing across Graphbanks,2019,26,1,3,1,20360,matthias lindemann,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Most semantic parsers that map sentences to graph-based meaning representations are hand-designed for specific graphbanks. We present a compositional neural semantic parser which achieves, for the first time, competitive accuracies across a diverse range of graphbanks. Incorporating BERT embeddings and multi-task learning improves the accuracy further, setting new states of the art on DM, PAS, PSD, AMR 2015 and EDS."
K19-2006,{S}aarland at {MRP} 2019: Compositional parsing across all graphbanks,2019,0,2,4,0.731707,5431,lucia donatelli,Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning,0,We describe the Saarland University submission to the shared task on Cross-Framework Meaning Representation Parsing (MRP) at the 2019 Conference on Computational Natural Language Learning (CoNLL).
W18-5018,Discovering User Groups for Natural Language Generation,2018,12,0,3,1,28053,nikos engonopoulos,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"We present a model which predicts how individual users of a dialog system understand and produce utterances based on user groups. In contrast to previous work, these user groups are not specified beforehand, but learned in training. We evaluate on two referring expression (RE) generation tasks; our experiments show that our model can identify user groups and learn how to most effectively talk to them, and can dynamically assign unseen users to the correct groups as they interact with the system."
P18-2099,Generalized chart constraints for efficient {PCFG} and {TAG} parsing,2018,19,0,3,0,5443,stefan grunewald,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Chart constraints, which specify at which string positions a constituent may begin or end, have been shown to speed up chart parsers for PCFGs. We generalize chart constraints to more expressive grammar formalisms and describe a neural tagger which predicts chart constraints at very high precision. Our constraints accelerate both PCFG and TAG parsing, and combine effectively with other pruning techniques (coarse-to-fine and supertagging) for an overall speedup of two orders of magnitude, while improving accuracy."
P18-1170,{AMR} dependency parsing with a typed semantic algebra,2018,24,1,5,1,1025,jonas groschwitz,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present a semantic parser for Abstract Meaning Representations which learns to parse strings into tree representations of the compositional structure of an AMR graph. This allows us to use standard neural techniques for supertagging and dependency tree parsing, constrained by a linguistically principled type system. We present two approximative decoding algorithms, which achieve state-of-the-art accuracy and outperform strong baselines."
W17-6810,A constrained graph algebra for semantic parsing with {AMR}s,2017,17,3,4,1,1025,jonas groschwitz,{IWCS} 2017 - 12th International Conference on Computational Semantics - Long papers,0,None
W17-6317,Coarse-To-Fine Parsing for Expressive Grammar Formalisms,2017,0,0,2,1,5808,christoph teichmann,Proceedings of the 15th International Conference on Parsing Technologies,0,"We generalize coarse-to-fine parsing to grammar formalisms that are more expressive than PCFGs and/or describe languages of trees or graphs. We evaluate our algorithm on PCFG, PTAG, and graph parsing. While we achieve the expected performance gains on PCFGs, coarse-to-fine does not help for PTAG and can even slow down parsing for graphs. We discuss the implications of this finding."
W17-6201,A Feature Structure Algebra for {FTAG},2017,14,0,1,1,987,alexander koller,Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms,0,None
W17-6202,Parsing Minimalist Languages with Interpreted Regular Tree Grammars,2017,14,1,2,1,1026,meaghan fowlie,Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms,0,None
W17-3520,Integrated sentence generation using charts,2017,0,0,1,1,987,alexander koller,Proceedings of the 10th International Conference on Natural Language Generation,0,"Integrating surface realization and the generation of referring expressions into a single algorithm can improve the quality of the generated sentences. Existing algorithms for doing this, such as SPUD and CRISP, are search-based and can be slow or incomplete. We offer a chart-based algorithm for integrated sentence generation and demonstrate its runtime efficiency."
P17-1063,Generating Contrastive Referring Expressions,2017,17,0,3,1,28425,martin villalba,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"The referring expressions (REs) produced by a natural language generation (NLG) system can be misunderstood by the hearer, even when they are semantically correct. In an interactive setting, the NLG system can try to recognize such misunderstandings and correct them. We present an algorithm for generating corrective REs that use contrastive focus ({``}no, the BLUE button{''}) to emphasize the information the hearer most likely misunderstood. We show empirically that these contrastive REs are preferred over REs without contrast marking."
E17-3008,{A}lto: Rapid Prototyping for Parsing and Translation,2017,15,2,3,0,26939,johannes gontrum,Proceedings of the Software Demonstrations of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We present Alto, a rapid prototyping tool for new grammar formalisms. Alto implements generic but efficient algorithms for parsing, translation, and training for a range of monolingual and synchronous grammar formalisms. It can easily be extended to new formalisms, which makes all of these algorithms immediately available for the new formalism."
W16-2402,Adaptive Importance Sampling from Finite State Automata,2016,0,0,3,1,5808,christoph teichmann,Proceedings of the {SIGFSM} Workshop on Statistical {NLP} and Weighted Automata,0,None
P16-1192,Efficient techniques for parsing with tree automata,2016,17,5,2,1,1025,jonas groschwitz,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Parsing for a wide variety of grammar formalisms can be performed by intersecting finite tree automata. However, naive implementations of parsing by intersection are very inefficient. We present techniques that speed up tree-automata-based parsing, to the point that it becomes practically feasible on realistic data when applied to context-free, TAG, and graph parsing. For graph parsing, we obtain the best runtimes in the literature."
W15-0126,Semantic Dependency Graph Parsing Using Tree Approximations,2015,23,3,2,0.352934,21438,vzeljko agic,Proceedings of the 11th International Conference on Computational Semantics,0,"In this contribution, we deal with graph parsing, i.e., mapping input strings to graph-structured output representations, using tree approximations. We experiment with the data from the SemEval 2014 Semantic Dependency Parsing (SDP) task. We define various tree approximation schemes for graphs, and make twofold use of them. First, we statically analyze the semantic dependency graphs, seeking to unscover which linguistic phenomena in particular require the additional annotation expressivity provided by moving from trees to graphs. We focus on undirected base cycles in the SDP graphs, and discover strong connections to grammatical control and coordination. Second, we make use of the approximations in a statistical parsing scenario. In it, we convert the training set graphs to dependency trees, and use the resulting treebanks to build standard dependency tree parsers. We perform lossy graph reconstructions on parser outputs, and evaluate our models as dependency graph parsers. Our system outperforms the baselines by a large margin, and evaluates as the best non-voting tree approximationxe2x80x93based parser on the SemEval 2014 data, scoring at just over 81% in labeled F1."
W15-0127,Semantic construction with graph grammars,2015,26,5,1,1,987,alexander koller,Proceedings of the 11th International Conference on Computational Semantics,0,"We introduce s-graph grammars, a new grammar formalism for computing graph-based semantic representations. Semantically annotated corpora which use graphs as semantic representations have recently become available, and there have been a number of data-driven systems for semantic parsing that can be trained on these corpora. However, it is hard to map the linguistic assumptions of these systems onto more classical insights on semantic construction. S-graph grammars use graphs as semantic representations, in a way that is consistent with more classical views on semantic construction. We illustrate this with a number of hand-written toy grammars, sketch the use of s-graph grammars for data-driven semantic parsing, and discuss formal aspects."
P15-2133,The Impact of Listener Gaze on Predicting Reference Resolution,2015,10,0,4,0,37466,nikolina koleva,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"We investigate the impact of listenerxe2x80x99s gaze on predicting reference resolution in situated interactions. We extend an existing model that predicts to which entity in the environment listeners will resolve a referring expression (RE). Our model makes use of features that capture which objects were looked at and for how long, reflecting listenersxe2x80x99 visual behavior. We improve a probabilistic model that considers a basic set of features for monitoring listenersxe2x80x99 movements in a virtual environment. Particularly, in complex referential scenes, where more objects next to the target are possible referents, gaze turns out to be beneficial and helps deciphering listenersxe2x80x99 intention. We evaluate performance at several prediction times before the listener performs an action, obtaining a highly significant accuracy gain."
P15-1143,Graph parsing with s-graph grammars,2015,15,15,2,1,1025,jonas groschwitz,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"A key problem in semantic parsing with graph-based semantic representations is graph parsing, i.e. computing all possible analyses of a given graph according to a grammar. This problem arises in training synchronous string-to-graph grammars, and when generating strings from them. We present two algorithms for graph parsing (bottom-up and top-down) with s-graph grammars. On the related problem of graph parsing with hyperedge replacement grammars, our implementations outperform the best previous system by several orders of magnitude."
J15-2002,Lexicalization and Generative Power in {CCG},2015,20,8,2,0.202442,12072,marco kuhlmann,Computational Linguistics,0,"The weak equivalence of Combinatory Categorial Grammar CCG and Tree-Adjoining Grammar TAG is a central result of the literature on mildly context-sensitive grammar formalisms. However, the categorial formalism for which this equivalence has been established differs significantly from the versions of CCG that are in use today. In particular, it allows restriction of combinatory rules on a per grammar basis, whereas modern CCG assumes a universal set of rules, isolating all cross-linguistic variation in the lexicon. In this article we investigate the formal significance of this difference. Our main result is that lexicalized versions of the classical CCG formalism are strictly less powerful than TAG."
W14-5002,Generating effective referring expressions using charts,2014,32,6,2,0,38341,nikolaos engonopoulos,Proceedings of the {INLG} and {SIGDIAL} 2014 Joint Session,0,"We present a novel approach for generating effective referring expressions (REs). We define a synchronous grammar formalism that relates surface strings with the sets of objects they describe through an abstract syntactic structure. The grammars may choose to require or not that REs are distinguishing. We then show how to compute a chart that represents, in finite space, the complete (possibly infinite) set of valid REs for a target object. Finally, we propose a probability model that predicts how the listener will understand the RE, and show how to compute the most effective RE according to this model from the chart."
S14-2081,{P}otsdam: Semantic Dependency Parsing by Bidirectional Graph-Tree Transformations and Syntactic Parsing,2014,18,4,2,0.352934,21438,vzeljko agic,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"We present the Potsdam systems that participated in the semantic dependency parsing shared task of SemEval 2014. They are based on linguistically motivated bidirectional transformations between graphs and trees and on utilization of syntactic dependency parsing. They were entered in both the closed track and the open track of the challenge, recording a peak average labeled F1 score of 78.60."
P13-1015,General binarization for parsing and translation,2013,23,3,2,0,41469,matthias buchse,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,Binarization of grammars is crucial for improving the complexity and performance of parsing and translation. We present a versatile binarization algorithm that can be tailored to a number of grammar formalisms by simply varying a formal parameter. We apply our algorithm to binarizing tree-to-string transducers used in syntax-based machine translation.
J13-4008,"Incremental, Predictive Parsing with Psycholinguistically Motivated {T}ree-{A}djoining {G}rammar",2013,67,34,3,0,5404,vera demberg,Computational Linguistics,0,"Psycholinguistic research shows that key properties of the human sentence processor are incrementality, connectedness partial structures contain no unattached nodes, and prediction upcoming syntactic structure is anticipated. There is currently no broad-coverage parsing model with these properties, however. In this article, we present the first broad-coverage probabilistic parser for PLTAG, a variant of TAG that supports all three requirements. We train our parser on a TAG-transformed version of the Penn Treebank and show that it achieves performance comparable to existing TAG parsers that are incremental but not predictive. We also use our PLTAG model to predict human reading times, demonstrating a better fit on the Dundee eye-tracking corpus than a standard surprisal model."
D13-1134,Predicting the Resolution of Referring Expressions from User Behavior,2013,14,8,4,1,28053,nikos engonopoulos,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"We present a statistical model for predicting how the user of an interactive, situated NLP system resolved a referring expression. The model makes an initial prediction based on the meaning of the utterance, and revises it continuously based on the userxe2x80x99s behavior. The combined model outperforms its components in predicting reference resolution and when to give feedback."
W12-4616,Decomposing {TAG} Algorithms Using Simple Algebraizations,2012,0,0,1,1,987,alexander koller,Proceedings of the 11th International Workshop on Tree Adjoining Grammars and Related Formalisms ({TAG}+11),0,"We review a number of different xe2x80x98algebraicxe2x80x99 perspectives on TAG and STAG in the framework of interpreted regular tree grammars (IRTGs). We then use this framework to derive a new parsing algorithm for TAGs, based on two algebras that describe strings and derived trees. Our algorithm is extremely modular, and can easily be adapted to the synchronous case."
W12-1604,Enhancing Referential Success by Tracking Hearer Gaze,2012,23,13,1,1,987,alexander koller,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"The ability to monitor the communicative success of its utterances and, if necessary, provide feedback and repair is useful for a dialog system. We show that in situated communication, eyetracking can be used to reliably and efficiently monitor the hearer's reference resolution process. An interactive system that draws on hearer gaze to provide positive or negative feedback after referring to objects outperforms baseline systems on metrics of referential success and user confusion."
E12-1077,Generation of landmark-based navigation instructions from open-source data,2012,24,9,2,0,43600,markus drager,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We present a system for the real-time generation of car navigation instructions with landmarks. Our system relies exclusively on freely available map data from OpenStreetMap, organizes its output to fit into the available time until the next driving maneuver, and reacts in real time to driving errors. We show that female users spend significantly less time looking away from the road when using our system compared to a baseline system."
W11-2902,A Generalized View on Parsing and Translation,2011,37,23,1,1,987,alexander koller,Proceedings of the 12th International Conference on Parsing Technologies,0,"We present a formal framework that generalizes a variety of monolingual and synchronous grammar formalisms for parsing and translation. Our framework is based on regular tree grammars that describe derivation trees, which are interpreted in arbitrary algebras. We obtain generic parsing algorithms by exploiting closure properties of regular tree languages."
W11-2815,Combining symbolic and corpus-based approaches for the generation of successful referring expressions,2011,29,16,2,1,42413,konstantina garoufi,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,We present an approach to the generation of referring expressions (REs) which computes the unique RE that it predicts to be fastest for the hearer to resolve. The system operates by learning a maximum entropy model for referential success from a corpus and using the model's weights as costs in a metric planning problem. Our system outperforms the baselines both on predicted RE success and on similarity to human-produced successful REs. A task-based evaluation in the context of the GIVE-2.5 Challenge on Generating Instructions in Virtual Environments verifies the higher RE success scores of the system.
W11-2829,Generation Challenges 2011 Preface,2011,0,0,3,0.0328947,26421,anja belz,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"Generation Challenges 2011 (GenChal'11) was the fifth round of shared-task evaluation competitions (STECs) involving the generation of natural language. It followed four previous events: the Pilot Attribute Selection for Generating Referring Expressions (ASGRE) Challenge in 2007 which had its results meeting at UCNLGMT in Copenhagen, Denmark; Referring Expression Generation (REG) Challenges in 2008, with a results meeting at INLG'08 in Ohio, US; Generation Challenges 2009 with a results meeting at ENLG'09 in Athens, Greece; and most recently Generation Challenges 2010 with a results meeting at INLG'10 in Trim, Ireland. More information about all these NLG STEC events can be found via the links on the Generation Challenges homepage (http://www.nltg.brighton.ac.uk/research/genchal11)."
W11-2845,Report on the Second Second Challenge on Generating Instructions in Virtual Environments ({GIVE}-2.5),2011,14,29,5,0,27625,kristina striegnitz,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"GIVE-2.5 evaluates eight natural language generation (NLG) systems that guide human users through solving a task in a virtual environment. The data is collected via the Internet, and to date, 536 interactions of subjects with one of the NLG systems have been recorded. The systems are compared using both task performance measures and subjective ratings by human users."
W11-2851,The {P}otsdam {NLG} systems at the {GIVE}-2.5 Challenge,2011,8,8,2,1,42413,konstantina garoufi,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"We present the Potsdam natural language generation systems P1 and P2 of the GIVE-2.5 Challenge. The systems implement two different referring expression generation models from Garoufi and Koller (2011) while behaving identically in all other respects. In particular, P1 combines symbolic and corpus-based methods for the generation of successful referring expressions, while P2 is based on a purely symbolic model which serves as a qualified baseline for comparison. We describe how the systems operated in the challenge and discuss the results, which indicate that P1 outperforms P2 in terms of several measures of referring expression success."
R11-1064,Learning Script Participants from Unlabeled Data,2011,26,11,2,1,21823,michaela regneri,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"We introduce a system that learns the participants of arbitrary given scripts. This system processes data from web experiments, in which each participant can be realized with different expressions. It computes participants by encoding semantic similarity and global structural information into an Integer Linear Program. An evaluation against a gold standard shows that we significantly outperform two informed baselines."
W10-4416,Sentence Generation as Planning with Probabilistic {LTAG},2010,22,7,2,0,33764,daniel bauer,Proceedings of the 10th International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+10),0,"We present PCRISP, a sentence generation system for probabilistic TAG grammars which performs sentence planning and surface realization in an integrated fashion, in the style of the SPUD system. PCRISP operates by converting the generation problem into a metric planning problem and solving it using an offthe-shelf planner. We evaluate PCRISP on the WSJ corpus and identify trade-offs between coverage, efficiency, and accuracy."
W10-4225,Generation Challenges 2010 Preface,2010,0,0,3,0.0328947,26421,anja belz,Proceedings of the 6th International Natural Language Generation Conference,0,None
W10-4233,Report on the Second {NLG} Challenge on Generating Instructions in Virtual Environments ({GIVE}-2),2010,15,49,1,1,987,alexander koller,Proceedings of the 6th International Natural Language Generation Conference,0,"We describe the second installment of the Challenge on Generating Instructions in Virtual Environments (GIVE-2), a shared task for the NLG community which took place in 2009--10. We evaluated seven NLG systems by connecting them to 1825 users over the Internet, and report the results of this evaluation in terms of objective and subjective measures."
P10-1004,Computing Weakest Readings,2010,29,11,1,1,987,alexander koller,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"We present an efficient algorithm for computing the weakest readings of semantically ambiguous sentences. A corpus-based evaluation with a large-scale grammar shows that our algorithm reduces over 80% of sentences to one or two readings, in negligible runtime, and thus makes it possible to work with semantic representations derived by deep large-scale grammars."
P10-1055,The Importance of Rule Restrictions in {CCG},2010,17,4,2,0.202442,12072,marco kuhlmann,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"Combinatory Categorial Grammar (CCG) is generally construed as a fully lexicalized formalism, where all grammars use one and the same universal set of rules, and cross-linguistic variation is isolated in the lexicon. In this paper, we show that the weak generative capacity of this 'pure' form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG."
P10-1100,Learning Script Knowledge with Web Experiments,2010,31,78,2,1,21823,michaela regneri,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"We describe a novel approach to unsupervised learning of the events that make up a script, along with constraints on their temporal ordering. We collect natural-language descriptions of script-specific event sequences from volunteers over the Internet. Then we compute a graph representation of the script's temporal structure using a multiple sequence alignment algorithm. The evaluation of our system shows that we outperform two informed baselines."
P10-1159,Automated Planning for Situated Natural Language Generation,2010,23,27,2,1,42413,konstantina garoufi,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"We present a natural language generation approach which models, exploits, and manipulates the non-linguistic context in situated communication, using techniques from AI planning. We show how to generate instructions which deliberately guide the hearer to a location that is convenient for the generation of simple referring expressions, and how to generate referring expressions with context-dependent adjectives. We implement and evaluate our approach in the framework of the Challenge on Generating Instructions in Virtual Environments, finding that it performs well even under the constraints of realtime generation."
gargett-etal-2010-give,The {GIVE}-2 Corpus of Giving Instructions in Virtual Environments,2010,7,47,3,0.47619,19304,andrew gargett,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We present the GIVE-2 Corpus, a new corpus of human instruction giving. The corpus was collected by asking one person in each pair of subjects to guide the other person towards completing a task in a virtual 3D environment with typed instructions. This is the same setting as that of the recent GIVE Challenge, and thus the corpus can serve as a source of data and as a point of comparison for NLG systems that participate in the GIVE Challenge. The instruction-giving data we collect is multilingual (45 German and 63 English dialogues), and can easily be extended to further languages by using our software, which we have made available. We analyze the corpus to study the effects of learning by repeated participation in the task and the effects of the participants' spatial navigation abilities. Finally, we present a novel annotation scheme for situated referring expressions and compare the referring expressions in the German and English data."
W09-0628,Report on the {F}irst {NLG} {C}hallenge on {G}enerating {I}nstructions in {V}irtual {E}nvironments ({GIVE}),2009,7,30,2,0,45130,donna byron,Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009),0,"We describe the first installment of the Challenge on Generating Instructions in Virtual Environments (GIVE), a new shared task for the NLG community. We motivate the design of the challenge, describe how we carried it out, and discuss the results of the system evaluation."
P09-2076,Validating the web-based evaluation of {NLG} systems,2009,7,12,1,1,987,alexander koller,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"The GIVE Challenge is a recent shared task in which NLG systems are evaluated over the Internet. In this paper, we validate this novel NLG evaluation methodology by comparing the Internet-based results with results we collected in a lab experiment. We find that the results delivered by both methods are consistent, but the Internet-based approach offers the statistical power necessary for more fine-grained evaluations and is cheaper to carry out."
E09-2009,The Software Architecture for the First Challenge on Generating Instructions in Virtual Environments,2009,40,6,1,1,987,alexander koller,Proceedings of the Demonstrations Session at {EACL} 2009,0,"The GIVE Challenge is a new Internet-based evaluation effort for natural language generation systems. In this paper, we motivate and describe the software infrastructure that we developed to support this challenge."
E09-1052,A Logic of Semantic Representations for Shallow Parsing,2009,15,3,1,1,987,alexander koller,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"One way to construct semantic representations in a robust manner is to enhance shallow language processors with semantic components. Here, we provide a model theory for a semantic formalism that is designed for this, namely Robust Minimal Recursion Semantics (rmrs). We show that rmrs supports a notion of entailment that allows it to form the basis for comparing the semantic output of different parses of varying depth."
E09-1053,Dependency Trees and the Strong Generative Capacity of {CCG},2009,20,11,1,1,987,alexander koller,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"We propose a novel algorithm for extracting dependencies from the derivations of a large fragment of CCG. Unlike earlier proposals, our dependency structures are always tree-shaped. We then use these dependency trees to compare the strong generative capacities of CCG and TAG and obtain surprising results: Both formalisms generate the same languages of derivation trees --- but the mechanisms they use to bring the words in these trees into a linear order are incomparable."
W08-1107,Referring Expressions as Formulas of Description Logic,2008,19,33,2,0,43683,carlos areces,Proceedings of the Fifth International Natural Language Generation Conference,0,"In this paper, we propose to reinterpret the problem of generating referring expressions (GRE) as the problem of computing a formula in a description logic that is only satisfied by the referent. This view offers a new unifying perspective under which existing GRE algorithms can be compared. We also show that by applying existing algorithms for computing simulation classes in description logic, we can obtain extremely efficient algorithms for relational referring expressions without any danger of running into infinite regress."
P08-2062,Efficient Processing of Underspecified Discourse Representations,2008,14,5,3,1,21823,michaela regneri,"Proceedings of ACL-08: HLT, Short Papers",0,"Underspecification-based algorithms for processing partially disambiguated discourse structure must cope with extremely high numbers of readings. Based on previous work on dominance graphs and weighted tree grammars, we provide the first possibility for computing an underspecified discourse description and a best discourse representation efficiently enough to process even the longest discourses in the RST Discourse Treebank."
P08-1026,Regular Tree Grammars as a Formalism for Scope Underspecification,2008,29,17,1,1,987,alexander koller,Proceedings of ACL-08: HLT,1,"We propose the use of regular tree grammars (RTGs) as a formalism for the underspecified processing of scope ambiguities. By applying standard results on RTGs, we obtain a novel algorithm for eliminating equivalent readings and the first efficient algorithm for computing the best reading of a scope ambiguity. We also show how to derive RTGs from more traditional underspecified descriptions."
P07-1043,Sentence generation as a planning problem,2007,13,31,1,1,987,alexander koller,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,We translate sentence generation from TAG grammars with semantic and pragmatic information into a planning problem by encoding the contribution of each word declaratively and explicitly. This allows us to exploit the performance of off-the-shelf planners. It also opens up new perspectives on referring expression generation and the relationship between language and action.
W06-3904,Towards a redundancy elimination algorithm for underspecified descriptions,2006,13,6,1,1,987,alexander koller,Proceedings of the Fifth International Workshop on Inference in Computational Semantics ({IC}o{S}-5),0,"This paper proposes an efficient algorithm for the redundancy elimination problem: Given an underspecified semantic representation (USR), compute an USR which has fewer readings, but still describes at least one representative of each semantic equivalence class of the original readings. The algorithm operates on underspecified chart representations which are derived from dominance graphs; it can be applied to the USRs computed by largescale grammars. To our knowledge, it is the first redundancy elimination algorithm which maintains underspecification, rather than just enumerating non-redundant readings."
P06-1052,An Improved Redundancy Elimination Algorithm for Underspecified Representations,2006,15,10,1,1,987,alexander koller,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We present an efficient algorithm for the redundancy elimination problem: Given an underspecified semantic representation (USR) of a scope ambiguity, compute an USR with fewer mutually equivalent readings. The algorithm operates on underspecified chart representations which are derived from dominance graphs; it can be applied to the USRs computed by large-scale grammars. We evaluate the algorithm on a corpus, and show that it reduces the degree of ambiguity significantly while taking negligible runtime."
W05-1105,The Evolution of Dominance Constraint Solvers,2005,11,9,1,1,987,alexander koller,Proceedings of Workshop on Software,0,"We describe the evolution of solvers for dominance constraints, a formalism used in underspecified semantics, and present a new graph-based solver using charts. An evaluation on real-world data shows that each solver (including the new one) is significantly faster than its predecessors. We believe that our strategy of successively tailoring a powerful formalism to the actual inputs is more generally applicable."
P05-3003,Efficient Solving and Exploration of Scope Ambiguities,2005,12,13,1,1,987,alexander koller,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"We present the currently most efficient solver for scope underspecification; it also converts between different underspecification formalisms and counts readings. Our tool makes the practical use of large-scale grammars with (underspecified) semantic output more feasible, and can be used in grammar debugging."
P04-1032,"{M}inimal {R}ecursion {S}emantics as Dominance Constraints: Translation, Evaluation, and Analysis",2004,13,26,2,0,51759,ruth fuchss,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,We show that a practical translation of MRS descriptions into normal dominance constraints is feasible. We start from a recent theoretical translation and verify its assumptions on the outputs of the English Resource Grammar (ERG) on the Redwoods corpus. The main assumption of the translation---that all relevant underspecified descriptions are nets---is validated for a large majority of cases; all non-nets computed by the ERG seem to be systematically incomplete.
P04-1051,Computing Locally Coherent Discourses,2004,17,43,3,0,51763,ernst althaus,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,We present the first algorithm that computes optimal orderings of sentences into a locally coherent discourse. The algorithm runs very efficiently on a variety of coherence measures from the literature. We also show that the discourse ordering problem is NP-complete and cannot be approximated.
C04-1026,A Relational Syntax-Semantics Interface Based on Dependency Grammar,2004,17,32,3,0,51326,ralph debusmann,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"We propose a syntax-semantics interface that realises the mapping between syntax and semantics as a relation and does not make functionality assumptions in either direction. This interface is stated in terms of Extensible Dependency Grammar (XDG), a grammar formalism we newly specify. XDG's constraint-based parser supports the concurrent flow of information between any two levels of linguistic representation, even when only partial analyses are available. This generalises the concept of underspecification."
C04-1049,Talking robots with {L}ego {M}ind{S}torms,2004,17,14,1,1,987,alexander koller,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"This paper shows how talking robots can be built from off-the-shelf components, based on the Lego MindStorms robotics platform. We present four robots that students created as final projects in a seminar we supervised. Because Lego robots are so affordable, we argue that it is now feasible for any dialogue researcher to tackle the interesting challenges at the robot-dialogue interface."
E03-1024,Underspecification formalisms: Hole semantics as dominance constraints,2003,0,0,1,1,987,alexander koller,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,None
P02-1003,Generation as Dependency Parsing,2002,13,55,1,1,987,alexander koller,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"Natural-Language Generation from flat semantics is an NP-complete problem. This makes it necessary to develop algorithms that run with reasonable efficiency in practice despite the high worst-case complexity. We show how to convert TAG generation problems into dependency parsing problems, which is useful because optimizations in recent dependency parsers based on constraint programming tackle exactly the combinatorics that make generation hard. Indeed, initial experiments display promising runtimes."
C02-1113,Natural Language and Inference in a Computer Game,2002,10,6,2,0,51434,malte gabsdil,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"We present an engine for text adventures - computer games with which the player interacts using natural language. The system employs current methods from computational linguistics and an efficient inference system for description logic to make the interaction more natural. The inference system is especially useful in the linguistic modules dealing with reference resolution and generation and we show how we use it to rank different readings in the case of referential and syntactic ambiguities. It turns out that the player's utterances are naturally restricted in the game scenario, which simplifies the language processing task."
P01-1011,Underspecified Beta Reduction,2001,15,6,3,0,53863,manuel bodirsky,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"For ambiguous sentences, traditional semantics construction produces large numbers of higher-order formulas, which must then be xcexb2-reduced individually. Underspecified versions can produce compact descriptions of all readings, but it is not known how to perform xcexb2-reduction on these descriptions. We show how to do this using xcexb2-reduction constraints in the constraint language for xcexbb-structures (CLLS)."
P00-1047,A Polynomial-Time Fragment of Dominance Constraints,2000,0,0,1,1,987,alexander koller,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,None
C00-1067,On Underspecified Processing of Dynamic Semantics,2000,15,11,1,1,987,alexander koller,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"We propose a new inference system which operates on underspecified semantic representations of scope and anaphora. This system exploits anaphoric accessibility conditions from dynamic semantics to disambiguate scope ambiguities if possible. The main feature of the system is that it deals with underspecified descriptions directly, i. e. without enumerating readings."
