1991.tc-1.14,C90-3006,0,0.167519,"Missing"
1991.tc-1.14,C90-3059,0,0.0491463,"ormation not contained in the 'source text' at all (a similar idea for 'automated text composition' in Japanese has been suggested by Saito & Tomita 1986, while Ahmad Zaki & Noor 1991 describe a system for composing official letters in Malay). Such a system has a good division of both knowledge and labour, since the system knows about translation, while the user knows only about the desired communicative content of the message. In this connection, we should also mention the idea of multilingual text generation 'without a source text' (Somers et al. 1990), an approach shared by the FoG system (Bourbeau et al. 1990, Kittredge & Polguère 1991a,b). 156 Translating and the Computer 13 Finally, we should mention 'Example-Based MT' (EBMT) (Sumita et al. 1990, Jones 1991, Sato 1991, Sumita & Iida 1991) where a corpus of texts with their translations serves as a knowledge base for MT: previously translated text fragments are seen as examples on which to base the translation of a given text. This idea stems from a general proposal made by Kay in 1987 (Kay 1989:195), and also seems to have been in Nagao's mind in his (1984) article. The idea is to use a multilingual corpus of texts already translated (by humans)"
1991.tc-1.14,J90-2002,0,0.0958692,"database. Unlike in rule-based MT, there is not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen repercussions on the rest of the system, which sometimes do not surface until many months after the change was made, and therefore are extremely difficult to trace. The use of existing translations also underlies the approach called 'Memory-Based MT' (Sato & Nagao 1990, Kitano et al. 1991), and the use of the 'Bilingual Knowledge Bank' in DLT (Sadler 1989, 1991, Sadler & Vendelmans 1990), while EBMT can be regarded as a special case of Corpus-Based MT (cf. Brown et al. 1990, 1991; Chen et al. 1991; Gale & Church 1991; Sebba 1991). THE PROPOSED SYSTEM How do these new research directions fit together? Each area of research outlined in above can be classified in terms of five features: monolingual, i.e. is the system designed for monolingual users? dialogue-based, i.e. does the system assume a system-user dialogue? example-based, i.e. does the system use example translations? context-based, i.e. does the system use contextual knowledge? sublanguage-based, i.e. does the system use domain knowledge? However, not all features are common to any one piece of research i"
1991.tc-1.14,P91-1022,0,0.0843194,"Missing"
1991.tc-1.14,1991.mtsummit-papers.5,0,0.217993,"-based MT, there is not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen repercussions on the rest of the system, which sometimes do not surface until many months after the change was made, and therefore are extremely difficult to trace. The use of existing translations also underlies the approach called 'Memory-Based MT' (Sato & Nagao 1990, Kitano et al. 1991), and the use of the 'Bilingual Knowledge Bank' in DLT (Sadler 1989, 1991, Sadler & Vendelmans 1990), while EBMT can be regarded as a special case of Corpus-Based MT (cf. Brown et al. 1990, 1991; Chen et al. 1991; Gale & Church 1991; Sebba 1991). THE PROPOSED SYSTEM How do these new research directions fit together? Each area of research outlined in above can be classified in terms of five features: monolingual, i.e. is the system designed for monolingual users? dialogue-based, i.e. does the system assume a system-user dialogue? example-based, i.e. does the system use example translations? context-based, i.e. does the system use contextual knowledge? sublanguage-based, i.e. does the system use domain knowledge? However, not all features are common to any one piece of research in a generalised and cohe"
1991.tc-1.14,P91-1023,0,0.035548,"s not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen repercussions on the rest of the system, which sometimes do not surface until many months after the change was made, and therefore are extremely difficult to trace. The use of existing translations also underlies the approach called 'Memory-Based MT' (Sato & Nagao 1990, Kitano et al. 1991), and the use of the 'Bilingual Knowledge Bank' in DLT (Sadler 1989, 1991, Sadler & Vendelmans 1990), while EBMT can be regarded as a special case of Corpus-Based MT (cf. Brown et al. 1990, 1991; Chen et al. 1991; Gale & Church 1991; Sebba 1991). THE PROPOSED SYSTEM How do these new research directions fit together? Each area of research outlined in above can be classified in terms of five features: monolingual, i.e. is the system designed for monolingual users? dialogue-based, i.e. does the system assume a system-user dialogue? example-based, i.e. does the system use example translations? context-based, i.e. does the system use contextual knowledge? sublanguage-based, i.e. does the system use domain knowledge? However, not all features are common to any one piece of research in a generalised and coherent manner. In cont"
1991.tc-1.14,C90-3081,0,0.132978,"ent innovations have nevertheless provided encouraging signs that there are new avenues to explore in the field of MT. Although first suggested by Kay (1973), the idea of an MT system for monolingual user seems not to have been followed up until quite recently (unless one considers TITUS (Ducrot 1985) to be an MT system). Several proposals for interactive MT for monolingual users appear to have been initiated at about the same time, including DLT (Schubert 1986), the CMU system (Carbonell & Tomita 1987), Ntran (Whitelock et al. 1986, Johnson & Whitelock 1987), Zajac's (1988) system, and XTRA (Huang 1990). In systems for monolingual users it is the system which knows about translation into the target language, and the user who knows about the global context of the source text, and about the finer subtleties of the source language. The system has linguistic knowledge of the source language, but relies on the user to supply contextual and real-world knowledge in the form of an interaction. On the other hand, once the source text has been sufficiently analyzed, the system takes over completely. There is no conflict between what the system assumes to be the extent of the user's knowledge, nor in t"
1991.tc-1.14,C88-1053,0,0.165273,"t recognised by at least one of the manufacturers of CAT systems (Seal 1992). The use of MT with restricted input was probably first reported by Elliston (1979), and gained respectability through the great success of the Météo project (Chandioux & Guérard 1981), where MT took over a translation task too boring for any human doing it to last more than a few months, yet sufficiently constrained to allow an MT system to be devised which only makes mistakes when the input is ill-formed. Nevertheless, it is only recently that the obvious connection with 'sublanguage' has been made (Kittredge 1987, Isabelle et al. 1988, Kosaka et al. 1988, Luckhardt 1991). On the negative side, it is still the case that typically the MT system dictates the restrictions rather than vice versa: as recently as two years ago at this conference, Pym (1990) described the use of prescriptive writing rules to enable Weidner's MicroCat system to be used, and Sager talked positively of ""'Systran French' or 'Logos German' ... system-specific target language forms ... based on the designers' simplified conception of the source language"" (Sager 1990:7). Frankly, we do not see this in such a positive light. The typical computational and"
1991.tc-1.14,C88-2142,0,0.406672,"1989:195), and also seems to have been in Nagao's mind in his (1984) article. The idea is to use a multilingual corpus of texts already translated (by humans) as a knowledge base in an MT system, so that the existing (and guaranteed) translations serve as a model for new translations. EBMT proceeds by finding suitable examples in the database and then recombining them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text, a problem that we have been working on independently at UMIST (Carroll 1990) cf. also Kay & Röscheisen (1988) and Kitano & Higuchi (1991). The advantages of EBMT are that translation quality is assured, because the example translations are real. The system knows its limitations: if a suitable example cannot be found, the system will not translate on a word-for-word basis as in rule-based MT. This approach does not depend on structure preservation as a first choice, mentioned above. And perhaps most interesting of all, it is easy to extend an EBMT system: we simply add more examples to the database. Unlike in rule-based MT, there is not the overhead of 'entropy' of performance, where the addition of a"
1991.tc-1.14,1991.tc-1.14,1,0.0541379,"o have been in Nagao's mind in his (1984) article. The idea is to use a multilingual corpus of texts already translated (by humans) as a knowledge base in an MT system, so that the existing (and guaranteed) translations serve as a model for new translations. EBMT proceeds by finding suitable examples in the database and then recombining them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text, a problem that we have been working on independently at UMIST (Carroll 1990) cf. also Kay & Röscheisen (1988) and Kitano & Higuchi (1991). The advantages of EBMT are that translation quality is assured, because the example translations are real. The system knows its limitations: if a suitable example cannot be found, the system will not translate on a word-for-word basis as in rule-based MT. This approach does not depend on structure preservation as a first choice, mentioned above. And perhaps most interesting of all, it is easy to extend an EBMT system: we simply add more examples to the database. Unlike in rule-based MT, there is not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen rep"
1991.tc-1.14,E91-1054,0,0.0812191,"cturers of CAT systems (Seal 1992). The use of MT with restricted input was probably first reported by Elliston (1979), and gained respectability through the great success of the Météo project (Chandioux & Guérard 1981), where MT took over a translation task too boring for any human doing it to last more than a few months, yet sufficiently constrained to allow an MT system to be devised which only makes mistakes when the input is ill-formed. Nevertheless, it is only recently that the obvious connection with 'sublanguage' has been made (Kittredge 1987, Isabelle et al. 1988, Kosaka et al. 1988, Luckhardt 1991). On the negative side, it is still the case that typically the MT system dictates the restrictions rather than vice versa: as recently as two years ago at this conference, Pym (1990) described the use of prescriptive writing rules to enable Weidner's MicroCat system to be used, and Sager talked positively of ""'Systran French' or 'Logos German' ... system-specific target language forms ... based on the designers' simplified conception of the source language"" (Sager 1990:7). Frankly, we do not see this in such a positive light. The typical computational and linguistic design features of the '2n"
1991.tc-1.14,C82-1034,0,0.48552,"tic high quality MT (FAHQT) of unrestricted texts is an unattainable goal. Amongst the strategies proposed to mitigate this, the most popular have been interaction with a user, and restrictions on the input. Coupled with certain typical computational and linguistic design features, these approaches have come to be known as '2nd generation MT' (Vauquois 1976). But there is now a feeling that 2nd generation MT has in some sense failed, or at least reached an impasse (cf. Somers 1990). The interactive solution comes in the form of the widely promoted 'Translator's Workbench' idea (e.g. Kay 1980, Melby 1982), the main aims of which are to help translators to translate texts. Typically, the system proposes a translation, and then has a more or less user-friendly interactive post-editing phase; in some more ambitious cases, the system attempts to translate the input text with assistance from the human user in the form of interactions to help disambiguate source text or make lexical and stylistic selections in the target text. In this scenario, both the system and the user have knowledge about both source and target language, and it is sometimes difficult to see where the most appropriate division o"
1991.tc-1.14,C90-3101,0,0.0944652,"most interesting of all, it is easy to extend an EBMT system: we simply add more examples to the database. Unlike in rule-based MT, there is not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen repercussions on the rest of the system, which sometimes do not surface until many months after the change was made, and therefore are extremely difficult to trace. The use of existing translations also underlies the approach called 'Memory-Based MT' (Sato & Nagao 1990, Kitano et al. 1991), and the use of the 'Bilingual Knowledge Bank' in DLT (Sadler 1989, 1991, Sadler & Vendelmans 1990), while EBMT can be regarded as a special case of Corpus-Based MT (cf. Brown et al. 1990, 1991; Chen et al. 1991; Gale & Church 1991; Sebba 1991). THE PROPOSED SYSTEM How do these new research directions fit together? Each area of research outlined in above can be classified in terms of five features: monolingual, i.e. is the system designed for monolingual users? dialogue-based, i.e. does the system assume a system-user dialogue? example-based, i.e. does the system use example translations? context-based, i.e. does the system use contextual knowledge? sublanguage-based, i.e. does the system u"
1991.tc-1.14,C90-3044,0,0.0508102,"ased MT. This approach does not depend on structure preservation as a first choice, mentioned above. And perhaps most interesting of all, it is easy to extend an EBMT system: we simply add more examples to the database. Unlike in rule-based MT, there is not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen repercussions on the rest of the system, which sometimes do not surface until many months after the change was made, and therefore are extremely difficult to trace. The use of existing translations also underlies the approach called 'Memory-Based MT' (Sato & Nagao 1990, Kitano et al. 1991), and the use of the 'Bilingual Knowledge Bank' in DLT (Sadler 1989, 1991, Sadler & Vendelmans 1990), while EBMT can be regarded as a special case of Corpus-Based MT (cf. Brown et al. 1990, 1991; Chen et al. 1991; Gale & Church 1991; Sebba 1991). THE PROPOSED SYSTEM How do these new research directions fit together? Each area of research outlined in above can be classified in terms of five features: monolingual, i.e. is the system designed for monolingual users? dialogue-based, i.e. does the system assume a system-user dialogue? example-based, i.e. does the system use exam"
1991.tc-1.14,P91-1024,0,0.0625265,"scribe a system for composing official letters in Malay). Such a system has a good division of both knowledge and labour, since the system knows about translation, while the user knows only about the desired communicative content of the message. In this connection, we should also mention the idea of multilingual text generation 'without a source text' (Somers et al. 1990), an approach shared by the FoG system (Bourbeau et al. 1990, Kittredge & Polguère 1991a,b). 156 Translating and the Computer 13 Finally, we should mention 'Example-Based MT' (EBMT) (Sumita et al. 1990, Jones 1991, Sato 1991, Sumita & Iida 1991) where a corpus of texts with their translations serves as a knowledge base for MT: previously translated text fragments are seen as examples on which to base the translation of a given text. This idea stems from a general proposal made by Kay in 1987 (Kay 1989:195), and also seems to have been in Nagao's mind in his (1984) article. The idea is to use a multilingual corpus of texts already translated (by humans) as a knowledge base in an MT system, so that the existing (and guaranteed) translations serve as a model for new translations. EBMT proceeds by finding suitable examples in the databas"
1992.tmi-1.13,1990.tc-1.1,0,0.0250708,"user, and what the user already knows, or between the extent to which the system or the user should take the initiative, which might differ from occasion to occasion. Although first suggested by Kay [20], the alternative idea of an MT system for a monolingual user seems only to have really been followed up about five years ago, when several proposals for interactive MT for monolingual users were apparently initiated [7,14,17,38,48,49]. The idea to develop this sort of interaction in the direction of a more sophisticated clarification dialogue is now gaining currency with the emergence of DBMT [3,4,47] and the notion of 'MT without a source text' [43], where the dialogue aims not merely at disambiguating a given text, but in helping the user to compose it in the first place. 2.2 MT as multilingual text generation If there is no source text, the focus obviously falls upon the generation of the target text(s), a problem in MT which was for a long time seriously underestimated (cf. [27]). Our present approach has been influenced by the 'phrasebook' approach to speech translation [44], in which set phrases are stored, as in a holidaymaker's phrasebook, and retrieved by the fairly crude, though"
1992.tmi-1.13,C90-3006,0,0.104092,"user, and what the user already knows, or between the extent to which the system or the user should take the initiative, which might differ from occasion to occasion. Although first suggested by Kay [20], the alternative idea of an MT system for a monolingual user seems only to have really been followed up about five years ago, when several proposals for interactive MT for monolingual users were apparently initiated [7,14,17,38,48,49]. The idea to develop this sort of interaction in the direction of a more sophisticated clarification dialogue is now gaining currency with the emergence of DBMT [3,4,47] and the notion of 'MT without a source text' [43], where the dialogue aims not merely at disambiguating a given text, but in helping the user to compose it in the first place. 2.2 MT as multilingual text generation If there is no source text, the focus obviously falls upon the generation of the target text(s), a problem in MT which was for a long time seriously underestimated (cf. [27]). Our present approach has been influenced by the 'phrasebook' approach to speech translation [44], in which set phrases are stored, as in a holidaymaker's phrasebook, and retrieved by the fairly crude, though"
1992.tmi-1.13,J90-2002,0,0.284925,"expressed by them. 2.3 Example-Based MT (EBMT) and corpus-based MT Perhaps the most important feature of the system is that it follows very closely some of the ideas of EBMT, which originated with Nagao [30], but have only recently been taken up [18,23,32,33,34,36,37,45,46]. In EBMT, a corpus of texts with their translations (which have been done by humans, and so are of guaranteed quality) serves as a knowledge base for MT: previously translated text fragments are seen as examples on which to base the translation of a given text. EBMT can be regarded as a special case of corpus-based MT (cf. [5,10,39]). 152 EBMT proceeds by finding suitable examples in the database and then 'recombining' them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text ([8,22,40]), and the alignment of translation pairs, given a bilingual corpus ([6,9,10,12,23]). The advantages of EBMT are that translation quality is assured, because the example translations are real. The system knows its limitations: if a suitable example cannot be found, the system will not translate on a word-for-word basis as in rule-based MT. This approach"
1992.tmi-1.13,P91-1022,0,0.0542797,"ons (which have been done by humans, and so are of guaranteed quality) serves as a knowledge base for MT: previously translated text fragments are seen as examples on which to base the translation of a given text. EBMT can be regarded as a special case of corpus-based MT (cf. [5,10,39]). 152 EBMT proceeds by finding suitable examples in the database and then 'recombining' them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text ([8,22,40]), and the alignment of translation pairs, given a bilingual corpus ([6,9,10,12,23]). The advantages of EBMT are that translation quality is assured, because the example translations are real. The system knows its limitations: if a suitable example cannot be found, the system will not translate on a word-for-word basis as in rule-based MT. This approach does not depend on structure preservation as a first choice (cf. [41], p.84), and perhaps most interesting of all, it is easy to extend an EBMT system: we simply add more examples to the database. Unlike in rule-based MT, there is not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen re"
1992.tmi-1.13,1991.mtsummit-papers.5,0,0.0873851,"expressed by them. 2.3 Example-Based MT (EBMT) and corpus-based MT Perhaps the most important feature of the system is that it follows very closely some of the ideas of EBMT, which originated with Nagao [30], but have only recently been taken up [18,23,32,33,34,36,37,45,46]. In EBMT, a corpus of texts with their translations (which have been done by humans, and so are of guaranteed quality) serves as a knowledge base for MT: previously translated text fragments are seen as examples on which to base the translation of a given text. EBMT can be regarded as a special case of corpus-based MT (cf. [5,10,39]). 152 EBMT proceeds by finding suitable examples in the database and then 'recombining' them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text ([8,22,40]), and the alignment of translation pairs, given a bilingual corpus ([6,9,10,12,23]). The advantages of EBMT are that translation quality is assured, because the example translations are real. The system knows its limitations: if a suitable example cannot be found, the system will not translate on a word-for-word basis as in rule-based MT. This approach"
1992.tmi-1.13,P91-1023,0,0.0245111,"ons (which have been done by humans, and so are of guaranteed quality) serves as a knowledge base for MT: previously translated text fragments are seen as examples on which to base the translation of a given text. EBMT can be regarded as a special case of corpus-based MT (cf. [5,10,39]). 152 EBMT proceeds by finding suitable examples in the database and then 'recombining' them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text ([8,22,40]), and the alignment of translation pairs, given a bilingual corpus ([6,9,10,12,23]). The advantages of EBMT are that translation quality is assured, because the example translations are real. The system knows its limitations: if a suitable example cannot be found, the system will not translate on a word-for-word basis as in rule-based MT. This approach does not depend on structure preservation as a first choice (cf. [41], p.84), and perhaps most interesting of all, it is easy to extend an EBMT system: we simply add more examples to the database. Unlike in rule-based MT, there is not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen re"
1992.tmi-1.13,C90-3081,0,0.028095,"where the most appropriate division of labour between the computer and the human should occur, and there is sometimes even a conflict between what the system offers the translator-user, and what the user already knows, or between the extent to which the system or the user should take the initiative, which might differ from occasion to occasion. Although first suggested by Kay [20], the alternative idea of an MT system for a monolingual user seems only to have really been followed up about five years ago, when several proposals for interactive MT for monolingual users were apparently initiated [7,14,17,38,48,49]. The idea to develop this sort of interaction in the direction of a more sophisticated clarification dialogue is now gaining currency with the emergence of DBMT [3,4,47] and the notion of 'MT without a source text' [43], where the dialogue aims not merely at disambiguating a given text, but in helping the user to compose it in the first place. 2.2 MT as multilingual text generation If there is no source text, the focus obviously falls upon the generation of the target text(s), a problem in MT which was for a long time seriously underestimated (cf. [27]). Our present approach has been influenc"
1992.tmi-1.13,C88-1053,0,0.25279,"preservation as a first choice (cf. [41], p.84), and perhaps most interesting of all, it is easy to extend an EBMT system: we simply add more examples to the database. Unlike in rule-based MT, there is not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen repercussions on the rest of the system, which sometimes do not surface until many months after the change was made, and therefore are extremely difficult to trace. 2.4 Sublanguage MT It is again relatively recent that the notion of MT with restricted input has come to be associated with 'sublanguage' ([16,24,25,26]), as opposed to the case previously, when it was typically the MT system which dictated the restrictions rather than vice versa (e.g. [11,31]). In the system described here, the sublanguage approach gives us not only vocabulary and syntax, but also the contextual and domain knowledge employed by the system. And, in keeping with the strong corpus-based approach, these knowledge sources are derived directly from an analysis of corpora ([2]), not from some linguist's introspection, as is the case in conventional rule-based MT systems. An additional point of interest in this research is the contr"
1992.tmi-1.13,C88-2142,0,0.0586019,"[18,23,32,33,34,36,37,45,46]. In EBMT, a corpus of texts with their translations (which have been done by humans, and so are of guaranteed quality) serves as a knowledge base for MT: previously translated text fragments are seen as examples on which to base the translation of a given text. EBMT can be regarded as a special case of corpus-based MT (cf. [5,10,39]). 152 EBMT proceeds by finding suitable examples in the database and then 'recombining' them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text ([8,22,40]), and the alignment of translation pairs, given a bilingual corpus ([6,9,10,12,23]). The advantages of EBMT are that translation quality is assured, because the example translations are real. The system knows its limitations: if a suitable example cannot be found, the system will not translate on a word-for-word basis as in rule-based MT. This approach does not depend on structure preservation as a first choice (cf. [41], p.84), and perhaps most interesting of all, it is easy to extend an EBMT system: we simply add more examples to the database. Unlike in rule-based MT, there is not the overh"
1992.tmi-1.13,E91-1054,0,0.0179995,"preservation as a first choice (cf. [41], p.84), and perhaps most interesting of all, it is easy to extend an EBMT system: we simply add more examples to the database. Unlike in rule-based MT, there is not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen repercussions on the rest of the system, which sometimes do not surface until many months after the change was made, and therefore are extremely difficult to trace. 2.4 Sublanguage MT It is again relatively recent that the notion of MT with restricted input has come to be associated with 'sublanguage' ([16,24,25,26]), as opposed to the case previously, when it was typically the MT system which dictated the restrictions rather than vice versa (e.g. [11,31]). In the system described here, the sublanguage approach gives us not only vocabulary and syntax, but also the contextual and domain knowledge employed by the system. And, in keeping with the strong corpus-based approach, these knowledge sources are derived directly from an analysis of corpora ([2]), not from some linguist's introspection, as is the case in conventional rule-based MT systems. An additional point of interest in this research is the contr"
1992.tmi-1.13,1992.tmi-1.4,0,0.230654,"user's input with the stored examples, parsing of a traditional nature may be employed, but the primary technique will involve stochastic or other pattern matching techniques. Because the aim is to match inputs with similar, but usually not identical examples in the database, the matching techniques must be flexible enough to locate a range of candidate matches against a given input. For this reason, pattern matching incorporating a similarity measure is indicated, such as the techniques proposed in [8,22,23,40], though we are also experimenting with a connectionist approach to this problem ([28]). 156 The data forming the multilingual corpus of examples are derived empirically from real-life examples of job adverts. For practical reasons, we cannot expect to have available a truly parallel corpus of texts in this domain. The contrastive linguistic knowledge of the system cannot therefore be captured by paired examples of translational equivalents as in the IBM statistical approach for example ([5,6]), so the more abstract intentional model is relied on as a kind of mediator, where it is the functional rather than formal property of the text fragment that gives its target language cou"
1992.tmi-1.13,C82-1034,0,0.0253375,"ratificational approach to both linguistic and computing aspects, leading to a predominantly bottom-up compositional system design, and the reliance on the intuitions and introspection of linguists rather than 'real' data. The system design is influenced by a number of recent research directions including Dialogue-Based MT with a monolingual user, Example-Based MT, corpus-based MT, and the use of sublanguage. 2.1 Dialogue-Based MT (DBMT) with a monolingual user Until recently, the interactive approach to MT almost inevitably came in the form of the widely promoted Translator's Workbench' idea [21,29], the main aims of which are to help translators to translate texts. Now it has been acknowledged that there is a drawback in this approach, which is that it is sometimes difficult to see where the most appropriate division of labour between the computer and the human should occur, and there is sometimes even a conflict between what the system offers the translator-user, and what the user already knows, or between the extent to which the system or the user should take the initiative, which might differ from occasion to occasion. Although first suggested by Kay [20], the alternative idea of an"
1992.tmi-1.13,C90-3101,0,0.0203272,"fective, technique of recognising keywords in a particular order in the input speech signal. It also builds on research on interactive generation of stereotypical texts ([1,19,35]), where texts in certain restricted domains are stored and retrieved as appropriate through interaction with users, and are reformulated to fulfill the specific requirements expressed by them. 2.3 Example-Based MT (EBMT) and corpus-based MT Perhaps the most important feature of the system is that it follows very closely some of the ideas of EBMT, which originated with Nagao [30], but have only recently been taken up [18,23,32,33,34,36,37,45,46]. In EBMT, a corpus of texts with their translations (which have been done by humans, and so are of guaranteed quality) serves as a knowledge base for MT: previously translated text fragments are seen as examples on which to base the translation of a given text. EBMT can be regarded as a special case of corpus-based MT (cf. [5,10,39]). 152 EBMT proceeds by finding suitable examples in the database and then 'recombining' them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text ([8,22,40]), and the alignment"
1992.tmi-1.13,C90-3044,0,0.0602821,"fective, technique of recognising keywords in a particular order in the input speech signal. It also builds on research on interactive generation of stereotypical texts ([1,19,35]), where texts in certain restricted domains are stored and retrieved as appropriate through interaction with users, and are reformulated to fulfill the specific requirements expressed by them. 2.3 Example-Based MT (EBMT) and corpus-based MT Perhaps the most important feature of the system is that it follows very closely some of the ideas of EBMT, which originated with Nagao [30], but have only recently been taken up [18,23,32,33,34,36,37,45,46]. In EBMT, a corpus of texts with their translations (which have been done by humans, and so are of guaranteed quality) serves as a knowledge base for MT: previously translated text fragments are seen as examples on which to base the translation of a given text. EBMT can be regarded as a special case of corpus-based MT (cf. [5,10,39]). 152 EBMT proceeds by finding suitable examples in the database and then 'recombining' them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text ([8,22,40]), and the alignment"
1992.tmi-1.13,C90-3048,1,0.876507,"extent to which the system or the user should take the initiative, which might differ from occasion to occasion. Although first suggested by Kay [20], the alternative idea of an MT system for a monolingual user seems only to have really been followed up about five years ago, when several proposals for interactive MT for monolingual users were apparently initiated [7,14,17,38,48,49]. The idea to develop this sort of interaction in the direction of a more sophisticated clarification dialogue is now gaining currency with the emergence of DBMT [3,4,47] and the notion of 'MT without a source text' [43], where the dialogue aims not merely at disambiguating a given text, but in helping the user to compose it in the first place. 2.2 MT as multilingual text generation If there is no source text, the focus obviously falls upon the generation of the target text(s), a problem in MT which was for a long time seriously underestimated (cf. [27]). Our present approach has been influenced by the 'phrasebook' approach to speech translation [44], in which set phrases are stored, as in a holidaymaker's phrasebook, and retrieved by the fairly crude, though effective, technique of recognising keywords in a"
1992.tmi-1.13,P91-1024,0,0.0413779,"fective, technique of recognising keywords in a particular order in the input speech signal. It also builds on research on interactive generation of stereotypical texts ([1,19,35]), where texts in certain restricted domains are stored and retrieved as appropriate through interaction with users, and are reformulated to fulfill the specific requirements expressed by them. 2.3 Example-Based MT (EBMT) and corpus-based MT Perhaps the most important feature of the system is that it follows very closely some of the ideas of EBMT, which originated with Nagao [30], but have only recently been taken up [18,23,32,33,34,36,37,45,46]. In EBMT, a corpus of texts with their translations (which have been done by humans, and so are of guaranteed quality) serves as a knowledge base for MT: previously translated text fragments are seen as examples on which to base the translation of a given text. EBMT can be regarded as a special case of corpus-based MT (cf. [5,10,39]). 152 EBMT proceeds by finding suitable examples in the database and then 'recombining' them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text ([8,22,40]), and the alignment"
1992.tmi-1.13,C86-1077,0,0.0221674,"where the most appropriate division of labour between the computer and the human should occur, and there is sometimes even a conflict between what the system offers the translator-user, and what the user already knows, or between the extent to which the system or the user should take the initiative, which might differ from occasion to occasion. Although first suggested by Kay [20], the alternative idea of an MT system for a monolingual user seems only to have really been followed up about five years ago, when several proposals for interactive MT for monolingual users were apparently initiated [7,14,17,38,48,49]. The idea to develop this sort of interaction in the direction of a more sophisticated clarification dialogue is now gaining currency with the emergence of DBMT [3,4,47] and the notion of 'MT without a source text' [43], where the dialogue aims not merely at disambiguating a given text, but in helping the user to compose it in the first place. 2.2 MT as multilingual text generation If there is no source text, the focus obviously falls upon the generation of the target text(s), a problem in MT which was for a long time seriously underestimated (cf. [27]). Our present approach has been influenc"
1997.mtsummit-plenaries.12,1995.tmi-1.17,0,0.010592,"uctures their system will cover. The second approach has been reported for example by Furuse & Iida (1992) and further developed in the same authors’ 1994 and 1996 papers. The basic idea is to try to discover what the rule underlying similar examples is, and thereby infer linguistic rules on this basis. This is an interesting hybrid, because it is data-driven, but rule-like in application, and in theory should benefit from the advantages of both approaches. The best example of the third approach is in the PANGLOSS system reported by Frederking & Nirenburg (1994), Frederking et al. (1994), and Brown & Frederking (1995), in which three quite different methodologies are applied in parallel, with a top-level monitor attempting to reconcile the different results. In PANGLOSS, the three approaches used almost epitomize the three extremes of MT system design: a knowledge-based system, an example-based system, and a rule-based lexical transfer system. 2.3. Languages covered One thing to notice is that MT research has still not significantly ventured much beyond the major world languages, perhaps for obvious economic reasons. As ever, political as well as economic considerations are a force in certain (geographical"
1997.mtsummit-plenaries.12,1996.amta-1.21,0,0.0374132,"ility and establishing their credibility as one of the leading MT providers. 3.3. Pre- and post-editing Let us turn finally to the ages-old question of pre- and post-editing as a means of mitigating the weaknesses of MT systems. It is now well accepted that the input to most MT systems needs to be restricted if the output is to be useful without wholesale post-editing, and traditionally these restrictions have been labelled ‘sublanguage’ if they occur naturally, and ‘controlled language’ if they are artificially imposed. It is encouraging to see both these approaches flourishing. For example, Chandioux & Grimaila (1996) report how a version of MÉTÉO®, the long-time standard-bearer of sublanguage MT, was developed for use at the Atlanta Olympic Games, while there is a growing community of controlled language users and researchers, many of whom focus on the link between controlled language and MT (e.g. Adriaens 1995, Mitamura & Nyberg 1995, van der Eijck 1996). I wish to end this article with a brief suggestion of a possibly new working practice for MT users.This is a simple and obvious idea, but one which I have not seen mentioned anywhere else. Until I find a better term, I call it ‘Post-editing the source t"
1997.mtsummit-plenaries.12,1996.amta-1.24,0,0.0302326,"ved more or less automatically from data; analogy-based systems where the examples are generalized so as to take on the form of rules; true hybrid systems, where the alternative approaches work alongside. The first of the alternatives mentioned above is now almost universally embraced: with the availability of machine-readable dictionaries as well as multilingual corpora, many researchers are turning their attention to the extraction of linguistic knowledge, for use in rule-based systems, from these resources. There is of course discussion and debate about the limitations of this process (cf. Church 1996, Wilks 1996), but at the very least, most MT research system developers will work from a reference corpus which defines the range of vocabulary and structures their system will cover. The second approach has been reported for example by Furuse & Iida (1992) and further developed in the same authors’ 1994 and 1996 papers. The basic idea is to try to discover what the rule underlying similar examples is, and thereby infer linguistic rules on this basis. This is an interesting hybrid, because it is data-driven, but rule-like in application, and in theory should benefit from the advantages of bot"
1997.mtsummit-plenaries.12,1996.amta-1.19,0,0.0268188,"inted at in vague terms in the ALPAC report, cf. Hutchins (1996). 3. We use the traditional linguistic notation of prefixing an asterisk to indicate an ungrammatical string. 119 hold of MT software, there has emerged a new ballpark for MT use where all these restrictions and limitations are ignored — yet it seems to be the fastest growing area of use for MT. I am referring of course to translation of materials found on the World Wide Web and, to a lesser extent, of e-mails and bulletin-board postings. Pioneered by CompuServe (Harrison 1992), and demonstrated at the first AMTA meeting in 1994, Flanagan (1996) reported that users are at first “amazed”, then disappointed, then pragmatic about the quality of the translations. Translation of this nature is especially difficult, because as a text-type e-mails and postings to bulletin boards are often informal, even ungrammatical (especially regarding punctuation, capitalization and spelling). Yet on-line translation has clearly been accepted as a useful service. In Japan, it is the main reason for purchase of MT software, which now often is included in Internet software packages sold there. The major MT software developers now recognise the opportunity"
1997.mtsummit-plenaries.12,W97-0409,0,0.0928896,"e approaches used almost epitomize the three extremes of MT system design: a knowledge-based system, an example-based system, and a rule-based lexical transfer system. 2.3. Languages covered One thing to notice is that MT research has still not significantly ventured much beyond the major world languages, perhaps for obvious economic reasons. As ever, political as well as economic considerations are a force in certain (geographical) locations, no better illustrated than in work on DIPLOMAT, a speech translation system for which English is paired with Serbo-Croatian, Haitian Creole and Korean (Frederking et al. 1997). Older readers will remember that researchers at Logos worked on Vietnamese and then Farsi (Persian) before they settled on German. The influence of the funders is obvious here. Certainly within the European Union, less dominant languages such as Dutch, Danish and Portuguese have received attention, but it is still the ‘big five’ (French, German, Italian, Spanish, Japanese) that are targeted, and almost always paired with English. Systems handling Russian, Chinese, Korean and Arabic are only just beginning to appear in listings of commercially available systems1. It is also interesting to not"
1997.mtsummit-plenaries.12,W97-0406,0,0.111121,"nction are quite enormous, especially in terms of interpreting the pragmatic aspects of the dialogue. Other distinctions that might impinge on the design of an SLT system include • • • • whether it is face-to-face or telephonic; whether it has the possibility of interactive disambiguation and/or confirmation, and if so ... whether this also is speech-based (introducing the difficulty of identifying system-user &quot;metadialogue&quot;, cf. Somers et al. 1990) or on a separate user interface (cf. Frederking et al. 1997); whether users are purely monolingual or may switch languages from time to time (cf. Fung et al. 1997). Almost all the SLT literature focuses on dialogue translation, with very little work as yet reported on what might be termed, by analogy with MT, Machine Interpretation, that is, simultaneous or consecutive translation of spoken language in the context of a meeting or a person addressing a group of people. Interestingly, this might prove to be a somewhat less difficult task than dialogue translation, apart from the exigencies of real-time processing of course, since the type of language that gets interpreted (by human interpreters) is usually much more formal than everyday dialogue, and clos"
1997.mtsummit-plenaries.12,C94-1015,0,0.0581165,"Missing"
1997.mtsummit-plenaries.12,C96-1070,0,0.0301375,"Missing"
1997.mtsummit-plenaries.12,C96-1072,0,0.0170718,"inguistic rule systems. Nevertheless, a shift in emphasis in terms of what MT systems are used for has caused a number of interesting problems into the limelight. While the recognition of the impossibility of fully automatic high-quality translation of unrestricted texts let MT researchers ‘off the hook’ to a certain extent, the sudden interest in using MT to get rough translations, in particular in the context of the World Wide Web and translation of e-mail, has put a number of topics back on the agenda. Among these is the intriguing problem of recognising and dealing with proper names (e.g. Gallippi 1996, Yoshimura et al. 1997). In the case of translation between languages using different scripts, this might involve transliteration which, as Knight & Graehl (1997) show, is not a trivial matter. A similar problem, in that it involves recognition and so often leads to the prevention of translation, is the fact that Web pages and e-mails often mix languages or contain literal strings (such as URLs or e-mail addresses) which should not be translated. This is not dissimilar to the problem, in document translation, of recognising figures and tables. 116 2.2. Analogy-based MT At the beginning of thi"
1997.mtsummit-plenaries.12,1995.tmi-1.24,0,0.0186623,"e that after all the ‘second generation’ approach can provide the basis of some commercial systems, with a number of commercially available products developed from what started out as essentially research systems. Nevertheless, I still suspect that the development from research lab prototype running on a large workstation (or even mainframe) to marketable product running on a PC owes more to software engineering than to computational linguistics, and it is fair to say that the grammars and rule-bases inside the systems would still look fairly unfamiliar to a linguistics major (cf. for example Gdaniec & Schmid, 1995). 3.1. Tools for users One of the most important changes of focus over the last few years has been the renewal of interest in developing sophisticated tools for translators. Ideas about what such tools should look like remained fairly static for a long period: if we look at Martin Kay’s (1980) blueprint2 for a Translator’s Workstation, we can see the model for almost all MT and translation-related products to be developed over the next 15 years. Only with the emergence of statistical and corpus-based research methods have some really innovative ideas been added to that early design (cf. Isabel"
1997.mtsummit-plenaries.12,1993.tmi-1.17,0,0.0285864,"Translator’s Workbench this tool which is related to the TM, but whose purpose is to search for previous translations of a given word or phrase as a reference for the translator, rather than whole sentences to be pasted in to the target text. Again, the idea for such a tool can be found in earlier literature: Kjaersgaard (1987) makes such a proposal, but is unclear how to implement it, while Harris’s (1988) notion of “bi-text” is clearly relevant. The CITI group (now moved to Université de Montréal) have developed an impressive implementation of this idea based on the Canadian Hansard corpus (Isabelle et al. 1993). 3.1.3. Checking for mistranslations. In a similar fashion, tools which help the translator check for translation errors are now appearing. Macklovitch (1994) describes a tool, again based on aligned parallel corpora, that can check for “deceptive cognates” (faux amis) like library!librairie, and also for caiques (e.g. *certificat de naissance for birth certificate).3 Another problem for translators is inconsistent translations of the same or similar pieces of text. As Merkel (1996) describes, although TM is useful for preventing this, there is the problem of detecting inconsistencies after t"
1997.mtsummit-plenaries.12,E87-1020,0,0.040612,"ilable from the mid-1980s in ALPS, one of the first commercially available MT systems (Sibley 1988, Weaver 1988). 3.1.2. Bilingual concordances. With the availability of large bilingual corpora, and especially alignment algorithms to process them, it is now possible to incorporate in the Translator’s Workbench this tool which is related to the TM, but whose purpose is to search for previous translations of a given word or phrase as a reference for the translator, rather than whole sentences to be pasted in to the target text. Again, the idea for such a tool can be found in earlier literature: Kjaersgaard (1987) makes such a proposal, but is unclear how to implement it, while Harris’s (1988) notion of “bi-text” is clearly relevant. The CITI group (now moved to Université de Montréal) have developed an impressive implementation of this idea based on the Canadian Hansard corpus (Isabelle et al. 1993). 3.1.3. Checking for mistranslations. In a similar fashion, tools which help the translator check for translation errors are now appearing. Macklovitch (1994) describes a tool, again based on aligned parallel corpora, that can check for “deceptive cognates” (faux amis) like library!librairie, and also for"
1997.mtsummit-plenaries.12,P16-5003,0,0.0693046,"Missing"
1997.mtsummit-plenaries.12,1994.amta-1.21,0,0.0350428,"the translator, rather than whole sentences to be pasted in to the target text. Again, the idea for such a tool can be found in earlier literature: Kjaersgaard (1987) makes such a proposal, but is unclear how to implement it, while Harris’s (1988) notion of “bi-text” is clearly relevant. The CITI group (now moved to Université de Montréal) have developed an impressive implementation of this idea based on the Canadian Hansard corpus (Isabelle et al. 1993). 3.1.3. Checking for mistranslations. In a similar fashion, tools which help the translator check for translation errors are now appearing. Macklovitch (1994) describes a tool, again based on aligned parallel corpora, that can check for “deceptive cognates” (faux amis) like library!librairie, and also for caiques (e.g. *certificat de naissance for birth certificate).3 Another problem for translators is inconsistent translations of the same or similar pieces of text. As Merkel (1996) describes, although TM is useful for preventing this, there is the problem of detecting inconsistencies after they have been made. And a further tool for the translator based on parallel text alignment techniques is described by Melamed (1996), who shows how it may be p"
1997.mtsummit-plenaries.12,1996.amta-1.16,0,0.0212977,"ontréal) have developed an impressive implementation of this idea based on the Canadian Hansard corpus (Isabelle et al. 1993). 3.1.3. Checking for mistranslations. In a similar fashion, tools which help the translator check for translation errors are now appearing. Macklovitch (1994) describes a tool, again based on aligned parallel corpora, that can check for “deceptive cognates” (faux amis) like library!librairie, and also for caiques (e.g. *certificat de naissance for birth certificate).3 Another problem for translators is inconsistent translations of the same or similar pieces of text. As Merkel (1996) describes, although TM is useful for preventing this, there is the problem of detecting inconsistencies after they have been made. And a further tool for the translator based on parallel text alignment techniques is described by Melamed (1996), who shows how it may be possible to detect portions of text that have been omitted. 3.2. MT on the Web One of the most interesting developments in the last few years is one which somewhat goes against the grain of MT use: while members of the MT community have been persuading the general public of the limitations of MT software, and carefully nurturing"
1997.mtsummit-plenaries.12,1995.tmi-1.12,0,0.0685845,"Missing"
1997.mtsummit-plenaries.12,C90-3048,1,0.788621,"te towards a common goal, as opposed to “adversarial” dialogues, e.g. between business persons negotiating a contract. The implications of this apparently minor distinction are quite enormous, especially in terms of interpreting the pragmatic aspects of the dialogue. Other distinctions that might impinge on the design of an SLT system include • • • • whether it is face-to-face or telephonic; whether it has the possibility of interactive disambiguation and/or confirmation, and if so ... whether this also is speech-based (introducing the difficulty of identifying system-user &quot;metadialogue&quot;, cf. Somers et al. 1990) or on a separate user interface (cf. Frederking et al. 1997); whether users are purely monolingual or may switch languages from time to time (cf. Fung et al. 1997). Almost all the SLT literature focuses on dialogue translation, with very little work as yet reported on what might be termed, by analogy with MT, Machine Interpretation, that is, simultaneous or consecutive translation of spoken language in the context of a meeting or a person addressing a group of people. Interestingly, this might prove to be a somewhat less difficult task than dialogue translation, apart from the exigencies of r"
1997.mtsummit-plenaries.12,1997.tmi-1.2,0,0.0262926,"systems. Nevertheless, a shift in emphasis in terms of what MT systems are used for has caused a number of interesting problems into the limelight. While the recognition of the impossibility of fully automatic high-quality translation of unrestricted texts let MT researchers ‘off the hook’ to a certain extent, the sudden interest in using MT to get rough translations, in particular in the context of the World Wide Web and translation of e-mail, has put a number of topics back on the agenda. Among these is the intriguing problem of recognising and dealing with proper names (e.g. Gallippi 1996, Yoshimura et al. 1997). In the case of translation between languages using different scripts, this might involve transliteration which, as Knight & Graehl (1997) show, is not a trivial matter. A similar problem, in that it involves recognition and so often leads to the prevention of translation, is the fact that Web pages and e-mails often mix languages or contain literal strings (such as URLs or e-mail addresses) which should not be translated. This is not dissimilar to the problem, in document translation, of recognising figures and tables. 116 2.2. Analogy-based MT At the beginning of this decade, an apparently"
1997.tc-1.13,1996.amta-1.1,0,0.024985,"raining corpus. For more on tagging see Barnbrook (1996) [18]. 4.6. Example-based MT A final avenue that might be worth exploring is Example-based MT (EBMT). In this approach to MT, the main database is a set of previously translated segment pairs. Translation of a new text proceeds by searching this database for a closely matching example, and then using it as a model for the new translation. As a translator&apos;s aid, this approach is known as ""Translation memory"" of course, but there has been some research on developing EBMT as a fully automatic approach to MT (e.g. Somers and Jones 1991 [19]; Collins et al. 1996 [20]). The main problems in EBMT, assuming of course that an aligned bilingual corpus has been obtained and that its coverage is suitably broad, concern the manipulation of partial matches, for example where the sentence to be translated is a bit like two or more examples in the database, but not exactly like any of them: the question is how to ""clone"" the new translation from the matched bits, i.e. how do we know how to glue together the fragments? Current thinking in EBMT circles seems to be that a hybrid of EBMT and traditional rule-based MT is appropriate for this case, which brings us ba"
1999.mtsummit-1.78,P87-1027,0,0.014418,"tool in the essentially human process of identifying word meanings and cataloguing them. Of course, for many languages this has been done by lexicographers. Published dictionaries do exist for many of the languages we are interested in, and here there is a small glimmer of hope. Many dictionaries nowadays are computer-typeset so that machine-readable dictionaries are available, although they may include type-setting and printing codes and so on. Software that can extract from these the information that is needed for an on-line resource that is useful for translators has been widely reported (Boguraev et al., 1987; Farwell et al., 1993; Walker & Amsler, 1986), and Mágan Muñoz (1998) discusses this tactic specifically for a minority language. Unfortunately, this situation does not apply to all the languages we are interested in. For languages of the minority interest, dictionaries are often published only in the country where the language is spoken, where the publication methods are typically more old-fashioned including traditional lead type-setting or even copying camera-ready type-written pages. To convert these into machine-readable form by scanning them with OCR equipment implies a massive amount o"
1999.mtsummit-1.78,J93-2002,0,0.01417,"extracted from their English-Chinese bilingual corpus. Dagan & Church (1994) describe a semi-automatic tool for constructing bilingual glossaries. Fung et al. (1996) show how the linguistic properties of certain languages can make this task more straightforward. 4.4 Developing Linguistic Descriptions For most other purposes, a fuller linguistic description of the language is necessary. Sophisticated grammar checkers, and certainly CAT or MT tools, are usually based on some sort of linguistic rule-base. Although some work has been done on automatically extracting linguistic rules from corpora (Brent, 1993), nothing of a significant scale has been achieved without the help of a rulebased parser or an existing tree-bank (Briscoe & Carroll, 1997; Grishman & Sterling, 1992; Manning, 1993). Two proposals directly related to developing MT systems for low-density languages describe software involving sophisticated interaction with a bilingual human expert (Jones & Havrilla, 1998; Nirenburg & Raskin, 1998). A more viable alternative might be to try to develop linguistic resources by adapting existing MT Summit VII Sept. 1999 grammars. This might be particularly plausible where the new language belongs"
1999.mtsummit-1.78,A97-1052,0,0.0152808,"ingual glossaries. Fung et al. (1996) show how the linguistic properties of certain languages can make this task more straightforward. 4.4 Developing Linguistic Descriptions For most other purposes, a fuller linguistic description of the language is necessary. Sophisticated grammar checkers, and certainly CAT or MT tools, are usually based on some sort of linguistic rule-base. Although some work has been done on automatically extracting linguistic rules from corpora (Brent, 1993), nothing of a significant scale has been achieved without the help of a rulebased parser or an existing tree-bank (Briscoe & Carroll, 1997; Grishman & Sterling, 1992; Manning, 1993). Two proposals directly related to developing MT systems for low-density languages describe software involving sophisticated interaction with a bilingual human expert (Jones & Havrilla, 1998; Nirenburg & Raskin, 1998). A more viable alternative might be to try to develop linguistic resources by adapting existing MT Summit VII Sept. 1999 grammars. This might be particularly plausible where the new language belongs to the same language family as a more established language: a Bosnian grammar, for example, could perhaps be developed on the basis of Russ"
1999.mtsummit-1.78,1996.amta-1.1,0,0.0988862,"Missing"
1999.mtsummit-1.78,P98-2160,0,0.0256854,". Sophisticated grammar checkers, and certainly CAT or MT tools, are usually based on some sort of linguistic rule-base. Although some work has been done on automatically extracting linguistic rules from corpora (Brent, 1993), nothing of a significant scale has been achieved without the help of a rulebased parser or an existing tree-bank (Briscoe & Carroll, 1997; Grishman & Sterling, 1992; Manning, 1993). Two proposals directly related to developing MT systems for low-density languages describe software involving sophisticated interaction with a bilingual human expert (Jones & Havrilla, 1998; Nirenburg & Raskin, 1998). A more viable alternative might be to try to develop linguistic resources by adapting existing MT Summit VII Sept. 1999 grammars. This might be particularly plausible where the new language belongs to the same language family as a more established language: a Bosnian grammar, for example, could perhaps be developed on the basis of Russian or Czech. there is no commercial interest in these languages. It is to be hoped that at least some of the lines of enquiry suggested here will prove fruitful in the short term. An alternative to full linguistic analysis is tagging. A tagged corpus is a usef"
1999.mtsummit-1.78,C92-2099,0,0.0296796,"t al. (1996) show how the linguistic properties of certain languages can make this task more straightforward. 4.4 Developing Linguistic Descriptions For most other purposes, a fuller linguistic description of the language is necessary. Sophisticated grammar checkers, and certainly CAT or MT tools, are usually based on some sort of linguistic rule-base. Although some work has been done on automatically extracting linguistic rules from corpora (Brent, 1993), nothing of a significant scale has been achieved without the help of a rulebased parser or an existing tree-bank (Briscoe & Carroll, 1997; Grishman & Sterling, 1992; Manning, 1993). Two proposals directly related to developing MT systems for low-density languages describe software involving sophisticated interaction with a bilingual human expert (Jones & Havrilla, 1998; Nirenburg & Raskin, 1998). A more viable alternative might be to try to develop linguistic resources by adapting existing MT Summit VII Sept. 1999 grammars. This might be particularly plausible where the new language belongs to the same language family as a more established language: a Bosnian grammar, for example, could perhaps be developed on the basis of Russian or Czech. there is no c"
1999.mtsummit-1.78,jones-havrilla-1998-twisted,0,0.012251,"he language is necessary. Sophisticated grammar checkers, and certainly CAT or MT tools, are usually based on some sort of linguistic rule-base. Although some work has been done on automatically extracting linguistic rules from corpora (Brent, 1993), nothing of a significant scale has been achieved without the help of a rulebased parser or an existing tree-bank (Briscoe & Carroll, 1997; Grishman & Sterling, 1992; Manning, 1993). Two proposals directly related to developing MT systems for low-density languages describe software involving sophisticated interaction with a bilingual human expert (Jones & Havrilla, 1998; Nirenburg & Raskin, 1998). A more viable alternative might be to try to develop linguistic resources by adapting existing MT Summit VII Sept. 1999 grammars. This might be particularly plausible where the new language belongs to the same language family as a more established language: a Bosnian grammar, for example, could perhaps be developed on the basis of Russian or Czech. there is no commercial interest in these languages. It is to be hoped that at least some of the lines of enquiry suggested here will prove fruitful in the short term. An alternative to full linguistic analysis is tagging"
1999.mtsummit-1.78,E93-1015,0,0.0610362,"Missing"
1999.mtsummit-1.78,A94-1006,0,\N,Missing
1999.mtsummit-1.78,P93-1032,0,\N,Missing
1999.mtsummit-1.78,C98-2155,0,\N,Missing
1999.mtsummit-1.78,H91-1026,0,\N,Missing
2000.tc-1.5,1989.mtsummit-1.18,0,0.190402,"Missing"
2000.tc-1.5,1994.amta-1.25,0,0.087094,"Missing"
2000.tc-1.5,H93-1040,0,\N,Missing
2000.tc-1.5,1993.mtsummit-1.24,0,\N,Missing
2001.mtsummit-ebmt.6,1999.mtsummit-1.36,0,0.0573108,"Missing"
2001.mtsummit-ebmt.6,1997.tmi-1.13,0,0.0228752,"stance algorithm (Levenshtein, 1966) is widely used, sometimes effectively weighting certain words or categories favourably (e.g. Cranias et al., 1997; Furuse & Iida, 1994; Veale & Way, 1997). While many CBR and EBMT systems try to retrieve the single best match, or at least to supply a ranking to a set of matches, some systems permit multiple retrievals, the idea being that the correct solution will result from taking the best bits of each of them. These might also be described as partial retrievals, where the cases are decomposed, making a collection of “substrings” (Nirenburg et al., 1993; Brown, 1997), “fragments” (Somers et al., 1994) or “chunks” (Cunningham et al., 1994; Collins, 1998) of matched material. Figure 3 illustrates this idea. The idea of using fragments of cases is found in a danger/NN0 of/PRP NN0 &lt; &gt; above/PRP danger/NN0 of/PRP of/PRP NN0 &lt; &gt; above/PRP above/PRP CRD m/NP0 there/PNP is/VVV a/AT0 avalanche/NN0 &lt; &gt; above/PRP there/PNP is/VVV is/VVV a/AT0 danger/NN0 of/PRP avalanche/NN0 avalanche/NN0 above/PRP CRD m/NP0 avalanche/NN0 above/PRP of/PRP avalanche/NN0 there/PNP is/VVV &lt; &gt; a/AT0 is/VVV &lt; &gt; a/AT0 there/PNP is/VVV a/AT0 &lt; &gt; danger/NN0 &lt; &gt; of/PRP there/PNP is/VVV &lt; &gt; da"
2001.mtsummit-ebmt.6,1999.tmi-1.3,0,0.0312331,"rocess (e.g. Sato & Nagao, 1990; Watanabe, 1992; and several others) or for certain problems (e.g. Sumita et al., 1990). Similarly, in many CBR systems the adaptation stage (see below) is rule-based (Leake, 1996:11), while some systems have a rule-based compoinent as a back-up if not relevant cases are available (e.g. Goel et al., 1994; Koton, 1988). A feature of recent EBMT research has been the tendency to take similar examples and store them as a single generalized example, sometimes so much so that they resemble traditional transfer rules (e.g. Kitano & Higuchi, 1991; Furuse & Iida, 1992; Brown, 1999). Some researchers report procedures for automatically discovering generalized patterns (Cicekli & Güvenir, 1996; Güvenir & Tunç, 1996; Güvenir & Cicekli, 1998; McTait & Trujillo, 1999). The notion of “generalization” is found in the CBR literature, but in a limited way. Riesbeck & Schank (1989:36ff) describe the dynamic formation of “new abstractions … when a number of cases are discovered to share some common set of features”, and Branting (1989) describes a system which integrates generalizations into a CBR system. Hammond (1989) similarly suggests that abstract cases can be created where c"
2001.mtsummit-ebmt.6,1999.mtsummit-1.92,0,0.0280792,"without adding to the capabilities of a system. Such cases might or might not affect the efficiency of retrieval, depending on the retrieval algorithm.” (p. 567) A similar point can be made with regard to EBMT (see Somers, 1999:121). If we construct the example-base froma corpus, sthere will be repetition and overlap. Some examples will mutually reinforce each other, being identical, or exemplifying the same translation phenomenon. But other examples will be in conflict: the same or similar phrase in one language may have two different translations for no other reason than inconsistency (e.g. Carl & Hansen, 1999:619). Where examples reinforce each other this may or may not be useful. Some systems (e.g. Somers et al., 1994; Öz & Cicekli, 1998; Murata et al., 1999) involve a similarity metric which is sensitive to frequency. But if no such weighting is used, multiple similar or identical examples are just extra baggage, introducing a kind of spurious ambiguity because there seem to be multiple alternative solutions to the same problem. Conclusions The aim of this essay was to see if the similarity between EBMT and CBR was anything more than skin-deep. My hope was to find some inspiration in the CBR lit"
2001.mtsummit-ebmt.6,1996.amta-1.1,0,0.105418,"Missing"
2001.mtsummit-ebmt.6,C94-1015,0,0.0180734,"en in early systems where examples are stored as tree structures, little detail is given concerning how tree structures are compared. A similarity metric which makes use of linear distance in a hierarchical thesaurus is widely used for quantifying word similarity (e.g. Nagao, 1984). For the most part, in EBMT the examples have very simple structures, typically sequences of words (this is the case with TMs), or word–tag pairs. The string-edit distance algorithm (Levenshtein, 1966) is widely used, sometimes effectively weighting certain words or categories favourably (e.g. Cranias et al., 1997; Furuse & Iida, 1994; Veale & Way, 1997). While many CBR and EBMT systems try to retrieve the single best match, or at least to supply a ranking to a set of matches, some systems permit multiple retrievals, the idea being that the correct solution will result from taking the best bits of each of them. These might also be described as partial retrievals, where the cases are decomposed, making a collection of “substrings” (Nirenburg et al., 1993; Brown, 1997), “fragments” (Somers et al., 1994) or “chunks” (Cunningham et al., 1994; Collins, 1998) of matched material. Figure 3 illustrates this idea. The idea of using"
2001.mtsummit-ebmt.6,1999.tmi-1.10,0,0.143388,"(see below) is rule-based (Leake, 1996:11), while some systems have a rule-based compoinent as a back-up if not relevant cases are available (e.g. Goel et al., 1994; Koton, 1988). A feature of recent EBMT research has been the tendency to take similar examples and store them as a single generalized example, sometimes so much so that they resemble traditional transfer rules (e.g. Kitano & Higuchi, 1991; Furuse & Iida, 1992; Brown, 1999). Some researchers report procedures for automatically discovering generalized patterns (Cicekli & Güvenir, 1996; Güvenir & Tunç, 1996; Güvenir & Cicekli, 1998; McTait & Trujillo, 1999). The notion of “generalization” is found in the CBR literature, but in a limited way. Riesbeck & Schank (1989:36ff) describe the dynamic formation of “new abstractions … when a number of cases are discovered to share some common set of features”, and Branting (1989) describes a system which integrates generalizations into a CBR system. Hammond (1989) similarly suggests that abstract cases can be created where common sets of features are shared. Bergmann & Wilke (1996) explore the idea further. On the other hand, Kolodner (1993:7) suggests that generalization, although possible, is not a signi"
2001.mtsummit-ebmt.6,1999.tmi-1.7,0,0.0267973,"(p. 567) A similar point can be made with regard to EBMT (see Somers, 1999:121). If we construct the example-base froma corpus, sthere will be repetition and overlap. Some examples will mutually reinforce each other, being identical, or exemplifying the same translation phenomenon. But other examples will be in conflict: the same or similar phrase in one language may have two different translations for no other reason than inconsistency (e.g. Carl & Hansen, 1999:619). Where examples reinforce each other this may or may not be useful. Some systems (e.g. Somers et al., 1994; Öz & Cicekli, 1998; Murata et al., 1999) involve a similarity metric which is sensitive to frequency. But if no such weighting is used, multiple similar or identical examples are just extra baggage, introducing a kind of spurious ambiguity because there seem to be multiple alternative solutions to the same problem. Conclusions The aim of this essay was to see if the similarity between EBMT and CBR was anything more than skin-deep. My hope was to find some inspiration in the CBR literature to push EBMT forward. I think we have shown that in many respects EBMT can be described using CBR terminology, but for the most part we do not lea"
2001.mtsummit-ebmt.6,1993.tmi-1.4,0,0.299192,"airs. The string-edit distance algorithm (Levenshtein, 1966) is widely used, sometimes effectively weighting certain words or categories favourably (e.g. Cranias et al., 1997; Furuse & Iida, 1994; Veale & Way, 1997). While many CBR and EBMT systems try to retrieve the single best match, or at least to supply a ranking to a set of matches, some systems permit multiple retrievals, the idea being that the correct solution will result from taking the best bits of each of them. These might also be described as partial retrievals, where the cases are decomposed, making a collection of “substrings” (Nirenburg et al., 1993; Brown, 1997), “fragments” (Somers et al., 1994) or “chunks” (Cunningham et al., 1994; Collins, 1998) of matched material. Figure 3 illustrates this idea. The idea of using fragments of cases is found in a danger/NN0 of/PRP NN0 &lt; &gt; above/PRP danger/NN0 of/PRP of/PRP NN0 &lt; &gt; above/PRP above/PRP CRD m/NP0 there/PNP is/VVV a/AT0 avalanche/NN0 &lt; &gt; above/PRP there/PNP is/VVV is/VVV a/AT0 danger/NN0 of/PRP avalanche/NN0 avalanche/NN0 above/PRP CRD m/NP0 avalanche/NN0 above/PRP of/PRP avalanche/NN0 there/PNP is/VVV &lt; &gt; a/AT0 is/VVV &lt; &gt; a/AT0 there/PNP is/VVV a/AT0 &lt; &gt; danger/NN0 &lt; &gt; of/PRP there/PNP"
2001.mtsummit-ebmt.6,oz-cicekli-1998-ordering,0,0.0262305,"trieval algorithm.” (p. 567) A similar point can be made with regard to EBMT (see Somers, 1999:121). If we construct the example-base froma corpus, sthere will be repetition and overlap. Some examples will mutually reinforce each other, being identical, or exemplifying the same translation phenomenon. But other examples will be in conflict: the same or similar phrase in one language may have two different translations for no other reason than inconsistency (e.g. Carl & Hansen, 1999:619). Where examples reinforce each other this may or may not be useful. Some systems (e.g. Somers et al., 1994; Öz & Cicekli, 1998; Murata et al., 1999) involve a similarity metric which is sensitive to frequency. But if no such weighting is used, multiple similar or identical examples are just extra baggage, introducing a kind of spurious ambiguity because there seem to be multiple alternative solutions to the same problem. Conclusions The aim of this essay was to see if the similarity between EBMT and CBR was anything more than skin-deep. My hope was to find some inspiration in the CBR literature to push EBMT forward. I think we have shown that in many respects EBMT can be described using CBR terminology, but for the m"
2001.mtsummit-ebmt.6,N01-1019,0,0.0306281,"Missing"
2001.mtsummit-ebmt.6,1999.mtsummit-1.48,0,0.0317037,"ry) Figure 2. Example of a case, cited in Kolodner (1993:172) As in many other aspects of CBR, we should be guided by the intuitive nature of this approach, and consider as indexes the kinds of features that humans might naturally select. So how can we relate this terminology to EBMT? In the EBMT literature, the nature of the case base is widely discussed (cf. Somers, 1999). The cases (examples) are represented in a variety of formats, such as lexically aligned tagged sentences (e.g. Kitano, 1993), tree structures (e.g. Sato & Nagao, 1990; Al-Adhaileh & Kong, 1999), multi-level lattices (e.g. Planas & Furuse, 1999), and so on. Theoretically the cases could “speak for themselves” and be stored as unanalysed pairs of strings, though no EBMT system is reported to take this extreme step. This is the case with Translation Memories, a special case of EBMT which, in CBR terms, has the retrieval and storage functions, but leaves adaptation to the human user. One of the ironies of EBMT is that the mechanisms used to produce the annotations (in CBR terms, indexes) for the cases, and also to analyse a new case into the appropriate format, are usually the same as, or very similar to, the rules found in the rule-bas"
2001.mtsummit-ebmt.6,C90-3044,0,0.268685,"ed advantages of CBR is that it overcomes the “knowledge acquisition bottleneck” (Hayes-Roth et al., 1983) of hand-coding a great number of rules, and verifying how they interact with each other. The complexity of real-world domains, according to Riesbeck & Schank (1989:26), makes it “impossible or impractical to specify fully all the rules involved.” In CBR, when the existing “rules” don’t work (i.e. there is no suitable case in the case-base), one simply adds a new one. Such claims have been made for CBR and related techniques (e.g. Watson & Marir, 1994:348) as well as for EBMT itself (e.g. Sato & Nagao, 1990). Crucial Elements of CBR Most texts discussing CBR are agreed on the essential elements that make up a CBR system, namely the database of “cases”, of course, and the accompanying design format consisting of the classic “CBR cycle”, as illustrated in Figure 1. A new problem must be appropriately indexed to enable suitable past cases to be retrieved. These must then be adapted to the new problem, and the proposed solution tested. If the proposed solution is inappropriate, an explanation is usually offered, and repair must be attempted; once a correct solution is found, this can be added to the"
2001.mtsummit-ebmt.6,P91-1024,0,0.0912203,"Missing"
2001.mtsummit-ebmt.6,C92-2115,0,0.0324627,"is the case with Translation Memories, a special case of EBMT which, in CBR terms, has the retrieval and storage functions, but leaves adaptation to the human user. One of the ironies of EBMT is that the mechanisms used to produce the annotations (in CBR terms, indexes) for the cases, and also to analyse a new case into the appropriate format, are usually the same as, or very similar to, the rules found in the rule-based systems they are supposed to replace. Many of the earliest EBMT systems were hybrids, using the example-based method for only a part of the process (e.g. Sato & Nagao, 1990; Watanabe, 1992; and several others) or for certain problems (e.g. Sumita et al., 1990). Similarly, in many CBR systems the adaptation stage (see below) is rule-based (Leake, 1996:11), while some systems have a rule-based compoinent as a back-up if not relevant cases are available (e.g. Goel et al., 1994; Koton, 1988). A feature of recent EBMT research has been the tendency to take similar examples and store them as a single generalized example, sometimes so much so that they resemble traditional transfer rules (e.g. Kitano & Higuchi, 1991; Furuse & Iida, 1992; Brown, 1999). Some researchers report procedure"
2001.mtsummit-teach.8,1985.tc-1.13,0,0.2415,"s might appreciate it, but translators and language learners would be distinctly unimpressed. All this has changed radically in the last few years of course, as we shall see later. There is of course a considerable literature on MT, translation software and Language Engineering in general, but only a small proportion of that literature relates to the teaching of MT, or the use of MT in the classroom, and most of it is very recent. The earliest literature that we have been able to find is typified by a series of articles by Loffler-Laurian (1983, 1985, 1987) which are rather general in nature. Corness (1985, 1988) gives details of the use of ALPS’s interactive MT system with advanced learners of German. This use of MT as a type of CALL is also seen in more recent articles such as Ball (1989), Richmond (1994), Anderson (1995), and Lewis (1997), whereas other recent articles are more explicitly concerned with CAT tools and their relevance to trainee translators (e.g. Haller, 1994; Balkan et al., 1997; Bohm, 1997; Schmitt, 1998; Kenny, 1999). 3 MT for Students of Computing, Linguistics, and CL Historically, MT was probably the first non-numerical use of computers proposed. From early (not entirely"
2001.mtsummit-teach.8,1998.tc-1.6,0,0.0367184,"ideration (i) the competence of the typical user in various areas, (ii) the competence stated as being necessary by the documentation and (iii) the competence actually needed to understand the documentation. The quality of the documentation can also be assessed by looking at the complexity of the language, the appropriateness of the jargon used, and the clarity of explanations. The completeness of the documentation can be assessed by looking to see if it explains in sufficient detail how to carry out translation itself, dictionary editing, translation memory manipulation, and any other tasks. Hartley and Schubert (1998) emphasize the practical side of MT in the translator’s training, suggesting exercises that simulate workflow environments where MT and CAT tools might play a part. Translation of course normally involves a translator and a customer, but several other “agents” may also be involved: a reviser, a broker, publisher, and the original author. Depending on the type of translation, it may also involve specialist technicians, lexicographers and terminologists. Thinking about the “Translator’s Workstation” scenario, the technology involved includes not just computers and peripherals, but e-mail, exchan"
2001.mtsummit-teach.8,mowatt-somers-2000-mt,1,0.772374,"For example, there should be a way to indicate, when entering a compound noun like (French) poste de travail ‘workstation’, that it is the word poste which should be inflected for plural. An effectiveness evaluation would confirm that marking poste as inflectable (and travail as invariant) does indeed lead to the correct translations of both singular and plural, in both directions. This is of course a trivial example, but gives some idea of the kind of exercise that can be undertaken. We have already mentioned evaluation of software; an interesting related task is reviewing the documentation. Mowatt & Somers (2000) have developed a number of criteria for this kind of approach. They suggest evaluating whether the documentation is pitched at an appropriate level for the assumed users of the software, taking into consideration (i) the competence of the typical user in various areas, (ii) the competence stated as being necessary by the documentation and (iii) the competence actually needed to understand the documentation. The quality of the documentation can also be assessed by looking at the complexity of the language, the appropriateness of the jargon used, and the clarity of explanations. The completenes"
2001.mtsummit-teach.8,2000.tc-1.5,1,0.822028,"tions suggested in the literature, students have neither the time nor the resources to get statistically significant results. For example, any evaluation that requires judges to give a subjective evaluation of some aspect of the system requires quite a large experimental population. Nevertheless, they can gain a realistic impression of what is involved in setting up an evaluation even if they cannot see it through to its end result. Comparative evaluation of a single system translating different types of texts, or different systems translating the same text may be particularly revealing (e.g. Somers & Wild, 2000). Often, students may want to work in languages for which there are as yet no commercially available systems. In this case, a good assignment is to focus on the “for assimilation” function of MT, where it is used to produce a rough gist of an otherwise unreadable text. Students are asked to find a text (on the Web for example) in a language which is covered by the systems at their disposal but which is unfamiliar for them. Post-editing to turn raw output into publishable quality is another exercise that students can undertake. Students should work into their native language if possible, though"
2003.mtsummit-papers.49,2004.iwslt-papers.8,0,0.045613,"Missing"
2003.mtsummit-papers.49,2002.tmi-tmiw.4,0,0.0996732,"Missing"
2003.mtsummit-tttt.6,2002.eamt-1.7,0,0.0347927,"rature describing teaching of MT aimed at CL and CS students can be divided into those that use standard programming languages, and those that have developed more task-specific tools. We have described Way’s (2002) approach above. The students of v. Hahn & Vertan have arguably an even more difficult task, as they are left to devise on their own the basic architecture. From their discussion it appears that the only tools provided beforehand for the students is a corpus of test sentences, and a full-form lexicon in an XML-like formalism. No mention is made of the choice of programming language. Amores (2002) describes Xepisteme, a tool for developing LFG-based MT systems. Amores stresses that the transparency of the system means that the user requires no programming skills theough he admits that an appropriate specification language must be learned, entailing the “usual difficulty” (p. 65), and indeed the examples of rules and so on that are shown suggest that this specification language is effectively a high-level task-specific programming language. Nevertheless, the tool also has a graphical interface that displays c- and f-structures, and the illustration is reminiscent to this author of the M"
2003.mtsummit-tttt.6,C88-1008,0,0.101231,"the systems described here were developed with the help of students at UMIST. An obvious and reasonable initial question might be why working on model implementations in Prolog might be useful, and to what sort of student? Way (2002) describes how his students undergo three years of training in CL including programming in various languages. he states that these students “may find themselves in the position of implementing changes to current systems, or indeed developing new ones” (p. 54). He describes exercises which involve Prolog programming within a framework based on Eurotra’s Eframework (Bech & Nygaard, 1988), and it might be an interesting point of discussion for both Way and the current author whether Prolog is the most appropriate vehicle for this activity, given its lack of status as a programming language of choice for a real industrial application. We will leave this discussion for another time! 2. Similar approaches The (relatively restricted) literature describing teaching of MT aimed at CL and CS students can be divided into those that use standard programming languages, and those that have developed more task-specific tools. We have described Way’s (2002) approach above. The students of"
2003.mtsummit-tttt.6,1991.mtsummit-papers.7,0,0.0945641,"t the wrong solutions.) French morphology is quite rich, particularly in adjective and verb paradigms: this richness involves not so much a large range of inflections, but a large variety of interactions between stems and endings. Supposing, for example, that the word basses was not in the lexicon. According to our rules, there are 21 different interpretations of this string, assuming it is inflected (9). 5 The development of the morphological interaction part was carried out by Gillian Chamberlain for her 1994 MSc dissertation. 6 The corpus was obtained from colleagues at ISSCO, Geneva – cf. Bouillon & Boesefeldt (1991). 7 The fact that the source language is French but the interactions are presented in English is a superficial anomaly. stem basse basse basses basses basses basses basses basses basse basses basse basse basses basses bass bass basse basx bas bas basses cat n n adj adj adj adj adj adj adj adj adj adj adj adj adj adj adj adj adj adj adj gen masc fem masc masc masc masc masc masc masc masc masc masc masc fem fem fem fem fem fem fem fem nmbr pl pl sing sing sing sing sing sing pl pl pl pl pl sing pl pl pl pl pl pl pl para 1 2 6 11 15 18 1 2 3 6 18 18 1 2 3 4 6 15 18 (9) 21 possible interpretation"
2003.mtsummit-tttt.6,J89-1003,0,0.085205,"Missing"
2003.mtsummit-tttt.6,2002.eamt-1.9,0,0.0319342,"that an appropriate specification language must be learned, entailing the “usual difficulty” (p. 65), and indeed the examples of rules and so on that are shown suggest that this specification language is effectively a high-level task-specific programming language. Nevertheless, the tool also has a graphical interface that displays c- and f-structures, and the illustration is reminiscent to this author of the Metalshop tool that developers of the Metal system had available in the 1980s, as illustrated in Hutchins & Somers (1992: 264ff),and still available to users of the commercial T1 system. Sheremetyeva (2002) illustrates the use of the “developer tools” part of the APTrans system. It si not always clear from the paper how all the tools are used, the impression is that the ideal user will be a highly trained computational linguist. But no programming skills as such seem to be implied. nt(F,G,H,I,J,syn(Lab,B1,Mods),U,Z) :copylabel(nt(F,G),nt(F1,G1)), bbrackets(B,U,V), preconj(PC,Mods,Mods1,V,W), ntbase(F1,G1,H,I,J,B,SynO,W,X), ntconj(F1,G1,F,G,H,I,J,PC,SynO, syn(Lab,B1,Mods1),X,Y), ebrackets(B1,Y,Z). (2) Example from LMT (McCord, 1989:37)1 3. Systems that students can develop 3.1 A really dumb syste"
2003.mtsummit-tttt.6,2001.mtsummit-teach.8,1,0.738603,"lustrations of various approaches to MT. The systems include a dumb word-for-word system, DCG-based “transfer” system, an interlingua-based system with an LFG-like interface structure, a firstgeneration-like Russian-English system, an interactive system, and an implementation based on early example-based MT. 1. Introduction There is something of a consensus in the recent literature on “MT in the Classroom” that distinguishes the teaching of MT to different target students, notably Computer Science (CS) and Computational Linguistics (CL) students vs. trainee translators (cf. Kenny & Way, 2001; Somers, 2001) among others. The present paper discusses the development of “toy” systems (cf. v. Hahn & Vertan, 2002), specifically written in Prolog, developed with the aim of providing relatively complex natural-language programs for students of Prolog and, secondarily, to provide demos of various approaches to MT. A number of different of languages are illustrated, usually for no other reason than variety. Some of the systems described here were developed with the help of students at UMIST. An obvious and reasonable initial question might be why working on model implementations in Prolog might be useful"
2003.mtsummit-tttt.6,2002.eamt-1.8,0,0.0650577,"Missing"
2003.mtsummit-tttt.6,2002.eamt-1.6,0,0.0161502,"r discusses the development of “toy” systems (cf. v. Hahn & Vertan, 2002), specifically written in Prolog, developed with the aim of providing relatively complex natural-language programs for students of Prolog and, secondarily, to provide demos of various approaches to MT. A number of different of languages are illustrated, usually for no other reason than variety. Some of the systems described here were developed with the help of students at UMIST. An obvious and reasonable initial question might be why working on model implementations in Prolog might be useful, and to what sort of student? Way (2002) describes how his students undergo three years of training in CL including programming in various languages. he states that these students “may find themselves in the position of implementing changes to current systems, or indeed developing new ones” (p. 54). He describes exercises which involve Prolog programming within a framework based on Eurotra’s Eframework (Bech & Nygaard, 1988), and it might be an interesting point of discussion for both Way and the current author whether Prolog is the most appropriate vehicle for this activity, given its lack of status as a programming language of cho"
2003.mtsummit-tttt.6,C86-1077,0,0.447086,"s explanation. does your sister speak Russian ? no, she doesn’t say, but she understands all, what she reads. a brother’s English newspaper is here. from the coast of the sea to our house is not remote. at-home is your father ? do you wish the plate of the meat ? a left sleeve of the new woollen dress too(much) is long and narrow. (8) Example translations from the Georgetwon [sic] system. cated interactive interfaces available with commercial systems, so the aim with this system was more to explore some issues which had become apparent at the time when I was associated with the Ntran project (Whitelock et al., 1986), and in my own even earlier work (Somers & Johnson, 1979). These issues are that the system must know not only when to interact, but also how. If the system interacts whenever it meets a problem, from the user’s point of view the interactions may seem disjointed and illogical, since they will be following the system’s “flight-path”. So for example, it may do lexical disambiguation for various parts of the SL text, then “come back” to do some syntactic disambiguation, and then return for a third time to the “same” problem if there is a question of TL lexical choice. On top of this, there may b"
2006.eamt-1.6,1996.amta-1.19,0,0.0430857,"Missing"
2006.eamt-1.6,W01-0515,0,0.0820141,"Missing"
2006.eamt-1.6,P02-1040,0,0.0958221,"Missing"
2007.tc-1.1,2003.mtsummit-eval.1,0,0.0449819,"2003). Producing lexicographic resources and rules for MT systems is a laborious and expensive process (Kilgarriff & Tugwell, 2001: 187), and a number of approaches have been proposed in MTrelated research and development to overcome the challenges posed by what Farwell et al. (1992: 532) among others have called the “lexical acquisition bottleneck”. These consist, for example, in reusing 1 already existing lexical resources to design new MT systems (Bond et al., 2001) or in fine-tuning customisable software to specific domains by adding the relevant terminology to augment or refine coverage (Ayan et al., 2003). In particular, cost-effective approaches that rely on repurposing available lexical components have been successfully applied to the development of MT systems covering lowdensity languages, as reported in Diaz de Ilarraza et al. (2000), Weerasinghe (2002) and Karagol-Ayan et al. (2003). In recent years the Internet has spurred and enabled the appearance of a host of tools and resources that rely on intensive lexicographic work, including mono- and multilingual online dictionaries and lexical look-up facilities, browsable term banks as well as web-based MT systems. At the same time, over the"
2007.tc-1.7,W07-1806,0,0.0236425,"ient consultation, to save the doctor's time. This might be a suitable application for computer-based interviewing (cf. Bachman 2003). The next step might be the doctor-patient consultation itself, which has been the focus of much attention. While some developers (e.g. Bouillon et al. 2005) originally assumed that the patient's role in this can be reduced to simple responses involving yes/no responses, gestures and perhaps a limited vocabulary of simple answers, current clinical theory in contrast focuses on patient-centred medicine (cf. Stewart et al. 2003), an issue mentioned for example by Bouillon et al. (2007). The session will see the doctor eliciting information in order to make a diagnosis as foreseen, but also explaining the condition and the treatment, exploring the patient's feelings about the situation, and inviting the patient to ask questions. So the dialogue is very much a two-way interaction. Of course this presents massive difficulties for SLT system design. After the initial consultation, the next step may involve a trip to the pharmacist to get some drugs or equipment. Apart from the human interaction, the drugs (or whatever) will include written instructions and information: frequenc"
2007.tc-1.7,2005.eamt-1.8,0,0.0183457,"any medical expertise, nor possibly the high level of education and openness to new technology that is often assumed in the literature on SLT. If this is the patient's first encounter with this particular healthcare institution, they may wish to get their ""history"", a task nowadays often done separately from the main doctor-patient consultation, to save the doctor's time. This might be a suitable application for computer-based interviewing (cf. Bachman 2003). The next step might be the doctor-patient consultation itself, which has been the focus of much attention. While some developers (e.g. Bouillon et al. 2005) originally assumed that the patient's role in this can be reduced to simple responses involving yes/no responses, gestures and perhaps a limited vocabulary of simple answers, current clinical theory in contrast focuses on patient-centred medicine (cf. Stewart et al. 2003), an issue mentioned for example by Bouillon et al. (2007). The session will see the doctor eliciting information in order to make a diagnosis as foreseen, but also explaining the condition and the treatment, exploring the patient's feelings about the situation, and inviting the patient to ask questions. So the dialogue is ve"
2007.tc-1.7,lavie-etal-2002-nespole,0,0.0450437,"to first-time (or one-time) untrained users (Johnson, 2004). 6 http://sail.usc.edu/transonics/demo/ transedit021r.mov http://www.youtube.com/watch?v=zNZeFJY53Is 8 http.//domino.watson.ibm.com/comm/research.nsf/pages/r.uit.innovation.html 7 6 (a) Converser's input screen showing correction of speech recognition with handwriting (Seligman and Dillinger 2006) (b) MedSLT patient's screen showing possible answers to the most recent question (Bouillon et al. 2007) (c) The MASTOR system8 Figure 2. Examples of on-screen interfaces supporting the spoken language translation Although research (e.g. by Costantini et al. 2002) suggests that multimodal interfaces are superior to speech-only systems, there are some situations where this will be impractical. Figure 3 shows two more versions of the S-MINDS system for use in hospital situations where it is not convenient for either user to access a computer screen, and where the device is necessarily entirely speech-driven. (a) One-way translation: the patient is not wearing a headset. The system is running on the computer in the background (b) Both users have headsets; the physician needs to be ""hands free"". The system is running on the PDA which the therapist is weari"
2007.tc-1.7,W06-3703,0,0.0674955,"Missing"
2007.tc-1.7,P05-3023,0,0.167163,"w.darpa.mil/ipto/ programs/cast/. 4 4 motivates differences in hardware, overall design, and coverage, but there may be other more subtle differences that result especially from the situation in which it was envisaged that the CAST systems would be used. System CCLINC MASTOR Speechalator Laser ACTD no name Transonics Accultran S-MINDS Converser Developers MITLincoln Lab (Lee et al. 2002) IBM Yorktown Heights (Zhou et al. 2003) Carnegie Mellon University (Waibel et al.2003) Carnegie Mellon University (Schulz et al. 2004) SRI Menlo Park CA (Kathol et al. 2005) University of Southern California (Ettelaie et al. 2005) A-Life Medical Inc, San Diego CA (Heinze et al. 2006) Sehda Inc, Mountain View CA (Ehsani et al. 2006) Spoken Translation, Berkeley CA www.spokentranslation.com/products/ healthcare IBM Yorktown Heights MASTOR MedSLT domino.watson.ibm.com/comm/pr.nsf/ pages/news.20061013_mastor.html ISSCO, University of Geneva www.issco.unige.ch/projects/medslt/ S:M|NDS Fluential Inc, Sunnyvale Ca Domains Languages doctor-patient dialogue English, Korean medical emergencies English, Mandarin medical interviews English, Arabic doctor-patient dialogue English, Thai f'irst medical exchanges English, Pashto docto"
2007.tc-1.7,N04-3003,0,0.0290767,"s were developed on the assumption that it is the doctor who controls the device: MedSLT originally allowed only for the doctor to pose questions, which were answered by a nod or a shake of the head. In the Transonics system, it seems to be a design decision, There is, however, an asymmetry in the dialogue management in control, given the desire for the Englishspeaking doctor to be in control of the device and the primary ""director"" of the dialog. (Ettelaie et al. 2005:89, emphasis added) based on the belief that the English speaker [...] is expected to have greater technological familiarity (Precoda et al. 2004:9) so that the medical care-giver will maintain the initiative in the dialogue, will have sole access to the controls and display of the translation device, and will operate the push-to-talk controls for both him or herself and the [P]ersian patient. (Narayanan et al. 2004:101) This set up is illustrated in Figure 1a, taken from an on-line demo of the Transonics system. Contrast Figure 1b, showing practitioner and patient sharing a device (in this case not for speech translation), and Figure 1c, the military version of the S-MINDS system, illustrating a highly portable wearable device with th"
2007.tc-1.7,N04-3010,0,0.0249799,"vailable for the relatively small number of the world's ""major"" languages. It is an inconvenience, but surely not a coincidence, that the groups most badly affected by communication barriers in healthcare speak languages which, for well understood commercial reasons, have not received the attention of computational linguists and language technologists. So even if we wanted to build a pipeline SLT system for, say, Somali or Sylheti or Urdu, we would struggle to find any of the components. The effort required to develop SLT for a new language should not be underestimated (cf. Black et al. 2002, Schultz et al. 2004, Zhou et al. 2004, Narayanan et al. 2004, 2006, Kathol et al. 2005, Besacier et al. 2006, Schultz and Black 2006). The conventional solution lies in a menu-driven phrase-book approach, with prerecorded ""translations"" of predetermined phrases, though we have explored the possibility of ""faking"" speech synthesis as an interim solution to this (Evans et al. 2002, Somers et al. 2006) with a fairly promising evaluation based on the doctor-patient dialogue scenario using a German synthesizer to produce fake Somali output. Even more audaciously we have attempted ""fake"" speech recognition by tricking"
2007.tc-1.7,W06-3701,0,0.0203183,"Commonly nowadays, systems take advantage of the additional modalities offered by a graphical interface, where a text trace of what was understood (verbatim transcription and/or paraphrase of the translation to be output) as well as illustrations can reinforce the users' confidence in the system. Figure 2 shows three examples. Somers and Lovel (2003) assumed that different user interfaces are needed for different users, and these interfaces must accommodate all sorts of users, with or without experience of computers, able or not to type on a keyboard, use a mouse or mousepad, or even to read (Seligman and Dillinger 2006, Somers et al. in press).It is noticeable that the examples in Figure 2 are all highly dependent on text, which may not be appropriate for some users with limited literacy due to visual impairment or lack of education. Incorporating more symbolic graphics into an interface is an area of complexity, as Johnson et al. (2006) report. Iconic text-free symbols, for example to represent ""please repeat"", or ""next question"", or abstract concepts such as ""very"" are not always as instantly understandable as some designers think. Considering the use of symbols form AAC (augmentative and alternative comm"
2007.tc-1.7,W03-2206,1,0.844103,"ch) communication aids on laptops and tablet PCs: with the laptop, controlled by a mouse or mouse-pad, the practitioner tends to take the initiative, while with the tablet, which comes with a stylus, the patient takes the lead (Somers et al. in press). 3.2 Multimodality Commonly nowadays, systems take advantage of the additional modalities offered by a graphical interface, where a text trace of what was understood (verbatim transcription and/or paraphrase of the translation to be output) as well as illustrations can reinforce the users' confidence in the system. Figure 2 shows three examples. Somers and Lovel (2003) assumed that different user interfaces are needed for different users, and these interfaces must accommodate all sorts of users, with or without experience of computers, able or not to type on a keyboard, use a mouse or mousepad, or even to read (Seligman and Dillinger 2006, Somers et al. in press).It is noticeable that the examples in Figure 2 are all highly dependent on text, which may not be appropriate for some users with limited literacy due to visual impairment or lack of education. Incorporating more symbolic graphics into an interface is an area of complexity, as Johnson et al. (2006)"
2007.tc-1.7,somers-etal-2006-developing,1,0.8553,"d a pipeline SLT system for, say, Somali or Sylheti or Urdu, we would struggle to find any of the components. The effort required to develop SLT for a new language should not be underestimated (cf. Black et al. 2002, Schultz et al. 2004, Zhou et al. 2004, Narayanan et al. 2004, 2006, Kathol et al. 2005, Besacier et al. 2006, Schultz and Black 2006). The conventional solution lies in a menu-driven phrase-book approach, with prerecorded ""translations"" of predetermined phrases, though we have explored the possibility of ""faking"" speech synthesis as an interim solution to this (Evans et al. 2002, Somers et al. 2006) with a fairly promising evaluation based on the doctor-patient dialogue scenario using a German synthesizer to produce fake Somali output. Even more audaciously we have attempted ""fake"" speech recognition by tricking an English ASR system into recognizing a limited vocabulary of Urdu words, with astonishingly good results when the system has to choose from a set of possible responses (Rizvi 2007). Some of the research in medical SLT can be criticized for being more led by the available technology than by any study of what users really need - what can we achieve given the state of the art in A"
2007.tc-1.7,2003.mtsummit-papers.49,1,0.737262,"ers, and indeed is used as a means of reassuring users of the high quality of translation obtainable. 9 http://www.youtube.com/watch?v=zNZeFJY53Is 7 This being the case, one starts to question whether in fact translation is the most appropriate road to go down. While earlier apparently dismissing VoxTec's Phraselator or Ectaco's Medical SpeechGuard as mere speech-activated phrase-books earlier, it is arguable that in fact that is the more reasonable approach to the problem at the moment. Evaluation of pipeline SLT architectures confirms that (conventional) MT is the weakest link in the chain (Somers and Sugita 2003, Lee 2007), so it is clear that the translation function of the system has to take full advantage of what is known and predictable about the things that are going to be said. Similarly, the robustness of ASR is variable: while an input window in which the user can correct the misrecognised utterance seems attractive, in some cases it might be easier to select the input from a drop-down menu of appropriate and likely utterances. These can be associated with prerecorded translations, which would also cut out the processing time-lag noticeable in the demos of even the most polished systems. Anot"
2007.tc-1.7,N03-4015,0,0.0485007,"Missing"
2007.tc-1.7,W06-3704,0,\N,Missing
2007.tc-1.7,W06-3709,0,\N,Missing
2007.tmi-papers.25,W07-1806,0,0.0852996,"er-based interviewing (cf. Bachman 2003). The next step might be the doctor–patient consultation itself, which has been the focus of much attention (e.g. papers at the recent Workshop on Medical Speech Translation at HLT/NAACL in New York in 2006). While some developers (e.g. Bouillon et al. 2005) originally assumed that the patient’s role in this can be reduced to simple responses involving yes/no responses, gestures and perhaps a limited vocabulary of simple answers, current clinical theory in contrast focuses on patient-centred medicine (cf. Stewart et al. 2003), an approach now adopted by Bouillon et al. (2007). The session will see the doctor eliciting information in order to make a diagnosis as foreseen, but also explaining the condition and the treatment, exploring the patient’s feelings about the situation, and inviting the patient to ask questions. So the dialogue is very much a two-way interaction. Of course this presents massive difficulties for SLT system design. After the initial consultation, the next step may involve a trip to the pharmacist to get some drugs or equipment. Apart from the human interaction, the drugs (or whatever) will include written instructions and information: frequenc"
2007.tmi-papers.25,2005.eamt-1.8,0,0.0983377,"is often assumed in the literature on SLT. If this is the patient’s first encounter with this particular healthcare institution, they may wish to get their “history”, a task nowadays often done separately from the main doctor–patient consultation, to save the doctor’s time. This might be a suitable application for computer-based interviewing (cf. Bachman 2003). The next step might be the doctor–patient consultation itself, which has been the focus of much attention (e.g. papers at the recent Workshop on Medical Speech Translation at HLT/NAACL in New York in 2006). While some developers (e.g. Bouillon et al. 2005) originally assumed that the patient’s role in this can be reduced to simple responses involving yes/no responses, gestures and perhaps a limited vocabulary of simple answers, current clinical theory in contrast focuses on patient-centred medicine (cf. Stewart et al. 2003), an approach now adopted by Bouillon et al. (2007). The session will see the doctor eliciting information in order to make a diagnosis as foreseen, but also explaining the condition and the treatment, exploring the patient’s feelings about the situation, and inviting the patient to ask questions. So the dialogue is very much"
2007.tmi-papers.25,P05-3023,0,0.0249617,"e explanations and demonstrations by the practitioner, and typically also elicitation of further information from the patient. Hospital treatment would involve interaction with a wide range of staff, again not all medical experts. All this introduces the question of who is the principle user of a communication device, which will have a bearing on many design issues. In contrast for example with several medical SLT designs, where it is assumed that the doctor is the one who controls the dialogue and accordingly controls the SLT system interface (Narayanan et al. 2004:101, Bouillon et al. 2005, Ettelaie et al. 2005:89), we might propose that it is the patient who is going to be the regular user, and who should therefore “own” the device. At the very least, it should be recognised that a communication device (whether SLT or some other technology, see below) will typically have two users at any time, who may have very different skills and expectations, and these need to be taken into consideration in the design. Indeed, just like the healthcare providers, as already mentioned, not all patients are alike, and they may represent a wide range of levels of language ability (both native and target), literacy,"
2007.tmi-papers.25,N04-3003,0,0.0283204,"s taken, and these are worth briefly repeating here in connection with our proposal that SLT – especially as currently implemented – is not always the most appropriate technology for all LEP patients’ (and their clinicians’) needs. We have already mentioned the fact that current SLT systems inevitably see the doctor as being in control of the system and hence of the dialogue itself. Several assumptions underlying this set-up are false: the doctor’s familiarity with computers in general and the SLT device in particular is assumed to be superior to the patient’s (e.g. Narayanan et al. 2004:101, Precoda et al. 2004:9, Bouillon et al. 2007:42), but this may not be true, especially if the patient becomes a regular user. In our own research, admittedly with a much simpler device (Johnson 2007, Somers & Lovel 2007, Somers et al. in prep.), we found many patients more than willing to share or even take over control of the device, as shown in Figure 2a, in contrast to the scenario presented in the on-line video demo of an SLT system (Figure 2b), where the doctor (the one in the white coat) has total control to the extent that the patient is not even allowed to see the screen. Sharing the device will also faci"
2007.tmi-papers.25,somers-etal-2006-developing,1,0.882895,"Missing"
2007.tmi-papers.25,W03-2206,1,0.461428,"s in healthcare provision in these communities and communication difficulties are identified as a major factor (e.g. Jones & Gill 1998, Fassil 2000, Jacobs et al. 2001, Bischoff et al. 2003, Flores et al. 2005, Westberg & Sorensen 2005), and an equally rich literature, which we will not review here, discusses traditional ways of addressing this problem, through use of interpreters and other services. Our interest is in the extent that language technology, including but not limited to machine translation (MT), may be able to provide some support as a contribution to a solution to this problem (Somers & Lovel 2003). Two aspects of this issue need to be underlined immediately. First, it should be realised that this is a problem not just for the LEP patients, but for the healthcare providers with whom they need to interact: it is a matter not only of making oneself understood, but of understanding too. This seems to be an obvious point, but is often overlooked, for example in papers with titles referring to “problems of refugees” and so on, when more properly the focus should be on “problems of communication”. By the same token, note the use of the term “healthcare providers”: this is not just a problem f"
2007.tmi-papers.25,2003.mtsummit-papers.49,1,0.793679,"Missing"
A97-1040,H92-1022,0,0.0227939,"nowledge"" of the system simply by adding more examples: if they contain ""new"" structures, the knowledge base is extended; if they mirror existing examples, the system still benefits since the evidence for one interpretation or another is thereby strengthened. 4.2 The matching algorithm The matcher, which has been developed from one first used in the MEG project ( S o m e r s e t al., 1994), processes the new text in a linear fashion, having first divided it into manageable portions, on the basis of punctuation, lay-out, formatting and so on. The input is tagged, using a standard tagger, e.g. (Brill, 1992). There is no need to train the tagger on our text type, because the actual tags do not matter, as long as tagging is consistent. The matching process then involves ""sliding"" one phrase past the other, identifying ""strong"" matches (word and tag) or ""weak"" (tag only) matches, and allowing for gaps in the match, in a method not unlike dynamic programming. The matches are then scored accordingly. The result is a set of possible matches linked to correctly filled schemas, so that even previously unseen words can normally be correctly assigned to the appropriate slot. The approach is not without it"
A97-1040,W96-0411,0,0.0264887,"hat cannedtext approaches, template-based approaches and g r a m m a r - b a s e d approaches to natural language generation - while they are often contrasted - m a y in fact be regarded as different points on a scale, from the very specific to the very general. In a sense, templates are just generalized canned texts, and grammars are just generalized templates. Indeed, the possibility of combining these different modes of generation has recently been highlighted as one of the keys to efficient use of natural language generation techniques in practical applications (van Noord & Neumann, 1996; Busemann, 1996). 6.3 high-level text structuring, such as assembling paragraphs into documents. ""The basic idea is to use hypertext mechanisms to enable users to dynamically select the paragraphs they wish to read, and therefore in essence perform their own high-level textplanning"" (P~eiter & Mellish, 1993), p.3. Second, but related to the first point, the hypertext capabilities are also a mild form of tailoring to the needs of different users. Users are expected to explore only links containing information that they need. Hypertext is generated by means of rules t h a t are very similar to the g r a m m a r"
A97-1040,A94-1001,0,0.0684236,"Missing"
A97-1040,1996.amta-1.19,0,0.0174632,"middeling en Beroepsopleiding), Mick Riley (Newcastle upon Tyne City Council), and Teresa Paskiewicz and Mark Stairmand (UMIST). The URL for the project's web site is h t t p ://www.mari. co. u k / t r e e / . 269 T R E E therefore offers two significant services: intelligent search and summarization on the one hand, and these independent of the original language of the job ad on the other. It could be argued that the latter at least could be achieved by hooking a commercial Machine Translation (MT) system up to an Internet employment service. Although MT has had some success on the Internet (Flanagan, 1996), this is with largely sympathetic users who understand well the limitations of MT. Its use for a more delicate task aimed at the general public, especially a public which is not necessarily highly educated, is certainly out of the question, for well known reasons which we need not explore here. Suffice to say that an experiment in Canada using an M T system for precisely this application (Murray, 1989) was far from successful. It is also apparent that for many jobs in a location where a different language is spoken, sufficient linguistic knowledge at least to read an ad for a job in that regi"
A97-1040,X93-1015,0,0.0623927,"Missing"
A97-1040,W98-1400,0,0.212343,"Missing"
A97-1040,C90-1014,0,0.0774551,"Missing"
A97-1040,J96-4008,0,\N,Missing
C86-1026,C82-1062,0,\N,Missing
C90-3048,C86-1007,0,0.0237955,"Missing"
C90-3048,1993.tmi-1.14,0,0.0828039,"Missing"
C90-3048,C86-1077,0,0.248654,"Missing"
C90-3048,C82-1034,0,0.4329,"Missing"
C90-3048,C88-2155,0,0.605756,"Missing"
C90-3048,P88-1019,1,\N,Missing
C98-2195,J99-2005,1,\N,Missing
C98-2195,J96-4002,0,\N,Missing
J88-1009,P84-1101,0,0.0282557,"t be tackled before long. The first is the question of ill-formed input, discussed by Weischedel and Ramshaw. To be fair, it must be said that although this paper is very interesting, the relevance to MT is not brought out as it might have been: indeed, MT is only mentioned once; a significant part of the chapter is given over to an example of the need to infer speakers&apos; goals when interpreting interaction with a database (it is not obvious that there is a major need for such processing in MT); and there is no discussion of the varying needs for robustness in different types of MT system (cf. Arnold and Johnson 1984). On the other hand, much of the paper concerns different sources of ill-formedness, and notes that for each type different Computational Linguistics, Volume 14, Number 1, Winter 1988 Book Reviews solutions may be appropriate. The relevance here for MT does not need stating. The authors first make a distinction between &quot;absolute&quot; ill-formedness, such as misspellings, homonym confusion, omission, ungrammaticality, selection restriction violation and presupposition violation, and what they call &quot;relative&quot; ill-formedness, i.e., input which a human would judge well-formed, but which is ill-formed"
J90-1009,J86-2003,0,0.0658911,"Missing"
J99-2005,J96-4002,0,0.193096,"Computerised Articulation Test), which I had developed to automate the assessment of children's articulation tests. At the heart of this program was an algorithm very similar to the one reported by Covington. Whereas Covington seeks to align the segments in possible historical cognates, CAT aligns the segments of a child's articulation with those of the adult model, and on the basis of this looks for evidence of the phonological processes listed in Table 1. For example, if elephant [ehfAnt] is pronounced [evot], we need to decide which of several possible alignments is the most plausible (cf. Covington 1996, 481): ~--vo-t ~iIfont ev~t--clIfont cv~---t ¢iIfont e--vot¢iIfont etc. If applied to a body of articulation data, e.g., a corpus of, say, 45 words elicited from the child as in a standardized articulationtest,the evidence of each phonological process can be quantified, and the overall picture compared with the model of the average child, to give an individual's &quot;articulation age&quot; and profile. * Centre for ComputationalLinguistics,UMIST,Manchester,England. E-mail:harold@cd.umist.ac.uk (~) 1999Associationfor ComputationalLinguistics Computational Linguistics Volume 25, Number 2 Table 1 Phonolo"
J99-2005,P98-2200,1,0.907002,"Missing"
J99-2005,C98-2195,1,\N,Missing
P88-1019,1987.mtsummit-1.14,1,0.836573,"Missing"
P88-1019,C88-2103,1,\N,Missing
P98-2200,J96-4002,0,0.108305,"r reduction where the 1227 resulting segment has some of the features of both elements in the original cluster (e.g. sleep [tip]). It would be appropriate here to review the software currently available to speech clinicians, but lack of space prevents us from doing so (see Somers, forthcoming). Suffice it to say that software does exist, but is mainly for grammatical and lexical analysis. Of the tiny number of programs which specifically address the problem of articulation testing, none, as far as one can tell, involve automatic alignment of the data. 1.2. Segment alignment In a recent paper, Covington (1996) described an algorithm for aligning historical cognates. The present author was struck by the possibility of using this technique for the child-language application, a task for which a somewhat similar algorithm had been developed some years ago (Somers 1978, 1979). In both algorithms, the phonetic segments are interpreted as bundles of phonetic features, and the algorithms include a simple similarity metric for comparing the segments pairwise. The algorithms differ somewhat in the way the search space is reduced, but the results are quite comparable (Somers, forthcoming). Coincidentally, a r"
P98-2200,J99-2005,1,\N,Missing
somers-etal-2006-developing,W03-2206,1,\N,Missing
U05-1012,P03-2024,0,0.035673,"Missing"
U05-1012,somers-etal-2006-developing,1,0.83278,"Missing"
U05-1012,W03-2206,1,0.834802,"d two varieties of Portuguese. The list is impressive, but there are still thousands of languages not covered. Our interest is in providing language technology-based support for speakers of ‘minor’ languages1 when they find themselves in situations 1 A ‘minor’ language is any language which is not a where their lack of ability in another language is a significant disadvantage: we have been focusing on the case of newly arrived immigrants seeking healthcare (a visit to the doctor), but the possibilities are almost endless. This is the scenario envisaged by the CANES framework,2 as described by Somers and Lovel (2003) and Somers et al. (2004). This envisages software support for getting general information about healthcare problems, arranging an appointment at the clinic or hospital, understanding information leaflets and instructions regarding treatment and drugs, and of course faceto-face meetings with healthcare providers, notably GPs and nurses. Other projects in this field have focused on spoken language translation (SLT) of the doctor–patient interview (Rayner et al., 2003; Narayanan et al., 2004). We have recognized that, while face-to-face dialogues have an important role in the pathway to healthca"
U05-1012,2003.mtsummit-papers.49,1,0.831915,"Missing"
U05-1019,bernth-mccord-2000-effect,0,0.0265677,"ers now see on-line MT as a way of getting their message translated. They have become users of MT for dissemination, although typically they do not fit the profile outlined in Table 1, and it has been argued (Gaspari, 2004; Somers and Gaspari, 2005) that web-page designers need to be better educated about what MT can and cannot do. It is not unreasonable therefore for web-page designers to seek some way of knowing how well their web pages will be translated well by free online MT services. There has been a fair amount of research recently on ‘translatability’. (Gdaniec, 1994; Bernth, 1999a,b; Bernth and McCord, 2000; Underwood and Jongejan, 2001; Bernth and Gdaniec, 2002; O’Brien, in press). Research has focussed on identifying ‘translatability indicators’, stylistic or grammatical linguistic features that are known to be problematic for MT (so a more transparent name would perhaps be ‘translation difficulty indicators’). For example, mid-sentence parenthetical statements or the use of the passive voice could respectively be classified as stylistic and grammatical indicators. While such measures are of use to linguists, and to designers of controlled languages, they mean little or nothing to the average"
U05-1019,1996.amta-1.19,0,0.0470997,"cases, we find RTT to be a poor predictor of quality, with high BLEU and F-scores for RTTs when the forward translation was poor. We discuss why this is the case, and conclude that, even if it seemed obvious that RTT was good for nothing, at least we now have some tangible evidence. 1 Introduction Macklovitch (2001:27) talks of “the spectacular growth and pervasiveness of the World Wide Web” leading to a “democratization” of Machine Translation (MT) which has “profoundly transformed the MT business”. The availability of free on-line MT systems, since CompuServe’s initial experiments in 1994 (Flanagan, 1996) and then more significantly AltaVista’s collaboration with Systran from 1997 onwards (Yang and Lange, 1998), has indeed revolutionized the MT world, creating a whole new and significantly large community of users, mostly with little or no knowledge or understanding of how MT works or even, in some cases, how language works. Such users are, nevertheless, keen to know how good MT output is, and frequently resort to the intuitive technique of ‘round-trip translation’ (RTT), or ‘back-andforth translation’, in which they take a given text or sentence, have it translated into some foreign language"
U05-1019,2004.eamt-1.8,0,0.0199439,"see a lot of web pages with explicit links to Assimilation many SLs, one TL any style any topic poor quality OK post-editing if needed user is reader Dissemination one SL, many TLs controlled style restricted topic(s) good quality required no post-editing user is author Table 1. Differences between MT for assimilation and MT for dissemination MT services, which means that web-page designers now see on-line MT as a way of getting their message translated. They have become users of MT for dissemination, although typically they do not fit the profile outlined in Table 1, and it has been argued (Gaspari, 2004; Somers and Gaspari, 2005) that web-page designers need to be better educated about what MT can and cannot do. It is not unreasonable therefore for web-page designers to seek some way of knowing how well their web pages will be translated well by free online MT services. There has been a fair amount of research recently on ‘translatability’. (Gdaniec, 1994; Bernth, 1999a,b; Bernth and McCord, 2000; Underwood and Jongejan, 2001; Bernth and Gdaniec, 2002; O’Brien, in press). Research has focussed on identifying ‘translatability indicators’, stylistic or grammatical linguistic features that are"
U05-1019,1994.amta-1.13,0,0.0831303,"which means that web-page designers now see on-line MT as a way of getting their message translated. They have become users of MT for dissemination, although typically they do not fit the profile outlined in Table 1, and it has been argued (Gaspari, 2004; Somers and Gaspari, 2005) that web-page designers need to be better educated about what MT can and cannot do. It is not unreasonable therefore for web-page designers to seek some way of knowing how well their web pages will be translated well by free online MT services. There has been a fair amount of research recently on ‘translatability’. (Gdaniec, 1994; Bernth, 1999a,b; Bernth and McCord, 2000; Underwood and Jongejan, 2001; Bernth and Gdaniec, 2002; O’Brien, in press). Research has focussed on identifying ‘translatability indicators’, stylistic or grammatical linguistic features that are known to be problematic for MT (so a more transparent name would perhaps be ‘translation difficulty indicators’). For example, mid-sentence parenthetical statements or the use of the passive voice could respectively be classified as stylistic and grammatical indicators. While such measures are of use to linguists, and to designers of controlled languages, t"
U05-1019,C90-3074,0,0.442187,"the author explains the technique, and suggests that “In theory, the back translated English should match the original English.” Several garbled examples are then given, and the article concludes “Would you trust your surgeon using these instructions?” Another website recognizes the problem “Machine translations can produce text that is garbled or hilariously inaccurate”, and suggests as a resolution “Test the precision of your translated text by sending a phrase on a round trip through the translation engine.” (Anon, 2005). The dangers of this approach have long been appreciated: for example Huang (1990), addressing the problem of evaluating output when you do not know the target language, describes it as the “seemingly most natural way” to evaluate a translation, but quickly warns that the results are not reliable. More recently, O’Connell (2001) gives the following sound advice on an IBM website: “A common misunderstanding about MT evaluation is the belief that back translation can disclose a system’s usability. […] The theory is that if back translation returns [the source language] input exactly, the system performs well for this language pair. In reality, evaluators cannot tell if errors"
U05-1019,P02-1040,0,0.0870857,"work, we might hope that the quality of the RTT will reflect the quality of the FT: if this is true, then at least RTT could be used to help lay-users to decide which system to use, when they are faced with a large number to choose from. In order to explore this hypothesis, we set up a first experiment in which 129 we took four texts representing various language pairs, translated them each using five free on-line MT systems,1 then translated the resulting FT back into the original language using the same system. We used two standard measures to evaluate the results, the familiar BLEU metric (Papineni et al., 2002), and Turian et al.’s (2003) F-score metric. A number of researchers have commented on the fact that BLEU scores do not always agree with the Fscore, based on precision and recall, nor sometimes with human judgments, especially for shorter stretches of text (e.g. Way and Gough, in press). In addition, alternative packages available on the Web offering implementations of BLEU give significantly different results. Accordingly, we used our own implementations of BLEU and F-score,2 and show results with both metrics; while they sometimes rank the translations differently, they both tell the same o"
U05-1019,2003.mtsummit-papers.51,0,0.116251,"Missing"
U05-1019,2001.mtsummit-papers.65,0,0.0443092,"a way of getting their message translated. They have become users of MT for dissemination, although typically they do not fit the profile outlined in Table 1, and it has been argued (Gaspari, 2004; Somers and Gaspari, 2005) that web-page designers need to be better educated about what MT can and cannot do. It is not unreasonable therefore for web-page designers to seek some way of knowing how well their web pages will be translated well by free online MT services. There has been a fair amount of research recently on ‘translatability’. (Gdaniec, 1994; Bernth, 1999a,b; Bernth and McCord, 2000; Underwood and Jongejan, 2001; Bernth and Gdaniec, 2002; O’Brien, in press). Research has focussed on identifying ‘translatability indicators’, stylistic or grammatical linguistic features that are known to be problematic for MT (so a more transparent name would perhaps be ‘translation difficulty indicators’). For example, mid-sentence parenthetical statements or the use of the passive voice could respectively be classified as stylistic and grammatical indicators. While such measures are of use to linguists, and to designers of controlled languages, they mean little or nothing to the average lay-user. Even if RTT is not r"
W03-2206,W97-0905,0,\N,Missing
W03-2206,J97-1005,0,\N,Missing
W03-2206,J93-1007,0,\N,Missing
W03-2206,J93-2002,0,\N,Missing
W06-3705,lavie-etal-2002-nespole,0,0.0235943,"evaluated for appropriateness, an issue not addressed in any of the reports on research in medical SLT that we have read. For example, Bouillon et al. (2005) show a screenshot which includes the graphic reproduced in Figure 2. The text suggests that the user (i.e. the doctor?) can click on the picture to set the topic domain. It is not clear why a graphic is more suitable for the doctor-user than a drop-down text menu; there is no mention of whether the patient is encouraged to use the diagram, but if so one wonders for what purpose, and if it is the best choice of graphic. Research (e.g. by Costantini et al. 2002) suggests that multimodal interfaces are superior to speech-only systems, so there is some scope for exploration here. (2006) report. Iconic text-free symbols, for example to represent “please repeat”, or “next question”, or abstract concepts such as “very” are not always as instantly understandable as some designers think. Considering the use of symbols from AAC (augmentative and alternative communication) designed for speech-impaired disabled users by patients with limited English, we noticed that AAC symbol sets have a systematic iconicity that regular users learn, but which may be opaque t"
W06-3705,P05-3023,0,0.026563,"medical professional”. A significant common factor in the descriptions of the systems seems to be that it is the doctor who controls the device. This may be because it can only handle one-way translation, as is the case of MedSLT, “. . . the dialogue can be mostly initiated by the doctor, with the patient giving only non-verbal responses” (Bouillon et al., 2005), or may be an explicit design decision: There is, however, an assymmetry in the dialogue management in control, given the desire for the English-speaking doctor to be in control of the device and the primary “director” of the dialog. (Ettelaie et al., 2005, 89) [emphasis added] It is understandable that as a regular user, the medical professional may eventually have more familiarity with the system, but this should be reflected in there being different user-interfaces (see Somers and Lovel 2003). We find regrettable however the assumption that “the English speaker [. . . ] is expected to have greater technological familiarity” (Precoda et al., 2004, 9) or that the medical care-giver will maintain the initiative in the dialogue, will have sole access to the controls and display of the translation device, and will operate the 1 We give here one i"
W06-3705,W02-0710,0,0.0128613,"influences research. We also need to consider more carefully the design of the feedback and verification elements of systems, and the need for realistic evaluations. 1 Introduction 2 Who are the users? The doctor–patient consultation is a central element of the “pathway to healthcare”, and with language problems recognised as the single most significant barrier on this pathway, spoken-language translation We start by looking at the assumed profile of users of medical SLT systems. Systems that have been developed so far can be divided into those for use in the doctors office – notably, MedSLT (Rayner and Bouillon, 2002), CCLINC (Lee et al., 2002), and (honourable mention) the early work done at CMU (Tomita et al., 1988)1 – and those for use for first contact with medical professionals “in the field”, developed under DARPA’s CAST programme:2 MASTOR (Zhou et al., 2004), Speechalator (Waibel et al., 2003), Transonics (Narayanan et al., 2004) and SRI’s system (Precoda et al., 2004). This distinction mainly motivates differences in hardware, overall design, and coverage, but there may be other more subtle differences that result especially from the situation in which it was envisaged that the CAST systems would b"
W06-3705,2003.mtsummit-papers.49,1,0.750152,"ifficult, and SLT evaluation even more so. Most researchers agree that measures of translation fidelity in comparison with a gold-standard translation, as seen in text MT evaluation, are largely irrelevant: a task-based evaluation is more appropriate. In the case of medical SLT this presumably means simulating the typical situation that the technology will be used in, which involves patients with medical problems seeking assistance. Since SLT is a pipeline technology, the individual components could be evaluated separately, and indeed the effects of the contributing technologies assessed (cf. Somers and Sugita 2003). Once again, literacy issues will cloud any evaluation of speech recognition accuracy that relies on its speech-to-text function, and evaluation of speech synthesis must simulate a realistic task (cf. comments on SUS, above). Evaluations that have been reported suggest using real medical professionals and actors playing the part of patients: this scenario is well established in the medical world, where “standardized patients” (SPs) – actors trained to behave like patients – have been used since the 1960s. One problem with SPs for systems handling “low density” languages like Persian, Pashto a"
W06-3705,1983.tc-1.13,0,0.558331,"Missing"
W06-3705,N04-3003,0,\N,Missing
W06-3705,2005.eamt-1.8,0,\N,Missing
W06-3705,W03-2206,1,\N,Missing
W06-3705,somers-etal-2006-developing,1,\N,Missing
W98-1216,C94-2174,0,0.234206,"l prefer terms like &apos;register&apos; (which Biber uses); an affinity with work on genre detection will also be apparent. Because there is sometimes some dispute about the use of the term &apos;sublanguage&apos;, let us clarify from the start that for our purposes a sublanguage is an identifiable genre or text-type in a given subject field, with a relatively or even absolutely closed set of syntactic structures and vocabulary. In recent years, the availability of large corpora and &apos;new&apos; methods to process them have led to renewed interest in the question of sublanguage identification (e.g. Sekine 1997), while Karlgren & Cutting (1994) and Kessler et al. (1997) have focussed on the narrower but clearly related questio.n of genre. Our purpose in this paper is to explore a technique for identifying whether a set of texts &apos;belong to&apos; the II Somers il II 131 Use Weighted Cusums to Identify Sublanguages Harold Somers (1998) An Attempt to Use Weighted Cusums to Identify Sublanguages. In D.M.W. Powers (ed.) NeMLaP3/CoNLL 98: New Methods in Language Processing and Computational Natural Language Learning, ACL, pp 131-139. II same sublanguage, and of quantifying the difference between texts: our technique compares texts palrwise and"
W98-1216,P97-1005,0,0.211926,"(which Biber uses); an affinity with work on genre detection will also be apparent. Because there is sometimes some dispute about the use of the term &apos;sublanguage&apos;, let us clarify from the start that for our purposes a sublanguage is an identifiable genre or text-type in a given subject field, with a relatively or even absolutely closed set of syntactic structures and vocabulary. In recent years, the availability of large corpora and &apos;new&apos; methods to process them have led to renewed interest in the question of sublanguage identification (e.g. Sekine 1997), while Karlgren & Cutting (1994) and Kessler et al. (1997) have focussed on the narrower but clearly related questio.n of genre. Our purpose in this paper is to explore a technique for identifying whether a set of texts &apos;belong to&apos; the II Somers il II 131 Use Weighted Cusums to Identify Sublanguages Harold Somers (1998) An Attempt to Use Weighted Cusums to Identify Sublanguages. In D.M.W. Powers (ed.) NeMLaP3/CoNLL 98: New Methods in Language Processing and Computational Natural Language Learning, ACL, pp 131-139. II same sublanguage, and of quantifying the difference between texts: our technique compares texts palrwise and delivers a &apos;score&apos; which c"
Y10-1041,2007.mtsummit-papers.19,0,0.527693,"single analogical equation which otherwise had only one solution in ALEPH, and is accordingly much slower. While Lepage and colleagues have had ∗ The research is supported by the Science Foundation Ireland (Grant 07/CE/I1142) as part of the Centre for Next Generation Localization (http://www.cngl.ie) at Dublin City University. Copyright 2010 by Sandipan Dandapat, Sara Morrissey, Sudip Kumar Naskar, and Harold Somers 365 366 Poster Papers modest success using PA for a full translation task, the idea is adapted to translating unknown words in the context of another approach to MT as reported by Denoual (2007), Langlais and Patry (2007), and Langlais et al. (2009). Denoual’s (2007) experiments attempt to translate all unknown words in a Japanese–English task and have reported that translation adequacy (NIST score) improves but fluency (BLEU score) remains stable or is decreased. Langlais and Patry (2007) had more success in handling unknown words while the language pairs are quite close in morphological structure. Langlais and Yvon (2008) use PA to supplement the words and phrases for standard SMT when a word to be translated is not covered by the statistical model. Finally, Langlais et al. (2009)"
Y10-1041,P08-1045,0,0.0732534,"Missing"
Y10-1041,D07-1092,0,0.659524,"1 Introduction In the EBMT workshop in Phuket, Thailand, Lepage and Denoual (2005a) presented “The ‘purest’ EBMT system ever built: no variable, no templates, no training, examples, just examples, only examples”. This purely data-driven approach to MT uses the notion of proportional analogy (PA, described below), a type of analogical learning, the very simplicity of which is its attraction. We have attempted to reimplement the method in order to verify the previous authors’ claims. It has been noted, that the PA-based system works well in the case of shorter sentences with similar structure (Langlais and Patry, 2007). Thus we have taken named entity (NE) transliteration as a case study because NEs are typically short. Furthermore, it was reported (Hermjakob et. al, 2008) that the state-of-the-art SMT system can’t handle NEs that are not found in the training parallel text. In this paper we describe an experiment in which we use the method to handle unknown named entities (NEs) in an English-Hindi transliteration task. The idea introduced in Lepage and Denoual (2005a) is explained in considerably more detail in Lepage and Denoual (2005b, c). ALEPH system is an implementation of the research described in th"
Y10-1041,C08-2013,0,0.537519,"Poster Papers modest success using PA for a full translation task, the idea is adapted to translating unknown words in the context of another approach to MT as reported by Denoual (2007), Langlais and Patry (2007), and Langlais et al. (2009). Denoual’s (2007) experiments attempt to translate all unknown words in a Japanese–English task and have reported that translation adequacy (NIST score) improves but fluency (BLEU score) remains stable or is decreased. Langlais and Patry (2007) had more success in handling unknown words while the language pairs are quite close in morphological structure. Langlais and Yvon (2008) use PA to supplement the words and phrases for standard SMT when a word to be translated is not covered by the statistical model. Finally, Langlais et al. (2009) applied the method to the translation of medical terms and showed little improvement on purely statistical approaches. Since no off-the-shelf implementation is available for solving analogies, we have implemented our own EBMT system from scratch using PA based on the description in Lepage (2005c). It is often the case that a PAbased system suffers from low recall. First we try to improve the PA-based system by introducing new heurist"
Y10-1041,E09-1056,0,0.669284,"only one solution in ALEPH, and is accordingly much slower. While Lepage and colleagues have had ∗ The research is supported by the Science Foundation Ireland (Grant 07/CE/I1142) as part of the Centre for Next Generation Localization (http://www.cngl.ie) at Dublin City University. Copyright 2010 by Sandipan Dandapat, Sara Morrissey, Sudip Kumar Naskar, and Harold Somers 365 366 Poster Papers modest success using PA for a full translation task, the idea is adapted to translating unknown words in the context of another approach to MT as reported by Denoual (2007), Langlais and Patry (2007), and Langlais et al. (2009). Denoual’s (2007) experiments attempt to translate all unknown words in a Japanese–English task and have reported that translation adequacy (NIST score) improves but fluency (BLEU score) remains stable or is decreased. Langlais and Patry (2007) had more success in handling unknown words while the language pairs are quite close in morphological structure. Langlais and Yvon (2008) use PA to supplement the words and phrases for standard SMT when a word to be translated is not covered by the statistical model. Finally, Langlais et al. (2009) applied the method to the translation of medical terms"
Y10-1041,P98-1120,0,0.867743,"logy PAs are global relationships between four objects - A : B :: C : D , read as “A is to B as C is to D”. The symbol ‘::’ is sometimes replaced with an equals sign (=) to denote an equation. This formulation as an equation can have zero, one, or more solutions if any of the objects (usually D) is considered as a variable. PAs are often seen as a way of knowledge representation in Artificial Intelligence due to their power to represent world knowledge and the lexical relation encoded in them. In NLP, the analogies are used as an instrument to explain inflectional and derivational morphology (Lepage, 1998). 2.2 EBMT using Analogy Lepage and Denoual (2005a,b,c) showed how an EBMT system can be built based on the algorithm proposed by Lepage (1998). Treating a sentence as a string of characters, they note that PAs can be handled as in (1). (1) They swam in the sea : They swam across the river :: It floated in the sea : It floated across the river To build up an EBMT system, we must assume a database of example pairs, where each pair is a source and target language translation equivalent. For the first three sentences in (1), the translation equivalents in Spanish are given in (2). (2) a. Nadarón"
Y10-1041,C04-1106,0,0.0684331,"Missing"
Y10-1041,2005.mtsummit-ebmt.11,0,0.870088,"for tackling English–Hindi Named Entity (NE) Transliteration. We have implemented our own EBMT system using proportional analogy and have found that the analogy-based system on its own has low precision but a high recall due to the fact that a large number of names are untransliterated with the approach. However, mitigating problems in analogy-based EBMT with SMT and vice-versa have shown considerable improvement over the individual approach. Keywords: Example Based Machine Translation, Proportional Analogy, Named Entity Transliteration 1 Introduction In the EBMT workshop in Phuket, Thailand, Lepage and Denoual (2005a) presented “The ‘purest’ EBMT system ever built: no variable, no templates, no training, examples, just examples, only examples”. This purely data-driven approach to MT uses the notion of proportional analogy (PA, described below), a type of analogical learning, the very simplicity of which is its attraction. We have attempted to reimplement the method in order to verify the previous authors’ claims. It has been noted, that the PA-based system works well in the case of shorter sentences with similar structure (Langlais and Patry, 2007). Thus we have taken named entity (NE) transliteration as"
Y10-1041,2005.iwslt-1.4,0,0.228595,"for tackling English–Hindi Named Entity (NE) Transliteration. We have implemented our own EBMT system using proportional analogy and have found that the analogy-based system on its own has low precision but a high recall due to the fact that a large number of names are untransliterated with the approach. However, mitigating problems in analogy-based EBMT with SMT and vice-versa have shown considerable improvement over the individual approach. Keywords: Example Based Machine Translation, Proportional Analogy, Named Entity Transliteration 1 Introduction In the EBMT workshop in Phuket, Thailand, Lepage and Denoual (2005a) presented “The ‘purest’ EBMT system ever built: no variable, no templates, no training, examples, just examples, only examples”. This purely data-driven approach to MT uses the notion of proportional analogy (PA, described below), a type of analogical learning, the very simplicity of which is its attraction. We have attempted to reimplement the method in order to verify the previous authors’ claims. It has been noted, that the PA-based system works well in the case of shorter sentences with similar structure (Langlais and Patry, 2007). Thus we have taken named entity (NE) transliteration as"
Y10-1041,2007.iwslt-1.7,0,0.0662448,"nsliteration task. The idea introduced in Lepage and Denoual (2005a) is explained in considerably more detail in Lepage and Denoual (2005b, c). ALEPH system is an implementation of the research described in their three 2005 papers, and was tested on a corpus of 160K English, Japanese and Chinese sentences, from the C-STAR project’s BTEC, a travel and tourism domain corpus. The system did very well on data from the IWSLT 2004 competition, coming a close second to the competition winner on all measures. The ALEPH system evolved into a new system, named GREYC, with some modification described in Lepage and Lardilleux (2007). The GREYC system also incorporated new heuristics and had an additional refinement of non-determinism to generate all possible solutions for a single analogical equation which otherwise had only one solution in ALEPH, and is accordingly much slower. While Lepage and colleagues have had ∗ The research is supported by the Science Foundation Ireland (Grant 07/CE/I1142) as part of the Centre for Next Generation Localization (http://www.cngl.ie) at Dublin City University. Copyright 2010 by Sandipan Dandapat, Sara Morrissey, Sudip Kumar Naskar, and Harold Somers 365 366 Poster Papers modest succes"
Y10-1041,2006.iwslt-evaluation.4,0,0.0168074,"s expected to work best with our current experimental setup. 4 Experiments We have tested our EBMT system using PA for a NE transliteration task from English to Hindi. Five different experiments were conducted based on our EBMT system using PA. We shall call PACLIC 24 Proceedings 369 these analogy-based EBMT (AEBMT).The five experiments deal with the five different heuristics described in 3.1. Each of these five experiments was also tested with a time bound of one second and three seconds to understand the effect of time while using analogy-based system. In parallel, we have also used MaTrEx (Stroppa and Way, 2006), an open source statistical MT (SMT) system in order to estimate the relative performance of the models. Furthermore, the SMT system can be trained at character-, syllable- and word-level using appropriate examplebases. We have found that there are cases where AEBMT correctly produces the transliteration but SMT fails and vice versa. In order to further improve the transliteration accuracy, we use a combination of AEBMT with SMT. We combine these two systems in two ways. We assume that the transliteration of a word w produced by AEBMT and SMT are respectively TAEBMT(w) and TSMT(w). First, we"
Y10-1041,C98-1116,0,\N,Missing
Y10-1041,W09-3502,0,\N,Missing
Y98-1019,C92-1019,0,0.0372495,"+ d)(c + d) Dunning (1993) notes that MI is subject to overestimation when the counts are small and thus proposes using log likelihood ratio G2 as a significance test for estimating surprise and coincidence of a rare event. G 2 is computed by the formula in (6). (6). G2 = a log a + b log b + c log c + d log d • (a+b)log(a+b) — (a+c)log(a+c) — (b+d)log(b+d) — (c+d)log(c+d) + (a+b+c+d)log(a+b+c+d) We conducted experiments testing all the statistical measures described above with a Chinese text of 5155 words. The Chinese text was preprocessed by the Chinese word segmentation program reported in Chen and Liu (1992). The results of the tests are shown in Table 1. Bigrams with a t-score lower than 1.65 have been left out. As can be seen in Table 1, the performance of MI and t-score is not satisfactory, for many uninteresting bigrams containing pronouns and determiners are incorrectly extracted. It is obvious in Table 1 that (1: 12 and G2 outperform MI and t-score. Nevertheless, (112 gives a zero value for word pairs which always co-occur with each other, since b + d in (6) is zero if word pairs always co-occur. Therefore, bigrams consisting of proper nouns such as .1. I `Hsiao Hung&apos;, Ni le &apos;Ho Te&apos;, &apos;Te Fe"
Y98-1019,J90-1003,0,0.0301191,"proposed to identify significant lexical relations. These measures, however, are designed to work with large corpora with millions of words. Accordingly, they do not perform well in relatively small texts with a few thousand words. This paper presents a statistical method that is well-suited to extracting recurrent phrases and terms from relatively small texts. The method, a variant of Fung and Church&apos;s (1994) K-vec algorithm, is shown to be in line with linguistic generalisations about lexical cohesion in text structures. 2. Statistical Measures for Identifying Interesting Lexical Relations Church and Hanks (1990) and Church et al. (1991) use mutual information (MI) to estimate associations between two words. Mutual information is defined as follows. (1) 1(x, y) = log2 P(x, y) P(x)P(y) MI compares the joint probability P(x, y) (i.e. the probability of the co-occurrence of x and y) with P(x) and P(y), the independent probabilities of x and y (chance). If there is a strong association between word x and word y, then the joint probability P(x, y) will be much larger than chance P(x)P(y), and accordingly 1(x, y) > 0. If no significant relation holds between x and y, 1(x, y) will approximate to zero. If x i"
Y98-1019,J93-1003,0,0.0242677,"sed. These methods require the contingency table in (3). (3). a=k(AB) c = k(A —B) b=k(--AB) d k(—A —B) where A and B are the words in question, and k is the count of the bigrams. The — sign means not; so for example c is the count of the bigram where A is followed by a word other than B. One of the alternatives to MI is the association measure IM, which is very similar to MI. IM is calculated as in (4) (cf. Daille (1996)). (4). IM = log2 a (a + b)(a + c) In addition, Gale and Church (1991) introduce the 0.2 coefficient using the formula in (5). (5). 2 = (axd—bxc)2 (a + b)(a + c)(b + d)(c + d) Dunning (1993) notes that MI is subject to overestimation when the counts are small and thus proposes using log likelihood ratio G2 as a significance test for estimating surprise and coincidence of a rare event. G 2 is computed by the formula in (6). (6). G2 = a log a + b log b + c log c + d log d • (a+b)log(a+b) — (a+c)log(a+c) — (b+d)log(b+d) — (c+d)log(c+d) + (a+b+c+d)log(a+b+c+d) We conducted experiments testing all the statistical measures described above with a Chinese text of 5155 words. The Chinese text was preprocessed by the Chinese word segmentation program reported in Chen and Liu (1992). The re"
Y98-1019,C94-2178,0,0.0786307,"ne function word. For instance, G 2 gives a larger value to — 13.7. yi wei &apos;one CLASSIFIER&apos; than the more interesting proper names /j I lisiao Hung&apos; and g . 0E7 `Lu Anni&apos;. IM seems to outperform all the other statistical measures in small texts. By setting the threshold to —3, all the proper names together with some interesting terms such as tat `feminism&apos;, tt &apos;equal right&apos;, fiec AA &apos;administrative staffcan be extracted. However, IM has a serious defect: its threshold value is difficult to determine. 3. Modifying Fung and Church&apos;s (1994) K-vec Algorithm to Extract Recurrent Monolingual Terms Fung and Church (1994) propose a simple algorithm to find word correspondences from unaligned parallel texts. The basic idea is that a true word pair should have similar distributions in terms of the position of its occurrence in the text. To estimate the similarity of co-occurrence, the parallel texts are split into the same number of segments (K) and the distributions of each word are represented in a 1...K binary vector. For instance, suppose the Chinese and English texts are divided into ten segments. Suppose further that the Chinese word tig4t. daxue occurs ten times, with the first 3 occurrences in the fourth"
Y98-1019,J93-1007,0,0.152509,"Missing"
