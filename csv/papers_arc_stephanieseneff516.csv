W15-3814,Using word embedding for bio-event extraction,2015,8,18,5,0,9098,chen li,Proceedings of {B}io{NLP} 15,0,"Bio-event extraction is an important phase towards the goal of extracting biological networks from the scientific literature. Recent advances in word embedding make computation of word distribution more ef- ficient and possible. In this study, we investigate methods bringing distributional characteristics of words in the text into event extraction by using the latest word embedding methods. By using bag-ofwords (BOW) features as the baseline, the result has been improved by the introduction of word-embedding features, and is comparable to the state-of-the-art solution."
W10-4316,Utilizing Review Summarization in a Spoken Recommendation System,2010,9,4,2,1,3323,jingjing liu,Proceedings of the {SIGDIAL} 2010 Conference,0,"In this paper we present a framework for spoken recommendation systems. To provide reliable recommendations to users, we incorporate a review summarization technique which extracts informative opinion summaries from grass-roots users' reviews. The dialogue system then utilizes these review summaries to support both quality-based opinion inquiry and feature-specific entity search. We propose a probabilistic language generation approach to automatically creating recommendations in spoken natural language from the text-based opinion summaries. A user study in the restaurant domain shows that the proposed approaches can effectively generate reliable and helpful recommendations in human-computer conversations."
W10-4317,Dialogue Management Based on Entities and Constraints,2010,11,13,2,1,45081,yushi xu,Proceedings of the {SIGDIAL} 2010 Conference,0,"This paper introduces a new dialogue management framework for goal-directed conversations. A declarative specification defines the domain-specific elements and guides the dialogue manager, which communicates with the knowledge sources to complete the specified goal. The user is viewed as another knowledge source. The dialogue manager finds the next action by a mixture of rule-based reasoning and a simple statistical model. Implementation in the flight-reservation domain demonstrates that the framework enables the developer to easily build a conversational dialogue system."
N10-1008,Dialogue-Oriented Review Summary Generation for Spoken Dialogue Recommendation Systems,2010,25,17,2,1,3323,jingjing liu,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"In this paper we present an opinion summarization technique in spoken dialogue systems. Opinion mining has been well studied for years, but very few have considered its application in spoken dialogue systems. Review summarization, when applied to real dialogue systems, is much more complicated than pure text-based summarization. We conduct a systematic study on dialogue-system-oriented review analysis and propose a three-level framework for a recommendation dialogue system. In previous work we have explored a linguistic parsing approach to phrase extraction from reviews. In this paper we will describe an approach using statistical models such as decision trees and SVMs to select the most representative phrases from the extracted phrase set. We will also explain how to generate informative yet concise review summaries for dialogue purposes. Experimental results in the restaurant domain show that the proposed approach using decision tree algorithms achieves an outperformance of 13% compared to SVM models and an improvement of 36% over a heuristic rule baseline. Experiments also show that the decision-tree-based phrase selection model can achieve rather reliable predictions on the phrase label, comparable to human judgment. The proposed statistical approach is based on domain-independent learning features and can be extended to other domains effectively."
mcgraw-etal-2010-collecting,Collecting Voices from the Cloud,2010,22,56,4,0,46312,ian mcgraw,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The collection and transcription of speech data is typically an expensive and time-consuming task. Voice over IP and cloud computing are poised to greatly reduce this impediment to research on spoken language interfaces in many domains. This paper documents our efforts to deploy speech-enabled web interfaces to large audiences over the Internet via Amazon Mechanical Turk, an online marketplace for work. Using the open source WAMI Toolkit, we collected corpora in two different domains which collectively constitute over 113 hours of speech. The first corpus contains 100,000 utterances of read speech, and was collected by asking workers to record street addresses in the United States. For the second task, we collected conversations with FlightBrowser, a multimodal spoken dialogue system. The FlightBrowser corpus obtained contains 10,651 utterances composing 1,113 individual dialogue sessions from 101 distinct users. The aggregate time spent collecting the data for both corpora was just under two weeks. At times, our servers were logging audio from workers at rates faster than real-time. We describe the process of collection and transcription of these corpora while providing an analysis of the advantages and limitations to this data collection method."
O09-4001,"Speech-Based Interactive Games for Language Learning: Reading, Translation, and Question-Answering",2009,49,106,2,1,45081,yushi xu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 14, Number 2, June 2009-Special Issue on Computer Assisted Language Learning",0,"This paper concerns a framework for building interactive speech-based language learning games. The core of the framework, the dialogue manager, controls the game procedure via a control script. The control script allows the developers to have easy access to the natural language process capabilities provided by six core building blocks. Using the framework, three games for Mandarin learning were implemented: a reading game, a translation game, and a question-answering game. We verified the effectiveness and usefulness of the framework by evaluating the three games. In the in-lab and public evaluation phases, we collected a total of 4025 utterances from 31 subjects. The evaluation showed that the game systems responded to the users' utterances appropriately about 89% of the time, and assessment of the users' performances correlated well with their human-judged proficiency."
D09-1017,Review Sentiment Scoring via a Parse-and-Paraphrase Paradigm,2009,23,77,2,1,3323,jingjing liu,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a parse-and-paraphrase paradigm to assess the degrees of sentiment for product reviews. Sentiment identification has been well studied; however, most previous work provides binary polarities only (positive and negative), and the polarity of sentiment is simply reversed when a negation is detected. The extraction of lexical features such as unigram/bigram also complicates the sentiment classification task, as linguistic structure such as implicit long-distance dependency is often disregarded. In this paper, we propose an approach to extracting adverb-adjective-noun phrases based on clause structure obtained by parsing sentences into a hierarchical representation. We also propose a robust general solution for modeling the contribution of adverbials and negation to the score for degree of sentiment. In an application involving extracting aspect-based pros and cons from restaurant reviews, we obtained a 45% relative improvement in recall through the use of parsing methods, while also improving precision."
W08-0801,A Multimodal Home Entertainment Interface via a Mobile Device,2008,28,10,4,0.9965,47779,alexander gruenstein,Proceedings of the {ACL}-08: {HLT} Workshop on Mobile Language Processing,0,"We describe a multimodal dialogue system for interacting with a home entertainment center via a mobile device. In our working prototype, users may utilize both a graphical and speech user interface to search TV listings, record and play television programs, and listen to music. The developed framework is quite generic, potentially supporting a wide variety of applications, as we demonstrate by integrating a weather forecast application. In the prototype, the mobile device serves as the locus of interaction, providing both a small touchscreen display, and speech input and output; while the TV screen features a larger, richer GUI. The system architecture is agnostic to the location of the natural language processing components: a consistent user experience is maintained regardless of whether they run on a remote server or on the device itself."
P08-1021,Correcting Misuse of Verb Forms,2008,11,48,2,0,2821,john lee,Proceedings of ACL-08: HLT,1,"This paper proposes a method to correct English verb form errors made by non-native speakers. A basic approach is template matching on parse trees. The proposed method improves on this approach in two ways. To improve recall, irregularities in parse trees caused by verb form errors are taken into account; to improve precision, n-gram counts are utilized to filter proposed corrections. Evaluation on non-native corpora, representing two genres and mother tongues, shows promising results."
2008.amta-papers.21,Two-Stage Translation: A Combined Linguistic and Statistical Machine Translation Framework,2008,19,9,2,1,45081,yushi xu,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"We propose a two-stage system for spoken language machine translation. In the first stage, the source sentence is parsed and paraphrased into an intermediate language which retains the words in the source language but follows the word order of the target language as much as feasible. This stage is mostly linguistic. In the second stage, a statistical MT is performed to translate the intermediate language into the target language. For the task of English-to-Mandarin translation, we achieved a 2.5 increase in BLEU score and a 45{\%} decrease in GIZA-Alignment Crossover, on IWSLT-06 data. In a human evaluation of the sentences that differed, the two-stage system was preferred three times as often as the baseline."
N07-4007,Spoken Dialogue Systems for Language Learning,2007,6,12,1,1,36748,stephanie seneff,Proceedings of Human Language Technologies: The Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics ({NAACL}-{HLT}),0,"This demonstration will illustrate interactive computer games intended to help a native speaker of English learn Mandarin. These systems provide users with humanlike conversational exercises with contextualized help mechanisms. Two distinctly different activities, a translation game and a dialogue game are illustrated. The level of difficulty can be manipulated, and the sentence variations covered by the systems familiarize users with different expressions of the same meaning. The systems preserve the qualities of a typical computer system, being infinitely patient and available any time of day. Students will be able to repeatedly practice conversation with no embarrassment."
N07-2039,Reversible Sound-to-Letter/Letter-to-Sound Modeling Based on Syllable Structure,2007,8,11,1,1,36748,stephanie seneff,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,"This paper describes a new grapheme-to-phoneme framework, based on a combination of formal linguistic and statistical methods. A context-free grammar is used to parse words into their underlying syllable structure, and a set of sub-word spellneme units encoding both phonemic and graphemic information can be automatically derived from the parsed words. A statistical n-gram model can then be trained on a large lexicon of words represented in terms of these linguistically motivated subword units. The framework has potential applications in modeling unknown words and in linking spoken spellings with spoken pronunciations for fully automatic new-word acquisition via dialogue interaction. Results are reported on sound-to-letter experiments for the nouns in the Phonebook corpus."
N07-1059,Automatic Assessment of Student Translations for Foreign Language Tutoring,2007,16,37,2,0,4722,chao wang,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"This paper introduces the use of speech translation technology for a new type of voice-interactive Computer Aided Language Learning (CALL) application. We describe a computer game we have developed, in which the system presents sentences in a studentxe2x80x99s native language to elicit spoken translations in the target new language. A critical technology is an algorithm to automatically verify the appropriateness of the studentxe2x80x99s translation using linguistic analysis. Evaluation results are presented on the systemxe2x80x99s ability to match human judgment of the correctness of a studentxe2x80x99s translation, for a set of 1115 utterances collected from 9 learners of Mandarin Chinese translating flight domain sentences. We also demonstrate the effective use of context information to improve both recognition performance on non-native speech as well as the systemxe2x80x99s accuracy in judging the translation quality."
2007.sigdial-1.21,Releasing a Multimodal Dialogue System into the Wild: User Support Mechanisms,2007,12,25,2,0.9965,47779,alexander gruenstein,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"We present City Browser, a web-based platform which provides multimodal access to urban information. We concentrate on aspects of the system that make it compelling for sustained interaction, yet accessible to new users. First, we discuss the architecturexe2x80x99s portability, demonstrating how new databases containing Points of Interest (POIs) may easily be added. We then describe two interface techniques which mitigate the complexity of interacting with these potentially large databases: (1) contextsensitive utterance suggestions and (2) multimodal correction of speech recognition hypotheses. Finally, we evaluate the platform with data collected from users via the web."
2006.amta-papers.24,Combining Linguistic and Statistical Methods for Bi-directional {E}nglish {C}hinese Translation in the Flight Domain,2006,15,12,1,1,36748,stephanie seneff,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"In this paper, we discuss techniques to combine an interlingua translation framework with phrase-based statistical methods, for translation from Chinese into English. Our goal is to achieve high-quality translation, suitable for use in language tutoring applications. We explore these ideas in the context of a flight domain, for which we have a large corpus of English queries, obtained from users interacting with a dialogue system. Our techniques exploit a pre-existing English-to-Chinese translation system to automatically produce a synthetic bilingual corpus. Several experiments were conducted combining linguistic and statistical methods, and manual evaluation was conducted for a set of 460 Chinese sentences. The best performance achieved an {``}adequate{''} or better analysis (3 or above rating) on nearly 94{\%} of the 409 parsable subset. Using a Rover scheme to combine four systems resulted in an {``}adequate or better{''} rating for 88{\%} of all the utterances."
2006.amta-panels.4,Combining interlingua with {SMT},2006,-1,-1,1,1,36748,stephanie seneff,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Panel on hybrid machine translation: why and how?,0,None
2006.amta-panels.4,{MT} for social impact,2006,-1,-1,1,1,36748,stephanie seneff,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Panel on machine translation for social impact,0,None
2005.sigdial-1.7,Automatic Induction of Language Model Data for A Spoken Dialogue System,2005,-1,-1,2,1,47426,grace chung,Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue,0,None
2005.sigdial-1.15,Developing City Name Acquisition Strategies in Spoken Dialogue Systems Via User Simulation,2005,-1,-1,2,0,51151,ed filisko,Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue,0,None
W04-3006,Error Detection and Recovery in Spoken Dialogue Systems,2004,-1,-1,2,0,51356,edward filisko,Proceedings of the {HLT}-{NAACL} 2004 Workshop on Spoken Language Understanding for Conversational Systems and Higher Level Linguistic Information for Speech Processing,0,None
W03-0707,Flexible and Personalizable Mixed-Initiative Dialogue Systems,2003,12,15,2,1,51,james glass,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Research Directions in Dialogue Processing,0,"This paper describes our vision for a future time when end users of mixed-initiative spoken dialogue systems will be able to dynamically configure the system to suit their personalized goals. We argue that spoken dialogue systems will only become a common utility in society once they can be reconfigured, essentially instantaneously, to support a new working vocabulary within a new domain or subdomain. For example, if a user is interested in restaurants in Seattle, the system would go off-line to gather information from resources such as the Web, and would infer from that knowledge an appropriate working vocabulary, language models, and dialogue control mechanism for a subsequent spoken conversation on this topic. In addition to painting this vision, the paper also discusses our recent research efforts directed towards the technology development necessary to realize this larger goal."
N03-1005,Automatic Acquisition of Names Using Speak and Spell Mode in Spoken Dialogue Systems,2003,17,33,2,1,47426,grace chung,Proceedings of the 2003 Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper describes a novel multi-stage recognition procedure for deducing the spelling and pronunciation of an open set of names. The overall goal is the automatic acquisition of unknown words in a human computer conversational system. The names are spoken and spelled in a single utterance, achieving a concise and natural dialogue flow. The first recognition pass extracts letter hypotheses from the spelled part of the waveform and maps them to phonemic hypotheses via a hierarchical sublexical model capable of generating graphemephoneme mappings. A second recognition pass determines the name by combining information from the spoken and spelled part of the waveform, augmented with language model constraints. The procedure is integrated into a spoken dialogue system where users are asked to enroll their names for the first time. The acquisition process is implemented in multiple parallel threads for real-time operation. Subsequent to inducing the spelling and pronunciation of a new name, a series of operations automatically updates the recognition and natural language systems to immediately accommodate the new word. Experiments show promising results for letter and phoneme accuracies on a preliminary dataset."
H01-1032,Hypothesis Selection and Resolution in the Mercury Flight Reservation System,2001,10,3,1,1,36748,stephanie seneff,Proceedings of the First International Conference on Human Language Technology Research,0,"In a spoken dialogue system, the degree to which the dialogue manager informs and controls the behavior of other human language technology components is an important research topic. Although each separate server can be developed and trained on its own, it must function as part of an entire system, and do so in the context of a complex dialogue with a human user. The dialogue manager is the one component that has not only local information from each server, but also global knowledge about the task and specific knowledge about a particular user's constraints. In this paper, we describe various algorithms we have developed for exploiting the knowledge of the dialogue manager in the selection of recognition hypotheses in the context of human-machine interactions. We describe enhancements we have made to other human language technology servers for the purpose of providing useful information to the dialogue manager, as well as new capabilities in the dialogue manager itself aimed at detecting and repairing problematic spots in the dialogue. We conclude by describing some evaluation metrics and tools we have developed for monitoring system performance."
H01-1041,Interlingua-Based Broad-Coverage {K}orean-to-{E}nglish Translation in {CCLINC},2001,15,7,3,1,8302,youngsuk lee,Proceedings of the First International Conference on Human Language Technology Research,0,"At MIT Lincoln Laboratory, we have been developing a Korean-to-English machine translation system CCLINC (Common Coalition Language System at Lincoln Laboratory). The CCLINC Korean-to-English translation system consists of two core modules, language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame. The key features of the system include: (i) Robust efficient parsing of Korean (a verb final language with over case markers, relatively free word order, and frequent omissions of arguments). (ii) High quality translation via word sense disambiguation and accurate word order generation of the target language. (iii) Rapid system development and porting to new domains via knowledge-based automated acquisition of grammars. Having been trained on Korean newspaper articles on missiles and chemical biological warfare, the system produces the translation output sufficient for content understanding of the original document."
W00-0303,Dialogue Management in the Mercury Flight Reservation System,2000,-1,-1,1,1,36748,stephanie seneff,ANLP-NAACL 2000 Workshop: Conversational Systems,0,None
polifroni-seneff-2000-galaxy,Galaxy-{II} as an Architecture for Spoken Dialogue Evaluation,2000,8,35,2,1,45985,joseph polifroni,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"The GALAXY-II architecture, comprised of a centralized hub mediating the interaction among a suite of human language technology servers, provides both a useful tool for implementing systems and also a streamlined way of configuring the evaluation of these systems. In this paper, we discuss our ongoing efforts in evaluation of spoken dialogue systems, with particular attention to the way in which the architecture facilitates the development of a variety of evaluation configurations. We furthermore propose two new metrics for automatic evaluation of the discourse and dialogue components of a spoken dialogue system, which we call xe2x80x9cuser frustrationxe2x80x9d and xe2x80x9cinformation bit"
P97-1016,Ambiguity Resolution for Machine Translation of Telegraphic Messages,1997,7,8,3,1,8302,youngsuk lee,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,"Telegraphic messages with numerous instances of omission pose a new challenge to parsing in that a sentence with omission causes a higher degree of ambiguity than a sentence without omission. Misparsing induced by omissions has a far-reaching consequence in machine translation. Namely, a misparse of the input often leads to a translation into the target language which has incoherent meaning in the given context. This is more frequently the case if the structures of the source and target languages are quite different, as in English and Korean. Thus, the question of how we parse telegraphic messages accurately and efficiently becomes a critical issue in machine translation. In this paper we describe a technical solution for the issue, and present the performance evaluation of a machine translation system on telegraphic messages before and after adopting the proposed solution. The solution lies in a grammar design in which lexicalized grammar rules defined in terms of semantic categories and syntactic rules defined in terms of part-of-speech are utilized together. The proposed grammar achieves a higher parsing coverage without increasing the amount of ambiguity/misparsing when compared with a purely lexicalized semantic grammar, and achieves a lower degree of ambiguity/misparses without decreasing the parsing coverage when compared with a purely syntactic grammar."
1997.mtsummit-workshop.9,Simplification of nomenclature leads to an ideal {IL} for human language communication,1997,6,0,5,1,8302,youngsuk lee,AMTA/SIG-IL First Workshop on Interlinguas,0,"In this talk, we advocate the view that simplification of nomenclature, stated in linguistically well-motivated concepts, leads to an ideal IL for human language communication systems including multi-lingual machine translation and spoken language dialogue systems. To advocate this view, we describe our method of constructing IL representations in developing our multilingual machine translation system, CCLINC (cf. Tummala et al. 1995, Weinstein et al. 1996, Lee et al. 1997), and give a demonstration of two-way English/Korean translation by CCLINC. At MIT Lincoln Laboratory, we have been developing a multi-lingual machine translation system, called CCLINC. The core of CCLINC consists of the language understanding system (TINA, cf. Seneff 1992) and the language generation system (GENESIS, cf. Glass et al. 1994). The system has been applied to English-to-French, English-to-Korean and Korean-to-English translations. In designing an IL representation, we have been following two developmental strategies: First, simplification of nomenclature. Second, preservation of the predicate/argument structure of the input sentence. These strategies are largely drawn from the experience of applying the language understanding/generation system to spoken language dialogue systems (cf. Zue et al 1996). Simplification of nomenclature provides a very general IL which can be used in various application areas including information access from a database, language tutoring, and conversational systems. Preservation of predicate/argument structure facilitates generation of multiple output languages, which are accurately ordered in each target language. The intermediate meaning representation, which we call a semantic frame, is derived from the parse tree of the input sentence. All major parse tree constituents (regardless of whether they are semantic or syntactic) are reduced into one of three major categories in the semantic frame, namely, clause, topic and predicate. All noun phrase expressions are mapped onto xe2x80x9ctopic.xe2x80x9d All adjectives, prepositional phrases, and verb phrases, are mapped onto xe2x80x9cpredicate.xe2x80x9d The frame hierarchy structure encodes dependencies among clauses, topics, and predicates. Thus the predicate/argument structure of the input sentence is preserved. Information regarding the sentence type such as declarative, and imperative, is encoded at the xe2x80x98clausexe2x80x99 level. The ontology of each category in the semantic frame is described in English for reasons of convenience, and the formalism has been incrementally enriched as we develop experience from working with diverse language classes."
C96-2119,Automatic {E}nglish-to-{K}orean Text Translation of Telegraphic Messages in a Limited Domain,1996,9,5,4,0.716233,52246,clifford weinstein,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"This paper describes our work-in-progress in automatic English-to-Korean text translation. This work is an initial step toward the ultimate goal of text and speech translation for enhanced multilingual and multinational operations. For this purpose, we have adopted an interlingua approach with natural language understanding (TINA) and generation (GENESIS) modules at the core. We tackle the ambiguity problem by incorporating syntactic and semantic categories in the analysis grammar. Our system is capable of producing accurate translation of complex sentences (38 words) and sentence fragments as well as average length (12 words) grammatical sentences. Two types of system evaluation have been carried out: one for grammar coverage and the other for overall performance. For system robustness, integration of two subsystems is under way: (i) a rule-based part-of-speech tagger to handle unknown words/constructions, and (ii) a word-forword translator to handle other system failures."
H94-1037,{PEGASUS}: A Spoken Language Interface for On-Line Air Travel Planning,1994,12,27,2,0.711388,45080,victor zue,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"This paper describes PEGASUS, a spoken language interface for on-line air travel planning that we have recently developed. PEGASUS leverages off our spoken language technology development in the ATIS domain, and enables users to book flights using the American Airlines EAASY SABRE system. The input query is transformed by the speech understanding system to a frame representation that captures its meaning. The tasks of the System Manager include transforming the semantic representation into an EAASY SABRE command, transmitting it to the application backend, formatting and interpreting the resulting information, and managing the dialogue. Preliminary evaluation results suggest that users can learn to make productive use of PEGASUS for travel planning, although much work remains to be done."
H94-1055,Phonological Parsing for Bi-directional Letter-to-Sound/Sound-to-Letter Generation,1994,10,18,2,0,36519,helen meng,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"In this paper, we describe a reversible letter-to-sound/sound-to-letter generation system based on an approach which combines a rule-based formalism with data-driven techniques. We adopt a probabilistic parsing strategy to provide a hierarchical lexical analysis of a word, including information such as morphology, stress, syllabification, phonemics and graphemics. Long-distance constraints are propagated by enforcing local constraints throughout the hierarchy. Our training and testing corpora are derived from the high-frequency portion of the Brown Corpus (10,000 words), augmented with markers indicating stress and word morphology. We evaluated our performance based on an unseen test set. The percentage of nonparsable words for letter-to-sound and sound-to-letter generation were 6% and 5% respectively. Of the remaining words our system achieved a word accuracy of 71.8% and a phoneme accuracy of 92.5% for letter-to-sound generation, and a word accuracy of 55.8% and letter accuracy of 89.4% for sound-to-letter generation. We also compared our hierarchical approach with an alternative, single-layer approach to demonstrate how the hierarchy provides a parsimonious description for English orthographic-phonological regularities, while simultaneously attaining competitive generation accuracy."
J92-1004,{TINA}: A Natural Language System for Spoken Language Applications,1992,27,332,1,1,36748,stephanie seneff,Computational Linguistics,0,"A new natural language system, TINA, has been developed for applications involving spoken language tasks. TINA integrates key ideas from context free grammars, Augmented Transition Networks (ATN's), and the unification concept. TINA provides a seamless interface between syntactic and semantic analysis, and also produces a highly constraining probabilistic language model to improve recognition performance. An initial set of context-free rewrite rules provided by hand is first converted to a network structure. Probability assignments on all arcs in the network are obtained automatically from a set of example sentences. The parser uses a stack decoding search strategy, with a top-down control flow, and includes a feature-passing mechanism to deal with long-distance movement, agreement, and semantic constraints. TINA provides an automatic sentence generation capability that has been effective for identifying overgeneralization problems as well as in producing a word-pair language model for a recognizer. The parser is currently integrated with MIT's SUMMIT recognizer for use in two application domains, with the parser screening recognizer outputs either at the sentential level or to filter partial theories during the active search process."
H92-1005,Experiments in Evaluating Interactive Spoken Language Systems,1992,4,37,3,1,45985,joseph polifroni,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,"As the DARPA spoken language community moves towards developing useful systems for interactive problem solving, we must explore alternative evaluation procedures that measure whether these systems aid people in solving problems within the task domain. In this paper, we describe several experiments exploring new evaluation procedures. To look at end-to-end evaluation, we modified our data collection procedure slightly in order to experiment with several objective task completion measures. We found that the task completion time is well correlated with the number of queries used. We also explored log file evaluation, where evaluators were asked to judge the clarity of the query and the correctness of the response based on examination of the log file. Our results show that seven evaluators were unanimous on more than 80% of the queries, and that at least 6 out of 7 evaluators agreed over 90% of the time. Finally, we applied these new procedures to compare two systems, one system requiring a complete parse and the other using the more flexible robust parsing mechanism. We found that these metrics could distinguish between these systems: there were significant differences in ability to complete the task, number of queries required to complete the task, and score (as computed through a log file evaluation) between the robust and the non-robust modes."
H92-1016,The {MIT} {ATIS} System: {F}ebruary 1992 Progress Report,1992,9,16,8,0.705968,45080,victor zue,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,"This paper describes the status of the MIT ATIS system as of February 1992, focusing especially on the changes made to the SUMMIT recognizer. These include context-dependent phonetic modelling, the use of a bigram language model in conjunction with a probabilistic LR parser, and refinements made to the lexicon. Together with the use of a larger training set, these modifications combined to reduce the speech recognition word and sentence error rates by a factor of 2.5 and 1.6, respectively, on the October '91 test set. The weighted error for the entire spoken language system on the same test set is 49.3%. Similar results were also obtained on the February '92 benchmark evaluation."
H92-1060,A Relaxation Method for Understanding Speech Utterances,1992,12,32,1,1,36748,stephanie seneff,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,"This paper describes an extension to the MIT ATIS (Air Travel Information Service) system, which allows it to answer a question when a full linguistic analysis fails. This robust parsing capability was achieved through minor extensions of pre-existing components already in place for the full linguistic analysis component. Robust parsing is applied only after a full analysis has failed, and it involves the two stages of 1) parsing a set of phrases and clauses, and 2) gluing them together to obtain a single semantic frame encoding the full meaning of the sentence. We have assessed the degree of success of the robust parsing mechanism through a breakdown of the performance of robustly parsed vs. fully parsed sentences on the October '91 dry-run test set. It was clear that the robust parser allowed us to answer many more questions correctly, as over a third of the sentences were not covered by the grammar. We also report here on the performance of the system on the February '92 test sentences, and discuss some issues with regard to the evaluation methodology."
H91-1014,Development and Preliminary Evaluation of the {MIT} {ATIS} System,1991,8,17,1,1,36748,stephanie seneff,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,"This paper represents a status report on the MIT ATIS system. The most significant new achievement is that we now have a speech-input mode. It is based on the MIT SUMMIT system using context independent phone models, and includes a word-pair grammar with perplexity 92 (on the June-90 test set). In addition, we have completely redesigned the back-end component, in order to emphasize portability and extensibility. The parser now produces an intermediate semantic frame representation, which serves as the focal point for all back-end operations, such as history management, text generation, and SQL query generation. Most of those aspects of the system that are tied to a particular domain are now entered through a set of tables associated with a small artificial language for decoding them. We have also improved the display of the database table, making it considerably easier for a subject to comprehend the information given. We report here on the results of the official DARPA February-91 evaluation, as well as on results of an evaluation on data collected at MIT, for both speech input and text input."
H91-1070,Interactive Problem Solving and Dialogue in the {ATIS} Domain,1991,4,40,1,1,36748,stephanie seneff,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,"This paper describes the present status of the discourse and dialogue models within the MIT ATIS system, extended to support the notion of booking a flight. The discourse model includes not only the resolution of explicit anaphoric references, but also indirect and direct references to information mentioned earlier in the conversation, such as a direct reference to an entry in a previously displayed table or an indirect reference to a date, as in the following Thursday. The system keeps a history table containing objects such as flights and dates, represented as semantic frames, as well as the active ticket, previously booked tickets, and previously displayed tables. During flight reservations scenarios, the system monitors the state of the ticket (which is displayed to the user), making sure that all information is complete (by querying the user) before allowing a booking. It may even initiate calls to the database to provide additional unsolicited information as appropriate. We have collected several dialogues of subjects using the system to make reservations, and from these, we are learning how to design better dialogue models."
H91-1071,Collection of Spontaneous Speech for the {ATIS} Domain and Comparative Analyses of Data Collected at {MIT} and {TI},1991,8,13,2,1,45985,joseph polifroni,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,"As part of our development of a spoken language system in the ATIS domain, we have begun a small-scale effort in collecting spontaneous speech data. Our procedure differs from the one used at Texas Instruments (TI) in many respects, the most important being the reliance on an existing system, rather than a wizard, to participate in data collection. Over the past few months, we have collected over 3,600 spontaneously generated sentences from 100 subjects. This paper documents our data collection process, and makes some comparative analyses of our data with those collected at TI. The advantages as well as disadvantages of this method of data collection will be discussed."
H91-1072,Integrating Syntax and Semantics into Spoken Language Understanding,1991,11,2,2,0.284277,45475,lynette hirschman,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,"This paper describes several experiments combining natural language and acoustic constraints to improve overall performance of the MIT VOYAGER spoken language system. This system couples the SUMMIT speech recognition system with the TINA language understanding system to answer spoken queries about navigational assistance in the Cambridge, MA, area. The overall goal of our research is to combine acoustic, syntactic and semantic knowledge sources. Our first experiment showed improvement by combining acoustic score and parse probability normalized for number of terminals. Results were further improved by the use of an explicit rejection criterion based on normalized parse probabilities. The use of the combined parse/acoustic score, together with the rejection criterion, gave an improvement in overall score of more than 33% on both training and test data, where score is defined as percent correct minus percent incorrect. Experiments on a fully integrated system which uses the parser to predict possible next words to the recognizer are now underway."
H90-1028,Preliminary {ATIS} Development at {MIT},1990,5,8,7,0.5,45080,victor zue,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"DARPA has recently initiated a plan for a common spoken language task, to be developed independently by all members of the DARPA community, with the hope that it will provide a mechanism leading to appropriate formal evaluation procedures at the level of spoken language. The task that was selected for this purpose is the Air Travel Information System (ATIS) task, based on selected tables from the Official Airline Guide (OAG). It was decided that the first evaluation would be limited in scope to deal with text input only, and to cover only sentences that could be understood unambiguously out of context. Data have been recorded over the past several months at Texas Instruments, using an interface that involves a wizard who fully interprets the meaning of the subject's sentences, and generates database responses using a menu driven data access system."
H90-1043,Recent Progress on the {VOYAGER} System,1990,9,18,8,0.5,45080,victor zue,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"The VOYAGER speech recognition system, which was described in some detail at the last DARPA meeting [9], is an urban exploration system which provides the user with help in locating various sites in the area of Cambridge, Massachusetts. The system has a limited database of objects such as banks, restaurants, and post offices and can provide information about these objects (e.g., phone numbers, type of cuisine served) as well as providing navigational assistance between them. VOYAGER accepts both spoken and typed input and responds in the form of text, graphics, and synthesized speech. Since the last meeting, we have made developments to VOYAGER that have had an impact on the usability of the system."
H90-1074,Recent Progress on the {SUMMIT} System,1990,11,13,7,0.5,45080,victor zue,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"The SUMMIT system is a speaker-independent, continuous-speech recognition system that we have developed at MIT [12]. To date, the system has been ported to a variety of tasks with vocabulary sizes up to 1000 words and perplexities up to 73. The architecture of this system is a product of two guiding principles. First, we desired a framework that could be flexible and modular so that we could explore alternative strategies for embedding speech knowledge into the system. Second, we required that the system be stochastic and trainable from a large body of speech data to account for our current incomplete knowledge of the acoustic realization of speech. The current implementation of the system is a reflection of both of these ideas. SUMMIT differs from the majority of prevailing HMM approaches in many respects ranging from its use of auditory models and selected acoustic measurements, to its segmental framework and use of pronunciation networks. In time, the specific implementation of these ideas will undoubtedly be modified as we discover superior techniques and approaches. Until phonetic and word recognition accuracies are competitive with those of human listeners however, we believe it will be appropriate to incorporate both notions of flexibility and trainability into the system."
W89-0222,Probabilistic Parsing for Spoken Language Applications,1989,0,5,1,1,36748,stephanie seneff,Proceedings of the First International Workshop on Parsing Technologies,0,"A new natural language system, TINA, has been developed for applications involving spoken language tasks, which integrate key ideas from context free grammars, Augmented Transition Networks (ATN{'}s) [6], and Lexical Functional Grammars (LFG{'}s) [1]. The parser uses a best-first strategy, with probability assignments on all arcs obtained automatically from a set of example sentences. An initial context-free grammar, derived from the example sentences, is first converted to a probabilistic network structure. Control includes both top-down and bottom-up cycles, and key parameters are passed among nodes to deal with long-distance movement, agreement, and semantic constraints. The probabilities provide a natural mechanism for exploring more common grammatical constructions first. One novel feature of TINA is that it provides an atuomatic sentence generation capability, which has been very effective for identifying overgeneration problems. A fully integrated spoken language system using this parser is under development."
H89-2008,The {VOYAGER} Speech Understanding System: A Progress Report,1989,5,14,7,0,45080,victor zue,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,"As part of the DARPA Spoken Language System program, we recently initiated an effort in spoken language understanding. A spoken language system addresses applications in which speech is used for interactive problem solving between a person and a computer. In these applications, not only must the system convert the speech signal into text, it must also understand the linguistic structure of a sentence in order to generate the correct response. This paper describes our early experience with the development of the MIT VOYAGER spoken language system."
H89-2018,The Collection and Preliminary Analysis of a Spontaneous Speech Database,1989,4,22,8,0,45080,victor zue,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,"As part of our effort in developing a spoken language system for interactive problem solving, we recently collected a sizeable amount of speech data. This database is composed of spontaneous sentences which were collected during a simulated human/machine dialogue. Since a computer log of the spoken dialogue was maintained, we were able to ask the subjects to provide read versions of the sentences as well. This paper documents the data collection process, and provides some preliminary analyses of the collected data."
H89-2022,Preliminary Evaluation of the {VOYAGER} Spoken Language System,1989,5,9,7,0,45080,victor zue,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,"VOYAGER is a speech understanding system currently under development at MIT. It provides information and navigational assistance for a geographical area within the city of Cambridge, Massachusetts. Recently, we have completed the initial implementation of the system. This paper describes the preliminary evaluation of VOYAGER, using a spontaneous speech database that was also recently collected."
H89-1026,{TINA}: A Probabilistic Syntactic Parser for Speech Understanding Systems,1989,10,31,1,1,36748,stephanie seneff,"Speech and Natural Language: Proceedings of a Workshop Held at Philadelphia, {P}ennsylvania, {F}ebruary 21-23, 1989",0,"A natural language system, TINA, which integrates key ideas from context-free grammars, augmented transition networks (ATNs), and unification grammars has been developed. The parser uses a best-first search strategy, with probability assignments on all arcs obtained automatically from a set of example sentences. An initial context-free grammar, derived from the example sentences, is converted to an implicit probabilistic network structure. Control includes both top-down and bottom-up cycles, and key parameters are passed among nodes to deal with long-distance movement and agreement constraints. The probabilities provide a natural mechanism for exploring more common grammatical constructions first. Arc probabilities reduce test-set perplexity sixfold. A strategy for dealing with movement that can handle nested and chained gaps efficiently and rejects crossed gaps is introduced. >"
H89-1027,The {MIT} {SUMMIT} Speech Recognition System: A Progress Report,1989,12,78,4,0,45080,victor zue,"Speech and Natural Language: Proceedings of a Workshop Held at Philadelphia, {P}ennsylvania, {F}ebruary 21-23, 1989",0,"Recently, we initiated a project to develop a phonetically-based spoken language understanding system called SUMMIT. In contrast to many of the past efforts that make use of heuristic rules whose development requires intense knowledge engineering, our approach attempts to express the speech knowledge within a formal framework using well-defined mathematical tools. In our system, features and decision strategies are discovered and trained automatically, using a large body of speech data. This paper describes the system, and documents its current performance."
