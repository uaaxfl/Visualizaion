2021.emnlp-main.203,Syntactically-Informed Unsupervised Paraphrasing with Non-Parallel Data,2021,-1,-1,4,0,9060,erguang yang,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Previous works on syntactically controlled paraphrase generation heavily rely on large-scale parallel paraphrase data that is not easily available for many languages and domains. In this paper, we take this research direction to the extreme and investigate whether it is possible to learn syntactically controlled paraphrase generation with nonparallel data. We propose a syntactically-informed unsupervised paraphrasing model based on conditional variational auto-encoder (VAE) which can generate texts in a specified syntactic structure. Particularly, we design a two-stage learning method to effectively train the model using non-parallel data. The conditional VAE is trained to reconstruct the input sentence according to the given input and its syntactic structure. Furthermore, to improve the syntactic controllability and semantic consistency of the pre-trained conditional VAE, we fine-tune it using syntax controlling and cycle reconstruction learning objectives, and employ Gumbel-Softmax to combine these new learning objectives. Experiment results demonstrate that the proposed model trained only on non-parallel data is capable of generating diverse paraphrases with specified syntactic structure. Additionally, we validate the effectiveness of our method for generating syntactically adversarial examples on the sentiment analysis task."
2021.ccl-1.52,åºäºå¤ä»»å¡æ ç­¾ä¸è´æ§æºå¶çä¸­æå½åå®ä½è¯å«({C}hinese Named Entity Recognition based on Multi-task Label Consistency Mechanism),2021,-1,-1,5,0,11783,shuning lv,Proceedings of the 20th Chinese National Conference on Computational Linguistics,0,"{``}å®ä½è¾¹çé¢æµå¯¹ä¸­æå½åå®ä½è¯å«è³å
³éè¦ãç°æç ç©¶ä¸ºæ¹åè¾¹çè¯å«æææåºçå¤ä»»å¡å­¦ä¹ æ¹æ³ä»
èèä¸åè¯ä»»å¡ç»å,ç¼ºå°å¤ä»»å¡æ ç­¾è®­ç»æ°æ®,æ æ³å­¦å°ä»»å¡çæ ç­¾ä¸è´æ§å
³ç³»ãæ¬ææåºä¸ç§æ°çåºäºå¤ä»»å¡æ ç­¾ä¸è´æ§æºå¶çä¸­æå½åå®ä½è¯å«æ¹æ³:å°åè¯åè¯æ§ä¿¡æ¯èå
¥å½åå®ä½è¯å«æ¨¡å,ä½¿ä¸ç§ä»»å¡èåè®­ç»;å»ºç«åºäºæ ç­¾ä¸è´æ§æºå¶çå¤ä»»å¡å­¦ä¹ æ¨¡å¼,æ¥æè·æ ç­¾ä¸è´æ§å
³ç³»åå­¦ä¹ å¤ä»»å¡è¡¨ç¤ºãå
¨æ ·æ¬åå°æ ·æ¬å®éªè¡¨æäºæ¹æ³çæææ§ã{''}"
2021.ccl-1.68,èåå¤é¨ç¥è¯çå¼æ¾åå¤è¿°æ¨¡æ¿è·åæ¹æ³(An Open Domain Paraphrasing Template Acquisition Method Based on External Knowledge),2021,-1,-1,3,0,11685,bo jin,Proceedings of the 20th Chinese National Conference on Computational Linguistics,0,"{``}å¦ä½ææè¯­è¨èµæºä¸­ä¸°å¯çå¤è¿°æ¨¡æ¿,æ¯å¤è¿°ç ç©¶ä¸­çä¸é¡¹éè¦ä»»å¡ãå·²ææ¹æ³å¨äººå·¥ç»å®ç§å­å®ä½å¯¹çåºç¡ä¸,å©ç¨å®ä½å
³ç³»,éè¿èªä¸¾è¿­ä»£æ¹å¼,ä»å¼æ¾åè·åå¤è¿°æ¨¡æ¿,è§é¿å¯¹å¹³è¡è¯­ææå¯æ¯è¯­æçä¾èµ,ä½æ¯è¯¥æ¹æ³éäººå·¥ç»å®å®ä½å¯¹,å®ä½å
³ç³»åé;å¨è¿­ä»£è¿ç¨ä¸­è¯­ä¹ä¼åçåç§»,å½±åè·åè´¨éãéå¯¹è¿äºé®é¢,æä»¬èèç¥è¯åºä¸­å
å«æè¿°ç¹å®è¯­ä¹å
³ç³»çå®ä½å¯¹(å³å
³ç³»ä¸å
ç»),æåºèåå¤é¨ç¥è¯çå¼æ¾åå¤è¿°æ¨¡æ¿èªå¨è·åæ¹æ³ãé¦å
,å°å
³ç³»ä¸å
ç»ä¸å¼æ¾åææ¬å¯¹é½,è·åå
³ç³»å¯¹åºææ¬,å¹¶å°ææ¬ä¸­è¯­ä¹ä¸°å¯é¨åæ³åæåéæ§½,è·åå
³ç³»æ¨¡æ¿;æ¥çè®¾è®¡æ¨¡æ¿è¡¨ç¤ºæ¹æ³,æ¬æå©ç¨é¢è®­ç»è¯­è¨æ¨¡å,å¨æ¨¡æ¿è¡¨ç¤ºä¸­èååéæ§½è¯­ä¹;æå,æ ¹æ®è·å¾çæ¨¡æ¿è¡¨ç¤º,è®¾è®¡èªå¨èç±»ä¸ç­éæ¹æ³,è·åé«ç²¾åº¦çå¤è¿°æ¨¡æ¿ãå¨èåèªå¨è¯æµä¸äººå·¥è¯æµçè¯ä»·æ¹æ³ä¸,å®éªç»æè¡¨æ,æ¬ææåºçæ¹æ³å®ç°äºå¨å¼æ¾åæ°æ®ä¸å¤è¿°æ¨¡æ¿çèªå¨æ³åä¸è·å,è½å¤è·å¾è´¨éé«ãè¯­ä¹ä¸è´çå¤è¿°æ¨¡æ¿ã{''}"
2020.coling-main.209,A Learning-Exploring Method to Generate Diverse Paraphrases with Multi-Objective Deep Reinforcement Learning,2020,-1,-1,4,1,9061,mingtong liu,Proceedings of the 28th International Conference on Computational Linguistics,0,"Paraphrase generation (PG) is of great importance to many downstream tasks in natural language processing. Diversity is an essential nature to PG for enhancing generalization capability and robustness of downstream applications. Recently, neural sequence-to-sequence (Seq2Seq) models have shown promising results in PG. However, traditional model training for PG focuses on optimizing model prediction against single reference and employs cross-entropy loss, which objective is unable to encourage model to generate diverse paraphrases. In this work, we present a novel approach with multi-objective learning to PG. We propose a learning-exploring method to generate sentences as learning objectives from the learned data distribution, and employ reinforcement learning to combine these new learning objectives for model training. We first design a sample-based algorithm to explore diverse sentences. Then we introduce several reward functions to evaluate the sampled sentences as learning signals in terms of expressive diversity and semantic fidelity, aiming to generate diverse and high-quality paraphrases. To effectively optimize model performance satisfying different evaluating aspects, we use a GradNorm-based algorithm that automatically balances these training objectives. Experiments and analyses on Quora and Twitter datasets demonstrate that our proposed method not only gains a significant increase in diversity but also improves generation quality over several state-of-the-art baselines."
2020.ccl-1.19,åºäºå¾ç¥ç»ç½ç»çæ±è¯­ä¾å­åæåè¯­ä¹ç»åè®¡ç®èåæ¨¡å(Joint Learning {C}hinese Dependency Parsing and Semantic Composition based on Graph Neural Network),2020,-1,-1,4,0,6492,kai wang,Proceedings of the 19th Chinese National Conference on Computational Linguistics,0,"ç»åååè¡¨æå¥å­çè¯­ä¹ç±å
¶æææåçè¯­ä¹æç
§ä¸å®è§åç»åèæ, ç±æ­¤åºäºå¥æ³ç»æçè¯­ä¹ç»åè®¡ç®ä¸ç´æ¯ä¸ä¸ªéè¦çæ¢ç´¢æ¹å,å
¶ä¸­éç¨æ ç»æçç»åè®¡ç®æ¹æ³æå
·æä»£è¡¨æ§ãä½æ¯è¯¥æ¹æ³é¾ä»¥åºç¨äºå¤§è§æ¨¡æ°æ®å¤ç,ä¸»è¦é®é¢æ¯å
¶è¯­ä¹ç»åçé¡ºåºä¾èµäºå
·ä½æ çç»æ,æ æ³å®ç°å¹¶è¡å¤çãæ¬ææåºä¸ç§åºäºå¾çä¾å­å¥æ³åæåè¯­ä¹ç»åè®¡ç®çèåæ¡æ¶,å¹¶åå©å¤è¿°è¯å«ä»»å¡è®­ç»è¯­ä¹ç»åæ¨¡ååå¥æ³åææ¨¡åãä¸æ¹é¢å¾æ¨¡åå¯ä»¥å¨è®­ç»åé¢æµé¶æ®µéç¨å¹¶è¡å¤ç,æå¤§ç¼©ç­è®¡ç®æ¶é´;å¦ä¸æ¹é¢èåå¥æ³åæçè¯­ä¹ç»åæ¡æ¶ä¸å¿
ä¾èµå¤é¨å¥æ³åæå¨,åæ¶ä¸¤ä¸ªä»»å¡çèåå­¦ä¹ å¯ä½¿è¯­ä¹è¡¨ç¤ºåæ¶å­¦ä¹ å¥æ³ç»æåè¯­ä¹çä¸ä¸æä¿¡æ¯ãæä»¬å¨å
¬å¼æ±è¯­å¤è¿°è¯å«æ°æ®éLCQMCä¸è¿è¡è¯æµ,å®éªç»ææ¾ç¤ºåç¡®çæ¥è¿æ ç»æç»åæ¹æ³,è¾¾å°79.54{\%},èé¢æµéåº¦æåé«è¾¾30åã"
2020.ccl-1.21,èåä¾å­åæçæ±è¯­è¯­ä¹ç»åæ¨¡å({C}hinese Semantic Composition Model with Dependency Parsing),2020,-1,-1,2,0,22018,yuanmeng chen,Proceedings of the 19th Chinese National Conference on Computational Linguistics,0,"å¨è¯­ä¹ç»åæ¹æ³ä¸­,ç»æåæ¹æ³å¼ºè°ä»¥ç»æä¿¡æ¯æå¯¼è¯ä¹è¡¨ç¤ºçç»åæ¹å¼ãç°æç»æåè¯­ä¹ç»åæ¹æ³ä½¿ç¨å¤é¨åæå¨è·åå¥æ³ç»æä¿¡æ¯,å¯¼è´å¥æ³åæä¸è¯­ä¹ç»åç¸äºå²è£,å¥æ³åæçç²¾åº¦ä¸¥éå¶çº¦è¯­ä¹ç»åæ¨¡åçæ§è½,ä¸è®­ç»æ°æ®é¢åä¸ä¸è´ç­é®é¢ä¼è¿ä¸æ­¥å å§æ§è½çä¸éãå¯¹æ­¤,æ¬ææåºèåä¾å­åæçè¯­ä¹ç»åæ¨¡å,å°ä¾å­åæä¸è¯­ä¹ç»åè¿è¡èå,ä¸æ¹é¢å¨è®­ç»è¯­ä¹ç»åæ¨¡åæ¶å¯¹ä¾å­åææ¨¡åè¿è¡å¾®è°,ä½¿å
¶è½å¤æ´éåºè¯­ä¹ç»åæ¨¡åä½¿ç¨çè®­ç»æ°æ®çé¢åç¹ç¹;å¦ä¸æ¹é¢,å¨è¯­ä¹ç»åé¨åå å
¥ä¾å­åæçä¸­é´ä¿¡æ¯è¡¨ç¤º,è·åæ´ä¸°å¯çç»æä¿¡æ¯åè¯­ä¹ä¿¡æ¯,ä»¥æ­¤æ¥éä½è¯­ä¹ç»åæ¨¡åå¯¹ä¾å­åæéè¯¯ç»æçææåº¦,æåæ¨¡åçé²æ£æ§ãæä»¬ä»¥æ±è¯­ä¸ºå
·ä½ç ç©¶å¯¹è±¡,å°è¯­ä¹ç»åæ¨¡åç¨äºå¤è¿°è¯å«ä»»å¡,å¹¶å¨CTB5æ±è¯­ä¾å­åææ°æ®åLCQMCæ±è¯­å¤è¿°è¯å«æ°æ®ä¸éªè¯æ¬ææåºçæ¨¡åãå®éªç»ææ¾ç¤º,æ¬ææææ¹æ³å¨å¤è¿°è¯å«ä»»å¡ä¸çé¢æµæ­£ç¡®çåF1å¼ä¸åå«è¾¾å°76.81{\%}å78.03{\%};æä»¬è¿ä¸æ­¥è®¾è®¡å®éªå¯¹èåå­¦ä¹ åä¸­é´ä¿¡æ¯å©ç¨çæææ§è¿è¡éªè¯,å¹¶ä¸ç¸å
³ä»£è¡¨æ§å·¥ä½è¿è¡äºå¯¹æ¯åæã"
2020.ccl-1.76,A Joint Model for Graph-based {C}hinese Dependency Parsing,2020,4,0,3,0,22116,xingchen li,Proceedings of the 19th Chinese National Conference on Computational Linguistics,0,"In Chinese dependency parsing, the joint model of word segmentation, POS tagging and dependency parsing has become the mainstream framework because it can eliminate error propagation and share knowledge, where the transition-based model with feature templates maintains the best performance. Recently, the graph-based joint model (Yan et al., 2019) on word segmentation and dependency parsing has achieved better performance, demonstrating the advantages of the graph-based models. However, this work can not provide POS information for downstream tasks, and the POS tagging task was proved to be helpful to the dependency parsing according to the research of the transition-based model. Therefore, we propose a graph-based joint model for Chinese word segmentation, POS tagging and dependency parsing. We designed a charater-level POS tagging task, and then train it jointly with the model of Yan et al. (2019). We adopt two methods of joint POS tagging task, one is by sharing parameters, the other is by using tag attention mechanism, which enables the three tasks to better share intermediate information and improve each other{'}s performance. The experimental results on the Penn Chinese treebank (CTB5) show that our proposed joint model improved by 0.38{\%} on dependency parsing than the model of Yan et al. (2019). Compared with the best transition-based joint model, our model improved by 0.18{\%}, 0.35{\%} and 5.99{\%} respectively in terms of word segmentation, POS tagging and dependency parsing."
D19-1267,Original Semantics-Oriented Attention and Deep Fusion Network for Sentence Matching,2019,0,0,2,1,9061,mingtong liu,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Sentence matching is a key issue in natural language inference and paraphrase identification. Despite the recent progress on multi-layered neural network with cross sentence attention, one sentence learns attention to the intermediate representations of another sentence, which are propagated from preceding layers and therefore are uncertain and unstable for matching, particularly at the risk of error propagation. In this paper, we present an original semantics-oriented attention and deep fusion network (OSOA-DFN) for sentence matching. Unlike existing models, each attention layer of OSOA-DFN is oriented to the original semantic representation of another sentence, which captures the relevant information from a fixed matching target. The multiple attention layers allow one sentence to repeatedly read the important information of another sentence for better matching. We then additionally design deep fusion to propagate the attention information at each matching layer. At last, we introduce a self-attention mechanism to capture global context to enhance attention-aware representation within each sentence. Experiment results on three sentence matching benchmark datasets SNLI, SciTail and Quora show that OSOA-DFN has the ability to model sentence matching more precisely."
W16-4608,System Description of bjtu{\\_}nlp Neural Machine Translation System,2016,10,0,4,0,33574,shaotong li,Proceedings of the 3rd Workshop on {A}sian Translation ({WAT}2016),0,"This paper presents our machine translation system that developed for the WAT2016 evalua-tion tasks of ja-en, ja-zh, en-ja, zh-ja, JPCja-en, JPCja-zh, JPCen-ja, JPCzh-ja. We build our system based on encoder{--}decoder framework by integrating recurrent neural network (RNN) and gate recurrent unit (GRU), and we also adopt an attention mechanism for solving the problem of information loss. Additionally, we propose a simple translation-specific approach to resolve the unknown word translation problem. Experimental results show that our system performs better than the baseline statistical machine translation (SMT) systems in each task. Moreover, it shows that our proposed approach of unknown word translation performs effec-tively improvement of translation results."
W15-5010,A Dependency-to-String Model for {C}hinese-{J}apanese {SMT} System,2015,4,1,2,0,36541,hua shan,Proceedings of the 2nd Workshop on {A}sian Translation ({WAT}2015),0,None
W15-3910,A Hybrid Transliteration Model for {C}hinese/{E}nglish Named Entities {---}{BJTU}-{NLP} Report for the 5th Named Entities Workshop,2015,8,2,8,0,36734,dandan wang,Proceedings of the Fifth Named Entity Workshop,0,"This paper presents our system (BJTU-NLP system) for the NEWS2015 evaluation task of Chinese-to-English and English-to-Chinese named entity transliteration. Our system adopts a hybrid machine transliteration approach, which combines several features. To further improve the result, we adopt external data extracted from wikipeda to expand the training set. In addition, pre-processing and post-processing rules are utilized to further improve the performance. The final performance on the test corpus shows that our system achieves comparable results with other state-of-the-art systems."
W15-3503,Integrating Case Frame into {J}apanese to {C}hinese Hierarchical Phrase-based Translation Model,2015,15,0,4,1,6532,jinan xu,Proceedings of the 1st Workshop on Semantics-Driven Statistical Machine Translation ({S}2{MT} 2015),0,"This paper presents a novel approach to enhance hierarchical phrase-based (HPB) machine translation systems with case frame (CF).we integrate the Japanese shallow CF into both rule extraction and decoding. All of these rules are then employed to decode new sentences in Japanese with source language case frame. The results of experiments carried out on Japanese-Chinese test sets. It shows that our approach maintains the advantages of HPB translation systems while at the same time naturally incorporates CF constraints. The case frame rules can complement Hiero-style rules. Our approach is especially effective for language pairs with large word order differences, such as Japanese-to-Chinese."
W14-7005,System Description: Dependency-based Pre-ordering for {J}apanese-{C}hinese Machine Translation,2014,8,1,2,0,38092,jingsheng cai,Proceedings of the 1st Workshop on {A}sian Translation ({WAT}2014),0,This paper describes the Beijing Jiaotong University Japanese-Chinese machine translation system which participated in the 1st Workshop on Asian Translation (WAT 2014). We propose a preordering approach based on dependency parsing for Japanese-Chinese statistical machine translation (SMT). Our system achieves a BLEU of 24.12 and a RIBES of 79.48 on the Japanese-Chinese translation task in the official evaluation.
P14-2026,Dependency-based Pre-ordering for {C}hinese-{E}nglish Machine Translation,2014,19,13,4,0,38092,jingsheng cai,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"In statistical machine translation (SMT), syntax-based pre-ordering of the source language is an effective method for dealing with language pairs where there are great differences in their respective word orders. This paper introduces a novel pre-ordering approach based on dependency parsing for Chinese-English SMT. We present a set of dependency-based preordering rules which improved the BLEU score by 1.61 on the NIST 2006 evaluation data. We also investigate the accuracy of the rule set by conducting human evaluations."
I13-1120,An Approach of Hybrid Hierarchical Structure for Word Similarity Computing by {H}ow{N}et,2013,6,1,3,1,3317,jiangming liu,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Word similarity computing is an important and fundamental task in the field of natural language processing. Most of word similarity methods perform well in synonyms, but not well between words whose similarity is vague. To overcome this problem, this paper proposes an approach of hybrid hierarchical structure computing Chinese word similarity to achieve fine-grained similarity results with HowNet 2008. The experimental results prove that the method has a better effect on computing similarity of synonyms and antonyms including nouns, verbs and adjectives. Besides, it performs stably on standard data provided by SemEval 2012."
I11-1035,Improving {C}hinese Word Segmentation and {POS} Tagging with Semi-supervised Methods Using Large Auto-Analyzed Data,2011,26,59,5,0,29973,yiou wang,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"This paper presents a simple yet effective semi-supervised method to improve Chinese word segmentation and POS tagging. We introduce novel features derived from large auto-analyzed data to enhance a simple pipelined system. The auto-analyzed data are generated from unlabeled data by using a baseline system. We evaluate the usefulness of our approach in a series of experiments on Penn Chinese Treebanks and show that the new features provide substantial performance gains in all experiments. Furthermore, the results of our proposed method are superior to the best reported results in the literature."
D11-1007,{SMT} Helps Bitext Dependency Parsing,2011,22,9,5,0.760905,21231,wenliang chen,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"We propose a method to improve the accuracy of parsing bilingual texts (bitexts) with the help of statistical machine translation (SMT) systems. Previous bitext parsing methods use human-annotated bilingual treebanks that are hard to obtain. Instead, our approach uses an auto-generated bilingual treebank to produce bilingual constraints. However, because the auto-generated bilingual treebank contains errors, the bilingual constraints are noisy. To overcome this problem, we use large-scale unannotated data to verify the constraints and design a set of effective bilingual features for parsing models based on the verified results. The experimental results show that our new parsers significantly outperform state-of-the-art baselines. Moreover, our approach is still able to provide improvement when we use a larger monolingual treebank that results in a much stronger baseline. Especially notable is that our approach can be used in a purely monolingual setting with the help of SMT."
zhang-etal-2008-word,Word Alignment Annotation in a {J}apanese-{C}hinese Parallel Corpus,2008,5,0,1,1,9062,yujie zhang,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Parallel corpora are critical resources for machine translation research and development since parallel corpora contain translation equivalences of various granularities. Manual annotation of word {\&} phrase alignment is of significance to provide gold-standard for developing and evaluating both example-based machine translation model and statistical machine translation model. This paper presents the work of word {\&} phrase alignment annotation in the NICT Japanese-Chinese parallel corpus, which is constructed at the National Institute of Information and Communications Technology (NICT). We describe the specification of word alignment annotation and the tools specially developed for the manual annotation. The manual annotation on 17,000 sentence pairs has been completed. We examined the manually annotated word alignment data and extracted translation knowledge from the word {\&} phrase aligned corpus."
I08-1012,Dependency Parsing with Short Dependency Relations in Unlabeled Data,2008,18,27,4,1,21231,wenliang chen,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"This paper presents an effective dependency parsing approach of incorporating short dependency information from unlabeled data. The unlabeled data is automatically parsed by a deterministic dependency parser, which can provide relatively high performance for short dependencies between words. We then train another parser which uses the information on short dependency relations extracted from the output of the first parser. Our proposed approach achieves an unlabeled attachment score of 86.52, an absolute 1.24% improvement over the baseline system on the data set of Chinese Treebank."
N07-1005,Automatic Evaluation of Machine Translation Based on Rate of Accomplishment of Sub-Goals,2007,14,2,3,0.134002,30019,kiyotaka uchimoto,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"The quality of a sentence translated by a machine translation (MT) system is difficult to evaluate. We propose a method for automatically evaluating the quality of each translation. In general, when translating a given sentence, one or more conditions should be satisfied to maintain a high translation quality. In EnglishJapanese translation, for example, prepositions and infinitives must be appropriately translated. We show several procedures that enable evaluating the quality of a translated sentence more appropriately than using conventional methods. The first procedure is constructing a test set where the conditions are assigned to each test-set sentence in the form of yes/no questions. The second procedure is developing a system that determines an answer to each question. The third procedure is combining a measure based on the questions and conventional measures. We also present a method for automatically generating sub-goals in the form of yes/no questions and estimating the rate of accomplishment of the sub-goals. Promising results are shown."
D07-1122,A Two-Stage Parser for Multilingual Dependency Parsing,2007,14,7,2,1,21231,wenliang chen,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"We present a two-stage multilingual dependency parsing system submitted to the Multilingual Track of CoNLL-2007. The parser first identifies dependencies using a deterministic parsing method and then labels those dependencies as a sequence labeling problem. We describe the features used in each stage. For four languages with different values of ROOT, we design some special features for the ROOT labeler. Then we present evaluation results and error analyses focusing on Chinese."
2007.mtsummit-papers.73,Building {J}apanese-{C}hinese translation dictionary based on {EDR} {J}apanese-{E}nglish bilingual dictionary,2007,2,6,1,1,9062,yujie zhang,Proceedings of Machine Translation Summit XI: Papers,0,"We launched a 5-year-project in 2006 to develop a Japanese-Chinese machine translation system for translating scientific and technical papers. As part of that project, we are currently building a Japanese-Chinese translation dictionary based on the EDR Japanese-English bilingual dictionary. This paper presents the design and construction of the Japanese-Chinese translation dictionary, including specifications for translating Japanese information into Chinese and annotating related information, tools developed for assisting manual annotation, and some result that have already been achieved."
W06-0116,{C}hinese Named Entity Recognition with Conditional Random Fields,2006,3,53,2,1,21231,wenliang chen,Proceedings of the Fifth {SIGHAN} Workshop on {C}hinese Language Processing,0,"We present a Chinese Named Entity Recognition (NER) system submitted to the close track of Sighan Bakeoff2006. We define some additional features via doing statistics in training corpus. Our system incorporates basic features and additional features based on Conditional Random Fields (CRFs). In order to correct inconsistently results, we perform the postprocessing procedure according to n-best results given by the CRFs model. Our final system achieved a F-score of 85.14 at MSRA, 89.03 at CityU, and 76.27 at LDC."
P06-2013,An Empirical Study of {C}hinese Chunking,2006,25,43,2,1,21231,wenliang chen,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"In this paper, we describe an empirical study of Chinese chunking on a corpus, which is extracted from UPENN Chinese Treebank-4 (CTB4). First, we compare the performance of the state-of-the-art machine learning models. Then we propose two approaches in order to improve the performance of Chinese chunking. 1) We propose an approach to resolve the special problems of Chinese chunking. This approach extends the chunk tags for every problem by a tag-extension function. 2) We propose two novel voting methods based on the characteristics of chunking task. Compared with traditional voting methods, the proposed voting methods consider long distance information. The experimental results show that the SVMs model outperforms the other models and that our proposed approaches can improve performance significantly."
I05-2015,Building an Annotated {J}apanese-{C}hinese Parallel Corpus - A Part of {NICT} Multilingual Corpora,2005,9,9,1,1,9062,yujie zhang,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"We are constricting a Japanese-Chinese parallel corpus, which is a part of the NICT Multilingual Corpora. The corpus is general domain, of large scale of about 40,000 sentence pairs, long sentences, annotated with detailed information and high quality. To the best of our knowledge, this will be the first annotated JapaneseChinese parallel corpus in the world. We created the corpus by selecting Japanese sentences from Mainichi Newspaper and then manually translating them into Chinese. We then annotated the corpus with morphological and syntactic structures and alignments at word and phrase levels. This paper describes the specification in human translation and the scheme of detailed information annotation, and the tools we developed in the corpus construction. The experience we obtained and points we paid special attentions are also introduced for share with other researches in corpora construction."
2005.mtsummit-papers.10,Building an Annotated {J}apanese-{C}hinese Parallel Corpus {--} A Part of {NICT} Multilingual Corpora,2005,9,9,1,1,9062,yujie zhang,Proceedings of Machine Translation Summit X: Papers,0,"We are constricting a Japanese-Chinese parallel corpus, which is a part of the NICT Multilingual Corpora. The corpus is general domain, of large scale of about 40,000 sentence pairs, long sentences, annotated with detailed information and high quality. To the best of our knowledge, this will be the first annotated Japanese-Chinese parallel corpus in the world. We created the corpus by selecting Japanese sentences from Mainichi Newspaper and then manually translating them into Chinese. We then annotated the corpus with morphological and syntactic structures and alignments at word and phrase levels. This paper describes the specification in human translation and detailed information annotation, and the tools we developed in the project. The experience we obtained and points we paid special attentions are also introduced for share with other researches in corpora construction."
2005.mtsummit-papers.18,A Multi-aligner for {J}apanese-{C}hinese Parallel Corpora,2005,-1,-1,1,1,9062,yujie zhang,Proceedings of Machine Translation Summit X: Papers,0,"Automatic word alignment is an important technology for extracting translation knowledge from parallel corpora. However, automatic techniques cannot resolve this problem completely because of variances in translations. We therefore need to investigate the performance potential of automatic word alignment and then decide how to suitably apply it. In this paper we first propose a lexical knowledge-based approach to word alignment on a Japanese-Chinese corpus. Then we evaluate the performance of the proposed approach on the corpus. At the same time we also apply a statistics-based approach, the well-known toolkit GIZA++, to the same test data. Through comparison of the performances of the two approaches, we propose a multi-aligner, exploiting the lexical knowledge-based aligner and the statistics-based aligner at the same time. Quantitative results confirmed the effectiveness of the multi-aligner."
2005.mtsummit-invited.7,Introduction to {C}hina{'}s {HTRDP} Machine Translation Evaluation,2005,-1,-1,5,0,5775,qun liu,Proceedings of Machine Translation Summit X: Invited papers,0,"Since 1994, China{'}s HTRDP machine translation evaluation has been conducted for five times. Systems of various translation directions between Chinese, English, Japanese and French have been tested. Both human evaluation and automatic evaluation are conducted in HTRDP evaluation. In recent years, the evaluation was organized jointly with NICT of Japan. This paper introduces some details of this evaluation."
Y04-1018,Acquiring Compound Word Translations both Automatically and Dynamically,2004,5,5,1,1,9062,yujie zhang,"Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation",0,This paper addresses the problem of compound word translation and proposes the approaches to acquiring translations. The proposed approaches focus on exploring web data and utilizing English translations to link words of the source language and the correspondences in the target language. The paper uses Japanese-Chinese language pairs for the sake of illustration and shows initial experimental results. The proposed method is language-independent and therefore can be applied to other language pairs.
W04-2208,Multilingual Aligned Parallel Treebank Corpus Reflecting Contextual Information and Its Applications,2004,13,18,2,0.134002,30019,kiyotaka uchimoto,Proceedings of the Workshop on Multilingual Linguistic Resources,0,"This paper describes Japanese-English-Chinese aligned parallel treebank corpora of newspaper articles. They have been constructed by translating each sentence in the Penn Treebank and the Kyoto University text corpus into a corresponding natural sentence in a target language. Each sentence is translated so as to reflect its contextual information and is annotated with morphological and syntactic structures and phrasal alignment. This paper also describes the possible applications of the parallel corpus and proposes a new framework to aid in translation. In this framework, parallel translations whose source language sentence is similar to a given sentence can be semi-automatically generated. In this paper we show that the framework can be achieved by using our aligned parallel treebank corpus."
W03-1714,Semantic Maps for Word Alignment in Bilingual Parallel Corpora,2003,11,4,2,0,33252,qing ma,Proceedings of the Second {SIGHAN} Workshop on {C}hinese Language Processing,0,"Effective self-organizing techniques for constructing monolingual semantic maps of Japanese and Chinese have already been developed. By extending the monolingual map to a bilingual semantic map, we have proposed a semantics-based approach for word alignment in a Japanese/Chinese bilingual corpus."
C02-1056,Paraphrasing of {C}hinese Utterances,2002,5,13,1,1,9062,yujie zhang,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"One of the key issues in spoken language translation is how to deal with unrestricted expressions in spontaneous utterances. This research is centered on the development of a Chinese paraphraser that automatically paraphrases utterances prior to transfer in Chinese-Japanese spoken language translation. In this paper, a pattern-based approach to paraphrasing is proposed for which only morphological analysis is required. In addition, a pattern construction method is described through which paraphrasing patterns can be efficiently learned from a paraphrase corpus and human experience. Using the implemented paraphraser and the obtained patterns, a paraphrasing experiment was conducted and the results were evaluated."
Y99-1026,A Classification Tree Approach to Automatic Segmentation of {J}apanese Compound Sentences,1999,6,0,1,1,9062,yujie zhang,"Proceedings of the 13th Pacific Asia Conference on Language, Information and Computation",0,None
Y98-1022,Automatic Bunsetsu Segmentation of {J}apanese Sentences Using a Classification Tree,1998,9,1,1,1,9062,yujie zhang,"Proceedings of the 12th Pacific Asia Conference on Language, Information and Computation",0,"Bunsetsu, which is comprised of a content word followed by, possibly 0, function words, is a convenient unit for dependency structure analysis of Japanese. There are, however, no spaces indicating bunsetsu boundaries in the orthographic writing of Japanese. Thus a sentence must be segmented into bunsetsu's by some means prior to dependency structure analysis. Conventionally, such segmentation has been performed by using some kind of hand-crafted rules. This paper describes a novel segmentation method using a classification tree, by which knowledge about bunsetsu boundaries is automatically acquired from a labeled corpus. The method enables quick and easy adaptation to a new task domain, and also to a new system of morpheme categorization without the need of changing the algorithm. Effectiveness of this method is shown through experiments on an ATR corpus and an EDR corpus."
