K19-2003,The {ERG} at {MRP} 2019: Radically Compositional Semantic Dependencies,2019,-1,-1,2,0,2623,stephan oepen,Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning,0,"The English Resource Grammar (ERG) is a broad-coverage computational grammar of English that outputs underspecified logical-form representations of meaning in a framework dubbed English Resource Semantics (ERS). Two of the target representations in the the 2019 Shared Task on Cross-Framework Meaning Representation Parsing (MRP 2019) derive graph-based simplifications of ERS, viz. Elementary Dependency Structures (EDS) and DELPH-IN MRS Bi-Lexical Dependencies (DM). As a point of reference outside the official MRP competition, we parsed the evaluation strings using the ERG and converted the resulting meaning representations to EDS and DM. These graphs yield higher evaluation scores than the purely data-driven parsers in the actual shared task, suggesting that the general-purpose linguistic knowledge about English grammar encoded in the ERG can add value when parsing into these meaning representations."
W16-0511,{UW}-{S}tanford System Description for {AESW} 2016 Shared Task on Grammatical Error Detection,2016,2,2,1,1,26293,dan flickinger,Proceedings of the 11th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,None
N16-4001,{E}nglish {R}esource {S}emantics,2016,0,1,1,1,26293,dan flickinger,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Tutorial Abstracts,0,None
L16-1630,Towards Comparability of Linguistic Graph {B}anks for Semantic Parsing,2016,20,7,6,0,2623,stephan oepen,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We announce a new language resource for research on semantic parsing, a large, carefully curated collection of semantic dependency graphs representing multiple linguistic traditions. This resource is called SDP{\textasciitilde}2016 and provides an update and extension to previous versions used as Semantic Dependency Parsing target representations in the 2014 and 2015 Semantic Evaluation Exercises. For a common core of English text, this third edition comprises semantic dependency graphs from four distinct frameworks, packaged in a unified abstract format and aligned at the sentence and token levels. SDP 2016 is the first general release of this resource and available for licensing from the Linguistic Data Consortium in May 2016. The data is accompanied by an open-source SDP utility toolkit and system results from previous contrastive parsing evaluations against these target representations."
W15-0128,Layers of Interpretation: On Grammar and Compositionality,2015,39,14,2,0,11448,emily bender,Proceedings of the 11th International Conference on Computational Semantics,0,"With the recent resurgence of interest in semantic annotation of corpora for improved semantic parsing, we observe a tendency which we view as ill-advised, to conflate sentence meaning and speaker meaning into a single mapping, whether done by annotators or by a parser. We argue instead for the more traditional hypothesis that sentence meaning, but not speaker meaning, is compositional, and accordingly that NLP systems would benefit from reusable, automatically derivable, taskindependent semantic representations which target sentence meaning, in order to capture exactly the information in the linguistic signal itself. We further argue that compositional construction of such sentence meaning representations affords better consistency, more comprehensiveness, greater scalability, and less duplication of effort for each new NLP application. For concreteness, we describe one well-tested grammar-based method for producing sentence meaning representations which is efficient for annotators, and which exhibits many of the above benefits. We then report on a small inter-annotator agreement study to quantify the consistency of semantic representations produced via this grammar-based method."
S15-2153,{S}em{E}val 2015 Task 18: Broad-Coverage Semantic Dependency Parsing,2015,-1,-1,6,0,2623,stephan oepen,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,None
S14-2008,{S}em{E}val 2014 Task 8: Broad-Coverage Semantic Dependency Parsing,2014,30,71,5,0,2623,stephan oepen,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"Task 18 at SemEval 2015 defines Broad-Coverage Semantic Dependency Parsing (SDP) as the problem of recovering sentence-internal predicatexe2x80x93argument relationships for all content words, i.e. the sema ..."
flickinger-etal-2014-towards,Towards an Encyclopedia of Compositional Semantics: Documenting the Interface of the {E}nglish {R}esource {G}rammar,2014,16,9,1,1,26293,dan flickinger,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We motivate and describe the design and development of an emerging encyclopedia of compositional semantics, pursuing three objectives. We first seek to compile a comprehensive catalogue of interoperable semantic analyses, i.e., a precise characterization of meaning representations for a broad range of common semantic phenomena. Second, we operationalize the discovery of semantic phenomena and their definition in terms of what we call their semantic fingerprint, a formal account of the building blocks of meaning representation involved and their configuration. Third, we ground our work in a carefully constructed semantic test suite of minimal exemplars for each phenomenon, along with a `target{'} fingerprint that enables automated regression testing. We work towards these objectives by codifying and documenting the body of knowledge that has been constructed in a long-term collaborative effort, the development of the LinGO English Resource Grammar. Documentation of its semantic interface is a prerequisite to use by non-experts of the grammar and the analyses it produces, but this effort also advances our own understanding of relevant interactions among phenomena, as well as of areas for future work in the grammar."
W13-5707,"On Different Approaches to Syntactic Analysis Into Bi-Lexical Dependencies. An Empirical Comparison of Direct, {PCFG}-Based, and {HPSG}-Based Parsers",2013,0,3,4,1,35341,angelina ivanova,Proceedings of the 13th International Conference on Parsing Technologies ({IWPT} 2013),0,None
W13-3609,Toward More Precision in Correction of Grammatical Errors,2013,13,5,1,1,26293,dan flickinger,Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task,0,"We describe a system for detecting and correcting instances of a small class of frequently occurring grammatical error types in a corpus of essays which have been manually annotated for these errors. Our system employs a precise broad-coverage grammar of English which has been augmented with a set of mal-rules and malentries to explicitly license certain types of erroneous expressions. The derivation tree produced by a parser using this grammar identifies the location and type of an error in an ill-formed sentence, enabling a postprocessing script to use the tree and the inventory of error types to delete and/or insert tokens in order to produce a corrected version of the original sentence."
W12-3602,Who Did What to Whom? A Contrastive Study of Syntacto-Semantic Dependencies,2012,32,39,4,1,35341,angelina ivanova,Proceedings of the Sixth Linguistic Annotation Workshop,0,"We investigate aspects of interoperability between a broad range of common annotation schemes for syntacto-semantic dependencies. With the practical goal of making the LinGO Redwoods Treebank accessible to broader usage, we contrast seven distinct annotation schemes of functor--argument structure, both in terms of syntactic and semantic relations. Drawing examples from a multi-annotated gold standard, we show how abstractly similar information can take quite different forms across frameworks. We further seek to shed light on the representational 'distance' between pure bilexical dependencies, on the one hand, and full-blown logical-form propositional semantics, on the other hand. Furthermore, we propose a fully automated conversion procedure from (logical-form) meaning representation to bilexical semantic dependencies."
N12-1070,Multimodal Grammar Implementation,2012,9,3,2,0,42823,katya alahverdzhieva,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"This paper reports on an implementation of a multimodal grammar of speech and co-speech gesture within the lkb/pet grammar engineering environment. The implementation extends the English Resource Grammar (erg, Flickinger (2000)) with hpsg types and rules that capture the form of the linguistic signal, the form of the gestural signal and their relative timing to constrain the meaning of the multimodal action. The grammar yields a single parse tree that integrates the spoken and gestural modality thereby drawing on standard semantic composition techniques to derive the multimodal meaning representation. Using the current machinery, the main challenge for the grammar engineer is the nonlinear input: the modalities can overlap temporally. We capture this by identical speech and gesture token edges. Further, the semantic contribution of gestures is encoded by lexical rules transforming a speech phrase into a multimodal entity of conjoined spoken and gestural semantics."
read-etal-2012-wesearch,"The {W}e{S}earch Corpus, Treebank, and Treecache {--} A Comprehensive Sample of User-Generated Content",2012,16,8,2,0,35001,jonathon read,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present the WeSearch Data Collection (WDC)âa freely redistributable, partly annotated, comprehensive sample of User-Generated Content. The WDC contains data extracted from a range of genres of varying formality (user forums, product review sites, blogs and Wikipedia) and covers two different domains (NLP and Linux). In this article, we describe the data selection and extraction process, with a focus on the extraction of linguistic content from different sources. We present the format of syntacto-semantic annotations found in this resource and present initial parsing results for these data, as well as some reflections following a first round of treebanking."
I11-1028,{T}reeblazing: Using External Treebanks to Filter Parse Forests for Parse Selection and Treebanking,2011,27,5,3,0,32906,andrew mackinlay,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"We describe xe2x80x9ctreeblazingxe2x80x9d, a method of using annotations from the GENIA treebank to constrain a parse forest from an HPSG parser. Combining this with self-training, we show significant dependency score improvements in a task of adaptation to the biomedical domain, reducing error rate by 9% compared to out-of-domain gold data and 6% compared to self-training. We also demonstrate improvements in treebanking efficiency, requiring 25% fewer decisions, and 17% less annotation time."
D11-1037,Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus,2011,36,25,2,0.490535,11448,emily bender,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"In order to obtain a fine-grained evaluation of parser accuracy over naturally occurring text, we study 100 examples each of ten reasonably frequent linguistic phenomena, randomly selected from a parsed version of the English Wikipedia. We construct a corresponding set of gold-standard target dependencies for these 1000 sentences, operationalize mappings to these targets from seven state-of-the-art parsers, and evaluate the parsers against this data to measure their level of success in identifying these dependencies."
flickinger-etal-2010-wikiwoods,{W}iki{W}oods: Syntacto-Semantic Annotation for {E}nglish {W}ikipedia,2010,10,37,1,1,26293,dan flickinger,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"WikiWoods is an ongoing initiative to provide rich syntacto-semantic annotations for English Wikipedia. We sketch an automated processing pipeline to extract relevant textual content from Wikipedia sources, segment documents into sentence-like units, parse and disambiguate using a broad-coverage precision grammar, and support the export of syntactic and semantic information in various formats. The full parsed corpus is accompanied by a subset of Wikipedia articles for which gold-standard annotations in the same format were produced manually. This subset was selected to represent a coherent domain, Wikipedia entries on the broad topic of Natural Language Processing."
W08-1304,Toward a Cross-Framework Parser Annotation Standard,2008,13,0,1,1,26293,dan flickinger,Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation,0,"Efficient and precise comparison of parser results across frameworks will require a negotiated agreement on a target representation which embodies a good balance of three competing dimensions: consistency, clarity, and flexibility. The various annotations provided in the COLING-08 shared task for the ten 'required' Wall Street Journal sentences can serve as a useful basis for these negotations. While there is of course substantial overlap in the content of the various schemes for these sentences, no one of the schemes is ideal. This paper presents some desiderata for a negotiated target annotation scheme for which straightforward mappings can be constructed from each of the supplied annotation schemes."
adolphs-etal-2008-fine,Some Fine Points of Hybrid Natural Language Parsing,2008,25,31,5,0,34902,peter adolphs,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Large-scale grammar-based parsing systems nowadays increasingly rely on independently developed, more specialized components for pre-processing their input. However, different tools make conflicting assumptions about very basic properties such as tokenization. To make linguistic annotation gathered in pre-processing available to ÂdeepÂ parsing, a hybrid NLP system needs to establish a coherent mapping between the two universes. Our basic assumption is that tokens are best described by attribute value matrices (AVMs) that may be arbitrarily complex. We propose a powerful resource-sensitive rewrite formalism, Âchart mappingÂ, that allows us to mediate between the token descriptions delivered by shallow pre-processing components and the input expected by the grammar. We furthermore propose a novel way of unknown word treatment where all generic lexical entries are instantiated that are licensed by a particular token AVM. Again, chart mapping is used to give the grammar writer full control as to which items (e.g. native vs. generic lexical items) enter syntactic parsing. We discuss several further uses of the original idea and report on early experiences with the new machinery."
2007.tmi-papers.18,Towards hybrid quality-oriented machine translation {--} on linguistics and probabilities in {MT},2007,-1,-1,6,0.781758,2623,stephan oepen,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
W06-0502,Multilingual Ontology Acquisition from Multiple {MRD}s,2006,18,10,5,0,31491,eric nichols,Proceedings of the 2nd Workshop on Ontology Learning and Population: Bridging the Gap between Text and Knowledge,0,"In this paper, we outline the development of a system that automatically constructs ontologies by extracting knowledge from dictionary definition sentences using Robust Minimal Recursion Semantics (RMRS). Combining deep and shallow parsing resource through the common formalism of RMRS allows us to extract ontological relations in greater quantity and quality than possible with any of the methods independently. Using this method, we construct ontologies from two different Japanese lexicons and one English lexicon. We then link them to existing, handcrafted ontologies, aligning them at the word-sense level. This alignment provides a representative evaluation of the quality of the relations being extracted. We present the results of this ontology construction and discuss how our system was designed to handle multiple lexicons and languages."
2006.eamt-1.16,Identifying Complex Phenomena in a Corpus via a Treebank Lens,2006,-1,-1,1,1,26293,dan flickinger,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,None
U05-1001,Dimensions of Deep Grammar Validation,2005,9,0,1,1,26293,dan flickinger,Proceedings of the Australasian Language Technology Workshop 2005,0,"In order to arrive at a more disciplined approach to the sustained development of linguistically rich grammars, I present a methodology for grammar validation, identifying principal dimensions of the task, and illustrating the application of the method for one release cycle of the open-source English Resource Grammar."
I05-2035,Rapid Prototyping of Scalable Grammars: Towards Modularity in Extensions to a Language-Independent Core,2005,17,46,2,1,11448,emily bender,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"We present a new way to simplify the construction of precise broad-coverage grammars, employing typologicallymotivated, customizable extensions to a language-independent core grammar. Each xe2x80x98modulexe2x80x99 represents a salient dimension of cross-linguistic variation, and presents the grammar developer with simple choices that result in automatically generated language-specific software. We illustrate the approach for several phenomena and explore the interdependence of the modules."
2005.mtsummit-papers.22,{SEM}-{I} Rational {MT}: Enriching Deep Grammars with a Semantic Interface for Scalable Machine Translation,2005,11,15,1,1,26293,dan flickinger,Proceedings of Machine Translation Summit X: Papers,0,"In the LOGON machine translation system where semantic transfer using Minimal Recursion Semantics is being developed in conjunction with two existing broad-coverage grammars of Norwegian and English, we motivate the use of a grammar-specific semantic interface (SEM-I) to facilitate the construction and maintenance of a scalable translation engine. The SEM-I is a theoretically grounded component of each grammar, capturing several classes of lexical regularities while also serving the crucial engineering function of supplying a reliable and complete specification of the elementary predications the grammar can realize. We make extensive use of underspecification and type hierarchies to maximize generality and precision."
2005.mtsummit-osmtw.3,Open Source Machine Translation with {DELPH}-{IN},2005,0,27,5,0,6126,francis bond,Workshop on open-source machine translation,0,The Deep Linguistic Processing with HPSG Initiative (DELPH-IN) provides the infrastructure needed to produce open-source semantic transfer-based...
2005.eamt-1.27,Holistic regression testing for high-quality {MT}: some methodological and technological reflections,2005,-1,-1,3,1,2623,stephan oepen,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,None
copestake-etal-2004-lexicon,A Lexicon Module for a Grammar Development Environment,2004,7,11,5,0.57556,6790,ann copestake,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,Past approaches to developing an effective lexicon component in a grammar development environment have suffered from a number of usability and efficiency issues. We present a lexical database module currently in use by a number of grammar development projects. The database module presented addresses issues which have caused problems in the past and the power of a database architecture provides a number of practical advantages as well as a solid framework for future extension.
baldwin-etal-2004-road,Road-testing the {E}nglish {R}esource {G}rammar Over the {B}ritish {N}ational {C}orpus,2004,8,56,3,0,1468,timothy baldwin,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper addresses two questions: (1) when a large deep processing resource developed for relatively closed domains is run over open text, what coverage does it have, and (2) what are the most effective and time-efficient ways of consolidating gaps in the coverage of such as resource?"
2004.tmi-1.2,Som {\\aa} kapp-ete med trollet? {--} Towards {MRS}-based {N}orwegian-{E}nglish machine translation,2004,11,36,7,1,2623,stephan oepen,Proceedings of the 10th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,"We present a relatively large-scale initiative in high-quality MT based on semantic transfer, reviewing the motivation for this approach, general architecture and components involved, and preliminary experience from a first round of system integration (to be accompanied by a hands-on system demonstration, if appropriate)."
W02-1502,The Grammar Matrix: An Open-Source Starter-Kit for the Rapid Development of Cross-linguistically Consistent Broad-Coverage Precision Grammars,2002,18,154,2,1,11448,emily bender,{COLING}-02: Grammar Engineering and Evaluation,0,"The grammar matrix is an open-source starter-kit for the development of broad-coverage HPSGs. By using a type hierarchy to represent cross-linguistic generalizations and providing compatibility with other open-source tools for grammar engineering, evaluation, parsing and generation, it facilitates not only quick start-up but also rapid growth towards the wide coverage necessary for robust natural language processing and the precision parses and semantic representations necessary for natural language understanding."
W02-1508,Parallel Distributed Grammar Engineering for Practical Applications,2002,16,16,4,1,2623,stephan oepen,{COLING}-02: Grammar Engineering and Evaluation,0,"Based on a detailed case study of parallel grammar development distributed across two sites, we review some of the requirements for regression testing in grammar engineering, summarize our approach to systematic competence and performance profiling, and discuss our experience with grammar development for a commercial application. If possible, the workshop presentation will be organized around a software demonstration."
copestake-etal-2002-multiword,Multiword expressions: linguistic precision and reusability,2002,4,52,7,0.508937,6790,ann copestake,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper discusses the approach to multiword expressions being adopted in the LinGO English Resource Grammar (http://lingo.stanford.edu), a broad-scale bidirectional grammar of English in the HPSG framework. We discuss how the lexicon of multiword expressions is encoded in a database and describe the implications for building a reusable lexical resource."
C02-2025,The {L}in{GO} Redwoods Treebank: Motivation and Preliminary Applications,2002,19,117,5,1,2623,stephan oepen,{COLING} 2002: The 17th International Conference on Computational Linguistics: Project Notes,0,"The LinGO Redwoods initiative is a seed activity in the design and development of a new type of treebank. While several medium- to large-scale treebanks exist for English (and for other major languages), pre-existing publicly available resources exhibit the following limitations: (i) annotation is mono-stratal, either encoding topological (phrase structure) or tectogrammatical (dependency) information, (ii) the depth of linguistic information recorded is comparatively shallow, (iii) the design and format of linguistic representation in the treebank hard-wires a small, predefined range of ways in which information can be extracted from the treebank, and (iv) representations in existing treebanks are static and over the (often year- or decade-long) evolution of a large-scale treebank tend to fall behind the development of the field. LinGO Redwoods aims at the development of a novel treebanking methodology, rich in nature and dynamic both in the ways linguistic data can be retrieved from the treebank in varying granularity and in the constant evolution and regular updating of the treebank itself. Since October 2001, the project is working to build the foundations for this new type of treebank, to develop a basic set of tools for treebank construction and maintenance, and to construct an initial set of 10,000 annotated trees to be distributed together with the tools under an open-source license."
W01-1512,Using an Open-Source Unification-Based System for {CL}/{NLP} Teaching,2001,5,3,3,0,53792,anne copestake,Proceedings of the {ACL} 2001 Workshop on Sharing Tools and Resources,0,We demonstrate the open-source LKB system which has been used to teach the fundamentals of constraint-based grammar development to several groups of students.
P01-1019,An Algebra for Semantic Construction in Constraint-based Grammars,2001,7,121,3,0.403557,6790,ann copestake,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"We develop a framework for formalizing semantic construction within grammars expressed in typed feature structure logics, including HPSG. The approach provides an alternative to the lambda calculus; it maintains much of the desirable flexibility of unification-based approaches to composition, while constraining the allowable operations in order to capture basic generalizations and improve maintainability."
copestake-flickinger-2000-open,An Open Source Grammar Development Environment and Broad-coverage {E}nglish Grammar Using {HPSG},2000,32,235,2,0.807115,6790,ann copestake,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"The LinGO (Linguistic Grammars Online) projectxe2x80x99s English Resource Grammar and the LKB grammar development environment are language resources which are freely available for download for any purpose, including commercial use (see http://lingo.stanford.edu). Executable programs and source code are both included. In this paper, we give an outline of the LinGO English grammar and LKB system, and discuss the ways in which they are currently being used. The grammar and processing system can be used independently or combined to give a central component which can be exploited in a variety of ways. Our intention in writing this paper is to encourage more people to use the technology, which supports collaborative development on many levels."
1995.tmi-1.2,Translation using {M}inimal {R}ecursion {S}emantics,1995,-1,-1,2,0.537619,6790,ann copestake,Proceedings of the Sixth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
J92-3002,Inheritance and Complementation: a Case Study of Easy Adjectives and Related Nouns,1992,48,39,1,1,26293,dan flickinger,Computational Linguistics,0,"Mechanisms for representing lexically the bulk of syntactic and semantic information for a language have been under active development, as is evident in the recent studies contained in this volume. Our study serves to highlight some of themost useful tools available for structured lexical representation, in particular (multiple) inheritance, default specification, and lexical rules. It then illustrates the value of these mechanisms in illuminating one corner of the lexicon involving an unusual kind of complementation among a group of adjectives exemplified by easy. The virtues of the structured lexicon are its succinctness and its tendency to highlight significant clusters of linguistic properties. From its succinctness follow two practical advantages, namely its ease of maintenance and modification. In order to suggest how important these may be practically, we extend the analysis of adjectival complementation in several directions. These further illustrate how the use of inheritance in lexical representation permits exact and explicit characterizations of phenomena in the language under study. We demonstrate how the use of the mechanisms employed in the analysis of easy enables us to give a unified account of related phenomena featuring nouns such as pleasure, and even the adverbs (adjectival specifiers) too and enough. Along the way we motivate some elaborations of the HPSG (head-driven phrase structure grammar) framework in which we couch our analysis, and offer several avenues for further study of this part of the English lexicon."
