2009.jeptalnrecital-court.5,W04-2322,0,0.0343493,"Missing"
2009.jeptalnrecital-court.5,J05-2005,0,0.110676,"Missing"
2019.jeptalnrecital-court.1,Q17-1010,0,0.0257183,"Missing"
2019.jeptalnrecital-court.1,L16-1319,0,0.0641752,"Missing"
2019.jeptalnrecital-court.1,P14-5010,0,0.00471491,"Missing"
2019.jeptalnrecital-court.1,C12-1167,0,0.0528697,"Missing"
2019.jeptalnrecital-court.3,2009.jeptalnrecital-long.19,0,0.175793,"Missing"
2019.jeptalnrecital-court.3,2007.jeptalnrecital-long.9,0,0.130347,"Missing"
2019.jeptalnrecital-court.3,P09-1113,0,0.244352,"Missing"
2019.jeptalnrecital-court.3,J18-2001,1,0.827876,"Missing"
2019.jeptalnrecital-court.3,C12-1115,1,0.86751,"Missing"
2019.jeptalnrecital-court.3,N16-1013,1,0.900403,"Missing"
2019.jeptalnrecital-court.3,W04-2322,0,0.098493,"Missing"
2019.jeptalnrecital-court.3,2007.jeptalnrecital-long.37,0,0.104449,"Missing"
2019.jeptalnrecital-court.3,W13-4002,1,0.888754,"Missing"
afantenos-etal-2012-empirical,C10-1001,1,\N,Missing
afantenos-etal-2012-empirical,J00-3005,0,\N,Missing
afantenos-etal-2012-empirical,J96-1002,0,\N,Missing
afantenos-etal-2012-empirical,J95-2003,0,\N,Missing
afantenos-etal-2012-empirical,J05-2005,0,\N,Missing
afantenos-etal-2012-empirical,prasad-etal-2008-penn,0,\N,Missing
afantenos-etal-2012-empirical,J86-3001,0,\N,Missing
afantenos-etal-2012-empirical,W04-2322,0,\N,Missing
afantenos-etal-2012-empirical,2009.jeptalnrecital-court.23,0,\N,Missing
C08-2002,W07-1515,0,\N,Missing
C10-1001,P09-1075,0,\N,Missing
C12-1115,afantenos-etal-2012-empirical,1,0.465285,"Missing"
C12-1115,W05-0613,0,0.375219,"Missing"
C12-1115,P09-1075,0,0.242414,"Missing"
C12-1115,P12-1007,0,0.252293,"Missing"
C12-1115,W10-0906,0,0.0364718,"Missing"
C12-1115,D12-1083,0,0.122087,"Missing"
C12-1115,D09-1036,0,0.0316192,"Missing"
C12-1115,P11-1100,0,0.0274662,"Missing"
C12-1115,W10-4310,0,0.00580537,"Missing"
C12-1115,P02-1047,0,0.183084,"Missing"
C12-1115,H05-1066,0,0.324517,"Missing"
C12-1115,P09-1108,0,0.0310392,"Missing"
C12-1115,prasad-etal-2008-penn,0,0.0252028,"Missing"
C12-1115,W09-3813,0,0.534127,"Missing"
C12-1115,N03-1030,0,0.51331,"Missing"
C12-1115,N09-1064,0,0.116075,"Missing"
C12-1115,W06-1317,0,0.184087,"Missing"
C12-1115,D09-1018,0,\N,Missing
C12-1115,W01-1605,0,\N,Missing
C14-1206,P98-1013,0,0.604436,"Missing"
C14-1206,candito-etal-2010-statistical,0,0.0203741,"), alternation (ou/or), commentary (au fait/by the way), rephrasing (du moins/at least), and evidence (effectivement/indeed). We searched our syntactically parsed corpus for connectors. When a connector is found and its syntactic category verified, if it is close enough to the root of the sentence (at most one dependency link from the root), we look for an inter-sentential link. The first verb of our pair corresponds in this case 1. 2. 3. 4. Available as an SQLite database at https://dl.dropboxusercontent.com/u/78938139/v2r_db http://alpage.inria.fr/statgram/frdep/fr_stat_dep_parsing.html or (Candito et al., 2010) Freely available at : https://gforge.inria.fr/frs/download.php/31052/lexconn.tar.gz. We illustrate each relation with examples of potentially ambiguous markers. 2185 to the last verb of the previous sentence in the case of connectors for narration, or to its main verb for all the other relations. We search for the second verb in the pair within a window of two dependency links after the connector. If the connector is not close enough to the root of the sentence, we look for a intra-sentential link. In this case, we look for the two verbs of the pair in the same sentence within a forward and b"
C14-1206,J96-2004,0,0.228852,"of context evaluation For out of context judgments, we adopted the following protocol : one of the authors chose for each relation 100 verbs with equivalent proportions of good and bad normalized PMI scores. Then the other 6. We simplified their measure by ignoring IDF (inverse document frequency) and the distance between the verbs, as neither measure applies to our task. 2187 three authors judged the validity of associating each of the 300 pairs with the corresponding relation, without any knowledge of the source of these pairs. We measured the inter-annotator agreements with Cohen’s Kappa (Carletta, 1996), which resulted in : 0.17 for cause, 0.42 for narration and 0.56 for contrast as mean values. If a 0.6 kappa serves a measure for a feasible semantic judgment task, out of context judgments appear very difficult, with only contrastive pairs as a relative exception. We decided to only consider judgments about contrast, after an adjudication phase, and we evaluated the measures presented in section 3 to see if they could discriminate between the two verb groups, those judged positively or negatively according to human annotations. A MannWhitney U statistical test showed all of our measures to b"
C14-1206,P08-1090,0,0.0560942,"Missing"
C14-1206,W04-3205,0,0.544983,"extraction. 1 Introduction Relational lexical resources, which describe semantic relations between lexical items, have traditionally focused on relations like synonymy or similarity in thesauri, perhaps including some hierarchical semantic relations like hyperonymy or hyponomy or part-whole relations as in the resource Wordnet (Felbaum, 1998). Some distributional thesauri contain more varied relations, see e.g. (Grefenstette, 1994), however these relations are not typed. The lexical semantics given by FrameNet (Baker et al., 1998) does include causal and temporal relations, as does Verbocean (Chklovski and Pantel, 2004), but coverage is limited and empirical validation of these resources is partial and still largely remains to be done. Lexical relations, in particular between verbs, are nevertheless crucial for understanding natural language and for many information processing tasks. They are needed for textual inference, in which one has to infer certain relations between eventualities (Hashimoto et al., 2009; Tremper and Frank, 2013), for information extraction tasks, like finding temporal relations between eventualities mentioned in a text (UzZaman et al., 2013), for automatic summarization (Liu et al., 2"
C14-1206,D11-1027,0,0.245803,"ence of explicit discourse markers (Sporleder and Lascarides, 2008). In this paper we report on our efforts to extract semantic relations essential to the analysis of discourse and its interpretation, in which links are made between units of text or rather their semantic representations as in (1) in virtue of semantic information about the two main verbs of those clauses. (1) The candidate demonstrated his expertise during the interview. The committee was completely convinced. We follow similar work on the extraction of causal, temporal, entailment and presuppositional relations from corpora (Do et al., 2011; Chambers and Jurafsky, 2008; Hashimoto et al., 2009; Tremper and Frank, 2013), though our goals and validation methods are different. While one of our goals is to use this information to improve performance in predicting discourse relations between clauses, we believe that such a lexical resource will have other uses in other tasks in which semantic information is needed. Discourse analysis is a difficult task. Rhetorical relations are frequently implicit and require for their identification inference using diverse sources of lexical and compositional semantic information. In the Penn Discou"
C14-1206,P12-1007,0,0.0257762,"scourse relations. An inductive logic programming approach is finally used exploiting the interaction between causal pairs and discourse relations in order to extract causal links. Those papers focus on specific relations with the exception of Chklovski and Pantel (2004) who do not present a systematic evaluation of their results. An important difference of our approach is also to consider predicates and their negation as separate entries. Finally, we mention the approaches which while focusing on the learning of discourse structures, nonetheless enrich their systems with lexical information. Feng and Hirst (2012) have used H ILDA (Hernault et al., 2010) adding more features. A specific family of features represents lexical similarity based on the hierarchical distance in V ERB N ET and W ORD N ET. In a similar fashion, Wellner et al. (2006) focus on intra-sentential discourse relations adding lexical information on the features based on measures proposed by Lin (1998) calculated on the British National Corpus. Those approaches use thus only information on lexical similarity without semantically typing this link. The impact of this information seems limited. As far as evaluation is concerned, our metho"
C14-1206,D09-1122,0,0.0381845,"Missing"
C14-1206,W12-4107,0,0.0135779,"hklovski and Pantel (2004), for example, rely on specific patterns constructed manually for each semantic relation between (similarity, strength, antonymy, enablement and temporal happens-before). They use the web as a corpus in order to estimate the PMI between a pattern and a pair of verbs (a precise measurement cannot be achieved over the web since the probability of a pattern is not precisely known over all the web). A threshold on the value of the PMI (manually fixed) permits thus to determine the pairs of verbs that are related to the relation denoted by the pattern. In the same spirit, Kozareva (2012) is using a weakly supervised approach for the extraction of pairs of verbs that are potentially implied in a cause-effect relation. Her method consists in using patterns applied to the web in order to extract pairs and generate new seeds. Do et al. (2011) focus on causal relations and take into account not only verbs but also event denoting nouns. According to this paper, an event is denoted by a predicate with a specific number of arguments and thus the association of the events is the sum of the association between predicates, between predicates and arguments and between arguments. Their as"
C14-1206,C02-1144,0,0.0913723,"se mutual information) and their variants, as well as some measures specific to the association of a causal relation between items (Do et al., 2011). We also experimented with a new measure specifically designed for our knowledge base. Measures of lexical association used in research on co-occurrences in distributional semantics pick out significant associations, taking into account the frequency of the related items. We examined over 10 measures ; we discuss the ones with the best results (see section 4). One simple measure, PMI, and its variants, normalized, local (Evert, 2005), discounted (Lin and Pantel, 2002), which are designed to reduce biases in the original measure, work well. The idea behind PMI is to estimate whether the probability of the co-occurrence of two items is greater than the a priori probability of the two items appearing independently. In distributional semantics, the measure is also used to estimate the significance of two items co-occurring with a particular grammatical dependency relation like the subject or object relation between an NP and a verb. This use of PMI measures over triples in distributional semantics fits perfectly with our task of measuring the significance of t"
C14-1206,P98-2127,0,0.0960764,"is also to consider predicates and their negation as separate entries. Finally, we mention the approaches which while focusing on the learning of discourse structures, nonetheless enrich their systems with lexical information. Feng and Hirst (2012) have used H ILDA (Hernault et al., 2010) adding more features. A specific family of features represents lexical similarity based on the hierarchical distance in V ERB N ET and W ORD N ET. In a similar fashion, Wellner et al. (2006) focus on intra-sentential discourse relations adding lexical information on the features based on measures proposed by Lin (1998) calculated on the British National Corpus. Those approaches use thus only information on lexical similarity without semantically typing this link. The impact of this information seems limited. As far as evaluation is concerned, our method is similar to that followed in Tremper and Frank (2013) for implication relations combining in and out of context evaluation for verbal associations. Their inter-annotator agreement is similar to ours (0.42-0.44 of Kappa) with very different choices : the anno2191 tators were supposed to discriminate verbal links between the different possible sub-cases. The"
C14-1206,P07-2047,0,0.0261752,"Missing"
C14-1206,P02-1047,0,0.170163,"k. The first group aims to alleviate the lack of annotated data for discourse parsing by using a weakly supervised approach, exploiting the presence of discourse connectors in a large non-annotated corpus. Each pair of elementary discourse units is automatically annotated with the discourse relation triggered by the presence of the connector (connectors are often filtered for non-discursive uses). Those connectors are afterwards eliminated from the corpus so that the model trained on this dataset will not be informed by the presence of those connectors. The pioneering article in this group is Marcu and Echihabi (2002). Such learning methods with such “artificial data” obtain low scores, barely above chance as shown in Sporleder and Lascarides (2008). Braud and Denis (2013) observe that the performance of a classifier for the prediction of implicit relations is much lower when using “artificial” data than on “natural” data (implicit relations annotated by a human being). They propose a method which exploits these two different kinds of datasets together in various mixtures and on the level of the prediction algorithm, obtaining thus a significant improvement on the Annodis corpus. Our approach is different"
C14-1206,N13-1024,0,0.0648113,"as : PMI = log( P (V1 , V2 , R) ) P (V1 ) × P (V2 ) × P (R) PMI _normalized = PMI −2 log(P (V1 , V2 , R)) Indeed, when we have a complete co-occurrence of the three items, we have : P (V1 ) = P (V2 ) = P (R) = P (V1 , V2 , R), and PMI = −2 log(P (V1 , V2 , R)). The values of normalized PMI lie between −1 and 1, approaching −1 when the items never appear together, taking the value 0 in the case of independence, and the value 1 when they always appear together. We also considered a weighted PMI measure (Lin and Pantel, 2002) that corrects the bias of PMI for rare triples. A specificity measure (Mirroshandel et al., 2013), originally used to measure the precision of subcategorization frames, also performed well : specificity = 1 P (V1 , V2 , R) P (V1 , V2 , R) P (V1 , V2 , R) × (P +P +P ) 3 P (V1 , Vi , R) P (Vi , V2 , R) P (V1 , V2 , Ri ) i i i A version of Do et al. (2011)’s measure for triples involving causal relations did not fare so well on other types of relation. The definition of the measure can be found in (Do et al., 2011). 6 Finally, we investigated a measure that evaluates the contribution of each element in the triple to the significance measure (this measure is similar to specificity). 1 Wcombin"
C14-1206,C12-1115,1,0.863642,"Missing"
C14-1206,prasad-etal-2008-penn,0,0.210684,"on the .fr domain. We first parsed the documents in our corpus using BONSAI 2 , which first produced a morpho-syntactic labeling using MElt (Denis and Sagot, 2012) and then a syntactic analysis in the form of dependency trees via a French version of the MaltParser (Nivre et al., 2007). Our goal is to find pairs of verbs linked by a relation explicitly marked by a discourse connector in the corpus, as an indication of a regular semantic relation between the two verbs. The relations we have considered are common to most theories of discourse analysis, and they can be grouped into four classes (Prasad et al., 2008) : causal (contingency) relations, temporal relations, comparison relations (mainly contrast type relations), and expansion relations (e.g. elaboration or continuation). To find explicitly marked relations, we used a lexicon of discourse connectors for French, the manually constructed LEXCONN resource (Roze et al., 2012) 3 . LEXCONN includes 358 connectors and gives their syntactic category as well as associated discourse relations inspired from (Asher and Lascarides, 2003). Some connectors are ambiguous in that they are associated with several relations. We used only the unambiguous connector"
C14-1206,sagot-2010-lefff,0,0.0685602,"Missing"
C14-1206,S13-2001,0,0.114442,"large non-annotated corpus. Each pair of elementary discourse units is automatically annotated with the discourse relation triggered by the presence of the connector (connectors are often filtered for non-discursive uses). Those connectors are afterwards eliminated from the corpus so that the model trained on this dataset will not be informed by the presence of those connectors. The pioneering article in this group is Marcu and Echihabi (2002). Such learning methods with such “artificial data” obtain low scores, barely above chance as shown in Sporleder and Lascarides (2008). Braud and Denis (2013) observe that the performance of a classifier for the prediction of implicit relations is much lower when using “artificial” data than on “natural” data (implicit relations annotated by a human being). They propose a method which exploits these two different kinds of datasets together in various mixtures and on the level of the prediction algorithm, obtaining thus a significant improvement on the Annodis corpus. Our approach is different and complementary ; we isolate the semantic relations between pairs of verbs. We can use that as a feature on discourse units for discourse parsing but it has"
C14-1206,W06-1317,0,0.0561899,"xception of Chklovski and Pantel (2004) who do not present a systematic evaluation of their results. An important difference of our approach is also to consider predicates and their negation as separate entries. Finally, we mention the approaches which while focusing on the learning of discourse structures, nonetheless enrich their systems with lexical information. Feng and Hirst (2012) have used H ILDA (Hernault et al., 2010) adding more features. A specific family of features represents lexical similarity based on the hierarchical distance in V ERB N ET and W ORD N ET. In a similar fashion, Wellner et al. (2006) focus on intra-sentential discourse relations adding lexical information on the features based on measures proposed by Lin (1998) calculated on the British National Corpus. Those approaches use thus only information on lexical similarity without semantically typing this link. The impact of this information seems limited. As far as evaluation is concerned, our method is similar to that followed in Tremper and Frank (2013) for implication relations combining in and out of context evaluation for verbal associations. Their inter-annotator agreement is similar to ours (0.42-0.44 of Kappa) with ver"
C14-1206,C98-1013,0,\N,Missing
C14-1206,C98-2122,0,\N,Missing
C14-1206,afantenos-etal-2012-empirical,1,\N,Missing
C86-1127,E83-1009,0,0.0585918,"Missing"
D13-1035,Q13-1005,0,0.0263927,"adapt their algorithm from coherence relations to unary dialogue acts. Further, while they assume that preferences are given, here we apply versions of the NLP techniques from Cadilhac et al (2012) to estimate the preferences of EDUs automatically. And we go further than any of these works by using the elicited preferences to infer the domain-level actions that result from information exchanged in the conversation. In this respect, our work relates to models for grounding language, where semantic parsing techniques are used to automatically map linguistic instructions to domain-level actions (Artzi and Zettlemoyer, 2013; Kim and Mooney, 2013). Our domain of application is more challenging, however: to our knowledge, this is the first attempt to map non-cooperative dialogues into predictions about domain-level actions. We can tackle these strategic scenarios because we exploit a logic of preferences as part of our model, yielding inferences about rational action even when agents’ preferences conflict. Compared to previous work, our task is new. Our aim is not to predict what dialogue act to perform next, but what non verbal action should be performed, mapping dialogue acts to non verbal actions. The differenc"
D13-1035,I11-1132,1,0.757664,"position of the speaker’s first turn in the dialogue. We have 15 unigram and bigram features (at levels 0 and -1), as well as templates that combine feature values for the two levels. These include 14 boolean features that indicate if the EDU contains: bargaining verbs (e.g. trade, offer), references to another player (e.g. you), resource tokens as encoded in a task dedicated lexicon (e.g. wheat, clay), quantifiers (e.g. one, none), anaphoric pronouns, occurrences of “for” prepositional phrases (e.g. wheat for clay), acceptance words (e.g. OK), negation words, emoticons, opinion words (from (Benamara et al., 2011)), words of politeness, exclamation marks, questions, and finally whether the EDU’s speaker has talked previously in the dialogue. The last feature gives the EDU speaker lemma. In addition, 3 unigram and bigram booleans indicate whether the current EDU contains the most frequent tokens, couple of tokens and syntactic patterns in our corpus. Finally, we use 2 composed bigram features that encode whether the EDU contains an acceptance or refusal word, given that the previous EDU is a question. To assign sequential tags of dialogue acts within a negotiation dialogue, we use the CRF++ tool (crfpp."
D13-1035,W11-2023,1,0.906158,"s of resources in the EDUs (Givable, etc.) to identify the preference that a speaker conveys in the EDU, and we use the dialogue acts (Offer, Accept, etc.) to update a model of the preferences expressed so far in the dialogue with this new preference (see Section 5.2). Our model of preferences consists of a set of partial CP-nets, one for each player (see Section 5.1 for details). The resulting CP-nets are then used to infer the executed trading action (if any) automatically, via wellunderstood principles from game theory for identifying rational behavior (Bonzon, 2007). 5.1 CP-Nets Following Cadilhac et al. (2011), we use CP-nets (Boutilier et al., 2004) to model preferences and their dependencies. CP-nets are compatible with the kind of partial information about preferences that utterances reveal, and inference with CP-nets is com361 putationally efficient. Just as Bayesian nets are a graphical model that exploits probabilistic conditional independence to provide a compact representation of a joint probability distribution (Pearl, 1988), CP-nets are a graphical model that exploits conditional preferential independence to provide a compact representation of the preference order over all outcomes. The C"
D13-1035,2005.sigdial-1.9,0,0.0601039,"Missing"
D13-1035,W02-0213,0,0.0928596,"Missing"
D13-1035,P13-1022,0,0.0245899,"herence relations to unary dialogue acts. Further, while they assume that preferences are given, here we apply versions of the NLP techniques from Cadilhac et al (2012) to estimate the preferences of EDUs automatically. And we go further than any of these works by using the elicited preferences to infer the domain-level actions that result from information exchanged in the conversation. In this respect, our work relates to models for grounding language, where semantic parsing techniques are used to automatically map linguistic instructions to domain-level actions (Artzi and Zettlemoyer, 2013; Kim and Mooney, 2013). Our domain of application is more challenging, however: to our knowledge, this is the first attempt to map non-cooperative dialogues into predictions about domain-level actions. We can tackle these strategic scenarios because we exploit a logic of preferences as part of our model, yielding inferences about rational action even when agents’ preferences conflict. Compared to previous work, our task is new. Our aim is not to predict what dialogue act to perform next, but what non verbal action should be performed, mapping dialogue acts to non verbal actions. The difference between our work and"
D13-1035,D10-1084,0,0.022097,"FP FN TN WP Accuracy 10 43 154 15 73.4 Table 5: Results for the end to end trade prediction. 365 6 6.1 Related Work Dialogue act modeling Most work on dialogue act modeling focuses on spoken dialogue (Stolcke et al., 2000; Fern´andez et al., 2005; Keizer et al., 2002). But live chats introduce specific complications (Kim et al., 2012): ill-formed data, abbreviations and acronyms, emotional indicators and entanglement (especially for multi-party chat). Among related work in this emerging field, Joty et al. (2011) use unsupervised learning to model dialogue acts in Twitter, Ivanovic (2008) and Kim et al. (2010) analyze one-to-one online chat in a customer service domain, and Wu et al. (2002) and Kim et al. (2012) predict dialogue acts in a multi-party setting. We used a similar classifier to predict dialogue acts as the one reported in (Kim et al., 2012) and evaluation yields similar results. This paper proposes an approach to dialogue act identification in online chat that aims to predict strategic actions like bargaining. Compared to (Sidner, 1994) and DAMSL (Core and Allen, 1997), our domain level annotation is much more detailed: we not only predict moves like Accept but also features like the G"
D13-1035,Y12-1050,0,0.0151934,"asks: automatically identifying each EDU’s dialogue act; detecting the EDU’s resources; and specifying the attributes of those resources (i.e., Givable, Receivable, etc.). 359 4.1 Identifying dialogue acts As is well established, one EDU’s dialogue act depends on previous dialogue acts (Stolcke et al., 2000). In our corpus, Accept or Reject frequently follow Offer and Counteroffer. Since labeling is sequential, we use Conditional Random Fields (CRFs) to learn dialogue acts. CRFs have been shown to yield better results in dialogue act classification on online chat than HMM-SVN and Naive Bayes (Kim et al., 2012). We use three types of features: lexical, syntactic and semantic. And we exploit them as unigrams and bigrams: unigrams associate the value of the feature with the current output class (level 0); bigrams take account of the value of the feature associated with a combination of the current output class and previous output class (level -1). 6 features were used exclusively as unigrams: the EDU’s position in the dialogue, its first and last words, its subject lemma, a boolean feature to indicate if the current speaker is the one that initiates the dialogue and the position of the speaker’s first"
D13-1035,P03-1054,0,0.009038,"Missing"
D13-1035,J00-3003,0,0.154358,"unknown values: the annotation tool inserts a ? in these cases. We also insist that the annotators resolve anaphoric dependencies when specifying values to attributes, as shown in EDU (4) in Table 1. 4 Dialogue act and resource prediction Predicting the executed trades from the dialogues starts with three sub-tasks: automatically identifying each EDU’s dialogue act; detecting the EDU’s resources; and specifying the attributes of those resources (i.e., Givable, Receivable, etc.). 359 4.1 Identifying dialogue acts As is well established, one EDU’s dialogue act depends on previous dialogue acts (Stolcke et al., 2000). In our corpus, Accept or Reject frequently follow Offer and Counteroffer. Since labeling is sequential, we use Conditional Random Fields (CRFs) to learn dialogue acts. CRFs have been shown to yield better results in dialogue act classification on online chat than HMM-SVN and Naive Bayes (Kim et al., 2012). We use three types of features: lexical, syntactic and semantic. And we exploit them as unigrams and bigrams: unigrams associate the value of the feature with the current output class (level 0); bigrams take account of the value of the feature associated with a combination of the current o"
D15-1109,afantenos-etal-2012-empirical,1,0.36216,"Missing"
D15-1109,D12-1083,0,0.0469426,"tract al., 2008), focuses on decisions about the discourse connectives that label the attachment of potentially arbitrary text spans but does not make any claims as to what the overall discourse structure of the resulting annotation looks like. Further, all computational work on the PDTB takes the attachments as given in discourse parsing tasks. In both cases, the attachment problem, finding which discourse units are attached to which, is vastly simplified, though this has enabled researchers to explore various approaches for discourse parsing (Marcu, 2000; Sagae, 2009; Hernault et al., 2010; Joty et al., 2012). Our paper’s main contribution is to provide a discourse parsing model for multi-party chat dialogue (i.e. typed online dialogue), trained on a large corpus we have developed annotated with full discourse structures. We study attachment problem in detail for this genre, without using the simplifying hypotheses mentioned above that we know to be inadequate. In the following section, we describe the Settlers of Catan game and our corpus in more detail and discuss some problematic structures for discourse parsing from our corpus. We motivate our choice of a particular discourse theory, the Segme"
D15-1109,P13-1048,0,0.0212985,". The first one concerns the learning of a model for intra-turn utterances,2 while the second models inter-turn utterances. The intra-turn model considers as input during learning all pairs of EDUs (i, j) with i 6= j. The inter-turn model on the other hand does not contain any backward links during learning. In other words it takes as input all pairs of EDUs (i, j) with i < j. We apply the turn constraint not only during learning of the local models, but also during decoding. This practice is also followed—at the sentence level—for monologues (Wellner and Pustejovsky, 2007; Joty et al., 2012; Joty et al., 2013), though our turn constraint, we believe, is firmly supported not only by our data but also by a good theoretical model of dialogue. set of SDRT relations. The upshot of this is that we are building a local sort of model that learns relations between individual EDUs with a certain probability but that it does not learn a local or even global structure. One of the drawbacks of this approach, however, is that it does not guarantee an object that is well formed. Learning a probability distribution over EDUs and then choosing the most probable relation or attachment for each pair of EDUs potential"
D15-1109,P09-1075,0,0.0474273,"usible alternative to MST on DAGs. pendence of local attachment decisions. There is also work on discourse structure within a single sentence; e.g., Soricut and Marcu (2003) makes use of dynamic programming along with a standard bottom-up chart parsing, while Sagae (2009) uses shift-reduce algorithm for intra-sentential discourse analysis. Such approaches do not apply to our data, as most of the structure in our dialogues lies beyond the sentence level. As for document-level discourse parsers, Subba and Di Eugenio (2009) use a transition-based approach, following the paradigm of Sagae (2009). duVerle and Prendinger (2009) and Hernault et al. (2010) both rely on locally greedy methods. Like us, they treat attachment prediction and relation label prediction as independent problems. Feng and Hirst (2012) extend this approach by additional feature engineering but is restricted to sentence-level parsing. Finally, Joty et al. (2012) present a sentence-level discourse parser that uses Conditional Random Fields to capture label interdependencies and chart parsing for decoding. Joty et al. (2013) and Joty et al. (2015) extend this approach on the level of documents and have the best results non-dependency based discour"
D15-1109,J15-3002,0,0.0142091,"Missing"
D15-1109,P14-1003,0,0.447967,"respectively. In this paper we present the first ever, to the best of our knowledge, discourse parser for multi-party chat dialogues. Discourse in multi-party dialogues dramatically differs from monologues since threaded conversations are commonplace rendering prediction of the discourse structure compelling. Moreover, the fact that our data come from chats renders the use of syntactic and lexical information useless since people take great liberties in expressing themselves lexically and syntactically. We use the dependency parsing paradigm as has been done in the past (Muller et al., 2012; Li et al., 2014). We learn local probability distributions and then use MST for decoding. We achieve 0.680 F1 on unlabelled structures and 0.516 F1 on fully labeled structures which is better than many state of the art systems for monologues, despite the inherent difficulties that multi-party chat dialogues have. 1 Introduction Discourse parsing is a difficult, multifaceted problem involving the understanding and modeling of various semantic and pragmatic phenomena as well as understanding the structural properties that a discourse graph can have. Unsurprisingly, most extant theories and computational approac"
D15-1109,C96-1058,0,0.0415699,"roduce this technique is Muller et al. (2012), working with a small French language corpus, A NN ODIS (Afantenos et al., 2012a). They use a similar approach to us, including the classic version of the MST decoder. They also used an A∗ search as another decoding mechanism but it gave the same results as MST. As we have said, our results better theirs both on attachment and full labeled structures. In the context of RST, Hirao et al. (2013) and Li et al. (2014) transform RST trees into dependency structures; we have discussed their in section 4.1. Li et al. (2014) use both the Eisner algorithm (Eisner, 1996) as well as the MST algorithm from McDonald et al. (2005). As we mentioned, our labelled scores are higher than theirs, though we are cautious of making comparisons across such different corpora. Most work on discourse parsing focuses on the task of discourse relation labeling between pairs of discourse units—e.g., Marcu and Echihabi (2002) Sporleder and Lascarides (2005) and Lin et al. (2009). This corresponds to our local model. As we have shown in this paper, this setting makes an unwarranted assumption, as it assumes indeThe best results for the global parsing problem exploited the turn co"
D15-1109,D09-1036,0,0.0404142,"Missing"
D15-1109,J10-3004,0,0.0286739,"o last gives us an F-score of 0.584 for attachment and 0.391 when we add the relations as well. Using only classification from the local probability distribution without decoding gives 0.541 for attachment and 0.446 for attachments and relations. 6 Related Work To date, discourse parsing has almost exclusively been applied to monologue. Multi-party chat dialogues have never been considered before. Baldridge and Lascarides (2005) predicted tree discourse structures for 2 party “directed” dialogues from the Verbmobil corpus by training a PCFG that exploited the structure of the underlying task. Elsner and Charniak (2010), Elsner and Charniak (2011) are presenting a combination of local coherence models initially provided for monologues showing that those models can satisfactorily model local coherence in chat dialogues. Nonetheless they do not present a full-fledged discourse parsing model. Our data required a more open domain approach and a more sophisticated approach to structure. Our use of dependency parsing for learning discourse structure has a few antecedents in the literature on monologue. One of the first papers to introduce this technique is Muller et al. (2012), working with a small French language"
D15-1109,P11-1118,0,0.0541483,"f 0.584 for attachment and 0.391 when we add the relations as well. Using only classification from the local probability distribution without decoding gives 0.541 for attachment and 0.446 for attachments and relations. 6 Related Work To date, discourse parsing has almost exclusively been applied to monologue. Multi-party chat dialogues have never been considered before. Baldridge and Lascarides (2005) predicted tree discourse structures for 2 party “directed” dialogues from the Verbmobil corpus by training a PCFG that exploited the structure of the underlying task. Elsner and Charniak (2010), Elsner and Charniak (2011) are presenting a combination of local coherence models initially provided for monologues showing that those models can satisfactorily model local coherence in chat dialogues. Nonetheless they do not present a full-fledged discourse parsing model. Our data required a more open domain approach and a more sophisticated approach to structure. Our use of dependency parsing for learning discourse structure has a few antecedents in the literature on monologue. One of the first papers to introduce this technique is Muller et al. (2012), working with a small French language corpus, A NN ODIS (Afanteno"
D15-1109,P14-5010,0,0.00282118,"Missing"
D15-1109,P12-1007,0,0.0641479,"mic programming along with a standard bottom-up chart parsing, while Sagae (2009) uses shift-reduce algorithm for intra-sentential discourse analysis. Such approaches do not apply to our data, as most of the structure in our dialogues lies beyond the sentence level. As for document-level discourse parsers, Subba and Di Eugenio (2009) use a transition-based approach, following the paradigm of Sagae (2009). duVerle and Prendinger (2009) and Hernault et al. (2010) both rely on locally greedy methods. Like us, they treat attachment prediction and relation label prediction as independent problems. Feng and Hirst (2012) extend this approach by additional feature engineering but is restricted to sentence-level parsing. Finally, Joty et al. (2012) present a sentence-level discourse parser that uses Conditional Random Fields to capture label interdependencies and chart parsing for decoding. Joty et al. (2013) and Joty et al. (2015) extend this approach on the level of documents and have the best results non-dependency based discourse parsing, with an F1 of 0.689 on unlabelled structures and 0.5587 on labelled structures. Our scores are very close to Joty et al.’s, however, and achieved with much simpler methods"
D15-1109,P02-1047,0,0.0233897,"results better theirs both on attachment and full labeled structures. In the context of RST, Hirao et al. (2013) and Li et al. (2014) transform RST trees into dependency structures; we have discussed their in section 4.1. Li et al. (2014) use both the Eisner algorithm (Eisner, 1996) as well as the MST algorithm from McDonald et al. (2005). As we mentioned, our labelled scores are higher than theirs, though we are cautious of making comparisons across such different corpora. Most work on discourse parsing focuses on the task of discourse relation labeling between pairs of discourse units—e.g., Marcu and Echihabi (2002) Sporleder and Lascarides (2005) and Lin et al. (2009). This corresponds to our local model. As we have shown in this paper, this setting makes an unwarranted assumption, as it assumes indeThe best results for the global parsing problem exploited the turn constraint both during learning the local model and during decoding. Within a turn, our discourse structures are simple and largely linear; the best intra-turn results came from using Last. Most of our interlocutors did not create elaborate discourse structures with long-distance attachments within the same turn. The inter-turn level was a di"
D15-1109,H05-1066,0,0.166495,"the baseline L AST, where each EDU is attached to the immediately preceding EDU in the linear, textual order. 2 EDU s are considered as belonging to the same turn if they are by the same speaker without any interjection from an other speaker. In other words any consecutive EDU by the same speaker is considered as belonging to the same turn. 932 Maximum Spanning Trees To answer our questions, “how many non-tree-like structures are there?"" and ""how far can tree decoding algorithms get us in multi-party dialogue?"", our first decoder is the classic Maximum Spanning Trees (MST) algorithm— used by McDonald et al. (2005) for syntactic dependency parsing as well as by Muller et al. (2012) and Li et al. (2014) for discourse parsing—tweaking it in order to produce structures that are closer to the ones specific to multiparty dialogue. We are looking for: T∗ = argmax X T a spanning tree of G  w(e) = log w(e) e∈E(T ) p(e) 1 − p(e)  G being the complete graph of possible edges returned by the classifiers ; E(D) representing the edges of D. The weight function w computes the log-odds of the probability returned by the model. We used Chu-Liu-Edmonds version of the MST algorithm (Chu and Liu, 1965; Edmonds, 1967), w"
D15-1109,D13-1158,0,0.168211,"Missing"
D15-1109,C12-1115,1,0.854617,"d in sections 6 and 7 respectively. In this paper we present the first ever, to the best of our knowledge, discourse parser for multi-party chat dialogues. Discourse in multi-party dialogues dramatically differs from monologues since threaded conversations are commonplace rendering prediction of the discourse structure compelling. Moreover, the fact that our data come from chats renders the use of syntactic and lexical information useless since people take great liberties in expressing themselves lexically and syntactically. We use the dependency parsing paradigm as has been done in the past (Muller et al., 2012; Li et al., 2014). We learn local probability distributions and then use MST for decoding. We achieve 0.680 F1 on unlabelled structures and 0.516 F1 on fully labeled structures which is better than many state of the art systems for monologues, despite the inherent difficulties that multi-party chat dialogues have. 1 Introduction Discourse parsing is a difficult, multifaceted problem involving the understanding and modeling of various semantic and pragmatic phenomena as well as understanding the structural properties that a discourse graph can have. Unsurprisingly, most extant theories and com"
D15-1109,prasad-etal-2008-penn,0,0.0608184,"Missing"
D15-1109,W09-3813,0,0.0605521,"use {firstname.lastname@irit.fr} Abstract al., 2008), focuses on decisions about the discourse connectives that label the attachment of potentially arbitrary text spans but does not make any claims as to what the overall discourse structure of the resulting annotation looks like. Further, all computational work on the PDTB takes the attachments as given in discourse parsing tasks. In both cases, the attachment problem, finding which discourse units are attached to which, is vastly simplified, though this has enabled researchers to explore various approaches for discourse parsing (Marcu, 2000; Sagae, 2009; Hernault et al., 2010; Joty et al., 2012). Our paper’s main contribution is to provide a discourse parsing model for multi-party chat dialogue (i.e. typed online dialogue), trained on a large corpus we have developed annotated with full discourse structures. We study attachment problem in detail for this genre, without using the simplifying hypotheses mentioned above that we know to be inadequate. In the following section, we describe the Settlers of Catan game and our corpus in more detail and discuss some problematic structures for discourse parsing from our corpus. We motivate our choice"
D15-1109,W03-2106,0,0.112429,"Missing"
D15-1109,N03-1030,0,0.0274768,".955 0.516 0.892 0.562 0.808 0.616 0.922 0.514 0.861 0.561 0.489 0.492 0.558 0.411 0.521 0.448 G LOBAL 0.697 0.663 0.680 0.688 0.655 0.671 0.529 0.503 0.516 Table 3: Evaluation results. gorithm, and an enhanced version of it in order to produce structures closer to the ones we observe. We obtain the best results using the enhanced version of the MST algorithm. In future work, we plan to investigate ILP constraints in greater depth to develop a plausible alternative to MST on DAGs. pendence of local attachment decisions. There is also work on discourse structure within a single sentence; e.g., Soricut and Marcu (2003) makes use of dynamic programming along with a standard bottom-up chart parsing, while Sagae (2009) uses shift-reduce algorithm for intra-sentential discourse analysis. Such approaches do not apply to our data, as most of the structure in our dialogues lies beyond the sentence level. As for document-level discourse parsers, Subba and Di Eugenio (2009) use a transition-based approach, following the paradigm of Sagae (2009). duVerle and Prendinger (2009) and Hernault et al. (2010) both rely on locally greedy methods. Like us, they treat attachment prediction and relation label prediction as inde"
D15-1109,N09-1064,0,0.0165497,"Missing"
D15-1109,D07-1010,0,0.0286673,"d to split our local model into two different ones. The first one concerns the learning of a model for intra-turn utterances,2 while the second models inter-turn utterances. The intra-turn model considers as input during learning all pairs of EDUs (i, j) with i 6= j. The inter-turn model on the other hand does not contain any backward links during learning. In other words it takes as input all pairs of EDUs (i, j) with i < j. We apply the turn constraint not only during learning of the local models, but also during decoding. This practice is also followed—at the sentence level—for monologues (Wellner and Pustejovsky, 2007; Joty et al., 2012; Joty et al., 2013), though our turn constraint, we believe, is firmly supported not only by our data but also by a good theoretical model of dialogue. set of SDRT relations. The upshot of this is that we are building a local sort of model that learns relations between individual EDUs with a certain probability but that it does not learn a local or even global structure. One of the drawbacks of this approach, however, is that it does not guarantee an object that is well formed. Learning a probability distribution over EDUs and then choosing the most probable relation or att"
D15-1109,J96-1002,0,\N,Missing
D15-1109,D13-1035,1,\N,Missing
D17-1136,H91-1060,0,0.548578,"iscourse structure for text exist, discourse parsing work has largely concentrated on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) and the RST Discourse Treebank (RST-DT) (Carlson et al., 2003), which is the largest corpus of texts annotated with full discourse structures. The RST-DT, annotated in the style of RST, consists of 385 news articles from the Penn Treebank, split into a training and test sets of 347 and 38 documents.The standard evaluation procedure for RST discourse parsing, RST-Parseval, proposed by Marcu (2000), adapts the Parseval procedure for syntactic parsing (Black et al., 1991). RST-Parseval computes scores on discourse structures with no label (S A sample of RST discourse parsers Almost all RST discourse parsers are evaluated on the test section of the RST-DT using manually segmented Elementary Discourse Units (EDUs). We contacted by email the main or corresponding author of each recently (2013–2017) published, textlevel RST discourse parser evaluated in this setting and asked the authors to provide us with the predictions they used in their study or a procedure that would enable us to reproduce identical or at least similar predictions. When our attempts were unsu"
D17-1136,E17-1028,0,0.217094,"greedy parser with linear-chain CRF models (Feng and Hirst, 2014). We use the version of the parser available on the author’s webpage, that lacks post-editing and contextual features. BPS16 is a sequence-to-sequence parser, heuristically constrained to build trees, with a hierarchical neural network model (hierarchical biLSTM) (Braud et al., 2016). LLC16 is a CKY chart parser with a hierarchical neural network model (attention-based hierarchical bi-LSTM) (Li et al., 2016). BCS17 mono, BCS17 cross+dev are two variants of a transition-based parser that uses a feed-forward neural network model (Braud et al., 2017). JE14 DPLP is a shift-reduce parser that uses an SVM model (Ji and Eisenstein, 2014). We use predictions provided by the author, from an improved, unpublished version of the parser. The first four parsers (HHN16 HILDA, SHV15 D, JCN15 1S-1S, FH14 gCRF) use, as features, only localist representations of the input and parsing state, i.e. surface-form and syntactic information: length of discourse units (DUs), distance between DUs, n-grams of words and POS tags, relations of syntactic dominance between DUs. . . The last five parsers (BPS16, LLC16, BCS17 mono and cross+dev, JE14 DPLP concat) build"
D17-1136,C16-1179,0,0.283961,"ield (DCRF) models, in its 1 sentence - 1 subtree (1S-1S) variant that builds a document-level RST tree on top of sentence-level subtrees built for each sentence independently (Joty et al., 2013, 2015). FH14 gCRF is a two stage (sentence- then documentlevel) bottom-up, greedy parser with linear-chain CRF models (Feng and Hirst, 2014). We use the version of the parser available on the author’s webpage, that lacks post-editing and contextual features. BPS16 is a sequence-to-sequence parser, heuristically constrained to build trees, with a hierarchical neural network model (hierarchical biLSTM) (Braud et al., 2016). LLC16 is a CKY chart parser with a hierarchical neural network model (attention-based hierarchical bi-LSTM) (Li et al., 2016). BCS17 mono, BCS17 cross+dev are two variants of a transition-based parser that uses a feed-forward neural network model (Braud et al., 2017). JE14 DPLP is a shift-reduce parser that uses an SVM model (Ji and Eisenstein, 2014). We use predictions provided by the author, from an improved, unpublished version of the parser. The first four parsers (HHN16 HILDA, SHV15 D, JCN15 1S-1S, FH14 gCRF) use, as features, only localist representations of the input and parsing state"
D17-1136,W09-3813,0,0.461052,"n the other hand, RST-Parseval considers approximately twice as many nodes as the original Parseval would on binarized trees (at most 2n − 2 nodes for n EDUs, compared to n − 1 attachments in a binary tree), and the relation labels of most nuclei are redundant with the nuclearity of a node and its sister (S PAN for a nucleus whose sisters are satellites, and the same label as its sisters for a nucleus whose sisters are nuclei). Both aspects artificially raise the level of agreement between RST trees, especially when using manual EDU segmentation. However, all the parsers in our sample except (Sagae, 2009; Heilman and Sagae, 2015) predict binary trees over manually segmented EDUs and evaluate them against right-heavy binarized reference trees. In this setting, Marcu’s encoding of RST trees RST-Parseval are no longer motivated. We can thus revert to using the standard Parseval procedure on a representation of binary RST trees where each internal node is a labelled attachment decision to obtain a more accurate evaluation of RST parser performance. Figure 1 represents (a) an original RST tree using Marcu’s encoding, (b) its right-heavy binarized version, (c) the tree of labelled attachment decisi"
D17-1136,N15-3001,0,0.337333,"Missing"
D17-1136,P14-1048,0,0.466863,"of discourse units, logistic regression for relation labelling) and a slightly different feature set adapted to use predicted syntactic dependency trees (Surdeanu et al., 2015). JCN15 1S-1S is a two stage (sentencethen document-level) CKY chart parser with Dynamic Conditional Random Field (DCRF) models, in its 1 sentence - 1 subtree (1S-1S) variant that builds a document-level RST tree on top of sentence-level subtrees built for each sentence independently (Joty et al., 2013, 2015). FH14 gCRF is a two stage (sentence- then documentlevel) bottom-up, greedy parser with linear-chain CRF models (Feng and Hirst, 2014). We use the version of the parser available on the author’s webpage, that lacks post-editing and contextual features. BPS16 is a sequence-to-sequence parser, heuristically constrained to build trees, with a hierarchical neural network model (hierarchical biLSTM) (Braud et al., 2016). LLC16 is a CKY chart parser with a hierarchical neural network model (attention-based hierarchical bi-LSTM) (Li et al., 2016). BCS17 mono, BCS17 cross+dev are two variants of a transition-based parser that uses a feed-forward neural network model (Braud et al., 2017). JE14 DPLP is a shift-reduce parser that uses"
D17-1136,W16-3616,0,0.043084,". We contacted by email the main or corresponding author of each recently (2013–2017) published, textlevel RST discourse parser evaluated in this setting and asked the authors to provide us with the predictions they used in their study or a procedure that would enable us to reproduce identical or at least similar predictions. When our attempts were unsuccessful we tried to reproduce similar predictions from published materiel (source code, binaries, model). We managed to obtain or reproduce predictions for 9 parsers from 8 studies. The first parser, denoted HHN16 HILDA, is a reimplementation (Hayashi et al., 2016) of the classic, bottom-up, greedy HILDA parser with a linear SVM model (Hernault et al., 2010) ; this parser serves as a reference point to evaluate the progress made by more recent parsers. SHV15 1319 Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1319–1324 c Copenhagen, Denmark, September 7–11, 2017. 2017 Association for Computational Linguistics D is a variant of the HILDA parser with different models (perceptron for attachment of discourse units, logistic regression for relation labelling) and a slightly different feature set adapted to use p"
D17-1136,P14-1002,0,0.70097,"ersion of the parser available on the author’s webpage, that lacks post-editing and contextual features. BPS16 is a sequence-to-sequence parser, heuristically constrained to build trees, with a hierarchical neural network model (hierarchical biLSTM) (Braud et al., 2016). LLC16 is a CKY chart parser with a hierarchical neural network model (attention-based hierarchical bi-LSTM) (Li et al., 2016). BCS17 mono, BCS17 cross+dev are two variants of a transition-based parser that uses a feed-forward neural network model (Braud et al., 2017). JE14 DPLP is a shift-reduce parser that uses an SVM model (Ji and Eisenstein, 2014). We use predictions provided by the author, from an improved, unpublished version of the parser. The first four parsers (HHN16 HILDA, SHV15 D, JCN15 1S-1S, FH14 gCRF) use, as features, only localist representations of the input and parsing state, i.e. surface-form and syntactic information: length of discourse units (DUs), distance between DUs, n-grams of words and POS tags, relations of syntactic dominance between DUs. . . The last five parsers (BPS16, LLC16, BCS17 mono and cross+dev, JE14 DPLP concat) build distributed representations of DUs, complemented with a subset of localist represent"
D17-1136,J15-3002,0,0.440507,"Missing"
D17-1136,P13-1048,0,0.0718467,"2017. 2017 Association for Computational Linguistics D is a variant of the HILDA parser with different models (perceptron for attachment of discourse units, logistic regression for relation labelling) and a slightly different feature set adapted to use predicted syntactic dependency trees (Surdeanu et al., 2015). JCN15 1S-1S is a two stage (sentencethen document-level) CKY chart parser with Dynamic Conditional Random Field (DCRF) models, in its 1 sentence - 1 subtree (1S-1S) variant that builds a document-level RST tree on top of sentence-level subtrees built for each sentence independently (Joty et al., 2013, 2015). FH14 gCRF is a two stage (sentence- then documentlevel) bottom-up, greedy parser with linear-chain CRF models (Feng and Hirst, 2014). We use the version of the parser available on the author’s webpage, that lacks post-editing and contextual features. BPS16 is a sequence-to-sequence parser, heuristically constrained to build trees, with a hierarchical neural network model (hierarchical biLSTM) (Braud et al., 2016). LLC16 is a CKY chart parser with a hierarchical neural network model (attention-based hierarchical bi-LSTM) (Li et al., 2016). BCS17 mono, BCS17 cross+dev are two variants o"
D17-1136,D16-1035,0,0.540401,"ubtrees built for each sentence independently (Joty et al., 2013, 2015). FH14 gCRF is a two stage (sentence- then documentlevel) bottom-up, greedy parser with linear-chain CRF models (Feng and Hirst, 2014). We use the version of the parser available on the author’s webpage, that lacks post-editing and contextual features. BPS16 is a sequence-to-sequence parser, heuristically constrained to build trees, with a hierarchical neural network model (hierarchical biLSTM) (Braud et al., 2016). LLC16 is a CKY chart parser with a hierarchical neural network model (attention-based hierarchical bi-LSTM) (Li et al., 2016). BCS17 mono, BCS17 cross+dev are two variants of a transition-based parser that uses a feed-forward neural network model (Braud et al., 2017). JE14 DPLP is a shift-reduce parser that uses an SVM model (Ji and Eisenstein, 2014). We use predictions provided by the author, from an improved, unpublished version of the parser. The first four parsers (HHN16 HILDA, SHV15 D, JCN15 1S-1S, FH14 gCRF) use, as features, only localist representations of the input and parsing state, i.e. surface-form and syntactic information: length of discourse units (DUs), distance between DUs, n-grams of words and POS"
D19-1234,D15-1109,1,0.497956,"models, especially for dialogue. Standard supervised models struggle to capture the sparse attachments, even when relatively large annotated corpora are available. In addition, the annotation process is time consuming and often fraught with errors and disagreements, even among expert annotators. This motivated us to explore the data programming approach that exploits expert linguistic knowledge in a more compact and consistent rule based form. Given our interest in the analysis of multi-party dialogues, we used the STAC corpus of multiparty chats, an initial version of which is described in (Afantenos et al., 2015; Perret et al., 2016). In all versions of this corpus, dialogue structures are directed acyclical graphs (DAGs) formed according to SDRT2 (Asher and Lascarides, 2003; Asher et al., 2016). An SDRT discourse structure is a graph, hV, E1 , E2 , `, Lasti, where: V is a set of nodes or Discourse Units (DUs); E1 ⊆ V 2 is a set of edges between DUs representing coherence relations; E2 ⊆ V 2 represents a dependency relation between DUs; `: E1 → R is a labeling function that assigns a semantic type to an edge in E1 from a set R of discourse relation types, and Last is a designated element of V giving"
D19-1234,L16-1432,1,0.899443,"on process is time consuming and often fraught with errors and disagreements, even among expert annotators. This motivated us to explore the data programming approach that exploits expert linguistic knowledge in a more compact and consistent rule based form. Given our interest in the analysis of multi-party dialogues, we used the STAC corpus of multiparty chats, an initial version of which is described in (Afantenos et al., 2015; Perret et al., 2016). In all versions of this corpus, dialogue structures are directed acyclical graphs (DAGs) formed according to SDRT2 (Asher and Lascarides, 2003; Asher et al., 2016). An SDRT discourse structure is a graph, hV, E1 , E2 , `, Lasti, where: V is a set of nodes or Discourse Units (DUs); E1 ⊆ V 2 is a set of edges between DUs representing coherence relations; E2 ⊆ V 2 represents a dependency relation between DUs; `: E1 → R is a labeling function that assigns a semantic type to an edge in E1 from a set R of discourse relation types, and Last is a designated element of V giving the last DU relative to textual or temporal order. E2 is used to represent Complex Discourse Units (CDUs), which are clusters of two or more DUs connected as an ensemble to other DUs in t"
D19-1234,P09-1075,0,0.0346891,"ures provides useful semantic infor1 https://www.irit.fr/STAC/ 2296 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2296–2305, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics mation to the “downstream” models used, for example, in the production of intelligent meeting managers or the analysis of user interactions in online fora. However, despite considerable efforts to retrieve discourse structures automatically (Fisher and Roark, 2007; Duverle and Prendinger, 2009; Li et al., 2014; Joty et al., 2013; Ji and Eisenstein, 2014; Yoshida et al., 2014; Li et al., 2014; Surdeanu et al., 2015), we are still a long way from usable discourse models, especially for dialogue. Standard supervised models struggle to capture the sparse attachments, even when relatively large annotated corpora are available. In addition, the annotation process is time consuming and often fraught with errors and disagreements, even among expert annotators. This motivated us to explore the data programming approach that exploits expert linguistic knowledge in a more compact and consiste"
D19-1234,P07-1062,0,0.444255,"f their discourse structures provides useful semantic infor1 https://www.irit.fr/STAC/ 2296 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2296–2305, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics mation to the “downstream” models used, for example, in the production of intelligent meeting managers or the analysis of user interactions in online fora. However, despite considerable efforts to retrieve discourse structures automatically (Fisher and Roark, 2007; Duverle and Prendinger, 2009; Li et al., 2014; Joty et al., 2013; Ji and Eisenstein, 2014; Yoshida et al., 2014; Li et al., 2014; Surdeanu et al., 2015), we are still a long way from usable discourse models, especially for dialogue. Standard supervised models struggle to capture the sparse attachments, even when relatively large annotated corpora are available. In addition, the annotation process is time consuming and often fraught with errors and disagreements, even among expert annotators. This motivated us to explore the data programming approach that exploits expert linguistic knowledge"
D19-1234,P13-1048,0,0.0278786,"w.irit.fr/STAC/ 2296 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2296–2305, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics mation to the “downstream” models used, for example, in the production of intelligent meeting managers or the analysis of user interactions in online fora. However, despite considerable efforts to retrieve discourse structures automatically (Fisher and Roark, 2007; Duverle and Prendinger, 2009; Li et al., 2014; Joty et al., 2013; Ji and Eisenstein, 2014; Yoshida et al., 2014; Li et al., 2014; Surdeanu et al., 2015), we are still a long way from usable discourse models, especially for dialogue. Standard supervised models struggle to capture the sparse attachments, even when relatively large annotated corpora are available. In addition, the annotation process is time consuming and often fraught with errors and disagreements, even among expert annotators. This motivated us to explore the data programming approach that exploits expert linguistic knowledge in a more compact and consistent rule based form. Given our intere"
D19-1234,P14-1003,0,0.113583,"infor1 https://www.irit.fr/STAC/ 2296 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2296–2305, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics mation to the “downstream” models used, for example, in the production of intelligent meeting managers or the analysis of user interactions in online fora. However, despite considerable efforts to retrieve discourse structures automatically (Fisher and Roark, 2007; Duverle and Prendinger, 2009; Li et al., 2014; Joty et al., 2013; Ji and Eisenstein, 2014; Yoshida et al., 2014; Li et al., 2014; Surdeanu et al., 2015), we are still a long way from usable discourse models, especially for dialogue. Standard supervised models struggle to capture the sparse attachments, even when relatively large annotated corpora are available. In addition, the annotation process is time consuming and often fraught with errors and disagreements, even among expert annotators. This motivated us to explore the data programming approach that exploits expert linguistic knowledge in a more compact and consistent rule based for"
D19-1234,N15-3001,0,0.0160284,"ural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2296–2305, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics mation to the “downstream” models used, for example, in the production of intelligent meeting managers or the analysis of user interactions in online fora. However, despite considerable efforts to retrieve discourse structures automatically (Fisher and Roark, 2007; Duverle and Prendinger, 2009; Li et al., 2014; Joty et al., 2013; Ji and Eisenstein, 2014; Yoshida et al., 2014; Li et al., 2014; Surdeanu et al., 2015), we are still a long way from usable discourse models, especially for dialogue. Standard supervised models struggle to capture the sparse attachments, even when relatively large annotated corpora are available. In addition, the annotation process is time consuming and often fraught with errors and disagreements, even among expert annotators. This motivated us to explore the data programming approach that exploits expert linguistic knowledge in a more compact and consistent rule based form. Given our interest in the analysis of multi-party dialogues, we used the STAC corpus of multiparty chats"
D19-1234,D14-1196,0,0.0224229,"Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2296–2305, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics mation to the “downstream” models used, for example, in the production of intelligent meeting managers or the analysis of user interactions in online fora. However, despite considerable efforts to retrieve discourse structures automatically (Fisher and Roark, 2007; Duverle and Prendinger, 2009; Li et al., 2014; Joty et al., 2013; Ji and Eisenstein, 2014; Yoshida et al., 2014; Li et al., 2014; Surdeanu et al., 2015), we are still a long way from usable discourse models, especially for dialogue. Standard supervised models struggle to capture the sparse attachments, even when relatively large annotated corpora are available. In addition, the annotation process is time consuming and often fraught with errors and disagreements, even among expert annotators. This motivated us to explore the data programming approach that exploits expert linguistic knowledge in a more compact and consistent rule based form. Given our interest in the analysis of multi-party dialogues, we"
D19-1234,P09-1113,0,0.232175,"Missing"
D19-1234,J18-2001,1,0.815746,"2 points with classic MST and MS-DAG and 4 points with the variants favoring relation instances with shorter attachments. It is not surprising that MST improves the GEN results, since it eliminates some of the false positive relations that pass the generative threshold and includes some of the false negative relations that fall below the threshold. The general inverse power law distribution of discourse attachments explains the good performance of the MST shortest link variant. GEN + “MST-short” has the highest attachment score of all approaches to the problem of attachment in the literature (Morey et al., 2018), though we are cautious in comparing scores for systems applied to different corpora. Finally, we wanted to see how GEN and our other models fared on our version of the (Perret 2302 Precision Recall F1 score Accuracy 0.54 0.33 0.56 0.73 0.59 0.55 0.80 0.48 0.52 0.49 0.55 0.47 0.52 0.61 0.53 0.84 0.75 0.88 0.91 0.89 0.28 0.49 0.68 0.59 0.40 0.65 0.38 0.44 0.67 0.74 0.86 0.91 0.69 0.73 0.66 0.71 0.68 0.72 0.92 0.93 SUPERVISED BASELINES LAST BiLSTM on Gold labels BERT on Gold labels LogReg* on Gold labels BERT+LogReg* on Gold labels SNORKEL PIPELINE GEN + Disc (BiLSTM) GEN + Disc (BERT) GEN + Di"
D19-1234,C12-1115,1,0.929203,"representing coherence relations; E2 ⊆ V 2 represents a dependency relation between DUs; `: E1 → R is a labeling function that assigns a semantic type to an edge in E1 from a set R of discourse relation types, and Last is a designated element of V giving the last DU relative to textual or temporal order. E2 is used to represent Complex Discourse Units (CDUs), which are clusters of two or more DUs connected as an ensemble to other DUs in the graph. As learning this type of recursive structure presents difficulties beyond the scope of this paper, we followed a “flattening” strategy similar to (Muller et al., 2012) to remove CDUs. This process yields a set V ∗, which is V without CDUs, and a set E∗1 , a flattened version of E1 . Building these structures typically requires three steps: (i) segmenting the text into the basic units of the discourse, typically clauses - these are EDUs or Elementary Discourse Units; these, together with CDUs, form the set of nodes V in 2 Segmented Discourse Representation Theory the graph; (ii) predicting the attachments between DUs, i.e. to identify the elements in E1 ; (iii) predicting the semantic type of the edge in E1 . This paper focuses on step (ii). Our dialogue str"
D19-1234,N16-1013,1,0.308454,"dialogue. Standard supervised models struggle to capture the sparse attachments, even when relatively large annotated corpora are available. In addition, the annotation process is time consuming and often fraught with errors and disagreements, even among expert annotators. This motivated us to explore the data programming approach that exploits expert linguistic knowledge in a more compact and consistent rule based form. Given our interest in the analysis of multi-party dialogues, we used the STAC corpus of multiparty chats, an initial version of which is described in (Afantenos et al., 2015; Perret et al., 2016). In all versions of this corpus, dialogue structures are directed acyclical graphs (DAGs) formed according to SDRT2 (Asher and Lascarides, 2003; Asher et al., 2016). An SDRT discourse structure is a graph, hV, E1 , E2 , `, Lasti, where: V is a set of nodes or Discourse Units (DUs); E1 ⊆ V 2 is a set of edges between DUs representing coherence relations; E2 ⊆ V 2 represents a dependency relation between DUs; `: E1 → R is a labeling function that assigns a semantic type to an edge in E1 from a set R of discourse relation types, and Last is a designated element of V giving the last DU relative t"
E93-1030,P91-1008,1,0.919079,"Missing"
E93-1030,J88-2003,0,0.12185,"Missing"
E93-1030,J88-2004,0,0.0425827,"Missing"
E93-1030,J91-4003,0,0.0231066,"Missing"
E93-1030,C88-2120,0,0.0437935,"Missing"
E93-1030,H92-1086,0,0.0221243,"Missing"
E93-1030,J86-3001,0,\N,Missing
F12-2026,W05-0613,0,0.0548971,"Missing"
F12-2026,W11-2023,1,0.840081,"Missing"
F12-2026,S12-1018,1,0.821137,"Missing"
F14-1022,P98-1013,0,0.0514405,"Missing"
F14-1022,candito-etal-2010-statistical,0,0.0695714,"Missing"
F14-1022,J96-2004,0,0.0413584,"Missing"
F14-1022,P08-1090,0,0.084999,"Missing"
F14-1022,W04-3205,0,0.146831,"Missing"
F14-1022,D11-1027,0,0.0448053,"Missing"
F14-1022,P12-1007,0,0.0310809,"Missing"
F14-1022,D09-1122,0,0.0610891,"Missing"
F14-1022,W12-4107,0,0.0401257,"Missing"
F14-1022,P98-2127,0,0.57691,"Missing"
F14-1022,C02-1144,0,0.135074,"Missing"
F14-1022,P07-2047,0,0.0417827,"Missing"
F14-1022,P02-1047,0,0.083139,"Missing"
F14-1022,N13-1024,0,0.0317988,"Missing"
F14-1022,prasad-etal-2008-penn,0,0.0329853,"Missing"
F14-1022,sagot-2010-lefff,0,0.0524525,"Missing"
F14-1022,S13-2001,0,0.0800276,"Missing"
J16-4005,D10-1115,0,0.72257,"irs in total (see Appendix A). We created vectors for each of the adjective–noun combinations—using both the LVW and TENSOR approach—and computed the top 10 most similar nouns and top 10 most similar adjectives for each of the vectors using cosine similarity. For comparison, we also computed the results for the original, non-composed noun vector 6 We used a fairly large, paragraph-like window of four sentences. 714 Asher et al. Integrating Type Theory and Distributional Semantics (UNMODIFIED), as well as for composed adjective–noun vectors created using the lexical function (LEXFUNC) model of Baroni and Zamparelli (2010).7 Two of the authors, both experts in formal semantics, evaluated the resulting sets, guided by the following criteria: 1. Meaning shift — Do the distributional approaches predict a meaning shift in the composition of an adjective with a noun? 2. Subsectivity and intersectivity — Given an adjective A and noun N and their composition AN, do the methods predict: (a) Subsectivity — Does the composed adjective–noun meaning predict the individual noun meaning, i.e., AN(x) → N(x)? For example, former is not subsective, but small is. (b) Intersectivity — Does the composed adjective–noun meaning pred"
J16-4005,P14-1114,0,0.03945,"Missing"
J16-4005,J90-1003,0,0.194852,"the algebraic structures for both approaches. We tagged the corpus with part-of-speech tags, lemmatized it with the Stanford Part-Of-Speech Tagger (Toutanova and Manning 2000; Toutanova et al. 2003), and parsed it using MaltParser (Nivre, Hall, and Nilsson 2006). For the LVW approach, the matrices needed for our NMF factorization were extracted from the corpus. We built the model, using 5 K nouns (or 2 K adjectives), 80 K dependency relations, and 2K context words6 (excluding stop words) with highest frequency in the training set. All matrices were weighted using pointwise mutual information (Church and Hanks 1990). The NMF model was carried out using K = 600 (the number of factorized dimensions in the model), and applying 50 iterations. For our second approach, the tensor factorization approach, we extracted our input tensor X of 5K nouns by 2K adjectives by 80 K dependency relations from the corpus. The tensor X was weighted using a three-way extension of pointwise mutual information (Van de Cruys 2011). We set K = 300 as our number of latent factors. The value was chosen as a trade-off between a model that is both rich enough, and does not require an excessive amount of memory (for the modeling of th"
J16-4005,D10-1113,0,0.0564397,"Missing"
J16-4005,P13-4006,0,0.0402287,"Missing"
J16-4005,D11-1027,0,0.0718312,"Missing"
J16-4005,D08-1094,0,0.176475,"Missing"
J16-4005,W09-0208,0,0.0187636,"in this article exploits the latent space to determine the features that are important for a particular context, and adapt the original (out-of-context) dependency-based feature vector of the target word accordingly. This allows for a more precise and more distinct computation of word meaning in context. Secondly, Dinu and Lapata use window-based context features to build their latent model, whereas our approach combines both window-based and dependency-based features. There exists a large body of work on lexical substitution that aims to compute the meaning of words in context. Erk and Pado´ (2008, 2009) make use of selectional preferences to express the meaning of a word in context; to compute the meaning of a word in the presence of an argument, they multiply the word’s vector with a vector that captures the inverse selectional preferences of the argument. Thater, Furstenau, ¨ and Pinkal (2010) extend the approach based on selectional preferences by incorporating second-order cooccurrences in their model; their model allows first-order co-occurrences to act as a filter upon the second-order vector space, which computes meaning in context. And Erk and Pado´ (2010) propose an exemplar-based a"
J16-4005,P10-2017,0,0.384565,"ndix A). We created vectors for each of the adjective–noun combinations—using both the LVW and TENSOR approach—and computed the top 10 most similar nouns and top 10 most similar adjectives for each of the vectors using cosine similarity. For comparison, we also computed the results for the original, non-composed noun vector 6 We used a fairly large, paragraph-like window of four sentences. 714 Asher et al. Integrating Type Theory and Distributional Semantics (UNMODIFIED), as well as for composed adjective–noun vectors created using the lexical function (LEXFUNC) model of Baroni and Zamparelli (2010).7 Two of the authors, both experts in formal semantics, evaluated the resulting sets, guided by the following criteria: 1. Meaning shift — Do the distributional approaches predict a meaning shift in the composition of an adjective with a noun? 2. Subsectivity and intersectivity — Given an adjective A and noun N and their composition AN, do the methods predict: (a) Subsectivity — Does the composed adjective–noun meaning predict the individual noun meaning, i.e., AN(x) → N(x)? For example, former is not subsective, but small is. (b) Intersectivity — Does the composed adjective–noun meaning pred"
J16-4005,W11-0112,0,0.130056,"Missing"
J16-4005,D11-1129,0,0.0307761,"or space, which computes meaning in context. And Erk and Pado´ (2010) propose an exemplar-based approach, in which the meaning of a word in context is represented by the activated exemplars that are most similar to it. 11 For a different take on this issue, see, e.g., Beltagy, Erk, and Mooney (2014). 719 Computational Linguistics Volume 42, Number 4 Coecke, Sadrzadeh, and Clark (2011) introduce an abstract categorial framework that unifies both certain theories of syntactic structure and certain general approaches to DS. A number of instantiations of the framework are tested experimentally in Grefenstette and Sadrzadeh (2011a, 2011b). The key idea is that relational words (e.g., adjectives or verbs) have a rich (multi-dimensional) structure that acts as a filter on their arguments. Like Mitchell and Lapata (2010) and Baroni and Zamparelli (2010), they explore the idea that lexical semantics and composition can be done in a fully algebraic setting, which is quite different from our hybrid view. Coecke, Sadrzadeh, and Clark and TCL both use a categorial semantics. The categorial structure of the former is a compact closed category, which means decomposition does not hold. From their categorial model of an adjective"
J16-4005,W11-2507,0,0.0194235,"or space, which computes meaning in context. And Erk and Pado´ (2010) propose an exemplar-based approach, in which the meaning of a word in context is represented by the activated exemplars that are most similar to it. 11 For a different take on this issue, see, e.g., Beltagy, Erk, and Mooney (2014). 719 Computational Linguistics Volume 42, Number 4 Coecke, Sadrzadeh, and Clark (2011) introduce an abstract categorial framework that unifies both certain theories of syntactic structure and certain general approaches to DS. A number of instantiations of the framework are tested experimentally in Grefenstette and Sadrzadeh (2011a, 2011b). The key idea is that relational words (e.g., adjectives or verbs) have a rich (multi-dimensional) structure that acts as a filter on their arguments. Like Mitchell and Lapata (2010) and Baroni and Zamparelli (2010), they explore the idea that lexical semantics and composition can be done in a fully algebraic setting, which is quite different from our hybrid view. Coecke, Sadrzadeh, and Clark and TCL both use a categorial semantics. The categorial structure of the former is a compact closed category, which means decomposition does not hold. From their categorial model of an adjective"
J16-4005,Q15-1027,0,0.0289345,"Missing"
J16-4005,P13-1131,0,0.0140331,"work to reach its full potential. Boleda et al. (2013) also compared several methods of adjective–noun composition, and we have used their method to determine which iteration of the TENSOR method should produce the best results without being overfitted to the corpus. However, we have compared various composition methods with respect to the predictions on several semantic dimensions; they compare methods with respect to variance from predicted distributions. Thus, our evaluation is one that is external to DS methods; theirs is not. Other interesting approaches to integrating FS and DS include Melamud et al. (2013) and Beltagy, Erk, and Mooney (2014). Like them, we are interested in rules that 720 Asher et al. Integrating Type Theory and Distributional Semantics relate to lexical inference. However, we integrate these directly into the compositional process using the TCL functor approach. 7. Conclusions Our article has provided a case study of one way to integrate formal and distributional methods in lexical semantics. We have examined how one formal theory, TCL, corresponds in its treatments of adjective–noun composition to some distributional models of composition that can automatically provide inform"
J16-4005,nivre-etal-2006-maltparser,0,0.0508861,"Missing"
J16-4005,C14-1097,0,0.109341,"Missing"
J16-4005,P10-1097,0,0.0557259,"Missing"
J16-4005,N03-1033,0,0.0207924,"muddy bank and financial bank, the top similar words are {hillside, slope, ledge, cliff, ridge} and {bank, broker, insurer, firm, banker}, respectively. 3.3 Implementational Details This section contains a number of implementational details for both our approaches. We used the UKWaC corpus (Baroni et al. 2009), an Internet corpus of about 1.5 billion 713 Computational Linguistics Volume 42, Number 4 words, to construct the algebraic structures for both approaches. We tagged the corpus with part-of-speech tags, lemmatized it with the Stanford Part-Of-Speech Tagger (Toutanova and Manning 2000; Toutanova et al. 2003), and parsed it using MaltParser (Nivre, Hall, and Nilsson 2006). For the LVW approach, the matrices needed for our NMF factorization were extracted from the corpus. We built the model, using 5 K nouns (or 2 K adjectives), 80 K dependency relations, and 2K context words6 (excluding stop words) with highest frequency in the training set. All matrices were weighted using pointwise mutual information (Church and Hanks 1990). The NMF model was carried out using K = 600 (the number of factorized dimensions in the model), and applying 50 iterations. For our second approach, the tensor factorization"
J16-4005,W00-1308,0,0.13938,"he expressions muddy bank and financial bank, the top similar words are {hillside, slope, ledge, cliff, ridge} and {bank, broker, insurer, firm, banker}, respectively. 3.3 Implementational Details This section contains a number of implementational details for both our approaches. We used the UKWaC corpus (Baroni et al. 2009), an Internet corpus of about 1.5 billion 713 Computational Linguistics Volume 42, Number 4 words, to construct the algebraic structures for both approaches. We tagged the corpus with part-of-speech tags, lemmatized it with the Stanford Part-Of-Speech Tagger (Toutanova and Manning 2000; Toutanova et al. 2003), and parsed it using MaltParser (Nivre, Hall, and Nilsson 2006). For the LVW approach, the matrices needed for our NMF factorization were extracted from the corpus. We built the model, using 5 K nouns (or 2 K adjectives), 80 K dependency relations, and 2K context words6 (excluding stop words) with highest frequency in the training set. All matrices were weighted using pointwise mutual information (Church and Hanks 1990). The NMF model was carried out using K = 600 (the number of factorized dimensions in the model), and applying 50 iterations. For our second approach, t"
J16-4005,W11-1303,1,0.827423,"Missing"
J16-4005,D11-1094,1,0.870873,"Missing"
J16-4005,C04-1146,0,0.161442,"Missing"
J16-4005,Q13-1015,0,\N,Missing
J16-4005,P15-1028,1,\N,Missing
J18-2001,D15-1109,1,0.896619,"discourse units. While dependency graphs on their own do not suffice to fully represent CDUs, Perret et al. (2016) also shows how dependency structures can approximate CDUs by distributing the relations in which a CDU is an argument over the CDU’s member EDUs. Dependency structures for discourse formalisms less constrained than RST’s constituent trees are easy to make and to use, because dependency structures are semantically more transparent than c-structures. The same semantic interpretation relation holds when we relax dependency trees to non-projective trees as in Muller et al. (2012) and Afantenos et al. (2015) or to directed acyclic graphs as in Perret et al. (2016). CDUs aside, dependency structures exhibit the actual semantic arguments of the relations and are much closer to a logical formalism in which binary relations could hold in all sorts of graph configurations. A constituency based approach like RST’s arguably does not exhibit the actual semantic arguments of discourse relations—hence, the need for a nuclearity principle. 208 Morey, Muller, and Asher A Dependency Perspective on RST Discourse Parsing and Evaluation 3.2 Dependency-Based Alternatives to RST Trees As we have just seen, the not"
J18-2001,L16-1432,1,0.879435,"w how dependency parsing can provide comparable analyses to constituent-based parsers for the RST corpus, an added advantage of dependency parsing formalisms like the one we have proposed here is that it is easily adaptable: (1) to discourse structures that are not projective trees—Muller et al. (2012) use non-projective maximum spanning tree (MST) algorithms to compute dependency trees in an SDRT style on the Annodis corpus of French texts; (2) to structures that are not even treelike, for instance, representations for multi-party chat conversations— Perret et al. (2016) use the STAC corpus (Asher et al. 2016) where discourse annotations are not trees but only directed acyclic graphs, which constituent parsers based on RST projective tree formalisms cannot reproduce. Perret et al. (2016) have shown how a dependency formalism combined with constraints implemented in ILP can learn such structures with comparable measures of success to the efforts on the more constrained RST tree bank. Dependency parsing also easily handles long distance dependencies without the computation of nuclearity features. Venant et al. (2013) have shown that nuclearity computations cannot handle all long distance dependencies"
J18-2001,D15-1263,0,0.409716,"Missing"
J18-2001,H91-1060,0,0.555704,"approaches. We will consider dependency-based evaluation in Sections 3.5 and 3.6, and see how they differ in the kind of information they measure. The differences partially reflect similar discussions within the syntactic community, where dependency structures have been advocated in part because of issues with constituentbased evaluation (Carroll, Briscoe, and Sanfilippo 1998; Carroll, Minnen, and Briscoe 1999). Constituency-based approaches naturally lend themselves to evaluation procedures that originated in the syntactic parsing literature. The most common evaluation procedure is Parseval (Black et al. 1991), which combines precision and recall on (typed) constituents, plus a Crossing Parentheses score, which is the ratio of the number of predicted constituents that cross a gold standard constituent with respect to the total number of predicted constituents. Early work on RST parsing (Marcu 2000) introduced a modified version of Parseval to accommodate RST c-trees encoded as outlined above. This early work addressed the two tasks of segmenting elementary discourse units and parsing. As almost all existing work assumes gold segmentation and focuses on the parsing task itself, and because the trees"
J18-2001,E17-1028,0,0.230168,"Missing"
J18-2001,C16-1179,0,0.131024,"Missing"
J18-2001,W04-2324,0,0.0602846,"framework is that it generalizes naturally from RST constituent trees to other more permissive discourse structures. Frameworks like SDRT or GraphBank assume more general structures than trees (respectively, directed acyclic graphs and arbitrary graphs). Venant et al. (2013) show that differences between frameworks can be encoded with different, additional structural constraints on a dependency based graph. Thus, dependency graphs capture commonalities between these different types of representation, and it is easy to convert them into a dependency graph between EDUs. It was already shown in Danlos (2004) that some discourse constructs would be more appropriately represented as directed acyclic graphs. Although we will show below how dependency parsing can provide comparable analyses to constituent-based parsers for the RST corpus, an added advantage of dependency parsing formalisms like the one we have proposed here is that it is easily adaptable: (1) to discourse structures that are not projective trees—Muller et al. (2012) use non-projective maximum spanning tree (MST) algorithms to compute dependency trees in an SDRT style on the Annodis corpus of French texts; (2) to structures that are n"
J18-2001,P09-1075,0,0.0544663,"ependency metrics for syntactic parsing, we defined and implemented several metrics on the dependencies of head-ordered RST d-trees: unlabeled attachment score (UAS), labeled attachment score where the label is restricted to nuclearity (LAS-N), relation (LAS-R), or includes both (LAS-F). The source code of the new parsers and evaluation procedures is available online.4 We distinguish three groups among RST parsers. The first group consists of constituency parsers that do not use the notion of head EDU. HHN16 HILDA is a reimplementation by Hayashi, Hirao, and Nagata (2016) of the HILDA parser (duVerle and Prendinger 2009; Hernault et al. 2010), which was one of the first text-level discourse parsers to be published that was trained and evaluated on the RST-DT. It is a greedy bottom–up parser that uses two support vector machine models to predict structures and their labeling, on a set of lexical, syntactic, and structural features. SHV15 D follows the same architecture as HILDA, with minor differences in the models (perceptron for structure, logistic regression for labeling) and features (syntactic features expressed on dependency trees) (Surdeanu, Hicks, and Valenzuela-Esc´arcega 2015). JCN15 1S-1S is a two-"
J18-2001,C96-1058,0,0.253167,"by the different empirical motivations behind their development. Li et al. (2014) adapt a syntactic dependency parser, the MSTParser of McDonald, Crammer, and Pereira (2005), to predict RST dependency trees over a text segmented in EDUs instead of syntactic dependency trees over sentences segmented in tokens. They convert the RST constituency trees from the RST-DT to RST dependency trees that they use for training and evaluation. They report experiments with two decoders implemented in the original MSTParser, the non-projective Maximum Spanning Tree decoder and the projective Eisner decoder (Eisner 1996). Although the authors initially point out that a given simple RST dependency tree can correspond to several RST constituency trees, they do not describe any mechanism to cope with this issue and yet report RST-Parseval scores for projective variants of their parser. It turns out that their implementation of the RST-Parseval procedure does not operate on pairs of reference and predicted RST constituency trees but rather on pairs of reference and predicted RST dependency trees. For each RST dependency tree, constituency spans are computed from the transitive closure of its adjacency matrix (i.e"
J18-2001,P14-1048,0,0.354471,"Missing"
J18-2001,P15-1147,0,0.0922104,"r-level structures, to yield a directed tree structure over the discourse units of a text. Simple dependency structures are simplified representations of more complex SDRT graph structures (Muller et al. 2012), or a simplified representation of RST structures (Li et al. 2014), with some applications to specific tasks (Hirao et al. 2013). As we will show, this engenders some information loss. Once one takes the order of attachment into account, however, dependency representations do not in principle imply a loss of information, as established in the syntactic domain by Fern´andez-Gonz´alez and Martins (2015), using the notion of headordered dependency structures. Applying the head-ordered idea to discourse provides some advantages over the use of constituent structures, as head-ordered structures do not assume a higher abstraction level, a potentially contentious issue in discourse analysis (Hobbs et al. 1987). They also lend themselves to different computational models, as is also the case in syntactic parsing. We also relate this to how some work already makes use of a related notion of head constituent to inform discourse parsing. Dependency structures are also more general, and allow for the"
J18-2001,J86-3001,0,0.574341,"e or direction of an attachment. As we have been at some pains to point out, nuclearity and headedness are not the same thing; headedness does not determine nuclearity, because where a and b are EDUs, the two simple trees [aN , bS ] and [aN , bN ] (since we are just looking at structure and nuclearity, we have omitted any of the relational decorations) have the same head. And nuclearity by itself does not determine headedness even though its introduction by Marcu (2000) was semantically motivated in an effort to find the core or central idea in a span; a notion is reflected in other theories (Grosz and Sidner 1986; Asher 1993) by the use of coordinating and subordinating discourse relations. Consider, for instance, the following hypothetical tree structure [[aN bN ]N , cS ], where [aN bN ] is a subtree and the nucleus of the larger tree that includes c. An admittedly somewhat crazy interpretive principle that takes the head of the multinuclear relation to be the rightmost one locally but takes the leftmost one as the head projected up through the tree would yield the following non-projective dependency structure: {a ← b, a → c}. A saner, interpretive principle would be the one that we suggested earlier"
J18-2001,W16-3616,0,0.214358,"Missing"
J18-2001,D13-1158,0,0.239063,"a constituency-based approach to discourse analysis. We argue that the problem is more naturally formulated as the prediction of a dependency structure, on which simpler parsing strategies can be competitively applied. We show how to evaluate both families of discourse parsers in a constituent-based and a dependency-based framework. Discourse aspects are becoming more and more present in various NLP tasks. Text-level structures are useful as a representation of the coherence of a text and its topical organization, with applications to summarization (Marcu 2000; Louis, Joshi, and Nenkova 2010; Hirao et al. 2013), sentiment analysis (Bhatia, Ji, and Eisenstein 2015), or document classification (Ji and Smith 2017). Most empirical approaches to this problem focus on predicting structures following RST and are based on the corresponding RST-Discourse Treebank corpus (RST-DT), a large annotated resource of texts for discourse analysis in English (Hernault et al., 2010; Feng and Hirst 2014; Ji and Eisenstein 2014; Joty, Cartenini, and Ng 2015). On the other hand, there is a need to examine in depth some of the representational choices made within the RST framework. Many discourse parsers for RST have made"
J18-2001,J87-3004,0,0.596203,"specific tasks (Hirao et al. 2013). As we will show, this engenders some information loss. Once one takes the order of attachment into account, however, dependency representations do not in principle imply a loss of information, as established in the syntactic domain by Fern´andez-Gonz´alez and Martins (2015), using the notion of headordered dependency structures. Applying the head-ordered idea to discourse provides some advantages over the use of constituent structures, as head-ordered structures do not assume a higher abstraction level, a potentially contentious issue in discourse analysis (Hobbs et al. 1987). They also lend themselves to different computational models, as is also the case in syntactic parsing. We also relate this to how some work already makes use of a related notion of head constituent to inform discourse parsing. Dependency structures are also more general, and allow for the different structures advocated by the various aforementioned theories: tree structures (projective or not) or graph structures. They can thus provide a common representation framework between the different existing corpora. Dependency parsing also comes with different evaluation measures from those used in"
J18-2001,P14-1002,0,0.365502,"NLP tasks. Text-level structures are useful as a representation of the coherence of a text and its topical organization, with applications to summarization (Marcu 2000; Louis, Joshi, and Nenkova 2010; Hirao et al. 2013), sentiment analysis (Bhatia, Ji, and Eisenstein 2015), or document classification (Ji and Smith 2017). Most empirical approaches to this problem focus on predicting structures following RST and are based on the corresponding RST-Discourse Treebank corpus (RST-DT), a large annotated resource of texts for discourse analysis in English (Hernault et al., 2010; Feng and Hirst 2014; Ji and Eisenstein 2014; Joty, Cartenini, and Ng 2015). On the other hand, there is a need to examine in depth some of the representational choices made within the RST framework. Many discourse parsers for RST have made simplifying assumptions with respect to the linguistic annotations for practical purposes, and these choices affect the generality of the models and their evaluation. We thus focus on the issue of predicting a structure for a text, comparing different representations over the RST-DT. We will analyze the impact of the practical choices one makes while doing discourse parsing, while taking into account"
J18-2001,P17-1092,0,0.211813,"Missing"
J18-2001,J15-3002,0,0.486435,"Missing"
J18-2001,D14-1220,0,0.0571356,"y to the constituents of phrase structure grammars. However, this similarity is more apparent than real; discourse structure even in its RST format is a relational structure, formalized 198 Morey, Muller, and Asher A Dependency Perspective on RST Discourse Parsing and Evaluation as a set of “discourse constituents” together with a set of relations, instances of which hold between the constituents. All of this suggests a different approach to discourse parsing—namely, “dependency parsing,” which has gained some currency in the discourse parsing community (Muller et al. 2012; Hirao et al. 2013; Li et al. 2014). Discourse dependency parsing is analogous to syntactic dependency analysis, where units are directly related to each other without intermediate upper-level structures, to yield a directed tree structure over the discourse units of a text. Simple dependency structures are simplified representations of more complex SDRT graph structures (Muller et al. 2012), or a simplified representation of RST structures (Li et al. 2014), with some applications to specific tasks (Hirao et al. 2013). As we will show, this engenders some information loss. Once one takes the order of attachment into account, ho"
J18-2001,D16-1035,0,0.344873,"Missing"
J18-2001,P14-1003,0,0.0684512,"y to the constituents of phrase structure grammars. However, this similarity is more apparent than real; discourse structure even in its RST format is a relational structure, formalized 198 Morey, Muller, and Asher A Dependency Perspective on RST Discourse Parsing and Evaluation as a set of “discourse constituents” together with a set of relations, instances of which hold between the constituents. All of this suggests a different approach to discourse parsing—namely, “dependency parsing,” which has gained some currency in the discourse parsing community (Muller et al. 2012; Hirao et al. 2013; Li et al. 2014). Discourse dependency parsing is analogous to syntactic dependency analysis, where units are directly related to each other without intermediate upper-level structures, to yield a directed tree structure over the discourse units of a text. Simple dependency structures are simplified representations of more complex SDRT graph structures (Muller et al. 2012), or a simplified representation of RST structures (Li et al. 2014), with some applications to specific tasks (Hirao et al. 2013). As we will show, this engenders some information loss. Once one takes the order of attachment into account, ho"
J18-2001,W10-4327,0,0.138157,"Missing"
J18-2001,P05-1012,0,0.202213,"Missing"
J18-2001,D17-1136,1,0.890361,"Missing"
J18-2001,C12-1115,1,0.924099,"Missing"
J18-2001,N16-1013,1,0.956246,"d as the second argument of the ATTRIBUTION relation the content given by EDUs (π2 , π4 , π5 ) in the current annotation. One could make the R EASON relation that holds between [π2 , . . . , π4 ] and π5 multinuclear, and one could have a version of the Nuclearity Principle which gathered then (π2 , π4 , π5 ) into a complex discourse unit (CDU) that was the argument of the E XPLANATION relation. But this CDU would not correspond to a well-formed RST tree, because it does not correspond to a contiguous span. Although such structures are studied in other frameworks like SDRT (Venant et al. 2013; Perret et al. 2016), they have not been studied computationally nor even theoretically within the RST framework as far as we know. This simple example already points to a potential empirical problem with RST’s conception of structure. The relative unclarity of how to determine the arguments of discourse relations in an RST tree complicates efforts to capture semantically relevant information in these structures, and thus undermines a semantic argument for analyzing discourse in terms of constituent structures like RST tree structures. On the other hand, although most computational approaches have eschewed a prin"
J18-2001,prasad-etal-2008-penn,0,0.314698,"Missing"
J18-2001,W09-3813,0,0.177106,"ics that are used to assess the performance of discourse parsers, as we will see in Section 4. Even though n-ary trees are not so frequent in the RST-DT corpus, binarization applied high up in the original tree can drastically change an evaluation score. Figure 8 later in this article shows what happens when binarized structures differ (left vs. right): all relevant arguments’ substructures have different spans, generating multiple errors down the tree. Theoretically and empirically, the binarization of RST c-trees is not trivially reversible, a point that is overlooked in most studies except Sagae (2009) and Hernault et al. (2010). Headed RST c-trees. In the formal presentation of RST trees by Marcu (2000), each node is assigned a promotion set containing its most important EDUs, in accordance with the Nuclearity Principle. The promotion set of a node is recursively defined as the union of the promotion sets of its nuclei, the promotion set of each leaf (EDU) being the EDU itself. Semantically, promotion sets are said to provide a validation criterion for relations between wider discourse units: A relation can hold between two discourse units if it also holds between their promotion sets. Thi"
J18-2001,W05-1513,0,0.028646,"otion set of each leaf (EDU) being the EDU itself. Semantically, promotion sets are said to provide a validation criterion for relations between wider discourse units: A relation can hold between two discourse units if it also holds between their promotion sets. This leads Marcu to use the promotion set of (non-elementary) discourse units as a proxy to extract semantic similarity (WordNet)based features between these units, in his early shift-reduce RST discourse parser (Marcu 2000). Sagae pursued Marcu’s line of work by adapting the shift-reduce parser he had developed for syntactic parsing (Sagae and Lavie 2005) to RST discourse parsing (Sagae 2009). Sagae’s syntactic parser is a lexicalized shift-reduce parser that simultaneously produces both a dependency and a constituent structure, using features related to either of the two types of structures being built. Building an RST tree from EDUs is essentially similar to building a syntactic tree from tokens, save for the fact that discourse units have a promotion set rather than a unique head, because discourse relations can relate two or more nuclei of equal importance whereas syntactic dependencies (usually) asymmetrically relate a head and a dependen"
J18-2001,N03-1030,0,0.240644,"ly modified by two satellites via different relations, in a format suitable for training and evaluating parsers. Without these specific constructs, however, a more natural encoding would have put the relations labels higher up, on the node dominating the related constituents. This raises problems we will come back to in Section 2.4. The standard evaluation procedure for RST discourse parsers is Marcu’s (2000) adaptation of the Parseval procedure to this encoding, which we name RST-Parseval. Binarization. It is standard practice since the first proposals on RST discourse parsing (Reitter 2003; Soricut and Marcu 2003) to train and evaluate parsers on a right-heavy (, R) (S PAN, N) (A TTRIBUTION, S) (R EASON, S) (S PAN, N) π1 (S AME -U NIT, N) (S PAN, N) (R ESTATEMENT- E, S) π2 (S AME -U NIT, N) π5 π4 π3 Figure 2 Constituent tree corresponding to the RST tree in Figure 1. 203 Computational Linguistics Volume 44, Number 2 binarized version of the c-trees from the RST-DT. This is mostly accidental: constituencybased RST discourse parsers inherit a limitation shared by most syntactic constituencybased parsers that operate better, if not only, on binary trees. Such binarization is, however, not a theoretically"
J18-2001,N15-3001,0,0.0864493,"Missing"
J18-2001,W13-4002,1,0.959595,"ver, that would yield as the second argument of the ATTRIBUTION relation the content given by EDUs (π2 , π4 , π5 ) in the current annotation. One could make the R EASON relation that holds between [π2 , . . . , π4 ] and π5 multinuclear, and one could have a version of the Nuclearity Principle which gathered then (π2 , π4 , π5 ) into a complex discourse unit (CDU) that was the argument of the E XPLANATION relation. But this CDU would not correspond to a well-formed RST tree, because it does not correspond to a contiguous span. Although such structures are studied in other frameworks like SDRT (Venant et al. 2013; Perret et al. 2016), they have not been studied computationally nor even theoretically within the RST framework as far as we know. This simple example already points to a potential empirical problem with RST’s conception of structure. The relative unclarity of how to determine the arguments of discourse relations in an RST tree complicates efforts to capture semantically relevant information in these structures, and thus undermines a semantic argument for analyzing discourse in terms of constituent structures like RST tree structures. On the other hand, although most computational approaches"
J18-2001,D14-1196,0,0.166773,"Missing"
L16-1167,D15-1109,1,0.887071,"Missing"
L16-1167,D13-1158,0,0.023627,"os et al., 2015; Perret et al., 2016, for example) simplify the underlying structures by a head replacement strategy (HR) that removes nodes representing CDUs from the original hypergraphs and replacing any incoming or outgoing edges on these nodes on the heads of those CDUs, forming thus dependency structures and not hypergraphs. We adapted this strategy as well for the purposes of this paper. An example transformation is provided in Figure 5. The result of the transformation for the example text is shown in Figure 6b. In the case of RST we follow the procedure that was initially proposed by Hirao et al. (2013) and later followed by Li et al. (2014). The first step in this approach includes binarizing the RST trees. In other words we transform all multi-nuclear relations into nested binary relations with the left-most EDU being the head. Dependencies go from nucleus to satellite. For illustration, a dependency structure 1054 1 reason 1 reason Elab. π1 concession Elab. 1 3 e-elab. Elab. 2 4 C. =⇒ e-elab. 2 π2 5 C. 6 2 3 3 4 5 (a) RST Elab. 4 joint C. background 5 C. elaboration 6 1 contrast 2 comment 3 4 5 (b) SDRT Figure 5: An example of SDRT dependency graph transformation support rebut for the RST"
L16-1167,P14-1003,0,0.0399048,"example) simplify the underlying structures by a head replacement strategy (HR) that removes nodes representing CDUs from the original hypergraphs and replacing any incoming or outgoing edges on these nodes on the heads of those CDUs, forming thus dependency structures and not hypergraphs. We adapted this strategy as well for the purposes of this paper. An example transformation is provided in Figure 5. The result of the transformation for the example text is shown in Figure 6b. In the case of RST we follow the procedure that was initially proposed by Hirao et al. (2013) and later followed by Li et al. (2014). The first step in this approach includes binarizing the RST trees. In other words we transform all multi-nuclear relations into nested binary relations with the left-most EDU being the head. Dependencies go from nucleus to satellite. For illustration, a dependency structure 1054 1 reason 1 reason Elab. π1 concession Elab. 1 3 e-elab. Elab. 2 4 C. =⇒ e-elab. 2 π2 5 C. 6 2 3 3 4 5 (a) RST Elab. 4 joint C. background 5 C. elaboration 6 1 contrast 2 comment 3 4 5 (b) SDRT Figure 5: An example of SDRT dependency graph transformation support rebut for the RST tree of Figure 3 is shown in Figure 6a"
L16-1167,C12-1115,1,0.908495,"Missing"
L16-1167,D15-1110,1,0.92578,"rse units (EDUs) as used in RST and SDRT (see below). The argumentation structure scheme then distinguishes between simple support (one ADU provides a justification of another) and linked support, where several ADUs collectively fulfil the role of justification. On the side of attacks, we separate rebutting (denying the validity of a statement) and undercutting (denying the relevance of a statement in supporting another). The scheme is designed in such a way that the fine-grained representations can be reduced to coarser ones that, for example, only distinguish between support and attack (see Peldszus and Stede (2015)), as it is customary in much of the related work on argumentation mining. In Figure 2, we show the representation for the sample text given in Figure 1. The nodes of this graph represent the propositions expressed in text segments (grey boxes), and their shape indicates the role in the dialectical exchange: Round nodes are proponent’s nodes, square ones are opponent’s nodes. The arcs connecting the nodes represent different supporting (arrow-head links) and attacking moves (circle/square-head links). By means of recursive application of relations, representations of relatively complex texts c"
L16-1167,W14-2112,1,0.829844,"ternative medical treatments. Not all practices and approaches that are lumped together under this term may have been proven in clinical trials, yet it’s precisely their positive effect when accompanying conventional ’western’ medical therapies that’s been demonstrated as beneficial. Besides many general practitioners offer such counselling and treatments in parallel anyway - and who would want to question their broad expertise? by two experts, and they apply equally to the English translation. The guidelines are specified in Stede (2016). They have been shown to yield reliable agreement, see Peldszus (2014). The annotated corpus contains 576 ADUs, of which 451 are proponent and 125 opponent ones. The most frequent relation is S UPPORT (263), followed by R EBUT (108), U N DERCUT (63). L INKED relations (21) and support by E X AMPLE (9) occure only rarely. [e1] Health insurance companies should naturally cover alternative medical treatments. Figure 1: Sample text from Microtext Corpus 3. Argumentation structure The initial release of the corpus already incorporated argumentation structures for all texts, following the scheme devised in Peldszus and Stede (2013), which itself is based on Freeman’s"
L16-1167,N16-1013,1,0.877768,"Missing"
L16-1167,prasad-etal-2008-penn,0,0.0854361,"s of discourse structure, and between discourse and argumentation. We converted the three annotation formats to a common dependency tree format that enables to compare the structures, and we describe some initial findings. Keywords: Discourse structure, Argumentation, Multi-layer annotation 1. Introduction In recent years, three approaches to analyzing and representing discourse structure have resulted in various annotated corpora and in implemented discourse parsers: • The Penn Discourse Treebank (PDTB) annotates individual connectives with their coherence relations and their argument spans (Prasad et al., 2008). • Rhetorical Structure Theory (RST) predicts tree structures on the grounds of underlying coherence relations that are mostly defined in terms of speaker intentions (Mann and Thompson, 1988). • Segmented Discourse Representation Theory (SDRT) exploits graphs to model discourse structures and defines coherence relations via their semantic effects on commitments rather than relative to speaker intentions (Asher and Lascarides, 2003; Lascarides and Asher, 2009). Of these, only RST and SDRT aim at predicting a full discourse structure, and our concern in this paper is with these two theories. To"
L16-1167,stede-neumann-2014-potsdam,1,0.83797,"y with other projects, we decided to build two versions of RST trees for texts with embedded EDUs: One version ignores them, while the other splits them off and uses an artificial “Same-Unit” relation to repair the structure (cf. Carlson et al. (2003)). Figure 3: Rhetorical structure of the example text As a result of the finer segmentation, 83 ADUs not directly corresponding with an EDU have been split up, so that the final corpus contains 680 EDUs. 6. 5. RST The RST annotations have been created according to the guidelines (Stede, 2016) that were developed for the Potsdam Commentary Corpus (Stede and Neumann, 2014, in German). The relation set is quite close to the original proposal of Mann and Thompson (1988) and that of the RST website2 , but some relation definitions have been slightly modified to make the guidelines more amenable to argumentative text, as it is found in newspaper commentaries or in the short texts of the corpus we introduce here. Furthermore, the guidelines present the relation set in four different groups: primarily-semantic, primarily-pragmatic, textual, multinuclear. The assignment to ’semantic’ and ’pragmatic’ relations largely agrees with the subject-matter/presentational divi"
L16-1167,W13-4002,1,0.907618,"will see. 7.2. From Discourse Structures to Dependency Structures As pointed out above, SDRT makes use of CDUs to represent larger units of discourse. RST, on the other hand, makes use of some version of the “Nuclearity Principle” to determine what is the exact scope of a discourse relation. The presence of CDUs complicates our translation from SDRT graphs to a common dependency graph format capable of handling most RST trees and SDRT graphs (Perret et al., 2016). But most formulations of the Nuclearity Principle also hinder a structural match between RST trees and SDRT graphs, as detailed in Venant et al. (2013). The authors of this paper axiomatize both RST trees and SDRT graphs in an ecumenical fragment of monadic second order logic, so that precise translation results can be proved concerning the posited structures of the two theories. They show that if one restricts SDRT graphs to those that have just one incoming arc to each node, then one SDRT graph may correspond to several RST trees. On the other hand, the expressive capacities of SDRT outrun those of theories that require tree-like discourse structures, and Afantenos et al. (2015) have shown that we need this expressive capacity for multi-pa"
L16-1167,W01-1605,0,\N,Missing
L16-1432,afantenos-etal-2010-learning,1,0.856163,"Missing"
L16-1432,D15-1109,1,0.875536,"Missing"
L16-1432,D13-1035,1,0.897714,"Missing"
L16-1432,P05-1029,0,0.0340107,"discussions” of (Wahlster, 2000), our dialogues are spontaneous exchanges between human participants. There is no face to face communication, but participants exploit the virtual environment in communication as Examples 2 and 3 show, even if they can’t demonstrate the visually presented elements in that environment. Because the environment is dynamic (players’ actions are changing the game board), the dialogue is largely reactive with few long distance attachments (greater than five turns away), although attachments of discourse moves to moves two to five turns away are relatively common as (Ginzburg and Fernández, 2005) noted for multi-party dialogue ellipses. Bargaining, for example, is a core of many of our dialogues with a pattern of offers and counteroffers, often leading to an explicit acceptance or rejection, which might be subsequently attached to the initial offer. Nevertheless, 2722 discussions, especially those involving multiple threads between subgroups of participants do occasionally create intuitive, long distance and crossing dependencies between dialogue moves. Multiple threads are of course particular to dialogue, and something we have observed in group discussions like those in the classroo"
L16-1432,J86-3001,0,0.6653,"our chats are competing to win the game. This means that they have interests that are opposed; they sometimes don’t reveal information that another agent asks for and even arguably lie or at least misdirect in the sense of (Asher and Lascarides, 2013; Asher et al., 2015). Consider Example 4 with the relevant hidden resources for each player in parentheses: 846 847 tk gwfs Example 4 (ore=0) anyone got some ore? (ore=2) nope sorry Our chat dialogues are thus not completely cooperative as, for example, are those discussed in (Grosz, 1979), and so do not follow a common, intended plan structure (Grosz and Sidner, 1986; Grosz and Sidner, 1990). 2. Theoretical background for the annotation model There are several theories of discourse structure for texts: RST (Mann and Thompson, 1987), LDM (Polanyi et al., 2004), the graphbank model (Wolf and Gibson, 2005), DLTAG (Forbes et al., 2003), PDTB (Prasad et al., 2008), and SDRT (Asher and Lascarides, 2003). However, data from our corpus rule out DLTAG, LDM, and RST as candidate theories because they posit tree-based discourse structures. In particular, our corpus contains frequent acknowledgments or other moves directed at more than one player as shown in this exc"
L16-1432,D13-1158,0,0.0894685,"Missing"
L16-1432,W15-0123,1,0.896293,"Missing"
L16-1432,P14-1003,0,0.14864,"Missing"
L16-1432,P05-1012,0,0.108284,"Missing"
L16-1432,C12-1115,1,0.925904,"Missing"
L16-1432,N16-1013,1,0.7683,"Missing"
L16-1432,2009.jeptalnrecital-court.5,1,0.731667,"This snapshot shows the perspective of the game administrator; normally, the type of resources that a player has is revealed only to that player. The moves from the “Game” window and those from “History” are automatically recorded and aligned in a game log, which allows us to Figure 1: Snapshot of a Catan game board replay an entire game.3 The .soclog files, segmented files, and annotated files from our corpus, which we describe below, are available online.4 Our data differed considerably from written singleauthored text in other corpora that we have examined in earlier annotation campaigns (Péry-Woodley et al., 2009). In addition to negotiation dialogues, it features creative nouns (dolly for sheep), novel verbs (as I alt tab back from the tutorial), and V ellipsis without a surface antecedent (I can wheat for clay). The text is messy, requiring robust parsing to deal with ubiquitous misspellings, contractions, and missing punctuation. Another feature of our corpus is the presence of subdialogues or threads that divide, merge, or get dropped as the dialogue proceeds. Example 1 contains at least 3 threads, The authors gratefully acknowledge research support from ERC Advanced Researcher Grant n.269427. 1 St"
L16-1432,W04-2322,0,0.0946406,"Missing"
L16-1432,prasad-etal-2008-penn,0,0.245581,"e relevant hidden resources for each player in parentheses: 846 847 tk gwfs Example 4 (ore=0) anyone got some ore? (ore=2) nope sorry Our chat dialogues are thus not completely cooperative as, for example, are those discussed in (Grosz, 1979), and so do not follow a common, intended plan structure (Grosz and Sidner, 1986; Grosz and Sidner, 1990). 2. Theoretical background for the annotation model There are several theories of discourse structure for texts: RST (Mann and Thompson, 1987), LDM (Polanyi et al., 2004), the graphbank model (Wolf and Gibson, 2005), DLTAG (Forbes et al., 2003), PDTB (Prasad et al., 2008), and SDRT (Asher and Lascarides, 2003). However, data from our corpus rule out DLTAG, LDM, and RST as candidate theories because they posit tree-based discourse structures. In particular, our corpus contains frequent acknowledgments or other moves directed at more than one player as shown in this excerpt from our corpus: 234 235 236 237 238 gwfs inca Ccg gwfs dmm 239 gwfs Example 5 anyone got wheat for a sheep? sorry, not me [nope.]a [you seem to have lots of sheep!]b yup baaa i think i’d rather hang on to my wheat i’m afraid kk I’ll take my chances then... GWFS initiates an exchange in turn"
L16-1432,J05-2005,0,0.127332,"ides, 2013; Asher et al., 2015). Consider Example 4 with the relevant hidden resources for each player in parentheses: 846 847 tk gwfs Example 4 (ore=0) anyone got some ore? (ore=2) nope sorry Our chat dialogues are thus not completely cooperative as, for example, are those discussed in (Grosz, 1979), and so do not follow a common, intended plan structure (Grosz and Sidner, 1986; Grosz and Sidner, 1990). 2. Theoretical background for the annotation model There are several theories of discourse structure for texts: RST (Mann and Thompson, 1987), LDM (Polanyi et al., 2004), the graphbank model (Wolf and Gibson, 2005), DLTAG (Forbes et al., 2003), PDTB (Prasad et al., 2008), and SDRT (Asher and Lascarides, 2003). However, data from our corpus rule out DLTAG, LDM, and RST as candidate theories because they posit tree-based discourse structures. In particular, our corpus contains frequent acknowledgments or other moves directed at more than one player as shown in this excerpt from our corpus: 234 235 236 237 238 gwfs inca Ccg gwfs dmm 239 gwfs Example 5 anyone got wheat for a sheep? sorry, not me [nope.]a [you seem to have lots of sheep!]b yup baaa i think i’d rather hang on to my wheat i’m afraid kk I’ll ta"
N16-1013,D15-1109,1,0.473898,"Nicholas Asher Mathieu Morey IRIT, Universit´e de Toulouse & CNRS 118 Route de Narbonne, 31062 Toulouse, France {firstname.lastname@irit.fr} Abstract and non-treelike discourse structures is ripe for investigation and potentially important for other genres like the discourse analysis of fora (Wang et al., 2011, for example). This paper proposes a method based on constraints using Integer Linear Programming decoding over local probability distributions to investigate both treelike and non-treelike, full discourse structures for multi-party dialogue. We show that our method outperforms that of Afantenos et al. (2015) on the corpus they developed. In this paper we present the first, to the best of our knowledge, discourse parser that is able to predict non-tree DAG structures. We use Integer Linear Programming (ILP) to encode both the objective function and the constraints as global decoding over local scores. Our underlying data come from multi-party chat dialogues, which require the prediction of DAGs. We use the dependency parsing paradigm, as has been done in the past (Muller et al., 2012; Li et al., 2014; Afantenos et al., 2015), but we use the underlying formal framework of SDRT and exploit SDRT’s no"
N16-1013,W05-0613,0,0.097565,"methods. They 106 treat attachment prediction and relation label prediction as independent problems. Feng and Hirst (2012) extend this approach by additional feature engineering but is restricted to sentence-level parsing. Joty et al. (2013) and Joty et al. (2015) present a textlevel discourse parser that uses Conditional Random Fields to capture label inter-dependencies and chart parsing for decoding and have the best results on non-dependency based discourse parsing, with an F1 of 0.689 on unlabelled structures and 0.5587 on labelled structures. The afore-cited work concerns only monologue. Baldridge and Lascarides (2005) predicted tree discourse structures for 2 party “directed” dialogues from the Verbmobil corpus by training a PCFG that exploited the structure of the underlying task. Elsner and Charniak (2010), Elsner and Charniak (2011) present a combination of local coherence models initially provided for monologues showing that those models can satisfactorily model local coherence in chat dialogues. However, they do not present a full discourse parsing model. Our data required a more open domain approach and a more sophisticated approach to structure. Afantenos et al. (2015) worked on multi-party chat dia"
N16-1013,J96-1002,0,0.095223,"re no formal guarantees that the predicted structures will be well-formed. They could for example contain cycles although they should be DAGs. Most approaches have circumvented this problem by using global decoding over local scores and by imposing specific constraints upon decoding. But, those constraints were mostly limited to the production of maximum spanning trees, and not full DAGs. We perform global decoding as well but use Integer Linear Programming (ILP) with an objective function and constraints that allow non-tree DAGs. We use a regularized maximum entropy (shortened MaxEnt) model (Berger et al., 1996) to get the local scores, both for attachment and labelling. ILP for Global Decoding. ILP essentially involves an objective function that needs to be maximized under specific constraints. Our goal is to build the directed graph G = hV, E, Ri with R being a function that provides labels for the edges in E. Vertices (EDUs) are referred by their position in textual order, indexed from 1. The m labels are referred by their index in alphabetical order, starting from 1. Let n = |V |. The local model provides us with two real-valued functions: sa : {1, . . . , n}2 7→ [0, 1] sr : {1, . . . , n}2 × {1,"
N16-1013,D15-1262,0,0.0270709,"Missing"
N16-1013,D13-1035,1,0.88729,"Missing"
N16-1013,J14-1002,0,0.0169007,"s using HR on the gold and MST decoding. We need to investigate further constraints, and to refine and improve our features to get a better local model. Our local model will eventually need to be replaced by one that takes into account more of the surrounding structure when it assigns scores to attachments and labels. We also plan to investigate the use of recurrent neural networks in order to improve our local model. 6 Related Work ILP has been used for various computational linguistics tasks: syntactic parsing (Martins et al., 2010; Fern´andez-Gonz´alez and Martins, 2015), semantic parsing (Das et al., 2014), coreference resolution (Denis and Baldridge, 2007) and temporal analysis (Denis and Muller, 2011). As far as we know, we are the first to use ILP to predict discourse structures. Our use of dependency structures for discourse also has antecedents in the literature. The first we know of is Muller et al. (2012). Their prediction Decoder Model L AST L OCAL MST ILP – local local local L AST L OCAL MST ILP – local local local L AST L OCAL MST ILP – local local local Unlabelled Attachment Labelled Attachment Precision Recall F1 Precision Recall F1 Head (no distribution) 0.602 0.566 0.584 0.403 0.3"
N16-1013,N07-1030,0,0.0108757,"need to investigate further constraints, and to refine and improve our features to get a better local model. Our local model will eventually need to be replaced by one that takes into account more of the surrounding structure when it assigns scores to attachments and labels. We also plan to investigate the use of recurrent neural networks in order to improve our local model. 6 Related Work ILP has been used for various computational linguistics tasks: syntactic parsing (Martins et al., 2010; Fern´andez-Gonz´alez and Martins, 2015), semantic parsing (Das et al., 2014), coreference resolution (Denis and Baldridge, 2007) and temporal analysis (Denis and Muller, 2011). As far as we know, we are the first to use ILP to predict discourse structures. Our use of dependency structures for discourse also has antecedents in the literature. The first we know of is Muller et al. (2012). Their prediction Decoder Model L AST L OCAL MST ILP – local local local L AST L OCAL MST ILP – local local local L AST L OCAL MST ILP – local local local Unlabelled Attachment Labelled Attachment Precision Recall F1 Precision Recall F1 Head (no distribution) 0.602 0.566 0.584 0.403 0.379 0.391 0.664 0.379 0.483 0.591 0.337 0.429 0.688 0"
N16-1013,P09-1075,0,0.196479,"lobal structure. In essence the problem that they treat corresponds only to our local model. As we have argued above, this setting makes an unwarranted assumption, as it assumes independence of local attachment decisions. There is also work on discourse structure within a single sentence; e.g., Soricut and Marcu (2003), Sagae (2009). Such approaches do not apply to our data, as most of the structure in our dialogues lies beyond the sentence level. As for other document-level discourse parsers, Subba and Di Eugenio (2009) use a transition-based approach, following the paradigm of Sagae (2009). duVerle and Prendinger (2009) and Hernault et al. (2010) both rely on locally greedy methods. They 106 treat attachment prediction and relation label prediction as independent problems. Feng and Hirst (2012) extend this approach by additional feature engineering but is restricted to sentence-level parsing. Joty et al. (2013) and Joty et al. (2015) present a textlevel discourse parser that uses Conditional Random Fields to capture label inter-dependencies and chart parsing for decoding and have the best results on non-dependency based discourse parsing, with an F1 of 0.689 on unlabelled structures and 0.5587 on labelled st"
N16-1013,C96-1058,0,0.173863,".370 0.471 0.544 0.311 0.396 0.710 0.594 0.647 0.535 0.448 0.488 0.680 0.657 0.668 0.528 0.510 0.519 Full distribution 0.701 0.498 0.582 0.505 0.360 0.420 0.681 0.448 0.541 0.558 0.367 0.443 0.737 0.524 0.613 0.561 0.399 0.466 0.703 0.649 0.675 0.549 0.507 0.527 Table 2: Evaluation results. model uses local probability distributions and global decoding, and they transform their data using HR, and so ignore the semantics of discourse relations. Hirao et al. (2013) and Li et al. (2014) also exploit dependency structures by transforming RST trees. Li et al. (2014) used both the Eisner algorithm (Eisner, 1996) as well as the MST algorithm as decoders. We plan to apply ILP techniques to the RST Tree Bank to compare our method with theirs. Most work on discourse parsing focuses on the task of discourse relation labeling between pairs of discourse units—e.g., Marcu and Echihabi (2002) Sporleder and Lascarides (2005) and Lin et al. (2009)—without worrying about global structure. In essence the problem that they treat corresponds only to our local model. As we have argued above, this setting makes an unwarranted assumption, as it assumes independence of local attachment decisions. There is also work on"
N16-1013,J10-3004,0,0.0310875,"sentence-level parsing. Joty et al. (2013) and Joty et al. (2015) present a textlevel discourse parser that uses Conditional Random Fields to capture label inter-dependencies and chart parsing for decoding and have the best results on non-dependency based discourse parsing, with an F1 of 0.689 on unlabelled structures and 0.5587 on labelled structures. The afore-cited work concerns only monologue. Baldridge and Lascarides (2005) predicted tree discourse structures for 2 party “directed” dialogues from the Verbmobil corpus by training a PCFG that exploited the structure of the underlying task. Elsner and Charniak (2010), Elsner and Charniak (2011) present a combination of local coherence models initially provided for monologues showing that those models can satisfactorily model local coherence in chat dialogues. However, they do not present a full discourse parsing model. Our data required a more open domain approach and a more sophisticated approach to structure. Afantenos et al. (2015) worked on multi-party chat dialogues with the same corpus, but they too did not consider the semantics of discourse relations and replaced CDUs with their heads using HR. While this allowed them to use MST decoding over loca"
N16-1013,P11-1118,0,0.0133614,"et al. (2013) and Joty et al. (2015) present a textlevel discourse parser that uses Conditional Random Fields to capture label inter-dependencies and chart parsing for decoding and have the best results on non-dependency based discourse parsing, with an F1 of 0.689 on unlabelled structures and 0.5587 on labelled structures. The afore-cited work concerns only monologue. Baldridge and Lascarides (2005) predicted tree discourse structures for 2 party “directed” dialogues from the Verbmobil corpus by training a PCFG that exploited the structure of the underlying task. Elsner and Charniak (2010), Elsner and Charniak (2011) present a combination of local coherence models initially provided for monologues showing that those models can satisfactorily model local coherence in chat dialogues. However, they do not present a full discourse parsing model. Our data required a more open domain approach and a more sophisticated approach to structure. Afantenos et al. (2015) worked on multi-party chat dialogues with the same corpus, but they too did not consider the semantics of discourse relations and replaced CDUs with their heads using HR. While this allowed them to use MST decoding over local probability distributions,"
N16-1013,P12-1007,0,0.0228851,"ence of local attachment decisions. There is also work on discourse structure within a single sentence; e.g., Soricut and Marcu (2003), Sagae (2009). Such approaches do not apply to our data, as most of the structure in our dialogues lies beyond the sentence level. As for other document-level discourse parsers, Subba and Di Eugenio (2009) use a transition-based approach, following the paradigm of Sagae (2009). duVerle and Prendinger (2009) and Hernault et al. (2010) both rely on locally greedy methods. They 106 treat attachment prediction and relation label prediction as independent problems. Feng and Hirst (2012) extend this approach by additional feature engineering but is restricted to sentence-level parsing. Joty et al. (2013) and Joty et al. (2015) present a textlevel discourse parser that uses Conditional Random Fields to capture label inter-dependencies and chart parsing for decoding and have the best results on non-dependency based discourse parsing, with an F1 of 0.689 on unlabelled structures and 0.5587 on labelled structures. The afore-cited work concerns only monologue. Baldridge and Lascarides (2005) predicted tree discourse structures for 2 party “directed” dialogues from the Verbmobil co"
N16-1013,P15-1147,0,0.0646919,"Missing"
N16-1013,D13-1158,0,0.0548517,"Structures. Predicting full SDRSs (V, E1 , E2 , `) with E2 6= ∅ has been to date impossible, because no reliable method has been identified in the literature for calculating edges in E2 . Instead, most approaches (Muller et al., 2012; Afantenos et al., 2015, for example) simplify the underlying structures by a head replacement strategy (HR) that removes nodes representing CDUs from the original hypergraphs and replacing any incoming or outgoing edges on these nodes on the heads of those CDUs, forming thus dependency structures and not hypergraphs. A similar approach has also been followed by Hirao et al. (2013) and Li et al. (2014) in the context of RST to deal with multi-nuclear relations. Transforming SDRSs using HR does not come without its problems. The decision to attach all incoming and outgoing links to a CDU to its head is one with little theoretical or semantic justification. The semantic effects of attaching an EDU to a CDU are not at all the same as attaching an EDU to the head of the CDU. For example, suppose we have a simple discourse with the following EDUs marked by brackets and discourse connectors in bold : (2) [The French economy continues to suffer]a because [high labor costs rema"
N16-1013,P13-1048,0,0.0234218,"Marcu (2003), Sagae (2009). Such approaches do not apply to our data, as most of the structure in our dialogues lies beyond the sentence level. As for other document-level discourse parsers, Subba and Di Eugenio (2009) use a transition-based approach, following the paradigm of Sagae (2009). duVerle and Prendinger (2009) and Hernault et al. (2010) both rely on locally greedy methods. They 106 treat attachment prediction and relation label prediction as independent problems. Feng and Hirst (2012) extend this approach by additional feature engineering but is restricted to sentence-level parsing. Joty et al. (2013) and Joty et al. (2015) present a textlevel discourse parser that uses Conditional Random Fields to capture label inter-dependencies and chart parsing for decoding and have the best results on non-dependency based discourse parsing, with an F1 of 0.689 on unlabelled structures and 0.5587 on labelled structures. The afore-cited work concerns only monologue. Baldridge and Lascarides (2005) predicted tree discourse structures for 2 party “directed” dialogues from the Verbmobil corpus by training a PCFG that exploited the structure of the underlying task. Elsner and Charniak (2010), Elsner and Cha"
N16-1013,J15-3002,0,0.0406597,"09). Such approaches do not apply to our data, as most of the structure in our dialogues lies beyond the sentence level. As for other document-level discourse parsers, Subba and Di Eugenio (2009) use a transition-based approach, following the paradigm of Sagae (2009). duVerle and Prendinger (2009) and Hernault et al. (2010) both rely on locally greedy methods. They 106 treat attachment prediction and relation label prediction as independent problems. Feng and Hirst (2012) extend this approach by additional feature engineering but is restricted to sentence-level parsing. Joty et al. (2013) and Joty et al. (2015) present a textlevel discourse parser that uses Conditional Random Fields to capture label inter-dependencies and chart parsing for decoding and have the best results on non-dependency based discourse parsing, with an F1 of 0.689 on unlabelled structures and 0.5587 on labelled structures. The afore-cited work concerns only monologue. Baldridge and Lascarides (2005) predicted tree discourse structures for 2 party “directed” dialogues from the Verbmobil corpus by training a PCFG that exploited the structure of the underlying task. Elsner and Charniak (2010), Elsner and Charniak (2011) present a"
N16-1013,P14-1003,0,0.78446,"discourse structures for multi-party dialogue. We show that our method outperforms that of Afantenos et al. (2015) on the corpus they developed. In this paper we present the first, to the best of our knowledge, discourse parser that is able to predict non-tree DAG structures. We use Integer Linear Programming (ILP) to encode both the objective function and the constraints as global decoding over local scores. Our underlying data come from multi-party chat dialogues, which require the prediction of DAGs. We use the dependency parsing paradigm, as has been done in the past (Muller et al., 2012; Li et al., 2014; Afantenos et al., 2015), but we use the underlying formal framework of SDRT and exploit SDRT’s notions of left and right distributive relations. We achieve an Fmeasure of 0.531 for fully labeled structures which beats the previous state of the art. 1 Introduction Multi-party dialogue parsing, in which complete discourse structures for multi-party dialogue or its close cousin, multi-party chat, are automatically constructed, is still in its infancy. Nevertheless, these are now very common forms of communication on the Web. Dialogue appears also importantly different from monologue. Afantenos"
N16-1013,D09-1036,0,0.154759,"Missing"
N16-1013,P14-5010,0,0.0028749,"Missing"
N16-1013,P02-1047,0,0.030536,"ble 2: Evaluation results. model uses local probability distributions and global decoding, and they transform their data using HR, and so ignore the semantics of discourse relations. Hirao et al. (2013) and Li et al. (2014) also exploit dependency structures by transforming RST trees. Li et al. (2014) used both the Eisner algorithm (Eisner, 1996) as well as the MST algorithm as decoders. We plan to apply ILP techniques to the RST Tree Bank to compare our method with theirs. Most work on discourse parsing focuses on the task of discourse relation labeling between pairs of discourse units—e.g., Marcu and Echihabi (2002) Sporleder and Lascarides (2005) and Lin et al. (2009)—without worrying about global structure. In essence the problem that they treat corresponds only to our local model. As we have argued above, this setting makes an unwarranted assumption, as it assumes independence of local attachment decisions. There is also work on discourse structure within a single sentence; e.g., Soricut and Marcu (2003), Sagae (2009). Such approaches do not apply to our data, as most of the structure in our dialogues lies beyond the sentence level. As for other document-level discourse parsers, Subba and Di Eugenio ("
N16-1013,D10-1004,0,0.00961894,"the alternatives and better than the previous state of the art on dependency trees using HR on the gold and MST decoding. We need to investigate further constraints, and to refine and improve our features to get a better local model. Our local model will eventually need to be replaced by one that takes into account more of the surrounding structure when it assigns scores to attachments and labels. We also plan to investigate the use of recurrent neural networks in order to improve our local model. 6 Related Work ILP has been used for various computational linguistics tasks: syntactic parsing (Martins et al., 2010; Fern´andez-Gonz´alez and Martins, 2015), semantic parsing (Das et al., 2014), coreference resolution (Denis and Baldridge, 2007) and temporal analysis (Denis and Muller, 2011). As far as we know, we are the first to use ILP to predict discourse structures. Our use of dependency structures for discourse also has antecedents in the literature. The first we know of is Muller et al. (2012). Their prediction Decoder Model L AST L OCAL MST ILP – local local local L AST L OCAL MST ILP – local local local L AST L OCAL MST ILP – local local local Unlabelled Attachment Labelled Attachment Precision Re"
N16-1013,H05-1066,0,0.0152962,"capturing different dialogue types and linguistic constraints. Finally, we included various minor constraints, such as the fact that EDUs cannot be attached to themselves,5 if EDUs i and j are not attached the pair is not assigned any discourse relation label,6 EDUs within a sequence of contributions by the same speaker in our corpus are linked at least to the previous EDU (Afantenos et al., 2015)7 and edges with zero score are not included in the graph.8 For purposes of comparison with the ILP decoder, we tested the Chu-Liu-Edmonds version of the classic Maximum Spanning Tree (MST) algorithm McDonald et al. (2005) used for discourse parsing by Muller et al. (2012) and Li et al. (2014) and by Afantenos et al. (2015) on the Settlers corpus. This algorithm requires a specific node to be the root, i.e. a node without any incoming edges, of the initial complete graph. For each dialogue, we made an artificial node as the root with special dummy features. At the end of the procedure, this node points to the real root of the discourse graph. As baseline measures, we included what we call a L OCAL decoder which creates a simple classifier out of the raw local probability distribution. Since we use MaxEnt, this"
N16-1013,C12-1115,1,0.8627,"d non-treelike, full discourse structures for multi-party dialogue. We show that our method outperforms that of Afantenos et al. (2015) on the corpus they developed. In this paper we present the first, to the best of our knowledge, discourse parser that is able to predict non-tree DAG structures. We use Integer Linear Programming (ILP) to encode both the objective function and the constraints as global decoding over local scores. Our underlying data come from multi-party chat dialogues, which require the prediction of DAGs. We use the dependency parsing paradigm, as has been done in the past (Muller et al., 2012; Li et al., 2014; Afantenos et al., 2015), but we use the underlying formal framework of SDRT and exploit SDRT’s notions of left and right distributive relations. We achieve an Fmeasure of 0.531 for fully labeled structures which beats the previous state of the art. 1 Introduction Multi-party dialogue parsing, in which complete discourse structures for multi-party dialogue or its close cousin, multi-party chat, are automatically constructed, is still in its infancy. Nevertheless, these are now very common forms of communication on the Web. Dialogue appears also importantly different from mono"
N16-1013,prasad-etal-2008-penn,0,0.251577,"Missing"
N16-1013,W09-3813,0,0.0483895,"the RST Tree Bank to compare our method with theirs. Most work on discourse parsing focuses on the task of discourse relation labeling between pairs of discourse units—e.g., Marcu and Echihabi (2002) Sporleder and Lascarides (2005) and Lin et al. (2009)—without worrying about global structure. In essence the problem that they treat corresponds only to our local model. As we have argued above, this setting makes an unwarranted assumption, as it assumes independence of local attachment decisions. There is also work on discourse structure within a single sentence; e.g., Soricut and Marcu (2003), Sagae (2009). Such approaches do not apply to our data, as most of the structure in our dialogues lies beyond the sentence level. As for other document-level discourse parsers, Subba and Di Eugenio (2009) use a transition-based approach, following the paradigm of Sagae (2009). duVerle and Prendinger (2009) and Hernault et al. (2010) both rely on locally greedy methods. They 106 treat attachment prediction and relation label prediction as independent problems. Feng and Hirst (2012) extend this approach by additional feature engineering but is restricted to sentence-level parsing. Joty et al. (2013) and Jot"
N16-1013,N03-1030,0,0.138299,"o apply ILP techniques to the RST Tree Bank to compare our method with theirs. Most work on discourse parsing focuses on the task of discourse relation labeling between pairs of discourse units—e.g., Marcu and Echihabi (2002) Sporleder and Lascarides (2005) and Lin et al. (2009)—without worrying about global structure. In essence the problem that they treat corresponds only to our local model. As we have argued above, this setting makes an unwarranted assumption, as it assumes independence of local attachment decisions. There is also work on discourse structure within a single sentence; e.g., Soricut and Marcu (2003), Sagae (2009). Such approaches do not apply to our data, as most of the structure in our dialogues lies beyond the sentence level. As for other document-level discourse parsers, Subba and Di Eugenio (2009) use a transition-based approach, following the paradigm of Sagae (2009). duVerle and Prendinger (2009) and Hernault et al. (2010) both rely on locally greedy methods. They 106 treat attachment prediction and relation label prediction as independent problems. Feng and Hirst (2012) extend this approach by additional feature engineering but is restricted to sentence-level parsing. Joty et al."
N16-1013,N09-1064,0,0.100897,"Missing"
N16-1013,D11-1002,0,0.0580876,"Missing"
N16-1013,W01-1605,0,\N,Missing
P15-1028,D12-1050,0,0.0232909,"unction model and generalised lexical function model on different datasets, which involve more complex compositional phenomena. node in a syntactic tree is assigned both a vector and a matrix; the vector captures the actual meaning of the constituent, while the matrix models the way it changes the meaning of neighbouring words and phrases. They use an extrinsic evaluation, using the model for a sentiment prediction task. They show that their model gets better results than the additive, multiplicative, and lexical function approach. Other researchers, however, have published different results. Blacoe and Lapata (2012) evaluated the additive and multiplicative model, as well as Socher et al.’s (2012) approach on two different tasks: Mitchell & Lapata’s (2010) similarity task and a paraphrase detection task. They find that the additive and multiplicative models reach better scores than Socher et al.’s model. Tensors have been used before to model different aspects of natural language. Giesbrecht (2010) describes a tensor factorization model for the construction of a distributional model that is sensitive to word order. And Van de Cruys (2010) uses a tensor factorization model in order to construct a three-wa"
P15-1028,candito-etal-2010-statistical,0,0.0426075,"Missing"
P15-1028,J90-1003,0,0.325191,"t set for French tions from the QuestionBank5 . For both corpora, we extracted the lemmas of all nouns, adjectives and (bag of words) context words. We only kept those lemmas that consist of alphabetic characters.6 We then selected the 10K most frequent lemmas for each category (nouns, adjectives, context words), making sure to include all the words from the test set. As a final step, we created our semantic space vectors using adjectives and nouns as instances, and bag of words context words as features. The resulting vectors were weighted using positive point-wise mutual information (ppmi, (Church and Hanks, 1990)), and all vectors were normalized to unit length. We then compared the different composition methods on different versions of the same semantic space (both for French and English): the full semantic space, a reduced version of the space to 300 dimensions using singular value decomposition (svd, (Golub and Van Loan, 1996)), and a reduced version of the space to 300 dimensions using non-negative matrix factorization (nmf, (Lee and Seung, 2000)). We did so in order to test each method in its optimal conditions. In fact: eralised approach. • Previous research has indicated that the lexical functi"
P15-1028,S13-2007,0,0.013015,"uires only the knowledge of the vectors blood, donation and campaign. We would then perform the following computations: blood donation = (N × blood) × donation blood donation campaign = (N × blood donation) × campaign and this allows us to avoid the sparse data problem for the LF approach in generating the matrix BLOOD DONATION . Once we have obtained the tensor A , we verify experimentally its relevance to composition, in order to check whether a tensor optimising the equations in Figure 4 would be semantically interesting. 3 3.1 (2010) and the SEMEVAL-2013 task evaluating phrasal semantics (Korkontzelos et al., 2013). The task is to make a judgement about the semantic similarity of a short word sequence (an adjectivenoun combination) and a single noun. This is important, as composition models need to be able to treat word sequences of arbitrary length. Formally, the task is presented as: With comp = composition(adj, noun1 ) Evaluate similarity(comp, noun2 ) where the ‘composition’ function is carried out by the different composition models. ‘Similarity’ needs to be a binary function, with return values ‘similar’ and ‘non-similar’. Note, however, that the distributional approach yields a continuous similar"
P15-1028,2010.jeptalnrecital-long.3,0,0.0774218,"Missing"
P15-1028,P13-4006,0,0.187999,"ve and noun combined, which are perforce less exemplified than the presence of the noun or adjective in isolation. In Figure 2, each of the occurrences of ‘name’ can contribute to the information in the vector name but none can contribute to the vector evanescent name. Baroni and Zamparelli (2010) offer an explanation of how to cope with the potential sparse data problem for learning matrices for adjectives. Moreover, recent evaluations of LF show that existent corpora have enough data for it to provide a semantics for the most frequent adjectives and obtain better results than other methods (Dinu et al., 2013b). Nevertheless, LF has limitations in treating relatively rare adjectives. For example, the adjective ‘evanescent’ appears 359 times in the UKWaC corpus (Baroni et al., 2009). This is enough to generate a vector for evanescent, but may not be sufficient to generate a sufficient number of vectors evanescent noun to build the matrix EVANES CENT . More importantly, for noun-noun combinations, one may need to have a LF for a combination. To get the meaning of blood donation campaign in the LF approach, the matrix BLOOD DONATION must be combined to the vector campaign. Learning this matrix would"
P15-1028,W13-3206,0,0.0523727,"ve and noun combined, which are perforce less exemplified than the presence of the noun or adjective in isolation. In Figure 2, each of the occurrences of ‘name’ can contribute to the information in the vector name but none can contribute to the vector evanescent name. Baroni and Zamparelli (2010) offer an explanation of how to cope with the potential sparse data problem for learning matrices for adjectives. Moreover, recent evaluations of LF show that existent corpora have enough data for it to provide a semantics for the most frequent adjectives and obtain better results than other methods (Dinu et al., 2013b). Nevertheless, LF has limitations in treating relatively rare adjectives. For example, the adjective ‘evanescent’ appears 359 times in the UKWaC corpus (Baroni et al., 2009). This is enough to generate a vector for evanescent, but may not be sufficient to generate a sufficient number of vectors evanescent noun to build the matrix EVANES CENT . More importantly, for noun-noun combinations, one may need to have a LF for a combination. To get the meaning of blood donation campaign in the LF approach, the matrix BLOOD DONATION must be combined to the vector campaign. Learning this matrix would"
P15-1028,P98-2127,0,0.118857,"within the distributional framework for the cases of both adjectivenoun and noun-noun composition, making use of a newly developed dataset. Secondly, we propose a novel method for composition, which generalises the approach by Baroni and Zamparelli (2010). The performance of our novel method is also evaluated on our new dataset and proves competitive with the best methods. 1 Nicholas Asher IRIT & CNRS, Toulouse nicholas.asher@irit.fr Introduction In the course of the last two decades, there has been a growing interest in distributional methods for lexical semantics (Landauer and Dumais, 1997; Lin, 1998; Turney and Pantel, 2010). These methods are based on the distributional hypothesis (Harris, 1954), according to which words that appear in the same contexts tend to be similar in meaning. Inspired by Harris’ hypothesis, numerous researchers have developed algorithms that try to capture the semantics of individual words by looking at their distribution in a large corpus. Compared to manual studies common to formal semantics, distributional semantics offers substantially larger coverage since it is able to analyze 1A notable exception is (Marelli et al., 2014), who propose a large-scale evalua"
P15-1028,N10-3005,0,0.0191281,"sentiment prediction task. They show that their model gets better results than the additive, multiplicative, and lexical function approach. Other researchers, however, have published different results. Blacoe and Lapata (2012) evaluated the additive and multiplicative model, as well as Socher et al.’s (2012) approach on two different tasks: Mitchell & Lapata’s (2010) similarity task and a paraphrase detection task. They find that the additive and multiplicative models reach better scores than Socher et al.’s model. Tensors have been used before to model different aspects of natural language. Giesbrecht (2010) describes a tensor factorization model for the construction of a distributional model that is sensitive to word order. And Van de Cruys (2010) uses a tensor factorization model in order to construct a three-way selectional preference model of verbs, subjects, and objects. 5 6 Acknowledgments We thank Dinu et al. (2013a) for their work on the D is S e CT toolkit8 , which provides plenty of helpful functions for composition in distributional semantics. We also thank the OSIRIM platform9 for allowing us to do the computations we needed. Finally, we thank the reviewers of this paper for their ins"
P15-1028,S14-2001,0,0.0187765,"lexical semantics (Landauer and Dumais, 1997; Lin, 1998; Turney and Pantel, 2010). These methods are based on the distributional hypothesis (Harris, 1954), according to which words that appear in the same contexts tend to be similar in meaning. Inspired by Harris’ hypothesis, numerous researchers have developed algorithms that try to capture the semantics of individual words by looking at their distribution in a large corpus. Compared to manual studies common to formal semantics, distributional semantics offers substantially larger coverage since it is able to analyze 1A notable exception is (Marelli et al., 2014), who propose a large-scale evaluation dataset for composition at the sentence level. 281 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 281–291, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics side the scope of this paper. We tested three simple models of composition: a baseline method that discounts the contribution of the adjective completely, and the additive and multiplicative models of composition. The baseline method is defined as f"
P15-1028,D11-1129,0,0.10157,"o the fact that the subordinate noun in noun-noun combinations is more important than the adjective subordinate in adjective-noun combination. 4 Coecke et al. (2010) present an abstract theoretical framework in which a sentence vector is a function of the Kronecker product of its word vectors, which allows for greater interaction between the different word features. A number of instantiations of the framework – where the key idea is that relational words (e.g. adjectives or verbs) have a rich (multi-dimensional) structure that acts as a filter on their arguments – are tested experimentally in Grefenstette and Sadrzadeh (2011a) and Grefenstette and Sadrzadeh (2011b). The authors evaluated their models using a similarity task that is similar to the one used by Mitchell & Lapata. However, they use more complex compositional expressions: rather than using compositions of two words (such as a verb and an object), they use simple transitive phrases (subject-verbobject). They show that their instantiations of the categorical model reach better results than the additive and multiplicative models on their transitive similarity task. Related work Many researchers have already studied and evaluated different composition mod"
P15-1028,W11-2507,0,0.0709514,"o the fact that the subordinate noun in noun-noun combinations is more important than the adjective subordinate in adjective-noun combination. 4 Coecke et al. (2010) present an abstract theoretical framework in which a sentence vector is a function of the Kronecker product of its word vectors, which allows for greater interaction between the different word features. A number of instantiations of the framework – where the key idea is that relational words (e.g. adjectives or verbs) have a rich (multi-dimensional) structure that acts as a filter on their arguments – are tested experimentally in Grefenstette and Sadrzadeh (2011a) and Grefenstette and Sadrzadeh (2011b). The authors evaluated their models using a similarity task that is similar to the one used by Mitchell & Lapata. However, they use more complex compositional expressions: rather than using compositions of two words (such as a verb and an object), they use simple transitive phrases (subject-verbobject). They show that their instantiations of the categorical model reach better results than the additive and multiplicative models on their transitive similarity task. Related work Many researchers have already studied and evaluated different composition mod"
P15-1028,nivre-etal-2006-maltparser,0,0.0864781,"om negative test set for English in the same fashion we did for the second negative test set for French. Finally, the original test set also contains nounnoun compounds so we also created a test set for that. This gave us 226 positive and negative pairs for the noun-noun composition. 3.2 Semantic space construction In this section, we describe the construction of our semantic space. Our semantic space for French was built using the FRWaC corpus (Baroni et al., 2009) – about 1,6 billion words of web texts – which has been tagged with MElt tagger (Denis et al., 2010) and parsed with MaltParser (Nivre et al., 2006a), trained on a dependency-based version of the French treebank (Candito et al., 2010). Our semantic space for English has been built using the UKWaC corpus (Baroni et al., 2009), which consists of about 2 billion words extracted from the web. The corpus has been part of speech tagged and lemmatized with Stanford Part-OfSpeech Tagger (Toutanova and Manning, 2000; Toutanova et al., 2003), and parsed with MaltParser (Nivre et al., 2006b) trained on sections 2-21 of the Wall Street Journal section of the Penn Treebank extended with about 4000 ques4 i.e. less than 200 times for adjectives and les"
P15-1028,W13-0112,0,0.0150056,"nd Zamparelli (2010) evaluate their lexical function model within a somewhat different context. They evaluated their model by looking at its capacity of reconstructing the adjective noun vectors that have not been seen during training. Their results show that their lexical function model obtains the best results for the reconstruction of the original co-occurrence vectors, followed by the additive model. We observe the same tendency in our evaluation results for French, although our results for English show a different picture. We would like to explore this discordance further in future work. Grefenstette et al. (2013) equally propose a generalisation of the lexical function model that uses tensors. Their goal is to model transitive verbs, and the way we acquire our tensor is similar to theirs. In fact, they use the LF approach in order to learn VERB OBJECT matrices that may be multiplied by a subject vector to obtain the subject verb object vector. In a second step, they learn a tensor for each individual verb, which is similar to how we learn our adjective tensor A . Noun-noun The noun-noun tests (Table 3) yields similar results to the adjective-noun tests. This is not so surprising since noun noun compou"
P15-1028,P81-1022,0,0.601482,"Missing"
P15-1028,D12-1110,0,0.0647462,"a in a systematic way is Mitchell and Lapata’s (2008) approach. They explore a number of different models for vector composition, of which vector addition (the sum of each feature) and vector multiplication (the element-wise multiplication of each feature) are the most important. They evaluate their models on a noun-verb phrase similarity task. Human annotators were asked to judge the similarity of two composed pairs (by attributing a certain score). The model’s task is then to reproduce the human judgements. Their results show that the multiplicative model yields the best results, along with Socher et al. (2012) present a compositional model based on a recursive neural network. Each 288 In future work, we would like to test different sizes of dimensionality reduction, in order to optimize our generalised lexical function model. Moreover, it is possible that better results may be obtained by proposing multiple generalised lexical functions, rather than a single one. We could, e.g., try to separate the intersective adjectives from non-intersective adjectives. And finally, we would like to further explore the performance of the lexical function model and generalised lexical function model on different d"
P15-1028,W00-1308,0,0.151951,"uction of our semantic space. Our semantic space for French was built using the FRWaC corpus (Baroni et al., 2009) – about 1,6 billion words of web texts – which has been tagged with MElt tagger (Denis et al., 2010) and parsed with MaltParser (Nivre et al., 2006a), trained on a dependency-based version of the French treebank (Candito et al., 2010). Our semantic space for English has been built using the UKWaC corpus (Baroni et al., 2009), which consists of about 2 billion words extracted from the web. The corpus has been part of speech tagged and lemmatized with Stanford Part-OfSpeech Tagger (Toutanova and Manning, 2000; Toutanova et al., 2003), and parsed with MaltParser (Nivre et al., 2006b) trained on sections 2-21 of the Wall Street Journal section of the Penn Treebank extended with about 4000 ques4 i.e. less than 200 times for adjectives and less than 1500 times for nouns 285 positive examples random negative examples Wiktionary-based negative examples (mot court, abr´eviation) ‘short word’, ‘abbreviation’ (ouvrage litt´eraire, essai) ‘literary work’, ‘essay’ (compagnie honorifique, ordre) ‘honorary company’, ‘order’ (importance fortuit, gamme) ‘accidental importance’, ‘range’ (penchant autoritaire, ile"
P15-1028,N03-1033,0,0.0345002,"Our semantic space for French was built using the FRWaC corpus (Baroni et al., 2009) – about 1,6 billion words of web texts – which has been tagged with MElt tagger (Denis et al., 2010) and parsed with MaltParser (Nivre et al., 2006a), trained on a dependency-based version of the French treebank (Candito et al., 2010). Our semantic space for English has been built using the UKWaC corpus (Baroni et al., 2009), which consists of about 2 billion words extracted from the web. The corpus has been part of speech tagged and lemmatized with Stanford Part-OfSpeech Tagger (Toutanova and Manning, 2000; Toutanova et al., 2003), and parsed with MaltParser (Nivre et al., 2006b) trained on sections 2-21 of the Wall Street Journal section of the Penn Treebank extended with about 4000 ques4 i.e. less than 200 times for adjectives and less than 1500 times for nouns 285 positive examples random negative examples Wiktionary-based negative examples (mot court, abr´eviation) ‘short word’, ‘abbreviation’ (ouvrage litt´eraire, essai) ‘literary work’, ‘essay’ (compagnie honorifique, ordre) ‘honorary company’, ‘order’ (importance fortuit, gamme) ‘accidental importance’, ‘range’ (penchant autoritaire, ile) ‘authoritarian slope’,"
P15-1028,C10-1142,0,0.0929425,"distributions in a vector space model. However, it is not straightforward to construct meaning representations beyond the level of individual words – i.e. the combination of words into larger units – using distributional methods. Our contribution is twofold. First of all, we carry out a largescale evaluation, comparing different composition methods within the distributional framework for the cases of both adjectivenoun and noun-noun composition, making use of a newly developed dataset. Secondly, we propose a novel method for composition, which generalises the approach by Baroni and Zamparelli (2010). The performance of our novel method is also evaluated on our new dataset and proves competitive with the best methods. 1 Nicholas Asher IRIT & CNRS, Toulouse nicholas.asher@irit.fr Introduction In the course of the last two decades, there has been a growing interest in distributional methods for lexical semantics (Landauer and Dumais, 1997; Lin, 1998; Turney and Pantel, 2010). These methods are based on the distributional hypothesis (Harris, 1954), according to which words that appear in the same contexts tend to be similar in meaning. Inspired by Harris’ hypothesis, numerous researchers hav"
P15-1028,D10-1115,0,\N,Missing
P15-1028,P08-1028,0,\N,Missing
P15-1028,C98-2122,0,\N,Missing
P19-1061,D15-1109,1,0.937715,"Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics After applying the LFs to the unannotated data and training the generative model, the F1 score for attachment was 4 points higher than that for the supervised method, showing that hybrid learning architectures combining expert linguistic conceptual knowledge with data-driven techniques can be highly competitive with standard learning approaches. 2 elementary discourse units, a “local model”, with a positive F1 attachment score of 63.5; global decoding constraints produce a slight improvement in attachment scores. (Afantenos et al., 2015) uses a similar strategy on an early version of the STAC corpus. (Perret et al., 2016) targets a more elaborate approximation of SDRT graphs on a later version of the STAC corpus and reports a local model F1 attachment of .483. It then uses Integer Linear Programming (ILP) to encode global decoding constraints to improve the F1 attachment score (0.689). (Ratner et al., 2016) introduced the data programming paradigm, along with a framework, Snorkel (Ratner et al., 2017), which uses a weak supervision method (Zhou, 2017), to apply labels to large data sets by way of heuristic labeling functions"
P19-1061,L16-1432,1,0.898866,"uses a generative model to unify the noisy labels by generating a probability distribution for all labels for each data point. This set of probabilities replaces the ground-truth labels in a standard discriminative model outfitted with a noise-aware loss function and trained on a sufficiently large data set. State of the Art Given that our interest lies in the analysis of multiparty dialogue, we followed (Afantenos et al., 2015; Perret et al., 2016) and used the STAC corpus, in which dialogue structures are assumed to be directed acyclical graphs (DAG) as in SDRT2 (Asher and Lascarides, 2003; Asher et al., 2016). An SDRT discourse structure is a graph, hV, E1 , E2 , `, Lasti, where: V is a set of nodes or discourse units (DUs); E1 ⊆ V 2 is a set of edges between DUs representing coherence relations; E2 ⊆ V 2 represents a dependency relation between DUs; ` : E1 → R is a labeling function that assigns a semantic type to an edge in E1 from a set R of discourse relation types, and Last is a designated element of V giving the last DU relative to textual or temporal order. E2 is used to represent Complex Discourse Units (CDUs), which are clusters of two or more DUs which are connected as an ensemble to oth"
P19-1061,P09-1075,0,0.0936711,"Missing"
P19-1061,P14-1002,0,0.0926795,"Missing"
P19-1061,P13-1048,0,0.152327,"Missing"
P19-1061,D14-1196,0,0.0497233,"Missing"
P19-1061,D16-1035,0,0.0881724,"Missing"
P19-1061,P14-1003,0,0.0308853,"decide where a given discourse unit attaches to other units in a text in order to form a coherent discourse structure. Although approaching this problem using Snorkel requires significant modifications to the structure of the heuristics, we show that weak supervision methods can be more than competitive with classical supervised learning approaches to the attachment problem. 1 Introduction Discourse structures for texts represent relational semantic structures that convey causal, topical, argumentative relations inter alia or more generally coherence relations. Following (Muller et al., 2012; Li et al., 2014; Morey et al., 2018), we represent them as dependency structures or graphs containing a set of nodes that represent discourse units (DUs), or instances of propositional content, and a set of labelled arcs that represent coherent relations between DUs. For dialogues with multiple interlocutors, extraction of their discourse structures could provide useful semantic information to the “downstream” models used, for example, in the production of intelligent meeting man1 https://www.irit.fr/STAC/ 640 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 640–"
P19-1061,P09-1113,0,0.0432088,"estimated by minimizing the negative log marginal likelihood of the output of an observed matrix Λ as in (2). argminθ − log X pθ (Λ, Y ) (2) Y The generative model thus estimates the accuracy of each LF, a marginal probability for each label, and consequently a probability for positive attachment. In this model, the true class labels yi are latent variables that generate the labeling function outputs. The model in (1) presupposes that the LFs are independent, but this assumption doesn’t always hold: one LF might be a variation of another or they might depend on a common source of information (Mintz et al., 2009). We will look at dependencies between LFs in future work. 642 Individual LF Performances Coverage True Pos True Neg False Pos 0.32 282 9397 239 0.31 84 9476 4 0.31 758 8636 134 0.16 13 4596 319 0.32 21 9371 617 0.21 2 6535 0 0.32 16 9818 110 0.31 613 8867 83 0.21 82 6351 84 0.31 236 8199 1053 0.32 123 8632 1140 0.21 12 6369 57 0.32 9 10026 7 0.32 67 9694 214 0.31 48 9420 96 0.32 50 9612 251 0.32 14 9978 11 QAP LL QAP NLNL Result NLNL Result LNL Result LL Result NLL Continuation LL Continuation NLNL Sequence NLL Sequence NLNL Comment LL Comment NLL Conditional LL Elaboration LL Elaboration NLN"
P19-1061,J18-2001,1,0.791582,"ven discourse unit attaches to other units in a text in order to form a coherent discourse structure. Although approaching this problem using Snorkel requires significant modifications to the structure of the heuristics, we show that weak supervision methods can be more than competitive with classical supervised learning approaches to the attachment problem. 1 Introduction Discourse structures for texts represent relational semantic structures that convey causal, topical, argumentative relations inter alia or more generally coherence relations. Following (Muller et al., 2012; Li et al., 2014; Morey et al., 2018), we represent them as dependency structures or graphs containing a set of nodes that represent discourse units (DUs), or instances of propositional content, and a set of labelled arcs that represent coherent relations between DUs. For dialogues with multiple interlocutors, extraction of their discourse structures could provide useful semantic information to the “downstream” models used, for example, in the production of intelligent meeting man1 https://www.irit.fr/STAC/ 640 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 640–645 c Florence, Italy"
P19-1061,C12-1115,1,0.871748,"t, in which one must decide where a given discourse unit attaches to other units in a text in order to form a coherent discourse structure. Although approaching this problem using Snorkel requires significant modifications to the structure of the heuristics, we show that weak supervision methods can be more than competitive with classical supervised learning approaches to the attachment problem. 1 Introduction Discourse structures for texts represent relational semantic structures that convey causal, topical, argumentative relations inter alia or more generally coherence relations. Following (Muller et al., 2012; Li et al., 2014; Morey et al., 2018), we represent them as dependency structures or graphs containing a set of nodes that represent discourse units (DUs), or instances of propositional content, and a set of labelled arcs that represent coherent relations between DUs. For dialogues with multiple interlocutors, extraction of their discourse structures could provide useful semantic information to the “downstream” models used, for example, in the production of intelligent meeting man1 https://www.irit.fr/STAC/ 640 Proceedings of the 57th Annual Meeting of the Association for Computational Lingui"
P19-1061,N16-1013,1,0.935701,"lying the LFs to the unannotated data and training the generative model, the F1 score for attachment was 4 points higher than that for the supervised method, showing that hybrid learning architectures combining expert linguistic conceptual knowledge with data-driven techniques can be highly competitive with standard learning approaches. 2 elementary discourse units, a “local model”, with a positive F1 attachment score of 63.5; global decoding constraints produce a slight improvement in attachment scores. (Afantenos et al., 2015) uses a similar strategy on an early version of the STAC corpus. (Perret et al., 2016) targets a more elaborate approximation of SDRT graphs on a later version of the STAC corpus and reports a local model F1 attachment of .483. It then uses Integer Linear Programming (ILP) to encode global decoding constraints to improve the F1 attachment score (0.689). (Ratner et al., 2016) introduced the data programming paradigm, along with a framework, Snorkel (Ratner et al., 2017), which uses a weak supervision method (Zhou, 2017), to apply labels to large data sets by way of heuristic labeling functions that can access distant, disparate knowledge sources. These labels are then used to tr"
P91-1008,J88-2003,0,0.0583094,"Missing"
P91-1008,J88-2006,0,0.0573782,"man&apos;s (1988) tripartite structure of events, where an event consists of a preparatory phase, a culmination and a consequent phase. 55 logical forms. They indicate, therefore, that the constraints on the use of the above discourse relations cannot rely solely on the logical forms of the sentences concerned. eludes a causal &apos;law&apos; gained from perception and experience that relates falling and pushing: 3 • Causal Law 3 Connected events el where x falls and e2 where y pushes z are normally such that e2 No theory at present is able to explain the distinct temporal structures of all the above texts. Webber (1988) observes that Kamp & Rohrer (1983), Partee (1984), Hinrichs (1986) and Dowty (1986) don&apos;t account for the backwards movement of time in (2) and (3). Webber (1988) can account for the backwards movement of time in (2), but her theory is unable to predict that mismatching the descriptive order of events and their temporal order is allowed in some cases (e.g. (2) and (3)) but not in others (e.g. (1), which would be misleading if the situation being described were one where the greeting happened before Max stood causes el. There is no similar law for standing up and greeting. The above law is a d"
P91-1008,C88-2120,0,\N,Missing
P92-1001,P91-1008,1,0.911495,"Missing"
P92-1001,P84-1044,0,0.0788087,"Missing"
P92-1001,P84-1085,0,0.0618376,"Missing"
P92-1001,C92-2108,1,0.880872,"Missing"
P92-1001,C88-2120,0,0.0612825,"ncorporate MCT into DICE's formal model of discourse structure, where its interaction with other causal information and strategies for interpretation can be precisely calculated. Discourse Interpretation and Commonsense Entailment DICE (Discourse and C_ommonsense Entailment) starts with traditional discourse representation structures (cf. K a m p 1981), but goes on to assume with Grosz and Sidner (1986) that candidate discourses possess hierarchical structure, with units linked by discourse relations modelled after those proposed by IIobbs (1979, 1985) (cf. also T h o m p s o n and Mann 1987, Scha and Polanyi 1988). 1 Lascarides and Asher (1991a) use Narration, Explanation, Background, Result and Elaboration. These are the discourse relations central to temporal import and they are the only ones we consider here. Full coverage of text would require a larger set of relations, akin to that in T h o m p s o n and Mann (1987). DICE is a dynamic, logical theory for determining the discourse relations between sentences in a text, and the temporal relations between the eventualities they describe. T h e logic used is the nonmonotonic logic Commonsense Entailment (CE) proposed by Asher and Morreau (1991). Impli"
P92-1001,J86-3001,0,\N,Missing
P94-1006,P91-1008,1,0.910216,"ations that express the discourse function of the constituents in the communicative plan of the author, and we permit interaction between reasoning about rhetorical relations and reasoning about beliefs and desires. This paper provides the first steps towards a formal analysis of the interaction between intentional structure and informational structure. Our framework for discourse structure analysis is SDRT (Asher 1993). The basic representational structures of that theory may be used to characterise cognitive states. We will extend the logical engine used to infer rhetorical relations--DiCE (Lascarides and Asher 1991, 1993a, 1993b, Lascarides and Oberlander 1993)--to model inferences about intentional structure and its interaction with informational structure. This paper is about the flow of inference between communicative intentions, discourse structure and the domain during discourse processing. We augment a theory of discourse interpretation with a theory of distinct mental attitudes and reasoning about them, in order to provide an account of how the attitudes interact with reasoning about discourse structure. INTRODUCTION The flow of inference between communicative intentions and domain information is"
P94-1006,E93-1030,1,0.849361,"ld cause Bush to veto this bill. So, A must. have uttered (la) to support (lb). Hence I realises that A wan~ed BUSH&apos;S REQUIREMENTS We must represent both the intentional import and the informational import of a discourse simultaneously. So we need a theory of discourse structure where discourse relations central to intentional import and to informational import can hold simultaneously between the same constituents. A logical framework in which all those plausible relations between constituents that are consistent with each other are inferred, such as a nonmonotonic logic like that in D I C E (Lascarides and Asher, 1993a), would achieve this. So conceivably, a similar nonmonotonic logic for RST might solve the problem of keeping track of the intentional and informational 34 • SDRSS have a hierarchical configuration, and S D R T predicts points of a t t a c h m e n t in a discourse structure for new information. Using DICE we infer from the reader&apos;s knowledge resources which discourse relation should be used to do attachment. Lascarides and Asher (1991) introduce default rules representing the role of Gricean p r a g m a t i c m a x i m s and domain knowledge in calculating the value of the update function (r"
P94-1006,P92-1001,1,0.887721,"Missing"
P94-1006,E93-1031,1,0.750814,"n of the constituents in the communicative plan of the author, and we permit interaction between reasoning about rhetorical relations and reasoning about beliefs and desires. This paper provides the first steps towards a formal analysis of the interaction between intentional structure and informational structure. Our framework for discourse structure analysis is SDRT (Asher 1993). The basic representational structures of that theory may be used to characterise cognitive states. We will extend the logical engine used to infer rhetorical relations--DiCE (Lascarides and Asher 1991, 1993a, 1993b, Lascarides and Oberlander 1993)--to model inferences about intentional structure and its interaction with informational structure. This paper is about the flow of inference between communicative intentions, discourse structure and the domain during discourse processing. We augment a theory of discourse interpretation with a theory of distinct mental attitudes and reasoning about them, in order to provide an account of how the attitudes interact with reasoning about discourse structure. INTRODUCTION The flow of inference between communicative intentions and domain information is often essential to discourse processing. It is"
P94-1006,J92-4007,0,0.423055,"structure and its interaction with informational structure. This paper is about the flow of inference between communicative intentions, discourse structure and the domain during discourse processing. We augment a theory of discourse interpretation with a theory of distinct mental attitudes and reasoning about them, in order to provide an account of how the attitudes interact with reasoning about discourse structure. INTRODUCTION The flow of inference between communicative intentions and domain information is often essential to discourse processing. It is well reflected in this discourse from Moore and Pollack (1992): (1)a. George Bush supports big business. b. He&apos;s sure to veto House Bill 1711. There are at least three different interpretations. Consider Context 1: in this context the interpreter I believes that the author A wants to convince him that (lb) is true. For example, the context is one in which I has already uttered Bush won&apos;t veto any more bills. I reasons that A &apos; s linguistic behavior was intentional, and therefore that A believes that by saying (la) he will convince I that Bush will veto the bill. Even if I believed nothing about the bill, he now infers it&apos;s bad for big business. So we hav"
P94-1006,J86-3001,0,\N,Missing
S12-1018,W11-2023,1,0.505772,".co.uk/worldservice/ learningenglish). It contains 21 randomly selected dialogues, in which one agent (the customer) calls a service to book a room, a flight, a taxi, etc. Here is a typical fragment: π1 A: Northwind Airways, good morning. May I help you? π2 B: Yes, do you have any flights to Sydney next Tuesday? π3 A: Yes, there’s a flight at 16:45 and one at 18:00. π4 A: Economy, business class or first class ticket? π5 B: Economy, please. Our approach to preference acquisition exploits discourse structure and aims to study the impact of discourse for extracting and reasoning on preferences. Cadilhac et al. (2011) show how to compute automatically preference representations for a whole stretch of dialogue from the preference representations for elementary discourse units. Our annotation here concentrates on the commitments to pref107 erences expressed in elementary discourse units or EDU s. We analyze how the outcomes and the dependencies between them are linguistically expressed by performing, on each corpus, a two-level annotation. First, we perform a segmentation of the dialogue into EDUs. Second, we annotate preferences expressed by the EDUs. The examples above show the effects of segmentation. Eac"
S12-1018,C08-1031,0,0.0130598,"bsolute judgments towards objects or persons (positive, negative or neutral), while preferences concern relative judgments towards actions (preferring them or not over others). The following examples illustrate this: (a) The movie is not bad. (b) The scenario of the first season is better than the second one. (c) I would like to go to the cinema. Let’s go and see Madagascar 2. (a) expresses a direct positive opinion towards the movie but we do not know if this movie is the most preferred. (b) expresses a comparative opinion between two movies with respect to their shared features (scenarios) (Ganapathibhotla and Liu, 2008). If actions involving these movies (e.g. seeing them) are clear in the context, such a comparative opinion will imply a preference, ordering the first season scenario over the second. Finally, (c) expresses two preferences, one depending on the other. The first is that the speaker prefers to go to the cinema over other alternative actions; the second is, given that preference, that he wants to see Madagascar 2 over other possible movies. Reasoning about preferences is also distinct from reasoning about opinions. An agent’s preferences determine an order over outcomes that predicts how the age"
W08-0104,P92-1005,0,0.122885,"two reasons. Firstly, revision means that there is in principle no general way of stating what information is preserved from the previous discourse state to the current one. But if we construct logical form in a monotonic way—in our case, this means that the discourse structure for a conversation at turn n is an elementary substructure of the discourse structure at turn n + 1—then standard preservation results from model theory apply. Secondly, monotonicity guarantees that interpretation algorithms can proceed incrementally, combining information from various sources in a nondestructive way (Alshawi and Crouch, 1992). To our knowledge, there is currently no dynamic semantics for dialogue that yields adequate interpretations of corrections and implicit agreement. We will address this gap here. In Section 2, we re29 Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 29–36, c Columbus, June 2008. 2008 Association for Computational Linguistics view two existing approaches to motivate our basic strategy, which we then describe in Section 3. We will refine SDRT so that it tracks each dialogue participant’s public commitments. Further, while identifying a speech act involves default reasoni"
W08-0104,P94-1001,0,0.340397,"ialogue agents agree on. This includes implicit agreement: (1) a. b. c. A: The room went dark. A: Max turned out the light. B: And John drew the blinds. Intuitively, A and B agree that the room went dark, that Max turned out the light, and that the latter is at least part of the reason why the former occurred. Thus, implicatures can be agreed upon (that (1b) is part of the cause of (1a) goes beyond compositional semantics), and agreement can be implicated (B does not repeat (1a) and (1b) nor utter OK to indicate his agreement with A). In principle, the Grounding Acts Model (GAM, Traum (1994), Traum and Allen (1994)) supports implicit agreement. But it demands an acceptance act for agreement to occur, and its current rules don’t predict such an act from (1c). Segmented Discourse Representation Theory (SDRT, Asher and Lascarides (2003)) errs in the opposite direction. It stipulates A: It’s raining. B: No it’s not. A: OK. Since a correction negates content in the discourse context, an obvious strategy for maintaining consistency would be to revise the semantic representation of the context when updating it with a correction. But we want to avoid revision, both at the level of model theory and at the level"
W11-2023,W05-0613,1,0.901401,"Missing"
W11-2023,J98-4001,0,0.11267,"ed purely on Gricean cooperative principles (Grice, 1975). On a purely Gricean approach, conversation is cooperative in at least two ways: a basic level concerning the conventions that govern linguistic meaning (basic cooperativity); and a level concerning shared attitudes towards what is said, including shared intentions (content cooperativity). While basic cooperation is needed for communication to work at all, content cooperativity involves strongly cooperative axioms like Cooperativity (interlocutors normally adopt the speaker’s intentions) (Allen and Litman, 1987, Grosz and Sidner, 1990, Lochbaum, 1998). Our approach allows for divergent preferences and divergent intentions, i.e. conversations that aren’t based on content cooperativity. This will allow us to exploit information about conflicting agents’ preferences and game-theoretic techniques that are inherent in the logics of CP-nets for computing optimal moves (Bonzon, 2007). And in contrast to Franke et al. (2009), who analyse conversations where content cooperativity doesn’t hold using a game-theoretic framework, our approach allows for partial and qualitative representations of preferences rather than demanding complete and quantitati"
W12-3619,S12-1018,1,0.697462,"and Foo, 2004). Modeling preferences divides into three subtasks (Brafman and Domshlak, 2009): preference acquisition, which extracts preferences from users, preference modeling where a model of users’ preferences is built using a preference representation language and preference reasoning which aims at computing the set of optimal outcomes. We focus in this paper on a particular instantiation of the first task, extracting preferences from chat turns of actual conversation; and we propose an annotation scheme that is general enough to cover several domains. We extend the annotation scheme of (Cadilhac et al., 2012), which investigates preferences within negotiation dialogues with a common goal like fixing a meeting time (Verbmobil (CV )) or making a hotel or plane reservation (Booking (CB )) to a more complex domain provided by a corpus of on line chats concerning the game Settlers of Catan. In Settlers, players with opposing strategic Preferences in game theory A preference is traditionally a complete ordering by an agent over outcomes. In traditional game theory (Osborne and Rubinstein, 1994), preferences or utilities over outcomes drive rational, strategic decision. They are the terminal states of th"
W12-3802,abeille-godard-2010-grande,0,0.114657,"Missing"
W12-3802,I11-1132,1,0.901974,"Missing"
W12-3802,D08-1083,0,0.635539,"g with their direct translation in English. Note however that there are substantial semantic differences between the two languages. 2 Related Work 2.1 Negation in Sentiment Analysis Research efforts using negation in sentiment analysis can be grouped according to three main criteria: the effect of negation on opinion expressions, the types of negation used and the method employed 11 to update the prior polarity of opinion expressions. According to the first criterion, most approaches treat negation as polarity reversal (Polanyi and Zaenen, 2006; Wilson et al., 2005; Moilanen and Pulman, 2007; Choi and Cardie, 2008). However, negation cannot be reduced to reversing polarity. For example, if we assume that the score of the adjective “excellent” is +3, then the opinion score in “this student is not excellent” cannot be -3. It rather means that the student is not good enough. Hence, dealing with negation requires to go beyond polarity reversal. Liu and Seneff (2009) propose a linear additive model that treats negations as modifying adverbs. In the same way, in (Taboada et al., 2011), the negation of an opinion expression shifts the value of its score to the opposite polarity by a fixed amount. Thus a +2 adj"
W12-3802,P09-2044,0,0.0126464,"ions. In NLP, modality is less addressed than other linguistic operators, such as negations. Most of the computational studies involving modality are focused on: (i) building annotated resources in terms of factuality information and (ii) uncertainty modeling and hedge detection in texts. Among annotated resources, we cite the FactBank corpus (Saur´ı and Pustejovsky, 2009) and the BioScope corpus (Vincze et al., 2008). In the second research strand, the efforts go from detecting uncertainty in texts (Rubin, 2010), to finding hedges and their scopes in specialized corpora (Vincze et al., 2008; Ganter and Strube, 2009; Zhao et al., 2010). However, there is only partial overlapping between hedges and modal constructions. Hedges are linguistic means whereby the authors show that they cannot back their opinions with facts. Thus, hedges include certain modal constructions (especially epistemic), along with other markers such as indirect speech, e.g., “According to certain researchers,...”. On the 12 other hand, there are modal constructions which are not hedges, e.g. when expressing a factual possibility, without uncertainty on behalf of the speaker, e.g. may in “These insects may play a part in the reproducti"
W12-3802,N09-1057,0,0.0317149,"r, 2009). We thus distinguish three types of negation: negative operators, negative quantifiers and lexical negations and three types of modality: buletic, epistemic and deontic. We show that each type has a specific effect on the opinion expression in its scope: both on the polarity and the strength for negation, and on the strength and/or the degree of certainty for modality. These effects are structured as a set of hypotheses that we empirically validated via several linguistic experiments informed by native speakers. This evaluation methodology has already been used in sentiment analysis. Greene and Resnik (2009) chose psycholinguistic methods for assessing the connection between sentence structure and implicit sentiment. Taboada et al. (2011) used Mechanical Turk to check subjective dictionaries for consistency. The empirical results reported in this paper provide a basis for future opinion analysis systems that have to compute the sentiment orientation at the sentence or at the clause level. The methodology we used for deriving this basis was applied for French but it can be easily instantiated for other languages like English. In this paper, all examples are in French along with their direct transl"
W12-3802,D09-1017,0,0.405131,"sed and the method employed 11 to update the prior polarity of opinion expressions. According to the first criterion, most approaches treat negation as polarity reversal (Polanyi and Zaenen, 2006; Wilson et al., 2005; Moilanen and Pulman, 2007; Choi and Cardie, 2008). However, negation cannot be reduced to reversing polarity. For example, if we assume that the score of the adjective “excellent” is +3, then the opinion score in “this student is not excellent” cannot be -3. It rather means that the student is not good enough. Hence, dealing with negation requires to go beyond polarity reversal. Liu and Seneff (2009) propose a linear additive model that treats negations as modifying adverbs. In the same way, in (Taboada et al., 2011), the negation of an opinion expression shifts the value of its score to the opposite polarity by a fixed amount. Thus a +2 adjective is negated to a -2, but the negation of a very negative adjective is only slightly positive. Based on (Taboada et al., 2011)’s shift model, Yessenalina and Cardie (2011) propose to represent each word as a matrix and combine words using iterated matrix multiplication, which allows for modeling both additive (for negations) and multiplicative (fo"
W12-3802,W06-3907,0,0.0882226,"Missing"
W12-3802,J11-2001,0,0.732935,"modality: buletic, epistemic and deontic. We show that each type has a specific effect on the opinion expression in its scope: both on the polarity and the strength for negation, and on the strength and/or the degree of certainty for modality. These effects are structured as a set of hypotheses that we empirically validated via several linguistic experiments informed by native speakers. This evaluation methodology has already been used in sentiment analysis. Greene and Resnik (2009) chose psycholinguistic methods for assessing the connection between sentence structure and implicit sentiment. Taboada et al. (2011) used Mechanical Turk to check subjective dictionaries for consistency. The empirical results reported in this paper provide a basis for future opinion analysis systems that have to compute the sentiment orientation at the sentence or at the clause level. The methodology we used for deriving this basis was applied for French but it can be easily instantiated for other languages like English. In this paper, all examples are in French along with their direct translation in English. Note however that there are substantial semantic differences between the two languages. 2 Related Work 2.1 Negation"
W12-3802,W10-3111,0,0.567847,"can also express modality (e.g. ”a probable cause”). Negation and modality can aggregate in a variety of ways: (1) multiple negatives, e.g, “This restaurant never fails to disappoint on flavor”. In some languages, double negatives cancel the effect of negation, while in negative-concord languages like French, double negations usually intensify the effect of negation. (2) cumulative modalities, as in “You definitely must see this movie” and (3) both negation and modality, as in “you should not go see this movie”. Several reports have shown that negations and modalities are sentiment-relevant (Wiegand et al., 2010). Kennedy and Inkpen (2006) point out that 10 Proceedings of the ACL-2012 Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM-2012), c pages 10–18, Jeju, Republic of Korea, 13 July 2012. 2012 Association for Computational Linguistics negations are more sentiment-relevant than diminishers. Wilson et al. (2009) show that modalities as well as negations are good cues for opinion identification. Given that the sentiment-relevance of negations and modalities is an established fact, this paper aims to go further by exploring how this relevance is distilled accordi"
W12-3802,H05-1044,0,0.0697067,". In this paper, all examples are in French along with their direct translation in English. Note however that there are substantial semantic differences between the two languages. 2 Related Work 2.1 Negation in Sentiment Analysis Research efforts using negation in sentiment analysis can be grouped according to three main criteria: the effect of negation on opinion expressions, the types of negation used and the method employed 11 to update the prior polarity of opinion expressions. According to the first criterion, most approaches treat negation as polarity reversal (Polanyi and Zaenen, 2006; Wilson et al., 2005; Moilanen and Pulman, 2007; Choi and Cardie, 2008). However, negation cannot be reduced to reversing polarity. For example, if we assume that the score of the adjective “excellent” is +3, then the opinion score in “this student is not excellent” cannot be -3. It rather means that the student is not good enough. Hence, dealing with negation requires to go beyond polarity reversal. Liu and Seneff (2009) propose a linear additive model that treats negations as modifying adverbs. In the same way, in (Taboada et al., 2011), the negation of an opinion expression shifts the value of its score to the"
W12-3802,J09-3003,0,0.471032,"the effect of negation. (2) cumulative modalities, as in “You definitely must see this movie” and (3) both negation and modality, as in “you should not go see this movie”. Several reports have shown that negations and modalities are sentiment-relevant (Wiegand et al., 2010). Kennedy and Inkpen (2006) point out that 10 Proceedings of the ACL-2012 Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM-2012), c pages 10–18, Jeju, Republic of Korea, 13 July 2012. 2012 Association for Computational Linguistics negations are more sentiment-relevant than diminishers. Wilson et al. (2009) show that modalities as well as negations are good cues for opinion identification. Given that the sentiment-relevance of negations and modalities is an established fact, this paper aims to go further by exploring how this relevance is distilled according to the semantics of each operator. To this end, we first study several taxonomies along with their associated categories of both modality and negation given by the linguistic literature. Among these categories, we decide to choose the categories of (Godard, to appear) for negations. For modalities, we rely on the categories of (Larreya, 2004"
W12-3802,D11-1016,0,0.0534985,"opinion score in “this student is not excellent” cannot be -3. It rather means that the student is not good enough. Hence, dealing with negation requires to go beyond polarity reversal. Liu and Seneff (2009) propose a linear additive model that treats negations as modifying adverbs. In the same way, in (Taboada et al., 2011), the negation of an opinion expression shifts the value of its score to the opposite polarity by a fixed amount. Thus a +2 adjective is negated to a -2, but the negation of a very negative adjective is only slightly positive. Based on (Taboada et al., 2011)’s shift model, Yessenalina and Cardie (2011) propose to represent each word as a matrix and combine words using iterated matrix multiplication, which allows for modeling both additive (for negations) and multiplicative (for intensifiers) semantic effects. In our framework, we assume, as in (Liu and Seneff, 2009) and (Taboada et al., 2011), that negation affects both the polarity and the strength of an opinion expression. However, unlike other studies, we distill that effect depending on the type of the negation. Two main types of negation were studied in the literature: negators such as “not” and content word negators such as “eliminate"
W12-3802,W10-3014,0,0.0121327,"less addressed than other linguistic operators, such as negations. Most of the computational studies involving modality are focused on: (i) building annotated resources in terms of factuality information and (ii) uncertainty modeling and hedge detection in texts. Among annotated resources, we cite the FactBank corpus (Saur´ı and Pustejovsky, 2009) and the BioScope corpus (Vincze et al., 2008). In the second research strand, the efforts go from detecting uncertainty in texts (Rubin, 2010), to finding hedges and their scopes in specialized corpora (Vincze et al., 2008; Ganter and Strube, 2009; Zhao et al., 2010). However, there is only partial overlapping between hedges and modal constructions. Hedges are linguistic means whereby the authors show that they cannot back their opinions with facts. Thus, hedges include certain modal constructions (especially epistemic), along with other markers such as indirect speech, e.g., “According to certain researchers,...”. On the 12 other hand, there are modal constructions which are not hedges, e.g. when expressing a factual possibility, without uncertainty on behalf of the speaker, e.g. may in “These insects may play a part in the reproduction of plants as well"
W12-3802,W08-0606,0,\N,Missing
W13-0105,abeille-godard-2010-grande,0,0.0434285,"Missing"
W13-0105,W12-3802,1,0.93671,"The vertices of the graph are the opinion targets, opinion expressions and modifiers of opinion and the edges represent relations among them (mainly, opinion restriction and opinion expansion). Finally (Socher et al., 2012) propose a matrix-vector representations with a recursive neural network. The model is build on a parse tree where the nodes are associated to a vector. The matrix captures how each constituent modifies its neighbour. The model was applied to predict fine-grained sentiment distributions of adverb-adjective pairs. Based on linguistic experiments informed by native speakers (Benamara et al., 2012), we propose a sentiment composition model based on a parabolic representation where an opinion expression is represented as a point on a parabola. Our model is designed to handle the interactions between opinion expressions and specific linguistic operators at the sub-sentential level. This paper focus particularly on modality and negation but our model can be used to treat intensifier as well. Within the model, negation are modelled as functions over this parabola whereas modality through a family of parabolas of different slopes; each slope corresponds to a different certainty degree. The m"
W13-0105,D08-1083,0,0.184212,"are also available. Among them, we can cite the BioScope corpus (Vincze et al., 2008) and FactBank (Saur´ı and Pustejovsky, 2009). In sentiment analysis, the presence of modalities is generally used as a feature in a supervised learning setting for sentence-level opinion classification (Kobayakawa et al., 2009). However, to our knowledge, no work has investigated how modality impacts on opinions. There are two ways of treating negation when computing the contextual polarity an opinion expression at the sentense-level: (a) polarity reversal (Polanyi and Zaenen, 2006; Moilanen and Pulman, 2007; Choi and Cardie, 2008) that flips the prior polarity of the expression to its opposite value. For instance, if the score of the adjective “excellent” is +3, then the opinion in “this student is not excellent” is -3 ; (b) polarity shift (Taboada et al., 2011) that assumes that negation affects both the polarity and the strength. For instance, the opinion in “this student is not excellent” cannot be -3 ; it rather means that the student is not good enough. Two main types of negation were taken into account in these models: negators such as “not” and / or content word negators (Choi and Cardie, 2008) that can be posit"
W13-0105,P08-1118,0,0.0591452,"Missing"
W13-0105,D12-1110,0,0.073364,"e model is learned in order to assign ordinal sentiment scores to sentiment-bearing phrases. (Socher et al., 2011) model sentences in a vectorial representation and propose an approach based on semi-supervised recursive autoencoders in order to predict sentence-level sentiment distributions. (Wu et al., 2011) propose a graph-based method for computing a sentence-level sentiment representation. The vertices of the graph are the opinion targets, opinion expressions and modifiers of opinion and the edges represent relations among them (mainly, opinion restriction and opinion expansion). Finally (Socher et al., 2012) propose a matrix-vector representations with a recursive neural network. The model is build on a parse tree where the nodes are associated to a vector. The matrix captures how each constituent modifies its neighbour. The model was applied to predict fine-grained sentiment distributions of adverb-adjective pairs. Based on linguistic experiments informed by native speakers (Benamara et al., 2012), we propose a sentiment composition model based on a parabolic representation where an opinion expression is represented as a point on a parabola. Our model is designed to handle the interactions betwe"
W13-0105,D11-1014,0,0.142223,"dels: sentiment propagation, polarity conflict resolution and polarity reversal. (Shaikh et al., 2007) use verb frames representation for sentence-level classification and show that their compositional model outperfoms a non-compositional rule-based system. (Yessenalina and Cardie, 2011) represent each word as a matrix and combine words using iterated matrix multiplication, which allows for modelling both additive (for negations) and multiplicative (for intensifiers) semantic effects. This matrix-space model is learned in order to assign ordinal sentiment scores to sentiment-bearing phrases. (Socher et al., 2011) model sentences in a vectorial representation and propose an approach based on semi-supervised recursive autoencoders in order to predict sentence-level sentiment distributions. (Wu et al., 2011) propose a graph-based method for computing a sentence-level sentiment representation. The vertices of the graph are the opinion targets, opinion expressions and modifiers of opinion and the edges represent relations among them (mainly, opinion restriction and opinion expansion). Finally (Socher et al., 2012) propose a matrix-vector representations with a recursive neural network. The model is build o"
W13-0105,P08-1033,0,0.0120206,"egation and modality. We then give in section 3 the linguistic motivations behind our approach. The parabolic model and its evaluation are respectively described in section 4 and section 5. 2 Related Works The computational treatment of negation and modality has recently become an emerging research area. These complex linguistic phenomena have been shown to be relevant in several NLP applications such as sentiment analysis (Wiegand et al., 2010), information retrieval (Jia and Meng, 2009), recognizing contrasts and contradictions (de Marneffe and Manning, 2008) and biomedical text processing (Szarvas, 2008). Due to the emergence of this field, several workshops and conferences have been organized such as the Negation and Speculation in Natural Language Processing (NeSp-NLP 2010) workshop, the Extra-Propositional Aspects of Meaning in Computational Linguistics (ExPRom 2012) workshop, and the publication of a special issue of the journal Computational Linguistics. A number of resources annotated with factuality information are also available. Among them, we can cite the BioScope corpus (Vincze et al., 2008) and FactBank (Saur´ı and Pustejovsky, 2009). In sentiment analysis, the presence of modalit"
W13-0105,J11-2001,0,0.740384,"setting for sentence-level opinion classification (Kobayakawa et al., 2009). However, to our knowledge, no work has investigated how modality impacts on opinions. There are two ways of treating negation when computing the contextual polarity an opinion expression at the sentense-level: (a) polarity reversal (Polanyi and Zaenen, 2006; Moilanen and Pulman, 2007; Choi and Cardie, 2008) that flips the prior polarity of the expression to its opposite value. For instance, if the score of the adjective “excellent” is +3, then the opinion in “this student is not excellent” is -3 ; (b) polarity shift (Taboada et al., 2011) that assumes that negation affects both the polarity and the strength. For instance, the opinion in “this student is not excellent” cannot be -3 ; it rather means that the student is not good enough. Two main types of negation were taken into account in these models: negators such as “not” and / or content word negators (Choi and Cardie, 2008) that can be positive polarity shifters (like abate) or negative polarity shifters (like lack). Few studies take into account other types of negation. (Taboada et al., 2011) treat negative polarity items (NPIs) (as well as modalities) as “irrealis blocke"
W13-0105,W10-3111,0,0.0389371,"representation of extra-propositional aspects of meaning. The paper is organized as follow. We first give an overview of how existing sentiment analysis systems deal with negation and modality. We then give in section 3 the linguistic motivations behind our approach. The parabolic model and its evaluation are respectively described in section 4 and section 5. 2 Related Works The computational treatment of negation and modality has recently become an emerging research area. These complex linguistic phenomena have been shown to be relevant in several NLP applications such as sentiment analysis (Wiegand et al., 2010), information retrieval (Jia and Meng, 2009), recognizing contrasts and contradictions (de Marneffe and Manning, 2008) and biomedical text processing (Szarvas, 2008). Due to the emergence of this field, several workshops and conferences have been organized such as the Negation and Speculation in Natural Language Processing (NeSp-NLP 2010) workshop, the Extra-Propositional Aspects of Meaning in Computational Linguistics (ExPRom 2012) workshop, and the publication of a special issue of the journal Computational Linguistics. A number of resources annotated with factuality information are also ava"
W13-0105,D11-1123,0,0.0682253,"l model outperfoms a non-compositional rule-based system. (Yessenalina and Cardie, 2011) represent each word as a matrix and combine words using iterated matrix multiplication, which allows for modelling both additive (for negations) and multiplicative (for intensifiers) semantic effects. This matrix-space model is learned in order to assign ordinal sentiment scores to sentiment-bearing phrases. (Socher et al., 2011) model sentences in a vectorial representation and propose an approach based on semi-supervised recursive autoencoders in order to predict sentence-level sentiment distributions. (Wu et al., 2011) propose a graph-based method for computing a sentence-level sentiment representation. The vertices of the graph are the opinion targets, opinion expressions and modifiers of opinion and the edges represent relations among them (mainly, opinion restriction and opinion expansion). Finally (Socher et al., 2012) propose a matrix-vector representations with a recursive neural network. The model is build on a parse tree where the nodes are associated to a vector. The matrix captures how each constituent modifies its neighbour. The model was applied to predict fine-grained sentiment distributions of"
W13-0105,D11-1016,0,0.045755,"he verb confirm, the adjective good and the adverbs not and enough. Several computational models were proposed to account for sentiment composition. (Moilanen and Pulman, 2007) use a syntactic tree representation where nodes are associated to a set of specific handmade composition rules that treat both negation and intensifier via three models: sentiment propagation, polarity conflict resolution and polarity reversal. (Shaikh et al., 2007) use verb frames representation for sentence-level classification and show that their compositional model outperfoms a non-compositional rule-based system. (Yessenalina and Cardie, 2011) represent each word as a matrix and combine words using iterated matrix multiplication, which allows for modelling both additive (for negations) and multiplicative (for intensifiers) semantic effects. This matrix-space model is learned in order to assign ordinal sentiment scores to sentiment-bearing phrases. (Socher et al., 2011) model sentences in a vectorial representation and propose an approach based on semi-supervised recursive autoencoders in order to predict sentence-level sentiment distributions. (Wu et al., 2011) propose a graph-based method for computing a sentence-level sentiment r"
W13-0105,W08-0606,0,\N,Missing
W13-4002,C12-1115,1,0.803907,"Missing"
W13-4002,P84-1085,0,0.461615,"scope has great semantic impact on the phenomena we have mentioned, in exactly the way the relative scope of quantifiers make a great semantic difference in first order logic. By concentrating on exact meaning representations, however, the syntax-semantics interface becomes quite complex: as happens with quantifiers at the intra sentential level, discourse relations might semantically require a scope that is, at least a priori, not determined by syntactic considerations alone and violates surface order (see s2 ). Other theories like Polanyi’s Linguistic Discourse Model (LDM) of Polanyi 1985; Polanyi and Scha 1984, and DLTAG Webber et al. 1999 explicitly adopt a syntactic point of view, and RST with strongly constrained (tree-shaped) structures is subject to parsing approaches duVerle and Prendinger 2009; Sagae 2009; Subba and Di Eugenio 2009 that adhere to the syntactic approach in adopting decoding strategies of syntactic parsing. In such theories, discourse structure representations, subject to syntactic constraints (e.g. dominance of spans of text one over another) respect surface order but do not always and unproblematically yield a semantic interpretation that fits intuitions. According to Marcu"
W13-4002,W04-2322,0,0.156207,"Missing"
W13-4002,prasad-etal-2008-penn,0,0.32011,"Missing"
W13-4002,W09-3813,0,0.0787263,"entations, however, the syntax-semantics interface becomes quite complex: as happens with quantifiers at the intra sentential level, discourse relations might semantically require a scope that is, at least a priori, not determined by syntactic considerations alone and violates surface order (see s2 ). Other theories like Polanyi’s Linguistic Discourse Model (LDM) of Polanyi 1985; Polanyi and Scha 1984, and DLTAG Webber et al. 1999 explicitly adopt a syntactic point of view, and RST with strongly constrained (tree-shaped) structures is subject to parsing approaches duVerle and Prendinger 2009; Sagae 2009; Subba and Di Eugenio 2009 that adhere to the syntactic approach in adopting decoding strategies of syntactic parsing. In such theories, discourse structure representations, subject to syntactic constraints (e.g. dominance of spans of text one over another) respect surface order but do not always and unproblematically yield a semantic interpretation that fits intuitions. According to Marcu 1996, an RST tree is not by itself sufficient to generate desired predictions; he employs the nuclearity principle, NP, as an additional interpretation principle on scopes of relations. We focus on two theo"
W13-4002,W04-0213,0,0.0363448,"urse structure representations, subject to syntactic constraints (e.g. dominance of spans of text one over another) respect surface order but do not always and unproblematically yield a semantic interpretation that fits intuitions. According to Marcu 1996, an RST tree is not by itself sufficient to generate desired predictions; he employs the nuclearity principle, NP, as an additional interpretation principle on scopes of relations. We focus on two theories: RST, which offers the model for the annotations of the RST treebank Carlson, Marcu, and Okurowski 2002 and the Potsdam commentary corpus Stede 2004, and on SDRT, which counts several small corpora annotated with semantic scopes, Discor Baldridge, Asher, and Hunter 2007 and Annodis Afantenos et al. 2012. We describe these theories in section 2. We will also compare these two theories to dependency tree representations of discourse Muller et al. 2012. Section 3 introduces a language for describing semantics scopes of relations that is powerful enough to: i) compare the expressiveness (in terms of what different scopes can be expressed) of the different formalisms considered; ii) give a formal target language that will provide comparable in"
W13-4002,N09-1064,0,0.0280014,"Missing"
W13-4002,P99-1006,0,0.159306,"Missing"
W13-4002,J05-2005,0,0.18991,"tative tasks. There is also some agreement over the taxonomy of discourse relations —almost all current theories include expressions that refer to relations like Elaboration, Explanation, Result, Narration, Contrast, Attribution. Sanders, Spooren, and Noordman 1992; Bateman and Rondhuis 1997 discuss correspondences between different taxonomies. Different theories, however, assume different sets of constraints that govern these representations; some advocate trees: RST Mann and Thompson 1987, DLTAG Webber et al. 1999; others, graphs of different sorts: SDRT Asher and Lascarides 2003, Graphbank Wolf and Gibson 2005. Consider: (1) Elab1 (Attr(Elab2 (C1N , C2S )N , C3S )N , C4S ) [“he was a very aggressive firefighter.]C1 [he loved the work he was in,”]C2 [said acting fire chief Lary Garcia.]C3 . [”He couldn’t be bested in terms of his willingness and his ability to do something to help you survive.”]C4 (from Egg and Redeker 2010) Using RST, Egg and Redeker 2010 provide the tree annotated with nuclearity features for this example (given by the linear encoding in (s1 )), while SDRT provides 1 The Penn Discourse Treebank Prasad et al. 2008 could also be considered as a corpus with partial dependency structu"
W13-4002,afantenos-etal-2012-empirical,1,0.895142,"Missing"
W13-4002,E93-1004,0,0.412741,"Missing"
W13-4002,P09-1075,0,0.309074,"ating on exact meaning representations, however, the syntax-semantics interface becomes quite complex: as happens with quantifiers at the intra sentential level, discourse relations might semantically require a scope that is, at least a priori, not determined by syntactic considerations alone and violates surface order (see s2 ). Other theories like Polanyi’s Linguistic Discourse Model (LDM) of Polanyi 1985; Polanyi and Scha 1984, and DLTAG Webber et al. 1999 explicitly adopt a syntactic point of view, and RST with strongly constrained (tree-shaped) structures is subject to parsing approaches duVerle and Prendinger 2009; Sagae 2009; Subba and Di Eugenio 2009 that adhere to the syntactic approach in adopting decoding strategies of syntactic parsing. In such theories, discourse structure representations, subject to syntactic constraints (e.g. dominance of spans of text one over another) respect surface order but do not always and unproblematically yield a semantic interpretation that fits intuitions. According to Marcu 1996, an RST tree is not by itself sufficient to generate desired predictions; he employs the nuclearity principle, NP, as an additional interpretation principle on scopes of relations. We focus"
W13-4002,egg-redeker-2010-complex,0,0.307826,"Missing"
W13-4002,E95-1035,0,\N,Missing
W15-0123,Q13-1003,0,\N,Missing
W15-0123,P05-1029,0,\N,Missing
W15-0123,W13-4002,1,\N,Missing
W15-0131,P94-1001,0,0.613457,"er hand, our semantics poses difficulties for the analysis of particular dialogue moves, in particular acknowledgments, and of disputes. We provide a second semantics that addresses these difficulties. 1 Introduction Ambiguity arises in dialogue content at various levels of granularity—lexical, syntactic, semantic levels and at the level of discourse structure. In context, these ambiguities trigger pragmatic inferences. These different mechanisms interact in an especially complex way in computing a semantics in terms of commitments, which is for many reasons an attractive idea (Hamblin, 1987; Traum and Allen, 1994; Traum, 1994). To see why, assume as most do that conversation is a rational activity designed to achieve certain goals that the dialogue’s participants aim to accomplish by talking with their interlocutors. Pragmatic inferences are drawn by rational conversationalists by reasoning on the basis of these conversational objectives and the dialogue context. Assume further that the coherence of a dialogue agent i’s contribution is tied to the possibility of inferring coherence relations between i’s utterances which often constrain in return the possible disambiguisation of those utterances, and f"
