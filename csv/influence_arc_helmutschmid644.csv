2020.coling-main.488,D15-1056,0,0.0126585,"ually simpler and faster, requires fewer hyperparameters – which can be crucial in a data-scarce scenario – and performs much better, especially for difficult tasks. For P ET, expert knowledge is mostly encoded in the mapping from a language model’s prediction to labels, which is why we focus on automating this part. The complementary problem of automatically transforming inputs before processing them with a language model has been studied by Jiang et al. (2019). This is also closely related to approaches for extracting patterns in relation extraction (Brin, 1999; Agichtein and Gravano, 2000; Batista et al., 2015; Bouraoui et al., 2020). 3 Pattern-Exploiting Training We review Pattern-Exploiting Training (P ET) as proposed by Schick and Sch¨utze (2020a). Let M be a pretrained masked language model (MLM), T its vocabulary and [MASK] ∈ T the mask token. We consider the task of mapping textual inputs x ∈ X to some label y ∈ Y where we assume w.l.o.g. that Y = {1, . . . , k} for some k ∈ N. In addition to training data T = {(x1 , y1 ), . . . , (xn , yn )}, P ET requires a set of pattern-verbalizer pairs (PVPs). As exemplified in Figure 1, each PVP p = (P, v) consists of • a pattern P that is used to conve"
2020.coling-main.488,D19-1109,0,0.0226759,"proach for identifying words that can serve as proxies for labels given small amounts of training data. At its core, our approach breaks the intractable problem of finding the mapping that maximizes the likelihood of the training data into several manageable subproblems. Integrating our approach into P ET significantly outperforms regular supervised training and almost matches the performance of P ET with a manually defined mapping. 2 Related Work Reformulating problems as language modeling tasks has been explored in fully unsupervised settings (Radford et al., 2019; Puri and Catanzaro, 2019; Davison et al., 2019), in few-shot scenarios with limited amounts of training data (Opitz, 2019; Shwartz et al., 2020; Brown et al., 2020), and even in high-resource settings (Raffel et al., 2019). The same idea is also commonly used for probing the knowledge contained within pretrained language models (Petroni et al., 2019; Talmor et al., 2019; Schick and Sch¨utze, 2020b; Ettinger, 2020, inter alia). 1 Our implementation is publicly available at https://github.com/timoschick/pet. This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License det"
2020.coling-main.488,N19-1423,0,0.0371033,"em with a pretrained language model and map the predicted words to labels. Manually defining this mapping between words and labels requires both domain expertise and an understanding of the language model’s abilities. To mitigate this issue, we devise an approach that automatically finds such a mapping given small amounts of training data. For a number of tasks, the mapping found by our approach performs almost as well as hand-crafted label-to-word mappings.1 1 Introduction Pretraining language models on large corpora has led to improvements on a wide range of NLP tasks (Radford et al., 2018; Devlin et al., 2019; Liu et al., 2019, inter alia), but learning to solve tasks from only a few examples remains a challenging problem. As small datasets are common for many realworld applications of NLP, solving this challenge is crucial to enable broad applicability. A promising direction for many tasks is to reformulate them (e.g., by appending an instruction such as “translate into French”) so that they can directly be solved by a pretrained language model (Radford et al., 2019; Schick and Sch¨utze, 2020a; Brown et al., 2020). The key idea of P ET (Schick and Sch¨utze, 2020a), one such approach aimed at text"
2020.coling-main.488,2020.tacl-1.3,0,0.022886,"hes the performance of P ET with a manually defined mapping. 2 Related Work Reformulating problems as language modeling tasks has been explored in fully unsupervised settings (Radford et al., 2019; Puri and Catanzaro, 2019; Davison et al., 2019), in few-shot scenarios with limited amounts of training data (Opitz, 2019; Shwartz et al., 2020; Brown et al., 2020), and even in high-resource settings (Raffel et al., 2019). The same idea is also commonly used for probing the knowledge contained within pretrained language models (Petroni et al., 2019; Talmor et al., 2019; Schick and Sch¨utze, 2020b; Ettinger, 2020, inter alia). 1 Our implementation is publicly available at https://github.com/timoschick/pet. This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 5569 Proceedings of the 28th International Conference on Computational Linguistics, pages 5569–5578 Barcelona, Spain (Online), December 8-13, 2020 qp (y |x) 1 Business [MASK] News: American Duo Wins Opening Beach Volleyball Match 2 World P (x) 3 Sports y v(y) x Figure 1: Exemplary application of a pattern-verbalizer pair p = (P, v): An input x is conver"
2020.wmt-1.131,P18-1073,0,0.310927,"resented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited the claims about data needs of supervised NMT and showed that with recent innovations in neural network and careful hyper-parameter tuning, NMT models outperform their phrase-based counterparts with training data as small as 100k tokens (15 times smaller than the data provided for this shared task). Standard techniques for low-resource machine translation include data augmentat"
2020.wmt-1.131,D18-1399,0,0.213784,"resented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited the claims about data needs of supervised NMT and showed that with recent innovations in neural network and careful hyper-parameter tuning, NMT models outperform their phrase-based counterparts with training data as small as 100k tokens (15 times smaller than the data provided for this shared task). Standard techniques for low-resource machine translation include data augmentat"
2020.wmt-1.131,W19-5301,0,0.0568547,"Missing"
2020.wmt-1.131,Q17-1010,0,0.0347637,"at we changed compared to the original system and keep the description of the other steps brief. In the first step, we build 300-dimensional monolingual n-gram embeddings for both Czech and SorMonolingual Data In total 696k monolingual Sorbian sentences were provided by the organizers. We noticed that the monolingual Sorbian data contain many OCRrelated errors originating from hyphenation. We thus removed all sentences ending with a hyphen. Additionally, we merged tokens ending with a hyphen with the adjacent one if such merging results 4.1 1105 Unsupervised SMT bian using FastText skip-gram (Bojanowski et al., 2017) on the above mentioned monolingual data. We restrict the vocabulary to the most frequent 200k, 400k, and 400k 1-, 2- and 3-grams, respectively. We map these embeddings to a shared bilingual space using VecMap (Artetxe et al., 2018a). In contrast to the original unsupervised SMT pipeline, which builds bilingual word embeddings (BWEs) without any cross-lingual signal, we use identical words occurring in both languages as the seed lexicon for the mapping. We found that the available small monolingual Sorbian corpus is not adequate to build BWEs in a fully unsupervised way. The corpora are tokeni"
2020.wmt-1.131,W19-5206,0,0.0159603,"ns, we limit the data mixes for training the Big architectures to 180M parallel sentences. One third of the data mix consists of oversampled authentic parallel data. In one set of experiments (Models 3, 4), the rest of the data consists of synthetic data: an equal number of samples of forward- and back-translation (which means that the monolingual Sorbian data is oversampled approximately 80×). In another set of experiments (Model 5), we additionally sample data from the machine-translated Czech-German data set where the Czech part has been automatically translated to Upper Sorbian. Following Caswell et al. (2019), we tag the synthetic data, having a separate tag for each of the synthetic data types. Further, we experiment with finetuning models originally trained for translation between Czech and German. The data for the parent models is prepared using the same protocol as for Model 4. Following Kocmi and Bojar (2018), we train the parent model until convergence and continue training with the German-Sorbian data. Based on preliminary results, we use the data mix for Model 4 for the German-to-Sorbian translation direction and the data mix for Model 5 for translating from Sorbian into German. 1108 Model"
2020.wmt-1.131,P17-2090,0,0.0157647,"howed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited the claims about data needs of supervised NMT and showed that with recent innovations in neural network and careful hyper-parameter tuning, NMT models outperform their phrase-based counterparts with training data as small as 100k tokens (15 times smaller than the data provided for this shared task). Standard techniques for low-resource machine translation include data augmentation with rulebased substitutions (Fadaee et al., 2017), by sam1104 Proceedings of the 5th Conference on Machine Translation (WMT), pages 1104–1111 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics Data # sent. # tok. # tok. # sent. Train de hsb 60k 822k 738k 13.7 12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Prov"
2020.wmt-1.131,L18-1550,0,0.0200445,"as well. 3.3 For transfer learning and the creation of synthetic data, we also used German-Czech parallel data. We downloaded all available parallel datasets from the Opus project (Tiedemann, 2012), which gave us 20.8M parallel sentences, which we further filtered. First, we filtered the parallel sentences by length. We estimated the mean and the standard deviation of the length ratio of German and Czech sentences and kept only those sentence pairs whose length ratio fitted into the interval of two times standard deviation around the mean. Then, we applied a language identifier from FastText (Grave et al., 2018) and only kept sentence pairs identified as GermanCzech. The filtering lefts us with 14.7M parallel sentences. 4 Authentic Parallel Data German-Czech Data Synthetic data from Czech-German The organizers of the shared task provided a parallel corpus of 60k sentences, and validation and development test data of 2k sentences each. The basic statistics about the data are presented in Table 1. Note that the sentences are on average much shorter and therefore also likely to be structurally simpler than in the type of sentences usually used in the WMT test sets. Since Upper Sorbian is related to Czec"
2020.wmt-1.131,W18-2703,0,0.0131086,"ne Translation (WMT), pages 1104–1111 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics Data # sent. # tok. # tok. # sent. Train de hsb 60k 822k 738k 13.7 12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token merges. The monolingual Sorbian data were used for traini"
2020.wmt-1.131,P18-4020,0,0.0268715,"Missing"
2020.wmt-1.131,W18-6325,0,0.0731864,"25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token merges. The monolingual Sorbian data were used for training the unsupervised Czech-Sorbian translation system (see Section 4.1) and for backtranslation in Sorbian-German systems. Besides, we use 60M German and 60M Czech sentences from the NewsCrawl data provided as mo"
2020.wmt-1.131,P07-2045,0,0.00940763,"ta. We restrict the vocabulary to the most frequent 200k, 400k, and 400k 1-, 2- and 3-grams, respectively. We map these embeddings to a shared bilingual space using VecMap (Artetxe et al., 2018a). In contrast to the original unsupervised SMT pipeline, which builds bilingual word embeddings (BWEs) without any cross-lingual signal, we use identical words occurring in both languages as the seed lexicon for the mapping. We found that the available small monolingual Sorbian corpus is not adequate to build BWEs in a fully unsupervised way. The corpora are tokenized and true-cased using Moses tools (Koehn et al., 2007). We note that because there are no available language rules for Sorbian, we used Czech rules for tokenization, which is reasonable because of the similarity of the two languages. We build phrase tables for both translation directions. For each source n-gram, we take 100 candidates with the closest embeddings based on cosine similarity and additional 100 candidates with the smallest edit distance. We calculate 5 scores for each pair: phrase and lexical translation probabilities and their inverse as in (Artetxe et al., 2018b), and their normalized edit distance. For phrases, the latter is calcu"
2020.wmt-1.131,W17-3204,0,0.0135707,"Western Slavic language related to Czech and Polish, it is possible to take advantage of relatively rich resources collected for these two languages. The German-Sorbian systems presented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited the claims about data needs of supervised NMT and showed that with recent innovations in neural network and careful hyper-parameter tuning, NMT models outperform their phrase-based counterparts with trainin"
2020.wmt-1.131,D18-2012,0,0.0163438,"k warm-up steps for the Base architecture and 32k warm-up steps for the Big architecture. The Base architecture is used for the initial systems which generate synthetic data via backwardand forward-translation. We use the Big architecture for the rest of the systems. 5.2 Training Data Preparation An overview of the data generation and system training steps is provided in Figure 1. We use a common BPE-based vocabulary (Sennrich et al., 2016c) for all systems which allows us to better ensemble our systems. Instead of proper tokenization, we use the pre-tokenization heuristic from SentencePiece (Kudo and Richardson, 2018) as implemented in YouTokenToMe.2 The BPE vocabulary consists of 16k merges and was fit using the authentic parallel training data only. 2 https://github.com/VKCOM/YouTokenToMe We apply BPE-dropout (Provilkov et al., 2020) of 0.1 on both the source and the target side of the data. We oversample the monolingual data 1000 times and with different segmentations (Model 2). We hypothesize that in the very low-resource setup, the BPE dropout serves more as a dataaugmentation technique than as regularization. Due to hardware limitations, we limit the data mixes for training the Big architectures to 1"
2020.wmt-1.131,J82-2005,0,0.69835,"Missing"
2020.wmt-1.131,P16-1009,0,0.537623,"rently low-resource problem without any chance that the resources available for Sorbian would ever approach the size of resources for languages spoken by millions of people. On the other hand, being a Western Slavic language related to Czech and Polish, it is possible to take advantage of relatively rich resources collected for these two languages. The German-Sorbian systems presented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited th"
2020.wmt-1.131,P16-1162,0,0.738073,"rently low-resource problem without any chance that the resources available for Sorbian would ever approach the size of resources for languages spoken by millions of people. On the other hand, being a Western Slavic language related to Czech and Polish, it is possible to take advantage of relatively rich resources collected for these two languages. The German-Sorbian systems presented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited th"
2020.wmt-1.131,P19-1021,0,0.0496486,"ack-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited the claims about data needs of supervised NMT and showed that with recent innovations in neural network and careful hyper-parameter tuning, NMT models outperform their phrase-based counterparts with training data as small as 100k tokens (15 times smaller than the data provided for this shared task). Standard techniques for low-resource machine translation include data augmentation with rulebased substitutions (Fadaee et al., 2017), by sam1104 Proceedings of the 5th Conference on Machine Translation (WMT), pages 1104–1111 c Online, November 19–20, 2020. 2020 Association for Computati"
2020.wmt-1.131,I17-2050,0,0.0153509,"12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token merges. The monolingual Sorbian data were used for training the unsupervised Czech-Sorbian translation system (see Section 4.1) and for backtranslation in Sorbian-German systems. Besides, we use 60M German and 60M Czech sentences from the NewsC"
2020.wmt-1.131,tiedemann-2012-parallel,0,0.0222884,"ermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token merges. The monolingual Sorbian data were used for training the unsupervised Czech-Sorbian translation system (see Section 4.1) and for backtranslation in Sorbian-German systems. Besides, we use 60M German and 60M Czech sentences from the NewsCrawl data provided as monolingual data for WMT shared tasks (Barrault et al., 2019). The monolingual data were used for generating synthetic training data via back- and forward-translation both for the German-Sorbian and German-Czech systems. In addition, the Czech monoling"
2020.wmt-1.131,P02-1040,0,0.108181,"de→hsb) translations. 5.3 Model Ensembling Following Sennrich et al. (2016a), we also experiment with ensembling several systems and combining systems trained in the left-to-right and right-toleft direction. We trained four models from random initialization and three models by transferring from CzechGerman translation. Note that the transferred models were initialized by the same model and only differed in the order of the training data. Further, we trained two models in the right-toleft direction, starting from random initialization. 6 Results The quantitative results in terms of BLEU score (Papineni et al., 2002) and ChrF (Popovi´c, 2017) score are presented in Table 3. The results were measured using SacreBLEU.3 The Base architecture trained using the parallel data only (Model 1) reaches a surprisingly high BLEU score, which is probably due to the quality of the manually curated training data, domain closeness of the train and test data, and relatively simple sentences both in the train and test sets. The data augmentation using BPE-dropout (Model 2) seems to have a substantial effect on the translation quality, improving the translation by 6–7 BLEU points. This is a much larger effect than Provilkov"
2020.wmt-1.131,W17-4770,0,0.0355876,"Missing"
2020.wmt-1.131,D18-1100,0,0.014892,"s (Fadaee et al., 2017), by sam1104 Proceedings of the 5th Conference on Machine Translation (WMT), pages 1104–1111 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics Data # sent. # tok. # tok. # sent. Train de hsb 60k 822k 738k 13.7 12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sente"
2020.wmt-1.131,2020.acl-main.170,0,0.187155,"017), by sam1104 Proceedings of the 5th Conference on Machine Translation (WMT), pages 1104–1111 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics Data # sent. # tok. # tok. # sent. Train de hsb 60k 822k 738k 13.7 12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token me"
2020.wmt-1.131,P12-1049,1,0.779845,"er Sorbian, using transliteration. More precisely, we transliterate Czech words from the German-Czech parallel data which were not seen by the SMT system during training, assuming that the translations of these words are missing in the Sorbian vocabulary on the target side as well. We extracted the training data for the transliteration system using a preliminary transliteration mining model, filtered the data using a preliminary transliteration model, and trained the final transliteration model on the filtered data. Transliteration mining. Our transliteration mining is similar to the model by Sajjad et al. (2012). It consists of a transliteration submodel and a noise submodel. The transliteration submodel is a unigram model over transliteration units (TUs) which jointly generates a source and a target language string. The English-German transliteration pair (Gorbatchev, Gorbatschow) could be generated as the following sequence of TUs: G:G o:o r:r b:b a:a t:t s: c:c h:h e:o v:w. We use only 1-1, 0-1, and 1-0 TUs. The probability p(a) of a sequence of TUs is the product of the unigram probabilities p(ai ): p(a) = p(a1 , ..., an ) = n Y p(ai ) i=1 Probability ptrans (s, t) of a string pair is obtained by"
2020.wmt-1.131,D16-1163,0,0.0240659,"60k 822k 738k 13.7 12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token merges. The monolingual Sorbian data were used for training the unsupervised Czech-Sorbian translation system (see Section 4.1) and for backtranslation in Sorbian-German systems. Besides, we use 60M German and 60M Czech"
2020.wmt-1.131,W16-2323,0,0.295248,"rently low-resource problem without any chance that the resources available for Sorbian would ever approach the size of resources for languages spoken by millions of people. On the other hand, being a Western Slavic language related to Czech and Polish, it is possible to take advantage of relatively rich resources collected for these two languages. The German-Sorbian systems presented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited th"
C00-2105,P99-1035,0,0.0364807,"Missing"
C00-2105,E99-1016,0,0.0946008,"ts.  for part-of-speech tagging. Another HMM-based approach has been developed by Mats Rooth (Rooth, 1992). It integrates two HMMs; one of them models noun chunks internally, the other models the context of noun chunks. Abney's cascaded nitestate parser (Abney, 1996) also contains a processing step which recognises noun chunks and other types of chunks. Ramshaw and Marcus (Ramshaw and Marcus, 1995) successfully applied Eric Brill's transformation-based learning method to the chunking problem. Voutilainen's NPtool (Voutilainen, 1993) is based on his constraint-grammar system. Finally, Brants (Brants, 1999) described a German chunker which was implemented with cascaded Markov Models. In this paper, a probabilistic context-free parser is applied to the noun chunking task. The German grammar used in the experiments was semiautomatically extended with robustness rules in order to be able to process arbitrary input. The grammar parameters were trained on unlabelled data. A novel algorithm is used for noun chunk extraction. It maximises the probability of the chunk set. The following section introduces the grammar framework, followed by a description of the chunking algorithm in section 3, and the ex"
C00-2105,W98-1505,0,0.143589,"chunks. The robustness rules for the chunker are described in section 2.3. 2.1 (Head-Lexicalised) Probabilistic Context-Free Grammars A probabilistic context-free grammar (PCFG) is a context-free grammar which assigns a probability P to each context-free grammar rule in the rule set R. QThe probability of a parse tree T is de ned as r2R P (r)jrj , where jrj is the number of times rule r was applied to build T . The parameters of PCFGs can be learned from unparsed corpora using the Inside-Outside algorithm (Lari and Young, 1990). Head-lexicalised probabilistic context-free grammars (H-L PCFG) (Carroll and Rooth, 1998) extend the PCFG approach by incorporating information about the lexical head of constituents into the probabilistic model.1 Each node in a parse of a HL PCFG is labelled with a category and the lexical head of the category. A H-L PCFG rule looks like a PCFG rule in which one of the daughters has been marked as the head. The rule probabilities Prule (C ! jC ) are replaced by lexicalised rule probabilities Prule (C ! jC; h) where h is the lexical head of the mother constituent C . The probability of a rule therefore depends not only on the category of the mother node, but also on its lexical he"
C00-2105,P98-1035,0,0.0133887,"s de ned according to Abney's chunk style (Abney, 1991) who describes chunks as syntactic units which correspond in some way to prosodic patterns, containing a content word surrounded by some function word(s): all words from the beginning of the noun phrase to the head noun are included.3 The di erent kinds of noun chunks covered by our grammar are listed below and illustrated with examples:  a combination of a non-obligatory determiner, optional adjectives or cardinals and the noun 1 Other types of lexicalised PCFGs have been described in (Charniak, 1997), (Collins, 1997), (Goodman, 1997), (Chelba and Jelinek, 1998) and (Eisner and Satta, 1999). 2 The restricted corpora were extracted automatically from the Huge German Corpus (HGC), a collection of German newspapers as well as specialised magazines for industry, law, computer science. 3 As you will see below, there is one exception, noun chunks re ned by a proper name, which end with the name instead of the head noun. itself: (1) eine gute Idee a good idea (2) vielen Menschen for many people (3) deren kunstliche Stimme whose arti cial voice (4) elf Ladungen eleven cargos (5) Wasser water and prepositional phrases where the de nite article of the embedde"
C00-2105,A88-1019,0,0.110008,". of the country involved. `Leading economists with doubtable reputations are involved in guiding the country in times of bottlenecks.' A tool which identi es noun chunks is useful for term extraction (most technical terms are nouns or complex noun groups), for lexicographic purposes (see (Tapanainen and Jarvinen, 1998) on syntactically organised concordancing), and as index terms for information retrieval. Chunkers may also mark other types of chunks like verb groups, adverbial phrases or adjectival phrases. Several methods have been developed for noun chunking. Church's noun phrase tagger (Church, 1988), one of the rst noun chunkers, was based on a Hidden Markov Model (HMM) similar to those used Thanks to Mats Rooth and Uli Heid for many helpful comments.  for part-of-speech tagging. Another HMM-based approach has been developed by Mats Rooth (Rooth, 1992). It integrates two HMMs; one of them models noun chunks internally, the other models the context of noun chunks. Abney's cascaded nitestate parser (Abney, 1996) also contains a processing step which recognises noun chunks and other types of chunks. Ramshaw and Marcus (Ramshaw and Marcus, 1995) successfully applied Eric Brill's transformat"
C00-2105,P97-1003,0,0.058638,"oun chunk concept in the grammar is de ned according to Abney's chunk style (Abney, 1991) who describes chunks as syntactic units which correspond in some way to prosodic patterns, containing a content word surrounded by some function word(s): all words from the beginning of the noun phrase to the head noun are included.3 The di erent kinds of noun chunks covered by our grammar are listed below and illustrated with examples:  a combination of a non-obligatory determiner, optional adjectives or cardinals and the noun 1 Other types of lexicalised PCFGs have been described in (Charniak, 1997), (Collins, 1997), (Goodman, 1997), (Chelba and Jelinek, 1998) and (Eisner and Satta, 1999). 2 The restricted corpora were extracted automatically from the Huge German Corpus (HGC), a collection of German newspapers as well as specialised magazines for industry, law, computer science. 3 As you will see below, there is one exception, noun chunks re ned by a proper name, which end with the name instead of the head noun. itself: (1) eine gute Idee a good idea (2) vielen Menschen for many people (3) deren kunstliche Stimme whose arti cial voice (4) elf Ladungen eleven cargos (5) Wasser water and prepositional phr"
C00-2105,P99-1059,0,0.0135105,"hunk style (Abney, 1991) who describes chunks as syntactic units which correspond in some way to prosodic patterns, containing a content word surrounded by some function word(s): all words from the beginning of the noun phrase to the head noun are included.3 The di erent kinds of noun chunks covered by our grammar are listed below and illustrated with examples:  a combination of a non-obligatory determiner, optional adjectives or cardinals and the noun 1 Other types of lexicalised PCFGs have been described in (Charniak, 1997), (Collins, 1997), (Goodman, 1997), (Chelba and Jelinek, 1998) and (Eisner and Satta, 1999). 2 The restricted corpora were extracted automatically from the Huge German Corpus (HGC), a collection of German newspapers as well as specialised magazines for industry, law, computer science. 3 As you will see below, there is one exception, noun chunks re ned by a proper name, which end with the name instead of the head noun. itself: (1) eine gute Idee a good idea (2) vielen Menschen for many people (3) deren kunstliche Stimme whose arti cial voice (4) elf Ladungen eleven cargos (5) Wasser water and prepositional phrases where the de nite article of the embedded noun chunk is morphological"
C00-2105,P96-1024,0,0.0584566,"Missing"
C00-2105,1997.iwpt-1.13,0,0.0159286,"in the grammar is de ned according to Abney's chunk style (Abney, 1991) who describes chunks as syntactic units which correspond in some way to prosodic patterns, containing a content word surrounded by some function word(s): all words from the beginning of the noun phrase to the head noun are included.3 The di erent kinds of noun chunks covered by our grammar are listed below and illustrated with examples:  a combination of a non-obligatory determiner, optional adjectives or cardinals and the noun 1 Other types of lexicalised PCFGs have been described in (Charniak, 1997), (Collins, 1997), (Goodman, 1997), (Chelba and Jelinek, 1998) and (Eisner and Satta, 1999). 2 The restricted corpora were extracted automatically from the Huge German Corpus (HGC), a collection of German newspapers as well as specialised magazines for industry, law, computer science. 3 As you will see below, there is one exception, noun chunks re ned by a proper name, which end with the name instead of the head noun. itself: (1) eine gute Idee a good idea (2) vielen Menschen for many people (3) deren kunstliche Stimme whose arti cial voice (4) elf Ladungen eleven cargos (5) Wasser water and prepositional phrases where the de"
C00-2105,W95-0107,0,0.0866362,"developed for noun chunking. Church's noun phrase tagger (Church, 1988), one of the rst noun chunkers, was based on a Hidden Markov Model (HMM) similar to those used Thanks to Mats Rooth and Uli Heid for many helpful comments.  for part-of-speech tagging. Another HMM-based approach has been developed by Mats Rooth (Rooth, 1992). It integrates two HMMs; one of them models noun chunks internally, the other models the context of noun chunks. Abney's cascaded nitestate parser (Abney, 1996) also contains a processing step which recognises noun chunks and other types of chunks. Ramshaw and Marcus (Ramshaw and Marcus, 1995) successfully applied Eric Brill's transformation-based learning method to the chunking problem. Voutilainen's NPtool (Voutilainen, 1993) is based on his constraint-grammar system. Finally, Brants (Brants, 1999) described a German chunker which was implemented with cascaded Markov Models. In this paper, a probabilistic context-free parser is applied to the noun chunking task. The German grammar used in the experiments was semiautomatically extended with robustness rules in order to be able to process arbitrary input. The grammar parameters were trained on unlabelled data. A novel algorithm is"
C00-2105,W93-0306,0,0.0200504,"similar to those used Thanks to Mats Rooth and Uli Heid for many helpful comments.  for part-of-speech tagging. Another HMM-based approach has been developed by Mats Rooth (Rooth, 1992). It integrates two HMMs; one of them models noun chunks internally, the other models the context of noun chunks. Abney's cascaded nitestate parser (Abney, 1996) also contains a processing step which recognises noun chunks and other types of chunks. Ramshaw and Marcus (Ramshaw and Marcus, 1995) successfully applied Eric Brill's transformation-based learning method to the chunking problem. Voutilainen's NPtool (Voutilainen, 1993) is based on his constraint-grammar system. Finally, Brants (Brants, 1999) described a German chunker which was implemented with cascaded Markov Models. In this paper, a probabilistic context-free parser is applied to the noun chunking task. The German grammar used in the experiments was semiautomatically extended with robustness rules in order to be able to process arbitrary input. The grammar parameters were trained on unlabelled data. A novel algorithm is used for noun chunk extraction. It maximises the probability of the chunk set. The following section introduces the grammar framework, fo"
C00-2105,C98-1035,0,\N,Missing
C02-1029,J97-4005,0,\N,Missing
C02-1029,P00-1061,0,\N,Missing
C02-1029,C02-1075,0,\N,Missing
C02-1029,C02-1108,1,\N,Missing
C02-1029,P01-1060,1,\N,Missing
C02-1029,P02-1035,0,\N,Missing
C02-1029,P89-1018,0,\N,Missing
C02-1029,E95-1012,0,\N,Missing
C02-1029,P99-1069,0,\N,Missing
C02-1108,W98-1505,0,\N,Missing
C02-1108,P97-1003,0,\N,Missing
C04-1024,W98-1115,0,0.0323751,"troduction Large context-free grammars extracted from treebanks achieve high coverage and accuracy, but they are difficult to parse with because of their massive ambiguity. The application of standard chart-parsing techniques often fails due to excessive memory and runtime requirements. Treebank grammars are mostly used as probabilistic grammars and users are usually only interested in the best analysis, the Viterbi parse. To speed up Viterbi parsing, sophisticated search strategies have been developed which find the most probable analysis without examining the whole set of possible analyses (Charniak et al., 1998; Klein and Manning, 2003a). These methods reduce the number of generated edges, but increase the amount of time needed for each edge. The parser described in this paper follows a contrary approach: instead of reducing the number of edges, it minimises the costs of building edges in terms of memory and runtime. The new parser, called BitPar, is based on a bitvector implementation (cf. (Graham et al., 1980)) of the well-known Cocke-Younger-Kasami (CKY) algorithm (Kasami, 1965; Younger, 1967). It builds a compact “parse forest” representation of all analyses in two steps. In the first step, a CK"
C04-1024,N03-1016,0,0.166278,"t-free grammars extracted from treebanks achieve high coverage and accuracy, but they are difficult to parse with because of their massive ambiguity. The application of standard chart-parsing techniques often fails due to excessive memory and runtime requirements. Treebank grammars are mostly used as probabilistic grammars and users are usually only interested in the best analysis, the Viterbi parse. To speed up Viterbi parsing, sophisticated search strategies have been developed which find the most probable analysis without examining the whole set of possible analyses (Charniak et al., 1998; Klein and Manning, 2003a). These methods reduce the number of generated edges, but increase the amount of time needed for each edge. The parser described in this paper follows a contrary approach: instead of reducing the number of edges, it minimises the costs of building edges in terms of memory and runtime. The new parser, called BitPar, is based on a bitvector implementation (cf. (Graham et al., 1980)) of the well-known Cocke-Younger-Kasami (CKY) algorithm (Kasami, 1965; Younger, 1967). It builds a compact “parse forest” representation of all analyses in two steps. In the first step, a CKY-style recogniser fills"
C04-1024,P03-1054,0,0.12127,"t-free grammars extracted from treebanks achieve high coverage and accuracy, but they are difficult to parse with because of their massive ambiguity. The application of standard chart-parsing techniques often fails due to excessive memory and runtime requirements. Treebank grammars are mostly used as probabilistic grammars and users are usually only interested in the best analysis, the Viterbi parse. To speed up Viterbi parsing, sophisticated search strategies have been developed which find the most probable analysis without examining the whole set of possible analyses (Charniak et al., 1998; Klein and Manning, 2003a). These methods reduce the number of generated edges, but increase the amount of time needed for each edge. The parser described in this paper follows a contrary approach: instead of reducing the number of edges, it minimises the costs of building edges in terms of memory and runtime. The new parser, called BitPar, is based on a bitvector implementation (cf. (Graham et al., 1980)) of the well-known Cocke-Younger-Kasami (CKY) algorithm (Kasami, 1965; Younger, 1967). It builds a compact “parse forest” representation of all analyses in two steps. In the first step, a CKY-style recogniser fills"
C04-1095,J94-1002,0,\N,Missing
C04-1095,W96-0213,0,\N,Missing
C04-1095,J90-3003,0,\N,Missing
C04-1095,P03-1062,0,\N,Missing
C04-1095,A00-1031,0,\N,Missing
C08-1098,A00-1031,0,0.623001,"-stuttgart.de Abstract We present a HMM part-of-speech tagging method which is particularly suited for POS tagsets with a large number of fine-grained tags. It is based on three ideas: (1) splitting of the POS tags into attribute vectors and decomposition of the contextual POS probabilities of the HMM into a product of attribute probabilities, (2) estimation of the contextual probabilities with decision trees, and (3) use of high-order HMMs. In experiments on German and Czech data, our tagger outperformed stateof-the-art POS taggers. 1 Introduction A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.) computes the most probable ˆ ˆ POS tag sequence tˆN 1 = t1 , ..., tN for a given word N sequence w1 . N N tˆN 1 = arg max p(t1 , w1 ) tN 1 POS taggers are usually trained on corpora with between 50 and 150 different POS tags. Tagsets of this size contain little or no information about number, gender, case and similar morphosyntactic features. For languages with a rich morphology such as German or Czech, more fine-grained tagsets are often considered more appropriate. The additional information may also help to disambiguate the (base) part of speech. Without gender information, for inst"
C08-1098,gimenez-marquez-2004-svmtool,0,0.072167,"Missing"
C08-1098,W07-1709,0,0.0474068,"Missing"
C08-1098,N03-1033,0,0.00696441,"Missing"
C08-1098,P98-1080,0,0.0428505,"Missing"
C08-1098,P01-1035,0,0.0224641,"Missing"
C08-1098,C94-1025,0,0.185424,"Missing"
C08-1098,C98-1077,0,\N,Missing
C12-2105,P04-1082,0,0.203759,"rve the parallelism. The German example on the bottom shows a coordination of two sentences that share the finite and the passive auxiliary with each other, both represented as a phonetically empty head in the structure. By introducing empty nodes into the annotation, the parallelism in the underlying syntactic structure of the two conjuncts is preserved. We would like to stress that the problem of empty heads in dependency syntax is rather different from the problem of introducing trace elements previously addressed by work on the English Penn Treebank (Johnson, 2002; Dienes and Dubey, 2003; Campbell, 2004). The PTB encodes a lot of different elements that do not show on the surface, but most of these would be leaf nodes in dependency representation.1 1 There is a small number of cases, where the PTB annotates a missing verb (marked as *?*, see Section 4.6 in Bies et al. (1995)). We found 581 instances of those in the whole corpus, 293 of which were dominated by a VP node. Only those empty elements correspond to empty heads in a dependency representation since they would normally have dependents on their own. But in contrast to dependency formalisms, it is not a problem to annotate a head-less p"
C12-2105,W11-0417,0,0.208415,"ian. We conclude with an error analysis and a discussion of the results. 2 Related Work We are aware of two previous papers where the issue of empty heads has been addressed in the context of dependency parsing: One is Dukes and Habash (2011) who present a parser for the Quranic Arabic Dependency Treebank, which also contains empty heads. Unfortunately, they do not evaluate or discuss the role of empty heads. Their solution of the problem – introducing a new transition into a transition-based parser – is similar to one of our proposed procedures (the in-parsing approach). The other work is by Chaitanya et al. (2011), who use hand-crafted rules to recover empty nodes from the output of a rule-based dependency parser for the Hindi Dependency Treebank. They achieve good results on some phenomena and a bit lower results on others, proving that it is indeed possible to treat this problem in syntactic processing. However, given that their data base is very small, and they used a rule-based, language-specific approach, the question remains if we can use statistical learning to address this problem. 3 Approaches for Parsing with Empty Heads The parser that we use for our experiment is basically a best-first pars"
C12-2105,P03-1055,0,0.710356,"ead can be used to preserve the parallelism. The German example on the bottom shows a coordination of two sentences that share the finite and the passive auxiliary with each other, both represented as a phonetically empty head in the structure. By introducing empty nodes into the annotation, the parallelism in the underlying syntactic structure of the two conjuncts is preserved. We would like to stress that the problem of empty heads in dependency syntax is rather different from the problem of introducing trace elements previously addressed by work on the English Penn Treebank (Johnson, 2002; Dienes and Dubey, 2003; Campbell, 2004). The PTB encodes a lot of different elements that do not show on the surface, but most of these would be leaf nodes in dependency representation.1 1 There is a small number of cases, where the PTB annotates a missing verb (marked as *?*, see Section 4.6 in Bies et al. (1995)). We found 581 instances of those in the whole corpus, 293 of which were dominated by a VP node. Only those empty elements correspond to empty heads in a dependency representation since they would normally have dependents on their own. But in contrast to dependency formalisms, it is not a problem to annot"
C12-2105,W11-2912,0,0.42051,"oach where the presence of empty heads is determined by a classifier run prior to parsing. The paper is structured as follows: we first review some related work and continue with the presentation of the three different methods. We then define the metric that we use to measure the quality of the empty head prediction and use it to evaluate parsing experiments on German and Hungarian. We conclude with an error analysis and a discussion of the results. 2 Related Work We are aware of two previous papers where the issue of empty heads has been addressed in the context of dependency parsing: One is Dukes and Habash (2011) who present a parser for the Quranic Arabic Dependency Treebank, which also contains empty heads. Unfortunately, they do not evaluate or discuss the role of empty heads. Their solution of the problem – introducing a new transition into a transition-based parser – is similar to one of our proposed procedures (the in-parsing approach). The other work is by Chaitanya et al. (2011), who use hand-crafted rules to recover empty nodes from the output of a rule-based dependency parser for the Hindi Dependency Treebank. They achieve good results on some phenomena and a bit lower results on others, pro"
C12-2105,N10-1115,0,0.0348517,"recover empty nodes from the output of a rule-based dependency parser for the Hindi Dependency Treebank. They achieve good results on some phenomena and a bit lower results on others, proving that it is indeed possible to treat this problem in syntactic processing. However, given that their data base is very small, and they used a rule-based, language-specific approach, the question remains if we can use statistical learning to address this problem. 3 Approaches for Parsing with Empty Heads The parser that we use for our experiment is basically a best-first parser like the ones described in (Goldberg and Elhadad, 2010; Tratz and Hovy, 2011), which is trained with the Guided Learning technique proposed in Shen et al. (2007) embedded in a MIRA framework (Crammer et al., 2003). The best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In"
C12-2105,P02-1018,0,0.449938,"ces, an empty head can be used to preserve the parallelism. The German example on the bottom shows a coordination of two sentences that share the finite and the passive auxiliary with each other, both represented as a phonetically empty head in the structure. By introducing empty nodes into the annotation, the parallelism in the underlying syntactic structure of the two conjuncts is preserved. We would like to stress that the problem of empty heads in dependency syntax is rather different from the problem of introducing trace elements previously addressed by work on the English Penn Treebank (Johnson, 2002; Dienes and Dubey, 2003; Campbell, 2004). The PTB encodes a lot of different elements that do not show on the surface, but most of these would be leaf nodes in dependency representation.1 1 There is a small number of cases, where the PTB annotates a missing verb (marked as *?*, see Section 4.6 in Bies et al. (1995)). We found 581 instances of those in the whole corpus, 293 of which were dominated by a VP node. Only those empty elements correspond to empty heads in a dependency representation since they would normally have dependents on their own. But in contrast to dependency formalisms, it i"
C12-2105,P06-2066,0,0.0283657,"resort to a swap operation as is done in Tratz and Hovy (2011). It also increases theoretical decoding complexity to O(n2 ). However, there are non-projective structures that cannot be produced by this approach.2 To allow the derivation of these structures, we reintroduce the swap operation from the parser in Tratz and Hovy (2011), but during training, the parser is only allowed to apply the swap operation in case of an ill-nested structure, which leads to a very small number of swaps. 2 These structures do not fulfill the well-nestedness condition that is described in Bodirsky et al. (2005); Kuhlmann and Nivre (2006) and appear for example in German centerfield scrambling structures. 1083 The feature set of the parser uses the word forms, lemmata, POS tags, and already predicted dependency labels for the head and its prospective dependent, as well as combinations thereof for up to three surrounding tokens in the sentence. The same features and combinations are extracted for up to three surrounding partially built structures. We also add features for the left-most and right-most dependent of a token, the labels of the dependents, distance features, and valency features as proposed by Zhang and Nivre (2011)"
C12-2105,P05-1012,0,0.0104219,"guage-specific approach, the question remains if we can use statistical learning to address this problem. 3 Approaches for Parsing with Empty Heads The parser that we use for our experiment is basically a best-first parser like the ones described in (Goldberg and Elhadad, 2010; Tratz and Hovy, 2011), which is trained with the Guided Learning technique proposed in Shen et al. (2007) embedded in a MIRA framework (Crammer et al., 2003). The best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In contrast to the best-first parser in Goldberg and Elhadad (2010), the decoding algorithm is modified so that it works like the LTAG dependency parser described in Shen and Joshi (2008), which allows an edge to attach to an inside node of an already built structure. This difference makes it possible to directly produce a large portion of non-p"
C12-2105,W04-2407,0,0.0203665,"eads The parser that we use for our experiment is basically a best-first parser like the ones described in (Goldberg and Elhadad, 2010; Tratz and Hovy, 2011), which is trained with the Guided Learning technique proposed in Shen et al. (2007) embedded in a MIRA framework (Crammer et al., 2003). The best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In contrast to the best-first parser in Goldberg and Elhadad (2010), the decoding algorithm is modified so that it works like the LTAG dependency parser described in Shen and Joshi (2008), which allows an edge to attach to an inside node of an already built structure. This difference makes it possible to directly produce a large portion of non-projective structures (e. g. sentence extraposition or WH-extraction) without having to resort to a swap operation as is done in Tratz and Ho"
C12-2105,W01-0708,0,0.0254884,"before to-infinitive constructions) whereas our empty heads can occur more freely due to the free word order of German and Hungarian. We therefore pursue here a clause-based empty head preinsertion procedure since we think that the decision about inserting an empty head (which is basically the identification of the absence of the verb) can be made on the clause-level. For this, we implemented a clause boundary identification module and a classifier that predicts whether an empty word form should be inserted into a particular clause. Clause boundary identification is a difficult problem (cf. (Sang and Déjean, 2001)) as clauses usually form a hierarchy – and this hierarchy is important for predicting the insertion of empty heads. Our clause boundary detector achieves f-scores of 92.6 and 86.8 on the German and Hungarian development datasets respectively. These results are in line with the state-of-the-art results on the English Penn Treebank (Carreras et al., 2005; Ram and Lalitha Devi, 2008). If we evaluate only the in-sentence clauses, we get f-scores of 85.4 and 78.2 for German and Hungarian respectively. In order to decide whether to insert an empty head, we implemented a classifier that decides for"
C12-2105,seeker-kuhn-2012-making,1,0.832743,"e of the verb in the verb-second word order of German). For Hungarian, the manual annotation of the position of the empty word forms is quite irregular and we insert them at the beginning of the clause. Finally, we train the best-first parser on the original training dataset containing the gold standard empty heads and use it to parse the sentences that contain the automatically inserted empty heads from the preinserter. 4 Experiments In order to test the parsing methods, we performed two experiments each: we trained the parser on the German TiGer corpus using the dependency representation by Seeker and Kuhn (2012) , and on the Szeged Dependency Treebank of Hungarian (Vincze et al., 2010), both of which data sets explicitly represent empty heads in the dependency trees. Table 1 shows the data sizes and the splits we used for the experiment. The German data was preprocessed (lemma, POS, morphology) with the mate-tools,4 the Hungarian data comes with automatic annotation.5 data set German Hungarian # sentences 50,474 81,960 training # sents # empty 36,000 2,618 61,034 14,850 development # sents # empty 2,000 117 11,688 2,536 # sents 10,472 9,238 test # empty 722 2,106 Table 1: Data sets 4.1 Evaluation Met"
C12-2105,D08-1052,0,0.0558341,"best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In contrast to the best-first parser in Goldberg and Elhadad (2010), the decoding algorithm is modified so that it works like the LTAG dependency parser described in Shen and Joshi (2008), which allows an edge to attach to an inside node of an already built structure. This difference makes it possible to directly produce a large portion of non-projective structures (e. g. sentence extraposition or WH-extraction) without having to resort to a swap operation as is done in Tratz and Hovy (2011). It also increases theoretical decoding complexity to O(n2 ). However, there are non-projective structures that cannot be produced by this approach.2 To allow the derivation of these structures, we reintroduce the swap operation from the parser in Tratz and Hovy (2011), but during training"
C12-2105,P07-1096,0,0.0170372,"eve good results on some phenomena and a bit lower results on others, proving that it is indeed possible to treat this problem in syntactic processing. However, given that their data base is very small, and they used a rule-based, language-specific approach, the question remains if we can use statistical learning to address this problem. 3 Approaches for Parsing with Empty Heads The parser that we use for our experiment is basically a best-first parser like the ones described in (Goldberg and Elhadad, 2010; Tratz and Hovy, 2011), which is trained with the Guided Learning technique proposed in Shen et al. (2007) embedded in a MIRA framework (Crammer et al., 2003). The best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In contrast to the best-first parser in Goldberg and Elhadad (2010), the decoding algorithm is modified so th"
C12-2105,D11-1116,0,0.134076,"e output of a rule-based dependency parser for the Hindi Dependency Treebank. They achieve good results on some phenomena and a bit lower results on others, proving that it is indeed possible to treat this problem in syntactic processing. However, given that their data base is very small, and they used a rule-based, language-specific approach, the question remains if we can use statistical learning to address this problem. 3 Approaches for Parsing with Empty Heads The parser that we use for our experiment is basically a best-first parser like the ones described in (Goldberg and Elhadad, 2010; Tratz and Hovy, 2011), which is trained with the Guided Learning technique proposed in Shen et al. (2007) embedded in a MIRA framework (Crammer et al., 2003). The best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In contrast to the best-f"
C12-2105,vincze-etal-2010-hungarian,0,0.105132,"nual annotation of the position of the empty word forms is quite irregular and we insert them at the beginning of the clause. Finally, we train the best-first parser on the original training dataset containing the gold standard empty heads and use it to parse the sentences that contain the automatically inserted empty heads from the preinserter. 4 Experiments In order to test the parsing methods, we performed two experiments each: we trained the parser on the German TiGer corpus using the dependency representation by Seeker and Kuhn (2012) , and on the Szeged Dependency Treebank of Hungarian (Vincze et al., 2010), both of which data sets explicitly represent empty heads in the dependency trees. Table 1 shows the data sizes and the splits we used for the experiment. The German data was preprocessed (lemma, POS, morphology) with the mate-tools,4 the Hungarian data comes with automatic annotation.5 data set German Hungarian # sentences 50,474 81,960 training # sents # empty 36,000 2,618 61,034 14,850 development # sents # empty 2,000 117 11,688 2,536 # sents 10,472 9,238 test # empty 722 2,106 Table 1: Data sets 4.1 Evaluation Method Since the number of edges in the gold standard does not always equal th"
C12-2105,P11-2033,0,0.0210148,"lmann and Nivre (2006) and appear for example in German centerfield scrambling structures. 1083 The feature set of the parser uses the word forms, lemmata, POS tags, and already predicted dependency labels for the head and its prospective dependent, as well as combinations thereof for up to three surrounding tokens in the sentence. The same features and combinations are extracted for up to three surrounding partially built structures. We also add features for the left-most and right-most dependent of a token, the labels of the dependents, distance features, and valency features as proposed by Zhang and Nivre (2011) but adapted to the best-first decoder. For internal feature representation and combination the parser implements the hash kernel method by Bohnet (2010). 3.1 Empty Head Introduction during Parsing For the first method, we change the parser so that it can decide for an empty head during the parsing itself. To the three moves that the standard parser can perform – attach_left(label), attach_right(label), and swap – we add a fourth move (see Figure 2), that allows the parser to introduce an empty head for a particular dependent (together with a dependency label). This is similar in spirit to the"
C14-1041,C14-1181,0,0.0290178,"tion over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Seq"
C14-1041,D13-1174,0,0.344604,"o improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by Toutanova et al. (2008), de Gispert and Mariˆno (2008), Fraser et al. (2012), Chahuneau et al. (2013) and others. Koehn and Hoang (2007) proposed to integrate different levels of linguistic information as factors into the phrase-based translation model. Yeniterzi and Oflazer (2010) used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation,"
C14-1041,N12-1047,0,0.00920044,"urrani et al., 2014) to transliterate OOV words when translating into Russian. Tuning and Test: The systems were tuned on the dev2010 dataset and evaluated on the test2010-2013 datasets made available for the IWSLT-13 workshop. We performed a secondary set of experiments for German-English pairs using tuning and test sets made available for the WMT-13 workshop. We concatenated the news-test sets 2008 and 2009 to obtain a large dev-set of 4576 sentences. Evaluation was performed on the news-test set 2013 which contains 3000 sentences. Tuning was performed using the k-best batch MIRA algorithm (Cherry and Foster, 2012) with at most 25 iterations. We use BLEU (Papineni et al., 2002) as a metric to evaluate our results. Results I – Using Linguistic Annotation: We trained 5-gram OSM models over different representations and added these to the baseline system. First we evaluated Modeland (Mand ) which uses a MIRA tuned linear combination of different OSM models versus Modelor (Mor ) which computes only one OSM model but allows the generator to switch between different OSM models built on various generalized forms. Table 2 shows results from running experiments on German-English pairs. We found that the simpler"
C14-1041,N13-1003,0,0.251845,"t al., 2010; Wuebker and Ney, 2012). Automatically clustering the training data into word classes in order to obtain smoother 1 We are referring to hard clustering here. Soft clustering is intractable as it requires a marginalization over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due t"
C14-1041,J07-2003,0,0.0625223,"order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflectin"
C14-1041,P05-1066,1,0.078446,"nts the experimental setup and the results. Section 5 concludes the paper. 2 Related Work Previous work on integrating linguistic knowledge into SMT models can be broken into two groups. The first group focuses on using linguistic knowledge to improve reordering between syntactically different languages. A second group focuses on translating into morphologically rich languages. Initial efforts to use linguistic annotation focused on rearranging source sentences to be in the target order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based s"
C14-1041,2007.mtsummit-papers.16,0,0.201558,"Missing"
C14-1041,C10-2023,0,0.179282,"rd (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate s"
C14-1041,P11-1105,1,0.479753,"research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Sequence Model (Durrani et al., 2011) is an instance of the N-gram based SMT framework (Casacuberta and Vidal, 2004; Mari˜no et al., 2006). It represents the translation process through a sequence of operations. An operation can be to simultaneously generate source or target words or to perform reordering. Reordering is carried out through jump and gap operations. The model is different from its ancestors in that it strongly integrates translation and reordering into a single generative story in which translation decisions can influence and get impacted by the reordering decisions and vice versa. Given a bilingual sentence pair &lt;"
C14-1041,N13-1001,1,0.226932,"gically rich or syntactically divergent languages. The former becomes challenging due to lexical sparsity and the latter suffers from sparsity in learning underlying reordering patterns. The last decade of research in Statistical Machine Translation has witnessed many attempts to integrate linguistic analysis into SMT models, to address the challenges of (i) translating into morphologically rich language languages, (ii) modeling syntactic divergence across languages for better generalization in sparse data conditions. The integration of the Operation Sequence Model into phrase-based paradigm (Durrani et al., 2013a; Durrani et al., 2013b) improved the reordering capability and addressed the problem of the phrasal independence assumption in the phrase-based models. The OSM model integrates translation and reordering into a single generative story. By jointly considering translation and reordering context across phrasal boundaries, the OSM model considers much richer conditioning than phrasal translation and lexicalized reordering models. However, due to data sparsity the model often falls back to very small context sizes. We address this problem by learning operation sequences over generalized represent"
C14-1041,P13-2071,1,0.567963,"gically rich or syntactically divergent languages. The former becomes challenging due to lexical sparsity and the latter suffers from sparsity in learning underlying reordering patterns. The last decade of research in Statistical Machine Translation has witnessed many attempts to integrate linguistic analysis into SMT models, to address the challenges of (i) translating into morphologically rich language languages, (ii) modeling syntactic divergence across languages for better generalization in sparse data conditions. The integration of the Operation Sequence Model into phrase-based paradigm (Durrani et al., 2013a; Durrani et al., 2013b) improved the reordering capability and addressed the problem of the phrasal independence assumption in the phrase-based models. The OSM model integrates translation and reordering into a single generative story. By jointly considering translation and reordering context across phrasal boundaries, the OSM model considers much richer conditioning than phrasal translation and lexicalized reordering models. However, due to data sparsity the model often falls back to very small context sizes. We address this problem by learning operation sequences over generalized represent"
C14-1041,E14-4029,1,0.417624,"ack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by JunczysDowmunt (2012). For our German-to-English experiments, we used compound splitting (Koehn and Knight, 2003). German-to-English and English-to-German baseline systems also used POS and morphological target sequence models built on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models and as additional factors in phrase translation models (Koehn and Hoang, 2007). We used an unsupervised transliteration model (Durrani et al., 2014) to transliterate OOV words when translating into Russian. Tuning and Test: The systems were tuned on the dev2010 dataset and evaluated on the test2010-2013 datasets made available for the IWSLT-13 workshop. We performed a secondary set of experiments for German-English pairs using tuning and test sets made available for the WMT-13 workshop. We concatenated the news-test sets 2008 and 2009 to obtain a large dev-set of 4576 sentences. Evaluation was performed on the news-test set 2013 which contains 3000 sentences. Tuning was performed using the k-best batch MIRA algorithm (Cherry and Foster, 2"
C14-1041,P08-1115,0,0.0148386,"used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation, and which ones are better predicted through generation, also in the English-to-Arabic task. Several researchers attempted to use word lattices to handle generalized representation (Dyer et al., 2008; Hardmeier et al., 2010; Wuebker and Ney, 2012). Automatically clustering the training data into word classes in order to obtain smoother 1 We are referring to hard clustering here. Soft clustering is intractable as it requires a marginalization over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various"
C14-1041,2012.eamt-1.6,0,0.0235645,"Missing"
C14-1041,E12-1068,1,0.40458,"N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by Toutanova et al. (2008), de Gispert and Mariˆno (2008), Fraser et al. (2012), Chahuneau et al. (2013) and others. Koehn and Hoang (2007) proposed to integrate different levels of linguistic information as factors into the phrase-based translation model. Yeniterzi and Oflazer (2010) used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them"
C14-1041,P06-1121,0,0.00965802,"on rearranging source sentences to be in the target order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The i"
C14-1041,P14-1066,0,0.0440211,"hnique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Sequence Model (Durrani et al., 2011) is an instance of the N-gram based SMT framework (Casacuberta and Vidal, 2004; Mari˜no et al., 2006). It represents the translation process through a sequence of operations. An operation can be to simultaneo"
C14-1041,P12-1016,0,0.00479192,"group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by Toutanova et al. (2008), de Gispert and Mariˆno (2008), Fraser et al. (2012), Chahuneau et al. (2013) and others. Koehn and Hoang (2007) proposed to integrate different levels of linguistic information as factors into the phrase-based translation model. Yeniterzi and Oflazer (2010) used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation, and which ones are better predicted through generation, also in the English-to-Arabic task. Several researchers attempted to use word lattices to handle generalized representation (Dyer et al., 2008; Hardmeier et al., 2010; Wuebker and Ney, 2012). Automatically clustering the training data into word classes in order to obtain"
C14-1041,W10-1710,0,0.04755,"ic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation, and which ones are better predicted through generation, also in the English-to-Arabic task. Several researchers attempted to use word lattices to handle generalized representation (Dyer et al., 2008; Hardmeier et al., 2010; Wuebker and Ney, 2012). Automatically clustering the training data into word classes in order to obtain smoother 1 We are referring to hard clustering here. Soft clustering is intractable as it requires a marginalization over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (201"
C14-1041,2012.iwslt-papers.17,1,0.832647,"et al., 2007), replicating the settings described in (Birch et al., 2013) developed for the 2013 Workshop on Spoken Language Translation. The features included: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (Durrani et al., 2013b) with 4 additional supportive features: 2 gap-based penalties, 1 distance-based feature and 1 deletion penalty, lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by JunczysDowmunt (2012). For our German-to-English experiments, we used compound splitting (Koehn and Knight, 2003). German-to-English and English-to-German baseline systems also used POS and morphological target sequence models built on the in-domain subset of the parallel corpus using Kne"
C14-1041,W11-2123,0,0.00711102,"∆+0.54 27.71 ∆+0.44 31.55 ∆+0.09 27.32 ∆+0.05 31.58 ∆+0.12 27.20 ∆-0.07 31.40 ∆-0.06 27.15 ∆-0.12 Table 2: Evaluating Generalized OSM Models for German-English pairs – Bold: Statistically Significant (Koehn, 2004) w.r.t Baseline Baseline System: We trained a Moses system (Koehn et al., 2007), replicating the settings described in (Birch et al., 2013) developed for the 2013 Workshop on Spoken Language Translation. The features included: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (Durrani et al., 2013b) with 4 additional supportive features: 2 gap-based penalties, 1 distance-based feature and 1 deletion penalty, lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by Juncz"
C14-1041,E09-1043,1,0.844957,"focuses on using linguistic knowledge to improve reordering between syntactically different languages. A second group focuses on translating into morphologically rich languages. Initial efforts to use linguistic annotation focused on rearranging source sentences to be in the target order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into"
C14-1041,E14-1003,0,0.045332,"n and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Sequence Model (Durrani et al., 2011) is an instance of the N-gram based SMT framework (Casacuberta and Vidal, 2004; Mari˜no et al., 2006). It represents the translation process through a sequence of operations. An operation c"
C14-1041,P07-1019,0,0.0167512,"atures included: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (Durrani et al., 2013b) with 4 additional supportive features: 2 gap-based penalties, 1 distance-based feature and 1 deletion penalty, lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by JunczysDowmunt (2012). For our German-to-English experiments, we used compound splitting (Koehn and Knight, 2003). German-to-English and English-to-German baseline systems also used POS and morphological target sequence models built on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models and as additional factors in phrase translation models (Koehn and Hoang, 2007). We used an unsupervised transliterat"
C14-1041,D07-1091,1,0.330247,"can generalize better in sparse data conditions. The model benefits from wider contextual information as we show empirically in our results. We investigate two methods to combine generalized OSM models with the lexically driven OSM model and experimented on German-English translation tasks. Our best system that uses a linear combination of different OSM models gives significant improvements over a competitive baseline system. An improvement of up to +1.35 was observed on the English-to-German and up to +0.63 BLEU points on the German-to-English task over a factored augmented baseline system (Koehn and Hoang, 2007). POS taggers and morphological analyzers, however, are not available for many resource poor languages. In the second half of the paper we investigate whether annotating the data with automatic word This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 421 Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 421–432, Dublin, Ireland, August 23-29 2014. clusters helps improve t"
C14-1041,E03-1076,1,0.545896,"2013b) with 4 additional supportive features: 2 gap-based penalties, 1 distance-based feature and 1 deletion penalty, lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by JunczysDowmunt (2012). For our German-to-English experiments, we used compound splitting (Koehn and Knight, 2003). German-to-English and English-to-German baseline systems also used POS and morphological target sequence models built on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models and as additional factors in phrase translation models (Koehn and Hoang, 2007). We used an unsupervised transliteration model (Durrani et al., 2014) to transliterate OOV words when translating into Russian. Tuning and Test: The systems were tuned on the dev2010 dataset and evaluated on the test2010-2013 datasets made available for the IWSLT-13 workshop. We performed a secondary set of exper"
C14-1041,P07-2045,1,0.0212808,"Missing"
C14-1041,W04-3250,1,0.141116,"Missing"
C14-1041,N04-1022,0,0.0715901,"on Spoken Language Translation. The features included: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (Durrani et al., 2013b) with 4 additional supportive features: 2 gap-based penalties, 1 distance-based feature and 1 deletion penalty, lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by JunczysDowmunt (2012). For our German-to-English experiments, we used compound splitting (Koehn and Knight, 2003). German-to-English and English-to-German baseline systems also used POS and morphological target sequence models built on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models and as additional factors in phrase translation models (Koehn and Hoang, 2007"
C14-1041,N12-1005,0,0.0378999,"een a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Sequence Model (Durrani et al., 2011) is an instance of the N-gram based SMT framework (Casacuberta and Vidal, 2004; Mari˜no et al., 2006). It represents the translation process through a sequence of operation"
C14-1041,J06-4004,0,0.140693,"Missing"
C14-1041,W11-2124,0,0.0222468,"d to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by To"
C14-1041,J03-1002,0,0.0202923,"421–432, Dublin, Ireland, August 23-29 2014. clusters helps improve the performance. Word clustering is similar to POS-tagging/Morphological annotation except that it also captures interesting syntactic and lexical semantics, for example countries and languages are grouped in separate clusters, animate objects are differentiated from inanimate objects, colors are grouped in a separate cluster etc. Word clusters, however, deterministically map each word type to a unique1 cluster, unlike POS/Morph tagging, and therefore might be less useful for disambiguation. We use the mkcls utility in GIZA (Och and Ney, 2003) to cluster source and target vocabularies into classes and will therefore refer to automatic classes as Och clusters/classes in this paper. We first use Och classes as an additional factor in phrase-based translation model, along with a target LM model over cluster-ids to improve the baseline system. We then additionally use the OSM model over cluster-ids. Our experiments include translation from English to Dutch, French, Italian, Polish, Portuguese, Russian, Spanish, Slovenian and Turkish on IWSLT shared task data. Our results show an average improvement of +0.80, ranging from +0.41 to +2.02"
C14-1041,E99-1010,0,0.442864,"or the Germanto-English pair, giving a statistically significant gain of +0.63 on iwslt10 and +0.35 on wmt13 . Using both the models together did not give any further significant improvements. The results changed by +0.10 and -0.09 on the wmt13 and iwslt10 test-sets respectively. Results-II – Using Och Classes: In our secondary experiments we tested the effect of using Och clusters. The overall goal was to study whether using unsupervised word classes can serve the same purpose as POS tags and to compare the two methods of annotating the data. We obtained Och clusters using the mkcls utility (Och, 1999) in GIZA++ (Och and Ney, 2003). This is generally run during the alignment process where data is divided into 50 classes to estimate IBM Model-4. Chahuneau et al. (2013) found mapping data to 600 Och clusters useful, so we used this as well. We additionally experimented with using 200 and 1000 classes. We integrated Och clusters as additional factors4 when training the phrase-translation models and used a monolingual n-gram model over cluster-ids built on the target-side of the in-domain corpus. Then we added a 5-gram OSM model over cluster-ids. We replace surface forms with their cluster-ids"
C14-1041,P02-1040,0,0.100863,"nto Russian. Tuning and Test: The systems were tuned on the dev2010 dataset and evaluated on the test2010-2013 datasets made available for the IWSLT-13 workshop. We performed a secondary set of experiments for German-English pairs using tuning and test sets made available for the WMT-13 workshop. We concatenated the news-test sets 2008 and 2009 to obtain a large dev-set of 4576 sentences. Evaluation was performed on the news-test set 2013 which contains 3000 sentences. Tuning was performed using the k-best batch MIRA algorithm (Cherry and Foster, 2012) with at most 25 iterations. We use BLEU (Papineni et al., 2002) as a metric to evaluate our results. Results I – Using Linguistic Annotation: We trained 5-gram OSM models over different representations and added these to the baseline system. First we evaluated Modeland (Mand ) which uses a MIRA tuned linear combination of different OSM models versus Modelor (Mor ) which computes only one OSM model but allows the generator to switch between different OSM models built on various generalized forms. Table 2 shows results from running experiments on German-English pairs. We found that the simpler model Modeland outperforms Modelor in all the experiments. Model"
C14-1041,popovic-ney-2006-pos,0,0.201708,"Missing"
C14-1041,C12-2104,0,0.0162602,"lizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Sequence Model (Durrani et al., 2011) is an instance of the N-gram based SMT framework (Casacuberta and Vidal, 2004; Mari˜no et al., 2006). It represents the translation process through a sequ"
C14-1041,P08-1059,0,0.0128728,"1) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by Toutanova et al. (2008), de Gispert and Mariˆno (2008), Fraser et al. (2012), Chahuneau et al. (2013) and others. Koehn and Hoang (2007) proposed to integrate different levels of linguistic information as factors into the phrase-based translation model. Yeniterzi and Oflazer (2010) used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find"
C14-1041,W12-3157,0,0.0126006,"nal complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation, and which ones are better predicted through generation, also in the English-to-Arabic task. Several researchers attempted to use word lattices to handle generalized representation (Dyer et al., 2008; Hardmeier et al., 2010; Wuebker and Ney, 2012). Automatically clustering the training data into word classes in order to obtain smoother 1 We are referring to hard clustering here. Soft clustering is intractable as it requires a marginalization over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsi"
C14-1041,D13-1138,0,0.365066,"stering is intractable as it requires a marginalization over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be inte"
C14-1041,C04-1073,0,0.0421089,"Section 2 gives an account on related work. Section 3 discusses the factor-based OSM model. Section 4 presents the experimental setup and the results. Section 5 concludes the paper. 2 Related Work Previous work on integrating linguistic knowledge into SMT models can be broken into two groups. The first group focuses on using linguistic knowledge to improve reordering between syntactically different languages. A second group focuses on translating into morphologically rich languages. Initial efforts to use linguistic annotation focused on rearranging source sentences to be in the target order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and"
C14-1041,P10-1047,0,0.0375461,"ering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by Toutanova et al. (2008), de Gispert and Mariˆno (2008), Fraser et al. (2012), Chahuneau et al. (2013) and others. Koehn and Hoang (2007) proposed to integrate different levels of linguistic information as factors into the phrase-based translation model. Yeniterzi and Oflazer (2010) used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation, and which ones are better predicted through generation, also in the English-to-Arabic task. Several researchers attempted to use word lattices to handle generalized representation"
C14-1041,W06-3119,0,0.0289361,"sentences to be in the target order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and"
C14-1041,J04-2004,0,\N,Missing
C14-1041,2013.iwslt-evaluation.16,1,\N,Missing
C14-1041,W13-2201,1,\N,Missing
C14-1041,2013.iwslt-evaluation.3,1,\N,Missing
C94-1027,A92-1018,0,0.0967995,"phological analyzer. The tagger is trained with an analogy-driven learning procedure. Only preliminary results are presented, so that a comparison with other methods is difficult. Ill this paper, a part-of-speech tagger based on a multilayer perceptrou network is presented. It is similar to tile network of Nakamura et al. (1990) in so far as the same training procedure (Backpropagation) is used; but it differs in the structure of tile network and also in its purpose (disambignation vs. prediction). The performance of tl,e presented tagger is measured and compared to that of two other taggers (Cutting et al., 1992; Kempe, 1993). 3 NEURAL NETWORKS Artificial neural networks consist of a large number of simple processing units. These units are highly interconnected by directed weighted links. Associated with each unit is an activation value. Through tile connections, this activation is propagated to other units. In mnltilayer perceptron networks (MLP-networks), tile most popular network type, the processing units are arranged vertically in several layers (fig. I). Connections exist only between units in adjacent layers. The bottom layer is called input layer&apos;, because the activations of the units in this"
C94-1027,C90-3038,0,0.173969,"Missing"
C94-1027,A88-1019,0,\N,Missing
D12-1095,P05-1022,0,0.640872,"anking for phrase structure parsing. The proposed framework can be regarded as an extension of this approach. It has several advantages compared with the perceptron-based forest reranker. In this paper we focus on the most important one – and briefly discuss two others in Section 5 – which is enabling the use of any kind of learning to rank approaches. While the perceptron is fast to train, other machine learning approaches usually outperform it. Most of the existing learning to rank approaches are built on linear models and evaluate the candidates independently of each other (such as MaxEnt (Charniak and Johnson, 2005), SVMRank (Joachims, 2002), SoftRank (Guiver and Snelson, 2008)). Thus the choice 1039 of the learning method does not influence parsing time. We believe that the real bottleneck of parsing applications is parsing time and not training time. On the other hand, they can learn a better model (at the cost of higher training time) than the Perceptron. In theory, we can imagine learning to rank approaches which can not be reduced to the individual scoring of candidates at prediction time, for instance a decision tree-based pairwise ranker. Although such methods would also fit into the general subtr"
D12-1095,P04-1015,0,0.0931214,"the parsing algorithm reduces to perceptron-based forest parsing. If the “selection strategy” utilizes the base system ranking and training starts with a filtering step which keeps only candidate sets from the root node of the forest we get the offline version of the training procedure of the perceptron-based forest reranker of Huang (2008). As our approach is based on local ranking (local update in the online learning literature), it is highly related to early update which looks for the first local decision point where the oracle parse falls out from the beam. Early update was introduced by Collins and Roark (2004) for incremental parsing and adopted to forest reranking by Wang and Zong (2011). Besides phrase structure parsing, the forest reranking approach was successfully applied for dependency parsing as well. Hayashi et al. (2011) introduced a procedure where the interpolation of a generative and a forest-based discriminative parser is exploited. From the algorithmic point of view, our approach is probably most closely related to Searn (Daum´e et al., 2009) and Magerman (1995) as we also employ a particular machine learned model for a sequence of local decisions. The topological order of the parse f"
D12-1095,W11-2924,1,0.848015,"is different from the ’perceptron with global training’ as we conduct updates at every local decision point and we do offline training (’subtree ranking by AvgPer’). • The subtree ranker method using Maximum Entropy training (’subtree ranking by MaxEnt’). 1042 We (re)implemented these methods and used the same forests and the same feature sets for the comparative experiments. 4.4 Implementation Details We used the first-stage PCFG parser of Charniak and Johnson (2005) for English and BitPar (Schmid, 2004) for German. BitPar employs a grammar engineered for German (for details please refer to Farkas et al. (2011)). These two parsers are state-of-the-art PCFG parsers for English and German, respectively. For German the base parser and the reranker operate on the conflation of constituent labels and grammatical functions. For English, we used the forest extraction and pruning code of Huang (2008). The pruning removes hyperedges where the difference between the cost of the best derivation using this hyperedge and the cost of the globally best derivation is above some threshold. For German, we used the pruned parse forest of Bitpar (Schmid, 2004). After computing the posterior probability of each hyperedg"
D12-1095,P07-1050,0,0.0193862,"arameter optimization. Another chief advantage of the framework is that arbitrary learning to rank methods can be applied. We evaluated our reranking approach on German and English phrase structure parsing tasks and compared it to various state-of-the-art reranking approaches such as the perceptron-based forest reranker. The subtree ranking approach with a Maximum Entropy model significantly outperformed the other approaches. 1 Introduction Reranking has become a popular technique for solving various structured prediction tasks, such as phrase-structure (Collins, 2000) and dependency parsing (Hall, 2007), semantic role labeling (Toutanova et al., 2008) and machine translation (Shen et al., 2004). The idea is to (re)rank candidates extracted by a base system exploiting a rich feature set and operating at a global (usually sentence) level. Reranking achieved significant gains over the base system in many tasks because it has access to information/features which are not computable in the base system. Reranking also outperforms discriminative approaches which try to handle the entire candidate universe (cf. Turian et al. (2006)) because the base system effectively and efficiently filters out many"
D12-1095,D11-1137,0,0.0951197,"for reranking is the n-best list ranking procedure, where the base system extracts its top n global-level candidates with associated goodness scores that define an initial ranking. Then the task is to rerank these candidates by using a rich feature set. The bottleneck of this approach is the small number of candidates considered. Compared to n-best lists, packed parse forests encode more candidates in a compact way. Forest reranking methods have been proposed, which can exploit the richer set of candidates and they have been successfully applied for phrase-structure (Huang, 2008), dependency (Hayashi et al., 2011) parsing and machine translation (Li and Khudanpur, 2009) as well. Huang (2008) introduced the perceptron-based forest reranking approach. The core of the algorithm is a beam-search based decoder operating on the packed forest in a bottom-up manner. It follows the assumption that the feature values of the whole structure are the sum of the feature values of the local elements and they are designed to the usage of the perceptron update. Under these assumptions a 1-best Viterbi or beam-search decoder can be efficiently employed at parsing and training time. During training, it decodes the 1-best"
D12-1095,P08-1067,0,0.147466,"le. The standard approach for reranking is the n-best list ranking procedure, where the base system extracts its top n global-level candidates with associated goodness scores that define an initial ranking. Then the task is to rerank these candidates by using a rich feature set. The bottleneck of this approach is the small number of candidates considered. Compared to n-best lists, packed parse forests encode more candidates in a compact way. Forest reranking methods have been proposed, which can exploit the richer set of candidates and they have been successfully applied for phrase-structure (Huang, 2008), dependency (Hayashi et al., 2011) parsing and machine translation (Li and Khudanpur, 2009) as well. Huang (2008) introduced the perceptron-based forest reranking approach. The core of the algorithm is a beam-search based decoder operating on the packed forest in a bottom-up manner. It follows the assumption that the feature values of the whole structure are the sum of the feature values of the local elements and they are designed to the usage of the perceptron update. Under these assumptions a 1-best Viterbi or beam-search decoder can be efficiently employed at parsing and training time. Dur"
D12-1095,2008.amta-papers.12,0,0.0433754,"WSJ test 90.32 89.97 WB 83.83 83.34 Table 4: The results of the two selection strategies. Using the oracle trees proved to be better on each of the datasets. Extracting candidate lists from each of the local decision points might seem to be redundant. To gain some insight into this question, we investigated the effect of training instance filtering strategies on the Tiger treebank. We removed the training instances from the training sample T where the F-score of the oracle (sub)tree against the gold standard tree is less than a certain threshold (this data selection procedure was inspired by Li and Khudanpur (2008)). The idea behind this data selection is to eliminate bad training examples which might push the learner into the wrong direction. Figure 1 depicts the results on the Tiger treebank as a function of this data selection threshold. With this data selection strategy we could further gain 0.22 F-score percentage points achieving 79.58 (68.87) and we can conclude that omitting candidate sets far from the gold-standard tree helps training. Figure 1 also shows that too strict filtering hurts the performance. The result with threshold=90 is worse than the result without filtering. We should note that"
D12-1095,P95-1037,0,0.109089,"s for the first local decision point where the oracle parse falls out from the beam. Early update was introduced by Collins and Roark (2004) for incremental parsing and adopted to forest reranking by Wang and Zong (2011). Besides phrase structure parsing, the forest reranking approach was successfully applied for dependency parsing as well. Hayashi et al. (2011) introduced a procedure where the interpolation of a generative and a forest-based discriminative parser is exploited. From the algorithmic point of view, our approach is probably most closely related to Searn (Daum´e et al., 2009) and Magerman (1995) as we also employ a particular machine learned model for a sequence of local decisions. The topological order of the parse forest nodes can form the “sequence of choices” of Searn. The biggest differences between our approach and Searn are that we propose an approach employing beam search and the “policy” is a ranker in our framework instead of a multiclass classifier as there are no “actions” here, instead we have to choose from candidate sets in the forest reranking framework. In a wider sense, our approach can be regarded – like Searn – as an Inverse Reinforcement Learning approach where “"
D12-1095,C04-1024,1,0.772101,"of 0.3 on the German dataset. • The subtree ranker method using the Averaged Perceptron reranker. This is different from the ’perceptron with global training’ as we conduct updates at every local decision point and we do offline training (’subtree ranking by AvgPer’). • The subtree ranker method using Maximum Entropy training (’subtree ranking by MaxEnt’). 1042 We (re)implemented these methods and used the same forests and the same feature sets for the comparative experiments. 4.4 Implementation Details We used the first-stage PCFG parser of Charniak and Johnson (2005) for English and BitPar (Schmid, 2004) for German. BitPar employs a grammar engineered for German (for details please refer to Farkas et al. (2011)). These two parsers are state-of-the-art PCFG parsers for English and German, respectively. For German the base parser and the reranker operate on the conflation of constituent labels and grammatical functions. For English, we used the forest extraction and pruning code of Huang (2008). The pruning removes hyperedges where the difference between the cost of the best derivation using this hyperedge and the cost of the globally best derivation is above some threshold. For German, we used"
D12-1095,N04-1023,0,0.090629,"Missing"
D12-1095,J08-2002,0,0.0704792,"Missing"
D12-1095,W09-3820,0,0.465226,"† (67.97†) 79.36 (68.72) WSJ dev 90.58 90.81† 90.89 90.65† 91.14 WSJ test 89.60 90.01 90.11 89.97 90.32 WB 82.87 83.03† 83.55 83.04† 83.83 Table 2: The results achieved by various forest rerankers. The difference between the scores marked by † and the ’perceptron with global training’ were not statistically significant with p < 0.005 according to the the McNemar test. All other results are statistically different from this baseline. 2008) and selectively re-implemented feature templates from (Collins, 2000) and Charniak and Johnson (2005). For German we re-implemented the feature templates of Versley and Rehbein (2009) which is the state-of-the-art feature set for German. It consists of features constructed from the lexicalized parse tree and its typed dependencies along with features based on external statistical information (such as the clustering of unknown words according to their context of occurrence and PP attachment statistics gathered from the automatically POS tagged DE-WaC corpus, a 1.7G words sample of the German-language WWW). We filtered out rare features which occurred in less than 10 forests (we used the same non-tuned threshold for the English and German training sets as well). We also re-i"
D12-1095,I11-1140,0,0.240881,"strategy” utilizes the base system ranking and training starts with a filtering step which keeps only candidate sets from the root node of the forest we get the offline version of the training procedure of the perceptron-based forest reranker of Huang (2008). As our approach is based on local ranking (local update in the online learning literature), it is highly related to early update which looks for the first local decision point where the oracle parse falls out from the beam. Early update was introduced by Collins and Roark (2004) for incremental parsing and adopted to forest reranking by Wang and Zong (2011). Besides phrase structure parsing, the forest reranking approach was successfully applied for dependency parsing as well. Hayashi et al. (2011) introduced a procedure where the interpolation of a generative and a forest-based discriminative parser is exploited. From the algorithmic point of view, our approach is probably most closely related to Searn (Daum´e et al., 2009) and Magerman (1995) as we also employ a particular machine learned model for a sequence of local decisions. The topological order of the parse forest nodes can form the “sequence of choices” of Searn. The biggest differences"
D13-1032,P05-1022,0,0.0319742,"the size of the tagset and exponentially on the order of the CRF. This probably explains why CRFs, despite their outstanding accuracy, normally only are applied to tasks with small tagsets such as Named Entity Recognition and Chunking; if they are applied to tasks with bigger tagsets – e.g., to part-of-speech (POS) tagging for English – then they generally are used as 1st -order models. In this paper, we demonstrate that fast and accurate CRF training and tagging is possible for large tagsets of even thousands of tags by approximating the CRF objective function using coarse-to-fine decoding (Charniak and Johnson, 2005; Rush and We use POS tagging and combined POS and morphological (POS+MORPH) tagging to demonstrate the properties and benefits of our approach. POS+MORPH disambiguation is an important preprocessing step for syntactic parsing. It is usually tackled by applying sequence prediction. POS+MORPH tagging is also a good example of a task where CRFs are rarely applied as the tagsets are often so big that even 1st -order dynamic programming is too expensive. A workaround is to restrict the possible tag candidates per position by using either morphological analyzers (MAs), dictionaries or heuristics (H"
D13-1032,chrupala-etal-2008-learning,0,0.192881,"Missing"
D13-1032,P04-1015,0,0.100384,"chastic Gradient Descent (SGD) (Tsuruoka et al., 2009). We would like to create a cascade of increasingly complex lattices and update the weight vector with the gradient of the last lattice. The updates, however, are undefined if the gold sequence is pruned from the lattice. A solution would be to simply reinsert the gold sequence, but this yields poor results as the model never learns to keep the gold sequence in the lower-order lattices. As an alternative we perform the gradient update with the highest lattice still containing the gold sequence. This approach is similar to “early updating” (Collins and Roark, 2004) in perceptron learning, where during beam search an update with the highest scoring partial hypothe324 1: function G ET S UM L ATTICE(sentence, ~τ ) 2: gold-tags ← getTags(sentence) 3: candidates ← getAllCandidates(sentence) 4: lattice ← ZeroOrderLattice(candidates) 5: for i = 1 → n do 6: candidates ← lattice. prune(τi−1 ) 7: if gold-tags 6∈ candidates then 8: return lattice 9: end if 10: if i &gt; 1 then 11: candidates ← mergeStates(candidates) 12: end if 13: candidates ← addTransitions(candidates) 14: lattice ← SequenceLattice(candidates, i) 15: end for 16: return lattice 17: end function Figu"
D13-1032,W02-1001,0,0.351278,"Missing"
D13-1032,E12-1007,1,0.802045,"amouri et al., 2004), parts 1–3 in their latest versions (LDC2010T08, LDC2010T13, LDC2011T09). As training set we use parts 1 and 2 and part 3 up to section ANN20020815.0083. All consecutive sections up to ANN20021015.0096 are used as development set and the remainder as test set. We use the unvocalized and pretokenized transliterations as input. For Czech and Spanish, we use the CoNLL 2009 data sets (Hajiˇc et al., 2009); for German, the TIGER treebank (Brants et al., 2002) with the split from Fraser et al. (2013); for Hungarian, the Szeged treebank (Csendes et al., 2005) with the split from Farkas et al. (2012). For English we use the Penn Treebank (Marcus et al., 1993) with the split from Toutanova et al. (2003). We also compute the possible POS+MORPH tags for every word using MAs. For Arabic we use the AraMorph reimplementation of Buckwalter (2002), for Czech the “free” morphology (Hajiˇc, 2001), for Spanish Freeling (Padr´o and Stanilovsky, 2012), for German DMOR (Schiller, 1995) and for Hungarian Experiments We run POS+MORPH tagging experiments on Arabic (ar), Czech (cs), Spanish (es), German (de) and Hungarian (hu). The following table shows the typetoken (T/T) ratio, the average number of tags"
D13-1032,J13-1005,1,0.761979,"Missing"
D13-1032,gimenez-marquez-2004-svmtool,0,0.0158455,"Missing"
D13-1032,A00-2013,0,0.0755341,"Missing"
D13-1032,P10-1050,0,0.0195055,"losses in accuracy. Lavergne et al. (2010) make use of feature sparsity to significantly speed up training for moderate tagset sizes (&lt; 100) and huge feature spaces. It is unclear if their approach would also work for huge tag sets (&gt; 1000). Coarse-to-fine decoding has been successfully applied to CYK parsing where full dynamic programming is often intractable when big grammars are used (Charniak and Johnson, 2005). Weiss and Taskar (2010) develop cascades of models of increasing complexity in a framework based on perceptron learning and an explicit trade-off between accuracy and efficiency. Kaji et al. (2010) propose a modified Viterbi algorithm that is still optimal but depending on task and especially for big tag sets might be several orders of magnitude faster. While their algorithm can be used to produce fast decoders, there is no such modification for the forward-backward algorithm used during CRF training. the Penn Arabic Treebank. Czech is a highly inflecting Slavic language with a large number of morphological features. Spanish is a Romance language. Based on the statistics above we can see that it has few POS+MORPH ambiguities. It is also the language with the smallest tagset and the only"
D13-1032,P10-1052,0,0.0187993,"Missing"
D13-1032,J93-2004,0,0.0449108,"C2010T08, LDC2010T13, LDC2011T09). As training set we use parts 1 and 2 and part 3 up to section ANN20020815.0083. All consecutive sections up to ANN20021015.0096 are used as development set and the remainder as test set. We use the unvocalized and pretokenized transliterations as input. For Czech and Spanish, we use the CoNLL 2009 data sets (Hajiˇc et al., 2009); for German, the TIGER treebank (Brants et al., 2002) with the split from Fraser et al. (2013); for Hungarian, the Szeged treebank (Csendes et al., 2005) with the split from Farkas et al. (2012). For English we use the Penn Treebank (Marcus et al., 1993) with the split from Toutanova et al. (2003). We also compute the possible POS+MORPH tags for every word using MAs. For Arabic we use the AraMorph reimplementation of Buckwalter (2002), for Czech the “free” morphology (Hajiˇc, 2001), for Spanish Freeling (Padr´o and Stanilovsky, 2012), for German DMOR (Schiller, 1995) and for Hungarian Experiments We run POS+MORPH tagging experiments on Arabic (ar), Czech (cs), Spanish (es), German (de) and Hungarian (hu). The following table shows the typetoken (T/T) ratio, the average number of tags of every word form that occurs more than once in the traini"
D13-1032,padro-stanilovsky-2012-freeling,0,0.0629783,"Missing"
D13-1032,W96-0213,0,0.097698,"the 0-order level. To decrease the number of tag candidates in the 0-order model, we decode in two steps by separating the fully specified tag into a coarse-grained part-of-speech (POS) tag and a finegrained MORPH tag containing the morphological features. We then first build a lattice over POS candidates and apply our pruning strategy. In a second step we expand the remaining POS tags into all the combinations with MORPH tags that were seen in the training set. We thus build a sequence of lattices of both increasing order and increasing tag complexity. 2.5 Feature Set We use the features of Ratnaparkhi (1996) and Manning (2011): the current, preceding and succeeding words as unigrams and bigrams and for rare words prefixes and suffixes up to length 10, and the occurrence of capital characters, digits and special characters. We define a rare word as a word with training set frequency ≤ 10. We concatenate every feature with the POS and MORPH tag and every morphological feature. E.g., for the word “der”, the POS tag art (article) and the MORPH tag gen|sg|fem (genitive, singular, feminine) we 325 Figure 2: Example training run of a pruned 1st -order model on German showing the fraction of pruned gold"
D13-1032,N12-1054,0,0.0175174,"Missing"
D13-1032,C08-1098,1,0.298369,"s and minus indicate models that are significantly better or worse than MA1. We can see that the improvements due to higher-order models are orthogonal to the improvements due to MAs for all languages. This was to be expected as MAs provide additional lexical knowledge while higher-order models provide additional information about the context. For Arabic and German the improvements of higher-order models are bigger than the improvements due to MAs. 4.7 Comparison with Baselines We use the following baselines: SVMTool (Gim´enez and M`arquez, 2004), an SVM-based discriminative tagger; RFTagger (Schmid and Laws, 2008), an n-gram Hidden Markov Model (HMM) tagger developed for POS+MORPH tagging; Morfette (Chrupała et al., 2008), an averaged perceptron with beam search decoder; CRFSuite (Okazaki, 2007), a fast CRF implementation; and the Stanford Tagger (Toutanova et al., 2003), a bidirectional Maximum Entropy Markov Model. For POS+MORPH tagging, all baselines are trained on the concatenation of POS tag and MORPH tag. We run SVMTool with the standard feature set and the optimal c-values ∈ {0.1, 1, 10}. Morfette is run with the default options. For CRFSuite we use l2 -regularized SGD training. We use the optim"
D13-1032,P07-1096,0,0.0225943,"Missing"
D13-1032,H05-1060,0,0.0203354,"lattice than a hard constraint. For some experiments we also use the output of a morphological analyzer (MA). In that case we simply use every analysis of the MA as a simple nominal feature. This approach is attractive because it does not require the output of the MA and the annotation of the treebank to be identical; in fact, it can even be used if treebank annotation and MA use completely different features. Because the weight vector dimensionality is high for large tagsets and productive languages, we use a hash kernel (Shi et al., 2009) to keep the dimensionality constant. 3 Related Work Smith et al. (2005) use CRFs for POS+MORPH tagging, but use a morphological analyzer for candidate selection. They report training times of several days and that they had to use simplified models for Czech. Several methods have been proposed to reduce CRF training times. Stochastic gradient descent can be applied to reduce the training time by a factor of 5 (Tsuruoka et al., 2009) and without drastic losses in accuracy. Lavergne et al. (2010) make use of feature sparsity to significantly speed up training for moderate tagset sizes (&lt; 100) and huge feature spaces. It is unclear if their approach would also work f"
D13-1032,N03-1033,0,0.57353,"ining set we use parts 1 and 2 and part 3 up to section ANN20020815.0083. All consecutive sections up to ANN20021015.0096 are used as development set and the remainder as test set. We use the unvocalized and pretokenized transliterations as input. For Czech and Spanish, we use the CoNLL 2009 data sets (Hajiˇc et al., 2009); for German, the TIGER treebank (Brants et al., 2002) with the split from Fraser et al. (2013); for Hungarian, the Szeged treebank (Csendes et al., 2005) with the split from Farkas et al. (2012). For English we use the Penn Treebank (Marcus et al., 1993) with the split from Toutanova et al. (2003). We also compute the possible POS+MORPH tags for every word using MAs. For Arabic we use the AraMorph reimplementation of Buckwalter (2002), for Czech the “free” morphology (Hajiˇc, 2001), for Spanish Freeling (Padr´o and Stanilovsky, 2012), for German DMOR (Schiller, 1995) and for Hungarian Experiments We run POS+MORPH tagging experiments on Arabic (ar), Czech (cs), Spanish (es), German (de) and Hungarian (hu). The following table shows the typetoken (T/T) ratio, the average number of tags of every word form that occurs more than once in the training set (A) and the number of tags of the mos"
D13-1032,P09-1054,0,0.119698,"adding transitions to the pruned lattice and pruning with threshold τ1 . The only difference to 0-order pruning is that we now have to run forward-backward to calculate the probabilities p(y|~x, t). Note that in theory we could also apply the pruning to transition probabilities of the form p(y, y 0 |~x, t); however, this does not seem to yield more accurate models and is less efficient than state pruning. For higher-order lattices we merge pairs of states into new states, add transitions and prune with threshold τi . We train the model using l1 -regularized Stochastic Gradient Descent (SGD) (Tsuruoka et al., 2009). We would like to create a cascade of increasingly complex lattices and update the weight vector with the gradient of the last lattice. The updates, however, are undefined if the gold sequence is pruned from the lattice. A solution would be to simply reinsert the gold sequence, but this yields poor results as the model never learns to keep the gold sequence in the lower-order lattices. As an alternative we perform the gradient update with the highest lattice still containing the gold sequence. This approach is similar to “early updating” (Collins and Roark, 2004) in perceptron learning, where"
D13-1032,C00-2137,0,0.0176944,"Missing"
D13-1032,W09-1201,0,\N,Missing
D14-1103,N09-2054,0,0.0728471,"iversity of Munich, Germany § Department of Informatics, University of Szeged, Hungary ‡ Heidelberg Institute for Theoretical Studies, Heidelberg, Germany muellets@cis.lmu.de 2 Abstract Petrov et al. (2006) introduce generative splitmerge training for PCFGs and provide a fully automatic method for training state-of-the-art phrase structure parsers. They argue that the resulting latent annotations are linguistically meaningful. Sun et al. (2008) induce latent sub-states into CRFs and show that noun phrase (NP) recognition can be improved, especially if no part-of-speech features are available. Huang et al. (2009) apply split-merge training to create HMMs with latent annotations (HMM-LA) for Chinese POS tagging. They report that the method outperforms standard generative bigram and trigram tagging, but do not compare to discriminative methods. Eidelman et al. (2010) show that a bidirectional variant of latent HMMs with incorporation of prosodic information can yield state-of-the-art results in POS tagging of conversational speech. In this paper we propose a method to increase dependency parser performance without using additional labeled or unlabeled data by refining the layer of predicted part-of-spee"
D14-1103,N07-1051,0,0.0556405,"ile Hidden Markov Models with latent annotations (HMMLA) (Huang et al., 2009), stay somewhat behind the performance of state-of-the-art discriminative taggers (Eidelman et al., 2010). In this paper we address the question of whether the resulting latent POS tags are linguistically meaningful and useful for upstream tasks such as syntactic parsing. We find that this is indeed the case, leading to a procedure that significantly increases the performance of dependency parsers. The procedure is attractive because the refinement of predicted part-of-speech sequences using a coarse-tofine strategy (Petrov and Klein, 2007) is fast and efficient. More precisely, we show that incorporating the induced POS into a state-of-the-art dependency parser (Bohnet, 2010) gives increases in Labeled Attachment Score (LAS): from 90.34 to 90.57 for English and from 87.92 to 88.24 (resp. 88.35 to 88.51) for German without using (resp. with using) morphological features. 3 Split-Merge Training for HMMs Split-merge training for HMMs (Huang et al., 2009) iteratively splits every tag into two subtags. Word emission and tag transition probabilities of subtags are then initialized close to the values of the parent tags but with some"
D14-1103,P06-1055,0,0.172311,"tion of prosodic information can yield state-of-the-art results in POS tagging of conversational speech. In this paper we propose a method to increase dependency parser performance without using additional labeled or unlabeled data by refining the layer of predicted part-of-speech (POS) tags. We perform experiments on English and German and show significant improvements for both languages. The refinement is based on generative split-merge training for Hidden Markov models (HMMs). 1 Related Work Introduction Probabilistic Context-free Grammars with latent annotations (PCFG-LA) have been shown (Petrov et al., 2006) to yield phrase structure parsers with state-of-the-art accuracy. While Hidden Markov Models with latent annotations (HMMLA) (Huang et al., 2009), stay somewhat behind the performance of state-of-the-art discriminative taggers (Eidelman et al., 2010). In this paper we address the question of whether the resulting latent POS tags are linguistically meaningful and useful for upstream tasks such as syntactic parsing. We find that this is indeed the case, leading to a procedure that significantly increases the performance of dependency parsers. The procedure is attractive because the refinement o"
D14-1103,C00-2137,0,\N,Missing
D14-1103,C08-1106,0,\N,Missing
D14-1103,W09-1201,0,\N,Missing
D14-1103,petrov-etal-2012-universal,0,\N,Missing
D14-1103,D10-1080,0,\N,Missing
E09-1079,H92-1022,0,0.208116,"Missing"
E09-1079,A88-1019,0,0.79281,"Missing"
E09-1079,P89-1015,0,0.431466,"Missing"
E09-1079,J93-2004,0,0.0449137,"kers, Urdu has noThere are various questions that need to be answered during the design of a tagset. The granularity of the tagset is the first problem in this regard. A tagset may consist either of general parts of speech only or it may consist of additional morpho-syntactic categories such as number, gender and case. In order to facilitate the tagger training and to reduce the lexical and syntactic ambiguity, we decided to concentrate on the syntactic categories of the language. Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of manual tagging2 (Marcus et al., 1993). Urdu is influenced from Arabic, and can be considered as having three main parts of speech, namely noun, verb and particle (Platts, 1909; Javed, 1981; Haq, 1987). However, some grammarians proposed ten main parts of speech for Urdu (Schmidt, 1999). The work of Urdu grammar writers provides a full overview of all the features of the language. However, in the perspective of the tagset, their analysis is lacking the computational grounds. The semantic, morphological and syntactic categories are mixed in their distribution of parts of speech. For example, Haq (1987) divides the common nouns into"
E09-1079,C94-1027,1,0.754708,"Missing"
E09-1079,C08-1098,1,\N,Missing
E09-1079,A00-1031,0,\N,Missing
E09-1079,gimenez-marquez-2004-svmtool,0,\N,Missing
E12-1007,E03-1012,0,0.43377,"Missing"
E12-1007,C10-1011,0,0.333815,"ide the issue of the internal structure of NPs, most sentence-level syntactic information in Hungarian is conveyed ´ Kiss, by morphology, not by configuration (E. 2002). A large part of the methodology for syntactic parsing has been developed for English. However, parsing non-configurational and less configurational languages requires different techniques. In this study, we present results on Hungarian dependency parsing and we investigate this general issue in the case of English and Hungarian. We employed three state-of-the-art data-driven parsers (Nivre et al., 2004; McDonald et al., 2005; Bohnet, 2010), which achieved (un)labeled attachment scores on Hungarian not so different from the corresponding English scores (and even higher on certain domains/subcorpora). Our investigations show that the feature representation used by the data-driven parsers is so rich that they can – without any modification – effectively learn a reasonable model for non-configurational languages as well. We also conducted a systematic and comparative error analysis of the system’s outputs for Hungarian and English. This analysis highlights the challenges of parsing Hungarian and suggests that the further improvemen"
E12-1007,W06-2920,0,0.200297,"Missing"
E12-1007,D07-1101,0,0.0214338,"on-based system, which uses an arc-eager system along with support vector machines to learn the scoring function for transitions and which uses greedy, deterministic onebest search at parsing time. As one of the graphbased parsers, we employed the MST parser (McDonald et al., 2005) with a second-order feature decoder. It uses an approximate exhaustive search for unlabeled parsing, then a separate arc label classifier is applied to label each arc. The Mate parser (Bohnet, 2010) is an efficient second order dependency parser that models the interaction between siblings as well as grandchildren (Carreras, 2007). Its decoder works on labeled edges, i.e. it uses a single-step approach for obtaining labeled dependency trees. Mate uses a rich and 4 The JAVA implementation of the morphological analyser and the slightly modified POS tagger along with trained models are available at http://www.inf.u-szeged. hu/rgai/magyarlanc. 58 corpus newspaper short business fiction law computer composition #sent. 9189 8616 9279 8347 8653 22248 length 21.6 23.6 12.6 27.3 21.9 13.7 CPOS 97.2 98.0 96.9 98.3 96.4 96.7 DPOS 96.5 97.7 95.8 98.1 95.8 95.6 ULA 88.0 (90.0) 93.8 (94.8) 87.7 (89.4) 90.6 (90.7) 91.3 (92.8) 92.7 (9"
E12-1007,C96-1058,0,0.0840122,"ds inside of constituents to be consecutive and it naturally represent discontinuous constructions, which are frequent in languages where grammatical relations are often signaled by morphology instead of word order (McDonald and Nivre, 2011). The two main efficient approaches for dependency parsing are the graph-based and the transition-based parsers. The graph-based models look for the highest scoring directed spanning tree in the complete graph whose nodes are the words of the sentence in question. They solve the machine learning problem of finding the optimal scoring function of subgraphs (Eisner, 1996; McDonald et al., 2005). The transition-based approaches parse a sentence in a single left-to-right pass over the words. The next transition in these systems is predicted by a classifier that is based on history-related features (Kudo and Matsumoto, 2002; Nivre et al., 2004). Although the available treebanks for Hungarian are relatively big (82K sentences) and fully manually annotated, the studies on parsing Hungarian are rather limited. The Szeged (Constituency) Treebank (Csendes et al., 2005) con56 sists of six domains – namely, short business news, newspaper, law, literature, compositions"
E12-1007,D07-1097,0,0.0321724,"are efficiently identified by our morphological analyser. The most frequent morphological features which cannot be disambiguated at the word level are related to suffixes with multiple functions or the word itself cannot be unambiguously segmented into morphemes. Although the number of such ambiguous cases is low, they form important features for the parser, thus we will focus on the more accurate handling of these cases in future work. Comparison to CoNLL-2007 results: The best performing participant of the CoNLL-2007 Shared Task (Nivre et al., 2007) achieved an ULA of 83.6 and LAS of 80.3 (Hall et al., 2007) on the Hungarian corpus. The difference between the top performing English and Hungarian systems were 8.14 ULA and 9.3 LAS. The results reported in 2007 were significantly lower and the gap between English and Hungarian is higher than our current values. To locate the sources of difference we carried out other experiments with Mate on the CoNLL-2007 dataset using the gold-standard POS tags (the shared task used gold-standard POS tags for evaluation). First we trained and evaluated Mate on the original CoNLL-2007 datasets, where it achieved ULA 84.3 and LAS 80.0. Then we used the sentences of"
E12-1007,W02-2016,0,0.0111191,"The two main efficient approaches for dependency parsing are the graph-based and the transition-based parsers. The graph-based models look for the highest scoring directed spanning tree in the complete graph whose nodes are the words of the sentence in question. They solve the machine learning problem of finding the optimal scoring function of subgraphs (Eisner, 1996; McDonald et al., 2005). The transition-based approaches parse a sentence in a single left-to-right pass over the words. The next transition in these systems is predicted by a classifier that is based on history-related features (Kudo and Matsumoto, 2002; Nivre et al., 2004). Although the available treebanks for Hungarian are relatively big (82K sentences) and fully manually annotated, the studies on parsing Hungarian are rather limited. The Szeged (Constituency) Treebank (Csendes et al., 2005) con56 sists of six domains – namely, short business news, newspaper, law, literature, compositions and informatics – and it is manually annotated for the possible alternatives of words’ morphological analyses, the disambiguated analysis and constituency trees. We are aware of only two articles on phrase-structure parsers which were trained and evaluate"
E12-1007,J11-1007,0,0.0114111,"). This train of thought indicates that the cross-lingual comparison of final parser scores should be conducted very carefully. 3 Related work We decided to focus on dependency parsing in this study as it is a superior framework for nonconfigurational languages. It has gained interest in natural language processing recently because the representation itself does not require the words inside of constituents to be consecutive and it naturally represent discontinuous constructions, which are frequent in languages where grammatical relations are often signaled by morphology instead of word order (McDonald and Nivre, 2011). The two main efficient approaches for dependency parsing are the graph-based and the transition-based parsers. The graph-based models look for the highest scoring directed spanning tree in the complete graph whose nodes are the words of the sentence in question. They solve the machine learning problem of finding the optimal scoring function of subgraphs (Eisner, 1996; McDonald et al., 2005). The transition-based approaches parse a sentence in a single left-to-right pass over the words. The next transition in these systems is predicted by a classifier that is based on history-related features"
E12-1007,H05-1066,0,0.74539,"tence level. Leaving aside the issue of the internal structure of NPs, most sentence-level syntactic information in Hungarian is conveyed ´ Kiss, by morphology, not by configuration (E. 2002). A large part of the methodology for syntactic parsing has been developed for English. However, parsing non-configurational and less configurational languages requires different techniques. In this study, we present results on Hungarian dependency parsing and we investigate this general issue in the case of English and Hungarian. We employed three state-of-the-art data-driven parsers (Nivre et al., 2004; McDonald et al., 2005; Bohnet, 2010), which achieved (un)labeled attachment scores on Hungarian not so different from the corresponding English scores (and even higher on certain domains/subcorpora). Our investigations show that the feature representation used by the data-driven parsers is so rich that they can – without any modification – effectively learn a reasonable model for non-configurational languages as well. We also conducted a systematic and comparative error analysis of the system’s outputs for Hungarian and English. This analysis highlights the challenges of parsing Hungarian and suggests that the fur"
E12-1007,P05-1013,0,0.021246,"he internal structures of Named Entities and we imagine a pipeline where a Named Entity Recogniser precedes the parsing step. Empty copula: In the verbless clauses (predicative nouns or adjectives) the Szeged Dependency Treebank introduces virtual nodes (16,000 items in the corpus). This solution means that a similar tree structure is ascribed to the same sentence in the present third person singular and all the other tenses / persons. A further argument for the use of a virtual node is that the virtual node is always present at the syntactic level 2 Using the transitive closure definition of Nivre and Nilsson (2005). 57 corpus Hungarian English dev test dev test Malt ULA LAS 88.3 (89.9) 85.7 (87.9) 88.7 (90.2) 86.1 (88.2) 87.8 (89.1) 84.5 (86.1) 88.8 (89.9) 86.2 (87.6) MST ULA LAS 86.9 (88.5) 80.9 (82.9) 87.5 (89.0) 81.6 (83.5) 89.4 (91.2) 86.1 (87.7) 90.7 (91.8) 87.7 (89.2) Mate ULA LAS 89.7 (91.1) 86.8 (89.0) 90.1 (91.5) 87.2 (89.4) 91.6 (92.7) 88.5 (90.0) 92.6 (93.4) 90.3 (91.5) Table 1: Results achieved by the three parsers on the (full) Hungarian (Szeged Dependency Treebank) and English (CoNLL-2009) datasets. The scores in brackets are achieved with gold-standard POS tagging. since it is overt in al"
E12-1007,W04-2407,0,0.0175033,"Missing"
E12-1007,2004.eamt-1.17,0,0.0785525,"Missing"
E12-1007,N03-1033,0,0.00635951,"egedTreebank. Tools: We employed a finite state automatabased morphological analyser constructed from the morphdb.hu lexical resource (Tr´on et al., 2006) and we used the MSD-style morphological code system of the Szeged TreeBank (Alexin et al., 2003). The output of the morphological analyser is a set of possible lemma–morphological analysis pairs. This set of possible morphological analyses for a word form is then used as possible alternatives – instead of open and closed tag sets – in a standard sequential POS tagger. Here, we applied the Conditional Random Fields-based Stanford POS tagger (Toutanova et al., 2003) and carried out 5-fold-cross POS training/tagging inside the subcorpora.4 For the English experiments we used the predicted POS tags provided for the CoNLL-2009 shared task (Hajiˇc et al., 2009). As the dependency parser we employed three state-of-the-art data-driven parsers, a transitionbased parser (Malt) and two graph-based parsers (MST and Mate parsers). The Malt parser (Nivre et al., 2004) is a transition-based system, which uses an arc-eager system along with support vector machines to learn the scoring function for transitions and which uses greedy, deterministic onebest search at pars"
E12-1007,tron-etal-2006-morphdb,0,0.468383,"Missing"
E12-1007,vincze-etal-2010-hungarian,1,0.867873,"Missing"
E12-1007,W09-1201,0,\N,Missing
E12-1007,D07-1096,0,\N,Missing
faass-etal-2010-design,E03-1087,0,\N,Missing
faass-etal-2010-design,E06-2001,0,\N,Missing
faass-etal-2010-design,quasthoff-etal-2006-corpus,0,\N,Missing
faass-etal-2010-design,hinrichs-etal-2010-weblicht,0,\N,Missing
faass-etal-2010-design,schmid-etal-2004-smor,1,\N,Missing
faass-etal-2010-design,heid-etal-2010-corpus,1,\N,Missing
H05-1065,W98-1505,0,0.465224,"lyses as shown in figure 1 (for arbitrary depths). It also fails to represent non-local dependencies, like the one between Vertrag (contract) and L¨osung (solution) in the second analysis of figure 1. N N N V N N N V miet Vertrags Pref V Suff V N N V N .. ung miet Vertrag sauf Losung .. auf los Figure 1: Two morphological analyses of the German word Mietvertragsaufl¨osung (leasing contract cancellation); the first one is correct. Given the limitations of weighted finite-state transducers, we propose to use a more powerful formalism, namely head-lexicalized probabilistic context-free grammars (Carroll and Rooth, 1998; Charniak, 1997) to rank the analyses. Context-free grammars have, of course, no difficulties to generate the analyses shown in figure 1. By assigning probabilities to the grammar rules, we obtain a probabilistic context-free grammar (PCFG) which allows the parser to distinguish between frequent and rare morphological constructions. Nouns e.g. are much more likely to be compounds than verbs. In headlexicalized PCFGs (HL-PCFGs), the probability of a rule also depends on the lexical head of the constituent. HL-PCFGs are therefore able to learn that nouns headed by Problem (problem) are more lik"
H05-1065,E03-1076,0,0.0388032,"by a part-of-speech tagger and that frequent words can be disambiguated manually. 8 Related Work New methods are often first developed for English and later adapted to other languages. This might explain why morphological disambiguation has been so rarely addressed in the past: English morphology is seldom ambiguous except for noun compounds. We are not aware of any work on the disambiguation of morphological analyses which is directly comparable to ours. Mark Lauer (1995) only considered English noun compounds and applied a different disambiguation strategy based on word association scores. Koehn and Knight (2003) proposed a splitting method for German compounds and showed that it improves statistical machine translation. Compounds are split into smaller pieces (which have to be words themselves) if the geometric mean of the word frequencies of the pieces is higher than the frequency of the compound. Information from a bilingual corpus is used to improve the splitting accuracy. Andreas Eisele (unpublished work) implemented a statistical disambiguator for German based on weighted finite-state transducers as described in the introduction. However, his system fails to represent and disambiguate the ambigu"
H05-1065,P95-1007,0,0.0198931,"Missing"
H05-1065,schmid-etal-2004-smor,1,0.866297,"Missing"
heid-etal-2010-corpus,hinrichs-etal-2010-weblicht,1,\N,Missing
heid-etal-2010-corpus,C04-1024,1,\N,Missing
heid-etal-2010-corpus,W07-1501,0,\N,Missing
heid-etal-2010-corpus,kountz-etal-2008-laf,1,\N,Missing
heid-etal-2010-corpus,P10-4005,1,\N,Missing
I11-1015,C08-1068,0,0.517934,"ration. They build a conditional probability model. The graphemebased model performs better than the phonemebased model and the hybrid model. This motivates our use of grapheme-based models. In this paper, we use a grapheme-based approach for transliteration from Hindi to Urdu. The phoneme-based approach would involve the conversion of Hindi and Urdu text into a phonemic representation which is not a trivial task as the short vowel ‘a’ is not written in Hindi text and no short vowels are written in Urdu text. The difficulty of this additional step would be likely to lead to additional errors. Malik et al. (2008) and Malik et al. (2009) work on transliteration from Hindi to Urdu and Urdu to Hindi respectively. They use the rules of SAMPA (Speech Assessment Methods Pho3 Extraction of Transliteration Pairs We automatically word-align the parallel corpus and extract a word list, later referred to as “list of word pairs“ (see Section 5, for details on training data). We use two methods to extract transliteration pairs from the list of word pairs. In the first 1 SAMPA and XSAMPA are used to represent the IPA symbols using 7-bit printable ASCII characters. 130 iteration which best predicts the held-out data"
I11-1015,W09-3536,0,0.117608,"ditional probability model. The graphemebased model performs better than the phonemebased model and the hybrid model. This motivates our use of grapheme-based models. In this paper, we use a grapheme-based approach for transliteration from Hindi to Urdu. The phoneme-based approach would involve the conversion of Hindi and Urdu text into a phonemic representation which is not a trivial task as the short vowel ‘a’ is not written in Hindi text and no short vowels are written in Urdu text. The difficulty of this additional step would be likely to lead to additional errors. Malik et al. (2008) and Malik et al. (2009) work on transliteration from Hindi to Urdu and Urdu to Hindi respectively. They use the rules of SAMPA (Speech Assessment Methods Pho3 Extraction of Transliteration Pairs We automatically word-align the parallel corpus and extract a word list, later referred to as “list of word pairs“ (see Section 5, for details on training data). We use two methods to extract transliteration pairs from the list of word pairs. In the first 1 SAMPA and XSAMPA are used to represent the IPA symbols using 7-bit printable ASCII characters. 130 iteration which best predicts the held-out data is selected as the stop"
I11-1015,P10-1048,1,0.879527,"Missing"
I11-1015,J03-1002,0,0.0156683,"Missing"
I11-1015,P09-1016,0,0.0358459,"Missing"
I11-1015,P06-2025,0,0.254507,"Missing"
I11-1015,P11-1044,1,0.904408,"In this paper, the term transliteration pair refers to a word pair where the words are transliterations of each other and the term transliteration unit refers to a character pair where the characters are transliterations of each other. We are interested in building joint source channel models for transliteration. Because we do not have a list of transliteration pairs to use as training data in building such a transliteration model, we use two methods to extract the list of transliteration pairs from a parallel corpus of Hindi/Urdu. The first method uses the transliteration mining algorithm of Sajjad et al. (2011) to automatically extract transliteration pairs. This approach does not use any language specific knowledge. The second method uses handcrafted transliteration rules specific to the mapping between Hindi and Urdu to extract transliteration pairs. We automatically align the two lists of extracted transliteration pairs at the character level and learn two transliteration models. We compare the results with three other transliteration systems. Both of our transliteration systems perform better than the other systems. The 1-best output of the transliteration system built on the list extracted usin"
I11-1015,P08-1045,0,0.30392,"Missing"
I11-1015,W98-1005,0,0.0866721,"n pairs. This method does not use any language dependent information. In the second approach, we use a rule-based method to extract transliteration pairs. Both processes are imperfect, meaning that there is noise in the extracted list of transliteration pairs. We build a joint source channel model as described by Li et al. (2004) and Ekbal et al. (2006) on the extracted list of transliteration pairs. The following sections describe the two mining approaches and the model in detail. Previous Work Transliteration can be done with phoneme-based or grapheme-based models. Knight and Graehl (1998), Stalls and Knight (1998), Al-Onaizan and Knight (2002) and Pervouchine et al. (2009) use the phoneme-based approach for transliteration. Kashani et al. (2007) and Al-Onaizan and Knight (2002) use a grapheme-based model to transliterate from Arabic into English. Al-Onaizan and Knight (2002) compare a grapheme-based approach, a phoneme-based approach and a linear combination of both for transliteration. They build a conditional probability model. The graphemebased model performs better than the phonemebased model and the hybrid model. This motivates our use of grapheme-based models. In this paper, we use a grapheme-bas"
I11-1015,N03-1017,0,0.0309845,"Missing"
I11-1015,P04-1021,0,0.16253,"Missing"
I11-1015,N10-1077,1,\N,Missing
I11-1015,W02-0505,0,\N,Missing
I11-1015,J98-4003,0,\N,Missing
J13-1005,E06-2001,0,0.074573,"e derivational rule applied at the node in question. The last and biggest group of the pattern features is formed by the bilexical dependencies. They are based on the head word of the constituent node in question and its daughters. Versley and Rehbein (2009) have also introduced features that exploit statistical information gathered from an external data set and aim to resolve PP attachment ambiguity. Mutual information values were gathered on the association between nouns and immediately following prepositions, as well as between prepositions and closely following verbs on the DE-WaC corpus (Baroni and Kilgarriff 2006). These feature values were then used at NP→PP and VP→PP daughter attachments. A total of 2.7 million features ﬁred in the Tiger train. We ignored features ﬁring in less than ﬁve sentences for computational efﬁciency, resulting in 117,000 extremely sparse features. 7.3 Monolingual Reranking Experiments We rerank 100-best lists from BitPar (Schmid 2004), which uses the grammar extraction procedure and lexical resources introduced in Section 3. In each of the experiments we extracted the grammar from the Tiger train and used it to obtain the 100-best parses for the sentences of the evaluation co"
J13-1005,H91-1060,0,0.502125,"l reranking, which will be discussed later. 70 Fraser et al. Knowledge Sources for Parsing German to the same format as the gold standard trees by undoing Steps 2, 3, and 4 of Section 3.1. This conversion involves four steps: 1. Demarkovization removes all the auxiliary nodes introduced by markovization and raises their children to the next non-auxiliary node. 2. The added unary-branching nodes are eliminated. 3. The original grammatical function labels NK inside of NPs and PPs, and CJ inside of coordinated phrases, are restored. 4. All feature annotations are deleted. We use PARSEVAL scores (Black et al. 1991) and the standard evaluation tool evalb16 to compare the converted parse trees with the gold standard parse trees using labeled F-score. We report accuracies for all test sentences and not just sentences of length up to 40. We do not evaluate parsers with gold standard POS tags, but instead automatically infer them. These considerations make our evaluation setting as close to the real-world setting as possible. We report results for evaluations with and without grammatical functions. We report PARSEVAL scores with grammatical functions inside parentheses after the results using only basic cons"
J13-1005,A00-1031,0,0.0930958,"ecause some of the rules which are not markovized are also covered by markovization rules. 3.7 Dealing with Unknown Words and Unseen POS Tags BitPar includes a sophisticated POS guesser that uses several strategies to deal with unknown words and unseen POS tags of known words. Unknown words are divided into eight classes11 based on regular expressions that are manually deﬁned. These classes distinguish between lower-case words, capitalized words, all upper-case words, hyphenated words, numbers, and so forth. For each word class, BitPar builds a sufﬁx tree (Weischedel et al. 1993; Schmid 1995; Brants 2000) from the sufﬁxes of all words in the lexicon up to a length of 7. At each node of the sufﬁx tree, it sums up the conditional POS probabilities (given the word) over all known words with that sufﬁx. By summing POS probabilities rather than frequencies, all words have the same weight, which is appropriate here because we need to model the POS probabilities of infrequent words. BitPar computes POS probability estimates for each node using the sum of probabilities as a pseudo-frequency for each tag. The estimates are recursively smoothed with the Witten-Bell method using the smoothed POS probabil"
J13-1005,N10-1015,0,0.0304786,"Missing"
J13-1005,D08-1092,0,0.164596,"(+1.06) +0.78 (+1.00) +0.09 (+0.01) +0.78 (+0.70) The parse tree in Figure 6 demonstrates the value of bilingual features. It was produced by the monolingual reranker and it incorrectly combines the two adverbs aber and ebenso into an adverbial phrase and places this under the VP. The bilingual reranker instead attaches the two adverbs separately at the S level. The attachment to the S node indicates that the two adverbs modify the modal verb kann and not the full verb sagen. This is triggered by the feature POSPar2Prj. 8.3 Previous Work on Bitext Parsing Bitext parsing was also addressed by Burkett and Klein (2008). In that work, they use feature functions deﬁned on triples of (English parse tree, Chinese parse tree, alignment) which are combined in a log-linear model, much as we do. In later work (Burkett, Blitzer, and Klein 2010), they developed a uniﬁed joint model for solving the same problem using a weakly synchronized grammar. To train these models they use a small parallel Treebank that contains gold standard trees for parallel sentences in Chinese and English, whereas we only require gold standard trees for the language we are reranking. Another important difference is that Burkett and Klein (20"
J13-1005,P11-2037,0,0.0377588,"Missing"
J13-1005,P04-1082,0,0.0497864,"Missing"
J13-1005,P05-1022,0,0.827942,"at the gain of the two sets of reranking features (monolingual and bilingual) is additive, suggesting that they capture different types of information. The resulting parser is currently the best constituent parser for German (with or without bilingual features). In particular, we show that the baseline parser without reranking is competitive with the previous state of the art (the Berkeley parser) and that the re-ranking can add an important gain. 2. Previous Work Constituent parsing for English is well studied. The best generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCF"
J13-1005,P97-1003,0,0.510396,"es without a subject. We also mark conjunct clauses with the feature nosubj if they are neither headed by an imperative nor contain a child node with the grammatical function SB (subject) or EP (expletive). This is useful in order to correctly parse coordinations where the subject is dropped in the second conjunct. 3.6 Markovization The Tiger Treebank uses rather ﬂat structures where nodes have up to 25 child nodes. This causes sparse data problems because only some of the possible rules of that length actually appear in the training corpus. The sparse data problem is solved by markovization (Collins 1997; Klein and Manning 2003), which splits long rules into a set of shorter rules. The shorter rules generate the child nodes of the original rule one by one. First, the left siblings of the head child of the rule are generated from left to right, then the right siblings are generated from right to left. Finally, the head is generated. Figure 4 shows the markovization of the rule NP → NM NN PP PP. The auxiliary symbols that are used here encode information about the parent category, the head child, and previously generated children. Because all auxiliary symbols encode the head category, the head"
J13-1005,A92-1018,0,0.0352465,"Missing"
J13-1005,W06-2929,0,0.0602476,"Missing"
J13-1005,P03-1013,0,0.0390987,"generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previ"
J13-1005,P01-1024,0,0.0588643,"ment by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information"
J13-1005,P08-1109,0,0.0939797,"Missing"
J13-1005,W07-1203,0,0.0147603,"d parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information and achieve a larger improvement. We use the monolingual feature set of Versley and Rehbein in our reranker, but add further monolingual features as well as bilingu"
J13-1005,2008.amta-srw.2,0,0.0296618,"-HD VP-OC Man kann AVP-MO one can ADV-MO ADV-HD aber ebenso but just-as-well VVINF-HD , sagen say S-OC , KOUS-CP PPER-SB ADJD-PD VAFIN-HD dass sie anspruchsvoll sind that they demanding are Figure 6 Erroneous parse produced by the reranker using only monolingual features, which is corrected by bilingual features. The sentence means One can, however, just as well say that they are demanding. 81 Computational Linguistics Volume 39, Number 1 improve ranking of German BitPar parses in the held-out test sets, which is a form of self-training. Two other interesting studies in this area are those of Fossum and Knight (2008) and of Huang, Jiang, and Liu (2009). They improve English prepositional phrase attachment using features from a Chinese sentence. Unlike our approach, however, they do not require a Chinese syntactic parse as the word order in Chinese is sufﬁcient to unambiguously determine the correct attachment point of the prepositional phrase in the English sentence without using a Chinese syntactic parse. We know of no other work that has investigated to what extent monolingual and bilingual features in parse reranking are complementary. In particular, the work on bitext parsing by Burkett and Klein (200"
J13-1005,E09-1033,1,0.938949,"nominal head. The extraction of verbal heads is somewhat more complicated. In order to obtain the correct verbal head of a clause irrespective of the verb position (verb-ﬁrst, verbsecond, verb-ﬁnal), we extract all verbs that are dominated by the clause and a possibly empty sequence of VP-OC or VP-PD (statal passive) nodes and an optional VZ-HD node. Then we take the ﬁrst non-ﬁnite verb, or alternatively the ﬁrst ﬁnite verb if all verbs were ﬁnite. In order to avoid sparse data problems caused by the many different inﬂections of German verbs, we lemmatize the verbs. ¨ 21 In Fraser, Wang, and Schutze (2009) we used Minimum Error Rate Training. Once we made this change to maximum entropy the results on small feature sets became similar (details omitted). 22 An exception to this is that if a PP argument dominates a node of category PROAV-PH, it is considered a PROAV-PH argument. An example is the sentence Er [he] wartet [waits] (PP-OP (PROAV-PH darauf [for this]), (S-RE dass [that] sie [she] kommt [comes])). 74 Fraser et al. Knowledge Sources for Parsing German Table 2 Arguments used in extracted subcategorization frames. NP-SB, PN-SB, CNP-SB, S-SB, VP-SB NP-OA, PN-OA, CNP-OA NP-DA, PN-DA, CNP-DA"
J13-1005,N06-1024,0,0.0274491,"Missing"
J13-1005,W08-1007,0,0.160992,"sing is which type of parsing formalism to adopt, constituency or dependency. It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but"
J13-1005,W08-2122,0,0.027458,". The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information and achieve a larger improvement. We use the mon"
J13-1005,P08-1067,0,0.0386001,"ious state of the art (the Berkeley parser) and that the re-ranking can add an important gain. 2. Previous Work Constituent parsing for English is well studied. The best generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been deve"
J13-1005,D09-1127,0,0.0481369,"Missing"
J13-1005,J98-4004,0,0.233603,"s the chart as a large bit vector. This representation is memory efﬁcient and allows full parsing (without search space pruning) with large treebank grammars. BitPar is also quite fast because the basic parsing operations are parallelized by means of (single-instruction) and-operations on bitvectors. BitPar can either be used to compute the most likely parse (Viterbi parse), or the full set of parses in the form of a parse forest, or the n-best parse trees. 3.1 Grammar The grammar and lexicon used by our generative parser are extracted from the Tiger2 Treebank (Brants et al. 2002). Similar to Johnson (1998) and Klein and Manning (2003) we improve the accuracy of the unlexicalized parser by reﬁning the non-terminal symbols of the grammar to encode relevant contextual information. This reﬁnement weakens the strong independence assumptions of PCFGs and improves parsing accuracy. The extraction of the grammar and lexicon involves the following steps: 1. Discontinuous constituents are eliminated (Section 3.2). 2. Treebank annotations are transformed (Section 3.4) and augmented (Section 3.5). 3. Grammar rules, lexical rules, and their frequencies are extracted from the annotated parse trees. 4. The gr"
J13-1005,P03-1054,0,0.408779,"rge bit vector. This representation is memory efﬁcient and allows full parsing (without search space pruning) with large treebank grammars. BitPar is also quite fast because the basic parsing operations are parallelized by means of (single-instruction) and-operations on bitvectors. BitPar can either be used to compute the most likely parse (Viterbi parse), or the full set of parses in the form of a parse forest, or the n-best parse trees. 3.1 Grammar The grammar and lexicon used by our generative parser are extracted from the Tiger2 Treebank (Brants et al. 2002). Similar to Johnson (1998) and Klein and Manning (2003) we improve the accuracy of the unlexicalized parser by reﬁning the non-terminal symbols of the grammar to encode relevant contextual information. This reﬁnement weakens the strong independence assumptions of PCFGs and improves parsing accuracy. The extraction of the grammar and lexicon involves the following steps: 1. Discontinuous constituents are eliminated (Section 3.2). 2. Treebank annotations are transformed (Section 3.4) and augmented (Section 3.5). 3. Grammar rules, lexical rules, and their frequencies are extracted from the annotated parse trees. 4. The grammar is markovized (Section"
J13-1005,2005.mtsummit-papers.11,0,0.0116501,"to German, and sums all the span differences. It is measured in words. In addition to PPParentPrjWord we implement two bonus features, NonPPWord and NonPPPer. The former simply calculates the number of words that 79 Computational Linguistics Volume 39, Number 1 do not belong to PP phrases in the sentence, and the latter computes the non-PP proportion in a character-based fashion. These can be thought of as tunable parameters which adjust PPParentPrjWord to not disfavor large PPs. The other selected projection features are described in Table 4. Probabilistic Feature Functions. We use Europarl (Koehn 2005), from which we extract a parallel corpus of approximately 1.22 million sentence pairs, to estimate the probabilistic feature functions described in this section. We describe the feature PTag, despite the fact that it was not selected by the feature analysis, because several variations (described next) were selected. PTag measures tagging inconsistency based on estimating the probability for each English word that it has a particular POS tag, given the aligned German word’s POS tag. To avoid noisy feature values due to outliers and parse errors, we bound the value of PTag at 5.26 We use relati"
J13-1005,W06-1614,0,0.0820292,"Missing"
J13-1005,P04-1042,0,0.0790196,"Missing"
J13-1005,N06-1020,0,0.165602,"Missing"
J13-1005,P06-1043,0,0.0877529,"Missing"
J13-1005,E06-1011,0,0.0241518,"key question for MR&LC parsing is which type of parsing formalism to adopt, constituency or dependency. It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with con"
J13-1005,W98-0509,0,0.0308318,"roduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performa"
J13-1005,N07-1051,0,0.0190713,"information. The resulting parser is currently the best constituent parser for German (with or without bilingual features). In particular, we show that the baseline parser without reranking is competitive with the previous state of the art (the Berkeley parser) and that the re-ranking can add an important gain. 2. Previous Work Constituent parsing for English is well studied. The best generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Wo"
J13-1005,W08-1005,0,0.136381,"ge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein a"
J13-1005,W06-1608,0,0.0290991,"for German previously by Versley and Rehbein (2009). We show that the richer subcategorization-based framework for monolingual reranking is effective; it has comparable performance to the sparse feature set—moreover, they complement each other. For bilingual reranking, we present our approach to bitext parsing, where a German parse is found that minimizes syntactic divergence with an automatically generated parse of its English translation. We pursue this approach for a number of reasons. First, one limiting factor for syntactic approaches to statistical machine translation is parse quality (Quirk and Corston-Oliver 2006). Improved parses of bitext should result in improved machine translation. Second, as more and more texts are available in several languages, it will be increasingly the case that a text to be parsed is itself part of a bitext. Third, we hope that the improved parses of bitext can serve as higher quality training data for improving monolingual parsing using a process similar to self-training (McClosky, Charniak, and Johnson 2006a). We show that the three different knowledge sources we use in this paper (lexical knowledge, monolingual features, and bilingual features) are valuable separately. W"
J13-1005,P05-1034,0,0.0754638,"Missing"
J13-1005,W08-1006,0,0.02696,"tent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexica"
J13-1005,N10-1049,0,0.0149329,"search question.3 Constituent parses often provide more information than dependency parses. An example is the coordination ambiguity in old men and women versus old men and children. The correct constituent parse for the ﬁrst expression contains a coordination at the noun level whereas the parse for the second expression coordinates at the level of NPs. The dependency structures of both expressions, on the other hand, are usually identical and thus unable to reﬂect the fact that old modiﬁes women but not children. It is possible, in principle, to encode the difference in dependency trees (cf. Rambow 2010), 2 This is due to how the evalb tool used to calculate PARSEVAL works. If a constituent is not perfectly matched, the grammatical function is considered to be wrong, even if there was a partial match (at the token level). This is not a problem with dependency-based evaluation. For further discussion of the PARSEVAL metric and dependency-based evaluation see, for example, Rehbein and van Genabith (2007) and Tsarfaty, Nivre, and Andersson (2012). 3 Two possible solutions are to use TedEval (Tsarfaty, Nivre, and Andersson 2012), or to conduct an analysis of grammatical functions at the token lev"
J13-1005,W07-2460,0,0.0876378,"Missing"
J13-1005,C04-1056,0,0.0313236,"ky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to"
J13-1005,C04-1024,1,0.911442,"y and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information and achieve a larger improvement. We use the monolingual feature set of Versley and Rehbein in our reranker, but add further monolingual features as well as bilingual features. 3. Generative Parsing Framework Our generative parser is an unlexicalized PCFG parser which is based on the BitPar parser (Schmid 2004). BitPar uses a fast bitvector-based implementation of the wellknown Cocke-Younger-Kasami algorithm and stores the chart as a large bit vector. This representation is memory efﬁcient and allows full parsing (without search space pruning) with large treebank grammars. BitPar is also quite fast because the basic parsing operations are parallelized by means of (single-instruction) and-operations on bitvectors. BitPar can either be used to compute the most likely parse (Viterbi parse), or the full set of parses in the form of a parse forest, or the n-best parse trees. 3.1 Grammar The grammar and l"
J13-1005,P06-1023,1,0.822361,"tuents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but the direct comparison is not fair as it required phrase boundaries to be correct on the constituent side while the tokens were the unit of evaluation on the dependency side.2 How to carry out an absolutely fair comparison of the two representations is still an open research question.3 Consti"
J13-1005,schmid-etal-2004-smor,1,0.827637,"Missing"
J13-1005,C10-2129,0,0.260946,"parsing formalism to adopt, constituency or dependency. It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but the direct comparis"
J13-1005,P10-1111,0,0.0405122,"Missing"
J13-1005,P08-1066,0,0.0270618,"Missing"
J13-1005,E12-1006,0,0.13257,"Missing"
J13-1005,W10-1401,0,0.107052,"Missing"
J13-1005,C10-1123,0,0.0139946,"ion, acting together. The most natural way of doing this in a language like German is to perform this integration of the two knowledge sources directly as part of parsing. We do this by annotating constituent labels with grammatical function where appropriate. In contrast with syntactic parses of strongly conﬁgurational languages like English, syntactic parses of German are not useful for most tasks without having 4 We do note, however, that there are a few translation systems which use a dependency representation directly (e.g., Quirk, Menezes, and Cherry 2005; Shen, Xu, and Weischedel 2008; Tu et al. 2010). 61 Computational Linguistics Volume 39, Number 1 grammatical functions indicated. It is not even possible to access the basic subcategorization of the verb (such as determining the subject) without grammatical functions. We argue that MR&LC languages like German should always be evaluated on labelscum-grammatical-function. Our last main contribution in this paper concerns the fact that we believe that MR&LC languages give rise to more ambiguity than languages that are predominantly conﬁgurational or morphological. As an example consider the German sentence “Die [the] Katze [cat] jagt [hunts]"
J13-1005,W09-3820,0,0.334604,"disambiguation. We believe that this distinguishing characteristic of MR&LC languages makes it necessary to tap additional knowledge sources. In this paper, we look at two such knowledge sources: monolingual reranking (which captures global properties of well-formed parses for additional disambiguation) and bilingual reranking (which exploits parallel text in a different language for disambiguation). For monolingual reranking, we deﬁne a novel set of rich features based on subcategorization frames. We compare our compact feature set with a sparse feature set designed for German previously by Versley and Rehbein (2009). We show that the richer subcategorization-based framework for monolingual reranking is effective; it has comparable performance to the sparse feature set—moreover, they complement each other. For bilingual reranking, we present our approach to bitext parsing, where a German parse is found that minimizes syntactic divergence with an automatically generated parse of its English translation. We pursue this approach for a number of reasons. First, one limiting factor for syntactic approaches to statistical machine translation is parse quality (Quirk and Corston-Oliver 2006). Improved parses of b"
J13-1005,J93-2006,0,0.218488,"re spurious ambiguities. They arise because some of the rules which are not markovized are also covered by markovization rules. 3.7 Dealing with Unknown Words and Unseen POS Tags BitPar includes a sophisticated POS guesser that uses several strategies to deal with unknown words and unseen POS tags of known words. Unknown words are divided into eight classes11 based on regular expressions that are manually deﬁned. These classes distinguish between lower-case words, capitalized words, all upper-case words, hyphenated words, numbers, and so forth. For each word class, BitPar builds a sufﬁx tree (Weischedel et al. 1993; Schmid 1995; Brants 2000) from the sufﬁxes of all words in the lexicon up to a length of 7. At each node of the sufﬁx tree, it sums up the conditional POS probabilities (given the word) over all known words with that sufﬁx. By summing POS probabilities rather than frequencies, all words have the same weight, which is appropriate here because we need to model the POS probabilities of infrequent words. BitPar computes POS probability estimates for each node using the sum of probabilities as a pseudo-frequency for each tag. The estimates are recursively smoothed with the Witten-Bell method usin"
J13-1005,W08-1008,0,\N,Missing
J13-1005,P02-1018,0,\N,Missing
J13-1005,J05-1003,0,\N,Missing
J15-2001,W13-2257,0,0.0166003,"ight words lets the translation accuracy drop because of search errors (Koehn et al. 2005). The use of a hard limit is undesirable for German–English and similar language pairs with significantly different syntactic structures. Several researchers have tried to address this problem. Moore and Quirk (2007) proposed improved future cost estimation to enable higher distortion limits in phrasal MT. Green, Galley, and Manning (2010) additionally proposed discriminative distortion models to achieve better translation accuracy than the baseline phrase-based system for a distortion limit of 15 words. Bisazza and Federico (2013) recently proposed a novel method to dynamically select which longrange reorderings to consider during the hypothesis extension process in a phrasebased decoder and showed an improvement in a German–English task by increasing the distortion limit to 18. Spurious Phrasal Segmentation. A problem with the phrase-based model is that there is no unique correct phrasal segmentation of a sentence. Therefore, all possible ways of segmenting a bilingual sentence consistent with the word alignment are learned and used. This leads to two problems: (i) phrase frequencies are obtained by counting all possi"
J15-2001,J93-2003,0,0.090203,"tics Volume 41, Number 2 better than state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems (Ncode) on standard translation tasks. We compare the reordering component of the OSM to the Moses lexical reordering model by integrating it into Moses. Our results show that OSM outperforms lexicalized reordering on all translation tasks. The translation quality is shown to be improved further by learning generalized representations with a POS-based OSM. 1. Introduction Statistical Machine Translation (SMT) advanced near the beginning of the century from word-based models (Brown et al. 1993) towards more advanced models that take contextual information into account. Phrase-based (Koehn, Och, and Marcu 2003; Och and Ney 2004) and N-gram-based (Casacuberta and Vidal 2004; Marino ˜ et al. 2006) models are two instances of such frameworks. Although the two models have some common properties, they are substantially different. The present work is a step towards combining the benefits and remedying the flaws of these two frameworks. Phrase-based systems have a simple but effective mechanism that learns larger chunks of translation called bilingual phrases.1 Memorizing larger units enabl"
J15-2001,N10-2003,0,0.0347044,"Missing"
J15-2001,N13-1003,0,0.0149619,"ccount how previous words were translated and reordered. Although such an independence assumption is useful to reduce sparsity, it is overly generalizing and does not help to disambiguate good reorderings from the bad ones. Moreover, a vast majority of extracted phrases are singletons and the corresponding probability of orientation given phrase-pair estimates are based on a single observation. Due to sparsity, the model falls back to use one-word phrases instead, the orientation of which is ambiguous and can only be judged based on context that is ignored. This drawback has been addressed by Cherry (2013) by using sparse features for reordering models. Hard Distortion Limit. The lexicalized reordering model fails to filter out bad largescale reorderings effectively (Koehn 2010). A hard distortion limit is therefore required during decoding in order to produce good translations. A distortion limit beyond eight words lets the translation accuracy drop because of search errors (Koehn et al. 2005). The use of a hard limit is undesirable for German–English and similar language pairs with significantly different syntactic structures. Several researchers have tried to address this problem. Moore and"
J15-2001,J07-2003,0,0.0395574,"mework. We also use four supportive features: the Gap, Open Gap, Gap-distance, and Deletion counts, as described earlier (see Section 3.6.1). 6.1 Baseline Our Moses (Koehn et al. 2007) baseline systems are based on the setup described in Durrani et al. (2013b). We trained our systems with the following settings: maximum sentence length 80, grow-diag-final and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield 2011) used at runtime, distortion limit of 6, minimum Bayes-risk decoding (Kumar and Byrne 2004), cube pruning (Huang and Chiang 2007), and the no-reordering-over-punctuation heuristic. We used factored models (Koehn and Hoang 2007), for German–English and English–German. We trained the lexicalized reordering model (Koehn et al. 2005) with msd-bidirectional-fe settings. 6.2 Results Table 5 shows that the OSM results in higher gains than the lexicalized reordering model on top of a plain phrase-based baseline (Pb). The average improvement obtained using the lexicalized reordering model (Pblex ) over the baseline (Pb) is 0.50. In comparison, the average improvement obtained by using the OSM (Pbosm ) over the baseline (Pb) is 0"
J15-2001,N07-2035,0,0.0710623,"Missing"
J15-2001,2005.iwslt-1.25,0,0.0712731,"taining content words (which are less frequent than functional words). For example, the alignment link hinunterschuttete ¨ – ‘down’ is deleted and only the link hinunterschuttete ¨ – ‘poured’ is retained because ‘down’ occurs more frequently than ‘poured’. Crego and Yvon (2009) used split tokens to deal with this phenomenon. For MTU-based decoding we also need to deal with unaligned target words. For each unaligned target word, we determine the (left or right) neighbor that it appears more frequently with and align it with the same source word as this neighbor. Crego, de Gispert, and Marino ˜ (2005) and Marino ˜ et al. (2006) instead used lexical probabilities p( f |e) obtained from IBM Model 1 (Brown et al. 1993) to decide whether to attach left or right. A more sophisticated strategy based on part-of-speech entropy was proposed by Gispert and Marino ˜ (2006). 4.2 Initial Evaluation We evaluated our systems on German-to-English, French-to-English, and Spanish-toEnglish news translation for the purpose of development and evaluation. We used data from the eighth version of the Europarl Corpus and the News Commentary made available for the translation task of the Eighth Workshop on Statist"
J15-2001,2007.mtsummit-papers.16,0,0.0557062,"ce 164 Durrani et al. Operation Sequence Model versa. Notice how the reordering decision is triggered by the translation decision in the example. The probability of a gap insertion operation after the generation of the auxiliaries wurden ¨ – ‘would’ will be high because reordering is necessary in order to move the second part of the German verb complex (stimmen) to its correct position at the end of the clause. Complex reorderings can be achieved by inserting multiple gaps and/or recursively inserting a gap within a gap. Consider the generation of the example in Figure 3 (borrowed from Chiang [2007]). The generation of this bilingual sentence pair proceeds as follows: Generate(Aozhou, Australia) Generate(shi, is) Insert Gap Generate(zhiyi, one of ) At this point, the (partial) Chinese and English sentences look like this: Aozhou shi zhiyi ↓ Australia is one of The translator now jumps back and recursively inserts a gap inside of the gap before continuing translation: Jump Back (1) Insert Gap Generate(shaoshu, the few) Generate(guojia, countries) Aozhou shi shaoshu guojia ↓ zhiyi Australia is one of the few countries The rest of the sentence pair is generated as follows: Jump Back (1) Ins"
J15-2001,2009.eamt-1.10,0,0.0196584,"aligned and discontinuous targets. If a source word is aligned with multiple target words that are not consecutive, first the link to the least frequent target word is identified, and the group (consecutive adjacent words) of links containing this word is retained while the others are deleted. The intuition here is to keep the alignments containing content words (which are less frequent than functional words). For example, the alignment link hinunterschuttete ¨ – ‘down’ is deleted and only the link hinunterschuttete ¨ – ‘poured’ is retained because ‘down’ occurs more frequently than ‘poured’. Crego and Yvon (2009) used split tokens to deal with this phenomenon. For MTU-based decoding we also need to deal with unaligned target words. For each unaligned target word, we determine the (left or right) neighbor that it appears more frequently with and align it with the same source word as this neighbor. Crego, de Gispert, and Marino ˜ (2005) and Marino ˜ et al. (2006) instead used lexical probabilities p( f |e) obtained from IBM Model 1 (Brown et al. 1993) to decide whether to attach left or right. A more sophisticated strategy based on part-of-speech entropy was proposed by Gispert and Marino ˜ (2006). 4.2"
J15-2001,C10-2023,0,0.0480813,"Missing"
J15-2001,N13-1001,1,0.781265,"the subsequent parts of discontinuous target cepts to appear after the first word of the cept. During decoding we use phrase-internal alignments to hypothesize such a linearization. This is done only for the estimation of the OSM, and the target for all other purposes is generated in its original order. This heuristic allows us to deal with target discontinuities without extending the operation sequence model in complicated ways. It results in better BLEU accuracy in comparison with the post-editing of the alignments method described in Section 4.1. For details and empirical results refer to Durrani et al. (2013a) (see Table 2 therein, compare Rows 4 and 5). Note that the OSM, like the discontinuous phrase-based model (Galley and Manning 2010), allows all possible geometries as shown in Figure 7. However, because our decoder only uses continuous phrases, we cannot hypothesize (ii) and (iii) unless they appear inside of a phrase. But our model could be integrated into a discontinuous phrase-based system to overcome this limitation. 6. Further Comparative Experiments Our model, like the reordering models (Tillmann and Zhang 2005; Galley and Manning 2008) used in phrase-based decoders, is lexicalized. H"
J15-2001,P13-2071,1,0.853331,"the subsequent parts of discontinuous target cepts to appear after the first word of the cept. During decoding we use phrase-internal alignments to hypothesize such a linearization. This is done only for the estimation of the OSM, and the target for all other purposes is generated in its original order. This heuristic allows us to deal with target discontinuities without extending the operation sequence model in complicated ways. It results in better BLEU accuracy in comparison with the post-editing of the alignments method described in Section 4.1. For details and empirical results refer to Durrani et al. (2013a) (see Table 2 therein, compare Rows 4 and 5). Note that the OSM, like the discontinuous phrase-based model (Galley and Manning 2010), allows all possible geometries as shown in Figure 7. However, because our decoder only uses continuous phrases, we cannot hypothesize (ii) and (iii) unless they appear inside of a phrase. But our model could be integrated into a discontinuous phrase-based system to overcome this limitation. 6. Further Comparative Experiments Our model, like the reordering models (Tillmann and Zhang 2005; Galley and Manning 2008) used in phrase-based decoders, is lexicalized. H"
J15-2001,W13-2212,1,0.943997,"the subsequent parts of discontinuous target cepts to appear after the first word of the cept. During decoding we use phrase-internal alignments to hypothesize such a linearization. This is done only for the estimation of the OSM, and the target for all other purposes is generated in its original order. This heuristic allows us to deal with target discontinuities without extending the operation sequence model in complicated ways. It results in better BLEU accuracy in comparison with the post-editing of the alignments method described in Section 4.1. For details and empirical results refer to Durrani et al. (2013a) (see Table 2 therein, compare Rows 4 and 5). Note that the OSM, like the discontinuous phrase-based model (Galley and Manning 2010), allows all possible geometries as shown in Figure 7. However, because our decoder only uses continuous phrases, we cannot hypothesize (ii) and (iii) unless they appear inside of a phrase. But our model could be integrated into a discontinuous phrase-based system to overcome this limitation. 6. Further Comparative Experiments Our model, like the reordering models (Tillmann and Zhang 2005; Galley and Manning 2008) used in phrase-based decoders, is lexicalized. H"
J15-2001,C14-1041,1,0.834353,". It also shows the model sizes when filtered on news-test2013. A similar amount of reduction could be achieved by applying filtering to the OSMs following the language model filtering described by Heafield and Lavie (2010). 15 We also tried to amalgamate lexically driven OSM and generalized OSMs into a single model rather than using these as separate features. However, this attempt was unsuccessful (See Durrani et al. [2014] for details). 16 We also found using morphological tags and automatic word clusters to be useful in our recent IWSLT evaluation campaign (Birch, Durrani, and Koehn 2013; Durrani et al. 2014). 17 The code for the OSM in Moses can be greatly optimized but requires major modifications to source and target phrase classes in Moses. 182 Durrani et al. Operation Sequence Model Table 8 Wall-clock decoding times (in minutes) on WMT-13. Into English From English Pblex Pblex+osm Pblex Pblex+osm DE FR ES 61 108 111 88 Δ 27 163 Δ 55 142 Δ 31 143 113 74 158 Δ 15 154 Δ 41 109 Δ 35 Avg 93 131 Δ 38 110 140 Δ 30 Table 9 Data sizes (in number of sentences) and memory usage (in giga-bytes). Columns: Phrase translation and lexicalized reordering tables give overall model sizes/sizes when filtered on"
J15-2001,P11-1105,1,0.82518,"Missing"
J15-2001,D08-1089,0,0.42418,"d tasks of translating German–English, French–English, and Spanish–English pairs. Our integration gives statistically significant improvements over submission quality baseline systems. Section 7 concludes. 2. Previous Work 2.1 Phrase-Based SMT The phrase-based model (Koehn et al. 2003; Och and Ney 2004) segments a bilingual sentence pair into phrases that are continuous sequences of words. These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang 2005) or block of phrases (Galley and Manning 2008). Phrase-based models memorize local dependencies such as short reorderings, translations of idioms, and the insertion and deletion of words sensitive to local context. Phrase-based systems, however, have the following drawbacks. Handling of Non-local Dependencies. Phrase-based SMT models dependencies between words and their translations inside of a phrase well. However, dependencies across phrase boundaries are ignored because of the strong phrasal independence assumption. Consider the bilingual sentence pair shown in Figure 1(a). Reordering of the German word stimmen is internal to the phras"
J15-2001,N10-1129,0,0.038666,"Missing"
J15-2001,W11-2123,0,0.0840724,"extracting the MTUs within the phrase pair and using phrase internal alignments. The OSM is used as a feature in the log-linear framework. We also use four supportive features: the Gap, Open Gap, Gap-distance, and Deletion counts, as described earlier (see Section 3.6.1). 6.1 Baseline Our Moses (Koehn et al. 2007) baseline systems are based on the setup described in Durrani et al. (2013b). We trained our systems with the following settings: maximum sentence length 80, grow-diag-final and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield 2011) used at runtime, distortion limit of 6, minimum Bayes-risk decoding (Kumar and Byrne 2004), cube pruning (Huang and Chiang 2007), and the no-reordering-over-punctuation heuristic. We used factored models (Koehn and Hoang 2007), for German–English and English–German. We trained the lexicalized reordering model (Koehn et al. 2005) with msd-bidirectional-fe settings. 6.2 Results Table 5 shows that the OSM results in higher gains than the lexicalized reordering model on top of a plain phrase-based baseline (Pb). The average improvement obtained using the lexicalized reordering model (Pblex ) over"
J15-2001,P07-1019,0,0.00922897,"linear framework. We also use four supportive features: the Gap, Open Gap, Gap-distance, and Deletion counts, as described earlier (see Section 3.6.1). 6.1 Baseline Our Moses (Koehn et al. 2007) baseline systems are based on the setup described in Durrani et al. (2013b). We trained our systems with the following settings: maximum sentence length 80, grow-diag-final and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield 2011) used at runtime, distortion limit of 6, minimum Bayes-risk decoding (Kumar and Byrne 2004), cube pruning (Huang and Chiang 2007), and the no-reordering-over-punctuation heuristic. We used factored models (Koehn and Hoang 2007), for German–English and English–German. We trained the lexicalized reordering model (Koehn et al. 2005) with msd-bidirectional-fe settings. 6.2 Results Table 5 shows that the OSM results in higher gains than the lexicalized reordering model on top of a plain phrase-based baseline (Pb). The average improvement obtained using the lexicalized reordering model (Pblex ) over the baseline (Pb) is 0.50. In comparison, the average improvement obtained by using the OSM (Pbosm ) over the baseline (Pb) is 0"
J15-2001,koen-2004-pharaoh,0,0.186183,"used in our model is the Source Gap Width. This feature only applies in the case of a discontinuous translation unit and computes the distance between the words of a gappy cept. Let f = f1 . . . , fi , . . . , fn be a gappy source cept where xi is the index of the ith source word in the cept f . The value of the gap-width penalty is calculated as: wj = n  xi − xi−1 − 1 i=2 4. MTU-Based Search We explored two decoding strategies in this work. Our first decoder complements the model and only uses minimal translation units in left-to-right stack-based decoding, similar to that used in Pharaoh (Koehn 2004a). The overall process can be roughly divided into the following steps: (i) extraction of translation units, (ii) future cost estimation, (iii) hypothesis extension, and (iv) recombination and pruning. The last two steps are repeated iteratively until all the words in the source sentence have been translated. Our hypotheses maintain the index of the last source word covered (j), the position of the right-most source word covered so far (Z), the number of open gaps, the number of gaps so far inserted, the previously generated operations, the generated target string, and the accumulated values"
J15-2001,W04-3250,1,0.372367,"Missing"
J15-2001,J10-4005,0,0.083559,"ambiguate good reorderings from the bad ones. Moreover, a vast majority of extracted phrases are singletons and the corresponding probability of orientation given phrase-pair estimates are based on a single observation. Due to sparsity, the model falls back to use one-word phrases instead, the orientation of which is ambiguous and can only be judged based on context that is ignored. This drawback has been addressed by Cherry (2013) by using sparse features for reordering models. Hard Distortion Limit. The lexicalized reordering model fails to filter out bad largescale reorderings effectively (Koehn 2010). A hard distortion limit is therefore required during decoding in order to produce good translations. A distortion limit beyond eight words lets the translation accuracy drop because of search errors (Koehn et al. 2005). The use of a hard limit is undesirable for German–English and similar language pairs with significantly different syntactic structures. Several researchers have tried to address this problem. Moore and Quirk (2007) proposed improved future cost estimation to enable higher distortion limits in phrasal MT. Green, Galley, and Manning (2010) additionally proposed discriminative d"
J15-2001,2005.iwslt-1.8,1,0.753813,"Missing"
J15-2001,D07-1091,1,0.765644,"Missing"
J15-2001,N03-1017,1,0.0601065,"information available in phrases can be used to improve the search performance and translation quality. Finally, we probe whether integrating our model into the phrase-based SMT framework addresses the mentioned drawbacks and improves translation quality. Section 6 provides an empirical evaluation of our integration on six standard tasks of translating German–English, French–English, and Spanish–English pairs. Our integration gives statistically significant improvements over submission quality baseline systems. Section 7 concludes. 2. Previous Work 2.1 Phrase-Based SMT The phrase-based model (Koehn et al. 2003; Och and Ney 2004) segments a bilingual sentence pair into phrases that are continuous sequences of words. These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang 2005) or block of phrases (Galley and Manning 2008). Phrase-based models memorize local dependencies such as short reorderings, translations of idioms, and the insertion and deletion of words sensitive to local context. Phrase-based systems, however, have the following drawbacks. Handling of Non-local Dependenc"
J15-2001,N04-1022,0,0.17139,"Missing"
J15-2001,J06-4004,0,0.0271931,"Missing"
J15-2001,2007.mtsummit-papers.43,0,0.0235298,"rry (2013) by using sparse features for reordering models. Hard Distortion Limit. The lexicalized reordering model fails to filter out bad largescale reorderings effectively (Koehn 2010). A hard distortion limit is therefore required during decoding in order to produce good translations. A distortion limit beyond eight words lets the translation accuracy drop because of search errors (Koehn et al. 2005). The use of a hard limit is undesirable for German–English and similar language pairs with significantly different syntactic structures. Several researchers have tried to address this problem. Moore and Quirk (2007) proposed improved future cost estimation to enable higher distortion limits in phrasal MT. Green, Galley, and Manning (2010) additionally proposed discriminative distortion models to achieve better translation accuracy than the baseline phrase-based system for a distortion limit of 15 words. Bisazza and Federico (2013) recently proposed a novel method to dynamically select which longrange reorderings to consider during the hypothesis extension process in a phrasebased decoder and showed an improvement in a German–English task by increasing the distortion limit to 18. Spurious Phrasal Segmenta"
J15-2001,W11-2124,0,0.297085,"odel to the OSM and to see whether we can improve the performance further by using both models together. Our integration of the OSM into Moses gave a statistically significant improvement over a competitive baseline system in most cases. In order to assess the contribution of improved reordering versus the contribution of better modeling with MTUs in the OSM-augmented Moses system, we removed the reordering operations from the stream of operations. This is equivalent to integrating the conventional N-gram tuple sequence model (Marino ˜ et al. 2006) into a phrasebased decoder, as also tried by Niehues et al. (2011). Small gains were observed in most cases, showing that much of the improvement obtained by the OSM is due to better reordering. Generalized Operation Sequence Model. The primary strength of the OSM over the lexicalized reordering model is its ability to take advantage of the wider contextual information. In an error analysis we found that the lexically driven OSM often falls back to very small context sizes because of data sparsity. We show that this problem can be addressed by learning operation sequences over generalized representations such as POS tags. The article is organized into seven"
J15-2001,P03-1021,0,0.10251,"nments. The corpus conversion algorithm (Algorithm 1) maps each bilingual sentence pair given its alignment into a unique sequence of operations deterministically, thus maintaining a 1-to-1 correspondence. This property of the model is useful because it addresses the spurious phrasal segmentation problem in phrase-based models. A phrase-based model assigns different scores to a derivation based on which phrasal segmentation is chosen. Unlike this, the OSM assigns only one score because the model does not suffer from spurious ambiguity. 3.6.1 Discriminative Model. We use a log-linear approach (Och 2003) to make use of standard features along with several novel features that we introduce to improve endto-end accuracy. We search for a target string E that maximizes a linear combination of feature functions: Eˆ = arg max E ⎧ J ⎨ ⎩ j=1 λj hj (F, E) ⎫ ⎬ ⎭ where λj is the weight associated with the feature hj (F, E). Apart from the OSM and standard features such as target-side language model, length bonus, distortion limit, and IBM lexical features (Koehn, Och, and Marcu 2003), we used the following new features: Deletion Penalty. Deleting a source word (Generate Source Only (X)) is a common oper"
J15-2001,J03-1002,0,0.0268454,"4.2 Initial Evaluation We evaluated our systems on German-to-English, French-to-English, and Spanish-toEnglish news translation for the purpose of development and evaluation. We used data from the eighth version of the Europarl Corpus and the News Commentary made available for the translation task of the Eighth Workshop on Statistical Machine Translation.7 The bilingual corpora contained roughly 2M bilingual sentence pairs, which we obtained by concatenating news commentary (≈ 184K sentences) and Europarl for the estimation of the translation model. Word alignments were generated with GIZA++ (Och and Ney 2003), using the grow-diag-final-and heuristic8 (Koehn et al. 2005). All data are lowercased, and we use the Moses tokenizer. We took news-test-2008 as the dev set for optimization and news-test 2009-2012 for testing. The feature weights are tuned with Z-MERT (Zaidan 2009). 4.2.1 Baseline Systems. We compared our system with (i) Moses9 (Koehn et al. 2007), (ii) Phrasal10 (Cer et al. 2010), and (iii) Ncode11 (Crego, Yvon, and Marino ˜ 2011). We used 7 http://www.statmt.org/wmt13/translation-task.html 8 We also tested other symmetrization heuristics such as “Union” and “Intersection” but found the GD"
J15-2001,J04-4002,0,0.218255,"rd translation tasks. We compare the reordering component of the OSM to the Moses lexical reordering model by integrating it into Moses. Our results show that OSM outperforms lexicalized reordering on all translation tasks. The translation quality is shown to be improved further by learning generalized representations with a POS-based OSM. 1. Introduction Statistical Machine Translation (SMT) advanced near the beginning of the century from word-based models (Brown et al. 1993) towards more advanced models that take contextual information into account. Phrase-based (Koehn, Och, and Marcu 2003; Och and Ney 2004) and N-gram-based (Casacuberta and Vidal 2004; Marino ˜ et al. 2006) models are two instances of such frameworks. Although the two models have some common properties, they are substantially different. The present work is a step towards combining the benefits and remedying the flaws of these two frameworks. Phrase-based systems have a simple but effective mechanism that learns larger chunks of translation called bilingual phrases.1 Memorizing larger units enables the phrase-based model to learn local dependencies such as short-distance reorderings, idiomatic collocations, and insertions and del"
J15-2001,P05-1069,0,0.175007,"l evaluation of our integration on six standard tasks of translating German–English, French–English, and Spanish–English pairs. Our integration gives statistically significant improvements over submission quality baseline systems. Section 7 concludes. 2. Previous Work 2.1 Phrase-Based SMT The phrase-based model (Koehn et al. 2003; Och and Ney 2004) segments a bilingual sentence pair into phrases that are continuous sequences of words. These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang 2005) or block of phrases (Galley and Manning 2008). Phrase-based models memorize local dependencies such as short reorderings, translations of idioms, and the insertion and deletion of words sensitive to local context. Phrase-based systems, however, have the following drawbacks. Handling of Non-local Dependencies. Phrase-based SMT models dependencies between words and their translations inside of a phrase well. However, dependencies across phrase boundaries are ignored because of the strong phrasal independence assumption. Consider the bilingual sentence pair shown in Figure 1(a). Reordering of th"
J15-2001,P11-1086,0,0.0241791,"ns over a very competitive Moses baseline system. We showed that considering both translation and reordering context is important and ignoring reordering context results in a significant reduction in the performance. We also showed that an OSM based on surface forms suffers from data sparsity and that an OSM based on a generalized representation with part-of-speech tags improves the translation quality by considering a larger context. In the future we would like to study whether the insight of using minimal units for modeling and search based on composed rules would hold for hierarchical SMT. Vaswani et al. (2011) recently showed that a Markov model over the derivation history of minimal rules can obtain the same translation quality as using grammars formed with composed rules, which we believe is quite promising. Acknowledgments We would like to thank the anonymous reviewers and Andreas Maletti and Franc¸ois Yvon for their helpful feedback and suggestions. The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreements 287658 (EU-Bridge) and 287688 (MateCat). Alexander Fraser was funded by Deutsche Forschungsgemeinsc"
J15-2001,N13-1002,0,0.0122981,"(TSM) of Marino ˜ et al. (2006), except that we use phrase-internal reordering rather than POS-based rewrite rules to do the source linearization. Table 6 shows an average improvement of just 0.13 on top of the baseline phrase-based system with lexicalized reordering, which is much lower than the 0.46 points obtained with the full operation sequence model. Bilingual translation models (without reordering) have been integrated into phrase-based systems before, either inside the decoder (Niehues et al. 2011) or to rerank the N-best candidate translations in the output of a phrase-based system (Zhang et al. 2013). Both groups reported improvements of similar magnitude when using a targetorder left-to-right TSM model for German–English and French–English translation with shared task data, but higher gains on other data sets and language pairs. Zhang et al. (2013) showed further gains by combining models with target and source left-to-right and right-to-left orders. The assumption of generating the target in monotonic order is a weakness of our work that can be addressed following Zhang et al. (2013). By generating MTUs in source order and allowing gaps and jumps on the target side, the model will be ab"
J15-2001,N10-1140,0,\N,Missing
J15-2001,2006.iwslt-evaluation.17,0,\N,Missing
J15-2001,P07-2045,1,\N,Missing
J15-2001,J04-2004,0,\N,Missing
J15-2001,2014.iwslt-evaluation.6,1,\N,Missing
J15-2001,2013.iwslt-evaluation.3,1,\N,Missing
J17-2003,J84-3009,0,0.122732,"Missing"
J17-2003,2012.iwslt-papers.6,0,0.0419685,"Missing"
J17-2003,W10-2407,0,0.0148307,"threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration pairs for training. However, here the list is generally small. The systems thus do not solely rely on it to mine transliteration pairs. They use both the list of transliteration pairs and unlabeled data for training. We are only aware of two unsupervised systems (requiring no labeled data). One of them was proposed by Fei Huang (2005). He extracts named entity pairs from a bilingual corpus, converts all words into Latin script by romanization, and classifies them into transliterations and non-transliterations based on the edit distance. This system still req"
J17-2003,2014.eamt-1.17,0,0.0188764,"ations. Sajjad et al. (2013b) generated improved word alignment of the parallel training data by incorporating the transliteration mining module into GIZA++. Sajjad et al. (2013a), and Durrani et al. (2014) used transliteration mining to transliterate out-of-vocabulary words in a statistical machine translation system. They extracted transliteration pairs from the parallel corpus in an unsupervised fashion and trained a transliteration system on them. Kunchukuttan and Bhattacharyya (2015) showed the usefulness of unsupervised transliteration mining for the transliteration of Indian languages. Durrani and Koehn (2014) exploited the closeness between Urdu and Hindi using transliteration mining. They created synthetic Hindi-English parallel data by transliterating Urdu to Hindi. When they used the data for machine translation, it substantially improved translation quality. 10. Conclusions We presented a statistical model for mining transliteration pairs from a list of candidate pairs in a fully unsupervised fashion. Our model consists of sub-models for transliterations and non-transliterations that are interpolated. The transliteration sub-model is an n-gram model over 1–1, 0–1, and 1–0 character pairs and t"
J17-2003,P10-1048,1,0.805721,"language; (3) punctuation errors: one word has an additional punctuation symbol that makes the word pair a non-transliteration; (4) gold standard error: errors in the gold standard; (5) worst errors: word pairs that are far from being considered as transliteration pairs. Table 13 shows the number of errors of each type. The affix-based and pronunciation errors are the top errors made by the system. Both of them plus punctuation errors come under the broad definition of close transliterations. These word pairs are helpful because they provide useful character-level transliteration information. Durrani et al. (2010) incorporated our unsupervised transliteration mining system into machine translation. They showed that for language pairs with fewer transliterations, the close transliterations help to build a stronger transliteration system. Table 13 Types of errors made by the unsupervised transliteration mining system on the English/Arabic language pair. The numbers are based on randomly selected 100 word pairs that were wrongly classified by the mining system. Error Type Affix-based Error Gold Standard Error 372 Count Error Type Count Error Type Count 38 9 Pronunciation Error Worst Error 22 21 Punctuatio"
J17-2003,E14-4029,1,0.848098,"ost of the target language words in the cross-product list. The unsupervised system starts learning wrong transliterations because of their high frequency. Durrani et al. (2010) preprocess the candidate list before mining the transliteration pairs and remove words pairs with the most common source and target words. 9. Applications Our unsupervised transliteration mining system has been used in several NLP applications. Sajjad et al. (2013b) generated improved word alignment of the parallel training data by incorporating the transliteration mining module into GIZA++. Sajjad et al. (2013a), and Durrani et al. (2014) used transliteration mining to transliterate out-of-vocabulary words in a statistical machine translation system. They extracted transliteration pairs from the parallel corpus in an unsupervised fashion and trained a transliteration system on them. Kunchukuttan and Bhattacharyya (2015) showed the usefulness of unsupervised transliteration mining for the transliteration of Indian languages. Durrani and Koehn (2014) exploited the closeness between Urdu and Hindi using transliteration mining. They created synthetic Hindi-English parallel data by transliterating Urdu to Hindi. When they used the"
J17-2003,eisele-chen-2010-multiun,0,0.0445614,"Missing"
J17-2003,D11-1128,0,0.0606321,"Missing"
J17-2003,J93-1004,0,0.666995,"multigram sequences: p1 (e, f) = X p1 (a) (1) a∈Align(e,f ) where Align(e, f) returns all possible multigram sequences for the transliteration pair (e, f). In a unigram model, the probability of a multigram sequence a is the product of the probabilities of the multigrams it contains: p1 (a) = p1 (a1 a2 ...a|a |) = |a| Y p1 (aj ) (2) j=1 where |a |is the length of the sequence a. The non-transliteration sub-model generates source and target words that are unrelated. We model such pairs with two separate character unigram models (a source and a target model) whose probabilities are multiplied (Gale and Church 1993). Their parameters are learned from monolingual corpora and not updated during EM training. The non-transliteration sub-model is defined as follows: p2 (e, f) = pE (e)pF (f) (3) Q|e| Q|f| pE (e) = i=1 pE (ei ) and pF (f) = i=1 pF ( fi ) The transliteration mining model is obtained by interpolating the transliteration model p1 (e, f) and the non-transliteration model p2 (e, f): p(e, f) = (1 − λ )p1 (e, f) + λp2 (e, f) (4) where λ is the prior probability of non-transliteration. Interpolation with the non-transliteration model allows the transliteration model to concentrate on modeling translite"
J17-2003,W10-2405,0,0.150552,"it is attractive to extract transliteration pairs automatically from a noisy list of transliteration candidates, which can be obtained from aligned bilingual corpora, for instance. This extraction process is called transliteration mining. There are rule-based, supervised, semi-supervised, and unsupervised ways to mine transliteration pairs. Rule-based methods apply weighted handwritten rules that map characters between two languages, and compute a weighted edit distance metric that assigns a score to every candidate word pair. Pairs with an edit distance below a given threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration"
J17-2003,N03-1017,0,0.0598518,"Missing"
J17-2003,W15-3912,0,0.014598,"with the most common source and target words. 9. Applications Our unsupervised transliteration mining system has been used in several NLP applications. Sajjad et al. (2013b) generated improved word alignment of the parallel training data by incorporating the transliteration mining module into GIZA++. Sajjad et al. (2013a), and Durrani et al. (2014) used transliteration mining to transliterate out-of-vocabulary words in a statistical machine translation system. They extracted transliteration pairs from the parallel corpus in an unsupervised fashion and trained a transliteration system on them. Kunchukuttan and Bhattacharyya (2015) showed the usefulness of unsupervised transliteration mining for the transliteration of Indian languages. Durrani and Koehn (2014) exploited the closeness between Urdu and Hindi using transliteration mining. They created synthetic Hindi-English parallel data by transliterating Urdu to Hindi. When they used the data for machine translation, it substantially improved translation quality. 10. Conclusions We presented a statistical model for mining transliteration pairs from a list of candidate pairs in a fully unsupervised fashion. Our model consists of sub-models for transliterations and non-tr"
J17-2003,P04-1021,0,0.327325,"Missing"
J17-2003,W05-0809,0,0.0518742,"Missing"
J17-2003,W10-2412,0,0.014251,"ich can be obtained from aligned bilingual corpora, for instance. This extraction process is called transliteration mining. There are rule-based, supervised, semi-supervised, and unsupervised ways to mine transliteration pairs. Rule-based methods apply weighted handwritten rules that map characters between two languages, and compute a weighted edit distance metric that assigns a score to every candidate word pair. Pairs with an edit distance below a given threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration pairs for training. However, here the list is generally small. The systems thus do not solely rely on i"
J17-2003,W10-2408,0,0.0497492,"Missing"
J17-2003,J03-1002,0,0.0745413,"Missing"
J17-2003,I11-1015,1,0.907278,"utomatically from a noisy list of transliteration candidates, which can be obtained from aligned bilingual corpora, for instance. This extraction process is called transliteration mining. There are rule-based, supervised, semi-supervised, and unsupervised ways to mine transliteration pairs. Rule-based methods apply weighted handwritten rules that map characters between two languages, and compute a weighted edit distance metric that assigns a score to every candidate word pair. Pairs with an edit distance below a given threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration pairs for training. However, here the list is"
J17-2003,P11-1044,1,0.884668,"utomatically from a noisy list of transliteration candidates, which can be obtained from aligned bilingual corpora, for instance. This extraction process is called transliteration mining. There are rule-based, supervised, semi-supervised, and unsupervised ways to mine transliteration pairs. Rule-based methods apply weighted handwritten rules that map characters between two languages, and compute a weighted edit distance metric that assigns a score to every candidate word pair. Pairs with an edit distance below a given threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration pairs for training. However, here the list is"
J17-2003,P12-1049,1,0.795048,"Missing"
J17-2003,2013.iwslt-evaluation.8,1,0.860414,"ration Mining We observed that most of the word pairs in class 5 (worst errors) contain stop words. Because stop words are the most frequent words in a corpus, they occur with most of the target language words in the cross-product list. The unsupervised system starts learning wrong transliterations because of their high frequency. Durrani et al. (2010) preprocess the candidate list before mining the transliteration pairs and remove words pairs with the most common source and target words. 9. Applications Our unsupervised transliteration mining system has been used in several NLP applications. Sajjad et al. (2013b) generated improved word alignment of the parallel training data by incorporating the transliteration mining module into GIZA++. Sajjad et al. (2013a), and Durrani et al. (2014) used transliteration mining to transliterate out-of-vocabulary words in a statistical machine translation system. They extracted transliteration pairs from the parallel corpus in an unsupervised fashion and trained a transliteration system on them. Kunchukuttan and Bhattacharyya (2015) showed the usefulness of unsupervised transliteration mining for the transliteration of Indian languages. Durrani and Koehn (2014) ex"
J17-2003,W13-2228,1,0.851534,"ration Mining We observed that most of the word pairs in class 5 (worst errors) contain stop words. Because stop words are the most frequent words in a corpus, they occur with most of the target language words in the cross-product list. The unsupervised system starts learning wrong transliterations because of their high frequency. Durrani et al. (2010) preprocess the candidate list before mining the transliteration pairs and remove words pairs with the most common source and target words. 9. Applications Our unsupervised transliteration mining system has been used in several NLP applications. Sajjad et al. (2013b) generated improved word alignment of the parallel training data by incorporating the transliteration mining module into GIZA++. Sajjad et al. (2013a), and Durrani et al. (2014) used transliteration mining to transliterate out-of-vocabulary words in a statistical machine translation system. They extracted transliteration pairs from the parallel corpus in an unsupervised fashion and trained a transliteration system on them. Kunchukuttan and Bhattacharyya (2015) showed the usefulness of unsupervised transliteration mining for the transliteration of Indian languages. Durrani and Koehn (2014) ex"
J17-2003,P07-1109,0,0.0293419,"t distance below a given threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration pairs for training. However, here the list is generally small. The systems thus do not solely rely on it to mine transliteration pairs. They use both the list of transliteration pairs and unlabeled data for training. We are only aware of two unsupervised systems (requiring no labeled data). One of them was proposed by Fei Huang (2005). He extracts named entity pairs from a bilingual corpus, converts all words into Latin script by romanization, and classifies them into transliterations and non-transliterations based on the edit distance. This s"
J17-2003,W06-1630,0,0.0426347,"ent and accurate and can be used in three different training settings—unsupervised, semi-supervised, and supervised learning. Our method directly learns character correspondences between two scripts from a noisy unlabeled list of word pairs which contains both transliterations and non-transliterations. When such a list is extracted from an aligned bilingual corpus, for instance, it contains, 1 There are other approaches to transliteration mining that exploit phonetic similarity between languages (Aransa, Schwenk, and Barrault 2012) and make use of temporal information available with the data (Tao et al. 2006). We do not discuss them here because they are out of the scope of this work. 350 Sajjad et al. Statistical Models for Transliteration Mining apart from transliterations, also both translations and misalignments, which we will call non-transliterations. Our statistical model interpolates a transliteration sub-model and a nontransliteration sub-model. The intuition behind using two sub-models is that the transliteration pairs and non-transliteration pairs, which make up the unlabeled training data, have rather different characteristics and need to be modeled separately. Transliteration word pai"
J17-2003,W12-4410,0,\N,Missing
J17-2003,J93-2003,0,\N,Missing
J17-2003,C96-2141,0,\N,Missing
J17-2003,W98-1005,0,\N,Missing
J17-2003,W07-0703,0,\N,Missing
J17-2003,J07-3002,1,\N,Missing
J17-2003,W02-0505,0,\N,Missing
J17-2003,C08-1068,0,\N,Missing
J17-2003,N07-1046,0,\N,Missing
J17-2003,W09-3528,0,\N,Missing
J17-2003,N07-1047,0,\N,Missing
J17-2003,P06-1103,0,\N,Missing
J17-2003,P07-1119,0,\N,Missing
J17-2003,P06-1010,0,\N,Missing
J17-2003,P08-1045,0,\N,Missing
J17-2003,P06-2025,0,\N,Missing
J17-2003,W09-3525,0,\N,Missing
J17-2003,W09-3522,0,\N,Missing
J17-2003,W07-0711,0,\N,Missing
J17-2003,W04-3250,0,\N,Missing
J17-2003,2010.iwslt-papers.7,0,\N,Missing
J17-2003,I08-8003,0,\N,Missing
J17-2003,J98-4003,0,\N,Missing
J17-2003,W10-2404,0,\N,Missing
J17-2003,P00-1056,0,\N,Missing
J17-2003,W05-0606,0,\N,Missing
J17-2003,W09-3507,0,\N,Missing
J17-2003,W09-3504,0,\N,Missing
J17-2003,P03-1021,0,\N,Missing
N12-1043,J96-1002,0,0.047301,"useful across languages and what generic methods are appropriate for this goal. Previous work also has concentrated on traditional linguistic morphology whereas we compare linguistically motivated morphological segmentation with frequency-based segmentation and include shape features in our study. Our initial plan for this paper was to use complex language modeling frameworks that allow experimenters to include arbitrary features (including morphological and shape features) in the model. In particular, we looked at publicly available implementations of maximum entropy models (Rosenfeld, 1996; Berger et al., 1996) and random forests (Xu and Jelinek, 2004). However, we found that these methods do not currently scale to running a large set of experiments on a multi-gigabyte parallel corpus of 21 languages. Similar considerations apply to other sophisticated language modeling techniques like Pitman-Yor processes (Teh, 2006), recurrent neural networks (Mikolov et al., 2010) and FLMs in their general, more powerful form. In addition, perplexity reductions of these complex models compared to simpler state-of-the-art models are generally not large. We therefore decided to conduct our study in the framework of"
N12-1043,N03-2002,0,0.028016,"e morphological and shape features we use. Section 4 introduces language model and experimental setup. Section 5 discusses our results. Section 6 summarizes the contributions of this paper. 2 Related Work Whittaker and Woodland (2000) apply language modeling to morpheme sequences and investigate data-driven segmentation methods. Creutz et al. (2007) propose a similar method that improves speech recognition for highly inflecting languages. They use Morfessor (Creutz and Lagus, 2007) to split words into morphemes. Both approaches are essentially a simple form of a factored language model (FLM) (Bilmes and Kirchhoff, 2003). In a general FLM a number of different back-off paths are combined by a back-off function to improve the prediction after rare or unseen histories. Vergyri et al. (2004) apply FLMs and morphological features to Arabic speech recognition. These papers and other prior work on using mor387 phology in language modeling have been languagespecific and have paid less attention to the question as to how morphology can be useful across languages and what generic methods are appropriate for this goal. Previous work also has concentrated on traditional linguistic morphology whereas we compare linguisti"
N12-1043,J92-4003,0,0.343318,"Missing"
N12-1043,2005.mtsummit-papers.11,0,0.0301493,"competitive with Brown classes. Results and Discussion We performed all our experiments with an n-gram order of 4; this was the order for which the KN model performs best for all languages on the validation set. 5.1 Morphological model 4.4 Corpus Using grid search, we first determined on the validation set the optimal combination of three parameters: (i) θ ∈ {100, 200, 500, 1000, 2000, 5000}, (ii) φ ∈ {50, 100, 200, 500} and (iii) segmentation method. Recall that we only cluster words whose frequency is below θ and only consider the φ most Our experiments are performed on the Europarl corpus (Koehn, 2005), a parallel corpus of proceedings of the European Parliament in 21 languages. The languages are members of the following families: Baltic languages (Latvian, Lithuanian), Germanic languages (Danish, Dutch, English, Ger2 The tokenization of the Europarl corpus has a preference for splitting tokens in unclear cases. OOV rates would be higher for more conservative tokenization strategies. 4 A two-tailed paired t-test on the improvements by language shows that the morphological model significantly outperforms the distributional model with p=0.0027. A test on the Germanic, Romance and Greek langua"
N12-1043,P11-2092,1,0.825133,"Missing"
N12-1043,J11-4008,0,0.29333,"Missing"
N12-1043,P06-1124,0,0.0477794,"s paper was to use complex language modeling frameworks that allow experimenters to include arbitrary features (including morphological and shape features) in the model. In particular, we looked at publicly available implementations of maximum entropy models (Rosenfeld, 1996; Berger et al., 1996) and random forests (Xu and Jelinek, 2004). However, we found that these methods do not currently scale to running a large set of experiments on a multi-gigabyte parallel corpus of 21 languages. Similar considerations apply to other sophisticated language modeling techniques like Pitman-Yor processes (Teh, 2006), recurrent neural networks (Mikolov et al., 2010) and FLMs in their general, more powerful form. In addition, perplexity reductions of these complex models compared to simpler state-of-the-art models are generally not large. We therefore decided to conduct our study in the framework of smoothed n-gram models, which currently are an order of magnitude faster and more scalable. More specifically, we adopt a class-based approach, where words are clustered based on morphological and shape features. This approach has the nice property that the number of features used to estimate the classes does n"
N12-1043,P09-2087,0,0.0604016,"Missing"
N12-1043,W04-3242,0,\N,Missing
N13-1001,J93-2003,0,0.0650306,"arch performance and superior selection of translation units. In this paper we combine N-grambased modeling with phrase-based decoding, and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks. 1 Introduction Statistical Machine Translation advanced from word-based models (Brown et al., 1993) towards more sophisticated models that take contextual information into account. Phrase-based (Och and Ney, 2004; Koehn et al., 2003) and N-gram-based (Mari˜no et al., 2006) models are two instances of such frameworks. While the two models have some common properties, they are substantially different. ∗ Much of the work presented here was carried out while the first author was at the University of Stuttgart. Phrase-based systems employ a simple and effective machinery by learning larger chunks of translation called phrases1 . Memorizing larger units enables the phrase-based model to learn loc"
N13-1001,N10-2003,0,0.0274872,"and N-gram-based systems on German-to-English, French-to-English, and Spanish-to-English tasks13 . We used the official evaluation data (news-test sets) from the Statistical Machine Translation Workshops 2009-2011 for all three language pairs (German, Spanish and French). The feature weights for all the systems are tuned using the dev set news-dev2009a. We separately tune the baseline system (cept.500) and the phrase-based system (phrase.200) and do not hold the lambda vector constant like before. Baseline Systems: We also compared our system with i) Moses (Koehn et al., 2007), ii) Phrasal14 (Cer et al., 2010), and iii) Ncode (Crego et al., 2011). We used the default stack sizes of 100 for Moses15 , 200 for Phrasal, 25 for Ncode (with 2m stacks). A 5-gram English language model is used. Both phrase-based systems use 20-best phrases for translation, Ncode uses 25-best tuple translations. The training and test data for Ncode was tagged using TreeTagger (Schmid, 1994). All the baseline systems used lexicalized reordering model. A hard reordering limit16 of 6 words is used as a default in 13 We did not include the results of Spanish in the previous section due to space limitations but these are similar"
N13-1001,N07-2035,0,0.427586,"Missing"
N13-1001,2005.mtsummit-papers.37,0,0.122551,"Missing"
N13-1001,P11-1105,1,0.0967324,"ormation outside of phrases ii) it has issues handling long-distance reordering iii) it has the spurious phrasal segmentation problem which allows multiple derivations of a bilingual sentence pair having different model scores for each segmentation. Modeling with minimal translation units helps address some of these issues. The N-gram-based SMT framework is based on tuples. Tuples are minimal translation units composed of source and target cepts2 . N-gram-based models are Markov models over sequences of tuples (Mari˜no et al., 2006; Crego and Mari˜no, 2006) or operations encapsulating tuples (Durrani et al., 2011). This mechanism has several useful properties. Firstly, no phrasal independence assumption is made. The model has access to both source and target context outside of phrases. Secondly the model learns a unique derivation of a bilingual sentence given its alignment, thus avoiding the spurious segmentation problem. Using minimal translation units, however, results in a higher number of search errors because of i) 1 A phrase-pair in PBSMT is a sequence of source and target words that is translation of each other, and is not necessarily a linguistic constituent. Phrases are built by combining min"
N13-1001,2010.amta-papers.22,0,0.219773,"Missing"
N13-1001,D08-1089,0,0.282782,"-art N-gram-based systems (Ncode and OSM) on standard translation tasks. 2 Previous Work Phrase-based and N-gram-based SMT are alternative frameworks for string-to-string translation. Phrase-based SMT segments a bilingual sentence pair into phrases that are continuous sequences of words (Och and Ney, 2004; Koehn et al., 2003) or discontinuous sequences of words (Galley and Manning, 2010). These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang, 2005) or block of phrases (Galley and Manning, 2008). There are several drawbacks of the phrase-based model. Firstly it makes an independence assumption over phrases, according to which phrases are translated independently of each other, thus ignoring the contextual information outside of the phrasal boundary. This problem is corrected by the monolingual language model that takes context into account. But often the language model cannot compensate for the dispreference of the translation model for nonlocal dependencies. The second problem is that the model is unaware of the actual phrasal segmentation of a sentence during training. It therefore"
N13-1001,N03-1017,0,0.395697,", and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks. 1 Introduction Statistical Machine Translation advanced from word-based models (Brown et al., 1993) towards more sophisticated models that take contextual information into account. Phrase-based (Och and Ney, 2004; Koehn et al., 2003) and N-gram-based (Mari˜no et al., 2006) models are two instances of such frameworks. While the two models have some common properties, they are substantially different. ∗ Much of the work presented here was carried out while the first author was at the University of Stuttgart. Phrase-based systems employ a simple and effective machinery by learning larger chunks of translation called phrases1 . Memorizing larger units enables the phrase-based model to learn local dependencies such as short reorderings, idioms, insertions and deletions, etc. The model however, has the following drawbacks: i) i"
N13-1001,P07-2045,0,0.0197622,"other state-of-the-art phrase-based and N-gram-based systems on German-to-English, French-to-English, and Spanish-to-English tasks13 . We used the official evaluation data (news-test sets) from the Statistical Machine Translation Workshops 2009-2011 for all three language pairs (German, Spanish and French). The feature weights for all the systems are tuned using the dev set news-dev2009a. We separately tune the baseline system (cept.500) and the phrase-based system (phrase.200) and do not hold the lambda vector constant like before. Baseline Systems: We also compared our system with i) Moses (Koehn et al., 2007), ii) Phrasal14 (Cer et al., 2010), and iii) Ncode (Crego et al., 2011). We used the default stack sizes of 100 for Moses15 , 200 for Phrasal, 25 for Ncode (with 2m stacks). A 5-gram English language model is used. Both phrase-based systems use 20-best phrases for translation, Ncode uses 25-best tuple translations. The training and test data for Ncode was tagged using TreeTagger (Schmid, 1994). All the baseline systems used lexicalized reordering model. A hard reordering limit16 of 6 words is used as a default in 13 We did not include the results of Spanish in the previous section due to space"
N13-1001,koen-2004-pharaoh,0,0.151724,"ted as an N-gram model of operations using SRILM-Toolkit (Stolcke, 2002) with Kneser-Ney smoothing. A 9-gram model is used. Several count-based features such as gap and open gap penalties and distance-based features such as gap-width and reordering distance are added to the model, along with the lexical weighting and length penalty features in a standard log-linear framework (Durrani et al., 2011). 4 The generation is carried out in the order of the target language E. 4 4 4.1 Search Overview of Decoding Framework The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004a). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged in m stacks such that stack i maintains hypotheses that have already translated i many foreign words. The ultimate goal is to find the best scoring hypothesis, that has translated all the words in the foreign sentence. The overall process can be roughly divided into the following steps: i) extraction of translation units ii) future-cost estimation, iii) hypothesis extension iv) recombination and pruning. During the hypothesis extension each extracted phrase is translated into a sequence"
N13-1001,W04-3250,0,0.0729896,"ted as an N-gram model of operations using SRILM-Toolkit (Stolcke, 2002) with Kneser-Ney smoothing. A 9-gram model is used. Several count-based features such as gap and open gap penalties and distance-based features such as gap-width and reordering distance are added to the model, along with the lexical weighting and length penalty features in a standard log-linear framework (Durrani et al., 2011). 4 The generation is carried out in the order of the target language E. 4 4 4.1 Search Overview of Decoding Framework The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004a). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged in m stacks such that stack i maintains hypotheses that have already translated i many foreign words. The ultimate goal is to find the best scoring hypothesis, that has translated all the words in the foreign sentence. The overall process can be roughly divided into the following steps: i) extraction of translation units ii) future-cost estimation, iii) hypothesis extension iv) recombination and pruning. During the hypothesis extension each extracted phrase is translated into a sequence"
N13-1001,J06-4004,0,0.524902,"Missing"
N13-1001,J03-1002,0,0.0227905,"quality is measured through BLEU (Papineni et al., 2002). 6 Experimental Setup We initially experimented with two language pairs: German-to-English (G-E) and French-to-English (FE). We trained our system and the baseline systems on most of the data6 made available for the translation task of the Fourth Workshop on Statistical Machine Translation.7 We used 1M bilingual sentences, for the estimation of the translation model and 2M sentences from the monolingual corpus (news commentary) which also contains the English part of the bilingual corpus. Word alignments are obtained by running GIZA++ (Och and Ney, 2003) with the grow-diag-final-and (Koehn et al., 2005) symmetrization heuristic. We follow the training steps described in Durrani et al. (2011), consisting of i) post-processing the alignments to remove discontinuous and unaligned target cepts, ii) conversion of bilingual alignments into operation sequences, iii) estimation of the n-gram language models. 6 We did not use all the available data due to scalability issues. The scores reported are therefore well below those obtained by the systems submitted to the WMT evaluation series. 7 http://www.statmt.org/wmt09/translation-task.html 7 6.1 Search"
N13-1001,J04-4002,0,0.734935,"rase-based decoding, and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks. 1 Introduction Statistical Machine Translation advanced from word-based models (Brown et al., 1993) towards more sophisticated models that take contextual information into account. Phrase-based (Och and Ney, 2004; Koehn et al., 2003) and N-gram-based (Mari˜no et al., 2006) models are two instances of such frameworks. While the two models have some common properties, they are substantially different. ∗ Much of the work presented here was carried out while the first author was at the University of Stuttgart. Phrase-based systems employ a simple and effective machinery by learning larger chunks of translation called phrases1 . Memorizing larger units enables the phrase-based model to learn local dependencies such as short reorderings, idioms, insertions and deletions, etc. The model however, has the foll"
N13-1001,W99-0604,0,0.0862666,"st sentences. Firstly, we used future-cost ing can help improve search accuracy and translation estimates from the extracted phrases (see system quality. cept.500.fc in Table1). This however, leads to inconsistency in the cases where the future cost is es5.1 Training We extended the training steps in Durrani et al. timated from some phrasal unit that cannot be gen(2011) to extract a phrase lexicon from the paral- erated through the available cept translations. For lel data. We extract all phrase pairs of length 6 and example, say the best cost to cover the sequence below, that are consistent (Och et al., 1999) with “Wie heißen Sie” is given by the phrase “What is the word alignments. Only continuous phrases as your name”. The 20-best translation options in ceptused in a traditional phrase-based system are ex- based system, however, do not have tuples “Wie – tracted thus allowing only inside-out (Wu, 1997) What” and “heißen – name”. To remove this distype of alignments. The future cost of each fea- crepancy, we add all such tuples that are used in ture component used in the log-linear model is cal- the extracted phrases, to the list of extracted cepts culated. The operation sequence required to hypo"
N13-1001,P02-1040,0,0.107226,"Missing"
N13-1001,P05-1069,0,0.0446686,"systems (Moses and Phrasal) and two stateof-the-art N-gram-based systems (Ncode and OSM) on standard translation tasks. 2 Previous Work Phrase-based and N-gram-based SMT are alternative frameworks for string-to-string translation. Phrase-based SMT segments a bilingual sentence pair into phrases that are continuous sequences of words (Och and Ney, 2004; Koehn et al., 2003) or discontinuous sequences of words (Galley and Manning, 2010). These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang, 2005) or block of phrases (Galley and Manning, 2008). There are several drawbacks of the phrase-based model. Firstly it makes an independence assumption over phrases, according to which phrases are translated independently of each other, thus ignoring the contextual information outside of the phrasal boundary. This problem is corrected by the monolingual language model that takes context into account. But often the language model cannot compensate for the dispreference of the translation model for nonlocal dependencies. The second problem is that the model is unaware of the actual phrasal segmentat"
N13-1001,P11-1086,0,0.0996612,"tatistically significant improvements over all the baseline systems in most of the cases. We have shown the benefits of using phrase-based search with a model based on minimal units. In future work, we would like to study whether a phrase-based system like Moses or Phrasal can profit from an OSM-style or N-gramstyle feature. Feng et al. (2010) previously showed that adding a linearized source-side language model in a phrase-based system helped. It would also be interesting to study whether the insight of using minimal units for modeling and phrase-based search would hold for hierarchical SMT. Vaswani et al. (2011) recently showed that a Markov model over the derivation history of minimal rules can obtain the same translation quality as using grammars formed with composed rules. Acknowledgments Conclusion and Future Work We proposed a combination of using a model based on minimal units and decoding with phrases. Modeling with minimal units enables us to learn local and non-local dependencies in a unified manner and avoid spurious segmentation ambiguities. However, using minimal units also in the search presents a significant challenge because of the poor translation coverage, inaccurate future-cost esti"
N13-1001,J97-3002,0,0.189575,"et al. timated from some phrasal unit that cannot be gen(2011) to extract a phrase lexicon from the paral- erated through the available cept translations. For lel data. We extract all phrase pairs of length 6 and example, say the best cost to cover the sequence below, that are consistent (Och et al., 1999) with “Wie heißen Sie” is given by the phrase “What is the word alignments. Only continuous phrases as your name”. The 20-best translation options in ceptused in a traditional phrase-based system are ex- based system, however, do not have tuples “Wie – tracted thus allowing only inside-out (Wu, 1997) What” and “heißen – name”. To remove this distype of alignments. The future cost of each fea- crepancy, we add all such tuples that are used in ture component used in the log-linear model is cal- the extracted phrases, to the list of extracted cepts culated. The operation sequence required to hypoth- (system cept.500.fc.t). We also studied how much esize each phrase is generated and its future cost is gain we obtain by only adding tuples from phrases calculated. The future costs of other features such and using cept-based future-cost estimates (system as language models, lexicalized probabili"
N13-1001,N10-1140,0,\N,Missing
N13-1001,2005.iwslt-1.8,0,\N,Missing
P01-1060,P99-1059,0,0.0190738,"3  qZ§ 0   o q PF-F LOW( v )  1 Initial. float array o i  ¦w    { 2 o q«§ªs 3 for n in iz in top-down order     X& º 4 do o n q«§ X& » ®¯}}:º o lhs n q    5 for in rhs n      6 do o q©§ o q°  7 return y  qZ§ 0 n o q Figure 5: Inside algorithm. Figure 6: Flow algorithm. first constructed by tabular parsing, and then in a second pass parse forest symbols are split according to headedness. Such an algorithm is shown in appendix B. This procedure gives worst case time and space complexity which is proportional to the fifth power of the length of the sentence. See Eisner and Satta (1999) for discussion and an algorithm with time and space requirements proportional to the fourth power of the length of the input sentence in the worst case. In practical experience with broad-coverage context free grammars of several languages, we have not observed super-cubic average time or space requirements for our implementation. We believe this is because, for our grammars and corpora, there is limited ambiguity in the position of the head within a given category-span combination. The governor algorithm stated in the next section refers to headedness in parse forest rules. This can be repre"
P01-1060,1997.iwpt-1.10,0,0.0410864,"priate because Â  as defined in equation (5) is to be scaled by the relative weight of trees in      . In line 9 of the algorithm, Â is summed into the head child  . There is no scaling, because every       tree in  n is a tree in   . ¥ A probability parameter vector is used in the inside algorithm. In our implementation, we can use either a probabilistic context free grammar, or a lexicalized context free grammar which conditions rules on parent category and parent lexical head, and conditions the heads of non-head children on child category, parent category, and parent head (Eisner, 1997; Charniak, 1995; Carroll and Rooth, 1998). The requisite information is di rectly represented in our parse forests by  and £ . Thus the call to PF- INSIDE in line 1 of PFG OVERNORS may involve either a computation of PCFG inside probabilities, or head-lexicalized inside probabilities. However, in both cases the algorithm requires that the parse forest symbols be split according to heads, because of the reference to £  in line 10. Construction of headmarked parse forests is presented in the appendix. The LoPar parser (Schmid, 2000a) on which our implementation of the governor algorithm is"
P01-1060,P89-1018,0,0.161734,"of a labeled grammar representing two tree analyses of John reads every paper on markup. The labeling function drops |   P subscripts, so that  VP 6 VP.    forest symbol or rule  .3 Let   be the set of {  trees in g which contain  as a symbol or      use  as a rule. is defined to be the multiset   |      is the multiset image of   under  . of complete trees represented by the parse forest symbol or rule  . Where < is a probability function on trees licensed by the underlying grammar and  is a symbol or rule in v ,   3 Parse Forests A parse forest (see also Billot and Lang (1989)) in labeled grammar notation is a tu3y 3 3{ 3}| P 1&wx  iz  ~2 where ple v 3y 3 3{ 1&wC  iz ~2 is a context free grammar (consisting of non-terminals w , terminals y {  , rules i  , and a start symbol  ) and |  is a function which maps elements of w to non-terminals in an underlying grammar  3yr3 3{ y P 1&w i 2 and elements of  to termi | nals in . By using  on symbols on the left hand and right hand sides of a parse forest rule, |  can be extended to map the set of parse forest rules iK to the set of underlying grammar rules | i .  is also extended to map trees"
P01-1060,W98-1505,1,0.83396,"in equation (5) is to be scaled by the relative weight of trees in      . In line 9 of the algorithm, Â is summed into the head child  . There is no scaling, because every       tree in  n is a tree in   . ¥ A probability parameter vector is used in the inside algorithm. In our implementation, we can use either a probabilistic context free grammar, or a lexicalized context free grammar which conditions rules on parent category and parent lexical head, and conditions the heads of non-head children on child category, parent category, and parent head (Eisner, 1997; Charniak, 1995; Carroll and Rooth, 1998). The requisite information is di rectly represented in our parse forests by  and £ . Thus the call to PF- INSIDE in line 1 of PFG OVERNORS may involve either a computation of PCFG inside probabilities, or head-lexicalized inside probabilities. However, in both cases the algorithm requires that the parse forest symbols be split according to heads, because of the reference to £  in line 10. Construction of headmarked parse forests is presented in the appendix. The LoPar parser (Schmid, 2000a) on which our implementation of the governor algorithm is based represents the parse forest as a gr"
P01-1060,C00-2105,1,0.837501,"sentences, and answer terms within sentences. In collaboration with Pranav Anand and Eric Breck, we have incorporated governor markup in the question answering prototype, but not debugged or evaluated it. Expected governor markup summarizes syntactic structure in a weighted parse forest which is the product of exhaustive parsing and insideoutside computation. This is a strategy of dumbing down the product of computationally intensive statistical parsing into unstructured markup. Estimated frequency computations in parse forests have previously been applied to tagging and chunking (Schulte im Walde and Schmid, 2000). Governor markup differs in that it is reflective of higher-level syntax. The strategy has the advantage, in our view, that it allows one to base markup algorithms on relatively sophisticated grammars, and to take advantage of the lexically sensitive probabilistic weighting of trees which is provided by a lexicalized probability model. Localizing markup on the governed word increases pooling of frequencies, because the span of the phrase headed by the governed item is ignored. This idea could be exploited in other markup tasks. In a chunking task, categories and heads of chunks could be ident"
P06-1023,P04-1082,0,0.505567,"s, 1997; Charniak, 2000, and others) which are trained on the PENN treebank generate parse trees without empty categories. In order to augment such parsers with empty category prediction, three rather different strategies have been proposed: (i) pre-processing of the input sentence with a tagger which inserts empty categories into the input string of the parser (Dienes and Dubey, 2003b; Dienes and Dubey, 2003a). The parser treats the empty elements like normal input tokens. (ii) post-processing of the parse trees with a pattern matcher which adds empty categories after parsing (Johnson, 2001; Campbell, 2004; Levy and Manning, 2004) (iii) in-processing of the empty categories with a slash percolation mechanism (Dienes and Dubey, 2003b; Dienes and Dubey, 2003a). The empty elements are here generated by the grammar. Good results have been obtained with all three approaches, but (Dienes and Dubey, 2003b) reported that in their experiments, the in-processing of the empty categories only worked with lexicalized parsing. They explain that their unlex1 Introduction Empty categories (also called null elements) are used in the annotation of the PENN treebank (Marcus et al., 1993) in order to represent syn"
P06-1023,A00-2018,0,0.107123,"Missing"
P06-1023,P97-1003,0,0.0675589,"Missing"
P06-1023,W03-1005,0,0.358806,"J VP of WDT PRP VBP which they are ADJP-PRD JJ PP unaware -NONE*T*-1 Figure 1: Co-indexation of traces and fillers for determining the predicate-argument structure of a sentence. However, most broad-coverage statistical parsers (Collins, 1997; Charniak, 2000, and others) which are trained on the PENN treebank generate parse trees without empty categories. In order to augment such parsers with empty category prediction, three rather different strategies have been proposed: (i) pre-processing of the input sentence with a tagger which inserts empty categories into the input string of the parser (Dienes and Dubey, 2003b; Dienes and Dubey, 2003a). The parser treats the empty elements like normal input tokens. (ii) post-processing of the parse trees with a pattern matcher which adds empty categories after parsing (Johnson, 2001; Campbell, 2004; Levy and Manning, 2004) (iii) in-processing of the empty categories with a slash percolation mechanism (Dienes and Dubey, 2003b; Dienes and Dubey, 2003a). The empty elements are here generated by the grammar. Good results have been obtained with all three approaches, but (Dienes and Dubey, 2003b) reported that in their experiments, the in-processing of the empty catego"
P06-1023,P03-1055,0,0.435089,"J VP of WDT PRP VBP which they are ADJP-PRD JJ PP unaware -NONE*T*-1 Figure 1: Co-indexation of traces and fillers for determining the predicate-argument structure of a sentence. However, most broad-coverage statistical parsers (Collins, 1997; Charniak, 2000, and others) which are trained on the PENN treebank generate parse trees without empty categories. In order to augment such parsers with empty category prediction, three rather different strategies have been proposed: (i) pre-processing of the input sentence with a tagger which inserts empty categories into the input string of the parser (Dienes and Dubey, 2003b; Dienes and Dubey, 2003a). The parser treats the empty elements like normal input tokens. (ii) post-processing of the parse trees with a pattern matcher which adds empty categories after parsing (Johnson, 2001; Campbell, 2004; Levy and Manning, 2004) (iii) in-processing of the empty categories with a slash percolation mechanism (Dienes and Dubey, 2003b; Dienes and Dubey, 2003a). The empty elements are here generated by the grammar. Good results have been obtained with all three approaches, but (Dienes and Dubey, 2003b) reported that in their experiments, the in-processing of the empty catego"
P06-1023,P03-1054,0,0.397316,"tituents with empty elements. The scores of these constituents were too low compared with the scores of constituents without empty elements. They speculated that “doing an exhaustive search might help” here. In this paper, we confirm this hypothesis and show that it is possible to accurately predict empty categories with unlexicalized PCFG parsing and slash features if the true Viterbi parse is computed. In our experiments, we used the BitPar parser (Schmid, 2004) and a PCFG which was extracted from a version of the PENN treebank that was automatically annotated with features in the style of (Klein and Manning, 2003). ble that the filler dominates the trace. An example is the sentence “S-1 She had – he informed her *1 – kidney trouble” whose parse tree is shown in figure 3. Besides the slash features, we used other features in order to improve the parsing accuracy of the PCFG, inspired by the work of Klein and Manning (2003). The most important ones of these features1 will now be described in detail. Section 4.3 shows the impact of these features on labeled bracketing accuracy and empty category prediction. 2 Feature Annotation S feature The S node feature distinguishes between imperatives, finite clauses"
P06-1023,P04-1042,0,0.693302,"k, 2000, and others) which are trained on the PENN treebank generate parse trees without empty categories. In order to augment such parsers with empty category prediction, three rather different strategies have been proposed: (i) pre-processing of the input sentence with a tagger which inserts empty categories into the input string of the parser (Dienes and Dubey, 2003b; Dienes and Dubey, 2003a). The parser treats the empty elements like normal input tokens. (ii) post-processing of the parse trees with a pattern matcher which adds empty categories after parsing (Johnson, 2001; Campbell, 2004; Levy and Manning, 2004) (iii) in-processing of the empty categories with a slash percolation mechanism (Dienes and Dubey, 2003b; Dienes and Dubey, 2003a). The empty elements are here generated by the grammar. Good results have been obtained with all three approaches, but (Dienes and Dubey, 2003b) reported that in their experiments, the in-processing of the empty categories only worked with lexicalized parsing. They explain that their unlex1 Introduction Empty categories (also called null elements) are used in the annotation of the PENN treebank (Marcus et al., 1993) in order to represent syntactic phenomena like con"
P06-1023,J93-2004,0,0.0269241,"s after parsing (Johnson, 2001; Campbell, 2004; Levy and Manning, 2004) (iii) in-processing of the empty categories with a slash percolation mechanism (Dienes and Dubey, 2003b; Dienes and Dubey, 2003a). The empty elements are here generated by the grammar. Good results have been obtained with all three approaches, but (Dienes and Dubey, 2003b) reported that in their experiments, the in-processing of the empty categories only worked with lexicalized parsing. They explain that their unlex1 Introduction Empty categories (also called null elements) are used in the annotation of the PENN treebank (Marcus et al., 1993) in order to represent syntactic phenomena like constituent movement (e.g. whextraction), discontinuous constituents, and missing elements (PRO elements, empty complementizers and relative pronouns). Moved constituents are co-indexed with a trace which is located at the position where the moved constituent is to be interpreted. Figure 1 shows an example of constituent movement in a relative clause. Empty categories provide important information for the semantic interpretation, in particular 177 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meetin"
P06-1023,C04-1024,1,0.754872,"Computational Linguistics icalized PCFG parser produced poor results because the beam search strategy applied there eliminated many correct constituents with empty elements. The scores of these constituents were too low compared with the scores of constituents without empty elements. They speculated that “doing an exhaustive search might help” here. In this paper, we confirm this hypothesis and show that it is possible to accurately predict empty categories with unlexicalized PCFG parsing and slash features if the true Viterbi parse is computed. In our experiments, we used the BitPar parser (Schmid, 2004) and a PCFG which was extracted from a version of the PENN treebank that was automatically annotated with features in the style of (Klein and Manning, 2003). ble that the filler dominates the trace. An example is the sentence “S-1 She had – he informed her *1 – kidney trouble” whose parse tree is shown in figure 3. Besides the slash features, we used other features in order to improve the parsing accuracy of the PCFG, inspired by the work of Klein and Manning (2003). The most important ones of these features1 will now be described in detail. Section 4.3 shows the impact of these features on la"
P06-1023,J98-4004,0,\N,Missing
P06-1023,P02-1018,0,\N,Missing
P07-1013,P96-1041,0,0.118877,"Missing"
P07-1013,P07-1116,1,0.814641,"pect to CELEX manual annotation. Unsupervised Morphological Systems Most attractive among automatic systems are methods that use unsupervised learning, because these require neither an expert linguist to build large rule-sets and lexica nor large manually annotated word lists, but only large amounts of tokenized text, which can be acquired e.g. from the internet. Unsupervised methods are in principle6 languageindependent, and can therefore easily be applied to other languages. We compared four different state-of-the-art unsupervised systems for morphological decomposition (cf. (Demberg, 2006; Demberg, 2007)). The algorithms were trained on a German newspaper corpus (taz), containing about 240 million words. The same algorithms have previously been shown to help a speech recognition task (Kurimo et al., 2006). 5 Experimental Evaluations 5.1 Training Set and Test Set Design The German corpus used in these experiments is CELEX (German Linguistic User Guide, 1995). CELEX contains a phonemic representation of each 4 Eloquent Technology, Inc. (ETI) TTS system. http://www.mindspring.com/˜ssshp/ssshp_cd/ ss_eloq.htm 5 The lexicon used by SMOR, IMSLEX, contains morphologically complex entries, which lead"
P07-1013,P01-1053,0,0.171481,"Missing"
P07-1013,C86-1063,0,0.618043,"weight (such as German or Dutch), it is important to know where exactly the syllable boundaries are in order to correctly calculate syllable weight. For German, (M¨uller, 2001) show that information about stress assignment and the position of a syllable within a word improve g2p conversion. 1.2 Morphological Preprocessing It has been argued that using morphological information is important for languages where morphology has an important influence on pronunciation, syllabification and word stress such as German, Dutch, Swedish or, to a smaller extent, also English (Sproat, 1996; M¨obius, 2001; Pounder and Kommenda, 1986; Black et al., 1998; Taylor, 2005). Unfortunately, these papers do not quantify the contribution of morphological preprocessing in the task. Important questions when considering the integration of a morphological component into a speech 1 This issue is controversial among linguists; for an overview see (Jessen, 1998). Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 96–103, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics synthesis system are 1) How large are the improvements to be gained from morphological prepro"
P07-1013,schmid-etal-2004-smor,1,0.837765,"Missing"
P07-1013,J00-2003,0,\N,Missing
P08-1057,E03-1034,0,0.499721,"clustering approach that previously incorporated selectional preferences as verb features. However, her model was not soft-clustering, and she only used a simple approach to represent selectional preferences by WordNet’s top-level concepts, instead of making use of the whole hierarchy and more sophisticated methods, as in the current paper. Last but not least, there are other models of selectional preferences than the MDL model we used in our paper. Most such models also rely on the 503 WordNet hierarchy (Resnik, 1997; Abney and Light, 1999; Ciaramita and Johnson, 2000; Clark and Weir, 2002). Brockmann and Lapata (2003) compared some of the models against human judgements on the acceptability of sentences, and demonstrated that the models were significantly correlated with human ratings, and that no model performed best; rather, the different methods are suited for different argument relations. 5 Summary and Outlook This paper presented an innovative, complex approach to semantic verb classes that relies on selectional preferences as verb properties. The probabilistic verb class model underlying the semantic classes was trained by a combination of the EM algorithm and the MDL principle, providing soft cluste"
P08-1057,W98-1505,0,0.236617,"Missing"
P08-1057,C00-1028,0,0.558881,"knowledge, Schulte im Walde (2006) is the only hard-clustering approach that previously incorporated selectional preferences as verb features. However, her model was not soft-clustering, and she only used a simple approach to represent selectional preferences by WordNet’s top-level concepts, instead of making use of the whole hierarchy and more sophisticated methods, as in the current paper. Last but not least, there are other models of selectional preferences than the MDL model we used in our paper. Most such models also rely on the 503 WordNet hierarchy (Resnik, 1997; Abney and Light, 1999; Ciaramita and Johnson, 2000; Clark and Weir, 2002). Brockmann and Lapata (2003) compared some of the models against human judgements on the acceptability of sentences, and demonstrated that the models were significantly correlated with human ratings, and that no model performed best; rather, the different methods are suited for different argument relations. 5 Summary and Outlook This paper presented an innovative, complex approach to semantic verb classes that relies on selectional preferences as verb properties. The probabilistic verb class model underlying the semantic classes was trained by a combination of the EM al"
P08-1057,J02-2003,0,0.262808,"2006) is the only hard-clustering approach that previously incorporated selectional preferences as verb features. However, her model was not soft-clustering, and she only used a simple approach to represent selectional preferences by WordNet’s top-level concepts, instead of making use of the whole hierarchy and more sophisticated methods, as in the current paper. Last but not least, there are other models of selectional preferences than the MDL model we used in our paper. Most such models also rely on the 503 WordNet hierarchy (Resnik, 1997; Abney and Light, 1999; Ciaramita and Johnson, 2000; Clark and Weir, 2002). Brockmann and Lapata (2003) compared some of the models against human judgements on the acceptability of sentences, and demonstrated that the models were significantly correlated with human ratings, and that no model performed best; rather, the different methods are suited for different argument relations. 5 Summary and Outlook This paper presented an innovative, complex approach to semantic verb classes that relies on selectional preferences as verb properties. The probabilistic verb class model underlying the semantic classes was trained by a combination of the EM algorithm and the MDL pri"
P08-1057,C96-1055,0,0.0284114,"s that generalise over verbs according to their semantic properties. Intuitive examples of such classifications are the M OTION WITH A V EHICLE class, including verbs such as drive, fly, row, etc., or the B REAK A S OLID S URFACE WITH AN I NSTRUMENT class, including verbs such as break, crush, fracture, smash, etc. Semantic verb classifications are of great interest to computational linguistics, specifically regarding the pervasive problem of data sparseness in the processing of natural language. Up to now, such classifications have been used in applications such as word sense disambiguation (Dorr and Jones, 1996; Kohomban and Lee, 2005), machine translation (Prescher et al., 2000; Koehn and Hoang, 2007), document classification (Klavans and Kan, 1998), and in statistical lexical acquisition in general (Rooth et al., 1999; Merlo and Stevenson, 2001; Korhonen, 2002; Schulte im Walde, 2006). Given that the creation of semantic verb classifications is not an end task in itself, but depends on the application scenario of the classification, we find various approaches to an automatic induction of semantic verb classifications. For example, Siegel and McKeown (2000) used several machine learning algorithms"
P08-1057,P98-1112,0,0.0215797,"CLE class, including verbs such as drive, fly, row, etc., or the B REAK A S OLID S URFACE WITH AN I NSTRUMENT class, including verbs such as break, crush, fracture, smash, etc. Semantic verb classifications are of great interest to computational linguistics, specifically regarding the pervasive problem of data sparseness in the processing of natural language. Up to now, such classifications have been used in applications such as word sense disambiguation (Dorr and Jones, 1996; Kohomban and Lee, 2005), machine translation (Prescher et al., 2000; Koehn and Hoang, 2007), document classification (Klavans and Kan, 1998), and in statistical lexical acquisition in general (Rooth et al., 1999; Merlo and Stevenson, 2001; Korhonen, 2002; Schulte im Walde, 2006). Given that the creation of semantic verb classifications is not an end task in itself, but depends on the application scenario of the classification, we find various approaches to an automatic induction of semantic verb classifications. For example, Siegel and McKeown (2000) used several machine learning algorithms to perform an automatic aspectual classification of English verbs into event and stative verbs. Merlo and Stevenson (2001) presented an automa"
P08-1057,D07-1091,0,0.0101779,"such classifications are the M OTION WITH A V EHICLE class, including verbs such as drive, fly, row, etc., or the B REAK A S OLID S URFACE WITH AN I NSTRUMENT class, including verbs such as break, crush, fracture, smash, etc. Semantic verb classifications are of great interest to computational linguistics, specifically regarding the pervasive problem of data sparseness in the processing of natural language. Up to now, such classifications have been used in applications such as word sense disambiguation (Dorr and Jones, 1996; Kohomban and Lee, 2005), machine translation (Prescher et al., 2000; Koehn and Hoang, 2007), document classification (Klavans and Kan, 1998), and in statistical lexical acquisition in general (Rooth et al., 1999; Merlo and Stevenson, 2001; Korhonen, 2002; Schulte im Walde, 2006). Given that the creation of semantic verb classifications is not an end task in itself, but depends on the application scenario of the classification, we find various approaches to an automatic induction of semantic verb classifications. For example, Siegel and McKeown (2000) used several machine learning algorithms to perform an automatic aspectual classification of English verbs into event and stative verb"
P08-1057,P05-1005,0,0.022284,"verbs according to their semantic properties. Intuitive examples of such classifications are the M OTION WITH A V EHICLE class, including verbs such as drive, fly, row, etc., or the B REAK A S OLID S URFACE WITH AN I NSTRUMENT class, including verbs such as break, crush, fracture, smash, etc. Semantic verb classifications are of great interest to computational linguistics, specifically regarding the pervasive problem of data sparseness in the processing of natural language. Up to now, such classifications have been used in applications such as word sense disambiguation (Dorr and Jones, 1996; Kohomban and Lee, 2005), machine translation (Prescher et al., 2000; Koehn and Hoang, 2007), document classification (Klavans and Kan, 1998), and in statistical lexical acquisition in general (Rooth et al., 1999; Merlo and Stevenson, 2001; Korhonen, 2002; Schulte im Walde, 2006). Given that the creation of semantic verb classifications is not an end task in itself, but depends on the application scenario of the classification, we find various approaches to an automatic induction of semantic verb classifications. For example, Siegel and McKeown (2000) used several machine learning algorithms to perform an automatic a"
P08-1057,P03-1009,0,0.437238,"oaches to an automatic induction of semantic verb classifications. For example, Siegel and McKeown (2000) used several machine learning algorithms to perform an automatic aspectual classification of English verbs into event and stative verbs. Merlo and Stevenson (2001) presented an automatic classification of three types of English intransitive verbs, based on argument structure and heuristics to thematic relations. Pereira et al. (1993) and Rooth et al. (1999) relied on the ExpectationMaximisation algorithm to induce soft clusters of verbs, based on the verbs’ direct object nouns. Similarly, Korhonen et al. (2003) relied on the Information Bottleneck (Tishby et al., 1999) and subcategorisation frame types to induce soft verb clusters. This paper presents an innovative, complex approach to semantic verb classes that relies on selectional preferences as verb properties. The underlying linguistic assumption for this verb class model is that verbs which agree on their selectional preferences belong to a common semantic class. The model is implemented as a softclustering approach, in order to capture the polysemy of the verbs. The training procedure uses the Expectation-Maximisation (EM) algorithm (Baum, 19"
P08-1057,J98-2002,0,0.35937,"e data length, with the model length defined as the number of bits needed to encode the model and its parameters, and the data length defined as the number of bits required to encode the training data with the given model. According to coding theory, an optimal encoding uses −log2 p bits, on average, to encode data whose probability is p. Usually, the model length increases and the data length decreases as more parameters are added to a model. The MDL principle finds a compromise between the size of the model and the accuracy of the data description. Our selectional preference model relies on Li and Abe (1998), applying the MDL principle to determine selectional preferences of verbs and their arguments, by means of a concept hierarchy ordered by hypernym/hyponym relations. Given a set of nouns within a specific argument slot as a sample, the approach finds the cut3 in a concept hierarchy which minimises the sum of encoding both the model and the data. The model length (ML) is defined as k ∗ log2 |S|, ML = 2 with k the number of concepts in the partial hierarchy between the top concept and the concepts in the cut, and |S |the sample size, i.e., the total frequency of the data set. The data length (D"
P08-1057,P93-1024,0,0.94928,"e, 2006). Given that the creation of semantic verb classifications is not an end task in itself, but depends on the application scenario of the classification, we find various approaches to an automatic induction of semantic verb classifications. For example, Siegel and McKeown (2000) used several machine learning algorithms to perform an automatic aspectual classification of English verbs into event and stative verbs. Merlo and Stevenson (2001) presented an automatic classification of three types of English intransitive verbs, based on argument structure and heuristics to thematic relations. Pereira et al. (1993) and Rooth et al. (1999) relied on the ExpectationMaximisation algorithm to induce soft clusters of verbs, based on the verbs’ direct object nouns. Similarly, Korhonen et al. (2003) relied on the Information Bottleneck (Tishby et al., 1999) and subcategorisation frame types to induce soft verb clusters. This paper presents an innovative, complex approach to semantic verb classes that relies on selectional preferences as verb properties. The underlying linguistic assumption for this verb class model is that verbs which agree on their selectional preferences belong to a common semantic class. Th"
P08-1057,C00-2094,0,0.0238335,"Intuitive examples of such classifications are the M OTION WITH A V EHICLE class, including verbs such as drive, fly, row, etc., or the B REAK A S OLID S URFACE WITH AN I NSTRUMENT class, including verbs such as break, crush, fracture, smash, etc. Semantic verb classifications are of great interest to computational linguistics, specifically regarding the pervasive problem of data sparseness in the processing of natural language. Up to now, such classifications have been used in applications such as word sense disambiguation (Dorr and Jones, 1996; Kohomban and Lee, 2005), machine translation (Prescher et al., 2000; Koehn and Hoang, 2007), document classification (Klavans and Kan, 1998), and in statistical lexical acquisition in general (Rooth et al., 1999; Merlo and Stevenson, 2001; Korhonen, 2002; Schulte im Walde, 2006). Given that the creation of semantic verb classifications is not an end task in itself, but depends on the application scenario of the classification, we find various approaches to an automatic induction of semantic verb classifications. For example, Siegel and McKeown (2000) used several machine learning algorithms to perform an automatic aspectual classification of English verbs int"
P08-1057,W97-0209,0,0.237752,"ation to animacy. To the best of our knowledge, Schulte im Walde (2006) is the only hard-clustering approach that previously incorporated selectional preferences as verb features. However, her model was not soft-clustering, and she only used a simple approach to represent selectional preferences by WordNet’s top-level concepts, instead of making use of the whole hierarchy and more sophisticated methods, as in the current paper. Last but not least, there are other models of selectional preferences than the MDL model we used in our paper. Most such models also rely on the 503 WordNet hierarchy (Resnik, 1997; Abney and Light, 1999; Ciaramita and Johnson, 2000; Clark and Weir, 2002). Brockmann and Lapata (2003) compared some of the models against human judgements on the acceptability of sentences, and demonstrated that the models were significantly correlated with human ratings, and that no model performed best; rather, the different methods are suited for different argument relations. 5 Summary and Outlook This paper presented an innovative, complex approach to semantic verb classes that relies on selectional preferences as verb properties. The probabilistic verb class model underlying the semant"
P08-1057,P99-1014,0,0.788603,"OLID S URFACE WITH AN I NSTRUMENT class, including verbs such as break, crush, fracture, smash, etc. Semantic verb classifications are of great interest to computational linguistics, specifically regarding the pervasive problem of data sparseness in the processing of natural language. Up to now, such classifications have been used in applications such as word sense disambiguation (Dorr and Jones, 1996; Kohomban and Lee, 2005), machine translation (Prescher et al., 2000; Koehn and Hoang, 2007), document classification (Klavans and Kan, 1998), and in statistical lexical acquisition in general (Rooth et al., 1999; Merlo and Stevenson, 2001; Korhonen, 2002; Schulte im Walde, 2006). Given that the creation of semantic verb classifications is not an end task in itself, but depends on the application scenario of the classification, we find various approaches to an automatic induction of semantic verb classifications. For example, Siegel and McKeown (2000) used several machine learning algorithms to perform an automatic aspectual classification of English verbs into event and stative verbs. Merlo and Stevenson (2001) presented an automatic classification of three types of English intransitive verbs, based"
P08-1057,J06-2001,1,0.94211,"rush, fracture, smash, etc. Semantic verb classifications are of great interest to computational linguistics, specifically regarding the pervasive problem of data sparseness in the processing of natural language. Up to now, such classifications have been used in applications such as word sense disambiguation (Dorr and Jones, 1996; Kohomban and Lee, 2005), machine translation (Prescher et al., 2000; Koehn and Hoang, 2007), document classification (Klavans and Kan, 1998), and in statistical lexical acquisition in general (Rooth et al., 1999; Merlo and Stevenson, 2001; Korhonen, 2002; Schulte im Walde, 2006). Given that the creation of semantic verb classifications is not an end task in itself, but depends on the application scenario of the classification, we find various approaches to an automatic induction of semantic verb classifications. For example, Siegel and McKeown (2000) used several machine learning algorithms to perform an automatic aspectual classification of English verbs into event and stative verbs. Merlo and Stevenson (2001) presented an automatic classification of three types of English intransitive verbs, based on argument structure and heuristics to thematic relations. Pereira"
P08-1057,J00-4004,0,0.00912264,"pplications such as word sense disambiguation (Dorr and Jones, 1996; Kohomban and Lee, 2005), machine translation (Prescher et al., 2000; Koehn and Hoang, 2007), document classification (Klavans and Kan, 1998), and in statistical lexical acquisition in general (Rooth et al., 1999; Merlo and Stevenson, 2001; Korhonen, 2002; Schulte im Walde, 2006). Given that the creation of semantic verb classifications is not an end task in itself, but depends on the application scenario of the classification, we find various approaches to an automatic induction of semantic verb classifications. For example, Siegel and McKeown (2000) used several machine learning algorithms to perform an automatic aspectual classification of English verbs into event and stative verbs. Merlo and Stevenson (2001) presented an automatic classification of three types of English intransitive verbs, based on argument structure and heuristics to thematic relations. Pereira et al. (1993) and Rooth et al. (1999) relied on the ExpectationMaximisation algorithm to induce soft clusters of verbs, based on the verbs’ direct object nouns. Similarly, Korhonen et al. (2003) relied on the Information Bottleneck (Tishby et al., 1999) and subcategorisation f"
P08-1057,D07-1107,0,0.0451065,"Missing"
P08-1057,J01-3003,0,\N,Missing
P10-1048,P04-1021,0,0.0650915,"model decides whether Differently in Different Contexts to translate or transliterate and how it is able to choose among different valid transliterations given Hindi Urdu SAMPA Gloss the context. Section 8 concludes the paper. / simA Border/Seema / / 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The first group is generic transliteration work, which is evaluated outside of the context of translation. This work uses either grapheme or phoneme based models to transliterate words lists (Knight and Graehl, 1998; Li et al., 2004; Ekbal et al., 2006; Malik et al., 2008). The work by Malik et al. addresses Hindi to Urdu transliteration using hand-crafted rules and a phonemic representation; it ignores translation context. A second group deals with out-of-vocabulary words for SMT systems built on large parallel corpora, and therefore focuses on name transliteration, which is largely independent of context. AlOnaizan and Knight (2002) transliterate Arabic NEs into English and score them against their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such a"
P10-1048,P02-1051,0,0.0189206,"Missing"
P10-1048,C08-1068,0,0.105223,"Different Contexts to translate or transliterate and how it is able to choose among different valid transliterations given Hindi Urdu SAMPA Gloss the context. Section 8 concludes the paper. / simA Border/Seema / / 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The first group is generic transliteration work, which is evaluated outside of the context of translation. This work uses either grapheme or phoneme based models to transliterate words lists (Knight and Graehl, 1998; Li et al., 2004; Ekbal et al., 2006; Malik et al., 2008). The work by Malik et al. addresses Hindi to Urdu transliteration using hand-crafted rules and a phonemic representation; it ignores translation context. A second group deals with out-of-vocabulary words for SMT systems built on large parallel corpora, and therefore focuses on name transliteration, which is largely independent of context. AlOnaizan and Knight (2002) transliterate Arabic NEs into English and score them against their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such as web counts and using coreference to res"
P10-1048,P06-2025,0,0.116436,"ether Differently in Different Contexts to translate or transliterate and how it is able to choose among different valid transliterations given Hindi Urdu SAMPA Gloss the context. Section 8 concludes the paper. / simA Border/Seema / / 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The first group is generic transliteration work, which is evaluated outside of the context of translation. This work uses either grapheme or phoneme based models to transliterate words lists (Knight and Graehl, 1998; Li et al., 2004; Ekbal et al., 2006; Malik et al., 2008). The work by Malik et al. addresses Hindi to Urdu transliteration using hand-crafted rules and a phonemic representation; it ignores translation context. A second group deals with out-of-vocabulary words for SMT systems built on large parallel corpora, and therefore focuses on name transliteration, which is largely independent of context. AlOnaizan and Knight (2002) transliterate Arabic NEs into English and score them against their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such as web counts and usi"
P10-1048,moore-2002-fast,0,0.0206337,"Missing"
P10-1048,J03-1002,0,0.0455825,"Missing"
P10-1048,2001.mtsummit-papers.68,0,0.0625189,"Missing"
P10-1048,P08-1045,0,0.0400247,"Missing"
P10-1048,W07-0703,0,0.192128,"es such as web counts and using coreference to resolve ambiguity. These re-ranking methodologies can not be performed in SMT at the decoding time. An efficient way to compute and re-rank the transliterations of NEs and integrate them on the fly might be possible. However, this is not practical in our case as our model considers transliterations of all input words and not just NEs. A log-linear block transliteration model is applied to OOV NEs in Arabic to English SMT by Zhao et al. (2007). This work is also transliterating only NEs and not doing any disambiguation. The best method proposed by Kashani et al. (2007) integrates translations provided by external sources such as transliteration or rule-base translation of numbers and dates, for an arbitrary number of entries within the input text. Our work is different from Kashani et al. (2007) in that our model compares transliterations with translations Table 2: Hindi Words That Can Be Translated or Transliterated in Different Contexts which focus primarily on name transliteration, because we need different transliterations in different contexts; in their case context is irrelevant. For example: consider the problem of transliterating the English word “r"
P10-1048,2009.mtsummit-caasl.12,0,0.0167695,"table dynamically such that they can directly compete with translations during decoding. This is closer to our approach except that we use transliteration as an alternative to translation for all Hindi words. Our focus is disambiguation of Hindi homonyms whereas they are concentrating only on transliterating NE’s. Moreover, they are working with a large bitext so they can rely on their translation model and only need to transliterate NEs and OOVs. Our translation model is based on data which is both sparse and noisy. Therefore we pit transliterations against translations for every input word. Sinha (2009) presents a rule-based MT system that uses Hindi as a pivot to translate from English to Urdu. This work also uses transliteration only for the translation of unknown words. Their work can not be used for direct translation from Hindi to Urdu (independently of English) “due to various ambiguous mappings that have to be resolved”. The third group uses transliteration models inside of a cross-lingual IR system (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Pirkola et al., 2003). Picking a single best transliteration or translation in context is not important in an IR system. Instead,"
P10-1048,W03-1508,0,0.0274178,"translation model is based on data which is both sparse and noisy. Therefore we pit transliterations against translations for every input word. Sinha (2009) presents a rule-based MT system that uses Hindi as a pivot to translate from English to Urdu. This work also uses transliteration only for the translation of unknown words. Their work can not be used for direct translation from Hindi to Urdu (independently of English) “due to various ambiguous mappings that have to be resolved”. The third group uses transliteration models inside of a cross-lingual IR system (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Pirkola et al., 2003). Picking a single best transliteration or translation in context is not important in an IR system. Instead, all the options are used by giving them weights and context is typically not taken into account. 3 ematical formulation of our two models, Model-1 and Model-2. 3.1 Model-1 : Conditional Probability Model Applying a noisy channel model to compute the most probable translation u ˆn1 , we get: p(un1 )p(hn1 |un1 ) p(un1 |hn1 ) = arg max arg max n n u1 u1 (1) 3.1.1 Language Model The language model (LM) p(un1 ) is implemented as an n-gram model using the SRILM-Toolkit"
P10-1048,N07-1046,0,0.178172,"ainst their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such as web counts and using coreference to resolve ambiguity. These re-ranking methodologies can not be performed in SMT at the decoding time. An efficient way to compute and re-rank the transliterations of NEs and integrate them on the fly might be possible. However, this is not practical in our case as our model considers transliterations of all input words and not just NEs. A log-linear block transliteration model is applied to OOV NEs in Arabic to English SMT by Zhao et al. (2007). This work is also transliterating only NEs and not doing any disambiguation. The best method proposed by Kashani et al. (2007) integrates translations provided by external sources such as transliteration or rule-base translation of numbers and dates, for an arbitrary number of entries within the input text. Our work is different from Kashani et al. (2007) in that our model compares transliterations with translations Table 2: Hindi Words That Can Be Translated or Transliterated in Different Contexts which focus primarily on name transliteration, because we need different transliterations in d"
P10-1048,koen-2004-pharaoh,0,0.0404474,"ng convention in Urdu. For example (can go ; d ZA s@kt de) is alternathe previous section. Putting (11) and (12) in (10) we get p(hn1 |un1 ) = n Y λpw (hi , ui ) + (1 − λ)pc (hi , ui ) λpw (ui ) + (1 − λ)pc (ui ) (13) The idea is to interpolate joint probabilities and divide them by the interpolated marginals. The final equation for Model-2 is given as: i=1 u ˆn1 = arg max n u1 n Y pLM (ui |ui−1 i−k )× i=1 λpw (hi , ui ) + (1 − λ)pc (hi , ui ) λpw (ui ) + (1 − λ)pc (ui ) 3.3 (14) Search The decoder performs a stack-based search using a beam-search algorithm similar to the one used in Pharoah (Koehn, 2004a). It searches for an Urdu string that maximizes the product of translation probability and the language model probability (equation 1) by translating one Hindi word at a time. It is implemented as a two-level process. At the lower level, it computes n-best transliterations for each Hindi word hi according to pc (h, u). The joint probabilities given by pc (h, u) are marginalized for each Urdu transliteration to give pc (h|u). At the higher level, transliteration probabilities are interpolated with pw (h|u) and then multiplied with language model probabilities to give the probability of a hypo"
P10-1048,W04-3250,0,0.0158741,"ng convention in Urdu. For example (can go ; d ZA s@kt de) is alternathe previous section. Putting (11) and (12) in (10) we get p(hn1 |un1 ) = n Y λpw (hi , ui ) + (1 − λ)pc (hi , ui ) λpw (ui ) + (1 − λ)pc (ui ) (13) The idea is to interpolate joint probabilities and divide them by the interpolated marginals. The final equation for Model-2 is given as: i=1 u ˆn1 = arg max n u1 n Y pLM (ui |ui−1 i−k )× i=1 λpw (hi , ui ) + (1 − λ)pc (hi , ui ) λpw (ui ) + (1 − λ)pc (ui ) 3.3 (14) Search The decoder performs a stack-based search using a beam-search algorithm similar to the one used in Pharoah (Koehn, 2004a). It searches for an Urdu string that maximizes the product of translation probability and the language model probability (equation 1) by translating one Hindi word at a time. It is implemented as a two-level process. At the lower level, it computes n-best transliterations for each Hindi word hi according to pc (h, u). The joint probabilities given by pc (h, u) are marginalized for each Urdu transliteration to give pc (h|u). At the higher level, transliteration probabilities are interpolated with pw (h|u) and then multiplied with language model probabilities to give the probability of a hypo"
P10-1048,N10-1077,1,\N,Missing
P10-1048,P02-1040,0,\N,Missing
P10-1048,P07-2045,0,\N,Missing
P10-1048,J98-4003,0,\N,Missing
P11-1044,W10-2407,0,0.0865748,"Missing"
P11-1044,eisele-chen-2010-multiun,0,0.0441317,"corpora, we apply it to parallel corpora of English/Hindi and English/Arabic, and compare the transliteration mining results with a gold standard. 434 Table 2: Cognates from English/Russian corpus extracted by our system as transliteration pairs. None of them are correct transliteration pairs according to the gold standard. We use the English/Hindi corpus from the shared task on word alignment, organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts (WA05) (Martin et al., 2005). For English/Arabic, we use a freely available parallel corpus from the United Nations (UN) (Eisele and Chen, 2010). We randomly take 200,000 parallel sentences from the UN corpus of the year 2000. We create gold standards for both language pairs by randomly selecting a few thousand word pairs from the lists of word pairs extracted from the two corpora. We manually tag them as either transliterations or non-transliterations. The English/Hindi gold standard contains 180 transliteration pairs and 2084 non-transliteration pairs and the English/Arabic gold standard contains 288 transliteration pairs and 6639 non-transliteration pairs. We have submitted these gold standards with the paper. They are available to"
P11-1044,W08-0509,0,0.0150714,"ation pairs as transliterations (see table 3, last column). Most of these word pairs are close transliterations and differ by only one or two characters from perfect transliteration pairs. The close transliteration pairs provide many valid multigrams which may be helpful for the mining system. 4.3 Integration into Word Alignment Model In the previous section, we presented a method for the extraction of transliteration pairs from a parallel corpus. In this section, we will explain how to build a transliteration module on the extracted transliteration pairs and how to integrate it into MGIZA++ (Gao and Vogel, 2008) by interpolating it with the ttable probabilities of the IBM models and the HMM model. MGIZA++ is an extension of GIZA++. It has the ability to resume training from any model rather than starting with Model1. 4.3.1 Modified EM Training of the Word Alignment Models GIZA++ applies the IBM models (Brown et al., 1993) and the HMM model (Vogel et al., 1996) in both directions, i.e., source to target and target to source. The alignments are refined using the grow-diag-final-and heuristic (Koehn et al., 2003). GIZA++ generates a list of translation pairs with alignment probabilities, which is called"
P11-1044,D09-1024,0,0.039788,"-supervised systems on three language pairs. We are only aware of one previous work which uses transliteration information for word alignment. 6 They use the seed data as positive examples. In order to obtain also negative examples, they generate all possible word pairs from the source and target words in the seed data and extract the ones which are not transliterations but have a common substring of some minimal length. 7 They use the phrase table of Moses to build a mapping table between source and target characters. The mapping table is then used to construct a finite state transducer. 438 Hermjakob (2009) proposed a linguistically focused word alignment system which uses many features including hand-crafted transliteration rules for Arabic/English alignment. His evaluation did not explicitly examine the effect of transliteration (alone) on word alignment. We show that the integration of a transliteration system based on unsupervised transliteration mining increases the word alignment quality for the two language pairs we tested. 6 Conclusion We proposed a method to automatically extract transliteration pairs from parallel corpora without supervision or linguistic knowledge. We evaluated it aga"
P11-1044,W10-2405,0,0.0779976,"the test data and add them to the training data. Our method is different from the method of Sherif and Kondrak (2007) as our method is fully unsupervised, and because in each iteration, they add the most probable transliteration pairs to the training data, while we filter out the least probable transliteration pairs from the training data. The transliteration mining systems of the four NEWS10 participants are either based on discriminative or on generative methods. All systems use manually labelled (seed) data for the initial training. The system based on the edit distance method submitted by Jiampojamarn et al. (2010) performs best for the English/Russian task. Jiampojamarn et al. (2010) submitted another system based on a standard n-gram kernel which ranked first for the English/Hindi and English/Tamil tasks.6 For the English/Arabic task, the transliteration mining system of Noeman and Madkour (2010) was best. They normalize the English and Arabic characters in the training data which increases the recall.7 Our transliteration extraction method differs in that we extract transliteration pairs from a parallel corpus without supervision. The results of the NEWS10 experiments (Kumaran et al., 2010) show that"
P11-1044,P06-1103,0,0.112777,"WA05. Three systems, one limited and two un-limited, participated in the English/Hindi task. We outperform the limited system and one un-limited system. 5 Previous Research Previous work on transliteration mining uses a manually labelled set of training data to extract transliteration pairs from a parallel corpus or comparable corpora. The training data may contain a few hundred randomly selected transliteration pairs from a transliteration dictionary (Yoon et al., 2007; Sproat et al., 2006; Lee and Chang, 2003) or just a few carefully selected transliteration pairs (Sherif and Kondrak, 2007; Klementiev and Roth, 2006). Our work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate transliterations. A lot of work has been done on discovering and learning transliterations from comparable corpora by using temporal and phonetic informat"
P11-1044,N03-1017,0,0.329806,"am models of order > 1 did not work well because these models tended to learn noise (information from non-transliteration pairs) in the training data. For our experiments, we only trained g2p with the unigram model. In test mode, we look for the best sequence of multigrams given a fixed source and target string and return the probability of this sequence. For the mining process, we trained g2p on lists containing both transliteration pairs and nontransliteration pairs. 2.2 Statistical Machine Transliteration System We build a phrase-based MT system for transliteration using the Moses toolkit (Koehn et al., 2003). We also tried using g2p for implementing the transliteration decoder but found Moses to perform better. Moses has the advantage of using Minimum Error Rate Training (MERT) which optimizes transliteration accuracy rather than the likelihood of the training data as g2p does. The training data contains more non-transliteration pairs than transliteration pairs. We don’t want to maximize the likelihood of the non-transliteration pairs. Instead we want to optimize the transliteration performance for test data. Secondly, it is easy to use a large language model (LM) with Moses. We build the LM on t"
P11-1044,W10-2404,0,0.0889357,"Missing"
P11-1044,W03-0317,0,0.0228532,"sion of our word alignment system We compared our word alignment results with the systems presented at WA05. Three systems, one limited and two un-limited, participated in the English/Hindi task. We outperform the limited system and one un-limited system. 5 Previous Research Previous work on transliteration mining uses a manually labelled set of training data to extract transliteration pairs from a parallel corpus or comparable corpora. The training data may contain a few hundred randomly selected transliteration pairs from a transliteration dictionary (Yoon et al., 2007; Sproat et al., 2006; Lee and Chang, 2003) or just a few carefully selected transliteration pairs (Sherif and Kondrak, 2007; Klementiev and Roth, 2006). Our work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate transliterations. A lot of work has been done"
P11-1044,W05-0809,0,0.0389042,"oportion of transliterations than a parallel corpus. In order to examine how well our method performs on parallel corpora, we apply it to parallel corpora of English/Hindi and English/Arabic, and compare the transliteration mining results with a gold standard. 434 Table 2: Cognates from English/Russian corpus extracted by our system as transliteration pairs. None of them are correct transliteration pairs according to the gold standard. We use the English/Hindi corpus from the shared task on word alignment, organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts (WA05) (Martin et al., 2005). For English/Arabic, we use a freely available parallel corpus from the United Nations (UN) (Eisele and Chen, 2010). We randomly take 200,000 parallel sentences from the UN corpus of the year 2000. We create gold standards for both language pairs by randomly selecting a few thousand word pairs from the lists of word pairs extracted from the two corpora. We manually tag them as either transliterations or non-transliterations. The English/Hindi gold standard contains 180 transliteration pairs and 2084 non-transliteration pairs and the English/Arabic gold standard contains 288 transliteration pa"
P11-1044,W10-2408,0,0.0371531,"bable transliteration pairs from the training data. The transliteration mining systems of the four NEWS10 participants are either based on discriminative or on generative methods. All systems use manually labelled (seed) data for the initial training. The system based on the edit distance method submitted by Jiampojamarn et al. (2010) performs best for the English/Russian task. Jiampojamarn et al. (2010) submitted another system based on a standard n-gram kernel which ranked first for the English/Hindi and English/Tamil tasks.6 For the English/Arabic task, the transliteration mining system of Noeman and Madkour (2010) was best. They normalize the English and Arabic characters in the training data which increases the recall.7 Our transliteration extraction method differs in that we extract transliteration pairs from a parallel corpus without supervision. The results of the NEWS10 experiments (Kumaran et al., 2010) show that no single system performs well on all language pairs. Our unsupervised method seems robust as its performance is similar to or better than many of the semi-supervised systems on three language pairs. We are only aware of one previous work which uses transliteration information for word a"
P11-1044,J03-1002,0,0.0209882,"g criterion and return the filtered data set from this iteration. The stopping criterion uses unlabelled held-out data to predict the optimal stopping point. The following sections describe the transliteration mining method in detail. 3.1 Methodology We will first describe the iterative filtering algorithm (Algorithm 1) and then the algorithm for the stopping criterion (Algorithm 2). In practice, we first run Algorithm 2 for 100 iterations to determine the best number of iterations. Then, we run Algorithm 1 for that many iterations. Initially, the parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003), and the alignments are refined using the grow-diag-final-and heuristic (Koehn et al., 2003). We extract all word pairs which occur as 1-to-1 alignments in the word-aligned corpus. We ignore non-1-to-1 alignments because they are less likely to be transliterations for most language pairs. The extracted set of word pairs will be called “list of word pairs” later on. We use the list of word pairs as the training data for Algorithm 1. Algorithm 1 builds a joint sequence model using g2p on the training data and computes the joint probability of all word pairs according to g2p. We normalize the pr"
P11-1044,P07-1109,0,0.223769,"the systems presented at WA05. Three systems, one limited and two un-limited, participated in the English/Hindi task. We outperform the limited system and one un-limited system. 5 Previous Research Previous work on transliteration mining uses a manually labelled set of training data to extract transliteration pairs from a parallel corpus or comparable corpora. The training data may contain a few hundred randomly selected transliteration pairs from a transliteration dictionary (Yoon et al., 2007; Sproat et al., 2006; Lee and Chang, 2003) or just a few carefully selected transliteration pairs (Sherif and Kondrak, 2007; Klementiev and Roth, 2006). Our work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate transliterations. A lot of work has been done on discovering and learning transliterations from comparable corpora by using te"
P11-1044,P06-1010,0,0.0192233,"and Pti is the precision of our word alignment system We compared our word alignment results with the systems presented at WA05. Three systems, one limited and two un-limited, participated in the English/Hindi task. We outperform the limited system and one un-limited system. 5 Previous Research Previous work on transliteration mining uses a manually labelled set of training data to extract transliteration pairs from a parallel corpus or comparable corpora. The training data may contain a few hundred randomly selected transliteration pairs from a transliteration dictionary (Yoon et al., 2007; Sproat et al., 2006; Lee and Chang, 2003) or just a few carefully selected transliteration pairs (Sherif and Kondrak, 2007; Klementiev and Roth, 2006). Our work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate transliterations. A lot"
P11-1044,W06-1630,0,0.179402,"work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate transliterations. A lot of work has been done on discovering and learning transliterations from comparable corpora by using temporal and phonetic information (Tao et al., 2006; Klementiev and Roth, 2006; Sproat et al., 2006). We do not have access to this information. Sherif and Kondrak (2007) train a probabilistic transducer on 14 manually constructed transliteration pairs of English/Arabic. They iteratively extract transliteration pairs from the test data and add them to the training data. Our method is different from the method of Sherif and Kondrak (2007) as our method is fully unsupervised, and because in each iteration, they add the most probable transliteration pairs to the training data, while we filter out the least probable transliteration pairs from the"
P11-1044,C96-2141,0,0.420695,"tion, we presented a method for the extraction of transliteration pairs from a parallel corpus. In this section, we will explain how to build a transliteration module on the extracted transliteration pairs and how to integrate it into MGIZA++ (Gao and Vogel, 2008) by interpolating it with the ttable probabilities of the IBM models and the HMM model. MGIZA++ is an extension of GIZA++. It has the ability to resume training from any model rather than starting with Model1. 4.3.1 Modified EM Training of the Word Alignment Models GIZA++ applies the IBM models (Brown et al., 1993) and the HMM model (Vogel et al., 1996) in both directions, i.e., source to target and target to source. The alignments are refined using the grow-diag-final-and heuristic (Koehn et al., 2003). GIZA++ generates a list of translation pairs with alignment probabilities, which is called the t-table. In this section, we propose a method to modify the translation probabilities of the t-table by interpolating the translation counts with transliteration counts. The interpolation is done in both directions. In the following, we will only consider the e-to-f direction. The transliteration module which is used to calculate the conditional tr"
P11-1044,P07-1015,0,0.0435323,"of baseline GIZA++ and Pti is the precision of our word alignment system We compared our word alignment results with the systems presented at WA05. Three systems, one limited and two un-limited, participated in the English/Hindi task. We outperform the limited system and one un-limited system. 5 Previous Research Previous work on transliteration mining uses a manually labelled set of training data to extract transliteration pairs from a parallel corpus or comparable corpora. The training data may contain a few hundred randomly selected transliteration pairs from a transliteration dictionary (Yoon et al., 2007; Sproat et al., 2006; Lee and Chang, 2003) or just a few carefully selected transliteration pairs (Sherif and Kondrak, 2007; Klementiev and Roth, 2006). Our work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate tr"
P11-1044,J93-2003,0,\N,Missing
P11-1105,J93-2003,0,0.0466104,"near order. The generation of the second (and subsequent) German word in a multi-word cept can be delayed by gaps, jumps and the Generate Source Only operation defined below. Continue Source Cept: The German words added 2 However, Crego and Yvon (2009), in their N-gram system, use split rules to handle target-side gaps and show a slight improvement on a Chinese-English translation task. 3 Generating the English words in order is also what the decoder does when translating from German to English. 4 A cept is a group of words in one language translated as a minimal unit in one specific context (Brown et al., 1993). to the queue by the Generate (X,Y) operation are generated by the Continue Source Cept operation. Each Continue Source Cept operation removes one German word from the queue and copies it to the German string. If X contains more than one German word, say n many, then it requires n translation operations, an initial Generate (X1 ...Xn , Y ) operation and n − 1 Continue Source Cept operations. For example “hat...gelesen – read” is generated by the operation Generate (hat gelesen, read), which adds “hat” and “read” to the German and English strings and “gelesen” to a queue. A Continue Source Cep"
P11-1105,J07-2003,0,0.0818341,"n continuous phrases. Given the phrase inventory in Table 1, phrasal MT is able to generate example in Figure 1(a). The information “hat...gelesen – read” is internal to the phrase pair “hat er ein buch gelesen – he read a book”, and is therefore handled conveniently. On the other hand, the phrase table does not have the entry “hat er eine zeitung gelesen – he read a newspaper” (Figure 1(b)). Hence, there is no option but to translate “hat...gelesen” separately, translating “hat” to “has” which is a common translation for “hat” but wrong in the given context. Context-free hierarchical models (Chiang, 2007; Melamed, 2004) have rules like “hat er X gelesen – he read X” to handle such cases. Galley and Manning (2010) recently solved this problem for phrasal MT by extracting phrase pairs with source and target-side gaps. Our model can also use tuples with source-side discontinuities. The above sentence would be generated by the following sequence of operations: (i) generate “dann – then” (ii) insert a gap (iii) generate “er – he” (iv) backward jump to the gap (v) generate “hat...[gelesen] – read” (only “hat” and “read” are added to the sentences yet) (vi) jump forward to the right-most source word"
P11-1105,2009.eamt-1.10,0,0.0357915,"r discontinuous, but the words in Y (English) must be consecutive. This operation causes the words in Y and the first word in X to be added to the English and German strings respectively, that were generated so far. Subsequent words in X are added to a queue to be generated later. All the English words in Y are generated immediately because English is generated in linear order. The generation of the second (and subsequent) German word in a multi-word cept can be delayed by gaps, jumps and the Generate Source Only operation defined below. Continue Source Cept: The German words added 2 However, Crego and Yvon (2009), in their N-gram system, use split rules to handle target-side gaps and show a slight improvement on a Chinese-English translation task. 3 Generating the English words in order is also what the decoder does when translating from German to English. 4 A cept is a group of words in one language translated as a minimal unit in one specific context (Brown et al., 1993). to the queue by the Generate (X,Y) operation are generated by the Continue Source Cept operation. Each Continue Source Cept operation removes one German word from the queue and copies it to the German string. If X contains more tha"
P11-1105,C10-2023,0,0.0911957,"ing of translation context (Crego et al., 2005a). The tuples used in N-gram systems are much smaller translation units than phrases and are extracted in such a way that a unique segmentation of each bilingual sentence pair is produced. This helps N-gram systems to avoid the spurious phrasal segmentation problem. Reordering works by linearization of the source side and tuple unfolding (Crego et al., 2005b). The decoder uses word lattices which are built with linguistically motivated re-write rules. This mechanism is further enhanced with an N-gram model of bilingual units built using POS tags (Crego and Yvon, 2010). A drawback of their reordering approach is that search is only performed on a small number of reorderings that are pre-calculated on the source side independently of the target side. Often, the evidence for the correct ordering is provided by the target-side language model (LM). In the N-gram approach, the LM only plays a role in selecting between the precalculated orderings. Our model is based on the N-gram SMT model, but differs from previous N-gram systems in some important aspects. It uses operation n-grams rather than tuple n-grams. The reordering approach is entirely different and cons"
P11-1105,2005.iwslt-1.23,0,0.0188713,"hrasal MT is spurious phrasal segmentation. Given a sentence pair and a corresponding word alignment, phrasal MT can learn an arbitrary number of source segmentations. This is problematic during decoding because different compositions of the same minimal phrasal units are allowed to compete with each other. 2.2 Relation of our work to N-gram SMT N-gram based SMT is an alternative to hierarchical and non-hierarchical phrase-based systems. The main difference between phrase-based and N-gram SMT is the extraction procedure of translation units and the statistical modeling of translation context (Crego et al., 2005a). The tuples used in N-gram systems are much smaller translation units than phrases and are extracted in such a way that a unique segmentation of each bilingual sentence pair is produced. This helps N-gram systems to avoid the spurious phrasal segmentation problem. Reordering works by linearization of the source side and tuple unfolding (Crego et al., 2005b). The decoder uses word lattices which are built with linguistically motivated re-write rules. This mechanism is further enhanced with an N-gram model of bilingual units built using POS tags (Crego and Yvon, 2010). A drawback of their reo"
P11-1105,2005.mtsummit-papers.37,0,0.178798,"Missing"
P11-1105,N10-1140,0,0.215417,"e in Figure 1(a). The information “hat...gelesen – read” is internal to the phrase pair “hat er ein buch gelesen – he read a book”, and is therefore handled conveniently. On the other hand, the phrase table does not have the entry “hat er eine zeitung gelesen – he read a newspaper” (Figure 1(b)). Hence, there is no option but to translate “hat...gelesen” separately, translating “hat” to “has” which is a common translation for “hat” but wrong in the given context. Context-free hierarchical models (Chiang, 2007; Melamed, 2004) have rules like “hat er X gelesen – he read X” to handle such cases. Galley and Manning (2010) recently solved this problem for phrasal MT by extracting phrase pairs with source and target-side gaps. Our model can also use tuples with source-side discontinuities. The above sentence would be generated by the following sequence of operations: (i) generate “dann – then” (ii) insert a gap (iii) generate “er – he” (iv) backward jump to the gap (v) generate “hat...[gelesen] – read” (only “hat” and “read” are added to the sentences yet) (vi) jump forward to the right-most source word so far generated (vii) insert a gap (viii) continue the source cept (“gelesen” is inserted now) (ix) backward"
P11-1105,N03-1017,0,0.0592803,"and Generate Source Only. For a source cept coverd by indexes X1 , . . . , Xn , we get the feature value gj = X1 − S, where S is the index of the left-most source word where a gap starts. 8 Let X1 , . . . , Xn and Y1 , . . . , Ym represent indexes of the source words covered by the tuples tj and tj−1 respectively. The distance between tj and tj−1 is given as dj = min(|Xk − Yl |− 1) ∀ Xk ∈ {X1 , . . . , Xn } and ∀ Yl ∈ {Y1 , . . . , Ym } 1050 Lexical Features We also use source-to-target p(e|f ) and target-to-source p(f |e) lexical translation probabilities. Our lexical features are standard (Koehn et al., 2003). The estimation is motivated by IBM Model-1. Given a tuple ti with source words f = f1 , f2 , . . . , fn , target words e = e1 , e2 , . . . , em and an alignment a between the source word positions x = 1, . . . , n and the target word positions y = 1, . . . , m, the lexical feature pw (f |e) is computed as follows: n Y X 1 pw (f |e, a) = w(fx |ey ) |{y : (x, y) ∈ a}| x=1 ∀(x,y)∈a pw (e|f, a) is computed in the same way. 5 Decoding Our decoder for the new model performs a stackbased search with a beam-search algorithm similar to that used in Pharoah (Koehn, 2004a). Given an input sentence F ,"
P11-1105,2005.iwslt-1.8,0,0.0973201,"system on three data sets with German-to-English, Spanish-to-English and Frenchto-English news translations, respectively. We used data from the 4th version of the Europarl Corpus and the News Commentary which was made available for the translation task of the Fourth Workshop on Statistical Machine Translation.11 We use 200K bilingual sentences, composed by concatenating the entire news commentary (≈ 74K sentences) and Europarl (≈ 126K sentence), for the estimation of the translation model. Word alignments were generated with GIZA++ (Och and Ney, 2003), using the growdiag-final-and heuristic (Koehn et al., 2005). In order to obtain the best alignment quality, the alignment task is performed on the entire parallel data and not just on the training data we use. All data is lowercased, and we use the Moses tokenizer and recapitalizer. Our monolingual language model is trained on 500K sentences. These comprise 300K sentences from the monolingual corpus (news commentary) and 200K sentences from the target-side part of the bilingual corpus. The latter part is also used to train the prior probability model. The dev and test sets are news-dev2009a and news-dev2009b which contain 1025 and 1026 parallel senten"
P11-1105,koen-2004-pharaoh,0,0.0331812,"features are standard (Koehn et al., 2003). The estimation is motivated by IBM Model-1. Given a tuple ti with source words f = f1 , f2 , . . . , fn , target words e = e1 , e2 , . . . , em and an alignment a between the source word positions x = 1, . . . , n and the target word positions y = 1, . . . , m, the lexical feature pw (f |e) is computed as follows: n Y X 1 pw (f |e, a) = w(fx |ey ) |{y : (x, y) ∈ a}| x=1 ∀(x,y)∈a pw (e|f, a) is computed in the same way. 5 Decoding Our decoder for the new model performs a stackbased search with a beam-search algorithm similar to that used in Pharoah (Koehn, 2004a). Given an input sentence F , it first extracts a set of matching source-side cepts along with their n-best translations to form a tuple inventory. During hypothesis expansion, the decoder picks a tuple from the inventory and generates the sequence of operations required for the translation with this tuple in light of the previous hypothesis.9 The sequence of operations may include translation (generate, continue source cept etc.) and reordering (gap insertions, jumps) operations. The decoder also calculates the overall cost of the new hypothesis. Recombination is performed on hypotheses hav"
P11-1105,W04-3250,0,0.24088,"features are standard (Koehn et al., 2003). The estimation is motivated by IBM Model-1. Given a tuple ti with source words f = f1 , f2 , . . . , fn , target words e = e1 , e2 , . . . , em and an alignment a between the source word positions x = 1, . . . , n and the target word positions y = 1, . . . , m, the lexical feature pw (f |e) is computed as follows: n Y X 1 pw (f |e, a) = w(fx |ey ) |{y : (x, y) ∈ a}| x=1 ∀(x,y)∈a pw (e|f, a) is computed in the same way. 5 Decoding Our decoder for the new model performs a stackbased search with a beam-search algorithm similar to that used in Pharoah (Koehn, 2004a). Given an input sentence F , it first extracts a set of matching source-side cepts along with their n-best translations to form a tuple inventory. During hypothesis expansion, the decoder picks a tuple from the inventory and generates the sequence of operations required for the translation with this tuple in light of the previous hypothesis.9 The sequence of operations may include translation (generate, continue source cept etc.) and reordering (gap insertions, jumps) operations. The decoder also calculates the overall cost of the new hypothesis. Recombination is performed on hypotheses hav"
P11-1105,W09-0424,0,0.0505208,"enon more directly by means of tuples with source-side discon1047 tinuities. The most notable feature of our work is that it has a complete generative story of translation which combines translation and reordering operations into a single operation sequence model. Like the N-gram model2 , our model cannot deal with target-side discontinuities. These are eliminated from the training data by a post-editing process on the alignments (see Section 6). Galley and Manning (2010) found that target-side gaps were not useful in their system and not useful in the hierarchical phrase-based system Joshua (Li et al., 2009). 3 Generative Story Our generative story is motivated by the complex reorderings in the German-to-English translation task. The German and English sentences are jointly generated through a sequence of operations. The English words are generated in linear order3 while the German words are generated in parallel with their English translations. Occasionally the translator jumps back on the German side to insert some material at an earlier position. After this is done, it jumps forward again and continues the translation. The backward jumps always end at designated landing sites (gaps) which were"
P11-1105,J06-4004,0,0.19283,"Missing"
P11-1105,P04-1083,0,0.0444978,"hrases. Given the phrase inventory in Table 1, phrasal MT is able to generate example in Figure 1(a). The information “hat...gelesen – read” is internal to the phrase pair “hat er ein buch gelesen – he read a book”, and is therefore handled conveniently. On the other hand, the phrase table does not have the entry “hat er eine zeitung gelesen – he read a newspaper” (Figure 1(b)). Hence, there is no option but to translate “hat...gelesen” separately, translating “hat” to “has” which is a common translation for “hat” but wrong in the given context. Context-free hierarchical models (Chiang, 2007; Melamed, 2004) have rules like “hat er X gelesen – he read X” to handle such cases. Galley and Manning (2010) recently solved this problem for phrasal MT by extracting phrase pairs with source and target-side gaps. Our model can also use tuples with source-side discontinuities. The above sentence would be generated by the following sequence of operations: (i) generate “dann – then” (ii) insert a gap (iii) generate “er – he” (iv) backward jump to the gap (v) generate “hat...[gelesen] – read” (only “hat” and “read” are added to the sentences yet) (vi) jump forward to the right-most source word so far generate"
P11-1105,J03-1002,0,0.0254667,"k papers. 1051 Experimental Setup 7.1 Data We evaluated the system on three data sets with German-to-English, Spanish-to-English and Frenchto-English news translations, respectively. We used data from the 4th version of the Europarl Corpus and the News Commentary which was made available for the translation task of the Fourth Workshop on Statistical Machine Translation.11 We use 200K bilingual sentences, composed by concatenating the entire news commentary (≈ 74K sentences) and Europarl (≈ 126K sentence), for the estimation of the translation model. Word alignments were generated with GIZA++ (Och and Ney, 2003), using the growdiag-final-and heuristic (Koehn et al., 2005). In order to obtain the best alignment quality, the alignment task is performed on the entire parallel data and not just on the training data we use. All data is lowercased, and we use the Moses tokenizer and recapitalizer. Our monolingual language model is trained on 500K sentences. These comprise 300K sentences from the monolingual corpus (news commentary) and 200K sentences from the target-side part of the bilingual corpus. The latter part is also used to train the prior probability model. The dev and test sets are news-dev2009a"
P11-1105,J04-4002,0,0.0487591,"to marginalize the joint-probability model p(F, E). The search is then redefined as: ˆ = arg max pLM (E) p(F, E) E E ppr (E) Both, the monolingual language and the prior probability model are implemented as standard word-based n-gram models: J Y px (E) ≈ p(wj |wj−m+1 , . . . , wj−1 ) j=1 where m = 4 (5-gram model) for the standard monolingual model (x = LM ) and m = 8 (same as the operation model5 ) for the prior probability model (x = pr). In order to improve end-to-end accuracy, we introduce new features for our model and shift from the generative6 model to the standard log-linear approach (Och and Ney, 2004) to tune7 them. We search for a target string E which maximizes a linear combination of feature functions: 5 In decoding, the amount of context used for the prior probability is synchronized with the position of back-off in the operation model. 6 Our generative model is about 3 BLEU points worse than the best discriminative results. 7 We tune the operation, monolingual and prior probability models as separate features. We expect the prior probability model to get a negative weight but we do not force MERT to assign a negative weight to this feature. ˆ = arg max E E  J X  j=1   λj hj (F, E"
P11-1105,P02-1040,0,0.100978,"ecapitalizer. Our monolingual language model is trained on 500K sentences. These comprise 300K sentences from the monolingual corpus (news commentary) and 200K sentences from the target-side part of the bilingual corpus. The latter part is also used to train the prior probability model. The dev and test sets are news-dev2009a and news-dev2009b which contain 1025 and 1026 parallel sentences. The feature weights are tuned with Z-MERT (Zaidan, 2009). 7.2 Results Baseline: We compare our model to a recent version of Moses (Koehn et al., 2007) using Koehn’s training scripts and evaluate with BLEU (Papineni et al., 2002). We provide Moses with the same initial alignments as we are using to train our system.12 We use the default parameters for Moses, and a 5gram English language model (the same as in our system). We compare two variants of our system. The first system (T wno−rl ) applies no hard reordering limit and uses the distortion and gap distance penalty features as soft constraints, allowing all possible reorderings. The second system (T wrl−6 ) uses no distortion and gap distance features, but applies a hard constraint which limits reordering to no more than 6 11 http://www.statmt.org/wmt09/translation"
P11-1105,W09-0429,0,\N,Missing
P11-1105,P07-2045,0,\N,Missing
P12-1049,eisele-chen-2010-multiun,0,0.0346249,"Missing"
P12-1049,W10-2405,0,0.0874072,"led the “seed data”) for initial training. All systems which participated in the NEWS10 shared task are either supervised or semi-supervised. They are described in (Kumaran et al., 2010a). Our transliteration mining model can mine transliterations without using any labelled data. However, if there is some labelled data available, our system is able to use it effectively. The transliteration mining systems evaluated on the NEWS10 dataset generally used heuristic methods, discriminative models or generative models for transliteration mining (Kumaran et al., 2010a). The heuristic-based system of Jiampojamarn et al. (2010) is based on the edit distance method which scores the similarity between source and target words. They presented two discriminative methods – an SVM-based classifier and alignment-based string similarity for transliteration mining. These methods model the conditional probability distribution and require supervised/semi-supervised information for learning. We propose a flexible generative model for transliteration mining usable for both unsupervised and semi-supervised learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al.,"
P12-1049,N03-1017,0,0.0184368,"ikipedia pages written in different languages, which may be transliterations or translations. The seed data is a list of 1000 transliteration pairs provided to semi-supervised systems for initial training. We use the seed data only in our semi-supervised system, and not in the unsupervised system. The reference data is a small subset of the training data which is manually annotated with positive and negative examples. 5.1.1 Training We word-aligned the parallel phrases of the training data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using the grow-diagfinal-and heuristic (Koehn et al., 2003). We extract all word pairs which occur as 1-to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the word-aligned list. We compared the word-aligned list with the NEWS10 reference data and found that the word-aligned list is missing some transliteration pairs because of word-alignment errors. We built another list by adding a word pair for every source word that cooccurs with a target word in a parallel phrase/sentence and call it the cross-product list later on. The cross-product list is noisier but contains almost all transliteration pairs in the corpus. 473 EA EH ET ER 27"
P12-1049,P04-1021,0,0.212852,"Missing"
P12-1049,W05-0809,0,0.0377036,"Missing"
P12-1049,W10-2412,0,0.0242759,"uristic-based system of Jiampojamarn et al. (2010) is based on the edit distance method which scores the similarity between source and target words. They presented two discriminative methods – an SVM-based classifier and alignment-based string similarity for transliteration mining. These methods model the conditional probability distribution and require supervised/semi-supervised information for learning. We propose a flexible generative model for transliteration mining usable for both unsupervised and semi-supervised learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al., 2010), Finite State Automata (Noeman and Madkour, 2010) and Bayesian learning (Kahki et al., 2011) to learn transliteration pairs from labelled data. Our method is different from theirs as our generative story explains the unlabelled data using a combination of a transliteration and a non-transliteration sub-model. The transliteration model jointly generates source and target 470 strings, whereas the non-transliteration system generates them independently of each other. Sajjad et al. (2011) proposed a heuristic-based unsupervised transliteration mining sys"
P12-1049,R11-1053,0,0.0189504,"ases. This assumption is not followed for certain phrases like ”New York” and ”New Mexico”. EA EH ET ER Unsupervised SJD OU Semi-supervised/Supervised OS SBest GR DBN 87.4 92.2 90.1 76.0 92.7 96.3 94.6 83.1 92.4 95.7 93.2 79.4 91.5 94.4 91.4 87.5 94.1 93.2 95.5 92.3 95.5 93.9 82.5 Table 2: F-measure results on NEWS10 datasets where SJD is the unsupervised system of Sajjad11, OU is our unsupervised system built on the cross-product list, OS is our semi-supervised system, SBest is the best NEWS10 system, GR is the supervised system of Kahki et al. (2011) and DBN is the semi-supervised system of Nabende (2011) Our unsupervised mining system built on the cross-product list consistently outperforms the one built on the word-aligned list. Later, we consider only the system built on the cross-product list. Table 2 shows the results of our unsupervised system OU in comparison with the unsupervised system of Sajjad11 (SJD), the best semi-supervised systems presented at NEWS10 (SBEST ) and the best semi-supervised results reported on the NEWS10 dataset (GR, DBN ). On three language pairs, our unsupervised system performs better than all semisupervised systems which participated in NEWS10. It has competiti"
P12-1049,W10-2408,0,0.0248795,"method which scores the similarity between source and target words. They presented two discriminative methods – an SVM-based classifier and alignment-based string similarity for transliteration mining. These methods model the conditional probability distribution and require supervised/semi-supervised information for learning. We propose a flexible generative model for transliteration mining usable for both unsupervised and semi-supervised learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al., 2010), Finite State Automata (Noeman and Madkour, 2010) and Bayesian learning (Kahki et al., 2011) to learn transliteration pairs from labelled data. Our method is different from theirs as our generative story explains the unlabelled data using a combination of a transliteration and a non-transliteration sub-model. The transliteration model jointly generates source and target 470 strings, whereas the non-transliteration system generates them independently of each other. Sajjad et al. (2011) proposed a heuristic-based unsupervised transliteration mining system. We later call it Sajjad11. It is the only unsupervised mining system that was evaluated"
P12-1049,J03-1002,0,0.0287122,"ta, seed data and reference data. The NEWS10 data consists of pairs of titles of the same Wikipedia pages written in different languages, which may be transliterations or translations. The seed data is a list of 1000 transliteration pairs provided to semi-supervised systems for initial training. We use the seed data only in our semi-supervised system, and not in the unsupervised system. The reference data is a small subset of the training data which is manually annotated with positive and negative examples. 5.1.1 Training We word-aligned the parallel phrases of the training data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using the grow-diagfinal-and heuristic (Koehn et al., 2003). We extract all word pairs which occur as 1-to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the word-aligned list. We compared the word-aligned list with the NEWS10 reference data and found that the word-aligned list is missing some transliteration pairs because of word-alignment errors. We built another list by adding a word pair for every source word that cooccurs with a target word in a parallel phrase/sentence and call it the cross-product list later on. The cross-product lis"
P12-1049,P11-1044,1,0.89978,"arning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al., 2010), Finite State Automata (Noeman and Madkour, 2010) and Bayesian learning (Kahki et al., 2011) to learn transliteration pairs from labelled data. Our method is different from theirs as our generative story explains the unlabelled data using a combination of a transliteration and a non-transliteration sub-model. The transliteration model jointly generates source and target 470 strings, whereas the non-transliteration system generates them independently of each other. Sajjad et al. (2011) proposed a heuristic-based unsupervised transliteration mining system. We later call it Sajjad11. It is the only unsupervised mining system that was evaluated on the NEWS10 dataset up until now, as far as we know. That system is computationally expensive. We show in Section 5 that its runtime is much higher than that of our system. In this paper, we propose a novel model-based approach to transliteration mining. Our approach is language pair independent – at least for alphabetic languages – and efficient. Unlike the previous unsupervised system, and unlike the supervised and semi-supervised s"
P12-1049,W10-2407,0,\N,Missing
P12-1049,D11-1128,0,\N,Missing
P12-1049,W10-2403,0,\N,Missing
P12-1049,W10-2404,0,\N,Missing
P13-2071,N12-1047,0,0.023851,"sed 402 No. 1. 2. 3. 4. 5. System Baseline 1+pp 1+pp+tsm 1+pp+osm 1+osm* fr-en 31.89 31.87 31.94 32.17 32.13 es-en 35.07 35.09 35.25 35.50 35.65 cs-en 23.88 23.64 23.85 24.14 24.23 ru-en 33.45 33.04 32.97 33.21 33.91 en-fr 29.89 29.70 29.98 30.35 30.54 en-es 35.03 35.00 35.06 35.34 35.49 en-cs 16.22 16.17 16.30 16.49 16.62 en-ru 23.88 24.05 23.96 24.22 24.25 Table 2: Translating into and from English. Bold: Statistically Significant (Koehn, 2004) w.r.t Baseline 5 the first half for tuning and second for test. We test our systems on news-test 2012. We tune with the k-best batch MIRA algorithm (Cherry and Foster, 2012). Conclusion and Future Work We have addressed the problem of the independence assumption in PBSMT by integrating Ngram-based models inside a phrase-based system using a log-linear framework. We try to replicate the effect of rewrite and split rules as used in the TSM model through phrasal alignments. We presented a novel extension of the OSM model to handle unaligned and discontinuous target MTUs in the OSM model. Phrase-based search helps us to address these problems that are non-trivial to handle in the decoding frameworks of the N-grambased models. We tested our extentions and modification"
P13-2071,2012.iwslt-papers.17,1,0.551072,"continous phrases. The discontinuous MTUs that span beyond a phrasal length of 6 words are therefore never hypothesized. We would like to explore this further by extending the search to use discontinuous phrases (Galley and Manning, 2010). Moses Baseline: We trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row 2 (+pp) shows that the post-editing of alignments to remove unaligned and discontinuous target MTUs decreases the performance in the case of ru-en, csen and en-fr. Row 3 (+pp+tsm) shows that our integration of the TSM model slightly improves the BLEU scores for en-fr, and es-en. Results drop in ru-en and en-ru. Row"
P13-2071,N07-2035,0,0.16661,"Missing"
P13-2071,W11-2123,0,0.0901439,"s to the OSM model enables discontinuous MTUs, we did not fully utilize these during decoding, as Moses only uses continous phrases. The discontinuous MTUs that span beyond a phrasal length of 6 words are therefore never hypothesized. We would like to explore this further by extending the search to use discontinuous phrases (Galley and Manning, 2010). Moses Baseline: We trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row 2 (+pp) shows that the post-editing of alignments to remove unaligned and discontinuous target MTUs decreases the performance in the case of ru-en, csen and en-fr. Row 3 (+pp+tsm) shows that our int"
P13-2071,P07-1019,0,0.372958,"ore this further by extending the search to use discontinuous phrases (Galley and Manning, 2010). Moses Baseline: We trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row 2 (+pp) shows that the post-editing of alignments to remove unaligned and discontinuous target MTUs decreases the performance in the case of ru-en, csen and en-fr. Row 3 (+pp+tsm) shows that our integration of the TSM model slightly improves the BLEU scores for en-fr, and es-en. Results drop in ru-en and en-ru. Row 4 (+pp+osm) shows that the OSM model consistently improves the BLEU scores over the Baseline systems (Row 1) giving significant improvements in h"
P13-2071,2009.eamt-1.10,0,0.0260482,"ave ignored so far are the handling of MTUs which have discontinuous targets, and the handling of unaligned target words. Both TSM and OSM N-gram models generate MTUs linearly in left-to-right order. This assumption becomes problematic in the cases of MTUs that have target-side discontinuities (See Figure 2(a)). The MTU A → g . . . a can not be generated because of the intervening MTUs B → b, C . . . H → c and D → d. In the original TSM model, such cases are dealt with by merging all the intervening MTUs to form a bigger unit t01 in Figure 2(c). A solution that uses split-rules is proposed by Crego and Yvon (2009) but has not been adopted in Ncode (Crego et al., 2011), the state-of-the-art TSM Ngram system. Durrani et al. (2011) dealt with this problem by applying a post-processing (PP) heuristic that modifies the alignments to remove such cases. When a source word is aligned to a discontinuous target-cept, first the link to the least frequent target word is identified, and the group of links containing this word is retained while the others are deleted. The alignment in Figure 2(a), for example, is transformed to that in Figure 2(b). This allows OSM to extract the intervening MTUs t2 . . . t5 (Figure"
P13-2071,E09-1049,0,0.0142488,"-gram-based system. However, they do not use phrase-based models in their work, relying only on the OSM model. This paper combines insights from these recent pieces of work and show that phrase-based search combined with N-gram-based and phrase-based models in decoding is the overall best way to go. We integrate the two N-grambased models, TSM and OSM, into phrase-based Moses and show that the translation quality is improved by taking both translation and reordering context into account. Other approaches that explored such models in syntax-based systems used MTUs for sentence level reranking (Khalilov and Fonollosa, 2009), in dependency translation models (Quirk and Menezes, 2006) and in target language syntax systems (Vaswani et al., 2011). 3 Figure 1: Example (a) Word Alignments (b) Unfolded MTU Sequence (c) Operation Sequence (d) Step-wise Generation tem. Given a bilingual sentence pair (F, E) and its alignment (A), we first identify minimal translation units (MTUs) from it. An MTU is defined as a translation rule that cannot be broken down any further. The MTUs extracted from Figure 1(a) are A → a, B → b, C . . . H → c1 and D → d. These units are then generated left-to-right in two different ways, as we wi"
P13-2071,C10-2023,0,0.141203,"se399 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 399–405, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics baseline system, and shows statistically significant improvements in seven out of eight cases. 2 Previous Work Several researchers have tried to combine the ideas of phrase-based and N-gram-based SMT. Costajuss`a et al. (2007) proposed a method for combining the two approaches by applying sentence level reranking. Feng et al. (2010) added a linearized source-side language model in a phrase-based system. Crego and Yvon (2010) modified the phrasebased lexical reordering model of Tillman (2004) for an N-gram-based system. Niehues et al. (2011) integrated a bilingual language model based on surface word forms and POS tags into a phrasebased system. Zhang et al. (2013) explored multiple decomposition structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation wh"
P13-2071,W12-3139,1,0.843905,"y the decoder to arbitrarily generate unaligned MTUs but hypothesize these only when they appear within Parallel ≈39 M ≈15.6 M ≈15.2 M ≈2 M Monolingual ≈91 M ≈43.4 M ≈65.7 M ≈21.7 M ≈287.3 M Lang fr cs es ru en Table 1: Number of Sentences (in Millions) used for Training We follow the approach of Schwenk and Koehn (2008) and trained domain-specific language models separately and then linearly interpolated them using SRILM with weights optimized on the heldout dev-set. We concatenated the news-test sets from four years (2008-2011) to obtain a large devsetin order to obtain more stable weights (Koehn and Haddow, 2012). For Russian-English and English-Russian language pairs, we divided the tuning-set news-test 2012 into two halves and used 402 No. 1. 2. 3. 4. 5. System Baseline 1+pp 1+pp+tsm 1+pp+osm 1+osm* fr-en 31.89 31.87 31.94 32.17 32.13 es-en 35.07 35.09 35.25 35.50 35.65 cs-en 23.88 23.64 23.85 24.14 24.23 ru-en 33.45 33.04 32.97 33.21 33.91 en-fr 29.89 29.70 29.98 30.35 30.54 en-es 35.03 35.00 35.06 35.34 35.49 en-cs 16.22 16.17 16.30 16.49 16.62 en-ru 23.88 24.05 23.96 24.22 24.25 Table 2: Translating into and from English. Bold: Statistically Significant (Koehn, 2004) w.r.t Baseline 5 the first ha"
P13-2071,P11-1105,1,0.732808,"for an N-gram-based system. Niehues et al. (2011) integrated a bilingual language model based on surface word forms and POS tags into a phrasebased system. Zhang et al. (2013) explored multiple decomposition structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation which restricts the search to a small set of precomputed reorderings. Durrani et al. (2011) addressed this problem by coupling lexical generation and reordering information into a single generative process and enriching the N-gram models to learn lexical reordering triggers. Durrani et al. (2013) showed that using larger phrasal units during decoding is superior to MTU-based decoding in an N-gram-based system. However, they do not use phrase-based models in their work, relying only on the OSM model. This paper combines insights from these recent pieces of work and show that phrase-based search combined with N-gram-based and phrase-based models in decoding is the overall best way to"
P13-2071,N03-1017,1,0.0357267,"model that captures dependencies across phrasal boundaries. Some work has been done to combine insights from these two frameworks. A recent successful attempt showed the advantage of using phrasebased search on top of an N-gram-based model. We probe this question in the reverse direction by investigating whether integrating N-gram-based translation and reordering models into a phrase-based decoder helps overcome the problematic phrasal independence assumption. A large scale evaluation over 8 language pairs shows that performance does significantly improve. 1 Introduction Phrase-based models (Koehn et al., 2003; Och and Ney, 2004) learn local dependencies such as reorderings, idiomatic collocations, deletions and insertions by memorization. A fundamental drawback is that phrases are translated and reordered independently of each other and contextual information outside of phrasal boundaries is ignored. The monolingual language model somewhat reduces this problem. However i) often the language model cannot overcome the dispreference of the translation model for nonlocal dependencies, ii) source-side contextual dependencies are still ignored and iii) generation of lexical translations and reordering i"
P13-2071,N13-1001,1,0.531868,"on structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation which restricts the search to a small set of precomputed reorderings. Durrani et al. (2011) addressed this problem by coupling lexical generation and reordering information into a single generative process and enriching the N-gram models to learn lexical reordering triggers. Durrani et al. (2013) showed that using larger phrasal units during decoding is superior to MTU-based decoding in an N-gram-based system. However, they do not use phrase-based models in their work, relying only on the OSM model. This paper combines insights from these recent pieces of work and show that phrase-based search combined with N-gram-based and phrase-based models in decoding is the overall best way to go. We integrate the two N-grambased models, TSM and OSM, into phrase-based Moses and show that the translation quality is improved by taking both translation and reordering context into account. Other appr"
P13-2071,P07-2045,1,0.0139628,"deration consistently improves the performance of the baseline system. Our modification to the OSM model produces the best results giving significant improvements in most cases. Although our modifications to the OSM model enables discontinuous MTUs, we did not fully utilize these during decoding, as Moses only uses continous phrases. The discontinuous MTUs that span beyond a phrasal length of 6 words are therefore never hypothesized. We would like to explore this further by extending the search to use discontinuous phrases (Galley and Manning, 2010). Moses Baseline: We trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row"
P13-2071,2010.amta-papers.22,0,0.288871,"Missing"
P13-2071,W04-3250,1,0.53813,"Missing"
P13-2071,N04-1022,0,0.483452,"er hypothesized. We would like to explore this further by extending the search to use discontinuous phrases (Galley and Manning, 2010). Moses Baseline: We trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row 2 (+pp) shows that the post-editing of alignments to remove unaligned and discontinuous target MTUs decreases the performance in the case of ru-en, csen and en-fr. Row 3 (+pp+tsm) shows that our integration of the TSM model slightly improves the BLEU scores for en-fr, and es-en. Results drop in ru-en and en-ru. Row 4 (+pp+osm) shows that the OSM model consistently improves the BLEU scores over the Baseline systems (Row"
P13-2071,W11-2124,0,0.0307268,"Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics baseline system, and shows statistically significant improvements in seven out of eight cases. 2 Previous Work Several researchers have tried to combine the ideas of phrase-based and N-gram-based SMT. Costajuss`a et al. (2007) proposed a method for combining the two approaches by applying sentence level reranking. Feng et al. (2010) added a linearized source-side language model in a phrase-based system. Crego and Yvon (2010) modified the phrasebased lexical reordering model of Tillman (2004) for an N-gram-based system. Niehues et al. (2011) integrated a bilingual language model based on surface word forms and POS tags into a phrasebased system. Zhang et al. (2013) explored multiple decomposition structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation which restricts the search to a small set of precomputed reorderings. Durrani et al. (2011) addressed this problem by co"
P13-2071,J04-4002,0,0.11205,"dependencies across phrasal boundaries. Some work has been done to combine insights from these two frameworks. A recent successful attempt showed the advantage of using phrasebased search on top of an N-gram-based model. We probe this question in the reverse direction by investigating whether integrating N-gram-based translation and reordering models into a phrase-based decoder helps overcome the problematic phrasal independence assumption. A large scale evaluation over 8 language pairs shows that performance does significantly improve. 1 Introduction Phrase-based models (Koehn et al., 2003; Och and Ney, 2004) learn local dependencies such as reorderings, idiomatic collocations, deletions and insertions by memorization. A fundamental drawback is that phrases are translated and reordered independently of each other and contextual information outside of phrasal boundaries is ignored. The monolingual language model somewhat reduces this problem. However i) often the language model cannot overcome the dispreference of the translation model for nonlocal dependencies, ii) source-side contextual dependencies are still ignored and iii) generation of lexical translations and reordering is separated. The N-g"
P13-2071,P02-1040,0,0.106262,"trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row 2 (+pp) shows that the post-editing of alignments to remove unaligned and discontinuous target MTUs decreases the performance in the case of ru-en, csen and en-fr. Row 3 (+pp+tsm) shows that our integration of the TSM model slightly improves the BLEU scores for en-fr, and es-en. Results drop in ru-en and en-ru. Row 4 (+pp+osm) shows that the OSM model consistently improves the BLEU scores over the Baseline systems (Row 1) giving significant improvements in half the cases. The only result that is lower than the baseline system is that of the ru-en experiment, because OSM i"
P13-2071,N06-1002,0,0.0506902,"in their work, relying only on the OSM model. This paper combines insights from these recent pieces of work and show that phrase-based search combined with N-gram-based and phrase-based models in decoding is the overall best way to go. We integrate the two N-grambased models, TSM and OSM, into phrase-based Moses and show that the translation quality is improved by taking both translation and reordering context into account. Other approaches that explored such models in syntax-based systems used MTUs for sentence level reranking (Khalilov and Fonollosa, 2009), in dependency translation models (Quirk and Menezes, 2006) and in target language syntax systems (Vaswani et al., 2011). 3 Figure 1: Example (a) Word Alignments (b) Unfolded MTU Sequence (c) Operation Sequence (d) Step-wise Generation tem. Given a bilingual sentence pair (F, E) and its alignment (A), we first identify minimal translation units (MTUs) from it. An MTU is defined as a translation rule that cannot be broken down any further. The MTUs extracted from Figure 1(a) are A → a, B → b, C . . . H → c1 and D → d. These units are then generated left-to-right in two different ways, as we will describe next. 3.1 Tuple Sequence Model (TSM) The TSM tra"
P13-2071,I08-2089,1,0.813358,"ration is generated as soon as the MTU containing its previous target word is generated. In Figure 2(a), ε − f is generated immediately after MTU E − e is generated. In a sequence of unaligned source and target MTUs, unaligned source MTUs are generated before the unaligned target MTUs. We do not modify the decoder to arbitrarily generate unaligned MTUs but hypothesize these only when they appear within Parallel ≈39 M ≈15.6 M ≈15.2 M ≈2 M Monolingual ≈91 M ≈43.4 M ≈65.7 M ≈21.7 M ≈287.3 M Lang fr cs es ru en Table 1: Number of Sentences (in Millions) used for Training We follow the approach of Schwenk and Koehn (2008) and trained domain-specific language models separately and then linearly interpolated them using SRILM with weights optimized on the heldout dev-set. We concatenated the news-test sets from four years (2008-2011) to obtain a large devsetin order to obtain more stable weights (Koehn and Haddow, 2012). For Russian-English and English-Russian language pairs, we divided the tuning-set news-test 2012 into two halves and used 402 No. 1. 2. 3. 4. 5. System Baseline 1+pp 1+pp+tsm 1+pp+osm 1+osm* fr-en 31.89 31.87 31.94 32.17 32.13 es-en 35.07 35.09 35.25 35.50 35.65 cs-en 23.88 23.64 23.85 24.14 24.2"
P13-2071,N04-4026,0,0.0506055,"tional Linguistics, pages 399–405, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics baseline system, and shows statistically significant improvements in seven out of eight cases. 2 Previous Work Several researchers have tried to combine the ideas of phrase-based and N-gram-based SMT. Costajuss`a et al. (2007) proposed a method for combining the two approaches by applying sentence level reranking. Feng et al. (2010) added a linearized source-side language model in a phrase-based system. Crego and Yvon (2010) modified the phrasebased lexical reordering model of Tillman (2004) for an N-gram-based system. Niehues et al. (2011) integrated a bilingual language model based on surface word forms and POS tags into a phrasebased system. Zhang et al. (2013) explored multiple decomposition structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation which restricts the search to a small set of precomputed reorderings."
P13-2071,P11-1086,0,0.0372821,"s insights from these recent pieces of work and show that phrase-based search combined with N-gram-based and phrase-based models in decoding is the overall best way to go. We integrate the two N-grambased models, TSM and OSM, into phrase-based Moses and show that the translation quality is improved by taking both translation and reordering context into account. Other approaches that explored such models in syntax-based systems used MTUs for sentence level reranking (Khalilov and Fonollosa, 2009), in dependency translation models (Quirk and Menezes, 2006) and in target language syntax systems (Vaswani et al., 2011). 3 Figure 1: Example (a) Word Alignments (b) Unfolded MTU Sequence (c) Operation Sequence (d) Step-wise Generation tem. Given a bilingual sentence pair (F, E) and its alignment (A), we first identify minimal translation units (MTUs) from it. An MTU is defined as a translation rule that cannot be broken down any further. The MTUs extracted from Figure 1(a) are A → a, B → b, C . . . H → c1 and D → d. These units are then generated left-to-right in two different ways, as we will describe next. 3.1 Tuple Sequence Model (TSM) The TSM translation model assumes that MTUs are generated monotonically."
P13-2071,N13-1002,0,0.215931,"improvements in seven out of eight cases. 2 Previous Work Several researchers have tried to combine the ideas of phrase-based and N-gram-based SMT. Costajuss`a et al. (2007) proposed a method for combining the two approaches by applying sentence level reranking. Feng et al. (2010) added a linearized source-side language model in a phrase-based system. Crego and Yvon (2010) modified the phrasebased lexical reordering model of Tillman (2004) for an N-gram-based system. Niehues et al. (2011) integrated a bilingual language model based on surface word forms and POS tags into a phrasebased system. Zhang et al. (2013) explored multiple decomposition structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation which restricts the search to a small set of precomputed reorderings. Durrani et al. (2011) addressed this problem by coupling lexical generation and reordering information into a single generative process and enriching the N-gram models to learn"
P13-2071,N10-1140,0,\N,Missing
P13-2071,J06-4004,0,\N,Missing
schmid-etal-2004-smor,heid-etal-2002-using,1,\N,Missing
W11-2924,D10-1125,0,0.0414044,"Missing"
W11-2924,C10-1011,1,0.837107,"tituent labels (noGF) and on the conflation of these labels and grammatical functions (GF). We have to mention that our F-values are not comparable to the official results of PaGe – which was our original goal – because the evaluation metric there was a special imExperiments We evaluate our approach on the Tiger corpora of the Parsing German Shared Task (PaGe) (K¨ubler, 2008). Its training, development, and test datasets consist of 20894, 2611 and 2611 sentences respectively. We decided to use these corpora to be able to compare our results with other results. We used the dependency parser of Bohnet (2010) to generate the parses for the feature extraction. We selected the parser since it had top scores for German in the CoNLL Shared Task 2009. The parser is a second order dependency parser that models the interaction between siblings as well as grandchildren. The parser was after the Shared Task enhanced by a Hash Kernel, which leads to significantly higher accuracy. We generated the dependency structures by 10-fold cross-validation training of the training corpus. The model for the annotation of the test set and development set was trained on the entire training corpus. We evaluated the depend"
W11-2924,W08-2102,0,0.0262582,"discriminative dependency parsers – is also manifest which we will address as future work. Some generative parsing approaches exploited the difference between phrase-structure and dependency parsers. For instance, Klein and Manning (2003) introduced an approach where the objective function is the product of the probabilities of a generative phrase-structure and a dependency parsers. Model 1 of Collins (2003) is based on the dependencies between pairs of head words. On the other hand, the related work on this topic for discriminative parsing is sparse, we are only aware of the following works. Carreras et al. (2008) and Koo et al. (2010) introduced frameworks for joint learning of phrase-structure and dependency 209 Proceedings of the 12th International Conference on Parsing Technologies, pages 209–214, c 2011 Association for Computational Linguistics October 5-7, 2011, Dublin City University. have the corresponding arcs in the dependency tree. goal is to investigate the extension of the standard feature set of these models by features extracted from the automatic dependency parse of the sentence in question. 3 ConstRel features are similar to POSRel but use the constituent labels rather than the POS tag"
W11-2924,W09-0424,0,0.0189035,"es. Our prior experiments found the forest pruning threshold to be optimal at the order of 10−2 which resulted in packed forests with average node number of 108. The oracle scores were 87.1 and 91.4 for the 100-best lists and packed forests, respectively. At the second stage, we filtered out rare features (which occurred in less than 5 sentences). The new dependency parse-based feature set consists of 9240 and 5359 features before and after filtering. We employed the ranking MaxEnt implementation of the MALLET package (McCallum, 2002) and the average perceptron training of the Joshua package (Li et al., 2009). The update mechanism of the latter one was extended by using the F-score of the candidate full parse against the oracle parse as a loss function (see MIRA (Crammer and Singer, 2003) for the motivation). We used the state-of-the-art feature set of the German phrase-structure parse reranker of Versley and Rehbein (2009) as a baseline feature set. This feature set is rich and consists of features constructed from the lexicalized parse tree and its typed dependencies along with features based on external statistical information (like the clustering of unknown words according to their context of"
W11-2924,P05-1022,0,0.919132,"hes have been proved to be effective for phrase-structure and dependency parsers in the last decade. Here, we aim to exploit the divergence in these approaches and show the utility of features extracted from the automatic dependency parses of sentences for a discriminative phrase-structure parser. Our experiments show a significant improvement over the state-of-the-art German discriminative constituent parser. 2 1 Introduction Feature-Rich Parse Reranking The most successful supervised phrase-structure parsers are feature-rich discriminative parsers which heavily depend on an underlying PCFG (Charniak and Johnson, 2005; Huang, 2008). These approaches consists of two stages. At the first stage they apply a PCFG to extract possible parses. The full set of possible parses cannot be iterated through in practice, and is usually pruned as a consequence. The n-best list parsers keep just the 50-100 best parses according to the PCFG. Other methods remove nodes and hyperedges whose posterior probability is under a predefined threshold from the forest (chart). The task of the second stage is to select the best parse from the set of possible parses (i.e. rerank this set). These methods employ a large feature set (usua"
W11-2924,H05-1066,0,0.0766452,"plicated in the forest-based approaches. The conditional random field methods usually use only local features (Miyao and Tsujii, 2002; Finkel et al., 2008). Huang (2008) introduced a beam-search and average perceptron-based procedure for incorporating them, however his empirical results show only minor improvement from incorporating non-local features. In this study, we experiment with n-best list reranking and a packed-forest based model as well along with local features exclusively. Our Both phrase-structure and dependency parsers have developed a lot in the last decade (Nivre et al., 2004; McDonald et al., 2005; Charniak and Johnson, 2005; Huang, 2008). Different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques used (and a growing gap between researcher communities). In this work, we exploit this divergence and show the added value of features extracted from automatic dependency parses of sentences for a discriminative phrase-structure parser. We report results on German phrase-structure parsing, however, we note that the reverse direction of our approach – i.e. defining features from automatic phrase-structure parses for di"
W11-2924,J03-4003,0,0.0488488,"se-structure parser. We report results on German phrase-structure parsing, however, we note that the reverse direction of our approach – i.e. defining features from automatic phrase-structure parses for discriminative dependency parsers – is also manifest which we will address as future work. Some generative parsing approaches exploited the difference between phrase-structure and dependency parsers. For instance, Klein and Manning (2003) introduced an approach where the objective function is the product of the probabilities of a generative phrase-structure and a dependency parsers. Model 1 of Collins (2003) is based on the dependencies between pairs of head words. On the other hand, the related work on this topic for discriminative parsing is sparse, we are only aware of the following works. Carreras et al. (2008) and Koo et al. (2010) introduced frameworks for joint learning of phrase-structure and dependency 209 Proceedings of the 12th International Conference on Parsing Technologies, pages 209–214, c 2011 Association for Computational Linguistics October 5-7, 2011, Dublin City University. have the corresponding arcs in the dependency tree. goal is to investigate the extension of the standard"
W11-2924,P08-1109,0,0.0209595,"d from the forest (chart). The task of the second stage is to select the best parse from the set of possible parses (i.e. rerank this set). These methods employ a large feature set (usually a few millions features) (Collins, 2000; Charniak and Johnson, 2005). The n-best list approaches can straightforwardly employ local and non-local features as well because they decide at the sentence-level (Charniak and Johnson, 2005). Involving non-local features is more complicated in the forest-based approaches. The conditional random field methods usually use only local features (Miyao and Tsujii, 2002; Finkel et al., 2008). Huang (2008) introduced a beam-search and average perceptron-based procedure for incorporating them, however his empirical results show only minor improvement from incorporating non-local features. In this study, we experiment with n-best list reranking and a packed-forest based model as well along with local features exclusively. Our Both phrase-structure and dependency parsers have developed a lot in the last decade (Nivre et al., 2004; McDonald et al., 2005; Charniak and Johnson, 2005; Huang, 2008). Different approaches have been proved to be effective for these two parsing tasks which ha"
W11-2924,W04-2407,0,0.163726,"features is more complicated in the forest-based approaches. The conditional random field methods usually use only local features (Miyao and Tsujii, 2002; Finkel et al., 2008). Huang (2008) introduced a beam-search and average perceptron-based procedure for incorporating them, however his empirical results show only minor improvement from incorporating non-local features. In this study, we experiment with n-best list reranking and a packed-forest based model as well along with local features exclusively. Our Both phrase-structure and dependency parsers have developed a lot in the last decade (Nivre et al., 2004; McDonald et al., 2005; Charniak and Johnson, 2005; Huang, 2008). Different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques used (and a growing gap between researcher communities). In this work, we exploit this divergence and show the added value of features extracted from automatic dependency parses of sentences for a discriminative phrase-structure parser. We report results on German phrase-structure parsing, however, we note that the reverse direction of our approach – i.e. defining features from automatic phrase-"
W11-2924,W08-1007,0,0.0231942,"dels the interaction between siblings as well as grandchildren. The parser was after the Shared Task enhanced by a Hash Kernel, which leads to significantly higher accuracy. We generated the dependency structures by 10-fold cross-validation training of the training corpus. The model for the annotation of the test set and development set was trained on the entire training corpus. We evaluated the dependency parses themselves in line with PaGe. Table 1 shows the labeled (LAS) and unlabeled attachment scores (UAS) of the dependency parser and compares it with the Malt parser (Nivre et al., 2004; Hall and Nivre, 2008), which was the only and therefore best dependency parser that participated in the PaGe’s dependency parsing track. Bohnet’s parser reaches higher labeled and unlabeled scores. The last row shows the parsing accuracy with predicted Part-ofSpeech. We used the parses with predicted pos tags for our reranking experiments. 211 Table 3: Results achieved by the enriched feature set. Develop. Test noGF GF noGF GF Rafferty’08 77.40 – – – Versley’09 78.43 67.90 – – Baseline 78.48 66.29 79.21 66.63 RR 80.51 68.55 80.95 68.67 Dep 80.35 68.48 80.56 68.39 RR+Dep 81.34 69.73 81.49 69.44 AvgPer 81.41 69.67 8"
W11-2924,W08-1006,0,0.0260334,"0 – – Baseline 78.48 66.29 79.21 66.63 RR 80.51 68.55 80.95 68.67 Dep 80.35 68.48 80.56 68.39 RR+Dep 81.34 69.73 81.49 69.44 AvgPer 81.41 69.67 81.68 69.42 Table 2: Results achieved by dependency feature-based reranking. noGF GF Baseline 78.48 66.34 outArc 79.19 67.21 POSRel 79.99 68.13 ConstRel 79.67 67.72 All 80.20 68.32 All+Case 80.35 68.48 plementation for calculating F-value (which differs from evalb for example in handling punctuation marks) and it used gold-standard POS tags in the input (which we thought to be unrealistic). On the other hand, our results are comparable with results of Rafferty and Manning (2008) and Versley and Rehbein (2009). Table 2 shows the results achieved by the MaxEnt 100-best list reranker using one out of the three feature templates alone and their union (All) on the development set. All+Case refers to the enriched feature set incorporating case information for POS tag and grammatical functions for labels. Baseline here refers to the top parse of Bitpar (the first stage parser). We note that the inside probability estimation of Bitpar for an edge is always in our feature set. Each of the three feature templates achieved significant improvements over a strong baseline – note"
W11-2924,P08-1067,0,0.536996,"ffective for phrase-structure and dependency parsers in the last decade. Here, we aim to exploit the divergence in these approaches and show the utility of features extracted from the automatic dependency parses of sentences for a discriminative phrase-structure parser. Our experiments show a significant improvement over the state-of-the-art German discriminative constituent parser. 2 1 Introduction Feature-Rich Parse Reranking The most successful supervised phrase-structure parsers are feature-rich discriminative parsers which heavily depend on an underlying PCFG (Charniak and Johnson, 2005; Huang, 2008). These approaches consists of two stages. At the first stage they apply a PCFG to extract possible parses. The full set of possible parses cannot be iterated through in practice, and is usually pruned as a consequence. The n-best list parsers keep just the 50-100 best parses according to the PCFG. Other methods remove nodes and hyperedges whose posterior probability is under a predefined threshold from the forest (chart). The task of the second stage is to select the best parse from the set of possible parses (i.e. rerank this set). These methods employ a large feature set (usually a few mill"
W11-2924,C04-1024,1,0.870116,"ndency tree lays outside the span of words in question. We use the absolute count and the ratio of outArcs among the words of the span. The more arcs go out, the further away is the dependency subtree over the words of the constituent from a dominating subtree. Hence, these features try to capture the ”phraseness” of the span of words in question based on the dependency tree. For E1 we have outArc=2 and outArcRatio=2/4 as the parent of Inseln and von lay outside the constituent. For E2 we have outArc=1 and outArcRatio=1/5. 4 Two-Stage Parsing of German As a first-stage parser, we used BitPar (Schmid, 2004), a fast unlexicalized PCFG parser based on a first pass where non-probabilistic bottom-up parsing and top-down pruning is efficiently carried out by storing the chart in bit vectors. Bitpar constructs the probabilistic forest only after top-down pruning, i.e. after computing the posterior probability of each hyperedge given the input sentence. The forest is pruned by deleting hyperedges whose posterior probability is below some threshold. We used a treebank grammar enriched with case information, lexicalization of selected prepositions, conjunctions, and punctuation symbols, coarse parent cat"
W11-2924,W09-3820,0,0.676679,"ch occurred in less than 5 sentences). The new dependency parse-based feature set consists of 9240 and 5359 features before and after filtering. We employed the ranking MaxEnt implementation of the MALLET package (McCallum, 2002) and the average perceptron training of the Joshua package (Li et al., 2009). The update mechanism of the latter one was extended by using the F-score of the candidate full parse against the oracle parse as a loss function (see MIRA (Crammer and Singer, 2003) for the motivation). We used the state-of-the-art feature set of the German phrase-structure parse reranker of Versley and Rehbein (2009) as a baseline feature set. This feature set is rich and consists of features constructed from the lexicalized parse tree and its typed dependencies along with features based on external statistical information (like the clustering of unknown words according to their context of occurrences and PP attachment statistics gathered from the automatic POS tagged DE-WaC corpus, a 1.7G words sample of the German-language WWW). This feature set consists of 1.7 and 0.2 million of features before and after filtering and enables the direct comparison of our results with state-of-theart discriminative resu"
W11-2924,C10-2148,0,0.0425065,"POSRel but use the constituent labels rather than the POS tags of the heads. Thus, once again we do not have any positive feature for E1 , but for E2 we extract: VP-NP, VP-NP-OBJA, VP-PP, VP-PP-PP. We also investigated the role of case and grammatical functions and extended the POSRel and ConstRel feature sets by adding this information to the labels. For instance besides VVFIN-NN-OBJA and VP-NP-OBJA from our example E2 we also used VVFIN-NN-Acc-OBJA and VP-NP-OA-OBJA. Note that the value of outArc is 1 iff the word span in question has a dominating dependency subtree in the automatic parse. Wang and Zong (2010) prune hyperedges with outArc6= 1 thus this feature can be regarded as a generalization of their approach. Dependency Parse-Based Features for Phrase-Structure Parsing Given the automatic (1-best) dependency parse of the sentence in question, we defined three feature templates for representing hyperedges (i.e. a CFG rule applied over a certain span of words). We illustrate them on two hyperedges E1 = (NP die Inseln (PP von Rußland)) and E2 = (VP fordern (NP die Inseln) (PP von Rußland)). Let’s assume that the corresponding dependency subtree consists of the followDET ing arcs: ROOT→fordern, In"
W11-2924,W08-1008,0,\N,Missing
W13-2213,D11-1033,0,0.0919379,"Missing"
W13-2213,P05-1066,0,0.0443099,"a are also automatically tagged and phrases with words and POS tags on both sides are extracted. The POSbased OSM model is only used in the German-toEnglish and English-to-German experiments.4 So far, we only used coarse POS tags without gender and case information. 4 Constituent Parse Reordering Our German-to-English system used constituent parses for pre-ordering of the input. We parsed all of the parallel German to English data available, and the tuning, test and blind-test sets. We then applied reordering rules to these parses. We used the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data (training, tuning and test data). To produce the parses, we started with the generative BitPar parser trained on the Tiger treebank with optimizations of the grammar, as described by (Fraser et al., 2013). We then performed self-training using the high quality Europarl corpus - we parsed it, and then retrained the parser on the output. Decoder The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004). The decoder uses beam search to build up t"
W13-2213,P11-1105,1,0.934423,"rd Farkas4 1 2 University of Edinburgh – dnadir@inf.ed.ac.uk Ludwig Maximilian University Munich – schmid,fraser@cis.uni-muenchen.de 3 Qatar Computing Research Institute – hsajjad@qf.org.qa 4 University of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our proces"
W13-2213,N13-1001,1,0.917412,"ty of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our processing of the German and English data for German-English and English-German experiments. In Section 5 we describe the unsupervised transliteration mining that has been done for the Russian-English and"
W13-2213,P13-2071,1,0.919884,"ty of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our processing of the German and English data for German-English and English-German experiments. In Section 5 we describe the unsupervised transliteration mining that has been done for the Russian-English and"
W13-2213,W13-2212,1,0.928384,"ty of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our processing of the German and English data for German-English and English-German experiments. In Section 5 we describe the unsupervised transliteration mining that has been done for the Russian-English and"
W13-2213,J13-1005,1,0.871716,"Missing"
W13-2213,W09-0420,1,0.89655,"both sides are extracted. The POSbased OSM model is only used in the German-toEnglish and English-to-German experiments.4 So far, we only used coarse POS tags without gender and case information. 4 Constituent Parse Reordering Our German-to-English system used constituent parses for pre-ordering of the input. We parsed all of the parallel German to English data available, and the tuning, test and blind-test sets. We then applied reordering rules to these parses. We used the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data (training, tuning and test data). To produce the parses, we started with the generative BitPar parser trained on the Tiger treebank with optimizations of the grammar, as described by (Fraser et al., 2013). We then performed self-training using the high quality Europarl corpus - we parsed it, and then retrained the parser on the output. Decoder The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged"
W13-2213,W10-1734,1,0.864372,"Missing"
W13-2213,schmid-etal-2004-smor,1,0.739052,"Missing"
W13-2213,W11-2123,0,0.045987,"source-side cepts and source-word deletion. However, it doesn’t provide a mechanism to deal with unaligned and discontinuous target cepts. These are handled through a 3-step process3 in which we modify the alignments to remove discontinuous and unaligned target MTUs. Please see Durrani et al. (2011) for details. After modifying the alignments, we convert each bilingual sentence pair and its alignments into a sequence of operations as described above and learn an OSM model. To this end, a Kneser-Ney (Kneser and Ney, 1995) smoothed 9-gram model is trained with SRILM (Stolcke, 2002) while KenLM (Heafield, 2011) is used at runtime. Figure 1: Bilingual Sentence with Alignments sentence pair and its alignments as a unique sequence of operations. An operation either jointly generates source and target words, or it performs reordering by inserting gaps or jumping to gaps. We then learn a Markov model over a sequence of operations o1 , o2 , . . . , oJ that encapsulate MTUs and reordering information as: posm (o1 , ..., oJ ) = J Y j=1 p(oj |oj−n+1 , ..., oj−1 ) 2.3 We use additional features for our model and employ the standard log-linear approach (Och and Ney, 2004) to combine and tune them. We search fo"
W13-2213,I08-2089,0,0.179256,"estimation of the translation models is: de–en ≈ 4.5M and ru–en ≈ 2M parallel sentences. We were able to use all the available data for cs-to-en (≈ 15.6M sentences). However, sub-sampled data was used for en-to-cs (≈ 3M sentences), en-to-fr (≈ 7.8M sentences) and es–en (≈ 3M sentences). Monolingual Language Model: We used all the available training data (including LDC Gigaword data) for the estimation of monolingual language models: en ≈ 287.3M sentences, fr ≈ 91M, es ≈ 65.7M, cs ≈ 43.4M and ru ≈ 21.7M sentences. All data except for ru-en and en-ru was true-cased. We followed the approach of Schwenk and Koehn (2008) by training language models from each sub-corpus separately and then linearly interpolated them using SRILM with weights optimized on the held-out dev-set. We concatenated the news-test sets from four years (2008-2011) to obtain a large dev-set5 in order to obtain more stable weights (Koehn and Haddow, 2012). Decoder Settings: For each extracted input phrase only 15-best translation options were used during decoding.6 We used a hard reordering limit 5 For Russian-English and English-Russian language pairs, we divided the tuning-set news-test 2012 into two halves and used the first half for tu"
W13-2213,W13-2230,1,0.864769,"Missing"
W13-2213,W12-3139,0,0.0378184,"odel: We used all the available training data (including LDC Gigaword data) for the estimation of monolingual language models: en ≈ 287.3M sentences, fr ≈ 91M, es ≈ 65.7M, cs ≈ 43.4M and ru ≈ 21.7M sentences. All data except for ru-en and en-ru was true-cased. We followed the approach of Schwenk and Koehn (2008) by training language models from each sub-corpus separately and then linearly interpolated them using SRILM with weights optimized on the held-out dev-set. We concatenated the news-test sets from four years (2008-2011) to obtain a large dev-set5 in order to obtain more stable weights (Koehn and Haddow, 2012). Decoder Settings: For each extracted input phrase only 15-best translation options were used during decoding.6 We used a hard reordering limit 5 For Russian-English and English-Russian language pairs, we divided the tuning-set news-test 2012 into two halves and used the first half for tuning and second for test. 6 We could not experiment with higher n-best translation options due to a bug that was not fixed in time and hindered us from scaling. Sub-sampling Because of scalability problems we were not able to use the entire data made available for build125 of 16 words which disallows a jump b"
W13-2213,E03-1076,0,0.439555,"Missing"
W13-2213,koen-2004-pharaoh,0,0.0671416,"ering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data (training, tuning and test data). To produce the parses, we started with the generative BitPar parser trained on the Tiger treebank with optimizations of the grammar, as described by (Fraser et al., 2013). We then performed self-training using the high quality Europarl corpus - we parsed it, and then retrained the parser on the output. Decoder The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged in m stacks such that stack i maintains hypotheses that have already translated i many foreign words. The ultimate goal is to find the best scoring hypothesis, that translates all the words in the foreign sentence. During the hypothesis extension each extracted phrase is translated into a sequence of operations. The reordering opera4 This work is ongoing and we will present detailed experiments in the future. 124 ing the translation model in some cases. We used modified Moore-Lewis sampli"
W13-2213,J06-4004,0,0.0984652,"Missing"
W13-2213,J04-4002,0,0.0848361,"d with SRILM (Stolcke, 2002) while KenLM (Heafield, 2011) is used at runtime. Figure 1: Bilingual Sentence with Alignments sentence pair and its alignments as a unique sequence of operations. An operation either jointly generates source and target words, or it performs reordering by inserting gaps or jumping to gaps. We then learn a Markov model over a sequence of operations o1 , o2 , . . . , oJ that encapsulate MTUs and reordering information as: posm (o1 , ..., oJ ) = J Y j=1 p(oj |oj−n+1 , ..., oj−1 ) 2.3 We use additional features for our model and employ the standard log-linear approach (Och and Ney, 2004) to combine and tune them. We search for a target string E which maximizes a linear combination of feature functions: By coupling reordering with lexical generation, each (translation or reordering) decision depends on n − 1 previous (translation and reordering) decisions spanning across phrasal boundaries. The reordering decisions therefore influence lexical selection and vice versa. A heterogeneous mixture of translation and reordering operations enables us to memorize reordering patterns and lexicalized triggers unlike the classic N-gram model where translation and reordering are modeled se"
W13-2213,P11-1044,1,0.696753,"ing. We do not have such a list and making one is a cumbersome process. Instead, we use the unsupervised transliteration mining system of Sajjad et al. (2012) that takes a list of word pairs for training and extracts transliteration pairs that can be used for the training of the transliteration system. The procedure of mining transliteration pairs and transliterating OOVs is described as follows: We word-align the parallel corpus using GIZA++ in both direction and symmetrize the alignments using the grow-diag-final-and heuristic. We extract all word pairs which occur as 1to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the list of word pairs. We train the unsupervised transliteration mining system on the list of word pairs and extract transliteration pairs. We use these mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is applied in a post-processing step to transliterate OOVs. Please refer to Sajjad et al. (2013) for further details on our transliteration work. 6 7 Experiments Parallel Corpus: The amount of bitext used for the estimation of the translation models is: de–en ≈ 4.5M and ru–en ≈ 2M parallel sentences. We were able to u"
W13-2213,P12-1049,1,0.737125,"on system fails to translate out-of-vocabulary words (OOVs) as they are unknown to the training data. Most of the OOVs are named entities and simply passing them to the output often produces correct translations if source and target language use the same script. If the scripts are different transliterating them to the target language script could solve this problem. However, building a transliteration system requires a list of transliteration pairs for training. We do not have such a list and making one is a cumbersome process. Instead, we use the unsupervised transliteration mining system of Sajjad et al. (2012) that takes a list of word pairs for training and extracts transliteration pairs that can be used for the training of the transliteration system. The procedure of mining transliteration pairs and transliterating OOVs is described as follows: We word-align the parallel corpus using GIZA++ in both direction and symmetrize the alignments using the grow-diag-final-and heuristic. We extract all word pairs which occur as 1to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the list of word pairs. We train the unsupervised transliteration mining system on the list of word pairs and"
W13-2213,D11-1017,0,\N,Missing
W13-2213,E12-1074,1,\N,Missing
W13-2213,C04-1024,1,\N,Missing
W13-2213,W13-2228,1,\N,Missing
W13-2228,C12-1121,0,0.0548234,"Missing"
W13-2228,J03-1002,0,0.0274782,"n of PRO that optimizes BLEU+1 at corpus level. Section 5 and Section 6 present English/Russian and Russian/English machine translation experiments respectively. Section 7 concludes. Introduction We describe the QCRI-Munich-EdinburghStuttgart (QCRI-MES) English to Russian and Russian to English systems submitted to the Eighth Workshop on Statistical Machine Translation. We experimented using the standard Phrase-based Statistical Machine Translation System (PSMT) as implemented in the Moses toolkit (Koehn et al., 2007). The typical pipeline for translation involves word alignment using GIZA++ (Och and Ney, 2003), phrase extraction, tuning and phrase-based decoding. Our system is different from standard PSMT in three ways: • We integrate an unsupervised transliteration mining system (Sajjad et al., 2012) into the GIZA++ word aligner (Sajjad et al., 2011). 219 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 219–224, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 Transliteration Mining 2.1.1 Estimating Transliteration Probabilities We use the algorithm for the estimation of transliteration probabilities of Sajjad et al. (2011). We modify"
W13-2228,P03-1021,0,0.0050144,"as a list of word pairs. The unsupervised transliteration mining system trains on the list of word pairs and mines transliteration pairs. We use the mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is used in Algorithm 1 to generate transliteration probabilities of candidate word pairs and is also used in the postprocessing step to transliterate OOVs. We run GIZA++ with identical settings as described in Section 5.2. We interpolate for evPRO: Corpus-level BLEU Pairwise Ranking Optimization (PRO) (Hopkins and May, 2011) is an extension of MERT (Och, 2003) that can scale to thousands of parameters. It optimizes sentence-level BLEU+1 which is an add-one smoothed version of BLEU (Lin and Och, 2004). The sentence-level BLEU+1 has a bias towards producing short translations as add-one smoothing improves precision but does not change the brevity penalty. Nakov et al. (2012) fixed this by using several heuristics on brevity penalty, reference length and grounding the precision length. In our experiments, we use the improved version of PRO as provided by Nakov et al. (2012). We 221 MERT MIRA PRO PROv1 GIZA++ TA-GIZA++ OOV-TI 23.41 23.60 23.57 23.65 23"
W13-2228,P11-1044,1,0.923855,"QCRI-MES) English to Russian and Russian to English systems submitted to the Eighth Workshop on Statistical Machine Translation. We experimented using the standard Phrase-based Statistical Machine Translation System (PSMT) as implemented in the Moses toolkit (Koehn et al., 2007). The typical pipeline for translation involves word alignment using GIZA++ (Och and Ney, 2003), phrase extraction, tuning and phrase-based decoding. Our system is different from standard PSMT in three ways: • We integrate an unsupervised transliteration mining system (Sajjad et al., 2012) into the GIZA++ word aligner (Sajjad et al., 2011). 219 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 219–224, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 Transliteration Mining 2.1.1 Estimating Transliteration Probabilities We use the algorithm for the estimation of transliteration probabilities of Sajjad et al. (2011). We modify it to improve efficiency. In step 6 of Algorithm 1 instead of taking all f that coocur with e, we take only those that have a word length ratio in range of 0.8-1.2.1 This reduces cooc(e) by more than half and speeds up step 9 of Algorithm 1. The"
W13-2228,J93-2003,0,0.0261744,"Missing"
W13-2228,P11-1105,1,0.819552,"tion system on that. We compare its result with the Russian to English system trained on the un-processed parallel data. 6.1.2 Morphological Reduction English in comparison to Slavic group of languages is morphologically poor. For example, English has no morphological attributes for nouns and adjectives to express gender or case; verbs in English have no gender either. Russian, on the contrary, has rich morphology. It suffices to say that the Russian has 6 cases and 3 grammatical genders, which manifest themselves in different 2 We see similar gain in BLEU when using operation sequence model (Durrani et al., 2011) for decoding and transliterating OOVs in a post-processing step (Durrani et al., 2013). 222 Original corpus suffixes for nouns, pronouns, adjectives and some verb forms. When translating from Russian into English, a lot of these attributes become meaningless and excessive. It makes sense to reduce the number of morphological attributes before the text is supplied for the training of the MT system. We apply morphological reduction to nouns, pronouns, verbs, adjectives, prepositions and conjunctions. The rest of the POS (adverbs, particles, interjections and abbreviations) have no morphological"
W13-2228,P12-1049,1,0.919427,"on We describe the QCRI-Munich-EdinburghStuttgart (QCRI-MES) English to Russian and Russian to English systems submitted to the Eighth Workshop on Statistical Machine Translation. We experimented using the standard Phrase-based Statistical Machine Translation System (PSMT) as implemented in the Moses toolkit (Koehn et al., 2007). The typical pipeline for translation involves word alignment using GIZA++ (Och and Ney, 2003), phrase extraction, tuning and phrase-based decoding. Our system is different from standard PSMT in three ways: • We integrate an unsupervised transliteration mining system (Sajjad et al., 2012) into the GIZA++ word aligner (Sajjad et al., 2011). 219 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 219–224, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 Transliteration Mining 2.1.1 Estimating Transliteration Probabilities We use the algorithm for the estimation of transliteration probabilities of Sajjad et al. (2011). We modify it to improve efficiency. In step 6 of Algorithm 1 instead of taking all f that coocur with e, we take only those that have a word length ratio in range of 0.8-1.2.1 This reduces cooc(e) by more"
W13-2228,C08-1098,1,0.691413,"f English to Russian machine translation system evaluated on tst2012 and tst2013 using baseline GIZA++ alignment and transliteration augmented-GIZA++ alignment and post-processed the output by transliterating OOVs. Human evaluation in WMT13 is performed on TA-GIZA++ tested on tst2013 (marked with *) Table 1: BLEU scores of English to Russian machine translation system evaluated on tst2012 using baseline GIZA++ alignment and transliteration augmented-GIZA++. OOV-TI presents the score of the system trained using TA-GIZA++ after transliterating OOVs 5.4 tst2012 6.1.1 POS Tagging We use RFTagger (Schmid and Laws, 2008) for POS tagging. Despite the good quality of tagging provided by RFTagger, some errors seem to be unavoidable due to the ambiguity of certain grammatical forms in Russian. A good example of this is neuter nouns that have the same form in all cases, or feminine nouns, which have identical forms in singular genitive and plural nominative (Sharoff et al., 2008). Since Russian sentences have free word order, and the case of nouns cannot be determined on that basis, this imperfection can not be corrected during tagging or by postprocessing the tagger output. Russian/English Experiments In this sec"
W13-2228,W13-2213,1,0.727212,"n the un-processed parallel data. 6.1.2 Morphological Reduction English in comparison to Slavic group of languages is morphologically poor. For example, English has no morphological attributes for nouns and adjectives to express gender or case; verbs in English have no gender either. Russian, on the contrary, has rich morphology. It suffices to say that the Russian has 6 cases and 3 grammatical genders, which manifest themselves in different 2 We see similar gain in BLEU when using operation sequence model (Durrani et al., 2011) for decoding and transliterating OOVs in a post-processing step (Durrani et al., 2013). 222 Original corpus suffixes for nouns, pronouns, adjectives and some verb forms. When translating from Russian into English, a lot of these attributes become meaningless and excessive. It makes sense to reduce the number of morphological attributes before the text is supplied for the training of the MT system. We apply morphological reduction to nouns, pronouns, verbs, adjectives, prepositions and conjunctions. The rest of the POS (adverbs, particles, interjections and abbreviations) have no morphological attributes and are left unchanged. We apply morphological reduction to train, tune, de"
W13-2228,D11-1125,0,0.0171179,"ke Sajjad et al. (2011)) and later refer to them as a list of word pairs. The unsupervised transliteration mining system trains on the list of word pairs and mines transliteration pairs. We use the mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is used in Algorithm 1 to generate transliteration probabilities of candidate word pairs and is also used in the postprocessing step to transliterate OOVs. We run GIZA++ with identical settings as described in Section 5.2. We interpolate for evPRO: Corpus-level BLEU Pairwise Ranking Optimization (PRO) (Hopkins and May, 2011) is an extension of MERT (Och, 2003) that can scale to thousands of parameters. It optimizes sentence-level BLEU+1 which is an add-one smoothed version of BLEU (Lin and Och, 2004). The sentence-level BLEU+1 has a bias towards producing short translations as add-one smoothing improves precision but does not change the brevity penalty. Nakov et al. (2012) fixed this by using several heuristics on brevity penalty, reference length and grounding the precision length. In our experiments, we use the improved version of PRO as provided by Nakov et al. (2012). We 221 MERT MIRA PRO PROv1 GIZA++ TA-GIZA"
W13-2228,I08-2089,0,0.333709,"s are less likely to be transliterations. 220 very sensitive to the value of λ. We use λ = 50 for our experiments. The procedure we described of estimation of transliteration probabilities and modification of EM is also followed in the opposite direction f-to-e. 3 call it PROv1 later on. 5 5.1 Dataset The amount of bitext used for the estimation of the translation model is ≈ 2M parallel sentences. We use newstest2012a for tuning and newstest2012b (tst2012) as development set. The language model is estimated using large monolingual corpus of Russian ≈ 21.7M sentences. We follow the approach of Schwenk and Koehn (2008) by training domain-specific language models separately and then linearly interpolate them using SRILM with weights optimized on the held-out development set. We divide the tuning set newstest2012a into two halves and use the first half for tuning and second for test in order to obtain stable weights (Koehn and Haddow, 2012). Transliteration System The unsupervised transliteration mining system (as described in Section 2) outputs a list of transliteration pairs. We consider transliteration word pairs as parallel sentences by putting a space after every character of the words and train a PSMT s"
W13-2228,W12-3139,0,0.0320278,"d for the estimation of the translation model is ≈ 2M parallel sentences. We use newstest2012a for tuning and newstest2012b (tst2012) as development set. The language model is estimated using large monolingual corpus of Russian ≈ 21.7M sentences. We follow the approach of Schwenk and Koehn (2008) by training domain-specific language models separately and then linearly interpolate them using SRILM with weights optimized on the held-out development set. We divide the tuning set newstest2012a into two halves and use the first half for tuning and second for test in order to obtain stable weights (Koehn and Haddow, 2012). Transliteration System The unsupervised transliteration mining system (as described in Section 2) outputs a list of transliteration pairs. We consider transliteration word pairs as parallel sentences by putting a space after every character of the words and train a PSMT system for transliteration. We apply the transliteration system to OOVs in a post-processing step on the output of the machine translation system. Russian is a morphologically rich language. Different cases of a word are generally represented by adding suffixes to the root form. For OOVs that are named entities, transliterati"
W13-2228,sharoff-etal-2008-designing,0,0.0184257,"n system evaluated on tst2012 using baseline GIZA++ alignment and transliteration augmented-GIZA++. OOV-TI presents the score of the system trained using TA-GIZA++ after transliterating OOVs 5.4 tst2012 6.1.1 POS Tagging We use RFTagger (Schmid and Laws, 2008) for POS tagging. Despite the good quality of tagging provided by RFTagger, some errors seem to be unavoidable due to the ambiguity of certain grammatical forms in Russian. A good example of this is neuter nouns that have the same form in all cases, or feminine nouns, which have identical forms in singular genitive and plural nominative (Sharoff et al., 2008). Since Russian sentences have free word order, and the case of nouns cannot be determined on that basis, this imperfection can not be corrected during tagging or by postprocessing the tagger output. Russian/English Experiments In this section, we present translation experiments in Russian to English direction. We morphologically reduce the Russian side of the parallel data in a pre-processing step and train the translation system on that. We compare its result with the Russian to English system trained on the un-processed parallel data. 6.1.2 Morphological Reduction English in comparison to S"
W13-2228,N03-1017,0,0.00764806,", , , , ) and transliterate the stemmed form. For morphologically reduced Russian (see Section 6.1), we follow the same procedure as OOVs are unknown to the POS tagger too and are (incorrectly) not reduced to their root forms. For OOVs that are not identified as named entities, we transliterate them without any pre-processing. 4 English/Russian Experiments 5.2 Baseline Settings We word-aligned the parallel corpus using GIZA++ (Och and Ney, 2003) with 5 iterations of Model1, 4 iterations of HMM and 4 iterations of Model4, and symmetrized the alignments using the grow-diag-final-and heuristic (Koehn et al., 2003). We built a phrase-based machine translation system using the Moses toolkit. Minimum error rate training (MERT), margin infused relaxed algorithm (MIRA) and PRO are used to optimize the parameters. 5.3 Main System Settings Our main system involves a pre-processing step – unsupervised transliteration mining, and a postprocessing step – transliteration of OOVs. For the training of the unsupervised transliteration mining system, we take the word alignments from our baseline settings and extract all word pairs which occur as 1-to-1 alignments (like Sajjad et al. (2011)) and later refer to them as"
W13-2228,C96-2141,0,0.0435274,"word alignment models. They combined the translation probabilities of the IBM models and the HMM model with the transliteration probabilities. Consider pta (f |e) = fta (f, e)/fta (e) is the translation probability of the word alignment models. The interpolated probability is calculated by adding the smoothed alignment frequency fta (f, e) to the transliteration probability weight by the factor λ. The modified translation probabilities is given by: Transliteration Augmented-GIZA++ GIZA++ aligns parallel sentences at word level. It applies the IBM models (Brown et al., 1993) and the HMM model (Vogel et al., 1996) in both directions i.e. source to target and target to source. It generates a list of translation pairs with translation probabilities, which is called the t-table. Sajjad et al. (2011) used a heuristic-based transliteration mining system and integrated it into the GIZA++ word aligner. We follow a similar procedure but use the unsupervised transliteration mining system of Sajjad et al. (2012). pˆ(f |e) = We define a transliteration sub-model and train it on the transliteration pairs mined by the unsupervised transliteration mining system. We integrate it into the GIZA++ word aligner. The prob"
W13-2228,W13-2230,1,0.735961,"ng The linguistic processing of Russian involves POS tagging and morphological reduction. We first tag the Russian data using a fine grained tagset. The tagger identifies lemmas and the set of morphological attributes attached to each word. We reduce the number of these attributes by deleting some of them, that are not relevant for English (for example, gender agreement of verbs). This generates a morphologically reduced Russian which is used in parallel with English for the training of the machine translation system. Further details on the morphological processing of Russian are described in Weller et al. (2013). Results Table 1 summarizes English/Russian results on tst2012. Improved word alignment gives up to 0.13 BLEU points improvement. PROv1 improves translation quality and shows 0.08 BLEU point increase in BLEU in comparison to the parameters tuned using PRO. The transliteration of OOVs consistently improve translation quality by at least 0.1 BLEU point for all systems.2 This adds to a cumulative gain of up to 0.2 BLEU points. We summarize results of our systems trained on GIZA++ and transliteration augmented-GIZA++ (TA-GIZA++) and tested on tst2012 and tst2013 in Table 2. Both systems use PROv1"
W13-2228,P07-2045,0,\N,Missing
W13-2228,C04-1072,0,\N,Missing
W13-2230,W10-1749,0,0.0262519,"highest usefulness scores for the reordering task. Then we trained a new grammar on the concatenation of the Tiger corpus and the automatic parses from Europarl. The usefulness score estimates the value of a parse tree for the reordering task. We calculated this score as the similarity between the word order achieved by applying the parse tree-based reordering rules of Fraser (2009) and the word order indicated by the automatic word alignment between the German and English sentences in Europarl. We used the Kendall’s Tau Distance as the similarity metric of two word orderings (as suggested by Birch and Osborne (2010)). Following this, we performed linguisticallyinformed compound splitting, using the system of Fritzinger and Fraser (2010), which disambiguates competing analyses from the high-recall Stuttgart Morphological Analyzer SMOR (Schmid et al., 2004) using corpus statistics. We also split German portmanteaus like zum → zu dem (meaning to the). DE-EN (OSM) DE-EN (OSM) BitPar not self-trained DE-EN (Moses) DE-EN (Moses) BitPar not self-trained EN-DE (Moses) BLEU (ci) 27.60 27.48 BLEU (cs) 26.12 25.99 system name 27.14 25.65 26.82 25.36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES"
W13-2230,P12-1050,0,0.0143602,"tuent parses for pre-reordering. For DE-EN we also deal with word formation issues such as compound splitting. We did not perform inflectional normalization or generation for German due to time constraints, instead focusing 236 system our efforts on these issues for French and Russian as previously described. German to English German has a wider diversity of clausal orderings than English, all of which need to be mapped to the English SVO order. This is a difficult problem to solve during inference, as shown for hierarchical SMT by Fabienne Braune and Fraser (2012) and for phrase-based SMT by Bisazza and Federico (2012). We syntactically parsed all of the source side sentences of the parallel German to English data available, and the tuning, test and blindtest sets. We then applied reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Fraser et al. (2013). The parser was trained on the Tiger Tre"
W13-2230,P05-1022,0,0.0609343,".36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES not submitted Table 8: Results on WMT-2013 (blindtest) English to German The task of mapping English SVO order to the different clausal orders in German is difficult. For our English to German systems, we solved this by parsing the English and applying the system of Gojun and Fraser (2012) to reorder English into the correct German clausal order (depending on the clause type which is detected using the English parse, see (Gojun and Fraser, 2012) for further details). We primarily used the Charniak-Johnson generative parser (Charniak and Johnson, 2005) to parse the English Europarl data and the test data. However, due to time constraints we additionally used Berkeley parses of about 400K Europarl sentences and the other English parallel training data. We also left a small amount of the English parallel training data unparsed, which means that it was not reordered. For tune, test and blindtest (WMT2013), we used the Charniak-Johnson generative parser. Experiments and results We used all available training data for constrained systems; results for the WMT-2013 set are given in table 8. For the contrastive BitPar results, we reparsed WMT-2013."
W13-2230,N12-1047,0,0.0466778,"Moses system (DE-EN, EN-DE, EN-FR and FR-EN) or with an operation sequence model (RU-EN, DEEN), cf. Durrani et al. (2013b) for more details. An operation sequence model (OSM) is a stateof-the-art SMT-system that learns translation and reordering patterns by representing a sentence pair and its word alignment as a unique sequence of operations (see e.g. Durrani et al. (2011), Durrani et al. (2013a) for more details). For the Moses systems we used the old train-model perl scripts rather than the EMS, so we did not perform Good-Turing smoothing; parameter tuning was carried out with batch-mira (Cherry and Foster, 2012). 232 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 232–239, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 1 2 3 4 5 System Baseline Simplified French* Removal of empty lines Conversion of HTML special characters like &quot; to the corresponding characters Unification of words that were written both with an œ or with an oe to only one spelling Punctuation normalization and tokenization Putting together clitics and apostrophes like l ’ or d ’ to l’ and d’ la / l’ / les → le un / une → un Infl. form → lemma e. g. au → a` le Redu"
W13-2230,P05-1066,0,0.216656,"Missing"
W13-2230,P11-1105,1,0.789613,"eneral translation model, this method also allows the generation of inflected word forms which do not occur in the training data. 2 Experimental setup The translation experiments in this paper are carried out with either a standard phrase-based Moses system (DE-EN, EN-DE, EN-FR and FR-EN) or with an operation sequence model (RU-EN, DEEN), cf. Durrani et al. (2013b) for more details. An operation sequence model (OSM) is a stateof-the-art SMT-system that learns translation and reordering patterns by representing a sentence pair and its word alignment as a unique sequence of operations (see e.g. Durrani et al. (2011), Durrani et al. (2013a) for more details). For the Moses systems we used the old train-model perl scripts rather than the EMS, so we did not perform Good-Turing smoothing; parameter tuning was carried out with batch-mira (Cherry and Foster, 2012). 232 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 232–239, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 1 2 3 4 5 System Baseline Simplified French* Removal of empty lines Conversion of HTML special characters like &quot; to the corresponding characters Unification of words that we"
W13-2230,N13-1001,1,0.816849,"lly complex target language, we describe a two-step translation system built on non-inflected word stems with a post-processing component for predicting morphological features and the generation of inflected forms. In addition to the advantage of a more general translation model, this method also allows the generation of inflected word forms which do not occur in the training data. 2 Experimental setup The translation experiments in this paper are carried out with either a standard phrase-based Moses system (DE-EN, EN-DE, EN-FR and FR-EN) or with an operation sequence model (RU-EN, DEEN), cf. Durrani et al. (2013b) for more details. An operation sequence model (OSM) is a stateof-the-art SMT-system that learns translation and reordering patterns by representing a sentence pair and its word alignment as a unique sequence of operations (see e.g. Durrani et al. (2011), Durrani et al. (2013a) for more details). For the Moses systems we used the old train-model perl scripts rather than the EMS, so we did not perform Good-Turing smoothing; parameter tuning was carried out with batch-mira (Cherry and Foster, 2012). 232 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 232–239, c Sof"
W13-2230,2012.eamt-1.42,1,0.834142,"bmitted systems for DE-EN and EN-DE which used constituent parses for pre-reordering. For DE-EN we also deal with word formation issues such as compound splitting. We did not perform inflectional normalization or generation for German due to time constraints, instead focusing 236 system our efforts on these issues for French and Russian as previously described. German to English German has a wider diversity of clausal orderings than English, all of which need to be mapped to the English SVO order. This is a difficult problem to solve during inference, as shown for hierarchical SMT by Fabienne Braune and Fraser (2012) and for phrase-based SMT by Bisazza and Federico (2012). We syntactically parsed all of the source side sentences of the parallel German to English data available, and the tuning, test and blindtest sets. We then applied reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Frase"
W13-2230,E12-1068,1,0.847569,"ng all necessary morphological features for the translation output, which are then used to generate fully inflected forms. This two-step setup decreases the complexity of the translation task by removing languagespecific features from the translation model. Furthermore, generating inflected forms based on word stems and morphological features allows to gener233 ate forms which do not occur in the parallel training data – this is not possible in a standard SMT setup. The idea of separating the translation into two steps to deal with complex morphology was introduced by Toutanova et al. (2008). Fraser et al. (2012) applied this method to the language pair English-German with an additional special focus on word formation issues such as the splitting and merging of portmanteau prepositions and compounds. The presented inflection prediction systems focuses on nominal inflection; verbal inflection is not addressed. Morphological analysis and resources The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008). For generating inflected forms based on stems and morphological features, we use an ext"
W13-2230,J13-1005,1,0.858728,"Missing"
W13-2230,W09-0420,1,0.87823,"of clausal orderings than English, all of which need to be mapped to the English SVO order. This is a difficult problem to solve during inference, as shown for hierarchical SMT by Fabienne Braune and Fraser (2012) and for phrase-based SMT by Bisazza and Federico (2012). We syntactically parsed all of the source side sentences of the parallel German to English data available, and the tuning, test and blindtest sets. We then applied reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Fraser et al. (2013). The parser was trained on the Tiger Treebank (Brants et al., 2002) along with utilizing the Europarl corpus as unlabeled data. At the training of Bitpar, we followed the targeted self-training approach (Katz-Brown et al., 2011) as follows. We parsed the whole Europarl corpus using a grammar trained on the Tiger corpus and extracted the 100best parse trees for each sentence. We sel"
W13-2230,W10-1734,1,0.788681,"us and the automatic parses from Europarl. The usefulness score estimates the value of a parse tree for the reordering task. We calculated this score as the similarity between the word order achieved by applying the parse tree-based reordering rules of Fraser (2009) and the word order indicated by the automatic word alignment between the German and English sentences in Europarl. We used the Kendall’s Tau Distance as the similarity metric of two word orderings (as suggested by Birch and Osborne (2010)). Following this, we performed linguisticallyinformed compound splitting, using the system of Fritzinger and Fraser (2010), which disambiguates competing analyses from the high-recall Stuttgart Morphological Analyzer SMOR (Schmid et al., 2004) using corpus statistics. We also split German portmanteaus like zum → zu dem (meaning to the). DE-EN (OSM) DE-EN (OSM) BitPar not self-trained DE-EN (Moses) DE-EN (Moses) BitPar not self-trained EN-DE (Moses) BLEU (ci) 27.60 27.48 BLEU (cs) 26.12 25.99 system name 27.14 25.65 26.82 25.36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES not submitted Table 8: Results on WMT-2013 (blindtest) English to German The task of mapping English SVO order to the diffe"
W13-2230,E12-1074,1,0.864449,"s. We also split German portmanteaus like zum → zu dem (meaning to the). DE-EN (OSM) DE-EN (OSM) BitPar not self-trained DE-EN (Moses) DE-EN (Moses) BitPar not self-trained EN-DE (Moses) BLEU (ci) 27.60 27.48 BLEU (cs) 26.12 25.99 system name 27.14 25.65 26.82 25.36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES not submitted Table 8: Results on WMT-2013 (blindtest) English to German The task of mapping English SVO order to the different clausal orders in German is difficult. For our English to German systems, we solved this by parsing the English and applying the system of Gojun and Fraser (2012) to reorder English into the correct German clausal order (depending on the clause type which is detected using the English parse, see (Gojun and Fraser, 2012) for further details). We primarily used the Charniak-Johnson generative parser (Charniak and Johnson, 2005) to parse the English Europarl data and the test data. However, due to time constraints we additionally used Berkeley parses of about 400K Europarl sentences and the other English parallel training data. We also left a small amount of the English parallel training data unparsed, which means that it was not reordered. For tune, test"
W13-2230,D11-1017,0,0.051958,"d reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Fraser et al. (2013). The parser was trained on the Tiger Treebank (Brants et al., 2002) along with utilizing the Europarl corpus as unlabeled data. At the training of Bitpar, we followed the targeted self-training approach (Katz-Brown et al., 2011) as follows. We parsed the whole Europarl corpus using a grammar trained on the Tiger corpus and extracted the 100best parse trees for each sentence. We selected the parse tree among the 100 candidates which got the highest usefulness scores for the reordering task. Then we trained a new grammar on the concatenation of the Tiger corpus and the automatic parses from Europarl. The usefulness score estimates the value of a parse tree for the reordering task. We calculated this score as the similarity between the word order achieved by applying the parse tree-based reordering rules of Fraser (2009"
W13-2230,P10-1052,0,0.0314476,"Missing"
W13-2230,C12-1121,0,0.0602483,"Missing"
W13-2230,P11-1044,1,0.749892,"problem by stemming the OOVs based on a list of suffixes ( , , , , , ) and transliterating the stemmed forms. Voice Aspect Type Degree Type Formation Table 6: Rules for simplifying the morphological complexity for RU. training and extracts transliteration pairs that can be used for the training of the transliteration system. The procedure of mining transliteration pairs and transliterating OOVs is described as follows: We word-align the parallel corpus using GIZA++ and symmetrize the alignments using the grow-diagfinal-and heuristic. We extract all word pairs which occur as 1-to-1 alignments (Sajjad et al., 2011) and later refer to them as a list of word pairs. We train the unsupervised transliteration mining system on the list of word pairs and extract transliteration pairs. We use these mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is applied as a post-processing step to transliterate OOVs. The morphological reduction of Russian (cf. section 5) does not process most of the OOVs as they are also unknown to the POS tagger. So OOVs that we get are in their original form. When translitExperiments and results We trained the systems separately on GIZA++"
W13-2230,P12-1049,1,0.744729,", particles, interjections and abbreviations) have no morphological attributes. The list of the original and the reduced attributes is given in Table 6. Transliteration mining to handle OOVs The machine translation system fails to translate out-ofvocabulary words (OOVs) as they are unknown to the training data. Most of the OOVs are named entities and transliterating them to the target language script could solve this problem. The transliteration system requires a list of transliteration pairs for training. As we do not have such a list, we use the unsupervised transliteration mining system of Sajjad et al. (2012) that takes a list of word pairs for Part of Speech Noun Pronoun Verb Adjective Preposition Conjunction Attributes RFTagger Type Gender Number Case Reduced attributes Type Gender Number Case nom,gen,dat,acc,instr,prep gen,notgen Animate Case 2 Person Gender Number Case Person Gender Number Case nom,gen,dat,acc,instr,prep nom,notnom Syntactic type Animated Type VForm Tense Person Number Gender Voice Definiteness Aspect Case Type Degree Gender Number Case Definiteness Type Formation Case Type Formation SYS GIZA++ TA-GIZA++ Original corpus WMT-2012 WMT-2013 32.51 25.5 33.40 25.9* SYS GIZA++ TA-GI"
W13-2230,W13-2228,1,0.735928,"ng system on the list of word pairs and extract transliteration pairs. We use these mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is applied as a post-processing step to transliterate OOVs. The morphological reduction of Russian (cf. section 5) does not process most of the OOVs as they are also unknown to the POS tagger. So OOVs that we get are in their original form. When translitExperiments and results We trained the systems separately on GIZA++ and transliteration augmented-GIZA++ (TA-GIZA++) to compare their results; for more details see Sajjad et al. (2013). All systems are tuned using PROv1 (Nakov et al., 2012). The translation output is postprocessed to transliterate OOVs. Table 7 summarizes the results of RU-EN translation systems trained on the original corpus and on the morph-reduced corpus. Using TA-GIZA++ alignment gives the best results for both WMT2012 and WMT-2013, leading to an improvement of 0.4 BLEU points. The system built on the morph-reduced data leads to decreased BLEU results. However, the percentage of OOVs is reduced for both test sets when using the morph-reduced data set compared to the original data. An analysis of the out"
W13-2230,C08-1098,1,0.776757,"reas adjectives in English are not inflected at all. This causes data sparsity in coverage of French inflected forms. We try to overcome this problem by simplifying French inflected forms in a pre-processing step in order to adapt the French input better to the English output. Processing of the training and test data The pre-processing of the French input consists of two steps: (1) normalizing not well-formed data (cf. table 1) and (2) morphological simplification. In the second step, the normalized training data is annotated with Part-of-Speech tags (PoS-tags) and word lemmas using RFTagger (Schmid and Laws, 2008) which was trained on the French treebank (Abeill´e et al., 2003). French forms are then simplified according to the rules given in table 2. Data and experiments We trained a French to English Moses system on the preprocessed and BLEU (ci) 31.02 30.83 Table 3: Results of the French to English system (WMT-2012). The marked system (*) corresponds to the system submitted for manual evaluation. (cs: case-sensitive, ci: case-insensitive) Table 1: Text normalization for FR-EN. Definite determiners Indefinite determiners Adjectives Portmanteaus Verb participles inflected for gender and number ending"
W13-2230,schmid-etal-2004-smor,1,0.771053,"Missing"
W13-2230,I08-2089,0,0.135299,"h an œ or with an oe to only one spelling Punctuation normalization and tokenization Putting together clitics and apostrophes like l ’ or d ’ to l’ and d’ la / l’ / les → le un / une → un Infl. form → lemma e. g. au → a` le Reduced to non-inflected verb participle form ending in e´ d’ → de, qu’ → que, n’ → ne, ... Table 2: Rules for morphological simplification. The development data consists of the concatenated news-data sets from the years 2008-2011. Unless otherwise stated, we use all constrained data (parallel and monolingual). For the target-side language models, we follow the approach of Schwenk and Koehn (2008) and train a separate language model for each corpus and then interpolate them using weights optimized on development data. 3 French to English French has a much richer morphology than English; for example, adjectives in French are inflected with respect to gender and number whereas adjectives in English are not inflected at all. This causes data sparsity in coverage of French inflected forms. We try to overcome this problem by simplifying French inflected forms in a pre-processing step in order to adapt the French input better to the English output. Processing of the training and test data Th"
W13-2230,P08-1059,0,0.0269016,"step consists of predicting all necessary morphological features for the translation output, which are then used to generate fully inflected forms. This two-step setup decreases the complexity of the translation task by removing languagespecific features from the translation model. Furthermore, generating inflected forms based on word stems and morphological features allows to gener233 ate forms which do not occur in the parallel training data – this is not possible in a standard SMT setup. The idea of separating the translation into two steps to deal with complex morphology was introduced by Toutanova et al. (2008). Fraser et al. (2012) applied this method to the language pair English-German with an additional special focus on word formation issues such as the splitting and merging of portmanteau prepositions and compounds. The presented inflection prediction systems focuses on nominal inflection; verbal inflection is not addressed. Morphological analysis and resources The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008). For generating inflected forms based on stems and morphological f"
W13-2230,W13-2213,1,\N,Missing
