2020.paclic-1.62,Improving Semantic Similarity Calculation of {J}apanese Text for {MT} Evaluation,2020,-1,-1,4,0,15922,yuki tanahashi,"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation",0,None
2019.gwc-1.23,Towards linking synonymous expressions of compound verbs to {J}apanese {W}ord{N}et,2019,-1,-1,2,0,15923,kyoko kanzaki,Proceedings of the 10th Global Wordnet Conference,0,"This paper describes our project on Japanese compound verbs. Japanese {``}Verb (adnominal form) + Verb{''} compounds, which are treated as single verbs, frequently appear in daily communication. They are not sufficiently registered in Japanese dictionaries or thesauri. We are now compiling a list of the synonymous expressions of compound verbs in {``}compound verb lexicon{''} built by the National Institute of Japanese Language and Linguistics. We extracted synonymous words and phrases of compound verbs from five hundred million Japanese web corpora. As a result, synonymous expressions of 1800 compound verbs were obtained automatically among 2700 in the {``}compound verb lexicon{''}. From our data, we observed that some compound verbs represent not only motion but also additional nuances such as an emotional one. In order to reflect the abundant meanings that compound verbs own, we will try to think of a link of synonymous expressions to Japanese wordnet. Concretely, in the case of synonymous phrases, we try to link adverbial expressions which are a part of phrases to the adverbial synset in Japanese wordnet."
L18-1376,Building a List of Synonymous Words and Phrases of {J}apanese Compound Verbs,2018,0,0,2,1,15923,kyoko kanzaki,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L16-1350,{ASPEC}: {A}sian Scientific Paper Excerpt Corpus,2016,0,24,7,0,283,toshiaki nakazawa,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, we describe the details of the ASPEC (Asian Scientific Paper Excerpt Corpus), which is the first large-size parallel corpus of scientific paper domain. ASPEC was constructed in the Japanese-Chinese machine translation project conducted between 2006 and 2010 using the Special Coordination Funds for Promoting Science and Technology. It consists of a Japanese-English scientific paper abstract corpus of approximately 3 million parallel sentences (ASPEC-JE) and a Chinese-Japanese scientific paper excerpt corpus of approximately 0.68 million parallel sentences (ASPEC-JC). ASPEC is used as the official dataset for the machine translation evaluation workshop WAT (Workshop on Asian Translation)."
W14-0144,Fusion of Multiple Semantic Networks and Human Association,2014,1,0,1,1,15925,hitoshi isahara,Proceedings of the Seventh Global {W}ordnet Conference,0,"We are trying to construct a conceptual system that accurately represents human thoughts by fusing of semantic networks. As semantic networks to fuse, we use the Japanese Wordnet which is a thesaurus made manually based on linguistic intuition and the knowledge acquired automatically from the actual text stored in the huge corpus. Such knowledge are represented as mutual relations of the concepts of words. In order to acquire such relations, we focus on the case relations in sentences and calculate inclusive relations of co-occurrence by using Complementary Similarity Measure. As an application and verification of the conceptual system created, we try to simulate human associations by using the conceptual system. As an experimental result, we found the obvious difference in generated association links between using the semantic network of Japanese Wordnet and using the fused semantic networks with Japanese Wordnet and the acquired mutual relations."
2012.eamt-1.9,Building Translation Awareness in Occasional Authors: A User Case from {J}apan,2012,-1,-1,3,0,37934,midori tatsumi,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,None
2012.eamt-1.57,Readability and Translatability Judgments for {``}Controlled {J}apanese{''},2012,6,2,3,0,32117,anthony hartley,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"Abstract We report on an experiment to test the ef-ficacy of xe2x80x98controlled languagexe2x80x99 authoring of technical documents in Japanese, with respect both to the readability of the Jap-anese source and the quality of the Eng-lish machine-translated output. Using four MT systems, we tested two sets of writing rules designed for two document types written by authors with contrasting professional profiles. We elicited judg-ments from native speakers to establish the positive or negative impact of each rule on readability and translation quality. 1 Introduction It is widely acknowledged that the typological xe2x80x98distancexe2x80x99 between Japanese and English (the most common European target language for MT from Japanese) hampers the achievement of high-quality translation. We seek to address this challenge by investigating the feasibility of de-veloping a xe2x80x98controlled Japanesexe2x80x99 with explicit restrictions on vocabulary, syntax and style ade-quate for authoring technical documentation. Our starting point is sentences extracted from two types of document: consumer user manuals (UM) and company-internal documents articulat-ing the know-how of key employees (KH). UM are produced by professional technical authors, while KH are written as xe2x80x98one-offsxe2x80x99 by the em-ployees themselves, capturing their own know-how. Thus, there is a sharp difference in the ef-"
2012.amta-wptp.8,How Good Is Crowd Post-Editing? Its Potential and Limitations,2012,-1,-1,4,0,37934,midori tatsumi,Workshop on Post-Editing Technology and Practice,0,"This paper is a partial report of a research effort on evaluating the effect of crowd-sourced post-editing. We first discuss the emerging trend of crowd-sourced post-editing of machine translation output, along with its benefits and drawbacks. Second, we describe the pilot study we have conducted on a platform that facilitates crowd-sourced post-editing. Finally, we provide our plans for further studies to have more insight on how effective crowd-sourced post-editing is."
Y11-1053,System for Flexibly Judging the Misuse of Honorifics in {J}apanese,2011,1,2,4,0,43966,tamotsu shirado,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"We propose a system for flexibly judging the misusage of honorifics in Japanese sentence. The system can point out misused words and phrases, and can also indicate how they are misused. The system uses judgment rules whose degrees of validity in modern Japanese society are quantified by psychological experiments. The system can judge sentences flexibly based on the learner's linguistic level by tuning thresholds regarding the degree of validity. The proposed system is expected to be applied in practical computeraided education."
I11-1165,"Compiling Learner Corpus Data of Linguistic Output and Language Processing in Speaking, Listening, Writing, and Reading",2011,12,2,4,1,28269,katsunori kotani,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"A learnerxe2x80x99s language data of speaking, writing, listening, and reading have been compiled for a learner corpus in this study. The language data consist of linguistic output and language processing. Linguistic output refers to data of pronunciation, sentences, listening comprehension rate, and reading comprehension rate. Language processing refers to processing time and learnersxe2x80x99 self-judgment of their difficulty of processing in speaking, listening, and reading and the fluency of their writing. This learner corpus will contribute to making the language learning process more clearly visible."
sornlertlamvanich-etal-2010-language,Language Resource Management System for {A}sian {W}ord{N}et Collaboration and Its Web Service Application,2010,5,1,3,0,33512,virach sornlertlamvanich,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents the language resource management system for the development and dissemination of Asian WordNet (AWN) and its web service application. We develop the platform to establish a network for the cross language WordNet development. Each node of the network is designed for maintaining the WordNet for a language. Via the table that maps between each language WordNet and the Princeton WordNet (PWN), the Asian WordNet is realized to visualize the cross language WordNet between the Asian languages. We propose a language resource management system, called WordNet Management System (WNMS), as a distributed management system that allows the server to perform the cross language WordNet retrieval, including the fundamental web service applications for editing, visualizing and language processing. The WNMS is implemented on a web service protocol therefore each node can be independently maintained, and the service of each language WordNet can be called directly through the web service API. In case of cross language implementation, the synset ID (or synset offset) defined by PWN is used to determined the linkage between the languages."
W09-3401,Enhancing the {J}apanese {W}ord{N}et,2009,20,72,2,0,6126,francis bond,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"The Japanese WordNet currently has 51,000 synsets with Japanese entries. In this paper, we discuss three methods of extending it: increasing the cover, linking it to examples in corpora and linking it to other resources (SUMO and GoiTaikei). In addition, we outline our plans to make it more useful by adding Japanese definition sentences to each synset. Finally, we discuss how releasing the corpus under an open license has led to the construction of interfaces in a variety of programming languages."
W09-3420,{T}hai {W}ord{N}et Construction,2009,6,18,7,0,46895,sareewan thoongsup,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"This paper describes semi-automatic construction of Thai WordNet and the applied method for Asian wordNet. Based on the Princeton WordNet, we develop a method in generating a WordNet by using an existing bi-lingual dictionary. We align the PWN synset to a bilingual dictionary through the English equivalent and its part-of-speech (POS), automatically. Manual translation is also employed after the alignment. We also develop a web-based collaborative workbench, called KUI (Knowledge Unifying Initiator), for revising the result of synset assignment and provide a framework to create Asian WordNet via the linkage through PWN synset."
W09-3426,"Word Segmentation Standard in {C}hinese, {J}apanese and {K}orean",2009,0,6,2,0,15850,keysun choi,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"Word segmentation is a process to divide a sentence into meaningful units called word unit [ISO/DIS 24614-1]. What is a word unit is judged by principles for its internal integrity and external use constraints. A word unit's internal structure is bound by principles of lexical integrity, unpredictability and so on in order to represent one syntactically meaningful unit. Principles for external use include language economy and frequency such that word units could be registered in a lexicon or any other storage for practical reduction of processing complexity for the further syntactic processing after word segmentation. Such principles for word segmentation are applied for Chinese, Japanese and Korean, and impacts of the standard are discussed."
P09-1058,An Error-Driven Word-Character Hybrid Model for Joint {C}hinese Word Segmentation and {POS} Tagging,2009,24,92,6,1,8038,canasai kruengkrai,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"In this paper, we present a discriminative word-character hybrid model for joint Chinese word segmentation and POS tagging. Our word-character hybrid model offers high performance since it can handle both known and unknown words. We describe our strategies that yield good balance for learning the characteristics of known and unknown words and propose an error-driven policy that delivers such balance by acquiring examples of unknown words from particular errors in a training corpus. We describe an efficient framework for training our model based on the Margin Infused Relaxed Algorithm (MIRA), evaluate our approach on the Penn Chinese Treebank, and show that it achieves superior performance compared to the state-of-the-art approaches reported in the literature."
W08-1910,The {``}Close-Distant{''} Relation of Adjectival Concepts Based on Self-Organizing Map,2008,7,0,3,1,15923,kyoko kanzaki,Coling 2008: Proceedings of the Workshop on Cognitive Aspects of the Lexicon ({COGALEX} 2008),0,"In this paper we aim to detect some aspects of adjectival meanings. Concepts of adjectives are distributed by SOM (Self-Organizing map) whose feature vectors are calculated by MI (Mutual Information). For the SOM obtained, we make tight clusters from map nodes, calculated by cosine. In addition, the number of tight clusters obtained by cosine was increased using map nodes and Japanese thesaurus. As a result, the number of extended clusters of concepts was 149 clusters. From the map, we found 8 adjectival clusters in super-ordinate level and some tendencies of similar and dissimilar clusters."
W08-1506,The 2008 {M}ed{SLT} System,2008,7,0,7,0,11421,manny rayner,Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications,0,"MedSLT is a grammar-based medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different subdomains and multiple language pairs. Vocabulary ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo three different versions of the system: an anyto-any multilingual version involving the languages Japanese, English, French and Arabic, a bidirectional English $ Spanish version, and a mobile version running on a hand-held PDA. We will also demo the Regulus development environment, focussing on features which support rapid prototyping of grammar-based speech translation systems."
bond-etal-2008-boot,Boot-Strapping a {W}ord{N}et Using Multiple Existing {W}ord{N}ets,2008,12,28,2,0,6126,francis bond,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,In this paper we describe the construction of an illustrated Japanese Wordnet. We bootstrap the Wordnet using existing multiple existing wordnets in order to deal with the ambiguity inherent in translation. We illustrate it with pictures from the Open Clip Art Library.
vossen-etal-2008-kyoto,"{KYOTO}: a System for Mining, Structuring and Distributing Knowledge across Languages and Cultures",2008,32,44,7,0,5469,piek vossen,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We outline work performed within the framework of a current EC project. The goal is to construct a language-independent information system for a specific domain (environment/ecology/biodiversity) anchored in a language-independent ontology that is linked to wordnets in seven languages. For each language, information extraction and identification of lexicalized concepts with ontological entries is carried out by text miners (ÂKybotsÂ). The mapping of language-specific lexemes to the ontology allows for crosslinguistic identification and translation of equivalent terms. The infrastructure developed within this project enables long-range knowledge sharing and transfer across many languages and cultures, addressing the need for global and uniform transition of knowledge beyond the specific domains addressed here."
isahara-etal-2008-development,Development of the {J}apanese {W}ord{N}et,2008,6,79,1,1,15925,hitoshi isahara,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"After a long history of compilation of our own lexical resources, EDR Japanese/English Electronic Dictionary, and discussions with major players on development of various WordNets, Japanese National Institute of Information and Communications Technology started developing the Japanese WordNet in 2006 and will publicly release the first version, which includes both the synset in Japanese and the annotated Japanese corpus of SemCor, in June 2008. As the first step in compiling the Japanese WordNet, we added Japanese equivalents to synsets of the Princeton WordNet. Of course, we must also add some synsets which do not exist in the Princeton WordNet, and must modify synsets in the Princeton WordNet, in order to make the hierarchical structure of Princeton synsets represent thesaurus-like information found in the Japanese language, however, we will address these tasks in a future study. We then translated English sentences which are used in the SemCor annotation into Japanese and annotated them using our Japanese WordNet. This article describes the overview of our project to compile Japanese WordNet and other resources which relate to our Japanese WordNet."
yamamoto-etal-2008-extraction,Extraction of Informative Expressions from Domain-specific Documents,2008,13,2,2,1,15924,eiko yamamoto,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"What kinds of lexical resources are helpful for extracting useful information from domain-specific documents? Although domain-specific documents contain much useful knowledge, it is not obvious how to extract such knowledge efficiently from the documents. We need to develop techniques for extracting hidden information from such domain-specific documents. These techniques do not necessarily use state-of-the-art technologies and achieve deep and accurate language understanding, but are based on huge amounts of linguistic resources, such as domain-specific lexical databases. In this paper, we introduce two techniques for extracting informative expressions from documents: the extraction of related words that are not only taxonomically related but also thematically related, and the acquisition of salient terms and phrases. With these techniques we then attempt to automatically and statistically extract domain-specific informative expressions in aviation documents as an example and evaluate the results."
tohyama-etal-2008-construction-metadata,Construction of a Metadata Database for Efficient Development and Use of Language Resources,2008,2,2,5,0,46266,hitomi tohyama,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The National Institute of Information and Communications Technology (NICT) and Nagoya University have been jointly constructing a large scale database named SHACHI by collecting detailed meta-information on language resources (LRs) in Asia and Western countries, for the purpose of effectively combining LRs. The purpose of this project is to investigate languages, tag sets, and formats compiled in LRs throughout the world, to systematically store LR metadata, to create a search function for this information, and to ultimately utilize all this for a more efficient development of LRs. This metadata database contains more than 2,000 compiled LRs such as corpora, dictionaries, thesauruses and lexicons, forming a large scale metadata of LRs archive. Its metadata, an extended version of OLAC metadata set conforming to Dublin Core, which contain detailed meta-information, have been collected semi-automatically. This paper explains the design and the structure of the metadata database, as well as the realization of the catalogue search tool. Additionally, the website of this database is now open to the public and accessible to all Internet users."
bouillon-etal-2008-developing,Developing Non-{E}uropean Translation Pairs in a Medium-Vocabulary Medical Speech Translation System,2008,10,9,5,0,2866,pierrette bouillon,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We describe recent work on MedSLT, a medium-vocabulary interlingua-based medical speech translation system, focussing on issues that arise when handling languages of which the grammar engineer has little or no knowledge. We show how we can systematically create and maintain multiple forms of grammars, lexica and interlingual representations, with some versions being used by language informants, and some by grammar engineers. In particular, we describe the advantages of structuring the interlingua definition as a simple semantic grammar, which includes a human-readable surface form. We show how this allows us to rationalise the process of evaluating translations between languages lacking common speakers, and also makes it possible to create a simple generic tool for debugging to-interlingua translation rules. Examples presented focus on the concrete case of translation between Japanese and Arabic in both directions."
tongchim-etal-2008-dependency,A Dependency Parser for {T}hai,2008,16,5,4,1,48449,shisanu tongchim,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper presents some preliminary results of our dependency parser for Thai. It is part of an ongoing project in developing a syntactically annotated Thai corpus. The parser has been trained and tested by using the complete part of the corpus. The parser achieves 83.64{\%} as the root accuracy, 78.54{\%} as the dependency accuracy and 53.90{\%} as the complete sentence accuracy. The trained parser will be used as a preprocessing step in our corpus annotation workflow in order to accelerate the corpus development."
zhang-etal-2008-word,Word Alignment Annotation in a {J}apanese-{C}hinese Parallel Corpus,2008,5,0,5,1,9062,yujie zhang,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Parallel corpora are critical resources for machine translation research and development since parallel corpora contain translation equivalences of various granularities. Manual annotation of word {\&} phrase alignment is of significance to provide gold-standard for developing and evaluating both example-based machine translation model and statistical machine translation model. This paper presents the work of word {\&} phrase alignment annotation in the NICT Japanese-Chinese parallel corpus, which is constructed at the National Institute of Information and Communications Technology (NICT). We describe the specification of word alignment annotation and the tools specially developed for the manual annotation. The manual annotation on 17,000 sentence pairs has been completed. We examined the manually annotated word alignment data and extracted translation knowledge from the word {\&} phrase aligned corpus."
ma-etal-2008-selection,Selection of {J}apanese-{E}nglish Equivalents by Integrating High-quality Corpora and Huge Amounts of Web Data,2008,5,1,4,1,33252,qing ma,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"As a first step to developing systems that enable non-native speakers to output near-perfect English sentences for given mixed English-Japanese sentences, we propose new approaches for selecting English equivalents by using the number of hits for various contexts in large English corpora. As the large English corpora, we not only used the huge amounts of Web data but also the manually compiled large, high-quality English corpora. Using high-quality corpora enables us to accurately select equivalents, and using huge amounts of Web data enables us to resolve the problem of the shortage of hits that normally occurs when using only high-quality corpora. The types and lengths of contexts used to select equivalents are variable and optimally determined according to the number of hits in the corpora, so that performance can be further refined. Computer experiments showed that the precision of our methods was much higher than that of the existing methods for equivalent selection."
isahara-etal-2008-application,Application of Resource-based Machine Translation to Real Business Scenes,2008,3,1,1,1,15925,hitoshi isahara,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"As huge quantities of documents have become available, services using natural language processing technologies trained by huge corpora have emerged, such as information retrieval and information extraction. In this paper we verify the usefulness of resource-based, or corpus-based, translation in the aviation domain as a real business situation. This study is important from both a business perspective and an academic perspective. Intuitively, manuals for similar products, or manuals for different versions of the same product, are likely to resemble each other. Therefore, even with only a small training data, a corpus-based MT system can output useful translations. The corpus-based approach is powerful when the target is repetitive. Manuals for similar products, or manuals for different versions of the same product, are real-world documents that are repetitive. Our experiments on translation of manual documents are still in a beginning stage. However, the BLEU score from very small number of training sentences is already rather high. We believe corpus-based machine translation is a player full of promise in this kind of actual business scene."
kanzaki-etal-2008-extraction,Extraction of Attribute Concepts from {J}apanese Adjectives,2008,7,4,4,1,15923,kyoko kanzaki,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We describe various syntactic and semantic conditions for finding abstractnouns which refer to concepts of adjectives from a text, in an attempt to explore the creation of a thesaurus from text. Depending on usages, six kinds of syntactic patterns are shown. In the syntactic and semantic conditions an omission of an abstract noun is mainly used, but in addition, various linguistic clues are needed. We then compare our results with synsets of Japanese WordNet. From a viewpoint of Japanese WordNet, the degree of agreement of ?Attribute? between our data and Japanese WordNet was 22{\%}. On the other hand, the total number of differences of obtained abstract nouns was 267. From a viewpoint of our data,the degree of agreement of abstract nouns between our data and Japanese WordNet was 54{\%}."
I08-7020,Enhanced Tools for Online Collaborative Language Resource Development,2008,0,0,5,0.44091,33512,virach sornlertlamvanich,Proceedings of the 6th Workshop on {A}sian Language Resources,0,"This paper reports our recent work of tool development for language resource construction. To make a revision of Asian WordNet which is automatically generated by using the existing English translation dictionary, we propose an online collaborative tool which can organize multiple translations. To support the work of syntactic dependency tree annotation, we develop an editing suite which integrates the utilities for word segmentation, POS tagging and dependency tree into a sequence of editing."
I08-3005,{KUI}: an ubiquitous tool for collective intelligence development,2008,2,2,3,1,42113,thatsanee charoenporn,Proceedings of the {IJCNLP}-08 Workshop on {NLP} for Less Privileged Languages,0,"Collective intelligence is the capability for a group of people to collaborate in order to achieve goals in a complex context than its individual member. This common concept increases topic of interest in many sciences including computer science where computers are bring about as group support elements. This paper presents a new platform, called Knowledge Unifying Initiator (KUI) for knowledge development which enables connection and collaboration among individual intelligence in order to accomplish a complex mission. KUI is a platform to unify the various thoughts following the process of thinking, i.e., initiating the topic of interest, collecting the opinions to the selected topics, localizing the opinions through the translation or customization and posting for public hearing to conceptualize the knowledge. The process of thinking is done under the selectional preference simulated by voting mechanism in case that many alternatives occur. By measuring the history of participation of each member, KUI adaptively manages the reliability of each memberxe2x80x99s opinion and vote according to the estimated ExpertScore."
I08-2091,Synset Assignment for Bi-lingual Dictionary with Limited Resource,2008,5,6,4,0.44091,33512,virach sornlertlamvanich,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"This paper explores an automatic WordNet synset assignment to the bi-lingual dictionaries of languages having limited lexicon information. Generally, a term in a bilingual dictionary is provided with very limited information such as part-of-speech, a set of synonyms, and a set of English equivalents. This type of dictionary is comparatively reliable and can be found in an electronic form from various publishers. In this paper, we propose an algorithm for applying a set of criteria to assign a synset with an appropriate degree of confidence to the existing bi-lingual dictionary. We show the efficiency in nominating the synset candidate by using the most common lexical information. The algorithm is evaluated against the implementation of ThaiEnglish, Indonesian-English, and Mongolian-English bi-lingual dictionaries. The experiment also shows the effectiveness of using the same type of dictionary from different sources."
I08-2100,Non-Factoid {J}apanese Question Answering through Passage Retrieval that Is Weighted Based on Types of Answers,2008,16,2,5,0,16788,masaki murata,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"We constructed a system for answering nonfactoid Japanese questions. We used various methods of passage retrieval for the system. We extracted paragraphs based on terms from an input question and output them as the preferred answers. We classified the non-factoid questions into six categories. We used a particular method for each category. For example, we increased the scores of paragraphs including the word xe2x80x9creasonxe2x80x9d for questions including the word xe2x80x9cwhy.xe2x80x9d We participated at NTCIR-6 QAC-4, where our system obtained the most correct answers out of all the eight participating teams. The rate of accuracy was 0.77, which indicates that our methods were effective."
I08-1012,Dependency Parsing with Short Dependency Relations in Unlabeled Data,2008,18,27,5,1,21231,wenliang chen,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"This paper presents an effective dependency parsing approach of incorporating short dependency information from unlabeled data. The unlabeled data is automatically parsed by a deterministic dependency parser, which can provide relatively high performance for short dependencies between words. We then train another parser which uses the information on short dependency relations extracted from the output of the first parser. Our proposed approach achieves an unlabeled attachment score of 86.52, an absolute 1.24% improvement over the baseline system on the data set of Chinese Treebank."
I08-1031,Hypothesis Selection in Machine Transliteration: A Web Mining Approach,2008,14,7,2,0.833333,12929,jonghoon oh,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"We propose a new method of selecting hypotheses for machine transliteration. We generate a set of Chinese, Japanese, and Korean transliteration hypotheses for a given English word. We then use the set of transliteration hypotheses as a guide to finding relevant Web pages and mining contextual information for the transliteration hypotheses from the Web page. Finally, we use the mined information for machine-learning algorithms including support vector machines and maximum entropy model designed to select the correct transliteration hypothesis. In our experiments, our proposed method based on Web mining consistently outperformed systems based on simple Web counts used in previous work, regardless of the language."
C08-2030,Construction of an Infrastructure for Providing Users with Suitable Language Resources,2008,0,1,5,0,46266,hitomi tohyama,Coling 2008: Companion volume: Posters,0,"Our research organization has been constructing a large scale database named SHACHI by collecting detailed meta information on language resources (LRs) in Asia and Western countries. The metadata database contains more than 2,000 compiled LRs such as corpora, dictionaries, thesauruses and lexicons, forming a large scale metadata of LRs archive. Its metadata, an extended version of OLAC metadata set conforming to Dublin Core, have been collected semi-automatically. This paper explains the design and the structure of the metadata database, as well as the realization of the catalogue search tool."
C08-2031,Experiments in Base-{NP} Chunking and Its Role in Dependency Parsing for {T}hai,2008,9,0,3,1,48449,shisanu tongchim,Coling 2008: Companion volume: Posters,0,"This paper studies the role of base-NP information in dependency parsing for Thai. The baseline performance reveals that the base-NP chunking task for Thai is much more difficult than those of some languages (like English). The results show that the parsing performance can be improved (from 60.30% to 63.74%) with the use of base-NP chunk information, although the best chunker is still far from perfect (Fxefxbfxbd=1 = 83.06%)."
C08-1015,Learning Reliable Information for Dependency Parsing Adaptation,2008,15,20,3,1,21231,wenliang chen,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"In this paper, we focus on the adaptation problem that has a large labeled data in the source domain and a large but unlabeled data in the target domain. Our aim is to learn reliable information from unlabeled target domain data for dependency parsing adaptation. Current state-of-the-art statistical parsers perform much better for shorter dependencies than for longer ones. Thus we propose an adaptation approach by learning reliable information on shorter dependencies in an unlabeled target data to help parse longer distance words. The unlabeled data is parsed by a dependency parser trained on labeled source domain data. The experimental results indicate that our proposed approach outperforms the baseline system, and is better than current state-of-the-art adaptation techniques."
2008.amta-govandcom.25,Applicability of Resource-based Machine Translation to Airplane Manuals,2008,-1,-1,3,1,15924,eiko yamamoto,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Government and Commercial Uses of MT,0,"Machine translation (MT) has been studied and developed since the advent of computers, and yet is rarely used in actual business. For business use, rule-based MT has been developed, but it requires rules and a domain-specific dictionary that have been created manually. On the other hand, as huge amounts of text data have become available, corpus-based MT has been actively studied, particularly corpus-based statistical machine translation (SMT). In this study, we tested and verified the usefulness of SMT for aviation manuals. Manuals tend to be similar and repetitive, so SMT is powerful even with a small amount of training data. Although our experiments with SMT are at the preliminary stage, the BLEU score is high. SMT appears to be a powerful and promising technique in this domain."
Y07-1034,{J}apanese Expressions that Include {E}nglish Expressions,2007,0,0,5,0,16788,masaki murata,"Proceedings of the 21st Pacific Asia Conference on Language, Information and Computation",0,"We extracted English expressions that appear in Japanese sentences in newspaper articles and on the Internet. The results obtained from the newspaper articles showed that the preposition in has been regularly used for more than ten years, and it is still regularly used now. The results obtained from the Internet articles showed there were many kinds of English expressions from various parts of speech. We extracted some interesting expressions that included English prepositions and verb phrases. These were interesting because they had different word orders to the normal order in Japanese expressions. Comparing the extracted English and katakana expressions, we found that the expressions that are commonly used in Japanese are often written in the katakana syllabary and that the expressions that are not so often used in Japanese, such as prepositions, are hardly ever written in the katakana syllabary. Keyword: English expression, katakana expression, newspaper article, Internet"
P07-2036,Extracting Word Sets with Non-Taxonomical Relation,2007,7,3,2,1,15924,eiko yamamoto,Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,0,"At least two kinds of relations exist among related words: taxonomical relations and thematic relations. Both relations identify related words useful to language understanding and generation, information retrieval, and so on. However, although words with taxonomical relations are easy to identify from linguistic resources such as dictionaries and thesauri, words with thematic relations are difficult to identify because they are rarely maintained in linguistic resources. In this paper, we sought to extract thematically (non-taxonomically) related word sets among words in documents by employing case-marking particles derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval."
N07-1005,Automatic Evaluation of Machine Translation Based on Rate of Accomplishment of Sub-Goals,2007,14,2,4,1,30019,kiyotaka uchimoto,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"The quality of a sentence translated by a machine translation (MT) system is difficult to evaluate. We propose a method for automatically evaluating the quality of each translation. In general, when translating a given sentence, one or more conditions should be satisfied to maintain a high translation quality. In EnglishJapanese translation, for example, prepositions and infinitives must be appropriately translated. We show several procedures that enable evaluating the quality of a translated sentence more appropriately than using conventional methods. The first procedure is constructing a test set where the conditions are assigned to each test-set sentence in the form of yes/no questions. The second procedure is developing a system that determines an answer to each question. The third procedure is combining a measure based on the questions and conventional measures. We also present a method for automatically generating sub-goals in the form of yes/no questions and estimating the rate of accomplishment of the sub-goals. Promising results are shown."
N07-1061,A Comparison of Pivot Methods for Phrase-Based Statistical Machine Translation,2007,26,113,2,1,127,masao utiyama,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"We compare two pivot strategies for phrase-based statistical machine translation (SMT), namely phrase translation and sentence translation. The phrase translation strategy means that we directly construct a phrase translation table (phrase-table) of the source and target language pair from two phrase-tables; one constructed from the source language and English and one constructed from English and the target language. We then use that phrase-table in a phrase-based SMT system. The sentence translation strategy means that we first translate a source language sentence into n English sentences and then translate these n sentences into target language sentences separately. Then, we select the highest scoring sentence from these target sentences. We conducted controlled experiments using the Europarl corpus to evaluate the performance of these pivot strategies as compared to directly trained SMT systems. The phrase translation strategy significantly outperformed the sentence translation strategy. Its relative performance was 0.92 to 0.97 compared to directly trained SMT systems."
D07-1122,A Two-Stage Parser for Multilingual Dependency Parsing,2007,14,7,3,1,21231,wenliang chen,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"We present a two-stage multilingual dependency parsing system submitted to the Multilingual Track of CoNLL-2007. The parser first identifies dependencies using a deterministic parsing method and then labels those dependencies as a sequence labeling problem. We describe the features used in each stage. For four languages with different values of ROOT, we design some special features for the ROOT labeler. Then we present evaluation results and error analyses focusing on Chinese."
2007.mtsummit-papers.35,Development of a {J}apanese-{C}hinese machine translation system,2007,-1,-1,1,1,15925,hitoshi isahara,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.mtsummit-papers.47,Machine transliteration using multiple transliteration engines and hypothesis re-ranking,2007,-1,-1,2,0.833333,12929,jonghoon oh,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.mtsummit-papers.63,A {J}apanese-{E}nglish patent parallel corpus,2007,-1,-1,2,1,127,masao utiyama,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.mtsummit-papers.73,Building {J}apanese-{C}hinese translation dictionary based on {EDR} {J}apanese-{E}nglish bilingual dictionary,2007,2,6,3,1,9062,yujie zhang,Proceedings of Machine Translation Summit XI: Papers,0,"We launched a 5-year-project in 2006 to develop a Japanese-Chinese machine translation system for translating scientific and technical papers. As part of that project, we are currently building a Japanese-Chinese translation dictionary based on the EDR Japanese-English bilingual dictionary. This paper presents the design and construction of the Japanese-Chinese translation dictionary, including specifications for translating Japanese information into Chinese and annotating related information, tools developed for assisting manual annotation, and some result that have already been achieved."
Y06-1039,Construction of Adverb Dictionary that Relates to Speaker Attitudes and Evaluation of Its Effectiveness,2006,3,1,3,1,48624,toshiyuki kanamaru,"Proceedings of the 20th Pacific Asia Conference on Language, Information and Computation",0,"Adverbs can express a speakerxe2x80x99s attitude in a given situation on a specific matter. We constructed an adverb dictionary in which the attitude of the speaker is described. We also looked into whether or not adverbs could effectively be used as basic data to analyze reputations. We conducted three kinds of experiments to verify how effective and precise our dictionary was. First, we calculated the coverage ratio of the dictionary by comparing the ratios of appearances of all adverbs to the ratios of appearances of our dictionary items. Next, we attached a tag to 988 adverbs, and found that the coverage ratio of the tagged adverbs was 97.76% in the open data. Finally, we classified whether sentences were positively or negatively represented using the adverb dictionary and calculated that the accuracy of the classification was 86.5%."
W06-3707,{M}ed{SLT}: A Limited-Domain Unidirectional Grammar-Based Medical Speech Translator,2006,7,3,8,0,11421,manny rayner,Proceedings of the First International Workshop on Medical Speech Translation,0,"MedSLT is a unidirectional medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different language pairs and subdomains. Vocabulary ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo both the system itself and the development environment, which uses a combination of rule-based and data-driven methods to construct efficient recognisers, generators and transfer rule sets from small corpora."
W06-0201,Development of an Automatic Trend Exploration System using the {M}u{ST} Data Collection,2006,5,3,7,1,16788,masaki murata,Proceedings of the Workshop on Information Extraction Beyond The Document,0,"The automatic extraction of trend information from text documents such as newspaper articles would be useful for exploring and examining trends. To enable this, we used data sets provided by a workshop on multimodal summarization for trend information (the MuST Workshop) to construct an automatic trend exploration system. This system first extracts units, temporals, and item expressions from newspaper articles, then it extracts sets of expressions as trend information, and finally it arranges the sets and displays them in graphs. For example, when documents concerning the politics are given, the system extracts % and Cabinet approval rating as a unit and an item expression including temporal expressions. It next extracts values related to %. Finally, it makes a graph where temporal expressions are used for the horizontal axis and the value of percentage is shown on the vertical axis. This graph indicates the trend of Cabinet approval rating and is useful for investigating Cabinet approval rating. Graphs are obviously easy to recognize and useful for understanding information described in documents. In experiments, when we judged the extraction of a correct graph as the top output to be correct, the system accuracy was 0.2500 in evaluation A and 0.3334 in evaluation B. (In evaluation A, a graph where 75% or more of the points were correct was judged to be correct; in evaluation B, a graph where 50% or more of the points were correct was judged to be correct.) When we judged the extraction of a correct graph in the top five outputs to be correct, accuracy rose to 0.4167 in evaluation A and 0.6250 in evaluation B. Our system is convenient and effective because it can output a graph that includes trend information at these levels of accuracy when given only a set of documents as input."
W06-0116,{C}hinese Named Entity Recognition with Conditional Random Fields,2006,3,53,3,1,21231,wenliang chen,Proceedings of the Fifth {SIGHAN} Workshop on {C}hinese Language Processing,0,"We present a Chinese Named Entity Recognition (NER) system submitted to the close track of Sighan Bakeoff2006. We define some additional features via doing statistics in training corpus. Our system incorporates basic features and additional features based on Conditional Random Fields (CRFs). In order to correct inconsistently results, we perform the postprocessing procedure according to n-best results given by the CRFs model. Our final system achieved a F-score of 85.14 at MSRA, 89.03 at CityU, and 76.27 at LDC."
P06-2013,An Empirical Study of {C}hinese Chunking,2006,25,43,3,1,21231,wenliang chen,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"In this paper, we describe an empirical study of Chinese chunking on a corpus, which is extracted from UPENN Chinese Treebank-4 (CTB4). First, we compare the performance of the state-of-the-art machine learning models. Then we propose two approaches in order to improve the performance of Chinese chunking. 1) We propose an approach to resolve the special problems of Chinese chunking. This approach extends the chunk tags for every problem by a tag-extension function. 2) We propose two novel voting methods based on the characteristics of chunking task. Compared with traditional voting methods, the proposed voting methods consider long distance information. The experimental results show that the SVMs model outperforms the other models and that our proposed approaches can improve performance significantly."
P06-2042,Detection of Quotations and Inserted Clauses and Its Application to Dependency Structure Analysis in Spontaneous {J}apanese,2006,4,0,4,0,49924,ryoji hamabe,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"Japanese dependency structure is usually represented by relationships between phrasal units called bunsetsus. One of the biggest problems with dependency structure analysis in spontaneous speech is that clause boundaries are ambiguous. This paper describes a method for detecting the boundaries of quotations and inserted clauses and that for improving the dependency accuracy by applying the detected boundaries to dependency structure analysis. The quotations and inserted clauses are determined by using an SVM-based text chunking method that considers information on morphemes, pauses, fillers, etc. The information on automatically analyzed dependency structure is also used to detect the beginning of the clauses. Our evaluation experiment using Corpus of Spontaneous Japanese (CSJ) showed that the automatically estimated boundaries of quotations and inserted clauses helped to improve the accuracy of dependency structure analysis."
P06-2076,Machine-Learning-Based Transformation of Passive {J}apanese Sentences into Active by Separating Training Data into Each Input Particle,2006,6,1,4,1,16788,masaki murata,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"We developed a new method of transforming Japanese case particles when transforming Japanese passive sentences into active sentences. It separates training data into each input particle and uses machine learning for each particle. We also used numerous rich features for learning. Our method obtained a high rate of accuracy (94.30%). In contrast, a method that did not separate training data for any input particles obtained a lower rate of accuracy (92.00%). In addition, a method that did not have many rich features for learning used in a previous study (Murata and Isahara, 2003) obtained a much lower accuracy rate (89.77%). We confirmed that these improvements were significant through a statistical test. We also conducted experiments utilizing traditional methods using verb dictionaries and manually prepared heuristic rules and confirmed that our method obtained much higher accuracy rates than traditional methods."
tongchim-etal-2006-blind,Blind Evaluation for {T}hai Search Engines,2006,8,0,4,1,48449,shisanu tongchim,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper compares the effectiveness of two different Thai search engines by using a blind evaluation. The probabilistic-based dictionary-less search engine is evaluated against the traditional word-based indexing method. The web documents from 12 Thai newspaper web sites consisting of 83,453 documents are used as the test collection. The relevance judgment is conducted on the first five returned results from each system. The evaluation process is completely blind. That is, the retrieved documents from both systems are shown to the judges without any information about thesearch techniques. Statistical testing shows that the dictionary-less approach is better than the word-based indexingapproach in terms of the number of found documents and the number of relevance documents."
kruengkrai-etal-2006-conditional,A Conditional Random Field Framework for {T}hai Morphological Analysis,2006,14,27,3,1,8038,canasai kruengkrai,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper presents a framework for Thai morphological analysis based on the theoretical background of conditional random fields. We formulate morphological analysis of an unsegmented language as the sequential supervised learning problem. Given a sequence of characters, all possibilities of word/tag segmentation are generated, and then the optimal path is selected with some criterion. We examine two different techniques, including the Viterbi score and the confidence estimation. Preliminary results are given to show the feasibility of our proposed framework."
uchimoto-etal-2006-dependency,Dependency-structure Annotation to Corpus of Spontaneous {J}apanese,2006,10,3,6,1,30019,kiyotaka uchimoto,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In Japanese, syntactic structure of a sentence is generally represented by the relationship between phrasal units, or bunsetsus inJapanese, based on a dependency grammar. In the same way, thesyntactic structure of a sentence in a large, spontaneous, Japanese-speech corpus, the Corpus of Spontaneous Japanese (CSJ), isrepresented by dependency relationships between bunsetsus. This paper describes the criteria and definitions of dependency relationships between bunsetsus in the CSJ. The dependency structure of the CSJ is investigated, and the difference in the dependency structures ofwritten text and spontaneous speech is discussed in terms of thedependency accuracies obtained by using a corpus-based model. It is shown that the accuracy of automatic dependency-structure analysis canbe improved if characteristic phenomena of spontaneous speech such as self-corrections, basic utterance units in spontaneous speech, and bunsetsus that have no modifiee are detected and used for dependency-structure analysis."
kanamaru-etal-2006-creation,Creation of a {J}apanese Adverb Dictionary that Includes Information on the Speaker{'}s Communicative Intention Using Machine Learning,2006,2,0,3,1,48624,toshiyuki kanamaru,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Japanese adverbs are classified as either declarative or normal; the former declare the communicative intention of the speaker, while the latter convey a manner of action, a quantity, or a degree by which the adverb modifies the verb or adjective that it accompanies. We have automatically classified adverbs as either declarative or not declarative using a machine-learning method such as the maximum entropy method. We defined adverbs having positive or negative connotations as the positive data. We classified adverbs in the EDR dictionary and IPADIC used by Chasen using this result and built an adverb dictionary that contains descriptions of the communicative intentions of the speaker."
uchimoto-etal-2006-automatic,Automatic Detection and Semi-Automatic Revision of Non-Machine-Translatable Parts of a Sentence,2006,3,3,4,1,30019,kiyotaka uchimoto,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"We developed a method for automatically distinguishing the machine-translatable and non-machine-translatable parts of a given sentence for a particular machine translation (MT) system. They can be distinguished by calculating the similarity between a source-language sentence and its back translation for each part of the sentence. The parts with low similarities are highly likely to be non-machine-translatable parts. We showed that the parts of a sentence that are automatically distinguished as non-machine-translatable provide useful information for paraphrasing or revising the sentence in the source language to improve the quality of the translation by the MT system. We also developed a method of providing knowledge useful to effectively paraphrasing or revising the detected non-machine-translatable parts. Two types of knowledge were extracted from the EDR dictionary: one for transforming a lexical entry into an expression used in the definition and the other for conducting the reverse paraphrasing, which transforms an expression found in a definition into the lexical entry. We found that the information provided by the methods helped improve the machine translatability of the originally input sentences."
kanzaki-etal-2006-semantic,Semantic Analysis of Abstract Nouns to Compile a Thesaurus of Adjectives,2006,10,1,4,1,15923,kyoko kanzaki,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Aiming to compile a thesaurus of adjectives, we discuss how to extract abstract nouns categorizing adjectives, clarify the semantic and syntactic functions of these abstract nouns, and manually evaluate the capability to extract the Âinstance-categoryÂ relations. We focused on some Japanese syntactic structures and utilized possibility of omission of abstract noun to decide whether or not a semantic relation between an adjective and an abstract noun is an Âinstance-categoryÂ relation. For 63{\%} of the adjectives (57 groups/90 groups) in our experiments, our extracted categories were found to be most suitable. For 22 {\%} of the adjectives (20/90), the categories in the EDR lexicon were found to be most suitable. For 14{\%} of the adjectives (13/90), neither our extracted categories nor those in EDR were found to be suitable, or examineesÂ own categories were considered to be more suitable. From our experimental results, we found that the correspondence between a group of adjectives and their category name was more suitable in our method than in the EDR lexicon."
kuroda-etal-2006-getting,Getting Deeper Semantics than {B}erkeley {F}rame{N}et with {MSFA},2006,12,3,3,0.701754,45029,kow kuroda,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper illustrates relevant details of an on-going semantic-role annotation work based on a framework called MULTILAYERED/DIMENSIONAL SEMANTIC FRAME ANALYSIS (MSFA for short) (Kuroda and Isahara, 2005b), which is inspired by, if not derived from, Frame Semantics/Berkeley FrameNet approach to semantic annotation (Lowe et al., 1997; Johnson and Fillmore, 2000)."
charoenporn-etal-2006-word,Word Knowledge Acquisition for Computational Lexicon Construction,2006,8,0,5,1,42113,thatsanee charoenporn,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The growing of multilingual information processing technology has created the need of linguistic resources, especially lexical database. Many attempts were put to alter the traditional dictionary to computational dictionary, or widely named as computational lexicon. TCLÂs Computational Lexicon (TCLLEX) is a recent development of a large-scale Thai Lexicon, which aims to serve as a fundamental linguistic resource for natural language processing research. We design either terminology or ontology for structuring the lexicon based on the idea of computability and reusability."
yamamoto-etal-2006-detection,Detection of inconsistencies in concept classifications in a large dictionary {---} Toward an improvement of the {EDR} electronic dictionary {---},2006,4,0,3,1,15924,eiko yamamoto,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The EDR electronic dictionary is a machine-tractable dictionary developed for advanced computer-based processing of natural lan-guage. This dictionary comprises eleven sub-dictionaries, including a concept dictionary, word dictionaries, bilingual dictionaries, co-occurrence dictionaries, and a technical terminology dictionary. In this study, we focus on the concept dictionary and aim to revise the arrangement of concepts for improving the EDR electronic dictionary. We believe that unsuitable concepts in a class differ from other concepts in the same class from an abstract perspective. From this notion, we first try to automatically extract those concepts unsuited to the class. We then try semi-automatically to amend the concept explications used to explain the meanings to human users and rearrange them in suitable classes. In the experiment, we try to revise those concepts that are the lower-concepts of the concept ÂhumanÂ in the concept hierarchy and that are directly arranged under concepts with concept explications such as Âperson as defined by ÂÂ and Âperson viewed from Â.Â We analyze the result and evaluate our approach."
Y05-1014,"Analysis of Machine Translation Systems{'} Errors in Tense, Aspect, and Modality",2005,10,8,5,1,16788,masaki murata,"Proceedings of the 19th Pacific Asia Conference on Language, Information and Computation",0,"Errors of the translation of tense, aspect, and modality by machine translation systems were analyzed for six translation systems on the market and our new systems for translating tense, aspect, and modality. The results showed that our systems outperformed the other systems. They also showed that the other systems often produced progressive forms rather than the correct present forms. Our systems rarely made this mistake. Translation systems on the market could thus be improved by incorporating the methods used in our systems. Moreover, error analysis of the translation systems on the market identified information that would be useful for improving them."
P05-3030,Organizing {E}nglish Reading Materials for Vocabulary Learning,2005,2,0,3,1,127,masao utiyama,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"We propose a method of organizing reading materials for vocabulary learning. It enables us to select a concise set of reading texts (from a target corpus) that contains all the target vocabulary to be learned. We used a specialized vocabulary for an English certification test as the target vocabulary and used English Wikipedia, a free-content encyclopedia, as the target corpus. The organized reading materials would enable learners not only to study the target vocabulary efficiently but also to gain a variety of knowledge through reading. The reading materials are available on our web site."
I05-6002,Obtaining {J}apanese Lexical Units for Semantic Frames from {B}erkeley {F}rame{N}et Using a Bilingual Corpus,2005,10,2,4,1,48624,toshiyuki kanamaru,Proceedings of the Sixth International Workshop on Linguistically Interpreted Corpora ({LINC}-2005),0,None
I05-6009,Error Annotation for Corpus of {J}apanese Learner {E}nglish,2005,9,28,3,1,50987,emi izumi,Proceedings of the Sixth International Workshop on Linguistically Interpreted Corpora ({LINC}-2005),0,"In this paper, we discuss how error annotation for learner corpora should be done by explaining the state of the art of error tagging schemes in learner corpus research. Several learner corpora, including the NICT JLE (Japanese Learner English) Corpus that we have compiled are annotated with error tagsets designed by categorizing xe2x80x9clikelyxe2x80x9d errors implied from the existing canonical grammar rules or POS (part-of-speech) system in advance. Such error tagging can help to successfully assess to what extent learners can command the basic language system, especially grammar, but is insufficient for describing learnersxe2x80x99 communicative competence. To overcome this limitation, we reexamined learner language in the NICT JLE Corpus by focusing on xe2x80x9cintelligibilityxe2x80x9d and xe2x80x9cnaturalnessxe2x80x9d, and determined how the current error tagset should be revised."
I05-2008,A System to Solve Language Tests for Second Grade Students,2005,-1,-1,4,0,50069,manami saito,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,None
I05-2015,Building an Annotated {J}apanese-{C}hinese Parallel Corpus - A Part of {NICT} Multilingual Corpora,2005,9,9,4,1,9062,yujie zhang,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"We are constricting a Japanese-Chinese parallel corpus, which is a part of the NICT Multilingual Corpora. The corpus is general domain, of large scale of about 40,000 sentence pairs, long sentences, annotated with detailed information and high quality. To the best of our knowledge, this will be the first annotated JapaneseChinese parallel corpus in the world. We created the corpus by selecting Japanese sentences from Mainichi Newspaper and then manually translating them into Chinese. We then annotated the corpus with morphological and syntactic structures and alignments at word and phrase levels. This paper describes the specification in human translation and the scheme of detailed information annotation, and the tools we developed in the corpus construction. The experience we obtained and points we paid special attentions are also introduced for share with other researches in corpora construction."
I05-2024,Information Retrieval Capable of Visualization and High Precision,2005,7,2,4,1,33252,qing ma,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"We present a neural-network based selforganizing approach that enables visualization of the information retrieval while at the same time improving its precision. In computer experiments, two-dimensional documentary maps in which queries and documents were mapped in topological order according to their similarities were created. The ranking of the results retrieved using the maps was better than that of the results obtained using a conventional TFIDF method. Furthermore, the precision of the proposed method was much higher than that of the conventional TFIDF method when the process was focused on retrieving highly relevant documents, suggesting that the proposed method might be especially suited to information retrieval tasks in which precision is more critical than recall."
I05-2042,Toward a Unified Evaluation Method for Multiple Reading Support Systems: A Reading Speed-based Procedure,2005,2,0,5,1,28269,katsunori kotani,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"This paper proposes a unified evaluation method for multiple reading support systems such as a sentence translation system and a word translation system. In reading a non-native language text, these systems aim to lighten the reading burden. When we evaluate the performance of these systems, we cannot rely solely on these tests, as the output forms are different. Therefore, we must assess the performance of these systems based on the usersxe2x80x99 reading comprehension and reading speed. We will further support our findings with experimental results. They show that the reading-speed procedure is able to evaluate the support systems, as well as, the comprehensionbased procedure proposed by Ohguro (1993) and Fuji et al. (2001)."
I05-2043,Trend Survey on {J}apanese Natural Language Processing Studies over the Last Decade,2005,0,3,6,1,16788,masaki murata,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"Using natural language processing, we carried out a trend survey on Japanese natural language processing studies that have been done over the last ten years. We determined the changes in the number of papers published for each research organization and on each research area as well as the relationship between research organizations and research areas. This paper is useful for both recognizing trends in Japanese NLP and constructing a method of supporting trend surveys using NLP."
I05-1031,Analysis of an Iterative Algorithm for Term-Based Ontology Alignment,2005,11,1,5,1,48449,shisanu tongchim,Second International Joint Conference on Natural Language Processing: Full Papers,0,"This paper analyzes the results of automatic concept alignment between two ontologies. We use an iterative algorithm to perform concept alignment. The algorithm uses the similarity of shared terms in order to find the most appropriate target concept for a particular source concept. The results show that the proposed algorithm not only finds the relation between the target concepts and the source concepts, but the algorithm also shows some flaws in the ontologies. These results can be used to improve the correctness of the ontologies."
H05-2014,{J}apanese Speech Understanding using Grammar Specialization,2005,6,5,5,0,11421,manny rayner,Proceedings of {HLT}/{EMNLP} 2005 Interactive Demonstrations,0,"The most common speech understanding architecture for spoken dialogue systems is a combination of speech recognition based on a class N-gram language model, and robust parsing. For many types of applications, however, grammar-based recognition can offer concrete advantages. Training a good class N-gram language model requires substantial quantities of corpus data, which is generally not available at the start of a new project. Head-to-head comparisons of class N-gram/robust and grammar-based systems also suggest that users who are familiar with system coverage get better results from grammar-based architectures (Knight et al., 2001). As a consequence, deployed spoken dialogue systems for real-world applications frequently use grammar-based methods. This is particularly the case for speech translation systems. Although leading research systems like Verbmobil and NE-SPOLE! (Wahlster, 2000; Lavie et al., 2001) usually employ complex architectures combining statistical and rule-based methods, successful practical examples like Phraselator and S-MINDS (Phraselator, 2005; Sehda, 2005) are typically phrasal translators with grammar-based recognizers."
2005.mtsummit-papers.2,Selection of Entries for a Bilingual Dictionary from Aligned Translation Equivalents using Support Vector Machines,2005,-1,-1,5,1,51041,takeshi kutsumi,Proceedings of Machine Translation Summit X: Papers,0,"This paper claims that constructing a dictionary using bilingual pairs obtained from parallel corpora needs not only correct alignment of two noun phrases but also judgment of its appropriateness as an entry. It specifically addresses the latter task, which has been paid little attention. It demonstrates a method of selecting a suitable entry using Support Vector Machines, and proposes to regard as the features the common and the different parts between a current translation and a new translation. Using experiment results, this paper examines how selection performances are affected by the four ways of representing the common and the different parts: morphemes, parts of speech, semantic markers, and upper-level semantic markers. Moreover, we used n-grams of the common and the different parts of above four kinds of features. Experimental result found that representation by morphemes marked the best performance, F-measure of 0.803."
2005.mtsummit-papers.10,Building an Annotated {J}apanese-{C}hinese Parallel Corpus {--} A Part of {NICT} Multilingual Corpora,2005,9,9,4,1,9062,yujie zhang,Proceedings of Machine Translation Summit X: Papers,0,"We are constricting a Japanese-Chinese parallel corpus, which is a part of the NICT Multilingual Corpora. The corpus is general domain, of large scale of about 40,000 sentence pairs, long sentences, annotated with detailed information and high quality. To the best of our knowledge, this will be the first annotated Japanese-Chinese parallel corpus in the world. We created the corpus by selecting Japanese sentences from Mainichi Newspaper and then manually translating them into Chinese. We then annotated the corpus with morphological and syntactic structures and alignments at word and phrase levels. This paper describes the specification in human translation and detailed information annotation, and the tools we developed in the project. The experience we obtained and points we paid special attentions are also introduced for share with other researches in corpora construction."
2005.mtsummit-papers.18,A Multi-aligner for {J}apanese-{C}hinese Parallel Corpora,2005,-1,-1,4,1,9062,yujie zhang,Proceedings of Machine Translation Summit X: Papers,0,"Automatic word alignment is an important technology for extracting translation knowledge from parallel corpora. However, automatic techniques cannot resolve this problem completely because of variances in translations. We therefore need to investigate the performance potential of automatic word alignment and then decide how to suitably apply it. In this paper we first propose a lexical knowledge-based approach to word alignment on a Japanese-Chinese corpus. Then we evaluate the performance of the proposed approach on the corpus. At the same time we also apply a statistics-based approach, the well-known toolkit GIZA++, to the same test data. Through comparison of the performances of the two approaches, we propose a multi-aligner, exploiting the lexical knowledge-based aligner and the statistics-based aligner at the same time. Quantitative results confirmed the effectiveness of the multi-aligner."
2005.mtsummit-papers.25,Practicing Controlled Language through a Help System integrated into the Medical Speech Translation System ({M}ed{SLT}),2005,9,13,7,0,37884,marianne starlander,Proceedings of Machine Translation Summit X: Papers,0,"In this paper, we present evidence that providing users of a speech to speech translation system for emergency diagnosis (MedSLT) with a tool that helps them to learn the coverage greatly improves their success in using the system. In MedSLT, the system uses a grammar-based recogniser that provides more predictable results to the translation component. The help module aims at addressing the lack of robustness inherent in this type of approach. It takes as input the result of a robust statistical recogniser that performs better for out-of-coverage data and produces a list of in-coverage example sentences. These examples are selected from a defined list using a heuristic that prioritises sentences maximising the number of N-grams shared with those extracted from the recognition result."
2005.mtsummit-papers.31,Automatic Rating of Machine Translatability,2005,4,17,4,1,30019,kiyotaka uchimoto,Proceedings of Machine Translation Summit X: Papers,0,"We describe a method for automatically rating the machine translatability of a sentence for various machine translation (MT) systems. The method requires that the MT system can bidirectionally translate sentences in both source and target languages. However, it does not require reference translations, as is usual for automatic MT evaluation. By applying this method to every component of a sentence in a given source language, we can automatically identify the machine-translatable and non-machinetranslatable parts of a sentence for a particular MT system. We show that the parts of a sentence that are automatically identified as nonmachine-translatable provide useful information for paraphrasing or revising the sentence in the source language, thus improving the quality of the final translation."
2005.mtsummit-invited.7,Introduction to {C}hina{'}s {HTRDP} Machine Translation Evaluation,2005,-1,-1,6,0,5775,qun liu,Proceedings of Machine Translation Summit X: Invited papers,0,"Since 1994, China{'}s HTRDP machine translation evaluation has been conducted for five times. Systems of various translation directions between Chinese, English, Japanese and French have been tested. Both human evaluation and automatic evaluation are conducted in HTRDP evaluation. In recent years, the evaluation was organized jointly with NICT of Japan. This paper introduces some details of this evaluation."
2005.eamt-1.8,A generic multi-lingual open source platform for limited-domain medical speech translation,2005,9,42,9,0.359496,2866,pierrette bouillon,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,"We present an overview of MedSLT, an Open Source platform for developing limited-domain medical speech translation systems. We focus in particular on the speech understanding architecture, which uses grammar-based language models derived using cor- pus-based specialisation methods from a single linguistically motivated grammar, and summarise the results of two evaluations which investigate the appropriateness of these de- sign choices. Other sections describe the interlingua and its relationship with the recogni- tion architecture, and the current demo system."
Y04-1017,Constructing {E}nglish Reading Courseware,2004,3,2,3,1,127,masao utiyama,"Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation",0,"There is a wide range of English reading materials for EFL (English as a foreign language) learners. However, it is difficult for teachers to select appropriate materials to construct courseware that can be used for an English course. We propose a method for constructing courseware from a target vocabulary and a corpus. We used the specialized vocabulary for the Test of English for International Communication (TOEIC) and articles from The Daily Yomiurinewspaper to construct effective courseware. The constructed courseware consisted of articles in which the target vocabulary frequently occurred. Evaluation of the constructed courseware is ongoing. However, students have accepted it as an effective tool for learning the TOEIC vocabulary from real texts."
Y04-1018,Acquiring Compound Word Translations both Automatically and Dynamically,2004,5,5,2,1,9062,yujie zhang,"Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation",0,This paper addresses the problem of compound word translation and proposes the approaches to acquiring translations. The proposed approaches focus on exploring web data and utilizing English translations to link words of the source language and the correspondences in the target language. The paper uses Japanese-Chinese language pairs for the sake of illustration and shows initial experimental results. The proposed method is language-independent and therefore can be applied to other language pairs.
Y04-1019,Integrated Use of Internal and External Evidence in the Alignment of Multi-Word Named Entities,2004,0,0,5,1,51041,takeshi kutsumi,"Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation",0,None
Y04-1032,Three {E}nglish Learner Assistance Systems Using Automatic Paraphrasing Techniques,2004,9,1,2,1,16788,masaki murata,"Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation",0,"We developed three systems based on automatic paraphrasing techniques to help English learners and English-language beginners. One system extracts personal error patterns in the userxe2x80x99s English usage. The second transforms English sentences containing the letters xe2x80x9clxe2x80x9d and xe2x80x9crxe2x80x9d into sentences containing fewer instances of these letters, which Japanese people have trouble pronouncing properly in English. This system could be used, for example, to transform a draft of a presentation that a Japanese speaker was to present to an audience. The third is an annotation system that provides definition sentences of difficult English words, making them easier to understand. We believe that these systems will be useful both for learners of English and in studies on second-language acquisition."
W04-2208,Multilingual Aligned Parallel Treebank Corpus Reflecting Contextual Information and Its Applications,2004,13,18,6,1,30019,kiyotaka uchimoto,Proceedings of the Workshop on Multilingual Linguistic Resources,0,"This paper describes Japanese-English-Chinese aligned parallel treebank corpora of newspaper articles. They have been constructed by translating each sentence in the Penn Treebank and the Kyoto University text corpus into a corresponding natural sentence in a target language. Each sentence is translated so as to reflect its contextual information and is annotated with morphological and syntactic structures and phrasal alignment. This paper also describes the possible applications of the parallel corpus and proposes a new framework to aid in translation. In this framework, parallel translations whose source language sentence is similar to a given sentence can be semi-automatically generated. In this paper we show that the framework can be achieved by using our aligned parallel treebank corpus."
P04-3015,Hierarchy Extraction based on Inclusion of Appearance,2004,10,5,3,1,15924,eiko yamamoto,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"In this paper, we propose a method of automatically extracting word hierarchies based on the inclusion relation of appearance patterns from corpora. We apply a complementary similarity measure to find a hierarchical word structure. This similarity measure was developed for the recognition of degraded machine-printed text in the field and can be applied to estimate one-to-many relations. Our purpose is to extract word hierarchies from corpora automatically. As the initial task, we attempt to extract hierarchies of abstract nouns co-occurring with adjectives in Japanese and compare with hierarchies in the EDR electronic dictionary."
charoenporn-etal-2004-open,Open Collaborative Development of the {T}hai Language Resources for Natural Language Processing,2004,5,0,5,1,42113,thatsanee charoenporn,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Language Resources are recognized as an essential component in linguistic infrastructure and a starting point of Natural Language Processing systems and applications. In this paper, we describe the achievement of the development and the use of Thai Language Resources germinated with an open collaboration platform, under the collaboration between research institutes. The resources include either text or speech. Text resources are divided into lexicon database and annotated corpus. We started developing a corpus-based Thai-English lexicon database (LEXiTRON) since 1994. It was originated from a dictionary designed for using in developing a machine translation system. Since then the Thai POS was designed and evaluated in several applications (word segmentation, machine translation, grapheme-to-phoneme, etc.) Extending the lexicon database, POS tagged corpus (ORCHID), and speech corpora for both synthesis and recognition are developed and functioned as an important part of research and development on NLP or HLT. These language resources are available for academic experiment."
izumi-etal-2004-overview,The Overview of the {SST} Speech Corpus of {J}apanese Learner {E}nglish and Evaluation Through the Experiment on Automatic Detection of Learners{'} Errors,2004,5,37,3,1,50987,emi izumi,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper introduces an overview of the speech corpus of Japanese learner English compiled by National Institute of Information and Communications Technology by showing its data collection procedure and annotation schemes including error tagging. We have collected 1,200 interviews for three years. One of the most unique features of this corpus is that it contains rich information on learnersxe2x80x99 errors. We have performed error tagging for learnersxe2x80x99 grammatical and lexical errors with originally-designed error tagset. We also evaluated the corpus through the experiment on automatic detection of learnersxe2x80x99 errors by using error tag information in the corpus. We did this by using a machine learning model, Maximum Entropy (ME) model. Since we had obtained the limited amount of error-tagged data, we needed to make some efforts to enlarge training data. We added the correct sentences and artificially-made errors to the training data, and found that it improved accuracy. We are planning to make this corpus publicly available in the spring of 2004, so that teachers and researchers in many fields can use the data for their own interests, such as second language acquisition research, syllabus and material design, or the development of computerized pedagogical tools, by combining it with NLP technology."
kanzaki-etal-2004-extraction,Extraction of Hyperonymy of Adjectives from Large Corpora by Using the Neural Network Model,2004,1,2,5,1,15923,kyoko kanzaki,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"In this research, we extract hierarchical abstract concepts of adjectives automatically from large corpora by using the Neural Network Model. We show the hierarchies on the Semantic Map and compare the hierarchies in the Semantic Map and a manually prepared thesaurus. We recognized five types of distributions on the map. By comparing the Semantic Map and a manual thesaurus, we found that the word that the abstract noun belongs to, whether a person, thing or event, is introduced as the standard of classification in the manual thesaurus. On the other hand, in the Semantic Map, we found that abstract nouns belonging to people or events are distributed together. We also found that the hierarchies of sokumen (side), imi (meaning), and kanten (viewpoint) are necessary for a category of adjectives."
kruengkrai-etal-2004-enriching,Enriching a {T}hai Lexical Database with Selectional Preferences,2004,10,0,4,1,8038,canasai kruengkrai,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"A statistical corpus-based approach for acquiring selectional preferences of verbs is proposed. By parsing through text corpora, we obtain examples of context nouns that are considered to be the selectional preferences of a given verb. The approach is to generalize initial noun classes to the most appropriate levels on a semantic hierarchy. We present an iterative algorithm for generalization by combining an agglomerative merging and a model selection technique called the Bayesian Information Criterion (BIC). In our experiments, we consider the Web as the large corpora. We also propose approaches for extracting examples from the Web. Preliminarily experimental results are given to show the feasibility and effectiveness of our approach."
C04-1159,Dependency Structure Analysis and Sentence Boundary Detection in Spontaneous {J}apanese,2004,11,11,4,0,52399,kazuya shitaoka,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"This paper describes a project to detect dependencies between Japanese phrasal units called bunsetsus, and sentence boundaries in a spontaneous speech corpus. In monologues, the biggest problem with dependency structure analysis is that sentence boundaries are ambiguous. In this paper, we propose two methods for improving the accuracy of sentence boundary detection in spontaneous Japanese speech: One is based on statistical machine translation using dependency information and the other is based on text chunking using SVM. An F-measure of 84.9 was achieved for the accuracy of sentence boundary detection by using the proposed methods. The accuracy of dependency structure analysis was also improved from 75.2% to 77.2% by using automatically detected sentence boundaries. The accuracy of dependency structure analysis and that of sentence boundary detection were also improved by interactively using both automatically detected dependency structures and sentence boundaries."
C04-1165,Construction of an Objective Hierarchy of Abstract Concepts via Directional Similarity,2004,7,5,4,1,15923,kyoko kanzaki,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"The method of organization of word meanings is a crucial issue with lexical databases. Our purpose in this research is to extract word hierarchies from corpora automatically. Our initial task to this end is to determine adjective hyperonyms. In order to find adjective hyperonyms, we utilize abstract nouns. We constructed linguistic data by extracting semantic relations between abstract nouns and adjectives from corpus data and classifying abstract nouns based on adjective similarity using a self-organizing semantic map, which is a neural network model (Kohonen 1995). In this paper we describe how to hierarchically organize abstract nouns (adjective hyperonyms) in a semantic map mainly using CSM. We compare three hierarchical organizations of abstract nouns, according to CSM, frequency (Tf.CSM) and an alternative similarity measure based on coefficient overlap, to estimate hyperonym relations between words."
W03-1714,Semantic Maps for Word Alignment in Bilingual Parallel Corpora,2003,11,4,4,1,33252,qing ma,Proceedings of the Second {SIGHAN} Workshop on {C}hinese Language Processing,0,"Effective self-organizing techniques for constructing monolingual semantic maps of Japanese and Chinese have already been developed. By extending the monolingual map to a bilingual semantic map, we have proposed a semantics-based approach for word alignment in a Japanese/Chinese bilingual corpus."
W03-1607,Criterion for Judging Request Intention in Response Texts of Open-Ended Questionnaires,2003,6,4,3,0,52674,hiroko inui,Proceedings of the Second International Workshop on Paraphrasing,0,"Our general research aim is to extract the actual intentions of persons when they respond to open-ended questionnaires. These intentions include the desire to make requests, complaints, expressions of resignation and so forth, but here we focus on extracting the intention to make a request. To do so, we first have to judge whether their responses contain the intent to make a request. Therefore, as a first step, we have developed a criterion for judging the existence of request intentions in responses. This criterion, which is based on paraphrasing, is described in detail in this paper. Our assumption is that a response with request intentions can be paraphrased into a typical request expression, e.g., I would like to ..., while responses without request are not paraphrasable. The criterion is evaluated in terms of objectivity, reproducibility and effectiveness. Objectivity is demonstrated by showing that machine learning methods can learn the criterion from a set of intention-tagged data, while reproducibility, that the judgments of three annotators are reasonably consistent, and effectiveness, that judgments based not on the criterion but on intuition do not agree. This means the criterion is necessary to achieve reproducibility. These experiments indicate that the criterion can be used to judge the existence of request intentions in responses reliably."
W03-1204,Evaluation of Features for Sentence Extraction on Different Types of Corpora,2003,9,6,3,1,51944,chikashi nobata,Proceedings of the {ACL} 2003 Workshop on Multilingual Summarization and Question Answering,0,"We report evaluation results for our summarization system and analyze the resulting summarization data for three different types of corpora. To develop a robust summarization system, we have created a system based on sentence extraction and applied it to summarize Japanese and English newspaper articles, obtained some of the top results at two evaluation workshops. We have also created sentence extraction data from Japanese lectures and evaluated our system with these data. In addition to the evaluation results, we analyze the relationships between key sentences and the features used in sentence extraction. We find that discrete combinations of features match distributions of key sentences better than sequential combinations."
P03-2024,A Limited-Domain {E}nglish to {J}apanese Medical Speech Translator Built Using {REGULUS} 2,2003,5,12,4,0,11421,manny rayner,The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics,0,"We argue that verbal patient diagnosis is a promising application for limited-domain speech translation, and describe an architecture designed for this type of task which represents a compromise between principled linguistics-based processing on the one hand and efficient phrasal translation on the other. We propose to demonstrate a prototype system instantiating this architecture, which has been built on top of the Open Source REGULUS 2 platform. The prototype translates spoken yes-no questions about headache symptoms from English to Japanese, using a vocabulary of about 200 words."
P03-2026,Automatic Error Detection in the {J}apanese Learners{'} {E}nglish Spoken Data,2003,3,95,5,1,50987,emi izumi,The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics,0,"This paper describes a method of detecting grammatical and lexical errors made by Japanese learners of English and other techniques that improve the accuracy of error detection with a limited amount of training data. In this paper, we demonstrate to what extent the proposed methods hold promise by conducting experiments using our learner corpus, which contains information on learners' errors."
P03-2032,Extraction and Verification of {KO}-{OU} Expressions from Large Corpora,2003,0,0,4,0,52835,atsuko kida,The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics,0,"In the Japanese language, as a predicate is placed at the end of a sentence, the content of a sentence cannot be inferred until reaching the end. However, when the content is complicated and the sentence is long, people want to know at an earlier stage in the sentence whether the content is negative, affirmative, or interrogative. In Japanese, the grammatical form called the KO-OU relation exists. The KO-OU relation is a kind of concord. If a KO element appears, then an OU element appears in the latter part of a sentence. It is being pointed out that the KO-OU relation gives advance notice to the element that appears in the latter part of a sentence. In this paper, we present the method of extracting automatically the KO-OU expression data from large-scale electronic corpus and verify the usefulness of the KO-OU expression data."
P03-1010,Reliable Measures for Aligning {J}apanese-{E}nglish News Articles and Sentences,2003,7,144,2,1,127,masao utiyama,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"We have aligned Japanese and English news articles and sentences to make a large parallel corpus. We first used a method based on cross-language information retrieval (CLIR) to align the Japanese and English articles and then used a method based on dynamic programming (DP) matching to align the Japanese and English sentences in these articles. However, the results included many incorrect alignments. To remove these, we propose two measures (scores) that evaluate the validity of alignments. The measure for article alignment uses similarities in sentences aligned by DP matching and that for sentence alignment uses similarities in articles aligned by CLIR. They enhance each other to improve the accuracy of alignment. Using these measures, we have successfully constructed a large-scale article and sentence alignment corpus available to the public."
P03-1061,Morphological Analysis of a Large Spontaneous Speech Corpus in {J}apanese,2003,13,9,5,1,30019,kiyotaka uchimoto,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"This paper describes two methods for detecting word segments and their morphological information in a Japanese spontaneous speech corpus, and describes how to tag a large spontaneous speech corpus accurately by using the two methods. The first method is used to detect any type of word segments. The second method is used when there are several definitions for word segments and their POS categories, and when one type of word segments includes another type of word segments. In this paper, we show that by using semi-automatic analysis we achieve a precision of better than 99% for detecting and tagging short words and 97% for long words; the two types of words that comprise the corpus. We also show that better accuracy is achieved by using both methods than by using only the first."
W02-1107,Classification of Adjectival and Non-adjectival Nouns Based on their Semantic Behavior by Using a Self-Organizing Semantic Map,2002,7,3,4,1,15923,kyoko kanzaki,{COLING}-02: {SEMANET}: Building and Using Semantic Networks,0,"We treat nouns that behave adjectively, which we call adjectival nouns, extracted from large corpora. For example, in financial world and world of finance, financial and finance are different parts of speech, but their semantic behaviors are similar to each other. We investigate how adjectival nouns are similar to adjectives and different from non-adjectival nouns by using self-organizing semantic maps. We create five kinds of semantic maps, i.e., semantic maps of abstract nouns organized via (1) adjectives, (2) adjectival nouns, (3) non-adjectival nouns and (4) adjectival and adjectival nouns and a semantic map of adjectives, adjectival nouns and non-adjectival nouns organized via collocated abstract nouns, and compare them with each other to find similarities and differences."
murata-isahara-2002-automatic,"Automatic extraction of differences between spoken and written languages, and automatic translation from the written to the spoken language",2002,0,9,2,1,16788,masaki murata,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
nobata-etal-2002-summarization,Summarization System Integrated with Named Entity Tagging and {IE} pattern Discovery,2002,7,31,3,1,51944,chikashi nobata,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"We have introduced information extraction technique such as named entity tagging and pattern discovery to a summarization system based on sentence extraction technique, and evaluated the performance in the Document Understanding Conference 2001 (DUC-2001). We participated in the Single Document Summarization task in DUC-2001 and achieved one of the best performance in subjective evaluation of summarization results."
ogino-etal-2002-valence,The Valence Patterns of {J}apanese Verbs Extracted From The {EDR} Corpus,2002,1,0,2,0,53549,takano ogino,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper describes research on particular verb valences obtained from actual linguistic data. We created verb valence data using data from the EDR Co-occurrence Dictionary as our source. The EDR Co-occurrence Dictionary is coded with syntactic governing-dependent relation tags and semantic tags. The syntactic governing-dependent relations data in the EDR Co-occurrence Dictionary however, is expressed as individual constituent pairs. In this study, we grouped each of the governingdependent relation pairs according to their verb concepts and then unified them into a number of combinations based on case. After the data was automatically unified from the source data, we manually corrected mistaken governing-dependent relations, and also made changes to case where necessary. By following this procedure, we created basic valence data for each verb. Further, based on this valence data and the verb patterns created from it, we are currently looking into creating semantic groups for nouns on which semantic restrictions are imposed by the verb."
C02-2019,Morphological Analysis of the Spontaneous Speech Corpus,2002,7,7,5,1,30019,kiyotaka uchimoto,{COLING} 2002: The 17th International Conference on Computational Linguistics: Project Notes,0,"This paper describes a project tagging a spontaneous speech corpus with morphological information such as word segmentation and parts-of-speech. We use a morphological analysis system based on a maximum entropy model, which is independent of the domain of corpora. In this paper we show the tagging accuracy achieved by using the model and discuss problems in tagging the spontaneous speech corpus. We also show that a dictionary developed for a corpus on a certain domain is helpful for improving accuracy in analyzing a corpus on another domain."
C02-1060,Self-Organizing {C}hinese and {J}apanese Semantic Maps,2002,14,3,5,1,33252,qing ma,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper describes a corpus-based connectionist approach to the development of self-organizing Chinese and Japanese semantic maps, proposing an improved coding method using TFIDF term-weighting and newly introducing a numerical evaluation for objectively judging the results. The adaption of TFIDF term-weighting is proved to be effective by experimental comparisons with five other coding methods. The effectiveness and necessity of the proposed method for creating semantic maps are clarified by comparisons with a conventional clustering technique and multivariate statistical analysis."
C02-1064,Text Generation from Keywords,2002,15,23,3,1,30019,kiyotaka uchimoto,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"We describe a method for generating sentences from keywords or headwords. This method consists of two main parts, candidate-text construction and evaluation. The construction part generates text sentences in the form of dependency trees by using complementary information to replace information that is missing because of a knowledge gap and other missing function words to generate natural text sentences based on a particular monolingual corpus. The evaluation part consists of a model for generating an appropriate text when given keywords. This model considers not only word n-gram information, but also dependency information between words. Furthermore, it considers both string information and morphological information."
2002.tmi-papers.14,Correction of errors in a modality corpus used for machine translation using machine-learning,2002,-1,-1,5,1,16788,masaki murata,Proceedings of the 9th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
W01-1415,"Using a Support-Vector Machine for {J}apanese-to-{E}nglish Translation of Tense, Aspect, and Modality",2001,7,12,4,1,16788,masaki murata,Proceedings of the {ACL} 2001 Workshop on Data-Driven Methods in Machine Translation,0,"This paper describes experiments carried out using a variety of machine-learning methods, including the k-nearest neighborhood method that was used in a previous study, for the translation of tense, aspect, and modality. It was found that the support-vector machine method was the most precise of all the methods tested."
W01-0512,The Unknown Word Problem: a Morphological Analysis of {J}apanese Using Maximum Entropy Aided by a Dictionary,2001,0,45,3,1,30019,kiyotaka uchimoto,Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing,0,None
S01-1033,{J}apanese Word Sense Disambiguation using the Simple {B}ayes and Support Vector Machine Methods,2001,2,16,5,1,16788,masaki murata,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"We submitted four systems to the Japanese dictionary-based lexical-sample task of Senseval-2. They were i) the support vector machine method ii) the simple Bayes method, iii) a method combining the two, and iv) a method combining two kinds of each. The combined methods obtained the best precision among the submitted systems. After the contest, we tuned the parameter used in the simple Bayes method, and it obtained higher precision. An explanation of these systems used in Japanese word sense disambiguation was provided."
S01-1038,Word Translation Based on Machine Learning Models Using Translation Memory and Corpora,2001,1,0,4,1,30019,kiyotaka uchimoto,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"Senseval-2 was held in Spring, 2001. It consisted of several tasks in various languages. In this paper, we describe our system used for one of these tasks: the Japanese translation task. With an accuracy of 63.4%, our system was the third best system in the contest among nine systems developed by seven groups."
P01-1064,A Statistical Model for Domain-Independent Text Segmentation,2001,22,216,2,1,127,masao utiyama,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"We propose a statistical method that finds the maximum-probability segmentation of a given text. This method does not require training data because it estimates probabilities from the given text. Therefore, it can be applied to any text in any domain. An experiment showed that the method is more accurate than or at least as accurate as a state-of-the-art text segmentation system."
W00-0110,Similarities and Differences among Semantic Behaviors of {J}apanese Adnominal Constituents,2000,5,6,3,1,15923,kyoko kanzaki,{NAACL}-{ANLP} 2000 Workshop: Syntactic and Semantic Complexity in Natural Language Processing Systems,0,"This paper treats the classification of the semantic functions performed by adnominal constituents in Japanese, where many parts of speech act as adnominal constituents. In order to establish a formal treatment of the semantic roles, the similarities and differences among adnominal constituents, i.e. adjectives and noun  NO (in English of  noun) structures, which have a broad range of semantic functions, are discussed. This paper also proposes an objective method of classifying these constructs using a large amount of linguistic data. The feasibility of this was verified with a self-organizing semantic map based on a neural network model."
P00-1042,Named Entity Extraction Based on A Maximum Entropy Model and Transformation Rules,2000,13,63,5,1,30019,kiyotaka uchimoto,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"This paper describes named entity (NE) extraction based on a maximum entropy (M. E.) model and transformation rules. There are two types of named entities when focusing on the relationship between morphemes and NEs as defined in the NE task of the IREX competition held in 1999. Each NE consists of one or more morphemes, or includes a substring of a morpheme. We extract the former type of NE by using the M. E. model. We then extract the latter type of NE by applying transformation rules to the text."
sekine-isahara-2000-irex,{IREX}: {IR} {\\&} {IE} Evaluation Project in {J}apanese,2000,0,51,2,0.638505,1087,satoshi sekine,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"We will report on the IREX (Information Retrieval and Extraction Exercise) project. It is an evaluation-based project for Information Retrieval and Information Extraction in Japanese. The project started in May 1998 and concluded in September 1999 with the IREX workshop held in Tokyo with more than 150 attendance (IREX Commettee, 1999). There is a homepage of the project at (IREX, Homepage) and anyone can download almost all the data and the tools produced by the project for free."
maekawa-etal-2000-spontaneous,Spontaneous Speech Corpus of {J}apanese,2000,4,211,4,0,18342,kikuo maekawa,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"Design issues of a spontaneous speech corpus is described. The corpus under compilation will contain 800-1000 hour spontaneously uttered Common Japanese speech and the morphologically annotated transcriptions. Also, segmental and intonation labeling will be provided for a subset of the corpus. The primary application domain of the corpus is speech recognition of spontaneous speech, but we plan to make it useful for natural language processing and phonetic/linguistic studies also."
C00-2109,Backward Beam Search Algorithm for Dependency Analysis of {J}apanese,2000,8,19,3,0.638505,1087,satoshi sekine,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"Backward beam search for dependency analysis of Japanese is proposed. As dependencies normally go from left to right in Japanese, it is effective to analyze sentences backwards (from right to left). The analysis is based on a statistical method and employs a beam search strategy. Based on experiments varying the beam search width, we found that the accuracy is not sensitive to the beam width and even the analysis with a beam width of 1 gets almost the same dependency accuracy as the best accuracy using a wider beam width. This suggested a deterministic algorithm for backwards Japanese dependency analysis, although still the beam search is effective as the N-best sentence accuracy is quite high. The time of analysis is observed to be quadratic in the sentence length."
C00-2126,Word Order Acquisition from Corpora,2000,2,18,5,1,30019,kiyotaka uchimoto,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"In this paper we describe a method of acquiring word order from corpora. Word order is defined as the order of modifiers, or the order of phrasal units called 'bunsetsu' which depend on the same modifiee. The method uses a model which automatically discovers what the tendency of the word order in Japanese is by using various kinds of information in and around the target bunsetsus. This model shows us to what extent each piece of information contributes to deciding the word order and which word order tends to be selected when several kinds of information conflict. The contribution rate of each piece of information in deciding word order is efficiently learned by a model within a maximum entropy framework. The performance of this trained model can be evaluated by checking how many instances of word order selected by the model agree with those in the original text. In this paper, we show that even a raw corpus that has not been tagged can be used to train the model, if it is first analyzed by a parser. This is possible because the word order of the text in the corpus is correct."
C00-2128,A Statistical Approach to the Processing of Metonymy,2000,16,17,3,1,127,masao utiyama,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"This paper describes a statistical approach to the interpretation of metonymy. A metonymy is received as an input, then its possible interpretations are ranked by applying a statistical measure. The method has been tested experimentally. It correctly interpreted 53 out of 75 metonymies in Japanese."
C00-1074,Hybrid Neuro and Rule-Based Part of Speech Taggers,2000,6,13,4,1,33252,qing ma,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"A hybrid system for tagging part of speech is described that consists of a neuro tagger and a rule-based corrector. The neuro tagger is an initial-state annotator that uses different lengths of context based on longest context priority. Its inputs are weighted by information gains that are obtained by information maximization. The rule-based corrector is constructed by a set of transformation rules to make up for the shortcomings of the neuro tagger. Computer experiments show that almost 20% of the errors made by the neuro tagger are corrected by these transformation rules, so that the hybrid system can reach an accuracy of 95.5% counting only the ambiguous words and 99.1% counting all words when a small Thai corpus with 22,311 ambiguous words is used for training. This accuracy is far higher than that using an HMM and is also higher than that using a rule-based model."
C00-1082,Bunsetsu Identification Using Category-Exclusive Rules,2000,11,8,4,1,16788,masaki murata,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"This paper describes two new bunsetsu identification methods using supervised learning. Since Japanese syntactic analysis is usually done after bunsetsu identification, bunsetsu identification is important for analyzing Japanese sentences. In experiments comparing the four previously available machine-learning methods (decision tree, maximum-entropy method, example-based approach and decision list) and two new methods using category-exclusive rules, the new method using the category-exclusive rules with the highest similarity performed best."
2000.iwpt-1.43,Dependency Model using Posterior Context,2000,-1,-1,4,1,30019,kiyotaka uchimoto,Proceedings of the Sixth International Workshop on Parsing Technologies,0,"We describe a new model for dependency structure analysis. This model learns the relationship between two phrasal units called bunsetsus as three categories; {`}between{'}, {`}dependent{'}, and {`}beyond{'}, and estimates the dependency likelihood by considering not only the relationship between two bunsetsus but also the relationship between the left bunsetsu and all of the bunsetsus to its right. We implemented this model based on the maximum entropy model. When using the Kyoto University corpus, the dependency accuracy of our model was 88{\%}, which is about 1{\%} higher than that of the conventional model using exactly the same features."
W99-0205,Resolution of Indirect Anaphora in {J}apanese Sentences Using Examples: {``}{X} no {Y} ({Y} of {X}){''},1999,5,9,2,1,16788,masaki murata,Coreference and Its Applications,0,"A noun phrase can indirectly refer to an entity that has already been mentioned. For example, I went into an old house last night. The roof was leaking badly and .... indicates that the roof is associated with an old house, which was mentioned in the previous sentence. This kind of reference (indirect anaphora) has not been studied well in natural language processing, but is important for coherence resolution, language understanding, and machine translation. In order to analyze indirect anaphora, we need a case frame dictionary for nouns that contains knowledge of the relationships between two nouns but no such dictionary presently exists. Therefore, we are forced to use examples of X no Y (Y of X) and a verb case frame dictionary instead. We tried estimating indirect anaphora using this information and obtained a recall rate of 63% and a precision rate of 68% on test sentences. This indicates that the information of X no Y is useful to a certain extent when we cannot make use of a noun case frame dictionary. We estimated the results that would be given by a noun case frame dictionary, and obtained recall and precision rates of 71% and 82% respectively. Finally, we proposed a way to construct a noun case frame dictionary by using examples of X no Y."
W99-0206,Pronoun Resolution in {J}apanese Sentences Using Surface Expressions and Examples,1999,10,10,2,1,16788,masaki murata,Coreference and Its Applications,0,"In this paper, we present a method of estimating referents of demonstrative pronouns, personal pronouns, and zero pronouns in Japanese sentences using examples, surface expressions, topics and foci. Unlike conventional work which was semantic markers for semantic constraints, we used examples for semantic constraints and showed in our experiments that examples are as useful as semantic markers. We also propose many new methods for estimating referents of pronouns. For example, we use the form X of Y for estimating referents of demonstrative adjectives. In addition to our new methods, we used many conventional methods. As a result, experiments using these methods obtained a precision rate of 87% in estimating referents of demonstrative pronouns, personal pronouns, and zero pronouns for training sentences, and obtained a precision rate of 78% for test sentences."
P99-1063,Lexical Semantics to Disambiguate Polysemous Phenomena of {J}apanese Adnominal Constituents,1999,6,6,1,1,15925,hitoshi isahara,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,"We exploit and extend the Generative Lexicon Theory to develop a formal description of adnominal constituents in a lexicon which can deal with linguistic phenomena found in Japanese adnominal constituents. We classify the problematic behavior into static disambiguation and dynamic disambiguation tasks. Static disambiguation can be done using lexical information in a dictionary, whereas dynamic disambiguation requires inferences at the knowledge representation level."
E99-1026,{J}apanese Dependency Structure Analysis Based on Maximum Entropy Models,1999,8,51,3,1,30019,kiyotaka uchimoto,Ninth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,This paper describes a dependency structure analysis of Japanese sentences based on the maximum entropy models. Our model is created by learning the weights of some features from a training corpus to predict the dependency between bunsetsus or phrasal units. The dependency accuracy of our system is 87.2% using the Kyoto University corpus. We discuss the contribution of each feature set and the relationship between the number of training data and the accuracy.
1999.tmi-1.7,"An example-based approach to {J}apanese-to-{E}nglish translation of tense, aspect, and modality",1999,3,16,4,1,16788,masaki murata,Proceedings of the 8th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,"We have developed a new method for Japanese-to-English translation of tense, aspect, and modality that uses an example-based method. In this method the similarity between input and example sentences is defined as the degree of semantic matching between the expressions at the ends of the sentences. Our method also uses the k-nearest neighbor method in order to exclude the effects of noise; for example, wrongly tagged data in the bilingual corpora. Experiments show that our method can translate tenses, aspects, and modalities more accurately than the top-level MT software currently available on the market can. Moreover, it does not require hand-craft rules."
W98-0202,Intelligent Network News Reader with Visual User Interface,1998,4,2,1,1,15925,hitoshi isahara,Content Visualization and Intermedia Representations ({CVIR}{'}98),0,None
P98-2131,A Multi-Neuro Tagger Using Variable Lengths of Contexts,1998,7,14,8,0,55263,susann luperfoy,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"This paper presents a multi-neuro tagger that uses variable lengths of contexts and weighted inputs (with information gains) for part of speech tagging. Computer experiments show that it has a correct rate of over 94% for tagging ambiguous words when a small Thai corpus with 22,311 ambiguous words is used for training. This result is better than any of the results obtained using the single-neuro taggers with fixed but different lengths of contexts, which indicates that the multi-neuro tagger can dynamically find a suitable length of contexts in tagging."
C98-2127,A Multi-Neuro Tagger Using Variable Lengths of Contexts,1998,7,14,2,1,33252,qing ma,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"This paper presents a multi-neuro tagger that uses variable lengths of contexts and weighted inputs (with information gains) for part of speech tagging. Computer experiments show that it has a correct rate of over 94% for tagging ambiguous words when a small Thai corpus with 22,311 ambiguous words is used for training. This result is better than any of the results obtained using the single-neuro taggers with fixed but different lengths of contexts, which indicates that the multi-neuro tagger can dynamically find a suitable length of contexts in tagging."
1997.mtsummit-papers.11,{JEIDA}{'}s Bilingual Corpus and Other Corpora for {NLP} Research in {J}apan,1997,-1,-1,1,1,15925,hitoshi isahara,Proceedings of Machine Translation Summit VI: Papers,0,"The committee on text processing technology of JEIDA (Japan Electronics Industry Development Association) has been developing its bilingual corpus for research on machine translation systems since the 1996 Japanese fiscal year. An overview of this bilingual corpus is presented in this paper. And other linguistic data recently developed in Japan, which includes the RWC text database and the simple sentence data by the CRL and IPA."
1995.mtsummit-1.35,{JEIDA}{'}s test - sets for quality evaluation of {MT} systems,1995,-1,-1,1,1,15925,hitoshi isahara,Proceedings of Machine Translation Summit V,0,None
C86-1058,Context Analysis System for {J}apanese Text,1986,1,8,1,1,15925,hitoshi isahara,Coling 1986 Volume 1: The 11th International Conference on Computational Linguistics,0,"A natural language understanding system is described which extracts contextual information from Japanese texts. It integrates syntactic, semantic and contextual processing serially. The syntactic analyzer obtains rough syntactic structures from the text. The semantic analyzer treats modifying relations inside noun phrases and case relations among verbs and noun phrases. Then, the contextual analyzer obtains contextual information from the semantic structure extracted by the semantic analyzer. Our system understands the context using precoded contextual knowledge on terrorism and plugs the event information in input sentences into the contextual structure."
