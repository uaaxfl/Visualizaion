2007.iwslt-1.21,N03-1017,0,0.014972,"eering, Beihang University, China lizj@buaa.edu.cn Abstract In this paper, we describe our machine translation system which was used for the Chinese-to-English task in the IWSLT2007 evaluation campaign. The system is a statistical machine translation (SMT) system, while containing an example-based decoder. In this way, it will help to solve the re-ordering problem and other problems for spoken language MT, such as lots of omissions, idioms etc. We report the results of the system for the provided evaluation sets. 1. Introduction The state-of-the-art statistical machine translation (SMT) model [1][2] is the log-linear model [3], which provides a framework to incorporate any useful knowledge for machine translation, such as translation model, language model etc. In a SMT system, one important problem is the reordering between words and phrases, especially when the source language and target language are very different in word order, such as Chinese and English. For the spoken language translation, the re-ordering problem will be more crucial, since the spoken language is more flexible in word order. In addition, lots of omissions and idioms make the translation more difficult. In this p"
2007.iwslt-1.21,P05-1033,0,0.0618651,"ing, Beihang University, China lizj@buaa.edu.cn Abstract In this paper, we describe our machine translation system which was used for the Chinese-to-English task in the IWSLT2007 evaluation campaign. The system is a statistical machine translation (SMT) system, while containing an example-based decoder. In this way, it will help to solve the re-ordering problem and other problems for spoken language MT, such as lots of omissions, idioms etc. We report the results of the system for the provided evaluation sets. 1. Introduction The state-of-the-art statistical machine translation (SMT) model [1][2] is the log-linear model [3], which provides a framework to incorporate any useful knowledge for machine translation, such as translation model, language model etc. In a SMT system, one important problem is the reordering between words and phrases, especially when the source language and target language are very different in word order, such as Chinese and English. For the spoken language translation, the re-ordering problem will be more crucial, since the spoken language is more flexible in word order. In addition, lots of omissions and idioms make the translation more difficult. In this pape"
2007.iwslt-1.21,P02-1038,0,0.13263,"na lizj@buaa.edu.cn Abstract In this paper, we describe our machine translation system which was used for the Chinese-to-English task in the IWSLT2007 evaluation campaign. The system is a statistical machine translation (SMT) system, while containing an example-based decoder. In this way, it will help to solve the re-ordering problem and other problems for spoken language MT, such as lots of omissions, idioms etc. We report the results of the system for the provided evaluation sets. 1. Introduction The state-of-the-art statistical machine translation (SMT) model [1][2] is the log-linear model [3], which provides a framework to incorporate any useful knowledge for machine translation, such as translation model, language model etc. In a SMT system, one important problem is the reordering between words and phrases, especially when the source language and target language are very different in word order, such as Chinese and English. For the spoken language translation, the re-ordering problem will be more crucial, since the spoken language is more flexible in word order. In addition, lots of omissions and idioms make the translation more difficult. In this paper, we present our hybrid tra"
2007.iwslt-1.21,J97-3002,0,0.103743,"In addition, lots of omissions and idioms make the translation more difficult. In this paper, we present our hybrid translation system, which is a SMT system, while using an example-based decoder, which will use the translation examples to keep the translation structure, i.e. constraint the reordering, and make the omitted words having the chance to be translated. In our system, each translation example is a triple (C, E, TA), where C represents the Chinese sentence, E the English sentence, and TA is the word alignment between C and E, which satisfies the inversion transduction grammar (ITG) [4] constraint, i.e. the TA forms a constituent structure tree. This paper is organized as follows. In Section 2, we describe the various components in our system, especially the word aligner and decoder. In section 3, we report the experimental results of Chinese-English translation, and we conclude in section 4 and provide avenues for further research. 2. System Description Our machine translation system is a modular MT engine, which mainly consists of the following components: • Word Alignment: taking the bilingual sentence-aligned training corpus as input, obtains the Viterbi word alignment f"
2007.iwslt-1.21,J03-1002,0,0.00454951,"ponents: • Word Alignment: taking the bilingual sentence-aligned training corpus as input, obtains the Viterbi word alignment for each sentence pair, in our system, the word alignment must satisfy the ITG constraint. • Phrase Pair Extracting: taking the bilingual wordaligned training corpus as input, extracts the valid phrase pairs and builds the translation model and the reordering model. • Decoder: given a Chinese sentence as input, search the best translation using the word-aligned corpus and the translation model, reordering model and language model. 2.1. Word Alignment The word alignment [5] is the base of the SMT system. In our system, the word alignment for each sentence pair is used to build translation model and reordering model, and also used to provide the valid translation example. In our system, the word alignment needs to satisfy the ITG constraint, which is derived from the ITG grammar. The ITG is a synchronous PCFG, consisting of five types of rules: A⎯ ⎯→[ AA] |&lt; AA > |ci / e j |ci / ε |ε / e j (1) Where A is the non-terminal symbol, [] and &lt;> represent the two operations which generate outputs in straight and inverted orientation respectively. ci and e j are terminal"
2007.iwslt-1.21,2007.mtsummit-papers.14,1,0.82983,"l symbol, [] and &lt;> represent the two operations which generate outputs in straight and inverted orientation respectively. ci and e j are terminal symbols, which represent the words in both languages, ε is the null words. And each rule will be assigned a corresponding probability. The last three rules are called lexical rules. A word alignment statisfying the ITG will form a binary branching tree, see Figure 1. And it provides a flexible but effective way to interpret almost arbitrary word order. Wu[4] provides a DP algorithm to obtain the word alignment which satisfies the ITG constraint, we [6] have transferred the constraint to four simple position judgment procedures in an explicit way. So we can incorporate the ITG constraint as a feature into a log-linear word alignment model [7]. Given a sentence pair (C,E) , a log-linear word alignment is to find the best Amax, so that: A max = arg max A n ∑ λ f ( C , TA , E ) i i (2) i =1 Where the fi represents the feature and λi is the corresponding weight of the feature. In our word alignment model, it consists mainly of the following three features: • ITG constraint: counts the number of links in the word alignment, which violating the IT"
2007.iwslt-1.21,H05-1011,0,0.0241166,"guages, ε is the null words. And each rule will be assigned a corresponding probability. The last three rules are called lexical rules. A word alignment statisfying the ITG will form a binary branching tree, see Figure 1. And it provides a flexible but effective way to interpret almost arbitrary word order. Wu[4] provides a DP algorithm to obtain the word alignment which satisfies the ITG constraint, we [6] have transferred the constraint to four simple position judgment procedures in an explicit way. So we can incorporate the ITG constraint as a feature into a log-linear word alignment model [7]. Given a sentence pair (C,E) , a log-linear word alignment is to find the best Amax, so that: A max = arg max A n ∑ λ f ( C , TA , E ) i i (2) i =1 Where the fi represents the feature and λi is the corresponding weight of the feature. In our word alignment model, it consists mainly of the following three features: • ITG constraint: counts the number of links in the word alignment, which violating the ITG constraint. In order to ensure that the result word alignment satisfies the constituent structure, we set a very small negative weight for this feature, so that the word alignment will not be"
2007.iwslt-1.21,J00-2004,0,0.025032,"• Conditional Probability Model: we use a conditional probability as our base feature which accounts for the word correlation, f p (C, TA, E ) = log P( A |C , E ) = ∑ log p(a |c, e) (3) Where p ( a |c, e) is the alignment probability when c and e co-occur. • Distortion Model: we count the jump distance for this model: ∑ f d ( C , TA , E ) = (4) di i where the di represents the jump distance for each link in the word alignment, using one of the sentences as a reference. We [6] use a beam search algorithm to find the Viterbi word alignment which is similar with the competitive linking algorithm [8]. And we tune the feature weights using the perception training [7], over a development set we aligned manually. In the end, we will obtain the bilingual wordaligned training corpus, in which each word alignment satisfies the ITG constraint, i.e., it forms a constituent structure tree. 我 再次 检查 I checked my 我 bag 的 once 包 bilingual corpus, in which each word alignment satisfies the ITG constraint. For the word alignment forms a hierarchical binary tree, we can extract the phrase pairs in a straight-forward way, i.e. choosing each constituent as a phrase pair, called a block. We can also collect"
2007.iwslt-1.21,2003.mtsummit-papers.54,0,0.07886,"m ( E ) λlm (8) r ∈D again An invalid word alignment example ∏ Pr(r ) • Pr Where the Prlm ( E ) is the language model. So the decoder searches the best E* derived from the best derivation D*, when given a source sentence C. D* = arg max Pr( D) (9) c( D) =C In order to evaluate the example-based decoder, we develop a CKY style decoder as a baseline MT system, so that the (E,C) satisfies the ITG constraint. 2.2. Phrase Pair Extracting 2.3.2. The example-based decoder In our SMT model, we use the translation models and the reordering model as features. And we use a word-aligned The example-based [9] decoder consists of two components: • Retrieval of examples: given the input Chinese sentence C0 and the bilingual word-aligned corpus, collects a set of translation examples {( C1, E1, TA1) ,( ( C2, E2 , TA2),....} from the corpus, where the Ck in each translation example is similar to the input sentence. • Decoding: given the input and the translation examples and the translation models, language models and reordering model, searches the best translation for the input. In order to obtain the similarity between Ck and C0, a straight-forward method is to compute the edit distance, by giving e"
2007.iwslt-1.21,P02-1040,0,0.0764803,"tep, we use two simple rules to obtain the case sensitive outputs, the first rule is the capital letter of the first word in each sentence must be uppercase, and the second one is the word “i” must be “I”. Firstly, we tested our machine system with all English sentences in both training corpus and the reference set are tokenized, low cased and stemmed. The results are showed in Table 2. Table 2: Test results with English sentences are stemmed Decoder CKY-Decoder EB-Decoder Bleu 0.2741 0.3012 The first column lists the two decoders in our SMT system, and the second column lists the Bleu scores [10] for the two decoders. The results show that the example-based decoder achieves an improvement over the baseline decoder. Secondly, we considered the case information, i.e. we used the two rules to post-process the output. Also, we took into account the morphological changes of the English words. In order to find the most likely sequence, we use a 3-gram language model trained on an un-stemmed text. The 3-gram language model was trained on the English sentences of the training data, using the SRILM toolkit [11]. Table 3 lists the results. Table 3: Test results with English sentences are normal"
2007.mtsummit-papers.14,J93-2003,0,0.0306655,"Missing"
2007.mtsummit-papers.14,P03-1012,0,0.0226968,"Brown et al., 1993; Vogel et al. 1996; Och and Ney, 2003), which product good results on large sentence aligned bilingual corpora, especially when the two languages are closely related. But these generative models are complex, so that it is difficult to train the parameters in them, and incorporate new useful knowledge into them. In order to restrict the word order further, especially considering the word order problem in two languages which are not closely related, many researchers introduce syntactic knowledge in word alignment, which mainly adopts a tree structure (Yamada and Knight, 2001; Cherry and Lin, 2003; Gildea 2004 etc.). In these models, a syntactic tree of one sentence is parsed which is used to constrain the words order in another sentence; or two trees are both parsed, and then the word alignment problem is to find a mapping between the nodes in the trees. But in some languages, the syntactic trees are difficult to achieve, or the syntax between two languages are very different, so that the nodes in both trees are not easy to map. Accounting for these problems, Wu(1997) proposes a stochastic inversion transduction grammars(SITG), in which two simple operations are used to reorder the wo"
2007.mtsummit-papers.14,P06-2014,0,0.0726064,"Missing"
2007.mtsummit-papers.14,H91-1026,0,0.279686,"Missing"
2007.mtsummit-papers.14,W04-3228,0,0.0178236,"gel et al. 1996; Och and Ney, 2003), which product good results on large sentence aligned bilingual corpora, especially when the two languages are closely related. But these generative models are complex, so that it is difficult to train the parameters in them, and incorporate new useful knowledge into them. In order to restrict the word order further, especially considering the word order problem in two languages which are not closely related, many researchers introduce syntactic knowledge in word alignment, which mainly adopts a tree structure (Yamada and Knight, 2001; Cherry and Lin, 2003; Gildea 2004 etc.). In these models, a syntactic tree of one sentence is parsed which is used to constrain the words order in another sentence; or two trees are both parsed, and then the word alignment problem is to find a mapping between the nodes in the trees. But in some languages, the syntactic trees are difficult to achieve, or the syntax between two languages are very different, so that the nodes in both trees are not easy to map. Accounting for these problems, Wu(1997) proposes a stochastic inversion transduction grammars(SITG), in which two simple operations are used to reorder the words, and in t"
2007.mtsummit-papers.14,P05-1057,0,0.0390579,"Missing"
2007.mtsummit-papers.14,J00-2004,0,0.0760333,"cent, they can be merged into a larger group, too. After the word alignment, there may exist null links, so we need to combine groups which are not adjacent. At this time, each null link can be combined with any adjacent group. With the combine operation, we can output the constituent structure of the word alignment in the end. By transferring the constituent structure constraint to the above three operations, we will be able to use any search algorithm to find the best word alignment. Here we design a fast beam search algorithm, which derived partially from the competitive linking algorithm (Melamed 2000), see Figure 5 for detail. We collect firstly all possible a between the words in &lt; C , E &gt; to form a candidate set M , and sort them by the score ( a ) , which may be the correlation probability of the words in a , and depends on the models we will used. We then use the process defined in the Section 3 to produce a word alignment by using the Verify, Insert and Combine operations. For some different candidates may have an equal or near score, there may be many branches. But we will select the b branches to continue, and prune the branches by calculate the: score( A) = ∑ log(score( a )) . a Ou"
2007.mtsummit-papers.14,H05-1011,0,0.288218,"the word alignment only needs to satisfy the constituent structure, so that it achieves a great flexibility while preserving a weak but effective word order constraint. But this model uses a dynamic programming algorithm to search the best word alignment, which complexity is O(N 3 V 3T 3 ) , where V, T are the sentence lengths , when V and T are larger than 100 or even 50, it will be hard to bear in general PC machine. Besides, this model is also difficult to use other knowledge. In order to incorporate various knowledge into the word alignment effectively, some researchers (Liu et al., 2005; Moore, 2005; Taskar et al., 2005) almost at the same time propose a discriminative word alignment framework, where the knowledge, such as POS and lexicon, are cast as some features. So that, when solving the word alignment, we only needs to select the features and train the corresponding weights of them. Their work shows that, when the features are selected appropriately, even some easy features will produce good results. Recently, the base feature in most of these models is the word correlation model, and then incorporating some other easy features, such as jump distance, POS etc. In this paper, we prop"
2007.mtsummit-papers.14,P06-1065,0,0.0470672,"Missing"
2007.mtsummit-papers.14,J03-1002,0,0.0660727,"rations to ensure the constraint when search the best word alignment. In this way, we will be able to make use of the weak order constraint induced by the inversion transduction grammars (ITG), as well as the flexibility of the discriminative word alignment framework to incorporating any other useful features. 1 Introduction Most of recent statistical machine translation systems are based on word alignment, in which word re-ordering and multi-word alignment are two major problems. Most of initial work is derived from IBM models, or HMM model and Model 6 (Brown et al., 1993; Vogel et al. 1996; Och and Ney, 2003), which product good results on large sentence aligned bilingual corpora, especially when the two languages are closely related. But these generative models are complex, so that it is difficult to train the parameters in them, and incorporate new useful knowledge into them. In order to restrict the word order further, especially considering the word order problem in two languages which are not closely related, many researchers introduce syntactic knowledge in word alignment, which mainly adopts a tree structure (Yamada and Knight, 2001; Cherry and Lin, 2003; Gildea 2004 etc.). In these models,"
2007.mtsummit-papers.14,H05-1010,0,0.021719,"nment only needs to satisfy the constituent structure, so that it achieves a great flexibility while preserving a weak but effective word order constraint. But this model uses a dynamic programming algorithm to search the best word alignment, which complexity is O(N 3 V 3T 3 ) , where V, T are the sentence lengths , when V and T are larger than 100 or even 50, it will be hard to bear in general PC machine. Besides, this model is also difficult to use other knowledge. In order to incorporate various knowledge into the word alignment effectively, some researchers (Liu et al., 2005; Moore, 2005; Taskar et al., 2005) almost at the same time propose a discriminative word alignment framework, where the knowledge, such as POS and lexicon, are cast as some features. So that, when solving the word alignment, we only needs to select the features and train the corresponding weights of them. Their work shows that, when the features are selected appropriately, even some easy features will produce good results. Recently, the base feature in most of these models is the word correlation model, and then incorporating some other easy features, such as jump distance, POS etc. In this paper, we propose a novel method, wh"
2007.mtsummit-papers.14,C96-2141,0,0.169568,"Missing"
2007.mtsummit-papers.14,J97-3002,0,0.683409,"Missing"
2007.mtsummit-papers.14,P01-1067,0,0.0587369,"r HMM model and Model 6 (Brown et al., 1993; Vogel et al. 1996; Och and Ney, 2003), which product good results on large sentence aligned bilingual corpora, especially when the two languages are closely related. But these generative models are complex, so that it is difficult to train the parameters in them, and incorporate new useful knowledge into them. In order to restrict the word order further, especially considering the word order problem in two languages which are not closely related, many researchers introduce syntactic knowledge in word alignment, which mainly adopts a tree structure (Yamada and Knight, 2001; Cherry and Lin, 2003; Gildea 2004 etc.). In these models, a syntactic tree of one sentence is parsed which is used to constrain the words order in another sentence; or two trees are both parsed, and then the word alignment problem is to find a mapping between the nodes in the trees. But in some languages, the syntactic trees are difficult to achieve, or the syntax between two languages are very different, so that the nodes in both trees are not easy to map. Accounting for these problems, Wu(1997) proposes a stochastic inversion transduction grammars(SITG), in which two simple operations are"
2007.mtsummit-papers.14,C04-1030,0,0.0435176,"Missing"
2007.mtsummit-papers.14,W03-1730,0,0.0251742,"Missing"
2007.mtsummit-papers.14,W03-0303,0,0.244197,"Missing"
2020.acl-main.531,P17-2021,0,0.0218203,"oleft (R2L) and left-to-right (L2R) to improve the quality of machine translation. Non-Autoregressive decoding (Ghazvininejad et al., 2019) first predicts the target tokens and masked tokens, which will be filled in the next iterations. Then, the model predicts the unmasked tokens on top of the source text and a mixed translation consisting of the masked and unmasked tokens. Semi-autoregressive also (Akoury et al., 2019) predicts chunked fragments or the unmasked tokens based on the tree structure before the final translation. In addition, there are many existing works (Eriguchi et al., 2016; Aharoni and Goldberg, 2017; Wu et al., 2017; Wang et al., 2018; Dong and Lapata, 2018; Wang et al., 2018; Gu et al., 2018) which incorporate syntax information or the tree structure into NMT to improve the quality of translation results. 5 Conclusion In this work, we propose a novel approach that utilizes source text and additional soft templates. More specifically, our approach can extract the templates from the sub-tree, which derives from the specific depth of the constituency-based parse tree. Then, we use a Transformer model to predict the soft target templates conditioned on the source text. On top of soft templa"
2020.acl-main.531,P19-1122,0,0.0955751,"outperforms the baseline models on four benchmarks and demonstrate the effectiveness of soft target templates. 1 Target Recently, neural machine translation (NMT) (Wu et al., 2016; Gehring et al., 2017; Vaswani et al., 2017; Chen et al., 2018) has achieved significant progress. Some advanced models (Chatterjee et al., 2016; Niehues et al., 2016; Junczys-Dowmunt and Grundkiewicz, 2017; Geng et al., 2018; Zhou et al., 2019a) predict the ultimate translation by multi-pass generation conditioned on the previous text such as CMLMs (Ghazvininejad et al., 2019), ABD-NMT (Zhang et al., 2018), SynST (Akoury et al., 2019), and Deliberation Network (Xia et al., 2017). Inspired by these works and the successful application of templates for other intriguing tasks, including semantic parsing (Dong and Lapata, 2018), summarization (Cao et al., 2018; Wang et al., 2019a), question answering (Duan et al., 2017; Contribution during internship at Microsoft Research Asia. † Corresponding author. like playing basketball Figure 1: An example of template guided translation results. S denotes subject and VP denotes verb phrase. Introduction ∗ I Template S like VP Pandey et al., 2018), and other text generation tasks (Wiseman"
2020.acl-main.531,Q18-1031,0,0.0459095,"ion Network (Xia et al., 2017). Inspired by these works and the successful application of templates for other intriguing tasks, including semantic parsing (Dong and Lapata, 2018), summarization (Cao et al., 2018; Wang et al., 2019a), question answering (Duan et al., 2017; Contribution during internship at Microsoft Research Asia. † Corresponding author. like playing basketball Figure 1: An example of template guided translation results. S denotes subject and VP denotes verb phrase. Introduction ∗ I Template S like VP Pandey et al., 2018), and other text generation tasks (Wiseman et al., 2018; Guu et al., 2018), we assume the candidate templates of the target sentences can guide the sentence translation process. We denote these templates extracted from the constituencybased parse tree as soft templates, which consist of tags and target words. The templates are soft because no explicit paradigms are inaugurated to build new translation from them, and the target tokens could be modified. In order to effectively use the templates, we introduce soft template-based neural machine translation (ST-NMT), which can use source text and soft templates to predict the final translation. Our approach can be split"
2020.acl-main.531,I17-1013,0,0.0171418,"ces, we adopt the constituency-based parse tree to generate candidate templates. We incorporate the template information into the encoder-decoder framework to jointly utilize the templates and source text. Experiments show that our model significantly outperforms the baseline models on four benchmarks and demonstrate the effectiveness of soft target templates. 1 Target Recently, neural machine translation (NMT) (Wu et al., 2016; Gehring et al., 2017; Vaswani et al., 2017; Chen et al., 2018) has achieved significant progress. Some advanced models (Chatterjee et al., 2016; Niehues et al., 2016; Junczys-Dowmunt and Grundkiewicz, 2017; Geng et al., 2018; Zhou et al., 2019a) predict the ultimate translation by multi-pass generation conditioned on the previous text such as CMLMs (Ghazvininejad et al., 2019), ABD-NMT (Zhang et al., 2018), SynST (Akoury et al., 2019), and Deliberation Network (Xia et al., 2017). Inspired by these works and the successful application of templates for other intriguing tasks, including semantic parsing (Dong and Lapata, 2018), summarization (Cao et al., 2018; Wang et al., 2019a), question answering (Duan et al., 2017; Contribution during internship at Microsoft Research Asia. † Corresponding auth"
2020.acl-main.531,P18-1015,0,0.04749,"Missing"
2020.acl-main.531,P07-2045,0,0.0108457,"validation set is devtest2014, and the test set is newstest2014. ASPEC Japanese-Chinese We use 0.67M sentence pairs from ASPEC Japanese-Chinese corpus (Nakazawa et al., 2016) 2 . We use the devtest as the development data, which contains 2090 sentences, and the test data contains 2107 sentences with a single reference per source sentence. 3.2 Preprocessing and Training Details LDC Chinese-English The base Transformer model is used for this task, which includes 6 layers, each layer of which has the hidden dimensions of 512, feedforward dimensions of 2048 , and 8 attention heads. We use Moses (Koehn et al., 2007) to tokenize English sentences and our in-house tool to tokenize Chinese sentences. We use Byte Pair Encoding (BPE) (Sennrich et al., 2016) to encode 1 LDC2002E17, LDC2002E18, LDC2003E07, LDC2003E14, LDC2005E83, LDC2005T06, LDC2005T10, LDC2006E17, LDC2006E26, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006T06, LDC2004T08, LDC2005T10 2 http://orchid.kuee.kyoto-u.ac.jp/ASPEC/ sentences using a shared vocabulary of 40K symbols. IWSLT14 German-English We adopt the small setup of the Transformer model. The model has 6 layers with the embedding size of 512, a feedforward size of 1024, and 4 attention he"
2020.acl-main.531,N16-1046,0,0.0389191,"Missing"
2020.acl-main.531,P18-1008,0,0.301326,"as soft target templates to guide the translation procedure. In order to learn the syntactic structure of the target sentences, we adopt the constituency-based parse tree to generate candidate templates. We incorporate the template information into the encoder-decoder framework to jointly utilize the templates and source text. Experiments show that our model significantly outperforms the baseline models on four benchmarks and demonstrate the effectiveness of soft target templates. 1 Target Recently, neural machine translation (NMT) (Wu et al., 2016; Gehring et al., 2017; Vaswani et al., 2017; Chen et al., 2018) has achieved significant progress. Some advanced models (Chatterjee et al., 2016; Niehues et al., 2016; Junczys-Dowmunt and Grundkiewicz, 2017; Geng et al., 2018; Zhou et al., 2019a) predict the ultimate translation by multi-pass generation conditioned on the previous text such as CMLMs (Ghazvininejad et al., 2019), ABD-NMT (Zhang et al., 2018), SynST (Akoury et al., 2019), and Deliberation Network (Xia et al., 2017). Inspired by these works and the successful application of templates for other intriguing tasks, including semantic parsing (Dong and Lapata, 2018), summarization (Cao et al., 20"
2020.acl-main.531,P14-5010,0,0.00243224,"et al., 2017), we set the learning rate as 0.1. Chinese and Japanese sentences are tokenized with our in-house tools and encoded by BPE with a shared vocabulary of 10K symbols. 3.3 Evaluation We evaluate the performance of the translation results. The evaluation metric is BLEU (Papineni et al., 2002). For the Chinese-English and GermanEnglish translation tasks, we use case-insensitive tokenized BLEU scores. For the English-German translation task, we use case-sensitive tokenized BLEU scores for evaluation. All the experiments last for 150 epochs and use Stanford parser to generate templates (Manning et al., 2014). For all translation tasks, we use the checkpoint, which has the best valid performance on the valid set. For different test sets, we adapt the beam size and the length penalty to get better performance. In order to avoid the difference of the tokenizer for Chinese translation result evaluation, we adopt the character-level BLEU for testing. Checkpoint averaging is not used, except notification. 5983 Zh → En MT06 MT03 MT05 MT08 MT12 Avg. ConvS2S (Gehring et al., 2017) GNMT (Wu et al., 2016) 39.98 40.53 42.25 42.88 41.22 42.73 33.43 33.97 32.21 32.55 37.28 38.03 Transformer (our implementation"
2020.acl-main.531,P18-1068,0,0.115432,"t al., 2017; Vaswani et al., 2017; Chen et al., 2018) has achieved significant progress. Some advanced models (Chatterjee et al., 2016; Niehues et al., 2016; Junczys-Dowmunt and Grundkiewicz, 2017; Geng et al., 2018; Zhou et al., 2019a) predict the ultimate translation by multi-pass generation conditioned on the previous text such as CMLMs (Ghazvininejad et al., 2019), ABD-NMT (Zhang et al., 2018), SynST (Akoury et al., 2019), and Deliberation Network (Xia et al., 2017). Inspired by these works and the successful application of templates for other intriguing tasks, including semantic parsing (Dong and Lapata, 2018), summarization (Cao et al., 2018; Wang et al., 2019a), question answering (Duan et al., 2017; Contribution during internship at Microsoft Research Asia. † Corresponding author. like playing basketball Figure 1: An example of template guided translation results. S denotes subject and VP denotes verb phrase. Introduction ∗ I Template S like VP Pandey et al., 2018), and other text generation tasks (Wiseman et al., 2018; Guu et al., 2018), we assume the candidate templates of the target sentences can guide the sentence translation process. We denote these templates extracted from the constituency"
2020.acl-main.531,D17-1090,1,0.803851,"nced models (Chatterjee et al., 2016; Niehues et al., 2016; Junczys-Dowmunt and Grundkiewicz, 2017; Geng et al., 2018; Zhou et al., 2019a) predict the ultimate translation by multi-pass generation conditioned on the previous text such as CMLMs (Ghazvininejad et al., 2019), ABD-NMT (Zhang et al., 2018), SynST (Akoury et al., 2019), and Deliberation Network (Xia et al., 2017). Inspired by these works and the successful application of templates for other intriguing tasks, including semantic parsing (Dong and Lapata, 2018), summarization (Cao et al., 2018; Wang et al., 2019a), question answering (Duan et al., 2017; Contribution during internship at Microsoft Research Asia. † Corresponding author. like playing basketball Figure 1: An example of template guided translation results. S denotes subject and VP denotes verb phrase. Introduction ∗ I Template S like VP Pandey et al., 2018), and other text generation tasks (Wiseman et al., 2018; Guu et al., 2018), we assume the candidate templates of the target sentences can guide the sentence translation process. We denote these templates extracted from the constituencybased parse tree as soft templates, which consist of tags and target words. The templates are"
2020.acl-main.531,P16-1078,0,0.0162146,"019b,a) use the right-toleft (R2L) and left-to-right (L2R) to improve the quality of machine translation. Non-Autoregressive decoding (Ghazvininejad et al., 2019) first predicts the target tokens and masked tokens, which will be filled in the next iterations. Then, the model predicts the unmasked tokens on top of the source text and a mixed translation consisting of the masked and unmasked tokens. Semi-autoregressive also (Akoury et al., 2019) predicts chunked fragments or the unmasked tokens based on the tree structure before the final translation. In addition, there are many existing works (Eriguchi et al., 2016; Aharoni and Goldberg, 2017; Wu et al., 2017; Wang et al., 2018; Dong and Lapata, 2018; Wang et al., 2018; Gu et al., 2018) which incorporate syntax information or the tree structure into NMT to improve the quality of translation results. 5 Conclusion In this work, we propose a novel approach that utilizes source text and additional soft templates. More specifically, our approach can extract the templates from the sub-tree, which derives from the specific depth of the constituency-based parse tree. Then, we use a Transformer model to predict the soft target templates conditioned on the source"
2020.acl-main.531,D18-1048,0,0.0726954,"se tree to generate candidate templates. We incorporate the template information into the encoder-decoder framework to jointly utilize the templates and source text. Experiments show that our model significantly outperforms the baseline models on four benchmarks and demonstrate the effectiveness of soft target templates. 1 Target Recently, neural machine translation (NMT) (Wu et al., 2016; Gehring et al., 2017; Vaswani et al., 2017; Chen et al., 2018) has achieved significant progress. Some advanced models (Chatterjee et al., 2016; Niehues et al., 2016; Junczys-Dowmunt and Grundkiewicz, 2017; Geng et al., 2018; Zhou et al., 2019a) predict the ultimate translation by multi-pass generation conditioned on the previous text such as CMLMs (Ghazvininejad et al., 2019), ABD-NMT (Zhang et al., 2018), SynST (Akoury et al., 2019), and Deliberation Network (Xia et al., 2017). Inspired by these works and the successful application of templates for other intriguing tasks, including semantic parsing (Dong and Lapata, 2018), summarization (Cao et al., 2018; Wang et al., 2019a), question answering (Duan et al., 2017; Contribution during internship at Microsoft Research Asia. † Corresponding author. like playing ba"
2020.acl-main.531,C16-1172,0,0.0577942,"Missing"
2020.acl-main.531,W18-6301,0,0.0136486,"a label smoothing of 0.1. We use BPE to encode sentences with a shared vocabulary of 10K symbols. WMT14 English-German We use the big setting of Transformer (Vaswani et al., 2017), in which both the encoder and the decoder have 6 layers, with the embedding size of 1024, feedforward size of 4096, and 16 attention heads. The dropout rate is fixed as 0.3. We adopt Adam (Kingma and Ba, 2015) optimizer with a learning rate 0.1 of the similar learning rate schedule as Transformer (Vaswani et al., 2017). We set the batch size as 6000 and the update frequency as 16 on 8 GPUs for updating parameters (Ott et al., 2018) to imitate 128 GPUs. The datasets are encoded by BPE with a shared vocabulary (Sennrich et al., 2016) of 40K symbols. ASPEC Japanese-Chinese We use the base setting of Transformer the same to the ChineseEnglish translation task. Following the similar learning rate schedule (Vaswani et al., 2017), we set the learning rate as 0.1. Chinese and Japanese sentences are tokenized with our in-house tools and encoded by BPE with a shared vocabulary of 10K symbols. 3.3 Evaluation We evaluate the performance of the translation results. The evaluation metric is BLEU (Papineni et al., 2002). For the Chine"
2020.acl-main.531,P18-1123,0,0.0676718,"19), ABD-NMT (Zhang et al., 2018), SynST (Akoury et al., 2019), and Deliberation Network (Xia et al., 2017). Inspired by these works and the successful application of templates for other intriguing tasks, including semantic parsing (Dong and Lapata, 2018), summarization (Cao et al., 2018; Wang et al., 2019a), question answering (Duan et al., 2017; Contribution during internship at Microsoft Research Asia. † Corresponding author. like playing basketball Figure 1: An example of template guided translation results. S denotes subject and VP denotes verb phrase. Introduction ∗ I Template S like VP Pandey et al., 2018), and other text generation tasks (Wiseman et al., 2018; Guu et al., 2018), we assume the candidate templates of the target sentences can guide the sentence translation process. We denote these templates extracted from the constituencybased parse tree as soft templates, which consist of tags and target words. The templates are soft because no explicit paradigms are inaugurated to build new translation from them, and the target tokens could be modified. In order to effectively use the templates, we introduce soft template-based neural machine translation (ST-NMT), which can use source text and"
2020.acl-main.531,P02-1040,0,0.10654,"pdating parameters (Ott et al., 2018) to imitate 128 GPUs. The datasets are encoded by BPE with a shared vocabulary (Sennrich et al., 2016) of 40K symbols. ASPEC Japanese-Chinese We use the base setting of Transformer the same to the ChineseEnglish translation task. Following the similar learning rate schedule (Vaswani et al., 2017), we set the learning rate as 0.1. Chinese and Japanese sentences are tokenized with our in-house tools and encoded by BPE with a shared vocabulary of 10K symbols. 3.3 Evaluation We evaluate the performance of the translation results. The evaluation metric is BLEU (Papineni et al., 2002). For the Chinese-English and GermanEnglish translation tasks, we use case-insensitive tokenized BLEU scores. For the English-German translation task, we use case-sensitive tokenized BLEU scores for evaluation. All the experiments last for 150 epochs and use Stanford parser to generate templates (Manning et al., 2014). For all translation tasks, we use the checkpoint, which has the best valid performance on the valid set. For different test sets, we adapt the beam size and the length penalty to get better performance. In order to avoid the difference of the tokenizer for Chinese translation re"
2020.acl-main.531,P16-1162,0,0.428682,"-Chinese corpus (Nakazawa et al., 2016) 2 . We use the devtest as the development data, which contains 2090 sentences, and the test data contains 2107 sentences with a single reference per source sentence. 3.2 Preprocessing and Training Details LDC Chinese-English The base Transformer model is used for this task, which includes 6 layers, each layer of which has the hidden dimensions of 512, feedforward dimensions of 2048 , and 8 attention heads. We use Moses (Koehn et al., 2007) to tokenize English sentences and our in-house tool to tokenize Chinese sentences. We use Byte Pair Encoding (BPE) (Sennrich et al., 2016) to encode 1 LDC2002E17, LDC2002E18, LDC2003E07, LDC2003E14, LDC2005E83, LDC2005T06, LDC2005T10, LDC2006E17, LDC2006E26, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006T06, LDC2004T08, LDC2005T10 2 http://orchid.kuee.kyoto-u.ac.jp/ASPEC/ sentences using a shared vocabulary of 40K symbols. IWSLT14 German-English We adopt the small setup of the Transformer model. The model has 6 layers with the embedding size of 512, a feedforward size of 1024, and 4 attention heads. In order to prevent overfitting, we use a dropout of 0.3, a l2 weight decay of 10−4 , and a label smoothing of 0.1. We use BPE to enco"
2020.acl-main.531,D19-1633,0,0.0843568,"tes and source text. Experiments show that our model significantly outperforms the baseline models on four benchmarks and demonstrate the effectiveness of soft target templates. 1 Target Recently, neural machine translation (NMT) (Wu et al., 2016; Gehring et al., 2017; Vaswani et al., 2017; Chen et al., 2018) has achieved significant progress. Some advanced models (Chatterjee et al., 2016; Niehues et al., 2016; Junczys-Dowmunt and Grundkiewicz, 2017; Geng et al., 2018; Zhou et al., 2019a) predict the ultimate translation by multi-pass generation conditioned on the previous text such as CMLMs (Ghazvininejad et al., 2019), ABD-NMT (Zhang et al., 2018), SynST (Akoury et al., 2019), and Deliberation Network (Xia et al., 2017). Inspired by these works and the successful application of templates for other intriguing tasks, including semantic parsing (Dong and Lapata, 2018), summarization (Cao et al., 2018; Wang et al., 2019a), question answering (Duan et al., 2017; Contribution during internship at Microsoft Research Asia. † Corresponding author. like playing basketball Figure 1: An example of template guided translation results. S denotes subject and VP denotes verb phrase. Introduction ∗ I Template S like VP Pan"
2020.acl-main.531,D18-1037,0,0.0372152,"Missing"
2020.acl-main.531,P19-1207,0,0.347103,"achieved significant progress. Some advanced models (Chatterjee et al., 2016; Niehues et al., 2016; Junczys-Dowmunt and Grundkiewicz, 2017; Geng et al., 2018; Zhou et al., 2019a) predict the ultimate translation by multi-pass generation conditioned on the previous text such as CMLMs (Ghazvininejad et al., 2019), ABD-NMT (Zhang et al., 2018), SynST (Akoury et al., 2019), and Deliberation Network (Xia et al., 2017). Inspired by these works and the successful application of templates for other intriguing tasks, including semantic parsing (Dong and Lapata, 2018), summarization (Cao et al., 2018; Wang et al., 2019a), question answering (Duan et al., 2017; Contribution during internship at Microsoft Research Asia. † Corresponding author. like playing basketball Figure 1: An example of template guided translation results. S denotes subject and VP denotes verb phrase. Introduction ∗ I Template S like VP Pandey et al., 2018), and other text generation tasks (Wiseman et al., 2018; Guu et al., 2018), we assume the candidate templates of the target sentences can guide the sentence translation process. We denote these templates extracted from the constituencybased parse tree as soft templates, which consist of"
2020.acl-main.531,D18-1509,0,0.018984,"e the quality of machine translation. Non-Autoregressive decoding (Ghazvininejad et al., 2019) first predicts the target tokens and masked tokens, which will be filled in the next iterations. Then, the model predicts the unmasked tokens on top of the source text and a mixed translation consisting of the masked and unmasked tokens. Semi-autoregressive also (Akoury et al., 2019) predicts chunked fragments or the unmasked tokens based on the tree structure before the final translation. In addition, there are many existing works (Eriguchi et al., 2016; Aharoni and Goldberg, 2017; Wu et al., 2017; Wang et al., 2018; Dong and Lapata, 2018; Wang et al., 2018; Gu et al., 2018) which incorporate syntax information or the tree structure into NMT to improve the quality of translation results. 5 Conclusion In this work, we propose a novel approach that utilizes source text and additional soft templates. More specifically, our approach can extract the templates from the sub-tree, which derives from the specific depth of the constituency-based parse tree. Then, we use a Transformer model to predict the soft target templates conditioned on the source text. On top of soft templates and source text, we incorporate"
2020.acl-main.531,D18-1356,0,0.0718155,"Missing"
2020.acl-main.531,P17-1065,1,0.691077,"t (L2R) to improve the quality of machine translation. Non-Autoregressive decoding (Ghazvininejad et al., 2019) first predicts the target tokens and masked tokens, which will be filled in the next iterations. Then, the model predicts the unmasked tokens on top of the source text and a mixed translation consisting of the masked and unmasked tokens. Semi-autoregressive also (Akoury et al., 2019) predicts chunked fragments or the unmasked tokens based on the tree structure before the final translation. In addition, there are many existing works (Eriguchi et al., 2016; Aharoni and Goldberg, 2017; Wu et al., 2017; Wang et al., 2018; Dong and Lapata, 2018; Wang et al., 2018; Gu et al., 2018) which incorporate syntax information or the tree structure into NMT to improve the quality of translation results. 5 Conclusion In this work, we propose a novel approach that utilizes source text and additional soft templates. More specifically, our approach can extract the templates from the sub-tree, which derives from the specific depth of the constituency-based parse tree. Then, we use a Transformer model to predict the soft target templates conditioned on the source text. On top of soft templates and source te"
2020.ccl-1.89,P11-1056,0,0.0387487,"ely. CC The entity-relation extraction task aims to recognize the entity spans from a sentence and detect the relations holds between two entities. Generally, it can be formed as extracting triplets (e1 , r, e2 ), which denotes that the relation r holds between the head entity e1 and the tail entity e2 , i.e., (John Smith, Live-In, Atlanta). It plays a vital role in the information extraction area and has attracted increasing attention in recent years. Traditional pipelined methods divide the task into two phases, named entity recognition (NER) and relation extraction (RE) (Miwa et al., 2009; Chan and Roth, 2011; Lin et al., 2016). As such methods neglect the underlying correlations between the two phases and suffer from the error propagation issue, recent works propose to extract entities and relations jointly. These joint models fall into two paradigms. The first paradigm can be denoted as (e1 , e2 ) → r, which first recognizes all entities in the sentence, then classifies the relation depend on each extracted entity pairs. However, these methods require enumerating all possible entity pairs and the relation classification may be affected by the redundant ones. While another paradigm is referred as"
2020.ccl-1.89,P19-1285,0,0.0208175,"lute position representation. The Transformer structure (Vaswani et al., 2017) contains neither recurrence nor convolution, in order to inject the positional information to the model, it defines the sine and consine functions of different frequencies to encode absolute positions. However, such absolute positions cannot model the interaction information between any two input tokens explicitly. Therefore, the third catagroy extends the selfattention mechanism to consider the relative positions or distances between sequential elements. Such as the model by (Shaw et al., 2018) and Transformer-XL (Dai et al., 2019). Different from the relative positions metioned above, we propose the relative positions exspecially for entities. As such information is not necessary for non-entity tokens, and may introduce noise on the contrary. 3 Method In this section, we briefly present the details of the relative position representation based multi-head selection framework. The concept of multi-head means that any head entity may be relevant to multiple relations and tail entities (Bekoulis et al., 2018). Formally, denote E and R as the set of pre-defined entity types and relation categories, respectively. Given an in"
2020.ccl-1.89,N19-1423,0,0.0268846,"o the context fusion module to encoder the entity position-based features. Finally, a multi-head selection module is employed to simultaneously extract tuples of relation and tail entity for the input token (e.g., (Work-For, Center) and (Live-In, Atlanta) for the head entity Simth). Additionally, we present the strategy of global relation classification. We will elaborate on each of the modules in the following subsections. Encoder Module The encoder module aims at mapping discrete tokens into distributed semantic representations. Bidirectioal Encoder Representations from Transformers (BERT) (Devlin et al., 2019) is a pre-trained language representations built on the bidirectional self-attentive models. It is known as its powerful feature representative ability and recently breaks through the leaderboards of a wide range of natural language processing tasks, such as named entity recognition, word segmentation and question answering. Different from the previous work (Bekoulis et al., 2018) which uses the BiLSTM as the feature encoder, we use the BERT instead to better represent contextual features. As illustrated in Fig. 2, given a N -token sentence s = {s1 , s2 , . . . , sN }, a special classification"
2020.ccl-1.89,doddington-etal-2004-automatic,0,0.0848715,"ramework, and make detailed analyses to show its advantages. We evaluate the proposed method on two widely-used benchmarks for entity and relation extaction: CoNLL04 and ACE05. • CoNLL04 (Roth and Yih, 2004) defines 4 entity types including Location (LOC), Organization (ORG), Person (PER) and Other and 5 relation categories as Located-In, OrgBased-In, Live-In, Kill and Work-For. It consists of news articles from the Wall Street Journal and Associated Press. We use the data split by Gupta et al. (Gupta et al., 2016) (910 instances for training, 243 for validation and 288 for testing). • ACE05 (Doddington et al., 2004) provides 7 entity types: Location (LOC), Organization (ORG), Person (PER), Geopolitical Entity (GPE), Vehicle (VEH), Facility (FAC), Weapon (WEA) and 6 relation types: Organization affiliation (ORG-AFF), Person-Social (PER-SOC), Agent-Artifact (ART), PART-WHOLE, GPE affiliation (GEN-AFF), Physical (PHYS). It contains documents from different domains as newswire and online forums. We adopt the same data splits as the previous work (Miwa and Bansal, 2016) (351 documents for training, 80 for validation and 80 for testing). 4.2 Implemental Details Following previous works, we use the standard pre"
2020.ccl-1.89,P19-1136,0,0.0141314,"they ignore the interactions between the two phrases. To ease these problems, many joint models have been proposed to extract the relational triplets (e1 , r, e2 ), simultaneously. According to different extraction order, the joint models can be categorized into two paradigms. The first paradigm first identifies all entities in the sentence, then traverses each pair of entities and determines their potential relation. Various models have achieved promising results by exploiting recurrent neural network (Miwa and Bansal, 2016; Luan et al., 2019), graph convolutional network (Sun et al., 2019; Fu et al., 2019) and transformer-based structure (Eberts and Ulges, 2019; Wang et al., 2019). Though effective, these models need to examine every possible entity pairs, which inevitably contains a lot of redundant pairs. In the second paradigm, the head entities are detected first and the corresponding relations and tail entities are extracted later. Bekoulis et al. (Bekoulis et al., 2018) present the multi-head selection framework to automatically extract multiple entities and relations at once. Huang et al. (Huang et al., 2019) improve the MHS framework by using NER pretraining and soft label embedding fea"
2020.ccl-1.89,C16-1239,0,0.0301492,"Missing"
2020.ccl-1.89,P17-1085,0,0.0433706,"Missing"
2020.ccl-1.89,P19-1129,0,0.0656099,"ue, recent works propose to extract entities and relations jointly. These joint models fall into two paradigms. The first paradigm can be denoted as (e1 , e2 ) → r, which first recognizes all entities in the sentence, then classifies the relation depend on each extracted entity pairs. However, these methods require enumerating all possible entity pairs and the relation classification may be affected by the redundant ones. While another paradigm is referred as e1 → (r, e2), which detects head entities first and then predicts the corresponding relations and tail entities (Bekoulis et al., 2018; Li et al., 2019; Zhao et al., 2020). Comparing with the first paradigm, the second one can jointly identify entities and all the possible relations between them at once. A typical approach is the Multi-Head Selection (MHS) framework (Bekoulis et al., 2018). It first recognizes head entities using the BiLSTM-CRF structure and then performs tail entity extraction and relation extraction in one pass based on multiclass classification. The advantage of the MHS framework is obvious - it is efficient to work with the scenario, that one entity can involve several relational triplets, making this solution suitable f"
2020.ccl-1.89,P16-1200,0,0.0214812,"lation extraction task aims to recognize the entity spans from a sentence and detect the relations holds between two entities. Generally, it can be formed as extracting triplets (e1 , r, e2 ), which denotes that the relation r holds between the head entity e1 and the tail entity e2 , i.e., (John Smith, Live-In, Atlanta). It plays a vital role in the information extraction area and has attracted increasing attention in recent years. Traditional pipelined methods divide the task into two phases, named entity recognition (NER) and relation extraction (RE) (Miwa et al., 2009; Chan and Roth, 2011; Lin et al., 2016). As such methods neglect the underlying correlations between the two phases and suffer from the error propagation issue, recent works propose to extract entities and relations jointly. These joint models fall into two paradigms. The first paradigm can be denoted as (e1 , e2 ) → r, which first recognizes all entities in the sentence, then classifies the relation depend on each extracted entity pairs. However, these methods require enumerating all possible entity pairs and the relation classification may be affected by the redundant ones. While another paradigm is referred as e1 → (r, e2), whic"
2020.ccl-1.89,N19-1308,0,0.0246237,"fier. The pipelined methods suffer from error propagation issue and they ignore the interactions between the two phrases. To ease these problems, many joint models have been proposed to extract the relational triplets (e1 , r, e2 ), simultaneously. According to different extraction order, the joint models can be categorized into two paradigms. The first paradigm first identifies all entities in the sentence, then traverses each pair of entities and determines their potential relation. Various models have achieved promising results by exploiting recurrent neural network (Miwa and Bansal, 2016; Luan et al., 2019), graph convolutional network (Sun et al., 2019; Fu et al., 2019) and transformer-based structure (Eberts and Ulges, 2019; Wang et al., 2019). Though effective, these models need to examine every possible entity pairs, which inevitably contains a lot of redundant pairs. In the second paradigm, the head entities are detected first and the corresponding relations and tail entities are extracted later. Bekoulis et al. (Bekoulis et al., 2018) present the multi-head selection framework to automatically extract multiple entities and relations at once. Huang et al. (Huang et al., 2019) improve the MH"
2020.ccl-1.89,P16-1105,0,0.092338,"ed by a relation classifier. The pipelined methods suffer from error propagation issue and they ignore the interactions between the two phrases. To ease these problems, many joint models have been proposed to extract the relational triplets (e1 , r, e2 ), simultaneously. According to different extraction order, the joint models can be categorized into two paradigms. The first paradigm first identifies all entities in the sentence, then traverses each pair of entities and determines their potential relation. Various models have achieved promising results by exploiting recurrent neural network (Miwa and Bansal, 2016; Luan et al., 2019), graph convolutional network (Sun et al., 2019; Fu et al., 2019) and transformer-based structure (Eberts and Ulges, 2019; Wang et al., 2019). Though effective, these models need to examine every possible entity pairs, which inevitably contains a lot of redundant pairs. In the second paradigm, the head entities are detected first and the corresponding relations and tail entities are extracted later. Bekoulis et al. (Bekoulis et al., 2018) present the multi-head selection framework to automatically extract multiple entities and relations at once. Huang et al. (Huang et al.,"
2020.ccl-1.89,D14-1200,0,0.0280346,"Missing"
2020.ccl-1.89,D09-1013,0,0.0495958,"on ACE05, respectively. CC The entity-relation extraction task aims to recognize the entity spans from a sentence and detect the relations holds between two entities. Generally, it can be formed as extracting triplets (e1 , r, e2 ), which denotes that the relation r holds between the head entity e1 and the tail entity e2 , i.e., (John Smith, Live-In, Atlanta). It plays a vital role in the information extraction area and has attracted increasing attention in recent years. Traditional pipelined methods divide the task into two phases, named entity recognition (NER) and relation extraction (RE) (Miwa et al., 2009; Chan and Roth, 2011; Lin et al., 2016). As such methods neglect the underlying correlations between the two phases and suffer from the error propagation issue, recent works propose to extract entities and relations jointly. These joint models fall into two paradigms. The first paradigm can be denoted as (e1 , e2 ) → r, which first recognizes all entities in the sentence, then classifies the relation depend on each extracted entity pairs. However, these methods require enumerating all possible entity pairs and the relation classification may be affected by the redundant ones. While another pa"
2020.ccl-1.89,W04-2401,0,0.104699,"iment L2 where LNER , LGRC , and LMHS denote the loss function for head entity recognition, global relation classification and multi-head selection, respectively (Eq. 2, 13, 11), λ ∈ [0, 1] is the weight controling the trade-off of the global relation classification. L is averaged over samples for each batch. 4.1 Dataset CC In this section, we conduct extensive experiments to verify the effectiveness of our framework, and make detailed analyses to show its advantages. We evaluate the proposed method on two widely-used benchmarks for entity and relation extaction: CoNLL04 and ACE05. • CoNLL04 (Roth and Yih, 2004) defines 4 entity types including Location (LOC), Organization (ORG), Person (PER) and Other and 5 relation categories as Located-In, OrgBased-In, Live-In, Kill and Work-For. It consists of news articles from the Wall Street Journal and Associated Press. We use the data split by Gupta et al. (Gupta et al., 2016) (910 instances for training, 243 for validation and 288 for testing). • ACE05 (Doddington et al., 2004) provides 7 entity types: Location (LOC), Organization (ORG), Person (PER), Geopolitical Entity (GPE), Vehicle (VEH), Facility (FAC), Weapon (WEA) and 6 relation types: Organization a"
2020.ccl-1.89,N18-2074,0,0.0273984,"ernels. The second catagroy is the absolute position representation. The Transformer structure (Vaswani et al., 2017) contains neither recurrence nor convolution, in order to inject the positional information to the model, it defines the sine and consine functions of different frequencies to encode absolute positions. However, such absolute positions cannot model the interaction information between any two input tokens explicitly. Therefore, the third catagroy extends the selfattention mechanism to consider the relative positions or distances between sequential elements. Such as the model by (Shaw et al., 2018) and Transformer-XL (Dai et al., 2019). Different from the relative positions metioned above, we propose the relative positions exspecially for entities. As such information is not necessary for non-entity tokens, and may introduce noise on the contrary. 3 Method In this section, we briefly present the details of the relative position representation based multi-head selection framework. The concept of multi-head means that any head entity may be relevant to multiple relations and tail entities (Bekoulis et al., 2018). Formally, denote E and R as the set of pre-defined entity types and relation"
2020.ccl-1.89,P19-1131,0,0.0316245,"Missing"
2020.ccl-1.89,P19-1132,0,0.0513241,"Missing"
2020.coling-main.203,W16-2323,0,0.0305013,"ork and the attention mechanism (Bahdanau et al., 2014) for formality style transfer. NMT-Copy: Rao and Tetreault (2018) further use the copy mechanism (Gu et al., 2016) for enhancing the NMT baseline. PBMT-Combined: Rao and Tetreault (2018) report the result given by phrase-based statistical machine translation (PBMT) with a self-training method (Ueffing, 2006). We further reproduce the PBMTCombined results with our code and non-parallel language modeling data, denoted as PBMT-Combined*. NMT-Combined: Rao and Tetreault (2018) propose to synthesize a pseudo-parallel corpus by backtranslation (Sennrich et al., 2016) with the PBMT-Combined system. Then, the NMT model is trained on the combination of the parallel and pseudo-parallel corpora. The method is thus called NMT-Combined. As our augmented data and pre-processing are different with NMT-Combined, we further report the result with our code base, denoted as NMT-Combined*. JTHTA: Xu et al. (2019b) propose a method that uses one Seq2Seq model to do bi-directional transfer with formality annotations. They design formality classifier-guided loss and two reconstruction losses for jointly training. Notice that they combine the two domains for training, whic"
2020.coling-main.82,N18-1202,0,0.0316223,"layout variations. Recently, the rapid development of deep learning in computer vision has significantly boosted the data-driven image-based approaches for document layout analysis. Although these approaches have been widely adopted and made significant progress, they usually leverage visual features while neglecting textual features from the documents. Therefore, it is inevitable to explore how to leverage the visual and textual information in a unified way for document layout analysis. Nowadays, the state-of-the-art computer vision and NLP models are often built upon the pre-trained models (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018; Lample and Conneau, 2019; Yang et al., 2019; Dong et al., 2019; Raffel et al., 2019; Xu et al., 2019) followed by fine-tuning on specific downstream tasks, which achieves very promising results. However, pre-trained models not only require large-scale unlabeled data for self-supervised learning, but also need high quality labeled data for task-specific fine-tuning to achieve good performance. For document layout analysis tasks, there have been some image-based document layout datasets, while most of them are built for computer vision approaches and"
2020.coling-main.82,D19-1348,0,0.0586205,"Missing"
2020.findings-emnlp.140,I17-2069,0,0.0165153,"g to separate “content” and “style” of text and manipulate the style to induce transfer at inference time (Li et al., 2018; Fu et al., 2018; John et al., 2019). However, some works show that the disentanglement cannot be met and is not necessary, and leverage techniques like reconstruction and back-translation introduced in unsupervised machine translation (Lample et al., 2018), transformer (Dai et al., 2019) to achieve unsupervised style transfer. Different from style transfer, stylized response generation requires that the response is coherent with its context and the content can be varied. Akama et al. (2017) first train a basic model on a large-scale dialogue corpus and then fine-tune the model with a small stylized corpus. Niu and Bansal (2018) propose three weakly-supervised methods to generate polite responses using non-parallel data. Gao et al. (2019) build a structured latent space sharing between conversation modeling and style transfer. However, limited by the sparsity of the latent space, it is difficult to balance the style and contextual coherence while sampling in the neighborhood of the latent code of context at inference time. Pretraining Methods have led remarkable success in variou"
2020.findings-emnlp.140,N19-1423,0,0.0215877,"nsal (2018) propose three weakly-supervised methods to generate polite responses using non-parallel data. Gao et al. (2019) build a structured latent space sharing between conversation modeling and style transfer. However, limited by the sparsity of the latent space, it is difficult to balance the style and contextual coherence while sampling in the neighborhood of the latent code of context at inference time. Pretraining Methods have led remarkable success in various NLP tasks which demonstrates its great capabilities in language understanding and text generation (Radford et al., 2018, 2019; Devlin et al., 2019; Yang et al., 2019; Liu et al., 2019; Conneau and Lample, 2019; Clark et al., 2020). Recently, the pretraining methods have also been used to tackle the key challenges in dialogue systems such as context representation (Mehri et al., 2019), response selection (Henderson and Su, 2019), knowledge-grounded response 1549 generation (Zhao et al., 2020) and personalized response generation (Zheng et al., 2019). In particular, the large-scale pre-trained open-domain dialogue systems (Zhang et al., 2019b; Adiwardana et al., 2020) make a large step towards human-like chatbot against previous works whi"
2020.findings-emnlp.140,D12-1139,0,0.0820403,"Missing"
2020.findings-emnlp.140,D19-1190,0,0.152941,"Missing"
2020.findings-emnlp.140,P16-1094,0,0.0422656,"ask and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020). In this work, we study the problem of stylized response generation, which aims to incorporate the style information from non-parallel data into the generation process. Stylized Text Generation has attracted broad interest in recent years, especially the style transfer, which aims to alter one or more attributes of text while preserving the content. A prevalent idea of unsupervised style transfer is learning to separate “content” and “style” of text and manipulate the style to induce transfer at inference time (Li et al., 2018; Fu et"
2020.findings-emnlp.140,N18-1169,0,0.130778,"Missing"
2020.findings-emnlp.140,I17-1061,0,0.297754,"tyle. Such research could facilitate developers to customize their dialogue systems in terms of response styles, and thus broaden applications of the systems, from a social companion (Shum et al., 2018) or a virtual assistant (Ram et al., 2018) to a variety of vertical scenarios such as customer service (requiring a polite style), virtual characters in games (requiring specific personas), assistants in specific domains (requiring domain knowledge), etc. Normally, a target style is specified by a non-conversational corpus (e.g., novels, news, blogs, etc.) apart from the paired dialogue corpus (Luan et al., 2017; Niu and Bansal, 2018; Gao et al., 2019). Thus, the major challenge of the task lies in the scarcity of paired data for learning the correspondence between conversation contexts and proper responses in the desired style, which is a key factor in success of the neural dialogue models developed so far. As a result, it is very likely that a response either digresses from the context of the current dialogue (Luan et al., 2017; Gao et al., 2019), or loses fidelity to the target style (Niu and Bansal, 2018). We consider addressing the challenge by taking advantage of the large scale pre-trained lan"
2020.findings-emnlp.140,P19-1373,0,0.0117602,"arsity of the latent space, it is difficult to balance the style and contextual coherence while sampling in the neighborhood of the latent code of context at inference time. Pretraining Methods have led remarkable success in various NLP tasks which demonstrates its great capabilities in language understanding and text generation (Radford et al., 2018, 2019; Devlin et al., 2019; Yang et al., 2019; Liu et al., 2019; Conneau and Lample, 2019; Clark et al., 2020). Recently, the pretraining methods have also been used to tackle the key challenges in dialogue systems such as context representation (Mehri et al., 2019), response selection (Henderson and Su, 2019), knowledge-grounded response 1549 generation (Zhao et al., 2020) and personalized response generation (Zheng et al., 2019). In particular, the large-scale pre-trained open-domain dialogue systems (Zhang et al., 2019b; Adiwardana et al., 2020) make a large step towards human-like chatbot against previous works which rely on complex frameworks developed over many years. On this basis, we propose to study the open-domain stylized response generation with pre-trained models in this work. 3 oxt+1 , Ht+1 = Transformer(ext , Ht ), Approach We employ Dialo"
2020.findings-emnlp.140,Q18-1027,0,0.423159,"could facilitate developers to customize their dialogue systems in terms of response styles, and thus broaden applications of the systems, from a social companion (Shum et al., 2018) or a virtual assistant (Ram et al., 2018) to a variety of vertical scenarios such as customer service (requiring a polite style), virtual characters in games (requiring specific personas), assistants in specific domains (requiring domain knowledge), etc. Normally, a target style is specified by a non-conversational corpus (e.g., novels, news, blogs, etc.) apart from the paired dialogue corpus (Luan et al., 2017; Niu and Bansal, 2018; Gao et al., 2019). Thus, the major challenge of the task lies in the scarcity of paired data for learning the correspondence between conversation contexts and proper responses in the desired style, which is a key factor in success of the neural dialogue models developed so far. As a result, it is very likely that a response either digresses from the context of the current dialogue (Luan et al., 2017; Gao et al., 2019), or loses fidelity to the target style (Niu and Bansal, 2018). We consider addressing the challenge by taking advantage of the large scale pre-trained language models. The basi"
2020.findings-emnlp.140,P02-1040,0,0.107114,"he validation/test sets, and each context has at least 4 responses. Task arXiv-style Holmes-style Training Dconv Dstyle Reddit arXiv 10,000,000 1,347,538 Reddit Holmes 10,000,000 38,309 Validation Test Dval Dtest arXiv-style Reddit 2,000 2,000 Holmes-style Reddit 2,000 2,000 Table 1: Tasks and datasets 5.2 Evaluation Methodology We compare different models with both automatic metrics and human judgment. Automatic Metrics. For automatic evaluation, we measure the quality of generated responses from three aspects: Style Consistency, Relevance, and Diversity. The relevance is measured with BLEU (Papineni et al., 2002) and Rouge (Lin, 2004) 7 . To evaluate diversity, we follow Li et al. (2015) and use Distinct-1 (Dist-1) and Distinct-2 (Dist-2) as metrics which are calculated as ratios of distinct unigrams and bigrams in responses, respectively. In terms of style consistency, existing work only measures the style intensity using classifiers (Gao et al., 2019). However, the style of text is an amalgam, and differences between two styles are reflected in multiple linguistic dimensions (Verma and Srinivasan, 2019). Thus, we propose to evaluate the style of response from three perspectives: (1) Intensity: we re"
2020.findings-emnlp.140,P12-1000,0,0.228947,"Missing"
2020.findings-emnlp.140,P15-1152,0,0.0460083,"re three-fold: (1) proposal of tackling the problem of stylized response generation with pre-trained language models; (2) proposal of a word-level objective and a sentence-level objective in fine-tuning of a pre-trained language model for the task; and (3) empirical verification of the effectiveness of the proposed method on public datasets. 2 Related Work Open-domain Dialogue Generation has received more and more attention in NLP community. Inspired by neural machine translation, early works apply the sequence-to-sequence model to this task and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020"
2020.findings-emnlp.140,P19-1538,1,0.806335,"n has received more and more attention in NLP community. Inspired by neural machine translation, early works apply the sequence-to-sequence model to this task and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020). In this work, we study the problem of stylized response generation, which aims to incorporate the style information from non-parallel data into the generation process. Stylized Text Generation has attracted broad interest in recent years, especially the style transfer, which aims to alter one or more attributes of text while preserving the content. A prevalent idea of unsupervised"
2020.findings-emnlp.140,P19-1362,0,0.105059,"ilability of huge amount of human conversations on social media, there has been significant progress on building open-domain dialogue systems with natural language generation techniques. Though neural generative models are notorious for replying with bland responses (Li et al., 2015), some very recent work demonstrates that response generation models learned with pre-training techniques (Radford et al., 2019) can effectively overcome the deficiency suffered by previous models and are capable of having smooth conversations with humans through reasonable and specific replies (Wolf et al., 2019; Zhang et al., 2019b). The compelling performance exhibited by the pre-trained dialogue models encourages us to explore more difficult yet important problems in conversational AI. In this work, we study stylized response generation, that is responses provided by a ∗ Corresponding Author model should not only be coherent with the conversation contexts, but also be consistent with a designated style. Such research could facilitate developers to customize their dialogue systems in terms of response styles, and thus broaden applications of the systems, from a social companion (Shum et al., 2018) or a virtual assista"
2020.findings-emnlp.140,P18-1102,0,0.0135858,"on in NLP community. Inspired by neural machine translation, early works apply the sequence-to-sequence model to this task and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020). In this work, we study the problem of stylized response generation, which aims to incorporate the style information from non-parallel data into the generation process. Stylized Text Generation has attracted broad interest in recent years, especially the style transfer, which aims to alter one or more attributes of text while preserving the content. A prevalent idea of unsupervised style transfer is learning to separate"
2020.findings-emnlp.140,P18-1205,0,0.0236017,"on in NLP community. Inspired by neural machine translation, early works apply the sequence-to-sequence model to this task and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020). In this work, we study the problem of stylized response generation, which aims to incorporate the style information from non-parallel data into the generation process. Stylized Text Generation has attracted broad interest in recent years, especially the style transfer, which aims to alter one or more attributes of text while preserving the content. A prevalent idea of unsupervised style transfer is learning to separate"
2020.findings-emnlp.140,P17-1061,0,0.0331139,"anguage model for the task; and (3) empirical verification of the effectiveness of the proposed method on public datasets. 2 Related Work Open-domain Dialogue Generation has received more and more attention in NLP community. Inspired by neural machine translation, early works apply the sequence-to-sequence model to this task and achieve promising results (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). Since then, various architectures have been proposed to address the key challenges in open-domain dialogue systems, including suppressing the generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017a), context modeling (Serban et al., 2016, 2017; Xing et al., 2017b; Zhang et al., 2019a), controlling the attributes of responses (Xu et al., 2019; Zhou et al., 2017; Zhang et al., 2018a; Wang et al., 2018; See et al., 2019) and incorporating different types knowledge into generation (Li et al., 2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao et al., 2020). In this work, we study the problem of stylized response generation, which aims to incorporate the style information from non-parallel data into the generation process. Stylized Text Generation has attracted broad inte"
2020.lrec-1.236,P17-4012,0,0.0342952,"Missing"
2021.acl-long.421,P19-1299,0,0.0168099,"nts on cross-domain text classification demonstrate that CdKD achieves superior performance, which verifies the effectiveness in this novel setting. 1 Introduction Annotating sufficient training data is usually an expensive and time-consuming work for diverse application domains. Unsupervised Domain Adaptation (UDA) aims at solving this learning problem in the unlabeled target domain by utilizing the abundant knowledge in an existing domain called source domain, even when these domains may have different distributions. This technique has motivated research on cross-domain text classification (Chen et al., 2019; Ye et al., 2020; Gururangan et al., 2020). One of the important knowledge in the source domain is the labels of samples. Current methods mainly leverage the labeled source ∗ Corresponding author. data and unlabeled target data to learn the domaininvariant features (Tzeng et al., 2014; Ganin and Lempitsky, 2015) and the discriminative features (Saito et al., 2017; Ge et al., 2020) that are shared across different domains. Unfortunately, sometimes we are forbidden access to the source data, which are distributed on different devices and usually contain private information, e.g., user profile."
2021.acl-long.421,D14-1179,0,0.0205178,"Missing"
2021.acl-long.421,2020.acl-main.740,0,0.0584018,"Missing"
2021.acl-long.421,D14-1181,0,0.00251283,"et al., 2019). We compare with SHOT (Liang et al., 2020) for the UDA task without the source data. 1 http://jmcauley.ucsd.edu/data/amazon/ We also compare with the knowledge distillation method (KD) (Hinton et al., 2015) in our setting. In our experiments, three different extractors are selected. For Amazon-Feature dataset, the extractor is simply modeled as a typical 3-layer fully connected network (MLP) to transform 400d inputs into 50d latent feature vectors. Two types of networks are leveraged for Amazon-Text dataset to encode the original review texts, i.e., TextCNN and BertGRU. TextCNN (Kim, 2014) is a text convolutional network that consists of 150 convolutional filters with 3 different window sizes. We also evaluate the performance of cross-domain text classification on a pre-trained language model, i.e., BERT (Devlin et al., 2019). We freeze BERT model and construct a 2-layer bi-directional GRU (Cho et al., 2014) to learn from the representations produced by BERT. The classifier is modeled as a 2-layer fully connected network for all the settings. For CdKD, we consider to learn the source model fs by minimizing the standard cross-entropy loss. We randomly specify a 0.7/0.3 split in"
2021.acl-long.421,2020.emnlp-main.599,0,0.139221,"text classification demonstrate that CdKD achieves superior performance, which verifies the effectiveness in this novel setting. 1 Introduction Annotating sufficient training data is usually an expensive and time-consuming work for diverse application domains. Unsupervised Domain Adaptation (UDA) aims at solving this learning problem in the unlabeled target domain by utilizing the abundant knowledge in an existing domain called source domain, even when these domains may have different distributions. This technique has motivated research on cross-domain text classification (Chen et al., 2019; Ye et al., 2020; Gururangan et al., 2020). One of the important knowledge in the source domain is the labels of samples. Current methods mainly leverage the labeled source ∗ Corresponding author. data and unlabeled target data to learn the domaininvariant features (Tzeng et al., 2014; Ganin and Lempitsky, 2015) and the discriminative features (Saito et al., 2017; Ge et al., 2020) that are shared across different domains. Unfortunately, sometimes we are forbidden access to the source data, which are distributed on different devices and usually contain private information, e.g., user profile. Existing methods"
2021.acl-short.31,N19-1388,0,0.0333583,"nces among them. We combine the multilingual training objectives with the agreement term by randomly substituting some fragments of the source language with their counterpart translations of auxiliary languages. To examine the effectiveness of our method, we conduct experiments on the multilingual translation task of 10 language pairs. Experimental results show that our method achieves significant improvements over the previous multilingual baselines. 1 German Multilingual neural machine translation (MNMT) has experienced rapid growth in recent years (Johnson et al., 2017; Zhang et al., 2020; Aharoni et al., 2019; Wang et al., 2019). It is not only capable of translating among multiple language pairs by encouraging the crosslingual knowledge transfer to improve low-resource translation performance (Firat et al., 2016b; Zoph et al., 2016; Sen et al., 2019; Qin et al., 2020; Hedderich et al., 2020; Raffel et al., 2020), but also can handle multiple language pairs in a single model, reducing model parameters and training costs (Firat et al., 2016a; Blackwood et al., 2018; Wang et al., 2020; Sun et al., 2020). Previous works in MNMT simply optimize independent translation objectives and do not use arContr"
2021.acl-short.31,N19-1121,0,0.0224927,"Missing"
2021.acl-short.31,C18-1263,0,0.0176046,"an Multilingual neural machine translation (MNMT) has experienced rapid growth in recent years (Johnson et al., 2017; Zhang et al., 2020; Aharoni et al., 2019; Wang et al., 2019). It is not only capable of translating among multiple language pairs by encouraging the crosslingual knowledge transfer to improve low-resource translation performance (Firat et al., 2016b; Zoph et al., 2016; Sen et al., 2019; Qin et al., 2020; Hedderich et al., 2020; Raffel et al., 2020), but also can handle multiple language pairs in a single model, reducing model parameters and training costs (Firat et al., 2016a; Blackwood et al., 2018; Wang et al., 2020; Sun et al., 2020). Previous works in MNMT simply optimize independent translation objectives and do not use arContribution during internship at Microsoft Research Asia. † Corresponding author. English German + French English (b) Figure 1: Comparison between (a) the multilingual translation and (b) our agreement-based method. Introduction ∗ (a) German Alignment pairs bitrary auxiliary languages to encourage the agreement across different translation directions. As shown in Figure 1, the multilingual baseline is separately trained on French-English and GermanEnglish directio"
2021.acl-short.31,2020.eamt-1.49,0,0.0187435,"Machine Translation Previous works (Zoph et al., 2016; Firat et al., 2016b; Johnson et al., 2017) have explored different settings of the multilingual neural machine translation (MNMT). Recent studies show that MNMT (Blackwood et al., 2018; Platanios et al., 2018; Gu et al., 2018) helps improve the performance of the lowresource or zero-shot translation. Some researchers Agreement-based Learning Many works try to use the agreement-based method (Liang et al., 2007, 2006; Al-Shedivat and Parikh, 2019) to encourage agreement among different translation orders and directions (Liang et al., 2006; Castilho, 2020; Yang et al., 2020a; Cheng et al., 2016; Zhang et al., 2019). Besides, the agreement-based method is also used to minimize the difference between the representation of source and target sentence (Yang et al., 2019). Our method further explores the approach of the multilingual agreement. 7 Conclusion We propose a novel agreement-based framework to encourage multilingual agreement across different translation directions by the agreement term. Experimental results on the multilingual translation task demonstrate that our method effectively minimizes the gaps among different translation direction"
2021.acl-short.31,N13-1073,0,0.221871,"wstest19 Table 3: The statistics of the training, valid, and test sets on WMT datasets of 10 language pairs. Experiment Setup Multilingual Data 10.00M 10.00M 4.60M 4.80M 1.40M 0.70M 0.50M 0.26M 0.18M 0.08M Valid Baselines and Evaluation We compare our method against the following baselines. Bilingual baseline is trained on each language pair separately. One-to-Many and Manyto-One are trained on the En→X and X→En directions respectively. We collect all English sentences (33M) of the bilingual corpora described above and translate them into other languages sentences. We extract alignment pairs (Dyer et al., 2013) across different languages for our method. One-to-Many + Pseudo and Many-to-One + Pseudo are trained on multilingual data combined with the pseudo data. We average the last 5 checkpoints and employ the beam search strategy with a beam size of 5 for evaluation. The evaluation metric is case-sensitive detokenized sacreBLEU2 (Post, 2018). 1 https://github.com/google/ sentencepiece 2 BLEU+case.mixed+lang.{src}{tgt}+numrefs.1+smooth.exp+tok.13a+version.1.4.14 235 3.3 ▁m We adopt the Transformer big architecture as the backbone model for all our experiments, which has 6 layers with an embedding siz"
2021.acl-short.31,N16-1101,0,0.0163994,". To examine the effectiveness of our method, we conduct experiments on the multilingual translation task of 10 language pairs. Experimental results show that our method achieves significant improvements over the previous multilingual baselines. 1 German Multilingual neural machine translation (MNMT) has experienced rapid growth in recent years (Johnson et al., 2017; Zhang et al., 2020; Aharoni et al., 2019; Wang et al., 2019). It is not only capable of translating among multiple language pairs by encouraging the crosslingual knowledge transfer to improve low-resource translation performance (Firat et al., 2016b; Zoph et al., 2016; Sen et al., 2019; Qin et al., 2020; Hedderich et al., 2020; Raffel et al., 2020), but also can handle multiple language pairs in a single model, reducing model parameters and training costs (Firat et al., 2016a; Blackwood et al., 2018; Wang et al., 2020; Sun et al., 2020). Previous works in MNMT simply optimize independent translation objectives and do not use arContribution during internship at Microsoft Research Asia. † Corresponding author. English German + French English (b) Figure 1: Comparison between (a) the multilingual translation and (b) our agreement-based meth"
2021.acl-short.31,D16-1026,0,0.0553303,"Missing"
2021.acl-short.31,N18-1032,0,0.0474607,"Missing"
2021.acl-short.31,2020.emnlp-main.204,0,0.0284964,"multilingual translation task of 10 language pairs. Experimental results show that our method achieves significant improvements over the previous multilingual baselines. 1 German Multilingual neural machine translation (MNMT) has experienced rapid growth in recent years (Johnson et al., 2017; Zhang et al., 2020; Aharoni et al., 2019; Wang et al., 2019). It is not only capable of translating among multiple language pairs by encouraging the crosslingual knowledge transfer to improve low-resource translation performance (Firat et al., 2016b; Zoph et al., 2016; Sen et al., 2019; Qin et al., 2020; Hedderich et al., 2020; Raffel et al., 2020), but also can handle multiple language pairs in a single model, reducing model parameters and training costs (Firat et al., 2016a; Blackwood et al., 2018; Wang et al., 2020; Sun et al., 2020). Previous works in MNMT simply optimize independent translation objectives and do not use arContribution during internship at Microsoft Research Asia. † Corresponding author. English German + French English (b) Figure 1: Comparison between (a) the multilingual translation and (b) our agreement-based method. Introduction ∗ (a) German Alignment pairs bitrary auxiliary languages to enc"
2021.acl-short.31,Q17-1024,0,0.0520573,"Missing"
2021.acl-short.31,D18-2012,0,0.0136573,"use the same training, valid, and test sets as the previous work (Wang et al., 2020) to evaluate multilingual models by parallel data from multiple WMT datasets with various languages, including English (En), French (Fr), Czech (Cs), German (De), Finnish (Fi), Latvian (Lv), Estonian (Et), Romanian (Ro), Hindi (Hi), Turkish (Tr), and Gujarati (Gu). For each language, we concatenate the WMT data of the latest available year and get at most 10M sentences by randomly sampling. Detailed statistics of datasets are listed in Table 3. All sentences in our experiments are tokenized by SentencePiece1 (Kudo and Richardson, 2018). Test newstest13 newstest16 newstest16 newstest16 newsdev17 newsdev18 newsdev16 newsdev14 newstest16 newsdev19 newstest15 newstest18 newstest18 newstest18 newstest17 newstest18 newstest16 newstest14 newstest18 newstest19 Table 3: The statistics of the training, valid, and test sets on WMT datasets of 10 language pairs. Experiment Setup Multilingual Data 10.00M 10.00M 4.60M 4.80M 1.40M 0.70M 0.50M 0.26M 0.18M 0.08M Valid Baselines and Evaluation We compare our method against the following baselines. Bilingual baseline is trained on each language pair separately. One-to-Many and Manyto-One are"
2021.acl-short.31,N06-1014,0,0.3185,"Missing"
2021.acl-short.31,D18-1039,0,0.0355016,"Missing"
2021.acl-short.31,W18-6319,0,0.0120737,"separately. One-to-Many and Manyto-One are trained on the En→X and X→En directions respectively. We collect all English sentences (33M) of the bilingual corpora described above and translate them into other languages sentences. We extract alignment pairs (Dyer et al., 2013) across different languages for our method. One-to-Many + Pseudo and Many-to-One + Pseudo are trained on multilingual data combined with the pseudo data. We average the last 5 checkpoints and employ the beam search strategy with a beam size of 5 for evaluation. The evaluation metric is case-sensitive detokenized sacreBLEU2 (Post, 2018). 1 https://github.com/google/ sentencepiece 2 BLEU+case.mixed+lang.{src}{tgt}+numrefs.1+smooth.exp+tok.13a+version.1.4.14 235 3.3 ▁m We adopt the Transformer big architecture as the backbone model for all our experiments, which has 6 layers with an embedding size of 1024, a dropout of 0.1, the feed-forward network size of 4096, and 16 attention heads. We train multilingual models with Adam (Kingma and Ba, 2015) (β1 = 0.9, β2 = 0.98). The learning rate is set as 5e4 with a warm-up step of 4,000. The models are trained with the label smoothing cross-entropy with a smoothing ratio of 0.1. The ba"
2021.acl-short.31,P19-1297,0,0.0256514,"thod, we conduct experiments on the multilingual translation task of 10 language pairs. Experimental results show that our method achieves significant improvements over the previous multilingual baselines. 1 German Multilingual neural machine translation (MNMT) has experienced rapid growth in recent years (Johnson et al., 2017; Zhang et al., 2020; Aharoni et al., 2019; Wang et al., 2019). It is not only capable of translating among multiple language pairs by encouraging the crosslingual knowledge transfer to improve low-resource translation performance (Firat et al., 2016b; Zoph et al., 2016; Sen et al., 2019; Qin et al., 2020; Hedderich et al., 2020; Raffel et al., 2020), but also can handle multiple language pairs in a single model, reducing model parameters and training costs (Firat et al., 2016a; Blackwood et al., 2018; Wang et al., 2020; Sun et al., 2020). Previous works in MNMT simply optimize independent translation objectives and do not use arContribution during internship at Microsoft Research Asia. † Corresponding author. English German + French English (b) Figure 1: Comparison between (a) the multilingual translation and (b) our agreement-based method. Introduction ∗ (a) German Alignmen"
2021.acl-short.31,N19-1044,0,0.0373592,"Missing"
2021.acl-short.31,2020.acl-main.324,0,0.0247877,"(MNMT) has experienced rapid growth in recent years (Johnson et al., 2017; Zhang et al., 2020; Aharoni et al., 2019; Wang et al., 2019). It is not only capable of translating among multiple language pairs by encouraging the crosslingual knowledge transfer to improve low-resource translation performance (Firat et al., 2016b; Zoph et al., 2016; Sen et al., 2019; Qin et al., 2020; Hedderich et al., 2020; Raffel et al., 2020), but also can handle multiple language pairs in a single model, reducing model parameters and training costs (Firat et al., 2016a; Blackwood et al., 2018; Wang et al., 2020; Sun et al., 2020). Previous works in MNMT simply optimize independent translation objectives and do not use arContribution during internship at Microsoft Research Asia. † Corresponding author. English German + French English (b) Figure 1: Comparison between (a) the multilingual translation and (b) our agreement-based method. Introduction ∗ (a) German Alignment pairs bitrary auxiliary languages to encourage the agreement across different translation directions. As shown in Figure 1, the multilingual baseline is separately trained on French-English and GermanEnglish directions and cannot explicitly promote each"
2021.acl-short.31,2020.emnlp-main.75,0,0.123872,"achine translation (MNMT) has experienced rapid growth in recent years (Johnson et al., 2017; Zhang et al., 2020; Aharoni et al., 2019; Wang et al., 2019). It is not only capable of translating among multiple language pairs by encouraging the crosslingual knowledge transfer to improve low-resource translation performance (Firat et al., 2016b; Zoph et al., 2016; Sen et al., 2019; Qin et al., 2020; Hedderich et al., 2020; Raffel et al., 2020), but also can handle multiple language pairs in a single model, reducing model parameters and training costs (Firat et al., 2016a; Blackwood et al., 2018; Wang et al., 2020; Sun et al., 2020). Previous works in MNMT simply optimize independent translation objectives and do not use arContribution during internship at Microsoft Research Asia. † Corresponding author. English German + French English (b) Figure 1: Comparison between (a) the multilingual translation and (b) our agreement-based method. Introduction ∗ (a) German Alignment pairs bitrary auxiliary languages to encourage the agreement across different translation directions. As shown in Figure 1, the multilingual baseline is separately trained on French-English and GermanEnglish directions and cannot expli"
2021.acl-short.31,P19-1296,0,0.0208365,"MNMT (Blackwood et al., 2018; Platanios et al., 2018; Gu et al., 2018) helps improve the performance of the lowresource or zero-shot translation. Some researchers Agreement-based Learning Many works try to use the agreement-based method (Liang et al., 2007, 2006; Al-Shedivat and Parikh, 2019) to encourage agreement among different translation orders and directions (Liang et al., 2006; Castilho, 2020; Yang et al., 2020a; Cheng et al., 2016; Zhang et al., 2019). Besides, the agreement-based method is also used to minimize the difference between the representation of source and target sentence (Yang et al., 2019). Our method further explores the approach of the multilingual agreement. 7 Conclusion We propose a novel agreement-based framework to encourage multilingual agreement across different translation directions by the agreement term. Experimental results on the multilingual translation task demonstrate that our method effectively minimizes the gaps among different translation directions and significantly outperforms the multilingual baselines. The analytic experiment about the crosslingual representation shows the effectiveness of our multilingual agreement in minimizing the differences among dif"
2021.acl-short.31,2020.acl-main.148,0,0.0223165,"inimizes the differences among them. We combine the multilingual training objectives with the agreement term by randomly substituting some fragments of the source language with their counterpart translations of auxiliary languages. To examine the effectiveness of our method, we conduct experiments on the multilingual translation task of 10 language pairs. Experimental results show that our method achieves significant improvements over the previous multilingual baselines. 1 German Multilingual neural machine translation (MNMT) has experienced rapid growth in recent years (Johnson et al., 2017; Zhang et al., 2020; Aharoni et al., 2019; Wang et al., 2019). It is not only capable of translating among multiple language pairs by encouraging the crosslingual knowledge transfer to improve low-resource translation performance (Firat et al., 2016b; Zoph et al., 2016; Sen et al., 2019; Qin et al., 2020; Hedderich et al., 2020; Raffel et al., 2020), but also can handle multiple language pairs in a single model, reducing model parameters and training costs (Firat et al., 2016a; Blackwood et al., 2018; Wang et al., 2020; Sun et al., 2020). Previous works in MNMT simply optimize independent translation objectives"
2021.acl-short.31,D16-1163,0,0.024088,"ctiveness of our method, we conduct experiments on the multilingual translation task of 10 language pairs. Experimental results show that our method achieves significant improvements over the previous multilingual baselines. 1 German Multilingual neural machine translation (MNMT) has experienced rapid growth in recent years (Johnson et al., 2017; Zhang et al., 2020; Aharoni et al., 2019; Wang et al., 2019). It is not only capable of translating among multiple language pairs by encouraging the crosslingual knowledge transfer to improve low-resource translation performance (Firat et al., 2016b; Zoph et al., 2016; Sen et al., 2019; Qin et al., 2020; Hedderich et al., 2020; Raffel et al., 2020), but also can handle multiple language pairs in a single model, reducing model parameters and training costs (Firat et al., 2016a; Blackwood et al., 2018; Wang et al., 2020; Sun et al., 2020). Previous works in MNMT simply optimize independent translation objectives and do not use arContribution during internship at Microsoft Research Asia. † Corresponding author. English German + French English (b) Figure 1: Comparison between (a) the multilingual translation and (b) our agreement-based method. Introduction ∗ ("
2021.emnlp-main.14,N18-2105,0,0.224697,"ing, China {xnliang,lizj}@buaa.edu.cn; {frostwu,ethanlli}@tencent.com; Abstract universal and adaptive via extracting phrases based on information from input document itself. In this Embedding based methods are widely used paper, we focus on the unsupervised keyphrase exfor unsupervised keyphrase extraction (UKE) traction (UKE) model. tasks. Generally, these methods simply calculate similarities between phrase embeddings UKE has been widely studied (Mihalcea, 2004; and document embedding, which is insuffiWan and Xiao, 2008a; Bougouin et al., 2013; cient to capture different context for a more Boudin, 2018; Bennani-Smires et al., 2018; Sun effective UKE model. In this paper, we proet al., 2020) in the keyphrase extraction field. Repose a novel method for UKE, where local cently, with the development of text representaand global contexts are jointly modeled. From tion, embedding-based models (Bennani-Smires a global view, we calculate the similarity beet al., 2018; Sun et al., 2020) have achieved promistween a certain phrase and the whole docuing results and become the new state-of-the-art ment in the vector space as transitional embedding based models do. In terms of the local models. Usually,"
2021.emnlp-main.14,I13-1062,0,0.377053,"ent, Beihang University, Beijing, China 2 Tencent Cloud Xiaowei, Beijing, China {xnliang,lizj}@buaa.edu.cn; {frostwu,ethanlli}@tencent.com; Abstract universal and adaptive via extracting phrases based on information from input document itself. In this Embedding based methods are widely used paper, we focus on the unsupervised keyphrase exfor unsupervised keyphrase extraction (UKE) traction (UKE) model. tasks. Generally, these methods simply calculate similarities between phrase embeddings UKE has been widely studied (Mihalcea, 2004; and document embedding, which is insuffiWan and Xiao, 2008a; Bougouin et al., 2013; cient to capture different context for a more Boudin, 2018; Bennani-Smires et al., 2018; Sun effective UKE model. In this paper, we proet al., 2020) in the keyphrase extraction field. Repose a novel method for UKE, where local cently, with the development of text representaand global contexts are jointly modeled. From tion, embedding-based models (Bennani-Smires a global view, we calculate the similarity beet al., 2018; Sun et al., 2020) have achieved promistween a certain phrase and the whole docuing results and become the new state-of-the-art ment in the vector space as transitional embedd"
2021.emnlp-main.14,N19-1423,0,0.078136,"and become the new state-of-the-art ment in the vector space as transitional embedding based models do. In terms of the local models. Usually, these methods compute phrase view, we first build a graph structure based on embeddings and document embedding with static the document where phrases are regarded as word2vec models (e.g. GloVe (Pennington et al., vertices and the edges are similarities between 2014; Le and Mikolov, 2014; Pagliardini et al., vertices. Then, we proposed a new centrality 2018)) or dynamic pre-trained language models computation method to capture local salient (e.g. BERT (Devlin et al., 2019)). Then, they rank information based on the graph structure. Ficandidate phrases by computing the similarity benally, we further combine the modeling of global and local context for ranking. We evaltween phrases and the whole document in the vecuate our models on three public benchmarks tor space. Though, these methods performed better (Inspec, DUC 2001, SemEval 2010) and comthan traditional methods (Mihalcea, 2004; Wan and pare with existing state-of-the-art models. The Xiao, 2008a; Bougouin et al., 2013), the simple results show that our model outperforms most similarity between phrase and d"
2021.emnlp-main.14,2021.eacl-main.93,0,0.0316195,"is paper, we proposed a novel method which jointly models the local and global context of the input document. Specifically, we calculate the similarity between candidate phrases and the whole document for modeling global context. For local context modeling, we first build a graph structure, which represents each phrase as nodes and the edges are similarity between nodes. Then, we proposed a new centrality computation method, which is based on the insight that the most important information typically occurs at the start or end of documents (document boundary) (Lin and Hovy, 1997; Teufel, 1997; Dong et al., 2021), to measure salience of local context based on the graph structure. Finally, we further combine the measure of global similarity and local salience for ranking. To evaluate the effectiveness of our method, we compare our method with recent state-of-the-art models on three public benchmarks (Inspec, DUC 2001, SemEval 2010). The results show that our model can outperform most models while generalizing better on input documents with different domains and length. It is deservedly mentioned that our models have a huge improvement on long scientific documents. 2 Methodology vised keyphrase extracti"
2021.emnlp-main.14,P17-1102,0,0.036178,"Missing"
2021.emnlp-main.14,P14-1119,0,0.0709339,"Missing"
2021.emnlp-main.14,W03-1028,0,0.289061,"ence of phrases which do not appear near the boundary to the centrality of node i. Besides, we employ a threshold θ = β(max(eij − min(eij )) to filter the noise from nodes, which is far different from node i. We remove the influence of them to centrality by setting all eij < θ to zero. β is a hyper-parameter that controls the filter boundary. With the introduction of the noise filter strategy, we rewrite the Equ. (6) as Equ. (7). C(HKPi ) = (8) Experiments Datasets and Evaluation Metrics We evaluate our model on three public datasets: Inspec, DUC2001 and SemEval2010. The Inspec (7) X dataset (Hulth, 2003) consists of 2,000 short doc+λ max(eij − θ, 0) uments from scientific journal abstracts. We foldb (i)≥db (j) low previous works (Bennani-Smires et al., 2018; Where C(HKPi ) represents the local salience of Sun et al., 2020) to use 500 test documents and candidate phrase i. the version of uncontrolled annotated keyphrases For most long documents or news articles, the as ground truth. The DUC2001 dataset (Wan and author tends to write the key information at the Xiao, 2008a) is a collection of 308 long length beginning of the document. Florescu and Caragea news articles with average 828.4 tokens."
2021.emnlp-main.14,E14-1053,0,0.0286422,"ombine global similarity and boundary-aware centrality for local salient information to rank and extract phrases. Unsupervised keyphrase extraction can be divided into four main types: statistics-based models, graph-based models, topic-based models, and embedding-based models. Statistics-based models 5 Conclusion and Future Work (Campos et al., 2018) mainly analyze an article’s probability features such as word frequency fea- In this paper, we point out that embedding-based ture, position feature, linguistic features, etc. Topic- models ignore the local information and propose a based models (Jardine and Teufel, 2014; Liu et al., novel model which jointly models global and local 2009) focus on how to mine keyphrases by making context. Our model revisited degree centrality and use of the probability distribution of articles. modified it with boundary function for modeling local context. We combine global similarity with Graph-based models are the most proposed and popular used in early works which convert the doc- our proposed boundary-aware centrality to extract ument into a graph. Inspired by (Page et al., 1999), keyphrases. Experiments on 3 public benchmarks demonstrate that our model can effectively ca"
2021.emnlp-main.14,E17-2068,0,0.0121188,"and then fine-tuned on downWe can see that all keyphrases occur at the start stream tasks. The pre-trained language model withof the document. Our model extracted many correct phrases which are the same as gold truth and ex- out fine-tuning also can provide high quality embedding of natural texts for unsupervised tasks. tracted the phrase “existing word record"" which is semantically same with “word record"" in gold truth. Different from static word embedding, such as Word2Vec (Mikolov et al., 2013), GloVe (PenningIt is worth mentioning that our model focuses on ton et al., 2014), and FastText (Joulin et al., 2017). the boundary of the document and most extracted phrases were located at the start of the document, Pre-trained language models can encode words or sentences with context dynamically and solve the which is controlled by our setting of α. This proves the effectiveness of our boundary-aware central- OOV problem. In addition, pre-trained language models can provide document-level or sentenceity. From the figure, we also can find that wrong phrases are highly relevant to topics of this docu- level embedding which contains more semantic information than Sen2Vec (Pagliardini et al., 2018) ment, whi"
2021.emnlp-main.14,S10-1004,0,0.047616,"oc+λ max(eij − θ, 0) uments from scientific journal abstracts. We foldb (i)≥db (j) low previous works (Bennani-Smires et al., 2018; Where C(HKPi ) represents the local salience of Sun et al., 2020) to use 500 test documents and candidate phrase i. the version of uncontrolled annotated keyphrases For most long documents or news articles, the as ground truth. The DUC2001 dataset (Wan and author tends to write the key information at the Xiao, 2008a) is a collection of 308 long length beginning of the document. Florescu and Caragea news articles with average 828.4 tokens. The SemEval2010 dataset (Kim et al., 2010) contains (2017a) point out that the position-biased weight can greatly improve the performance for keyphrase ACM full length papers. In our experiments, we extraction and they employ the sum of the posi- use the 100 test documents and the combined set tion’s inverse of words in the document as the of author- and reader- annotated keyphrases. weight. For example, the word appearing at We follow the common practice and evaluate the 2th, 5th and 10th, has a weight p(wi ) = 1/2 + performance of our models in terms of f-measure 1/5 + 1/10 = 0.8. Our boundary-aware centrality at the top N keyphrase"
2021.emnlp-main.14,2021.findings-acl.147,1,0.729494,"ng et al., 2020), etc. In this paper, we choose BERT, the most used, to obtain vector representation of documents and phrases by merging the embedding of tokens. 4.2 Unsupervised Keyphrase Extraction phrases by measuring the similarity between phrase embedding and document embedding. (Sun et al., 2020) proposed SIFRank, which improves the static embedding from EmbedRank with a pretrained language model. Embedding-based models just measured the similarity between document and candidate phrases and ignored the local information. To jointly model global and local context (Zheng and Lapata, 2019; Liang et al., 2021), in this paper, we revisit degree centrality, which can model local context, and convert it into boundary-aware centrality. Then, we combine global similarity and boundary-aware centrality for local salient information to rank and extract phrases. Unsupervised keyphrase extraction can be divided into four main types: statistics-based models, graph-based models, topic-based models, and embedding-based models. Statistics-based models 5 Conclusion and Future Work (Campos et al., 2018) mainly analyze an article’s probability features such as word frequency fea- In this paper, we point out that em"
2021.emnlp-main.14,A97-1042,0,0.596809,"ion from context adequately, in this paper, we proposed a novel method which jointly models the local and global context of the input document. Specifically, we calculate the similarity between candidate phrases and the whole document for modeling global context. For local context modeling, we first build a graph structure, which represents each phrase as nodes and the edges are similarity between nodes. Then, we proposed a new centrality computation method, which is based on the insight that the most important information typically occurs at the start or end of documents (document boundary) (Lin and Hovy, 1997; Teufel, 1997; Dong et al., 2021), to measure salience of local context based on the graph structure. Finally, we further combine the measure of global similarity and local salience for ranking. To evaluate the effectiveness of our method, we compare our method with recent state-of-the-art models on three public benchmarks (Inspec, DUC 2001, SemEval 2010). The results show that our model can outperform most models while generalizing better on input documents with different domains and length. It is deservedly mentioned that our models have a huge improvement on long scientific documents. 2 Me"
2021.emnlp-main.14,D09-1027,0,0.0943428,"Missing"
2021.emnlp-main.14,P04-3020,0,0.749142,"Wu2 , Mu Li2 and Zhoujun Li1† State Key Lab of Software Development Environment, Beihang University, Beijing, China 2 Tencent Cloud Xiaowei, Beijing, China {xnliang,lizj}@buaa.edu.cn; {frostwu,ethanlli}@tencent.com; Abstract universal and adaptive via extracting phrases based on information from input document itself. In this Embedding based methods are widely used paper, we focus on the unsupervised keyphrase exfor unsupervised keyphrase extraction (UKE) traction (UKE) model. tasks. Generally, these methods simply calculate similarities between phrase embeddings UKE has been widely studied (Mihalcea, 2004; and document embedding, which is insuffiWan and Xiao, 2008a; Bougouin et al., 2013; cient to capture different context for a more Boudin, 2018; Bennani-Smires et al., 2018; Sun effective UKE model. In this paper, we proet al., 2020) in the keyphrase extraction field. Repose a novel method for UKE, where local cently, with the development of text representaand global contexts are jointly modeled. From tion, embedding-based models (Bennani-Smires a global view, we calculate the similarity beet al., 2018; Sun et al., 2020) have achieved promistween a certain phrase and the whole docuing results"
2021.emnlp-main.14,W04-3252,0,0.363219,"Missing"
2021.emnlp-main.14,N18-1049,0,0.0219319,"and FastText (Joulin et al., 2017). the boundary of the document and most extracted phrases were located at the start of the document, Pre-trained language models can encode words or sentences with context dynamically and solve the which is controlled by our setting of α. This proves the effectiveness of our boundary-aware central- OOV problem. In addition, pre-trained language models can provide document-level or sentenceity. From the figure, we also can find that wrong phrases are highly relevant to topics of this docu- level embedding which contains more semantic information than Sen2Vec (Pagliardini et al., 2018) ment, which is influenced by our phrase-document or Doc2Vec (Le and Mikolov, 2014). relevance weighting. This example shows that the joint modeling of global and local context can imELMo (Peters et al., 2018) employs Bi-LSTM prove the performance of keyphrase extraction and structure and concatenate forward and backward our model really captures local and global informa- information to capture bidirectional information. 161 BERT (Devlin et al., 2019) is a bidirectional transformer structure pre-trained language model. Compared with the concatenation of bidirectional information, BERT can capt"
2021.emnlp-main.14,D14-1162,0,0.124094,"Missing"
2021.emnlp-main.14,C16-1089,0,0.0281886,"Missing"
2021.emnlp-main.14,P19-1628,0,0.0188321,"et al., 2019), XLNET (Yang et al., 2020), etc. In this paper, we choose BERT, the most used, to obtain vector representation of documents and phrases by merging the embedding of tokens. 4.2 Unsupervised Keyphrase Extraction phrases by measuring the similarity between phrase embedding and document embedding. (Sun et al., 2020) proposed SIFRank, which improves the static embedding from EmbedRank with a pretrained language model. Embedding-based models just measured the similarity between document and candidate phrases and ignored the local information. To jointly model global and local context (Zheng and Lapata, 2019; Liang et al., 2021), in this paper, we revisit degree centrality, which can model local context, and convert it into boundary-aware centrality. Then, we combine global similarity and boundary-aware centrality for local salient information to rank and extract phrases. Unsupervised keyphrase extraction can be divided into four main types: statistics-based models, graph-based models, topic-based models, and embedding-based models. Statistics-based models 5 Conclusion and Future Work (Campos et al., 2018) mainly analyze an article’s probability features such as word frequency fea- In this paper,"
2021.emnlp-main.14,N18-1202,0,0.0235346,"ally and solve the which is controlled by our setting of α. This proves the effectiveness of our boundary-aware central- OOV problem. In addition, pre-trained language models can provide document-level or sentenceity. From the figure, we also can find that wrong phrases are highly relevant to topics of this docu- level embedding which contains more semantic information than Sen2Vec (Pagliardini et al., 2018) ment, which is influenced by our phrase-document or Doc2Vec (Le and Mikolov, 2014). relevance weighting. This example shows that the joint modeling of global and local context can imELMo (Peters et al., 2018) employs Bi-LSTM prove the performance of keyphrase extraction and structure and concatenate forward and backward our model really captures local and global informa- information to capture bidirectional information. 161 BERT (Devlin et al., 2019) is a bidirectional transformer structure pre-trained language model. Compared with the concatenation of bidirectional information, BERT can capture better context information. There are also a lot of other pre-trained language models such as RoBERTa (Liu et al., 2019), XLNET (Yang et al., 2020), etc. In this paper, we choose BERT, the most used, to ob"
2021.emnlp-main.14,2020.coling-main.184,0,0.0352814,"Missing"
2021.emnlp-main.14,W97-0710,0,0.43423,"quately, in this paper, we proposed a novel method which jointly models the local and global context of the input document. Specifically, we calculate the similarity between candidate phrases and the whole document for modeling global context. For local context modeling, we first build a graph structure, which represents each phrase as nodes and the edges are similarity between nodes. Then, we proposed a new centrality computation method, which is based on the insight that the most important information typically occurs at the start or end of documents (document boundary) (Lin and Hovy, 1997; Teufel, 1997; Dong et al., 2021), to measure salience of local context based on the graph structure. Finally, we further combine the measure of global similarity and local salience for ranking. To evaluate the effectiveness of our method, we compare our method with recent state-of-the-art models on three public benchmarks (Inspec, DUC 2001, SemEval 2010). The results show that our model can outperform most models while generalizing better on input documents with different domains and length. It is deservedly mentioned that our models have a huge improvement on long scientific documents. 2 Methodology vise"
2021.emnlp-main.771,P17-1176,0,0.0166798,"ode. To facilitate the study of this task, we create a dataset with multiple programming languages. The dataset is collected from commit and buggy-fixed histories of open-source software projects, where each example consists of buggy code, fixed code, and the corresponding commit message. We first introduce the cascaded methods as baseline. The cascaded model employs one model to repair code and the other to generate commit message successively. We enhance this cascaded model with three training approaches inspired by the low-resource machine translation, including the teacher-student method (Chen et al., 2017), the multi-task learning method (Domhan and Hieber, 2017), and the back-translation method (Sennrich et al., 2016a). To deal with the error propagation problem of the cascaded method, we propose a joint model which can achieve both code repair and commit message generation in a single model. We train and evaluate our model using the created triple (buggy-fixed-commit) dataset. The results demonstrate the validity of our proposed methods, which achieve a significant improvement over baseline in both qualities of code and commit messages. Particularly, the enhanced cascaded method obtains the b"
2021.emnlp-main.771,2020.emnlp-main.728,0,0.0161259,"an appropriate message, while the cascaded model fails may due to the error propagation. More examples on multilingual dataset are shown in Appendix D. 6 Related Work Our work is enlightened from two research lines of studies, which are automated code repair and commit message generation. We discuss these topics in the following. projects with numerous buggy-fixes pairs (Tufano et al., 2018; Chen et al., 2019; Vasic et al., 2019; Yasunaga and Liang, 2020). Tufano et al. (2018) first proposed using end-to-end neural machine translation model for learning bug-fixing patches. Besides, Guo et al. (2020) demonstrated that appropriately incorporating the natural language descriptions into the pre-train model could further improve the performance of code repair. Commit Message Generation Early work on automatic commit message generation translates source code changes (such as feature additions and bug repairs) into natural language based on predefined rules and templates (Buse and Weimer, 2010; Cortés-Coy et al., 2014). To overcome the limitation of high complexity and difficult extensibility, some researchers employ information retrieval methods to generate commit messages, which attempts to r"
2021.emnlp-main.771,D17-1158,0,0.0168867,"a dataset with multiple programming languages. The dataset is collected from commit and buggy-fixed histories of open-source software projects, where each example consists of buggy code, fixed code, and the corresponding commit message. We first introduce the cascaded methods as baseline. The cascaded model employs one model to repair code and the other to generate commit message successively. We enhance this cascaded model with three training approaches inspired by the low-resource machine translation, including the teacher-student method (Chen et al., 2017), the multi-task learning method (Domhan and Hieber, 2017), and the back-translation method (Sennrich et al., 2016a). To deal with the error propagation problem of the cascaded method, we propose a joint model which can achieve both code repair and commit message generation in a single model. We train and evaluate our model using the created triple (buggy-fixed-commit) dataset. The results demonstrate the validity of our proposed methods, which achieve a significant improvement over baseline in both qualities of code and commit messages. Particularly, the enhanced cascaded method obtains the best performance on code repair task, and the joint method"
2021.emnlp-main.771,P84-1044,0,0.302985,"Missing"
2021.emnlp-main.771,Q17-1024,0,0.0151993,"ination between 9787 cφ = sof tmax zc zTφ √ H ! zφ (9) the output state of commit message decoder and the gated fusion of context representations, which can be calculated as:  T oc = zc + Wo gδ δ + gζ ζ T  Joint Training We jointly train our model in an end-to-end manner, the overall loss is defined as (13) where LR (θ), LC (θ)and LT (θ) are used to optimize the repaired code generation, commit message generation, and binary sequence classification, respectively. When training multilingual model of fixing code and predicting commit message, following multilingual neural machine translation (Johnson et al., 2017), we mix the training corpus and add a special token (e.g., <java>) at the beginning of each input sequence to distinguish from different programming languages. 4 Train Valid Test Total Multi. Python Java Javascript C-sharp Cpp 36682 11129 21446 5424 8510 4585 1391 2680 678 1063 4586 1392 2681 678 1064 45853 13912 26807 6780 10637 Mono. Java 47775 3000 3000 53775 (12) where Wo ∈ RH×H is the learnable weights. denotes the element-wise product. LJ (θ) = LR (θ) + LC (θ) + LT (θ) Languages Data In this section, we describe the creation of the dataset in detail. We first describe how we collect the"
2021.emnlp-main.771,P17-2045,0,0.116157,"ly reduce debugging costs in software development and helps 1 Introduction programmers to understand the high-level rationale Deep learning has been demonstrated remarkably of changes, a lot of great work has been proposed to adept at numerous natural language processing deal with automated program repair (Tufano et al., (NLP) tasks, such as machine translation (Bah- 2018; Chen et al., 2019; Dinella et al., 2020; Yadanau et al., 2014), relation extraction (Zhang et al., sunaga and Liang, 2020; Tang et al., 2021) and 2017), grammar error correction (Ge et al., 2018), commit message generation (Loyola et al., 2017; and so on. The success of deep learning in NLP Liu et al., 2020; Nie et al., 2020), respectively. also promotes the development of which in pro- However, existing work tackles the two tasks ingramming languages (Clement et al., 2020; Lu dependently, ignoring the underlying relationship et al., 2021). Recently, researchers have exploited between these two closely related tasks, e.g., afdeep learning to programming-language related ter fixing the bug, commit message can record the tasks, such as code completion (Svyatkovskiy et al., process of code repair. Therefore it is crucial to 2020), aut"
2021.emnlp-main.771,P16-1162,0,0.561635,"is collected from commit and buggy-fixed histories of open-source software projects, where each example consists of buggy code, fixed code, and the corresponding commit message. We first introduce the cascaded methods as baseline. The cascaded model employs one model to repair code and the other to generate commit message successively. We enhance this cascaded model with three training approaches inspired by the low-resource machine translation, including the teacher-student method (Chen et al., 2017), the multi-task learning method (Domhan and Hieber, 2017), and the back-translation method (Sennrich et al., 2016a). To deal with the error propagation problem of the cascaded method, we propose a joint model which can achieve both code repair and commit message generation in a single model. We train and evaluate our model using the created triple (buggy-fixed-commit) dataset. The results demonstrate the validity of our proposed methods, which achieve a significant improvement over baseline in both qualities of code and commit messages. Particularly, the enhanced cascaded method obtains the best performance on code repair task, and the joint method behaves better than the cascaded method on commit messag"
2021.emnlp-main.771,2021.findings-acl.111,1,0.811582,"Missing"
2021.emnlp-main.771,P02-1040,0,0.109484,"e, and commit message. The statistics of the dataset used in this paper are summarized in Table 1. More processing details and statistics can be found in Appendix A and Appendix B. We release the datasets at https: //github.com/jqbemnlp/BFCsData. 5 5.1 Experiments Experimental Settings Evaluation Metrics We conduct evaluations on both code repair and commit message generation. For the code repair, we use exact match accuracy (Chen et al., 2018) to measure the percentage of the predicted fixed code that are exactly matching the truth fixed code. In addition, we also introduce the BLEU-4 score (Papineni et al., 2002) as a supplementary metric to evaluate their partial match. For the commit message generation, we use BLEU-4 and Rouge-L (Lin, 2004) to evaluate our model. 3 https://www.githubarchive.org https://docs.github.com/en/ free-pro-team@latest/rest 4 5 https://sites.google.com/view/ learning-fixes/data 9788 Models Naive Method Oracle Method Cascaded Model + Teacher-student + Multitask + Back-translation Joint Model Automated Code Repair BLEU-4 xMatch 87.45 0.00 85.07 3.21 88.23 6.16 87.94 8.33 87.73 5.26 87.61 8.01 Commit Message Generation BLEU-4 ROUGE-L 8.40 7.98 12.64 11.59 9.69 9.41 10.58 10.19 1"
2021.emnlp-main.771,D17-1182,0,0.0279627,"Missing"
2021.emnlp-main.771,W16-2323,0,0.311742,"is collected from commit and buggy-fixed histories of open-source software projects, where each example consists of buggy code, fixed code, and the corresponding commit message. We first introduce the cascaded methods as baseline. The cascaded model employs one model to repair code and the other to generate commit message successively. We enhance this cascaded model with three training approaches inspired by the low-resource machine translation, including the teacher-student method (Chen et al., 2017), the multi-task learning method (Domhan and Hieber, 2017), and the back-translation method (Sennrich et al., 2016a). To deal with the error propagation problem of the cascaded method, we propose a joint model which can achieve both code repair and commit message generation in a single model. We train and evaluate our model using the created triple (buggy-fixed-commit) dataset. The results demonstrate the validity of our proposed methods, which achieve a significant improvement over baseline in both qualities of code and commit messages. Particularly, the enhanced cascaded method obtains the best performance on code repair task, and the joint method behaves better than the cascaded method on commit messag"
2021.findings-acl.147,N19-1071,0,0.0163608,"lel datasets. Supervised summarization algorithms develop sharply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive summarization. However, most unsupervised summarization models are extractive (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Carbonell and Goldstein, 1998; Wan, 2008; Wan and Yang, 2008; Schluter and Søgaard, 2015; Zhao et al., 2020) and focused on the measure of sentence salient. Graph-based models are effective and widely concerned in unsupervised extractive methods. Different from traditional undirected graph rank models (Radev et al., 2000; Mihal"
2021.findings-acl.147,2020.acl-main.554,0,0.0203501,"acSum all focus on the facet which describes terroristic attacks in Iraq. However, FAR can cover all 3 facets in gold reference. This shows that our FAR can effectively improve the performance by reducing the facet bias problem. 6 Related Work Summarization is a long-standing challenge for researchers to address. Thanks to the power of the neural network and availability of large-scale parallel datasets. Supervised summarization algorithms develop sharply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive summarization. However, most unsupervised summarization models are extractive"
2021.findings-acl.147,P16-1046,0,0.0229968,". Extensive analyses confirm that the performance gains come from alleviating the facet bias problem. 1 Figure 1: Examples from New York Times. We selected part of key sentences from the source document to show in this table. “...” refers to the omissions of context sentences due to space limitation. Introduction Document summarization is the task of transforming a long document into a shorter version while retaining its most important content (Nenkova and McKeown, 2011).Existing extractive or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised met"
2021.findings-acl.147,P19-1098,0,0.0186627,"can see that sentences extracted by PacSum all focus on the facet which describes terroristic attacks in Iraq. However, FAR can cover all 3 facets in gold reference. This shows that our FAR can effectively improve the performance by reducing the facet bias problem. 6 Related Work Summarization is a long-standing challenge for researchers to address. Thanks to the power of the neural network and availability of large-scale parallel datasets. Supervised summarization algorithms develop sharply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive summarization. However, most unsupervised"
2021.findings-acl.147,N16-1012,0,0.0407289,"from a news report and only used to analyze the effectiveness of our model.) As shown in Table 5, we can see that sentences extracted by PacSum all focus on the facet which describes terroristic attacks in Iraq. However, FAR can cover all 3 facets in gold reference. This shows that our FAR can effectively improve the performance by reducing the facet bias problem. 6 Related Work Summarization is a long-standing challenge for researchers to address. Thanks to the power of the neural network and availability of large-scale parallel datasets. Supervised summarization algorithms develop sharply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and"
2021.findings-acl.147,N18-2097,0,0.11448,"are written by library scientists. Different from CNNDM, salient sentences distribute evenly in an article (Durrett et al., 2016). We filter out documents whose length of summaries are shorter than 50 tokens (Zheng and Lapata, 2019). MultiNews dataset consists of news articles and human-written summaries. The dataset is the first large-scale Multi-Documents Summarization (MDS) news dataset and comes from a diverse set of news sources (over 1500 sites) (Fabbri et al., 2019). arXiv&PubMed datasets are two long document datasets of scientific publications from arXiv.org (113k) and PubMed (215k) (Cohan et al., 2018). The task is to generate the abstract from the paper body. WikiSum dataset is a multi-documents summarization dataset from Wikipedia (Liu et al., 2018). We use the version provided by (Liu and Lapata, 2019a), which selects ranked top-40 paragraphs as input. For this dataset, we filter out documents whose summary length is less than 100 tokens. After the process, WikiSum test set contains 15,795 examples and the average length of summaries is 198. WikiHow dataset is a large-scale dataset of instructions from the online WikiHow.com website (Koupaee and Wang, 2018). The task is to generate the c"
2021.findings-acl.147,P16-1188,0,0.0183875,"Experiments Datasets We introduce the datasets used in our experiments in this section. CNN/DM dataset contains 93k articles from CNN, and 220k articles from Daily Mail newspapers (Hermann et al., 2015). We use the nonanonymous version. Following (Zheng and Lapata, 2019), documents whose length of summaries are shorter than 30 tokens are filtered out. NYT dataset contains articles published by the New York Times between January 1, 1987 and June 19, 2007 (Li et al., 2016). The summaries are written by library scientists. Different from CNNDM, salient sentences distribute evenly in an article (Durrett et al., 2016). We filter out documents whose length of summaries are shorter than 50 tokens (Zheng and Lapata, 2019). MultiNews dataset consists of news articles and human-written summaries. The dataset is the first large-scale Multi-Documents Summarization (MDS) news dataset and comes from a diverse set of news sources (over 1500 sites) (Fabbri et al., 2019). arXiv&PubMed datasets are two long document datasets of scientific publications from arXiv.org (113k) and PubMed (215k) (Cohan et al., 2018). The task is to generate the abstract from the paper body. WikiSum dataset is a multi-documents summarization"
2021.findings-acl.147,P19-1102,0,0.0121204,"out. NYT dataset contains articles published by the New York Times between January 1, 1987 and June 19, 2007 (Li et al., 2016). The summaries are written by library scientists. Different from CNNDM, salient sentences distribute evenly in an article (Durrett et al., 2016). We filter out documents whose length of summaries are shorter than 50 tokens (Zheng and Lapata, 2019). MultiNews dataset consists of news articles and human-written summaries. The dataset is the first large-scale Multi-Documents Summarization (MDS) news dataset and comes from a diverse set of news sources (over 1500 sites) (Fabbri et al., 2019). arXiv&PubMed datasets are two long document datasets of scientific publications from arXiv.org (113k) and PubMed (215k) (Cohan et al., 2018). The task is to generate the abstract from the paper body. WikiSum dataset is a multi-documents summarization dataset from Wikipedia (Liu et al., 2018). We use the version provided by (Liu and Lapata, 2019a), which selects ranked top-40 paragraphs as input. For this dataset, we filter out documents whose summary length is less than 100 tokens. After the process, WikiSum test set contains 15,795 examples and the average length of summaries is 198. WikiHo"
2021.findings-acl.147,K18-1040,0,0.0455017,"Missing"
2021.findings-acl.147,D18-1443,0,0.0120095,"e gains come from alleviating the facet bias problem. 1 Figure 1: Examples from New York Times. We selected part of key sentences from the source document to show in this table. “...” refers to the omissions of context sentences due to space limitation. Introduction Document summarization is the task of transforming a long document into a shorter version while retaining its most important content (Nenkova and McKeown, 2011).Existing extractive or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale a"
2021.findings-acl.147,W19-8665,0,0.0138412,"s shown in Table 5, we can see that sentences extracted by PacSum all focus on the facet which describes terroristic attacks in Iraq. However, FAR can cover all 3 facets in gold reference. This shows that our FAR can effectively improve the performance by reducing the facet bias problem. 6 Related Work Summarization is a long-standing challenge for researchers to address. Thanks to the power of the neural network and availability of large-scale parallel datasets. Supervised summarization algorithms develop sharply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive summarization. However,"
2021.findings-acl.147,D19-5406,0,0.012944,"d Lapata, 2019a), which selects ranked top-40 paragraphs as input. For this dataset, we filter out documents whose summary length is less than 100 tokens. After the process, WikiSum test set contains 15,795 examples and the average length of summaries is 198. WikiHow dataset is a large-scale dataset of instructions from the online WikiHow.com website (Koupaee and Wang, 2018). The task is to generate the concatenated summary-sentences from the paragraphs. BillSum dataset contains US Congressional bills and human-written reference summaries from the 103rd-115th (1993-2018) sessions of Congress (Kornilova and Eidelman, 2019). These datasets differ in scale, domain and task type. We collect details of the 8 corpus in Table 1. 4.2 Implementation Details and Metrics FAR has 4 hyper-parameters and the best set of them are chosen from the following setting: α ∈ {1, 2}, β ∈ {0.0, 0.1, . . . , 0.9}, λ1 + λ2 = 1, λ1 ∈ {0.0, 0.1, . . . , 1.0}. In most case, FAR with the default setting (α = 1, β = 0.5, λ1 = 0.5, λ2 = 0.5) can achieve satisfied performance on all datasets. We select best hyper-parameters by sampling 1,000 1688 Datasets Sources Type CNN/DM NYT MultiNews arXiv PubMed WikiSum WikiHow BillSum News News News Sc"
2021.findings-acl.147,W16-3617,0,0.0128032,"vector of “[CLS]” is used as sentence representations and we set µ to 1 following (Reimers and Gurevych, 2019) in post-training phase. 4 4.1 Experiments Datasets We introduce the datasets used in our experiments in this section. CNN/DM dataset contains 93k articles from CNN, and 220k articles from Daily Mail newspapers (Hermann et al., 2015). We use the nonanonymous version. Following (Zheng and Lapata, 2019), documents whose length of summaries are shorter than 30 tokens are filtered out. NYT dataset contains articles published by the New York Times between January 1, 1987 and June 19, 2007 (Li et al., 2016). The summaries are written by library scientists. Different from CNNDM, salient sentences distribute evenly in an article (Durrett et al., 2016). We filter out documents whose length of summaries are shorter than 50 tokens (Zheng and Lapata, 2019). MultiNews dataset consists of news articles and human-written summaries. The dataset is the first large-scale Multi-Documents Summarization (MDS) news dataset and comes from a diverse set of news sources (over 1500 sites) (Fabbri et al., 2019). arXiv&PubMed datasets are two long document datasets of scientific publications from arXiv.org (113k) and"
2021.findings-acl.147,N03-1020,0,0.320371,"Missing"
2021.findings-acl.147,P19-1500,0,0.272245,"iating the facet bias problem. 1 Figure 1: Examples from New York Times. We selected part of key sentences from the source document to show in this table. “...” refers to the omissions of context sentences due to space limitation. Introduction Document summarization is the task of transforming a long document into a shorter version while retaining its most important content (Nenkova and McKeown, 2011).Existing extractive or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale annotated document-summ"
2021.findings-acl.147,D19-1387,0,0.213859,"iating the facet bias problem. 1 Figure 1: Examples from New York Times. We selected part of key sentences from the source document to show in this table. “...” refers to the omissions of context sentences due to space limitation. Introduction Document summarization is the task of transforming a long document into a shorter version while retaining its most important content (Nenkova and McKeown, 2011).Existing extractive or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale annotated document-summ"
2021.findings-acl.147,W04-3252,0,0.671202,"ing its most important content (Nenkova and McKeown, 2011).Existing extractive or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale annotated document-summary pairs; 2). are more general for various scenarios. Graph-based models are commonly used in unsupervised extractive methods (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004). For example, Zheng and Lapata (2019) proposed a directed centrality-based method named PacSum 1685 Findings of the Association for Computational Linguis"
2021.findings-acl.147,N18-1158,0,0.0118299,"Lead selects the first k tokens as a summary. We also report previous best centrality-based model PacSum (Zheng and Lapata, 2019) in the third block of each table. Overall, FAR outperforms above-mentioned unsupervised strong baselines on most datasets, especially on long-document and multi-documents datasets and is more generalized than them for differnt types, domains datasets. Results on SDS Table 2 reports the results on single document summarization (SDS) datasets CNN/DM, NYT and WikiHow. PTR-GEN (See et al., 2017) is a supervised abstractive model with classic seq2seq structure. REFRESH (Narayan et al., 2018) and BertExt (Liu and Lapata, 2019b) are supervised extractive models. STAS (Xu et al., 2020) is the best unsupervised model on CNN/DM 1689 Method Oracle PTR-GEN Discourse-aware SummaRuNNer GlobalLocalCont Lead TextRank LexRank MMR PacSum FAR R-1 53.88 32.06 35.80 42.81 43.62 33.66 24.38 33.85 29.75 39.33 40.92 arXiv R-2 23.05 9.04 11.05 16.52 17.36 8.94 10.57 10.73 6.14 12.19 13.75 R-L 34.9 25.16 31.8 28.23 29.14 22.19 22.18 28.99 26.41 34.18 35.56 R-1 55.05 35.86 38.93 43.89 44.85 35.63 38.66 39.19 37.65 39.79 41.98 PubMed R-2 27.48 10.22 15.37 18.78 19.70 12.28 15.87 13.89 10.61 14.00 15.66"
2021.findings-acl.147,P11-5003,0,0.0366053,"method consistently outperforms strong baselines especially in longand multi-document scenarios and even performs comparably to some supervised models. Extensive analyses confirm that the performance gains come from alleviating the facet bias problem. 1 Figure 1: Examples from New York Times. We selected part of key sentences from the source document to show in this table. “...” refers to the omissions of context sentences due to space limitation. Introduction Document summarization is the task of transforming a long document into a shorter version while retaining its most important content (Nenkova and McKeown, 2011).Existing extractive or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter"
2021.findings-acl.147,W00-0403,0,0.418697,"version while retaining its most important content (Nenkova and McKeown, 2011).Existing extractive or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale annotated document-summary pairs; 2). are more general for various scenarios. Graph-based models are commonly used in unsupervised extractive methods (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004). For example, Zheng and Lapata (2019) proposed a directed centrality-based method named PacSum 1685 Findings of the Association"
2021.findings-acl.147,D19-1410,0,0.019753,"g model. The previous study shows that improving the quality of sentence representations helps improve the ranking performance (Zheng and Lapata, 2019; Dong et al., 2020). We post-train BERT on a sentence-level task constructed based on the corpus of a specific task. The idea is that its representation is affected not only by the words in it, but also the sentences around it. For a sentence in a document, we take its previous sentence and its following sentence to be positive examples and random sample sentences from documents as negative examples. The objective function follows that used in (Reimers and Gurevych, 2019). Specifically, for sentence si , a positive sentence sj , and a negative sentence sk , the BERT is trained to minimize the following equation: max(k vi − vj k − k vi − vk k +µ, 0) (7) where v is the sentence representation, and µ is margin which ensures that vj is at least µ closer to si than sk . The hidden state vector of “[CLS]” is used as sentence representations and we set µ to 1 following (Reimers and Gurevych, 2019) in post-training phase. 4 4.1 Experiments Datasets We introduce the datasets used in our experiments in this section. CNN/DM dataset contains 93k articles from CNN, and 220"
2021.findings-acl.147,P15-2138,0,0.144104,"wn, 2011).Existing extractive or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale annotated document-summary pairs; 2). are more general for various scenarios. Graph-based models are commonly used in unsupervised extractive methods (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004). For example, Zheng and Lapata (2019) proposed a directed centrality-based method named PacSum 1685 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 1685–1697 August 1–6,"
2021.findings-acl.147,P17-1099,0,0.0363626,"kan and Radev, 2004), MMR (Carbonell and Goldstein, 1998) in the second block of each table. Lead selects the first k tokens as a summary. We also report previous best centrality-based model PacSum (Zheng and Lapata, 2019) in the third block of each table. Overall, FAR outperforms above-mentioned unsupervised strong baselines on most datasets, especially on long-document and multi-documents datasets and is more generalized than them for differnt types, domains datasets. Results on SDS Table 2 reports the results on single document summarization (SDS) datasets CNN/DM, NYT and WikiHow. PTR-GEN (See et al., 2017) is a supervised abstractive model with classic seq2seq structure. REFRESH (Narayan et al., 2018) and BertExt (Liu and Lapata, 2019b) are supervised extractive models. STAS (Xu et al., 2020) is the best unsupervised model on CNN/DM 1689 Method Oracle PTR-GEN Discourse-aware SummaRuNNer GlobalLocalCont Lead TextRank LexRank MMR PacSum FAR R-1 53.88 32.06 35.80 42.81 43.62 33.66 24.38 33.85 29.75 39.33 40.92 arXiv R-2 23.05 9.04 11.05 16.52 17.36 8.94 10.57 10.73 6.14 12.19 13.75 R-L 34.9 25.16 31.8 28.23 29.14 22.19 22.18 28.99 26.41 34.18 35.56 R-1 55.05 35.86 38.93 43.89 44.85 35.63 38.66 39."
2021.findings-acl.147,W17-4507,0,0.0145455,"e or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale annotated document-summary pairs; 2). are more general for various scenarios. Graph-based models are commonly used in unsupervised extractive methods (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004). For example, Zheng and Lapata (2019) proposed a directed centrality-based method named PacSum 1685 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 1685–1697 August 1–6, 2021. ©2021 Associati"
2021.findings-acl.147,D08-1079,0,0.0509865,"lable. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive summarization. However, most unsupervised summarization models are extractive (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Carbonell and Goldstein, 1998; Wan, 2008; Wan and Yang, 2008; Schluter and Søgaard, 2015; Zhao et al., 2020) and focused on the measure of sentence salient. Graph-based models are effective and widely concerned in unsupervised extractive methods. Different from traditional undirected graph rank models (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004), (Zheng and Lapata, 2019) proposed directed centrality method, which is based on the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) assumption. (Dong et al., 2020) point out that PACSUM has position bias, which makes PACSUM not suitable for long document"
2021.findings-acl.147,2020.acl-main.553,0,0.0224673,"amples from New York Times. We selected part of key sentences from the source document to show in this table. “...” refers to the omissions of context sentences due to space limitation. Introduction Document summarization is the task of transforming a long document into a shorter version while retaining its most important content (Nenkova and McKeown, 2011).Existing extractive or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale annotated document-summary pairs; 2). are more general for various"
2021.findings-acl.147,D18-1451,0,0.0187379,"etwork and availability of large-scale parallel datasets. Supervised summarization algorithms develop sharply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive summarization. However, most unsupervised summarization models are extractive (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Carbonell and Goldstein, 1998; Wan, 2008; Wan and Yang, 2008; Schluter and Søgaard, 2015; Zhao et al., 2020) and focused on the measure of sentence salient. Graph-based models are effective and widely concerned in unsupervised extractive methods. Different from traditional undirect"
2021.findings-acl.147,D19-1389,0,0.012644,"harply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive summarization. However, most unsupervised summarization models are extractive (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Carbonell and Goldstein, 1998; Wan, 2008; Wan and Yang, 2008; Schluter and Søgaard, 2015; Zhao et al., 2020) and focused on the measure of sentence salient. Graph-based models are effective and widely concerned in unsupervised extractive methods. Different from traditional undirected graph rank models (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004), (Zheng and"
2021.findings-acl.147,D19-1298,0,0.0169793,"ts. 2) Especially on NYT, our model outperforms the previous best unsupervised extractive system STAS and supervised method REFERSH. After we re-implement the trigram blocking trick (i.e., removing sentences with repeating trigrams to existing summary sentences) which STAS used (Xu et al., 2020), FAR can achieve a better ROUGE-1 score 40.93/17.80/37.00 than STAS on CNN/DM. Results on LDS Table 3 reports the results on long document summarization (LDS) datasets arXiv, PubMed and BillSum. For supervised extractive models, we compare with SummaRuNNer (Nallapati et al., 2017) and GlobalLocalCont (Xiao and Carenini, 2019). We also compare with supervised abstractive models Discourse-aware (Cohan et al., 2018) and PRT-GEN. As shown in Table 3, our model has obviously higher ROUGE-1/2/L score (+1.89 +1.56 +1.38) on arXiv and (+2.22 +1.55 +1.45) on PubMed than PacSum. Compare with supervised models, our unsupervised model outperforms supervised abstractive models PTR-GEN and Discourse-aware, but still have a gap with supervised extractive models. The reason for this gap is that supervised extractive models can extract sentences with dynamic length through training with labeled corpus, but unsupervised models need"
2021.findings-acl.147,2020.findings-emnlp.161,0,0.27012,"ised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale annotated document-summary pairs; 2). are more general for various scenarios. Graph-based models are commonly used in unsupervised extractive methods (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004). For example, Zheng and Lapata (2019) proposed a directed centrality-based method named PacSum 1685 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 1685–1697 August 1–6, 2021. ©2021 Association for Computational Linguistics Figure 2"
2021.findings-acl.147,2020.findings-emnlp.168,0,0.0211582,"., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive summarization. However, most unsupervised summarization models are extractive (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Carbonell and Goldstein, 1998; Wan, 2008; Wan and Yang, 2008; Schluter and Søgaard, 2015; Zhao et al., 2020) and focused on the measure of sentence salient. Graph-based models are effective and widely concerned in unsupervised extractive methods. Different from traditional undirected graph rank models (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004), (Zheng and Lapata, 2019) proposed directed centra"
2021.findings-acl.147,D18-1088,0,0.0177477,"alyze the effectiveness of our model.) As shown in Table 5, we can see that sentences extracted by PacSum all focus on the facet which describes terroristic attacks in Iraq. However, FAR can cover all 3 facets in gold reference. This shows that our FAR can effectively improve the performance by reducing the facet bias problem. 6 Related Work Summarization is a long-standing challenge for researchers to address. Thanks to the power of the neural network and availability of large-scale parallel datasets. Supervised summarization algorithms develop sharply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsup"
2021.findings-acl.147,P19-1499,0,0.0143095,"blem. 1 Figure 1: Examples from New York Times. We selected part of key sentences from the source document to show in this table. “...” refers to the omissions of context sentences due to space limitation. Introduction Document summarization is the task of transforming a long document into a shorter version while retaining its most important content (Nenkova and McKeown, 2011).Existing extractive or abstractive methods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale annotated document-summary pairs; 2). are more"
2021.findings-acl.147,P19-1628,0,0.280163,"ods are mostly in supervised fashion which rely on large amounts of labeled corpora (Cheng and Lapata, 2016; Nallapati et al., 2017; Gehrmann et al., 2018; Liu and Lapata, 2019a,b; Zhang et al., 2019; Wang et al., 2020). However, this is not available for different summarization styles, domains, and languages. Fortunately, recent work has shown successful practices on unsupervised * Contribution † during internship at Tencent Inc. Corresponding Author extractive summarization (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Schluter and Søgaard, 2015; Tixier et al., 2017; Zheng and Lapata, 2019; Xu et al., 2020; Dong et al., 2020). Compare with supervised ones, unsupervised methods 1). remove the dependency on large-scale annotated document-summary pairs; 2). are more general for various scenarios. Graph-based models are commonly used in unsupervised extractive methods (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004). For example, Zheng and Lapata (2019) proposed a directed centrality-based method named PacSum 1685 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 1685–1697 August 1–6, 2021. ©2021 Association for Computational Lin"
2021.findings-acl.147,2020.acl-main.552,0,0.0105022,"scribes terroristic attacks in Iraq. However, FAR can cover all 3 facets in gold reference. This shows that our FAR can effectively improve the performance by reducing the facet bias problem. 6 Related Work Summarization is a long-standing challenge for researchers to address. Thanks to the power of the neural network and availability of large-scale parallel datasets. Supervised summarization algorithms develop sharply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive summarization. However, most unsupervised summarization models are extractive (Radev et al., 2000; Mihalcea and Tarau,"
2021.findings-acl.147,P19-1100,0,0.0166466,"ess of our model.) As shown in Table 5, we can see that sentences extracted by PacSum all focus on the facet which describes terroristic attacks in Iraq. However, FAR can cover all 3 facets in gold reference. This shows that our FAR can effectively improve the performance by reducing the facet bias problem. 6 Related Work Summarization is a long-standing challenge for researchers to address. Thanks to the power of the neural network and availability of large-scale parallel datasets. Supervised summarization algorithms develop sharply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive"
2021.findings-acl.147,P19-1503,0,0.0188958,"algorithms develop sharply (Chopra et al., 2016; Cao et al., 2018; Zhang et al., 2018; Zhong et al., 2019; Gehrmann et al., 2019; Cho et al., 2019; Jin et al., 2020b; Cao et al., 2020; Jin et al., 2020a; Zhong et al., 2020). However, high-quality parallel datasets are not always available. Researches on unsupervised summarization are necessary, which can be diveided into extractive and abstractive. Unsupervised abstractive summarization is more challenging than extractive. There are also many interesting works (Wang and Lee, 2018; F´evry and Phang, 2018; Baziotis et al., 2019; Jernite, 2019; Zhou and Rush, 2019; West et al., 2019; Chu and Liu, 2019; Yang et al., 2020) on unsupervised abstractive summarization. However, most unsupervised summarization models are extractive (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev, 2004; Carbonell and Goldstein, 1998; Wan, 2008; Wan and Yang, 2008; Schluter and Søgaard, 2015; Zhao et al., 2020) and focused on the measure of sentence salient. Graph-based models are effective and widely concerned in unsupervised extractive methods. Different from traditional undirected graph rank models (Radev et al., 2000; Mihalcea and Tarau, 2004; Erkan and Radev"
2021.findings-acl.402,N19-1423,0,0.00491742,"if si = a1 [B][S2 ][E] if si = a2 , (1) sˆi =  si otherwise tˆi = xi1 ..., [B], ak , [E], ..., xin , k ∈ {1, 2}, if ti contains ak . Among them, [S1 ], [S2 ], [B], [E] are newly-defined tokens. [B] and [E] are used to mark the start and the end position of the argument. We further replace the argument ak 4581 with the pre-defined token [Sk ], as aˆk = [Sk ] if ˆ aˆ1 and aˆ2 ∃i(si = ak ). Then, we concatenate d, as a sequence, and use special tokens [CLS] and [SEP] as sperators, formulated as ˆ [CLS]d[SEP] aˆ1 [SEP]aˆ2 [SEP]. (2) We feed the sequence into the pre-trained language model BERT (Devlin et al., 2019) and obtain the hidden semantic representation of each input tokens. Among them, h[CLS] ∈ Rdh is the hidden output of [CLS], where dh is the hidden size of BERT. We use h[CLS] to represent the global relational feature between a1 and a2 . To better represent the semantic information of arguments, we distill all the hidden states of ak ’s start marker in the sequence (Eq. 2), including those in the dialogue text, and formulate them as ha1k , ha2k , ..., haj k ∈ Rdh . Then, we apply a max pooling process to obtain a combined representation of ak : hak = max-pool(ha1k , ha2k , ..., haj k ). (3) N"
2021.findings-acl.402,P19-1136,0,0.0462821,"Missing"
2021.findings-acl.402,2020.acl-main.670,0,0.0210972,"Missing"
2021.findings-acl.402,N19-1308,0,0.0150909,"esk by nine o&apos;clock. S1: Sure. S2: No problem. (S1, per:boss, S3) (S2, per:boss, S3) Trigger Words: Relation: Figure 1: Examples from the DialogRE dataset. sn denotes the speaker of each utterance. The underlined text indicates the relation between the argument pairs. Introduction The task of relation extraction is to identify the relation facts between two arguments from plain text, which is the fundamental step of many natural language processing applications. Recent years have seen increasing efforts on sentence-level RE, e.g., relations only hold within a single sentence (Fu et al., 2019; Luan et al., 2019; Zhao et al., 2020; Wang and Lu, 2020; Wei et al., 2020). To adapt to complex scenarios, some current works have moved forward to the document-level RE, e.g., relations can exist across multiple sentences (Yao et al., 2019; Wang et al., 2020; Nan et al., 2020; Jain et al., 2020; Zhou et al., 2021). ∗ Work done during an internship at Tencent Cloud Xiaowei. † Corresponding Author. A more challenging yet practical extension is the dialogue-based relation extraction. The dialogues contain multi-turn conversations among a group of speakers. The relations not only exist between the entities in the"
2021.findings-acl.402,2020.acl-main.141,0,0.0127937,"pairs. Introduction The task of relation extraction is to identify the relation facts between two arguments from plain text, which is the fundamental step of many natural language processing applications. Recent years have seen increasing efforts on sentence-level RE, e.g., relations only hold within a single sentence (Fu et al., 2019; Luan et al., 2019; Zhao et al., 2020; Wang and Lu, 2020; Wei et al., 2020). To adapt to complex scenarios, some current works have moved forward to the document-level RE, e.g., relations can exist across multiple sentences (Yao et al., 2019; Wang et al., 2020; Nan et al., 2020; Jain et al., 2020; Zhou et al., 2021). ∗ Work done during an internship at Tencent Cloud Xiaowei. † Corresponding Author. A more challenging yet practical extension is the dialogue-based relation extraction. The dialogues contain multi-turn conversations among a group of speakers. The relations not only exist between the entities in the dialogue text but also the speakers of each utterance. Additionally, most of relations appear in multi-turn conversation, which require cross-sentence extraction. Considering the complexities, we divide the dialogue-based RE into three categories. In the firs"
2021.findings-acl.402,2020.emnlp-main.303,0,0.0122155,"etween the argument pairs. Introduction The task of relation extraction is to identify the relation facts between two arguments from plain text, which is the fundamental step of many natural language processing applications. Recent years have seen increasing efforts on sentence-level RE, e.g., relations only hold within a single sentence (Fu et al., 2019; Luan et al., 2019; Zhao et al., 2020; Wang and Lu, 2020; Wei et al., 2020). To adapt to complex scenarios, some current works have moved forward to the document-level RE, e.g., relations can exist across multiple sentences (Yao et al., 2019; Wang et al., 2020; Nan et al., 2020; Jain et al., 2020; Zhou et al., 2021). ∗ Work done during an internship at Tencent Cloud Xiaowei. † Corresponding Author. A more challenging yet practical extension is the dialogue-based relation extraction. The dialogues contain multi-turn conversations among a group of speakers. The relations not only exist between the entities in the dialogue text but also the speakers of each utterance. Additionally, most of relations appear in multi-turn conversation, which require cross-sentence extraction. Considering the complexities, we divide the dialogue-based RE into three categ"
2021.findings-acl.402,2020.emnlp-main.133,0,0.0192403,"problem. (S1, per:boss, S3) (S2, per:boss, S3) Trigger Words: Relation: Figure 1: Examples from the DialogRE dataset. sn denotes the speaker of each utterance. The underlined text indicates the relation between the argument pairs. Introduction The task of relation extraction is to identify the relation facts between two arguments from plain text, which is the fundamental step of many natural language processing applications. Recent years have seen increasing efforts on sentence-level RE, e.g., relations only hold within a single sentence (Fu et al., 2019; Luan et al., 2019; Zhao et al., 2020; Wang and Lu, 2020; Wei et al., 2020). To adapt to complex scenarios, some current works have moved forward to the document-level RE, e.g., relations can exist across multiple sentences (Yao et al., 2019; Wang et al., 2020; Nan et al., 2020; Jain et al., 2020; Zhou et al., 2021). ∗ Work done during an internship at Tencent Cloud Xiaowei. † Corresponding Author. A more challenging yet practical extension is the dialogue-based relation extraction. The dialogues contain multi-turn conversations among a group of speakers. The relations not only exist between the entities in the dialogue text but also the speakers o"
2021.findings-acl.402,2020.acl-main.136,0,0.0146199,"oss, S3) (S2, per:boss, S3) Trigger Words: Relation: Figure 1: Examples from the DialogRE dataset. sn denotes the speaker of each utterance. The underlined text indicates the relation between the argument pairs. Introduction The task of relation extraction is to identify the relation facts between two arguments from plain text, which is the fundamental step of many natural language processing applications. Recent years have seen increasing efforts on sentence-level RE, e.g., relations only hold within a single sentence (Fu et al., 2019; Luan et al., 2019; Zhao et al., 2020; Wang and Lu, 2020; Wei et al., 2020). To adapt to complex scenarios, some current works have moved forward to the document-level RE, e.g., relations can exist across multiple sentences (Yao et al., 2019; Wang et al., 2020; Nan et al., 2020; Jain et al., 2020; Zhou et al., 2021). ∗ Work done during an internship at Tencent Cloud Xiaowei. † Corresponding Author. A more challenging yet practical extension is the dialogue-based relation extraction. The dialogues contain multi-turn conversations among a group of speakers. The relations not only exist between the entities in the dialogue text but also the speakers of each utterance. A"
2021.findings-acl.402,P19-1074,0,0.0122114,"tes the relation between the argument pairs. Introduction The task of relation extraction is to identify the relation facts between two arguments from plain text, which is the fundamental step of many natural language processing applications. Recent years have seen increasing efforts on sentence-level RE, e.g., relations only hold within a single sentence (Fu et al., 2019; Luan et al., 2019; Zhao et al., 2020; Wang and Lu, 2020; Wei et al., 2020). To adapt to complex scenarios, some current works have moved forward to the document-level RE, e.g., relations can exist across multiple sentences (Yao et al., 2019; Wang et al., 2020; Nan et al., 2020; Jain et al., 2020; Zhou et al., 2021). ∗ Work done during an internship at Tencent Cloud Xiaowei. † Corresponding Author. A more challenging yet practical extension is the dialogue-based relation extraction. The dialogues contain multi-turn conversations among a group of speakers. The relations not only exist between the entities in the dialogue text but also the speakers of each utterance. Additionally, most of relations appear in multi-turn conversation, which require cross-sentence extraction. Considering the complexities, we divide the dialogue-based"
2021.findings-acl.402,2020.acl-main.444,0,0.0772764,"akers. We randomly mask the speaker tokens and use the context to predict who said the utterance. The trigger words prediction task is to detect the supportive context of the current relation. We solve it with a sequence labeling method. Moreover, we design an integration module for the relation extraction task to combine both the global dialogue representation and the local arguments representation. Finally, the three tasks are jointly trained based on a multi-task learning framework. Output: [Per: Parents] [CLS] Existing studies propose to solve this task through a speaker-aware BERT model (Yu et al., 2020) as well as a gaussian graph-based method (Xue et al., 2021). The former modifies the speaker arguments in dialogue text with special tokens to highlight the speaker-related information. The latter builds a latent multi-view graph to encode the long-distance dependency between arguments. However, these works regard dialogue as a plain text without considering the supporting information of relations and the characteristics of speakers. As been emphasized before (Xue et al., 2021), trigger words and speaker-related features play a critical role in dialogue-based relation extraction. In this case"
2021.findings-emnlp.107,2020.acl-main.708,0,0.220784,"nder both automatic and human evaluation metrics, particularly in terms of faithfulness to the structured data. These results suggest that TWT could be a useful controllable data-to-text benchmark, and may help innovate models to provide intelligent assistance for writing with structured data. generated text to describe all the records from the data. WikiBio (Lebret et al., 2016) requires the target text to cover salient records with no explicit guidance on the generated topic. ToTTo (Parikh et al., 2020) guide the topic of the generated target with a set of highlighted table cells. LogicNLG (Chen et al., 2020a) and Logic2Text (Chen et al., 2020b) address logical inference/generation in data-to-text. ROTOWIRE (Wiseman et al., 2017) and ToTTo (Parikh et al., 2020) also contain data that requires reasoning. Many existing works tend to train neural models in an end-to-end fashion (Liu et al., 2018; Wiseman et al., 2017, 2018; Chen et al., 2020c). Recently, large pre-trained models (Rothe et al., 2020; Raffel et al., 2020; Lewis et al., 2020) have also achieved new state-of-the-art results on data-to-text tasks. Reiter and Dale (1997) suggest that an NLG system consists of content planning and surface"
2021.findings-emnlp.107,2020.findings-emnlp.190,0,0.21102,"nder both automatic and human evaluation metrics, particularly in terms of faithfulness to the structured data. These results suggest that TWT could be a useful controllable data-to-text benchmark, and may help innovate models to provide intelligent assistance for writing with structured data. generated text to describe all the records from the data. WikiBio (Lebret et al., 2016) requires the target text to cover salient records with no explicit guidance on the generated topic. ToTTo (Parikh et al., 2020) guide the topic of the generated target with a set of highlighted table cells. LogicNLG (Chen et al., 2020a) and Logic2Text (Chen et al., 2020b) address logical inference/generation in data-to-text. ROTOWIRE (Wiseman et al., 2017) and ToTTo (Parikh et al., 2020) also contain data that requires reasoning. Many existing works tend to train neural models in an end-to-end fashion (Liu et al., 2018; Wiseman et al., 2017, 2018; Chen et al., 2020c). Recently, large pre-trained models (Rothe et al., 2020; Raffel et al., 2020; Lewis et al., 2020) have also achieved new state-of-the-art results on data-to-text tasks. Reiter and Dale (1997) suggest that an NLG system consists of content planning and surface"
2021.findings-emnlp.107,2020.acl-main.18,0,0.445783,"nder both automatic and human evaluation metrics, particularly in terms of faithfulness to the structured data. These results suggest that TWT could be a useful controllable data-to-text benchmark, and may help innovate models to provide intelligent assistance for writing with structured data. generated text to describe all the records from the data. WikiBio (Lebret et al., 2016) requires the target text to cover salient records with no explicit guidance on the generated topic. ToTTo (Parikh et al., 2020) guide the topic of the generated target with a set of highlighted table cells. LogicNLG (Chen et al., 2020a) and Logic2Text (Chen et al., 2020b) address logical inference/generation in data-to-text. ROTOWIRE (Wiseman et al., 2017) and ToTTo (Parikh et al., 2020) also contain data that requires reasoning. Many existing works tend to train neural models in an end-to-end fashion (Liu et al., 2018; Wiseman et al., 2017, 2018; Chen et al., 2020c). Recently, large pre-trained models (Rothe et al., 2020; Raffel et al., 2020; Lewis et al., 2020) have also achieved new state-of-the-art results on data-to-text tasks. Reiter and Dale (1997) suggest that an NLG system consists of content planning and surface"
2021.findings-emnlp.107,N19-1423,0,0.0172017,"77 1.36 1.25 1.87 1.32 Table 3: Human evaluation scores. Our model uses the causal with prefix mask for the decoder self-attention. where Lc is the original loss between the model’s output and the golden target, wj is the target token at position j. λ is a hyper-parameter representing the weight for the copy. 6 Experiments 1 Following Parikh et al. (2020) on selecting the baselines on ToTTo, we exam the following state-ofthe-art text generation approaches on TWT. • BERT2BERT (Rothe et al., 2020): A Transformer encoder-decoder model where the encoder and decoder are both initialized with BERT (Devlin et al., 2019). • T5 (Raffel et al., 2020): A pre-trained textto-text using the transformer framework. T5 achieved state-of-the-art results on many text generation benchmarks, including ToTTo. Note that for baseline models, the input is the metadata concatenated with the table flattened row by row, with no additional table-aware embeddings introduced in Section 5.1. 6.1 Setup We build the prefix-target pairs for training and validation by randomly selecting two prefixes of each table-sentence pair from the TWT train/validation set. The number of prefix-target pairs built for training/validation is 226, 126/"
2021.findings-emnlp.107,P19-1483,0,0.0179512,"irs is Additionally, we introduce faithfulness metrics to to break the sentence into two parts randomly, the measure the faithfulness of the generated text. Note first part will be the written prefix, and the second that models trained on TWT might provide intelpart is the target text to generate. However, the dif- ligent writing assistance, we also design several ficulty of generating correct target text on different metrics specifically targeting this scenario. 1246 4.1 Faithfulness Metrics We propose two evaluation metrics to measure the faithfulness: fact coverage and the modified PARENT (Dhingra et al., 2019). Fact Coverage is similar to the entity-centric metric (Liu et al., 2021), and the overall slot filling metric (Wang et al., 2018). Let Fg be the set of aligned facts of the golden target and the table data, and Fp be that for the generated target. Fact coverage is calculated as |Fp ∩ Fg |/|Fg |. Note that fact coverage of open-ended generated targets will be quite low. We use the same alignment method described in Section 3.2 to acquire Fg and Fp . PARENT (Dhingra et al., 2019) is a metric specifically designed for data-to-text evaluation that takes the input table into account. It computes"
2021.findings-emnlp.107,E17-1059,0,0.0257536,"valuatext that is not faithful on TWT. Therefore, tion. we design a novel approach with table-aware In NLG, one way to provide signals on what to attention visibility and copy mechanism over generate is to add constraints to the model output, the table. Experimental results show that our which falls in the task of controlled text generaapproach outperforms state-of-the-art methods under both automatic and human evaluation tion (CTG). Most CTG tasks are conditioned on metrics. several key-value pairs of control factors such as tone, tense, length, and sentiment (Hu et al., 2017; 1 Introduction Dong et al., 2017; Ficler and Goldberg, 2017). In data-to-text, Parikh et al. (2020) propose the dataset Data-to-text refers to the task of generating a target ToTTo to address content planning by highlighting textual description conditioned on the structured some cells in the table, the highlighted cells prosource data such as tables, graphs, and meaning vide strong guidance on what to generate. However, representations. Reiter and Dale (1997) suggest ToTTo lacks practical use, it would be difficult to that a natural language generation (NLG) system have tables with highlighted cells or ask the users consists"
2021.findings-emnlp.107,D18-2003,0,0.0187713,"the topics of generated text with highlighted cells. Gong et al. (2020) brings the sense of numerical value comparison into content planning. Li and Wan (2018) propose to generate templates and then fill the slots, while (Iso et al., 2019) incorporate writers’ information to generate text step-by-step. Gong et al. (2019) utilize hierarchical encoders with dual attention to consider both the table structure and history information. In NLG, controlled text generation is also a hot research topic. It considers controlling attributes, such as identity of the speaker (Li et al., 2016), sentiment (Dou et al., 2018), tense (Hu et al., 2017), politeness (Sennrich et al., 2016) and text length (Kikuchi et al., 2016). Our work could be considered as a middle-ground between data-to-text and controlled text generation and has more practical usage. 3 3.1 2 Related Work Task Definition and Dataset Construction Task Definition The task input is a tuple of table T, metadata M, Data-to-Text aims to generate natural language and a written prefix X. The metadata M may infrom structured data, which has been widely stud- clude the table caption, the title of the section that ied recently. Most prior works focus on sur"
2021.findings-emnlp.107,W17-4912,0,0.018795,"ot faithful on TWT. Therefore, tion. we design a novel approach with table-aware In NLG, one way to provide signals on what to attention visibility and copy mechanism over generate is to add constraints to the model output, the table. Experimental results show that our which falls in the task of controlled text generaapproach outperforms state-of-the-art methods under both automatic and human evaluation tion (CTG). Most CTG tasks are conditioned on metrics. several key-value pairs of control factors such as tone, tense, length, and sentiment (Hu et al., 2017; 1 Introduction Dong et al., 2017; Ficler and Goldberg, 2017). In data-to-text, Parikh et al. (2020) propose the dataset Data-to-text refers to the task of generating a target ToTTo to address content planning by highlighting textual description conditioned on the structured some cells in the table, the highlighted cells prosource data such as tables, graphs, and meaning vide strong guidance on what to generate. However, representations. Reiter and Dale (1997) suggest ToTTo lacks practical use, it would be difficult to that a natural language generation (NLG) system have tables with highlighted cells or ask the users consists of content planning (what t"
2021.findings-emnlp.107,W17-3518,0,0.0262306,"metadata M may infrom structured data, which has been widely stud- clude the table caption, the title of the section that ied recently. Most prior works focus on surface- contains the table, or other context around the talevel text generation in a specific domain or ble. The output target is denoted by Y , such that schema, such as ROBOCUP (Chen and Mooney, concatenating the prefix X and the output target 2008), WEATHERGOV (Liang et al., 2009), Y results in a fluent sentence that is faithful to the E2ENLG (Novikova et al., 2017), and WebNLG table T. The goal is to learn a data-to-text model (Gardent et al., 2017). These datasets expect the conditioned on the written prefix, P (Y |T, M, X). 1245 Property Number of prefix-target pairs Average prefix length (tokens) Average target length (tokens) Rows per table (average/median) Columns per table (average/median) Figure 2: ToTTo dataset example (Parikh et al., 2020). Figure 3: TabFact dataset example (Chen et al., 2019). 3.2 Dataset Construction ToTTo 27,042 10.9 15.8 32.8/16.0 6.8/6.0 TabFact 13,955 9.3 14.2 10.9/10.0 6.1/6.0 Table 1: TWT evaluation benchmark statistics. breakpoints is not equal. Therefore, we build TWT evaluation benchmark with selected"
2021.findings-emnlp.107,2020.findings-emnlp.262,0,0.0321246,"t al., 2017) and ToTTo (Parikh et al., 2020) also contain data that requires reasoning. Many existing works tend to train neural models in an end-to-end fashion (Liu et al., 2018; Wiseman et al., 2017, 2018; Chen et al., 2020c). Recently, large pre-trained models (Rothe et al., 2020; Raffel et al., 2020; Lewis et al., 2020) have also achieved new state-of-the-art results on data-to-text tasks. Reiter and Dale (1997) suggest that an NLG system consists of content planning and surface realization. Parikh et al. (2020) propose ToTTo to control the topics of generated text with highlighted cells. Gong et al. (2020) brings the sense of numerical value comparison into content planning. Li and Wan (2018) propose to generate templates and then fill the slots, while (Iso et al., 2019) incorporate writers’ information to generate text step-by-step. Gong et al. (2019) utilize hierarchical encoders with dual attention to consider both the table structure and history information. In NLG, controlled text generation is also a hot research topic. It considers controlling attributes, such as identity of the speaker (Li et al., 2016), sentiment (Dou et al., 2018), tense (Hu et al., 2017), politeness (Sennrich et al.,"
2021.findings-emnlp.107,D19-1310,0,0.0169004,"ained models (Rothe et al., 2020; Raffel et al., 2020; Lewis et al., 2020) have also achieved new state-of-the-art results on data-to-text tasks. Reiter and Dale (1997) suggest that an NLG system consists of content planning and surface realization. Parikh et al. (2020) propose ToTTo to control the topics of generated text with highlighted cells. Gong et al. (2020) brings the sense of numerical value comparison into content planning. Li and Wan (2018) propose to generate templates and then fill the slots, while (Iso et al., 2019) incorporate writers’ information to generate text step-by-step. Gong et al. (2019) utilize hierarchical encoders with dual attention to consider both the table structure and history information. In NLG, controlled text generation is also a hot research topic. It considers controlling attributes, such as identity of the speaker (Li et al., 2016), sentiment (Dou et al., 2018), tense (Hu et al., 2017), politeness (Sennrich et al., 2016) and text length (Kikuchi et al., 2016). Our work could be considered as a middle-ground between data-to-text and controlled text generation and has more practical usage. 3 3.1 2 Related Work Task Definition and Dataset Construction Task Definit"
2021.findings-emnlp.107,P16-1154,0,0.449303,"both factual and logical statements that are faithful to the structured data. Compared with other datasets, TWT is of practical use. The prefix controls the topic of the generated text, and the output model could assist in writing with structured data. Note that TWT differs from those datasets that provide only one golden sentence with no content planning signals. To generate text faithful to the data, we design a novel approach that leverages large pre-trained models (Rothe et al., 2020) with table-aware attention visibility (based on the written text) and copy mechanism (Oriol et al., 2015; Gu et al., 2016) over the table. Experimental results show that our approach outperforms state-of-the-art methods under both automatic and human evaluation metrics, particularly in terms of faithfulness to the structured data. These results suggest that TWT could be a useful controllable data-to-text benchmark, and may help innovate models to provide intelligent assistance for writing with structured data. generated text to describe all the records from the data. WikiBio (Lebret et al., 2016) requires the target text to cover salient records with no explicit guidance on the generated topic. ToTTo (Parikh et a"
2021.findings-emnlp.107,2020.acl-main.398,0,0.0243775,"data to assure the faithfulness of the generated target. Note that our model is based on the transformer encoder-decoder architecture (Rothe et al., 2020), both the encoder and the decoder are initialized with pre-trained parameters. 5.1 Table-aware Additional Embeddings A common way to encode structured data with transformer is to create a linearized sequence of the data and treat the linearized sequence as text. For table linearization, similar to Yin et al. (2020), we use the template hc |hr |v to represent each table cell, where hc and hr are column and row names of the cell v. Following Herzig et al. (2020) to represent the table structure, we add row embedding r and column embedding c. We also use a type embedding t to represent the input type, where the type could be the table cell or different metadata types. Given the input data, we first linearize the table row by row into a sequence of words and concatenate words of the metadata before the table words. The words are further tokenized with the WordPiece (Johnson et al., 2017) or SentencePiece (Kudo and Richardson, 2018) tokenizer. Let p be the positional embedding, w be the word embedding, and e denote the input representation, we have e ="
2021.findings-emnlp.107,D16-1140,0,0.0211846,"erical value comparison into content planning. Li and Wan (2018) propose to generate templates and then fill the slots, while (Iso et al., 2019) incorporate writers’ information to generate text step-by-step. Gong et al. (2019) utilize hierarchical encoders with dual attention to consider both the table structure and history information. In NLG, controlled text generation is also a hot research topic. It considers controlling attributes, such as identity of the speaker (Li et al., 2016), sentiment (Dou et al., 2018), tense (Hu et al., 2017), politeness (Sennrich et al., 2016) and text length (Kikuchi et al., 2016). Our work could be considered as a middle-ground between data-to-text and controlled text generation and has more practical usage. 3 3.1 2 Related Work Task Definition and Dataset Construction Task Definition The task input is a tuple of table T, metadata M, Data-to-Text aims to generate natural language and a written prefix X. The metadata M may infrom structured data, which has been widely stud- clude the table caption, the title of the section that ied recently. Most prior works focus on surface- contains the table, or other context around the talevel text generation in a specific domain o"
2021.findings-emnlp.107,D18-2012,0,0.0190851,"), we use the template hc |hr |v to represent each table cell, where hc and hr are column and row names of the cell v. Following Herzig et al. (2020) to represent the table structure, we add row embedding r and column embedding c. We also use a type embedding t to represent the input type, where the type could be the table cell or different metadata types. Given the input data, we first linearize the table row by row into a sequence of words and concatenate words of the metadata before the table words. The words are further tokenized with the WordPiece (Johnson et al., 2017) or SentencePiece (Kudo and Richardson, 2018) tokenizer. Let p be the positional embedding, w be the word embedding, and e denote the input representation, we have e = w + r + c + t + p. With transformer-based structures, finetuning task5.2 Encoder-Decoder Attention Visibility specific models with pre-trained parameters has achieved state-of-the-art results in text genera- The prefix provides the content planning signals on tion, achieving an astonishing level of fluency and the structured data. For example, in Figure 4, the coherence. Pre-trained models with a encoder- prefix &quot;Daniel was the&quot; indicates that the following decoder structu"
2021.findings-emnlp.107,D16-1128,0,0.0444351,"Missing"
2021.findings-emnlp.107,2020.acl-main.703,0,0.0258382,"th no explicit guidance on the generated topic. ToTTo (Parikh et al., 2020) guide the topic of the generated target with a set of highlighted table cells. LogicNLG (Chen et al., 2020a) and Logic2Text (Chen et al., 2020b) address logical inference/generation in data-to-text. ROTOWIRE (Wiseman et al., 2017) and ToTTo (Parikh et al., 2020) also contain data that requires reasoning. Many existing works tend to train neural models in an end-to-end fashion (Liu et al., 2018; Wiseman et al., 2017, 2018; Chen et al., 2020c). Recently, large pre-trained models (Rothe et al., 2020; Raffel et al., 2020; Lewis et al., 2020) have also achieved new state-of-the-art results on data-to-text tasks. Reiter and Dale (1997) suggest that an NLG system consists of content planning and surface realization. Parikh et al. (2020) propose ToTTo to control the topics of generated text with highlighted cells. Gong et al. (2020) brings the sense of numerical value comparison into content planning. Li and Wan (2018) propose to generate templates and then fill the slots, while (Iso et al., 2019) incorporate writers’ information to generate text step-by-step. Gong et al. (2019) utilize hierarchical encoders with dual attention to co"
2021.findings-emnlp.107,P16-1094,0,0.0265539,"020) propose ToTTo to control the topics of generated text with highlighted cells. Gong et al. (2020) brings the sense of numerical value comparison into content planning. Li and Wan (2018) propose to generate templates and then fill the slots, while (Iso et al., 2019) incorporate writers’ information to generate text step-by-step. Gong et al. (2019) utilize hierarchical encoders with dual attention to consider both the table structure and history information. In NLG, controlled text generation is also a hot research topic. It considers controlling attributes, such as identity of the speaker (Li et al., 2016), sentiment (Dou et al., 2018), tense (Hu et al., 2017), politeness (Sennrich et al., 2016) and text length (Kikuchi et al., 2016). Our work could be considered as a middle-ground between data-to-text and controlled text generation and has more practical usage. 3 3.1 2 Related Work Task Definition and Dataset Construction Task Definition The task input is a tuple of table T, metadata M, Data-to-Text aims to generate natural language and a written prefix X. The metadata M may infrom structured data, which has been widely stud- clude the table caption, the title of the section that ied recently."
2021.findings-emnlp.107,C18-1089,0,0.0640695,"any existing works tend to train neural models in an end-to-end fashion (Liu et al., 2018; Wiseman et al., 2017, 2018; Chen et al., 2020c). Recently, large pre-trained models (Rothe et al., 2020; Raffel et al., 2020; Lewis et al., 2020) have also achieved new state-of-the-art results on data-to-text tasks. Reiter and Dale (1997) suggest that an NLG system consists of content planning and surface realization. Parikh et al. (2020) propose ToTTo to control the topics of generated text with highlighted cells. Gong et al. (2020) brings the sense of numerical value comparison into content planning. Li and Wan (2018) propose to generate templates and then fill the slots, while (Iso et al., 2019) incorporate writers’ information to generate text step-by-step. Gong et al. (2019) utilize hierarchical encoders with dual attention to consider both the table structure and history information. In NLG, controlled text generation is also a hot research topic. It considers controlling attributes, such as identity of the speaker (Li et al., 2016), sentiment (Dou et al., 2018), tense (Hu et al., 2017), politeness (Sennrich et al., 2016) and text length (Kikuchi et al., 2016). Our work could be considered as a middle-"
2021.findings-emnlp.107,P09-1011,0,0.0244671,"ition and Dataset Construction Task Definition The task input is a tuple of table T, metadata M, Data-to-Text aims to generate natural language and a written prefix X. The metadata M may infrom structured data, which has been widely stud- clude the table caption, the title of the section that ied recently. Most prior works focus on surface- contains the table, or other context around the talevel text generation in a specific domain or ble. The output target is denoted by Y , such that schema, such as ROBOCUP (Chen and Mooney, concatenating the prefix X and the output target 2008), WEATHERGOV (Liang et al., 2009), Y results in a fluent sentence that is faithful to the E2ENLG (Novikova et al., 2017), and WebNLG table T. The goal is to learn a data-to-text model (Gardent et al., 2017). These datasets expect the conditioned on the written prefix, P (Y |T, M, X). 1245 Property Number of prefix-target pairs Average prefix length (tokens) Average target length (tokens) Rows per table (average/median) Columns per table (average/median) Figure 2: ToTTo dataset example (Parikh et al., 2020). Figure 3: TabFact dataset example (Chen et al., 2019). 3.2 Dataset Construction ToTTo 27,042 10.9 15.8 32.8/16.0 6.8/6.0"
2021.findings-emnlp.107,W17-5525,0,0.0150132,"metadata M, Data-to-Text aims to generate natural language and a written prefix X. The metadata M may infrom structured data, which has been widely stud- clude the table caption, the title of the section that ied recently. Most prior works focus on surface- contains the table, or other context around the talevel text generation in a specific domain or ble. The output target is denoted by Y , such that schema, such as ROBOCUP (Chen and Mooney, concatenating the prefix X and the output target 2008), WEATHERGOV (Liang et al., 2009), Y results in a fluent sentence that is faithful to the E2ENLG (Novikova et al., 2017), and WebNLG table T. The goal is to learn a data-to-text model (Gardent et al., 2017). These datasets expect the conditioned on the written prefix, P (Y |T, M, X). 1245 Property Number of prefix-target pairs Average prefix length (tokens) Average target length (tokens) Rows per table (average/median) Columns per table (average/median) Figure 2: ToTTo dataset example (Parikh et al., 2020). Figure 3: TabFact dataset example (Chen et al., 2019). 3.2 Dataset Construction ToTTo 27,042 10.9 15.8 32.8/16.0 6.8/6.0 TabFact 13,955 9.3 14.2 10.9/10.0 6.1/6.0 Table 1: TWT evaluation benchmark statistics"
2021.findings-emnlp.107,P02-1040,0,0.110006,"th logical inference over the data. Note that both ToTTo and TabFact contain text with logical inference. In total, we collected 128, 268 and 49, 417 table-sentence pairs from ToTTo and TabFact, respectively. After that, we resplit the table-sentence pairs to train/validation/test set as the TWT dataset. 4 Evaluation Metrics The size of the train/validation/test set for ToTTo source is 113, 063/7, 690/7, 515 and for TabFact is For evaluation on TWT, we adopt the commonly 39, 678/5, 009/4, 730. used metrics in text generation, including BLEU Now, we could build the prefix and the golden score (Papineni et al., 2002), BLEURT (Sellam target to generate by simulating the user writing et al., 2020), and BERTScore (Zhang et al., 2020). process. An easy way to build prefix-target pairs is Additionally, we introduce faithfulness metrics to to break the sentence into two parts randomly, the measure the faithfulness of the generated text. Note first part will be the written prefix, and the second that models trained on TWT might provide intelpart is the target text to generate. However, the dif- ligent writing assistance, we also design several ficulty of generating correct target text on different metrics specif"
2021.findings-emnlp.107,2020.emnlp-main.89,0,0.241189,"n a novel approach with table-aware In NLG, one way to provide signals on what to attention visibility and copy mechanism over generate is to add constraints to the model output, the table. Experimental results show that our which falls in the task of controlled text generaapproach outperforms state-of-the-art methods under both automatic and human evaluation tion (CTG). Most CTG tasks are conditioned on metrics. several key-value pairs of control factors such as tone, tense, length, and sentiment (Hu et al., 2017; 1 Introduction Dong et al., 2017; Ficler and Goldberg, 2017). In data-to-text, Parikh et al. (2020) propose the dataset Data-to-text refers to the task of generating a target ToTTo to address content planning by highlighting textual description conditioned on the structured some cells in the table, the highlighted cells prosource data such as tables, graphs, and meaning vide strong guidance on what to generate. However, representations. Reiter and Dale (1997) suggest ToTTo lacks practical use, it would be difficult to that a natural language generation (NLG) system have tables with highlighted cells or ask the users consists of content planning (what to say) and to highlight the cells in th"
2021.findings-emnlp.107,W18-6502,0,0.0182507,"of the generated text. Note first part will be the written prefix, and the second that models trained on TWT might provide intelpart is the target text to generate. However, the dif- ligent writing assistance, we also design several ficulty of generating correct target text on different metrics specifically targeting this scenario. 1246 4.1 Faithfulness Metrics We propose two evaluation metrics to measure the faithfulness: fact coverage and the modified PARENT (Dhingra et al., 2019). Fact Coverage is similar to the entity-centric metric (Liu et al., 2021), and the overall slot filling metric (Wang et al., 2018). Let Fg be the set of aligned facts of the golden target and the table data, and Fp be that for the generated target. Fact coverage is calculated as |Fp ∩ Fg |/|Fg |. Note that fact coverage of open-ended generated targets will be quite low. We use the same alignment method described in Section 3.2 to acquire Fg and Fp . PARENT (Dhingra et al., 2019) is a metric specifically designed for data-to-text evaluation that takes the input table into account. It computes smoothed n-gram precision and recall over both the generated target and the input table. Parikh et al. (2020) modifies this metric"
2021.findings-emnlp.107,D18-1356,0,0.0497623,"Missing"
2021.findings-emnlp.107,2020.acl-main.745,0,0.0207081,"d uni-directional attention for the generated target as the decoder selfattention visibility. We also introduce the copy mechanism over the table data to assure the faithfulness of the generated target. Note that our model is based on the transformer encoder-decoder architecture (Rothe et al., 2020), both the encoder and the decoder are initialized with pre-trained parameters. 5.1 Table-aware Additional Embeddings A common way to encode structured data with transformer is to create a linearized sequence of the data and treat the linearized sequence as text. For table linearization, similar to Yin et al. (2020), we use the template hc |hr |v to represent each table cell, where hc and hr are column and row names of the cell v. Following Herzig et al. (2020) to represent the table structure, we add row embedding r and column embedding c. We also use a type embedding t to represent the input type, where the type could be the table cell or different metadata types. Given the input data, we first linearize the table row by row into a sequence of words and concatenate words of the metadata before the table words. The words are further tokenized with the WordPiece (Johnson et al., 2017) or SentencePiece (K"
2021.findings-emnlp.107,2020.tacl-1.18,0,0.392139,"(Parikh et al., 2020) and TabFact (Chen et al., 2019). See Section 3 for details about the dataset construction. TWT contains both factual and logical statements that are faithful to the structured data. Compared with other datasets, TWT is of practical use. The prefix controls the topic of the generated text, and the output model could assist in writing with structured data. Note that TWT differs from those datasets that provide only one golden sentence with no content planning signals. To generate text faithful to the data, we design a novel approach that leverages large pre-trained models (Rothe et al., 2020) with table-aware attention visibility (based on the written text) and copy mechanism (Oriol et al., 2015; Gu et al., 2016) over the table. Experimental results show that our approach outperforms state-of-the-art methods under both automatic and human evaluation metrics, particularly in terms of faithfulness to the structured data. These results suggest that TWT could be a useful controllable data-to-text benchmark, and may help innovate models to provide intelligent assistance for writing with structured data. generated text to describe all the records from the data. WikiBio (Lebret et al., 2"
2021.findings-emnlp.107,P17-1099,0,0.0451077,"distribution: pcopy = σ(wxT xt + wsT st + whT∗ h∗t + b) where wx , ws , wh∗ , and b are learnable parameters, xt is the decoder input, st is the output of the last decoder layer, σ is the sigmoid and h∗t is P t function, ∗ t the context vector, ht = i ai hi , ai is the encoderdecoder attention weight that masked with visibility introduced in Section 5.2. Note that for the multi-head attention, we obtain pcopy by averaging that of all heads. Let Pvocab (w) be the probability of generating token w, which is calculated through two linear layers with the concatenation of st and h∗t as input (see See et al. (2017) for details), the final probability distribution over the extended vocabulary from the input data will be: X P (w) = (1 − pcopy )Pvocab (w) + pcopy ati i:wi =w Copy mechanism is mainly proposed to handle out-of-vocabulary words (OOV) (Oriol et al., 2015; Gu et al., 2016). However, in our task, many of the table values are not OOV. The reason we employ the copy mechanism is to explicitly &quot;teach&quot; the model when and which fact to copy from the input data to improve faithfulness. We consider tokens of the aligned facts in the golden target as copied tokens, denoted by Va . Following Chen et al. ("
2021.findings-emnlp.107,2020.acl-main.704,0,0.0459273,"Missing"
2021.findings-emnlp.107,N16-1005,0,0.0295095,"ng et al. (2020) brings the sense of numerical value comparison into content planning. Li and Wan (2018) propose to generate templates and then fill the slots, while (Iso et al., 2019) incorporate writers’ information to generate text step-by-step. Gong et al. (2019) utilize hierarchical encoders with dual attention to consider both the table structure and history information. In NLG, controlled text generation is also a hot research topic. It considers controlling attributes, such as identity of the speaker (Li et al., 2016), sentiment (Dou et al., 2018), tense (Hu et al., 2017), politeness (Sennrich et al., 2016) and text length (Kikuchi et al., 2016). Our work could be considered as a middle-ground between data-to-text and controlled text generation and has more practical usage. 3 3.1 2 Related Work Task Definition and Dataset Construction Task Definition The task input is a tuple of table T, metadata M, Data-to-Text aims to generate natural language and a written prefix X. The metadata M may infrom structured data, which has been widely stud- clude the table caption, the title of the section that ied recently. Most prior works focus on surface- contains the table, or other context around the talevel"
2021.naacl-main.312,R13-1027,0,0.0105799,"tence X of length m and target sentence Y of length n, we can construct n intermediate sentences Zk = (yn−k+1 , . . . , yn , [m], y1 , . . . , yn−k )(k ∈ [1, n]). Because the target sentence length n can be too long, we randomly sample S intermediate sentences from n intermediate sentences to construct the subset SY , where S is the number of sampled start positions. We apply scores calculated by the hard or soft Smart-Start methods to the loss of different intermediate samples to teach model which start position is better. This procedure can be described by the weighted log-likelihood (WML) (Dimitroff et al., 2013) reward function L over the dataset D as below:   wk log Pθ (Zk |X) L= (2) X,Y ∈D Zk ∈SY where SY is the subset containing S samples. wk is calculated by the hard or soft Smart-Start methods. For the hard Smart-Start method, we use the median training loss of intermediate samples as threshold to select appropriate samples to update model parameters. We calculate wk by comparing the training loss generated by the current model of each Zk from SY with the threshold as below: Our Smart-Start method is extremely interested in breaking up the limitation of this decoding order. Different from the"
2021.naacl-main.312,Q19-1042,0,0.033751,"Missing"
2021.naacl-main.312,W18-6301,0,0.0135741,"4000 warming-up steps. We set the number of sampled start positions S = 8 described as Equation 2. For the LDC Zh→En translation task, we use the Transformer_base setting with the embedding size as 512 and feed-forward network (FFN) size as 2048. For the IWSLT14 De→En translation task, we use the Transformer_small setting with embedding size as 512 and FFN size as 1024. The dropout is set as 0.3 and weight decay as 0.0001 to prevent overﬁtting. For the WMT14 En→De translation task, we use the Transformer_big setting with embedding size as 1024 and FFN size as 4096. Following the previos work (Ott et al., 2018), we accumulate the gradient for 16 iterations to simulate a 128-GPU environment. 3.2 3.3 In this section, we evaluate our method on three popular benchmarks. 3.1 Dataset Training Details Baselines and Results We conduct experiments on 8 NVIDIA 32G V100 We compare our method with the other baseGPUs and set batch size as 1024 tokens. In lines, including Transformer (Vaswani et al., 2017), RP Transformer (Shaw et al., 2018), Lightthe training stage, we adopt the Adam optimizer 3984 Zh → En MT06 MT02 MT03 MT05 MT08 MT12 Avg LightConv (Wu et al., 2019) DynamicConv (Wu et al., 2019) 43.41 43.65 42."
2021.naacl-main.312,P02-1040,0,0.109436,"Missing"
2021.naacl-main.312,W16-2323,0,0.114321,"he dataset D as below:   wk log Pθ (Zk |X) L= (2) X,Y ∈D Zk ∈SY where SY is the subset containing S samples. wk is calculated by the hard or soft Smart-Start methods. For the hard Smart-Start method, we use the median training loss of intermediate samples as threshold to select appropriate samples to update model parameters. We calculate wk by comparing the training loss generated by the current model of each Zk from SY with the threshold as below: Our Smart-Start method is extremely interested in breaking up the limitation of this decoding order. Different from the traditional L2R and R2L (Sennrich et al., 2016a), our Smart-Start method wk = δLk ≥Lmed (3) predicts median word yn−k+1 over the source sentence. Furthermore, we predict the right part of tarwhere δLk ≥Lmed equals to 1 if Lk ≥ Lmed else 0. get sentence (yn−k+1 , . . . , yn ) sequentially which Lmed is the median loss of the sample in SY . For is on the right part of this word. Finally, we gener- each intermediate sentence Zk ∈ SY , the objective ate the rest words (y1 , . . . , yn−k ) on the left part of of Zk is denoted as Lk = log Pθ (Zk |X). 3983 Final Translation ܻ : ݕଵ ݕ୬ି୩ାଵ 濷 濷 ݕ୬ି୩ Left-to-Right ܼ ՜ ܻ Intermediate Translati"
2021.naacl-main.312,P16-1162,0,0.430013,"he dataset D as below:   wk log Pθ (Zk |X) L= (2) X,Y ∈D Zk ∈SY where SY is the subset containing S samples. wk is calculated by the hard or soft Smart-Start methods. For the hard Smart-Start method, we use the median training loss of intermediate samples as threshold to select appropriate samples to update model parameters. We calculate wk by comparing the training loss generated by the current model of each Zk from SY with the threshold as below: Our Smart-Start method is extremely interested in breaking up the limitation of this decoding order. Different from the traditional L2R and R2L (Sennrich et al., 2016a), our Smart-Start method wk = δLk ≥Lmed (3) predicts median word yn−k+1 over the source sentence. Furthermore, we predict the right part of tarwhere δLk ≥Lmed equals to 1 if Lk ≥ Lmed else 0. get sentence (yn−k+1 , . . . , yn ) sequentially which Lmed is the median loss of the sample in SY . For is on the right part of this word. Finally, we gener- each intermediate sentence Zk ∈ SY , the objective ate the rest words (y1 , . . . , yn−k ) on the left part of of Zk is denoted as Lk = log Pθ (Zk |X). 3983 Final Translation ܻ : ݕଵ ݕ୬ି୩ାଵ 濷 濷 ݕ୬ି୩ Left-to-Right ܼ ՜ ܻ Intermediate Translati"
2021.naacl-main.312,N18-2074,0,0.0279932,"Missing"
2021.naacl-main.312,P18-2054,0,0.0189744,"models (Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Kalchbrenner et al., 2016; Gehring et al., 2017; Vaswani et al., 2017; He et al., 2018). Asynchronous and synchronous Bidirectional decoding Model (Zhang et al., 2018; Zhou et al., 2019b) exploits the contexts generated in the R2L manner to help the L2R translation. Previous non-monotonic methods (Serdyuk et al., 2018; Zhang et al., 2018; Zhou et al., 2019a,b; Zhang et al., 2019; Welleck et al., 2019) jointly leverage L2R and R2L information. Non-monotonic methods are also widely used in many tasks (Huang et al., 2018; Shu and Nakayama, 2018), such as parsing (Goldberg and Elhadad, 2010), image caption (Mehri and Sigal, 2018), and dependency parsing (Kiperwasser and Goldberg, 2016; Li et al., 2019). Similarly, insertion-based method (Gu et al., 2019; Stern et al., 2019) predicts the next token and its position to be inserted. 5 Conclusion In this work, we propose a novel method that breaks up the limitation of these decoding orders, called Smart-Start decoding. Our method predicts a median word and then generates the words on the right part. Finally, it generates words on the left. Experimental results show that our Smart-Start me"
2021.naacl-main.312,Q16-1032,0,0.0174688,"al., 2017; He et al., 2018). Asynchronous and synchronous Bidirectional decoding Model (Zhang et al., 2018; Zhou et al., 2019b) exploits the contexts generated in the R2L manner to help the L2R translation. Previous non-monotonic methods (Serdyuk et al., 2018; Zhang et al., 2018; Zhou et al., 2019a,b; Zhang et al., 2019; Welleck et al., 2019) jointly leverage L2R and R2L information. Non-monotonic methods are also widely used in many tasks (Huang et al., 2018; Shu and Nakayama, 2018), such as parsing (Goldberg and Elhadad, 2010), image caption (Mehri and Sigal, 2018), and dependency parsing (Kiperwasser and Goldberg, 2016; Li et al., 2019). Similarly, insertion-based method (Gu et al., 2019; Stern et al., 2019) predicts the next token and its position to be inserted. 5 Conclusion In this work, we propose a novel method that breaks up the limitation of these decoding orders, called Smart-Start decoding. Our method predicts a median word and then generates the words on the right part. Finally, it generates words on the left. Experimental results show that our Smart-Start method signiﬁcantly improves the quality of translation. Training Time The Transformer baseline costs Acknowledgments nearly 0.9 hours and our"
2021.naacl-main.312,P07-2045,0,0.00927966,"riments Number of Sampled Start Positions Figure 3: Results of different values of the number of sampled start positions on IWSLT14 De→En test set. IWSLT14 De-En corpus contains 16K training sequence pairs. The valid and test set both contain 7K sentence pairs. LDC Zh-En corpus is from the LDC corpus. The training data contains 1.4M sentence pairs. NIST 2006 is used as the valid set. NIST 2002, 2003, 2005, 2008, and 2012 are used as test sets. WMT14 En-De corpus has 4.5M sentence pairs. The newstest2013 and the newstest2014 are used as valid the test set. All languages are tokenized by Moses (Koehn et al., 2007) and our Chinese tokenizer, and then encoded using byte pair encoding (BPE) (Sennrich et al., 2016b) with 40K merge operations. The evaluation metric is BLEU (Papineni et al., 2002). (β1 = 0.9, β2 = 0.98) (Kingma and Ba, 2015) using the inverse sqrt learning rate schedule (Vaswani et al., 2017) with a learning rate of 0.1 and 4000 warming-up steps. We set the number of sampled start positions S = 8 described as Equation 2. For the LDC Zh→En translation task, we use the Transformer_base setting with the embedding size as 512 and feed-forward network (FFN) size as 2048. For the IWSLT14 De→En tra"
2021.naacl-main.312,D15-1166,0,0.0539853,"affecting the training time is the number of sampled start positions. We also investigate the proper value of the number of sampled start positions. In practice, smaller value such as 4 or 6 can also bring signiﬁcant improvements. Therefore, we choose a smaller value of the sampled start positions and use multiple GPUs to keep the training time in a reasonable range. 4 Related Work Neural Machine Translation (NMT) has attracted a lot of attention recently. The architecture of NMT models has evolved quickly so that there are many different models (Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Kalchbrenner et al., 2016; Gehring et al., 2017; Vaswani et al., 2017; He et al., 2018). Asynchronous and synchronous Bidirectional decoding Model (Zhang et al., 2018; Zhou et al., 2019b) exploits the contexts generated in the R2L manner to help the L2R translation. Previous non-monotonic methods (Serdyuk et al., 2018; Zhang et al., 2018; Zhou et al., 2019a,b; Zhang et al., 2019; Welleck et al., 2019) jointly leverage L2R and R2L information. Non-monotonic methods are also widely used in many tasks (Huang et al., 2018; Shu and Nakayama, 2018), such as parsing (Goldberg and Elhadad, 2010), im"
2021.naacl-main.312,W19-3620,0,0.0789923,"ersonality 晝ⴷ ⷿ㘖 . very 濿濼瀉濸濿瀌 Happy to talk with people , Yang Sen has a lively personality (a) Left-to-Right Translation: Le talks with people , Yang Sen is very lively . Smart-Start: Yang Sen has a lively personality . [m] Chatting with people , (b) Translation: Chatting with people , Yang Sen has a lively personality . Figure 1: Example of baseline method (a) and our Smart-Start method (b). “[m]” is designed to indicate the termination of the right part generation. “[m]” is an abbreviation of “[middle]”. There are some related works on non-monotonic text generation (Mehri and Sigal, 2018; Welleck et al., 2019; Gu et al., 2019; Zhou et al., 2019b,a). 1 Introduction Inspired by these works, we are extremely interNeural machine translation (NMT) has made re- ested in considering choosing one proper position to start decoding instead of L2R or R2L order. We markable progress in recent years. There has been much progress in encoder-decoder framework, in- propose a novel method called the Smart-Start decluding recurrent neural models (Wu et al., 2016), coding method. Speciﬁcally, our method starts the generation of target words from the right part of convolutional models (Gehring et al., 2017) and self-"
C12-1035,P12-1056,0,0.0170258,"h are partitioned into two subsets: a labeled set M l = {m1 , m2 , . . . , m L } and an unlabeled set M u = {m L+1 , m L+2 , . . . , m L+N }. M l includes only the example messages provided through user interaction, where each instance is associated with a predefined category ci with belonging to C = {c1 , c2 . . . cK }; while M u includes all the other messages. We aim to predict the category label for each data point in M u . Here we assume that each tweet belongs to only one category. Similar idea of assigning a single topic or category to a short sequence of words has been used before in (Diao et al., 2012) (Gruber et al., 2007) (Zhao et al., 2011). 2.1 The General Framework We now introduce the overview of the whole processing that aims to classify microblogging messages by exploiting the internal and external resources. The workflow consists of three phrases, as shown in Figure 1. It includes the preprocessing of external resources, preprocessing of microblogging messages, and construction of Semi-Supervised Bayesian Network (SSBN) model. Phrase 1: Preprocessing of External Resources Due to their short length, microblogging messages do not provide sufficient word co-occurrence or context share"
C12-1035,D09-1026,0,0.692779,"tive similarity measure (Hu et al., 2009). The data sparseness hinders general machine learning methods to achieve desirable accuracy. Second, microblogging messages are not well conformed as standard structures of documents. Sometimes they do not even obey grammatical rules (Hu and Liu, 2012b). Third, microblogs lack label information. It is time and labor consuming to label the huge amounts of messages. Intensive efforts have been made on the classification of short texts utilizing machine learning techniques (Nie et al., 2011). Some representative research efforts are based on topic model (Ramage et al., 2009) (Zhao et al., 2011). As these approaches heavily rely on the term co-occurrence information, the sparsity of short and informal messages unduly influence the significant improvement of the performance. Some others explore some traditional supervised learning methods to classify microblogging messages (Lee et al., 2011) (Zubiaga et al., 2011) (Sriram et al., 2010) (Tang et al., 2012). The sparsity problem again hinders the similarity measurement. Moreover, it is laborious and time consuming to obtain labeled data from microblogging. Consequently, new approaches towards microblog classification"
C16-1187,R13-1026,0,0.0312198,"need the information. Therefore, our effort is complementary to the existing work on response generation. It can keep the existing generation algorithms context-aware and improve their efficiency and robustness to noise. The task is challenging, as messages in a conversational environment are usually short and informal, and evidence that can indicate a message is context dependent is scarce. For example, on 3 million post-response pairs crawled from Weibo, the average length of messages is 4.65. On such short texts, classic NLP tools such as POS Tagger and Parser suffer from bad performance (Derczynski et al., 2013; Foster et al., 2011) and it is difficult to explicitly extract features that are discriminative on the two types of messages. More seriously, there are no large scale annotations available for building a supervised learning procedure. We consider leveraging the large amount of human-human conversation data available on the web to learn a message classifier. Our intuition is that a context dependent message has different linguistic context in different conversation sessions, therefore its responses could be more diverse on content than responses of a context independent message. To verify thi"
C16-1187,W11-2017,0,0.0295448,"proposal of learning weak supervision signals from responses of messages using large scale conversation data; 3) proposal of using an LSTM architecture to learn a message classifier; 4) empirical verification of the proposed method on human annotated data. 1991 2 Related Work Our work lies in the path of building chatbot systems with data-driven approaches. Differing from traditional dialogue systems (cf., (Young et al., 2013)) which rely on hand-crafted features and rules to generate reply sentences for specific applications such as voice dialling (Williams, 2008) and appointment scheduling (Janarthanam et al., 2011) etc., recent effort focuses on exploiting an end-to-end approach to learn a response generator from social conversation data for open domain dialogue (Koshinda et al., 2015; Higashinaka et al., 2016). For example, Ritter et al. (Ritter et al., 2011) employed a phrase-based machine translation model for response generation. In (Shang et al., 2015; Vinyals and Le, 2015), neural network architectures were proposed to learning response generators from one-round conversation data. Based on these work, Sordoni et al. (Sordoni et al., 2015b) incorporated linguistic context into the learning of respo"
C16-1187,D11-1054,0,0.254837,"ed method can significantly outperform baseline methods on accuracy of classification. 1 Introduction Together with the rapid growth of social media such as Twitter and Weibo, the amount of conversation data on the web has tremendously increased. This makes building open domain chatbot systems with data-driven approaches possible. To carry on reasonable conversations with humans, a chatbot system needs to generate proper response with regard to users’ messages. Recently, with the large amount of conversation data available, learning a response generator from data has drawn a lot of attention (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). A key step to coherent response generation is determining when to consider linguistic context of messages. Existing work on response generation, however, has overlooked this step. They either totally ignores linguistic context (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015) or simply considers context for every message (Sordoni et al., 2015b; Serban et al., 2015). The former case is easy to lead to irrelevant responses when users’ input messages rely on the context information in previous conversation turns, while the latter case is"
C16-1187,P15-1152,0,0.290145,"cantly outperform baseline methods on accuracy of classification. 1 Introduction Together with the rapid growth of social media such as Twitter and Weibo, the amount of conversation data on the web has tremendously increased. This makes building open domain chatbot systems with data-driven approaches possible. To carry on reasonable conversations with humans, a chatbot system needs to generate proper response with regard to users’ messages. Recently, with the large amount of conversation data available, learning a response generator from data has drawn a lot of attention (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). A key step to coherent response generation is determining when to consider linguistic context of messages. Existing work on response generation, however, has overlooked this step. They either totally ignores linguistic context (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015) or simply considers context for every message (Sordoni et al., 2015b; Serban et al., 2015). The former case is easy to lead to irrelevant responses when users’ input messages rely on the context information in previous conversation turns, while the latter case is costly (e.g., on mem"
C16-1187,N15-1020,0,0.139745,"eds to generate proper response with regard to users’ messages. Recently, with the large amount of conversation data available, learning a response generator from data has drawn a lot of attention (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015). A key step to coherent response generation is determining when to consider linguistic context of messages. Existing work on response generation, however, has overlooked this step. They either totally ignores linguistic context (Ritter et al., 2011; Shang et al., 2015; Vinyals and Le, 2015) or simply considers context for every message (Sordoni et al., 2015b; Serban et al., 2015). The former case is easy to lead to irrelevant responses when users’ input messages rely on the context information in previous conversation turns, while the latter case is costly (e.g., on memory and responding time) for building a real chatbot system and has the risk of bringing in noise to response generation especially when users want to end the current conversation topic and start a new one. According to our observation, there are two types of messages in a conversational environment. The first type is context dependent message, which means to reply to the message,"
C16-1187,P08-4001,0,0.0201772,"essages in a conversational environment; 2) proposal of learning weak supervision signals from responses of messages using large scale conversation data; 3) proposal of using an LSTM architecture to learn a message classifier; 4) empirical verification of the proposed method on human annotated data. 1991 2 Related Work Our work lies in the path of building chatbot systems with data-driven approaches. Differing from traditional dialogue systems (cf., (Young et al., 2013)) which rely on hand-crafted features and rules to generate reply sentences for specific applications such as voice dialling (Williams, 2008) and appointment scheduling (Janarthanam et al., 2011) etc., recent effort focuses on exploiting an end-to-end approach to learn a response generator from social conversation data for open domain dialogue (Koshinda et al., 2015; Higashinaka et al., 2016). For example, Ritter et al. (Ritter et al., 2011) employed a phrase-based machine translation model for response generation. In (Shang et al., 2015; Vinyals and Le, 2015), neural network architectures were proposed to learning response generators from one-round conversation data. Based on these work, Sordoni et al. (Sordoni et al., 2015b) inco"
C16-1187,P15-2041,0,0.0179695,"eration. In this paper, instead of studying how to incorporate context into response generation, we consider the problem that when we need context in the process. Our work can keep the existing generation algorithms context-aware and at the same time improve their efficiency and robustness. We employ a Recurrent Neural Network (RNN) architecture to learn a message classifier. RNN models (Elman, 1990), due to their capability of modeling sequences with arbitrary length, have been widely used in many natural language processing tasks such as language modeling (Mikolov et al., 2010) and tagging (Xu et al., 2015) etc. Recently, it is reported that Long Short Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) and Gated Recurrent Unit (GRU) (Cho et al., 2014) as two special RNN models which can capture long term dependencies in sequences outperform state of the art methods on tasks like machine translation (Sutskever et al., 2014) and response generation (Shang et al., 2015). In this paper, we apply the LSTM architecture to the task of context dependent message detection. We append LSTM with a two-layer feed-forward neural network, thus feature learning and model learning can be carried out simultane"
D18-1439,I13-1062,0,0.51954,"edelyan et al., 2008; Hulth, 2003; Shang et al., 2017) and selecting text chunks with certain postags (Liu et al., 2011; Wang et al., 2016; Le et al., 2016; Liu et al., 2015). The second phase is to rank the candidates with machine learning methods. Specifically, some researchers (Frank et al., 1999; Witten et al., 1999; Hulth, 2003; Medelyan et al., 2009; Gollapalli and Caragea, 2014) formulate the keyphrase extraction as a supervised classification problem, while others apply unsupervised approaches (Mihalcea and Tarau, 2004; Grineva et al., 2009; Liu et al., 2009, 2010; Zhang et al., 2013; Bougouin et al., 2013, 2016) on this task. Besides, Tomokiyo and Hurst (2003) employ two statistical language models to measure the informativeness for phrases. Liu et al. (2011) use a word alignment model to learn translation probabilities between the words in documents and the words in keyphrases, which alleviates the problem of vocabulary gaps. The latter group, generative methods, assigns keyphrases to a document with natural language generation techniques, and is capable of generating absent keyphrases. Owing to the development of neural networks (Bahdanau et al., 2014), Meng et al. (2017) apply an encoder-de"
D18-1439,C16-1277,0,0.0246302,"Missing"
D18-1439,P16-1154,0,0.585783,"appears in a source document, and absent keyphrase that does not appear in the document. Conventional approaches extract important text spans as candidate phrases and rank them as keyphrases (Hulth, 2003; Medelyan et al., 2008; Liu et al., 2011; Wu et al., 2015; Wang et al., 2016), that show promising results on the present keyphrases but cannot handle absent keyphrases. ∗ Corresponding Author To predict absent keyphrases, generative methods have been proposed by Meng et al. (2017). The approach employs a sequence-to-sequence (Seq2Seq) framework (Sutskever et al., 2014) with a copy mechanism (Gu et al., 2016) to encourage rare word generation, in which the encoder compresses the text into a dense vector and the decoder generates a phrase with a Recurrent Neural Network (RNN) language model, achieving stateof-the-art performance. Since a document corresponds to multiple keyphrases, the approach divides it into multiple document-keyphrase pairs as training instances. This approach, however, neglects the correlation among target keyphrases since it does not model the one-to-many relationship between the document and keyphrases. Therefore, keyphrase prediction only depends on the source document, and"
D18-1439,P13-2115,0,0.0881973,"t al., 2014) with a copy mechanism 4058 (Gu et al., 2016) to this task, achieving state-ofthe-art performance. Our work is a generation based approach. The main difference of our model is that we consider the correlation among keyphrases. Our model proposes a new review mechanism to enhance keyphrase diversity, while employs a coverage mechanism that has proven effective for summarization (See et al., 2017) and machine translation (Tu et al., 2016) to guarantee keyphrase coverage. Some previous works on keyword extraction have already exploited the correlation problem with a re-rank strategy (Habibi and Popescu-Belis, 2013; Ni et al., 2012). In contrast, we model the correlation in an end-to-end fashion. 3 KeyphraseGenerationwithCorrelation 3.1 Problem Formalization Suppose that we have a data set D = {xi , pi }N i=1 , where xi is a source text, pi = i {pi,j }M j=1 is the keyphrase set of xi , and N is the number of documents. Both the source text and target keyphrase are word sequences, donated as xi = (xi1 , xi2 , ..., xiT ) and pi,j = (y1i,j , y2i,j , ..., yLi,ji ) respectively. T and Li are the length of word sequences of xi and pi,j . Prior work aims to maximize the probability of QN Q Mi j=1 P (pi,j |xi )"
D18-1439,C10-2042,0,0.380189,"for evaluation and the rest are added to the training set. 4.3 Baseline Models We compare our model with extractive and generative approaches. The extractive baselines include Tf-idf, TextRank (Mihalcea and Tarau, 2004), SingleRank (Wan and Xiao, 2008), ExpandRank (Wan and Xiao, 2008), TopicRank1 (Bougouin et al., 2013), KEA (Witten et al., 1999) and Maui (Medelyan et al., 2009). The generative baselines include RNN and CopyRNN (Meng et al., 2017). In these baselines, the first five are unsupervised and the later four are supervised. We set up all the baselines following optimal settings in (Hasan and Ng, 2010), (Bougouin et al., 2013) and (Meng et al., 2017). To demonstrate the effectiveness of end-to-end learning, we compare CorrRNN to CopyRNN with post-processing. In post-precessing, we only keep the first appearence of keyphrase in duplicate predictions, duplication means that a phrase is a substring of another. The baseline can be seen as heuristic rules for improving the diversity, denoted as CopyRNNF . 4.4 Evaluation Metrics For a fair comparison, we evaluate the experiment results on present keyphrases and absent keyphrases separately, because extractive methods cannot generate absent keyphr"
D18-1439,W03-1028,0,0.96816,"t that is able to summarize a long document, organize contents and highlight important concepts, like ”virtual organizations” in Table 1. It provides readers with a rough understanding of a document without going through its content, and has many potential applications, such as information retrieval, text summarization and document classification. Keyphrase can be categorized into present keyphrase which appears in a source document, and absent keyphrase that does not appear in the document. Conventional approaches extract important text spans as candidate phrases and rank them as keyphrases (Hulth, 2003; Medelyan et al., 2008; Liu et al., 2011; Wu et al., 2015; Wang et al., 2016), that show promising results on the present keyphrases but cannot handle absent keyphrases. ∗ Corresponding Author To predict absent keyphrases, generative methods have been proposed by Meng et al. (2017). The approach employs a sequence-to-sequence (Seq2Seq) framework (Sutskever et al., 2014) with a copy mechanism (Gu et al., 2016) to encourage rare word generation, in which the encoder compresses the text into a dense vector and the decoder generates a phrase with a Recurrent Neural Network (RNN) language model, a"
D18-1439,S10-1004,0,0.708489,"rce code will be released at https://github.com/ nanfeng1101/s2s-kg. 4.2 Datasets Following Meng et al. (2017), we train our model on the KP20k dataset (Meng et al., 2017), which contains articles collected from various online digital libraries. The dataset has 527,830 articles for training and 20000 articles for validation. We evaluate our model on three benchmark datasets which are widely adopted in previous works, with the details described below: 4061 - NUS (Vijayakumar et al., 2016): It contains 211 papers with author-assigned keyphrases, all of which we use as test data. - Semeval-2010 (Kim et al., 2010): 288 articles are collected from the ACM Digital Library. 100 of them are used for test data and the rest are added to the training set. - Krapivin (Krapivin et al., 2008): This dataset contains 2304 papers. The first 400 papers in alphabetical order are used for evaluation and the rest are added to the training set. 4.3 Baseline Models We compare our model with extractive and generative approaches. The extractive baselines include Tf-idf, TextRank (Mihalcea and Tarau, 2004), SingleRank (Wan and Xiao, 2008), ExpandRank (Wan and Xiao, 2008), TopicRank1 (Bougouin et al., 2013), KEA (Witten et a"
D18-1439,W11-0316,0,0.847008,"ocument, organize contents and highlight important concepts, like ”virtual organizations” in Table 1. It provides readers with a rough understanding of a document without going through its content, and has many potential applications, such as information retrieval, text summarization and document classification. Keyphrase can be categorized into present keyphrase which appears in a source document, and absent keyphrase that does not appear in the document. Conventional approaches extract important text spans as candidate phrases and rank them as keyphrases (Hulth, 2003; Medelyan et al., 2008; Liu et al., 2011; Wu et al., 2015; Wang et al., 2016), that show promising results on the present keyphrases but cannot handle absent keyphrases. ∗ Corresponding Author To predict absent keyphrases, generative methods have been proposed by Meng et al. (2017). The approach employs a sequence-to-sequence (Seq2Seq) framework (Sutskever et al., 2014) with a copy mechanism (Gu et al., 2016) to encourage rare word generation, in which the encoder compresses the text into a dense vector and the decoder generates a phrase with a Recurrent Neural Network (RNN) language model, achieving stateof-the-art performance. Sin"
D18-1439,D10-1036,0,0.518236,"Missing"
D18-1439,D09-1027,0,0.881342,"extracting important n-grams (Hulth, 2003; Medelyan et al., 2008; Hulth, 2003; Shang et al., 2017) and selecting text chunks with certain postags (Liu et al., 2011; Wang et al., 2016; Le et al., 2016; Liu et al., 2015). The second phase is to rank the candidates with machine learning methods. Specifically, some researchers (Frank et al., 1999; Witten et al., 1999; Hulth, 2003; Medelyan et al., 2009; Gollapalli and Caragea, 2014) formulate the keyphrase extraction as a supervised classification problem, while others apply unsupervised approaches (Mihalcea and Tarau, 2004; Grineva et al., 2009; Liu et al., 2009, 2010; Zhang et al., 2013; Bougouin et al., 2013, 2016) on this task. Besides, Tomokiyo and Hurst (2003) employ two statistical language models to measure the informativeness for phrases. Liu et al. (2011) use a word alignment model to learn translation probabilities between the words in documents and the words in keyphrases, which alleviates the problem of vocabulary gaps. The latter group, generative methods, assigns keyphrases to a document with natural language generation techniques, and is capable of generating absent keyphrases. Owing to the development of neural networks (Bahdanau et a"
D18-1439,D09-1137,0,0.43814,"n based and generation based methods. The former group extracts important keyphrases in a document which consists of two phases. The first phase is to construct a set of phrase candidates with heuristic methods, such as extracting important n-grams (Hulth, 2003; Medelyan et al., 2008; Hulth, 2003; Shang et al., 2017) and selecting text chunks with certain postags (Liu et al., 2011; Wang et al., 2016; Le et al., 2016; Liu et al., 2015). The second phase is to rank the candidates with machine learning methods. Specifically, some researchers (Frank et al., 1999; Witten et al., 1999; Hulth, 2003; Medelyan et al., 2009; Gollapalli and Caragea, 2014) formulate the keyphrase extraction as a supervised classification problem, while others apply unsupervised approaches (Mihalcea and Tarau, 2004; Grineva et al., 2009; Liu et al., 2009, 2010; Zhang et al., 2013; Bougouin et al., 2013, 2016) on this task. Besides, Tomokiyo and Hurst (2003) employ two statistical language models to measure the informativeness for phrases. Liu et al. (2011) use a word alignment model to learn translation probabilities between the words in documents and the words in keyphrases, which alleviates the problem of vocabulary gaps. The lat"
D18-1439,P17-1099,0,0.106725,"generation techniques, and is capable of generating absent keyphrases. Owing to the development of neural networks (Bahdanau et al., 2014), Meng et al. (2017) apply an encoder-decoder framework (Sutskever et al., 2014) with a copy mechanism 4058 (Gu et al., 2016) to this task, achieving state-ofthe-art performance. Our work is a generation based approach. The main difference of our model is that we consider the correlation among keyphrases. Our model proposes a new review mechanism to enhance keyphrase diversity, while employs a coverage mechanism that has proven effective for summarization (See et al., 2017) and machine translation (Tu et al., 2016) to guarantee keyphrase coverage. Some previous works on keyword extraction have already exploited the correlation problem with a re-rank strategy (Habibi and Popescu-Belis, 2013; Ni et al., 2012). In contrast, we model the correlation in an end-to-end fashion. 3 KeyphraseGenerationwithCorrelation 3.1 Problem Formalization Suppose that we have a data set D = {xi , pi }N i=1 , where xi is a source text, pi = i {pi,j }M j=1 is the keyphrase set of xi , and N is the number of documents. Both the source text and target keyphrase are word sequences, donated"
D18-1439,W03-1805,0,0.320839,"7) and selecting text chunks with certain postags (Liu et al., 2011; Wang et al., 2016; Le et al., 2016; Liu et al., 2015). The second phase is to rank the candidates with machine learning methods. Specifically, some researchers (Frank et al., 1999; Witten et al., 1999; Hulth, 2003; Medelyan et al., 2009; Gollapalli and Caragea, 2014) formulate the keyphrase extraction as a supervised classification problem, while others apply unsupervised approaches (Mihalcea and Tarau, 2004; Grineva et al., 2009; Liu et al., 2009, 2010; Zhang et al., 2013; Bougouin et al., 2013, 2016) on this task. Besides, Tomokiyo and Hurst (2003) employ two statistical language models to measure the informativeness for phrases. Liu et al. (2011) use a word alignment model to learn translation probabilities between the words in documents and the words in keyphrases, which alleviates the problem of vocabulary gaps. The latter group, generative methods, assigns keyphrases to a document with natural language generation techniques, and is capable of generating absent keyphrases. Owing to the development of neural networks (Bahdanau et al., 2014), Meng et al. (2017) apply an encoder-decoder framework (Sutskever et al., 2014) with a copy mec"
D18-1439,P16-1008,0,0.456496,"stems” and ”multi agent”, the annotator will review the document and preceding keyphrases, then generate a phrase like ”norm conflict” to cover topics that have not been summarized by previous phrases. The iteration does not stop until all of a document’s topics are covered by keyphrases. We propose a new sequence-to-sequence architecture CorrRNN, capable of capturing correlation among keyphrases. Notably, correlation constraints in this paper are defined as keyphrases that should cover all topics in the source document and differ from each other. Specifically, we employ a coverage mechanism (Tu et al., 2016) to memorize which parts in the source document have been covered by previous phrases. In this way, the document coverage is modeled explicitly, enabling the generated keyphrases to cover more topics. Furthermore, we propose a review mechanism that considers the previous keyphrases in the generation process, in order to avoid the repetition in the final results. Concretely, the review mechanism explicitly models the correlation between the keyphrases that have been generated and the keyphrase that is going to be generated with a novel architecture. It extends the existing Seq2Seq model and cap"
D18-1439,I13-1002,0,0.0147108,"rams (Hulth, 2003; Medelyan et al., 2008; Hulth, 2003; Shang et al., 2017) and selecting text chunks with certain postags (Liu et al., 2011; Wang et al., 2016; Le et al., 2016; Liu et al., 2015). The second phase is to rank the candidates with machine learning methods. Specifically, some researchers (Frank et al., 1999; Witten et al., 1999; Hulth, 2003; Medelyan et al., 2009; Gollapalli and Caragea, 2014) formulate the keyphrase extraction as a supervised classification problem, while others apply unsupervised approaches (Mihalcea and Tarau, 2004; Grineva et al., 2009; Liu et al., 2009, 2010; Zhang et al., 2013; Bougouin et al., 2013, 2016) on this task. Besides, Tomokiyo and Hurst (2003) employ two statistical language models to measure the informativeness for phrases. Liu et al. (2011) use a word alignment model to learn translation probabilities between the words in documents and the words in keyphrases, which alleviates the problem of vocabulary gaps. The latter group, generative methods, assigns keyphrases to a document with natural language generation techniques, and is capable of generating absent keyphrases. Owing to the development of neural networks (Bahdanau et al., 2014), Meng et al. (20"
D18-1439,P17-1054,0,0.184564,"as information retrieval, text summarization and document classification. Keyphrase can be categorized into present keyphrase which appears in a source document, and absent keyphrase that does not appear in the document. Conventional approaches extract important text spans as candidate phrases and rank them as keyphrases (Hulth, 2003; Medelyan et al., 2008; Liu et al., 2011; Wu et al., 2015; Wang et al., 2016), that show promising results on the present keyphrases but cannot handle absent keyphrases. ∗ Corresponding Author To predict absent keyphrases, generative methods have been proposed by Meng et al. (2017). The approach employs a sequence-to-sequence (Seq2Seq) framework (Sutskever et al., 2014) with a copy mechanism (Gu et al., 2016) to encourage rare word generation, in which the encoder compresses the text into a dense vector and the decoder generates a phrase with a Recurrent Neural Network (RNN) language model, achieving stateof-the-art performance. Since a document corresponds to multiple keyphrases, the approach divides it into multiple document-keyphrase pairs as training instances. This approach, however, neglects the correlation among target keyphrases since it does not model the one-t"
D19-1197,W02-2211,0,0.0816066,"addition to model design, how to learn a generation model (Li et al., 2016c, 2017), and how to evaluate the models (Liu et al., 2016; Lowe et al., 2017; Tao et al., 2018), are drawing attention in the community of open domain dialogue generation. In this work, we study how to learn a response generation model from limited pairs, which breaks the assumption made by existing work. We propose response generation with paired and unpaired data. As far as we know, this is the first work on low-resource response generation for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores how to automatically mine templates from plain text and how to integrate the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and"
D19-1197,D14-1179,0,0.0369536,"Missing"
D19-1197,D17-1090,0,0.0272895,"airs, which breaks the assumption made by existing work. We propose response generation with paired and unpaired data. As far as we know, this is the first work on low-resource response generation for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores how to automatically mine templates from plain text and how to integrate the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/TobeyYang/S2S_Temp addition to structured templates, raw text retrieved from indexes is also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open"
D19-1197,W04-0601,0,0.0708975,"del design, how to learn a generation model (Li et al., 2016c, 2017), and how to evaluate the models (Liu et al., 2016; Lowe et al., 2017; Tao et al., 2018), are drawing attention in the community of open domain dialogue generation. In this work, we study how to learn a response generation model from limited pairs, which breaks the assumption made by existing work. We propose response generation with paired and unpaired data. As far as we know, this is the first work on low-resource response generation for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores how to automatically mine templates from plain text and how to integrate the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887"
D19-1197,W09-0613,0,0.0200496,"a generation model (Li et al., 2016c, 2017), and how to evaluate the models (Liu et al., 2016; Lowe et al., 2017; Tao et al., 2018), are drawing attention in the community of open domain dialogue generation. In this work, we study how to learn a response generation model from limited pairs, which breaks the assumption made by existing work. We propose response generation with paired and unpaired data. As far as we know, this is the first work on low-resource response generation for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores how to automatically mine templates from plain text and how to integrate the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/To"
D19-1197,N18-1032,0,0.0159977,"also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data th"
D19-1197,D18-1398,0,0.0245753,"also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data th"
D19-1197,Q18-1031,0,0.0468518,"te the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/TobeyYang/S2S_Temp addition to structured templates, raw text retrieved from indexes is also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), a"
D19-1197,N18-1093,0,0.073455,"asks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data through multitask learning (Zhang and Zong, 2016) or backtranslation (Sennri"
D19-1197,W18-3401,0,0.076381,"arious natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data through multitask learning (Zhang and Z"
D19-1197,D14-1181,0,0.00293569,"U hi + b), 1 n where v, b ∈ Rd2 , W, U ∈ Rd2 ×d2 are parameters. 4 Learning Approach Intuitively, we can estimate the parameters of the encoder-decoder and fine-tune the parameters of NHSMM by maximizing the likelihood of DP (i.e., MLE). However, since DP only contains a few pairs, the MLE approach may suffer from a dilemma: (1) if we stop training early, then both the template prior and the encoder-decoder are not X Si X log P (yi,t |yi,1:t−1 , Xi , Ti ). (3) (Xi ,Yi )∈DP t=1 Discriminator Update. The discriminator D is defined by a convolutional neural network (CNN) based binary classifier (Kim, 2014). D takes a message-response pair as input and outputs a score that indicates how likely the response is from humans. In the model, the message and the response are separately embedded as vectors by CNNs, and then the concatenation of the two vectors are fed to 1890 a 2-layer MLP to calculate the score. Let Yˆi be the response generated by G for Xi , then D is updated by maximizing the following objective: X log D(Xi , Yi ) + log(1 − D(Xi , Yˆi )) (Xi ,Yi )∈DP (4) Generator Update. The generator G is updated by the policy gradient method (Yu et al., 2017; Li et al., 2017). Let yˆ1:t be a parti"
D19-1197,P16-1094,0,0.142903,"e responses without any needs on rules, and have powered products in the industry such as Amazon Alexa (Ram et al., 2018) and Microsoft XiaoIce (Shum et al., 2018). State-of-the-art open domain response generation models are based on the encoder-decoder architecture (Vinyals and Le, 2015; Shang et al., 2015). On the one hand, with proper extensions to the vanilla structure, existing models now are able to naturally handle conversation contexts (Serban et al., 2016; Xing et al., 2018), and synthesize responses with various styles (Wang et al., 2017), emotions (Zhou et al., 2018), and personas (Li et al., 2016a). On the other hand, all the existing success of open domain response generation builds upon an assumption that the large scale of paired data (Shao et al., 2016) or conversation sessions (Sordoni et al., 2015) are available. In this work, we challenge this assumption by arguing that one cannot always obtain enough pairs or sessions for training a neural generation model. For example, although it has been indicated by existing work (Li et al., 2016b; Wang et al., 2018) that question asking in conversation can enhance user engagement, we find that in a public dataset1 with 5 million conversat"
D19-1197,D16-1127,0,0.261878,"e responses without any needs on rules, and have powered products in the industry such as Amazon Alexa (Ram et al., 2018) and Microsoft XiaoIce (Shum et al., 2018). State-of-the-art open domain response generation models are based on the encoder-decoder architecture (Vinyals and Le, 2015; Shang et al., 2015). On the one hand, with proper extensions to the vanilla structure, existing models now are able to naturally handle conversation contexts (Serban et al., 2016; Xing et al., 2018), and synthesize responses with various styles (Wang et al., 2017), emotions (Zhou et al., 2018), and personas (Li et al., 2016a). On the other hand, all the existing success of open domain response generation builds upon an assumption that the large scale of paired data (Shao et al., 2016) or conversation sessions (Sordoni et al., 2015) are available. In this work, we challenge this assumption by arguing that one cannot always obtain enough pairs or sessions for training a neural generation model. For example, although it has been indicated by existing work (Li et al., 2016b; Wang et al., 2018) that question asking in conversation can enhance user engagement, we find that in a public dataset1 with 5 million conversat"
D19-1197,D17-1230,0,0.0610089,"N) based binary classifier (Kim, 2014). D takes a message-response pair as input and outputs a score that indicates how likely the response is from humans. In the model, the message and the response are separately embedded as vectors by CNNs, and then the concatenation of the two vectors are fed to 1890 a 2-layer MLP to calculate the score. Let Yˆi be the response generated by G for Xi , then D is updated by maximizing the following objective: X log D(Xi , Yi ) + log(1 − D(Xi , Yˆi )) (Xi ,Yi )∈DP (4) Generator Update. The generator G is updated by the policy gradient method (Yu et al., 2017; Li et al., 2017). Let yˆ1:t be a partial response generated by G from beam search for message X until step t, then we adopt the Monte Carlo (MC) search method and sample N paths that supplement yˆ1:t as responses {Yˆi }N reward for i=1 . The intermediate 1 PN yˆ1:t is defined as Rt = N i=1 D(X, Yˆi ). The gradient for updating G is given by ∇J(θ) ≈ S X   ∇ log P (yˆt |ˆ y1:t−1 , X, T ) · Rt , t=1 (5) where θ represents the parameters of G, and T is a sampled template. To control the quality of MC search, we sample from top 50 most probable words at each step. The learning algorithm is summarized in Algorith"
D19-1197,D16-1230,0,0.0655554,"Missing"
D19-1197,P17-1103,0,0.0136973,"nslation, early work applies the sequence-to-sequence with attention model (Shang et al., 2015) to open domain response generation, and gets promising results. Later, the basic architecture is extended to suppress generic responses (Li et al., 2015; Zhao et al., 2017; Xing et al., 2017); to model the structure of conversation contexts (Serban et al., 2016); and to incorporate different types of knowledge into generation (Li et al., 2016a; Zhou et al., 2018). In addition to model design, how to learn a generation model (Li et al., 2016c, 2017), and how to evaluate the models (Liu et al., 2016; Lowe et al., 2017; Tao et al., 2018), are drawing attention in the community of open domain dialogue generation. In this work, we study how to learn a response generation model from limited pairs, which breaks the assumption made by existing work. We propose response generation with paired and unpaired data. As far as we know, this is the first work on low-resource response generation for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores"
D19-1197,P14-5010,0,0.00769277,"ed by softmax(W1 vjt + b1 ), where W1 ∈ RV ×d2 and b1 ∈ Rd2 are parameters with V the vacabulary size. Following Murphy (2002), the marginal distribution of Y can be obtained by the backward algorithm which is formulated as βt (i) , P (yt+1:S |qt = i) = K X βt∗ (j)A(i, j) j=1 βt∗ (j) , P (yt+1:S |qt+1 = j) D h i X = βt+d (j)P (d|j)P (yt+1:t+d |j, d) d=1 P (Y ) = K X β0∗ (j)P (q1 = j). j=1 (2) where qt is the hidden state of the t-th word in Y , and the base cases βS (i) = 1, ∀i ∈ {1, . . . , K}. Specifically, to learn more reasonable segmentations, we parsed every sentence by stanford parser (Manning et al., 2014) and forced NHSMM not to break syntactic elements such as VP and NP, etc. The parameters of the NHSMM are estimated by maximizing the log-likelihood of DU through backpropagation. 3.3 Response Generation with Template Prior We propose incorporating the templates parameterized by the NHSMM learned from DU into response generation as prior. Figure 1 illustrates the architecture of the generation model. In a nutshell, the model first samples a chain of states with duration as a template. The template specifies a segmentation of the response to generate. Then, the hidden representations of the seg"
D19-1197,P18-1123,0,0.0203065,"nto neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/TobeyYang/S2S_Temp addition to structured templates, raw text retrieved from indexes is also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recog"
D19-1197,P02-1040,0,0.103659,"Missing"
D19-1197,N19-1263,0,0.0386244,"erpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/TobeyYang/S2S_Temp addition to structured templates, raw text retrieved from indexes is also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskorie"
D19-1197,K18-1003,0,0.0246446,"rage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource problem, and the generation model is learned by an adversarial approach rather than by maximum likelihood estimation. Before us, the low-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data through multitask learning (Zhang and Zong, 2016) or backtranslation (Sennrich et al., 2015), we extract linguistic knowledge from the data as latent templates and use the templates"
D19-1197,P16-1009,0,0.092815,"Missing"
D19-1197,P15-1152,0,0.0762441,"Missing"
D19-1197,D13-1170,0,0.00714242,"Missing"
D19-1197,N15-1020,0,0.0669518,"Missing"
D19-1197,D17-1228,0,0.0378154,"Missing"
D19-1197,P18-1204,0,0.303312,"ntax of the unpaired data and then are used as prior in an encoder-decoder architecture for modeling the paired data. With the latent templates, the whole model is end-to-end learnable and can perform response generation in an explainable manner. To ensure the relevance of responses regarding input messages and at the same time make full use of the templates, we propose learning the generation model with an adversarial approach. Empirical studies are conducted on two tasks: question response generation and sentiment response generation. For the first task, we exploit the dataset published in (Wang et al., 2018) and augment the data with questions crawled from Zhihu4 . For the second task, we build a paired dataset from Twitter by filtering responses with an off-theshelf sentiment classifier and augment the dataset with tweets in positive sentiment extracted from a large scale tweet dataset published in (Cheng et al., 2010). Evaluation results on both auto3 The study in this work starts from response generation for single messages. One can easily extend the proposed approach to handle conversation history. 4 https://en.wikipedia.org/wiki/Zhihu matic metrics and human judgment indicate that with limit"
D19-1197,D18-1356,0,0.165961,"for open domain dialogue systems. Traditional template-based text generation (Becker, 2002; Foster and White, 2004; Gatt and Reiter, 2009) relies on handcrafted templates that are expensive to obtain. Recently, some work explores how to automatically mine templates from plain text and how to integrate the templates into neural architectures to enhance interpretability of generation. Along this line, Duan et al. (2017) mine patterns from related questions in community QA websites and leverage the patterns with a retrieval-based approach and a generation-based approach for question generation. Wiseman et al. (2018) exploit a hidden semi-markov model for joint template extraction and text generation. In 1887 5 https://github.com/TobeyYang/S2S_Temp addition to structured templates, raw text retrieved from indexes is also used as “soft templates” in various natural language generation tasks (Guu et al., 2018; Pandey et al., 2018; Cao et al., 2018; Peng et al., 2019). In this work, we leverage templates for open domain response generation. Our idea is inspired by (Wiseman et al., 2018), but latent templates estimated from one source are transferred to another source in order to handle the low-resource probl"
D19-1197,D16-1160,0,0.0298367,"ow-resource problem has been studied in tasks such as machine translation (Gu et al., 2018b,a), pos tagging (Kann et al., 2018), word embedding (Jiang et al., 2018), automatic speech recognition (T¨uske et al., 2014), taskoriented dialogue systems (Tran and Nguyen, 2018; Mi et al., 2019), etc. In this work, we pay attention to low-resource open domain response generation which is untouched by existing work. We propose attacking the problem with unpaired data, which is related to the effort in low-resource machine translation with monolingual data (Gulcehre et al., 2015; Sennrich et al., 2015; Zhang and Zong, 2016). Our method is unique in that rather than using the unpaired data through multitask learning (Zhang and Zong, 2016) or backtranslation (Sennrich et al., 2015), we extract linguistic knowledge from the data as latent templates and use the templates as prior in generation. 3 Low-Resource Response Generation In this section, we first formalize the setting upon which we study low-resource response generation and then elaborate the model of response generation with paired and unpaired data, including how to learn latent templates from the unpaired data, and how to perform generation with the templ"
D19-1356,Q13-1023,0,0.0519926,"Missing"
D19-1356,P18-1068,0,0.292847,"djective-Noun Phrasing Knowledge for Comparison Relation Prediction in Text-to-SQL Haoyan Liu1∗, Lei Fang2 , Qian Liu3 , Bei Chen2 , Jian-Guang Lou2 , Zhoujun Li1 1 State Key Lab of Software Development Environment, Beihang University, China 2 Microsoft Research, Beijing, China 3 State Key Lab of Virtual Reality Technology and Systems, Beihang University, China {haoyan.liu, qian.liu, lizj}@buaa.edu.cn; {leifa, beichen, jlou}@microsoft.com Abstract in ORDER BY expression). In most text-to-SQL models, the comparison relations are either generated using Seq2Seq architectures (Zhong et al., 2017; Dong and Lapata, 2018), or predicted using classifiers trained with output decoding features (Xu et al., 2017; Yu et al., 2018b). We give an example to show that external common knowledge is indispensable to truly understand the comparison relations on unseen data. One key component in text-to-SQL is to predict the comparison relations between columns and their values. To the best of our knowledge, no existing models explicitly introduce external common knowledge to address this problem, thus their capabilities of predicting comparison relations are limited beyond training data. In this paper, we propose to leverag"
D19-1356,P18-1033,0,0.0608135,"t al., 2017), which aims at mapping natural language to SQL queries, is one of the most important tasks in natural language processing. Most stateof-the-art models are end-to-end neural network based models (Zhang et al., 2017; Xu et al., 2017; Yu et al., 2018a; Herzig and Berant, 2018; Dong and Lapata, 2018; Yu et al., 2018b), which mainly extend the Seq2Seq architecture with some complicated network structures. As shown by Yu et al. (2018b), the performances of most methods are overstated, because they just match semantic parsing results, rather than truly understand the meanings of inputs (Finegan-Dollak et al., 2018). In this paper, we study the comparison relation prediction problem, as the comparison relations between columns and their values are not well understood by existing methods. In SQL queries, comparison relations are expressed by the comparison operators (=, 6=, <, ≤ , &gt;, ≥) and value ordering keywords (ASC, DESC ∗ This work was done when the first author was an intern at Microsoft Research Asia. Table 1 shows the basic information about the athletes of the 100-meter sprint. Given the query “what is the name of the oldest player ?”, the goal is to generate the SQL “SELECT name FROM players ORD"
D19-1356,D18-1190,0,0.0135365,"lit Spider dataset show that our approach achieves significant improvement over state-of-the-art methods on comparison relation prediction. 1 rank 1 2 3 name Martina Mirjana Justine time 110 9 120 5 120 9 birth date 19800930 19820309 19820601 Table 1: Player Basic Information. Introduction Text-to-SQL (Yaghmazadeh et al., 2017; Zhong et al., 2017), which aims at mapping natural language to SQL queries, is one of the most important tasks in natural language processing. Most stateof-the-art models are end-to-end neural network based models (Zhang et al., 2017; Xu et al., 2017; Yu et al., 2018a; Herzig and Berant, 2018; Dong and Lapata, 2018; Yu et al., 2018b), which mainly extend the Seq2Seq architecture with some complicated network structures. As shown by Yu et al. (2018b), the performances of most methods are overstated, because they just match semantic parsing results, rather than truly understand the meanings of inputs (Finegan-Dollak et al., 2018). In this paper, we study the comparison relation prediction problem, as the comparison relations between columns and their values are not well understood by existing methods. In SQL queries, comparison relations are expressed by the comparison operators (=,"
D19-1356,N18-2093,0,0.346094,"an Liu3 , Bei Chen2 , Jian-Guang Lou2 , Zhoujun Li1 1 State Key Lab of Software Development Environment, Beihang University, China 2 Microsoft Research, Beijing, China 3 State Key Lab of Virtual Reality Technology and Systems, Beihang University, China {haoyan.liu, qian.liu, lizj}@buaa.edu.cn; {leifa, beichen, jlou}@microsoft.com Abstract in ORDER BY expression). In most text-to-SQL models, the comparison relations are either generated using Seq2Seq architectures (Zhong et al., 2017; Dong and Lapata, 2018), or predicted using classifiers trained with output decoding features (Xu et al., 2017; Yu et al., 2018b). We give an example to show that external common knowledge is indispensable to truly understand the comparison relations on unseen data. One key component in text-to-SQL is to predict the comparison relations between columns and their values. To the best of our knowledge, no existing models explicitly introduce external common knowledge to address this problem, thus their capabilities of predicting comparison relations are limited beyond training data. In this paper, we propose to leverage adjective-noun phrasing knowledge mined from the web to predict the comparison relations in text-to-SQ"
D19-1356,D18-1193,0,0.262593,"an Liu3 , Bei Chen2 , Jian-Guang Lou2 , Zhoujun Li1 1 State Key Lab of Software Development Environment, Beihang University, China 2 Microsoft Research, Beijing, China 3 State Key Lab of Virtual Reality Technology and Systems, Beihang University, China {haoyan.liu, qian.liu, lizj}@buaa.edu.cn; {leifa, beichen, jlou}@microsoft.com Abstract in ORDER BY expression). In most text-to-SQL models, the comparison relations are either generated using Seq2Seq architectures (Zhong et al., 2017; Dong and Lapata, 2018), or predicted using classifiers trained with output decoding features (Xu et al., 2017; Yu et al., 2018b). We give an example to show that external common knowledge is indispensable to truly understand the comparison relations on unseen data. One key component in text-to-SQL is to predict the comparison relations between columns and their values. To the best of our knowledge, no existing models explicitly introduce external common knowledge to address this problem, thus their capabilities of predicting comparison relations are limited beyond training data. In this paper, we propose to leverage adjective-noun phrasing knowledge mined from the web to predict the comparison relations in text-to-SQ"
D19-1356,D18-1425,0,0.0860392,"Missing"
D19-1356,D17-1125,0,0.0142196,"Experimental results on both the original and the re-split Spider dataset show that our approach achieves significant improvement over state-of-the-art methods on comparison relation prediction. 1 rank 1 2 3 name Martina Mirjana Justine time 110 9 120 5 120 9 birth date 19800930 19820309 19820601 Table 1: Player Basic Information. Introduction Text-to-SQL (Yaghmazadeh et al., 2017; Zhong et al., 2017), which aims at mapping natural language to SQL queries, is one of the most important tasks in natural language processing. Most stateof-the-art models are end-to-end neural network based models (Zhang et al., 2017; Xu et al., 2017; Yu et al., 2018a; Herzig and Berant, 2018; Dong and Lapata, 2018; Yu et al., 2018b), which mainly extend the Seq2Seq architecture with some complicated network structures. As shown by Yu et al. (2018b), the performances of most methods are overstated, because they just match semantic parsing results, rather than truly understand the meanings of inputs (Finegan-Dollak et al., 2018). In this paper, we study the comparison relation prediction problem, as the comparison relations between columns and their values are not well understood by existing methods. In SQL queries, compar"
D19-1356,E14-4023,0,0.0171182,"ueries containing “old” in the training data, it’s easy for the trained models to remember that “old” means selecting a large value from column age. But if birth date is unseen in the training data, there is little chance to predict the comparison relation correctly without the common knowledge that “age” and “birth date” both represent age but have opposite value polarities. Similarly, for query “fast runner”, models should select a large value from column speed or a small value from column time. There are some related works that address the intensity of adjectives (De Melo and Bansal, 2013; Ruppenhofer et al., 2014; Sharma et al., 2017), however, 3515 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3515–3520, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics no existing work studies the relations between the value polarities of adjective-noun phrasing pairs. In this paper, we propose to explicitly incorporate the column value polarities as external knowledge in text-to-SQL models. Our goal is to scale the capabilities of existing models on compariso"
D19-1356,D17-1058,0,0.0127603,"the training data, it’s easy for the trained models to remember that “old” means selecting a large value from column age. But if birth date is unseen in the training data, there is little chance to predict the comparison relation correctly without the common knowledge that “age” and “birth date” both represent age but have opposite value polarities. Similarly, for query “fast runner”, models should select a large value from column speed or a small value from column time. There are some related works that address the intensity of adjectives (De Melo and Bansal, 2013; Ruppenhofer et al., 2014; Sharma et al., 2017), however, 3515 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3515–3520, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics no existing work studies the relations between the value polarities of adjective-noun phrasing pairs. In this paper, we propose to explicitly incorporate the column value polarities as external knowledge in text-to-SQL models. Our goal is to scale the capabilities of existing models on comparison relation prediction"
D19-1365,P19-1602,1,0.80732,"which is slightly different with the classic Transformer (Vaswani et al., 2017). Formally, the output of the attention layer is1 Related Work In the past few years, style-transfer generation has attracted increasing attention in NLP research. Early work transfers between modern English and the Shakespeare style with a phrase-based machine translation system (Xu et al., 2012). Recently, style transfer is more recognized as a controllable text generation problem (Hu et al., 2017), where the style may be designated as sentiment (Fu et al., 2018), tense (Hu et al., 2017), or even general syntax (Bao et al., 2019; Chen et al., 2019). In the above approaches, the training sentences are labeled with style information, but no parallel data are given. Xu et al. (2019a) take one step further and capture the most salient style by detecting global variance in a purely unsupervised manner (i.e., style labels are unknown). Formality style transfer is mostly driven by the GYAFC parallel corpus. Since a parallel corpus, softmax Q[Kenc ; Kdec ]T  √ [Venc ; Vdec ] dk (1) where Q, K, and V are defined the same as the scaled dot-product attention in Transformer, and dk is a scaling factor. [; ] is a concatenation o"
D19-1365,P11-1020,0,0.103436,"Missing"
D19-1365,P19-1599,0,0.031329,"different with the classic Transformer (Vaswani et al., 2017). Formally, the output of the attention layer is1 Related Work In the past few years, style-transfer generation has attracted increasing attention in NLP research. Early work transfers between modern English and the Shakespeare style with a phrase-based machine translation system (Xu et al., 2012). Recently, style transfer is more recognized as a controllable text generation problem (Hu et al., 2017), where the style may be designated as sentiment (Fu et al., 2018), tense (Hu et al., 2017), or even general syntax (Bao et al., 2019; Chen et al., 2019). In the above approaches, the training sentences are labeled with style information, but no parallel data are given. Xu et al. (2019a) take one step further and capture the most salient style by detecting global variance in a purely unsupervised manner (i.e., style labels are unknown). Formality style transfer is mostly driven by the GYAFC parallel corpus. Since a parallel corpus, softmax Q[Kenc ; Kdec ]T  √ [Venc ; Vdec ] dk (1) where Q, K, and V are defined the same as the scaled dot-product attention in Transformer, and dk is a scaling factor. [; ] is a concatenation operation; it enables"
D19-1365,N19-1423,0,0.0455954,"Missing"
D19-1365,C18-1086,0,0.338747,"Missing"
D19-1365,P02-1040,0,0.105484,"Missing"
D19-1365,N18-1012,0,0.223545,"we study how to harness rules into a stateof-the-art neural network that is typically pretrained on massive corpora. We propose three fine-tuning methods in this paper and achieve a new state-of-the-art on benchmark datasets. 1 Table 1: Example of informal sentence and the output of a rule-based system. Introduction Text formality research is essential for a wide range of NLP applications, such as non-native speaker assistants and child education. Due to the progress of deep learning techniques, researchers make a step from formality understanding to formality-aware text generation. Recently, Rao and Tetreault (2018) published a dataset, the Grammarly’s Yahoo Answers Formality Corpus (GYAFC), serving as a benchmark testbed for formality style transfer, which aims to generate a formal sentence given an informal one, while keeping its semantic meaning. Since the GYAFC dataset is small, existing studies have realized the importance of rules as a preprocessing step of informal text, typically handling capitalization (e.g., “ARE YOU KIDDING ME?”), character repetition (e.g., “noooo”), slang words (e.g., “wanna”), etc. While rule-based preprocessing could largely simplify the formality ∗ Corresponding author. O"
D19-1365,W16-2323,0,0.0343901,"a performance slightly lower than (but similar to) Rao and Tetreault (2018). NMT-Baseline: An RNN-based Seq2Seq model with the attention mechanism (Bahdanau et al., 2015) is trained to predict formal texts, given rule-preproccessed informal text. PBMT-Combined: Similar to NMT, this baseline trains a traditional phrase-based machine translation (PBMT) system, also taking the preprocessed text as input. Then, self-training (Ueff3575 2 https://github.com/openai/gpt-2 ing, 2006) is applied with an unlabeled in-domain dataset for further improvement. NMT-Combined: This method uses backtranslation (Sennrich et al., 2016) with the PBMTCombined system to synthesize a pseudo-parallel corpora. Then a Seq2Seq model is trained on the combination of the pseudo-parallel and parallel corpora. Note that the above baselines are reported by Rao and Tetreault (2018). Transformer-Combined: This setting in Xu et al. (2019b) is the same as NMT-Combined, except that it employs Transformer (Vaswani et al., 2017) as the encoder and decoder. JTHTA: Xu et al. (2019b) propose a bidirectional framework that can transfer formality from formal to informal or from informal to formal with one single encoder-decoder component. They join"
D19-1365,C12-1177,0,0.545559,"ialize them with the pretrained GPT-2 parameters (Radford et al., 2019). The architecture of a decoder GPT block performs attention to the context words and previous words with the same multi-head attention layer, illustrated in Figure 1, which is slightly different with the classic Transformer (Vaswani et al., 2017). Formally, the output of the attention layer is1 Related Work In the past few years, style-transfer generation has attracted increasing attention in NLP research. Early work transfers between modern English and the Shakespeare style with a phrase-based machine translation system (Xu et al., 2012). Recently, style transfer is more recognized as a controllable text generation problem (Hu et al., 2017), where the style may be designated as sentiment (Fu et al., 2018), tense (Hu et al., 2017), or even general syntax (Bao et al., 2019; Chen et al., 2019). In the above approaches, the training sentences are labeled with style information, but no parallel data are given. Xu et al. (2019a) take one step further and capture the most salient style by detecting global variance in a purely unsupervised manner (i.e., style labels are unknown). Formality style transfer is mostly driven by the GYAFC"
D19-1512,W18-5105,0,0.026626,"Missing"
D19-1512,W05-0909,0,0.132118,"t-TC, top 1 comment from beam search (beam size=5) is returned. GANN: the gated attention neural network proposed in (Zheng et al., 2018). The model is further improved by a generative adversarial net. We denote our model as “DeepCom” standing for “deep commenter”, as it is featured by a deep reading-commenting architecture. All baselines are implemented according to the details in the related papers and tuned on the validation sets. performance of different models with both automatic metrics and human judgment. In terms of automatic evaluation, we employ BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), ROUGE (Lin, 2004), and CIDEr (Vedantam et al., 2015) as metrics on both data. Besides these metrics, Qin et al. (2018) propose human score weighted metrics including W-BLEU, WMETEOR, W-ROUGE and W-CIDEr. These metrics, however, requires human judgment on each comment in the test set. Thus, we only involve results w.r.t. these metrics in Tencent data. As Qin et al. (2018) do not publish their code for metric calculation, we employ a popular NLG evaluation project available at https://github.com/ Maluuba/nlg-eval, and modify the scripts with the scores provided in the data according to the for"
D19-1512,P17-1171,0,0.0176652,"ws articles before generation and perform endto-end learning that can jointly optimize the comprehension model and the generation model. Our model is partially inspired by the recent success of machine reading comprehension (MRC), whose prosperity can be attributed to an increase of publicly available large scale annotated datasets, such as SQuAD (Rajpurkar et al., 2016, 2018) and MS Marco (Nguyen et al., 2016) etc. A great number of models have been proposed to tackle the MRC challenges, including BiDAF (Seo et al., 2016), r-net (Wang et al., 2017), DCN (Xiong et al., 2016), Document Reader (Chen and Bordes, 2017), QANet (Yu et al., 2018), and s-net (Tan et al., 2018) etc. Our work can be viewed as an application of MRC to a new NLG task. The task aims to generate a comment for a news article, which is different from existing MRC tasks whose goal is to answer a question. Our learning method is also different from those in the MRC works. 3 3.1 Approach Problem Formalization Suppose we have a dataset D = {(Ti , Bi , Ci )}N i=1 , where the i-th triple (Ti , Bi , Ci ) consists of a news title Ti , a news body Bi , and a comment Ci . Our goal is to estimate a probability distribution P (C|T, B) from D, and"
D19-1512,W14-4012,0,0.0860529,"Missing"
D19-1512,E17-1059,0,0.0221742,"ree-folds: (1) proposal of “read-attend-comment” procedure for news comment generation with a reading network and a generation network; (2) joint optimization of the two networks with an end-to-end learning approach; and (3) empirical verification of the effectiveness of the proposed model on two datasets. 2 Related Work News comment generation is a sub-task of natural language generation (NLG). Among various NLG tasks, the task studied in this paper is most related to summarization (Rush et al., 2015; Nallapati et al., 2016; See et al., 2017) and product review generation (Tang et al., 2016; Dong et al., 2017). However, there is stark difference between news comment generation and the other two tasks: the input of our task is an unstructured document, while the input of product review generation is structured attributes of a product; and the output of our task is a comment which often extends the content of the input with additional information, while the output of summarization is a condensed version of the input that contains the main information from the original. Very recently, there 1 https://www.yahoo.com/news/ fifa-rankings-france-number-one-112047790. emerge some studies on news comment gen"
D19-1512,P14-5010,0,0.00242161,"ria presented in Table 3. All text in the data is tokenized by a Chinese word segmenter Jieba (https: //github.com/fxsjy/jieba). The average lengths of news titles, news bodies, and comments are 15 words, 554 words and 17 words respectively. In addition to the Chinese data, we also build another dataset by crawling news articles and the associated comments from Yahoo! News. Besides upvotes and categories, side information in Yahoo data also includes paragraph marks, WIKI-entities, downvotes, abusevotes, and sentiment tagged by Yahoo!. Text in the data is tokenized by Stanford CoreNLP pipline (Manning et al., 2014). As pre-processing, we filter out news articles shorter than 30 words in the body and comments shorter than 10 words or longer than 100 words. Then, we remove news articles with less than 5 comments. If the number of comments of an article exceeds 30, we only keep top 30 comments with the most upvotes. On average, news titles, news bodies, and comments contain 12 words, 578 words and 32 words respectively. More information about Yahoo data can be found in Appendix A. After the pre-processing, we randomly sample a training set, a validation set, and a test set from the remaining data, and make"
D19-1512,P02-1040,0,0.110304,"Att-TC). In Seq2seq, Att, and Att-TC, top 1 comment from beam search (beam size=5) is returned. GANN: the gated attention neural network proposed in (Zheng et al., 2018). The model is further improved by a generative adversarial net. We denote our model as “DeepCom” standing for “deep commenter”, as it is featured by a deep reading-commenting architecture. All baselines are implemented according to the details in the related papers and tuned on the validation sets. performance of different models with both automatic metrics and human judgment. In terms of automatic evaluation, we employ BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), ROUGE (Lin, 2004), and CIDEr (Vedantam et al., 2015) as metrics on both data. Besides these metrics, Qin et al. (2018) propose human score weighted metrics including W-BLEU, WMETEOR, W-ROUGE and W-CIDEr. These metrics, however, requires human judgment on each comment in the test set. Thus, we only involve results w.r.t. these metrics in Tencent data. As Qin et al. (2018) do not publish their code for metric calculation, we employ a popular NLG evaluation project available at https://github.com/ Maluuba/nlg-eval, and modify the scripts with the scores provid"
D19-1512,P18-2124,0,0.025649,"Missing"
D19-1512,D16-1264,0,0.0273879,"rate news comments from news titles. The model is further improved by a generative adversarial net. Qin et al. (2018) publish a dataset with results of some basic models. Different from all the existing methods, we attempt to comprehend the entire news articles before generation and perform endto-end learning that can jointly optimize the comprehension model and the generation model. Our model is partially inspired by the recent success of machine reading comprehension (MRC), whose prosperity can be attributed to an increase of publicly available large scale annotated datasets, such as SQuAD (Rajpurkar et al., 2016, 2018) and MS Marco (Nguyen et al., 2016) etc. A great number of models have been proposed to tackle the MRC challenges, including BiDAF (Seo et al., 2016), r-net (Wang et al., 2017), DCN (Xiong et al., 2016), Document Reader (Chen and Bordes, 2017), QANet (Yu et al., 2018), and s-net (Tan et al., 2018) etc. Our work can be viewed as an application of MRC to a new NLG task. The task aims to generate a comment for a news article, which is different from existing MRC tasks whose goal is to answer a question. Our learning method is also different from those in the MRC works. 3 3.1 Approach Probl"
D19-1512,D15-1044,0,0.10392,"Missing"
D19-1512,P17-1099,0,0.0326474,"both automatic metrics and human judgment. Our contributions are three-folds: (1) proposal of “read-attend-comment” procedure for news comment generation with a reading network and a generation network; (2) joint optimization of the two networks with an end-to-end learning approach; and (3) empirical verification of the effectiveness of the proposed model on two datasets. 2 Related Work News comment generation is a sub-task of natural language generation (NLG). Among various NLG tasks, the task studied in this paper is most related to summarization (Rush et al., 2015; Nallapati et al., 2016; See et al., 2017) and product review generation (Tang et al., 2016; Dong et al., 2017). However, there is stark difference between news comment generation and the other two tasks: the input of our task is an unstructured document, while the input of product review generation is structured attributes of a product; and the output of our task is a comment which often extends the content of the input with additional information, while the output of summarization is a condensed version of the input that contains the main information from the original. Very recently, there 1 https://www.yahoo.com/news/ fifa-rankings"
D19-1512,P17-1018,0,0.0244754,"ll the existing methods, we attempt to comprehend the entire news articles before generation and perform endto-end learning that can jointly optimize the comprehension model and the generation model. Our model is partially inspired by the recent success of machine reading comprehension (MRC), whose prosperity can be attributed to an increase of publicly available large scale annotated datasets, such as SQuAD (Rajpurkar et al., 2016, 2018) and MS Marco (Nguyen et al., 2016) etc. A great number of models have been proposed to tackle the MRC challenges, including BiDAF (Seo et al., 2016), r-net (Wang et al., 2017), DCN (Xiong et al., 2016), Document Reader (Chen and Bordes, 2017), QANet (Yu et al., 2018), and s-net (Tan et al., 2018) etc. Our work can be viewed as an application of MRC to a new NLG task. The task aims to generate a comment for a news article, which is different from existing MRC tasks whose goal is to answer a question. Our learning method is also different from those in the MRC works. 3 3.1 Approach Problem Formalization Suppose we have a dataset D = {(Ti , Bi , Ci )}N i=1 , where the i-th triple (Ti , Bi , Ci ) consists of a news title Ti , a news body Bi , and a comment Ci . Our goa"
I08-4001,2007.mtsummit-papers.14,1,0.77163,"an be formed by merging two adjacent links gradually, we call the region is independent, and the corresponding block is also independent. In our system, the word alignment must satisfy the ITG constraint, i.e. the word alignment is able to form a binary branching tree. Figure 1(b) illustrates a word alignment example; the number below the word is the position index. In the example, the region (1..3, 3..5) is independent, and the block (最近 的 赌场，the nearest cassino) is also independent. In order to obtain the word alignment satisfying the ITG constraint, Wu(1997) propose a DP algorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a loglinear word alignment model (Moore, 2005). After obtaining the word-aligned corpus, in which each word alignment satisfy the ITG constraint, we can extract the blocks in a straightforward way. For the word alignment forms a hierarchical binary tree, we choose each constituent as a block. Each block is formed by combining one or more links, and must be independent. Considering the data sparseness, we limit the length of each block"
I08-4001,P05-1033,0,0.0321426,"glish. For the spoken language translation, the reordering problem will be more crucial, since the spoken language is more flexible in word order. In addition, lots of omissions and idioms make the translation more difficult. However, there exists some &quot;useful&quot; features, such as, most of the spoken text is shorter than the written text and there are some fixed translation 1 Yue-Xin Chen National Laboratory for Parallel and Distributed Processing, Changsha, China structures. For example, ( 你能…? / Would you please … ? ), (能…?/May I…?). We can learn these fixed structures and take them as rules, Chiang (2005) presents a method to learn these rules, and uses them in the SMT. Generally, the number of these rules will be very large. In this paper, we propose an example-based decoder in a SMT model, which will use the translation examples to keep the translation structure, i.e. constraint the reordering, and make the omitted words having the chance to be translated. The rest of this paper is organized as follows: Since our decoder is based on the inversion transduction grammars (ITG) (Wu, 1997), we introduce the ITG in Section 2 and describe the derived SMT model. In Section 3, we design the example-b"
I08-4001,W05-0833,0,0.0333934,"Missing"
I08-4001,H05-1011,0,0.012518,"word alignment is able to form a binary branching tree. Figure 1(b) illustrates a word alignment example; the number below the word is the position index. In the example, the region (1..3, 3..5) is independent, and the block (最近 的 赌场，the nearest cassino) is also independent. In order to obtain the word alignment satisfying the ITG constraint, Wu(1997) propose a DP algorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a loglinear word alignment model (Moore, 2005). After obtaining the word-aligned corpus, in which each word alignment satisfy the ITG constraint, we can extract the blocks in a straightforward way. For the word alignment forms a hierarchical binary tree, we choose each constituent as a block. Each block is formed by combining one or more links, and must be independent. Considering the data sparseness, we limit the length of each block as N (here N=3~5). We can also collect the reordering information between two blocks according to the orientation of the branches. Thus, we will build the translation models P (e |c) , P (c |e) , Plex (e |c)"
I08-4001,P02-1038,0,0.104045,"Missing"
I08-4001,J03-1002,0,0.00222421,"urn BEST_N(complete_templates); 28: End Figure 5. The decoding algorithm. Considering the size of the training corpus is relatively small, and the words in Chinese have no morphological changes, we stemmed the words in the English sentences. Table 1 shows the statistics for the training corpus, development set and test set. In order to compare with the other SMT systems, we choose the Moses 1 , which is an extension to the state-of-the-art SMT system Pharaoh (Koehn, 2004). We use the default tool in the Moses to train the model and tune the weights, in which the word alignment tool is Giza++ (Och and Ney 2003) and the language model tool is SRILM(Stolcke, 2002). The test results are showed in Table2. The first column lists the different MT systems, and the second column lists the Bleu scores (Papineni et. al, 2002) for the four decoders. The first system is the Moses, and the second is our SMT system described in section 2, which using a CKY-style decoder. We take them as baseline systems. The third is the hybrid system but 1 7 AddTemplate_Complete(templateA,I); Else http://www.statmt.org/moses/. Sixth SIGHAN Workshop on Chinese Language Processing only using the fast retrieval module and the fourt"
I08-4001,2003.mtsummit-papers.54,0,0.0337685,"lt from the Moses, we think that maybe the size of the training corpus is too small, so that the word alignment obtained by Giza++ is poor. The results show that the example-based decoder achieves an improvement over the baseline decoders. Decoder Bleu Moses 22.61 SMT-CKY 28.33 Hybrid MT with fast retrieval 30.03 Hybrid MT with refined retrieval 33.05 Table 2. Test results for several systems. 5 Related works There is some works about the hybrid machine translation. One way is to merge EBMT and SMT resources, such as Groves and Way (2005). Another way is to implement an exmaple-based decoder, Watanabe and Sumita (2003) presents an example-based decoder, which using a information retrieval framework to retrieve the examples; and when decoding, which runs a hill-climbing algorithm to modify the translation example ( Ck, Ek, Ak) to obtain an alignment ( C0, E&apos;k, A&apos;k). 6 Conclusions In this paper, we proposed a SMT system with an example-based decoder for the spoken language machine translation. This approach will take advantage of the constituent tree within the translation examples to constrain the flexible word reordering in the spoken language, and it will also make the omitted words have the chance to be t"
I08-4001,J97-3002,0,0.0161447,"能…? / Would you please … ? ), (能…?/May I…?). We can learn these fixed structures and take them as rules, Chiang (2005) presents a method to learn these rules, and uses them in the SMT. Generally, the number of these rules will be very large. In this paper, we propose an example-based decoder in a SMT model, which will use the translation examples to keep the translation structure, i.e. constraint the reordering, and make the omitted words having the chance to be translated. The rest of this paper is organized as follows: Since our decoder is based on the inversion transduction grammars (ITG) (Wu, 1997), we introduce the ITG in Section 2 and describe the derived SMT model. In Section 3, we design the example-based decoder. In Section 4, we test our model and compare it with the baseline system. Then, we conclude in Section 5 and Section 6. 2 The SMT model ITG is a synchronous context-free grammar, which generates two output streams simultaneously. It consists of the following five types of rules: p A ⎯⎯→[ AA] |&lt; AA &gt; |ci / e j |ci / ε |ε / e j (1) Where A is the non-terminal symbol, [] and &lt;&gt; represent the two operations which generate outputs in straight and inverted orientation respectivel"
I08-4001,koen-2004-pharaoh,0,\N,Missing
I08-4001,P02-1040,0,\N,Missing
J19-1005,D14-1179,0,0.00774847,"Missing"
J19-1005,N16-1108,0,0.0585039,"Missing"
J19-1005,C14-1088,0,0.024067,"ry and recent progress of chatbots, and application of text matching techniques in other tasks. Together with the review of existing work, we clarify the connection and difference between these works and our work in this article. 2.1 Chatbots Research on chatbots goes back to the 1960s when ELIZA (Weizenbaum 1966), an early chatbot, was designed with a large number of handcrafted templates and heuristic rules. 167 Computational Linguistics Volume 45, Number 1 ELIZA needs huge human effort but can only return limited responses. To remedy this, researchers have developed data-driven approaches (Higashinaka et al. 2014). The idea behind data-driven approaches is to build a chatbot with the large amount of conversation data available on social media such as forums and microblogging services. Methods along this line can be categorized into retrieval-based and generation-based ones. Generation-based chatbots reply to a message with natural language generation techniques. Early work (Ritter, Cherry, and Dolan 2011) regards messages and responses as source language and target language, respectively, and learn a phrase-based statistical machine translation model to translate a message to a response. Recently, toge"
J19-1005,D14-1181,0,0.00313027,"tenates the complement of each utterance with the last input; and in “combined,” s0 is the union of the other heuristics. Let vo = un in all heuristics, then the matching model of DL2R can be reformulated as mdl2r (s, r) = o X 0 (r)) MLP( fdl2r (vi )  fdl2r (vo )) · MLP( fdl2r (vi )  fdl2r (6) i=1 ~ v,1 , . . . , where MLP(· ) is a multi-layer perceptron. ∀v ∈ {v1 , . . . , vo }, suppose that {w ~ v,nv } represent embedding vectors of the words in v, then fdl2r (v) is given by w ~ v,1 , . . . , w ~ v,nv ) fdl2r (v) = CNN Bi-LSTM(w  (7) where CNN(· ) is a convolutional neural network (CNN) (Kim 2014) and Bi-LSTM(· ) is a bi-directional recurrent neural network with LSTM units (Bi-LSTM) (Graves, Mohamed, and Hinton 2013). The output of Bi-LSTM(· ) is all the hidden states of the Bi-LSTM 0 model. fdl2r (· ) is defined in the same way with fdl2r (· ). In DL2R, hdl2r (· ) can be viewed as an identity function on {fdl2r (v1 ), . . . , fdl2r (vo )}. Note that in the paper of Yan, Song, and Wu (2016), the authors also assume that each response candidate is associated with an antecedent posting p. This assumption does not always hold in multi-turn 1 We borrow the operator from MATLAB. 171 Computa"
J19-1005,N16-1014,0,0.190493,"such as flight booking, bus route enquiry, restaurant recommendation, and so forth; chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter, Cherry, and Dolan 2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage o"
J19-1005,P16-1094,0,0.129481,"such as flight booking, bus route enquiry, restaurant recommendation, and so forth; chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter, Cherry, and Dolan 2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage o"
J19-1005,D16-1127,0,0.163683,"such as flight booking, bus route enquiry, restaurant recommendation, and so forth; chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter, Cherry, and Dolan 2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage o"
J19-1005,D17-1230,0,0.0612794,"Missing"
J19-1005,P16-1098,0,0.0602627,"Missing"
J19-1005,D16-1176,0,0.045887,"Missing"
J19-1005,W15-4640,0,0.0590687,"he responses from the chatbot may drift to the topic of “Shanghai” if the chatbot pays significant attention to these words. Therefore, it is crucial yet non-trivial to let the chatbot understand the important points in the context and leverage them in matching and at the same time circumvent noise. Second, there is a clear dependency between Turn-5 and Turn-2 in the context, and the order of utterances matters in response selection because there will be different proper responses if we exchange Turn-3 and Turn-5. Existing work, including the recurrent neural network architectures proposed by Lowe et al. (2015), the deep learning to respond architecture proposed by Yan, Song, and Wu (2016), and the multi-view architecture proposed by Zhou et al. (2016), may lose important information in context-response matching because they follow the same paradigm to perform matching, which suffers clear drawbacks. In fact, although these models have different structures, they can be interpreted with a unified framework: A context and a response are first individually represented as vectors, and then their matching score is computed with the vectors. The context representation includes two layers. The first layer"
J19-1005,C16-1316,0,0.0795782,"ooking, bus route enquiry, restaurant recommendation, and so forth; chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter, Cherry, and Dolan 2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage of returning inform"
J19-1005,D16-1244,0,0.0684532,"Missing"
J19-1005,D14-1162,0,0.0842034,"Missing"
J19-1005,D11-1054,0,0.223411,"Missing"
J19-1005,P15-1152,0,0.148006,"Missing"
J19-1005,N15-1020,0,0.0241211,"to response generation; Li et al. (2016a) proposed a maximum mutual information objective to improve diversity of generated responses; Xing et al. (2017) and Mou et al. (2016) introduced external knowledge into the sequence-to-sequence model; Wu et al. (2018b) proposed decoding a response from a dynamic vocabulary; Li et al. (2016b) incorporated persona information into the sequence-to-sequence model to enhance response consistency with speakers; and Zhou et al. (2018) explored how to generate emotional responses with a memory augmented sequence-to-sequence model. In multi-turn conversation, Sordoni et al. (2015) compressed a context to a vector with a multi-layer perceptron in response generation; Serban et al. (2016) extended the sequence-to-sequence model to a hierarchical encoder-decoder structure; and under this structure, they further proposed two variants including VHRED (Serban et al. 2017b) and MrRNN (Serban et al. 2017a) to introduce latent and explicit variables into the generation process. Xing et al. (2018) exploited a hierarchical attention mechanism to highlight the effect of important words and utterances in generation. Upon these methods, reinforcement learning technique (Li et al. 20"
J19-1005,voorhees-tice-2000-trec,0,0.489297,"n candidates (Rn @k) as evaluation metrics. Here the matching models are required to return k most likely responses, and Rn @k = 1 if the true response is among the k candidates. Rn @k will become larger when k gets larger or n gets smaller. Rn @k has bias when there are multiple true candidates for a context. Hence, on the Douban corpus, apart from Rn @ks, we also followed the convention of information retrieval and used mean average precision (MAP) (Baeza-Yates, Ribeiro-Neto et al. 182 Wu et al. A Sequential Matching Framework for Retrieval-Based Chatbots 1999), mean reciprocal rank (MRR) (Voorhees and Tice 2000), and precision at position 1 (P@1) as evaluation metrics, which are defined as follows PNr MAP = 1 |S| X MRR = 1 |S| X P@1 = 1 |S| X AP(si ) , where AP(si ) = j=0 s i ∈S rel(rtop1 , si ) k=0 PNr rel(rk ,si ) j · rel(rj , si ) j=0 rel(rj , si ) s i ∈S RR(si ) , where RR(si ) = Pj 1 ranki (35) (36) (37) s i ∈S where ranki refers to the position of the first relevant response to context si in the ranking list; rj refers to the response ranked at the j-th position; rel(rj , si ) = 1 if rj is an appropriate response to context si , otherwise rel(rj , si ) = 0; rtop1 is the response ranked at the t"
J19-1005,P16-1122,0,0.065619,"Missing"
J19-1005,D13-1096,0,0.0265043,"naturally and meaningfully converse with humans on open domain topics (Ritter, Cherry, and Dolan 2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage of returning informative and fluent responses. Although most existing work on retrieval-based chatbots s"
J19-1005,N16-1170,0,0.0400905,"Missing"
J19-1005,P18-2067,1,0.863206,"open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage of returning informative and fluent responses. Although most existing work on retrieval-based chatbots studies response selection for single-turn conversation (Wang et al. 2013) in which conversation history is ignore"
J19-1005,P17-1046,1,0.592189,"and how they calculate the matching score with the two representations. The framework view unifies the existing models and indicates the common drawbacks they have: everything in the context is compressed to one or more fixed-length vectors before matching is conducted; and there is no interaction between the context and the response in the formation of their representations. The context is represented without enough supervision from the response, and so is the response. To overcome the drawbacks, we propose a sequential matching network (SMN) for context-response matching in our early work (Wu et al. 2017) where we construct Table 1 An example of multi-turn conversation. Turn-1 Turn-2 Turn-3 Turn-4 Turn-5 Context Human: How are you doing? ChatBot: I am going to hold a drum class in Shanghai. Anyone wants to join? The location is near Lujiazui. Human: Interesting! Do you have coaches who can help me practice drum? ChatBot: Of course. Human: Can I have a free first lesson? Response Candidates Response 1: Sure. Have you ever played drum before? X Response 2: What lessons do you want? 7 165 Computational Linguistics Volume 45, Number 1 a matching vector for each utterance–response pair through conv"
J19-1005,P15-1007,0,0.0606354,"Missing"
J19-1005,Q16-1019,0,0.0823372,"Missing"
J19-1005,D16-1036,0,0.133839,"2011). Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics. To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods (Shang, Lu, and Li 2015; Vinyals and Le 2015; Li et al. 2016b; Mou et al. 2016; Serban et al. 2016; Xing et al. 2017) and retrieval-based methods (Wang et al. 2013; Hu et al. 2014; Ji, Lu, and Li 2014; Wang et al. 2015; Yan, Song, and Wu 2016; Zhou et al. 2016; Wu et al. 2018a). Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data. In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage of returning informative and fluent responses. Although most existing work on retrieval-based chatbots studies response selection for single-turn conversation (Wang et al. 2013) in which conversation h"
J19-1005,P16-1044,0,\N,Missing
P10-1067,P02-1006,0,0.743531,"ed to comparative question identification and comparator mining from questions. However, their methods typically can achieve high precision but suffer from low recall (Jindal and Liu, 2006b) (J&L). However, ensuring high recall is crucial in our intended application scenario where users can issue arbitrary queries. To address this problem, we develop a weakly-supervised bootstrapping pattern learning method by effectively leveraging unlabeled questions. Bootstrapping methods have been shown to be very effective in previous information extraction research (Riloff, 1996; Riloff and Jones, 1999; Ravichandran and Hovy, 2002; Mooney and Bunescu, 2005; Kozareva et al., 2008). Our work is similar to them in terms of methodology using bootstrapping technique to extract entities with a specific relation. However, our task is different from theirs in that it requires not only extracting entities (comparator extraction) but also ensuring that the entities are extracted from comparative questions (comparative question identification), which is generally not required in IE task. 651 2.2 Jindal & Liu 2006 In this subsection, we provide a brief summary of the comparative mining method proposed by Jindal and Liu (2006a and"
P10-1067,P08-1119,0,0.00454293,"r mining from questions. However, their methods typically can achieve high precision but suffer from low recall (Jindal and Liu, 2006b) (J&L). However, ensuring high recall is crucial in our intended application scenario where users can issue arbitrary queries. To address this problem, we develop a weakly-supervised bootstrapping pattern learning method by effectively leveraging unlabeled questions. Bootstrapping methods have been shown to be very effective in previous information extraction research (Riloff, 1996; Riloff and Jones, 1999; Ravichandran and Hovy, 2002; Mooney and Bunescu, 2005; Kozareva et al., 2008). Our work is similar to them in terms of methodology using bootstrapping technique to extract entities with a specific relation. However, our task is different from theirs in that it requires not only extracting entities (comparator extraction) but also ensuring that the entities are extracted from comparative questions (comparative question identification), which is generally not required in IE task. 651 2.2 Jindal & Liu 2006 In this subsection, we provide a brief summary of the comparative mining method proposed by Jindal and Liu (2006a and 2006b), which is used as baseline for comparison a"
P14-1087,W09-2812,0,0.0199543,"set. T is the proportion of events in s which happen in the same time span as another event in any other sentence in S. Two events are said to be in the same time span if one happens within the time period the other happens in. For example, an event that takes place in “2014 June” is said to take place within the year “2014”. While T IME MMR is proposed here as an improvement over MMR, the premise is that incorporating temporal information can be helpful to minimize redundancy in summaries. In future work, one could apply it to other state-of-the-art lexical-based approaches including that of Hendrickx et al. (2009) and Celikyilmaz and HakkaniTur (2010). We also believe the same idea can be transplanted even to non-lexical motivated techniques such as the corpus-based similarity measure proposed by Xie and Liu (2008). We chose to use MMR here as a proof-of-concept to demonstrate the viability of such a technique, and to easily integrate our work into SWING. (4) where |Es |is the number of events found in s, and |T Sn − T S1 |is the temporal coverage of s. 3.3 Enhancing MMR with TimeMMR In the sentence re-ordering stage of the SWING pipeline, the iterative MMR algorithm is used to adjust the score of a ca"
P14-1087,P99-1071,0,0.251602,"Missing"
P14-1087,N03-1020,0,0.28595,"lue are the timelines used. 4 Experiments and Results The proposed timeline features and T IME MMR were implemented on top of SWING, and evaluated on the test documents from TAC-2011 (Owczarzak and Dang, 2011). SWING makes use of three generic features and two features targeted specifically at guided summarization. Since the focus of this paper is on multi-document summarization, we employ only the three generic features, i.e., 1) sentence position, 2) sentence length, and 3) interpolated n-gram document frequency in our experiments below. Summarization evaluation is done using ROUGE-2 (R-2) (Lin and Hovy, 2003), as it has previously been shown to correlate well with human assessment (Lin, 2004) and is often used to evaluate automatic text summarization. The results obtained are shown in Table 1. In the table, each row refers to a specific summarization system configuration. We also show the results of two reference systems, CLASSY (Conroy et al., 2011) and POLYCOM (Zhang et al., 2011), as benchmarks. CLASSY and POLYCOM are top performing systems at TAC-2011 (ranked 2nd and 3rd by R-2 in TAC 2011, respectively; the full version of SWING was ranked 1st with a R-2 score of 0.1380). From these results,"
P14-1087,P10-1084,0,0.0422125,"Missing"
P14-1087,C12-1129,1,0.852519,"in the standardized T IME ML annotation (Pustejovsky et al., 2003a). An event refers to an eventuality, a situation that occurs or an action; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex temporal relationship classification, and 3) event-event temporal relationship classification, are merged to obtain timelines (top half of Figure 3). We tap on existing systems for each of these steps (Ng and Kan, 2012; Str¨otgen and Gertz, 2013; Ng et al., 2013). Summarization. We make use of a state-ofthe-art summarization system, SWING (Ng et al., 2012) (bottom half of Figure 3). SWING is a supervised, extractive summarization system which ranks sentences based on scores computed using a set of features in the Sentence Scoring phase. The Maximal Marginal Relevance (MMR) algorithm is then used in the Sentence Re-ordering phase to re-order and select sentences to form the final summary. The timelines built in the earlier temporal processing can be incorporated into this pipeline by deriving a set of featur"
P14-1087,C12-1128,1,0.897655,"Missing"
P14-1087,D12-1062,0,0.0239019,"tion (TmpSum) track at the Text Retrieval Conference (Aslam et al., 2013). Given a large stream of data in real-time, the purpose of the TmpSum track is to look out for a query event, and retrieve specific details about the event over a period of time. Systems are also expected to identify the source sentences from which these details are retrieved. This is not the same as our approach here, which makes use of temporal information encoded in timelines to generate prose summaries. 3 well-understood constructs which have often been used to represent temporal information (Denis and Muller, 2011; Do et al., 2012). They indicate the temporal relationships between two basic temporal units: 1) events, and 2) time expressions (or timexes for short). In this work, we adopt the definitions proposed in the standardized T IME ML annotation (Pustejovsky et al., 2003a). An event refers to an eventuality, a situation that occurs or an action; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex temporal relationsh"
P14-1087,D13-1002,1,0.847029,"tejovsky et al., 2003a). An event refers to an eventuality, a situation that occurs or an action; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex temporal relationship classification, and 3) event-event temporal relationship classification, are merged to obtain timelines (top half of Figure 3). We tap on existing systems for each of these steps (Ng and Kan, 2012; Str¨otgen and Gertz, 2013; Ng et al., 2013). Summarization. We make use of a state-ofthe-art summarization system, SWING (Ng et al., 2012) (bottom half of Figure 3). SWING is a supervised, extractive summarization system which ranks sentences based on scores computed using a set of features in the Sentence Scoring phase. The Maximal Marginal Relevance (MMR) algorithm is then used in the Sentence Re-ordering phase to re-order and select sentences to form the final summary. The timelines built in the earlier temporal processing can be incorporated into this pipeline by deriving a set of features used to score sentences in Sentence Scorin"
P14-1087,W00-0405,0,0.250071,"lone made landfall. (3) The storm matched one in 1991 that sparked a tidal wave that killed an estimated 138,000 people, Karmakar told AFP. Figure 1: Modified extract from a news article which describes a cyclone landfall. Several events which appear in Figure 2 are bolded. Storm in 1991 set of heuristics, and also made use of lexical patterns to perform basic time normalization on terms like “today” relative to the document creation time. The induced ordering is used to present the selected summary content, following the chronological order in the original documents. In another line of work, Goldstein et al. (2000) made use of the temporal ordering of documents to be summarized. In computing the relevance of a passage for inclusion into the final summary, they considered the recency of the passage’s source document. Passages from more recent documents are deemed to be more important. Wan (2007) and Demartini et al. (2010) made similar assumptions in their work on T IMED T EXT R ANK and entity summarization, respectively. Instead of just considering the notion of recency, Liu et al. (2009) proposed an interesting approach using a temporal graph. Events within a document set correspond to vertices in thei"
P14-1087,S13-2001,0,0.0227806,"Missing"
P14-1087,S10-1010,0,\N,Missing
P16-1049,P05-1074,0,0.0295791,"Missing"
P16-1049,J93-2003,0,0.0563193,"hich will be introduced below. • response ranking, which ranks all response candidates in C and selects the most possible ˆ response candidate as S: Sˆ = arg max Rank(S, Q) S∈C • response triggering, which decides whether ˆ it is confident enough to response Q using S: 4.1 Word-level Feature We define three word-level features in this work: (1) hW M (S, Q) denotes a word matching feature that counts the number (weighted by the IDF value of each word in S) of non-stopwords shared by S and Q. (2) hW 2W (S, Q) denotes a word-toword translation-based feature that calculates the IBM model 1 score (Brown et al., 1993) of S and Q based on word alignments trained on ‘questionrelated question’ pairs using GIZA++ (Och and Ney, 2003). (3) hW 2V (S, Q) denotes a word embedding-based feature that calculates the average cosine distance between word embeddings of all non-stopword pairs hvSj , vQi i. vSj represent the word vector of j th word in S and vQj represent the word vector of ith word in Q. ˆ Q) I = T rigger(S, where I is a binary value. When I equals to true, let the response R = Sˆ and output R; otherwise, output nothing. In the following three sections, we will describe solutions of these three components"
P16-1049,P13-1158,0,0.0120646,"ng set. Each sentence in the document of a given question is labeled as 1 or 0, where 1 denotes the current sentence is a correct answer sentence, and 0 denotes the opposite meaning. Given a question, the task of WikiQA is to select answer sentences from all sentences in a question’s corresponding document. The training data settings of response ranking features are described below. 6 521 http://aka.ms/WikiQA Features Fw Fp Fs Fd Fr Fty Fto Fw denotes 3 word-level features, hW M , hW 2W and hW 2V . For hW 2W , GIZA++ is used to train word alignments on 11.6M ‘question-related question’ pairs (Fader et al., 2013) crawled from WikiAnswers.7 . For hW 2V , Word2Vec (Mikolov et al., 2013) is used to train word embedding on sentences from Wikipedia in English. Fp denotes 2 phrase-level features, hP P and hP T . For hP P , bilingual data8 is used to extract a phrase-based translation table (Koehn et al., 2003), from which paraphrases are extracted (Section 4.2.1). For hP T , GIZA++ trains word alignments on 4M ‘question-answer’ pairs9 crawled from Yahoo Answers10 , and then a phrase table is extracted from word alignments using the intersect-diag-grow refinement. Fs denotes 2 sentence-level features, hSCR a"
P16-1049,P15-1152,0,0.0316726,"Missing"
P16-1049,N10-1145,0,0.0135467,"hniques. However, collecting enough Q-R pairs to build chatbots is often intractable for many domains. Compared to previous methods, DocChat learns internal relationships between utterances and responses based on statistical models at different levels of granularity, and relax the dependency on Q-R pairs as response sources. These make DocChat as a general response generation solution to chatbots, with high adaptation capability. For answer sentence selection. Prior work in measuring the relevance between question and answer is mainly in word-level and syntactic-level (Wang and Manning, 2010; Heilman and Smith, 2010; Yih et al., 2013). Learning representation by neural network architecture (Yu et al., 2014; Wang and Nyberg, 2015; Severyn and Moschitti, 2015) has become a hot research topic to go beyond word-level or phrase-level methods. Compared to previous works we find that, (i) Large scale existing resources with noise have more advantages as training data. (ii) Knowledge-based semantic models can play important roles. at least one suitable response, but response ranking will output the best possible candidate all the time. So, we have to decide which responses are confident enough to be output, and"
P16-1049,C10-1131,0,0.0206887,"Missing"
P16-1049,P15-2116,0,0.0100083,"Missing"
P16-1049,N03-1017,0,0.0225488,"g document. The training data settings of response ranking features are described below. 6 521 http://aka.ms/WikiQA Features Fw Fp Fs Fd Fr Fty Fto Fw denotes 3 word-level features, hW M , hW 2W and hW 2V . For hW 2W , GIZA++ is used to train word alignments on 11.6M ‘question-related question’ pairs (Fader et al., 2013) crawled from WikiAnswers.7 . For hW 2V , Word2Vec (Mikolov et al., 2013) is used to train word embedding on sentences from Wikipedia in English. Fp denotes 2 phrase-level features, hP P and hP T . For hP P , bilingual data8 is used to extract a phrase-based translation table (Koehn et al., 2003), from which paraphrases are extracted (Section 4.2.1). For hP T , GIZA++ trains word alignments on 4M ‘question-answer’ pairs9 crawled from Yahoo Answers10 , and then a phrase table is extracted from word alignments using the intersect-diag-grow refinement. Fs denotes 2 sentence-level features, hSCR and hSDR . For hSCR , 4M ‘question-answer’ pairs (the same to hP T ) is used to train the CNN model. For hSDR , we randomly select 0.5M ‘sentence-next sentence’ pairs from English Wikipedia. Fd denotes document-level feature hDM . Here, we didn’t train a new model. Instead, we just reuse the CNN m"
P16-1049,D07-1003,0,0.00742056,"existing resources are readily available (such as Q-Q pairs, Q-A pairs, ‘sentence-next sentence’ pairs, and etc.), instead of requiring manually annotated data (such as WikiQA and QASent). Training of the response ranking model does need labeled data, but the size demanded is acceptable. Second, as the training data used in our approach come from open domain resources, we can expect a high adaptation capability and comparable results on other WikiQAlike tasks, as our models are task-independent. To verify the second advantage, we evaluate DocChat on another answer selection data set, QASent (Wang et al., 2007), and list results in Table 3. CN NW ikiQA and CN NQASent refer to the results of Yang et al. (2015)’s method, where the CNN models are trained on WikiQA’s training set and QASent’s training set respectively. All these three methods train feature weights using QASent’s development set. Table 3 tells, DocChat outperforms CN NW ikiQA in terms of MAP and MRR, and achieves comparable results compared to CN NQASent . The comparisons results show a good adaptation capability of DocChat. Table 4 evaluates the contributions of features at different levels of granularity. To highlight the differences,"
P16-1049,W00-0304,0,0.019256,"also, besides, moreover and etc., as the contents of sentences starting with such phrases usually depend on their context sentences, and they are not suitable for responses. 6 7 Experiments 7.1 Evaluation on QA (English) Take into account response ranking task and answer selection task are similar, we first evaluate DocChat in a QA scenario as a simulation. Here, response ranking is treated as the answer selection task, and response triggering is treated as the answer triggering task. Related Work For modeling dialogue. Previous works mainly focused on rule-based or learning-based approaches (Litman et al., 2000; Schatzmann et al., 2006; Williams and Young, 2007). These methods require efforts on designing rules or labeling data for training, which suffer the coverage issue. For short text conversation. With the fast development of social media, such as microblog and CQA services, large scale conversation data and data-driven approaches become possible. Ritter et al. (2011) proposed an SMT based method, which treats response generation as a machine translation task. Shang et al. (2015) presented an RNN based method, which is trained based on a large number of single round conversation data. Grammatic"
P16-1049,D15-1237,0,0.0100947,"Missing"
P16-1049,P13-1171,0,0.046252,"ing enough Q-R pairs to build chatbots is often intractable for many domains. Compared to previous methods, DocChat learns internal relationships between utterances and responses based on statistical models at different levels of granularity, and relax the dependency on Q-R pairs as response sources. These make DocChat as a general response generation solution to chatbots, with high adaptation capability. For answer sentence selection. Prior work in measuring the relevance between question and answer is mainly in word-level and syntactic-level (Wang and Manning, 2010; Heilman and Smith, 2010; Yih et al., 2013). Learning representation by neural network architecture (Yu et al., 2014; Wang and Nyberg, 2015; Severyn and Moschitti, 2015) has become a hot research topic to go beyond word-level or phrase-level methods. Compared to previous works we find that, (i) Large scale existing resources with noise have more advantages as training data. (ii) Knowledge-based semantic models can play important roles. at least one suitable response, but response ranking will output the best possible candidate all the time. So, we have to decide which responses are confident enough to be output, and which are not. In t"
P16-1049,P14-2105,0,0.0136102,"nguage) with its answer can be first parsed into a fact formatted as hesbj , rel, eobj i, where esbj denotes a subject entity detected from the question, rel denotes the relationship expressed by the question, eobj denotes an object entity found from the knowledge base based on esbj and rel. Then we can get hQ, reli pairs. This rel can help for modeling semantic relationships between Q and R. For example, the Q-A pair hWhat does Jimmy Neutron do? − inventori can be parsed into hJimmy Neutron, fictional character occupation, inventori where the rel is fictional character occupation. Similar to Yih et al. (2014), We use hQ, reli pairs as training data, and learn a rel-CNN model, which can encode each question Q (or each relation rel) into a relation embedding. For a given question Q, the corresponding relation rel+ is L = max{0, M − cosine(y(SX ), y(SY )) +cosine(y(SX ), y(SY− ))} where M is a constant, SY− is a negative instance. 4.3.1 Document-level Feature Causality Relationship Modeling We train the first attention-based sentence embedding model based on a set of ‘question-answer’ pairs as input sentence pairs, and then design a causality relationship-based feature as: hSCR (S, Q) = cosine(ySCR ("
P16-1049,J03-1002,0,0.0490153,"ossible ˆ response candidate as S: Sˆ = arg max Rank(S, Q) S∈C • response triggering, which decides whether ˆ it is confident enough to response Q using S: 4.1 Word-level Feature We define three word-level features in this work: (1) hW M (S, Q) denotes a word matching feature that counts the number (weighted by the IDF value of each word in S) of non-stopwords shared by S and Q. (2) hW 2W (S, Q) denotes a word-toword translation-based feature that calculates the IBM model 1 score (Brown et al., 1993) of S and Q based on word alignments trained on ‘questionrelated question’ pairs using GIZA++ (Och and Ney, 2003). (3) hW 2V (S, Q) denotes a word embedding-based feature that calculates the average cosine distance between word embeddings of all non-stopword pairs hvSj , vQi i. vSj represent the word vector of j th word in S and vQj represent the word vector of ith word in Q. ˆ Q) I = T rigger(S, where I is a binary value. When I equals to true, let the response R = Sˆ and output R; otherwise, output nothing. In the following three sections, we will describe solutions of these three components one by one. 3 X Response Retrieval Given a user utterance Q, the goal of response retrieval is to efficiently fi"
P16-1049,D11-1054,0,0.0213887,"sponse ranking is treated as the answer selection task, and response triggering is treated as the answer triggering task. Related Work For modeling dialogue. Previous works mainly focused on rule-based or learning-based approaches (Litman et al., 2000; Schatzmann et al., 2006; Williams and Young, 2007). These methods require efforts on designing rules or labeling data for training, which suffer the coverage issue. For short text conversation. With the fast development of social media, such as microblog and CQA services, large scale conversation data and data-driven approaches become possible. Ritter et al. (2011) proposed an SMT based method, which treats response generation as a machine translation task. Shang et al. (2015) presented an RNN based method, which is trained based on a large number of single round conversation data. Grammatical and fluency problems are the biggest issue for such generation-based approaches. Retrievalbased methods selects the most suitable response 7.1.1 Experiment Setup We select WikiQA6 as the evaluation data, as it is precisely constructed based on natural language questions and Wikipedia documents, which contains 2,118 ‘question-document’ pairs in the training set, 29"
P17-1046,P16-1094,0,0.0461305,"Missing"
P17-1046,D13-1096,0,0.841801,"t neural network (RNN) which models relationships among utterances. The final matching score is calculated with the hidden states of the RNN. An empirical study on two public data sets shows that SMN can significantly outperform stateof-the-art methods for response selection in multi-turn conversation. 1 utterance 3 utterance 4 utterance 5 response 1 response 2 Table 1: An example of multi-turn conversation the current conversation from a repository with response selection algorithms. While most existing work on retrieval-based chatbots studies response selection for single-turn conversation (Wang et al., 2013) which only considers the last input message, we consider the problem in a multi-turn scenario. In a chatbot, multi-turn response selection takes a message and utterances in its previous turns as input and selects a response that is natural and relevant to the whole context. The key to response selection lies in inputresponse matching. Different from single-turn conversation, multi-turn conversation requires matching between a response and a conversation context in which one needs to consider not only the matching between the response and the input message but also matching between responses a"
P17-1046,W15-4640,0,0.747982,"urnResponseSelection Our contributions in this paper are three-folds: (1) the proposal of a new context based matching model for multi-turn response selection in retrieval-based chatbots; (2) the publication of a large human-labeled data set to research communities; (3) empirical verification of the effectiveness of the model on public data sets. the order of the utterances matters in response selection: exchanging the third utterance and the fifth utterance may lead to different responses. Existing work, however, either ignores relationships among utterances when concatenating them together (Lowe et al., 2015), or loses important information in context in the process of converting the whole context to a vector without enough supervision from responses (e.g., by a hierarchical RNN (Zhou et al., 2016)). We propose a sequential matching network (SMN), a new context based matching model that can tackle both challenges in an end-to-end way. The reason that existing models lose important information in the context is that they first represent the whole context as a vector and then match the context vector with a response vector. Thus, responses in these models connect with the context until the final ste"
P17-1046,C16-1063,0,0.0880695,"r matching in its hidden states in the chronological order of the utterances in context. It models relationships and dependencies among the utterances in a matching fashion and has the utterance order supervise the accumulation of pair matching. The matching degree of the context and the response is computed by a logit 2 Related Work Recently, building a chatbot with data driven approaches (Ritter et al., 2011; Ji et al., 2014) has drawn significant attention. Existing work along this line includes retrieval-based methods (Hu et al., 2014; Ji et al., 2014; Wang et al., 2015; Yan et al., 2016; Wu et al., 2016b; Zhou et al., 2016; Wu et al., 2016a) and generation-based methods (Shang et al., 2015; Serban et al., 2015; Vinyals and Le, 2015; Li et al., 2015, 2016; Xing et al., 497 Word Embedding GRU1 Segment Pairs Word Pairs GRU2 u1 .... v1 .... .... .... .... un1 .... h '1 .... vn 1 h 'n1 vn h 'n L( ) Score un r M1, M2 Convolution Utterance-Response Matching (First Layer) Pooling Matching Accumulation Matching Prediction (Second Layer) (Third Layer) Figure 1: Architecture of SMN SMN first decomposes context-response matching into several utterance-response pair matching and then all pairs matchin"
P17-1046,D11-1054,0,0.715416,"class” and “drum” in context are very important. Without them, one may find responses relevant to the message (i.e., the fifth utterance of the context) but nonsense in the context (e.g., “what lessons do you want?”). Second, the message highly depends on the second utterance in the context, and Introduction Conversational agents include task-oriented dialog systems and non-task-oriented chatbots. Dialog systems focus on helping people complete specific tasks in vertical domains (Young et al., 2010), while chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter et al., 2011). Existing work on building chatbots includes generation -based methods and retrieval-based methods. Retrieval based chatbots enjoy the advantage of informative and fluent responses, because they select a proper response for ∗ Context Human: How are you doing? ChatBot: I am going to hold a drum class in Shanghai. Anyone wants to join? The location is near Lujiazui. Human: Interesting! Do you have coaches who can help me practice drum? ChatBot: Of course. Human: Can I have a free first lesson? Response Candidates Sure. Have you ever played drum before? X What lessons do you want? 7 Correspondin"
P17-1046,P15-1152,0,0.0917506,"es of a recurrent neural network with GRU following the chronological order of the utterances in the context. The third layer calculates the final matching score with the hidden states of the second layer. 2016; Serban et al., 2016). Our work is a retrievalbased method, in which we study context-based response selection. Early studies of retrieval-based chatbots focus on response selection for single-turn conversation (Wang et al., 2013; Ji et al., 2014; Wang et al., 2015; Wu et al., 2016b). Recently, researchers have begun to pay attention to multi-turn conversation. For example, Lowe et al. (2015) match a response with the literal concatenation of context utterances. Yan et al. (2016) concatenate context utterances with the input message as reformulated queries and perform matching with a deep neural network architecture. Zhou et al. (2016) improve multi-turn response selection with a multi-view model including an utterance view and a word view. Our model is different in that it matches a response with each utterance at first and accumulates matching information instead of sentences by a GRU, thus useful information for matching can be sufficiently retained. 3 3.1 SMN enjoys several ad"
P17-1046,N16-1174,0,0.0161726,"how much information from the previous hidden state and the current input flows to the current hidden state, thus important matching vectors (corresponding to important utterances) can be accumulated while noise in the vectors can be filtered out. 3.5 − 4 With [h01 , . . . , h0n ], we define g(s, r) as (6) where W2 and b2 are parameters. We consider three parameterizations for L[h01 , . . . , h0n ]: (1) only the last hidden state is used. Then L[h01 , . . . , h0n ] = h0n . (2) the hidden states are combined. Then, L[h01 , . . . , h0n ] = Pn linearly 0 i=1 wi hi , where wi ∈ R. (3) we follow (Yang et al., 2016) and employ an attention mechanism to combine the hidden states. Then, L[h01 , . . . , h0n ] is defined as 5 ti = tanh(W1,1 hui ,nu + W1,2 h0i + b1 ), exp(t> i ts ) , > (exp(t i ts )) i n X αi h0i , L[h01 , . . . , h0n ] = αi = P i=1 [yi log(g(si , ri )) + (1 − yi )log(1 − g(si , ri ))] . (8) Response Candidate Retrieval In practice, a retrieval-based chatbot, to apply the matching approach to the response selection, one needs to retrieve a number of response candidates from an index beforehand. While candidate retrieval is not the focus of the paper, it is an important step in a real system."
P17-1046,D16-1036,0,0.784002,"he publication of a large human-labeled data set to research communities; (3) empirical verification of the effectiveness of the model on public data sets. the order of the utterances matters in response selection: exchanging the third utterance and the fifth utterance may lead to different responses. Existing work, however, either ignores relationships among utterances when concatenating them together (Lowe et al., 2015), or loses important information in context in the process of converting the whole context to a vector without enough supervision from responses (e.g., by a hierarchical RNN (Zhou et al., 2016)). We propose a sequential matching network (SMN), a new context based matching model that can tackle both challenges in an end-to-end way. The reason that existing models lose important information in the context is that they first represent the whole context as a vector and then match the context vector with a response vector. Thus, responses in these models connect with the context until the final step in matching. To avoid information loss, SMN matches a response with each utterance in the context at the beginning and encodes important information in each pair into a matching vector. The m"
P17-1166,P11-1055,0,0.873149,"we can incorporate the weak ties between the two relations, extracting place of birth will provide evidence for prediction of place lived. Exploiting class ties is necessary for DS based relation extraction. In DS scenario, there is a challenge that one entity tuple can have multiple rela1810 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1810–1820 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1166 tion facts as shown in Table 1, which is called relation overlapping (Hoffmann et al., 2011; Surdeanu et al., 2012). However, the relations of one entity tuple can have class ties mentioned above which can be leveraged to enhance relation extraction for it narrowing down potential searching spaces and reducing uncertainties between relations when predicting unknown relations. If one pair entities has CEO of, it will contain founder of with high possibility. To exploit class ties between relations, we propose to make joint extraction for all positive labels of one entity tuple with considering pairwise connections between positive and negative labels inspired by (F¨urnkranz et al., 2"
P17-1166,P16-1200,0,0.147533,"be achieved by separated extraction for it dividing labels apart losing information of cooccurrence. To classify positive labels from negative ones, we adopt pairwise ranking to rank positive ones higher than negative ones, exploiting pairwise connections between them. In a word, joint extraction exploits class ties between relations and pairwise ranking classify positive labels from negative ones. Furthermore, combining information across sentences will be more appropriate for joint extraction which provides more information from other sentences to extract each relation (Zheng et al., 2016; Lin et al., 2016). In Table 1, sentence #1 is the evidence for place of birth, but it also expresses the meaning of “living in someplace”, so it can be aggregated with sentence #2 to extract place lived. Meanwhile, the word of “hometown” in sentence #2 can provide evidence for place of birth which should be combined with sentence #1 to extract place of birth. In this work, we propose a unified model that integrates pairwise ranking with CNN to exploit class ties. Inspired by the effectiveness of deep learning for modeling sentences (LeCun et al., 2015), we use CNN to encode sentences. Similar to (Santos et al."
P17-1166,P15-1061,0,0.496903,"et al., 2016). In Table 1, sentence #1 is the evidence for place of birth, but it also expresses the meaning of “living in someplace”, so it can be aggregated with sentence #2 to extract place lived. Meanwhile, the word of “hometown” in sentence #2 can provide evidence for place of birth which should be combined with sentence #1 to extract place of birth. In this work, we propose a unified model that integrates pairwise ranking with CNN to exploit class ties. Inspired by the effectiveness of deep learning for modeling sentences (LeCun et al., 2015), we use CNN to encode sentences. Similar to (Santos et al., 2015; Lin et al., 2016), we use class embeddings to represent relation classes. The whole model architecture is presented in Figure 1. We first use CNN to embed sentences, then we introduce two variant methods to combine the class embedding ?[#$ ] & ? c1 c2 bag representation vector sentence embedding encoded by CNN cm s combine sentences s1 s2 sn x1 x2 xn Figure 1: The main architecture of our model. embedded sentences into one bag representation vector aiming to aggregate information across sentences, after that we measure the similarity between bag representation and relation class in realvalue"
P17-1166,D12-1042,0,0.875708,"weak ties between the two relations, extracting place of birth will provide evidence for prediction of place lived. Exploiting class ties is necessary for DS based relation extraction. In DS scenario, there is a challenge that one entity tuple can have multiple rela1810 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1810–1820 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1166 tion facts as shown in Table 1, which is called relation overlapping (Hoffmann et al., 2011; Surdeanu et al., 2012). However, the relations of one entity tuple can have class ties mentioned above which can be leveraged to enhance relation extraction for it narrowing down potential searching spaces and reducing uncertainties between relations when predicting unknown relations. If one pair entities has CEO of, it will contain founder of with high possibility. To exploit class ties between relations, we propose to make joint extraction for all positive labels of one entity tuple with considering pairwise connections between positive and negative labels inspired by (F¨urnkranz et al., 2008; Zhang and Zhou, 200"
P17-1166,P16-1123,0,0.0327132,"Missing"
P17-1166,D15-1203,0,0.505628,"t extraction of relations, they only use information from single sentence losing information from other sentences. Han and Sun (2016) try to use Markov logic model to capture consistency between relation labels, on the contrary, our model leverages deep ranking to learn class ties automatically. With the remarkable success of deep learning in CV and NLP (LeCun et al., 2015), deep learning has been applied to relation extraction (Zeng et al., 2014, 2015; Santos et al., 2015; Lin et al., 2016), the specific deep learning architecture can be CNN (Zeng et al., 2014), RNN (Zhou et al., 2016), etc. Zeng et al. (2015) propose a piecewise convolutional neural network with multi-instance learning for DS based relation extraction, which improves the precision and recall significantly. Afterwards, Lin et al. (2016) introduce the mechanism of attention (Luong et al., 2015; Bahdanau et al., 2014) to select the sentences to relieve the wrong labelling problem and use all the information across sentences. However, the two deep learning based models only make separated extraction thus can not model class ties between relations. 2.2 Deep Learning to Rank Deep learning to rank has been widely used in many problems to"
P17-1166,C14-1220,0,0.0184427,"al. (2011) and Surdeanu et al. (2012) model this problem by multi-instance multi-label learning to extract overlapping relations. Though they also propose to make joint extraction of relations, they only use information from single sentence losing information from other sentences. Han and Sun (2016) try to use Markov logic model to capture consistency between relation labels, on the contrary, our model leverages deep ranking to learn class ties automatically. With the remarkable success of deep learning in CV and NLP (LeCun et al., 2015), deep learning has been applied to relation extraction (Zeng et al., 2014, 2015; Santos et al., 2015; Lin et al., 2016), the specific deep learning architecture can be CNN (Zeng et al., 2014), RNN (Zhou et al., 2016), etc. Zeng et al. (2015) propose a piecewise convolutional neural network with multi-instance learning for DS based relation extraction, which improves the precision and recall significantly. Afterwards, Lin et al. (2016) introduce the mechanism of attention (Luong et al., 2015; Bahdanau et al., 2014) to select the sentences to relieve the wrong labelling problem and use all the information across sentences. However, the two deep learning based models"
P17-1166,D15-1166,0,0.00440398,"ranking to learn class ties automatically. With the remarkable success of deep learning in CV and NLP (LeCun et al., 2015), deep learning has been applied to relation extraction (Zeng et al., 2014, 2015; Santos et al., 2015; Lin et al., 2016), the specific deep learning architecture can be CNN (Zeng et al., 2014), RNN (Zhou et al., 2016), etc. Zeng et al. (2015) propose a piecewise convolutional neural network with multi-instance learning for DS based relation extraction, which improves the precision and recall significantly. Afterwards, Lin et al. (2016) introduce the mechanism of attention (Luong et al., 2015; Bahdanau et al., 2014) to select the sentences to relieve the wrong labelling problem and use all the information across sentences. However, the two deep learning based models only make separated extraction thus can not model class ties between relations. 2.2 Deep Learning to Rank Deep learning to rank has been widely used in many problems to serve as a classification model. In image retrieval, Zhao et al. (2015) apply deep semantic ranking for multi-label image retrieval. In text matching, Severyn and Moschitti (2015) adopt learning to rank combined with deep CNN for short text pairs matchi"
P17-1166,P09-1113,0,0.870687,"e the effectiveness of our model to learn class ties. Our model outperforms the baselines significantly, achieving stateof-the-art performance. 1 #1 #2 Table 1: Training instances generated by freebase. Introduction Relation extraction (RE) aims to classify the relations between two given named entities from natural-language text. Supervised machine learning methods require numerous labeled data to work well. With the rapid growth of volume of relation types, traditional methods can not keep up with the step for the limitation of labeled data. In order to narrow down the gap of data sparsity, Mintz et al. (2009) propose distant supervision (DS) for relation extraction, which automati∗ Corresponding author. place lived (Patsy Ramsey, Atlanta) place of birth (Patsy Ramsey, Atlanta) Sentence Latent Label Patsy Ramsey has been living in place of birth Atlanta since she was born. Patsy Ramsy always loves At- place lived lanta since it is her hometown. cally generates training data by aligning a knowledge facts database (ie. Freebase (Bollacker et al., 2008)) with texts. Class ties mean the connections between relations in relation extraction. In general, we conclude that class ties can have two types: wea"
P17-1166,P16-2034,0,0.00467082,"also propose to make joint extraction of relations, they only use information from single sentence losing information from other sentences. Han and Sun (2016) try to use Markov logic model to capture consistency between relation labels, on the contrary, our model leverages deep ranking to learn class ties automatically. With the remarkable success of deep learning in CV and NLP (LeCun et al., 2015), deep learning has been applied to relation extraction (Zeng et al., 2014, 2015; Santos et al., 2015; Lin et al., 2016), the specific deep learning architecture can be CNN (Zeng et al., 2014), RNN (Zhou et al., 2016), etc. Zeng et al. (2015) propose a piecewise convolutional neural network with multi-instance learning for DS based relation extraction, which improves the precision and recall significantly. Afterwards, Lin et al. (2016) introduce the mechanism of attention (Luong et al., 2015; Bahdanau et al., 2014) to select the sentences to relieve the wrong labelling problem and use all the information across sentences. However, the two deep learning based models only make separated extraction thus can not model class ties between relations. 2.2 Deep Learning to Rank Deep learning to rank has been widely"
P18-2067,N16-1014,0,0.0430232,"0.526 0.565 everything the same as our approach but replace D with a set constructed by random sampling, denoted as model+WSrand. Table 3 reports the results. We can conclude that both the weak supervision and the strategy of training data construction are important to the success of the proposed learning approach. Training data construction plays a more crucial role, because it involves more true positives and negatives with different semantic distances to the positives into learning. Does updating the Seq2Seq model help? It is well known that Seq2Seq models suffer from the “safe response” (Li et al., 2016a) problem, which may bias the weak supervision signals to high-frequency responses. Therefore, we attempt to iteratively optimize the Seq2Seq model and the matching model and check if the matching model can be further improved. Specifically, we update the Seq2Seq model every 20 mini-batches with the policy-based reinforcement learning approach proposed in (Li et al., 2016b). The reward is defined as the matching score of a context and a response given by the matching model. Unfortunately, we do not observe significant improvement on the matching model. The result is attributed to two factors:"
P18-2067,D16-1127,0,0.0988774,"0.526 0.565 everything the same as our approach but replace D with a set constructed by random sampling, denoted as model+WSrand. Table 3 reports the results. We can conclude that both the weak supervision and the strategy of training data construction are important to the success of the proposed learning approach. Training data construction plays a more crucial role, because it involves more true positives and negatives with different semantic distances to the positives into learning. Does updating the Seq2Seq model help? It is well known that Seq2Seq models suffer from the “safe response” (Li et al., 2016a) problem, which may bias the weak supervision signals to high-frequency responses. Therefore, we attempt to iteratively optimize the Seq2Seq model and the matching model and check if the matching model can be further improved. Specifically, we update the Seq2Seq model every 20 mini-batches with the policy-based reinforcement learning approach proposed in (Li et al., 2016b). The reward is defined as the matching score of a context and a response given by the matching model. Unfortunately, we do not observe significant improvement on the matching model. The result is attributed to two factors:"
P18-2067,W15-4640,0,0.598699,"significant improvements when they are learned with the proposed method. 1 Introduction Recently, more and more attention from both academia and industry is paying to building nontask-oriented chatbots that can naturally converse with humans on any open domain topics. Existing approaches can be categorized into generationbased methods (Shang et al., 2015; Vinyals and Le, 2015; Serban et al., 2016; Sordoni et al., 2015; Xing et al., 2017; Serban et al., 2017; Xing et al., 2018) which synthesize a response with natural language generation techniques, and retrievalbased methods (Hu et al., 2014; Lowe et al., 2015; Yan et al., 2016; Zhou et al., 2016; Wu et al., 2017) which select a response from a pre-built index. In this work, we study response selection for retrieval-based chatbots, not only because retrieval-based methods can return fluent and informative responses, but also because they have been successfully applied to many real products such as the social-bot XiaoIce from Microsoft (Shum et al., 2018) and the E-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017). ∗ 1 The model performs well on randomly sampled data, but badly on human labeled data. Corresponding Author 420 Proce"
P18-2067,D13-1096,0,0.46557,"sed approaches in the teacher-student framework (Dehghani et al., 2017a,b), as there are no labeled data in learning. 3 Implementation Details 3.2 Single-turn Response Selection Experiment settings: in the STC (stands for Short Text Conversation) data set, the task is to select a proper response for a post in Weibo2 . The training set contains 4.8 million post-response (true response) pairs. The test set consists of 422 posts with each one associated with around 30 responses labeled by human annotators in “good” and “bad”. In total, there are 12, 402 labeled pairs in the test data. Following (Wang et al., 2013, 2015), we combine the score from a matching model with TF-IDF based cosine similarity using RankSVM whose parameters are chosen by 5-fold cross validation. Precision at position 1 (P@1) is employed as an evaluation metric. In addition to the models compared on the data in the existing literatures, we also implement dual LSTM (Lowe et al., 2015) as a baseline. As case studies, we learn a dual LSTM and an CNN (Hu et al., 2014) with the proposed approach, and denote them as LSTM+WS (Weak Supervision) and CNN+WS, respectively. When constructing D, we build an index with the training data using L"
P18-2067,P17-1046,1,0.89116,"sion for Response Selection in Retrieval-based Chatbots † Yu Wu† , Wei Wu‡ , Zhoujun Li†∗, Ming Zhou♦ State Key Lab of Software Development Environment, Beihang University, Beijing, China † Authors are supported by AdeptMind Scholarship ♦ Microsoft Research, Beijing, China ‡ Microsoft Corporation, Beijing, China {wuyu,lizj}@buaa.edu.cn {wuwei,mingzhou}@microsoft.com Abstract A key step to response selection is measuring the matching degree between a response candidate and an input which is either a single message (Hu et al., 2014) or a conversational context consisting of multiple utterances (Wu et al., 2017). While existing research focuses on how to define a matching model with neural networks, little attention has been paid to how to learn such a model when few labeled data are available. In practice, because human labeling is expensive and exhausting, one cannot have large scale labeled data for model training. Thus, a common practice is to transform the matching problem to a classification problem with human responses as positive examples and randomly sampled ones as negative examples. This strategy, however, oversimplifies the learning problem, as most of the randomly sampled responses are e"
P18-2067,P15-1152,0,0.381248,"Missing"
P18-2067,N15-1020,0,0.100849,"Missing"
P18-2067,D16-1036,0,0.792114,"e learned with the proposed method. 1 Introduction Recently, more and more attention from both academia and industry is paying to building nontask-oriented chatbots that can naturally converse with humans on any open domain topics. Existing approaches can be categorized into generationbased methods (Shang et al., 2015; Vinyals and Le, 2015; Serban et al., 2016; Sordoni et al., 2015; Xing et al., 2017; Serban et al., 2017; Xing et al., 2018) which synthesize a response with natural language generation techniques, and retrievalbased methods (Hu et al., 2014; Lowe et al., 2015; Yan et al., 2016; Zhou et al., 2016; Wu et al., 2017) which select a response from a pre-built index. In this work, we study response selection for retrieval-based chatbots, not only because retrieval-based methods can return fluent and informative responses, but also because they have been successfully applied to many real products such as the social-bot XiaoIce from Microsoft (Shum et al., 2018) and the E-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017). ∗ 1 The model performs well on randomly sampled data, but badly on human labeled data. Corresponding Author 420 Proceedings of the 56th Annual Meeting of"
S17-2045,P02-1034,0,0.0962705,"of representations of the two pieces of text is used as a feature. Longest common subsequence: we measure the lexical similarity of each text pair with the term-level longest common subsequence (LCS) (Allison and Dix, 1986). The length of LCS is normalized by dividing the maximum length of the two pieces of text. Word overlap: we calculate the normalized count of common ngrams (n=1,2,3) and nouns. Tree kernels: tree kernels are similarity functions used to measure the syntactic similarity of a text pair. We compute the subtree kernel (ST) (Schlkopf et al., 2003), the subset tree kernel (SST) (Collins and Duffy, 2002), and the partial tree kernel (PTK) (Moschitti, 2006) on the parse trees of a text pair. Translation probability: we learn word-toword translation probabilities using GIZA++ 1 with the unannotated Qatar Living data. In training, we regard questions as source language and their answers as target language. Following (Jeon et al., 2005), we use translation probability p(qusetion A|question B) and p(comment|question) as features for a questionii = σ(W (i) ex,i + U (i) hx,i−1 + b(i) ) fi = σ(W (f ) ex,i + U (f ) hx,i−1 + b(f ) ) oi = σ(W (o) ex,i + U (o) hx,i−1 + b(o) ) ui = tanh(W (u) ex,i + U (u)"
S17-2045,P03-1054,0,0.0058722,"1 , ..., ex,i , ..., ex,I ] and Sy = [ey,1 , ..., ey,i , ..., ey,J ] respectively, where ex,i , ey,i are the embeddings of the i-th words of Sx and Sy respectively. Then Sx and Sy are encoded in hidden sequences by a bi-LSTM which consists of a forward LSTM and a backward LSTM. The forward LSTM reads Sx in its order (i.e., from wx,1 to wx,I ) and transforms it to a forward hidden se→ − → − quence { h x,i }Ii=1 . ∀i ∈ {1, . . . , I}, h x,i is defined by: Preprocessing We exploit NLTK toolkit (Loper and Bird, 2002) to conduct stemming, tokenization, and POS tagging. We use Stanford PCFG parser (Klein and Manning, 2003) to get the parse tree of each sentence. 2.2 Neural Matching Features Traditional NLP Features The following features are designed based on words and syntactic analysis. Tf-idf cosine: each piece of text is converted to a one hot representation weighted by tf-idf values, where tf is the term frequency in the text, and idf is calculated using the unannotated Qatar corpora (Nakov et al., 2017). The cosine of representations of the two pieces of text is used as a feature. Longest common subsequence: we measure the lexical similarity of each text pair with the term-level longest common subsequence"
S17-2045,W02-0109,0,0.132576,", given a text pair (Sx , Sy ), the model looks up an embedding table to convert Sx and Sy to Sx = [ex,1 , ..., ex,i , ..., ex,I ] and Sy = [ey,1 , ..., ey,i , ..., ey,J ] respectively, where ex,i , ey,i are the embeddings of the i-th words of Sx and Sy respectively. Then Sx and Sy are encoded in hidden sequences by a bi-LSTM which consists of a forward LSTM and a backward LSTM. The forward LSTM reads Sx in its order (i.e., from wx,1 to wx,I ) and transforms it to a forward hidden se→ − → − quence { h x,i }Ii=1 . ∀i ∈ {1, . . . , I}, h x,i is defined by: Preprocessing We exploit NLTK toolkit (Loper and Bird, 2002) to conduct stemming, tokenization, and POS tagging. We use Stanford PCFG parser (Klein and Manning, 2003) to get the parse tree of each sentence. 2.2 Neural Matching Features Traditional NLP Features The following features are designed based on words and syntactic analysis. Tf-idf cosine: each piece of text is converted to a one hot representation weighted by tf-idf values, where tf is the term frequency in the text, and idf is calculated using the unannotated Qatar corpora (Nakov et al., 2017). The cosine of representations of the two pieces of text is used as a feature. Longest common subse"
S17-2045,S17-2003,0,0.0948239,"Missing"
W17-6004,D13-1044,0,0.152058,"ion. However, these text patterns are too fine-grained to be adapted to new data. There are also many ranking methods which can choose a best answer from a candidate answer set, such as: 1) a simple and commonly used method is to rank candidate answers by the similarities between candidate answers and the unanswered question in Vector Space Model (VSM). This method can be used with Latent Semantic Analysis and word2vec tool (Mikolov et al., 2013). 2) Another commonly used method is to compute the similarities by syntactic information. To improve performance of this method, tree edit distance (Severyn and Moschitti, 2013) and factor graph (Sun et al., 2013) can be used. 3) Some work rank candidate answers by a combination of features, e.g., lexical features, semantic features, statistical features and similarity features, and so on (Severyn and Moschitti, 2013; Khodadi and Abadeh, 2016). For comprehensive utilization of these features, some global optimization algorithms such as GA are needed (Figueroa and Neumann, 2008). POS tree’s leaf nodes. Moreover, the Genetic Algorithm (GA) (Andrew, 1993) is used to train the weights. The results of the experiments show that the weighted POS tree trained by GA can impro"
W17-6004,P08-1077,0,0.0164454,"taining, updating and ranking. Besides, this method has low adaptability to new domains. 2) The most commonly adopted method is to use Named Entity Recognition (NER) tools to extract Named Entity (NE) that matching with question type (Xu et al., 2003). This method is always used together with question type classification algorithm. The performance of this method will be limited by the performance of classification algorithm and NER tools. 3) Another commonly used method is to etract candidate answers with text patterns which are edited manually or generated automatically (Zhang and Lee, 2002; Bhagat and Ravichandran, 2008; Khashabi et al., 2016). This method has high precision. However, these text patterns are too fine-grained to be adapted to new data. There are also many ranking methods which can choose a best answer from a candidate answer set, such as: 1) a simple and commonly used method is to rank candidate answers by the similarities between candidate answers and the unanswered question in Vector Space Model (VSM). This method can be used with Latent Semantic Analysis and word2vec tool (Mikolov et al., 2013). 2) Another commonly used method is to compute the similarities by syntactic information. To imp"
W17-6004,N13-1106,0,0.0832521,"Missing"
W17-6004,P02-1006,0,0.206003,"cuss about related work. In section 3, a method to construct a POS tree and another method to train the POS tree with GA will be presented in detail. In section 4, the experimental results of 10-fold cross-validation will be shown. In section 5, this paper will be concluded. 2 Related Work Answer extraction is the most difficult part of a web-based QA system. As such, it is also the focus of this paper. Traditional web-based QA systems typically use search snippets directly (Brill et al., 2001; Sun et al., 2015). Although plain texts in the retrieved HTML documents can offer more information (Ravichandran and Hovy, 2002; Liu et al., 2014), the search snippets as high-quality summarizations generated by search engines can save web-based QA systems from having to crawl, parse and filter HTML documents. In spite of efficiency improved by search engines, they lead to another problem: some state-of-the-art answer extraction methods (Severyn and Moschitti, 2013; Yao et al., 2013; Liu et al., 2014) rely on syntactic information cound be seriously affected by these search snippets which consis of incomplete sentences. The process of extracting a final answer from the search snippets has two steps: 1) extract candida"
Y11-1013,2005.mtsummit-papers.30,0,0.13999,"e is to select and optimize the training corpus to adapt to the test set (Lu et al., 2007) or the domain (Yasuda et al,. 2008); the second one is to select the sentence pairs with high quality as training corpus (Chen et al., 2006; Han et al., 2009), in which the quality is measured through the features of the sentence pair itself, such as the number of words that can be translated each other in the sentence pair; the third one is to measure and sort the sentence pairs based on the number of unknown n-grams in the sentences, and then select the sentence pair with the highest scores each time (Eck et al. 2005). This type of approaches considers the quality difference between the sentence pairs in the corpus. However, it still views the sentence pairs as independent. ∗ The work reported in this paper was supported by National Natural Science Foundation of China, Contract No. 61003111; and supported by Research Fund for the Doctoral Program of Higher Education of China (New teacher Fund), Contract No. 20101102120016 Copyright 2011 by WenHan Chao, ZhouJun Li 25th Pacific Asia Conference on Language, Information and Computation, pages 120–129 120 In this paper, we assume the quality of the translation"
Y11-1013,W09-3106,0,0.0456251,"result with the one using the whole corpus. Keywords: Statistical Machine Translation, Corpus Selection, Graph 1 Introduction In statistical machine translation, large scale of bilingual corpus is very important. In order to improve the quality of translation, there are two viewpoints about the use of corpus. One way is to collect more and more bilingual corpus to improve the quality of translation model, such as extracting the sentence pairs from the comparable corpus (Smith et al., 2010; Uszkoreit et al., 2010). However, some researchers found that, after the quantity of the sentence pairs (Han et al., 2009) in the corpus reaches some extent, adding more sentence pairs will not improve the quality of translation significantly. On the other hand, larger and larger corpus will consume more and more resources, which hinders the research progress of machine translation in some degree. This type of approaches assumes the sentence pairs in the corpus are independent each other, not considering the relationship between sentence pairs and their effect on the translation. The other view is to mine the potential of training corpus through corpus selection and optimization to improve the quality of the tran"
Y11-1013,D07-1036,0,0.060524,"Missing"
Y11-1013,P10-2041,0,0.0632611,"Missing"
Y11-1013,N10-1063,0,0.0609082,"Missing"
Y11-1013,I08-2088,0,0.252015,"Missing"
Y11-1013,C10-1124,0,0.0247149,"e whole corpus by the graph-based selection approach as training set, we can obtain the near translation result with the one using the whole corpus. Keywords: Statistical Machine Translation, Corpus Selection, Graph 1 Introduction In statistical machine translation, large scale of bilingual corpus is very important. In order to improve the quality of translation, there are two viewpoints about the use of corpus. One way is to collect more and more bilingual corpus to improve the quality of translation model, such as extracting the sentence pairs from the comparable corpus (Smith et al., 2010; Uszkoreit et al., 2010). However, some researchers found that, after the quantity of the sentence pairs (Han et al., 2009) in the corpus reaches some extent, adding more sentence pairs will not improve the quality of translation significantly. On the other hand, larger and larger corpus will consume more and more resources, which hinders the research progress of machine translation in some degree. This type of approaches assumes the sentence pairs in the corpus are independent each other, not considering the relationship between sentence pairs and their effect on the translation. The other view is to mine the potent"
