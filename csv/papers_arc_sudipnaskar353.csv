2021.smm4h-1.30,Fine-tuning {BERT} to classify {COVID}19 tweets containing symptoms,2021,-1,-1,2,0,1242,rajarshi roychoudhury,Proceedings of the Sixth Social Media Mining for Health ({\\#}SMM4H) Workshop and Shared Task,0,"Twitter is a valuable source of patient-generated data that has been used in various population health studies. The first step in many of these studies is to identify and capture Twitter messages (tweets) containing medication mentions. Identifying personal mentions of COVID19 symptoms requires distinguishing personal mentions from other mentions such as symptoms reported by others and references to news articles or other sources. In this article, we describe our submission to Task 6 of the Social Media Mining for Health Applications (SMM4H) Shared Task 2021. This task challenged participants to classify tweets where the target classes are:(1) self-reports,(2) non-personal reports, and (3) literature/news mentions. Our system used a handcrafted preprocessing and word embeddings from BERT encoder model. We achieved an F1 score of 93{\%}"
2021.dravidianlangtech-1.46,{JUNLP}@{D}ravidian{L}ang{T}ech-{EACL}2021: Offensive Language Identification in {D}ravidian Langauges,2021,-1,-1,3,0,11189,avishek garain,Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages,0,"Offensive language identification has been an active area of research in natural language processing. With the emergence of multiple social media platforms offensive language identification has emerged as a need of the hour. Traditional offensive language identification models fail to deliver acceptable results as social media contents are largely in multilingual and are code-mixed in nature. This paper tries to resolve this problem by using IndicBERT and BERT architectures, to facilitate identification of offensive languages for Kannada-English, Malayalam-English, and Tamil-English code-mixed language pairs extracted from social media. The presented approach when evaluated on the test corpus provided precision, recall, and F1 score for language pair Kannada-English as 0.62, 0.71, and 0.66, respectively, for language pair Malayalam-English as 0.77, 0.43, and 0.53, respectively, and for Tamil-English as 0.71, 0.74, and 0.72, respectively."
2020.trac-1.14,{S}pyder: Aggression Detection on Multilingual Tweets,2020,-1,-1,4,0,14316,anisha datta,"Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying",0,"In the last few years, hate speech and aggressive comments have covered almost all the social media platforms like facebook, twitter etc. As a result hatred is increasing. This paper describes our (\textbf{Team name:} \textbf{Spyder}) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. The Organizers provided datasets in three languages {--} English, Hindi and Bengali. The task was to classify each instance of the test sets into three categories {--} {``}Overtly Aggressive{''} (OAG), {``}Covertly Aggressive{''} (CAG) and {``}Non-Aggressive{''} (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers. We obtained f1 score of 43.10{\%}, 59.45{\%} and 44.84{\%} respectively for English, Hindi and Bengali."
2020.icon-main.20,A New Approach to Claim Check-Worthiness Prediction and Claim Verification,2020,-1,-1,3,0,14317,shukrity si,Proceedings of the 17th International Conference on Natural Language Processing (ICON),0,"The more we are advancing towards a modern world, the more it opens the path to falsification in every aspect of life. Even in case of knowing the surrounding, common people can not judge the actual scenario as the promises, comments and opinions of the influential people at power keep changing every day. Therefore computationally determining the truthfulness of such claims and comments has a very important societal impact. This paper describes a unique method to extract check-worthy claims from the 2016 US presidential debates and verify the truthfulness of the check-worthy claims. We classify the claims for check-worthiness with our modified Tf-Idf model which is used in background training on fact-checking news articles (NBC News and Washington Post). We check the truthfulness of the claims by using POS, sentiment score and cosine similarity features."
2020.icon-main.55,A Rule Based Lightweight {B}engali Stemmer,2020,-1,-1,3,0,19187,souvick das,Proceedings of the 17th International Conference on Natural Language Processing (ICON),0,"In the field of Natural Language Processing (NLP) the process of stemming plays a significant role. Stemmer transforms an inflected word to its root form. Stemmer significantly increases the efficiency of Information Retrieval (IR) systems. It is a very basic yet fundamental text pre-processing task widely used in many NLP tasks. Several important works on stemming have been carried out by researchers in English and other major languages. In this paper, we study and review existing works on stemming in Bengali and other Indian languages. Finally, we propose a rule based approach that explores Bengali morphology and leverages WordNet to achieve better accuracy. Our algorithm produced stemming accuracy of 98.86{\%} for Nouns and 99.75{\%} for Verbs."
2020.icon-main.57,Deep Neural Model for {M}anipuri Multiword Named Entity Recognition with Unsupervised Cluster Feature,2020,-1,-1,3,0,19192,jimmy laishram,Proceedings of the 17th International Conference on Natural Language Processing (ICON),0,"The recognition task of Multi-Word Named Entities (MNEs) in itself is a challenging task when the language is inflectional and agglutinative. Having breakthrough NLP researches with deep neural network and language modelling techniques, the applicability of such techniques/algorithms for Indian language like Manipuri remains unanswered. In this paper an attempt to recognize Manipuri MNE is performed using a Long Short Term Memory (LSTM) recurrent neural network model in conjunction with Part Of Speech (POS) embeddings. To further improve the classification accuracy, word cluster information using K-means clustering approach is added as a feature embedding. The cluster information is generated using a Skip-gram based words vector that contains the semantic and syntactic information of each word. The model so proposed does not use extensive language morphological features to elevate its accuracy. Finally the model{'}s performance is compared with the other machine learning based Manipuri MNE models."
2020.coling-main.524,The Transference Architecture for Automatic Post-Editing,2020,-1,-1,4,0.610827,13776,santanu pal,Proceedings of the 28th International Conference on Computational Linguistics,0,"In automatic post-editing (APE) it makes sense to condition post-editing (pe) decisions on both the source (src) and the machine translated text (mt) as input. This has led to multi-encoder based neural APE approaches. A research challenge now is the search for architectures that best support the capture, preparation and provision of src and mt information and its integration with pe decisions. In this paper we present an efficient multi-encoder based APE model, called transference. Unlike previous approaches, it (i) uses a transformer encoder block for src, (ii) followed by a decoder block, but without masking for self-attention on mt, which effectively acts as second encoder combining src {--}{\textgreater} mt, and (iii) feeds this representation into a final decoder block generating pe. Our model outperforms the best performing systems by 1 BLEU point on the WMT 2016, 2017, and 2018 English{--}German APE shared tasks (PBSMT and NMT). Furthermore, the results of our model on the WMT 2019 APE task using NMT data shows a comparable performance to the state-of-the-art system. The inference time of our model is similar to the vanilla transformer-based NMT system although our model deals with two separate encoders. We further investigate the importance of our newly introduced second encoder and find that a too small amount of layers does hurt the performance, while reducing the number of layers of the decoder does not matter much."
W19-6702,Improving {CAT} Tools in the Translation Workflow: New Approaches and Evaluation,2019,13,0,4,0.256706,19096,mihaela vela,"Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks",0,"This paper describes strategies to improve an existing web-based computer-aided translation (CAT) tool entitled CATaLog Online. CATaLog Online provides a post-editing environment with simple yet helpful project management tools. It offers translation suggestions from translation memories (TM), machine translation (MT), and automatic post-editing (APE) and records detailed logs of post-editing activities. To test the new approaches proposed in this paper, we carried out a user study on an English--German translation task using CATaLog Online. User feedback revealed that the users preferred using CATaLog Online over existing CAT tools in some respects, especially by selecting the output of the MT system and taking advantage of the color scheme for TM suggestions."
W19-5332,{JU}-{S}aarland Submission to the {WMT}2019 {E}nglish{--}{G}ujarati Translation Shared Task,2019,-1,-1,5,0,23873,riktim mondal,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"In this paper we describe our joint submission (JU-Saarland) from Jadavpur University and Saarland University in the WMT 2019 news translation shared task for English{--}Gujarati language pair within the translation task sub-track. Our baseline and primary submissions are built using Recurrent neural network (RNN) based neural machine translation (NMT) system which follows attention mechanism. Given the fact that the two languages belong to different language families and there is not enough parallel data for this language pair, building a high quality NMT system for this language pair is a difficult task. We produced synthetic data through back-translation from available monolingual data. We report the translation quality of our English{--}Gujarati and Gujarati{--}English NMT systems trained at word, byte-pair and character encoding levels where RNN at word level is considered as the baseline and used for comparison purpose. Our English{--}Gujarati system ranked in the second position in the shared task."
S19-2118,{JU}{\\_}{ETCE}{\\_}17{\\_}21 at {S}em{E}val-2019 Task 6: Efficient Machine Learning and Neural Network Approaches for Identifying and Categorizing Offensive Language in Tweets,2019,0,0,4,0,25081,preeti mukherjee,Proceedings of the 13th International Workshop on Semantic Evaluation,0,"This paper describes our system submissions as part of our participation (team name: JU{\_}ETCE{\_}17{\_}21) in the SemEval 2019 shared task 6: {``}OffensEval: Identifying and Catego- rizing Offensive Language in Social Media{''}. We participated in all the three sub-tasks: i) Sub-task A: offensive language identification, ii) Sub-task B: automatic categorization of of- fense types, and iii) Sub-task C: offense target identification. We employed machine learn- ing as well as deep learning approaches for the sub-tasks. We employed Convolutional Neural Network (CNN) and Recursive Neu- ral Network (RNN) Long Short-Term Memory (LSTM) with pre-trained word embeddings. We used both word2vec and Glove pre-trained word embeddings. We obtained the best F1- score using CNN based model for sub-task A, LSTM based model for sub-task B and Lo- gistic Regression based model for sub-task C. Our best submissions achieved 0.7844, 0.5459 and 0.48 F1-scores for sub-task A, sub-task B and sub-task C respectively."
W18-6455,{ITER}: Improving Translation Edit Rate through Optimizable Edit Costs,2018,0,3,2,0,27728,joybrata panja,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"The paper presents our participation in the WMT 2018 Metrics Shared Task. We propose an improved version of Translation Edit/Error Rate (TER). In addition to including the basic edit operations in TER, namely - insertion, deletion, substitution and shift, our metric also allows stem matching, optimizable edit costs and better normalization so as to correlate better with human judgement scores. The proposed metric shows much higher correlation with human judgments than TER."
W18-6457,Keep It or Not: Word Level Quality Estimation for Post-Editing,2018,0,0,3,0,27729,prasenjit basu,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"The paper presents our participation in the WMT 2018 shared task on word level quality estimation (QE) of machine translated (MT) text, i.e., to predict whether a word in MT output for a given source context is correctly translated and hence should be retained in the post-edited translation (PE), or not. To perform the QE task, we measure the similarity of the source context of the target MT word with the context for which the word is retained in PE in the training data. This is achieved in two different ways, using \textit{Bag-of-Words} (\textit{BoW}) model and \textit{Document-to-Vector} (\textit{Doc2Vec}) model. In the \textit{BoW} model, we compute the cosine similarity while in the \textit{Doc2Vec} model we consider the Doc2Vec similarity. By applying the Kneedle algorithm on the F1mult vs. similarity score plot, we derive the threshold based on which OK/BAD decisions are taken for the MT words. Experimental results revealed that the Doc2Vec model performs better than the BoW model on the word level QE task."
W17-7519,Natural Language Programing with Automatic Code Generation towards Solving Addition-Subtraction Word Problems,2017,0,0,2,0,31194,sourav mandal,Proceedings of the 14th International Conference on Natural Language Processing ({ICON}-2017),0,None
W17-7537,Unsupervised Morpheme Segmentation Through Numerical Weighting and Thresholding,2017,0,0,2,1,5997,joy mahapatra,Proceedings of the 14th International Conference on Natural Language Processing ({ICON}-2017),0,None
W17-7539,Normalization of Social Media Text using Deep Neural Networks,2017,0,0,2,0,31215,ajay tiwari,Proceedings of the 14th International Conference on Natural Language Processing ({ICON}-2017),0,None
E17-2056,Neural Automatic Post-Editing Using Prior Alignment and Reranking,2017,0,9,2,0.935894,13776,santanu pal,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"We present a second-stage machine translation (MT) system based on a neural machine translation (NMT) approach to automatic post-editing (APE) that improves the translation quality provided by a first-stage MT system. Our APE system (APE{\_}Sym) is an extended version of an attention based NMT model with bilingual symmetry employing bidirectional models, mt{--}pe and pe{--}mt. APE translations produced by our system show statistically significant improvements over the first-stage MT, phrase-based APE and the best reported score on the WMT 2016 APE dataset by a previous neural APE system. Re-ranking (APE{\_}Rerank) of the n-best translations from the phrase-based APE and APE{\_}Sym systems provides further substantial improvements over the symmetric neural APE model. Human evaluation confirms that the APE{\_}Rerank generated PE translations improve on the previous best neural APE system at WMT 2016."
W16-6624,Statistical Natural Language Generation from Tabular Non-textual Data,2016,18,6,2,1,5997,joy mahapatra,Proceedings of the 9th International Natural Language Generation conference,0,None
W16-6308,Biomolecular Event Extraction using a Stacked Generalization based Classifier,2016,0,2,3,0,33366,amit majumder,Proceedings of the 13th International Conference on Natural Language Processing,0,None
W16-2333,{JU-USAAR}: A Domain Adaptive {MT} System,2016,27,1,4,0,33889,koushik pahari,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the JU-USAAR Englishxe2x80x90German domain adaptive machine translation (MT) system submitted to the IT domain translation task organized in WMT-2016 . Our system brings improvements over the in-domain baseline system by incorporating out-domain knowledge. We applied two methodologies to accelerate the performance of our in-domain MT system: (i) additional training material extraction from out-domain data using data selection method, and (ii) language model and translation model adaptation through interpolation. Our primary submission obtained a BLEU score of 34.5 (14.5 absolute and 72.5% relative improvements over baseline) and a TER score of 54.0 (14.7 absolute and 21.4% relative improvements over baseline)."
P16-2046,A Neural Network based Approach to Automatic Post-Editing,2016,18,10,2,0.975422,13776,santanu pal,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,None
L16-1095,{CAT}a{L}og Online: Porting a Post-editing Tool to the Web,2016,15,3,3,0.975422,13776,santanu pal,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents CATaLog online, a new web-based MT and TM post-editing tool. CATaLog online is a freeware software that can be used through a web browser and it requires only a simple registration. The tool features a number of editing and log functions similar to the desktop version of CATaLog enhanced with several new features that we describe in detail in this paper. CATaLog online is designed to allow users to post-edit both translation memory segments as well as machine translation output. The tool provides a complete set of log information currently not available in most commercial CAT tools. Log information can be used both for project management purposes as well as for the study of the translation process and translator{'}s productivity."
C16-2021,{CAT}a{L}og Online: A Web-based {CAT} Tool for Distributed Translation with Data Capture for {APE} and Translation Process Research,2016,4,1,2,0.975422,13776,santanu pal,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"We present a free web-based CAT tool called CATaLog Online which provides a novel and user-friendly online CAT environment for post-editors/translators. The goal is to support distributed translation, reduce post-editing time and effort, improve the post-editing experience and capture data for incremental MT/APE (automatic post-editing) and translation process research. The tool supports individual as well as batch mode file translation and provides translations from three engines {--} translation memory (TM), MT and APE. TM suggestions are color coded to accelerate the post-editing task. The users can integrate their personal TM/MT outputs. The tool remotely monitors and records post-editing activities generating an extensive range of post-editing logs."
C16-1241,Multi-Engine and Multi-Alignment Based Automatic Post-Editing and its Impact on Translation Productivity,2016,30,1,2,0.975422,13776,santanu pal,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"In this paper we combine two strands of machine translation (MT) research: automatic post-editing (APE) and multi-engine (system combination) MT. APE systems learn a target-language-side second stage MT system from the data produced by human corrected output of a first stage MT system, to improve the output of the first stage MT in what is essentially a sequential MT system combination architecture. At the same time, there is a rich research literature on parallel MT system combination where the same input is fed to multiple engines and the best output is selected or smaller sections of the outputs are combined to obtain improved translation output. In the paper we show that parallel system combination in the APE stage of a sequential MT-APE combination yields substantial translation improvements both measured in terms of automatic evaluation metrics as well as in terms of productivity improvements measured in a post-editing experiment. We also show that system combination on the level of APE alignments yields further improvements. Overall our APE system yields statistically significant improvement of 5.9{\%} relative BLEU over a strong baseline (English{--}Italian Google MT) and 21.76{\%} productivity increase in a human post-editing experiment with professional translators."
W15-5206,{CAT}a{L}og: New Approaches to {TM} and Post Editing Interfaces,2015,15,6,2,0,36496,tapas nayek,Proceedings of the Workshop Natural Language Processing for Translation Memories,0,None
W15-3017,{U}d{S}-Sant: {E}nglish{--}{G}erman Hybrid Machine Translation System,2015,19,5,2,1,13776,santanu pal,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,This paper describes the UdS-Sant Englishxe2x80x90German Hybrid Machine Translation (MT) system submitted to the Translation Task organized in the Workshop on Statistical Machine Translation (WMT) 2015. Our proposed hybrid system brings improvements over the baseline system by incorporating additional knowledge such as extracted bilingual named entities and bilingual phrase pairs induced from example-based methods. The reported final submission is the result of a hybrid system obtained from confusion network based system combination that combines the best performance of each individual system in a multi-engine pipeline.
W15-3026,{USAAR}-{SAPE}: An {E}nglish{--}{S}panish Statistical Automatic Post-Editing System,2015,32,11,3,1,13776,santanu pal,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"We describe the USAAR-SAPE Englishxe2x80x90 Spanish Automatic Post-Editing (APE) system submitted to the APE Task organized in the Workshop on Statistical Machine Translation (WMT) in 2015. Our system was able to improve upon the baseline MT system output by incorporating Phrase-Based Statistical MT (PBSMT) technique into the monolingual Statistical APE task (SAPE). The reported final submission crucially involves hybrid word alignment. The SAPE system takes raw Spanish Machine Translation (MT) output provided by the shared task organizers and produces post-edited Spanish text. The parallel data consist of English Text, raw machine translated Spanish output, and their corresponding manually post-edited versions. The major goal of the task is to reduce the post-editing effort by improving the quality of the MT output in terms of fluency and adequacy."
W14-5114,How Sentiment Analysis Can Help Machine Translation,2014,0,0,4,1,13776,santanu pal,Proceedings of the 11th International Conference on Natural Language Processing,0,None
W14-1009,Automatic Building and Using Parallel Resources for {SMT} from Comparable Corpora,2014,24,19,3,1,13776,santanu pal,Proceedings of the 3rd Workshop on Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"Building parallel resources for corpus based machine translation, especially Statistical Machine Translation (SMT), from comparable corpora has recently received wide attention in the field Machine Translation research. In this paper, we propose an automatic approach for extraction of parallel fragments from comparable corpora. The comparable corpora are collected from Wikipedia documents and this approach exploits the multilingualism of Wikipedia. The automatic alignment process of parallel text fragments uses a textual entailment technique and Phrase Based SMT (PBSMT) system. The parallel text fragments extracted thus are used as additional parallel translation examples to complement the training data for a PBSMT system. The additional training data extracted from comparable corpora provided significant improvements in terms of translation quality over the baseline as measured by BLEU."
pal-etal-2014-word,Word Alignment-Based Reordering of Source Chunks in {PB}-{SMT},2014,26,3,2,1,13776,santanu pal,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Reordering poses a big challenge in statistical machine translation between distant language pairs. The paper presents how reordering between distant language pairs can be handled efficiently in phrase-based statistical machine translation. The problem of reordering between distant languages has been approached with prior reordering of the source text at chunk level to simulate the target language ordering. Prior reordering of the source chunks is performed in the present work by following the target word order suggested by word alignment. The testset is reordered using monolingual MT trained on source and reordered source. This approach of prior reordering of the source chunks was compared with pre-ordering of source words based on word alignments and the traditional approach of prior source reordering based on language-pair specific reordering rules. The effects of these reordering approaches were studied on an English--Bengali translation task, a language pair with different word order. From the experimental results it was found that word alignment based reordering of the source chunks is more effective than the other reordering approaches, and it produces statistically significant improvements over the baseline system on BLEU. On manual inspection we found significant improvements in terms of word alignments."
2014.amta-wptp.5,Perception vs. reality: measuring machine translation post-editing productivity,2014,-1,-1,3,0.605519,4999,federico gaspari,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas,0,"This paper presents a study of user-perceived vs real machine translation (MT) post-editing effort and productivity gains, focusing on two bidirectional language pairs: English{---}German and English{---}Dutch. Twenty experienced media professionals post-edited statistical MT output and also manually translated comparative texts within a production environment. The paper compares the actual post-editing time against the users{'} perception of the effort and time required to post-edit the MT output to achieve publishable quality, thus measuring real (vs perceived) productivity gains. Although for all the language pairs users perceived MT post-editing to be slower, in fact it proved to be a faster option than manual translation for two translation directions out of four, i.e. for Dutch to English, and (marginally) for English to German. For further objective scrutiny, the paper also checks the correlation of three state-of-the-art automatic MT evaluation metrics (BLEU, METEOR and TER) with the actual post-editing time."
W13-2814,A Hybrid Word Alignment Model for Phrase-Based Statistical Machine Translation,2013,25,9,2,1,13776,santanu pal,Proceedings of the Second Workshop on Hybrid Approaches to Translation,0,This paper proposes a hybrid word alignment model for Phrase-Based Statistical Machine translation (PB-SMT). The proposed hybrid alignment model provides most informative alignment links which are offered by both unsupervised and semi-supervised word alignment models. Two unsupervised word alignment models (GIZA and Berkeley aligner) and a rule based aligner are combined together. The rule based aligner only aligns named entities (NEs) and chunks. The NEs are aligned through transliteration using a joint source-channel model. Chunks are aligned employing a bootstrapping approach by translating the source chunks into the target language using a baseline PB-SMT system and subsequently validating the target chunks using a fuzzy matching technique against the target corpus. All the experiments are carried out after single-tokenizing the multi-word NEs. Our best system provided significant improvements over the baseline as measured by BLEU.
N13-3005,A Web Application for the Diagnostic Evaluation of Machine Translation over Specific Linguistic Phenomena,2013,12,1,2,0.172925,9426,antonio toral,Proceedings of the 2013 {NAACL} {HLT} Demonstration Session,0,"This paper presents a web application and a web service for the diagnostic evaluation of Machine Translation (MT). These web-based tools are built on top of DELiC4MT, an opensource software package that assesses the performance of MT systems over user-defined linguistic phenomena (lexical, morphological, syntactic and semantic). The advantage of the web-based scenario is clear; compared to the standalone tool, the user does not need to carry out any installation, configuration or maintenance of the tool."
2013.mtsummit-papers.8,{MWE} Alignment in Phrase Based Statistical Machine Translation,2013,-1,-1,2,1,13776,santanu pal,Proceedings of Machine Translation Summit XIV: Papers,0,None
2013.mtsummit-papers.17,Meta-Evaluation of a Diagnostic Quality Metric for Machine Translation,2013,20,0,1,1,1243,sudip naskar,Proceedings of Machine Translation Summit XIV: Papers,0,"Diagnostic evaluation of machine translation (MT) is an approach to evaluation that provides finer-grained information compared to state-of-the-art automatic metrics. This paper evaluates DELiC4MT, a diagnostic metric that assesses the performance of MT systems on user-defined linguistic phenomena. We present the results obtained using this diagnostic metric when evaluating three MT systems that translate from English to French, with a comparison against both human judgements and a set of representative automatic evaluation metrics. In addition, as the diagnostic metric relies on word alignments, the paper compares the margin of error in diagnostic evaluation when using automatic word alignments as opposed to gold standard manual alignments. We observed that this diagnostic metric is capable of accurately reflecting translation quality, can be used reliably with automatic word alignments and, in general, correlates well with automatic metrics and, more importantly, with human judgements."
W12-5606,A Diagnostic Evaluation Approach Targeting {MT} Systems for {I}ndian Languages,2012,26,1,2,0,42065,renu balyan,Proceedings of the Workshop on Machine Translation and Parsing in {I}ndian Languages,0,"This paper addresses diagnostic evaluation of machine translation (MT) systems for Indian languages, English to Hindi translation in particular. Evaluation of MT output is an important but difficult task. The difficulty arises primarily from some inherent characteristics of the language pairs, which range from simple word-level discrepancies to more difficult structural variations for Hindi from English, such as reduplication of words, free word order etc. The proposed scheme is based on identification of linguistic units (often referred to as checkpoints). We use the diagnostic evaluation tool DELiC4MT to analyze the contribution of various PoS classes for different categories. We further suggest some additional checkpoints based on named entities, ambiguous words, word order and inflections that are relevant for the evaluation of Hindi. The evaluation of these checkpoints provides a detailed analysis and helps in monitoring how an MT system handles these linguistic phenomena as well. This also provides valuable feedback to MT developers as to where the system is performing poorly and how the output can possibly be improved. The effectiveness of the approach was tested on 5 English to Hindi MT systems and it was observed that the system-level DELiC4MT scores correlate well with the scores produced by the most commonly used automatic evaluation metrics (BLEU, NIST, METEOR and TER) while providing finer-grained information."
C12-1010,Translation Quality-Based Supplementary Data Selection by Incremental Update of Translation Models,2012,27,8,2,1,41915,pratyush banerjee,Proceedings of {COLING} 2012,0,"Supplementary data selection from out-of-domain or related-domain data is a well established technique in domain adaptation of statistical machine translation. The selection criteria for such data are mostly based on measures of similarity with available in-domain data, but not directly in terms of translation quality. In this paper, we present a technique for selecting supplementary data to improve translation performance, directly in terms of translation quality, measured by automatic evaluation metric scores. Batches of data selected from out-of-domain corpora are incrementally added to an existing baseline system and evaluated in terms of translation quality on a development set. A batch is selected only if its inclusion improves translation quality. To assist the process, we present a novel translation model merging technique that allows rapid retraining of the translation models with incremental data. When incorporated into the xe2x80x98in-domainxe2x80x99 translation models, the final cumulatively selected datasets are found to provide statistically significant improvements for a number of different supplementary datasets. Furthermore, the translation model merging technique is found to perform on a par with state-of-the-art methods of phrase-table combination."
2012.eamt-1.41,Domain Adaptation in {SMT} of User-Generated Forum Content Guided by {OOV} Word Reduction: Normalization and/or Supplementary Data,2012,14,19,2,1,41915,pratyush banerjee,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"This paper reports a set of domain adaptation techniques for improving Statistical Machine Translation (SMT) for usergenerated web forum content. We investigate both normalization and supplementary training data acquisition techniques, all guided by the aim of reducing the number of Out-Of-Vocabulary (OOV) items in the target language with respect to the training data. We classify OOVs into a set of types, and address each through dedicated normalization and/or supplementary training material selection-based approaches. We investigate the effect of these methods both in an additive as well as a contrastive scenario. Our findings show that (i) normalization and supplementary training material techniques can be complementary, (ii) for general forum data, fully automatic supplementary training data acquisition can perform as well or sometimes better than semi-automatic normalization (although tackling different types of OOVs) and (iii) for very noisy data, normalization really pays off."
2011.mtsummit-papers.32,Domain Adaptation in Statistical Machine Translation of User-Forum Data using Component Level Mixture Modelling,2011,-1,-1,2,1,41915,pratyush banerjee,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.mtsummit-papers.60,A Framework for Diagnostic Evaluation of {MT} Based on Linguistic Checkpoints,2011,-1,-1,1,1,1243,sudip naskar,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.iwslt-evaluation.4,The {DCU} machine translation systems for {IWSLT} 2011,2011,0,3,3,1,41915,pratyush banerjee,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we provide a description of the Dublin City University{'}s (DCU) submissions in the IWSLT 2011 evaluationcampaign.1 WeparticipatedintheArabic-Englishand Chinese-English Machine Translation(MT) track translation tasks. We use phrase-based statistical machine translation (PBSMT) models to create the baseline system. Due to the open-domain nature of the data to be translated, we use domain adaptation techniques to improve the quality of translation. Furthermore, we explore target-side syntactic augmentation for an Hierarchical Phrase-Based (HPB) SMT model. Combinatory Categorial Grammar (CCG) is used to extract labels for target-side phrases and non-terminals in the HPB system. Combining the domain adapted language models with the CCG-augmented HPB system gave us the best translations for both language pairs providing statistically significant improvements of 6.09 absolute BLEU points (25.94{\%} relative) and 1.69 absolute BLEU points (15.89{\%} relative) over the unadapted PBSMT baselines for the Arabic-English and Chinese-English language pairs, respectively."
2011.eamt-1.4,A Comparative Evaluation of Research vs. Online {MT} Systems,2011,19,3,3,0.172925,9426,antonio toral,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"This paper reports MT evaluation experiments that were conducted at the end of year 1 of the EU-funded CoSynen 1 project for three language combinations, considering translations from German, Italian and Dutch into English. We present a comparative evaluation of the MT software developed within the project against four of the leading free webbased MT systems across a range of state-of-the-art automatic evaluation metrics. The data sets from the news domain that were created and used for training purposes and also for this evaluation exercise, which are available to the research community, are also described. The evaluation results for the news domain are very encouraging: the CoSyne MT software consistently beats the rule-based MT systems, and for translations from Italian and Dutch into English in particular the scores given by some of the standard automatic evaluation metrics are not too distant from those obtained by wellestablished statistical online MT systems."
2011.eamt-1.29,Combining Semantic and Syntactic Generalization in Example-Based Machine Translation,2011,21,3,4,0,3154,sarah ebling,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"In this paper, we report our experiments in combining two EBMT systems that rely on generalized templates, Marclator and CMU-EBMT, on an Englishxe2x80x90German translation task. Our goal was to see whether a statistically significant improvement could be achieved over the individual performances of these two systems. We observed that this was not the case. However, our system consistently outperformed a lexical EBMT baseline system."
Y10-1041,Mitigating Problems in Analogy-based {EBMT} with {SMT} and vice versa: A Case Study with Named Entity Transliteration,2010,11,8,3,0.964912,6023,sandipan dandapat,"Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation",0,"Five years ago, a number of papers reported an experimental implementation of an Example Based Machine Translation (EBMT) system using proportional analogy. This approach, a type of analogical learning, was attractive because of its simplicity; and the paper reported considerable success with the method using various language pairs. In this paper, we describe our attempt to use this approach for tackling English-Hindi Named Entity (NE) Transliteration. We have implemented our own EBMT system using proportional analogy and have found that the analogy-based system on its own has low precision but a high recall due to the fact that a large number of names are untransliterated with the approach. However, mitigating problems in analogy-based EBMT with SMT and vice-versa have shown considerable improvement over the individual approach."
W10-3707,Handling Named Entities and Compound Verbs in Phrase-Based Statistical Machine Translation,2010,25,23,2,0.841323,13776,santanu pal,Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications,0,"Data preprocessing plays a crucial role in phrase-based statistical machine translation (PB-SMT). In this paper, we show how single-tokenization of two types of multi-word expressions (MWE), namely named entities (NE) and compound verbs, as well as their prior alignment can boost the performance of PB-SMT. Single-tokenization of compound verbs and named entities (NE) provides significant gains over the baseline PB-SMT system. Automatic alignment of NEs substantially improves the overall MT performance, and thereby the word alignment quality indirectly. For establishing NE alignments, we transliterate source NEs into the target language and then compare them with the target NEs. Target language NEs are first converted into a canonical form before the comparison takes place. Our best system achieves statistically significant improvements (4.59 BLEU points absolute, 52.5% relative improvement) on an Englishxe2x80x94Bangla translation task."
W10-1720,{MATREX}: The {DCU} {MT} System for {WMT} 2010,2010,29,40,8,0,38356,sergio penkale,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the DCU machine translation system in the evaluation campaign of the Joint Fifth Workshop on Statistical Machine Translation and Metrics in ACL-2010. We describe the modular design of our multi-engine machine translation (MT) system with particular focus on the components used in this participation. We participated in the English--Spanish and English--Czech translation tasks, in which we employed our multi-engine architecture to translate. We also participated in the system combination task which was carried out by the MBR decoder and confusion network decoder."
2010.amta-papers.16,Combining Multi-Domain Statistical Machine Translation Models using Automatic Classifiers,2010,20,31,4,1,41915,pratyush banerjee,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This paper presents a set of experiments on Domain Adaptation of Statistical Machine Translation systems. The experiments focus on Chinese-English and two domain-specific corpora. The paper presents a novel approach for combining multiple domain-trained translation models to achieve improved translation quality for both domain-specific as well as combined sets of sentences. We train a statistical classifier to classify sentences according to the appropriate domain and utilize the corresponding domain-specific MT models to translate them. Experimental results show that the method achieves a statistically significant absolute improvement of 1.58 BLEU (2.86{\%} relative improvement) score over a translation model trained on combined data, and considerable improvements over a model using multiple decoding paths of the Moses decoder, for the combined domain test set. Furthermore, even for domain-specific test sets, our approach works almost as well as dedicated domain-specific models and perfect classification."
2010.amta-papers.23,Supertags as Source Language Context in Hierarchical Phrase-Based {SMT},2010,31,16,2,1,5016,rejwanul haque,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"Statistical machine translation (SMT) models have recently begun to include source context modeling, under the assumption that the proper lexical choice of the translation for an ambiguous word can be determined from the context in which it appears. Various types of lexical and syntactic features have been explored as effective source context to improve phrase selection in SMT. In the present work, we introduce lexico-syntactic descriptions in the form of supertags as source-side context features in the state-of-the-art hierarchical phrase-based SMT (HPB) model. These features enable us to exploit source similarity in addition to target similarity, as modelled by the language model. In our experiments two kinds of supertags are employed: those from lexicalized tree-adjoining grammar (LTAG) and combinatory categorial grammar (CCG). We use a memory-based classification framework that enables the efficient estimation of these features. Despite the differences between the two supertagging approaches, they give similar improvements. We evaluate the performance of our approach on an English-to-Dutch translation task, and report statistically significant improvements of 4.48{\%} and 6.3{\%} BLEU scores in translation quality when adding CCG and LTAG supertags, respectively, as context-informed features."
Y09-2027,Experiments on Domain Adaptation for {E}nglish{--}{H}indi {SMT},2009,29,10,2,1,5016,rejwanul haque,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 2",0,"Statistical Machine Translation (SMT) systems are usually trained on large amounts of bilingual text and monolingual target language text. If a significant amount of out-of-domain data is added to the training data, the quality of translation can drop. On the other hand, training an SMT system on a small amount of training material for given in- domain data leads to narrow lexical coverage which again results in a low translation quality. In this paper, (i) we explore domain-adaptation techniques to combine large out-of-domain training data with small-scale in-domain training data for Englishxe2x80x94Hindi statistical machine translation and (ii) we cluster large out-of-domain training data to extract sentences similar to in-domain sentences and apply adaptation techniques to combine clustered sub-corpora with in-domain training data into a unified framework, achieving a 0.44 absolute corresponding to a 4.03% relative improvement in terms of BLEU over the baseline."
Y09-1019,Dependency Relations as Source Context in Phrase-Based {SMT},2009,31,9,2,1,5016,rejwanul haque,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 1",0,"The Phrase-Based Statistical Machine Translation (PB-SMT) model has recently begun to include source context modeling, under the assumption that the proper lexicaln choice of an ambiguous word can be determined from the context in which it appears. Various types of lexical and syntactic features such as words, parts-of-speech, andn supertags have been explored as effective source context in SMT. In this paper, we show that position-independent syntactic dependency relations of the head of a source phrase can be modeled as useful source context to improve target phrase selection and thereby improve overall performance of PB-SMT. On a Dutchxe2x80x94English translation task, by combining dependency relations and syntactic contextual features (part-of-speech), we achieved a 1.0 BLEU (Papineni et al., 2002) point improvement (3.1% relative) over the baseline."
W09-3523,{E}nglish-{H}indi Transliteration Using Context-Informed {PB}-{SMT}: the {DCU} System for {NEWS} 2009,2009,15,15,4,1,5016,rejwanul haque,Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration ({NEWS} 2009),0,"This paper presents English---Hindi transliteration in the NEWS 2009 Machine Transliteration Shared Task adding source context modeling into state-of-the-art log-linear phrase-based statistical machine translation (PB-SMT). Source context features enable us to exploit source similarity in addition to target similarity, as modelled by the language model. We use a memory-based classification framework that enables efficient estimation of these features while avoiding data sparseness problems.We carried out experiments both at character and transliteration unit (TU) level. Position-dependent source context features produce significant improvements in terms of all evaluation metrics."
2009.eamt-1.32,Using Supertags as Source Language Context in {SMT},2009,34,27,2,1,5016,rejwanul haque,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"Recent research has shown that Phrase-Based Statistical Machine Translation (PB-SMT) systems can benefit from twon enhancements: (i) using words and POS tags as context-informed features on the source side; and (ii) incorporating lexical syntactic descriptions in the form of supertags on the target side. In this work wen present a novel PB-SMT model that combines these two aspects by using supertags as source language contextinformed features. These features enable us to exploit source similarity in addition to target similarity, as modelled by the language model. In our experiments twon kinds of supertags are employed: those from Lexicalized Tree-Adjoining Grammar and Combinatory Categorial Grammar.n We use a memory-based classification framework that enables the estimation of these features while avoidingn problems of sparseness. Despite the differences between these two approaches, the supertaggers give similar improvements. We evaluate the performance of our approach on an English-to-Chinese translation task using a state-of-the-art phrase-based SMT system, and report ann improvement of 7.88% BLEU score in translation quality when adding supertags as context-informed features."
I08-6011,"{B}engali, {H}indi and {T}elugu to {E}nglish Ad-hoc Bilingual Task",2008,0,6,3,0,360,sivaji bandyopadhyay,Proceedings of the 2nd workshop on Cross Lingual Information Access ({CLIA}) Addressing the Information Need of Multilingual Societies,0,"This paper presents the experiments carried out at Jadavpur University as part of participation in the CLEF 2007 ad-hoc bilingual task. This is our first participation in the CLEF evaluation task and we have considered Bengali, Hindi and Telugu as query languages for the retrieval from English document collection. We have discussed our Bengali, Hindi and Telugu to English CLIR system as part of the ad-hoc bilingual task, English IR system for the ad-hoc monolingual task and the associated experiments at CLEF. Query construction was manual for Telugu-English ad-hoc bilingual task, while it was automatic for all other tasks."
S07-1043,{JU}-{SKNSB}: Extended {W}ord{N}et Based {WSD} on the {E}nglish All-Words Task at {S}em{E}val-1,2007,6,3,1,1,1243,sudip naskar,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper presents an Extended WordNet based word sense disambiguation system using a major modification to the Lesk algorithm. The algorithm tries to disambiguate nouns, verbs and adjectives. The algorithm relies on the POS-sense tagged synset glosses provided by the Extended WordNet. The basic unit of disambiguation of our algorithm is the entire sentence under consideration. It takes a global approach where all the words in the target sentence are simultaneously disambiguated. The context includes previous and next sentence. The system assigns the default WordNet first sense to a word when the algorithm fails to predict the sense of the word. The system produces a precision and recall of .402 on the SemEval-2007 English All-Words test data."
W06-2113,Handling of Prepositions in {E}nglish to {B}engali Machine Translation,2006,20,22,1,1,1243,sudip naskar,Proceedings of the Third {ACL}-{SIGSEM} Workshop on Prepositions,0,"The present study focuses on the lexical meanings of prepositions rather than on the thematic meanings because it is intended for use in an English-Bengali machine translation (MT) system, where the meaning of a lexical unit must be preserved in the target language, even though it may take a different syntactic form in the source and target languages. Bengali is the fifth language in the world in terms of the number of native speakers and is an important language in India. There is no concept of preposition in Bengali. English prepositions are translated to Bengali by attaching appropriate inflections to the head noun of the prepositional phrase (PP), i.e., the object of the preposition. The choice of the inflection depends on the spelling pattern of the translated Bengali head noun. Further postpositional words may also appear in the Bengali translation for some prepositions. The choice of the appropriate post-positional word depends on the WordNet synset information of the head noun. Idiomatic or metaphoric PPs are translated into Bengali by looking into a bilingual example base. The analysis presented here is general and applicable for translation from English to many other Indo-Aryan languages that handle prepositions using inflections and postpositions."
P06-2025,A Modified Joint Source-Channel Model for Transliteration,2006,12,52,2,0.0715511,363,asif ekbal,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,Most machine transliteration systems transliterate out of vocabulary (OOV) words through intermediate phonemic mapping. A framework has been presented that allows direct orthographical mapping between two languages that are of different origins employing different alphabet sets. A modified joint source-channel model along with a number of alternatives have been proposed. Aligned transliteration units along with their context are automatically derived from a bilingual training corpus to generate the collocational statistics. The transliteration units in Bengali words take the pattern CM where C represents a vowel or a consonant or a conjunct and M represents the vowel modifier or matra. The English transliteration units are of the form C*V* where C represents a consonant and V represents a vowel. A Bengali-English machine transliteration system has been developed based on the proposed models. The system has been trained to transliterate person names from Bengali to English. It uses the linguistic knowledge of possible conjuncts and diphthongs in Bengali and their equivalents in English. The system has been evaluated and it has been observed that the modified joint source-channel model performs best with a Word Agreement Ratio of 69.3% and a Transliteration Unit Agreement Ratio of 89.8%.
2005.mtsummit-posters.8,A Phrasal {EBMT} System for Translating {E}nglish to {B}engali,2005,7,16,1,1,1243,sudip naskar,Proceedings of Machine Translation Summit X: Posters,0,"The present work describes a Phrasal Example Based Machine Translation system from English to Bengali that identifies the phrases in the input through a shallow analysis, retrieves the target phrases using a Phrasal Example base and finally combines the target language phrases employing some heuristics based on the phrase ordering rules for Bengali. The paper focuses on the structure of the noun, verb and prepositional phrases in English and how these phrases are realized in Bengali. This study has an effect on the design of the phrasal Example Base and recombination rules for the target language phrases."
2005.mtsummit-posters.21,Use of Machine Translation in {I}ndia: Current Status,2005,-1,-1,1,1,1243,sudip naskar,Proceedings of Machine Translation Summit X: Posters,0,A survey of the machine translation systems that have been developed in India for translation from English to Indian languages and among Indian languages reveals that the MT softwares are used in field testing or are available as web translation service. These systems are also used for teaching machine translation to the students and researchers. Most of these systems are in the English-Hindi or Indian language-Indian language domain. The translation domains are mostly government documents/reports and news stories. There are a number of other MT systems that are at their various phases of development and have been demonstrated at various forums. Many of these systems cover other Indian languages beside Hindi.
