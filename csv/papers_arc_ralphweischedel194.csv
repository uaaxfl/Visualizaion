2021.naacl-main.343,Plot-guided Adversarial Example Construction for Evaluating Open-domain Story Generation,2021,-1,-1,4,0,4276,sarik ghazarian,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"With the recent advances of open-domain story generation, the lack of reliable automatic evaluation metrics becomes an increasingly imperative issue that hinders the fast development of story generation. According to conducted researches in this regard, learnable evaluation metrics have promised more accurate assessments by having higher correlations with human judgments. A critical bottleneck of obtaining a reliable learnable evaluation metric is the lack of high-quality training data for classifiers to efficiently distinguish plausible and implausible machine-generated stories. Previous works relied on \textit{heuristically manipulated} plausible examples to mimic possible system drawbacks such as repetition, contradiction, or irrelevant content in the text level, which can be \textit{unnatural} and \textit{oversimplify} the characteristics of implausible machine-generated stories. We propose to tackle these issues by generating a more comprehensive set of implausible stories using \textit{plots}, which are structured representations of controllable factors used to generate stories. Since these plots are compact and structured, it is easier to manipulate them to generate text with targeted undesirable properties, while at the same time maintain the grammatical correctness and naturalness of the generated sentences. To improve the quality of generated implausible stories, we further apply the adversarial filtering procedure presented by (CITATION) to select a more nuanced set of implausible texts. Experiments show that the evaluation metrics trained on our generated data result in more reliable automatic assessments that correlate remarkably better with human judgments compared to the baselines."
2021.naacl-demos.2,Machine-Assisted Script Curation,2021,-1,-1,7,0,2714,manuel ciosici,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations,0,"We describe Machine-Aided Script Curator (MASC), a system for human-machine collaborative script authoring. Scripts produced with MASC include (1) English descriptions of sub-events that comprise a larger, complex event; (2) event types for each of those events; (3) a record of entities expected to participate in multiple sub-events; and (4) temporal sequencing between the sub-events. MASC automates portions of the script creation process with suggestions for event types, links to Wikidata, and sub-events that may have been forgotten. We illustrate how these automations are useful to the script writer with a few case-study scripts."
2021.emnlp-main.493,Perhaps {PTLM}s Should Go to School {--} A Task to Assess Open Book and Closed Book {QA},2021,-1,-1,6,0,2714,manuel ciosici,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Our goal is to deliver a new task and leaderboard to stimulate research on question answering and pre-trained language models (PTLMs) to understand a significant instructional document, e.g., an introductory college textbook or a manual. PTLMs have shown great success in many question-answering tasks, given significant supervised training, but much less so in zero-shot settings. We propose a new task that includes two college-level introductory texts in the social sciences (American Government 2e) and humanities (U.S. History), hundreds of true/false statements based on review questions written by the textbook authors, validation/development tests based on the first eight chapters of the textbooks, blind tests based on the remaining textbook chapters, and baseline results given state-of-the-art PTLMs. Since the questions are balanced, random performance should be {\textasciitilde}50{\%}. T5, fine-tuned with BoolQ achieves the same performance, suggesting that the textbook{'}s content is not pre-represented in the PTLM. Taking the exam closed book, but having read the textbook (i.e., adding the textbook to T5{'}s pre-training), yields at best minor improvement (56{\%}), suggesting that the PTLM may not have {``}understood{''} the textbook (or perhaps misunderstood the questions). Performance is better ({\textasciitilde}60{\%}) when the exam is taken open-book (i.e., allowing the machine to automatically retrieve a paragraph and use it to answer the question)."
2020.findings-emnlp.273,Learning to Generalize for Sequential Decision Making,2020,-1,-1,2,0,11229,xusen yin,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"We consider problems of making sequences of decisions to accomplish tasks, interacting via the medium of language. These problems are often tackled with reinforcement learning approaches. We find that these models do not generalize well when applied to novel task domains. However, the large amount of computation necessary to adequately train and explore the search space of sequential decision making, under a reinforcement learning paradigm, precludes the inclusion of large contextualized language models, which might otherwise enable the desired generalization ability. We introduce a teacher-student imitation learning methodology and a means of converting a reinforcement learning model into a natural language understanding model. Together, these methodologies enable the introduction of contextualized language models into the sequential decision making problem space. We show that models can learn faster and generalize more, leveraging both the imitation learning and the reformulation. Our models exceed teacher performance on various held-out decision problems, by up to 7{\%} on in-domain problems and 24{\%} on out-of-domain problems."
2020.emnlp-main.351,Content Planning for Neural Story Generation with Aristotelian Rescoring,2020,-1,-1,3,0,12909,seraphina goldfarbtarrant,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Long-form narrative text generated from large language models manages a fluent impersonation of human writing, but only at the local sentence level, and lacks structure or global cohesion. We posit that many of the problems of story generation can be addressed via high-quality content planning, and present a system that focuses on how to learn good plot structures to guide story generation. We utilize a plot-generation language model along with an ensemble of rescoring models that each implement an aspect of good story-writing as detailed in Aristotle{'}s Poetics. We find that stories written with our more principled plot-structure are both more relevant to a given prompt and higher quality than baselines that do not content plan, or that plan in an unprincipled way."
K19-1062,Deep Structured Neural Network for Event Temporal Relation Extraction,2019,33,0,5,0,4843,rujun han,Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL),0,"We propose a novel deep structured learning framework for event temporal relation extraction. The model consists of 1) a recurrent neural network (RNN) to learn scoring functions for pair-wise relations, and 2) a structured support vector machine (SSVM) to make joint predictions. The neural network automatically learns representations that account for long-term contexts to provide robust features for the structured model, while the SSVM incorporates domain knowledge such as transitive closure of temporal relations as constraints to make better globally consistent decisions. By jointly training the two components, our model combines the benefits of both data-driven learning and knowledge exploitation. Experimental results on three high-quality event temporal relation datasets (TCR, MATRES, and TB-Dense) demonstrate that incorporated with pre-trained contextualized embeddings, the proposed model achieves significantly better performances than the state-of-the-art methods on all three datasets. We also provide thorough ablation studies to investigate our model."
L18-1031,When {ACE} met {KBP}: End-to-End Evaluation of Knowledge Base Population with Component-level Annotation,2018,0,0,4,0.869565,1264,bonan min,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
J18-4004,Last Words: What Can Be Accomplished with the State of the Art in Information Extraction? A Personal View,2018,3,0,1,1,4279,ralph weischedel,Computational Linguistics,0,"Though information extraction (IE) research has more than a 25-year history, F1 scores remain low. Thus, one could question continued investment in IE research. In this article, we present three applications where information extraction of entities, relations, and/or events has been used, and note the common features that seem to have led to success. We also identify key research challenges whose solution seems essential for broader successes. Because a few practical deployments already exist and because breakthroughs on particular challenges would greatly broaden the technology{'}s deployment, further R and D investments are justified."
I17-1068,Learning Transferable Representation for Bilingual Relation Extraction via Convolutional Neural Networks,2017,31,1,4,0.869565,1264,bonan min,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"Typically, relation extraction models are trained to extract instances of a relation ontology using only training data from a single language. However, the concepts represented by the relation ontology (e.g. ResidesIn, EmployeeOf) are language independent. The numbers of annotated examples available for a given ontology vary between languages. For example, there are far fewer annotated examples in Spanish and Japanese than English and Chinese. Furthermore, using only language-specific training data results in the need to manually annotate equivalently large amounts of training for each new language a system encounters. We propose a deep neural network to learn transferable, discriminative bilingual representation. Experiments on the ACE 2005 multilingual training corpus demonstrate that the joint training process results in significant improvement in relation classification performance over the monolingual counterparts. The learnt representation is discriminative and transferable between languages. When using 10{\%} (25K English words, or 30K Chinese characters) of the training data, our approach results in doubling F1 compared to a monolingual baseline. We achieve comparable performance to the monolingual system trained with 250K English words (or 300K Chinese characters) With 50{\%} of training data."
W13-0908,Automatic Extraction of Linguistic Metaphors with {LDA} Topic Modeling,2013,22,26,7,0,41123,ilana heintz,Proceedings of the First Workshop on Metaphor in {NLP},0,"We aim to investigate cross-cultural patterns of thought through cross-linguistic investigation of the use of metaphor. As a first step, we produce a system for locating instances of metaphor in English and Spanish text. In contrast to previous work which relies on resources like syntactic parsing and WordNet, our system is based on LDA topic modeling, enabling its application even to low-resource languages, and requires no labeled data. We achieve an F-score of 59% for English."
W11-1901,{C}o{NLL}-2011 Shared Task: Modeling Unrestricted Coreference in {O}nto{N}otes,2011,44,200,5,0,11322,sameer pradhan,Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,0,"The CoNLL-2011 shared task involved predicting coreference using OntoNotes data. Resources in this field have tended to be limited to noun phrase coreference, often on a restricted set of entities, such as ace entities. OntoNotes provides a large-scale corpus of general anaphoric coreference not restricted to noun phrases or to a specified set of entity types. OntoNotes also provides additional layers of integrated annotation, capturing additional shallow semantic structure. This paper briefly describes the OntoNotes annotation (coreference and other layers) and then describes the parameters of the shared task including the format, pre-processing information, and evaluation criteria, and presents and discusses the results achieved by the participating systems. Having a standard test set and evaluation parameters, all based on a new resource that provides multiple integrated annotation layers (parses, semantic roles, word senses, named entities and coreference) that could support joint models, should help to energize ongoing research in the task of entity and event coreference."
P11-2050,"Coreference for Learning to Extract Relations: Yes {V}irginia, Coreference Matters",2011,13,15,3,1,41124,ryan gabbard,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"As an alternative to requiring substantial supervised relation training data, many have explored bootstrapping relation extraction from a few seed examples. Most techniques assume that the examples are based on easily spotted anchors, e.g., names or dates. Sentences in a corpus which contain the anchors are then used to induce alternative ways of expressing the relation. We explore whether coreference can improve the learning process. That is, if the algorithm considered examples such as his sister, would accuracy be improved? With coreference, we see on average a 2-fold increase in F-Score. Despite using potentially errorful machine coreference, we see significant increase in recall on all relations. Precision increases in four cases and decreases in six."
P11-2059,Language Use: What can it tell us?,2011,14,10,4,1,4827,marjorie freedman,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"For 20 years, information extraction has focused on facts expressed in text. In contrast, this paper is a snapshot of research in progress on inferring properties and relationships among participants in dialogs, even though these properties/relationships need not be expressed as facts. For instance, can a machine detect that someone is attempting to persuade another to action or to change beliefs or is asserting their credibility? We report results on both English and Arabic discussion forums."
D11-1133,Extreme Extraction {--} Machine Reading in a Week,2011,19,23,7,1,4827,marjorie freedman,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"We report on empirical results in extreme extraction. It is extreme in that (1) from receipt of the ontology specifying the target concepts and relations, development is limited to one week and that (2) relatively little training data is assumed. We are able to surpass human recall and achieve an F1 of 0.51 on a question-answering task with less than 50 hours of effort using a hybrid approach that mixes active learning, bootstrapping, and limited (5 hours) manual rule writing. We compare the performance of three systems: extraction with handwritten rules, bootstrapped extraction, and a combination. We show that while the recall of the handwritten rules surpasses that of the learned system, the learned system is able to improve the overall recall and F1."
W10-0908,Empirical Studies in Learning to Read,2010,13,4,4,1,4827,marjorie freedman,Proceedings of the {NAACL} {HLT} 2010 First International Workshop on Formalisms and Methodology for Learning by Reading,0,"In this paper, we present empirical results on the challenge of learning to read. That is, given a handful of examples of the concepts and relations in an ontology and a large corpus, the system should learn to map from text to the concepts/relations of the ontology. In this paper, we report contrastive experiments on the recall, precision, and F-measure (F) of the mapping in the following conditions: (1) employing word-based patterns, employing semantic structure, and combining the two; and (2) fully automatic learning versus allowing minimal questions of a human informant."
J10-4005,String-to-Dependency Statistical Machine Translation,2010,45,47,3,1,6930,libin shen,Computational Linguistics,0,"We propose a novel string-to-dependency algorithm for statistical machine translation. This algorithm employs a target dependency language model during decoding to exploit long distance word relations, which cannot be modeled with a traditional n-gram language model. Experiments show that the algorithm achieves significant improvement in MT performance over a state-of-the-art hierarchical string-to-string system on NIST MT06 and MT08 newswire evaluation sets."
D10-1060,Statistical Machine Translation with a Factorized Grammar,2010,18,2,5,1,6930,libin shen,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"In modern machine translation practice, a statistical phrasal or hierarchical translation system usually relies on a huge set of translation rules extracted from bi-lingual training data. This approach not only results in space and efficiency issues, but also suffers from the sparse data problem. In this paper, we propose to use factorized grammars, an idea widely accepted in the field of linguistic grammar construction, to generalize translation rules, so as to solve these two problems. We designed a method to take advantage of the XTAG English Grammar to facilitate the extraction of factorized rules. We experimented on various setups of low-resource language translation, and showed consistent significant improvement in BLEU over state-of-the-art string-to-dependency baseline systems with 200K words of bi-lingual training data."
D09-1008,Effective Use of Linguistic and Contextual Information for Statistical Machine Translation,2009,26,42,5,1,6930,libin shen,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"Current methods of using lexical features in machine translation have difficulty in scaling up to realistic MT tasks due to a prohibitively large number of parameters involved. In this paper, we propose methods of using new linguistic and contextual features that do not suffer from this problem and apply them in a state-of-the-art hierarchical MT system. The features used in this work are non-terminal labels, non-terminal length distribution, source string context and source dependency LM scores. The effectiveness of our techniques is demonstrated by significant improvements over a strong base-line. On Arabic-to-English translation, improvements in lower-cased BLEU are 2.0 on NIST MT06 and 1.7 on MT08 newswire data on decoding output. On Chinese-to-English translation, the improvements are 1.0 on MT06 and 0.8 on MT08 newswire data."
P08-1066,A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model,2008,22,239,3,1,6930,libin shen,Proceedings of ACL-08: HLT,1,"In this paper, we propose a novel string-todependency algorithm for statistical machine translation. With this new framework, we employ a target dependency language model during decoding to exploit long distance word relations, which are unavailable with a traditional n-gram language model. Our experiments show that the string-to-dependency decoder achieves 1.48 point improvement in BLEU and 2.53 point improvement in TER compared to a standard hierarchical string-tostring system on the NIST 04 Chinese-English evaluation set."
N06-2015,{O}nto{N}otes: The 90{\\%} Solution,2006,13,537,5,0,1043,eduard hovy,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Short Papers",0,"We describe the OntoNotes methodology and its result, a large multilingual richly-annotated corpus constructed at 90% interannotator agreement. An initial portion (300K words of English newswire and 250K words of Chinese newswire) will be made available to the community during 2007."
H05-1039,Combining Deep Linguistics Analysis and Surface Pattern Learning: A Hybrid Approach to {C}hinese Definitional Question Answering,2005,15,12,2,0,10637,fuchun peng,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,We explore a hybrid approach for Chinese definitional question answering by combining deep linguistic analysis with surface pattern learning. We answer four questions in this study: 1) How helpful are linguistic analysis and pattern learning? 2) What kind of questions can be answered by pattern matching? 3) How much annotation is required for a pattern-based system to achieve good performance? 4) What linguistic features are most useful? Extensive experiments are conducted on biographical questions and other definitional questions. Major findings include: 1) linguistic analysis and pattern learning are complementary; both are required to make a good definitional QA system; 2) pattern matching is very effective in answering biographical questions while less effective for other definitional questions; 3) only a small amount of annotation is required for a pattern learning system to achieve good performance on biographical questions; 4) the most useful linguistic features are copulas and appositives; relations also play an important role; only some propositions convey vital facts.
H05-1082,A Methodology for Extrinsically Evaluating Information Extraction Performance,2005,2,4,6,1,43788,michael crystal,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"This paper reports a preliminary study addressing two challenges in measuring the effectiveness of information extraction (IE) technology:xe2x80xa2 Developing a methodology for extrinsic evaluation of IE; and,xe2x80xa2 Estimating the impact of improving IE technology on the ability to perform an application task.The methodology described can be employed for further controlled experiments regarding information extraction."
doddington-etal-2004-automatic,"The Automatic Content Extraction ({ACE}) Program {--} Tasks, Data, and Evaluation",2004,0,498,6,0,50401,george doddington,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,None
H01-1024,Experiments in Multi-Modal Automatic Content Extraction,2001,3,20,6,0,34887,lance ramshaw,Proceedings of the First International Conference on Human Language Technology Research,0,"Unlike earlier information extraction research programs, the new ACE (Automatic Content Extraction) program calls for entity extraction by identifying and linking all of the mentions of an entity in the source text, including names, descriptions, and pronouns. Coreference is therefore a key component. BBN has developed statistical co-reference models for this task, including one for pronoun co-reference that we describe here in some detail. In addition, ACE calls for extraction not just from clean text, but also from noisy speech and OCR input. Since speech recognizer output includes neither case nor punctuation, we have extended our statistical parser to perform sentence breaking integrated with parsing in a probabilistic model."
H01-1027,{F}act{B}rowser Demonstration,2001,2,5,4,1,21845,scott miller,Proceedings of the First International Conference on Human Language Technology Research,0,"The FactBrowser demonstration illustrates automatic database update from live feeds based on information extraction from text and the ability to browse the resulting database for unexpected connections. The technology used has four interesting features:1. The demonstration employs a light architecture based on the Web; using an XML-based client-server architecture, the graphical user interface requires only Internet Explorer 5.0 or higher. No application code resides on the client.2. A permanent database grows based on cross-document entity tracking and accumulating facts.3. The database is updated daily based on automatic processing of documents distributed by the Foreign Broadcasting Information Service (FBIS). Document capture and database update are fully automatic, requiring no human intervention.4. The following key components: name finding, parsing, and pronoun resolution are all based on the trained, language-independent statistical modeling techniques.The strategic focus throughout the design of FactBrowser has been on producing high precision output so as to maintain quality in the data base."
W00-1312,Cross-lingual Information Retrieval Using Hidden {M}arkov Models,2000,19,28,2,1,44605,jinxi xu,2000 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,"This paper presents empirical results in cross-lingual information retrieval using English queries to access Chinese documents (TREC-5 and TREC-6) and Spanish documents (TREC-4). Since our interest is in languages where resources may be minimal, we use an integrated probabilistic model that requires only a bilingual dictionary as a resource. We explore how a combined probability model of term translation and retrieval can reduce the effect of translation ambiguity. In addition, we estimate an upper bound on performance, if translation ambiguity were a solved problem. We also measure performance as a function of bilingual dictionary size."
boisen-etal-2000-annotating,Annotating Resources for Information Extraction,2000,9,13,5,1,54538,sean boisen,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"Trained systems for NE extraction have shown significant promise because of their robustness to errorful input and rapid adaptability. However, these learning algorithms have transferred the cost of development from skilled computational linguistic expertise to data annotation, putting a new premium on effective ways to produce high-quality annotated resources at minimal cost. The paper reflects on BBNxe2x80x99s four years of experience in the annotation of training data for Named Entity (NE) extraction systems discussing useful techniques for maximizing data quality and quantity."
A00-2030,A Novel Use of Statistical Parsing to Extract Information from Text,2000,9,187,4,1,21845,scott miller,1st Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the UPenn TREEBANK as a gold standard. In this paper we report adapting a lexicalized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations."
A00-1044,Named Entity Extraction from Noisy Input: Speech and {OCR},2000,5,45,5,0,50708,david miller,Sixth Applied Natural Language Processing Conference,0,"In this paper, we analyze the performance of name finding in the context of a variety of automatic speech recognition (ASR) systems and in the context of one optical character recognition (OCR) system. We explore the effects of word error rate from ASR and OCR, performance as a function of the amount of training data, and for speech, the effect of out-of-vocabulary errors and the loss of punctuation and mixed case"
X98-1014,Algorithms That Learn to Extract Information {BBN}: {TIPSTER} Phase {III},1998,6,6,7,1,21845,scott miller,"TIPSTER TEXT PROGRAM PHASE III: Proceedings of a Workshop held at Baltimore, {M}aryland, October 13-15, 1998",0,"All of BBN's research under the TIPSTER III program has focused on doing extraction by applying statistical models trained on annotated data, rather than by using programs that execute hand-written rules. Within the context of MUC-7, the SIFT system for extraction of template entities (TE) and template relations (TR) used a novel, integrated syntactic/semantic language model to extract sentence level information, and then synthesized information across sentences using in part a trained model for cross-sentence relations. At the named entity (NE) level as well, in both MET-1 and MUC-7, BBN employed a trained, HMM-based model.The results in these TIPSTER evaluations are evidence that such trained systems, even at their current level of development, can perform roughly on a par with those based on rules hand-tailored by experts. In addition, such trained systems have some significant advantages:xe2x80xa2 They can be easily ported to new domains by simply annotating fresh data.xe2x80xa2 The complex interactions that make rule-based systems difficult to develop and maintain can here be learned automatically from the training data.We believe that improved and extended versions of such trained models have the potential for significant further progress toward practical systems for information extraction."
M98-1009,{BBN}: Description of the {SIFT} System as Used for {MUC}-7,1998,0,53,7,1,21845,scott miller,"Seventh Message Understanding Conference ({MUC}-7): Proceedings of a Conference Held in Fairfax, Virginia, {A}pril 29 - May 1, 1998",0,None
A97-1029,{N}ymble: a High-Performance Learning Name-finder,1997,6,616,4,0.517241,47887,daniel bikel,Fifth Conference on Applied Natural Language Processing,0,"This paper presents a statistical, learned approach to finding names and other nonrecursive entities in text (as per the MUC-6 definition of the NE task), using a variant of the standard hidden Markov model. We present our justification for the problem and our approach, a detailed discussion of the model itself and finally the successful results of this new approach."
X96-1019,The {HOOKAH} Information Extraction System,1996,-1,-1,4,0,55857,chris barclay,"TIPSTER TEXT PROGRAM PHASE II: Proceedings of a Workshop held at Vienna, Virginia, May 6-8, 1996",0,None
X96-1026,{C}hinese Information Extraction and Retrieval,1996,1,3,4,1,54538,sean boisen,"TIPSTER TEXT PROGRAM PHASE II: Proceedings of a Workshop held at Vienna, Virginia, May 6-8, 1996",0,"This paper provides a summary of the following topics:1. what was learned from porting the INQUERY information retrieval engine and the INFINDER term finder to Chinese2. experiments at the University of Massachusetts evaluating INQUERY performance on Chinese newswire (Xinhua),3. what was learned from porting selected components of PLUM to Chinese4. experiments evaluating the POST part of speech tagger and named entity recognition on Chinese.5. program issues in technology development."
X96-1028,Progress in Information Extraction,1996,9,1,1,1,4279,ralph weischedel,"TIPSTER TEXT PROGRAM PHASE II: Proceedings of a Workshop held at Vienna, Virginia, May 6-8, 1996",0,"This paper provides a quick summary of the following topics: enhancements to the PLUM information extraction engine, what we learned from MUC-6 (the Sixth Message Understanding Conference), the results of an experiment on merging templates from two different information extraction engines, a learning technique for named entity recognition, and towards information extraction from speech."
X96-1055,Approaches in {MET} (Multi-Lingual Entity Task),1996,0,1,5,0.448718,55876,damaris ayuso,"TIPSTER TEXT PROGRAM PHASE II: Proceedings of a Workshop held at Vienna, Virginia, May 6-8, 1996",0,"BBN and FinCEN participated jointly in the Spanish language task for MET. BBN also participated in Chinese. We also fielded two approaches. The first approach is pattern based and has an architecture as shown in Figure 1. This approach was applied to both Chinese and Spanish. The algorithms (rectangles in the Figure) were used in the two languages; the only component difference was the New Mexico State University segmenter, used to find the word boundaries in Chinese. The components common to both languages are the message reader, which dealt with the input format and SGML conventions via a declarative format description; the part-of-speech tagger (BBN POST); a lexical pattern matcher driven by knowledge bases of patterns and lexicons specific to each language; and the SGML annotation generator. While not shown in Figure 1, an alias prediction algorithm was shared by both languages, using patterns unique to each language."
H94-1089,"Robustness, Portability and Scalability Language Systems",1994,0,0,1,1,4279,ralph weischedel,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"Our approach is to apply probabilistic language models and training over large corpora in all phases of natural language processing. This new approach will enable systems to adapt to both new task domains and linguistic expressions not seen before by semi-automatically acquiring 1) a domain model, 2) facts required for semantic processing, 3) grammar rules, 4) information about new words, 5) probability models on frequency of occurrence, and 6) rules for mapping from semantic representation to application structure."
X93-1019,{BBN}{'}s {PLUM} Probabilistic Language Understanding System,1993,6,3,1,1,4279,ralph weischedel,"TIPSTER TEXT PROGRAM: PHASE {I}: Proceedings of a Workshop held at Fredricksburg, Virginia, September 19-23, 1993",0,"Traditional approaches to the problem of extracting data from texts have emphasized hand-crafted linguistic knowledge. In contrast, BBN's PLUM system (Probabilistic Language Understanding Model) was developed as part of an ARPA-funded research effort on integrating probabilistic language models with more traditional linguistic techniques. Our research and development goals are:xe2x80xa2 Achieving high performance in objective evaluations, such as the Tipster evaluations.xe2x80xa2 Reducing human effort in porting the natural language algorithms to new domains and to new languages.xe2x80xa2 Providing technology that is scalable to realistic applications."
M93-1010,{BBN}: Description of the {PLUM} System as Used for {MUC}-5,1993,3,5,1,1,4279,ralph weischedel,"Fifth Message Understanding Conference ({MUC}-5): Proceedings of a Conference Held in Baltimore, {M}aryland, August 25-27, 1993",0,"NEC Corporation has had years of experience in natural language processing and machine translation[1, 2, 3, 4, 5], and currently markets commercial natural language processing systems. Utilizing dictionaries and parsing engines we have already had, we have developed the VENIEX System (VENus for Information EXtraction) as used for MUC-5 in only three months. Our method is to apply both domain-specific keyword-based analysis and full sentential parsing with general grammar[6, 7]. The keyword dictionary of VENIEX contains about thirty thousand entries, whose semantic structures are sub_ME_Capability frame, and the parsing and discourse processing are controlled with the information given in this semantic structure of keywords. The resulting scores of VENIEX for formal run texts were from 0.7181 (minimum) to 0.7548 (maximum) in Richness-Normalized Error and 48.33 in F-MEASURES (P&R)."
J93-2006,Coping with Ambiguity and Unknown Words through Probabilistic Models,1993,18,243,1,1,4279,ralph weischedel,Computational Linguistics,0,"From spring 1990 through fall 1991, we performed a battery of small experiments to test the effectiveness of supplementing knowledge-based techniques with probabilistic models. This paper reports our experiments in predicting parts of speech of highly ambiguous words, predicting the intended interpretation of an utterance when more than one interpretation satisfies all known syntactic and semantic constraints, and learning caseframe informationfor verbsfrom example uses.From these experiments, we are convinced that probabilistic models based on annotated corpora can effectively reduce the ambiguity in processing text and can be used to acquire lexical informationfrom a corpus, by supplementing knowledge-based techniques.Based on the results of those experiments, we have constructed a new natural language system (PLUM) for extracting data from text, e.g., newswire text."
H93-1045,Example-Based Correction of Word Segmentation and Part of Speech Labelling,1993,6,16,3,0,56656,tomoyoshi matsukawa,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,"This paper describes an example-based correction component for Japanese word segmentation and part of speech labelling (AMED), and a way of combining it with a pre-existing rule-based Japanese morphological analyzer and a probabilistic part of speech tagger.Statistical algorithms rely on frequency of phenomena or events in corpora; however, low frequency events are often inadequately represented. Here we report on an example based technique used in finding word segments and their part of speech in Japanese text. Rather than using hand-crafted rules, the algorithm employs example data, drawing generalizations during training."
H93-1073,Session 13: New Directions,1993,-1,-1,1,1,4279,ralph weischedel,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,None
H93-1080,"Robustness, Portability, and Scalability of Natural Language Systems",1993,0,0,1,1,4279,ralph weischedel,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,"In the DoD, every unit, from the smallest to the largest, communicates through messages. Messages are fundamental in command and control, intelligence analysis, and in planning and replanning. Our objective is to create algorithms that will1) robustly process open source text, identifying relevant messages, and updating a data base based on the relevant messages;2) reduce the effort required in porting natural language (NL) message processing software to a new domain from months to weeks; and3) be scalable to broad domains with vocabularies of tens of thousands of words."
M92-1007,{BBN} {PLUM}: {MUC}-4 Test Results and Analysis,1992,2,0,1,1,4279,ralph weischedel,"{F}ourth {M}essage {U}understanding {C}onference ({MUC}-4): Proceedings of a Conference Held in {M}c{L}ean, {V}irginia, {J}une 16-18, 1992",0,"Our mid-term to long-term goals in data extraction from text for the next one to three years are to achieve much greater portability to new languages and new domains, greater robustness, and greater scalability. The novel aspect to our approach is the use of learning algorithms and probabilistic models to learn the domain-specific and language-specific knowledge necessary for a new domain and new language. Learning algorithms should contribute to scalability by making it feasible to deal with domains where it would be infeasible to invest sufficient human effort to bring a system up. Probabilistic models can contribute to robustness by allowing for words, constructions, and forms not anticipated ahead of time and by looking for the most likely interpretation in context."
M92-1024,{BBN}: Description of the {PLUM} System as Used for {MUC}-4,1992,11,67,6,0.555556,55876,damaris ayuso,"{F}ourth {M}essage {U}understanding {C}onference ({MUC}-4): Proceedings of a Conference Held in {M}c{L}ean, {V}irginia, {J}une 16-18, 1992",0,"Traditional approaches to the problem of extracting data from texts have emphasized hand-crafted linguistic knowledge. In contrast, BBN's PLUM system (Probabilistic Language Understanding Model) was developed as part of a DARPA-funded research effort on integrating probabilistic language models with more traditional linguistic techniques. Our research and development goals arexe2x80xa2 more rapid development of new applications,xe2x80xa2 the ability to train (and re-train) systems based on user markings of correct and incorrect output,xe2x80xa2 more accurate selection among interpretations when more than one is found, andxe2x80xa2 more robust partial interpretation when no complete interpretation can be found."
H92-1063,A New Approach to Text Understanding,1992,8,5,1,1,4279,ralph weischedel,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,"This paper first briefly describes the architecture of PLUM, BBN's text Processing system, and then reports on some experiments evaluating the effectiveness of the design at the component level. Three features are unusual in PLUM's architecture: a domain-independent deterministic parser, processing of (the resulting) fragments at the semantic and discourse level, and probabilistic models."
H92-1098,"Robustness, Portability, and Scalability Language Systems",1992,-1,-1,1,1,4279,ralph weischedel,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,None
M91-1006,{BBN} {PLUM}: {MUC}-3 Test Results and Analysis,1991,5,1,1,1,4279,ralph weischedel,"{T}hird {M}essage {U}understanding {C}onference ({MUC}-3): Proceedings of a Conference Held in {S}an {D}iego, {C}alifornia, {M}ay 21-23, 1991",0,"Perhaps the most important facts about our participation in MUC-3 reflect our starting point and goals. In March, 1990, we initiated a pilot study on the feasibility and impact of applying statistical algorithms in natural language processing. The experiments were concluded in March, 1991 and lead us to believe that statistical approaches can effectively improve knowledge-based approaches [Weischedel, et al., 1991a, Weischedel, Meteer, and Schwartz, 1991]. Due to nature of that effort, we had focussed on many well-defined algorithm experiments. We did not have a complete message processing system; nor was the pilot study designed to create an application system."
M91-1021,{BBN}: Description of the {PLUM} System as Used for{MUC}-3,1991,-1,-1,1,1,4279,ralph weischedel,"{T}hird {M}essage {U}understanding {C}onference ({MUC}-3): Proceedings of a Conference Held in {S}an {D}iego, {C}alifornia, {M}ay 21-23, 1991",0,None
H91-1037,Partial Parsing: A Report on Work in Progress,1991,15,20,1,1,4279,ralph weischedel,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,"This paper reports a handful of experiments designed to test the feasibility of applying well-known partial parsing techniques to the problem of automatic data base update from an open-ended source of messages. and the feasiblity of automatically learning semantic knowledge from annotated examples. The challenges arise from the incompleteness of any lexicon, sentences that average over 20 words in length, and the lack of a complete semantics."
H91-1065,Studies in Part of Speech Labelling,1991,7,24,3,0,26017,marie meteer,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,"We report here on our experiments with POST (Part of Speech Tagger) to address problems of ambiguity and of understanding unknown words. Part of speech tagging, per se, is a well understood problem. Our paper reports experiments in three important areas: handling unknown words, limiting the size of the training set, and returning a set of the most likely tags for each word rather than a single tag. We describe the algorithms that we used and the specific results of our experiments on Wall Street Journal articles and on MUC terrorist messages."
H91-1079,Adaptive Natural Language Processing,1991,0,1,1,1,4279,ralph weischedel,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,"Abstract : A handful of special purpose systems have been successfully deployed to extract prespecified kinds of data from text. The limitation to widespread deployment of such systems is their assumption of a large volume of handcrafted, domain-dependent, and language-dependent knowledge in the form of rules. A new approach is to add automatically trainable probabilistic language models to linguistically based analysis. This offers several potential advantages: (1) Trainability by finding patterns in a large corpus, rather than handcrafting such patterns. (2) Improvability be re-estimating probabilities based on a user marking correct and incorrect output on a test set. (3) More accurate selection among interpretations when more than one is produced. (4) Robustness by finding the most likely partial interpretation when no complete interpretation can be found."
P90-1029,Multiple Underlying Systems: Translating User Requests into Programs to Produce Answers,1990,11,15,3,0,55866,robert bobrow,28th Annual Meeting of the Association for Computational Linguistics,1,"A user may typically need to combine the strengths of more than one system in order to perform a task. In this paper, we describe a component of the Janus natural language interface that translates intensional logic expressions representing the meaning of a request into executable code for each application program, chooses which combination of application systems to use, and designs the transfer of data among them in order to provide an answer. The complete Janus natural language system has been ported to two large command and control decision support aids."
H90-1069,Towards Understanding Text with a Very Large Vocabulary,1990,10,8,7,0.714286,55876,damaris ayuso,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"In order to meet the information processing demands of the next decade, natural language systems must have the capability of processing very large amounts of text, commonly called messages, from highly diverse sources written in any of a few dozen languages. One of the key issues in building systems with this scale of competence is handling large numbers of different words and word senses. Natural language understanding systems today are typically limited to vocabularies of less than 10,000 words; tomorrow's systems will need vocabularies at least 5 times that to effectively handle the volume and diversity of messages needing to be processed."
H90-1078,Adaptive Natural Language Processing,1990,0,2,1,1,4279,ralph weischedel,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"Current NLP technology is very weak at understanding new words, novel forms, or input containing errors. The objective of this project is a pilot study of several new ideas for the automatic adaptation and improvement of natural language processing (NLP) systems. The effort focuses particularly on automatically inferring the meaning of new words in context and on developing partial interpretations of language that is either fragmentary or beyond the capability of the NLP system to understand. The techniques are being evaluated in a message processing domain, such as automatic data base update based on articles from The Wall Street Journal on corporate takeover bids."
P89-1024,A Hybrid Approach to Representation in the {J}anus Natural Language Processor,1989,21,23,1,1,4279,ralph weischedel,27th Annual Meeting of the Association for Computational Linguistics,1,"In BBN's natural language understanding and generation system (Janus), we have used a hybrid approach to representation, employing an intensional logic for the representation of the semantics of utterances and a taxonomic language with formal semantics for specification of descriptive constants and axioms relating them. Remarkably, 99.9% of 7,000 vocabulary items in our natural language applications could be adequately axiomatized in the taxonomic language."
H89-2057,Research and Development in Natural Language Understanding,1989,0,0,1,1,4279,ralph weischedel,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,"There are three objectives of the contract: to perform research and development in parallel parsing, semantic representation, ill-formed input, discourse, and tools for linguistic knowledge acquisition, and to integrate software components from BBN and elsewhere to produce Janus, DARPA's New Generation Natural Language Interface, and to demonstrate state-of-the-art natural language technology in DARPA applications. The following software has been distributed: natural language system; IRACQ, knowledge acquisition system; System components and knowledge bases of Janus; KL-TWO knowledge representation and inference system integrated with Janus; various components for DARPA's Spoken Language Systems Project at BBN."
H89-2078,White Paper on Natural Language Processing,1989,0,16,1,1,4279,ralph weischedel,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,"We take the ultimate goal of natural language processing (NLP) to be the ability to use natural languages as effectively as humans do. Natural language, whether spoken, written, or typed, is the most natural means of communication between humans, and the mode of expression of choice for most of the documents they produce. As computers play a larger role in the preparation, acquisition, transmission, monitoring, storage, analysis, and transformation of information, endowing them with the ability to understand and generate information expressed in natural languages becomes more and more necessary. Some tasks currently performed by humans cannot be automated without endowing computers with natural language processing capabilities, and these provide two major challenges to NLP systems:1. Reading and writing text, applied to tasks such as message routing, abstracting, monitoring, summarizing, and entering information in databases, with applications, in such areas as intelligence, logistics, office automation, and libraries. Computers should be able to assimilate and compose extended communications.2. Translation, of documents or spoken language, with applications, in such areas as in science, diplomacy, multinational commerce, and intelligence. Computers should be able to understand input in more than one language, provide output in more than one language, and translate between languages."
H89-1013,Portability in the {J}anus Natural Language Interface,1989,6,11,1,1,4279,ralph weischedel,"Speech and Natural Language: Proceedings of a Workshop Held at Philadelphia, {P}ennsylvania, {F}ebruary 21-23, 1989",0,"Although natural language technology has achieved a high degree of domain independence through separating domain-independent modules from domain-dependent knowledge bases, portability, as measured by effort to move from one application to another, is still a problem. Here we describe a knowledge acquisition tool (KNACQ) that has sharply decreased our effort in building knowledge bases. The knowledge bases acquired with KNACQ are used by both the understanding components and the generation components of Janus."
P87-1005,An Environment for Acquiring Semantic Information,1987,19,23,3,0.714286,55876,damaris ayuso,25th Annual Meeting of the Association for Computational Linguistics,1,"An improved version of IRACQ (for Interpretation Rule ACQuisition) is presented. Our approach to semantic knowledge acquisition: 1) is in the context of a general purpose NL interface rather than one that accesses only databases, 2) employs a knowledge representation formalism with limited inferencing capabilities, 3) assumes a trained person but not an Al expert, and 4) provides a complete environment for not only acquiring semantic knowledge, but also maintaining and editing it in a consistent knowledge base. IRACQ is currently in use at the Naval Ocean Systems Center."
H86-1001,Research and Development in Natural Language Processing at {BBN} {L}aboratories in the {S}trategic {C}omputing {P}rogram,1986,10,0,1,1,4279,ralph weischedel,"Strategic Computing - Natural Language Workshop: Proceedings of a Workshop Held at Marina del Rey, California, May 1-2, 1986",0,"BBN's responsibility is to conduct research and development in natural language interface technology. This responsibility has three aspects:xe2x80xa2 to demonstrate state-of-the-art technology in a Strategic Computing application, collecting data regarding the effectiveness of the demonstrated heuristics,xe2x80xa2 to conduct research in natural language interface technology, as itemized in the description of JANUS later in this note, andxe2x80xa2 to integrate technology from other natural language interface contractors, including USC/Information Sciences Institute, the University of Pennsylvania, and the University of Massachusetts."
H86-1007,Out of the Laboratory: A Case Study with the {IRUS} Natural Language Interface,1986,16,2,1,1,4279,ralph weischedel,"Strategic Computing - Natural Language Workshop: Proceedings of a Workshop Held at Marina del Rey, California, May 1-2, 1986",0,"As part of DARPA's Strategic Computing Program, we have moved a large natural language system out of the laboratory. This involved:xe2x80xa2 Delivery of knowledge acquisition software to the Naval Ocean Systems Center (NOSC) to build linguistic knowledge bases, such as dictionary entries and case frames,xe2x80xa2 Demonstration of the natural language interface in a naval decision-making setting, andxe2x80xa2 Delivery of the interface software to Texas Instruments, which has integrated it into the total software package of the Strategic Computing Fleet Command Center Battle Management Program (FCCBMP).The resulting natural language interface will be delivered to the Pacific Fleet Command Center in Hawaii.This paper is an overview of this effort in technology transfer, indicating the technology features that have made this possible and reflecting upon what the experience illustrates regarding transportability, technology status, and delivery of natural language processing outside of a laboratory setting. The paper will be most valuable to those engaged in applying state-of-the-art techniques to deliver natural language interfaces and to those interested in developing the next generation of complete natural language interfaces."
H86-1017,Living Up to Expectations: Computing Expert Responses,1986,8,3,3,0,33217,aravind joshi,"Strategic Computing - Natural Language Workshop: Proceedings of a Workshop Held at Marina del Rey, California, May 1-2, 1986",0,"In cooperative man-machine interaction, it is necessary but not sufficient for a system to respond truthfully and informatively to a user's question. In particular, if the system has reason to believe that its planned response might mislead the user, then it must block that conclusion by modifying its response. This paper focusses on identifying and avoiding potentially misleading responses by acknowledging types of informing behavior usually expected of an expert. We attempt to give a formal account of several types of assertions that should be included in response to questions concerning the achievement of some goal (in addition to the simple answer), lest the questioner otherwise be misled."
1985.tmi-1.23,Reflections on the Knowledge Needed to Process Ill-Formed Language,1985,-1,-1,1,1,4279,ralph weischedel,Proceedings of the first Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
P84-1024,Semantic Interpretation Using {KL}-{ONE},1984,15,34,2,0.493927,57570,norman sondheimer,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,"This paper presents extensions to the work of Bobrow and Webber [Bobrow & Webber 80a, Bobrow & Webber 80b] on semantic interpretation using KL-ONE to represent knowledge. The approach is based on an extended case frame formalism applicable to all types of phrases, not just clauses. The frames are used to recognize semantically acceptable phrases, identify their structure, and, relate them to their meaning representation through translation rules. Approaches are presented for generating KL-ONE structures as the meaning of a sentence, for capturing semantic generalizations through abstract case frames, and for handling pronouns and relative clauses."
P84-1029,Preventing False Inferences,1984,11,33,3,0.179083,33217,aravind joshi,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,None
P84-1030,Problem Localization Strategies for Pramatics Processing in Natural-Language Front Ends,1984,10,4,2,0.256975,34887,lance ramshaw,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,"Problem localization is the identification of the most significant failures in the AND-OR tree resulting from an unsuccessful attempt to achieve a goal, for instance, in planning, backward-chaining inference, or top-down parsing. We examine heuristics and strategies for problem localization in the context of using a planner to check for pragmatic failures in natural language input to computer systems, such as a cooperative natural language interface to Unixxe2x84xa2 Our heuristics call for selecting the most hopeful branch at ORs, but the most problematic one at ANDs. Surprise scores and special-purpose rules are the main strategies suggested to determine this."
J83-3003,Meta-rules as a Basis for Processing Ill-Formed input,1983,46,94,1,1,4279,ralph weischedel,American Journal of Computational Linguistics,0,"If natural language processing systems are ever to achieve natural, cooperative behavior, they must be able to process input that is ill-formed lexically, syntactically, semantically, or pragmatically. Systems must be able to partially understand, or at least give specific, appropriate error messages, when input does not correspond to their model of language and of context.We propose meta-rules and a control structure under which they are invoked as a framework for processing ill-formed input. The left-hand side of a meta-rule diagnoses a problem as a violated rule of normal processing. The right-hand side relaxes the violated rule and states how processing may be resumed, if at all.Examples discussed in the paper include violated grammatical tests, omitted articles, homonyms, spelling/typographical errors, unknown words, violated selection restrictions, personification, and metonymy. An implementation of a meta-rule processor within the framework of an augmented transition network parser is also described."
A83-1014,Handling Ill-Formed Input: Session Introduction,1983,13,2,1,1,4279,ralph weischedel,First Conference on Applied Natural Language Processing,0,"In natural language access (e.g. English access) to information systems, the magnitude of the problem of absolute ill-formedness can be seen in several case studies. If one includes telegraphic and elliptical constructions in the class of absolute ill-formedness, then case s~udies reported in Thompson (1980) and Eastman and McLean (1981) indicate that as much as 25% of queries to questionanswering systems are absolutely illformed. On the other hand, no matter how large the dictionary, grammar, and underlying system, there will always be unknown words and phrases (e.g. proper names) and impossible requests (due to user misconceptions of the capabilities of the underlying system)."
P82-1016,An Improved Heuristic for Ellipsis Processing,1982,9,21,1,1,4279,ralph weischedel,20th Annual Meeting of the Association for Computational Linguistics,1,"Several natural language systems (e.g., Bobrow et al., 1977; Hendrix et al., 1978; Kwasny and Sondheimer, 1979) include heuristics for replacement and repetition ellipsis, but not expansion ellipsis. One general strategy has been to substitute fragments into the analysis of the previous input, e.g., substituting parse trees of the elliptical input into the parse trees of the previous input in LIFER (Hendrix, et al., 1978). This only applies to inputs of the same type, e.g., repeated questions."
P80-1025,If The Parser Fails,1980,5,9,1,1,4279,ralph weischedel,18th Annual Meeting of the Association for Computational Linguistics,1,None
J80-2003,Responding Intelligently to Unparsable Inputs,1980,22,55,1,1,4279,ralph weischedel,American Journal of Computational Linguistics,0,"All natural language systems are likely to receive inputs for which they are unprepared. The system must be able to respond to such inputs by explicitly indicating the reasons the input could not be understood, so that the user will have precise information for trying to rephrase the input. If natural language communication to data bases, to expert consultant systems, or to any other practical system is to be accepted by other than computer personnel, this is an absolute necessity.This paper presents several ideas for dealing with parts of this broad problem. One is the use of presupposition to detect user assumptions. The second is relaxation of tests while parsing. The third is a general technique for responding intelligently when no parse can be found. All of these ideas have been implemented and tested in one of two natural language systems. Some of the ideas are heuristics that might be employed by humans; others are engineering solutions for the problem of practical natural language systems."
C80-1008,A Rule-Based Approach to Ill-Formed Input,1980,35,14,2,0.493927,57570,norman sondheimer,{COLING} 1980 Volume 1: The 8th International Conference on Computational Linguistics,0,"Though natural language understanding systems have improved markedly in recent years, they have only begun to consider a major problem of truly natural input: ill-formedness. Quite often natural language input is ill-formed in the sense of being misspelled, ungrammatical, or not entirely meaningful. A requirement for any successful natural language interface must be that the system either intelligently guesses at a user's intent, requests direct clarification, or at the very least, accurately identifies the ill-formedness. This paper presents a proposal for the proper treatment of ill-formed input. Our conjecture is that ill-formedness should be treated as rule-based. Violation of the rules of normal processing should be used to signal ill-formedness. Meta-rules modifying the rules of normal processing should be used for error identification and recovery. These meta-rules correspond to types of errors. Evidence for this conjecture is presented as well as some open ~]estions."
J77-1008,Computation of a Subclass of Inferences: Presupposition and Entailment,1977,-1,-1,2,0,33217,aravind joshi,American Journal of Computational Linguistics,0,None
