2020.acl-main.342,C10-1021,0,0.566814,"an emotional change. It is a more challenging task due to the inherent ambiguity and subtlety of emotion expressions. Lee et al. (2010) first defined the emotion cause extraction as a word-level extraction task. They manually constructed a dataset from the Academia Sinica Balanced Chinese Corpus and generalized a series of linguistics rules based on the dataset. Based on this setting, there are some studies have been exploited for this task such as rule-based methods (Li and Xu, 2014; Gao et al., 2015; Yada et al., 2017) and machine learning methods (Ghazi et al., 2015; Song and Meng, 2015). Chen et al. (2010) converted the task from word-level to clause-level due to a clause may be the most appropriate unit to detect causes, and extracted causes using six groups of manually constructed linguistic cues. By following this task setting, Gui et al. (2014) extended the rule-based features to 25 linguistics cues, then trained classifiers on SVM and CRFs to detect causes. Gui et al. (2016) released a new Chinese emotion cause dataset collected from SINA city news 4 and proposed a multi-kernel based method to identify emotion causes. Following this corpus, Xu et al. (2019) proposed a learning to re-rank m"
2020.acl-main.342,N19-1423,0,0.00730032,"tion detection, cause detection, and their causality association can be jointly learned through joint decoding, without differentiating subtask structures, so that the maximum potential of information interaction between emotions and causes can be exploited. Besides, the proposed model processes the input sequence in a psycholinguistically motivated left to right order, consequently, reducing the number of potential pairs needed to be parsed and leading to speed up (if all clauses are connected by Cartesian products, the time complexity will be O(n2 )). Regarding feature representation, BERT (Devlin et al., 2019) is used to produce the deep and contextualized representation for each clause, and LSTMs (Hochreiter and Schmidhuber, 1997) are performed to capture long-term dependencies among input sequences. In addition, action history and relative distance information between the emotion-cause pairs are also encoded to benefit the task. To summarize, our contribution includes: • Learning with a transition-based framework, so that end-to-end emotion-cause pair extraction can be easily transformed into a parsinglike directed graph construction task. • With the proposed joint learning framework, our model c"
2020.acl-main.342,D19-1563,1,0.900676,"sad now}. The goal of ECPE is to identify all the pairs that have emotion causality in an emotion text. However, from both theoretical and computational perspectives, due to the inherent ambiguity and subtlety of emotions, it is hard for machines to build a mechanism for understanding emotion causality like human beings. Previous approaches mostly focused on detecting the causes towards the given annotation of emotions, which was followed by most of the recent studies in this field (Lee et al., 2010; Gui et al., 2014; Gao et al., 2015; Gui et al., 2016, 2017; Li et al., 2018; Xu et al., 2019; Fan et al., 2019). Nevertheless, it suffers that emotions must be annotated before extracting the causes, which limits the applications in real-world scenarios. Towards this issue, Xia and Ding (2019) presented a new task to extract emotion-cause pairs from the unannotated text. However, they followed a pipelined framework, which models emotions and causes separately, rather than joint decoding. Hence, to overcome the drawback of error propagation may occur in existing methods. Ideally, 3707 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3707–3717 c July 5 - 10,"
2020.acl-main.342,N18-2109,0,0.0618282,"Missing"
2020.acl-main.342,D17-1167,1,0.836413,"ed the rule-based features to 25 linguistics cues, then trained classifiers on SVM and CRFs to detect causes. Gui et al. (2016) released a new Chinese emotion cause dataset collected from SINA city news 4 and proposed a multi-kernel based method to identify emotion causes. Following this corpus, Xu et al. (2019) proposed a learning to re-rank method based on a series of emotion-dependent and emotion-independent features. Recently, inspired by the success of deep learning architecture, some studies focused on identifying emotion causes with well designed neural network and attention mechanism (Gui et al., 2017; Li et al., 2018, 2019; Fan et al., 2019; Xia et al., 2019; Ding et al., 2019). All of the above studies extracted emotion causes rely on the given emotion annotations, which limits the application in real-world scenarios due to the expensive annotations. Targeting this problem, Xia and Ding (2019) proposed a novel task based on ECE, namely emotion-cause pair extraction (ECPE), which aims at extracting emotions and the corresponding causes from unannotated emotion text. However, they followed a pipelined framework which first detects emotions and causes with individual learning frameworks, th"
2020.acl-main.342,D16-1170,1,0.76033,"sample should be {I lost my phone while shopping, I feel sad now}. The goal of ECPE is to identify all the pairs that have emotion causality in an emotion text. However, from both theoretical and computational perspectives, due to the inherent ambiguity and subtlety of emotions, it is hard for machines to build a mechanism for understanding emotion causality like human beings. Previous approaches mostly focused on detecting the causes towards the given annotation of emotions, which was followed by most of the recent studies in this field (Lee et al., 2010; Gui et al., 2014; Gao et al., 2015; Gui et al., 2016, 2017; Li et al., 2018; Xu et al., 2019; Fan et al., 2019). Nevertheless, it suffers that emotions must be annotated before extracting the causes, which limits the applications in real-world scenarios. Towards this issue, Xia and Ding (2019) presented a new task to extract emotion-cause pairs from the unannotated text. However, they followed a pipelined framework, which models emotions and causes separately, rather than joint decoding. Hence, to overcome the drawback of error propagation may occur in existing methods. Ideally, 3707 Proceedings of the 58th Annual Meeting of the Association for"
2020.acl-main.342,P82-1020,0,0.785516,"Missing"
2020.acl-main.342,W10-0206,0,0.766664,"“ I feel sad now”. Thus, the extracted results of this sample should be {I lost my phone while shopping, I feel sad now}. The goal of ECPE is to identify all the pairs that have emotion causality in an emotion text. However, from both theoretical and computational perspectives, due to the inherent ambiguity and subtlety of emotions, it is hard for machines to build a mechanism for understanding emotion causality like human beings. Previous approaches mostly focused on detecting the causes towards the given annotation of emotions, which was followed by most of the recent studies in this field (Lee et al., 2010; Gui et al., 2014; Gao et al., 2015; Gui et al., 2016, 2017; Li et al., 2018; Xu et al., 2019; Fan et al., 2019). Nevertheless, it suffers that emotions must be annotated before extracting the causes, which limits the applications in real-world scenarios. Towards this issue, Xia and Ding (2019) presented a new task to extract emotion-cause pairs from the unannotated text. However, they followed a pipelined framework, which models emotions and causes separately, rather than joint decoding. Hence, to overcome the drawback of error propagation may occur in existing methods. Ideally, 3707 Proceed"
2020.acl-main.342,D18-1506,0,0.13918,"t my phone while shopping, I feel sad now}. The goal of ECPE is to identify all the pairs that have emotion causality in an emotion text. However, from both theoretical and computational perspectives, due to the inherent ambiguity and subtlety of emotions, it is hard for machines to build a mechanism for understanding emotion causality like human beings. Previous approaches mostly focused on detecting the causes towards the given annotation of emotions, which was followed by most of the recent studies in this field (Lee et al., 2010; Gui et al., 2014; Gao et al., 2015; Gui et al., 2016, 2017; Li et al., 2018; Xu et al., 2019; Fan et al., 2019). Nevertheless, it suffers that emotions must be annotated before extracting the causes, which limits the applications in real-world scenarios. Towards this issue, Xia and Ding (2019) presented a new task to extract emotion-cause pairs from the unannotated text. However, they followed a pipelined framework, which models emotions and causes separately, rather than joint decoding. Hence, to overcome the drawback of error propagation may occur in existing methods. Ideally, 3707 Proceedings of the 58th Annual Meeting of the Association for Computational Linguist"
2020.acl-main.342,D18-1124,0,0.0282005,"otions and causes simultaneously to maximize the mutual benefits of subtasks, thus alleviating the drawback of error propagation. Transition-based system is usually designed to model the chunk-level relation in a sentence for dependency parsing (Zhang and Nivre, 2011; Wang et al., 2015; Fern´andez-Gonz´alez and G´omezRodr´ıguez, 2018). Apart from its application in dependency parsing, transition-based method has 3714 4 http://news.sina.com.cn/society/ also achieved great success in other natural language processing tasks, such as word segmentation (Zhang et al., 2016), information extraction (Wang et al., 2018b; Zhang et al., 2019), disfluency detection (Wang et al., 2017) and nested mention recognition (Wang et al., 2018a). To the best of our knowledge, this is the first work which extracts the emotion-cause pairs in an end-to-end manner. 7 Conclusion In this paper, we present a novel transition-based framework to extract emotion-cause pairs as a procedure of directed graph construction. Instead of previous pipelined approaches, the proposed framework incrementally outputs the emotion-cause pairs as a single task, thereby the interdependence between emotions and causes can be exploited more effect"
2020.acl-main.342,N15-1040,0,0.0303838,"unannotated emotion text. However, they followed a pipelined framework which first detects emotions and causes with individual learning frameworks, then performed emotion-cause pairing to eliminate the unmatched pairs, leading to a drawback of error propagation. In this work, we design a novel transition-based model to extract emotions and causes simultaneously to maximize the mutual benefits of subtasks, thus alleviating the drawback of error propagation. Transition-based system is usually designed to model the chunk-level relation in a sentence for dependency parsing (Zhang and Nivre, 2011; Wang et al., 2015; Fern´andez-Gonz´alez and G´omezRodr´ıguez, 2018). Apart from its application in dependency parsing, transition-based method has 3714 4 http://news.sina.com.cn/society/ also achieved great success in other natural language processing tasks, such as word segmentation (Zhang et al., 2016), information extraction (Wang et al., 2018b; Zhang et al., 2019), disfluency detection (Wang et al., 2017) and nested mention recognition (Wang et al., 2018a). To the best of our knowledge, this is the first work which extracts the emotion-cause pairs in an end-to-end manner. 7 Conclusion In this paper, we pre"
2020.acl-main.342,D17-1296,0,0.018959,"s of subtasks, thus alleviating the drawback of error propagation. Transition-based system is usually designed to model the chunk-level relation in a sentence for dependency parsing (Zhang and Nivre, 2011; Wang et al., 2015; Fern´andez-Gonz´alez and G´omezRodr´ıguez, 2018). Apart from its application in dependency parsing, transition-based method has 3714 4 http://news.sina.com.cn/society/ also achieved great success in other natural language processing tasks, such as word segmentation (Zhang et al., 2016), information extraction (Wang et al., 2018b; Zhang et al., 2019), disfluency detection (Wang et al., 2017) and nested mention recognition (Wang et al., 2018a). To the best of our knowledge, this is the first work which extracts the emotion-cause pairs in an end-to-end manner. 7 Conclusion In this paper, we present a novel transition-based framework to extract emotion-cause pairs as a procedure of directed graph construction. Instead of previous pipelined approaches, the proposed framework incrementally outputs the emotion-cause pairs as a single task, thereby the interdependence between emotions and causes can be exploited more effectively. Experimental results on a standard benchmark demonstrate"
2020.acl-main.342,P19-1096,0,0.727155,"erent ambiguity and subtlety of emotions, it is hard for machines to build a mechanism for understanding emotion causality like human beings. Previous approaches mostly focused on detecting the causes towards the given annotation of emotions, which was followed by most of the recent studies in this field (Lee et al., 2010; Gui et al., 2014; Gao et al., 2015; Gui et al., 2016, 2017; Li et al., 2018; Xu et al., 2019; Fan et al., 2019). Nevertheless, it suffers that emotions must be annotated before extracting the causes, which limits the applications in real-world scenarios. Towards this issue, Xia and Ding (2019) presented a new task to extract emotion-cause pairs from the unannotated text. However, they followed a pipelined framework, which models emotions and causes separately, rather than joint decoding. Hence, to overcome the drawback of error propagation may occur in existing methods. Ideally, 3707 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3707–3717 c July 5 - 10, 2020. 2020 Association for Computational Linguistics the emotion-cause structure should be considered as an integral framework, including representation learning, emotion-cause extrac"
2020.acl-main.342,P16-1040,0,0.0210489,"e are some studies have been exploited for this task such as rule-based methods (Li and Xu, 2014; Gao et al., 2015; Yada et al., 2017) and machine learning methods (Ghazi et al., 2015; Song and Meng, 2015). Chen et al. (2010) converted the task from word-level to clause-level due to a clause may be the most appropriate unit to detect causes, and extracted causes using six groups of manually constructed linguistic cues. By following this task setting, Gui et al. (2014) extended the rule-based features to 25 linguistics cues, then trained classifiers on SVM and CRFs to detect causes. Gui et al. (2016) released a new Chinese emotion cause dataset collected from SINA city news 4 and proposed a multi-kernel based method to identify emotion causes. Following this corpus, Xu et al. (2019) proposed a learning to re-rank method based on a series of emotion-dependent and emotion-independent features. Recently, inspired by the success of deep learning architecture, some studies focused on identifying emotion causes with well designed neural network and attention mechanism (Gui et al., 2017; Li et al., 2018, 2019; Fan et al., 2019; Xia et al., 2019; Ding et al., 2019). All of the above studies extra"
2020.acl-main.342,P11-2033,0,0.020669,"responding causes from unannotated emotion text. However, they followed a pipelined framework which first detects emotions and causes with individual learning frameworks, then performed emotion-cause pairing to eliminate the unmatched pairs, leading to a drawback of error propagation. In this work, we design a novel transition-based model to extract emotions and causes simultaneously to maximize the mutual benefits of subtasks, thus alleviating the drawback of error propagation. Transition-based system is usually designed to model the chunk-level relation in a sentence for dependency parsing (Zhang and Nivre, 2011; Wang et al., 2015; Fern´andez-Gonz´alez and G´omezRodr´ıguez, 2018). Apart from its application in dependency parsing, transition-based method has 3714 4 http://news.sina.com.cn/society/ also achieved great success in other natural language processing tasks, such as word segmentation (Zhang et al., 2016), information extraction (Wang et al., 2018b; Zhang et al., 2019), disfluency detection (Wang et al., 2017) and nested mention recognition (Wang et al., 2018a). To the best of our knowledge, this is the first work which extracts the emotion-cause pairs in an end-to-end manner. 7 Conclusion In"
2020.acl-main.342,P17-1113,0,0.0297421,"ted in this paper. The results are average score over 20 runs, and the best scores are in bold. which contains three models: 1) Indep: Emotion extraction and cause extraction are independently trained, then filtering the pairs that have no emotion causality; 2) Inter-CE: The difference is that the predictions of cause extraction are used to improve emotion extraction; 3) Inter-EC: Contrary to the Inter-CE, the predictions of emotion extraction are used to improve cause extraction. It is the current state-of-the-art model for this task. To compare with other joint models, we implement SL-BERT (Zheng et al., 2017) and MT-BERT (Caruana, 1993) for this task. The former aims to joint extract entities and relations based on a novel tagging scheme with multiple labels and the other is a multi-task learning framework by sharing the hidden layers among all tasks. We implement them both based on BERT to be consistent with our experimental setting. We also evaluate our model by only removing the transition procedure to reveal the effect of the transition-based algorithm, denoted as “-transition”. Besides, for a fair comparison, we use LSTM as the basic encoder of clauses instead of BERT and keep the same experi"
2020.coling-main.13,P19-1052,0,0.0710785,"for a given aspect. MGAN (Fan et al., 2018) exploits fine-grained and coarse-grained attention mechanisms to capture the word-level interaction between aspect and context. AOA (Huang et al., 2018) utilizes an attention-over-attention model to learn the interaction between aspect words and contextual words. TNet-LF (Li et al., 2018) exploits a target-specific transformation component to better integrate target information into the word representations. IARM (Majumder et al., 2018) extracts the influence of the neighboring aspects related information for the aspect sentiment analysis. TransCap (Chen and Qian, 2019) utilizes a transfer capsule network model for aspect sentiment analysis. IACapsNet (Du et al., 2019) adopts a capsule network to model vector-based feature representation and cluster features by an EM routing algorithm for a specific aspect. AEN (Song et al., 2019) explores an attention encoder network to extract contextual sentiment interactions for the aspect. TD-GAT (Huang and Carley, 2019) exploits a target-dependent graph attention network over dependency tree for aspect sentiment analysis. ASGCN-DT and ASGCN-DG (Zhang et al., 2019) extracts syntactical information and word dependencies"
2020.coling-main.13,D17-1047,0,0.432835,"ns Attribution 4.0 International Licence. //creativecommons.org/licenses/by/4.0/ Licence details: http: 150 Proceedings of the 28th International Conference on Computational Linguistics, pages 150–161 Barcelona, Spain (Online), December 8-13, 2020 The soup for the udon was soy sauce and water (a) Example of aspect-focused relations Great toppings definitely a place you need to check out positive negative (b) Example of inter-aspect relations Figure 1: Examples of the contextual relations of different aspect words within an aspect and the sentiment relations of different aspects in a sentence. Chen et al., 2017; Wang et al., 2018; Zheng et al., 2020). Subsequently, attention-based neural models are widely used in this task, which can enforce the model to focus on the given aspect (Wang et al., 2016b; Tang et al., 2016b; He et al., 2019). In most previous methods, however, they generally embed aspect information into the sentence representation to learn the pertinent sentiment features for the specific aspect, which leads to a lack of capturing the inter-aspect sentiment relations for a specific aspect. Analogously, most existing graph network-based model merely consider the syntactical dependencies"
2020.coling-main.13,N19-1423,0,0.50777,"Convolutional Networks. Graph convolutional network (GCN) has achieved promising performance in many NLP tasks (Kipf and Welling, 2017; Zhang et al., 2018; Huang et al., 2019; Yao et al., 2019). In aspect sentiment analysis, (Zhang et al., 2019) exploited GCN to capture syntactical information and word dependencies for the specific aspect over the dependency tree of a sentence. (Sun et al., 2019) proposed a GCN model over the dependency tree of the sentence to enhance the feature representations of aspects learned by a Bi-directional LSTM (Bi-LSTM). In addition, to develop the merit of BERT (Devlin et al., 2019), a GCN model based on selective attention was proposed to extract and aggregate the most important contextual features for the aspect representation (Hou et al., 2019). The above GCN-based models, however, neither considered the specific aspect when constructing the graph of the sentence nor extracted inter-aspect sentiment relations for the specific aspect. To this end, based on the merit of GCN in aspect sentiment analysis, we explore a novel solution of constructing syntactical dependency graph for a sentence according to the specific aspect and propose an Interactive Graph Convolutional N"
2020.coling-main.13,D19-1551,0,0.0994797,"attention mechanism to capture the contextual representations via paying attention to the key parts of the sentence according to the given aspect. (Tang et al., 2016b) proposed an attention-based memory network to store contextual words and conducted multi-hop attention to derive the sentiment representation for the aspect. (Chen et al., 2017) utilized a weighted-memory mechanism to produce a tailor-made memory for different opinion aspects based on memory network. In addition, (Xue and Li, 2018) utilized a gated CNN to selectively model the sentiment features according to the given aspect. (Du et al., 2019) adopted a capsule network to construct vector-based feature representation and cluster features by an EM routing algorithm. (Majumder et al., 2018) considered the neighboring aspect-related information for the aspect-specific sentiment analysis with memory networks. 151 Output Masking Aspect Relations GCN Layers Aspect-Focused LSTM Layers Dependency Tree Embedding Module … … … Attention Scores GCN Layers Inter-Aspect Screening of Aspects Figure 2: The architecture of the proposed Interactive Graph Convolutional Networks. Graph convolutional network (GCN) has achieved promising performance in"
2020.coling-main.13,D18-1380,0,0.0608675,"extual features for a given aspect with LSTMs. ATAE-LSTM (Wang et al., 2016b) explores aspect-specific attention mechanism based on LSTM. MemNet (Tang et al., 2016b) exploits word and position attention to focus on specific aspect by a multihop memory network. IAN (Ma et al., 2017) learns the interactive relationships for aspect and context representations by an interactive attention network. RAM (Chen et al., 2017) proposes a recurrent attention memory network for aspect sentiment analysis. GCAE (Xue and Li, 2018) explores a gated CNN to control the flow of features for a given aspect. MGAN (Fan et al., 2018) exploits fine-grained and coarse-grained attention mechanisms to capture the word-level interaction between aspect and context. AOA (Huang et al., 2018) utilizes an attention-over-attention model to learn the interaction between aspect words and contextual words. TNet-LF (Li et al., 2018) exploits a target-specific transformation component to better integrate target information into the word representations. IARM (Majumder et al., 2018) extracts the influence of the neighboring aspects related information for the aspect sentiment analysis. TransCap (Chen and Qian, 2019) utilizes a transfer ca"
2020.coling-main.13,P19-1048,0,0.0238008,"ember 8-13, 2020 The soup for the udon was soy sauce and water (a) Example of aspect-focused relations Great toppings definitely a place you need to check out positive negative (b) Example of inter-aspect relations Figure 1: Examples of the contextual relations of different aspect words within an aspect and the sentiment relations of different aspects in a sentence. Chen et al., 2017; Wang et al., 2018; Zheng et al., 2020). Subsequently, attention-based neural models are widely used in this task, which can enforce the model to focus on the given aspect (Wang et al., 2016b; Tang et al., 2016b; He et al., 2019). In most previous methods, however, they generally embed aspect information into the sentence representation to learn the pertinent sentiment features for the specific aspect, which leads to a lack of capturing the inter-aspect sentiment relations for a specific aspect. Analogously, most existing graph network-based model merely consider the syntactical dependencies between the specific aspect and the context (Zhang et al., 2019; Huang and Carley, 2019; Sun et al., 2019), which is insufficient to focus on which contextual dependencies along with aspect-specific words are essential for the spe"
2020.coling-main.13,D19-1549,0,0.234552,"-based neural models are widely used in this task, which can enforce the model to focus on the given aspect (Wang et al., 2016b; Tang et al., 2016b; He et al., 2019). In most previous methods, however, they generally embed aspect information into the sentence representation to learn the pertinent sentiment features for the specific aspect, which leads to a lack of capturing the inter-aspect sentiment relations for a specific aspect. Analogously, most existing graph network-based model merely consider the syntactical dependencies between the specific aspect and the context (Zhang et al., 2019; Huang and Carley, 2019; Sun et al., 2019), which is insufficient to focus on which contextual dependencies along with aspect-specific words are essential for the specific aspect and also largely ignore the sentiment relations between different aspects in the sentence. Since intuitively, the role of distinct aspect word is different in deriving aspect expression. Besides, there are intricate sentiment relations among different aspects in many instances. In this paper, we explore a novel solution to construct heterogeneous graphs of sentences via enriching the contextual syntactical dependency representations of the"
2020.coling-main.13,D19-1345,0,0.0198362,"representation and cluster features by an EM routing algorithm. (Majumder et al., 2018) considered the neighboring aspect-related information for the aspect-specific sentiment analysis with memory networks. 151 Output Masking Aspect Relations GCN Layers Aspect-Focused LSTM Layers Dependency Tree Embedding Module … … … Attention Scores GCN Layers Inter-Aspect Screening of Aspects Figure 2: The architecture of the proposed Interactive Graph Convolutional Networks. Graph convolutional network (GCN) has achieved promising performance in many NLP tasks (Kipf and Welling, 2017; Zhang et al., 2018; Huang et al., 2019; Yao et al., 2019). In aspect sentiment analysis, (Zhang et al., 2019) exploited GCN to capture syntactical information and word dependencies for the specific aspect over the dependency tree of a sentence. (Sun et al., 2019) proposed a GCN model over the dependency tree of the sentence to enhance the feature representations of aspects learned by a Bi-directional LSTM (Bi-LSTM). In addition, to develop the merit of BERT (Devlin et al., 2019), a GCN model based on selective attention was proposed to extract and aggregate the most important contextual features for the aspect representation (Hou"
2020.coling-main.13,P11-1016,0,0.14325,"oduced. • An Interactive Graph Convolutional Networks model is proposed to derive aspect-specific sentiment features by interactively extracting the sentiment relations within aspect words and across different aspects in the context. • Experimental results on four benchmark datasets show that the proposed model achieves the stateof-the-art performance in aspect sentiment analysis. 2 Related Work Some early works mostly use machine learning algorithms to capture the sentiment polarity based on rich features about content and syntactic structures in aspect sentiment analysis (Pang et al., 2008; Jiang et al., 2011; Kiritchenko et al., 2014). Recently, deep learning models have achieved promising performance in aspect sentiment analysis (Tang et al., 2016a; Wang et al., 2016b; Tang et al., 2016b; Chen et al., 2017; Ma et al., 2017; Xue and Li, 2018; Li et al., 2019; Liang et al., 2019). The majority of current approaches attempt to pay more attention to the specific aspect based on attention mechanism. (Wang et al., 2016b) exploited attention mechanism to capture the contextual representations via paying attention to the key parts of the sentence according to the given aspect. (Tang et al., 2016b) propo"
2020.coling-main.13,S14-2076,0,0.430092,"tive Graph Convolutional Networks model is proposed to derive aspect-specific sentiment features by interactively extracting the sentiment relations within aspect words and across different aspects in the context. • Experimental results on four benchmark datasets show that the proposed model achieves the stateof-the-art performance in aspect sentiment analysis. 2 Related Work Some early works mostly use machine learning algorithms to capture the sentiment polarity based on rich features about content and syntactic structures in aspect sentiment analysis (Pang et al., 2008; Jiang et al., 2011; Kiritchenko et al., 2014). Recently, deep learning models have achieved promising performance in aspect sentiment analysis (Tang et al., 2016a; Wang et al., 2016b; Tang et al., 2016b; Chen et al., 2017; Ma et al., 2017; Xue and Li, 2018; Li et al., 2019; Liang et al., 2019). The majority of current approaches attempt to pay more attention to the specific aspect based on attention mechanism. (Wang et al., 2016b) exploited attention mechanism to capture the contextual representations via paying attention to the key parts of the sentence according to the given aspect. (Tang et al., 2016b) proposed an attention-based memo"
2020.coling-main.13,P18-1087,0,0.0360106,"he interactive relationships for aspect and context representations by an interactive attention network. RAM (Chen et al., 2017) proposes a recurrent attention memory network for aspect sentiment analysis. GCAE (Xue and Li, 2018) explores a gated CNN to control the flow of features for a given aspect. MGAN (Fan et al., 2018) exploits fine-grained and coarse-grained attention mechanisms to capture the word-level interaction between aspect and context. AOA (Huang et al., 2018) utilizes an attention-over-attention model to learn the interaction between aspect words and contextual words. TNet-LF (Li et al., 2018) exploits a target-specific transformation component to better integrate target information into the word representations. IARM (Majumder et al., 2018) extracts the influence of the neighboring aspects related information for the aspect sentiment analysis. TransCap (Chen and Qian, 2019) utilizes a transfer capsule network model for aspect sentiment analysis. IACapsNet (Du et al., 2019) adopts a capsule network to model vector-based feature representation and cluster features by an EM routing algorithm for a specific aspect. AEN (Song et al., 2019) explores an attention encoder network to extra"
2020.coling-main.13,D19-1466,0,0.0174777,"n four benchmark datasets show that the proposed model achieves the stateof-the-art performance in aspect sentiment analysis. 2 Related Work Some early works mostly use machine learning algorithms to capture the sentiment polarity based on rich features about content and syntactic structures in aspect sentiment analysis (Pang et al., 2008; Jiang et al., 2011; Kiritchenko et al., 2014). Recently, deep learning models have achieved promising performance in aspect sentiment analysis (Tang et al., 2016a; Wang et al., 2016b; Tang et al., 2016b; Chen et al., 2017; Ma et al., 2017; Xue and Li, 2018; Li et al., 2019; Liang et al., 2019). The majority of current approaches attempt to pay more attention to the specific aspect based on attention mechanism. (Wang et al., 2016b) exploited attention mechanism to capture the contextual representations via paying attention to the key parts of the sentence according to the given aspect. (Tang et al., 2016b) proposed an attention-based memory network to store contextual words and conducted multi-hop attention to derive the sentiment representation for the aspect. (Chen et al., 2017) utilized a weighted-memory mechanism to produce a tailor-made memory for different"
2020.coling-main.13,P19-1462,1,0.842212,"datasets show that the proposed model achieves the stateof-the-art performance in aspect sentiment analysis. 2 Related Work Some early works mostly use machine learning algorithms to capture the sentiment polarity based on rich features about content and syntactic structures in aspect sentiment analysis (Pang et al., 2008; Jiang et al., 2011; Kiritchenko et al., 2014). Recently, deep learning models have achieved promising performance in aspect sentiment analysis (Tang et al., 2016a; Wang et al., 2016b; Tang et al., 2016b; Chen et al., 2017; Ma et al., 2017; Xue and Li, 2018; Li et al., 2019; Liang et al., 2019). The majority of current approaches attempt to pay more attention to the specific aspect based on attention mechanism. (Wang et al., 2016b) exploited attention mechanism to capture the contextual representations via paying attention to the key parts of the sentence according to the given aspect. (Tang et al., 2016b) proposed an attention-based memory network to store contextual words and conducted multi-hop attention to derive the sentiment representation for the aspect. (Chen et al., 2017) utilized a weighted-memory mechanism to produce a tailor-made memory for different opinion aspects base"
2020.coling-main.13,D18-1377,0,0.0448151,"Missing"
2020.coling-main.13,D14-1162,0,0.0970827,"e aim of aspect sentiment analysis is to predict the sentiment polarity over a given aspect in a sentence. 3.1 Embedding Module In our InterGCN model, each word embedding is a distributed representation of a word in the sentence, which is retrieved from the embedding lookup table V ∈ Rm×|N |according to the word index, where |N | is the vocabulary size. And thus, for a sentence with n words, we can get the corresponding embedding matrix x = [x1 , x2 , · · · , xn ], where xi ∈ Rm is the word embedding of wi , m is the dimension of word vectors. We exploit the pre-trained word embeddings GloVe (Pennington et al., 2014) and BERT (Devlin et al., 2019) to initialize word vectors, and fine-tune them during the training process. 152 3.2 Producing Ordinary Graphs over Dependency Tree Inspired by the previous GCN-based works (Zhang et al., 2019; Sun et al., 2019), we first produce an ordinary dependency graph for each input sentence over the dependency tree1 : Di,j ( 1 if i = j or wi , wj in the dependency tree of the sentence = 0 otherwise (1) After that, an adjacency matrix D ∈ Rn×n is derived via the dependency tree of the input sentence. 3.3 Refining Graphs for Specific Aspect To highlight the specific aspect"
2020.coling-main.13,S14-2004,0,0.0928357,"og(yij ) + λ||Θ||2 (15) i=1 j=1 Where S is the number of training samples, C is the number of classes. yˆ is the ground-truth distribution of sentiment. λ is the weight of the L2 regularization term. Θ denotes all trainable parameters. Dataset Positive Train Test R EST 14 L AP 14 R EST 15 R EST 16 2164 994 1178 1620 728 341 439 597 Neural Train Test 637 464 50 88 196 169 35 38 Negative Train Test 807 870 382 709 196 128 328 190 Table 1: Statistics of the experimental datasets. 4 4.1 Experiments Dataset and Experiment Setting We conduct experiments on four benchmark datasets from SemEval 2014 (Pontiki et al., 2014) (Restaurant14, Laptop14), SemEval 2015 (Pontiki et al., 2015) (Restaurant15), and SemEval 2016 (Pontiki et al., 2016) (Restaurant16). Each sample consists of the review sentences, aspects (single or multiple words), and the sentiment polarity towards to the aspects. The statistics of the datasets are shown in Table 1. 155 In our experiments, we use GloVe vectors (Pennington et al., 2014) to initialize each word into 300dimensional word embedding for all non-BERT models. The dimensionality of hidden vector representations is set to 300. The number of GCN layers is set to 2, which is the optima"
2020.coling-main.13,S15-2082,0,0.0844451,"Missing"
2020.coling-main.13,D19-1569,0,0.417646,"widely used in this task, which can enforce the model to focus on the given aspect (Wang et al., 2016b; Tang et al., 2016b; He et al., 2019). In most previous methods, however, they generally embed aspect information into the sentence representation to learn the pertinent sentiment features for the specific aspect, which leads to a lack of capturing the inter-aspect sentiment relations for a specific aspect. Analogously, most existing graph network-based model merely consider the syntactical dependencies between the specific aspect and the context (Zhang et al., 2019; Huang and Carley, 2019; Sun et al., 2019), which is insufficient to focus on which contextual dependencies along with aspect-specific words are essential for the specific aspect and also largely ignore the sentiment relations between different aspects in the sentence. Since intuitively, the role of distinct aspect word is different in deriving aspect expression. Besides, there are intricate sentiment relations among different aspects in many instances. In this paper, we explore a novel solution to construct heterogeneous graphs of sentences via enriching the contextual syntactical dependency representations of the key aspect words an"
2020.coling-main.13,C16-1311,0,0.437191,"ence. There is a sufficiently clear positive sentiment word (“great”) for aspect “toppings”, while for aspect “place”, which contains no sentiment expression, the sentiment polarity can also be identified thanks to the inter-aspect relations between aspect “toppings” and “place”. Hence, both aspect-focused and inter-aspect contextual relations should be considered for improving the performance of aspect sentiment analysis. Recently, with the development of deep learning technique, many neural network-based methods achieve promising performance in aspect sentiment analysis (Wang et al., 2016a; Tang et al., 2016a; ∗ Corresponding Author This work is licensed under a Creative Commons Attribution 4.0 International Licence. //creativecommons.org/licenses/by/4.0/ Licence details: http: 150 Proceedings of the 28th International Conference on Computational Linguistics, pages 150–161 Barcelona, Spain (Online), December 8-13, 2020 The soup for the udon was soy sauce and water (a) Example of aspect-focused relations Great toppings definitely a place you need to check out positive negative (b) Example of inter-aspect relations Figure 1: Examples of the contextual relations of different aspect words within an a"
2020.coling-main.13,D16-1021,0,0.456809,"ence. There is a sufficiently clear positive sentiment word (“great”) for aspect “toppings”, while for aspect “place”, which contains no sentiment expression, the sentiment polarity can also be identified thanks to the inter-aspect relations between aspect “toppings” and “place”. Hence, both aspect-focused and inter-aspect contextual relations should be considered for improving the performance of aspect sentiment analysis. Recently, with the development of deep learning technique, many neural network-based methods achieve promising performance in aspect sentiment analysis (Wang et al., 2016a; Tang et al., 2016a; ∗ Corresponding Author This work is licensed under a Creative Commons Attribution 4.0 International Licence. //creativecommons.org/licenses/by/4.0/ Licence details: http: 150 Proceedings of the 28th International Conference on Computational Linguistics, pages 150–161 Barcelona, Spain (Online), December 8-13, 2020 The soup for the udon was soy sauce and water (a) Example of aspect-focused relations Great toppings definitely a place you need to check out positive negative (b) Example of inter-aspect relations Figure 1: Examples of the contextual relations of different aspect words within an a"
2020.coling-main.13,D16-1059,0,0.251101,"aneously in the sentence. There is a sufficiently clear positive sentiment word (“great”) for aspect “toppings”, while for aspect “place”, which contains no sentiment expression, the sentiment polarity can also be identified thanks to the inter-aspect relations between aspect “toppings” and “place”. Hence, both aspect-focused and inter-aspect contextual relations should be considered for improving the performance of aspect sentiment analysis. Recently, with the development of deep learning technique, many neural network-based methods achieve promising performance in aspect sentiment analysis (Wang et al., 2016a; Tang et al., 2016a; ∗ Corresponding Author This work is licensed under a Creative Commons Attribution 4.0 International Licence. //creativecommons.org/licenses/by/4.0/ Licence details: http: 150 Proceedings of the 28th International Conference on Computational Linguistics, pages 150–161 Barcelona, Spain (Online), December 8-13, 2020 The soup for the udon was soy sauce and water (a) Example of aspect-focused relations Great toppings definitely a place you need to check out positive negative (b) Example of inter-aspect relations Figure 1: Examples of the contextual relations of different aspe"
2020.coling-main.13,D16-1058,0,0.656177,"aneously in the sentence. There is a sufficiently clear positive sentiment word (“great”) for aspect “toppings”, while for aspect “place”, which contains no sentiment expression, the sentiment polarity can also be identified thanks to the inter-aspect relations between aspect “toppings” and “place”. Hence, both aspect-focused and inter-aspect contextual relations should be considered for improving the performance of aspect sentiment analysis. Recently, with the development of deep learning technique, many neural network-based methods achieve promising performance in aspect sentiment analysis (Wang et al., 2016a; Tang et al., 2016a; ∗ Corresponding Author This work is licensed under a Creative Commons Attribution 4.0 International Licence. //creativecommons.org/licenses/by/4.0/ Licence details: http: 150 Proceedings of the 28th International Conference on Computational Linguistics, pages 150–161 Barcelona, Spain (Online), December 8-13, 2020 The soup for the udon was soy sauce and water (a) Example of aspect-focused relations Great toppings definitely a place you need to check out positive negative (b) Example of inter-aspect relations Figure 1: Examples of the contextual relations of different aspe"
2020.coling-main.13,P18-1088,0,0.0164844,"International Licence. //creativecommons.org/licenses/by/4.0/ Licence details: http: 150 Proceedings of the 28th International Conference on Computational Linguistics, pages 150–161 Barcelona, Spain (Online), December 8-13, 2020 The soup for the udon was soy sauce and water (a) Example of aspect-focused relations Great toppings definitely a place you need to check out positive negative (b) Example of inter-aspect relations Figure 1: Examples of the contextual relations of different aspect words within an aspect and the sentiment relations of different aspects in a sentence. Chen et al., 2017; Wang et al., 2018; Zheng et al., 2020). Subsequently, attention-based neural models are widely used in this task, which can enforce the model to focus on the given aspect (Wang et al., 2016b; Tang et al., 2016b; He et al., 2019). In most previous methods, however, they generally embed aspect information into the sentence representation to learn the pertinent sentiment features for the specific aspect, which leads to a lack of capturing the inter-aspect sentiment relations for a specific aspect. Analogously, most existing graph network-based model merely consider the syntactical dependencies between the specifi"
2020.coling-main.13,P18-1234,0,0.14027,"rimental results on four benchmark datasets show that the proposed model achieves the stateof-the-art performance in aspect sentiment analysis. 2 Related Work Some early works mostly use machine learning algorithms to capture the sentiment polarity based on rich features about content and syntactic structures in aspect sentiment analysis (Pang et al., 2008; Jiang et al., 2011; Kiritchenko et al., 2014). Recently, deep learning models have achieved promising performance in aspect sentiment analysis (Tang et al., 2016a; Wang et al., 2016b; Tang et al., 2016b; Chen et al., 2017; Ma et al., 2017; Xue and Li, 2018; Li et al., 2019; Liang et al., 2019). The majority of current approaches attempt to pay more attention to the specific aspect based on attention mechanism. (Wang et al., 2016b) exploited attention mechanism to capture the contextual representations via paying attention to the key parts of the sentence according to the given aspect. (Tang et al., 2016b) proposed an attention-based memory network to store contextual words and conducted multi-hop attention to derive the sentiment representation for the aspect. (Chen et al., 2017) utilized a weighted-memory mechanism to produce a tailor-made mem"
2020.coling-main.13,D18-1244,0,0.0261036,"vector-based feature representation and cluster features by an EM routing algorithm. (Majumder et al., 2018) considered the neighboring aspect-related information for the aspect-specific sentiment analysis with memory networks. 151 Output Masking Aspect Relations GCN Layers Aspect-Focused LSTM Layers Dependency Tree Embedding Module … … … Attention Scores GCN Layers Inter-Aspect Screening of Aspects Figure 2: The architecture of the proposed Interactive Graph Convolutional Networks. Graph convolutional network (GCN) has achieved promising performance in many NLP tasks (Kipf and Welling, 2017; Zhang et al., 2018; Huang et al., 2019; Yao et al., 2019). In aspect sentiment analysis, (Zhang et al., 2019) exploited GCN to capture syntactical information and word dependencies for the specific aspect over the dependency tree of a sentence. (Sun et al., 2019) proposed a GCN model over the dependency tree of the sentence to enhance the feature representations of aspects learned by a Bi-directional LSTM (Bi-LSTM). In addition, to develop the merit of BERT (Devlin et al., 2019), a GCN model based on selective attention was proposed to extract and aggregate the most important contextual features for the aspect"
2020.coling-main.13,D19-1464,0,0.563648,"sequently, attention-based neural models are widely used in this task, which can enforce the model to focus on the given aspect (Wang et al., 2016b; Tang et al., 2016b; He et al., 2019). In most previous methods, however, they generally embed aspect information into the sentence representation to learn the pertinent sentiment features for the specific aspect, which leads to a lack of capturing the inter-aspect sentiment relations for a specific aspect. Analogously, most existing graph network-based model merely consider the syntactical dependencies between the specific aspect and the context (Zhang et al., 2019; Huang and Carley, 2019; Sun et al., 2019), which is insufficient to focus on which contextual dependencies along with aspect-specific words are essential for the specific aspect and also largely ignore the sentiment relations between different aspects in the sentence. Since intuitively, the role of distinct aspect word is different in deriving aspect expression. Besides, there are intricate sentiment relations among different aspects in many instances. In this paper, we explore a novel solution to construct heterogeneous graphs of sentences via enriching the contextual syntactical dependency"
2020.coling-main.362,D18-1547,0,0.0829113,"Missing"
2020.coling-main.362,P19-1258,0,0.0843435,"een proposed and shown promising results. Mem2Seq (Madotto et al., 2018) and GLMP (Wu et al., 2019) further augmented memory based methods by incorporating copy mechanism (Gulcehre et al., 2016), which enable the models copy words from past dialog utterances or from KB. These methods use a shared memory for the KB triples and the dialog utterances, making it difficult to reason over the memory and distinguish between the two forms of data. Recently, there have been several works employing separate memories for modeling the dialog context and KB triples (Raghu et al., 2019; Reddy et al., 2019; Chen et al., 2019). For example, BossNet (Raghu et al., 2019) implicitly disentangled the language model from knowledge incorporation and thus enhance the ability of copying unseen KB entries. Multi-level memory model (Reddy et al., 2019) represented the KB results with a multi-level memory instead of the form of triples. WMM2Seq (Chen et al., 2019) adopted a working memory to interact with a dialog context memory and a KB memory. Nevertheless, existing methods still ignore the flow of history information during conversations, making it struggle to perform well in long-turn interactions. Different from the afor"
2020.coling-main.362,W17-5506,0,0.238423,"ory pointer at each turn. Experimental results on three benchmark datasets demonstrate that DDMN significantly outperforms the strong baselines in terms of both automatic evaluation and human evaluation. Our code is available at https://github.com/siat-nlp/DDMN. 1 Introduction Task-oriented dialog systems are designed to help users achieve specific goals with natural language, such as weather inquiry or restaurant reservation. Compared with traditional pipeline methods (Williams and Young, 2007; Young et al., 2013), end-to-end approaches recently have gained much attention (Zhao et al., 2017; Eric and Manning, 2017; Madotto et al., 2018), since they free the task-oriented dialog systems from the manually designed pipeline modules and can be automatically scaled up to new domains. Recently, sequence-to-sequence (Seq2Seq) models have dominated the study of end-to-end taskoriented dialog systems (Bordes et al., 2017). Different from typical Seq2Seq models for open-domain dialog systems, the successful conversations for task-oriented dialog systems heavily rely on both dialog history and domain-specific knowledge base (KB). To effectively incorporate KB information and perform knowledge-based reasoning, mem"
2020.coling-main.362,P16-1014,0,0.124282,"he decoder generates a response word by word. In particular, a word at time step t is either generated from the vocabulary or copied from one of the two memories (dialog history memory or KB memory). First, the decoder employs a GRU network defined in Eq. (2) for generation. The generation distribution over vocabulary Pg (yt ) can be obtained by feeding the decoder state st and ct (the reading output of dialog history memory at the last round) into a softmax layer, which is given by Pg (yt ) = softmax(W1 [st ; ct ]) (11) where W1 is a trainable parameter. Second, following the copy mechanism (Gulcehre et al., 2016) that the attention scores are viewed as the probability to form the copy distribution, we adopt the addressing result of dialog state memory at the last round as thePattention score at,j , thus the copy distribution over the dialog history memory is given by Pc (yt = w) = tj:wtj =w at,j . Third, we use the KB memory pointer P trkb to dynamically access the KB memory, and then employ the decoder state st defined in Eq. (2) to attend over the KB memory: K ˜K ˜K βt,j = softmax(αtj ), αtj = vbT tanh(Wb st + Ub c (12) j ), c j = cj × σj , j ∈ [1, l] where vb ,Wb , Ub are parameters to be learned,"
2020.coling-main.362,D15-1166,0,0.0404352,"r-parameter γ in the loss function is set to 1. The hyper-parameters are tuned with grid-search over the validation set using BLEU score as metric. We select the model with best BLEU score as an initialization for SCST training, and use the weighted sum of BLEU and entity F1 score as our reward metric. During the decoding stage, we use beam-search strategy with the beam size sampling from {1, 2, 4}. 3.3 Baselines We compare our model with several existing end-to-end task-oriented dialog systems: (1) Seq2Seq/+Attn that employs standard seq2seq with and without attention over the input context (Luong et al., 2015); (2) Ptr-Unk that employs a seq2seq model with a copy mechanism to copy unknown words during generation (Gulcehre et al., 2016); (3) Mem2Seq that employs a memory network based approach with multi-hop attention for attending over dialog history and KB triples (Madotto et al., 2018); (4) BossNet that employs a bag-of-sequences memory network for disentangling language model from KB incorporation in taskoriented dialogs (Raghu et al., 2019); (5) MLM that employs a multi-level memory network for modeling dialog context and KB results separately (Reddy et al., 2019); (6) GLMP that employs a memor"
2020.coling-main.362,P18-1136,0,0.580301,". Experimental results on three benchmark datasets demonstrate that DDMN significantly outperforms the strong baselines in terms of both automatic evaluation and human evaluation. Our code is available at https://github.com/siat-nlp/DDMN. 1 Introduction Task-oriented dialog systems are designed to help users achieve specific goals with natural language, such as weather inquiry or restaurant reservation. Compared with traditional pipeline methods (Williams and Young, 2007; Young et al., 2013), end-to-end approaches recently have gained much attention (Zhao et al., 2017; Eric and Manning, 2017; Madotto et al., 2018), since they free the task-oriented dialog systems from the manually designed pipeline modules and can be automatically scaled up to new domains. Recently, sequence-to-sequence (Seq2Seq) models have dominated the study of end-to-end taskoriented dialog systems (Bordes et al., 2017). Different from typical Seq2Seq models for open-domain dialog systems, the successful conversations for task-oriented dialog systems heavily rely on both dialog history and domain-specific knowledge base (KB). To effectively incorporate KB information and perform knowledge-based reasoning, memory augmented models ha"
2020.coling-main.362,C16-1205,0,0.0210655,"ep t. The j-th value of a ˜t is given by: attention vector a T (r) (r−1) a ˜t,j = softmax(et,j ), et,j = va(r) tanh(Wa(r) qt + U(r) a kt,j where (r) va , (r) Wa and (r) Ua are learnable parameters, (r−1) kt,j ) (3) is the j-th slot in K(r−1) at time step t. Dialog History Memory Reading The reading operation reads from the dialog history memory V (r) (r) ˜t with the guidance of a ˜t . The output of reading is given by to get the context representation c P (r) (r) ˜t = N c ˜t,j vj , where vj is the j-th memory slot in V. j=1 a Dialog State Memory Updating Inspired by the read-write operations (Meng et al., 2016; Meng et al., 2018), we define two types of operations for updating the dialog state memory: FORGET and ADD. FORGET is analogous to the forget gate in GRU, which determines the information to be removed from memory slots. Similarly, ADD operation decides how much current information should be written to the dialog state memory as the added content. Specifically, we first deploy another GRU network to imitate the decoder at round r, and obtain the (r) “intermediate” hidden state ˜st with reading output: (r) ˜st where (r) ˜t ) = GRU(qt , c (4) (r) ˜st is used to update the dialog state memory."
2020.coling-main.362,P02-1040,0,0.106854,"ossNet that employs a bag-of-sequences memory network for disentangling language model from KB incorporation in taskoriented dialogs (Raghu et al., 2019); (5) MLM that employs a multi-level memory network for modeling dialog context and KB results separately (Reddy et al., 2019); (6) GLMP that employs a memory network with a global memory pointer and a local memory pointer to strengthen the copy ability (Wu et al., 2019). 3.4 Evaluation Metrics Following previous works (Madotto et al., 2018; Wu et al., 2019), we evaluate our model and other baselines on two automatic evaluation metrics: BLEU (Papineni et al., 2002) and Entity F1. BLEU calculates n-gram overlaps between the generated response and the gold response. Entity F1 is computed by micro-averaging the precision and recall over KB entities in the entire set of system responses, which evaluates the performance of the model to generate relevant entities to achieve specific tasks from the provided KBs. It is noteworthy that entity F1 indicates the task-completion ability of the model, since KB entities are the key towards the dialog task. 4105 Model Seq2Seq Seq2Seq+Attn Ptr-Unk Mem2Seq BossNet MLM GLMP DDMN (Ours) DDMN+SCST (Ours) BLEU 8.4 9.3 8.3 12"
2020.coling-main.362,2020.acl-main.565,0,0.203808,"paring an output sequence y with the ground truth sequence using the evaluation metric of our choice. The SCST loss is given by T X s Lossrl = −(r(y ) − r(ˆ y )) log(P (yt )) (16) t=1 Thus, minimizing Lossrl is equivalent to maximizing the conditional likelihood of sampled sequence y s if it obtains a higher reward than the baseline yˆ, which improves the reward expectation of our model. 4104 3 3.1 Experimental Setup Datasets We perform experiments on three public multi-turn task-oriented dialog datasets: In-Car Assistant (Eric and Manning, 2017), CamRest (Wen et al., 2016) and Multi-WOZ 2.1 (Qin et al., 2020). In-Car Assistant dataset consists of 3,031 multi-turn dialogs in three distinct domains: schedule (Sch.), weather (Wea.), and navigation (Nav.). This dataset has an average of 2.6 turns, and the KB information is complicated, which has an average of 62.3 triples for every dialog. Following the data processing in Madotto et al. (2018), we obtain 2,425/302/304 dialogs for training/validation/test respectively. CamRest dataset consists of 676 conversations in the restaurant reservation domain with 5.1 turns on average. It has an average of 22.5 KB triples for every dialog. Following the data pr"
2020.coling-main.362,N19-1126,0,0.0267567,"Missing"
2020.coling-main.362,N19-1375,0,0.450382,"ention over the input context (Luong et al., 2015); (2) Ptr-Unk that employs a seq2seq model with a copy mechanism to copy unknown words during generation (Gulcehre et al., 2016); (3) Mem2Seq that employs a memory network based approach with multi-hop attention for attending over dialog history and KB triples (Madotto et al., 2018); (4) BossNet that employs a bag-of-sequences memory network for disentangling language model from KB incorporation in taskoriented dialogs (Raghu et al., 2019); (5) MLM that employs a multi-level memory network for modeling dialog context and KB results separately (Reddy et al., 2019); (6) GLMP that employs a memory network with a global memory pointer and a local memory pointer to strengthen the copy ability (Wu et al., 2019). 3.4 Evaluation Metrics Following previous works (Madotto et al., 2018; Wu et al., 2019), we evaluate our model and other baselines on two automatic evaluation metrics: BLEU (Papineni et al., 2002) and Entity F1. BLEU calculates n-gram overlaps between the generated response and the gold response. Entity F1 is computed by micro-averaging the precision and recall over KB entities in the entire set of system responses, which evaluates the performance o"
2020.coling-main.362,D16-1233,0,0.266298,"rd function, which is computed by comparing an output sequence y with the ground truth sequence using the evaluation metric of our choice. The SCST loss is given by T X s Lossrl = −(r(y ) − r(ˆ y )) log(P (yt )) (16) t=1 Thus, minimizing Lossrl is equivalent to maximizing the conditional likelihood of sampled sequence y s if it obtains a higher reward than the baseline yˆ, which improves the reward expectation of our model. 4104 3 3.1 Experimental Setup Datasets We perform experiments on three public multi-turn task-oriented dialog datasets: In-Car Assistant (Eric and Manning, 2017), CamRest (Wen et al., 2016) and Multi-WOZ 2.1 (Qin et al., 2020). In-Car Assistant dataset consists of 3,031 multi-turn dialogs in three distinct domains: schedule (Sch.), weather (Wea.), and navigation (Nav.). This dataset has an average of 2.6 turns, and the KB information is complicated, which has an average of 62.3 triples for every dialog. Following the data processing in Madotto et al. (2018), we obtain 2,425/302/304 dialogs for training/validation/test respectively. CamRest dataset consists of 676 conversations in the restaurant reservation domain with 5.1 turns on average. It has an average of 22.5 KB triples fo"
2020.coling-main.362,C18-1317,0,0.0248607,"., 2019), which model the dialog history and the KB knowledge as a bag of words in a flat memory. Despite the remarkable progress of previous studies, current memory based models for multi-turn taskoriented dialog systems still suffer from the following limitations. First, existing methods concatenate dialog utterances of current turn and previous turns as a whole, which ignore previous reasoning process performed by the model and are incapable of dynamically tracking long-term dialog states. These methods introduce much noise since previous utterances as the context is lengthy and redundant (Zhang et al., 2018). Taking the dialog in Table 1 as an example, when answering the user question in 6-th turn, it is difficult for the model to infer that the name of the restaurant is “cocum” from a long concatenated dialog context. Therefore, previous models struggle to work well in the situations that require many rounds of interactions to complete a specific task. Second, previous studies tend to confound dialog history with KB knowledge, and store them into a flat memory (Sukhbaatar et al., 2015; Eric and Manning, 2017; Madotto * Corresponding authors. This work was conducted when Jian Wang was interning a"
2020.coling-main.362,W17-5505,0,0.0184972,"ormation with a memory pointer at each turn. Experimental results on three benchmark datasets demonstrate that DDMN significantly outperforms the strong baselines in terms of both automatic evaluation and human evaluation. Our code is available at https://github.com/siat-nlp/DDMN. 1 Introduction Task-oriented dialog systems are designed to help users achieve specific goals with natural language, such as weather inquiry or restaurant reservation. Compared with traditional pipeline methods (Williams and Young, 2007; Young et al., 2013), end-to-end approaches recently have gained much attention (Zhao et al., 2017; Eric and Manning, 2017; Madotto et al., 2018), since they free the task-oriented dialog systems from the manually designed pipeline modules and can be automatically scaled up to new domains. Recently, sequence-to-sequence (Seq2Seq) models have dominated the study of end-to-end taskoriented dialog systems (Bordes et al., 2017). Different from typical Seq2Seq models for open-domain dialog systems, the successful conversations for task-oriented dialog systems heavily rely on both dialog history and domain-specific knowledge base (KB). To effectively incorporate KB information and perform knowle"
2020.emnlp-main.242,W19-4828,0,0.0255659,"ll in prior works. First, existing compression methods learn one-to-one layer mapping, where each student layer is guided by only one specific teacher layer. For example, BERT-PKD uses the 2, 4, 6, 8, 10 teacher layers to guide the 1 to 5 student layers, respectively. How3009 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 3009–3018, c November 16–20, 2020. 2020 Association for Computational Linguistics ever, these one-to-one layer mapping strategies are assigned based on empirical observations without theoretical guidance. Second, as revealed in (Clark et al., 2019), different BERT layers could learn different levels of linguistic knowledge. The oneto-one layer mapping strategy cannot learn an optimal, unified compressed model for different NLP tasks. In addition, most previous works do not consider the importance of each teacher layer and use the same layer weights among various tasks, which create a substantial barrier for generalizing the compressed model to different NLP tasks. Therefore, an adaptive compression model should be designed to transfer knowledge from all teacher layers dynamically and effectively for different NLP tasks. To address the a"
2020.emnlp-main.242,D19-1441,0,0.294073,"Missing"
2020.emnlp-main.242,P18-1031,0,0.0231371,"ave proven to be effective in many NLP tasks (Mikolov et al., 2013; Pennington et al., 2014; Joulin et al., 2016). Early efforts mainly focus on learning good word embeddings, such as word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014). Although these pre-trained embeddings can capture semantic meanings of words, they are context-free and fail to capture higher-level concepts in context, such as syntactic structures and polysemous disambiguation. Subsequently, researchers have shifted attention to contextual word embeddings learning, such as ELMo (Peters et al., 2018), ULMFit (Howard and Ruder, 2018), GPT (Radford et al., 2018), BERT (Devlin et al., 2018), ENRIE (Zhang et al., 2019), XL-Net (Yang et al., 2019), RoBERTa (Liu et al., 2019). For example, Devlin et al. (2018) released the BERT-base of 110 million parameters and BERT-large of 330 million parameters, which achieved significantly better results than previous methods on GLUE tasks. However, along with high-performance, the pretrained language models (e.g., BERT) usually have a large number of parameters, which require a high cost of computation and memory in inference. Recently, many attempts have been made to reduce the computat"
2020.emnlp-main.242,2020.acl-main.195,0,0.0481141,"idance of a large and complicated teacher network. Mukherjee and Awadallah (2019) distilled BERT into an LSTM network via both hard and soft distilling methods. Sun et al. (2019) proposed the BERT-PKD model to transfer the knowledge from both the final layer and the intermediate layers of the teacher network. Jiao et al. (2019) proposed the TinyBERT model, which performed the Transformer distillation at both pre-training and fine-tuning processes. Xu et al. (2020) proposed the BERT-of-Theseus model to learn a compact student network by replacing the teacher layers with 3010 their substitutes. Sun et al. (2020) introduced the MobileBERT model, which has the same number of layers with the teacher network, but was much narrower via adopting bottleneck structures. Wang et al. (2020) distilled the self-attention module of the last Transformer layer of the teacher network. However, the aforementioned BERT compression approaches struggle to find an optimal layer mapping between the teacher and student networks. Each student layer merely learns from a single teacher layer, which may lose rich linguistic knowledge contained in the teacher network. Different from previous methods, we propose a many-tomany la"
2020.emnlp-main.242,2021.ccl-1.108,0,0.229208,"Missing"
2020.emnlp-main.242,D14-1162,0,0.100986,"imal many-to-many layer mapping based on a solution to the well-known transportation problem. (3) We propose a cost attention mechanism to learn the layer weights used in EMD automatically, which can further improve the model’s performance and accelerate convergence time. (4) Extensive experiments on GLUE tasks show that BERT-EMD achieves better performance than the state-of-the-art BERT distillation methods. 2 Related Work Language models pre-trained on large-scale corpora can learn universal language representations, which have proven to be effective in many NLP tasks (Mikolov et al., 2013; Pennington et al., 2014; Joulin et al., 2016). Early efforts mainly focus on learning good word embeddings, such as word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014). Although these pre-trained embeddings can capture semantic meanings of words, they are context-free and fail to capture higher-level concepts in context, such as syntactic structures and polysemous disambiguation. Subsequently, researchers have shifted attention to contextual word embeddings learning, such as ELMo (Peters et al., 2018), ULMFit (Howard and Ruder, 2018), GPT (Radford et al., 2018), BERT (Devlin et al., 2018), ENRIE (Zha"
2020.emnlp-main.242,N18-1202,0,0.0464987,"guage representations, which have proven to be effective in many NLP tasks (Mikolov et al., 2013; Pennington et al., 2014; Joulin et al., 2016). Early efforts mainly focus on learning good word embeddings, such as word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014). Although these pre-trained embeddings can capture semantic meanings of words, they are context-free and fail to capture higher-level concepts in context, such as syntactic structures and polysemous disambiguation. Subsequently, researchers have shifted attention to contextual word embeddings learning, such as ELMo (Peters et al., 2018), ULMFit (Howard and Ruder, 2018), GPT (Radford et al., 2018), BERT (Devlin et al., 2018), ENRIE (Zhang et al., 2019), XL-Net (Yang et al., 2019), RoBERTa (Liu et al., 2019). For example, Devlin et al. (2018) released the BERT-base of 110 million parameters and BERT-large of 330 million parameters, which achieved significantly better results than previous methods on GLUE tasks. However, along with high-performance, the pretrained language models (e.g., BERT) usually have a large number of parameters, which require a high cost of computation and memory in inference. Recently, many attempts have"
2020.emnlp-main.242,W18-5446,0,0.0585905,"Missing"
2020.emnlp-main.242,2020.emnlp-main.496,0,0.0573353,"Missing"
2020.emnlp-main.242,2020.emnlp-main.633,0,0.264819,"distillation to compress the BERT model. Knowledge distillation using the teacher-student strategy learns a lightweight student network under the guidance of a large and complicated teacher network. Mukherjee and Awadallah (2019) distilled BERT into an LSTM network via both hard and soft distilling methods. Sun et al. (2019) proposed the BERT-PKD model to transfer the knowledge from both the final layer and the intermediate layers of the teacher network. Jiao et al. (2019) proposed the TinyBERT model, which performed the Transformer distillation at both pre-training and fine-tuning processes. Xu et al. (2020) proposed the BERT-of-Theseus model to learn a compact student network by replacing the teacher layers with 3010 their substitutes. Sun et al. (2020) introduced the MobileBERT model, which has the same number of layers with the teacher network, but was much narrower via adopting bottleneck structures. Wang et al. (2020) distilled the self-attention module of the last Transformer layer of the teacher network. However, the aforementioned BERT compression approaches struggle to find an optimal layer mapping between the teacher and student networks. Each student layer merely learns from a single t"
2020.emnlp-main.242,P19-1139,0,0.0178742,"014; Joulin et al., 2016). Early efforts mainly focus on learning good word embeddings, such as word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014). Although these pre-trained embeddings can capture semantic meanings of words, they are context-free and fail to capture higher-level concepts in context, such as syntactic structures and polysemous disambiguation. Subsequently, researchers have shifted attention to contextual word embeddings learning, such as ELMo (Peters et al., 2018), ULMFit (Howard and Ruder, 2018), GPT (Radford et al., 2018), BERT (Devlin et al., 2018), ENRIE (Zhang et al., 2019), XL-Net (Yang et al., 2019), RoBERTa (Liu et al., 2019). For example, Devlin et al. (2018) released the BERT-base of 110 million parameters and BERT-large of 330 million parameters, which achieved significantly better results than previous methods on GLUE tasks. However, along with high-performance, the pretrained language models (e.g., BERT) usually have a large number of parameters, which require a high cost of computation and memory in inference. Recently, many attempts have been made to reduce the computation overhead and model storage of pre-trained language models without performance sa"
2020.emnlp-main.281,P83-1025,0,0.168344,"uence-to-sequence (seq2seq) models (Bordes et al., 2017; Eric and Manning, 2017; Eric et al., 2017), which have taken the state-of-the-art of TDSs to a new level. These methods map dialogue context to output responses directly without explicitly providing handcrafted features and NLU/DST/DP labels, thus reduce human effort and are easily adapted to new domains. Despite the effectiveness of previous studies, there are several technical challenges in building a TDS that is capable of retrieving accurate entries from the knowledge base (KB) and generating human-like responses. (1) Previous work (Carbonell, 1983) shows that users of TDSs tend to use succinct language which often omits entities or concepts made in previous utterances. However, seq2seq models often ignore how the conversation evolves as information progresses (Raghu et al., 2019) and thus result in generating incoherent and ungrammatical responses that are dominated by words appearing with high frequency in 3498 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 3498–3507, c November 16–20, 2020. 2020 Association for Computational Linguistics the training data. (2) Seq2seq models suffer from ef"
2020.emnlp-main.281,P19-1258,0,0.0371921,"y of the neural network models has gained increasing attention. (Eric et al., 2017) proposed a copy augmented seq2seq model by copying relevant information directly from the KB information. Mem2Seq (Madotto et al., 2018) and GLMP (Wu et al., 2019) further augmented memory-based 3499 methods by incorporating copy mechanism (Gulcehre et al., 2016) to enable copying words from past dialog utterances or from KB when generating responses. Recently, separating memories for modeling dialog context and KB results are explored to improve the performance of TDSs (Raghu et al., 2019; Reddy et al., 2019; Chen et al., 2019). BossNet (Raghu et al., 2019) implicitly disentangled the language model from knowledge incorporation and thus enhanced the ability to copy unknown KB entries. Multi-level memory model (Reddy et al., 2019) represented the KB results using a multi-level memory instead of the form of triples. WMM2Seq (Chen et al., 2019) further employed a working memory to interact with two separated memories. Nevertheless, existing methods either achieve a good language model for the response generation or effective progress towards the KB modeling, but not both. 2.2 Student-teacher Learning Paradigm In parall"
2020.emnlp-main.281,W17-5506,0,0.258814,"erstanding (NLU), dialogue state tracking (DST), and dialogue policy (DP). A limitation of such pipelined design is that errors made in upper stream modules may propagate to downstream components, making it hard to identify and track the source of errors. In addition, these methods usually require a large number of handcrafted features and labels, which may restrict the expressive power and learnability of the models. To ameliorate the limitations with the conventional pipeline TDSs, great efforts have been made in designing deep neural network-based end-to-end solutions (Bordes et al., 2017; Eric et al., 2017; Madotto et al., 2018). Recent advances are overwhelmingly contributed by sequence-to-sequence (seq2seq) models (Bordes et al., 2017; Eric and Manning, 2017; Eric et al., 2017), which have taken the state-of-the-art of TDSs to a new level. These methods map dialogue context to output responses directly without explicitly providing handcrafted features and NLU/DST/DP labels, thus reduce human effort and are easily adapted to new domains. Despite the effectiveness of previous studies, there are several technical challenges in building a TDS that is capable of retrieving accurate entries from th"
2020.emnlp-main.281,E17-2075,0,0.272801,"ules may propagate to downstream components, making it hard to identify and track the source of errors. In addition, these methods usually require a large number of handcrafted features and labels, which may restrict the expressive power and learnability of the models. To ameliorate the limitations with the conventional pipeline TDSs, great efforts have been made in designing deep neural network-based end-to-end solutions (Bordes et al., 2017; Eric et al., 2017; Madotto et al., 2018). Recent advances are overwhelmingly contributed by sequence-to-sequence (seq2seq) models (Bordes et al., 2017; Eric and Manning, 2017; Eric et al., 2017), which have taken the state-of-the-art of TDSs to a new level. These methods map dialogue context to output responses directly without explicitly providing handcrafted features and NLU/DST/DP labels, thus reduce human effort and are easily adapted to new domains. Despite the effectiveness of previous studies, there are several technical challenges in building a TDS that is capable of retrieving accurate entries from the knowledge base (KB) and generating human-like responses. (1) Previous work (Carbonell, 1983) shows that users of TDSs tend to use succinct language which o"
2020.emnlp-main.281,P16-1014,0,0.138343,"t al., 2017; Madotto et al., 2018). However, as revealed by previous studies (Eric et al., 2017; Madotto et al., 2018), the performance of the seq2seq model deteriorates quickly with the increase of the length of the generated sequence. Therefore, how to improve the stability of the neural network models has gained increasing attention. (Eric et al., 2017) proposed a copy augmented seq2seq model by copying relevant information directly from the KB information. Mem2Seq (Madotto et al., 2018) and GLMP (Wu et al., 2019) further augmented memory-based 3499 methods by incorporating copy mechanism (Gulcehre et al., 2016) to enable copying words from past dialog utterances or from KB when generating responses. Recently, separating memories for modeling dialog context and KB results are explored to improve the performance of TDSs (Raghu et al., 2019; Reddy et al., 2019; Chen et al., 2019). BossNet (Raghu et al., 2019) implicitly disentangled the language model from knowledge incorporation and thus enhanced the ability to copy unknown KB entries. Multi-level memory model (Reddy et al., 2019) represented the KB results using a multi-level memory instead of the form of triples. WMM2Seq (Chen et al., 2019) further"
2020.emnlp-main.281,P84-1044,0,0.618577,"Missing"
2020.emnlp-main.281,P18-1133,0,0.0115033,"lete speciﬁc tasks with natural language. Conventional TDSs usually require a large number of handcrafted features, which may restrict the expressive power and learnability of the models (Williams and Young, 2007; Young et al., 2013). Inspired by the success of the sequence-tosequence (seq2seq) models in text generation, there are several studies that build TDSs with the seq2seq model in an end-to-end trainable way. These methods have shown promising results recently since they have a great ability to learn the latent representations of dialogue context and are easily adapted to a new domain (Lei et al., 2018; Eric et al., 2017; Madotto et al., 2018). However, as revealed by previous studies (Eric et al., 2017; Madotto et al., 2018), the performance of the seq2seq model deteriorates quickly with the increase of the length of the generated sequence. Therefore, how to improve the stability of the neural network models has gained increasing attention. (Eric et al., 2017) proposed a copy augmented seq2seq model by copying relevant information directly from the KB information. Mem2Seq (Madotto et al., 2018) and GLMP (Wu et al., 2019) further augmented memory-based 3499 methods by incorporating copy mec"
2020.emnlp-main.281,D16-1233,0,0.221518,"Missing"
2020.emnlp-main.281,D15-1166,0,0.266689,"ectively), which can be viewed as experts towards the goals. Then, we employ GAN to learn the student network, where the generator is the student network to produce dialogue responses, and two discriminators distinguish the learned output responses from student and teacher networks. Next, we will introduce the three networks and the GAN-based student-teacher learning paradigm in detail. 3.1 Student Network The student network a task-oriented dialogue system, which is responsible for both inquiring KB and generating human-like responses. In this study, the sequence-to-sequence (seq2seq) model (Luong et al., 2015) is used as the backbone to implement the student network. The seq2seq model additionally consists of a dialogue memory module and a KB memory module to store the information from the dialogue context and the retrieved KB entities, respectively. Encoder Each input token in the dialogue context is converted to a ﬁxed-length vector via an embedding layer. The input embedding sequence then goes into a layer of the bidirectional gated recurrent unit (BiGRU) (Chung et al., 2014) to learn the contextualized representation of the dialogue context, which is then passed into the dialogue memory. Dialog"
2020.emnlp-main.281,P18-1136,0,0.337746,"ialogue state tracking (DST), and dialogue policy (DP). A limitation of such pipelined design is that errors made in upper stream modules may propagate to downstream components, making it hard to identify and track the source of errors. In addition, these methods usually require a large number of handcrafted features and labels, which may restrict the expressive power and learnability of the models. To ameliorate the limitations with the conventional pipeline TDSs, great efforts have been made in designing deep neural network-based end-to-end solutions (Bordes et al., 2017; Eric et al., 2017; Madotto et al., 2018). Recent advances are overwhelmingly contributed by sequence-to-sequence (seq2seq) models (Bordes et al., 2017; Eric and Manning, 2017; Eric et al., 2017), which have taken the state-of-the-art of TDSs to a new level. These methods map dialogue context to output responses directly without explicitly providing handcrafted features and NLU/DST/DP labels, thus reduce human effort and are easily adapted to new domains. Despite the effectiveness of previous studies, there are several technical challenges in building a TDS that is capable of retrieving accurate entries from the knowledge base (KB) a"
2020.emnlp-main.281,P02-1040,0,0.107444,"14.1 14.79 17.35 16.80 17.23 17.05 Ent. F1 10.3 19.9 22.7 33.4 35.9 53.7 59.97 55.38 51.84 51.49 55.88 Sch.F1 9.7 23.4 26.9 49.3 50.2 54.5 69.56 63.50 60.71 61.18 67.53 Wea.F1 14.1 25.6 26.7 32.8 34.5 52.2 62.58 64.09 62.67 63.78 63.71 Nav.F1 7.0 10.8 14.9 20.0 21.6 55.6 52.98 45.90 40.76 39.14 44.86 Table 2: Automatic evaluation results on In-Car Assistant dataset. local memory pointer network (GLMP) (Wu et al., 2019). Automatic Evaluation Metrics Following previous works (Madotto et al., 2018; Wu et al., 2019), we evaluate TTOS and compared methods on two automatic evaluation metrics: BLEU (Papineni et al., 2002) and entity F1 (Madotto et al., 2018) scores. BLEU calculates n-gram overlaps between the generated response and the gold response, which could gauge the model’s ability to accurately generate the dialogue patterns seen in our data. BLEU shows a comparatively strong correlation with the human assessment on taskoriented systems (Sharma et al., 2017). Entity F1 is computed by micro-averaging the precision and recall over KB entities in the entire set of system responses, which evaluates the ability of the TDSs to generate relevant entities to accomplish speciﬁc tasks by inquiring the provided KB"
2020.emnlp-main.281,D19-1013,0,0.224037,"Missing"
2020.emnlp-main.281,N19-1126,0,0.0306866,"Missing"
2020.emnlp-main.281,N19-1375,0,0.743962,"the 2020 Conference on Empirical Methods in Natural Language Processing, pages 3498–3507, c November 16–20, 2020. 2020 Association for Computational Linguistics the training data. (2) Seq2seq models suffer from effectively reasoning over and incorporating KB information (Madotto et al., 2018). It is difﬁcult to encode and decode the knowledge from a large and dynamic KB, making the response generation unstable. In addition, typically, a shared memory is used for both dialogue context and KB triples, making the TDSs struggle to reason over the two forms of data. Although some previous methods (Reddy et al., 2019) leverage separate memories for modeling dialogue context and KB facts, they either focus on capturing the dialogue patterns or retrieving accurate KB entities, but not both. One possible solution to the aforementioned problems is to explicitly encourage the seq2seq model to learn dialogue patterns and model the exterior KB knowledge retrieval with separate guidance for each. In this study, we propose a “Two-Teacher OneStudent” learning framework (TTOS) for building a high-quality TDS (student), where a student network is encouraged to integrate the knowledge from two expert teacher networks."
2020.emnlp-main.289,C10-1021,0,0.0393833,"sed model incrementally processes the input sequences from left to right, always with linear time complexity. • Performance evaluation shows the superiority and robustness of the proposed model compared to a number of competitive baselines. 2 2.1 Methodology A Tagging Problem We define X = (x1 , x2 , . . . , xn ) as an ordered clause sequence for an emotion text. There are several emotions and at least one cause corresponds to these emotions. The goal is to output all potential pairs where exist emotion causality. Due to the difficulty describing the emotion/cause at the word or phrase level (Chen et al., 2010), in this paper, the “emotion” and “cause” are refer to “emotion clause” and “cause clause” , respectively. This research investigates such a problem by sequentially tagging each clause x ∈ X with twotuples label y = (b, d) ∈ Y , where b ∈ {C, O} and d ∈ {−(n − 1), . . . , −1, 0, 1, . . . , n − 1, ⊥}. Tag “C” represents the “Cause” tag which means the current clause is a cause clause, while tag “O” represent the “Other” tag, indicating the current clause is irrelevant to the final result. Moreover, d encodes the distance between the cause and the triggered emotion it relates to, e.g., “-1” den"
2020.emnlp-main.289,N19-1423,0,0.00521283,"contain the information of causes and the triggered emotions associated with these causes, and we realize it by coding the distance between linked components into the tags. Accordingly, an end-to-end model based on this tagging scheme is presented to process the input sequences from left to right, consequently, reducing the number of 3568 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 3568–3573, c November 16–20, 2020. 2020 Association for Computational Linguistics potential pairs needed to be parsed and leading to a speed up. Specifically, BERT (Devlin et al., 2019) is trained with the objective of masked language modeling and next-sentence prediction task, therefore, we base our model on the BERT to generate powerful, general-purpose linguistic representation for each clause. Then LSTMs (Hochreiter and Schmidhuber, 1997) will be applied to capture long-range dependencies among different clauses. To summarize, our contribution includes: • We frame the ECPE task as a sequence labeling problem and propose an end-to-end model based on a novel tagging scheme with multiple labels, thereby the emotion-cause structure can be extracted simultaneously. • The prop"
2020.emnlp-main.289,P17-1002,0,0.0132812,"pagation may occur from the first procedure to the second. Recent studies (Song et al., 2020; Tang et al., 2020) have focused on solving this task using multitask learning framework (Caruana, 1993) with welldesigned attention mechanism (Bahdanau et al., 2015), but they extract emotion-cause pairs by calculating a pair matrix, which is based on the likelihood of Cartesian product among all clauses in texts, thus leading to the computational cost is expensive, that is, the time complexity is O(n2 ). In this paper, we define the joint emotion-cause pair extraction as a sequence labeling problem (Eger et al., 2017; Zheng et al., 2017), so that the emotion-cause structure can be integrated into an unified framework, including representation learning, pair extraction, and causality reasoning. The challenge is to also include emotion causality into the tagging scheme, i.e., the traditional BIO tagging is not suitable for this task. Targeting this problem, we design a novel tagging scheme with multiple labels which contain the information of causes and the triggered emotions associated with these causes, and we realize it by coding the distance between linked components into the tags. Accordingly, an end-t"
2020.emnlp-main.289,D19-1563,1,0.824539,"ause pair extraction (ECPE) aims to extract all potential pairs of emotions and the corresponding causes from unannotated emotion texts, such as (c3 , c1 ) and (c3 , c2 ) in: Ex.1 A policeman visited the old man with the lost money, (c1 ) |and told him that the thief was caught. (c2 ) |The old man was very happy, (c3 ) |and deposited the money in the bank. (c4 ) This task for pair extraction closely relates to the traditional emotion cause extraction task, which aims at identifying the causes for a given emotion expression. Many works (Gui et al., 2017; Li et al., 2018, 2019; Xu et al., 2019; Fan et al., 2019; Xia et al., 2019; Ding et al., 2019) related to emotion cause extraction have been published recently, and all of them are evaluated with the dataset released by Gui et al. (2016). However, it suffers ∗ † Equal Contributions. Corresponding author. that emotions must be annotated before extracting the causes, which is labor intensive and limits the applications in real-world scenarios. Towards this issue, Xia and Ding (2019) presents a new task, namely emotion-cause pair extraction, to extract emotions and the corresponding causes together. In comparison, it is a more challenging task due to"
2020.emnlp-main.289,D17-1167,1,0.863186,"Missing"
2020.emnlp-main.289,D16-1170,1,0.887072,"A policeman visited the old man with the lost money, (c1 ) |and told him that the thief was caught. (c2 ) |The old man was very happy, (c3 ) |and deposited the money in the bank. (c4 ) This task for pair extraction closely relates to the traditional emotion cause extraction task, which aims at identifying the causes for a given emotion expression. Many works (Gui et al., 2017; Li et al., 2018, 2019; Xu et al., 2019; Fan et al., 2019; Xia et al., 2019; Ding et al., 2019) related to emotion cause extraction have been published recently, and all of them are evaluated with the dataset released by Gui et al. (2016). However, it suffers ∗ † Equal Contributions. Corresponding author. that emotions must be annotated before extracting the causes, which is labor intensive and limits the applications in real-world scenarios. Towards this issue, Xia and Ding (2019) presents a new task, namely emotion-cause pair extraction, to extract emotions and the corresponding causes together. In comparison, it is a more challenging task due to the inherent ambiguity and subtlety of emotions, especially when there is no annotation information provided before extraction. Following this task setting, they propose a two-step"
2020.emnlp-main.289,P82-1020,0,0.79872,"Missing"
2020.emnlp-main.289,D18-1506,0,0.122149,"in F 1 measure. 1 Introduction Emotion-cause pair extraction (ECPE) aims to extract all potential pairs of emotions and the corresponding causes from unannotated emotion texts, such as (c3 , c1 ) and (c3 , c2 ) in: Ex.1 A policeman visited the old man with the lost money, (c1 ) |and told him that the thief was caught. (c2 ) |The old man was very happy, (c3 ) |and deposited the money in the bank. (c4 ) This task for pair extraction closely relates to the traditional emotion cause extraction task, which aims at identifying the causes for a given emotion expression. Many works (Gui et al., 2017; Li et al., 2018, 2019; Xu et al., 2019; Fan et al., 2019; Xia et al., 2019; Ding et al., 2019) related to emotion cause extraction have been published recently, and all of them are evaluated with the dataset released by Gui et al. (2016). However, it suffers ∗ † Equal Contributions. Corresponding author. that emotions must be annotated before extracting the causes, which is labor intensive and limits the applications in real-world scenarios. Towards this issue, Xia and Ding (2019) presents a new task, namely emotion-cause pair extraction, to extract emotions and the corresponding causes together. In comparis"
2020.emnlp-main.289,P19-1096,0,0.385216,"nal emotion cause extraction task, which aims at identifying the causes for a given emotion expression. Many works (Gui et al., 2017; Li et al., 2018, 2019; Xu et al., 2019; Fan et al., 2019; Xia et al., 2019; Ding et al., 2019) related to emotion cause extraction have been published recently, and all of them are evaluated with the dataset released by Gui et al. (2016). However, it suffers ∗ † Equal Contributions. Corresponding author. that emotions must be annotated before extracting the causes, which is labor intensive and limits the applications in real-world scenarios. Towards this issue, Xia and Ding (2019) presents a new task, namely emotion-cause pair extraction, to extract emotions and the corresponding causes together. In comparison, it is a more challenging task due to the inherent ambiguity and subtlety of emotions, especially when there is no annotation information provided before extraction. Following this task setting, they propose a two-step approach to solve this task. However, limited by the inherent drawback of pipelined framework, error propagation may occur from the first procedure to the second. Recent studies (Song et al., 2020; Tang et al., 2020) have focused on solving this ta"
2020.emnlp-main.289,P17-1113,0,0.021821,"from the first procedure to the second. Recent studies (Song et al., 2020; Tang et al., 2020) have focused on solving this task using multitask learning framework (Caruana, 1993) with welldesigned attention mechanism (Bahdanau et al., 2015), but they extract emotion-cause pairs by calculating a pair matrix, which is based on the likelihood of Cartesian product among all clauses in texts, thus leading to the computational cost is expensive, that is, the time complexity is O(n2 ). In this paper, we define the joint emotion-cause pair extraction as a sequence labeling problem (Eger et al., 2017; Zheng et al., 2017), so that the emotion-cause structure can be integrated into an unified framework, including representation learning, pair extraction, and causality reasoning. The challenge is to also include emotion causality into the tagging scheme, i.e., the traditional BIO tagging is not suitable for this task. Targeting this problem, we design a novel tagging scheme with multiple labels which contain the information of causes and the triggered emotions associated with these causes, and we realize it by coding the distance between linked components into the tags. Accordingly, an end-to-end model based on"
2020.lrec-1.619,N19-1423,0,0.0420013,"Missing"
2020.lrec-1.619,C18-1156,0,0.0111958,"sarcasm is directional and aggressive. The target of sarcasm should be person, organization, country, etc. In the previous example, the target is “五个国家” (”the five countries”. Besides, we need to take sentence as a whole when judge it is or not. For example, “这么大项目才投资5000万美 元，够买一个杯子不？” (Only $50 million is invested in such a large project. Is it enough to buy a cup?) Although the last part is ambiguous, the first part is a straight negative expression. So it is a non-sarcastic sentence. Accurate detection of sarcasm requires a wealth of information, including context and background knowledge (Hazarika et al., 2018). For instance, “这个业务水平！牛 逼！” (Very professional! Awsome!) This sentence is a plain positive expression if we do not take its context into consideration. However, when given the context, which is “保胎药开成打胎药，妈妈胎儿不保，”医生回复‘笔 误’” (The fetal-protection medicine was prescribed as an abortion medicine, which leads to a mother losing her fetus. The doctor responded with a ”clerical error”), the above sentence is definitely sarcastic now. Most existing Chinese sarcasm dataset is based on Weibo data, which is a relatively free medium without contextual information and related background knowledge. To sol"
2020.lrec-1.619,P15-2124,0,0.0172346,"media and forums (Maynard and Greenwood, 2014). When users express their emotions through sarcasm, they tend to express the opposite of the emotional tendency that they want to express which always puzzle the sentiment analysis algorithms (Pang et al., 2008). Thus, the study on sarcasm detection and processing is important to improve the performance of text emotion analysis, question answering system and conversation robot. Currently, most existing sarcasm annotation corpus in on English text but few on Chinese, which is a barrier to sracasm detection research on Chinese (Walker et al., 2012; Joshi et al., 2015; Oraby et al., 2016; Khodak et al., 2018). In this paper, we present the work on designing and constructing a large high-quality Chinese sarcasm dataset. The raw text are collected from the user comments text from a news sites. We construct a balanced annotated dataset, which contains 2,486 sarcastic texts and 2,486 nonsarcastic texts, and an unbalanced dataset which contains 2,486 sarcastic texts and 89,296 non-sarcastic texts. Based on the constructed dataset, the performance of some existing sarcasm classification methods are evaluated. The rest of this paper is summarized as follows. Sect"
2020.lrec-1.619,L18-1102,0,0.0159233,"2014). When users express their emotions through sarcasm, they tend to express the opposite of the emotional tendency that they want to express which always puzzle the sentiment analysis algorithms (Pang et al., 2008). Thus, the study on sarcasm detection and processing is important to improve the performance of text emotion analysis, question answering system and conversation robot. Currently, most existing sarcasm annotation corpus in on English text but few on Chinese, which is a barrier to sracasm detection research on Chinese (Walker et al., 2012; Joshi et al., 2015; Oraby et al., 2016; Khodak et al., 2018). In this paper, we present the work on designing and constructing a large high-quality Chinese sarcasm dataset. The raw text are collected from the user comments text from a news sites. We construct a balanced annotated dataset, which contains 2,486 sarcastic texts and 2,486 nonsarcastic texts, and an unbalanced dataset which contains 2,486 sarcastic texts and 89,296 non-sarcastic texts. Based on the constructed dataset, the performance of some existing sarcasm classification methods are evaluated. The rest of this paper is summarized as follows. Section 2. briefly reviews the existing Chines"
2020.lrec-1.619,D14-1181,0,0.00325745,"arcastic user comment texts are randomly sampled from news A. In this way, the topic distribution of sarcastic user comment and non-sarcastic user comment is consistent. 5. Figure 1: Length distribution of sarcastic text and nonsarcastic text. 6. In this section, several sarcasm detection method based on typical text classification models are evaluated, in order to provide comparable baseline results for future research. The evaluation metrics used to measure the performance of models are accuracy and F1 score. As for the baseline models, they are chosen as follows: • textCNN: We use textCNN (Kim, 2014) as the baseline model to learn the feature representations from comment text, a softmax layer is used to generate final classification result. Corpus Statistics In order to have a more intuitive understanding of our developed sarcasm dataset, we do some related data statistics work, and also validate the classification effect of some commonly used text classification models on our balanced dataset. Table 4 shows the comparison of our dataset and exsiting sarcasm corpora including data source, data scale and obtaining method. As one can see, the number of sarcastic data contained in our datase"
2020.lrec-1.619,O16-1027,0,0.0137914,"Section 7. concludes. Corresponding Author: xuruifeng@hit.edu.cn 2. Related Work Tang and Chen (2014) collected sarcastic texts from Weibo by using the emoji as clue and using linguistic features and sentiment determination for identifying sarcastic text. The the language structure and sarcastic elements were analyzed and annotated. Liu et al. (2014) constructed three unbalanced dataset based on sarcastic data from Sina Weibo, Tencent Weibo and Netease Forum, respectively. They also proposed a multi-strategy integrated learning method to solve the data imbalance problem in sarcasm detection. Lin and Hsieh (2016) constructed a dataset based on the assumption that positive sentimental comments on negative issues is highly likely to has sarcasm. Through the Gossiping section of PTT, they semi-automatically constructed a dataset consists of 17,256 sarcastic comments and 9,373 non-sarcastic comments. Based on the corpus data, the performances of of the sarcasm detection methods based on Support Vector Machine with na¨ıve features and Convolutional Neural Network models were evaluated. Sun et al. (2016) constructed a sarcastic corpora with 1,030 documents from Sina Weibo through manually annotation, plus 1"
2020.lrec-1.619,maynard-greenwood-2014-cares,0,0.0255637,"ifier. Using the dataset as the benchmark, some sarcasm classification methods are evaluated. Keywords: sarcasm dataset, corpus design, Chinese 1. Introduction Sarcasm is a typical multi-layered semi-conscious language phenomenon. Essentially, there are a dual purpose expression. That is, the meaning of what a speaker wants to express is very different from the superficial meaning of what he/she says, and even in most cases the two meanings are completely opposite. Because of sarcasm’s unique language effect, it is widely used by users in internet applications such as social media and forums (Maynard and Greenwood, 2014). When users express their emotions through sarcasm, they tend to express the opposite of the emotional tendency that they want to express which always puzzle the sentiment analysis algorithms (Pang et al., 2008). Thus, the study on sarcasm detection and processing is important to improve the performance of text emotion analysis, question answering system and conversation robot. Currently, most existing sarcasm annotation corpus in on English text but few on Chinese, which is a barrier to sracasm detection research on Chinese (Walker et al., 2012; Joshi et al., 2015; Oraby et al., 2016; Khodak"
2020.lrec-1.619,W16-3604,0,0.0177474,"ynard and Greenwood, 2014). When users express their emotions through sarcasm, they tend to express the opposite of the emotional tendency that they want to express which always puzzle the sentiment analysis algorithms (Pang et al., 2008). Thus, the study on sarcasm detection and processing is important to improve the performance of text emotion analysis, question answering system and conversation robot. Currently, most existing sarcasm annotation corpus in on English text but few on Chinese, which is a barrier to sracasm detection research on Chinese (Walker et al., 2012; Joshi et al., 2015; Oraby et al., 2016; Khodak et al., 2018). In this paper, we present the work on designing and constructing a large high-quality Chinese sarcasm dataset. The raw text are collected from the user comments text from a news sites. We construct a balanced annotated dataset, which contains 2,486 sarcastic texts and 2,486 nonsarcastic texts, and an unbalanced dataset which contains 2,486 sarcastic texts and 89,296 non-sarcastic texts. Based on the constructed dataset, the performance of some existing sarcasm classification methods are evaluated. The rest of this paper is summarized as follows. Section 2. briefly revie"
2020.lrec-1.619,C14-1120,0,0.0160511,"hods are evaluated. The rest of this paper is summarized as follows. Section 2. briefly reviews the existing Chinese sarcasm dataset and related work. The definition of sarcasm and the design issues of the sarcasm corpus are presented in Section 3.. Section 4. presents the workflow and detailed our annotation process. The statistics of constructed corpus is presented in Section 5.. In Section 6., we simply evaluate some sarcasm classification models by using the constructed dataset as the benchmark data. Finally, Section 7. concludes. Corresponding Author: xuruifeng@hit.edu.cn 2. Related Work Tang and Chen (2014) collected sarcastic texts from Weibo by using the emoji as clue and using linguistic features and sentiment determination for identifying sarcastic text. The the language structure and sarcastic elements were analyzed and annotated. Liu et al. (2014) constructed three unbalanced dataset based on sarcastic data from Sina Weibo, Tencent Weibo and Netease Forum, respectively. They also proposed a multi-strategy integrated learning method to solve the data imbalance problem in sarcasm detection. Lin and Hsieh (2016) constructed a dataset based on the assumption that positive sentimental comments"
2020.lrec-1.619,walker-etal-2012-corpus,0,0.0355248,"tions such as social media and forums (Maynard and Greenwood, 2014). When users express their emotions through sarcasm, they tend to express the opposite of the emotional tendency that they want to express which always puzzle the sentiment analysis algorithms (Pang et al., 2008). Thus, the study on sarcasm detection and processing is important to improve the performance of text emotion analysis, question answering system and conversation robot. Currently, most existing sarcasm annotation corpus in on English text but few on Chinese, which is a barrier to sracasm detection research on Chinese (Walker et al., 2012; Joshi et al., 2015; Oraby et al., 2016; Khodak et al., 2018). In this paper, we present the work on designing and constructing a large high-quality Chinese sarcasm dataset. The raw text are collected from the user comments text from a news sites. We construct a balanced annotated dataset, which contains 2,486 sarcastic texts and 2,486 nonsarcastic texts, and an unbalanced dataset which contains 2,486 sarcastic texts and 89,296 non-sarcastic texts. Based on the constructed dataset, the performance of some existing sarcasm classification methods are evaluated. The rest of this paper is summari"
2020.lrec-1.619,P14-2084,0,0.0231744,"Collection To build a Chinese sarcasm data set, the first step is to choosing the proper raw text. Considering the openness of the data and the cost of labeling, etc., the candidate raw text need to meet following requirements: 1. The data must be open and easy to collect. Since the collected data is only used for academic research which is open and shared, the data of the collected objects must be open and can be legally reused. cial linguistic phenomenon, usually with some aggressiveness and occurs in a specific context, those factors make it not appear in high proportions in general text (Wallace et al., 2014). The anonymity of the network and the enthusiasm of discussion on social hot issues leads to frequent conflicts of different opinions, which makes the probability of sarcasm increases on social medias. But in general, the proportion of sarcastic data is normally small which brings much difficulty to sarcasm corpus construction. To save the cost for corpus construction, different collection of text objects are observed and compared. The data sources with relatively high proportion of sarcastic texts are selected for further annotation. To meet the above requirements, the user comments text fro"
2020.lrec-1.620,D17-1047,0,0.0147603,"ment of the Internet, it becomes easier to collect a large scale of public textual data. Identifying the sentiment corresponding to the financial entities such as companies from the financial text is crucial to financial investment and decision making. Thus, sentiment analysis techniques on financial text attracted much research interest in the recent years. Sentiment analysis (SA) is a hot research topic in natural language processing. It has gained increasing popularity due to the its widely applications (Pang et al., 2008). (Kim, 2014; Li et al., 2015; Zhou et al., 2016; Yang et al., 2016; Chen et al., 2017; Li et al., 2015) focused on classifying the given text as positive, negative, neutral at document level and sentence level. However, the accuracy of sentiment classification on multiple opinion aspects/targets level is unsatisfactory. Especially, such kind of fine-grained sentiment analysis is essential to many practical applications. Hence aspect-based sentiment analysis (ABSA) (Pontiki et al., 2014; Pontiki et al., 2016; Poria et al., 2016), target-based sentiment analysis (TBSA) (Tang et al., 2016a; Tang et al., 2016b; Dong et al., 2014; Wang et al., 2017) and targeted aspect-based sentim"
2020.lrec-1.620,N19-1423,0,0.0103063,"Missing"
2020.lrec-1.620,P14-2009,0,0.0231092,"et al., 2015; Zhou et al., 2016; Yang et al., 2016; Chen et al., 2017; Li et al., 2015) focused on classifying the given text as positive, negative, neutral at document level and sentence level. However, the accuracy of sentiment classification on multiple opinion aspects/targets level is unsatisfactory. Especially, such kind of fine-grained sentiment analysis is essential to many practical applications. Hence aspect-based sentiment analysis (ABSA) (Pontiki et al., 2014; Pontiki et al., 2016; Poria et al., 2016), target-based sentiment analysis (TBSA) (Tang et al., 2016a; Tang et al., 2016b; Dong et al., 2014; Wang et al., 2017) and targeted aspect-based sentiment analysis (TABSA) (Liang et al., 2019; Ma et al., 2018) had been proposed to tackle the subtler sentiment in term of different aspects/targets in a sentence. For TBSA, it aims to identify the sentiment expression and determine the polarities of different target entities. Take the following Ex.1, as an example, there are three entities in this paragraph, 乐 融 致 新(LeMall), 乐 视 网(LETV) and 乐 视控股(LeEco). 乐融致新(LeMall) and 乐视网(LETV) appear more than once and their corresponding sentiment polarities are negative, while for 乐 视 控 股(LeEco), the pol"
2020.lrec-1.620,L18-1423,0,0.0501695,"Missing"
2020.lrec-1.620,D14-1181,0,0.00239728,"ion, Chinese Financial Text 1. Introduction With the rapid development of the Internet, it becomes easier to collect a large scale of public textual data. Identifying the sentiment corresponding to the financial entities such as companies from the financial text is crucial to financial investment and decision making. Thus, sentiment analysis techniques on financial text attracted much research interest in the recent years. Sentiment analysis (SA) is a hot research topic in natural language processing. It has gained increasing popularity due to the its widely applications (Pang et al., 2008). (Kim, 2014; Li et al., 2015; Zhou et al., 2016; Yang et al., 2016; Chen et al., 2017; Li et al., 2015) focused on classifying the given text as positive, negative, neutral at document level and sentence level. However, the accuracy of sentiment classification on multiple opinion aspects/targets level is unsatisfactory. Especially, such kind of fine-grained sentiment analysis is essential to many practical applications. Hence aspect-based sentiment analysis (ABSA) (Pontiki et al., 2014; Pontiki et al., 2016; Poria et al., 2016), target-based sentiment analysis (TBSA) (Tang et al., 2016a; Tang et al., 201"
2020.lrec-1.620,P15-1101,0,0.0710848,"Missing"
2020.lrec-1.620,P19-1462,1,0.831829,"used on classifying the given text as positive, negative, neutral at document level and sentence level. However, the accuracy of sentiment classification on multiple opinion aspects/targets level is unsatisfactory. Especially, such kind of fine-grained sentiment analysis is essential to many practical applications. Hence aspect-based sentiment analysis (ABSA) (Pontiki et al., 2014; Pontiki et al., 2016; Poria et al., 2016), target-based sentiment analysis (TBSA) (Tang et al., 2016a; Tang et al., 2016b; Dong et al., 2014; Wang et al., 2017) and targeted aspect-based sentiment analysis (TABSA) (Liang et al., 2019; Ma et al., 2018) had been proposed to tackle the subtler sentiment in term of different aspects/targets in a sentence. For TBSA, it aims to identify the sentiment expression and determine the polarities of different target entities. Take the following Ex.1, as an example, there are three entities in this paragraph, 乐 融 致 新(LeMall), 乐 视 网(LETV) and 乐 视控股(LeEco). 乐融致新(LeMall) and 乐视网(LETV) appear more than once and their corresponding sentiment polarities are negative, while for 乐 视 控 股(LeEco), the polarity is neutral. † ‡ Ex.1 虽然乐 乐 融 致 新 增资获得通过， 但记者从乐 乐 视 网 人事处了解到， 今年至今，无论是乐 乐融 致 新 还是 乐 视 网"
2020.lrec-1.620,S14-2004,0,0.110695,"Missing"
2020.lrec-1.620,S15-2082,0,0.0725946,"Missing"
2020.lrec-1.620,S16-1002,0,0.0565388,"Missing"
2020.lrec-1.620,C16-1146,0,0.0160582,"a benchmark, some state-of-theart TBSA algorithms are evaluated. To sum up, the contributions of this paper are three folds: • We designed a target-based sentiment analysis corpus with clear definition and efficient annotations for TBSA task. • We proposed a detailed annotation guideline and annotation quality control scheme for constructing this corpus. • We presented a larg a Chinese Financial Target-based Sentiment Analysis corpus (FiTSA). The multiple financial entities, sentiment targets and corresponding polarities are annotated in paragraphs from Chinese financial news text. SentiHood (Saeidi et al., 2016) focused on locations and neighborhoods. Different from previous dataset, SentiHood replaced all targets with specific terms using Location 1 or Location 2. There exist few Chinese ABSA dataset. SemEval 2016 subtask 5 (Pontiki et al., 2016) released two domain-specific dataset for consumer electronics including mobile phones and digital cameras. For financial ABSA dataset, (Gaillat et al., 2018) constructed the SSIX corpora on stock market related microblog text which aimed at annotating continuous sentiment scores. FiQA 2018 challenge subtask1 constructed a financial ABSA dataset on micro-blo"
2020.lrec-1.620,N18-2028,0,0.0124393,"et-based sentiment analysis task. As we mentioned above, it is multiple target and multiple sentiment annotation corpus. Each entity appears 1.58 times on average in a paragraph, while for SemiEval ABSA corpus, it is much shorter than FiTSA and each target entity only appears once. Thus, some state-of-the-art methods can not be applied to this corpus straight forward. In the evaluation, we developed several ABSA/TBSA classifier including traditional machine learning baselines and the newest deep neural network models. For the deep neural network based models, pre-trained word embeddings from (Song et al., 2018) is used as the input for RNN based models: • LR: TF-IDF and some target entity attributes such as entity positions and appearing times in the text are used as features. Logistic Regression is applied as the classifier. • SVM: Using the features in LR and Support Vector Machine as the classifier. • XGBoost: Using the features in LR and Extreme Gradient Boosting method as the classifier. • LSTM-ATT: LSTM is applied for feature extraction. Attention mechanism is adopted to learn target entity related representations and MLP is adopted as the classifier. Table 3: The evaluation performance on FiT"
2020.lrec-1.620,C16-1311,0,0.129544,"ions (Pang et al., 2008). (Kim, 2014; Li et al., 2015; Zhou et al., 2016; Yang et al., 2016; Chen et al., 2017; Li et al., 2015) focused on classifying the given text as positive, negative, neutral at document level and sentence level. However, the accuracy of sentiment classification on multiple opinion aspects/targets level is unsatisfactory. Especially, such kind of fine-grained sentiment analysis is essential to many practical applications. Hence aspect-based sentiment analysis (ABSA) (Pontiki et al., 2014; Pontiki et al., 2016; Poria et al., 2016), target-based sentiment analysis (TBSA) (Tang et al., 2016a; Tang et al., 2016b; Dong et al., 2014; Wang et al., 2017) and targeted aspect-based sentiment analysis (TABSA) (Liang et al., 2019; Ma et al., 2018) had been proposed to tackle the subtler sentiment in term of different aspects/targets in a sentence. For TBSA, it aims to identify the sentiment expression and determine the polarities of different target entities. Take the following Ex.1, as an example, there are three entities in this paragraph, 乐 融 致 新(LeMall), 乐 视 网(LETV) and 乐 视控股(LeEco). 乐融致新(LeMall) and 乐视网(LETV) appear more than once and their corresponding sentiment polarities are neg"
2020.lrec-1.620,D16-1021,0,0.0679777,"ions (Pang et al., 2008). (Kim, 2014; Li et al., 2015; Zhou et al., 2016; Yang et al., 2016; Chen et al., 2017; Li et al., 2015) focused on classifying the given text as positive, negative, neutral at document level and sentence level. However, the accuracy of sentiment classification on multiple opinion aspects/targets level is unsatisfactory. Especially, such kind of fine-grained sentiment analysis is essential to many practical applications. Hence aspect-based sentiment analysis (ABSA) (Pontiki et al., 2014; Pontiki et al., 2016; Poria et al., 2016), target-based sentiment analysis (TBSA) (Tang et al., 2016a; Tang et al., 2016b; Dong et al., 2014; Wang et al., 2017) and targeted aspect-based sentiment analysis (TABSA) (Liang et al., 2019; Ma et al., 2018) had been proposed to tackle the subtler sentiment in term of different aspects/targets in a sentence. For TBSA, it aims to identify the sentiment expression and determine the polarities of different target entities. Take the following Ex.1, as an example, there are three entities in this paragraph, 乐 融 致 新(LeMall), 乐 视 网(LETV) and 乐 视控股(LeEco). 乐融致新(LeMall) and 乐视网(LETV) appear more than once and their corresponding sentiment polarities are neg"
2020.lrec-1.620,E17-1046,0,0.0170441,"et al., 2016; Yang et al., 2016; Chen et al., 2017; Li et al., 2015) focused on classifying the given text as positive, negative, neutral at document level and sentence level. However, the accuracy of sentiment classification on multiple opinion aspects/targets level is unsatisfactory. Especially, such kind of fine-grained sentiment analysis is essential to many practical applications. Hence aspect-based sentiment analysis (ABSA) (Pontiki et al., 2014; Pontiki et al., 2016; Poria et al., 2016), target-based sentiment analysis (TBSA) (Tang et al., 2016a; Tang et al., 2016b; Dong et al., 2014; Wang et al., 2017) and targeted aspect-based sentiment analysis (TABSA) (Liang et al., 2019; Ma et al., 2018) had been proposed to tackle the subtler sentiment in term of different aspects/targets in a sentence. For TBSA, it aims to identify the sentiment expression and determine the polarities of different target entities. Take the following Ex.1, as an example, there are three entities in this paragraph, 乐 融 致 新(LeMall), 乐 视 网(LETV) and 乐 视控股(LeEco). 乐融致新(LeMall) and 乐视网(LETV) appear more than once and their corresponding sentiment polarities are negative, while for 乐 视 控 股(LeEco), the polarity is neutral. †"
2020.lrec-1.620,N16-1174,0,0.0214239,"h the rapid development of the Internet, it becomes easier to collect a large scale of public textual data. Identifying the sentiment corresponding to the financial entities such as companies from the financial text is crucial to financial investment and decision making. Thus, sentiment analysis techniques on financial text attracted much research interest in the recent years. Sentiment analysis (SA) is a hot research topic in natural language processing. It has gained increasing popularity due to the its widely applications (Pang et al., 2008). (Kim, 2014; Li et al., 2015; Zhou et al., 2016; Yang et al., 2016; Chen et al., 2017; Li et al., 2015) focused on classifying the given text as positive, negative, neutral at document level and sentence level. However, the accuracy of sentiment classification on multiple opinion aspects/targets level is unsatisfactory. Especially, such kind of fine-grained sentiment analysis is essential to many practical applications. Hence aspect-based sentiment analysis (ABSA) (Pontiki et al., 2014; Pontiki et al., 2016; Poria et al., 2016), target-based sentiment analysis (TBSA) (Tang et al., 2016a; Tang et al., 2016b; Dong et al., 2014; Wang et al., 2017) and targeted"
2020.lrec-1.620,D16-1061,0,0.0198015,"1. Introduction With the rapid development of the Internet, it becomes easier to collect a large scale of public textual data. Identifying the sentiment corresponding to the financial entities such as companies from the financial text is crucial to financial investment and decision making. Thus, sentiment analysis techniques on financial text attracted much research interest in the recent years. Sentiment analysis (SA) is a hot research topic in natural language processing. It has gained increasing popularity due to the its widely applications (Pang et al., 2008). (Kim, 2014; Li et al., 2015; Zhou et al., 2016; Yang et al., 2016; Chen et al., 2017; Li et al., 2015) focused on classifying the given text as positive, negative, neutral at document level and sentence level. However, the accuracy of sentiment classification on multiple opinion aspects/targets level is unsatisfactory. Especially, such kind of fine-grained sentiment analysis is essential to many practical applications. Hence aspect-based sentiment analysis (ABSA) (Pontiki et al., 2014; Pontiki et al., 2016; Poria et al., 2016), target-based sentiment analysis (TBSA) (Tang et al., 2016a; Tang et al., 2016b; Dong et al., 2014; Wang et al.,"
2021.acl-long.497,N19-1423,0,0.0105474,"a sequence of actions to incrementally construct a directed argumentation graph, often with O(n) parsing complexity. This allows our model to avoid inefficient enumeration operations and reduce the number of potential AC pairs that need evaluating, thus alleviating the class imbalance problem and achieving speedup. Also, our transition-based model does not introduce any corpus-specific structural constraints, and thus can handle both tree and non-tree structured argumentation, yielding promising generalization ability. Furthermore, we enhance our transition-based model with pre-trained BERT (Devlin et al., 2019), and use LSTM (Hochreiter and Schmidhuber, 1997) to represent the parser state of our model. Extensive experiments on two public datasets with different structures show that our transitionbased model outperforms previous methods, and achieves state-of-the-art results. Further analysis reveals that our model is of low parsing complexity and has a strong structure adaptive ability. To the best of our knowledge, we are the first to investigate transition-based methods for AM. 2 Related Work In computational AM, there are mainly two types of approaches to model argumentation structures, that is,"
2021.acl-long.497,P17-1002,0,0.0171543,"in a number of studies in AM. Following this dataset, Persing and Ng (2016) and Stab and Gurevych (2017) leveraged the Integer Linear Programming (ILP) framework to jointly predict ARs and AC types, in which several structural constraints are defined to ensure the tree structures. The arg-microtext (MT) dataset, created by Peldszus (2014), is another tree structured dataset. Studies on this dataset usually apply decoding mechanisms based on tree structures, such as Minimum Spanning Trees (MST) (Peldszus and Stede, 2015) and ILP (Afantenos et al., 2018). Regarding neural network-based methods, Eger et al. (2017) studied AM as a dependency parsing and a sequence labeling problem with multiple neural networks. Potash et al. (2017) introduced the sequence-to-sequence based Pointer Networks (Vinyals et al., 2015) to AM, and used the output of encoder and decoder to identify AC types and the presence of ARs, respectively. Kuribayashi et al. (2019) proposed an argumentation structure parsing model based on span representation, which used ELMo (Peters et al., 2018) to obtain representations for ACs. 2.2 Non-tree Structured AM Those studies described in Section 2.1 are all based upon the assumption that the"
2021.acl-long.497,W18-5201,0,0.0137157,"8). ?? ··· Transition-based Methods ··· with precondition ··· 2.3 action prediction ··· real-life scenarios may not be such well-formed. Hence, some studies have focused on non-tree structured AM, and these studies typically use the Consumer Debt Collection Practices (CDCP) (Park and Cardie, 2018) dataset. Regarding this dataset, Niculae et al. (2017) presented a structured learning approach based on factor graphs, which can also handle the tree structured PE dataset. However, the factor graph needs to be specifically designed according to the types of argumentation structures. Galassi et al. (2018) adopted residual networks for AM on the CDCP dataset. Recently, Morio et al. (2020) proposed a model devoted to non-tree structured AM, with a task-specific parameterization module to encode ACs and a biaffine attention module to capture ARs. To the best of our knowledge, until now there is no universal method that can address both tree and non-tree structured argumentation without any corpus-specific design. Thus, in this work, we fill this gap by proposing a neural transition-based model that can identify both tree and non-tree argumentation structures without introducing any prior structur"
2021.acl-long.497,P18-1248,0,0.0307506,"Missing"
2021.acl-long.497,W15-0504,0,0.0186717,"al Contribution Corresponding Author Reason AC1 Reason AC5 AC3 Value Value Policy Reason Figure 1: An example of argumentation mining from the CDCP dataset (Park and Cardie, 2018). Policy, Fact, and Value represent the types of ACs and Reason refers to the types of ARs. Note that, the CDCP dataset we use is preprocessed by Niculae et al. (2017). Argumentation mining (AM) aims to identify the argumentation structures in text, which has received widespread attention in recent years (Lawrence and Reed, 2019). It has been shown beneficial in a broad range of fields, such as information retrieval (Carstens and Toni, 2015; Stab et al., 2018), automated essay scoring (Wachsmuth et al., 2016; Ke et al., 2018), and legal decision support (Palau and Moens, 2009; Walker et al., 2018). Given a piece of paragraph-level argumentative text, an AM system first detects argument components (ACs), which are segments of text with argumentative meaning, and then extracts the argumentative relations (ARs) between ACs to obtain an argumentation graph, where the nodes and edges represent ACs and ARs, † AC2 Fact Reason Introduction ∗ AC4 Policy respectively. An example of AM is shown in Figure 1, where the text is segmented into"
2021.acl-long.497,D19-1291,0,0.018295,"dentification (ARI), which identifies ARs between ACs; 4) Argumentative relation type classification (ARTC), which determines 6354 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6354–6364 August 1–6, 2021. ©2021 Association for Computational Linguistics the types of ARs (e.g., Reason and Evidence). Most previous works assume that subtask 1) ACS has been completed, that is, ACs have been segmented, and focus on other subtasks (Potash et al., 2017; Kuribayashi et al., 2019; Chakrabarty et al., 2019). In this paper, we also make such an assumption, and perform ACTC and ARI on this basis. Among all the subtasks of AM, ARI is the most challenging because it requires understanding complex semantic interactions between ACs. Most previous works exhaustively enumerate all possible pairs of ACs (i.e., all ACs are matched to each other by Cartesian products) to determine the ARs between them (Kuribayashi et al., 2019; Morio et al., 2020). However, these approaches are of low efficiency and can cause class imbalance, since the majority of AC pairs have no relation. Besides, due to different annota"
2021.acl-long.497,P19-1464,0,0.115595,") Argumentative relation identification (ARI), which identifies ARs between ACs; 4) Argumentative relation type classification (ARTC), which determines 6354 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6354–6364 August 1–6, 2021. ©2021 Association for Computational Linguistics the types of ARs (e.g., Reason and Evidence). Most previous works assume that subtask 1) ACS has been completed, that is, ACs have been segmented, and focus on other subtasks (Potash et al., 2017; Kuribayashi et al., 2019; Chakrabarty et al., 2019). In this paper, we also make such an assumption, and perform ACTC and ARI on this basis. Among all the subtasks of AM, ARI is the most challenging because it requires understanding complex semantic interactions between ACs. Most previous works exhaustively enumerate all possible pairs of ACs (i.e., all ACs are matched to each other by Cartesian products) to determine the ARs between them (Kuribayashi et al., 2019; Morio et al., 2020). However, these approaches are of low efficiency and can cause class imbalance, since the majority of AC pairs have no relation. Besid"
2021.acl-long.497,D14-1082,0,0.00933978,"ssification (ARTC) is that performing ARTC along with ACTC and ARI jointly will hurt the overall performance. More details on this issue will be discussed in Section 6.4. Formally, we assume a piece of argumentation related paragraph P = (w1 , w2 , . . . , wm ) consisting of m tokens and a set X = (x1 , x2 , . . . , xn ) consisting of n AC spans are given. Each AC span xi is a tuple containing the beginning token index ?0 ??−1 ?1 ?1 ??−2 stack AC type classifier ?1 buffer ?2 ?1 ?2 ? ··· ?? ?3 ··· Task Definition ?0 ··· 3 ?? ··· Transition-based methods are commonly used in dependency parsing (Chen and Manning, 2014; G´omez-Rodr´ıguez et al., 2018), and has also been successfully applied to other NLP tasks with promising performance, such as discourse parsing (Yu et al., 2018), information extraction (Zhang et al., 2019), word segmentation (Zhang et al., 2016) and mention recognition (Wang et al., 2018). ?? ··· Transition-based Methods ··· with precondition ··· 2.3 action prediction ··· real-life scenarios may not be such well-formed. Hence, some studies have focused on non-tree structured AM, and these studies typically use the Consumer Debt Collection Practices (CDCP) (Park and Cardie, 2018) dataset. R"
2021.acl-long.497,J19-4006,0,0.0258499,"r model achieves the best performance on two public datasets of different structures. 1 AM Argumentation Graph Equal Contribution Corresponding Author Reason AC1 Reason AC5 AC3 Value Value Policy Reason Figure 1: An example of argumentation mining from the CDCP dataset (Park and Cardie, 2018). Policy, Fact, and Value represent the types of ACs and Reason refers to the types of ARs. Note that, the CDCP dataset we use is preprocessed by Niculae et al. (2017). Argumentation mining (AM) aims to identify the argumentation structures in text, which has received widespread attention in recent years (Lawrence and Reed, 2019). It has been shown beneficial in a broad range of fields, such as information retrieval (Carstens and Toni, 2015; Stab et al., 2018), automated essay scoring (Wachsmuth et al., 2016; Ke et al., 2018), and legal decision support (Palau and Moens, 2009; Walker et al., 2018). Given a piece of paragraph-level argumentative text, an AM system first detects argument components (ACs), which are segments of text with argumentative meaning, and then extracts the argumentative relations (ARs) between ACs to obtain an argumentation graph, where the nodes and edges represent ACs and ARs, † AC2 Fact Reaso"
2021.acl-long.497,2020.acl-main.298,0,0.389578,"ssume that subtask 1) ACS has been completed, that is, ACs have been segmented, and focus on other subtasks (Potash et al., 2017; Kuribayashi et al., 2019; Chakrabarty et al., 2019). In this paper, we also make such an assumption, and perform ACTC and ARI on this basis. Among all the subtasks of AM, ARI is the most challenging because it requires understanding complex semantic interactions between ACs. Most previous works exhaustively enumerate all possible pairs of ACs (i.e., all ACs are matched to each other by Cartesian products) to determine the ARs between them (Kuribayashi et al., 2019; Morio et al., 2020). However, these approaches are of low efficiency and can cause class imbalance, since the majority of AC pairs have no relation. Besides, due to different annotation schemes, there are mainly two kinds of structures of argumentation graphs, tree (Stab and Gurevych, 2014; Peldszus, 2014) and non-tree (Park and Cardie, 2018). Briefly, in tree structures, each AC has at most one outgoing AR, but there is no such restriction in non-tree structures (Figure 1). However, studies on these two kinds of structures are usually conducted separately. To date, there is no universal method that can address"
2021.acl-long.497,P17-1091,0,0.0350645,"Missing"
2021.acl-long.497,L18-1257,0,0.29841,"d model for argumentation mining, which incrementally builds an argumentation graph by generating a sequence of actions, avoiding inefficient enumeration operations. Furthermore, our model can handle both tree and non-tree structured argumentation without introducing any structural constraints. Experimental results show that our model achieves the best performance on two public datasets of different structures. 1 AM Argumentation Graph Equal Contribution Corresponding Author Reason AC1 Reason AC5 AC3 Value Value Policy Reason Figure 1: An example of argumentation mining from the CDCP dataset (Park and Cardie, 2018). Policy, Fact, and Value represent the types of ACs and Reason refers to the types of ARs. Note that, the CDCP dataset we use is preprocessed by Niculae et al. (2017). Argumentation mining (AM) aims to identify the argumentation structures in text, which has received widespread attention in recent years (Lawrence and Reed, 2019). It has been shown beneficial in a broad range of fields, such as information retrieval (Carstens and Toni, 2015; Stab et al., 2018), automated essay scoring (Wachsmuth et al., 2016; Ke et al., 2018), and legal decision support (Palau and Moens, 2009; Walker et al., 2"
2021.acl-long.497,W14-2112,0,0.180733,"s of AM, ARI is the most challenging because it requires understanding complex semantic interactions between ACs. Most previous works exhaustively enumerate all possible pairs of ACs (i.e., all ACs are matched to each other by Cartesian products) to determine the ARs between them (Kuribayashi et al., 2019; Morio et al., 2020). However, these approaches are of low efficiency and can cause class imbalance, since the majority of AC pairs have no relation. Besides, due to different annotation schemes, there are mainly two kinds of structures of argumentation graphs, tree (Stab and Gurevych, 2014; Peldszus, 2014) and non-tree (Park and Cardie, 2018). Briefly, in tree structures, each AC has at most one outgoing AR, but there is no such restriction in non-tree structures (Figure 1). However, studies on these two kinds of structures are usually conducted separately. To date, there is no universal method that can address both tree and non-tree structured argumentation without any corpus-specific constraints. Towards these issues, we present a neural transition-based model for AM, which can classify the types of ACs and identify ARs simultaneously. Our model predicts a sequence of actions to incrementally"
2021.acl-long.497,D15-1110,0,0.0266982,"Stab and Gurevych (2014, 2017), the tree structured Persuasive Essay (PE) dataset has been utilized in a number of studies in AM. Following this dataset, Persing and Ng (2016) and Stab and Gurevych (2017) leveraged the Integer Linear Programming (ILP) framework to jointly predict ARs and AC types, in which several structural constraints are defined to ensure the tree structures. The arg-microtext (MT) dataset, created by Peldszus (2014), is another tree structured dataset. Studies on this dataset usually apply decoding mechanisms based on tree structures, such as Minimum Spanning Trees (MST) (Peldszus and Stede, 2015) and ILP (Afantenos et al., 2018). Regarding neural network-based methods, Eger et al. (2017) studied AM as a dependency parsing and a sequence labeling problem with multiple neural networks. Potash et al. (2017) introduced the sequence-to-sequence based Pointer Networks (Vinyals et al., 2015) to AM, and used the output of encoder and decoder to identify AC types and the presence of ARs, respectively. Kuribayashi et al. (2019) proposed an argumentation structure parsing model based on span representation, which used ELMo (Peters et al., 2018) to obtain representations for ACs. 2.2 Non-tree Str"
2021.acl-long.497,N16-1164,0,0.0228135,"1 Tree Structured AM Most previous works assume that the argumentation graphs can be viewed as tree or forest structures, which makes the problem computationally easier because many tree-based structural constraints can be applied. Under the theory of Van Eemeren et al. (2004), Palau and Moens (2009) modeled argumentation in the legal text as tree structures and used handcrafted context-free grammar to identify these structures. Presented by Stab and Gurevych (2014, 2017), the tree structured Persuasive Essay (PE) dataset has been utilized in a number of studies in AM. Following this dataset, Persing and Ng (2016) and Stab and Gurevych (2017) leveraged the Integer Linear Programming (ILP) framework to jointly predict ARs and AC types, in which several structural constraints are defined to ensure the tree structures. The arg-microtext (MT) dataset, created by Peldszus (2014), is another tree structured dataset. Studies on this dataset usually apply decoding mechanisms based on tree structures, such as Minimum Spanning Trees (MST) (Peldszus and Stede, 2015) and ILP (Afantenos et al., 2018). Regarding neural network-based methods, Eger et al. (2017) studied AM as a dependency parsing and a sequence labeli"
2021.acl-long.497,N18-1202,0,0.00804007,"uctures, such as Minimum Spanning Trees (MST) (Peldszus and Stede, 2015) and ILP (Afantenos et al., 2018). Regarding neural network-based methods, Eger et al. (2017) studied AM as a dependency parsing and a sequence labeling problem with multiple neural networks. Potash et al. (2017) introduced the sequence-to-sequence based Pointer Networks (Vinyals et al., 2015) to AM, and used the output of encoder and decoder to identify AC types and the presence of ARs, respectively. Kuribayashi et al. (2019) proposed an argumentation structure parsing model based on span representation, which used ELMo (Peters et al., 2018) to obtain representations for ACs. 2.2 Non-tree Structured AM Those studies described in Section 2.1 are all based upon the assumption that the argumentation forms tree structures. However, this assumption is somewhat idealistic since argumentation structures in 6355 Following previous works (Potash et al., 2017; Kuribayashi et al., 2019), we assume subtask 1) ACS has been completed, i.e., the spans of ACs are given. Then, we aim at jointly classifying AC types (ACTC) and determining the presence of ARs (ARI). The reason why we do not jointly conduct AR type classification (ARTC) is that perf"
2021.acl-long.497,D17-1143,0,0.336465,"Fact, Value, etc.); 3) Argumentative relation identification (ARI), which identifies ARs between ACs; 4) Argumentative relation type classification (ARTC), which determines 6354 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6354–6364 August 1–6, 2021. ©2021 Association for Computational Linguistics the types of ARs (e.g., Reason and Evidence). Most previous works assume that subtask 1) ACS has been completed, that is, ACs have been segmented, and focus on other subtasks (Potash et al., 2017; Kuribayashi et al., 2019; Chakrabarty et al., 2019). In this paper, we also make such an assumption, and perform ACTC and ARI on this basis. Among all the subtasks of AM, ARI is the most challenging because it requires understanding complex semantic interactions between ACs. Most previous works exhaustively enumerate all possible pairs of ACs (i.e., all ACs are matched to each other by Cartesian products) to determine the ARs between them (Kuribayashi et al., 2019; Morio et al., 2020). However, these approaches are of low efficiency and can cause class imbalance, since the majority of AC pai"
2021.acl-long.497,C14-1142,0,0.207119,"is. Among all the subtasks of AM, ARI is the most challenging because it requires understanding complex semantic interactions between ACs. Most previous works exhaustively enumerate all possible pairs of ACs (i.e., all ACs are matched to each other by Cartesian products) to determine the ARs between them (Kuribayashi et al., 2019; Morio et al., 2020). However, these approaches are of low efficiency and can cause class imbalance, since the majority of AC pairs have no relation. Besides, due to different annotation schemes, there are mainly two kinds of structures of argumentation graphs, tree (Stab and Gurevych, 2014; Peldszus, 2014) and non-tree (Park and Cardie, 2018). Briefly, in tree structures, each AC has at most one outgoing AR, but there is no such restriction in non-tree structures (Figure 1). However, studies on these two kinds of structures are usually conducted separately. To date, there is no universal method that can address both tree and non-tree structured argumentation without any corpus-specific constraints. Towards these issues, we present a neural transition-based model for AM, which can classify the types of ACs and identify ARs simultaneously. Our model predicts a sequence of actions"
2021.acl-long.497,J17-3005,0,0.346551,"previous works assume that the argumentation graphs can be viewed as tree or forest structures, which makes the problem computationally easier because many tree-based structural constraints can be applied. Under the theory of Van Eemeren et al. (2004), Palau and Moens (2009) modeled argumentation in the legal text as tree structures and used handcrafted context-free grammar to identify these structures. Presented by Stab and Gurevych (2014, 2017), the tree structured Persuasive Essay (PE) dataset has been utilized in a number of studies in AM. Following this dataset, Persing and Ng (2016) and Stab and Gurevych (2017) leveraged the Integer Linear Programming (ILP) framework to jointly predict ARs and AC types, in which several structural constraints are defined to ensure the tree structures. The arg-microtext (MT) dataset, created by Peldszus (2014), is another tree structured dataset. Studies on this dataset usually apply decoding mechanisms based on tree structures, such as Minimum Spanning Trees (MST) (Peldszus and Stede, 2015) and ILP (Afantenos et al., 2018). Regarding neural network-based methods, Eger et al. (2017) studied AM as a dependency parsing and a sequence labeling problem with multiple neur"
2021.acl-long.497,D18-1402,0,0.0179209,"ding Author Reason AC1 Reason AC5 AC3 Value Value Policy Reason Figure 1: An example of argumentation mining from the CDCP dataset (Park and Cardie, 2018). Policy, Fact, and Value represent the types of ACs and Reason refers to the types of ARs. Note that, the CDCP dataset we use is preprocessed by Niculae et al. (2017). Argumentation mining (AM) aims to identify the argumentation structures in text, which has received widespread attention in recent years (Lawrence and Reed, 2019). It has been shown beneficial in a broad range of fields, such as information retrieval (Carstens and Toni, 2015; Stab et al., 2018), automated essay scoring (Wachsmuth et al., 2016; Ke et al., 2018), and legal decision support (Palau and Moens, 2009; Walker et al., 2018). Given a piece of paragraph-level argumentative text, an AM system first detects argument components (ACs), which are segments of text with argumentative meaning, and then extracts the argumentative relations (ARs) between ACs to obtain an argumentation graph, where the nodes and edges represent ACs and ARs, † AC2 Fact Reason Introduction ∗ AC4 Policy respectively. An example of AM is shown in Figure 1, where the text is segmented into five ACs, and there"
2021.acl-long.497,C16-1158,0,0.0233275,"alue Policy Reason Figure 1: An example of argumentation mining from the CDCP dataset (Park and Cardie, 2018). Policy, Fact, and Value represent the types of ACs and Reason refers to the types of ARs. Note that, the CDCP dataset we use is preprocessed by Niculae et al. (2017). Argumentation mining (AM) aims to identify the argumentation structures in text, which has received widespread attention in recent years (Lawrence and Reed, 2019). It has been shown beneficial in a broad range of fields, such as information retrieval (Carstens and Toni, 2015; Stab et al., 2018), automated essay scoring (Wachsmuth et al., 2016; Ke et al., 2018), and legal decision support (Palau and Moens, 2009; Walker et al., 2018). Given a piece of paragraph-level argumentative text, an AM system first detects argument components (ACs), which are segments of text with argumentative meaning, and then extracts the argumentative relations (ARs) between ACs to obtain an argumentation graph, where the nodes and edges represent ACs and ARs, † AC2 Fact Reason Introduction ∗ AC4 Policy respectively. An example of AM is shown in Figure 1, where the text is segmented into five ACs, and there are four ARs. In this instance, the types of AC2"
2021.acl-long.497,W18-5209,0,0.0147084,"nd Cardie, 2018). Policy, Fact, and Value represent the types of ACs and Reason refers to the types of ARs. Note that, the CDCP dataset we use is preprocessed by Niculae et al. (2017). Argumentation mining (AM) aims to identify the argumentation structures in text, which has received widespread attention in recent years (Lawrence and Reed, 2019). It has been shown beneficial in a broad range of fields, such as information retrieval (Carstens and Toni, 2015; Stab et al., 2018), automated essay scoring (Wachsmuth et al., 2016; Ke et al., 2018), and legal decision support (Palau and Moens, 2009; Walker et al., 2018). Given a piece of paragraph-level argumentative text, an AM system first detects argument components (ACs), which are segments of text with argumentative meaning, and then extracts the argumentative relations (ARs) between ACs to obtain an argumentation graph, where the nodes and edges represent ACs and ARs, † AC2 Fact Reason Introduction ∗ AC4 Policy respectively. An example of AM is shown in Figure 1, where the text is segmented into five ACs, and there are four ARs. In this instance, the types of AC2 and AC3 are Fact (non-experiential objective proposition) and Value (proposition containin"
2021.acl-long.497,D18-1124,0,0.0218486,"8). ?? ··· Transition-based Methods ··· with precondition ··· 2.3 action prediction ··· real-life scenarios may not be such well-formed. Hence, some studies have focused on non-tree structured AM, and these studies typically use the Consumer Debt Collection Practices (CDCP) (Park and Cardie, 2018) dataset. Regarding this dataset, Niculae et al. (2017) presented a structured learning approach based on factor graphs, which can also handle the tree structured PE dataset. However, the factor graph needs to be specifically designed according to the types of argumentation structures. Galassi et al. (2018) adopted residual networks for AM on the CDCP dataset. Recently, Morio et al. (2020) proposed a model devoted to non-tree structured AM, with a task-specific parameterization module to encode ACs and a biaffine attention module to capture ARs. To the best of our knowledge, until now there is no universal method that can address both tree and non-tree structured argumentation without any corpus-specific design. Thus, in this work, we fill this gap by proposing a neural transition-based model that can identify both tree and non-tree argumentation structures without introducing any prior structur"
2021.acl-long.497,C18-1047,0,0.0229817,"8). ?? ··· Transition-based Methods ··· with precondition ··· 2.3 action prediction ··· real-life scenarios may not be such well-formed. Hence, some studies have focused on non-tree structured AM, and these studies typically use the Consumer Debt Collection Practices (CDCP) (Park and Cardie, 2018) dataset. Regarding this dataset, Niculae et al. (2017) presented a structured learning approach based on factor graphs, which can also handle the tree structured PE dataset. However, the factor graph needs to be specifically designed according to the types of argumentation structures. Galassi et al. (2018) adopted residual networks for AM on the CDCP dataset. Recently, Morio et al. (2020) proposed a model devoted to non-tree structured AM, with a task-specific parameterization module to encode ACs and a biaffine attention module to capture ARs. To the best of our knowledge, until now there is no universal method that can address both tree and non-tree structured argumentation without any corpus-specific design. Thus, in this work, we fill this gap by proposing a neural transition-based model that can identify both tree and non-tree argumentation structures without introducing any prior structur"
2021.acl-long.497,P16-1040,0,0.0123309,"ed AM Most previous works assume that the argumentation graphs can be viewed as tree or forest structures, which makes the problem computationally easier because many tree-based structural constraints can be applied. Under the theory of Van Eemeren et al. (2004), Palau and Moens (2009) modeled argumentation in the legal text as tree structures and used handcrafted context-free grammar to identify these structures. Presented by Stab and Gurevych (2014, 2017), the tree structured Persuasive Essay (PE) dataset has been utilized in a number of studies in AM. Following this dataset, Persing and Ng (2016) and Stab and Gurevych (2017) leveraged the Integer Linear Programming (ILP) framework to jointly predict ARs and AC types, in which several structural constraints are defined to ensure the tree structures. The arg-microtext (MT) dataset, created by Peldszus (2014), is another tree structured dataset. Studies on this dataset usually apply decoding mechanisms based on tree structures, such as Minimum Spanning Trees (MST) (Peldszus and Stede, 2015) and ILP (Afantenos et al., 2018). Regarding neural network-based methods, Eger et al. (2017) studied AM as a dependency parsing and a sequence labeli"
2021.acl-short.66,D18-1547,0,0.0326153,"Missing"
2021.acl-short.66,E17-2075,0,0.0993423,"ic network masking to alleviate the negative impact of fixed weights of old tasks on new tasks. We conduct extensive experiments on seven different tasks from three benchmark datasets and show empirically that TPEM leads to significantly improved results over the strong competitors. For reproducibility, we submit the code and data at: https://github.com/siat-nlp/TPEM. 1 Introduction Building a human-like task-oriented dialogue system is a long-term goal of AI. Great endeavors have been made in designing end-to-end taskoriented dialogue systems (TDSs) with sequenceto-sequence (Seq2Seq) models (Eric and Manning, 2017; Madotto et al., 2018; Gangi Reddy et al., 2019; Qin et al., 2020; Mi et al., 2019; He et al., 2020; Wang et al., 2020; Qin et al., 2021), which have taken the state-of-the-art of TDSs to a new level. Generally, Seq2Seq models leverage an encoder to create a vector representation of dialogue history and KB information, and then pass this representation into a decoder so as to output a response word by word. For example, GLMP (Wu ∗ This work was conducted when Binzong Geng was an intern at SIAT, Chinese Academy of Sciences. † Min Yang is corresponding author. et al., 2019) is a representative"
2021.acl-short.66,N19-1375,0,0.011719,"of fixed weights of old tasks on new tasks. We conduct extensive experiments on seven different tasks from three benchmark datasets and show empirically that TPEM leads to significantly improved results over the strong competitors. For reproducibility, we submit the code and data at: https://github.com/siat-nlp/TPEM. 1 Introduction Building a human-like task-oriented dialogue system is a long-term goal of AI. Great endeavors have been made in designing end-to-end taskoriented dialogue systems (TDSs) with sequenceto-sequence (Seq2Seq) models (Eric and Manning, 2017; Madotto et al., 2018; Gangi Reddy et al., 2019; Qin et al., 2020; Mi et al., 2019; He et al., 2020; Wang et al., 2020; Qin et al., 2021), which have taken the state-of-the-art of TDSs to a new level. Generally, Seq2Seq models leverage an encoder to create a vector representation of dialogue history and KB information, and then pass this representation into a decoder so as to output a response word by word. For example, GLMP (Wu ∗ This work was conducted when Binzong Geng was an intern at SIAT, Chinese Academy of Sciences. † Min Yang is corresponding author. et al., 2019) is a representative end-to-end TDS, which incorporates KB informatio"
2021.acl-short.66,2020.emnlp-main.281,1,0.729745,"extensive experiments on seven different tasks from three benchmark datasets and show empirically that TPEM leads to significantly improved results over the strong competitors. For reproducibility, we submit the code and data at: https://github.com/siat-nlp/TPEM. 1 Introduction Building a human-like task-oriented dialogue system is a long-term goal of AI. Great endeavors have been made in designing end-to-end taskoriented dialogue systems (TDSs) with sequenceto-sequence (Seq2Seq) models (Eric and Manning, 2017; Madotto et al., 2018; Gangi Reddy et al., 2019; Qin et al., 2020; Mi et al., 2019; He et al., 2020; Wang et al., 2020; Qin et al., 2021), which have taken the state-of-the-art of TDSs to a new level. Generally, Seq2Seq models leverage an encoder to create a vector representation of dialogue history and KB information, and then pass this representation into a decoder so as to output a response word by word. For example, GLMP (Wu ∗ This work was conducted when Binzong Geng was an intern at SIAT, Chinese Academy of Sciences. † Min Yang is corresponding author. et al., 2019) is a representative end-to-end TDS, which incorporates KB information into Seq2Seq model by using a global memory pointe"
2021.acl-short.66,P02-1040,0,0.111788,"method. Furthermore, we report results obtained by the base model when its parameters are optionally re-initialized after a task has been visited (denoted as Re-init). We also report the results of Re-init with network expansion (denoted as Re-init-expand). Different from GLMP that keeps learning a TDS by utilizing parameters learned from past tasks as initialization for the new task, both Re-init and Re-initexpand save a separate model for each task in inference without considering the continual learning scenario. 4 Experimental Results Main Results We evaluate TPEM and baselines with BLEU (Papineni et al., 2002) and entity F1 (Madotto et al., 2018). We conduct experiments by following the common continual learning setting, where experimental data from 7 domains arrives sequentially. The results of each task are reported after all 7 tasks have been learned. That is, each model keeps learning a new task by using the weights learned from past tasks as initialization. The evaluation results are reported in Table 1. The typical TDSs (i.e., Ptr-Unk, Mem2Seq, GLMP) perform much worse than the continual learning methods (UCL and TPEM). This is consistent with our claim that conventional TDSs suffer from cata"
2021.acl-short.66,2020.acl-main.565,0,0.0112824,"old tasks on new tasks. We conduct extensive experiments on seven different tasks from three benchmark datasets and show empirically that TPEM leads to significantly improved results over the strong competitors. For reproducibility, we submit the code and data at: https://github.com/siat-nlp/TPEM. 1 Introduction Building a human-like task-oriented dialogue system is a long-term goal of AI. Great endeavors have been made in designing end-to-end taskoriented dialogue systems (TDSs) with sequenceto-sequence (Seq2Seq) models (Eric and Manning, 2017; Madotto et al., 2018; Gangi Reddy et al., 2019; Qin et al., 2020; Mi et al., 2019; He et al., 2020; Wang et al., 2020; Qin et al., 2021), which have taken the state-of-the-art of TDSs to a new level. Generally, Seq2Seq models leverage an encoder to create a vector representation of dialogue history and KB information, and then pass this representation into a decoder so as to output a response word by word. For example, GLMP (Wu ∗ This work was conducted when Binzong Geng was an intern at SIAT, Chinese Academy of Sciences. † Min Yang is corresponding author. et al., 2019) is a representative end-to-end TDS, which incorporates KB information into Seq2Seq mod"
2021.acl-short.66,2020.coling-main.362,1,0.68595,"ents on seven different tasks from three benchmark datasets and show empirically that TPEM leads to significantly improved results over the strong competitors. For reproducibility, we submit the code and data at: https://github.com/siat-nlp/TPEM. 1 Introduction Building a human-like task-oriented dialogue system is a long-term goal of AI. Great endeavors have been made in designing end-to-end taskoriented dialogue systems (TDSs) with sequenceto-sequence (Seq2Seq) models (Eric and Manning, 2017; Madotto et al., 2018; Gangi Reddy et al., 2019; Qin et al., 2020; Mi et al., 2019; He et al., 2020; Wang et al., 2020; Qin et al., 2021), which have taken the state-of-the-art of TDSs to a new level. Generally, Seq2Seq models leverage an encoder to create a vector representation of dialogue history and KB information, and then pass this representation into a decoder so as to output a response word by word. For example, GLMP (Wu ∗ This work was conducted when Binzong Geng was an intern at SIAT, Chinese Academy of Sciences. † Min Yang is corresponding author. et al., 2019) is a representative end-to-end TDS, which incorporates KB information into Seq2Seq model by using a global memory pointer to filter irrelev"
2021.acl-short.66,D16-1233,0,0.0226054,"Missing"
2021.acl-short.66,P18-1136,0,0.111679,"leviate the negative impact of fixed weights of old tasks on new tasks. We conduct extensive experiments on seven different tasks from three benchmark datasets and show empirically that TPEM leads to significantly improved results over the strong competitors. For reproducibility, we submit the code and data at: https://github.com/siat-nlp/TPEM. 1 Introduction Building a human-like task-oriented dialogue system is a long-term goal of AI. Great endeavors have been made in designing end-to-end taskoriented dialogue systems (TDSs) with sequenceto-sequence (Seq2Seq) models (Eric and Manning, 2017; Madotto et al., 2018; Gangi Reddy et al., 2019; Qin et al., 2020; Mi et al., 2019; He et al., 2020; Wang et al., 2020; Qin et al., 2021), which have taken the state-of-the-art of TDSs to a new level. Generally, Seq2Seq models leverage an encoder to create a vector representation of dialogue history and KB information, and then pass this representation into a decoder so as to output a response word by word. For example, GLMP (Wu ∗ This work was conducted when Binzong Geng was an intern at SIAT, Chinese Academy of Sciences. † Min Yang is corresponding author. et al., 2019) is a representative end-to-end TDS, which"
2021.emnlp-main.19,2020.coling-main.72,0,0.122319,"nowledge base, vividly, a task learning methods, Li et al. (2020b) adopted word can connect or not to an aspect via various routes, the successful connection probability (cor- aspect category detection task to aggregate the sentiment for the aspect from the context. Chen et al. responding to the weight of an edge in a graph) can (2020) modeled document-level sentiment preferbe naturally regard as a Binomial Distribution. We ence with cooperative graph attention networks for hence examine the weights of edges via modeling all the probabilities of successful connection pos- document-level ACSA. Cai et al. (2020) explored a hierarchical graph convolutional network to model sibility based on the prior knowledge (routes and the inner- and inter-relations for aspects in senticonnection information) of external knowledge by means of Beta Distribution (Gupta and Nadarajah, ment prediction. 2004), which is the Conjugate prior distribution of In addition, to enhance the learning ability of the Binomial Distribution. In this way, all the proba- model, there are a series of studies that incorpobilities of aspect-aware words that connecting to rate external knowledge into the framework (Ma the aspect could be i"
2021.emnlp-main.19,2020.acl-main.338,0,0.137026,"the sentence. Here, the aspect category (hereinafter also referred to as aspect) generally consists of an entity E and an attribute A (i.e. E#A) or only an entity E. As shown in Figure 1, in sentence “This place is pricey, but the pizza is yummy.”, there are two aspects mentioned in the sentence: “RESTAURANT#PRICES” (negative) and “FOOD#QUALITY” (positive). Many existing research efforts focus on ACSA with deep learning methods to attend the significant information for the aspect category in sentiment prediction (Wang et al., 2016; Cheng et al., 2017; Liang et al., 2019a,b; Li et al., 2020a; Chen et al., 2020; Li et al., 2020b; Liang et al., 2020a). Despite promising progress made by existing methods, they are generally entangled about how to search the sentiment clues of coarse-grained aspects from the context. However, making sense of the aspectoriented sentiment words from the context purely based on the implicit aspects is a daunting task. This mostly due to 1) aspect categories generally 1 Introduction do not manifest in the context, and 2) multiple asAspect category sentiment analysis (ACSA) aims pects and sentiment polarities may be mentioned to detect the sentiment polarity for a coarse-gr"
2021.emnlp-main.19,N19-1423,0,0.0219115,"Missing"
2021.emnlp-main.19,D19-1549,0,0.0160019,"s the Beta Distribution of all importance probabilities θ, which is defined as: θα−1 (1 − θ)β−1 f (θ; α, β) , B(α, β) Z 1 B(α, β) , θα−1 (1 − θ)β−1 dθ (3) (4) 0 where B(·) is Beta function for normalization. Here α and β denote the parameters of the Beta Distribution towards the aspect which are learned by the prior knowledge from the external knowledge: α = Cis + 1, β = Cia − Cis + 1 (5) Based on it, we can derive a decent aspect-aware weight for each aspect-aware word. In addition, we Aspect-aware Graph Construction (6) Here inspired by many previous graph-based studies (Zhang et al., 2019; Huang and Carley, 2019; Liang et al., 2020b), we also employ dependency tree of the sentence to better capture the syntactical relations1 . That is, we add 1 to the edge weight of Ai,j if wi and wj contain dependency in the dependency tree of the sentence. Then we construct the undirected graph to enrich the affective and dependency information: Ai,j = Aj,i , and also set a self-loop for each word: Ai,i = 1. 3.4 Aspect-aware Sentiment Learning For each sentence, we first retrieve the embedding of each word in the sentence from the embedding lookup table V ∈ Rm×N . Thus for a sentence with n words, we can get the co"
2021.emnlp-main.19,2020.emnlp-main.287,0,0.277745,"cessarily occur in the sentence. Here, the aspect category (hereinafter also referred to as aspect) generally consists of an entity E and an attribute A (i.e. E#A) or only an entity E. As shown in Figure 1, in sentence “This place is pricey, but the pizza is yummy.”, there are two aspects mentioned in the sentence: “RESTAURANT#PRICES” (negative) and “FOOD#QUALITY” (positive). Many existing research efforts focus on ACSA with deep learning methods to attend the significant information for the aspect category in sentiment prediction (Wang et al., 2016; Cheng et al., 2017; Liang et al., 2019a,b; Li et al., 2020a; Chen et al., 2020; Li et al., 2020b; Liang et al., 2020a). Despite promising progress made by existing methods, they are generally entangled about how to search the sentiment clues of coarse-grained aspects from the context. However, making sense of the aspectoriented sentiment words from the context purely based on the implicit aspects is a daunting task. This mostly due to 1) aspect categories generally 1 Introduction do not manifest in the context, and 2) multiple asAspect category sentiment analysis (ACSA) aims pects and sentiment polarities may be mentioned to detect the sentiment pola"
2021.emnlp-main.19,P19-1462,1,0.833253,"words. ACSA does not necessarily occur in the sentence. Here, the aspect category (hereinafter also referred to as aspect) generally consists of an entity E and an attribute A (i.e. E#A) or only an entity E. As shown in Figure 1, in sentence “This place is pricey, but the pizza is yummy.”, there are two aspects mentioned in the sentence: “RESTAURANT#PRICES” (negative) and “FOOD#QUALITY” (positive). Many existing research efforts focus on ACSA with deep learning methods to attend the significant information for the aspect category in sentiment prediction (Wang et al., 2016; Cheng et al., 2017; Liang et al., 2019a,b; Li et al., 2020a; Chen et al., 2020; Li et al., 2020b; Liang et al., 2020a). Despite promising progress made by existing methods, they are generally entangled about how to search the sentiment clues of coarse-grained aspects from the context. However, making sense of the aspectoriented sentiment words from the context purely based on the implicit aspects is a daunting task. This mostly due to 1) aspect categories generally 1 Introduction do not manifest in the context, and 2) multiple asAspect category sentiment analysis (ACSA) aims pects and sentiment polarities may be mentioned to detec"
2021.emnlp-main.19,2020.coling-main.13,1,0.906182,"ory (hereinafter also referred to as aspect) generally consists of an entity E and an attribute A (i.e. E#A) or only an entity E. As shown in Figure 1, in sentence “This place is pricey, but the pizza is yummy.”, there are two aspects mentioned in the sentence: “RESTAURANT#PRICES” (negative) and “FOOD#QUALITY” (positive). Many existing research efforts focus on ACSA with deep learning methods to attend the significant information for the aspect category in sentiment prediction (Wang et al., 2016; Cheng et al., 2017; Liang et al., 2019a,b; Li et al., 2020a; Chen et al., 2020; Li et al., 2020b; Liang et al., 2020a). Despite promising progress made by existing methods, they are generally entangled about how to search the sentiment clues of coarse-grained aspects from the context. However, making sense of the aspectoriented sentiment words from the context purely based on the implicit aspects is a daunting task. This mostly due to 1) aspect categories generally 1 Introduction do not manifest in the context, and 2) multiple asAspect category sentiment analysis (ACSA) aims pects and sentiment polarities may be mentioned to detect the sentiment polarity for a coarse-grained in the same context. On the cont"
2021.emnlp-main.19,D19-1559,0,0.0209696,"words. ACSA does not necessarily occur in the sentence. Here, the aspect category (hereinafter also referred to as aspect) generally consists of an entity E and an attribute A (i.e. E#A) or only an entity E. As shown in Figure 1, in sentence “This place is pricey, but the pizza is yummy.”, there are two aspects mentioned in the sentence: “RESTAURANT#PRICES” (negative) and “FOOD#QUALITY” (positive). Many existing research efforts focus on ACSA with deep learning methods to attend the significant information for the aspect category in sentiment prediction (Wang et al., 2016; Cheng et al., 2017; Liang et al., 2019a,b; Li et al., 2020a; Chen et al., 2020; Li et al., 2020b; Liang et al., 2020a). Despite promising progress made by existing methods, they are generally entangled about how to search the sentiment clues of coarse-grained aspects from the context. However, making sense of the aspectoriented sentiment words from the context purely based on the implicit aspects is a daunting task. This mostly due to 1) aspect categories generally 1 Introduction do not manifest in the context, and 2) multiple asAspect category sentiment analysis (ACSA) aims pects and sentiment polarities may be mentioned to detec"
2021.emnlp-main.19,D14-1162,0,0.0840721,"Missing"
2021.emnlp-main.19,S15-2082,0,0.056533,"Missing"
2021.emnlp-main.19,S14-2004,0,0.122582,"Missing"
2021.emnlp-main.19,2021.acl-long.15,0,0.0195841,"inct pivot and then search the aspect-related words from external knowledge, called aspect-aware words, which are served as the substitutes of the coarse-grained aspect to construct graph of the context for the specific aspect. That is, external knowledge is deployed as a bridge between implicit aspect category and the context, so as to skillfully and actively build connections between highly aspect-related context words and the specific aspect by means of a graph construction. In addition, inspired by many previous graph-based methods (Yao et al., 2019; Qin et al., 2020; Liang et al., 2020b; Qin et al., 2021b,a; Zhang et al., 2021; Liang et al., 2021a), weights of edges in a graph are important for graph information aggregation. Moreover, based on our empirical study (as shown in Figure 3 and 4), the contributions of aspect-aware words to the aspect are obviously different. For example, the aspectaware word “place” is more important than “pizza” to the aspect entity “RESTAURANT”. Following that the main challenge of the idea evolves into how to determine the importance of aspect-aware words for the corresponding aspect, which can be leveraged as the weights of edges in a graph for learning the se"
2021.emnlp-main.19,2020.findings-emnlp.163,0,0.0948707,"Missing"
2021.emnlp-main.19,N19-1035,0,0.0752708,"R EST 15 Acc. F1 TC-LSTM (Tang et al., 2016) 76.39 58.70 ATAE-LSTM (Wang et al., 2016) 78.48 59.77 GCAE (Xue and Li, 2018) 77.55 57.43 AA-LSTM (Xing et al., 2019) CapsNet (Jiang et al., 2019) 78.14 61.57 AS-Capsules (Wang et al., 2019) GIN (Yin et al., 2020) 81.17 62.38 MIMLLN (Li et al., 2020b) 78.27 60.59 AAGCN-one (w/o distribution) 81.22 63.70 AAGCN-hop (w/o distribution) 81.31 64.08 AAGCN-BD (binomial) 81.39 64.78 AAGCN-PD (poisson) 81.45 64.27 AAGCN-GD (gamma) 82.11 65.30 AAGCN-c (ConceptNet) 82.36 66.82 AAGCN (ours) 82.79 67.43 BERT (Devlin et al., 2019) 82.41 64.35 BERT-QA (Sun et al., 2019) 82.53 64.89 CapsNet-BERT (Jiang et al., 2019) 81.89 61.85 GIN-BERT (Yin et al., 2020) 83.96 66.03 MIMLLN-BERT (Li et al., 2020b) 82.76 65.10 Hier-GCN-BERT (Cai et al., 2020) 64.23[ AAGCN-BERT-c (ConceptNet) 87.18 71.02 AAGCN-BERT (ours) 87.92 71.75 Model L AP 15 Acc. F1 74.13 60.08 75.32 63.02 75.30 62.87 74.71 61.75 75.93 63.18 75.30 61.39 77.16 62.53 76.92 62.97 77.26 63.45 76.73 63.68 77.58 64.62 78.73 65.12 80.02 65.87 81.57 66.23 82.73 62.37 82.19 59.75 82.97 65.29 82.98 62.36 - 62.13[ 85.23 71.52 85.82 72.39 R EST 16 Acc. F1 83.55 60.26 84.19 62.89 84.66 60.89 83.79 61.36 87.05"
2021.emnlp-main.19,C16-1311,0,0.184558,"0.3 after the embedding layer. For BERT-based models, we use the pre-trained uncased BERT-base (Devlin et al., 2019) with 768dimensional embedding4 , and the learning rate is 0.00002. SenticNet (Cambria et al., 2020), which contains affective commonsense relations between words, is employed to derive aspect-aware words in this work. We set the max hop number to 5. The 3 The source code of this work is released at https:// github.com/BinLiang-NLP/AAGCN-ACSA. 4 Since the baselines are BERT-base based, we construct our model based on BERT-base for a fair comparison. 212 R EST 15 Acc. F1 TC-LSTM (Tang et al., 2016) 76.39 58.70 ATAE-LSTM (Wang et al., 2016) 78.48 59.77 GCAE (Xue and Li, 2018) 77.55 57.43 AA-LSTM (Xing et al., 2019) CapsNet (Jiang et al., 2019) 78.14 61.57 AS-Capsules (Wang et al., 2019) GIN (Yin et al., 2020) 81.17 62.38 MIMLLN (Li et al., 2020b) 78.27 60.59 AAGCN-one (w/o distribution) 81.22 63.70 AAGCN-hop (w/o distribution) 81.31 64.08 AAGCN-BD (binomial) 81.39 64.78 AAGCN-PD (poisson) 81.45 64.27 AAGCN-GD (gamma) 82.11 65.30 AAGCN-c (ConceptNet) 82.36 66.82 AAGCN (ours) 82.79 67.43 BERT (Devlin et al., 2019) 82.41 64.35 BERT-QA (Sun et al., 2019) 82.53 64.89 CapsNet-BERT (J"
2021.emnlp-main.19,2020.acl-main.374,0,0.0199319,"lity based on the prior knowledge (routes and the inner- and inter-relations for aspects in senticonnection information) of external knowledge by means of Beta Distribution (Gupta and Nadarajah, ment prediction. 2004), which is the Conjugate prior distribution of In addition, to enhance the learning ability of the Binomial Distribution. In this way, all the proba- model, there are a series of studies that incorpobilities of aspect-aware words that connecting to rate external knowledge into the framework (Ma the aspect could be investigated, so as to determine et al., 2018; Zhang et al., 2020; Tian et al., 2020; the optimum confidence probability (weight) of Tong et al., 2020; Liang et al., 2021b). Among the aspect-aware word, called aspect-aware weight. them, Tian et al. (2020) modeled sentiment inSubsequently, we construct aspect-aware graph(s) formation at the word, polarity, and aspect level for each context with respect to the aspect based on into pre-trained sentiment representation in sentithe aspect-aware words paired with their weights. ment analysis based on the automatically-mined 209 Aspect-aware sentiment learning Aspect-aware words derivation Aspect-aware graphs construction Knowledge"
2021.emnlp-main.19,2020.acl-main.522,0,0.0427373,"-relations for aspects in senticonnection information) of external knowledge by means of Beta Distribution (Gupta and Nadarajah, ment prediction. 2004), which is the Conjugate prior distribution of In addition, to enhance the learning ability of the Binomial Distribution. In this way, all the proba- model, there are a series of studies that incorpobilities of aspect-aware words that connecting to rate external knowledge into the framework (Ma the aspect could be investigated, so as to determine et al., 2018; Zhang et al., 2020; Tian et al., 2020; the optimum confidence probability (weight) of Tong et al., 2020; Liang et al., 2021b). Among the aspect-aware word, called aspect-aware weight. them, Tian et al. (2020) modeled sentiment inSubsequently, we construct aspect-aware graph(s) formation at the word, polarity, and aspect level for each context with respect to the aspect based on into pre-trained sentiment representation in sentithe aspect-aware words paired with their weights. ment analysis based on the automatically-mined 209 Aspect-aware sentiment learning Aspect-aware words derivation Aspect-aware graphs construction Knowledge Hidden representations Attention scores Attribute graph Beta distr"
2021.emnlp-main.19,D16-1058,0,0.535381,"same color represent sentimentrelated words. ACSA does not necessarily occur in the sentence. Here, the aspect category (hereinafter also referred to as aspect) generally consists of an entity E and an attribute A (i.e. E#A) or only an entity E. As shown in Figure 1, in sentence “This place is pricey, but the pizza is yummy.”, there are two aspects mentioned in the sentence: “RESTAURANT#PRICES” (negative) and “FOOD#QUALITY” (positive). Many existing research efforts focus on ACSA with deep learning methods to attend the significant information for the aspect category in sentiment prediction (Wang et al., 2016; Cheng et al., 2017; Liang et al., 2019a,b; Li et al., 2020a; Chen et al., 2020; Li et al., 2020b; Liang et al., 2020a). Despite promising progress made by existing methods, they are generally entangled about how to search the sentiment clues of coarse-grained aspects from the context. However, making sense of the aspectoriented sentiment words from the context purely based on the implicit aspects is a daunting task. This mostly due to 1) aspect categories generally 1 Introduction do not manifest in the context, and 2) multiple asAspect category sentiment analysis (ACSA) aims pects and sentim"
2021.emnlp-main.19,P18-1234,0,0.0141848,"ith Beta Distribution is deployed to educe the aspect-aware weights for constructing the knowledge enhanced aspect-aware graph. (iii) An aspect-aware graph convolutional network is proposed to draw contextual sentiment dependencies to the aspect for sentiment detection and achieves state-of-the-art performance. 2 Related Work Previous studies in ACSA task largely pay attention to straightforwardly extract the contextual sentiment for coarse-grained aspect categories. Wang et al. (2016) proposed an attention-based LSTM model for selectively attending the regions of the context representations. Xue and Li (2018) exploited a gated convolutional neural network to selectively extract aspect-specific sentiment information for sentiment prediction. Xing et al. (2019) explored an aspect-aware LSTM to incorporate aspect information into LSTM cells for ACSA. In multiIn the light of the knowledge base, vividly, a task learning methods, Li et al. (2020b) adopted word can connect or not to an aspect via various routes, the successful connection probability (cor- aspect category detection task to aggregate the sentiment for the aspect from the context. Chen et al. responding to the weight of an edge in a graph)"
2021.emnlp-main.19,2020.acl-main.291,1,0.768063,"etwork to model sibility based on the prior knowledge (routes and the inner- and inter-relations for aspects in senticonnection information) of external knowledge by means of Beta Distribution (Gupta and Nadarajah, ment prediction. 2004), which is the Conjugate prior distribution of In addition, to enhance the learning ability of the Binomial Distribution. In this way, all the proba- model, there are a series of studies that incorpobilities of aspect-aware words that connecting to rate external knowledge into the framework (Ma the aspect could be investigated, so as to determine et al., 2018; Zhang et al., 2020; Tian et al., 2020; the optimum confidence probability (weight) of Tong et al., 2020; Liang et al., 2021b). Among the aspect-aware word, called aspect-aware weight. them, Tian et al. (2020) modeled sentiment inSubsequently, we construct aspect-aware graph(s) formation at the word, polarity, and aspect level for each context with respect to the aspect based on into pre-trained sentiment representation in sentithe aspect-aware words paired with their weights. ment analysis based on the automatically-mined 209 Aspect-aware sentiment learning Aspect-aware words derivation Aspect-aware graphs cons"
2021.emnlp-main.19,D19-1464,0,0.0339371,"Missing"
2021.emnlp-main.210,D19-1641,0,0.243407,"representation r mc and type representation r t into a shared space by φ (r mc , A) : r mc → Ar mc θ (r t , B) : r t → Br t , (3) where A ∈ Rds ×2dm and B ∈ Rds ×dt are learnable matrices. The matching score is defined as yt = φ (r mc , A)·θ (r t , B) = (Ar mc )&gt; Br t (4) During training, we match mention m with all the types in Ttrain , so the loss function for m is: Type Hierarchy-Aware (HA) Module In HA module, we use Transformer encoder (Vaswani et al., 2017) with mask-self-attention to capture the hierarchical information for better type representations. Besides, we take the encoder from Lin and Ji (2019) to learn the features of mentions and contexts. Then a similarity function is defined to compute the matching score between a mention and a candidate type based on the context. 2.3.1 Mention-Context Encoder In the mention-context encoder, an entity mention and its context are represented as the weighted sum of their ELMo word representations. Then the mention representation r m and context representation r c are concatenated as the final representation: r mc = r m ⊕ r c , where r m , r c ∈ Rdm , r mc ∈ R2dm , ⊕ denotes concatenation. 2.3.2 Hierarchy-Aware Type Encoder Given a type set T = Ttr"
2021.emnlp-main.210,E17-1075,0,0.0550379,"Missing"
2021.emnlp-main.210,N19-1423,0,0.208547,"e is the surface form of a type, which is a word or a phase, e.g., type name of /organization/corporation is corporation. (ii) Type hierarchy is the ontology structure connecting seen and unseen types. (iii) Background knowledge provides the external prior information that depicts types in detail, e.g., prototypes (Ma et al., 2016) and descriptions (Obeidat et al., 2019). MSF is composed of three modules, with each targeting a specific information source. (i) In the CA (Context-Consistency Aware) module, we measure the context consistency by large-scale pretrained language models, e.g., BERT (Devlin et al., 2019). By masking mentions and predicting the names of ground truth types through finetuning on the data of seen types, CA is expected to measure the context consistency of unseen types more precisely. (ii) In the HA (Type-Hierarchy Aware) module, we use Transformer encoder (Vaswani et al., 2017) to model the hierarchical dependency among types. There have been substantial works exploring type hierarchy in the supervised typing task (Shimaoka et al., 2017; Xu and Barbosa, 2018; Xiong et al., 2019), but only some preliminary research in ZFET (Ma et al., 2016; Zhang et al., 2020b). (iii) In the KA (B"
2021.emnlp-main.210,D19-1488,0,0.0282879,"with regard to macro F1 scores. More importantly, we further discuss the characteristics, merits and demerits of each information source and provide an intuitive understanding of the complementarity among them. Source2: Type Hierarchy Government … Overall Loss Fusion ?????? ?????? ?????? CA HA KA <Northwest and Midway are two of the …, /organization/corporation&gt; Fine-grained entity typing (FET) aims to detect the types of an entity mention given its context (Abhishek et al., 2017; Xu and Barbosa, 2018; Jin et al., 2019). The results of FET benefit lots of downstream tasks (Chen et al., 2020; Hu et al., 2019; Zhang et al., 2020a; Liu et al., 2021; Chu et al., 2020). In many scenarios, the type hierarchy is continuously evolving, which requires newly emerged types to be accounted into FET systems. As a result, zero-shot FET (ZFET) is welcomed to handle the new types which are unseen during training stage (Ma et al., 2016; Ren et al., 2020; Zhang et al., 2020b). The major challenge of ZFET is to build the semantic connections between the seen types (during training) and the unseen ones (during inference). Corresponding Author … Prototypes: western_union, quebecor, merrill, rtc, … Description: a bus"
2021.emnlp-main.210,C16-1017,0,0.308687,"ay are two of the …, /organization/corporation&gt; Fine-grained entity typing (FET) aims to detect the types of an entity mention given its context (Abhishek et al., 2017; Xu and Barbosa, 2018; Jin et al., 2019). The results of FET benefit lots of downstream tasks (Chen et al., 2020; Hu et al., 2019; Zhang et al., 2020a; Liu et al., 2021; Chu et al., 2020). In many scenarios, the type hierarchy is continuously evolving, which requires newly emerged types to be accounted into FET systems. As a result, zero-shot FET (ZFET) is welcomed to handle the new types which are unseen during training stage (Ma et al., 2016; Ren et al., 2020; Zhang et al., 2020b). The major challenge of ZFET is to build the semantic connections between the seen types (during training) and the unseen ones (during inference). Corresponding Author … Prototypes: western_union, quebecor, merrill, rtc, … Description: a business firm whose articles of incorporation have been approved in some state. Introduction ∗ Corporation Source3: Background Knowledge [Mention] 1 Organization [Context] [Type] Figure 1: Illustration of the proposed multi-source fusion model (MSF). Auxiliary information has been proved to be essential in this regard ("
2021.emnlp-main.210,N19-1087,0,0.0138639,"seen types (during training) and the unseen ones (during inference). Corresponding Author … Prototypes: western_union, quebecor, merrill, rtc, … Description: a business firm whose articles of incorporation have been approved in some state. Introduction ∗ Corporation Source3: Background Knowledge [Mention] 1 Organization [Context] [Type] Figure 1: Illustration of the proposed multi-source fusion model (MSF). Auxiliary information has been proved to be essential in this regard (Xian et al., 2019), with a variety of approaches focused on scattered information (Ma et al., 2016; Zhou et al., 2018; Obeidat et al., 2019; Ren et al., 2020; Zhang et al., 2020b). However, the power of auxiliary information has not been sufficiently exploited in existing solutions. Besides, the effects of each information source also remain to be clearly understood. In this paper, we propose a Multi-Source Fusion model (MSF) integrating three kinds of popular auxiliary information for ZFET, i.e., context consistency, type hierarchy, and background knowledge, as illustrated in Figure 1. (i) Context consistency means a correct type should be se2668 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Process"
2021.emnlp-main.210,D16-1144,0,0.176978,"score vector from a module for mention m towards all types t ∈ Ttest with x as component. µx and σx denote the mean and standard deviation of the vector x. The final decision score by our fusion model for type t is: scoret = λ1 s0t + λ2 yt0 + λ3 p0t , (11) where λ1 , λ2 , λ3 ≥ 0 are hyper-parameters and λ1 + λ2 + λ3 = 1. 3 3.1 Experimental Setup Datasets and Evaluation Metrics We evaluate our model on two widely-used datasets: {˜ r mc , r˜ tp , r˜ td , r˜ h } = W {r mc , r tp , r td , r h } (6) BBN (Weischedel and Brunstein, 2005) and Wiki 2671 (Ling and Weld, 2012). The version processed by Ren et al. (2016) is adopted for our experiments. Detailed statistics on two datasets are listed in Table 1. We do not use OntoNotes (Gillick et al., 2014) since it is hard to define the name, description and hierarchy for its special type /other. Types of both BBN and Wiki are organized into a 2-level hierarchy. There are 47 types in BBN and 113 types in Wiki. Following Ma et al. (2016); Zhang et al. (2020b), we use the coarse-grained (Level-1) types such as /organization for training (denoted as seen types), while the fine-grained (Level-2) types such as /organization/corporation are reserved for testing (de"
2021.emnlp-main.210,E17-1119,0,0.0290272,"ource. (i) In the CA (Context-Consistency Aware) module, we measure the context consistency by large-scale pretrained language models, e.g., BERT (Devlin et al., 2019). By masking mentions and predicting the names of ground truth types through finetuning on the data of seen types, CA is expected to measure the context consistency of unseen types more precisely. (ii) In the HA (Type-Hierarchy Aware) module, we use Transformer encoder (Vaswani et al., 2017) to model the hierarchical dependency among types. There have been substantial works exploring type hierarchy in the supervised typing task (Shimaoka et al., 2017; Xu and Barbosa, 2018; Xiong et al., 2019), but only some preliminary research in ZFET (Ma et al., 2016; Zhang et al., 2020b). (iii) In the KA (Background-Knowledge Aware) module, we introduce prototypes (Ma et al., 2016) and WordNet descriptions (Miller, 1995) as background knowledge of types. KA is embodied as natural language inference with a translation-based solution to better incorporate knowledge. Extensive experiments are carried out to verify the effectiveness of the proposed fusion model. We also conduct a deep analysis on the characteristics, merits and demerits of each information"
2021.emnlp-main.210,D19-1502,0,0.0474529,"Missing"
2021.emnlp-main.210,I17-1011,0,0.0226177,"in the KA module. Prototypes refer to the carefully selected mentions for a type based on Normalized Point-wise Mutual Information (NPMI), which provide a mention-level summary for types (Ma et al., 2016). Descriptions are queried from WordNet glosses (Miller, 1995) by type names, which provide a brief high-level summary for each type. 2.4.1 Inference from Background Knowledge We hope to infer whether a mention m matches a candidate type t, given the prototypes, type description and the context. In this work, we embody the KA module as natural language inference (NLI) from multiple premises (Lai et al., 2017). An ex1 The initialization details are presented in Appendix A ample is presented in Figure 2, with input the same 2670 Multiple Premises • • • Context-based premise: Northwest and Midway are two of the five airlines with which Budget has agreements. Prototypes-based premise: /organization/corporation has the following prototypes: western_union, … Description-based premise: /organization/corporation denotes a collection of business firms whose articles of incorporation have been approved in some state. where W ∈ Rdw ×2dm . We hope that r˜ mc + r˜ tp + r˜ td ≈ r˜ h when the hypothesis can be i"
2021.emnlp-main.210,D18-1121,0,0.0337611,"Missing"
2021.emnlp-main.210,N19-1084,0,0.0349593,"Missing"
2021.emnlp-main.210,N18-1002,0,0.0124422,"ontext-Consistency Aware) module, we measure the context consistency by large-scale pretrained language models, e.g., BERT (Devlin et al., 2019). By masking mentions and predicting the names of ground truth types through finetuning on the data of seen types, CA is expected to measure the context consistency of unseen types more precisely. (ii) In the HA (Type-Hierarchy Aware) module, we use Transformer encoder (Vaswani et al., 2017) to model the hierarchical dependency among types. There have been substantial works exploring type hierarchy in the supervised typing task (Shimaoka et al., 2017; Xu and Barbosa, 2018; Xiong et al., 2019), but only some preliminary research in ZFET (Ma et al., 2016; Zhang et al., 2020b). (iii) In the KA (Background-Knowledge Aware) module, we introduce prototypes (Ma et al., 2016) and WordNet descriptions (Miller, 1995) as background knowledge of types. KA is embodied as natural language inference with a translation-based solution to better incorporate knowledge. Extensive experiments are carried out to verify the effectiveness of the proposed fusion model. We also conduct a deep analysis on the characteristics, merits and demerits of each information source. We find that,"
2021.emnlp-main.210,2020.coling-main.7,0,0.102233,"acro F1 scores. More importantly, we further discuss the characteristics, merits and demerits of each information source and provide an intuitive understanding of the complementarity among them. Source2: Type Hierarchy Government … Overall Loss Fusion ?????? ?????? ?????? CA HA KA <Northwest and Midway are two of the …, /organization/corporation&gt; Fine-grained entity typing (FET) aims to detect the types of an entity mention given its context (Abhishek et al., 2017; Xu and Barbosa, 2018; Jin et al., 2019). The results of FET benefit lots of downstream tasks (Chen et al., 2020; Hu et al., 2019; Zhang et al., 2020a; Liu et al., 2021; Chu et al., 2020). In many scenarios, the type hierarchy is continuously evolving, which requires newly emerged types to be accounted into FET systems. As a result, zero-shot FET (ZFET) is welcomed to handle the new types which are unseen during training stage (Ma et al., 2016; Ren et al., 2020; Zhang et al., 2020b). The major challenge of ZFET is to build the semantic connections between the seen types (during training) and the unseen ones (during inference). Corresponding Author … Prototypes: western_union, quebecor, merrill, rtc, … Description: a business firm whose art"
2021.emnlp-main.210,D18-1231,0,0.0133239,"ctions between the seen types (during training) and the unseen ones (during inference). Corresponding Author … Prototypes: western_union, quebecor, merrill, rtc, … Description: a business firm whose articles of incorporation have been approved in some state. Introduction ∗ Corporation Source3: Background Knowledge [Mention] 1 Organization [Context] [Type] Figure 1: Illustration of the proposed multi-source fusion model (MSF). Auxiliary information has been proved to be essential in this regard (Xian et al., 2019), with a variety of approaches focused on scattered information (Ma et al., 2016; Zhou et al., 2018; Obeidat et al., 2019; Ren et al., 2020; Zhang et al., 2020b). However, the power of auxiliary information has not been sufficiently exploited in existing solutions. Besides, the effects of each information source also remain to be clearly understood. In this paper, we propose a Multi-Source Fusion model (MSF) integrating three kinds of popular auxiliary information for ZFET, i.e., context consistency, type hierarchy, and background knowledge, as illustrated in Figure 1. (i) Context consistency means a correct type should be se2668 Proceedings of the 2021 Conference on Empirical Methods in Na"
2021.emnlp-main.23,P82-1020,0,0.712871,"Missing"
2021.emnlp-main.23,2020.acl-main.631,0,0.158491,"en Institute of Advanced Technology, Chinese Academy of Sciences 3 Peng Cheng Laboratory, Shenzhen, China qlwang15@outlook.com, wenzhiyuan2012@gmail.com zhaoqin@hit.edu.cn min.yang@siat.ac.cn, xuruifeng@hit.edu.cn Abstract training data. However, labeling a large amount of aspect data may not be practical due to its cost. Aspect term extraction aims to extract aspect The other aims at addressing the data insuffiterms from a review sentence that users have ciency issue from a different perspective. For exexpressed opinions on. One of the remaining challenges for aspect term extraction reample, Li et al. (2020) generated the reviews while sides in the lack of sufficient annotated data. preserving the original aspects via formulating the While self-training is potentially an effective data augmentation as a conditional generation task. method to address this issue, the pseudo-labels However, varying only a small number of consecit yields on unlabeled data could induce noise. utive non-aspect words in the reviews would limit In this paper, we use two means to alleviate the semantic diversity of the sample. Chen and the noise in the pseudo-labels. One is that inQian (2020) tackled long-tail distributio"
2021.emnlp-main.23,D17-1310,0,0.0146511,"{Du/i }Ti=1 , we set T to 4; and for each subset size, we set |Du/i |= i ∗ 1k. We run all experiments in a single Tesla V100S GPU. 4.3 Baselines To evaluate the effectiveness of our method, we compare it with four groups of baselines. The first group of baselines are the SemEval winners. IHSRD (Chernyshevich, 2014), DLIREC (Toh and Wang, 2014), EliXa (San Vicente et al., 2015) and NLANGP (Toh and Su, 2016) are the winners for Lap14, Res14, Res15, and Res16 datasets, respectively. The second group of baselines generally employs neural networks with complex structures to solve ATE, such as MIN (Li and Lam, 2017), HAST (Li et al., 2018), Seq2Seq4ATE (Ma et al., 2019), DECNN (Xu et al., 2018), and CLATE (Yang et al., 2020). The third group of baselines aims to tackle the problem of insufficient annotated data, such as conditional data augmentation (CDA) (Li et al., 2020) and soft prototype trained on external data (SoftProtoE) (Chen and Qian, 2020). The last group of baselines is our customized model for clear comparison. BiLSTM(BERT, BERT-PT)TC uses the BiLSTM (pre-trained BERT, posttrained BERT-PT (Xu et al., 2019)) with a linear layer for token classification. BERT-RC (Mao et al., 2021) treats ATE a"
2021.emnlp-main.23,P14-1033,0,0.079392,"Missing"
2021.emnlp-main.23,2020.emnlp-main.164,0,0.0920577,"nts to verify its effectiveness and generalization. to ATE, such as LSTM (Liu et al., 2015), CNN (Xu et al., 2018), Attention (Li et al., 2018), BERT (Xu et al., 2019), and constituency parsing (Yang et al., 2020). A recent trend is towards the unified framework (Li et al., 2019; Mao et al., 2021). So far, one of the remaining challenges for ATE is the insufficient of annotated data, especially as neural models become more large and more complex. To address this issue, Li et al. (2020) presented a conditional data augmentation approach for ATE. In addition, to solve the data sparsity problem, Chen and Qian (2020) introduced soft prototypes trained by internal or external data. In this paper, we focus on the the insufficient of labeled data scenario, and alleviate it via self-training and unlabeled data. 2 3 Related Work Self-training The self-training proposed by Scudder (1965) is a semi-supervised approach that leverages unlabeled data to create better models. Self-training first trains a base model on a small amount of labeled data; then utilizes it to pseudolabel unlabeled data, and uses pseudo-labels data to augment the labeled data; finally iteratively retrains the model. Recently, it yields stat"
2021.emnlp-main.23,N19-1423,0,0.0202406,"e = gi[byi ] n i (3) where gi ∈ R3 is the logit vector of the token xi , and gi[byi ] is a logit value corresponding to prediction ybi . degree indicates the difficultness of the sample, and the larger the value the easier the sample is. In addition, we find that the progressive subset size is kept incremental in favor of performance improvement. 3.3 3.5 3.2 Overview Aspect Term Extraction Model We formulate ATE as a token-level classification task, where for each token xi in the sentence, our ATE model assigns a label yi . Our ATE model uses BiLSTM (Hochreiter and Schmidhuber, 1997) or BERT (Devlin et al., 2019) as encoder. The encoder takes a sequence of tokens as input, and produces a sequence of contextual hidden states. To obtain Discriminator Intuitively, filtering out all the noise in the pseudolabels accurately and automatically is not quite realistic. We can only filter the noise as much as possible, and to this end, a discriminator is introduced. It makes a true-false determination for each of the inferred aspect terms based on the corresponding contextual. Subsequently, we evaluate 259 whether the sample is suitable for re-training the base model based on the discrimination results of all a"
2021.emnlp-main.23,D12-1123,0,0.0128619,"-training method focuses on easier samples in the early stage, and uses hard samples in the later stage. Our aim is to reduce the noise in the pseudo-labels: the pseudolabels for easy examples are less prone to errors, and model that have been previously learned could yield more accurate pseudo-labels at later stage. Method Aspect Term Extraction Earlier research en- 3.1 Problem Formulation deavors focused on exploiting pre-defined rules Given a token sequence x = {x1 , x2 , ......, xn } (Hu and Liu, 2004; Wu et al., 2009), hand-craft fea- of length n, the ATE task can be characterized tures (Liu et al., 2012), or prior knowledge (Chen as a token-level classification problem. The ATE et al., 2014) to solve ATE. Recently, researchers model takes x as input and outputs a label sequence employed some deep learning and parse techniques y = {y1 , y2 , ......, yn }, where yi ∈ {B, I, O} is 258 Dividing unlabeled dataset ?? into progressive subsets {??/? }? for curriculum learning Train ATE model with labeled dataset ? Train discriminator with labeled dataset ? and filtered pseudolabeled data Infer pseudo-labels on unlabeled data ??/? Use discriminator to filter noisy pseudolabels Re-train ATE model with"
2021.emnlp-main.23,D15-1168,0,0.0173984,"he following contributions: (a) To the best of our knowledge, we are the first to use self-training to address the problem of insufficient labeled data in ATE; (b) To mitigate the noise introduced by self-training, we refine the general self-training to progressive self-training and bring in a discriminator to filter the noisy pseudo-labels; (c) Experimental results on four ATE datasets show that our method outperforms the baselines and achieves the state-of-the-art performance. Furthermore, we conduct extensive experiments to verify its effectiveness and generalization. to ATE, such as LSTM (Liu et al., 2015), CNN (Xu et al., 2018), Attention (Li et al., 2018), BERT (Xu et al., 2019), and constituency parsing (Yang et al., 2020). A recent trend is towards the unified framework (Li et al., 2019; Mao et al., 2021). So far, one of the remaining challenges for ATE is the insufficient of annotated data, especially as neural models become more large and more complex. To address this issue, Li et al. (2020) presented a conditional data augmentation approach for ATE. In addition, to solve the data sparsity problem, Chen and Qian (2020) introduced soft prototypes trained by internal or external data. In th"
2021.emnlp-main.23,P19-1344,0,0.0492095,"ulated ATE as a refine the conventional self-training to progressive sequence labeling problem or a token-level classi- self-training. Here, we use a progressive subset at fication problem. The current state-of-the-art neu- each iteration instead of the entire unlabeled data ral models can be classified into two categories. set. During the iterative process, the unlabeled One designs the sophisticated model with a variety samples in the subset become harder and more nuof techniques, such as history attention (Li et al., merous. Our motivation stems from curriculum 2018), sequence to sequence (Ma et al., 2019), and learning (Bengio et al., 2009), where we expect to constituency lattice (Yang et al., 2020). Although infer pseudo-labels for unlabeled data in the order these models achieve satisfactory performance, its of easy to hard and few to many. In this process, sufficient condition is the availability of sufficient easy unlabeled data will bring in little noise, and ∗ Corresponding author. model that have been previously learned will be 257 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 257–268 c November 7–11, 2021. 2021 Association for Computatio"
2021.emnlp-main.23,D14-1162,0,0.0851235,"tively. We select the first 2,754 and 6,754 samples from Amazon Cell Phones and Accessories dataset2 (He and McAuley, 2016) and Yelp Review dataset3 (Zhang et al., 2015), respectively. The former is treated as unlabeled data in the laptop domain, while the latter is considered as unlabeled data in the restaurant domain. After these samples are preprocessed4 , we can obtain 10k unlabeled data. 4.2 Implementation Details We choose two representative encoders (BiLSTM and BERT) as the backbone to implement our method5 . For BiLSTM encoder, the word embeddings are initialized with GloVe-840B-300d (Pennington et al., 2014). The hidden size is set to 300, and we use Adam (Kingma and Ba, 2014) with the learning rate of 1e-4 to optimize parameters. For BERT encoder, we use the BERTbase with 12 attention heads, 12 hidden layers and the hidden size of 768, resulting into 110M pretrained parameters. During the fine-tuning process, we employ AdamW (Loshchilov and Hutter, 2018) to optimize parameters. The learning rates are 3e-5 and 3e-4 for the pre-trained parameters and the added parameters, respectively. In addition, we set batch size to 48 and dropout rate to 0.1. For the progressive set {Du/i }Ti=1 , we set T to 4"
2021.emnlp-main.23,S16-1002,0,0.0669978,"Missing"
2021.emnlp-main.23,S15-2082,0,0.0738727,"Missing"
2021.emnlp-main.23,S14-2004,0,0.0416513,"discriminator fdis using Dd via Eq. 4 5: for each subset Du/i in Du do use fAT E to infer pseudo-labels on Du/i via Eq. 2, 6: thus Du/i = {(˜ xi , ybi )}i use fdis to filter the noise in the pseudo-labels via 7: 0 Eq. 5, and obtain Du/i ∈ Du/i 0 8: 9: 10: 11: 12: 13: 4 4.1 Df u += Du/i Dd += {(˜ xi , a ˜i , y˜i )}i by synthesizing positive and 0 negative samples from Du/i train a new base model fAT E by pre-training on Df u and fine-tuning on D via Eq. 1 retrain fdis using Dd via Eq. 4 end for return fAT E Experiments Datasets We conduct experiments on four datasets from SemEval 2014 Task 4 (Pontiki et al., 2014), SemEval 2015 Task 12 (Pontiki et al., 2015), and SemEval 2016 Task 5 (Pontiki et al., 2016). Statistics of the datasets are presented in Table 2. In addition, as 3.6 Training Xu et al. (2018) did, we randomly hold out 150 We first train a base model on labeled data and use examples from the train set as the validation set for the average logit from the base model to partition tuning hyper-parameters. We employ the F1 metric 1 We use NLTK to derive the POS tag of each token. to evaluate the performance of the models. 260 #Sent #Aspect Lap14 train test 3045 800 2342 650 Res14 train test 3041 8"
2021.emnlp-main.23,S15-2127,0,0.0230154,"hilov and Hutter, 2018) to optimize parameters. The learning rates are 3e-5 and 3e-4 for the pre-trained parameters and the added parameters, respectively. In addition, we set batch size to 48 and dropout rate to 0.1. For the progressive set {Du/i }Ti=1 , we set T to 4; and for each subset size, we set |Du/i |= i ∗ 1k. We run all experiments in a single Tesla V100S GPU. 4.3 Baselines To evaluate the effectiveness of our method, we compare it with four groups of baselines. The first group of baselines are the SemEval winners. IHSRD (Chernyshevich, 2014), DLIREC (Toh and Wang, 2014), EliXa (San Vicente et al., 2015) and NLANGP (Toh and Su, 2016) are the winners for Lap14, Res14, Res15, and Res16 datasets, respectively. The second group of baselines generally employs neural networks with complex structures to solve ATE, such as MIN (Li and Lam, 2017), HAST (Li et al., 2018), Seq2Seq4ATE (Ma et al., 2019), DECNN (Xu et al., 2018), and CLATE (Yang et al., 2020). The third group of baselines aims to tackle the problem of insufficient annotated data, such as conditional data augmentation (CDA) (Li et al., 2020) and soft prototype trained on external data (SoftProtoE) (Chen and Qian, 2020). The last group of b"
2021.emnlp-main.23,S16-1045,0,0.0152073,"e parameters. The learning rates are 3e-5 and 3e-4 for the pre-trained parameters and the added parameters, respectively. In addition, we set batch size to 48 and dropout rate to 0.1. For the progressive set {Du/i }Ti=1 , we set T to 4; and for each subset size, we set |Du/i |= i ∗ 1k. We run all experiments in a single Tesla V100S GPU. 4.3 Baselines To evaluate the effectiveness of our method, we compare it with four groups of baselines. The first group of baselines are the SemEval winners. IHSRD (Chernyshevich, 2014), DLIREC (Toh and Wang, 2014), EliXa (San Vicente et al., 2015) and NLANGP (Toh and Su, 2016) are the winners for Lap14, Res14, Res15, and Res16 datasets, respectively. The second group of baselines generally employs neural networks with complex structures to solve ATE, such as MIN (Li and Lam, 2017), HAST (Li et al., 2018), Seq2Seq4ATE (Ma et al., 2019), DECNN (Xu et al., 2018), and CLATE (Yang et al., 2020). The third group of baselines aims to tackle the problem of insufficient annotated data, such as conditional data augmentation (CDA) (Li et al., 2020) and soft prototype trained on external data (SoftProtoE) (Chen and Qian, 2020). The last group of baselines is our customized mod"
2021.emnlp-main.23,S14-2038,0,0.0210866,"process, we employ AdamW (Loshchilov and Hutter, 2018) to optimize parameters. The learning rates are 3e-5 and 3e-4 for the pre-trained parameters and the added parameters, respectively. In addition, we set batch size to 48 and dropout rate to 0.1. For the progressive set {Du/i }Ti=1 , we set T to 4; and for each subset size, we set |Du/i |= i ∗ 1k. We run all experiments in a single Tesla V100S GPU. 4.3 Baselines To evaluate the effectiveness of our method, we compare it with four groups of baselines. The first group of baselines are the SemEval winners. IHSRD (Chernyshevich, 2014), DLIREC (Toh and Wang, 2014), EliXa (San Vicente et al., 2015) and NLANGP (Toh and Su, 2016) are the winners for Lap14, Res14, Res15, and Res16 datasets, respectively. The second group of baselines generally employs neural networks with complex structures to solve ATE, such as MIN (Li and Lam, 2017), HAST (Li et al., 2018), Seq2Seq4ATE (Ma et al., 2019), DECNN (Xu et al., 2018), and CLATE (Yang et al., 2020). The third group of baselines aims to tackle the problem of insufficient annotated data, such as conditional data augmentation (CDA) (Li et al., 2020) and soft prototype trained on external data (SoftProtoE) (Chen an"
2021.emnlp-main.23,D09-1159,0,0.0759374,"is a common strategy in curriculum learning (Bengio et al., 2009). Our progressive self-training method focuses on easier samples in the early stage, and uses hard samples in the later stage. Our aim is to reduce the noise in the pseudo-labels: the pseudolabels for easy examples are less prone to errors, and model that have been previously learned could yield more accurate pseudo-labels at later stage. Method Aspect Term Extraction Earlier research en- 3.1 Problem Formulation deavors focused on exploiting pre-defined rules Given a token sequence x = {x1 , x2 , ......, xn } (Hu and Liu, 2004; Wu et al., 2009), hand-craft fea- of length n, the ATE task can be characterized tures (Liu et al., 2012), or prior knowledge (Chen as a token-level classification problem. The ATE et al., 2014) to solve ATE. Recently, researchers model takes x as input and outputs a label sequence employed some deep learning and parse techniques y = {y1 , y2 , ......, yn }, where yi ∈ {B, I, O} is 258 Dividing unlabeled dataset ?? into progressive subsets {??/? }? for curriculum learning Train ATE model with labeled dataset ? Train discriminator with labeled dataset ? and filtered pseudolabeled data Infer pseudo-labels on un"
2021.emnlp-main.23,P18-2094,0,0.163112,"ns: (a) To the best of our knowledge, we are the first to use self-training to address the problem of insufficient labeled data in ATE; (b) To mitigate the noise introduced by self-training, we refine the general self-training to progressive self-training and bring in a discriminator to filter the noisy pseudo-labels; (c) Experimental results on four ATE datasets show that our method outperforms the baselines and achieves the state-of-the-art performance. Furthermore, we conduct extensive experiments to verify its effectiveness and generalization. to ATE, such as LSTM (Liu et al., 2015), CNN (Xu et al., 2018), Attention (Li et al., 2018), BERT (Xu et al., 2019), and constituency parsing (Yang et al., 2020). A recent trend is towards the unified framework (Li et al., 2019; Mao et al., 2021). So far, one of the remaining challenges for ATE is the insufficient of annotated data, especially as neural models become more large and more complex. To address this issue, Li et al. (2020) presented a conditional data augmentation approach for ATE. In addition, to solve the data sparsity problem, Chen and Qian (2020) introduced soft prototypes trained by internal or external data. In this paper, we focus on t"
2021.emnlp-main.23,N19-1242,0,0.106452,"t to use self-training to address the problem of insufficient labeled data in ATE; (b) To mitigate the noise introduced by self-training, we refine the general self-training to progressive self-training and bring in a discriminator to filter the noisy pseudo-labels; (c) Experimental results on four ATE datasets show that our method outperforms the baselines and achieves the state-of-the-art performance. Furthermore, we conduct extensive experiments to verify its effectiveness and generalization. to ATE, such as LSTM (Liu et al., 2015), CNN (Xu et al., 2018), Attention (Li et al., 2018), BERT (Xu et al., 2019), and constituency parsing (Yang et al., 2020). A recent trend is towards the unified framework (Li et al., 2019; Mao et al., 2021). So far, one of the remaining challenges for ATE is the insufficient of annotated data, especially as neural models become more large and more complex. To address this issue, Li et al. (2020) presented a conditional data augmentation approach for ATE. In addition, to solve the data sparsity problem, Chen and Qian (2020) introduced soft prototypes trained by internal or external data. In this paper, we focus on the the insufficient of labeled data scenario, and all"
2021.emnlp-main.23,2020.coling-main.73,0,0.231482,"or a token-level classi- self-training. Here, we use a progressive subset at fication problem. The current state-of-the-art neu- each iteration instead of the entire unlabeled data ral models can be classified into two categories. set. During the iterative process, the unlabeled One designs the sophisticated model with a variety samples in the subset become harder and more nuof techniques, such as history attention (Li et al., merous. Our motivation stems from curriculum 2018), sequence to sequence (Ma et al., 2019), and learning (Bengio et al., 2009), where we expect to constituency lattice (Yang et al., 2020). Although infer pseudo-labels for unlabeled data in the order these models achieve satisfactory performance, its of easy to hard and few to many. In this process, sufficient condition is the availability of sufficient easy unlabeled data will bring in little noise, and ∗ Corresponding author. model that have been previously learned will be 257 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 257–268 c November 7–11, 2021. 2021 Association for Computational Linguistics better and thus generate less noise at later stages. The other is to use a discri"
2021.emnlp-main.319,D19-1291,0,0.0740369,"tion mining has received increasing re- APE, and have also been exploited in other tasks search attention in recent years. Existing studies (Hua et al., 2019b; Fromm et al., 2020). can be categorized into monological argumentation Cheng et al. (2020) proposed to tackle APE by (Stab and Gurevych, 2014; Eger et al., 2017; Potash decomposing it into a sequence labeling task and a et al., 2017; Kuribayashi et al., 2019) and dialog- sentence relation classification task, with the first ical argumentation (Swanson et al., 2015; Morio subtask extracting the arguments in each review and Fujita, 2018; Chakrabarty et al., 2019), with or rebuttal, and the second subtask determining the former identifying the argumentation structure whether two sentences belong to the same pair of of a single monological document, and the latter fo- arguments. These two subtasks are jointly opti∗ Corresponding Author mized within a multi-task learning framework, and 3923 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 3923–3934 c November 7–11, 2021. 2021 Association for Computational Linguistics Sent Review This work applies convolutional neural networks to Sent-1 the task of RGB-D indoor"
2021.emnlp-main.319,D18-1069,1,0.836801,"tion, According to Figure 4(b), we find that it is most such as argumentation structure parsing(Stab and 3930 Gurevych, 2017; Afantenos et al., 2018; Kuribayashi et al., 2019; Hua et al., 2019b; Morio et al., 2020), automated essay scoring(Wachsmuth et al., 2016; Ke et al., 2018; Song et al., 2020), argument quality assessment(Wachsmuth et al., 2017; Gretz et al., 2020; Lauscher et al., 2020), argumentation strategies modeling(Khatib et al., 2016, 2017), etc. Since real-life argumentation is usually in the form of dialogue, some prior work focuses on dialogical argumentation. Morio and Fujita (2018) employed a pointer network to predict argumentation structures in discussion threads. Chakrabarty et al. (2019) studied the relations between argument components in online discussion forums with pre-trained models and discourse relations. Ji et al. (2019) proposed a discrete argument representation learning method to extract argument pairs. However, these studies above assumed that the boundaries of arguments have been given. Recently, Cheng et al. (2020) present a new task named argument pair extraction, which is more challenging as it requires both identifying arguments from plain text and"
2021.emnlp-main.319,2020.emnlp-main.569,0,0.424648,"results show mentation and can also support other related tasks, that our approach significantly outperforms such as argument generation (Hua et al., 2019a) the current state-of-the-art model. and debate summarization (Chowanda et al., 2017). Due to the rich interaction of complex arguments, 1 Introduction peer review and rebuttal are perfect resources for Argumentation mining has received increasing re- APE, and have also been exploited in other tasks search attention in recent years. Existing studies (Hua et al., 2019b; Fromm et al., 2020). can be categorized into monological argumentation Cheng et al. (2020) proposed to tackle APE by (Stab and Gurevych, 2014; Eger et al., 2017; Potash decomposing it into a sequence labeling task and a et al., 2017; Kuribayashi et al., 2019) and dialog- sentence relation classification task, with the first ical argumentation (Swanson et al., 2015; Morio subtask extracting the arguments in each review and Fujita, 2018; Chakrabarty et al., 2019), with or rebuttal, and the second subtask determining the former identifying the argumentation structure whether two sentences belong to the same pair of of a single monological document, and the latter fo- arguments. These"
2021.emnlp-main.319,N19-1423,0,0.00674272,"the adjacency matrix A ∈ R(m+n)×(m+n) of ISRG can be derived as:   ω I (si , sj ) si , sj ∈ V    ω I (s , s ) s , s ∈ B i j i j Aij = (3) C  ω (si , sj ) si ∈ V, sj ∈ B    ω C (s , s ) s ∈ B, s ∈ V i j i j 3.2 Mutual Guidance Framework Our proposed Mutually Guided Framework (MGF) first encodes the sentences and employs a nonguided sequence tagger to identify the arguments in the review and rebuttal. Then, after obtaining a relation-oriented sentence representation by graph convolution, two mutually guided taggers are used to extract argument pairs. Sentence Encoder. We apply BERT (Devlin et al., 2019) to obtain the representation of each sentence and use LSTM (Hochreiter and Schmidhuber, 1997) to encode the contextual long-term dependencies of sentences. Specifically, for each sentence si from V or B, we feed it into BERT and get the sentence embedding ei ∈ Rdb by mean pooling over all token representations, where db is the vector dimension of the last layer of BERT. Hence, the sentences in V and B can be represented as V = (ev1 , ev2 , . . . , evm ) and B = (eb1 , eb2 , . . . , ebn ). Subsequently, V and B are separately fed into a bidirectional LSTM (BiLSTM), and the hidden states from b"
2021.emnlp-main.319,P17-1002,0,0.0195667,"ur approach significantly outperforms such as argument generation (Hua et al., 2019a) the current state-of-the-art model. and debate summarization (Chowanda et al., 2017). Due to the rich interaction of complex arguments, 1 Introduction peer review and rebuttal are perfect resources for Argumentation mining has received increasing re- APE, and have also been exploited in other tasks search attention in recent years. Existing studies (Hua et al., 2019b; Fromm et al., 2020). can be categorized into monological argumentation Cheng et al. (2020) proposed to tackle APE by (Stab and Gurevych, 2014; Eger et al., 2017; Potash decomposing it into a sequence labeling task and a et al., 2017; Kuribayashi et al., 2019) and dialog- sentence relation classification task, with the first ical argumentation (Swanson et al., 2015; Morio subtask extracting the arguments in each review and Fujita, 2018; Chakrabarty et al., 2019), with or rebuttal, and the second subtask determining the former identifying the argumentation structure whether two sentences belong to the same pair of of a single monological document, and the latter fo- arguments. These two subtasks are jointly opti∗ Corresponding Author mized within a mul"
2021.emnlp-main.319,P19-1255,0,0.151481,"arguments relations between two sentences and thus facan be complicated, for example, one argument cilitates the extraction of argument pairs. Our proposed method can better represent the holismay be paired with multiple other arguments, formtic argument-level semantics and thus explicing one-to-many relations. This task is essential itly capture the complex correlations between for understanding the structure of dialogical arguargument pairs. Experimental results show mentation and can also support other related tasks, that our approach significantly outperforms such as argument generation (Hua et al., 2019a) the current state-of-the-art model. and debate summarization (Chowanda et al., 2017). Due to the rich interaction of complex arguments, 1 Introduction peer review and rebuttal are perfect resources for Argumentation mining has received increasing re- APE, and have also been exploited in other tasks search attention in recent years. Existing studies (Hua et al., 2019b; Fromm et al., 2020). can be categorized into monological argumentation Cheng et al. (2020) proposed to tackle APE by (Stab and Gurevych, 2014; Eger et al., 2017; Potash decomposing it into a sequence labeling task and a et al."
2021.emnlp-main.319,N19-1219,0,0.106716,"arguments relations between two sentences and thus facan be complicated, for example, one argument cilitates the extraction of argument pairs. Our proposed method can better represent the holismay be paired with multiple other arguments, formtic argument-level semantics and thus explicing one-to-many relations. This task is essential itly capture the complex correlations between for understanding the structure of dialogical arguargument pairs. Experimental results show mentation and can also support other related tasks, that our approach significantly outperforms such as argument generation (Hua et al., 2019a) the current state-of-the-art model. and debate summarization (Chowanda et al., 2017). Due to the rich interaction of complex arguments, 1 Introduction peer review and rebuttal are perfect resources for Argumentation mining has received increasing re- APE, and have also been exploited in other tasks search attention in recent years. Existing studies (Hua et al., 2019b; Fromm et al., 2020). can be categorized into monological argumentation Cheng et al. (2020) proposed to tackle APE by (Stab and Gurevych, 2014; Eger et al., 2017; Potash decomposing it into a sequence labeling task and a et al."
2021.emnlp-main.319,D17-1141,0,0.0546025,"Missing"
2021.emnlp-main.319,W18-5202,0,0.0172394,"logical argumentation, According to Figure 4(b), we find that it is most such as argumentation structure parsing(Stab and 3930 Gurevych, 2017; Afantenos et al., 2018; Kuribayashi et al., 2019; Hua et al., 2019b; Morio et al., 2020), automated essay scoring(Wachsmuth et al., 2016; Ke et al., 2018; Song et al., 2020), argument quality assessment(Wachsmuth et al., 2017; Gretz et al., 2020; Lauscher et al., 2020), argumentation strategies modeling(Khatib et al., 2016, 2017), etc. Since real-life argumentation is usually in the form of dialogue, some prior work focuses on dialogical argumentation. Morio and Fujita (2018) employed a pointer network to predict argumentation structures in discussion threads. Chakrabarty et al. (2019) studied the relations between argument components in online discussion forums with pre-trained models and discourse relations. Ji et al. (2019) proposed a discrete argument representation learning method to extract argument pairs. However, these studies above assumed that the boundaries of arguments have been given. Recently, Cheng et al. (2020) present a new task named argument pair extraction, which is more challenging as it requires both identifying arguments from plain text and"
2021.emnlp-main.319,C16-1324,0,0.0421412,"Missing"
2021.emnlp-main.319,2020.acl-main.298,0,0.125041,"our observation in Table 1 that the average number of sentences contained in each argument is 3.1. Since the majority of arguments contain a small number 6 Related Work of sentences, we should not connect two sentences that have a long distance. Otherwise, the semantic Most existing studies in the field of argumenrepresentation of arguments will be distorted. taion mining focus on monological argumentation, According to Figure 4(b), we find that it is most such as argumentation structure parsing(Stab and 3930 Gurevych, 2017; Afantenos et al., 2018; Kuribayashi et al., 2019; Hua et al., 2019b; Morio et al., 2020), automated essay scoring(Wachsmuth et al., 2016; Ke et al., 2018; Song et al., 2020), argument quality assessment(Wachsmuth et al., 2017; Gretz et al., 2020; Lauscher et al., 2020), argumentation strategies modeling(Khatib et al., 2016, 2017), etc. Since real-life argumentation is usually in the form of dialogue, some prior work focuses on dialogical argumentation. Morio and Fujita (2018) employed a pointer network to predict argumentation structures in discussion threads. Chakrabarty et al. (2019) studied the relations between argument components in online discussion forums with pre-trained"
2021.emnlp-main.319,P19-1464,0,0.173341,"urrent state-of-the-art model. and debate summarization (Chowanda et al., 2017). Due to the rich interaction of complex arguments, 1 Introduction peer review and rebuttal are perfect resources for Argumentation mining has received increasing re- APE, and have also been exploited in other tasks search attention in recent years. Existing studies (Hua et al., 2019b; Fromm et al., 2020). can be categorized into monological argumentation Cheng et al. (2020) proposed to tackle APE by (Stab and Gurevych, 2014; Eger et al., 2017; Potash decomposing it into a sequence labeling task and a et al., 2017; Kuribayashi et al., 2019) and dialog- sentence relation classification task, with the first ical argumentation (Swanson et al., 2015; Morio subtask extracting the arguments in each review and Fujita, 2018; Chakrabarty et al., 2019), with or rebuttal, and the second subtask determining the former identifying the argumentation structure whether two sentences belong to the same pair of of a single monological document, and the latter fo- arguments. These two subtasks are jointly opti∗ Corresponding Author mized within a multi-task learning framework, and 3923 Proceedings of the 2021 Conference on Empirical Methods in Nat"
2021.emnlp-main.319,2020.coling-main.402,0,0.0161092,"ces, we should not connect two sentences that have a long distance. Otherwise, the semantic Most existing studies in the field of argumenrepresentation of arguments will be distorted. taion mining focus on monological argumentation, According to Figure 4(b), we find that it is most such as argumentation structure parsing(Stab and 3930 Gurevych, 2017; Afantenos et al., 2018; Kuribayashi et al., 2019; Hua et al., 2019b; Morio et al., 2020), automated essay scoring(Wachsmuth et al., 2016; Ke et al., 2018; Song et al., 2020), argument quality assessment(Wachsmuth et al., 2017; Gretz et al., 2020; Lauscher et al., 2020), argumentation strategies modeling(Khatib et al., 2016, 2017), etc. Since real-life argumentation is usually in the form of dialogue, some prior work focuses on dialogical argumentation. Morio and Fujita (2018) employed a pointer network to predict argumentation structures in discussion threads. Chakrabarty et al. (2019) studied the relations between argument components in online discussion forums with pre-trained models and discourse relations. Ji et al. (2019) proposed a discrete argument representation learning method to extract argument pairs. However, these studies above assumed that the"
2021.emnlp-main.319,2020.coling-main.13,1,0.828487,"Missing"
2021.emnlp-main.319,D17-1143,0,0.0568212,"Missing"
2021.emnlp-main.319,P19-1617,0,0.0560346,"Missing"
2021.emnlp-main.319,C14-1142,0,0.0298798,"her related tasks, that our approach significantly outperforms such as argument generation (Hua et al., 2019a) the current state-of-the-art model. and debate summarization (Chowanda et al., 2017). Due to the rich interaction of complex arguments, 1 Introduction peer review and rebuttal are perfect resources for Argumentation mining has received increasing re- APE, and have also been exploited in other tasks search attention in recent years. Existing studies (Hua et al., 2019b; Fromm et al., 2020). can be categorized into monological argumentation Cheng et al. (2020) proposed to tackle APE by (Stab and Gurevych, 2014; Eger et al., 2017; Potash decomposing it into a sequence labeling task and a et al., 2017; Kuribayashi et al., 2019) and dialog- sentence relation classification task, with the first ical argumentation (Swanson et al., 2015; Morio subtask extracting the arguments in each review and Fujita, 2018; Chakrabarty et al., 2019), with or rebuttal, and the second subtask determining the former identifying the argumentation structure whether two sentences belong to the same pair of of a single monological document, and the latter fo- arguments. These two subtasks are jointly opti∗ Corresponding Author"
2021.emnlp-main.319,J17-3005,0,0.0667465,"Missing"
2021.emnlp-main.319,W15-4631,0,0.0269209,"complex arguments, 1 Introduction peer review and rebuttal are perfect resources for Argumentation mining has received increasing re- APE, and have also been exploited in other tasks search attention in recent years. Existing studies (Hua et al., 2019b; Fromm et al., 2020). can be categorized into monological argumentation Cheng et al. (2020) proposed to tackle APE by (Stab and Gurevych, 2014; Eger et al., 2017; Potash decomposing it into a sequence labeling task and a et al., 2017; Kuribayashi et al., 2019) and dialog- sentence relation classification task, with the first ical argumentation (Swanson et al., 2015; Morio subtask extracting the arguments in each review and Fujita, 2018; Chakrabarty et al., 2019), with or rebuttal, and the second subtask determining the former identifying the argumentation structure whether two sentences belong to the same pair of of a single monological document, and the latter fo- arguments. These two subtasks are jointly opti∗ Corresponding Author mized within a multi-task learning framework, and 3923 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 3923–3934 c November 7–11, 2021. 2021 Association for Computational Linguis"
2021.emnlp-main.319,P19-1260,0,0.0565911,"Missing"
2021.emnlp-main.319,C16-1158,0,0.0140985,"umber of sentences contained in each argument is 3.1. Since the majority of arguments contain a small number 6 Related Work of sentences, we should not connect two sentences that have a long distance. Otherwise, the semantic Most existing studies in the field of argumenrepresentation of arguments will be distorted. taion mining focus on monological argumentation, According to Figure 4(b), we find that it is most such as argumentation structure parsing(Stab and 3930 Gurevych, 2017; Afantenos et al., 2018; Kuribayashi et al., 2019; Hua et al., 2019b; Morio et al., 2020), automated essay scoring(Wachsmuth et al., 2016; Ke et al., 2018; Song et al., 2020), argument quality assessment(Wachsmuth et al., 2017; Gretz et al., 2020; Lauscher et al., 2020), argumentation strategies modeling(Khatib et al., 2016, 2017), etc. Since real-life argumentation is usually in the form of dialogue, some prior work focuses on dialogical argumentation. Morio and Fujita (2018) employed a pointer network to predict argumentation structures in discussion threads. Chakrabarty et al. (2019) studied the relations between argument components in online discussion forums with pre-trained models and discourse relations. Ji et al. (2019)"
2021.emnlp-main.319,2020.acl-main.451,0,0.0805014,"Missing"
2021.emnlp-main.319,K17-1045,0,0.0656006,"Missing"
2021.findings-acl.220,2020.acl-main.10,0,0.0340331,"Metrics1 for open-domain dialogue systems. A prediction model is designed to estimate the reliability of the given reference set. We show how its predicted results can be helpful to augment the reference set, and thus improve the reliability of the metric. Experiments validate both the effectiveness of our prediction model and that the reliability of reference-based metrics improves with the augmented reference sets. 1 Introduction The lack of reliable automatic evaluation metrics is a major impediment to the development of opendomain dialogue systems (Li and Jurafsky, 2016; Gao et al., 2019; Li et al., 2020a). The underlying difficulty in evaluation lies in the diversity of the possible outcomings. Existing evaluation metrics for open-domain dialogue systems can be ∗ Corresponding authors Interested reader may contact the authors to obtain a copy of the code and the data. 1 Tencent AI Lab, Shenzhen, China shumingshi@tencent.com roughly divided into reference-based and referencefree metrics. Reference-based metrics usually measure how similar a generated response is to the reference responses. Reference-free metrics, on the other hand, measure the quality of a response without any reference and u"
2021.findings-acl.220,W04-1013,0,0.442918,"reference and usually focus on specific aspects of the responses. For example, much work often computes the perplexity of a generated response as a measure of fluency (Li et al., 2020b), and adopts Dist-1/2 (Li et al., 2016b) to measure the diversity of the response. In this work, we focus on reference-based metrics. BLEU (Papineni et al., 2002), originally for machine translation, is now a popular referencebased metric to evaluate open-domain dialog systems automatically. However, it has been shown that BLEU and other word-overlap metrics such as METEOR (Banerjee and Lavie, 2005) and ROUGE (Lin, 2004), rely on surface-form similarities only without considering the semantic diversity, thus fail to correlate well with human judgements (Liu et al., 2016). Instead, embedding-based metrics are adopted to consider the semantic meaning of a word defined by a distributed representation. For example, Zhang et al. (2020) introduce an embedding-based metric BERTScore that computes the similarity between the generated response and reference responses using contextual embeddings obtained from BERT (Devlin et al., 2019). Intuitively, the reliability of a referenced-based metric depends on two factors: ("
2021.findings-acl.220,P04-1077,0,0.150156,"EAM](BS) model in interactive annotations, respectively. “HumanREAM](BS)” denotes the annotator with the model assistance and “Human” is the annotator without the model assistance. The most commonly used reference-based metrics for dialog systems were originally proposed for machine translation. They typically count the amount of word-overlap between the generated response and the reference response. BLEU (Papineni et al., 2002) is the most widely used metric in machine translation that calculates the geometric mean of the precision for n-gram. Other related word-overlap metrics such as NIST (Lin and Och, 2004), METEOR (Banerjee and Lavie, 2005) and ROUGE (Lin, 2004) also have been used for dialogue evaluation. Instead of using word-overlap based metrics, embedding-based metrics are adopted to consider the semantic meaning of a word as defined by a distributed representation. They typically compute the similarity between the generated response and reference response using approximated sentencelevel representations. The most commonly used word embedding based metrics use a heuristic to combine the vector representation of the individual word in the sentence. For example, Embedding Average (Foltz et a"
2021.findings-acl.220,D16-1230,0,0.11833,"Missing"
2021.findings-acl.220,2021.findings-acl.193,0,0.481841,"he correlation results using the augmented response set from annotators in the second group are not stable. Though the overall trend is increasing, the final obtained reference set has even worse correlations than a much small augmented set from the first group. This shows that our interactive annotation strategy is effective to help annotators avoid writing responses with unsatisfactory quality. 6 0.40 Related Work Automatic evaluation is crucial to the research of open-domain dialog systems (Li and Jurafsky, 2016; Li et al., 2017; Gao et al., 2019; Venkatesh et al., 2018; Chan et al., 2021; Xiang et al., 2021). Existing metrics can be broadly categorized into reference-based and reference-free metrics (Chen et al., 2021). In this work, we focus on referencebased metrics, which usually measure how similar a generated response is to the reference response. 40 60 Number of references 80 100 Figure 4: Pearson correlations of the reference sets constructed with/without the REAM](BS) model in interactive annotations, respectively. “HumanREAM](BS)” denotes the annotator with the model assistance and “Human” is the annotator without the model assistance. The most commonly used reference-based metrics for d"
2021.findings-acl.220,D18-1297,1,0.897301,"Missing"
2021.findings-acl.220,P17-1103,0,0.0750574,"evel representations. The most commonly used word embedding based metrics use a heuristic to combine the vector representation of the individual word in the sentence. For example, Embedding Average (Foltz et al., 1998; Mitchell and Lapata, 2008), Vector Extrema (Forgues and Pineau, 2014), and Greedy Matching (Rus and Lintean, 2012). Zhang et al. (2020) introduce a better embeddingbased metric BERTScore that computes token similarity using contextual embeddings that capture the specific use of a word in a sentence. A few reference-based metrics for dialog systems are learnable functions. ADEM (Lowe et al., 2017) which is based on neural networks is trained to predict a score of a response given its query and a reference response. RUBER (Tao et al., 2018) 2494 evaluates responses with a blending of scores from the referenced and unreferenced metrics. RUBER is learnable, but its training does not require human annotation scores. As discussed from the very beginning of our work, all the above work focus on designing a better metric. However, the reliability of the reference set is also a key to improve the correlation of reference-based metrics, but not investigated in detail in previous work. Therefore"
2021.findings-acl.220,P08-1028,0,0.35562,"Banerjee and Lavie, 2005) and ROUGE (Lin, 2004) also have been used for dialogue evaluation. Instead of using word-overlap based metrics, embedding-based metrics are adopted to consider the semantic meaning of a word as defined by a distributed representation. They typically compute the similarity between the generated response and reference response using approximated sentencelevel representations. The most commonly used word embedding based metrics use a heuristic to combine the vector representation of the individual word in the sentence. For example, Embedding Average (Foltz et al., 1998; Mitchell and Lapata, 2008), Vector Extrema (Forgues and Pineau, 2014), and Greedy Matching (Rus and Lintean, 2012). Zhang et al. (2020) introduce a better embeddingbased metric BERTScore that computes token similarity using contextual embeddings that capture the specific use of a word in a sentence. A few reference-based metrics for dialog systems are learnable functions. ADEM (Lowe et al., 2017) which is based on neural networks is trained to predict a score of a response given its query and a reference response. RUBER (Tao et al., 2018) 2494 evaluates responses with a blending of scores from the referenced and unrefe"
2021.findings-acl.220,P02-1040,0,0.1293,"ngshi@tencent.com roughly divided into reference-based and referencefree metrics. Reference-based metrics usually measure how similar a generated response is to the reference responses. Reference-free metrics, on the other hand, measure the quality of a response without any reference and usually focus on specific aspects of the responses. For example, much work often computes the perplexity of a generated response as a measure of fluency (Li et al., 2020b), and adopts Dist-1/2 (Li et al., 2016b) to measure the diversity of the response. In this work, we focus on reference-based metrics. BLEU (Papineni et al., 2002), originally for machine translation, is now a popular referencebased metric to evaluate open-domain dialog systems automatically. However, it has been shown that BLEU and other word-overlap metrics such as METEOR (Banerjee and Lavie, 2005) and ROUGE (Lin, 2004), rely on surface-form similarities only without considering the semantic diversity, thus fail to correlate well with human judgements (Liu et al., 2016). Instead, embedding-based metrics are adopted to consider the semantic meaning of a word defined by a distributed representation. For example, Zhang et al. (2020) introduce an embeddin"
2021.findings-emnlp.70,D16-1170,1,0.82418,"otion reasoner to generate the response. Specifically, a gated attention mechanism is designed to incorporate emotion cause information into the response generator. accurately perceive and respond to implicit emotions. Li et al. (2020a) exploits user feedback and multi-granularity emotion, and introduces an adversarial learning framework to capture the nuances of user emotion. Emotion cause extraction (ECE), aims at exploring the reason for emotion change and what causes a certain emotion. Lee et al. (2010); Chen et al. (2010) first define it as a word-level and clauselevel task respectively. Gui et al. (2016) proposes the first open dataset for ECE, and it serves as a standard benchmark up till now. Xia and Ding (2019) reforms ECE into emotion-cause pair extraction task. Similar to ECE, Poria et al. (2020) first introduces the task of recognizing emotion cause in conversations. Our framework that explicitly considers the emotion cause for empathetic response generation is shown in Figure 1. Our framework contains two components: an emotion reasoner and a response generator. The emotion reasoner is used to predict a context emotion label and locate words related to the emotion cause, based on the d"
2021.findings-emnlp.70,N18-2008,0,0.0217038,"d significantly outperform other compared methods, resulting in more empathetic responses. 2 Related Work In recent years, neural approaches to open-domain dialogue systems have achieved great progress (Serban et al., 2016; Wolf et al., 2019; Zhang et al., 2020b; Zhou et al., 2020; Xu et al., 2020; Wang et al., 2021). Especially, incorporating personality and emotional features can make dialogue systems more human-like. For emotion-aware response generation, it aims at generating responses corresponding to specific emotions. Several methods are proposed to tackle this task (Zhou et al., 2018; Huang et al., 2018; Colombo et al., 2019; Song et al., 2019; Shen and Feng, 2020; Xu et al., 2021; Majumder et al., 2021). Empathetic response generation is a sub-task of emotion-aware response generation, Rashkin et al. (2019) first proposes a standard benchmark that contains large-scale empathetic conversations. Lin et al. (2020) adapts GPT2 (Radford et al., 2019) to generate empathetic responses via transfer learning and continues to improve its response quality via active learning and negative training. Welivita and Pu (2020) develops a taxonomy of empathetic listener intents by human judges to generate mor"
2021.findings-emnlp.70,W10-0206,0,0.0494795,"the dialogue context. The response generator makes use of the emotional information obtained from the emotion reasoner to generate the response. Specifically, a gated attention mechanism is designed to incorporate emotion cause information into the response generator. accurately perceive and respond to implicit emotions. Li et al. (2020a) exploits user feedback and multi-granularity emotion, and introduces an adversarial learning framework to capture the nuances of user emotion. Emotion cause extraction (ECE), aims at exploring the reason for emotion change and what causes a certain emotion. Lee et al. (2010); Chen et al. (2010) first define it as a word-level and clauselevel task respectively. Gui et al. (2016) proposes the first open dataset for ECE, and it serves as a standard benchmark up till now. Xia and Ding (2019) reforms ECE into emotion-cause pair extraction task. Similar to ECE, Poria et al. (2020) first introduces the task of recognizing emotion cause in conversations. Our framework that explicitly considers the emotion cause for empathetic response generation is shown in Figure 1. Our framework contains two components: an emotion reasoner and a response generator. The emotion reasoner"
2021.findings-emnlp.70,N16-1014,0,0.580082,"r your children! Table 1: An example of empathetic responding from empathetic-dialogues dataset. An empathetic dialogue model is required to generate an appropriate response given the dialogue context. The utterance highlighted in blue contains the emotion cause. Introduction In recent years, open-domain dialogue systems are becoming increasingly ubiquitous and have been extensively leveraged for mental healthcare and entertainment (Oh et al., 2017; Zhou et al., 2020; Sharma et al., 2020). In part, this progress is driven by advances in neural response generation models (Vinyals and Le, 2015; Li et al., 2016a,c; Gao et al., 2019a,b) which have shown success in generating fluent and relevant responses, given a wide variety of user inputs. However, people can still feel a clear gap between humans and machines when conversing with them. One of the primary reasons is that existing dialogue systems lack emotion understanding and empathy (Rashkin et al., 2019). Empathetic responding is a desirable communicative ∗ † Equal Contribution Corresponding author skill that can make more natural communication in daily conversations (Callender, 2015). Table 1 shows an example of empathetic responding from empath"
2021.findings-emnlp.70,D16-1127,0,0.260494,"r your children! Table 1: An example of empathetic responding from empathetic-dialogues dataset. An empathetic dialogue model is required to generate an appropriate response given the dialogue context. The utterance highlighted in blue contains the emotion cause. Introduction In recent years, open-domain dialogue systems are becoming increasingly ubiquitous and have been extensively leveraged for mental healthcare and entertainment (Oh et al., 2017; Zhou et al., 2020; Sharma et al., 2020). In part, this progress is driven by advances in neural response generation models (Vinyals and Le, 2015; Li et al., 2016a,c; Gao et al., 2019a,b) which have shown success in generating fluent and relevant responses, given a wide variety of user inputs. However, people can still feel a clear gap between humans and machines when conversing with them. One of the primary reasons is that existing dialogue systems lack emotion understanding and empathy (Rashkin et al., 2019). Empathetic responding is a desirable communicative ∗ † Equal Contribution Corresponding author skill that can make more natural communication in daily conversations (Callender, 2015). Table 1 shows an example of empathetic responding from empath"
2021.findings-emnlp.70,2020.coling-main.394,0,0.366315,"ng from empathetic-dialogues dataset (Rashkin et al., 2019). A speaker is talking about a situation that happened to him/her related to a lonely feeling and a listener needs to respond with an appropriate emotion. Therefore, empathy is important in conversations. However, endowing dialogue systems with the capability of emotion understanding and empathetic responding is challenging. Most of the existing approaches improve empathetic response generation from two directions. The first usually promotes the model’s emotion understanding (Lubis et al., 2018; Rashkin et al., 2019; Lin et al., 2019; Li et al., 2020b). In this line of work, models are often trained to predict an emotion state of the speaker and generate a response based on the emotion state. The second focuses on improving response generation strategy (Welivita and Pu, 2020; Shin et al., 2020; Majumder et al., 2020). For example, Shin et al. (2020) proposes to use the look-ahead of user emotion to model empathetic response generation and improve the empathetic responding model via Reinforcement Learning. Majumder et al. (2020) presents an ap807 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 807–819 November"
2021.findings-emnlp.70,D19-1012,0,0.339071,"mpathetic responding from empathetic-dialogues dataset (Rashkin et al., 2019). A speaker is talking about a situation that happened to him/her related to a lonely feeling and a listener needs to respond with an appropriate emotion. Therefore, empathy is important in conversations. However, endowing dialogue systems with the capability of emotion understanding and empathetic responding is challenging. Most of the existing approaches improve empathetic response generation from two directions. The first usually promotes the model’s emotion understanding (Lubis et al., 2018; Rashkin et al., 2019; Lin et al., 2019; Li et al., 2020b). In this line of work, models are often trained to predict an emotion state of the speaker and generate a response based on the emotion state. The second focuses on improving response generation strategy (Welivita and Pu, 2020; Shin et al., 2020; Majumder et al., 2020). For example, Shin et al. (2020) proposes to use the look-ahead of user emotion to model empathetic response generation and improve the empathetic responding model via Reinforcement Learning. Majumder et al. (2020) presents an ap807 Findings of the Association for Computational Linguistics: EMNLP 2021, pages"
2021.findings-emnlp.70,2020.emnlp-main.721,0,0.0649622,"Missing"
2021.findings-emnlp.70,P02-1040,0,0.108744,"Missing"
2021.findings-emnlp.70,P19-1534,0,0.294511,"y ubiquitous and have been extensively leveraged for mental healthcare and entertainment (Oh et al., 2017; Zhou et al., 2020; Sharma et al., 2020). In part, this progress is driven by advances in neural response generation models (Vinyals and Le, 2015; Li et al., 2016a,c; Gao et al., 2019a,b) which have shown success in generating fluent and relevant responses, given a wide variety of user inputs. However, people can still feel a clear gap between humans and machines when conversing with them. One of the primary reasons is that existing dialogue systems lack emotion understanding and empathy (Rashkin et al., 2019). Empathetic responding is a desirable communicative ∗ † Equal Contribution Corresponding author skill that can make more natural communication in daily conversations (Callender, 2015). Table 1 shows an example of empathetic responding from empathetic-dialogues dataset (Rashkin et al., 2019). A speaker is talking about a situation that happened to him/her related to a lonely feeling and a listener needs to respond with an appropriate emotion. Therefore, empathy is important in conversations. However, endowing dialogue systems with the capability of emotion understanding and empathetic respondi"
2021.findings-emnlp.70,2020.emnlp-main.425,0,0.0314639,"! I wanted to join a group for local moms Target: That’s a good idea! This way you can meet friends for yourself, also maybe for your children! Table 1: An example of empathetic responding from empathetic-dialogues dataset. An empathetic dialogue model is required to generate an appropriate response given the dialogue context. The utterance highlighted in blue contains the emotion cause. Introduction In recent years, open-domain dialogue systems are becoming increasingly ubiquitous and have been extensively leveraged for mental healthcare and entertainment (Oh et al., 2017; Zhou et al., 2020; Sharma et al., 2020). In part, this progress is driven by advances in neural response generation models (Vinyals and Le, 2015; Li et al., 2016a,c; Gao et al., 2019a,b) which have shown success in generating fluent and relevant responses, given a wide variety of user inputs. However, people can still feel a clear gap between humans and machines when conversing with them. One of the primary reasons is that existing dialogue systems lack emotion understanding and empathy (Rashkin et al., 2019). Empathetic responding is a desirable communicative ∗ † Equal Contribution Corresponding author skill that can make more nat"
2021.findings-emnlp.70,2020.acl-main.52,0,0.0187721,"in more empathetic responses. 2 Related Work In recent years, neural approaches to open-domain dialogue systems have achieved great progress (Serban et al., 2016; Wolf et al., 2019; Zhang et al., 2020b; Zhou et al., 2020; Xu et al., 2020; Wang et al., 2021). Especially, incorporating personality and emotional features can make dialogue systems more human-like. For emotion-aware response generation, it aims at generating responses corresponding to specific emotions. Several methods are proposed to tackle this task (Zhou et al., 2018; Huang et al., 2018; Colombo et al., 2019; Song et al., 2019; Shen and Feng, 2020; Xu et al., 2021; Majumder et al., 2021). Empathetic response generation is a sub-task of emotion-aware response generation, Rashkin et al. (2019) first proposes a standard benchmark that contains large-scale empathetic conversations. Lin et al. (2020) adapts GPT2 (Radford et al., 2019) to generate empathetic responses via transfer learning and continues to improve its response quality via active learning and negative training. Welivita and Pu (2020) develops a taxonomy of empathetic listener intents by human judges to generate more controlled and interpretable responses. Shin et al. (2020) u"
2021.findings-emnlp.70,P19-1359,0,0.0198155,"methods, resulting in more empathetic responses. 2 Related Work In recent years, neural approaches to open-domain dialogue systems have achieved great progress (Serban et al., 2016; Wolf et al., 2019; Zhang et al., 2020b; Zhou et al., 2020; Xu et al., 2020; Wang et al., 2021). Especially, incorporating personality and emotional features can make dialogue systems more human-like. For emotion-aware response generation, it aims at generating responses corresponding to specific emotions. Several methods are proposed to tackle this task (Zhou et al., 2018; Huang et al., 2018; Colombo et al., 2019; Song et al., 2019; Shen and Feng, 2020; Xu et al., 2021; Majumder et al., 2021). Empathetic response generation is a sub-task of emotion-aware response generation, Rashkin et al. (2019) first proposes a standard benchmark that contains large-scale empathetic conversations. Lin et al. (2020) adapts GPT2 (Radford et al., 2019) to generate empathetic responses via transfer learning and continues to improve its response quality via active learning and negative training. Welivita and Pu (2020) develops a taxonomy of empathetic listener intents by human judges to generate more controlled and interpretable responses."
2021.findings-emnlp.70,2020.cl-1.2,0,0.0339102,"Missing"
2021.findings-emnlp.70,2020.coling-main.429,0,0.212576,", empathy is important in conversations. However, endowing dialogue systems with the capability of emotion understanding and empathetic responding is challenging. Most of the existing approaches improve empathetic response generation from two directions. The first usually promotes the model’s emotion understanding (Lubis et al., 2018; Rashkin et al., 2019; Lin et al., 2019; Li et al., 2020b). In this line of work, models are often trained to predict an emotion state of the speaker and generate a response based on the emotion state. The second focuses on improving response generation strategy (Welivita and Pu, 2020; Shin et al., 2020; Majumder et al., 2020). For example, Shin et al. (2020) proposes to use the look-ahead of user emotion to model empathetic response generation and improve the empathetic responding model via Reinforcement Learning. Majumder et al. (2020) presents an ap807 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 807–819 November 7–11, 2021. ©2021 Association for Computational Linguistics proach to mimic the emotion of the speaker while accounting for their affective polarity. However, both kinds of existing methods only consider using the surface informa"
2021.findings-emnlp.70,P19-1096,0,0.0177235,"emotion cause information into the response generator. accurately perceive and respond to implicit emotions. Li et al. (2020a) exploits user feedback and multi-granularity emotion, and introduces an adversarial learning framework to capture the nuances of user emotion. Emotion cause extraction (ECE), aims at exploring the reason for emotion change and what causes a certain emotion. Lee et al. (2010); Chen et al. (2010) first define it as a word-level and clauselevel task respectively. Gui et al. (2016) proposes the first open dataset for ECE, and it serves as a standard benchmark up till now. Xia and Ding (2019) reforms ECE into emotion-cause pair extraction task. Similar to ECE, Poria et al. (2020) first introduces the task of recognizing emotion cause in conversations. Our framework that explicitly considers the emotion cause for empathetic response generation is shown in Figure 1. Our framework contains two components: an emotion reasoner and a response generator. The emotion reasoner is used to predict a context emotion label and locate words related to the emotion cause, based on the dialogue context. The response generator is responsible for incorporating the information obtained from the emoti"
2021.findings-emnlp.70,2020.acl-demos.30,0,0.19618,"n be summarized as follows: in empathetic response generation. • To incorporate emotion cause into response generation, we devise a gated attention mechanism and explore both hard and soft gating strategies, which allow the model to focus on emotion cause related words. • Experimental results show that our proposed models benefit from the emotion cause and significantly outperform other compared methods, resulting in more empathetic responses. 2 Related Work In recent years, neural approaches to open-domain dialogue systems have achieved great progress (Serban et al., 2016; Wolf et al., 2019; Zhang et al., 2020b; Zhou et al., 2020; Xu et al., 2020; Wang et al., 2021). Especially, incorporating personality and emotional features can make dialogue systems more human-like. For emotion-aware response generation, it aims at generating responses corresponding to specific emotions. Several methods are proposed to tackle this task (Zhou et al., 2018; Huang et al., 2018; Colombo et al., 2019; Song et al., 2019; Shen and Feng, 2020; Xu et al., 2021; Majumder et al., 2021). Empathetic response generation is a sub-task of emotion-aware response generation, Rashkin et al. (2019) first proposes a standard benchma"
2021.semeval-1.63,W18-4411,0,0.0208471,"Missing"
2021.semeval-1.63,N19-1423,0,0.0128512,"eri et al., 2020) further extends the dataset to 5 languages: Arabic, Danish, English, Greek, and Turkish. 3 where hk (yk ; x) is the score of the tag yk at the k time step. Then, the conditional probability is obtained by a normalization operation: exp(S(x, y)) . e )) e ∈Y exp(S(x, y y P (y|x) = P where Y contains all possible paths of tag sequences. During inference, the predicted tag seˆ is obtained by: quence y Methods In the section, we describe how toxic span detection is formalized and corresponding solutions in detail. 3.1 (2) Sequence Labeling ˆ = arg max P (y|x). y y∈Y We adopt BERT(Devlin et al., 2019) and BERT+LSTM(Hochreiter et al., 1997) as the language encoder respectively, resulting in two solutions: BERT+CRF and BERT+LSTM+CRF. The reason for adding LSTM is that we believe that the contextual representation refined by LSTM could be more sensitive to the position of tokens. 3.2 The BIO tag scheme is utilized to locating toxic spans, where B (Begin) corresponds to the first token in a toxic span, I (Inside) corresponds to the inside and end tokens in a toxic span, and O corresponds to those no-toxic tokens. Following most existing work (Lample et al., 2016; Ma and Hovy, 2016), we leverag"
2021.semeval-1.63,P19-1051,0,0.139317,"=1 2 https://www.kaggle.com/c/jigsaw-toxic-commentclassification-challenge 522 (3) Span Boundary Detection Different from SL formalization, SBD formalization utilizes the start and end positions tagging scheme to represent toxic spans. SBD formalization was originally applied in the machine reading comprehension task (Seo et al., 2016; Wang and Jiang, 2016). In these works, two n-classifiers are employed to predict the start position and end position separately, where n denotes the length of the input sentence. However, this strategy can only output a single span for an input sentence. Later, Hu et al. (2019b) extended the two n-classifiers strategy by a heuristic multi-span decoding algorithm. But this is not a concise and efficient solution for multi-span scenario, as the decoding algorithm relies on two hyper-parameters: (1) γ, the minimum score threshold, (2) K, the maximum number of spans. In addition to the two n-classifiers strategy, a more recent and popular strategy is to employ two binary classifiers to determine whether each token is the start (end) position or not (Li et al., 2020; Wei et al., 2020; Yu et al., 2019). In this paper, we adopt the binary classifiers strategy for SBD form"
2021.semeval-1.63,W18-4401,0,0.0214842,"ve high precision but rather low recall, and are strongly interpretable and flexible in practice. First, we mine a toxic lexicon from the training set by a simple statistical strategy. Next, WordNet (Fellbaum, 2010) and GloVe (Pennington et al., 2014) are utilized to extend this lexicon further. With a toxic lexicon, we extract toxic spans through word-level matching. 2 Related Work In recent years, cyber violence has become a widespread societal concern, and how to identify and filter hate speech has become an important topic in machine learning. TRAC proposes an aggression recognition task (Kumar et al., 2018) that provides a dataset of 15,000 annotated Facebook posts and comments in English and Hindi for 521 Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021), pages 521–526 Bangkok, Thailand (online), August 5–6, 2021. ©2021 Association for Computational Linguistics O B I I O O O ?1 ?2 ?3 ?4 ?3 ?4 ?? S ?1 (a) ?2 E ?3 ?4 ?3 ?4 ?? (b) Figure 1: Comparison of SL and SBD, (a) denotes SL, (b) denotes SBD. training and validation. The task aims to classify comments into three categories: non-aggressive, covertly aggressive, and overly aggressive. The Toxic Comment Classi"
2021.semeval-1.63,N16-1030,0,0.037351,"x P (y|x). y y∈Y We adopt BERT(Devlin et al., 2019) and BERT+LSTM(Hochreiter et al., 1997) as the language encoder respectively, resulting in two solutions: BERT+CRF and BERT+LSTM+CRF. The reason for adding LSTM is that we believe that the contextual representation refined by LSTM could be more sensitive to the position of tokens. 3.2 The BIO tag scheme is utilized to locating toxic spans, where B (Begin) corresponds to the first token in a toxic span, I (Inside) corresponds to the inside and end tokens in a toxic span, and O corresponds to those no-toxic tokens. Following most existing work (Lample et al., 2016; Ma and Hovy, 2016), we leverage Conditional Random Fields (CRF) (Lafferty et al., 2001) for learning and inference. In addition to token-level classification, CRF models the dependencies between tags in a tag sequence by the transition matrix A ∈ RK×K , where K is the size of the tag space, i.e. K = 3. For the contextual representation x ∈ Rn×h , the score of a tag sequence y ∈ Rn in CRF is defined as: S(x, y) =h1 (y1 ; x)+ (1) n−1  X hk+1 (yk+1 ; x) + Ayk ,yk+1 . k=1 2 https://www.kaggle.com/c/jigsaw-toxic-commentclassification-challenge 522 (3) Span Boundary Detection Different from SL f"
2021.semeval-1.63,2020.acl-main.519,0,0.0316811,"of the input sentence. However, this strategy can only output a single span for an input sentence. Later, Hu et al. (2019b) extended the two n-classifiers strategy by a heuristic multi-span decoding algorithm. But this is not a concise and efficient solution for multi-span scenario, as the decoding algorithm relies on two hyper-parameters: (1) γ, the minimum score threshold, (2) K, the maximum number of spans. In addition to the two n-classifiers strategy, a more recent and popular strategy is to employ two binary classifiers to determine whether each token is the start (end) position or not (Li et al., 2020; Wei et al., 2020; Yu et al., 2019). In this paper, we adopt the binary classifiers strategy for SBD formalization and describe the details below. Split Num Train 6894 Dev 1723 Test 2000 BERT+LSTM+CRF BERT+CRF BERT+Span Ensemble Table 1: Data statistics. Given the contextual representation x = {x1 , x2 , · · · , xn } ∈ Rn×h , for the location i, we calculate the probability of whether it is a start position by Equation (4) and the probability of whether it is a end position by Equation (5). pstart (i) = σ(W1&gt; xi + b1 ), pend (i) = σ(W2&gt; [xi ; pstart (i)] + b2 ), 4.3 (7) 5 Ensemble Strategy Ex"
2021.semeval-1.63,P16-1101,0,0.0362417,"dopt BERT(Devlin et al., 2019) and BERT+LSTM(Hochreiter et al., 1997) as the language encoder respectively, resulting in two solutions: BERT+CRF and BERT+LSTM+CRF. The reason for adding LSTM is that we believe that the contextual representation refined by LSTM could be more sensitive to the position of tokens. 3.2 The BIO tag scheme is utilized to locating toxic spans, where B (Begin) corresponds to the first token in a toxic span, I (Inside) corresponds to the inside and end tokens in a toxic span, and O corresponds to those no-toxic tokens. Following most existing work (Lample et al., 2016; Ma and Hovy, 2016), we leverage Conditional Random Fields (CRF) (Lafferty et al., 2001) for learning and inference. In addition to token-level classification, CRF models the dependencies between tags in a tag sequence by the transition matrix A ∈ RK×K , where K is the size of the tag space, i.e. K = 3. For the contextual representation x ∈ Rn×h , the score of a tag sequence y ∈ Rn in CRF is defined as: S(x, y) =h1 (y1 ; x)+ (1) n−1  X hk+1 (yk+1 ; x) + Ayk ,yk+1 . k=1 2 https://www.kaggle.com/c/jigsaw-toxic-commentclassification-challenge 522 (3) Span Boundary Detection Different from SL formalization, SBD fo"
2021.semeval-1.63,W18-4423,0,0.0364524,"Missing"
2021.semeval-1.63,2021.semeval-1.6,0,0.0463561,"Missing"
2021.semeval-1.63,D14-1162,0,0.0869599,"the ensemble approach, and we can observe that our lexicon-based approaches obtain notable results in the F 1-score. In addition, we also calculate the average precision and average recall values of different methods on the test set, and our original lexicon-based approach even outperforms ensemble approaches in average precision, but there is still a significant gap in an average recall. Since the lexicon-based approaches can only identify the toxic words in the lexicon, the recall can be improved by expanding the toxic lexicon. To improve the recall, we use WordNet (Miller, 1995) and GloVe (Pennington et al., 2014) to expand the toxic lexicon. In detail, we collect synsets of each toxic from WordNet, and collect the nearest similar words by calculating cosine similarity of GloVe vectors. The performances of the two expanded approaches are shown in Table 3. Although the recall of two approaches improves over the original lexicon, the precision decreases significantly, which indicating that there are a considerable number of non-toxic words in the synonyms found through WordNet. Besides, we explore the impact of threshold θ when mining the original lexicon on performance. The performances with different t"
2021.semeval-1.63,2020.acl-main.136,0,0.0176988,"ence. However, this strategy can only output a single span for an input sentence. Later, Hu et al. (2019b) extended the two n-classifiers strategy by a heuristic multi-span decoding algorithm. But this is not a concise and efficient solution for multi-span scenario, as the decoding algorithm relies on two hyper-parameters: (1) γ, the minimum score threshold, (2) K, the maximum number of spans. In addition to the two n-classifiers strategy, a more recent and popular strategy is to employ two binary classifiers to determine whether each token is the start (end) position or not (Li et al., 2020; Wei et al., 2020; Yu et al., 2019). In this paper, we adopt the binary classifiers strategy for SBD formalization and describe the details below. Split Num Train 6894 Dev 1723 Test 2000 BERT+LSTM+CRF BERT+CRF BERT+Span Ensemble Table 1: Data statistics. Given the contextual representation x = {x1 , x2 , · · · , xn } ∈ Rn×h , for the location i, we calculate the probability of whether it is a start position by Equation (4) and the probability of whether it is a end position by Equation (5). pstart (i) = σ(W1&gt; xi + b1 ), pend (i) = σ(W2&gt; [xi ; pstart (i)] + b2 ), 4.3 (7) 5 Ensemble Strategy Experimental Setup D"
2021.semeval-1.63,N18-1095,0,0.0394392,"Missing"
2021.semeval-1.63,N12-1084,0,0.10001,"Missing"
2021.semeval-1.63,S19-2010,0,0.0185077,"ugust 5–6, 2021. ©2021 Association for Computational Linguistics O B I I O O O ?1 ?2 ?3 ?4 ?3 ?4 ?? S ?1 (a) ?2 E ?3 ?4 ?3 ?4 ?? (b) Figure 1: Comparison of SL and SBD, (a) denotes SL, (b) denotes SBD. training and validation. The task aims to classify comments into three categories: non-aggressive, covertly aggressive, and overly aggressive. The Toxic Comment Classification Challenge 5 2 is an open competition in Kaggle that provides participants with comments from Wikipedia and defines six toxic categories: toxic, severe toxic, obscene, threat, insult, identity hate. In SemEval 2019 task 6 (Zampieri et al., 2019), in addition to whether the comment is offensive, the type of the attack and the target of the attack are also included. Based on this, Semeval 2020 task 12 (Zampieri et al., 2020) further extends the dataset to 5 languages: Arabic, Danish, English, Greek, and Turkish. 3 where hk (yk ; x) is the score of the tag yk at the k time step. Then, the conditional probability is obtained by a normalization operation: exp(S(x, y)) . e )) e ∈Y exp(S(x, y y P (y|x) = P where Y contains all possible paths of tag sequences. During inference, the predicted tag seˆ is obtained by: quence y Methods In the se"
D16-1170,D14-1190,0,0.0228518,"ysis is to determine the taxonomy of emotions. Researchers have proposed a list of primary emotions(Plutchik, 1980; Ekman, 1984; Turner, 2000). In this study, we adopt Ekman’s emotion classification (Ekman, 1984), which identifies six primary emotions, namely happiness, sadness, fear, anger, disgust and surprise, known as the “Big6”1 scheme in the W3C Emotion Markup Language. This list is agreed upon by most previous works in Chinese emotion analysis. The second issue is how to do emotion classification and emotion information extraction. 1 http://www.w3.org/TR/emotion-voc/xml#big6 1640 Beck (Beck et al., 2014) proposed a Multi-task Gaussian-process based method for emotion classification. Xu (Xu et al., 2012) used a coarse to fine method to classify emotions in Chinese blog. Gao (Gao et al., 2013) proposed a joint model to cotrain a polarity classifier and an emotion classifier. Chang (Chang et al., 2015) used linguistic template to predict reader’s emotions. Das (Das and Bandyopadhyay, 2010) used an unsupervised method to extract emotion feelers from Bengali blog. There are other studies focused on joint learning with sentiment (Luo et al., 2015; Mohtarami et al., 2013), emotion in tweets or blog"
D16-1170,P15-2127,0,0.185522,"n Lu3 and Yu Zhou1 1. School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen Graduate School, Shenzhen, China 2. Guangdong Provincial Engineering Technology Research Center for Data Science 3. Department of Computing, the Hong Kong Polytechnic University, Hong Kong guilin.nlp@gmail.com;wudongyinhit@gmail.com;xuruifeng@hitsz.edu.cn; csluqin@comp.polyu.edu.hk;zhouyu.nlp@gmail.com Abstract tudies in emotion analysis focus on emotion classification including detection of emotions expressed by writers of text (Gao et al., 2013) as well as prediction of reader emotions (Chang et al., 2015). There are also some information extraction tasks in emotion analysis, such as extracting the feeler of emotion (Das and Bandyopadhyay, 2010). However, these methods need to observe emotion linked expressions. Sometimes, however, we care more about the stimuli, or the cause of an emotion. For instance, manufacturers want to know why people love, or hate a certain product. The White House may also prefer to know the cause of the emotional text “Let us hit the streets” rather than the distribution of different emotions. In this paper, we present our work in emotion cause extraction. Since there"
D16-1170,C10-1021,0,0.68951,"powerful medium anywhere and anytime. How to analyze the emotions of individuals through their writings becomes a new challenge for NLP. In recent years, s∗ corresponding author There are three main challenges in the study of emotion cause extraction. The first is that, up to now, there is no open dataset available for emotion cause extraction. This may explain why there are only few studies on emotion causes. The second is that, there is no formal definition about event in emotion cause extraction even though some researches claim that they extract events of emotion causes (Lee et al., 2010; Chen et al., 2010). The third is that, due to the complexity in annotation, the size of corpus for emotion cause extraction is usually very small. Due to this limitation, many machine learning methods are not suited for emotion cause detection. How to mine deep knowledge of a language for emotion causes is another thorny issue. In this paper, we first present an annotated dataset for emotion cause extraction to be released to the public. We then propose to use a 7-tuple to define emotion cause events. Based on this general defi1639 Proceedings of the 2016 Conference on Empirical Methods in Natural Language Proc"
D16-1170,P02-1034,0,0.0357596,"ETs, emotion cause extraction becomes a classification problem. If an ET is an emotion cause, the label should be positive. Otherwise, the label should be negative. A binary classifier should be used. 4.2 Emotion Cause Extraction After the construction of ETs, we obtain positive and negative ET samples. Due to small amount of training samples, it is necessary to capture all features in the ETs. We choose convolution kernel based SVMs because it can search all possible syntactic features under a tree structure. Convolution kernel function The convolution kernel, also known as the tree kernel (Collins and Duffy, 2002), is widely used in many NLP tasks (Srivastava et al., 2013; Moschitti, 2006). For any two inputs T1 and T2 based on a tree structure , the kernel is defined as: K(T1 , T2 ) = X X δ(n1 , n2 ). (1) n1 ∈T1 n2 ∈T2 Here, n1 and n2 are tree nodes. δ is a function defined recursively: 1.δ(n1 , n2 ) = 0 if the productions of n1 and n2 are different; 2.Else, δ(n1 , n2 ) = 1 if n1 and n2 are matching in pre-terminals; 3.Otherwise, δ(n1 , n2 ) = Y (1 + δ(c(n1 , i), c(n2 , i))). i Here, c(n, i) is the i-th node of n. However, the above tree kernel definition does not consider terminals, which means that"
D16-1170,Y10-1071,0,0.176185,"China 2. Guangdong Provincial Engineering Technology Research Center for Data Science 3. Department of Computing, the Hong Kong Polytechnic University, Hong Kong guilin.nlp@gmail.com;wudongyinhit@gmail.com;xuruifeng@hitsz.edu.cn; csluqin@comp.polyu.edu.hk;zhouyu.nlp@gmail.com Abstract tudies in emotion analysis focus on emotion classification including detection of emotions expressed by writers of text (Gao et al., 2013) as well as prediction of reader emotions (Chang et al., 2015). There are also some information extraction tasks in emotion analysis, such as extracting the feeler of emotion (Das and Bandyopadhyay, 2010). However, these methods need to observe emotion linked expressions. Sometimes, however, we care more about the stimuli, or the cause of an emotion. For instance, manufacturers want to know why people love, or hate a certain product. The White House may also prefer to know the cause of the emotional text “Let us hit the streets” rather than the distribution of different emotions. In this paper, we present our work in emotion cause extraction. Since there is no open dataset available, the lack of annotated resources has limited the research in this area. Thus, we first present a dataset we buil"
D16-1170,P13-1095,0,0.012971,"proposed a Multi-task Gaussian-process based method for emotion classification. Xu (Xu et al., 2012) used a coarse to fine method to classify emotions in Chinese blog. Gao (Gao et al., 2013) proposed a joint model to cotrain a polarity classifier and an emotion classifier. Chang (Chang et al., 2015) used linguistic template to predict reader’s emotions. Das (Das and Bandyopadhyay, 2010) used an unsupervised method to extract emotion feelers from Bengali blog. There are other studies focused on joint learning with sentiment (Luo et al., 2015; Mohtarami et al., 2013), emotion in tweets or blog (Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014; Liu et al., 2013; Quan and Ren, 2009), and emotional lexicon construction (Yang et al., 2014; Staiano and Guerini, 2014; Mohammad and Turney, 2013). However, these related works all focused on analysis of emotion expressions rather than emotion causes.. Sophia M. Y. Lee first proposed a task on emotion cause extraction (Lee et al., 2010). They manually constructed a corpus from Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen and Lee (Chen et al., 2010) proposed a rule based method to detect emotion causes. The basic idea is to make"
D16-1170,W10-0206,0,0.696817,"ions through this powerful medium anywhere and anytime. How to analyze the emotions of individuals through their writings becomes a new challenge for NLP. In recent years, s∗ corresponding author There are three main challenges in the study of emotion cause extraction. The first is that, up to now, there is no open dataset available for emotion cause extraction. This may explain why there are only few studies on emotion causes. The second is that, there is no formal definition about event in emotion cause extraction even though some researches claim that they extract events of emotion causes (Lee et al., 2010; Chen et al., 2010). The third is that, due to the complexity in annotation, the size of corpus for emotion cause extraction is usually very small. Due to this limitation, many machine learning methods are not suited for emotion cause detection. How to mine deep knowledge of a language for emotion causes is another thorny issue. In this paper, we first present an annotated dataset for emotion cause extraction to be released to the public. We then propose to use a 7-tuple to define emotion cause events. Based on this general defi1639 Proceedings of the 2016 Conference on Empirical Methods in N"
D16-1170,P13-2091,0,0.0262073,"classification. Xu (Xu et al., 2012) used a coarse to fine method to classify emotions in Chinese blog. Gao (Gao et al., 2013) proposed a joint model to cotrain a polarity classifier and an emotion classifier. Chang (Chang et al., 2015) used linguistic template to predict reader’s emotions. Das (Das and Bandyopadhyay, 2010) used an unsupervised method to extract emotion feelers from Bengali blog. There are other studies focused on joint learning with sentiment (Luo et al., 2015; Mohtarami et al., 2013), emotion in tweets or blog (Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014; Liu et al., 2013; Quan and Ren, 2009), and emotional lexicon construction (Yang et al., 2014; Staiano and Guerini, 2014; Mohammad and Turney, 2013). However, these related works all focused on analysis of emotion expressions rather than emotion causes.. Sophia M. Y. Lee first proposed a task on emotion cause extraction (Lee et al., 2010). They manually constructed a corpus from Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen and Lee (Chen et al., 2010) proposed a rule based method to detect emotion causes. The basic idea is to make linguistic rules for cause extraction. Some studies (Gui e"
D16-1170,D15-1297,0,0.0275477,"tp://www.w3.org/TR/emotion-voc/xml#big6 1640 Beck (Beck et al., 2014) proposed a Multi-task Gaussian-process based method for emotion classification. Xu (Xu et al., 2012) used a coarse to fine method to classify emotions in Chinese blog. Gao (Gao et al., 2013) proposed a joint model to cotrain a polarity classifier and an emotion classifier. Chang (Chang et al., 2015) used linguistic template to predict reader’s emotions. Das (Das and Bandyopadhyay, 2010) used an unsupervised method to extract emotion feelers from Bengali blog. There are other studies focused on joint learning with sentiment (Luo et al., 2015; Mohtarami et al., 2013), emotion in tweets or blog (Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014; Liu et al., 2013; Quan and Ren, 2009), and emotional lexicon construction (Yang et al., 2014; Staiano and Guerini, 2014; Mohammad and Turney, 2013). However, these related works all focused on analysis of emotion expressions rather than emotion causes.. Sophia M. Y. Lee first proposed a task on emotion cause extraction (Lee et al., 2010). They manually constructed a corpus from Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen and Lee (Chen et al., 2010) propo"
D16-1170,P13-1097,0,0.0286999,"/emotion-voc/xml#big6 1640 Beck (Beck et al., 2014) proposed a Multi-task Gaussian-process based method for emotion classification. Xu (Xu et al., 2012) used a coarse to fine method to classify emotions in Chinese blog. Gao (Gao et al., 2013) proposed a joint model to cotrain a polarity classifier and an emotion classifier. Chang (Chang et al., 2015) used linguistic template to predict reader’s emotions. Das (Das and Bandyopadhyay, 2010) used an unsupervised method to extract emotion feelers from Bengali blog. There are other studies focused on joint learning with sentiment (Luo et al., 2015; Mohtarami et al., 2013), emotion in tweets or blog (Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014; Liu et al., 2013; Quan and Ren, 2009), and emotional lexicon construction (Yang et al., 2014; Staiano and Guerini, 2014; Mohammad and Turney, 2013). However, these related works all focused on analysis of emotion expressions rather than emotion causes.. Sophia M. Y. Lee first proposed a task on emotion cause extraction (Lee et al., 2010). They manually constructed a corpus from Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen and Lee (Chen et al., 2010) proposed a rule based method t"
D16-1170,D14-1123,0,0.0158183,"thod for emotion classification. Xu (Xu et al., 2012) used a coarse to fine method to classify emotions in Chinese blog. Gao (Gao et al., 2013) proposed a joint model to cotrain a polarity classifier and an emotion classifier. Chang (Chang et al., 2015) used linguistic template to predict reader’s emotions. Das (Das and Bandyopadhyay, 2010) used an unsupervised method to extract emotion feelers from Bengali blog. There are other studies focused on joint learning with sentiment (Luo et al., 2015; Mohtarami et al., 2013), emotion in tweets or blog (Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014; Liu et al., 2013; Quan and Ren, 2009), and emotional lexicon construction (Yang et al., 2014; Staiano and Guerini, 2014; Mohammad and Turney, 2013). However, these related works all focused on analysis of emotion expressions rather than emotion causes.. Sophia M. Y. Lee first proposed a task on emotion cause extraction (Lee et al., 2010). They manually constructed a corpus from Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen and Lee (Chen et al., 2010) proposed a rule based method to detect emotion causes. The basic idea is to make linguistic rules for cause extraction. S"
D16-1170,D14-1127,0,0.0127211,"aussian-process based method for emotion classification. Xu (Xu et al., 2012) used a coarse to fine method to classify emotions in Chinese blog. Gao (Gao et al., 2013) proposed a joint model to cotrain a polarity classifier and an emotion classifier. Chang (Chang et al., 2015) used linguistic template to predict reader’s emotions. Das (Das and Bandyopadhyay, 2010) used an unsupervised method to extract emotion feelers from Bengali blog. There are other studies focused on joint learning with sentiment (Luo et al., 2015; Mohtarami et al., 2013), emotion in tweets or blog (Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014; Liu et al., 2013; Quan and Ren, 2009), and emotional lexicon construction (Yang et al., 2014; Staiano and Guerini, 2014; Mohammad and Turney, 2013). However, these related works all focused on analysis of emotion expressions rather than emotion causes.. Sophia M. Y. Lee first proposed a task on emotion cause extraction (Lee et al., 2010). They manually constructed a corpus from Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen and Lee (Chen et al., 2010) proposed a rule based method to detect emotion causes. The basic idea is to make linguistic rules for ca"
D16-1170,D09-1150,0,0.0157741,"(Xu et al., 2012) used a coarse to fine method to classify emotions in Chinese blog. Gao (Gao et al., 2013) proposed a joint model to cotrain a polarity classifier and an emotion classifier. Chang (Chang et al., 2015) used linguistic template to predict reader’s emotions. Das (Das and Bandyopadhyay, 2010) used an unsupervised method to extract emotion feelers from Bengali blog. There are other studies focused on joint learning with sentiment (Luo et al., 2015; Mohtarami et al., 2013), emotion in tweets or blog (Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014; Liu et al., 2013; Quan and Ren, 2009), and emotional lexicon construction (Yang et al., 2014; Staiano and Guerini, 2014; Mohammad and Turney, 2013). However, these related works all focused on analysis of emotion expressions rather than emotion causes.. Sophia M. Y. Lee first proposed a task on emotion cause extraction (Lee et al., 2010). They manually constructed a corpus from Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen and Lee (Chen et al., 2010) proposed a rule based method to detect emotion causes. The basic idea is to make linguistic rules for cause extraction. Some studies (Gui et al., 2014; Li and X"
D16-1170,W11-1720,0,0.339925,"Missing"
D16-1170,D13-1144,0,0.0640194,"lem. If an ET is an emotion cause, the label should be positive. Otherwise, the label should be negative. A binary classifier should be used. 4.2 Emotion Cause Extraction After the construction of ETs, we obtain positive and negative ET samples. Due to small amount of training samples, it is necessary to capture all features in the ETs. We choose convolution kernel based SVMs because it can search all possible syntactic features under a tree structure. Convolution kernel function The convolution kernel, also known as the tree kernel (Collins and Duffy, 2002), is widely used in many NLP tasks (Srivastava et al., 2013; Moschitti, 2006). For any two inputs T1 and T2 based on a tree structure , the kernel is defined as: K(T1 , T2 ) = X X δ(n1 , n2 ). (1) n1 ∈T1 n2 ∈T2 Here, n1 and n2 are tree nodes. δ is a function defined recursively: 1.δ(n1 , n2 ) = 0 if the productions of n1 and n2 are different; 2.Else, δ(n1 , n2 ) = 1 if n1 and n2 are matching in pre-terminals; 3.Otherwise, δ(n1 , n2 ) = Y (1 + δ(c(n1 , i), c(n2 , i))). i Here, c(n, i) is the i-th node of n. However, the above tree kernel definition does not consider terminals, which means that the actual words in a sentence are ignored. As emotions cau"
D16-1170,P14-2070,0,0.0105484,"Missing"
D16-1170,P14-2069,0,0.0123206,"fy emotions in Chinese blog. Gao (Gao et al., 2013) proposed a joint model to cotrain a polarity classifier and an emotion classifier. Chang (Chang et al., 2015) used linguistic template to predict reader’s emotions. Das (Das and Bandyopadhyay, 2010) used an unsupervised method to extract emotion feelers from Bengali blog. There are other studies focused on joint learning with sentiment (Luo et al., 2015; Mohtarami et al., 2013), emotion in tweets or blog (Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014; Liu et al., 2013; Quan and Ren, 2009), and emotional lexicon construction (Yang et al., 2014; Staiano and Guerini, 2014; Mohammad and Turney, 2013). However, these related works all focused on analysis of emotion expressions rather than emotion causes.. Sophia M. Y. Lee first proposed a task on emotion cause extraction (Lee et al., 2010). They manually constructed a corpus from Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen and Lee (Chen et al., 2010) proposed a rule based method to detect emotion causes. The basic idea is to make linguistic rules for cause extraction. Some studies (Gui et al., 2014; Li and Xu, 2014; Gao et al., 2015) extended the rule based meth"
D17-1167,D14-1190,0,0.0625937,"Missing"
D17-1167,P15-2127,0,0.0423877,"the taxonomy of emotions. Researchers have proposed a list of primary emotions (Plutchik, 1980; Ekman, 1984; Turner, 2000). In this study, we Existing work in emotion analysis mostly focuses on emotion classification (Li et al., 2013; Zhou et al., 2016) and emotion information extraction (Balahur et al., 2013). Xu et al. (2012) used a coarse to fine method to classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rat"
D17-1167,C10-1021,0,0.529812,"joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes based on manually define linguistic rules. Some studies (Gui et al., 2014; Li and Xu, 2014; Gao et al., 2015) extended the rule based method to informal text in Weibo text (Chinese tweets). Other than rule based methods, Russo et al. (2011) proposed a crowdsourcing method to construct a common-sense knowledge base which is related to emotion causes. But it is challenging to extend the common-sense knowledge base automatically. Ghazi et al. (2015) used Conditional Random Fields (CRFs) to extract emotion causes. However, it requires emotion"
D17-1167,Y10-1071,0,0.18817,"ure. 1 Introduction With the rapid growth of social network platforms, more and more people tend to share their experiences and emotions online. Emotion analysis of online text becomes a new challenge in Natural Language Processing (NLP). In recent years, studies in emotion analysis largely focus on emotion classification including detection of writers’ emotions (Gao et al., 2013) as well as readers’ emotions (Chang et al., 2015). There are also some information extraction tasks defined in emotion analysis (Chen et al., 2016; Balahur et al., 2011), such as extracting the feeler of an emotion (Das and Bandyopadhyay, 2010). These methods † Corresponding Author: xuruifeng@hit.edu.cn assume that emotion expressions are already observed. Sometimes, however, we care more about the stimuli, or the cause of an emotion. For instance, Samsung wants to know why people love or hate Note 7 rather than the distribution of different emotions. Ex.1 我的手机昨天丢了，我现在很难过。 Ex.1 Because I lost my phone yesterday, I feel sad now. In an example shown above, “sad” is an emotion word, and the cause of “sad” is “I lost my phone”. The emotion cause extraction task aims to identify the reason behind an emotion expression. It is a more diffi"
D17-1167,P13-1095,0,0.0353223,"classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes based on manually define linguistic rules. Some studies (Gui et al., 2014; Li and Xu, 2014;"
D17-1167,D14-1181,0,0.00503362,"t by an attention mechanism. Based on the learned attention result, the network maps the text into a low dimensional vector space. This vector is then used to generate an answer. Existing memory network based approaches to QA use weighted sum of attentions to jointly consider short text segments stored in memory. However, they do not explicitly model sequential information in the context. In this paper, we propose a new deep memory network architecture to model the context of each word simultaneously by multiple memory slots which capture sequential information using convolutional operations (Kim, 2014), and achieves the state-of-the-art performance compared to existing methods which use manual rules, common sense knowledge bases or other machine learning models. The rest of the paper is organized as follows. Section 2 gives a review of related works on emotion analysis. Section 3 presents our proposed deep memory network based model for emotion cause extraction. Section 4 discusses evaluation results. Finally, Section 5 concludes the work and outlines the future directions. 2 Related Work Identifying emotion categories in text is one of the key tasks in NLP (Liu, 2015). Going one step furth"
D17-1167,W10-0206,0,0.743034,"s to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes based on manually define linguistic rules. Some studies (Gui et al., 2014; Li and Xu, 2014; Gao et al., 2015) extended the rule based method to informal text in Weibo text (Chinese tweets). Other than rule based methods, Russo et al. (2011) proposed a crowdsourcing method to construct a common-sense knowledge base which is related to emotion causes. But it is challe"
D17-1167,P13-2091,0,0.0388326,"to fine method to classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes based on manually define linguistic rules. Some studies (Gui et al.,"
D17-1167,D15-1297,0,0.0226715,"16) and emotion information extraction (Balahur et al., 2013). Xu et al. (2012) used a coarse to fine method to classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method"
D17-1167,D14-1123,0,0.0222424,"(2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes based on manually define linguistic rules. Some studies (Gui et al., 2014; Li and Xu, 2014; Gao et al., 2015) extended the rule based"
D17-1167,D14-1127,0,0.0455892,"inese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes based on manually define linguistic rules. Some studies (Gui et al., 2014; Li and Xu, 2014; Gao et al., 2015) exten"
D17-1167,D09-1150,0,0.0406229,"2012) used a coarse to fine method to classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes based on manually define linguistic rules. Some st"
D17-1167,W11-1720,0,0.272973,"Missing"
D17-1167,P14-2070,0,0.0182461,"al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes based on manually define linguistic rules. Some studies (Gui et al., 2014; Li and Xu, 2014; Gao et al., 2015) extended the rule based method to informal text in Weibo text (Chinese tweets). Other than rule based methods, Russo et al. (2011)"
D17-1167,D16-1021,0,0.0120791,"use extraction requires an understanding of a given piece of text in order to correctly identify the relation between the description of an event which causes an emotion and the expression of that emotion, it can essentially be considered as a QA task. In our work, we choose the memory network, which is designed to model the relation between a story and a query for QA systems (Weston et al., 2014; Sukhbaatar et al., 2015). Apart from its application in QA, memory network has also achieved great successes in other NLP tasks, such as machine translation (Luong et al., 2015), sentiment analysis (Tang et al., 2016) or summarization (M. Rush et al., 2015). To the best of our knowledge, this is the first work which uses memory network for emotion cause extraction. 3 Our Approach In this section, we will first define our task. Then, a brief introduction of memory network will be given, including its basic learning structure of memory network and deep architecture. Last, our modified deep memory network for emotion cause extraction will be presented. 3.1 Task Definition The formal definition of emotion cause extraction is given in (Gui et al., 2016). In this task, a given document, which is a passage about"
D17-1167,D15-1166,0,0.00787256,"in their model learning. Since emotion cause extraction requires an understanding of a given piece of text in order to correctly identify the relation between the description of an event which causes an emotion and the expression of that emotion, it can essentially be considered as a QA task. In our work, we choose the memory network, which is designed to model the relation between a story and a query for QA systems (Weston et al., 2014; Sukhbaatar et al., 2015). Apart from its application in QA, memory network has also achieved great successes in other NLP tasks, such as machine translation (Luong et al., 2015), sentiment analysis (Tang et al., 2016) or summarization (M. Rush et al., 2015). To the best of our knowledge, this is the first work which uses memory network for emotion cause extraction. 3 Our Approach In this section, we will first define our task. Then, a brief introduction of memory network will be given, including its basic learning structure of memory network and deep architecture. Last, our modified deep memory network for emotion cause extraction will be presented. 3.1 Task Definition The formal definition of emotion cause extraction is given in (Gui et al., 2016). In this task, a g"
D17-1167,D15-1044,0,0.0332273,"of a given piece of text in order to correctly identify the relation between the description of an event which causes an emotion and the expression of that emotion, it can essentially be considered as a QA task. In our work, we choose the memory network, which is designed to model the relation between a story and a query for QA systems (Weston et al., 2014; Sukhbaatar et al., 2015). Apart from its application in QA, memory network has also achieved great successes in other NLP tasks, such as machine translation (Luong et al., 2015), sentiment analysis (Tang et al., 2016) or summarization (M. Rush et al., 2015). To the best of our knowledge, this is the first work which uses memory network for emotion cause extraction. 3 Our Approach In this section, we will first define our task. Then, a brief introduction of memory network will be given, including its basic learning structure of memory network and deep architecture. Last, our modified deep memory network for emotion cause extraction will be presented. 3.1 Task Definition The formal definition of emotion cause extraction is given in (Gui et al., 2016). In this task, a given document, which is a passage about an emotion event, contains an emotion wo"
D17-1167,P13-1097,0,0.0280841,"formation extraction (Balahur et al., 2013). Xu et al. (2012) used a coarse to fine method to classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes"
D17-1167,P14-2069,0,0.014941,"classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014). However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes. Lee et al. (2010) first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes based on manually define linguistic rules. Some studies (Gui et al., 2014; Li and Xu, 2014; Gao et al., 2015) extended the rule based method to informal text in Weibo text (Chinese tweets). Other than rule based m"
D17-1167,D16-1061,0,0.0378978,"categories in text is one of the key tasks in NLP (Liu, 2015). Going one step further, emotion cause extraction can reveal important information about what causes a certain emotion and why there is an emotion change. In this section, we introduce related work on emotion analysis including emotion cause extraction. In emotion analysis, we first need to determine the taxonomy of emotions. Researchers have proposed a list of primary emotions (Plutchik, 1980; Ekman, 1984; Turner, 2000). In this study, we Existing work in emotion analysis mostly focuses on emotion classification (Li et al., 2013; Zhou et al., 2016) and emotion information extraction (Balahur et al., 2013). Xu et al. (2012) used a coarse to fine method to classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader’s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments (Luo"
D18-1069,W10-0214,0,0.0407167,"ributions of this paper are: (1) We propose a neural attention model for (dis)agreement inference which converts this Introduction The rise of various discussion forums and online debate platforms, has given users a lot of opportunities to express themselves and argue with each other. The online argumentation and discussion are always initiated and evolved by expressions of agreement or disagreement of participants. Inferring the agreement/disagreement in online debates is crucial for many other tasks in broader analysis of social media and argumentation mining, such as stance identification (Somasundaran and Wiebe, 2010), claim/argument extraction (Hidey et al., 2017) and persuasion analysis (Tan et al., 2016). It is observed that the expression of agreement/disagreement in debates can be decomposed into two factors: 1) the self-expression of claims and 2) argumentative expressions to interact with other participants. To illustrate this observation, we show some examples in Figure 1, which is one of quote-response pair (Q-R pair) in 4forum online ∗ Corresponding author. 665 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 665–670 c Brussels, Belgium, October 31 - N"
D18-1069,P17-1021,0,0.025089,"uote and response. In other NLP tasks, the end-to-end deep learning approaches with attention mechanism have shown impressive results. The attention mechanism is proposed by Bahdanau et al. (2014) in machine translation for selecting alignment between original words and foreign words before translation. For Document Classification, Yang et al. (2016) apply a hierarchical attention from word-level to sentence-level with learnable context vector. In Natural Language Inference (NLI), Liu et al. (2016) construct an inner-attention with mean pooling vector to seize important part from text itself. Hao et al. (2017) propose an cross attention modeling mutual influence between question and answer for Question Answering (QA). But there is no neural attention model incorporating both contextual and interactive information in the scenario of (dis)agreement inference. Self Attention The first source taken into consideration should be the text sequence itself, i.e. the attention from quote to quote itself and that from response to response itself. When issuing an opinion, people tend to center on several keywords which convey the main idea. Thus in some sense, self attention is a kind of dependency parsing tha"
D18-1069,walker-etal-2012-corpus,0,0.141389,"can be represented as [r1 , r2 , · · · , rT ], which shares the same vector space with quote. To model the dependence relation of text sequence, we leverage bidirectional LSTM (BiLSTM) to encode quote and response. The BiLSTM consists of a forward −−−−→ LST M which reads the text from x1 to xT and ←−−−− a backward LST M which reads from xT to x1 : Related Work With the development of social forums, works on (dis)agreement inference have shifted to online debate. Abbott et al. (2011) utilize wordbased and dependencies-based features to recognize disagreement in Internet Argument Corpus (IAC) (Walker et al., 2012). Rosenthal and McKeown (2015) present a new corpus derived from participant information, Agreement by Create Debaters (ABCD), and investigate new features for conversational structure. Further, Menini and Tonelli (2016) develop a SVM classifier to detect disagreement, relying on three aspects including sentiment-based, semantic and surface features extracted from both whole text and topic-related part. However, the performances of all these models highly depend on the quality of hand-crafted features. And these representations cannot reflect the interaction between quote and response. → − −−−"
D18-1069,N16-1174,0,0.0277847,"tegrates the information around xt . The quote − → ← − and response are encoded as hQ = [hQ ; hQ ] ∈ − → ← − RT ×2d and hR = [hR ; hR ] ∈ RT ×2d respectively. 3.2 Attention Component After encoding the implicit word semantics, we acquire the representation of both quote and response. In other NLP tasks, the end-to-end deep learning approaches with attention mechanism have shown impressive results. The attention mechanism is proposed by Bahdanau et al. (2014) in machine translation for selecting alignment between original words and foreign words before translation. For Document Classification, Yang et al. (2016) apply a hierarchical attention from word-level to sentence-level with learnable context vector. In Natural Language Inference (NLI), Liu et al. (2016) construct an inner-attention with mean pooling vector to seize important part from text itself. Hao et al. (2017) propose an cross attention modeling mutual influence between question and answer for Question Answering (QA). But there is no neural attention model incorporating both contextual and interactive information in the scenario of (dis)agreement inference. Self Attention The first source taken into consideration should be the text sequen"
D18-1069,W17-5102,0,0.0152504,"tion model for (dis)agreement inference which converts this Introduction The rise of various discussion forums and online debate platforms, has given users a lot of opportunities to express themselves and argue with each other. The online argumentation and discussion are always initiated and evolved by expressions of agreement or disagreement of participants. Inferring the agreement/disagreement in online debates is crucial for many other tasks in broader analysis of social media and argumentation mining, such as stance identification (Somasundaran and Wiebe, 2010), claim/argument extraction (Hidey et al., 2017) and persuasion analysis (Tan et al., 2016). It is observed that the expression of agreement/disagreement in debates can be decomposed into two factors: 1) the self-expression of claims and 2) argumentative expressions to interact with other participants. To illustrate this observation, we show some examples in Figure 1, which is one of quote-response pair (Q-R pair) in 4forum online ∗ Corresponding author. 665 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 665–670 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computatio"
D18-1069,P82-1020,0,0.785571,"Missing"
D18-1069,C16-1232,0,0.199702,"GOOD all the time … Quote God IS GOOD all the time … Then why doesn&apos;t He answer prayers like He says He will in the Bible ? Response Then why doesn&apos;t He answer prayers like He says He will in the Bible ? Figure 1: Sampled Q-R Pair with topic of evolution where the words colored red deliver crucial meaning of the text itself, while the words colored blue clarify the interactive relation between users. Previous works on agreement/disagreement inference mainly focus on exploiting features to model the semantic information which only reveals author’s self-expression. (Rosenthal and McKeown, 2015; Menini and Tonelli, 2016). These existing models treat agreement/disagreement inference as a ordinary sentiment classification problem and ignore the interactions between participants in the discussion. In order to jointly leverage the semantic information of the text and interactions between Q-R pairs, we regard the (dis)agreement inference as a special case of Natural Language Inference (NLI) (Rockt¨aschel et al., 2016), and propose a hybrid neural attention model to this problem. The proposed model consists of two kinds of attention: 1) self attention locates salient parts in text of quote and response, and 2) cros"
D18-1069,D14-1162,0,0.0810211,"g from gradient vanishing results in the poor performance. It is the hybrid attention that effects. As for ABCD, compared with ME based on textual features, Our BiLSTM-hybrid also gives superior performance of average F 1 in 3-way inference. Since ABCD is a corpus annotated by meta-thread rules, the ME attaching conversational structure attains the best Experiment and Results As prior work, we concentrate on direct disagreement and agreement between quote-response (QR) pairs. Specifically, in the proposed model, the size of hidden units is 128 and all word embeddings are initialized by GloVe (Pennington et al., 2014) of 300d. Both length of quote and response are set to 64, padded where necessary. Adam is the optimizer of model whose learning rate is 1e − 3, β is (0.9, 0.999),  is 1e − 8 and weight decay is 1e − 5. All models are trained by mini-batch of 32 instances, with 5-fold cross validation. 4.1 # Neutral 72,683 • Agreement by Create Debaters (ABCD) (Rosenthal and McKeown, 2015) is developed from createdebate.com with labels of agreement, disagreement and neutral. As the original settings, the comparison experiments are conducted on a balanced training set by downsampling and the full test set. whe"
D18-1069,W15-4625,0,0.372689,"rt models. 1 Disagree God IS GOOD all the time … Quote God IS GOOD all the time … Then why doesn&apos;t He answer prayers like He says He will in the Bible ? Response Then why doesn&apos;t He answer prayers like He says He will in the Bible ? Figure 1: Sampled Q-R Pair with topic of evolution where the words colored red deliver crucial meaning of the text itself, while the words colored blue clarify the interactive relation between users. Previous works on agreement/disagreement inference mainly focus on exploiting features to model the semantic information which only reveals author’s self-expression. (Rosenthal and McKeown, 2015; Menini and Tonelli, 2016). These existing models treat agreement/disagreement inference as a ordinary sentiment classification problem and ignore the interactions between participants in the discussion. In order to jointly leverage the semantic information of the text and interactions between Q-R pairs, we regard the (dis)agreement inference as a special case of Natural Language Inference (NLI) (Rockt¨aschel et al., 2016), and propose a hybrid neural attention model to this problem. The proposed model consists of two kinds of attention: 1) self attention locates salient parts in text of quot"
D18-1354,K16-1002,0,0.244028,"al., 2016b; Xing et al., 2017; Zhou et al., 2017b) and modifying the architecture of existing models (Li et al., 2016a; Xu et al., 2017; Zhou et al., 2017a). Another solution to address this problem is to add stochastic latent variables in order to change the deterministic structure of Seq2Seq models. VAE (Kingma and Welling, 2013) is one of the most successful models (Serban et al., 2017; Zhao et al., 2017; Shen et al., 2017; Cao and Clark, 2017). However, VAE-based models only use a single latent variable to encode the whole response sequence, thus suffering from the model collapse problem (Bowman et al., 2016). To overcome this problem, we propose a novel model that based on the variational autoregressive decoder to better represent highly structural latent variables. 2.2 Variational Autoregressive Models Recently, some works attempted to combine VAE with autoregressive models to better process input sequences. Broadly speaking, they can be categorized into two groups. Methods in the first group leverage autoregressive models to improve the inference of traditional VAEs. The most well-known model is Inverse Autoregressive Flow (IAF), which used a series of invertible transformations based on the au"
D18-1354,E17-2029,0,0.0370672,"eneric responses, such as I don’t know (Li et al., 2016a). Various approaches have been proposed to address this problem, including adding additional information (Li et al., 2016b; Xing et al., 2017; Zhou et al., 2017b) and modifying the architecture of existing models (Li et al., 2016a; Xu et al., 2017; Zhou et al., 2017a). Another solution to address this problem is to add stochastic latent variables in order to change the deterministic structure of Seq2Seq models. VAE (Kingma and Welling, 2013) is one of the most successful models (Serban et al., 2017; Zhao et al., 2017; Shen et al., 2017; Cao and Clark, 2017). However, VAE-based models only use a single latent variable to encode the whole response sequence, thus suffering from the model collapse problem (Bowman et al., 2016). To overcome this problem, we propose a novel model that based on the variational autoregressive decoder to better represent highly structural latent variables. 2.2 Variational Autoregressive Models Recently, some works attempted to combine VAE with autoregressive models to better process input sequences. Broadly speaking, they can be categorized into two groups. Methods in the first group leverage autoregressive models to imp"
D18-1354,N16-1014,0,0.0894923,"associating latent variables to different time steps of autoregressive decoder and approximating the posterior of latent variables by augmenting the hidden states of a backward RNN. • A BOW based auxiliary objective is proposed to help preserving the diversity of generated responses. 2 2.1 Related Work Conversational Systems As neural network based models dominate the research in natural language processing, Seq2Seq models have been widely used for response generation (Sordoni et al., 2015). However, Seq2seq models suffer from the problem of generating generic responses, such as I don’t know (Li et al., 2016a). Various approaches have been proposed to address this problem, including adding additional information (Li et al., 2016b; Xing et al., 2017; Zhou et al., 2017b) and modifying the architecture of existing models (Li et al., 2016a; Xu et al., 2017; Zhou et al., 2017a). Another solution to address this problem is to add stochastic latent variables in order to change the deterministic structure of Seq2Seq models. VAE (Kingma and Welling, 2013) is one of the most successful models (Serban et al., 2017; Zhao et al., 2017; Shen et al., 2017; Cao and Clark, 2017). However, VAE-based models only us"
D18-1354,P16-1094,0,0.131353,"associating latent variables to different time steps of autoregressive decoder and approximating the posterior of latent variables by augmenting the hidden states of a backward RNN. • A BOW based auxiliary objective is proposed to help preserving the diversity of generated responses. 2 2.1 Related Work Conversational Systems As neural network based models dominate the research in natural language processing, Seq2Seq models have been widely used for response generation (Sordoni et al., 2015). However, Seq2seq models suffer from the problem of generating generic responses, such as I don’t know (Li et al., 2016a). Various approaches have been proposed to address this problem, including adding additional information (Li et al., 2016b; Xing et al., 2017; Zhou et al., 2017b) and modifying the architecture of existing models (Li et al., 2016a; Xu et al., 2017; Zhou et al., 2017a). Another solution to address this problem is to add stochastic latent variables in order to change the deterministic structure of Seq2Seq models. VAE (Kingma and Welling, 2013) is one of the most successful models (Serban et al., 2017; Zhao et al., 2017; Shen et al., 2017; Cao and Clark, 2017). However, VAE-based models only us"
D18-1354,D17-1222,1,0.881935,"Missing"
D18-1354,D16-1230,0,0.071479,"Missing"
D18-1354,N15-1020,0,0.0998218,"Missing"
D18-1354,D17-1065,0,0.0351809,"e diversity of generated responses. 2 2.1 Related Work Conversational Systems As neural network based models dominate the research in natural language processing, Seq2Seq models have been widely used for response generation (Sordoni et al., 2015). However, Seq2seq models suffer from the problem of generating generic responses, such as I don’t know (Li et al., 2016a). Various approaches have been proposed to address this problem, including adding additional information (Li et al., 2016b; Xing et al., 2017; Zhou et al., 2017b) and modifying the architecture of existing models (Li et al., 2016a; Xu et al., 2017; Zhou et al., 2017a). Another solution to address this problem is to add stochastic latent variables in order to change the deterministic structure of Seq2Seq models. VAE (Kingma and Welling, 2013) is one of the most successful models (Serban et al., 2017; Zhao et al., 2017; Shen et al., 2017; Cao and Clark, 2017). However, VAE-based models only use a single latent variable to encode the whole response sequence, thus suffering from the model collapse problem (Bowman et al., 2016). To overcome this problem, we propose a novel model that based on the variational autoregressive decoder to better"
D18-1354,P17-1061,0,0.404009,"te-of-the-art baselines. 1 Figure 1: Distributions of latent variable Introduction Recently, variational Bayesian models have shown attractive merits from both theoretical and practical perspectives (Kingma and Welling, 2013). As one of the most successful variational Bayesian models, Conditional Variational Auto-Encoder (CVAE) (Kingma et al., 2014) was proposed to improve upon the traditional Sequence-to-Sequence (Seq2Seq) dialogue models. The CVAE based models incorporate stochastic latent variables into decoders in order to generate more relevant and diverse responses (Serban et al., 2017; Zhao et al., 2017; Shen et al., 2017). However, existing CVAE ∗ Corresponding author As illustrated in Figure 1, the unimodal latent variable z used in the conventional VAE usually captures simple unimodal pattern of responses. However, in open-domain conversations, an utterance may have various responses which form complex multimodal distributions. To overcome this problem and improve the quality of generated responses, we propose a novel model, named Variational Autoregressive Decoder (VAD) to iteratively incorporate a series of latent variables into the autoregressive decoder. In particular, a distinct late"
D19-1350,P18-1189,0,0.0473887,"Missing"
D19-1350,P17-1036,0,0.0177494,"lexity and topic coherence measure compared to state-of-the-art neural topic models. 1 Introduction Probabilistic topic models have been used widely in nature language processing (Li et al., 2016; Zeng et al., 2018). The fundamental principle is that words are assumed to be generated from latent topics which can be inferred from data based on word co-occurrence patterns (Neal, 1993; Andrieu et al., 2003). In recent years, Variational Autoencoder (VAE) has been proved more effective and efficient to approximating deep, complex and underestimated variance in integrals (Kingma and Welling, 2013; He et al., 2017). However, the VAE-based topic models focus on the construction of deep neural networks to approximate the § † The two authors contributed equally to this work. Corresponding author. intractable distribution between observed words and latent topics based on log-likelihood and the learning objective is to minimise the error of reconstructing the original documents based on the learned latent topic vectors rather than improving the quality of learned topics, for example, measured by coherence scores (Kingma and Welling, 2013; Sønderby et al., 2016; Miao et al., 2016; Card et al., 2017; Srivastav"
D19-1350,P16-1199,1,0.84341,"ls to guide the learning of a VAE-based topic model. Furthermore, our proposed model is able to automatically separating background words dynamically from topic words, thus eliminating the pre-processing step of filtering infrequent and/or top frequent words, typically required for learning traditional topic models. Experimental results on the 20 Newsgroups and the NIPS datasets show superior performance both on perplexity and topic coherence measure compared to state-of-the-art neural topic models. 1 Introduction Probabilistic topic models have been used widely in nature language processing (Li et al., 2016; Zeng et al., 2018). The fundamental principle is that words are assumed to be generated from latent topics which can be inferred from data based on word co-occurrence patterns (Neal, 1993; Andrieu et al., 2003). In recent years, Variational Autoencoder (VAE) has been proved more effective and efficient to approximating deep, complex and underestimated variance in integrals (Kingma and Welling, 2013; He et al., 2017). However, the VAE-based topic models focus on the construction of deep neural networks to approximate the § † The two authors contributed equally to this work. Corresponding auth"
D19-1350,P18-1091,0,0.0164164,"e the vocabulary size and achieve better topic extraction results. Word filtering is often done heuristically. Although there have been attempts to automatically distinguishing background words and topic words, existing approaches either require a switch variable defined at each word position to indicate whether the word is a background word, which makes the models cumbersome, or model each latent topic as the deviation in logfrequency from a constant background distribution (Eisenstein et al., 2011; Smith et al., 2018). In this paper, we propose a new framework to use reinforcement learning (Pan et al., 2018; Qin et al., 2018; Yin et al., 2018) to incorporate the topic coherence measures into the learning of a neural topic model and filter background words dynamically. More concretely, given an input document, its constituent words will first be sampled 3478 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3478–3483, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics Figure 1: Neural topic model with reinforcement learning. by a weight vector w"
D19-1350,P18-1199,0,0.0214504,"ize and achieve better topic extraction results. Word filtering is often done heuristically. Although there have been attempts to automatically distinguishing background words and topic words, existing approaches either require a switch variable defined at each word position to indicate whether the word is a background word, which makes the models cumbersome, or model each latent topic as the deviation in logfrequency from a constant background distribution (Eisenstein et al., 2011; Smith et al., 2018). In this paper, we propose a new framework to use reinforcement learning (Pan et al., 2018; Qin et al., 2018; Yin et al., 2018) to incorporate the topic coherence measures into the learning of a neural topic model and filter background words dynamically. More concretely, given an input document, its constituent words will first be sampled 3478 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3478–3483, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics Figure 1: Neural topic model with reinforcement learning. by a weight vector which assigns highe"
D19-1350,P17-1072,0,0.0418122,"Missing"
D19-1350,P18-1053,0,0.0267251,"tter topic extraction results. Word filtering is often done heuristically. Although there have been attempts to automatically distinguishing background words and topic words, existing approaches either require a switch variable defined at each word position to indicate whether the word is a background word, which makes the models cumbersome, or model each latent topic as the deviation in logfrequency from a constant background distribution (Eisenstein et al., 2011; Smith et al., 2018). In this paper, we propose a new framework to use reinforcement learning (Pan et al., 2018; Qin et al., 2018; Yin et al., 2018) to incorporate the topic coherence measures into the learning of a neural topic model and filter background words dynamically. More concretely, given an input document, its constituent words will first be sampled 3478 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3478–3483, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics Figure 1: Neural topic model with reinforcement learning. by a weight vector which assigns higher weights to words"
D19-1350,N18-1035,0,0.0294293,"earning of a VAE-based topic model. Furthermore, our proposed model is able to automatically separating background words dynamically from topic words, thus eliminating the pre-processing step of filtering infrequent and/or top frequent words, typically required for learning traditional topic models. Experimental results on the 20 Newsgroups and the NIPS datasets show superior performance both on perplexity and topic coherence measure compared to state-of-the-art neural topic models. 1 Introduction Probabilistic topic models have been used widely in nature language processing (Li et al., 2016; Zeng et al., 2018). The fundamental principle is that words are assumed to be generated from latent topics which can be inferred from data based on word co-occurrence patterns (Neal, 1993; Andrieu et al., 2003). In recent years, Variational Autoencoder (VAE) has been proved more effective and efficient to approximating deep, complex and underestimated variance in integrals (Kingma and Welling, 2013; He et al., 2017). However, the VAE-based topic models focus on the construction of deep neural networks to approximate the § † The two authors contributed equally to this work. Corresponding author. intractable dist"
D19-1563,D17-1047,1,0.831698,"Missing"
D19-1563,D18-1066,0,0.112865,"(c−2 ), (c−1 ), and (c0 ). The goal of ECA is to determine which clause contains emotion cause (e.g., (c−1 )) for an emotion word (e.g., happiness in (c0 )). Previous approaches for emotion cause analysis mostly depend on rule-based methods (Lee et al., 2010; Chen et al., 2010) and machine learning algorithms (Ghazi et al., 2015; Gui et al., 2016; Xu et al., 2019). Most of them rely heavily on complicated linguistic rules or feature engineering, which is time-consuming and labor-intensive. Recent studies have focused on solving the task using neural models (Gui et al., 2017; Li et al., 2018a; Chen et al., 2018; Li et al., 2019) with well designed attention mechanism based on local text. Despite the effectiveness of neural models, there are some defects in previous studies. First, they usually consider each clause individually, i.e., ignoring the discourse context information that can impact the semantic expression among different clauses of a document. Second, prior knowledge such as sentiment lexicon and relative position information that can provide crucial emotion cause cues has not been fully exploited in neural models. To alleviate these limitations, we propose a regularized hierarchical neura"
D19-1563,C10-1021,0,0.84091,"ovided by users. Emotion cause analysis (ECA) aims to identify the reasons behind a certain emotion expression in an event text, for example: Ex.1 When the children saw the gifts I prepared carefully, (c−2 )|they cheered happily and hugged me. (c−1 ) |I was full of happiness. (c0 ) Here, Ex.1 shows a document with three clauses marked as (c−2 ), (c−1 ), and (c0 ). The goal of ECA is to determine which clause contains emotion cause (e.g., (c−1 )) for an emotion word (e.g., happiness in (c0 )). Previous approaches for emotion cause analysis mostly depend on rule-based methods (Lee et al., 2010; Chen et al., 2010) and machine learning algorithms (Ghazi et al., 2015; Gui et al., 2016; Xu et al., 2019). Most of them rely heavily on complicated linguistic rules or feature engineering, which is time-consuming and labor-intensive. Recent studies have focused on solving the task using neural models (Gui et al., 2017; Li et al., 2018a; Chen et al., 2018; Li et al., 2019) with well designed attention mechanism based on local text. Despite the effectiveness of neural models, there are some defects in previous studies. First, they usually consider each clause individually, i.e., ignoring the discourse context in"
D19-1563,D14-1179,0,0.0343443,"Missing"
D19-1563,D17-1167,1,0.818974,"cument with three clauses marked as (c−2 ), (c−1 ), and (c0 ). The goal of ECA is to determine which clause contains emotion cause (e.g., (c−1 )) for an emotion word (e.g., happiness in (c0 )). Previous approaches for emotion cause analysis mostly depend on rule-based methods (Lee et al., 2010; Chen et al., 2010) and machine learning algorithms (Ghazi et al., 2015; Gui et al., 2016; Xu et al., 2019). Most of them rely heavily on complicated linguistic rules or feature engineering, which is time-consuming and labor-intensive. Recent studies have focused on solving the task using neural models (Gui et al., 2017; Li et al., 2018a; Chen et al., 2018; Li et al., 2019) with well designed attention mechanism based on local text. Despite the effectiveness of neural models, there are some defects in previous studies. First, they usually consider each clause individually, i.e., ignoring the discourse context information that can impact the semantic expression among different clauses of a document. Second, prior knowledge such as sentiment lexicon and relative position information that can provide crucial emotion cause cues has not been fully exploited in neural models. To alleviate these limitations, we pro"
D19-1563,D16-1170,1,0.2569,"ns behind a certain emotion expression in an event text, for example: Ex.1 When the children saw the gifts I prepared carefully, (c−2 )|they cheered happily and hugged me. (c−1 ) |I was full of happiness. (c0 ) Here, Ex.1 shows a document with three clauses marked as (c−2 ), (c−1 ), and (c0 ). The goal of ECA is to determine which clause contains emotion cause (e.g., (c−1 )) for an emotion word (e.g., happiness in (c0 )). Previous approaches for emotion cause analysis mostly depend on rule-based methods (Lee et al., 2010; Chen et al., 2010) and machine learning algorithms (Ghazi et al., 2015; Gui et al., 2016; Xu et al., 2019). Most of them rely heavily on complicated linguistic rules or feature engineering, which is time-consuming and labor-intensive. Recent studies have focused on solving the task using neural models (Gui et al., 2017; Li et al., 2018a; Chen et al., 2018; Li et al., 2019) with well designed attention mechanism based on local text. Despite the effectiveness of neural models, there are some defects in previous studies. First, they usually consider each clause individually, i.e., ignoring the discourse context information that can impact the semantic expression among different clau"
D19-1563,D14-1181,0,0.00355089,"al results on the English dataset, we follow the results that are implemented in (Li et al., 2019), the only available results on this dataset (p &lt;0.001). Table 2: Experimental results on the Chinese dataset. Superscript ∗ indicates the results are reported in (Gui et al., 2017) and the rest are reprinted from the corresponding publications (p &lt;0.001). LambdaMART extracts emotion causes using learning to rank methods which based on the emotion-independent and emotiondependent features (Xu et al., 2019). • Deep learning method: CNN is a convolutional neural network for sentence classification (Kim, 2014). ConvMS-Memnet considers emotion cause analysis as a reading comprehension task and designs a multiple-slot deep memory network to model context information (Gui et al., 2017). CANN uses a co-attention neural network to identify emotion causes (Li et al., 2018a). HCS is proposed by Yu et al. (2019) using a multiplelevel hierarchical network to detect the emotion causes. MANN is the current state-ofthe-art method employing a multi-attentionbased model for emotion cause extraction (Li et al., 2019). RHNN is our proposed model. 5.1 P 0.1651 0.2757 0.7218 0.4605 0.7933 0.6901 Main Results The exp"
D19-1563,W10-0206,0,0.438743,"e emotion cause provided by users. Emotion cause analysis (ECA) aims to identify the reasons behind a certain emotion expression in an event text, for example: Ex.1 When the children saw the gifts I prepared carefully, (c−2 )|they cheered happily and hugged me. (c−1 ) |I was full of happiness. (c0 ) Here, Ex.1 shows a document with three clauses marked as (c−2 ), (c−1 ), and (c0 ). The goal of ECA is to determine which clause contains emotion cause (e.g., (c−1 )) for an emotion word (e.g., happiness in (c0 )). Previous approaches for emotion cause analysis mostly depend on rule-based methods (Lee et al., 2010; Chen et al., 2010) and machine learning algorithms (Ghazi et al., 2015; Gui et al., 2016; Xu et al., 2019). Most of them rely heavily on complicated linguistic rules or feature engineering, which is time-consuming and labor-intensive. Recent studies have focused on solving the task using neural models (Gui et al., 2017; Li et al., 2018a; Chen et al., 2018; Li et al., 2019) with well designed attention mechanism based on local text. Despite the effectiveness of neural models, there are some defects in previous studies. First, they usually consider each clause individually, i.e., ignoring the"
D19-1563,P15-1101,0,0.0484834,"Missing"
D19-1563,D18-1506,0,0.178681,"clauses marked as (c−2 ), (c−1 ), and (c0 ). The goal of ECA is to determine which clause contains emotion cause (e.g., (c−1 )) for an emotion word (e.g., happiness in (c0 )). Previous approaches for emotion cause analysis mostly depend on rule-based methods (Lee et al., 2010; Chen et al., 2010) and machine learning algorithms (Ghazi et al., 2015; Gui et al., 2016; Xu et al., 2019). Most of them rely heavily on complicated linguistic rules or feature engineering, which is time-consuming and labor-intensive. Recent studies have focused on solving the task using neural models (Gui et al., 2017; Li et al., 2018a; Chen et al., 2018; Li et al., 2019) with well designed attention mechanism based on local text. Despite the effectiveness of neural models, there are some defects in previous studies. First, they usually consider each clause individually, i.e., ignoring the discourse context information that can impact the semantic expression among different clauses of a document. Second, prior knowledge such as sentiment lexicon and relative position information that can provide crucial emotion cause cues has not been fully exploited in neural models. To alleviate these limitations, we propose a regularize"
D19-1563,P18-1087,1,0.899852,"Missing"
D19-1563,P17-1154,0,0.0573365,"sing multiple-user structures. Besides, Yu et al. (2019) proposed a multiple-level hierarchical network-based clause selection strategy. Li et al. (2019) proposed a multi-attention-based neural model to capture the mutual influences between the emotion clause and each candidate clause, and then generate the representations for the above two clauses separately. This method achieves the current best performance. However, the existing approaches usually focus on the local textural information, ignoring the discourse structure (Zubiaga et al., 2018), and prior knowledge such as sentiment lexicon (Qian et al., 2017) and relative position information, which can provide important emotion cues for emotion cause analysis task. 7 Conclusion and Future Work In this paper, we provide a regularized hierarchical neural network (RHNN) for emotion cause analysis. The proposed model aggregates discourse context information through a hierarchical learning structure and restrains the parameters with knowledge-based regularizations. We evaluate the proposed model on two public datasets in different languages. The experimental results demonstrate that our proposed method achieves the stateof-the-art performance on both"
D19-1563,D18-1137,0,0.0294088,"Missing"
D19-1563,D16-1061,0,0.0694939,"Missing"
D19-1563,W11-1720,0,0.811794,"Missing"
D19-1563,H05-1044,0,0.0637208,"lected from English novels. Each document of both datasets has only one emotion word and one or more emotion causes. It has been ensured that the emotion and the causes are relevant. The documents are segmented into several clauses manually for emotion cause analysis. The details about the two datasets are summarized in Table 1. 4.2 lected from HowNet (Dong et al., 2006) sentiment analysis lexicon set4 and the second part comes from NTUSD (Ku et al., 2006). The combination of the two parts serves as the Chinese sentiment lexicon of this research. The English sentiment lexicon comes from MPQA (Wilson et al., 2005) and we only select the words with high sentiment polarity, because they are less sensitive to contextual information and usually express consistence sentiment polarities from their prior polarity. For both sentiment lexica, we filter out the words that are not in the datasets. Ultimately, 2022 and 1348 sentiment words are selected for the Chinese and English dataset respectively. Online learning is performed with the Adam optimizer (Kingma and Ba, 2015) and initial learning rate 0.001 is adopted. The number of layers in Bi-GRU is set to 2 and dropout rate 0.5 is used to avoid overfitting. The"
D19-1563,N16-1174,0,0.117078,"Missing"
D19-1654,P14-2009,0,0.0759332,"convolutional neural networks and selectively output aspect related features for classification with gating mechanisms. Subsequently, Transformer (Vaswani et al., 2017) and BERT based methods (Devlin et al., 2018) have shown high potentials on ABSA task. There are also several studies attempting to simulate the process of human reading cognition to further improve the performance of ABSA (Lei et al., 2019; Yang et al., 2019). So far, several ABSA datasets have been constructed, including SemEval-2014 Restaurant Review dataset, Laptop Review dataset (Pontiki et al., 2014) and Twitter dataset (Dong et al., 2014). Although these three datasets have since become the benchmark datasets for the ABSA task, most sentences in these datasets consist of only one aspect or multiple aspects with the same sentiment polarity (see Table 1)2 , which makes aspect-based sentiment analysis degenerate to sentence-level sentiment analysis. Based on our empirical observation, the sentence-level sentiment classifiers without considering aspects can still achieve competitive results with many recent ABSA methods (see TextCNN and LSTM in Table 3). On the other hand, even advanced ABSA methods trained on these datasets can h"
D19-1654,S14-2004,0,0.42864,"Missing"
D19-1654,D16-1021,0,0.0541898,"sentations of sentences and aspects with pre-trained BERT. We then feed the sentence and aspect representations into capsule layers and predict the corresponding sentiment polarities. 4 4.1 Experiments Experimental Setup Experimental Data In order to evaluate the effectiveness of our model, we conduct experiments on the two MAMS datasets and SemEval-14 Restaurant Review (Pontiki et al., 2014) dataset. All models share the same data pre-processing procedure, and use the same pre-trained word embeddings. Baseline Methods We compare CapsNet with various baselines. (1) LSTM based models: TD LSTM (Tang et al., 2016a), AT LSTM (Wang et al., 2016), ATAE LSTM (Wang et al., 2016), BiLSTM enhanced with attention mechanism, IAN (Ma et al., 2017) and AOA LSTM (Huang et al., 2018); (2) CNN based model: GCAE (Xue and Li, 2018); (3) Attention based models: MemNet (Tang et al., 2016b) and AEN (Song et al., 2019). To verify the effectiveness of combining capsule networks and BERT, we also compare the performance of CapsNet-BERT with vanilla BERT model. Vanilla BERT model adopts “[CLS] sentence [SEP] aspect [SEP]” as input and predicts the sentiment polarity of the sentence towards the given aspect. Implementation D"
D19-1654,D16-1058,0,0.737445,"ntroduction Aspect-based sentiment analysis (ABSA) aims at identifying the sentiment polarity towards the specific aspect in a sentence. An target aspect refers to a word or a phrase describing an aspect of an entity. For example, in the sentence “The decor is not special at all but their amazing food makes up for it”, there are two aspect terms “decor” and “food”, and they are associated with negative and positive sentiment respectively. Recently, neural network methods have dominated the study of ABSA since these methods can be trained end-to-end and automatically learn important features. (Wang et al., 2016) proposed to learn an embedding vector for each aspect, and these aspect embeddings were used to calculate the attention weights to capture important information with regard to the given aspects. (Tang ∗ Min Yang is corresponding author Data and code can be found as: https://github.com/siatnlp/MAMS-for-ABSA 1 et al., 2016b) developed the deep memory network to compute the importance degree and text representation of each context word with multiple attention layers. (Ma et al., 2017) introduced the interactive attention networks (IAN) to interactively learn attentions in contexts and targets, a"
D19-1654,D14-1162,0,0.0950078,"attention mechanism, IAN (Ma et al., 2017) and AOA LSTM (Huang et al., 2018); (2) CNN based model: GCAE (Xue and Li, 2018); (3) Attention based models: MemNet (Tang et al., 2016b) and AEN (Song et al., 2019). To verify the effectiveness of combining capsule networks and BERT, we also compare the performance of CapsNet-BERT with vanilla BERT model. Vanilla BERT model adopts “[CLS] sentence [SEP] aspect [SEP]” as input and predicts the sentiment polarity of the sentence towards the given aspect. Implementation Details In all experiments, we use 300-dimentional word vectors pre-trained by GloVe (Pennington et al., 2014) to initialize the word embedding vectors for non-BERT models. The capsule size is set to 300. The batch sizes are set to 64 and 32 for CapsNet and CapsNet-BERT respectively. We use Adam optimizer (Kingma and Ba, 2015) to train our models. The learning rates are set to 0.0003 and 0.00003 for CapsNet and CapsNet-BERT respectively. We run all models for 5 times and report the average results on the test datasets. We fine-tune the hyper-parameters for all baselines on the validation set. 6283 Method TextCNN LSTM TD LSTM AT LSTM ATAE LSTM BiLSTM+Attn IAN AOA LSTM AEN MemNet GCAE CapsNet BERT CapsN"
I11-1168,H93-1012,0,0.198979,"Missing"
I11-1168,P01-1070,0,0.0691857,"Missing"
I11-1168,passonneau-2006-measuring,0,\N,Missing
L18-1078,strotgen-gertz-2012-temporal,0,0.0760372,"Missing"
L18-1078,W16-5002,0,0.0709891,"Missing"
L18-1078,D11-1147,0,0.0885703,"Missing"
L18-1078,W08-0606,0,0.0330734,"first priority is to figure out the types of uncertainty in microblogs. Kiefer (2005) pointed out that uncertainty can be divided into Epistemic and Hypothetical. Epistemic contains Possible and Probable. In fact, the two subclasses are fairly similar in Chinese. Wei (2013) observed Question and External frequently appeared on these posts or comments which reveals uncertainty. Considering Dynamic, one sub-class of Hypothetical, hardly existing in Chinese microblogs, we removed this label in our annotation scheme. At present, there are several corpora in different domains: (1) BioScope corpus (Vincze et al., 2008) annotated uncertainty, negation sentences and their scope in biomedical texts containing 20,879 sentences from 3,236 documents. (2) the dataset for CoNLL’2010 shared task (Vincze, 2010) consisted of biological part of BioScope corpus and the selection of Wikipedia articles, which annotated uncertain sentences and cues. (3) Uncertainty Corpus in complex spoken dialogue systems derived from 120 digital dialogues recording from 60 students, totaling 2,171 turns for students and 2,531 turns for tutor. (4) The Scientific Literature Corpus for Chinese (Chen et al., 2013 ) including 19 full papers a"
L18-1078,W10-3001,0,0.0887126,"Missing"
L18-1078,J96-2004,0,0.756853,"Missing"
O05-2006,P97-1008,0,0.0324378,"Missing"
O05-2006,P97-1009,0,0.229488,"Missing"
O05-2006,M98-1006,0,0.0571489,"Missing"
O05-2006,J93-1007,0,0.287471,"Missing"
O05-2006,P03-1016,0,0.126057,"Missing"
O05-2006,W03-1708,0,0.0411392,"Missing"
O05-2006,J90-1003,0,\N,Missing
O05-2006,W00-1209,0,\N,Missing
O05-4006,J90-1003,0,0.0287936,"Missing"
O05-4006,W99-0707,0,0.0516261,"Missing"
O05-4006,J93-2004,0,0.0264824,"Missing"
O05-4006,xia-etal-2000-developing,0,0.0976994,"Missing"
O05-4006,C02-1145,0,0.0465314,"Missing"
P14-2101,W13-0102,0,0.0313411,"Missing"
P14-2101,C10-2069,0,0.332195,"ing of the Association for Computational Linguistics (Short Papers), pages 618–624, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics relating to a topic; and - We show that summarisation algorithms, which are independent of extenal sources, can be used with success to label topics, presenting a higher perfomance than the top-n terms baseline. was defined as an optimisation problem involving the minimisation of the KL divergence between a given topic and the candidate labels while maximising the mutual information between these two word distributions. Lau et al. (2010) proposed to label topics by selecting top-n terms to label the overall topic based on different ranking mechanisms including pointwise mutual information and conditional probabilities. 2 Methodology We propose to approach the topic labelling problem as a multi-document summarisation task. The following describes our proposed framework to characterise documents relevant to a topic. Methods relying on external sources for automatic labelling of topics include the work by Magatti et al. (2009) which derived candidate topic labels for topics induced by LDA using the hierarchy obtained from the Go"
P14-2101,P11-1154,0,0.769254,"dels Learned from Twitter by Summarisation Amparo Elizabeth Cano Basave† Yulan He‡ Ruifeng Xu§ † Knowledge Media Institute, Open University, UK ‡ School of Engineering and Applied Science, Aston University, UK § Key Laboratory of Network Oriented Intelligent Computation Shenzhen Graduate School, Harbin Institute of Technology, China amparo.cano@open.ac.uk, y.he@cantab.net, xuruifeng@hitsz.edu.cn Abstract ence (Aletras and Stevenson, 2013; Mimno et al., 2011; Newman et al., 2010) and for characterising the semantic content of a topic through automatic labelling techniques (Hulpus et al., 2013; Lau et al., 2011; Mei et al., 2007). In this paper we focus on the latter. Our research task of automatic labelling a topic consists on selecting a set of words that best describes the semantics of the terms involved in this topic. The most generic approach to automatic labelling has been to use as primitive labels the topn words in a topic distribution learned by a topic model such as LDA (Griffiths and Steyvers, 2004; Blei et al., 2003). Such top words are usually ranked using the marginal probabilities P (wi |tj ) associated with each word wi for a given topic tj . This task can be illustrated by consideri"
P14-2101,E12-1022,0,0.0130221,"opic pairs (ti − tj ) do j 8: Collect relevant news articles CN W of topic tj from the NW set. j 9: Extract the headlines of news articles from CN W and select the top x most frequent words as the gold standard label for topic ti in the TW set 10: end for ROUGE-1 These steps can be outlined as follows:1) We ran LDA on TW and NW separately for each category with the number of topics set to 100; 2) We then aligned the Twitter topics and Newswire topics by the similarity measurement of word distributions of these topics (Ercan and Cicekli, 2008; Haghighi and Vanderwende, 2009; Wang et al., 2009; Delort and Alfonseca, 2012); 3) Finally to generate the GS label for each aligned topic pair (ti − tj ), we extracted the headlines of the news articles relevant to tj and selected the top x most frequent words (after stop word removal and stemming). The generated label was used as the gold War DisAc Edu LawCri TT 0.162 0.134 0.106 0.035 SB 0.184 0.194 0.240 0.159 TFIDF 0.192 0.160 0.187 0.149 MMR 0.154 0.132 0.104 0.034 TR 0.141 0.124 0.023 0.115 Table 1: Average ROUGE-1 for topic labels at x = {1..10}, generated from the TW dataset. The generated labels with summarisation at x = 5 are presented in Table 2, where GS re"
P14-2101,N06-1059,0,0.0446431,"Evaluation of automatic topic labelling often relied on human assessment which requires heavy manual effort (Lau et al., 2011; Hulpus et al., 2013). However performing human evaluations of Social Media test sets comprising thousands of inputs become a difficult task. This is due to both the corpus size, the diversity of event-related topics and the limited availability of domain experts. To alleviate this issue here, we followed the distribution similarity approach, which has been widely applied in the automatic generation of gold standards (GSs) for summary evaluations (Donaway et al., 2000; Lin et al., 2006; Louis and Nenkova, 2009; Louis and Nenkova, 2013). This approach compares two corpora, one for which no GS labels exist, against a reference corpus for which a GS exists. In our case these corpora correspond to the TW and a Newswire dataset (NW). Since previous Maximal Marginal Relevance (MMR) This is a relevance based ranking algorithm (Carbonell and Goldstein, 1998), which avoids redundancy in the documents used for generating a summary. It measures the degree of dissimilarity between the documents considered and previously selected ones already in the ranked list. Text Rank (TR) This is a"
P14-2101,P12-1056,0,0.153845,"ia, WordNet) for supporting the automatic labelling of topics by deriving candidate labels by means of lexical (Lau et al., 2011; Magatti et al., 2009; Mei et al., 2007) or graphbased (Hulpus et al., 2013) algorithms applied on these sources. Mei et al. (2007) proposed an unsupervised probabilistic methodology to automatically assign a label to a topic model. Their proposed approach Introduction Topic model based algorithms applied to social media data have become a mainstream technique in performing various tasks including sentiment analysis (He, 2012) and event detection (Zhao et al., 2012; Diao et al., 2012). However, one of the main challenges is the task of understanding the semantics of a topic. This task has been approached by investigating methodologies for identifying meaningful topics through semantic coher618 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 618–624, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics relating to a topic; and - We show that summarisation algorithms, which are independent of extenal sources, can be used with success to label topics, presenting a higher perfo"
P14-2101,W04-1013,0,0.0259931,"eprocessing steps were performed on NW. Therefore, following a similarity alignment approach we performed the steps oulined in Algorithm 1 for generating the GS topic labels of a topic in TW. standard label for the corresponding Twitter topic ti in the topic pair. 4 Experimental Results We compared the results of the summarisation techniques with the top terms (TT) of a topic as our baseline. These TT set corresponds to the top x terms ranked based on the probability of the word given the topic (p(w|k)) from the topic model. We evaluated these summarisation approaches with the ROUGE-1 method (Lin, 2004), a widely used summarisation evaluation metric that correlates well with human evaluation (Liu and Liu, 2008). This method measures the overlap of words between the generated summary and a reference, in our case the GS generated from the NW dataset. The evaluation was performed at x = {1, .., 10}. Figure 1 presents the ROUGE-1 performance of the summarisation approaches as the lengthx of the generated topic label increases. We can see in all four categories that the SB and TFIDF approaches provide a better summarisation coverage as the length of the topic label increases. In particular, in bo"
P14-2101,W00-0408,0,0.0353846,"Missing"
P14-2101,P08-2051,0,0.018893,"med the steps oulined in Algorithm 1 for generating the GS topic labels of a topic in TW. standard label for the corresponding Twitter topic ti in the topic pair. 4 Experimental Results We compared the results of the summarisation techniques with the top terms (TT) of a topic as our baseline. These TT set corresponds to the top x terms ranked based on the probability of the word given the topic (p(w|k)) from the topic model. We evaluated these summarisation approaches with the ROUGE-1 method (Lin, 2004), a widely used summarisation evaluation metric that correlates well with human evaluation (Liu and Liu, 2008). This method measures the overlap of words between the generated summary and a reference, in our case the GS generated from the NW dataset. The evaluation was performed at x = {1, .., 10}. Figure 1 presents the ROUGE-1 performance of the summarisation approaches as the lengthx of the generated topic label increases. We can see in all four categories that the SB and TFIDF approaches provide a better summarisation coverage as the length of the topic label increases. In particular, in both the Education and Law & Crime categories, both SB and TFIDF outperforms TT and TR by a large margin. The ob"
P14-2101,D09-1032,0,0.0116069,"matic topic labelling often relied on human assessment which requires heavy manual effort (Lau et al., 2011; Hulpus et al., 2013). However performing human evaluations of Social Media test sets comprising thousands of inputs become a difficult task. This is due to both the corpus size, the diversity of event-related topics and the limited availability of domain experts. To alleviate this issue here, we followed the distribution similarity approach, which has been widely applied in the automatic generation of gold standards (GSs) for summary evaluations (Donaway et al., 2000; Lin et al., 2006; Louis and Nenkova, 2009; Louis and Nenkova, 2013). This approach compares two corpora, one for which no GS labels exist, against a reference corpus for which a GS exists. In our case these corpora correspond to the TW and a Newswire dataset (NW). Since previous Maximal Marginal Relevance (MMR) This is a relevance based ranking algorithm (Carbonell and Goldstein, 1998), which avoids redundancy in the documents used for generating a summary. It measures the degree of dissimilarity between the documents considered and previously selected ones already in the ranked list. Text Rank (TR) This is a graph-based summariser m"
P14-2101,N09-1041,0,0.0214889,"case 0.7) 6: end for 7: for each of the extracted topic pairs (ti − tj ) do j 8: Collect relevant news articles CN W of topic tj from the NW set. j 9: Extract the headlines of news articles from CN W and select the top x most frequent words as the gold standard label for topic ti in the TW set 10: end for ROUGE-1 These steps can be outlined as follows:1) We ran LDA on TW and NW separately for each category with the number of topics set to 100; 2) We then aligned the Twitter topics and Newswire topics by the similarity measurement of word distributions of these topics (Ercan and Cicekli, 2008; Haghighi and Vanderwende, 2009; Wang et al., 2009; Delort and Alfonseca, 2012); 3) Finally to generate the GS label for each aligned topic pair (ti − tj ), we extracted the headlines of the news articles relevant to tj and selected the top x most frequent words (after stop word removal and stemming). The generated label was used as the gold War DisAc Edu LawCri TT 0.162 0.134 0.106 0.035 SB 0.184 0.194 0.240 0.159 TFIDF 0.192 0.160 0.187 0.149 MMR 0.154 0.132 0.104 0.034 TR 0.141 0.124 0.023 0.115 Table 1: Average ROUGE-1 for topic labels at x = {1..10}, generated from the TW dataset. The generated labels with summarisatio"
P14-2101,J13-2002,0,0.0158926,"en relied on human assessment which requires heavy manual effort (Lau et al., 2011; Hulpus et al., 2013). However performing human evaluations of Social Media test sets comprising thousands of inputs become a difficult task. This is due to both the corpus size, the diversity of event-related topics and the limited availability of domain experts. To alleviate this issue here, we followed the distribution similarity approach, which has been widely applied in the automatic generation of gold standards (GSs) for summary evaluations (Donaway et al., 2000; Lin et al., 2006; Louis and Nenkova, 2009; Louis and Nenkova, 2013). This approach compares two corpora, one for which no GS labels exist, against a reference corpus for which a GS exists. In our case these corpora correspond to the TW and a Newswire dataset (NW). Since previous Maximal Marginal Relevance (MMR) This is a relevance based ranking algorithm (Carbonell and Goldstein, 1998), which avoids redundancy in the documents used for generating a summary. It measures the degree of dissimilarity between the documents considered and previously selected ones already in the ranked list. Text Rank (TR) This is a graph-based summariser method (Mihalcea and Tarau,"
P14-2101,N13-1135,0,0.0127601,"s on topics derived from well formatted and static documents. However in contrast to this type of content, the labelling of topics derived from tweets presents different challenges. In nature micropost content is sparse and present ill-formed words. Moreover, the use of Twitter as the “what’shappening-right now” tool, introduces new eventdependent relations between words which might not have a counter part in existing knowledge sources (e.g. Wikipedia). Our original interest in labelling topics stems from work in topic model based event extraction from social media, in particular from tweets (Shen et al., 2013; Diao et al., 2012). As opposed to previous approaches, the research presented in this paper addresses the labelling of topics exposing event-related content that might not have a counter part on existing external sources. Based on the observation that a short summary of a collection of documents can serve as a label characterising the collection, we propose to generate topic label candidates based on the summarisation of a topic’s relevant documents. Our contributions are two-fold: - We propose a novel approach for topics labelling that relies on term relevance of documents 2.2 Automatic Lab"
P14-2101,P09-2075,0,0.013068,"of the extracted topic pairs (ti − tj ) do j 8: Collect relevant news articles CN W of topic tj from the NW set. j 9: Extract the headlines of news articles from CN W and select the top x most frequent words as the gold standard label for topic ti in the TW set 10: end for ROUGE-1 These steps can be outlined as follows:1) We ran LDA on TW and NW separately for each category with the number of topics set to 100; 2) We then aligned the Twitter topics and Newswire topics by the similarity measurement of word distributions of these topics (Ercan and Cicekli, 2008; Haghighi and Vanderwende, 2009; Wang et al., 2009; Delort and Alfonseca, 2012); 3) Finally to generate the GS label for each aligned topic pair (ti − tj ), we extracted the headlines of the news articles relevant to tj and selected the top x most frequent words (after stop word removal and stemming). The generated label was used as the gold War DisAc Edu LawCri TT 0.162 0.134 0.106 0.035 SB 0.184 0.194 0.240 0.159 TFIDF 0.192 0.160 0.187 0.149 MMR 0.154 0.132 0.104 0.034 TR 0.141 0.124 0.023 0.115 Table 1: Average ROUGE-1 for topic labels at x = {1..10}, generated from the TW dataset. The generated labels with summarisation at x = 5 are pres"
P14-2101,D12-1134,0,0.0256048,"urces (e.g. Wikipedia, WordNet) for supporting the automatic labelling of topics by deriving candidate labels by means of lexical (Lau et al., 2011; Magatti et al., 2009; Mei et al., 2007) or graphbased (Hulpus et al., 2013) algorithms applied on these sources. Mei et al. (2007) proposed an unsupervised probabilistic methodology to automatically assign a label to a topic model. Their proposed approach Introduction Topic model based algorithms applied to social media data have become a mainstream technique in performing various tasks including sentiment analysis (He, 2012) and event detection (Zhao et al., 2012; Diao et al., 2012). However, one of the main challenges is the task of understanding the semantics of a topic. This task has been approached by investigating methodologies for identifying meaningful topics through semantic coher618 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 618–624, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics relating to a topic; and - We show that summarisation algorithms, which are independent of extenal sources, can be used with success to label topics, prese"
P14-2101,D11-1024,0,0.075931,"Missing"
P14-2101,N10-1012,0,0.0824927,"Missing"
P14-2101,W04-3252,0,\N,Missing
P14-2139,W06-1615,0,0.0434173,"Related works TTL has been widely used before the formal concept and definition of TTL was given in (Arnold, 2007). Wan introduced the co-training method into cross-lingual opinion analysis (Wan, 2009; Zhou et al., 2011), and Aue et al. introduced transfer learning into cross domain analysis (Aue, 2005) which solves similar problems. In this paper, we will use the terms source language and target language to refer to all cross lingual/domain analysis. Traditionally, transfer learning methods focus on how to estimate the confidence score of transferred samples in the target language or domain (Blitzer et al, 2006, Huang et al., 2007; Sugiyama et al., 2008, Chen et al, 2011, Lu et al., 2011). In some tasks, researchers utilize NLP tools such as alignment to reduce the bias towards that of ___________________ 860 *Corresponding author Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 860–865, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics the source language in transfer learning (Meng et al., 2012). However, detecting misclassification in transferred samples (referred to as class noise) and reducing"
P14-2139,P13-2084,0,0.0282056,"two basic methods for class noise detection in machine learning. The first is the classification based method (Brodley and Friedl, 1999; Zhu et al, 2003; Zhu 2004; Sluban et al., 2010) and the second is the graph based method (Zighed et al, 2002; Muhlenbach et al, 2004; Jiang and Zhou, 2004). Class noise detection can also be applied to semi-supervised learning because noise can accumulate in iterations too. Li employed Zighed’s cut edge weight statistic method in self-training (Li and Zhou, 2005) and co-training (Li and Zhou, 2011). Chao used Li’s method in tri-training (Chao et al, 2008). (Fukumoto et al, 2013) used the support vectors to detect class noise in semi-supervised learning. In TTL, however, training and testing samples cannot be assumed to have the same distributions. Thus, noise detection methods used in semisupervised learning are not directly suited in TTL. Y. Cheng has tried to use semi-supervised method (Jiang and Zhou, 2004) in transfer learning (Cheng and Li, 2009). His experiment showed that their approach would work when the source domain and the target domain share similar distributions. How to reduce negative transfers is still a problem in transfer learning. 3 Our Approach In"
P14-2139,P09-1027,0,0.379913,"are used beating the performance degradation curse of most transfer learning methods when training data reaches certain size. The rest of the paper is organized as follows. Section 2 introduces related works in transfer learning, cross lingual opinion analysis, and class noise detection technology. Section 3 presents our algorithm. Section 4 gives performance evaluation. Section 5 concludes this paper. 2 Related works TTL has been widely used before the formal concept and definition of TTL was given in (Arnold, 2007). Wan introduced the co-training method into cross-lingual opinion analysis (Wan, 2009; Zhou et al., 2011), and Aue et al. introduced transfer learning into cross domain analysis (Aue, 2005) which solves similar problems. In this paper, we will use the terms source language and target language to refer to all cross lingual/domain analysis. Traditionally, transfer learning methods focus on how to estimate the confidence score of transferred samples in the target language or domain (Blitzer et al, 2006, Huang et al., 2007; Sugiyama et al., 2008, Chen et al, 2011, Lu et al., 2011). In some tasks, researchers utilize NLP tools such as alignment to reduce the bias towards that of __"
P14-2139,W03-1730,0,0.0705095,"Missing"
P14-2139,P11-1033,0,0.0361894,"TTL was given in (Arnold, 2007). Wan introduced the co-training method into cross-lingual opinion analysis (Wan, 2009; Zhou et al., 2011), and Aue et al. introduced transfer learning into cross domain analysis (Aue, 2005) which solves similar problems. In this paper, we will use the terms source language and target language to refer to all cross lingual/domain analysis. Traditionally, transfer learning methods focus on how to estimate the confidence score of transferred samples in the target language or domain (Blitzer et al, 2006, Huang et al., 2007; Sugiyama et al., 2008, Chen et al, 2011, Lu et al., 2011). In some tasks, researchers utilize NLP tools such as alignment to reduce the bias towards that of ___________________ 860 *Corresponding author Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 860–865, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics the source language in transfer learning (Meng et al., 2012). However, detecting misclassification in transferred samples (referred to as class noise) and reducing negative transfers are still an unresolved problem. There are two basic methods"
P14-2139,P12-1060,0,0.431442,"focus on how to estimate the confidence score of transferred samples in the target language or domain (Blitzer et al, 2006, Huang et al., 2007; Sugiyama et al., 2008, Chen et al, 2011, Lu et al., 2011). In some tasks, researchers utilize NLP tools such as alignment to reduce the bias towards that of ___________________ 860 *Corresponding author Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 860–865, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics the source language in transfer learning (Meng et al., 2012). However, detecting misclassification in transferred samples (referred to as class noise) and reducing negative transfers are still an unresolved problem. There are two basic methods for class noise detection in machine learning. The first is the classification based method (Brodley and Friedl, 1999; Zhu et al, 2003; Zhu 2004; Sluban et al., 2010) and the second is the graph based method (Zighed et al, 2002; Muhlenbach et al, 2004; Jiang and Zhou, 2004). Class noise detection can also be applied to semi-supervised learning because noise can accumulate in iterations too. Li employed Zighed’s c"
P15-2003,D14-1110,0,0.187102,"Missing"
P15-2003,D14-1179,0,0.0363681,"Missing"
P15-2003,C14-1048,0,0.0187377,"resentations of word senses. Our learned representations outperform the publicly available embeddings on 2 out of 4 metrics in the word similarity task, and 6 out of 13 sub tasks in the analogical reasoning task. 1 Introduction With the rapid development of deep neural networks and parallel computing, distributed representation of knowledge attracts much research interest. Models for learning distributed representations of knowledge have been proposed at different granularity level, including word sense level (Huang et al., 2012; Chen et al., 2014; Neelakantan et al., 2014; Tian et al., 2014; Guo et al., 2014), word level (Rummelhart, 1986; Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Mikolov et al., 2010; Mikolov et al., 2013), phrase level (Socher et al., 2010; Zhang et al., 2014; Cho et al., 2014), sentence level (Mikolov et al., 2010; Socher et al., 2013; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014), discourse level (Ji and Eisenstein, 2014) and document level (Le and Mikolov, 2014). Focusing on the aforementioned two problems, this paper proposes to learn distributed representations of word senses through WordNet gloss composition and context clusterin"
P15-2003,P12-1092,0,0.678402,"eddings are used by a context clustering based model to generate the distributed representations of word senses. Our learned representations outperform the publicly available embeddings on 2 out of 4 metrics in the word similarity task, and 6 out of 13 sub tasks in the analogical reasoning task. 1 Introduction With the rapid development of deep neural networks and parallel computing, distributed representation of knowledge attracts much research interest. Models for learning distributed representations of knowledge have been proposed at different granularity level, including word sense level (Huang et al., 2012; Chen et al., 2014; Neelakantan et al., 2014; Tian et al., 2014; Guo et al., 2014), word level (Rummelhart, 1986; Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Mikolov et al., 2010; Mikolov et al., 2013), phrase level (Socher et al., 2010; Zhang et al., 2014; Cho et al., 2014), sentence level (Mikolov et al., 2010; Socher et al., 2013; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014), discourse level (Ji and Eisenstein, 2014) and document level (Le and Mikolov, 2014). Focusing on the aforementioned two problems, this paper proposes to learn distributed rep"
P15-2003,P14-1002,0,0.00766999,"odels for learning distributed representations of knowledge have been proposed at different granularity level, including word sense level (Huang et al., 2012; Chen et al., 2014; Neelakantan et al., 2014; Tian et al., 2014; Guo et al., 2014), word level (Rummelhart, 1986; Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Mikolov et al., 2010; Mikolov et al., 2013), phrase level (Socher et al., 2010; Zhang et al., 2014; Cho et al., 2014), sentence level (Mikolov et al., 2010; Socher et al., 2013; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014), discourse level (Ji and Eisenstein, 2014) and document level (Le and Mikolov, 2014). Focusing on the aforementioned two problems, this paper proposes to learn distributed representations of word senses through WordNet gloss composition and context clustering. The basic idea is that a word sense is represented as a synonym set (synset) in WordNet. In this way, instead of assigning a fixed sense number to each word as in the 15 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 15–20, c Beijing, China, Ju"
P15-2003,P14-1062,0,0.00623338,"ng, distributed representation of knowledge attracts much research interest. Models for learning distributed representations of knowledge have been proposed at different granularity level, including word sense level (Huang et al., 2012; Chen et al., 2014; Neelakantan et al., 2014; Tian et al., 2014; Guo et al., 2014), word level (Rummelhart, 1986; Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Mikolov et al., 2010; Mikolov et al., 2013), phrase level (Socher et al., 2010; Zhang et al., 2014; Cho et al., 2014), sentence level (Mikolov et al., 2010; Socher et al., 2013; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014), discourse level (Ji and Eisenstein, 2014) and document level (Le and Mikolov, 2014). Focusing on the aforementioned two problems, this paper proposes to learn distributed representations of word senses through WordNet gloss composition and context clustering. The basic idea is that a word sense is represented as a synonym set (synset) in WordNet. In this way, instead of assigning a fixed sense number to each word as in the 15 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on"
P15-2003,P10-1040,0,0.0320513,"ure work. the closest to vb − va + vc . WordRep is a benchmark collection for the research on learning distributed word representations, which expands the Mikolov et al.’s analogical reasoning questions. In our experiments, we use one evaluation set in WordRep, the WordNet collection which consists of 13 sub tasks. We use the precision p × 100 as metric for each sub task. Table 2 shows the results on the 13 sub tasks. The Word Pair column is the number of word pairs of each sub task. The results of C&W were obtained using the 50-dimensional word embeddings that were made publicly available by Turian et al. (2010).6 The CBOW results were previously reported in (Gao et al., 2014). It can be observed that among 13 subtasks, our model outperforms the others by a good margin in 6 subtasks, Attribute, Causes, Entails, IsA, MadeOf and RelatedTo. 3.3 Analogical Reasoning Task 3.4 Discussion The analogical reasoning task introduced by (Mikolov et al., 2013) consists of questions of the form “a is to b is as c is to ”, where (a, b) and (c, ) are two word pairs. The goal is to find a word d∗ in vocabulary V whose representation vector is Although our evaluation results on the word similarity task and the analogi"
P15-2003,D14-1181,0,0.062281,"ion of knowledge attracts much research interest. Models for learning distributed representations of knowledge have been proposed at different granularity level, including word sense level (Huang et al., 2012; Chen et al., 2014; Neelakantan et al., 2014; Tian et al., 2014; Guo et al., 2014), word level (Rummelhart, 1986; Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Mikolov et al., 2010; Mikolov et al., 2013), phrase level (Socher et al., 2010; Zhang et al., 2014; Cho et al., 2014), sentence level (Mikolov et al., 2010; Socher et al., 2013; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014), discourse level (Ji and Eisenstein, 2014) and document level (Le and Mikolov, 2014). Focusing on the aforementioned two problems, this paper proposes to learn distributed representations of word senses through WordNet gloss composition and context clustering. The basic idea is that a word sense is represented as a synonym set (synset) in WordNet. In this way, instead of assigning a fixed sense number to each word as in the 15 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan"
P15-2003,P14-1011,0,0.0245325,"oning task. 1 Introduction With the rapid development of deep neural networks and parallel computing, distributed representation of knowledge attracts much research interest. Models for learning distributed representations of knowledge have been proposed at different granularity level, including word sense level (Huang et al., 2012; Chen et al., 2014; Neelakantan et al., 2014; Tian et al., 2014; Guo et al., 2014), word level (Rummelhart, 1986; Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Mikolov et al., 2010; Mikolov et al., 2013), phrase level (Socher et al., 2010; Zhang et al., 2014; Cho et al., 2014), sentence level (Mikolov et al., 2010; Socher et al., 2013; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014), discourse level (Ji and Eisenstein, 2014) and document level (Le and Mikolov, 2014). Focusing on the aforementioned two problems, this paper proposes to learn distributed representations of word senses through WordNet gloss composition and context clustering. The basic idea is that a word sense is represented as a synonym set (synset) in WordNet. In this way, instead of assigning a fixed sense number to each word as in the 15 Proceedings of the 53rd Annua"
P15-2003,D14-1113,0,0.674777,"ac.uk 1 Abstract In distributed representations of word senses, each word sense is usually represented by a dense and real-valued vector in a low-dimensional space which captures the contextual semantic information. Most existing approaches adopted a clusterbased paradigm, which produces different sense vectors for each polysemy or homonymy through clustering the context of a target word. However, this paradigm usually has two limitations: (1) The performance of these approaches is sensitive to the clustering algorithm which requires the setting of the sense number for each word. For example, Neelakantan et al. (2014) proposed two clustering based model: the Multi-Sense Skip-Gram (MSSG) model and Non-Parametric Multi-Sense Skip-Gram (NP-MSSG) model. MSSG assumes each word has the same k-sense (e.g. k = 3), i.e., the same number of possible senses. However, the number of senses in WordNet (Miller, 1995) varies from 1 such as “ben” to 75 such as “break”. As such, fixing the number of senses for all words would result in poor representations. NP-MSSG can learn the number of senses for each word directly from data. But it requires a tuning of a hyperparameter λ which controls the creation of cluster centroids"
P15-2003,D13-1170,0,0.00141234,"and parallel computing, distributed representation of knowledge attracts much research interest. Models for learning distributed representations of knowledge have been proposed at different granularity level, including word sense level (Huang et al., 2012; Chen et al., 2014; Neelakantan et al., 2014; Tian et al., 2014; Guo et al., 2014), word level (Rummelhart, 1986; Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Mikolov et al., 2010; Mikolov et al., 2013), phrase level (Socher et al., 2010; Zhang et al., 2014; Cho et al., 2014), sentence level (Mikolov et al., 2010; Socher et al., 2013; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014), discourse level (Ji and Eisenstein, 2014) and document level (Le and Mikolov, 2014). Focusing on the aforementioned two problems, this paper proposes to learn distributed representations of word senses through WordNet gloss composition and context clustering. The basic idea is that a word sense is represented as a synonym set (synset) in WordNet. In this way, instead of assigning a fixed sense number to each word as in the 15 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th Interna"
P15-2003,C14-1016,0,\N,Missing
P19-1462,D17-1047,0,0.138726,", where opinions on the aspects “SAFETY” and “PRICE” are expressed for target “location1” but not for target “location2”, whose Corresponding Author Aspect Sentiment location1 SAFETY Positive location1 PRICE Negative location2 TRANSIT Negative Figure 1: Example of TABSA task. Highly correlative words and corresponding aspects are in the same color. Entity names are masked by location1 and location2. Introduction ∗ Target Aspect-based sentiment analysis (ABSA) is a basic subtask of TABSA, which aims at inferring the sentiment polarities of different aspects in the sentence (Ruder et al., 2016; Chen et al., 2017; Gui et al., 2017; Peng et al., 2018; Ma et al., 2018a). Recently, attention-based neural models achieve remarkable success in ABSA (Fan et al., 2018; Wang et al., 2016; Tang et al., 2016). In TABSA task, the attention-based sentiment LSTM (Ma et al., 2018b) is proposed to tackle the challenges of both aspect-based sentiment analysis and targeted sentiment analysis by incorporating external knowledge. For neural model improvement, a delayed memory is proposed to track and update the states of targets at the right time with external memory (Liu et al., 2018). Despite the remarkable progress ma"
P19-1462,N18-2045,0,0.241864,"n the sentence (Ruder et al., 2016; Chen et al., 2017; Gui et al., 2017; Peng et al., 2018; Ma et al., 2018a). Recently, attention-based neural models achieve remarkable success in ABSA (Fan et al., 2018; Wang et al., 2016; Tang et al., 2016). In TABSA task, the attention-based sentiment LSTM (Ma et al., 2018b) is proposed to tackle the challenges of both aspect-based sentiment analysis and targeted sentiment analysis by incorporating external knowledge. For neural model improvement, a delayed memory is proposed to track and update the states of targets at the right time with external memory (Liu et al., 2018). Despite the remarkable progress made by the previous works, they usually utilize contextindependent or randomly initialized vectors to rep4678 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4678–4683 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics • The aspect embedding is fine-tuned to be close to the highly correlated target and be away from the irrelevant targets. • Experiment results on SentiHood and Semeval 2015 show that our proposed method can be directly incorporated into embeddingbased TABSA"
P19-1462,D18-1504,0,0.0359414,"Missing"
P19-1462,D16-1058,0,0.177406,"ation1 SAFETY Positive location1 PRICE Negative location2 TRANSIT Negative Figure 1: Example of TABSA task. Highly correlative words and corresponding aspects are in the same color. Entity names are masked by location1 and location2. Introduction ∗ Target Aspect-based sentiment analysis (ABSA) is a basic subtask of TABSA, which aims at inferring the sentiment polarities of different aspects in the sentence (Ruder et al., 2016; Chen et al., 2017; Gui et al., 2017; Peng et al., 2018; Ma et al., 2018a). Recently, attention-based neural models achieve remarkable success in ABSA (Fan et al., 2018; Wang et al., 2016; Tang et al., 2016). In TABSA task, the attention-based sentiment LSTM (Ma et al., 2018b) is proposed to tackle the challenges of both aspect-based sentiment analysis and targeted sentiment analysis by incorporating external knowledge. For neural model improvement, a delayed memory is proposed to track and update the states of targets at the right time with external memory (Liu et al., 2018). Despite the remarkable progress made by the previous works, they usually utilize contextindependent or randomly initialized vectors to rep4678 Proceedings of the 57th Annual Meeting of the Association fo"
P19-1462,D17-1056,0,0.0184271,"he fine-tuning method aims to move closer to the homologous target and further away from the irrelevant one by iteratively minimizes the squared Euclidean. The objective function is thus divided into two parts: d(˜ a, ˜t, t0 ) = n hX m  X i=1 where mean(·) is an average function, and the vector u can be computed by a non-linear function of basic embedding matrix X: u = f (X |· W + b) (4) where f is a non-linear operation function like sigmoid, W ∈ Rm and b ∈ Rn denote the weight matrix and bias respectively. The target representation is inspired by the recent success of embedding refinement (Yu et al., 2017). For each target, our reconstruction operation aims to get a contextual relevant embedding by iteratively minimizes the squared Euclidean between the target and the highly correlative words in the sentence. The objective function is defined as: d(˜t, t) = n X m  X (t˜ji − tji )2 + λu0i i=1 (5) j=1 where λu0i aims to control the sparseness of vector u0 . Through the iterative procedure, the vector representation of the target will be iteratively updated until the number of the non-zero elements of vector u0 less than the threshold value: k 6 c. Where k is the number of the non-zero elements"
P19-1462,P18-1233,0,0.0249984,"TY” and “PRICE” are expressed for target “location1” but not for target “location2”, whose Corresponding Author Aspect Sentiment location1 SAFETY Positive location1 PRICE Negative location2 TRANSIT Negative Figure 1: Example of TABSA task. Highly correlative words and corresponding aspects are in the same color. Entity names are masked by location1 and location2. Introduction ∗ Target Aspect-based sentiment analysis (ABSA) is a basic subtask of TABSA, which aims at inferring the sentiment polarities of different aspects in the sentence (Ruder et al., 2016; Chen et al., 2017; Gui et al., 2017; Peng et al., 2018; Ma et al., 2018a). Recently, attention-based neural models achieve remarkable success in ABSA (Fan et al., 2018; Wang et al., 2016; Tang et al., 2016). In TABSA task, the attention-based sentiment LSTM (Ma et al., 2018b) is proposed to tackle the challenges of both aspect-based sentiment analysis and targeted sentiment analysis by incorporating external knowledge. For neural model improvement, a delayed memory is proposed to track and update the states of targets at the right time with external memory (Liu et al., 2018). Despite the remarkable progress made by the previous works, they usuall"
P19-1462,D14-1162,0,0.0903388,"Missing"
P19-1462,S15-2082,0,0.162248,"Missing"
P19-1462,D16-1103,0,0.0372224,"en in Figure 1, e.g., where opinions on the aspects “SAFETY” and “PRICE” are expressed for target “location1” but not for target “location2”, whose Corresponding Author Aspect Sentiment location1 SAFETY Positive location1 PRICE Negative location2 TRANSIT Negative Figure 1: Example of TABSA task. Highly correlative words and corresponding aspects are in the same color. Entity names are masked by location1 and location2. Introduction ∗ Target Aspect-based sentiment analysis (ABSA) is a basic subtask of TABSA, which aims at inferring the sentiment polarities of different aspects in the sentence (Ruder et al., 2016; Chen et al., 2017; Gui et al., 2017; Peng et al., 2018; Ma et al., 2018a). Recently, attention-based neural models achieve remarkable success in ABSA (Fan et al., 2018; Wang et al., 2016; Tang et al., 2016). In TABSA task, the attention-based sentiment LSTM (Ma et al., 2018b) is proposed to tackle the challenges of both aspect-based sentiment analysis and targeted sentiment analysis by incorporating external knowledge. For neural model improvement, a delayed memory is proposed to track and update the states of targets at the right time with external memory (Liu et al., 2018). Despite the rem"
P19-1462,C16-1146,0,0.480093,"spect from the context. Hence the embeddings of targets and aspects can be refined from the highly correlative words instead of using context-independent or randomly initialized vectors. Experiment results on two benchmark datasets show that our approach yields the state-of-the-art performance in TABSA task. 1 location1 is your best bet for secure although expensive and location2 is too far Targeted aspect-based sentiment analysis (TABSA) aims at detecting aspects according to the specific target and inferring sentiment polarities corresponding to different target-aspect pairs simultaneously (Saeidi et al., 2016). For example, in sentence “location1 is your best bet for secure although expensive and location2 is too far.”, for target “location1”, the sentiment polarity is positive towards aspect “SAFETY” but is negative towards aspect “PRICE”. While “location2” only express negative polarity about aspect “TRANSIT-LOCATION”. This can be seen in Figure 1, e.g., where opinions on the aspects “SAFETY” and “PRICE” are expressed for target “location1” but not for target “location2”, whose Corresponding Author Aspect Sentiment location1 SAFETY Positive location1 PRICE Negative location2 TRANSIT Negative Figu"
P19-1462,D16-1021,0,0.0712332,"ive location1 PRICE Negative location2 TRANSIT Negative Figure 1: Example of TABSA task. Highly correlative words and corresponding aspects are in the same color. Entity names are masked by location1 and location2. Introduction ∗ Target Aspect-based sentiment analysis (ABSA) is a basic subtask of TABSA, which aims at inferring the sentiment polarities of different aspects in the sentence (Ruder et al., 2016; Chen et al., 2017; Gui et al., 2017; Peng et al., 2018; Ma et al., 2018a). Recently, attention-based neural models achieve remarkable success in ABSA (Fan et al., 2018; Wang et al., 2016; Tang et al., 2016). In TABSA task, the attention-based sentiment LSTM (Ma et al., 2018b) is proposed to tackle the challenges of both aspect-based sentiment analysis and targeted sentiment analysis by incorporating external knowledge. For neural model improvement, a delayed memory is proposed to track and update the states of targets at the right time with external memory (Liu et al., 2018). Despite the remarkable progress made by the previous works, they usually utilize contextindependent or randomly initialized vectors to rep4678 Proceedings of the 57th Annual Meeting of the Association for Computational Ling"
S10-1100,E06-1027,0,0.0251099,"accuracy, and 0.936 and 0.933 (ranked 2nd and 3rd) micro accuracy, respectively. 1 Introduction Sentiment analysis is always puzzled by the context-dependent sentiment words that one word brings positive, neutral or negative meanings in different contexts. Hatzivassiloglou and Mckeown (1997) predicated the polarity of adjectives by using the pairs of adjectives linked by consecutive or negation conjunctions. Turney and Littman (2003) determined the polarity of sentiment words by estimating the point-wise mutual information between sentiment words and a set of seed words with strong polarity. Andreevskaia and Bergler (2006) used a Sentiment Tag Extraction Program to extract sentimentbearing adjectives from WordNet. Esuli and Sebasian (2006) studied the context-dependent sentiment words in WordNet but ignored the inChunyu Kit2 2 City University of Hong Kong, Hong Kong ctckit@cityu.edu.hk stances in real context. Wu et al. (2008) applied collocation plus a SVM classifier in Chinese sentiment adjectives disambiguation. Xu et al. (2008) proposed a semi-supervised learning algorithm to learn new sentiment word and their contextdependent characteristics. Semeval-2 Task 18 is designed to provide a common framework and"
S10-1100,P97-1023,0,0.769044,"Missing"
S10-1100,W05-0408,0,\N,Missing
S10-1100,esuli-sebastiani-2006-sentiwordnet,0,\N,Missing
W04-1113,J93-1007,0,0.254135,"Missing"
W04-1113,J90-1003,0,\N,Missing
W04-1113,P03-1016,0,\N,Missing
W04-1113,P97-1009,0,\N,Missing
W04-1114,C02-1145,0,0.0905706,"Missing"
W04-1114,J90-1003,0,\N,Missing
W04-1114,J93-2004,0,\N,Missing
W07-1511,W03-2405,0,0.024716,"lysis. However, the performances of automatic collocation extraction systems are not satisfactory (Pecina 2005). A problem is that collocations are word combinations that co-occur within a short context, but not all such co-occurrences are true collocations. Further examinations is needed to filter out pseudo-collocations once co-occurred word pairs are identified. A collocation bank with true collocations annotated is naturally an indispensable resource for collocation research. (Kosho et al. 2000) presented their works of collocation annotation on Japanese text. Also, the Turkish treebank, (Bedin 2003) included collocation annotation as one step in its annotation. These two collocation banks provided collocation identification and co-occurrence verification information. (Tutin 2005) used shallow analysis based on finite state transducers and lexicon-grammar to identify and annotate collocations in a French corpus. This collocation bank further provided the lexical functions of the collocations. However to this day, there is no reported Chinese collocation bank available. 61 Proceedings of the Linguistic Annotation Workshop, pages 61–68, c Prague, June 2007. 2007 Association for Computationa"
W07-1511,shudo-etal-2000-collocations,0,0.0790794,"Missing"
W07-1511,J93-1007,0,\N,Missing
W07-1511,P05-2003,0,\N,Missing
W10-4154,S07-1027,0,0.0127506,"b People Search (WePS and WePS2) provides a standard evaluation, which focuses on information extraction of personal named-entities in Web data (Artiles et al., 2007; Artiles et al., 2009; Sekine and Artiles, 2009). Generally speaking, both clusterbased techniques which cluster documents corresponding to one person with similar contexts, global features and document features (Han et al. 2004; Pedersen et al. 2005; Elmacioglu et al. 2007; Pedersen and Anagha 2007; Rao et al. 2007) and information extraction based techniques which recognizes/extracts the description features of one person name (Heyl and Neumann 2007; Chen et al. 2009) are adopted. Considering that these evaluations are only applied to English text, CIPS-SIGHAN 2010 bakeoff proposed the first evaluation campaign on Chinese person name disambiguation. In this evaluation, corresponding to given index person name string, the systems are required to recognize each identical person having the index string as substring and classify the document corresponding to each identical person into a group. This paper presents the design and implementation of HITSZ_CITYU system in this bakeoff. This system incorporates both recognition/extract technique a"
W10-4154,S07-1012,0,0.0355233,"Missing"
W10-4154,S07-1042,0,0.0266269,"Missing"
W10-4154,S07-1058,0,0.0132327,"ambiguation (Fleischman and Hovy 2004; Li et al. 2004; Niu et al. 2004; Bekkerman and McCallum 2005; Chen and Martin 2007; Song et al. 2009). To promote the research in this area, Web People Search (WePS and WePS2) provides a standard evaluation, which focuses on information extraction of personal named-entities in Web data (Artiles et al., 2007; Artiles et al., 2009; Sekine and Artiles, 2009). Generally speaking, both clusterbased techniques which cluster documents corresponding to one person with similar contexts, global features and document features (Han et al. 2004; Pedersen et al. 2005; Elmacioglu et al. 2007; Pedersen and Anagha 2007; Rao et al. 2007) and information extraction based techniques which recognizes/extracts the description features of one person name (Heyl and Neumann 2007; Chen et al. 2009) are adopted. Considering that these evaluations are only applied to English text, CIPS-SIGHAN 2010 bakeoff proposed the first evaluation campaign on Chinese person name disambiguation. In this evaluation, corresponding to given index person name string, the systems are required to recognize each identical person having the index string as substring and classify the document corresponding to each"
W11-1724,esuli-sebastiani-2006-sentiwordnet,0,0.0287299,"Missing"
W11-1724,P07-1123,0,0.0327815,"nts, reviews and recommendations in different languages have been shared on the Internet. Accordingly, automated opinion analysis has attracted growing attentions. Opinion analysis, also known as sentiment analysis, sentiment classification, and opinion mining, aims to identify opinions in text and classify their sentiment polarity (Pang and Lee, 2008). Cross lingual opinion analysis (CLOA) techniques are investigated to improve opinion analysis in TL through leveraging the opinion-related resources, such as dictionaries and annotated corpus in SL. Some CLOA works used bilingual dictionaries (Mihalcea et al., 2007), or aligned corpus (Kim and Hovy, 2006) to align the expressions between source and target languages. These works are puzzled by the limited aligned opinion resources. Alternatively, some works used machine translation system to do the opinion expression alignment. Banea et al. (2008) proposed several approaches for cross lingual subjectivity analysis by directly applying the translations of opinion corpus in source language to train the opinion classifier on target language. Wan (2009) combined the annotated English reviews, unannotated Chinese reviews and their translations to co-train two"
W11-1724,N06-1026,0,0.0295223,"nt languages have been shared on the Internet. Accordingly, automated opinion analysis has attracted growing attentions. Opinion analysis, also known as sentiment analysis, sentiment classification, and opinion mining, aims to identify opinions in text and classify their sentiment polarity (Pang and Lee, 2008). Cross lingual opinion analysis (CLOA) techniques are investigated to improve opinion analysis in TL through leveraging the opinion-related resources, such as dictionaries and annotated corpus in SL. Some CLOA works used bilingual dictionaries (Mihalcea et al., 2007), or aligned corpus (Kim and Hovy, 2006) to align the expressions between source and target languages. These works are puzzled by the limited aligned opinion resources. Alternatively, some works used machine translation system to do the opinion expression alignment. Banea et al. (2008) proposed several approaches for cross lingual subjectivity analysis by directly applying the translations of opinion corpus in source language to train the opinion classifier on target language. Wan (2009) combined the annotated English reviews, unannotated Chinese reviews and their translations to co-train two separate classifiers for each language,"
W11-1724,D08-1014,0,0.0864079,"n text and classify their sentiment polarity (Pang and Lee, 2008). Cross lingual opinion analysis (CLOA) techniques are investigated to improve opinion analysis in TL through leveraging the opinion-related resources, such as dictionaries and annotated corpus in SL. Some CLOA works used bilingual dictionaries (Mihalcea et al., 2007), or aligned corpus (Kim and Hovy, 2006) to align the expressions between source and target languages. These works are puzzled by the limited aligned opinion resources. Alternatively, some works used machine translation system to do the opinion expression alignment. Banea et al. (2008) proposed several approaches for cross lingual subjectivity analysis by directly applying the translations of opinion corpus in source language to train the opinion classifier on target language. Wan (2009) combined the annotated English reviews, unannotated Chinese reviews and their translations to co-train two separate classifiers for each language, respectively. 182 Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 182–188, c 24 June, 2011, Portland, Oregon, USA 2011 Association for Computational Linguistics These works d"
W11-1724,P09-1027,0,0.614445,", such as dictionaries and annotated corpus in SL. Some CLOA works used bilingual dictionaries (Mihalcea et al., 2007), or aligned corpus (Kim and Hovy, 2006) to align the expressions between source and target languages. These works are puzzled by the limited aligned opinion resources. Alternatively, some works used machine translation system to do the opinion expression alignment. Banea et al. (2008) proposed several approaches for cross lingual subjectivity analysis by directly applying the translations of opinion corpus in source language to train the opinion classifier on target language. Wan (2009) combined the annotated English reviews, unannotated Chinese reviews and their translations to co-train two separate classifiers for each language, respectively. 182 Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 182–188, c 24 June, 2011, Portland, Oregon, USA 2011 Association for Computational Linguistics These works directly used all of the translation of annotated corpus in source language as the training data for target language without considering the following two problems: (1) the machine translation errors propaga"
W11-1724,P07-1056,0,0.0222921,"guage training corpus by random. The opinion analysis results are evaluated with simplified Chinese testing dataset SCt under lenient and strict evaluation standard 2 , respectively, as described in (Seki et al., 2008). Note Lang. SCs SCt T Cs ENs SC TC EN subjective/objective Lenient Strict Training 424 130/294  Test 4877 1869/3008 898/2022 Training 1365 740/625  Training 1694 648/1046  Data Total Table 1: The NTCIR-7 MOAT Corpora(unit:sentence). In the document-level review polarity classification experiment,, we used the dataset adopted in (Wan, 2009). Its English subset is collected by Blitzer et al. (2007), which contains a collection of 8,000 product reviews about four types of products: books, DVDs, electronics and kitchen appliances. For each type of products, there are 1,000 positive reviews and 1,000 negative ones, respectively. The Chinese subset has 451 positive reviews and 435 negative reviews of electronics products such as mp3 players, mobile phones etc. In our experiments, the Chinese subset is further split into two parts randomly: TL training dataset and test set. The cross lingual review polarity classification task is then denoted by DocSC: EN→SC. In this study, Google Translate3"
W11-1724,D08-1058,0,0.344601,"Missing"
W12-4512,W97-1306,0,0.185464,"Missing"
W12-4512,D08-1031,0,0.0249163,"respectively. As for the test dataset, the achieved F1 scores are 0.5749 and 0.6508, respectively. This encouraging performance shows the effectiveness of our proposed coreference resolution system. 1 Introduction Coreference resolution aims to find out the different mentions in a document which refer to the same entity in reality (Sundheim and Beth, 1995; Lang et al. 1997; Chinchor and Nancy, 1998;). It is a core component in natural language processing and information extraction. Both rule-based approach (Lee et al. 2011) and statistic-based approach (Soon et al., 2001; Ng and Cardie, 2002; Bengtson and Roth, 2008; Stoyanov et al., 2009; Chen et al. 2011) are proposed in coreference resolution study. Besides the frequently used syntactic and semantic features, the more linguistic features are exploited in recent works (Versley, 2007; Kong et al. 2010). CoNLL-2012 proposes a shared task, “Modeling multilingual unrestricted coreference in the OntoNotes” (Pradhan et al. 2012). This is an extension of the CoNLL-2011 shared task. The task involves automatic anaphoric mention detection and coreference resolution across three languages including English, Chinese and Arabic. HLT_HITSZ group participated in the"
W12-4512,M95-1002,0,0.0564341,"Missing"
W12-4512,C10-1068,0,0.0283211,"Missing"
W12-4512,P02-1014,0,0.0639179,"English and Chinese, respectively. As for the test dataset, the achieved F1 scores are 0.5749 and 0.6508, respectively. This encouraging performance shows the effectiveness of our proposed coreference resolution system. 1 Introduction Coreference resolution aims to find out the different mentions in a document which refer to the same entity in reality (Sundheim and Beth, 1995; Lang et al. 1997; Chinchor and Nancy, 1998;). It is a core component in natural language processing and information extraction. Both rule-based approach (Lee et al. 2011) and statistic-based approach (Soon et al., 2001; Ng and Cardie, 2002; Bengtson and Roth, 2008; Stoyanov et al., 2009; Chen et al. 2011) are proposed in coreference resolution study. Besides the frequently used syntactic and semantic features, the more linguistic features are exploited in recent works (Versley, 2007; Kong et al. 2010). CoNLL-2012 proposes a shared task, “Modeling multilingual unrestricted coreference in the OntoNotes” (Pradhan et al. 2012). This is an extension of the CoNLL-2011 shared task. The task involves automatic anaphoric mention detection and coreference resolution across three languages including English, Chinese and Arabic. HLT_HITSZ"
W12-4512,J01-4004,0,0.120176,"evelopment data of English and Chinese, respectively. As for the test dataset, the achieved F1 scores are 0.5749 and 0.6508, respectively. This encouraging performance shows the effectiveness of our proposed coreference resolution system. 1 Introduction Coreference resolution aims to find out the different mentions in a document which refer to the same entity in reality (Sundheim and Beth, 1995; Lang et al. 1997; Chinchor and Nancy, 1998;). It is a core component in natural language processing and information extraction. Both rule-based approach (Lee et al. 2011) and statistic-based approach (Soon et al., 2001; Ng and Cardie, 2002; Bengtson and Roth, 2008; Stoyanov et al., 2009; Chen et al. 2011) are proposed in coreference resolution study. Besides the frequently used syntactic and semantic features, the more linguistic features are exploited in recent works (Versley, 2007; Kong et al. 2010). CoNLL-2012 proposes a shared task, “Modeling multilingual unrestricted coreference in the OntoNotes” (Pradhan et al. 2012). This is an extension of the CoNLL-2011 shared task. The task involves automatic anaphoric mention detection and coreference resolution across three languages including English, Chinese a"
W12-4512,P09-1074,0,0.0250835,"Missing"
W12-4512,W11-1919,0,0.0346855,"Missing"
W12-4512,W11-1902,0,\N,Missing
W12-4512,D07-1052,0,\N,Missing
W12-4512,W12-4501,0,\N,Missing
W12-4512,M98-1001,0,\N,Missing
W12-4512,W11-1921,0,\N,Missing
W12-6326,P98-1012,0,0.287534,"Missing"
W12-6326,S07-1058,0,0.0588558,"Missing"
W12-6326,C98-1012,0,\N,Missing
W14-6817,P11-1115,0,0.090837,"Missing"
W14-6817,W14-6819,0,0.0268337,"Missing"
W14-6817,W14-6830,0,0.0507852,"Missing"
W14-6817,W14-6818,0,\N,Missing
W15-3111,D11-1014,0,0.0300569,"n. It is now widely used in sentiment classiﬁcation for English. As for Chinese sentiment analysis, Minlie Huang et al. (2014) proposed a new word detection method by mining the frequent sentiment word patterns. This method may discover new sentiment words from a large scale of unlabeled texts. With the rapid development of pre-trained word embedding and deep neural networks, a new way to represent texts and features is devloped. Mikolov et al. (2013) showed that word embedding represents words with meaningful syntactic and semantic information eﬀectively. Recursive neural network proposed by Socher et al. (2011a; 2011b; 2013) is shown eﬃcient to construct sentence representations based on the word embedding. Convolutional neural networks (CNN), another deep learn model which achieved success in image recognition ﬁeld, was applied to nature language processing with word embedTopic-based sentiment analysis for Chinese microblog aims to identify the user attitude on speciﬁed topics. In this paper, we propose a joint model by incorporating Support Vector Machines (SVM) and deep neural network to improve the performance of sentiment analysis. Firstly, a SVM Classiﬁer is constructed using N-gram, NPOS and"
W15-3111,baccianella-etal-2010-sentiwordnet,0,0.0142862,"ﬁcation results. Thus, feature engineering, a method for extracting eﬀective features from texts, plays an important role. Some commonly used features in sentiment classiﬁcation are unigram, bigram and sentiment words. However, these features cannot work well for cross-domain sentiment classiﬁcation because of the lack of domain knowledge. Danushka Bollegala et al. (2011) used multiple sources to construct a sentiment sensitive thesaurus to overcome the lack of domain knowledge. New sentiment words expansion is another kind of approach to improve the performance of sentiment analysis. Strfano Baccianella et al. (2010) constructed SentiWordNet by extending WordNet with sentiment information. It is now widely used in sentiment classiﬁcation for English. As for Chinese sentiment analysis, Minlie Huang et al. (2014) proposed a new word detection method by mining the frequent sentiment word patterns. This method may discover new sentiment words from a large scale of unlabeled texts. With the rapid development of pre-trained word embedding and deep neural networks, a new way to represent texts and features is devloped. Mikolov et al. (2013) showed that word embedding represents words with meaningful syntactic an"
W15-3111,D13-1170,0,0.00836156,"Missing"
W15-3111,P11-1014,0,0.0330104,"Technology Shenzhen Graduate School, Shenzhen, China caoyuhuiszu@gmail.com xuruifeng@hitsz.edu.cn Abstract Naïve Bayes and Maximum Entropy. The machine learning based approach uses feature vectors as the input of classiﬁcation to predict the classiﬁcation results. Thus, feature engineering, a method for extracting eﬀective features from texts, plays an important role. Some commonly used features in sentiment classiﬁcation are unigram, bigram and sentiment words. However, these features cannot work well for cross-domain sentiment classiﬁcation because of the lack of domain knowledge. Danushka Bollegala et al. (2011) used multiple sources to construct a sentiment sensitive thesaurus to overcome the lack of domain knowledge. New sentiment words expansion is another kind of approach to improve the performance of sentiment analysis. Strfano Baccianella et al. (2010) constructed SentiWordNet by extending WordNet with sentiment information. It is now widely used in sentiment classiﬁcation for English. As for Chinese sentiment analysis, Minlie Huang et al. (2014) proposed a new word detection method by mining the frequent sentiment word patterns. This method may discover new sentiment words from a large scale o"
W15-3111,P14-1050,0,0.0146085,"ntiment words. However, these features cannot work well for cross-domain sentiment classiﬁcation because of the lack of domain knowledge. Danushka Bollegala et al. (2011) used multiple sources to construct a sentiment sensitive thesaurus to overcome the lack of domain knowledge. New sentiment words expansion is another kind of approach to improve the performance of sentiment analysis. Strfano Baccianella et al. (2010) constructed SentiWordNet by extending WordNet with sentiment information. It is now widely used in sentiment classiﬁcation for English. As for Chinese sentiment analysis, Minlie Huang et al. (2014) proposed a new word detection method by mining the frequent sentiment word patterns. This method may discover new sentiment words from a large scale of unlabeled texts. With the rapid development of pre-trained word embedding and deep neural networks, a new way to represent texts and features is devloped. Mikolov et al. (2013) showed that word embedding represents words with meaningful syntactic and semantic information eﬀectively. Recursive neural network proposed by Socher et al. (2011a; 2011b; 2013) is shown eﬃcient to construct sentence representations based on the word embedding. Convolu"
W15-3111,D14-1181,0,0.00610468,"topic. To identify the opinions of users, sentiment analysis techniques are investigated to classify texts into diﬀerent categorizations according to their sentiment polarities. Most existing sentiment classiﬁcation techniques are based on machine learning algorithms, such as Support Vector Machine, 61 Proceedings of the Eighth SIGHAN Workshop on Chinese Language Processing (SIGHAN-8), pages 61–67, c Beijing, China, July 30-31, 2015. 2015 Association for Computational Linguistics and Asian Federation of Natural Language Processing siﬁers are integrated to generate the ﬁnal output. dings. Yoon Kim (2014) used CNN with pretrained word embedding to achieve state-ofthe-art performances on some sentence classiﬁcation tasks, including sentiment classiﬁcation. Siwei Lai et al. (2015) incorporated global information in a recurrent convolutional neural network. It obtained further improvements comparing to other deep learning models. In this paper, we propose a joint model which incorporates traditional machine learning based method (SVM) and deep learning model. Two diﬀerent classiﬁers are developed. One is a word feature based SVM classiﬁer which uses word unigram, bigram and sentiment words as fea"
xu-etal-2008-opinion,W03-1017,0,\N,Missing
xu-etal-2008-opinion,W03-0404,0,\N,Missing
xu-etal-2008-opinion,P03-1027,0,\N,Missing
xu-etal-2008-opinion,J04-3002,0,\N,Missing
xu-etal-2008-opinion,W02-1011,0,\N,Missing
xu-etal-2008-opinion,P97-1023,0,\N,Missing
