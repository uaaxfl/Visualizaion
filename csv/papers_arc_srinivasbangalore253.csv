2021.naacl-industry.9,A Hybrid Approach to Scalable and Robust Spoken Language Understanding in Enterprise Virtual Agents,2021,-1,-1,8,0,4697,ryan price,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers,0,"Spoken language understanding (SLU) extracts the intended mean- ing from a user utterance and is a critical component of conversational virtual agents. In enterprise virtual agents (EVAs), language understanding is substantially challenging. First, the users are infrequent callers who are unfamiliar with the expectations of a pre-designed conversation flow. Second, the users are paying customers of an enterprise who demand a reliable, consistent and efficient user experience when resolving their issues. In this work, we describe a general and robust framework for intent and entity extraction utilizing a hybrid of statistical and rule-based approaches. Our framework includes confidence modeling that incorporates information from all components in the SLU pipeline, a critical addition for EVAs to en- sure accuracy. Our focus is on creating accurate and scalable SLU that can be deployed rapidly for a large class of EVA applications with little need for human intervention."
2021.naacl-industry.27,Intent Features for Rich Natural Language Understanding,2021,-1,-1,4,0.833333,4770,brian lester,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers,0,"Complex natural language understanding modules in dialog systems have a richer understanding of user utterances, and thus are critical in providing a better user experience. However, these models are often created from scratch, for specific clients and use cases and require the annotation of large datasets. This encourages the sharing of annotated data across multiple clients. To facilitate this we introduce the idea of \textit{intent features}: domain and topic agnostic properties of intents that can be learnt from the syntactic cues only, and hence can be shared. We introduce a new neural network architecture, the Global-Local model, that shows significant improvement over strong baselines for identifying these features in a deployed, multi-intent natural language understanding module, and more generally in a classification setting where a part of an utterance has to be classified utilizing the whole context."
2020.findings-emnlp.166,Constrained Decoding for Computationally Efficient Named Entity Recognition Taggers,2020,-1,-1,5,0.833333,4770,brian lester,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"Current state-of-the-art models for named entity recognition (NER) are neural models with a conditional random field (CRF) as the final layer. Entities are represented as per-token labels with a special structure in order to decode them into spans. Current work eschews prior knowledge of how the span encoding scheme works and relies on the CRF learning which transitions are illegal and which are not to facilitate global coherence. We find that by constraining the output to suppress illegal transitions we can train a tagger with a cross-entropy loss twice as fast as a CRF with differences in F1 that are statistically insignificant, effectively eliminating the need for a CRF. We analyze the dynamics of tag co-occurrence to explain when these constraints are most effective and provide open source implementations of our tagger in both PyTorch and TensorFlow."
K18-2015,The {SLT}-Interactions Parsing System at the {C}o{NLL} 2018 Shared Task,2018,0,0,3,0,29432,riyaz bhat,Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"This paper describes our system (SLT-Interactions) for the CoNLL 2018 shared task: Multilingual Parsing from Raw Text to Universal Dependencies. Our system performs three main tasks: word segmentation (only for few treebanks), POS tagging and parsing. While segmentation is learned separately, we use neural stacking for joint learning of POS tagging and parsing tasks. For all the tasks, we employ simple neural network architectures that rely on long short-term memory (LSTM) networks for learning task-dependent features. At the basis of our parser, we use an arc-standard algorithm with Swap action for general non-projective parsing. Additionally, we use neural stacking as a knowledge transfer mechanism for cross-domain parsing of low resource domains. Our system shows substantial gains against the UDPipe baseline, with an average improvement of 4.18{\%} in LAS across all languages. Overall, we are placed at the 12th position on the official test sets."
chen-bangalore-2017-underspecification,Underspecification in Natural Language Understanding for Dialog Automation,2017,0,0,2,0,15412,john chen,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"With the increasing number of communication platforms that offer variety of ways of connecting two interlocutors, there is a resurgence of chat-based dialog systems. These systems, typically known as \textit{chatbots} have been successfully applied in a range of consumer and enterprise applications. A key technology in such chat-bots is robust natural language understanding (NLU) which can significantly influence and impact the efficacy of the conversation and ultimately the user-experience. While NLU is far from perfect, this paper illustrates the role of \textit{underspecification} and its impact on successful dialog completion."
W16-3626,Rapid Prototyping of Form-driven Dialogue Systems Using an Open-source Framework,2016,8,4,3,1,33730,svetlana stoyanchev,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,None
W16-3309,Revisiting Supertagging and Parsing: How to Use Supertags in Transition-Based Parsing,2016,1,0,5,0,33762,wonchang chung,Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms ({TAG}+12),0,We discuss the use of supertags derived from a TAG in transition-based parsing. We show some initial experimental results which suggest that using a representation of a supertag in terms of its structural and linguistic dimensions outperforms the use of atomic supertags.
W14-4211,Exploring System Combination approaches for {I}ndo-{A}ryan {MT} Systems,2014,15,2,5,0,22835,karan singla,Proceedings of the {EMNLP}{'}2014 Workshop on Language Technology for Closely Related Languages and Language Variants,0,Statistical Machine Translation (SMT) systems are heavily dependent on the quality of parallel corpora used to train translation models. Translation quality between certain Indian languages is often poor due to the lack of training data of good quality. We used triangulation as a technique to improve the quality of translations in cases where the direct translation model did not perform satisfactorily. Triangulation uses a third language as a pivot between the source and target languages to achieve an improved and more efficient translation model in most cases. We also combined multi-pivot models using linear mixture and obtained significant improvement in BLEU scores compared to the direct source-target models.
W14-4006,Reducing the Impact of Data Sparsity in Statistical Machine Translation,2014,24,3,3,0,22835,karan singla,"Proceedings of {SSST}-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"Morphologically rich languages generally require large amounts of parallel data to adequately estimate parameters in a statistical Machine Translation(SMT) system. However, it is time consuming and expensive to create large collections of parallel data. In this paper, we explore two strategies for circumventing sparsity caused by lack of large parallel corpora. First, we explore the use of distributed representations in an Recurrent Neural Network based language model with different morphological features and second, we explore the use of lexical resources such as WordNet to overcome sparsity of content words."
S14-2014,{AT}{\\&}{T}: The Tag{\\&}Parse Approach to Semantic Parsing of Robot Spatial Commands,2014,5,3,4,1,33730,svetlana stoyanchev,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"The Tag&Parse approach to semantic parsing first assigns semantic tags to each word in a sentence and then parses the tag sequence into a semantic tree. We use statistical approach for tagging, parsing, and reference resolution stages. Each stage produces multiple hypotheses which are re-ranked using spatial validation. We evaluate the Tag&Parse approach on a corpus of Robotic Spatial Commands as part of the SemEval Task6 exercise. Our system accuracy is 87.35% and 60.84% with and without spatial validation."
C14-1092,A Framework for Translating {SMS} Messages,2014,26,3,3,1,27370,vivek sridhar,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"Short Messaging Service (SMS) has become a popular form of communication. While it is predominantly used for monolingual communication, it can be extremely useful for facilitating cross-lingual communication through statistical machine translation. In this work we present an application of statistical machine translation to SMS messages. We decouple the SMS translation task into normalization followed by translation so that one can exploit existing bitext resources and present a novel unsupervised normalization approach using distributed representation of words learned through neural networks. We describe several surrogate data that are good approximations to real SMS data feeds and use a hybrid translation approach using finite-state transducers. Both objective and subjective evaluation indicate that our approach is highly suitable for translating SMS messages."
2014.iwslt-papers.2,Towards simultaneous interpreting: the timing of incremental machine translation and speech synthesis,2014,18,1,2,0,21478,timo baumann,Proceedings of the 11th International Workshop on Spoken Language Translation: Papers,0,"In simultaneous interpreting, human experts incrementally construct and extend partial hypotheses about the source speaker{'}s message, and start to verbalize a corresponding message in the target language, based on a partial translation {--} which may have to be corrected occasionally. They commence the target utterance in the hope that they will be able to finish understanding the source speaker{'}s message and determine its translation in time for the unfolding delivery. Of course, both incremental understanding and translation by humans can be garden-pathed, although experts are able to optimize their delivery so as to balance the goals of minimal latency, translation quality and high speech fluency with few corrections. We investigate the temporal properties of both translation input and output to evaluate the tradeoff between low latency and translation quality. In addition, we estimate the improvements that can be gained with a tempo-elastic speech synthesizer."
2014.eamt-1.18,{SEECAT}: {ASR} {\\&} Eye-tracking enabled computer-assisted translation,2014,9,4,7,0,4977,mercedes garciamartinez,Proceedings of the 17th Annual conference of the European Association for Machine Translation,0,"Tiping has traditionally been the only input method used by human translators working with computer-assisted translation (CAT) tools. However, speech is a natural communication channel for humans and, in principle, it should be faster and easier than typing from a keyboard. This contribution investigates the integration of automatic speech recognition (ASR) in a CAT workbench testing its real use byn human translators while post-editing machine translation (MT) outputs. This paper also explores the use of MT combined with ASR in order to improve recognition accuracy in a workbench integrating eye-tracking functionalities to collect process-oriented information about translatorsxe2x80x99 performance."
2014.amta-workshop.6,Predicting post-editor profiles from the translation process,2014,10,2,5,0,22835,karan singla,Workshop on interactive and adaptive machine translation,0,"The purpose of the current investigation is to predict post-editor profiles based on user behaviour and demographics using machine learning techniques to gain a better understanding of post-editor styles. Our study extracts process unit features from the CasMaCat LS14 database from the CRITT Translation Process Research Database (TPR-DB). The analysis has two main research goals: We create n-gram models based on user activity and part-of-speech sequences to automatically cluster post-editors, and we use discriminative classifier models to characterize post-editors based on a diverse range of translation process features. The classification and clustering of participants resulting from our study suggest this type of exploration could be used as a tool to develop new translation tool features or customization possibilities."
N13-1023,Segmentation Strategies for Streaming Speech Translation,2013,24,29,3,1,27370,vivek sridhar,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"The study presented in this work is a first effort at real-time speech translation of TED talks, a compendium of public talks with different speakers addressing a variety of topics. We address the goal of achieving a system that balances translation accuracy and latency. In order to improve ASR performance for our diverse data set, adaptation techniques such as constrained model adaptation and vocal tract length normalization are found to be useful. In order to improve machine translation (MT) performance, techniques that could be employed in real-time such as monotonic and partial translation retention are found to be of use. We also experiment with inserting text segmenters of various types between ASR and MT in a series of real-time translation experiments. Among other results, our experiments demonstrate that a good segmentation is useful, and a novel conjunction-based segmentation strategy improves translation quality nearly as much as other strategies such as comma-based segmentation. It was also found to be important to synchronize various pipeline components in order to minimize latency."
I13-1141,Incremental Segmentation and Decoding Strategies for Simultaneous Translation,2013,21,12,3,0.784314,8930,mahsa yarmohammadi,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Simultaneous translation is the challenging task of listening to source language speech, and at the same time, producing target language speech. Human interpreters achieve this task routinely and effortlessly, using different strategies in order to minimize the latency in producing target language. Toward modeling the human interpretation process, we propose a novel input segmentation method using the phrase alignment structure of the language pair. We compare and contrast three incremental decoding and two different input segmentation strategies, including our proposed method, for simultaneous translation. We present accuracy and latency tradeoffs for each of the decoding strategies when applied to audio lectures from the TED collection."
N12-1048,Real-time Incremental Speech-to-Speech Translation of Dialogs,2012,21,26,1,1,4704,srinivas bangalore,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In a conventional telephone conversation between two speakers of the same language, the interaction is real-time and the speakers process the information stream incrementally. In this work, we address the problem of incremental speech-to-speech translation (S2S) that enables cross-lingual communication between two remote participants over a telephone. We investigate the problem in a novel real-time Session Initiation Protocol (SIP) based S2S framework. The speech translation is performed incrementally based on generation of partial hypotheses from speech recognition. We describe the statistical models comprising the S2S system and the SIP architecture for enabling real-time two-way cross-lingual dialog. We present dialog experiments performed in this framework and study the tradeoff in accuracy versus latency in incremental speech translation. Experimental results demonstrate that high quality translations can be generated with the incremental approach with approximately half the latency associated with non-incremental approach."
C12-1013,Harvesting Parallel Text in Multiple Languages with Limited Supervision,2012,17,6,4,1,37457,luciano barbosa,Proceedings of {COLING} 2012,0,"The Web is an ever increasing, dynamically changing, multilingual repository of text. There have been several approaches to harvest this repository for bootstrapping, supplementing and adapting data needed for training models in speech and language applications. In this paper, we present semi-supervised and unsupervised approaches to harvesting multilingual text that rely on a key observation of link collocation. We demonstrate the eectiveness of our approach in the context of statistical machine translation by harvesting parallel texts and training translation models in 20 dierent languages. Furthermore, by exploiting the DOM trees of parallel webpages, we extend our harvesting technique to create parallel data for resource limited languages in an unsupervised manner. We also present some interesting observations concerning the socio-economic factors that the multilingual Web reflects."
P11-2107,Predicting Relative Prominence in Noun-Noun Compounds,2011,14,3,2,1,38801,taniya mishra,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"There are several theories regarding what influences prominence assignment in English noun-noun compounds. We have developed corpus-driven models for automatically predicting prominence assignment in noun-noun compounds using feature sets based on two such theories: the informativeness theory and the semantic composition theory. The evaluation of the prediction models indicate that though both of these theories are relevant, they account for different types of variability in prominence assignment."
I11-1048,Crawling Back and Forth: Using Back and Out Links to Locate Bilingual Sites,2011,30,7,2,1,37457,luciano barbosa,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"This paper presents a novel crawling strategy to locate bilingual sites. It does so by focusing on the Web graph neighborhood of these sites and exploring the patterns of the links in this region to guide its visitation policy. A sub-task in the problem of bilingual site discovery is the job of detecting bilingual sites, i.e., given a Web site, verify whether it is bilingual or not. We perform this task by combining supervised learning and language identification. Experimental results demonstrate that our crawler outperforms previous crawling approaches and produces a high-quality collection of bilingual sites, which we evaluate in the context of machine translation in the tourism and hospitality domain. The parallel text obtained using our novel crawling strategy results in a relative improvement of 22% in BLEU score (English-to-Spanish) over an out-ofdomain seed translation model trained on the European parliamentary proceedings."
W10-3805,Phrase Based Decoding using a Discriminative Model,2010,17,0,3,0,21982,prasanth kolachina,Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation,0,"In this paper, we present an approach to statistical machine translation that combines the power of a discriminative model (for training a model for Machine Translation), and the standard beam-search based decoding technique (for the translation of an input sentence). A discriminative approach for learning lexical selection and reordering utilizes a large set of feature functions (thereby providing the power to incorporate greater contextual and linguistic information), which leads to an effective training of these models. This model is then used by the standard state-of-art Moses decoder (Koehn et al., 2007) for the translation of an input sentence."
P10-4011,Speech-Driven Access to the Deep Web on Mobile Devices,2010,8,2,2,1,38801,taniya mishra,Proceedings of the {ACL} 2010 System Demonstrations,0,"The Deep Web is the collection of information repositories that are not indexed by search engines. These repositories are typically accessible through web forms and contain dynamically changing information. In this paper, we present a system that allows users to access such rich repositories of information on mobile devices using spoken language."
N10-1007,Qme! : A Speech-based Question-Answering system on Mobile Devices,2010,23,16,2,1,38801,taniya mishra,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Mobile devices are becoming the dominant mode of information access despite being cumbersome to input text using small keyboards and browsing web pages on small screens. We present Qme!, a speech-based question-answering system that allows for spoken queries and retrieves answers to the questions instead of web pages. We present bootstrap methods to distinguish dynamic questions from static questions and we show the benefits of tight coupling of speech recognition and retrieval components of the system."
N09-2047,{MICA}: A Probabilistic Dependency Parser Based on Tree Insertion Grammars (Application Note),2009,16,20,1,1,4704,srinivas bangalore,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"MICA is a dependency parser which returns deep dependency representations, is fast, has state-of-the-art performance, and is freely available."
N09-2071,Tightly coupling Speech Recognition and Search,2009,7,3,2,1,38801,taniya mishra,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"In this paper, we discuss the benefits of tightly coupling speech recognition and search components in the context of a speech-driven search application. We demonstrate that by incorporating constraints from the information repository that is being searched not only improves the speech recognition accuracy but also results in higher search accuracy."
J09-3002,{A}rticles: Robust Understanding in Multimodal Interfaces,2009,85,32,1,1,4704,srinivas bangalore,Computational Linguistics,0,"Multimodal grammars provide an effective mechanism for quickly creating integration and understanding capabilities for interactive systems supporting simultaneous use of multiple input modalities. However, like other approaches based on hand-crafted grammars, multimodal grammars can be brittle with respect to unexpected, erroneous, or disfluent input. In this article, we show how the finite-state approach to multimodal language processing can be extended to support multimodal applications combining speech with complex freehand pen input, and evaluate the approach in the context of a multimodal conversational system (MATCH). We explore a range of different techniques for improving the robustness of multimodal integration and understanding. These include techniques for building effective language models for speech recognition when little or no multimodal training data is available, and techniques for robust multimodal understanding that draw on classification, machine translation, and sequence edit methods. We also explore the use of edit-based methods to overcome mismatches between the gesture stream and the speech stream."
E09-1012,Incremental Parsing Models for Dialog Task Structure,2009,30,16,1,1,4704,srinivas bangalore,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"In this paper, we present an integrated model of the two central tasks of dialog management: interpreting user actions and generating system actions. We model the interpretation task as a classification problem and the generation task as a prediction problem. These two tasks are interleaved in an incremental parsing-based dialog model. We compare three alternative parsing methods for this dialog model using a corpus of human-human spoken dialog from a catalog ordering domain that has been annotated for dialog acts and task/subtask information. We contrast the amount of context provided by each method and its impact on performance."
E09-1028,Effects of Word Confusion Networks on Voice Search,2009,10,15,2,0,10466,junlan feng,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"Mobile voice-enabled search is emerging as one of the most popular applications abetted by the exponential growth in the number of mobile devices. The automatic speech recognition (ASR) output of the voice query is parsed into several fields. Search is then performed on a text corpus or a database. In order to improve the robustness of the query parser to noise in the ASR output, in this paper, we investigate two different methods to query parsing. Both methods exploit multiple hypotheses from ASR, in the form of word confusion networks, in order to achieve tighter coupling between ASR and query parsing and improved accuracy of the query parser. We also investigate the results of this improvement on search accuracy. Word confusion-network based query parsing outperforms ASR 1-best based query-parsing by 2.7% absolute and the search performance improves by 1.8% absolute on one of our data sets."
W08-2120,Trainable Speaker-Based Referring Expression Generation,2008,16,21,3,0,33009,giuseppe fabbrizio,{C}o{NLL} 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,0,"Previous work in referring expression generation has explored general purpose techniques for attribute selection and surface realization. However, most of this work did not take into account: a) stylistic differences between speakers; or b) trainable surface realization approaches that combine semantic and word order information. In this paper we describe and evaluate several end-to-end referring expression generation algorithms that take into consideration speaker style and use data-driven surface realization techniques."
W08-1133,Referring Expression Generation Using Speaker-based Attribute Selection and Trainable Realization ({ATTR}),2008,12,14,3,0,33009,giuseppe fabbrizio,Proceedings of the Fifth International Natural Language Generation Conference,0,"In the first REG competition, researchers proposed several general-purpose algorithms for attribute selection for referring expression generation. However, most of this work did not take into account: a) stylistic differences between speakers; or b) trainable surface realization approaches that combine semantic and word order information. In this paper we describe and evaluate several end-to-end referring expression generation algorithms that take into consideration speaker style and use data-driven surface realization techniques."
P08-2057,Enriching Spoken Language Translation with Dialog Acts,2008,13,8,2,1,27370,vivek sridhar,"Proceedings of ACL-08: HLT, Short Papers",0,"Current statistical speech translation approaches predominantly rely on just text transcripts and do not adequately utilize the rich contextual information such as conveyed through prosody and discourse function. In this paper, we explore the role of context characterized through dialog acts (DAs) in statistical translation. We demonstrate the integration of the dialog acts in a phrase-based statistical translation framework, employing 3 limited domain parallel corpora (Farsi-English, Japanese-English and Chinese-English). For all three language pairs, in addition to producing interpretable DA enriched target language translations, we also obtain improvements in terms of objective evaluation metrics such as lexical selection accuracy and BLEU score."
D08-1028,{H}ot{S}pots: {V}isualizing Edits to a Text,2008,10,0,1,1,4704,srinivas bangalore,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"Compared to the telephone, email based customer care is increasingly becoming the preferred channel of communication for corporations and customers. Most email-based customer care management systems provide a method to include template texts in order to reduce the handling time for a customer's email. The text in a template is suitably modified into a response by a customer care agent. In this paper, we present two techniques to improve the effectiveness of a template by providing tools for the template authors. First, we present a tool to track and visualize the edits made by agents to a template which serves as a vital feedback to the template authors. Second, we present a novel method that automatically extracts potential templates from responses authored by agents. These methods are investigated in the context of an email customer care analysis tool that handles over a million emails a year."
W07-0413,Three models for discriminative machine translation using Global Lexical Selection and Sentence Reconstruction,2007,10,9,2,0.555556,18971,sriram venkatapathy,"Proceedings of {SSST}, {NAACL}-{HLT} 2007 / {AMTA} Workshop on Syntax and Structure in Statistical Translation",0,"Machine translation of a source language sentence involves selecting appropriate target language words and ordering the selected words to form a well-formed target language sentence. Most of the previous work on statistical machine translation relies on (local) associations of target words/phrases with source words/phrases for lexical selection. In contrast, in this paper, we present a novel approach to lexical selection where the target words are associated with the entire source sentence (global) without the need for local associations. This technique is used by three models (Bag-of-words model, sequential model and hierarchical model) which predict the target language words given a source sentence and then order the words appropriately. We show that a hierarchical model performs best when compared to the other two models."
P07-1020,Statistical Machine Translation through Global Lexical Selection and Sentence Reconstruction,2007,26,47,1,1,4704,srinivas bangalore,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"Machine translation of a source language sentence involves selecting appropriate target language words and ordering the selected words to form a well-formed target language sentence. Most of the previous work on statistical machine translation relies on (local) associations of target words/phrases with source words/phrases for lexical selection. In contrast, in this paper, we present a novel approach to lexical selection where the target words are associated with the entire source sentence (global) without the need to compute local associations. Further, we present a technique for reconstructing the target language sentence from the selected words. We compare the results of this approach against those obtained from a finite-state based statistical machine translation system which relies on local lexical associations."
N07-1001,Exploiting Acoustic and Syntactic Features for Prosody Labeling in a Maximum Entropy Framework,2007,19,20,2,1,27370,vivek sridhar,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,None
2007.mtsummit-papers.32,Report on the {NSF}-sponsored Human Language Technology Workshop on Industrial Centers,2007,-1,-1,3,0,40215,mary harper,Proceedings of Machine Translation Summit XI: Papers,0,None
P06-1026,Learning the Structure of Task-Driven Human-Human Dialogs,2006,37,61,1,1,4704,srinivas bangalore,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Data-driven techniques have been used for many computational linguistics tasks. Models derived from data are generally more robust than hand-crafted systems since they better reflect the distribution of the phenomena being modeled. With the availability of large corpora of spoken dialog, dialog management is now reaping the benefits of data-driven techniques. In this paper, we compare two approaches to modeling subtask structure in dialog: a chunk-based model of subdialog sequences, and a parse-based, or hierarchical, model. We evaluate these models using customer agent dialogs from a catalog service domain."
E06-1046,Edit Machines for Robust Multimodal Language Processing,2006,24,1,1,1,4704,srinivas bangalore,11th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Multimodal grammars provide an expressive formalism for multimodal integration and understanding. However, handcrafted multimodal grammars can be brittle with respect to unexpected, erroneous, or disfluent inputs. Spoken language (speech-only) understanding systems have addressed this issue of lack of robustness of hand-crafted grammars by exploiting classification techniques to extract fillers of a frame representation. In this paper, we illustrate the limitations of such classification approaches for multimodal integration and understanding and present an approach based on edit machines that combine the expressiveness of multimodal grammars with the robustness of stochastic language models of speech recognition. We also present an approach where the edit operations are trained from data using a noisy channel model paradigm. We evaluate and compare the performance of the hand-crafted and learned edit machines in the context of a multimodal conversational system (MATCH)."
2006.iwslt-evaluation.2,Finite-state transducer-based statistical machine translation using joint probabilities,2006,16,1,1,1,4704,srinivas bangalore,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we present our system for statistical machine translation that is based on weighted finite-state transducers. We describe the construction of the transducer, the estimation of the weights, acquisition of phrases (locally ordered tokens) and the mechanism we use for global reordering. We also present a novel approach to machine translation that uses a maximum entropy model for parameter estimation and contrast its performance to the finite-state translation model on the IWSLT Chinese-English data sets."
P04-3021,Compiling Boostexter Rules into a Finite-state Transducer,2004,18,2,1,1,4704,srinivas bangalore,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"A number of NLP tasks have been effectively modeled as classification tasks using a variety of classification techniques. Most of these tasks have been pursued in isolation with the classifier assuming unambiguous input. In order for these techniques to be more broadly applicable, they need to be extended to apply on weighted packed representations of ambiguous input. One approach for achieving this is to represent the classification model as a weighted finite-state transducer (WFST). In this paper, we present a compilation procedure to convert the rules resulting from an AdaBoost classifier into an WFST. We validate the compilation technique by applying the resulting WFST on a call-routing application."
P04-3033,{MATCH}kiosk: A Multimodal Interactive City Guide,2004,14,23,2,1,38458,michael johnston,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"Multimodal interfaces provide more flexible and compelling interaction and can enable public information kiosks to support more complex tasks for a broader community of users. MATCHKiosk is a multimodal interactive city guide which provides users with the freedom to interact using speech, pen, touch or multimodal inputs. The system responds by generating multimodal presentations that synchronize synthetic speech with a life-like virtual agent and dynamically generated graphics."
N04-1005,Balancing data-driven and rule-based approaches in the context of a Multimodal Conversational System,2004,-1,-1,1,1,4704,srinivas bangalore,Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004,0,None
W02-2214,Context-Free Parsing of a {T}ree {A}djoining {G}rammar Using Finite-State Machines,2002,15,3,4,0,5812,alexis nasr,Proceedings of the Sixth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+6),0,None
W02-2236,Reranking an n-gram supertagger,2002,21,15,2,1,15412,john chen,Proceedings of the Sixth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+6),0,"As shown by Srinivas (1997), standard n-gram modeling may be used to perform supertag disambiguation with accuracy that is adequate for partial parsing, but in general not sufficient for full parsing. A serious problem is that n-gram modeling usually considers a very small, fixed context and does not perform well with large tag sets, such as those generated by automatic grammar extraction (Xia, 1999; Chen and Vijay-Shanker, 2000; Chiang, 2000). As an alternative, Chen, Bangalore and Vijay-Shanker (1999) introduce class-based supertagging. An example of class tagging is n-best trigram-based supertagging, which assigns to each word the top n most likely supertags as determined by an n-gram supertagging model. Class-based supertagging can be performed much more accurately than supertagging with only a small increase in ambiguity. In a second phase, the most likely candidate from the class is chosen. In this paper, we investigate an approach to such a choice based on reranking a set of candidate supertags and their confidence scores. RankBoost (Freund et al., 1998) is the boosting algorithm that we use in order to learn to rerank outputs. It also has been used with good effect in reranking outputs of a statistical parser (Collins, 2000) and ranking sentence plans (Walker, Rambow and Rogati, 2001). RankBoost may learn to correct biases that are inherent in n-gram modeling which lead to systematic errors in supertagging (cf. (van Halteren, 1996)). RankBoost can also use a variety of local and long distance features more easily than n-gram-based approaches (cf. (Chen, Bangalore and Vijay-Shanker, 1999)) because it makes sparse data less of an issue. The outline of this paper is as follows. First, we develop the background and motivations behind the task of reranking the output of an n-best trigram supertagger. Second, we introduce RankBoost as the approach that we adopt in order to train the reranker. Third, we perform an initial set of experiments where the reranker is trained with different feature subsets. Fourth, we perform an in-depth analysis of several reranking models. Fifth, after pointing out causes that at times render the reranker ineffective, we develop and test some new models that attempt to sidestep these limitations. Lastly, after some significance testing results, we state our conclusions and remark on potential future directions."
W02-1035,Extracting Clauses for Spoken Language Understanding in Conversational Systems,2002,11,5,2,0.45977,4699,narendra gupta,Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing ({EMNLP} 2002),0,"Spontaneous human utterances in the context of human-human and human-machine dialogs are rampant with dysfluencies, and speech repairs. Furthermore, when recognized using a speech recognizer, these utterances produce a sequence of words with no identification of clausal units. Such long strings of words combined with speech errors pose a difficult problem for spoken language parsing and understanding. In this paper, we address the issue of editing speech repairs as well as segmenting user utterances into clause units with a view of parsing and understanding spoken language utterances. We present generative and discriminative models for this task and present evaluation results on the human-human conversations obtained from the Switch board corpus."
P02-1048,{MATCH}: An Architecture for Multimodal Dialogue Systems,2002,12,219,2,1,38458,michael johnston,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"Mobile interfaces need to allow the user and system to adapt their choice of communication modes according to user preferences, the task at hand, and the physical and social environment. We describe a multimodal application architecture which combines finite-state multimodal language processing, a speech-act based multimodal dialogue manager, dynamic multimodal output generation, and user-tailored text planning to enable rapid prototyping of multimodal interfaces with flexible input and adaptive output. Our testbed application MATCH (Multimodal Access To City Help) provides a mobile multimodal speech-pen interface to restaurant and sub-way information for New York City."
C02-2026,Creating a Finite-State Parser with Application Semantics,2002,7,10,2,0,1354,owen rambow,{COLING} 2002: The 17th International Conference on Computational Linguistics: Project Notes,0,"Parsli is a finite-state (FS) parser which can be tailored to the lexicon, syntax, and semantics of a particular application using a hand-editable declarative lexicon. The lexicon is defined in terms of a lexicalized Tree Adjoining Grammar, which is subsequently mapped to a FS representation. This approach gives the application designer better and easier control over the natural language understanding component than using an off-the-shelf parser. We present results using Parsli on an application that creates 3D-images from typed input."
C02-1134,Bootstrapping Bilingual Data using Consensus Translation for a Multilingual Instant Messaging System,2002,13,40,1,1,4704,srinivas bangalore,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"One of the primary issues in training statistical translation models is the paucity of bilingual data. In this paper, we propose techniques to alleviate the bilingual data bottleneck by creating a consensus from translations of monolingual data provided by several off-the-shelf translation engines. We compute the consensus alignment using a multi-sequence alignment algorithm used for DNA sequence alignment. We present an application of this technique to bootstrap bilingual data for the general domain of instant messaging. We train hierarchical statistical translation models on the bootstrapped bilingual data and show that the resulting statistical translation model outperforms each individual off-the-shelf translation system."
C02-1138,Towards Automatic Generation of Natural Language Generation Systems,2002,17,27,2,1,15412,john chen,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"Systems that interact with the user via natural language are in their infancy. As these systems mature and become more complex, it would be desirable for a system developer if there were an automatic method for creating natural language generation components that can produce quality output efficiently. We conduct experiments that show that this goal appears to be realizable. In particular we discuss a natural language generation system that is composed of SPoT, a trainable sentence planner, and FER-GUS, a stochastic surface, realizer. We show how these stochastic NLG components can be made to work together, that they can be ported to new domains with apparent ease, and that such NLG components can be integrated in a real-time dialog system."
W01-0520,Impact of Quality and Quantity of Corpora on Stochastic Generation,2001,0,11,1,1,4704,srinivas bangalore,Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing,0,None
N01-1018,A Finite-State Approach to Machine Translation,2001,22,41,1,1,4704,srinivas bangalore,Second Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"The problem of machine translation can be viewed as consisting of two subproblems: (a) lexical selection; (b) lexical reordering. We propose stochastic finite-state models for these two subproblems. Stochastic finite-state models are efficiently able to learn from data, effective for decoding and are associated with a calculus for composing models which allows for tight integration of constraints from various levels of language processing. We present a method for learning stochastic finite-state models for lexical choice and lexical reordering that are trained automatically from pairs of source and target utterances. We use this method to develop models for English-Japanese translation and present the performance of these models for translation of speech and text. We also evaluate the efficacy of such a translation model in the context of a call routing task of unconstrained speech utterances."
H01-1055,Natural Language Generation in Dialog Systems,2001,18,35,2,0,1354,owen rambow,Proceedings of the First International Conference on Human Language Technology Research,0,"Recent advances in Automatic Speech Recognition technology have put the goal of naturally sounding dialog systems within reach. However, the improved speech recognition has brought to light a new problem: as dialog systems understand more of what the user tells them, they need to be more sophisticated at responding to the user. The issue of system response to users has been extensively studied by the natural language generation community, though rarely in the context of dialog systems. We show how research in generation can be adapted to dialog systems, and how the high cost of hand-crafting knowledge-based generation systems can be overcome by employing machine learning techniques."
W00-2004,"Using {TAG}s, a Tree Model, and a Language Model for Generation",2000,4,41,1,1,4704,srinivas bangalore,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,None
W00-1401,Evaluation Metrics for Generation,2000,11,138,1,1,4704,srinivas bangalore,{INLG}{'}2000 Proceedings of the First International Conference on Natural Language Generation,0,"Certain generation applications may profit from the use of stochastic methods. In developing stochastic methods, it is crucial to be able to quickly assess the relative merits of different approaches or models. In this paper, we present several types of intrinsic (system internal) metrics which we have used for baseline quantitative assessment. This quantitative assessment should then be augmented to a fuller evaluation that examines qualitative aspects. To this end, we describe an experiment that tests correlation between the quantitative metrics and human qualitative judgment. The experiment confirms that intrinsic metrics cannot replace human evaluation, but some correlate significantly with human judgments of quality and understandability and can be used for evaluation during development."
W00-0508,Stochastic Finite-State models for Spoken Language Machine Translation,2000,31,51,1,1,4704,srinivas bangalore,{ANLP}-{NAACL} 2000 Workshop: Embedded Machine Translation Systems,0,"Stochastic finite-state models are efficiently learnable from data, effective for decoding and are associated with a calculus for composing models which allows for tight integration of constraints from various levels of language processing. In this paper, we present a method for stochastic finite-state machine translation that is trained automatically from pairs of source and target utterances. We use this method to develop models for English-Japanese and Japanese-English translation. We have embedded the Japanese-English translation system in a call routing task of unconstrained speech utterances. We evaluate the efficacy of the translation system in the context of this application."
P00-1059,Corpus-Based Lexical Choice in Natural Language Generation,2000,7,73,1,1,4704,srinivas bangalore,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"Choosing the best lexeme to realize a meaning in natural language generation is a hard task. We investigate different tree-based stochastic models for lexical choice. Because of the difficulty of obtaining a sense-tagged corpus, we generalize the notion of synonymy. We show that a tree-based model can achieve a word-bag based accuracy of 90%, representing an improvement over the baseline."
J00-1004,Learning dependency translation models as collections of finite state head transducers,2000,0,0,2,0,54633,hiyan alsawi,Computational Linguistics,0,"The paper defines weighted head transducers, finite-state machines that perform middle-out string transduction. These transducers are strictly more expressive than the special case of standard left..."
C00-1007,Exploiting a Probabilistic Hierarchical Model for Generation,2000,12,183,1,1,4704,srinivas bangalore,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"Previous stochastic approaches to generation do not include a tree-based representation of syntax. While this may be adequate or even advantageous for some applications, other applications profit from using as much syntactic knowledge as is available, leaving to a stochastic model only those issues that are not determined by the grammar. We present initial results showing that a tree-based model derived from a tree-annotated corpus improves on a tree model derived from an unannotated corpus, and that a tree-based stochastic model with a hand-crafted grammar outperforms both."
C00-1054,Finite-state Multimodal Parsing and Understanding,2000,27,121,2,1,38458,michael johnston,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"Multimodal interfaces require effective parsing and understanding of utterances whose content is distributed across multiple input modes. Johnston 1998 presents an approach in which strategies for multimodal integration are stated declaratively using a unification-based grammar that is used by a multi-dimensional chart parser to compose inputs. This approach is highly expressive and supports a broad class of interfaces, but offers only limited potential for mutual compensation among the input modes, is subject to significant concerns in terms of computational complexity, and complicates selection among alternative multimodal interpretations of the input. In this paper, we present an alternative approach in which multimodal parsing and understanding are achieved using a weighted finite-state device which takes speech and gesture streams as inputs and outputs their joint interpretation. This approach is significantly more efficient, enables tight-coupling of multimodal understanding with speech recognition, and provides a general probabilistic framework for multimodal ambiguity resolution."
J99-2004,{S}upertagging: An Approach to Almost Parsing,1999,58,331,1,1,4704,srinivas bangalore,Computational Linguistics,0,"In this paper, we have proposed novel methods for robust parsing that integrate the flexibility of linguistically motivated lexical descriptions with the robustness of statistical techniques. Our thesis is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions (supertags) that impose complex constraints in a local context. The supertags are designed such that only those elements on which the lexical item imposes constraints appear within a given supertag. Further, each lexical item is associated with as many supertags as the number of different syntactic contexts in which the lexical item can appear. This makes the number of different descriptions for each lexical item much larger than when the descriptions are less complex, thus increasing the local ambiguity for a parser. But this local ambiguity can be resolved by using statistical distributions of supertag co-occurrences collected from a corpus of parses. We have explored these ideas in the context of the Lexicalized Tree-Adjoining Grammar (LTAG) framework. The supertags in LTAG combine both phrase structure information and dependency information in a single representation. Supertag disambiguation results in a representation that is effectively a parse (an almost parse), and the parser need only combine the individual supertags. This method of parsing can also be used to parse sentence fragments such as in spoken utterances where the disambiguated supertag sequence may not combine into a single structure."
E99-1025,New Models for Improving Supertag Disambiguation,1999,21,32,2,1,15412,john chen,Ninth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In previous work, supertag disambiguation has been presented as a robust partial parsing technique. In this paper we present two approaches: contextual models, which exploit a variety of features in order to improve supertag performance, and class-based models, which assign sets of supertags to words in order to substantially improve accuracy with only a slight increase in ambiguity."
W98-1122,Automatic Acquisition of Phrase Grammars for Stochastic Language Modeling,1998,13,10,2,0,2754,giuseppe riccardi,Sixth Workshop on Very Large Corpora,0,None
W98-0102,Transplanting supertags from {E}nglish to {S}panish,1998,0,4,1,1,4704,srinivas bangalore,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,None
P98-1006,Automatic Acquisition of Hierarchical Transduction Models for Machine Translation,1998,10,42,2,0,41856,hiyan alshawi,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"We describe a method for the fully automatic learning of hierarchical finite state translation models. The input to the method is transcribed speech utterances and their corresponding human translations, and the output is a set of head transducers, i.e. statistical lexical head-outward transducers. A word-alignment function and a head-ranking function are first obtained, and then counts are generated for hypothesized state transitions of head transducers whose lexical translations and word order changes are consistent with the alignment. The method has been applied to create an English-Spanish translation model for a Speech translation application, with word accuracy of over 75% as measured by a string-distance comparison to three reference translations."
C98-1006,Automatic Acquisition of Hierarchical Transduction Models for Machine Translation,1998,10,42,2,0,41856,hiyan alshawi,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"We describe a method for the fully automatic learning of hierarchical finite state translation models. The input to the method is transcribed speech utterances and their corresponding human translations, and the output is a set of head transducers, i.e. statistical lexical head-outward transducers. A word-alignment function and a head-ranking function are first obtained, and then counts are generated for hypothesized state transitions of head transducers whose lexical translations and word order changes are consistent with the alignment. The method has been applied to create an English-Spanish translation model for a Speech translation application, with word accuracy of over 75% as measured by a string-distance comparison to three reference translations."
