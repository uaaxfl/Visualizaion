2021.eval4nlp-1.15,Error Identification for Machine Translation with Metric Embedding and Attention,2021,-1,-1,1,1,8609,raphael rubino,Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems,0,None
2021.acl-long.566,Scientific Credibility of Machine Translation Research: A Meta-Evaluation of 769 Papers,2021,-1,-1,3,0.337458,8610,benjamin marie,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"This paper presents the first large-scale meta-evaluation of machine translation (MT). We annotated MT evaluations conducted in 769 research papers published from 2010 to 2020. Our study shows that practices for automatic MT evaluation have dramatically changed during the past decade and follow concerning trends. An increasing number of MT evaluations exclusively rely on differences between BLEU scores to draw conclusions, without performing any kind of statistical significance testing nor human evaluation, while at least 108 metrics claiming to be better than BLEU have been proposed. MT evaluations in recent papers tend to copy and compare automatic metric scores from previous work to claim the superiority of a method or an algorithm without confirming neither exactly the same training, validating, and testing data have been used nor the metric scores are comparable. Furthermore, tools for reporting standardized metric scores are still far from being widely adopted by the MT community. After showing how the accumulation of these pitfalls leads to dubious evaluation, we propose a guideline to encourage better automatic MT evaluation along with a simple meta-evaluation scoring method to assess its credibility."
2020.wmt-1.23,Combination of Neural Machine Translation Systems at {WMT}20,2020,-1,-1,2,0.337458,8610,benjamin marie,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents neural machine translation systems and their combination built for the WMT20 English-Polish and Japanese-{\textgreater}English translation tasks. We show that using a Transformer Big architecture, additional training data synthesized from monolingual data, and combining many NMT systems through n-best list reranking improve translation quality. However, while we observed such improvements on the validation data, we did not observed similar improvements on the test data. Our analysis reveals that the presence of translationese texts in the validation data led us to take decisions in building NMT systems that were not optimal to obtain the best results on the test data."
2020.wmt-1.121,{NICT} {K}yoto Submission for the {WMT}{'}20 Quality Estimation Task: Intermediate Training for Domain and Task Adaptation,2020,-1,-1,1,1,8609,raphael rubino,Proceedings of the Fifth Conference on Machine Translation,0,"This paper describes the NICT Kyoto submission for the WMT{'}20 Quality Estimation (QE) shared task. We participated in Task 2: Word and Sentence-level Post-editing Effort, which involved Wikipedia data and two translation directions, namely English-to-German and English-to-Chinese. Our approach is based on multi-task fine-tuned cross-lingual language models (XLM), initially pre-trained and further domain-adapted through intermediate training using the translation language model (TLM) approach complemented with a novel self-supervised learning task which aim is to model errors inherent to machine translation outputs. Results obtained on both word and sentence-level QE show that the proposed intermediate training method is complementary to language model domain adaptation and outperforms the fine-tuning only approach."
2020.ngt-1.3,Balancing Cost and Benefit with Tied-Multi Transformers,2020,-1,-1,2,0,286,raj dabre,Proceedings of the Fourth Workshop on Neural Generation and Translation,0,"We propose a novel procedure for training multiple Transformers with tied parameters which compresses multiple models into one enabling the dynamic choice of the number of encoder and decoder layers during decoding. In training an encoder-decoder model, typically, the output of the last layer of the N-layer encoder is fed to the M-layer decoder, and the output of the last decoder layer is used to compute loss. Instead, our method computes a single loss consisting of NxM losses, where each loss is computed from the output of one of the M decoder layers connected to one of the N encoder layers. Such a model subsumes NxM models with different number of encoder and decoder layers, and can be used for decoding with fewer than the maximum number of encoder and decoder layers. Given our flexible tied model, we also address to a-priori selection of the number of encoder and decoder layers for faster decoding, and explore recurrent stacking of layers and knowledge distillation for model compression. We present a cost-benefit analysis of applying the proposed approaches for neural machine translation and show that they reduce decoding costs while preserving translation quality."
2020.coling-main.385,Intermediate Self-supervised Learning for Machine Translation Quality Estimation,2020,-1,-1,1,1,8609,raphael rubino,Proceedings of the 28th International Conference on Computational Linguistics,0,"Pre-training sentence encoders is effective in many natural language processing tasks including machine translation (MT) quality estimation (QE), due partly to the scarcity of annotated QE data required for supervised learning. In this paper, we investigate the use of an intermediate self-supervised learning task for sentence encoder aiming at improving QE performances at the sentence and word levels. Our approach is motivated by a problem inherent to QE: mistakes in translation caused by wrongly inserted and deleted tokens. We modify the translation language model (TLM) training objective of the cross-lingual language model (XLM) to orientate the pre-trained model towards the target task. The proposed method does not rely on annotated data and is complementary to QE methods involving pre-trained sentence encoders and domain adaptation. Experiments on English-to-German and English-to-Russian translation directions show that intermediate learning improves over domain adaptated models. Additionally, our method reaches results in par with state-of-the-art QE models without requiring the combination of several approaches and outperforms similar methods based on pre-trained sentence encoders."
2020.acl-main.532,Tagged Back-translation Revisited: Why Does It Really Work?,2020,-1,-1,2,0.337458,8610,benjamin marie,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"In this paper, we show that neural machine translation (NMT) systems trained on large back-translated data overfit some of the characteristics of machine-translated texts. Such NMT systems better translate human-produced translations, i.e., translationese, but may largely worsen the translation quality of original texts. Our analysis reveals that adding a simple tag to back-translations prevents this quality degradation and improves on average the overall translation quality by helping the NMT system to distinguish back-translated data from original parallel data during training. We also show that, in contrast to high-resource configurations, NMT systems trained in low-resource settings are much less vulnerable to overfit back-translations. We conclude that the back-translations in the training data should always be tagged especially when the origin of the text to be translated is unknown."
W18-6452,Findings of the {WMT} 2018 Shared Task on Automatic Post-Editing,2018,0,2,3,0.370419,13898,rajen chatterjee,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"We present the results from the fourth round of the WMT shared task on MT Automatic Post-Editing. The task consists in automatically correcting the output of a {``}black-box{''} machine translation system by learning from human corrections. Keeping the same general evaluation setting of the three previous rounds, this year we focused on one language pair (English-German) and on domain-specific data (Information Technology), with MT outputs produced by two different paradigms: phrase-based (PBSMT) and neural (NMT). Five teams submitted respectively 11 runs for the PBSMT subtask and 10 runs for the NMT subtask. In the former subtask, characterized by original translations of lower quality, top results achieved impressive improvements, up to -6.24 TER and +9.53 BLEU points over the baseline {``}\textit{do-nothing}{''} system. The NMT subtask proved to be more challenging due to the higher quality of the original translations and the availability of less training data. In this case, top results show smaller improvements up to -0.38 TER and +0.8 BLEU points."
W18-6469,{DFKI}-{MLT} System Description for the {WMT}18 Automatic Post-editing Task,2018,0,0,2,0,5252,daria pylypenko,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"This paper presents the Automatic Post-editing (APE) systems submitted by the DFKI-MLT group to the WMT{'}18 APE shared task. Three monolingual neural sequence-to-sequence APE systems were trained using target-language data only: one using an attentional recurrent neural network architecture and two using the attention-only (\textit{transformer}) architecture. The training data was composed of machine translated (MT) output used as source to the APE model aligned with their manually post-edited version or reference translation as target. We made use of the provided training sets only and trained APE models applicable to phrase-based and neural MT outputs. Results show better performances reached by the attention-only model over the recurrent one, significant improvement over the baseline when post-editing phrase-based MT output but degradation when applied to neural MT output."
W17-4717,Findings of the 2017 Conference on Machine Translation ({WMT}17),2017,0,109,14,0,292,ondvrej bojar,Proceedings of the Second Conference on Machine Translation,0,"This paper presents the results of the WMT17 shared tasks, which includedn three machine translation (MT) tasks (news, biomedical, and multimodal), two evaluation tasks (metrics and run-time estimation of MT quality), an automatic post-editing task, a neural MT training task, and a bandit learning task."
I17-1049,Using Explicit Discourse Connectives in Translation for Implicit Discourse Relation Classification,2017,0,3,3,0,8446,wei shi,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"Implicit discourse relation recognition is an extremely challenging task due to the lack of indicative connectives. Various neural network architectures have been proposed for this task recently, but most of them suffer from the shortage of labeled data. In this paper, we address this problem by procuring additional training data from parallel corpora: When humans translate a text, they sometimes add connectives (a process known as \textit{explicitation}). We automatically back-translate it into an English connective and use it to infer a label with high confidence. We show that a training set several times larger than the original training set can be generated this way. With the extra labeled instances, we show that even a simple bidirectional Long Short-Term Memory Network can outperform the current state-of-the-art."
E17-3002,Common Round: Application of Language Technologies to Large-Scale Web Debates,2017,10,0,11,0,23887,hans uszkoreit,Proceedings of the Software Demonstrations of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Web debates play an important role in enabling broad participation of constituencies in social, political and economic decision-taking. However, it is challenging to organize, structure, and navigate a vast number of diverse argumentations and comments collected from many participants over a long time period. In this paper we demonstrate Common Round, a next generation platform for large-scale web debates, which provides functions for eliciting the semantic content and structures from the contributions of participants. In particular, Common Round applies language technologies for the extraction of semantic essence from textual input, aggregation of the formulated opinions and arguments. The platform also provides a cross-lingual access to debates using machine translation."
W16-3423,Re-assessing the Impact of {SMT} Techniques with Human Evaluation: a Case Study on {E}nglish{---}{C}roatian,2016,0,4,2,0.0864235,9426,antonio toral,Proceedings of the 19th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W16-2301,Findings of the 2016 Conference on Machine Translation,2016,113,137,16,0,292,ondvrej bojar,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the results of the WMT16 shared tasks, which included five machine translation (MT) tasks (standard news, IT-domain, biomedical, multimodal, pronoun), three evaluation tasks (metrics, tuning, run-time estimation of MT quality), and an automatic post-editing task and bilingual document alignment task. This year, 102 MT systems from 24 institutions (plus 36 anonymized online systems) were submitted to the 12 translation directions in the news translation task. The IT-domain task received 31 submissions from 12 institutions in 7 directions and the Biomedical task received 15 submissions systems from 5 institutions. Evaluation was both automatic and manual (relative ranking and 100-point scale assessments). The quality estimation task had three subtasks, with a total of 14 teams, submitting 39 entries. The automatic post-editing task had a total of 6 teams, submitting 11 entries."
N16-1110,Information Density and Quality Estimation Features as Translationese Indicators for Human Translation Classification,2016,24,2,1,1,8609,raphael rubino,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
C16-1072,Modeling Diachronic Change in Scientific Writing with Information Density,2016,0,0,1,1,8609,raphael rubino,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Previous linguistic research on scientific writing has shown that language use in the scientific domain varies considerably in register and style over time. In this paper we investigate the introduction of information theory inspired features to study long term diachronic change on three levels: lexis, part-of-speech and syntax. Our approach is based on distinguishing between sentences from 19th and 20th century scientific abstracts using supervised classification models. To the best of our knowledge, the introduction of information theoretic features to this task is novel. We show that these features outperform more traditional features, such as token or character n-grams, while leading to more compact models. We present a detailed analysis of feature informativeness in order to gain a better understanding of diachronic change on different linguistic levels."
W15-4944,{A}bu-{M}a{T}ran: Automatic building of Machine Translation,2015,48,0,6,0.106361,9426,antonio toral,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W15-3022,{A}bu-{M}a{T}ran at {WMT} 2015 Translation Task: Morphological Segmentation and Web Crawling,2015,28,8,1,1,8609,raphael rubino,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper presents the machine translation systems submitted by the Abu-MaTran project for the Finnishxe2x80x90English language pair at the WMT 2015 translation task. We tackle the lack of resources and complex morphology of the Finnish language by (i) crawling parallel and monolingual data from the Web and (ii) applying rule-based and unsupervised methods for morphological segmentation. Several statistical machine translation approaches are evaluated and then combined to obtain our final submissions, which are the top performing English-to-Finnish unconstrained (all automatic metrics) and constrained (BLEU), and Finnish-to-English constrained (TER) systems."
2015.eamt-1.45,{A}bu-{M}a{T}ran: Automatic building of Machine Translation,2015,48,0,6,0.106361,9426,antonio toral,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,None
W14-3319,{A}bu-{M}a{T}ran at {WMT} 2014 Translation Task: Two-step Data Selection and {RBMT}-Style Synthetic Rules,2014,20,4,1,1,8609,raphael rubino,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper presents the machine translation systems submitted by the AbuMaTran project to the WMT 2014 translation task. The language pair concerned is Englishxe2x80x90French with a focus on French as the target language. The French to English translation direction is also considered, based on the word alignment computed in the other direction. Large language and translation models are built using all the datasets provided by the shared task organisers, as well as the monolingual data from LDC. To build the translation models, we apply a two-step data selection method based on bilingual crossentropy difference and vocabulary saturation, considering each parallel corpus individually. Synthetic translation rules are extracted from the development sets and used to train another translation model. We then interpolate the translation models, minimising the perplexity on the development sets, to obtain our final SMT system. Our submission for the English to French translation task was ranked second amongst nine teams and a total of twenty submissions."
rubino-etal-2014-quality,Quality Estimation for Synthetic Parallel Data Generation,2014,22,1,1,1,8609,raphael rubino,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,This paper presents a novel approach for parallel data generation using machine translation and quality estimation. Our study focuses on pivot-based machine translation from English to Croatian through Slovene. We generate an EnglishâCroatian version of the Europarl parallel corpus based on the EnglishâSlovene Europarl corpus and the Apertium rule-based translation system for SloveneâCroatian. These experiments are to be considered as a first step towards the generation of reliable synthetic parallel data for under-resourced languages. We first collect small amounts of aligned parallel data for the SloveneâCroatian language pair in order to build a quality estimation system for sentence-level Translation Edit Rate (TER) estimation. We then infer TER scores on automatically translated Slovene to Croatian sentences and use the best translations to build an EnglishâCroatian statistical MT system. We show significant improvement in terms of automatic metrics obtained on two test sets using our approach compared to a random selection of synthetic parallel data.
C14-1194,Quality Estimation of {E}nglish-{F}rench Machine Translation: A Detailed Study of the Role of Syntax,2014,32,5,4,0.9375,27769,rasoul kaljahi,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"We investigate the usefulness of syntactic knowledge in estimating the quality of English-French translations. We find that dependency and constituency tree kernels perform well but the error rate can be further reduced when these are combined with hand-crafted syntactic features. Both types of syntactic features provide information which is complementary to tried-and-tested nonsyntactic features. We then compare source and target syntax and find that the use of parse trees of machine translated sentences does not affect the performance of quality estimation nor does the intrinsic accuracy of the parser itself. However, the relatively flat structure of the French Treebank does appear to have an adverse effect, and this is significantly improved by simple transformations of the French trees. Finally, we provide further evidence of the usefulness of these transformations by applying them in a separate task xe2x80x90 parser accuracy prediction."
2014.eamt-1.45,Extrinsic evaluation of web-crawlers in machine translation: a study on {C}roatian-{E}nglish for the tourism domain,2014,-1,-1,2,0.106361,9426,antonio toral,Proceedings of the 17th Annual conference of the European Association for Machine Translation,0,None
W13-2227,The {CNGL}-{DCU}-{P}rompsit Translation Systems for {WMT}13,2013,14,10,1,1,8609,raphael rubino,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper presents the experiments conducted by the Machine Translation group at DCU and Prompsit Language Engineering for the WMT13 translation task. Three language pairs are considered: SpanishEnglish and French-English in both directions and German-English in that direction. For the Spanish-English pair, the use of linguistic information to select parallel data is investigated. For the FrenchEnglish pair, the usefulness of the small indomain parallel corpus is evaluated, compared to an out-of-domain parallel data sub-sampling method. Finally, for the German-English system, we describe our work in addressing the long distance reordering problem and a system combination strategy."
W13-2249,{DCU}-{S}ymantec at the {WMT} 2013 Quality Estimation Shared Task,2013,9,7,1,1,8609,raphael rubino,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We describe the two systems submitted by the DCU-Symantec team to Task 1.1. of the WMT 2013 Shared Task on Quality Estimation for Machine Translation. Task 1.1 involve estimating postediting effort for English-Spanish translation pairs in the news domain. The two systems use a wide variety of features, of which the most effective are the word-alignment, n-gram frequency, language model, POS-tag-based and pseudoreferences ones. Both systems perform at a similarly high level in the two tasks of scoring and ranking translations, although there is some evidence that the systems are over-fitting to the training data."
W13-2255,An Approach Using Style Classification Features for Quality Estimation,2013,10,1,2,0,19792,erwan moreau,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"In this paper we describe our participation to the WMT13 Shared Task on Quality Estimation. The main originality of our approach is to include features originally designed to classify text according to some authorxe2x80x99s style. This implies the use of reference categories, which are meant to represent the quality of the MT output."
I13-1153,Parser Accuracy in Quality Estimation of Machine Translation: A Tree Kernel Approach,2013,26,5,3,1,27769,rasoul kaljahi,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We report on experiments designed to investigate the role of syntactic features in the task of quality estimation for machine translation, focusing on the effect of parser accuracy. Tree kernels are used to predict the segment-level BLEU score of EnglishFrench translations. In order to examine the effect of the accuracy of the parse tree on the accuracy of the quality estimation system, we experiment with various parsing systems which differ substantially with respect to their Parseval f-scores. We find that it makes very little difference which system we choose to use in the quality estimation task xe2x80x90 this effect is particularly apparent for source-side English parse trees."
I13-1166,Estimating the Quality of Translated User-Generated Content,2013,24,2,1,1,8609,raphael rubino,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,Previous research on quality estimation for machine translation has demonstrated the possibility of predicting the translation quality of well-formed data. We present a first study on estimating the translation quality of user-generated content. Our dataset contains English technical forum comments which were translated into French by three automatic systems. These translations were rated in terms of both comprehensibility and fidelity by human annotators. Our experiments show that tried-and-tested quality estimation features work well on this type of data but that extending this set can be beneficial. We also show that the performance of particular types of features depends on the type of system used to produce the translation.
2013.mtsummit-posters.12,Key Problems in Conversion from Simplified to Traditional {C}hinese Characters Topic Models for Translation Quality Estimation for Gisting Purposes,2013,-1,-1,1,1,8609,raphael rubino,Proceedings of Machine Translation Summit XIV: Posters,0,None
2013.mtsummit-posters.13,Topic Models for Translation Quality Estimation for Gisting Purposes,2013,22,19,1,1,8609,raphael rubino,Proceedings of Machine Translation Summit XIV: Posters,0,"This paper addresses the problem of predicting how adequate a machine translation is for gisting purposes. It focuses on the contribution of lexicalised features based on different types of topic models, as we believe these features are more robust than those used in previous work, which depend on linguistic processors that are often unreliable on automatic translations. Experiments with a number of datasets show promising results: the use of topic models outperforms the state-of-the-art approaches by a large margin in all datasets annotated for adequacy."
2013.mtsummit-papers.13,Quality Estimation-guided Data Selection for Domain Adaptation of {SMT},2013,-1,-1,2,0,41915,pratyush banerjee,Proceedings of Machine Translation Summit XIV: Papers,0,None
W12-5706,Sentence-Level Quality Estimation for {MT} System Combination,2012,25,9,2,0,37719,tsuyoshi okita,Proceedings of the Second Workshop on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid {MT},0,"This paper provides the system description of the Dublin City University system combination module for our participation in the system combination task in the Second Workshop on Applying Machine Learning Techniques to Optimize the Division of Labour in Hybrid MT (ML4HMT12). We incorporated a sentence-level quality score, obtained by sentence-level Quality Estimation (QE), as meta information guiding system combination. Instead of using BLEU or (minimum average) TER, we select a backbone for the confusion network using the estimated quality score. For the Spanish-English data, our strategy improved 0.89 BLEU points absolute compared to the best single score and 0.20 BLEU points absolute compared to the standard system combination strategy."
W12-3117,{DCU}-Symantec Submission for the {WMT} 2012 Quality Estimation Task,2012,30,30,1,1,8609,raphael rubino,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper describes the features and the machine learning methods used by Dublin City University (DCU) and SYMANTEC for the WMT 2012 quality estimation task. Two sets of features are proposed: one constrained, i.e. respecting the data limitation suggested by the workshop organisers, and one unconstrained, i.e. using data or tools trained on data that was not provided by the workshop organisers. In total, more than 300 features were extracted and used to train classifiers in order to predict the translation quality of unseen data. In this paper, we focus on a subset of our feature set that we consider to be relatively novel: features based on a topic model built using the Latent Dirichlet Allocation approach, and features based on source and target language syntax extracted using part-of-speech (POS) taggers and parsers. We evaluate nine feature combinations using four classification-based and four regression-based machine learning techniques."
F12-2049,Post-{\\'e}dition statistique pour l{'}adaptation aux domaines de sp{\\'e}cialit{\\'e} en traduction automatique (Statistical Post-Editing of Machine Translation for Domain Adaptation) [in {F}rench],2012,0,0,1,1,8609,raphael rubino,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
C12-1014,An Evaluation of Statistical Post-Editing Systems Applied to {RBMT} and {SMT} Systems,2012,17,10,2,0,33757,hanna bechara,Proceedings of {COLING} 2012,0,"Statistical post-editing (SPE) of the output produced by rule-based MT (RBMT) systems has been reported to produce extraordinary BLEU (and other automatic evaluation) score improvements. SPE has also been applied to the output of statistical MT (SMT) systems, albeit with more mixed results. We present a statistical post-editing pipeline and evaluate the outputs using automatic and human evaluation techniques, comparing the two SPE pipeline systems (RBMT  SPE and SMT  SPE) with the pure RBMT and SMT system, in an SPE scenario that uses independently existing bitext data, rather than manually corrected first stage MT output, as its training data. Our results show that although automatic evaluation metrics favour the pure SMT system, human evaluators prefer the output provided by the statistically post-edited RBMT system."
2012.eamt-1.55,Statistical Post-Editing of Machine Translation for Domain Adaptation,2012,25,1,1,1,8609,raphael rubino,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,This paper presents a statistical approach to adapt out-of-domain machine translation systems to the medical domain through an unsupervised post-editing step. A statistical post-editing model is built on statistical machine translation (SMT) outputs aligned with their translation references. Evaluations carried out to translate medical texts from French to English show that an out-of-domain machine translation system can be adapted a posteriori to a specific domain. Two SMT systems are studied: a state-of-the-art phrasebased implementation and an online publicly available system. Our experiments also indicate that selecting sentences for post-editing leads to significant improvements of translation quality and that more gains are still possible with respect to an oracle measure.
2012.amta-papers.27,A Detailed Analysis of Phrase-based and Syntax-based {MT}: The Search for Systematic Differences,2012,29,5,2,1,27769,rasoul kaljahi,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This paper describes a range of automatic and manual comparisons of phrase-based and syntax-based statistical machine translation methods applied to English-German and English-French translation of user-generated content. The syntax-based methods underperform the phrase-based models and the relaxation of syntactic constraints to broaden translation rule coverage means that these models do not necessarily generate output which is more grammatical than the output produced by the phrase-based models. Although the systems generate different output and can potentially be fruitfully combined, the lack of systematic difference between these models makes the combination task more challenging."
W11-2154,The {LIGA} ({LIG}/{LIA}) Machine Translation System for {WMT} 2011,2011,7,2,2,0,43044,marion potet,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper describes the system submitted by the Laboratory of Informatics of Grenoble (LIG) for the fifth Workshop on Statistical Machine Translation. We participated to the news shared translation task for the French-English language pair. We investigated differents techniques to simply deal with Out-Of-Vocabulary words in a statistical phrase-based machine translation system and analyze their impact on translation quality. The final submission is a combination between a standard phrase-based system using the Moses decoder, with appropriate setups and pre-processing, and a lemmatized system to deal with Out-Of-Vocabulary conjugated verbs."
R09-2012,Exploring Context Variation and Lexicon Coverage in Projection-based Approach for Term Translation,2009,19,4,1,1,8609,raphael rubino,Proceedings of the Student Research Workshop,0,"Identifying translations in comparable corpora has inspired many studies in bilingual terminology extraction [4, 5]. Projection-based approaches, which are among the most popular ones, rely on a seed bilingual lexicon. Surprisingly, there is no careful analysis of the impact of the size the initial context and coverage of the lexicon. This is precisely the focus of this study. We observe that source context size and lexicon coverage influence robustness in projection-based term translation. In particular, we show that increasing the number of seed words by a factor of three leads to a 20% relative improvement in accuracy."
