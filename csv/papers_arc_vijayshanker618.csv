2021.bionlp-1.1,Improving {BERT} Model Using Contrastive Learning for Biomedical Relation Extraction,2021,-1,-1,3,0,12136,peng su,Proceedings of the 20th Workshop on Biomedical Language Processing,0,"Contrastive learning has been used to learn a high-quality representation of the image in computer vision. However, contrastive learning is not widely utilized in natural language processing due to the lack of a general method of data augmentation for text data. In this work, we explore the method of employing contrastive learning to improve the text representation from the BERT model for relation extraction. The key knob of our framework is a unique contrastive pre-training step tailored for the relation extraction tasks by seamlessly integrating linguistic knowledge into the data augmentation. Furthermore, we investigate how large-scale data constructed from the external knowledge bases can enhance the generality of contrastive pre-training of BERT. The experimental results on three relation extraction benchmark datasets demonstrate that our method can improve the BERT model representation and achieve state-of-the-art performance. In addition, we explore the interpretability of models by showing that BERT with contrastive pre-training relies more on rationales for prediction. Our code and data are publicly available at: https://github.com/AnonymousForNow."
W17-2323,Noise Reduction Methods for Distantly Supervised Biomedical Relation Extraction,2017,14,8,3,0,8484,gang li,{B}io{NLP} 2017,0,"Distant supervision has been applied to automatically generate labeled data for biomedical relation extraction. Noise exists in both positively and negatively-labeled data and affects the performance of supervised machine learning methods. In this paper, we propose three novel heuristics based on the notion of proximity, trigger word and confidence of patterns to leverage lexical and syntactic information to reduce the level of noise in the distantly labeled data. Experiments on three different tasks, extraction of protein-protein-interaction, miRNA-gene regulation relation and protein-localization event, show that the proposed methods can improve the F-score over the baseline by 6, 10 and 14 points for the three tasks, respectively. We also show that when the models are configured to output high-confidence results, high precisions can be obtained using the proposed methods, making them promising for facilitating manual curation for databases."
W17-2326,Identifying Comparative Structures in Biomedical Text,2017,12,4,5,0,31956,samir gupta,{B}io{NLP} 2017,0,"Comparison sentences are very commonly used by authors in biomedical literature to report results of experiments. In such comparisons, authors typically make observations under two different scenarios. In this paper, we present a system to automatically identify such comparative sentences and their components i.e. the compared entities, the scale of the comparison and the aspect on which the entities are being compared. Our methodology is based on dependencies obtained by applying a parser to extract a wide range of comparison structures. We evaluated our system for its effectiveness in identifying comparisons and their components. The system achieved a F-score of 0.87 for comparison sentence identification and 0.77-0.81 for identifying its components."
W12-2420,{R}ank{P}ref: Ranking Sentences Describing Relations between Biomedical Entities with an Application,2012,25,7,2,0,42334,catalina tudor,{B}io{NLP}: Proceedings of the 2012 Workshop on Biomedical Natural Language Processing,0,"This paper presents a machine learning approach that selects and, more generally, ranks sentences containing clear relations between genes and terms that are related to them. This is treated as a binary classification task, where preference judgments are used to learn how to choose a sentence from a pair of sentences. Features to capture how the relationship is described textually, as well as how central the relationship is in the sentence, are used in the learning process. Simplification of complex sentences into simple structures is also applied for the extraction of the features. We show that such simplification improves the results by up to 13%. We conducted three different evaluations and we found that the system significantly outperforms the baselines."
W09-1107,A Method for Stopping Active Learning Based on Stabilizing Predictions and the Need for User-Adjustable Stopping,2009,20,41,2,1,31907,michael bloodgood,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL}-2009),0,"A survey of existing methods for stopping active learning (AL) reveals the needs for methods that are: more widely applicable; more aggressive in saving annotations; and more stable across changing datasets. A new method for stopping AL based on stabilizing predictions is presented that addresses these needs. Furthermore, stopping methods are required to handle a broad range of different annotation/performance tradeoff valuations. Despite this, the existing body of work is dominated by conservative methods with little (if any) attention paid to providing users with control over the behavior of stopping methods. The proposed method is shown to fill a gap in the level of aggressiveness available for stopping AL and supports providing users with control over stopping behavior."
N09-2035,Taking into Account the Differences between Actively and Passively Acquired Data: The Case of Active Learning with Support Vector Machines for Imbalanced Datasets,2009,8,37,2,1,31907,michael bloodgood,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"Actively sampled data can have very different characteristics than passively sampled data. Therefore, it's promising to investigate using different inference procedures during AL than are used during passive learning (PL). This general idea is explored in detail for the focused case of AL with cost-weighted SVMs for imbalanced data, a situation that arises for many HLT tasks. The key idea behind the proposed InitPA method for addressing imbalance is to base cost models during AL on an estimate of overall corpus imbalance computed via a small unbiased sample rather than the imbalance in the labeled training data, which is the leading method used during PL."
W08-0604,Mining the Biomedical Literature for Genic Information,2008,-1,-1,2,0,42334,catalina tudor,Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,0,None
W08-0620,An Approach to Reducing Annotation Costs for {B}io{NLP},2008,6,2,2,1,31907,michael bloodgood,Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,0,"There is a broad range of BioNLP tasks for which active learning (AL) can significantly reduce annotation costs and a specific AL algorithm we have developed is particularly effective in reducing annotation costs for these tasks. We have previously developed an AL algorithm called ClosestInitPA that works best with tasks that have the following characteristics: redundancy in training material, burdensome annotation costs, Support Vector Machines (SVMs) work well for the task, and imbalanced datasets (i.e. when set up as a binary classification problem, one class is substantially rarer than the other). Many BioNLP tasks have these characteristics and thus our AL algorithm is a natural approach to apply to BioNLP tasks."
W07-1024,Adaptation of {POS} Tagging for Multiple {B}io{M}edical Domains,2007,6,5,3,1,12327,john miller,"Biological, translational, and clinical language processing",0,"Part of Speech (POS) tagging is often a prerequisite for tasks such as partial parsing and information extraction. However, when a POS tagger is simply ported to another domain the tagger's accuracy drops. This problem can be addressed through hand annotation of a corpus in the new domain and supervised training of a new tagger. In our methodology, we use existing raw text and a generic POS annotated corpus to develop taggers for new domains without hand annotation or supervised training. We focus in particular on out-of-vocabulary words since they reduce accuracy (Lease and Charniak. 2005; Smith et al. 2005)."
D07-1118,Building Domain-Specific Taggers without Annotated (Domain) Data,2007,14,9,3,1,12327,john miller,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"Part of speech tagging is a fundamental component in many NLP systems. When taggers developed in one domain are used in another domain, the performance can degrade considerably. We present a method for developing taggers for new domains without requiring POS annotated text in the new domain. Our method involves using raw domain text and identifying related words to form a domain specific lexicon. This lexicon provides the initial lexical probabilities for EM training of an HMM model. We evaluate the method by applying it in the Biology domain and show that we achieve results that are comparable with some taggers developed for this domain."
W06-3321,Rapid Adaptation of {POS} Tagging for Domain Specific Uses,2006,5,2,4,1,12327,john miller,Proceedings of the {HLT}-{NAACL} {B}io{NLP} Workshop on Linking Natural Language and Biology,0,"Part-of-speech (POS) tagging is a fundamental component for performing natural language tasks such as parsing, information extraction, and question answering. When POS taggers are trained in one domain and applied in significantly different domains, their performance can degrade dramatically. We present a methodology for rapid adaptation of POS taggers to new domains. Our technique is unsupervised in that a manually annotated corpus for the new domain is not necessary. We use suffix information gathered from large amounts of raw text as well as orthographic information to increase the lexical coverage. We present an experiment in the Biological domain where our POS tagger achieves results comparable to POS taggers specifically trained to this domain."
W03-1601,Generation of Single-sentence Paraphrases from Predicate/Argument Structure using Lexico-grammatical Resources,2003,9,33,3,0,52673,raymond kozlowski,Proceedings of the Second International Workshop on Paraphrasing,0,"Paraphrases, which stem from the variety of lexical and grammatical means of expressing meaning available in a language, pose challenges for a sentence generation system. In this paper, we discuss the generation of paraphrases from predicate/argument structure using a simple, uniform generation methodology. Central to our approach are lexico-grammatical resources which pair elementary semantic structures with their syntactic realization and a simple but powerful mechanism for combining resources."
W03-1315,An Investigation of Various Information Sources for Classifying Biological names,2003,12,12,3,1,49025,manabu torii,Proceedings of the {ACL} 2003 Workshop on Natural Language Processing in Biomedicine,0,"The classification task is an integral part of named entity extraction. This task has not received much attention in the biomedical setting, partly due to the fact that protein name recognition has been the focus of the majority of the work in this field. We study this problem and focus on different sources of information that can be utilized for the classification task and investigate the extent of their contributions for classification in this domain. However, while developing a specific algorithm for the classification of the names is not our main focus, we make use of some simple techniques to investigate different sources of information and verify our intuitions about their usefulness."
J01-1004,{D}-Tree Substitution Grammars,2001,40,38,2,0.193083,1354,owen rambow,Computational Linguistics,0,"There is considerable interest among computational linguists in lexicalized grammatical frame-works; lexicalized tree adjoining grammar (LTAG) is one widely studied example. In this paper, we investigate how derivations in LTAG can be viewed not as manipulations of trees but as manipulations of tree descriptions. Changing the way the lexicalized formalism is viewed raises questions as to the desirability of certain aspects of the formalism. We present a new formalism, d-tree substitution grammar (DSG). Derivations in DSG involve the composition of d-trees, special kinds of tree descriptions. Trees are read off from derived d-trees. We show how the DSG formalism, which is designed to inherit many of the characterestics of LTAG, can be used to express a variety of linguistic analyses not available in LTAG."
2000.iwpt-1.9,Automated Extraction of {TAG}s from the {Penn} {Treebank},2000,-1,-1,2,0,15412,john chen,Proceedings of the Sixth International Workshop on Parsing Technologies,0,"The accuracy of statistical parsing models can be improved with the use of lexical information. Statistical parsing using Lexicalized tree adjoining grammar (LTAG), a kind of lexicalized grammar, has remained relatively unexplored. We believe that is largely in part due to the absence of large corpora accurately bracketed in terms of a perspicuous yet broad coverage LTAG. Our work attempts to alleviate this difficulty. We extract different LTAGs from the Penn Treebank. We show that certain strategies yield an improved extracted LTAG in terms of compactness, broad coverage, and supertagging accuracy. Furthermore, we perform a preliminary investigation in smoothing these grammars by means of an external linguistic resource, namely, the tree families of an XTAG grammar, a hand built grammar of English."
W98-0104,Motion verbs and semantic features in {TAG},1998,0,0,3,0,42142,tonia bleam,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,None
W98-0112,{TAG} derivation as monotonic {C}-command,1998,-1,-1,2,0,2215,robert frank,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,None
W98-0135,Wh-islands in {TAG} and related formalisms,1998,1,2,2,0.319149,1354,owen rambow,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,None
W98-0143,Consistent grammar development using partial-tree descriptions for {L}exicalized {T}ree-{A}djoining {G}rammars,1998,3,14,3,0,16067,fei xia,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,None
P98-2188,Dialogue Act Tagging with Transformation-Based Learning,1998,18,83,3,0,46878,ken samuel,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"For the task of recognizing dialogue acts, we are applying the Transformation-Based Learning (TBL) machine learning algorithm. To circumvent a sparse data problem, we extract values of well-motivated features of utterances, such as speaker direction, punctuation marks, and a new feature, called dialogue act cues, which we find to be more effective than cue phrases and word n-grams in practice. We present strategies for constructing a set of dialogue act cues automatically by minimizing the entropy of the distribution of dialogue acts in a training corpus, filtering out irrelevant dialogue act cues, and clustering semantically-related words. In addition, to address limitations of TBL, we introduce a Monte Carlo strategy for training efficiently and a committee method for computing confidence measures. These ideas are combined in our working implementation, which labels held-out data as accurately as any other reported system for the dialogue act tagging task."
C98-2183,Dialogue Act Tagging with Transformation-Based Learning,1998,18,83,3,0,46878,ken samuel,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"For the task of recognizing dialogue acts, we are applying the Transformation-Based Learning (TBL) machine learning algorithm. To circumvent a sparse data problem, we extract values of well-motivated features of utterances, such as speaker direction, punctuation marks, and a new feature, called dialogue act cues, which we find to be more effective than cue phrases and word n-grams in practice. We present strategies for constructing a set of dialogue act cues automatically by minimizing the entropy of the distribution of dialogue acts in a training corpus, filtering out irrelevant dialogue act cues, and clustering semantically-related words. In addition, to address limitations of TBL, we introduce a Monte Carlo strategy for training efficiently and a committee method for computing confidence measures. These ideas are combined in our working implementation, which labels held-out data as accurately as any other reported system for the dialogue act tagging task."
P95-1013,Compilation of {HPSG} to {TAG},1995,7,42,4,0,54903,robert kasper,33rd Annual Meeting of the Association for Computational Linguistics,1,"We present an implemented compilation algorithm that translates HPSG into lexicalized feature-based TAG, relating concepts of the two theories. While HPSG has a more elaborated principle-based theory of possible phrase structures, TAG provides the means to represent lexicalized structures more explicitly. Our objectives are met by giving clear definitions that determine the projection of structures from the lexicon, and identify maximal projections, auxiliary trees and foot nodes."
P95-1021,{D}-Tree Grammars,1995,18,95,2,0.319149,1354,owen rambow,33rd Annual Meeting of the Association for Computational Linguistics,1,"DTG are designed to share some of the advantages of TAG while overcoming some of its limitations. DTG involve two composition operations called subsertion and sister-adjunction. The most distinctive feature of DTG is that, unlike TAG, there is complete uniformity in the way that the two DTG operations relate lexical items: subsertion always corresponds to complementation and sister-adjunction to modification. Furthermore, DTG, unlike TAG, can provide a uniform analysis for wh-movement in English and Kashmiri, despite the fact that the wh element in Kashmiri appears in sentence-second position, and not sentence-initial position as in English."
1995.iwpt-1.30,Parsing {D}-Tree Grammars,1995,0,11,1,1,12137,vijayshanker,Proceedings of the Fourth International Workshop on Parsing Technologies,0,
J93-4002,Parsing Some Constrained Grammar Formalisms,1993,22,79,1,1,12137,vijayshanker,Computational Linguistics,0,In this paper we present a scheme to extend a recognition algorithm for Context-Free Grammars (CFG) that can be used to derive polynomial-time recognition algorithms for a set of for-malisms that generate a superset of languages generated by CFG. We describe the scheme by developing a Cocke-Kasami-Younger (CKY)-like pure bottom-up recognition algorithm for Linear Indexed Grammars and show how it can be adapted to give algorithms for Tree Adjoining Grammars and Combinatory Categorial Grammars. This is the only polynomial-time recognition algorithm for Combinatory Categorial Grammars that we are aware of.The main contribution of this paper is the general scheme we propose for parsing a variety of formalisms whose derivation process is controlled by an explicit or implicit stack. The ideas presented here can be suitably modified for other parsing styles or used in the generalized framework set out by Lang (1990).
E93-1045,The Use of Shared Forests in {T}ree {A}djoining {G}rammar Parsing,1993,10,28,1,1,12137,vijayshanker,Sixth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,We study parsing of tree adjoining grammars with particular emphasis on the use of shared forests to represent all the parse trees deriving a well-formed string. We show that there are two distinct ways of representing the parse forest one of which involves the use of linear indexed grammars and the other the use of context-free grammars. The work presented in this paper is intended to give a general framework for studying tag parsing. The schemes using lig and cfg to represent parses can be seen to underly most of the existing tag parsing algorithms.
P92-1007,A Functional Approach to Generation with {TAG},1992,17,8,2,0.909091,31670,kathleen mccoy,30th Annual Meeting of the Association for Computational Linguistics,1,"It has been hypothesized that Tree Adjoining Grammar (TAG) is particularly well suited for sentence generation. It is unclear, however, how a sentence generation system based on TAG should choose among the syntactic possibilities made available in the grammar. In this paper we consider the question of what needs to be done to generate with TAGs and explain a generation system that provides the necessary features. This approach is compared with other TAG-based generation systems. Particular attention is given to Mumble-86 which, like our system, makes syntactic choice on sophisticated functional grounds."
P92-1010,Reasoning with Descriptions of Trees,1992,8,32,2,0,15524,james rogers,30th Annual Meeting of the Association for Computational Linguistics,1,"In this paper we introduce a logic for describing trees which allows us to reason about both the parent and domination relationship. The use of domination has found a number of applications, such as in deterministic parsers based on Description theory (Marcus, Hindle & Fleck, 1983), in a compact organization of the basic structures of Tree-Adjoining Grammars (Vijay-Shanker & Schabes, 1992), and in a new characterization of the adjoining operation that allows a clean integration of TAGs into the unification-based framework (Vijay-Shanker, 1992) Our logic serves to formalize the reasoning on which these applications are based."
J92-4004,Using Descriptions of Trees in a {T}ree {A}djoining {G}rammar,1992,22,110,1,1,12137,vijayshanker,Computational Linguistics,0,"This paper describes a new interpretation of Tree Adjoining Grammars (TAG) that allows the embedding of TAG in the unification framework in a manner consistent with the declarative approach taken in this framework. In the new interpretation we present in this paper, the objects manipulated by a TAG are considered to be descriptions of trees. This is in contrast to the traditional view that in a TAG the composition operations of adjoining and substitution combine trees. Borrowing ideas from Description Theory, we propose quasi-trees as a means to represent partial descriptions of trees. Using quasi-trees, we are able to justify the definition of feature structure-based Tree Adjoining Grammars (FTAG) that was first given in Vijay-Shanker (1987) and Vijay-Shanker and Joshi (1988). In the definition of the FTAG formalism given here, we argue that a grammar manipulates descriptions of trees (i.e., quasi-trees); whereas the structures derived by a grammar are trees that are obtained by taking the minimal readings of such descriptions. We then build on and refine the earlier version of FTAG, give examples that illustrate the usefulness of embedding TAG in the unification framework, and present a logical formulation (and its associated semantics) of FTAG that shows the separation between descriptions of well-formed structures and the actual structures that are derived, a theme that is central to this work. Finally, we discuss some questions that are raised by our new interpretation of the TAG formalism: questions dealing with the nature and definition of the adjoining operation (in contrast to substitution), its relation to multi-component adjoining, and the distinctions between auxiliary and initial structures."
C92-1034,Structure Sharing in {L}exicalized {T}ree-{A}djoining {G}rammars,1992,15,38,1,1,12137,vijayshanker,{COLING} 1992 Volume 1: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"We present a scheme for efficiently representing a lexicalized tree-adjoining grammar (LTAG). The proposed representational scheme allows for structure-sharing between lexical entries and the trees associated with the lexical items. A compact organization is achieved by organizing the lexicon in a hierarchical fashion and using inheritance as well as by using lexical and syntactic rules.While different organizations (Flickinger, 1987; Pollard and Sag, 1987; Shieber, 1986) of the lexicon have been proposed, in the scheme we propose, the inheritance hierarchy not only provides structure-sharing of lexical information but also of the associated elementary trees of extended domain of locality. Furthermore, the lexical and syntactic rules can be used to derive new elementary trees from the default structures specified in the hierarchical lexicon.In the envisaged scheme, the use of a hierarchical lexicon and of lexical and syntactic rules for lexicalized tree-adjoining grammars will capture important linguistic generalizations and also allows for a space efficient representation of the grammar. This will allow for easy maintenance and facilitate updates to the grammar."
W90-0205,Embedded Pushdown Automata,1990,-1,-1,1,1,12137,vijayshanker,Proceedings of the First International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+1),0,None
W90-0101,Using {T}ree {A}djoining {G}rammars Systemic Framework in the,1990,0,3,2,0.909091,31670,kathleen mccoy,Proceedings of the Fifth International Workshop on Natural Language Generation,0,None
P90-1001,Polynomial Time Parsing of {C}ombinatory {C}ategorial {G}rammars,1990,11,49,1,1,12137,vijayshanker,28th Annual Meeting of the Association for Computational Linguistics,1,"In this paper we present a polynomial time parsing algorithm for Combinatory Categorial Grammar. The recognition phase extends the CKY algorithm for CFG. The process of generating a representation of the parse trees has two phases. Initially, a shared forest is build that encodes the set of all derivation trees for the input string. This shared forest is then pruned to remove all spurious ambiguity."
P90-1035,Deterministic Left to Right Parsing of Tree Adjoining Languages,1990,10,27,2,0,55905,yves schabes,28th Annual Meeting of the Association for Computational Linguistics,1,"We define a set of deterministic bottom-up left to right parsers which analyze a subset of Tree Adjoining Languages. The LR parsing strategy for Context Free Grammars is extended to Tree Adjoining Grammars (TAGs). We use a machine, called Bottom-up Embedded Push Down Automation (BEPDA), that recognizes in a bottom-up fashion the set of Tree Adjoining Languages (and exactly this set). Each parser consists of a finite state control that drives the moves of a Bottom-up Embedded Pushdown Automaton. The parsers handle deterministically some context-sensitive Tree Adjoining Languages. In this paper, we informally describe the BEPDA then given a parsing table, we explain the LR parsing algorithm. We then show how to construct an LR(0) parsing table (no lookahead). An example of a context-sensitive language recognized deterministically is given. Then, we explain informally the construction of SLR(1) parsing tables for BEPDA. We conclude with a discussion of our parsing method and current work."
J90-1002,An Interpretation of Negation in Feature Structure Descriptions,1990,13,13,2,0,57516,anuj dawar,Computational Linguistics,0,"Feature structures are informational elements that have been used in several linguistic theories and in computational systems for natural language processing. A logical calculus has been developed and used as a description language for feature structures. In the present work, a framework in three-valued logic is suggested for defining the semantics of a feature structure description language, allowing for a more complete set of logical operators. In particular, an interpretation of the negation and implication operators is examined within this framework. We extend this approach to interpret descriptions that involve existence (or nonexistence) of values for attributes. A definition of augmented feature structures is proposed, and one particular interpretation of the description language with a negation operator is described. A sound and complete proof system is presented for the logic thus obtained and its computational aspects studied."
W89-0218,Recognition of {C}ombinatory {C}ategorial {G}rammars and Linear Indexed Grammars,1989,0,1,1,1,12137,vijayshanker,Proceedings of the First International Workshop on Parsing Technologies,0,
P89-1003,A Three-Valued Interpretation of Negation in Feature Structure Descriptions,1989,9,12,2,0,57516,anuj dawar,27th Annual Meeting of the Association for Computational Linguistics,1,"Feature structures are informational elements that have been used in several linguistic theories and in computational systems for natural-language processing. A logical calculus has been developed and used as a description language for feature structures. In the present work, a framework in three-valued logic is suggested for defining the semantics of a feature structure description language, allowing for a more complete set of logical operators. In particular, the semantics of the negation and implication operators are examined. Various proposed interpretations of negation and implication are compared within the suggested framework. One particular interpretation of the description language with a negation operator is described and its computational aspects studied."
P89-1027,Treatment of Long Distance Dependencies in {LFG} and {TAG}: Functional Uncertainty in {LFG} Is a Corollary in {TAG},1989,9,7,2,0,33217,aravind joshi,27th Annual Meeting of the Association for Computational Linguistics,1,"In this paper the functional uncertainty machinery in LFG is compared with the treatment of long distance dependencies in TAG. It is shown that the functional uncertainty machinery is redundant in TAG, i.e., what functional uncertainty accomplishes for LFG follows from the TAG formalism itself and some aspects of the linguistic theory instantiated in TAG. It is also shown that the analyses provided by the functional uncertainty machinery can be obtained without requiring power beyond mildly context-sensitive grammars. Some linguistic and computational aspects of these results have been briefly discussed also."
C88-2147,Feature Structures Based {T}ree {A}djoining {G}rammars,1988,9,90,1,1,12137,vijayshanker,{C}oling {B}udapest 1988 Volume 2: {I}nternational {C}onference on {C}omputational {L}inguistics,0,"We have embedded Tree Adjoining Grammars (TAG) in a feature structure based unification system. The resulting system, Feature Structure based Tree Adjoining Grammars (FTAG), captures the principle of factoring dependencies and recursion, fundamental to TAG's. We show that FTAG has an enhanced descriptive capacity compared to TAG formalism. We consider some restricted versions of this system and some possible linguistic stipulations that can be made. We briefly describe a calculus to represent the structures used by this system, extending on the work of Rounds, and Kasper [Rounds et al. 1986, Kasper et al. 1986] involving the logical formulation of feature structures."
P87-1015,Characterizing Structural Descriptions Produced by Various Grammatical Formalisms,1987,13,217,1,1,12137,vijayshanker,25th Annual Meeting of the Association for Computational Linguistics,1,"We consider the structural descriptions produced by various grammatical formalisms in terms of the complexity of the paths and the relationship between paths in the sets of structural descriptions that each system can generate. In considering the relationship between formalisms, we show that it is useful to abstract away from the details of the formalism, and examine the nature of their derivation process as reflected by properties of their derivation trees. We find that several of the formalisms considered can be seen as being closely related since they have derivation tree sets with the same structure as those produced by Context-Free Grammars. On the basis of this observation, we describe a class of formalisms which we call Linear Context-Free Rewriting Systems, and show they are recognizable in polynomial time and generate only semilinear languages."
P86-1011,The Relationship Between {T}ree {A}djoining {G}rammars And Head Grammars,1986,6,14,2,0,58137,weir,24th Annual Meeting of the Association for Computational Linguistics,1,We examine the relationship between the two grammatical formalisms: Tree Adjoining Grammars and Head Grammars. We briefly investigate the weak equivalence of the two formalisms. We then turn to a discussion comparing the linguistic expressiveness of the two formalisms.
C86-1048,Tree Adjoining and Head Wrapping,1986,4,30,1,1,12137,vijayshanker,Coling 1986 Volume 1: The 11th International Conference on Computational Linguistics,0,"In this paper we discuss the formal relationship between thw classes of languages generated by Tree Adjoining Grammars and Head Grammars. In particular, we show that Head Languages are included in Tree Adjoining Languages and that Tree Adjoining Grammars are equivalent to a modification of Head Grammars called Modified Head Grammars. The inclusion of MHL in HL, and thus the equivalence of HG's and TAG's in the most general case remains to be established."
