1999.mtsummit-1.37,J90-2002,0,0.456976,"Missing"
1999.mtsummit-1.37,J93-2003,0,0.00718993,"Missing"
1999.mtsummit-1.37,1999.mtsummit-1.92,1,0.845676,"Missing"
1999.mtsummit-1.37,1997.tmi-1.14,0,0.115704,"d dramatically in such a way that not only statistics but also other learning techniques have entered the MT domain. Artificial neural networks were used for MT (McLean, 1992) or to transfer a source language parse tree into a target language parse tree (Wang and Waibel, 1995). Hiroshi et al. (1996) describe an MT system which makes use of genetic algorithms to optimize translation rules. Other approaches mix more or less shallow linguistic analysis with statistics (Knight et al., 1994) or with symbolic inductive methods (Sato and Nagao, 1990; Güvenir and Tunc 1996; Güvenir and Cicekli, 1998; Collins and Cunningham, 1997; Collins, 1999). Knight et al. (1994) ranks semantic analyzes of an input sentence by statistical means to filter out least probable analyses. Sato and Nagao (1990) replace subtrees in a tree bank of syntactically analyzed source-target language equivalences to obtain target language parse trees. Güvenir and Tunc (1996), Güvenir and Cicekli (1998) Collins and Cunningham (1997) and Collins (1999) induce translation templates to map a generalized input sentence into the target language. Different as they are, these approaches have in common that they use a corpus of reference translations which"
1999.mtsummit-1.37,C96-2178,0,0.0215335,"nger considered as deduction but rather as a stochastic process which relies on a number of random variables. Given a well evolved stochastic theory and powerful hardware, random variables could be computed from a sufficiently large set of example translations. - 250- Since then machine learning technologies have evolved dramatically in such a way that not only statistics but also other learning techniques have entered the MT domain. Artificial neural networks were used for MT (McLean, 1992) or to transfer a source language parse tree into a target language parse tree (Wang and Waibel, 1995). Hiroshi et al. (1996) describe an MT system which makes use of genetic algorithms to optimize translation rules. Other approaches mix more or less shallow linguistic analysis with statistics (Knight et al., 1994) or with symbolic inductive methods (Sato and Nagao, 1990; Güvenir and Tunc 1996; Güvenir and Cicekli, 1998; Collins and Cunningham, 1997; Collins, 1999). Knight et al. (1994) ranks semantic analyzes of an input sentence by statistical means to filter out least probable analyses. Sato and Nagao (1990) replace subtrees in a tree bank of syntactically analyzed source-target language equivalences to obtain ta"
1999.mtsummit-1.37,1994.amta-1.18,0,0.0502003,"ld be computed from a sufficiently large set of example translations. - 250- Since then machine learning technologies have evolved dramatically in such a way that not only statistics but also other learning techniques have entered the MT domain. Artificial neural networks were used for MT (McLean, 1992) or to transfer a source language parse tree into a target language parse tree (Wang and Waibel, 1995). Hiroshi et al. (1996) describe an MT system which makes use of genetic algorithms to optimize translation rules. Other approaches mix more or less shallow linguistic analysis with statistics (Knight et al., 1994) or with symbolic inductive methods (Sato and Nagao, 1990; Güvenir and Tunc 1996; Güvenir and Cicekli, 1998; Collins and Cunningham, 1997; Collins, 1999). Knight et al. (1994) ranks semantic analyzes of an input sentence by statistical means to filter out least probable analyses. Sato and Nagao (1990) replace subtrees in a tree bank of syntactically analyzed source-target language equivalences to obtain target language parse trees. Güvenir and Tunc (1996), Güvenir and Cicekli (1998) Collins and Cunningham (1997) and Collins (1999) induce translation templates to map a generalized input sentenc"
1999.mtsummit-1.37,1992.tmi-1.4,0,0.388391,"In 1990 a new epoch started when Brown et al. (1990) presented a paper on statistics-based MT. Translation was no longer considered as deduction but rather as a stochastic process which relies on a number of random variables. Given a well evolved stochastic theory and powerful hardware, random variables could be computed from a sufficiently large set of example translations. - 250- Since then machine learning technologies have evolved dramatically in such a way that not only statistics but also other learning techniques have entered the MT domain. Artificial neural networks were used for MT (McLean, 1992) or to transfer a source language parse tree into a target language parse tree (Wang and Waibel, 1995). Hiroshi et al. (1996) describe an MT system which makes use of genetic algorithms to optimize translation rules. Other approaches mix more or less shallow linguistic analysis with statistics (Knight et al., 1994) or with symbolic inductive methods (Sato and Nagao, 1990; Güvenir and Tunc 1996; Güvenir and Cicekli, 1998; Collins and Cunningham, 1997; Collins, 1999). Knight et al. (1994) ranks semantic analyzes of an input sentence by statistical means to filter out least probable analyses. Sat"
1999.mtsummit-1.37,W98-1231,1,\N,Missing
1999.mtsummit-1.92,1999.mtsummit-1.37,1,0.850667,"Missing"
1999.mtsummit-1.92,P98-2139,0,0.0287997,"Nübel and SeewaldHeeg, 1998)). In a fully automatic evaluation scenario, translation quality criteria are fully formalized such that a computer program can check the translation result without the need for a human supervisor. Such method usually makes use of a test corpus to check the generated translations against an “ideal” translation contained in the test corpus. Again, several measures have been proposed to grade the translation quality automatically. These measures compare the generated translation string with the ideal translation string and quantify the difference between the two. In (Meyers et al., 1998) it is claimed that fully automatic evaluation methods can be used to validate enhancement efforts in MT systems, and it reensure that incremental changes of a system are for the better rather than for the worse. Meyers et al. (1998) proposes an evaluation procedure which computes the ratio between the complement of the intersection set of the generated translation T and the ideal translation and the combined length of these two sentences (|I + T|) as shown in equation 1. - 618- The expression denotes the size of the intersection of the generated translation T and the ideal translation I. |T |"
1999.mtsummit-1.92,1998.tc-1.2,0,0.0345523,"y of methods have been proposed in the literature to quantify the quality of MT systems but yet there is no general agreement on MT evaluation methodology. This is partly due to the problem of the “ideal” translation (i.e. to decide which of a number of possible translations is the “best” one) and partly due to the state-of-the-art in MT (i.e. one cannot expect a high quality all purpose MT system). Evaluation methods in the last few years examined the structure and complexity of the input and generated output text, recent research in MT evaluation has shifted to a “task-diagnostic approach” (Vanni, 1998) which focuses on the applicability of the generated translation text. Roughly, one can distinguish between manual evaluation methods and (fully) automatic evaluation methods. In the former case a bilingually skilled person checks the output of the translation system and validates the translation outcome according to pre-defined set of quality criteria (cf. e.g. (Nübel and SeewaldHeeg, 1998)). In a fully automatic evaluation scenario, translation quality criteria are fully formalized such that a computer program can check the translation result without the need for a human supervisor. Such met"
2001.mtsummit-ebmt.2,2001.mtsummit-ebmt.1,0,0.13325,"can be checked and handled more easily. According to (Somers, 1999), EBMT systems di er in the number and the quality of resources used and in the way this knowledge is represented, stored and used for translation. How1 These expressions are typically sentences but can be single words, clauses or paragraphs. ever, EBMT systems di er also in the way generalizations are computed. In the framework of EBMT, a number of methods have been proposed for inducing translation grammars. In so-called pure"" EBMT systems, the only available knowledge resource is the aligned text itself (cf. (Block, 2000; Brown, 2001)), while in richer systems linguistic knowledge resources are used to a varying degree (cf. (Guvenir and Cicekli, 1998) and this present approach). In almost all cases where generalizations are induced from aligned texts, a set of two or more alignments are compared and suitable sub-sequences are replaced by variables. Grammar induction from sets of monolingual examples have been studied since the 1960s. As early as 1967, Gold showed that even regular grammars cannot be exactly identi ed from positive examples alone. This insight is based on the fact that there will always be at least two pos"
2001.mtsummit-ebmt.2,W01-0718,1,0.648243,"y, each generalization gk is associated with a set of lexical transfer rules Cgk which have been replaced in the generalization (i.e. the daughters of the generalization gk ) and a set of references Rgk . Since generalizations are generated from alignments and from the extracted lexical transfer rules, the set of references Rgk may consist of alignments ai and/or transfer rules cj . The probability of an alignment ai is its frequency in the aligned text P divided by the number n of alignments in P . ) f g ) f g ) f g The notation used here is slightly di erent from a previous presentation in (Carl, 2001). 3 p(ai) = f(an i ) (1) The probability of a lexical transfer rule cj is a function of the number of times cj has been extracted from alignments ai; i = 1 : : :n, the cardinality #Cai of the set Cai and the size of P: p(cj ) = 1 #Cai + n X (2) p ai 2Acj The probability of a generalization gk equals the maximum probability of the reference r Rgk from which gk has been generated. 2 p(gk ) = max p(r Rgk ) (3) Based on these probabilities, a weight is computed for each ai , cj , gk . The weight w(rj ) of a lexical transfer rule or an alignment equals the maximumweight of the generalization that h"
2001.mtsummit-ebmt.2,2001.mtsummit-ebmt.3,0,0.108604,"attractive and so it seems desirable to nd a compromise between the size of the hypothesis description and their generality. The compromise for the induction of translation grammars has been to look for collocations in the left-hand side (LHS) and Generalization of Di erences in Alignments (Guvenir and Cicekli, 1998) Alignments: ticket from Mary Mary'den bir bilet aldim 1. I took a 2. I took a pen from Mary Mary'den bir kalem aldim $ $ Generalization of Di erences: from Mary 3. I took a 1 X $ Mary'den bir aldim Y1 Generalization of Di erences and Generalization of Similarities in Alignments (McTait, 2001) Alignments: 4. The commission 5. Our government gave gave Generalization of Di erences: 6. (...) gave the plan all laws up up (...) up Generalization of Similarities: 7. The commission (...) the plan (...) 8. Our government (...) all laws (...) $ $ La commission abandonna le plan Notre gouvernement abandonna toutes les lois (...) abandonna (...) La commission Notre gouvernement (...) (...) le plan toutes les lois $ $ $ Generalization of Chunk Pairs in Alignments (Block, 2000): Alignment: 9. das ist was Sie l l l which l is wollen am Mittwoch morgen l l zuruckzukommen what you were wanting to"
2001.mtsummit-ebmt.2,C00-2139,0,0.0603203,"Missing"
2003.jeptalnrecital-tutoriel.1,1999.mtsummit-1.36,0,0.232418,"Missing"
2003.jeptalnrecital-tutoriel.1,1999.mtsummit-1.75,0,0.15583,"r et adapter les s´equences de mots qui diff`erent dans les exemples de la base et les nouvelles phrases a` traduire. Un excellent survol de ces techniques et de leur enjeu se trouve dans (Somers, 1999; Somers, 2003). Dans mon article je pr´esente plus en detail :   Approches en termes de temps d’ex´ecution Approches en termes de compilation — Repr´esentations en sch´emas — Repr´esentations en arbres syntaxiques 3 La traduction guid´ee par l’exemple (EBMT) 3.1 Approches en termes de temps d’ex´ecution 3.1.1 Segmentation dynamique Dans l’approche propos´e par (Andriamanankasina et al., 2003; Andriamanankasina et al., 1999) les exemples sont balis´es et les correspondances entre les mots des deux phrases sont marqu´es. L’exemple le plus proche a` la phrase nouvelle a` traduire est rech´erch´e et des s´equences e´ gaux sont traduites en langue cible. Ce processus est iter´e jusqu’`a ce que la phrase est enti`eremente traduite o`u il n’y as plus d’exemple proche disponible dans la base. La traduction peut eˆ tre corrig´ee manuellement et inser´ee dans la base de mani`ere dynamique. Andriamanankasina et al. montrent que ce cycle d’apprentissage ameliore les r´esultats de traduction obtenu. La traduction guid´ee par"
2003.jeptalnrecital-tutoriel.1,J90-2002,0,0.657705,"Missing"
2003.jeptalnrecital-tutoriel.1,C96-1030,0,0.340257,"Missing"
2003.jeptalnrecital-tutoriel.1,1997.tmi-1.13,0,0.799772,"Missing"
2003.jeptalnrecital-tutoriel.1,1999.tmi-1.3,0,0.757028,"Missing"
2003.jeptalnrecital-tutoriel.1,2003.eamt-1.4,1,0.309517,"rien, et  est   . de son instruction de tireur d’´elite other sniper training +  + reste  other   reste de son  de  training + instruction sniper + tireur d’´elite his target + sa cible + sa  his  the mission + - + lala mission  the  mission + mission a failure + un e´ chec + un  a  6 Exp´eriences en traduction guid´ee par l’exemple Dans cette section nous g´en´erons des grammaires avec l’approche present´e en section 5. Un texte test est traduit avec EDGAR pr´esent´e en section 4. Une description plus e´ tendue des exp´eriences peut eˆ tre trouv´e dans (Carl & Langlais, 2003). Les exp´eriences se basent sur le Canadian Hansards, texte bilingue Anglais + Franc¸ais. Nous pr´esentons des exp´eriences diff´erentes d’extraction de grammaire aussi bien en ce qui concerne le nombre d’exemples que le degr´e d’ambigu¨ıt´e de la grammaire g´en´er´ee. 6.1 Extraction d’une grammaire de traduction Les ressources utilis´ees pour extraire une grammaire de traduction (GT - ) Anglais + Franc¸ais incluent un dictionnaire bilingue de 77.016 entr´ees, un programme de segmentation en segments et un ensemble de 50.000 exemples de traduction align´es du Canadian Hansard. Le dictionnaire"
2003.jeptalnrecital-tutoriel.1,1999.mtsummit-1.37,1,0.851967,"Missing"
2003.jeptalnrecital-tutoriel.1,1997.tmi-1.14,0,0.365714,"ont marqu´es. L’exemple le plus proche a` la phrase nouvelle a` traduire est rech´erch´e et des s´equences e´ gaux sont traduites en langue cible. Ce processus est iter´e jusqu’`a ce que la phrase est enti`eremente traduite o`u il n’y as plus d’exemple proche disponible dans la base. La traduction peut eˆ tre corrig´ee manuellement et inser´ee dans la base de mani`ere dynamique. Andriamanankasina et al. montrent que ce cycle d’apprentissage ameliore les r´esultats de traduction obtenu. La traduction guid´ee par l’exemple 3.1.2 Adaptabilit´e versus similarit´e en recherche Dans le syst`eme de (Collins & Cunningham, 1997; Collins, 1998), voir aussi : (Collins & Somers, 2003), les exemples sont balis´es et segment´es et portent l’information du rˆole syntaxique. Les segments correspondants sont connect´es d’une langue a` l’autre. Le processus de recherche inclut une mesure d’adaptabilit´e qui indique la similarit´e de l’exemple par rapport a` son contexte externe. La notion adaptation-guided retrieval (recherche guid´ee par l’adaptabilit´e) indique le degr´e auquel les exemples retrouv´es sont un bon mod`ele pour la traduction desir´e : alors que le “CASE A” est plus similaire du “INPUT”, “CASE B” est le meill"
2003.jeptalnrecital-tutoriel.1,C94-1014,0,0.666725,"Missing"
2003.jeptalnrecital-tutoriel.1,1992.tmi-1.12,0,0.954385,"Missing"
2003.jeptalnrecital-tutoriel.1,C94-1015,0,0.357654,"Missing"
2003.jeptalnrecital-tutoriel.1,C92-2101,0,0.473039,"Missing"
2003.jeptalnrecital-tutoriel.1,2002.jeptalnrecital-long.2,0,0.126719,"Missing"
2003.jeptalnrecital-tutoriel.1,1999.tmi-1.10,0,0.321006,"Missing"
2003.jeptalnrecital-tutoriel.1,2003.jeptalnrecital-tutoriel.1,1,0.0529494,"apprises en forme de sch´emas de traduction (translation template). Un sch´ema de traduction est un exemple de traduction g´eneralis´e dont certaines parties ont e´ t´e remplac´ees par des variables li´ees. Deux exemples de traduction : I took a ticket from Mary I took a pen from Mary + + Mary’den bir Mary’den bir bilet kalem aldim aldim G´en´eralisation de diff´erences et extraction de correspondances lexicales : I took a aldim ,.- from Mary + Mary’den bir /0ticket pen + + bilet kalem Michael Carl 3.2.2 Extraction “linguistic-heavy” : Microsoft Research MT (MSR-MT) (Richardson et al., 2001; Menezes & Richardson, 2003) utilisent des r`egles pour obtenir les formes logiques des exemples. Ces repr´esentations sont connect´ees grˆace a` un lexique bilingue. Ensuite des connections ambigu¨es sont nettoy´ees avec des r`egles de pr´ef´erence. Finalement des structures de transfert de haute qualit´e (ce qu’ils apellent des transfer mappings) sont extraites. Pour chaque structure de transfert la fr´equence est calcul´ees et un contexte suffisant est gard´e pour distinguer les “mappings” ambigu¨es pendant la traduction. 12 En Informaci´on del hiperv´ınculo, haga clic en la direcci´on del hiperv´ınculo. Exemple de tr"
2003.jeptalnrecital-tutoriel.1,P98-2139,0,0.567596,"Missing"
2003.jeptalnrecital-tutoriel.1,P02-1040,0,0.0736869,"Missing"
2003.jeptalnrecital-tutoriel.1,2001.mtsummit-papers.53,0,0.157824,"Ces correspondances sont apprises en forme de sch´emas de traduction (translation template). Un sch´ema de traduction est un exemple de traduction g´eneralis´e dont certaines parties ont e´ t´e remplac´ees par des variables li´ees. Deux exemples de traduction : I took a ticket from Mary I took a pen from Mary + + Mary’den bir Mary’den bir bilet kalem aldim aldim G´en´eralisation de diff´erences et extraction de correspondances lexicales : I took a aldim ,.- from Mary + Mary’den bir /0ticket pen + + bilet kalem Michael Carl 3.2.2 Extraction “linguistic-heavy” : Microsoft Research MT (MSR-MT) (Richardson et al., 2001; Menezes & Richardson, 2003) utilisent des r`egles pour obtenir les formes logiques des exemples. Ces repr´esentations sont connect´ees grˆace a` un lexique bilingue. Ensuite des connections ambigu¨es sont nettoy´ees avec des r`egles de pr´ef´erence. Finalement des structures de transfert de haute qualit´e (ce qu’ils apellent des transfer mappings) sont extraites. Pour chaque structure de transfert la fr´equence est calcul´ees et un contexte suffisant est gard´e pour distinguer les “mappings” ambigu¨es pendant la traduction. 12 En Informaci´on del hiperv´ınculo, haga clic en la direcci´on del"
2003.jeptalnrecital-tutoriel.1,C90-3044,0,0.413847,"Missing"
2003.jeptalnrecital-tutoriel.1,C92-2115,0,0.236971,"Missing"
2003.jeptalnrecital-tutoriel.1,1993.tmi-1.25,0,0.912643,"Missing"
2003.jeptalnrecital-tutoriel.1,P98-2223,0,0.492396,"Missing"
2003.jeptalnrecital-tutoriel.1,W01-1406,0,\N,Missing
2003.jeptalnrecital-tutoriel.1,2001.mtsummit-ebmt.4,0,\N,Missing
2003.jeptalnrecital-tutoriel.1,P91-1024,0,\N,Missing
2003.jeptalnrecital-tutoriel.1,W98-1231,1,\N,Missing
2003.jeptalnrecital-tutoriel.1,C98-2134,0,\N,Missing
2003.jeptalnrecital-tutoriel.1,C98-2218,0,\N,Missing
2004.iwslt-evaluation.5,P00-1056,0,0.0649659,"Missing"
2004.iwslt-evaluation.5,J93-2003,0,0.00553426,"Missing"
2004.iwslt-evaluation.5,W04-3227,0,\N,Missing
2004.iwslt-evaluation.5,2003.mtsummit-papers.53,0,\N,Missing
2004.iwslt-evaluation.5,koen-2004-pharaoh,0,\N,Missing
2004.iwslt-evaluation.5,W99-0604,0,\N,Missing
2004.iwslt-evaluation.5,W03-1001,0,\N,Missing
2004.iwslt-evaluation.5,P98-2158,0,\N,Missing
2004.iwslt-evaluation.5,C98-2153,0,\N,Missing
2004.iwslt-evaluation.5,A00-1019,1,\N,Missing
2004.iwslt-evaluation.5,N03-1017,0,\N,Missing
2004.iwslt-evaluation.5,W03-0303,0,\N,Missing
2004.iwslt-evaluation.5,N04-1033,0,\N,Missing
2005.eamt-1.10,P99-1071,0,0.0280613,"of the template grammar is enriched with further lexical and grammatical variation patterns. We show how we induce a template grammar and how it is enriched with additional paraphrasing knowledge. We suggest a framework for weighing and training the template grammars and show that the enriched template grammars produce better paraphrases. 1. Introduction Paraphrasing is frequently used as an instrument to improve the output of various NLP applications. On the one hand, it is used to cope with the highly variable character of natural language in applications like multi-document summarisation (Barzilay et al., 1999) where phrases reporting on the same fact have to be found in input documents. Moreover, in controlled language machine translation (Mitamura and Nyberg, 2001) replacing a source language (SL) item with a paraphrase that is better suited to the requirements of the MT engine boosts the performance of the system, whereas in information retrieval or question answering (Jacquemin et al., 1997; Rinaldi et al., 2003) query expansion by means of paraphrases leads to increased retrieval efficiency. On the other hand, paraphrasing is used to control the generation process within NLP applications. It ma"
2005.eamt-1.10,2003.eamt-1.7,0,0.149006,"means of paraphrases leads to increased retrieval efficiency. On the other hand, paraphrasing is used to control the generation process within NLP applications. It may help produce the best-suited utterance in a given situation (Iordanskaja et al., 1991; Robin, 1994; Dras, 1999). In this paper we describe an approach to corpusbased generation within an MT framework in which paraphrasing is used as a verifying instrument and a means to improve the performance of the system. The approach developed in this paper is a contribution to METIS-II. In the EU-project METIS-II, a follow-up to METIS-I 1 (Dologlou et al., 2003), the aim is to investigate the possibilities to develop a data-driven MT system using a huge monolingual target language (TL) corpus and a bilingual dictionary. While the dictionary is used to map SL items onto the TL, the corpus serves as a model to generate the TL sentences. This parallels with shake & bake (S&B) (Whitelock, 1992). In S&B the bilin1 66 http://www.ilsp.gr/metis2/ gual knowledge is exhausted by the equivalence of basic expressions and TL generation is under direct control of the TL grammar. This makes large scale structural reorganisation of the TL possible and overcomes the"
2005.eamt-1.10,P97-1004,0,0.0264293,"s an instrument to improve the output of various NLP applications. On the one hand, it is used to cope with the highly variable character of natural language in applications like multi-document summarisation (Barzilay et al., 1999) where phrases reporting on the same fact have to be found in input documents. Moreover, in controlled language machine translation (Mitamura and Nyberg, 2001) replacing a source language (SL) item with a paraphrase that is better suited to the requirements of the MT engine boosts the performance of the system, whereas in information retrieval or question answering (Jacquemin et al., 1997; Rinaldi et al., 2003) query expansion by means of paraphrases leads to increased retrieval efficiency. On the other hand, paraphrasing is used to control the generation process within NLP applications. It may help produce the best-suited utterance in a given situation (Iordanskaja et al., 1991; Robin, 1994; Dras, 1999). In this paper we describe an approach to corpusbased generation within an MT framework in which paraphrasing is used as a verifying instrument and a means to improve the performance of the system. The approach developed in this paper is a contribution to METIS-II. In the EU-p"
2005.eamt-1.10,W03-1604,0,0.178084,"ve the output of various NLP applications. On the one hand, it is used to cope with the highly variable character of natural language in applications like multi-document summarisation (Barzilay et al., 1999) where phrases reporting on the same fact have to be found in input documents. Moreover, in controlled language machine translation (Mitamura and Nyberg, 2001) replacing a source language (SL) item with a paraphrase that is better suited to the requirements of the MT engine boosts the performance of the system, whereas in information retrieval or question answering (Jacquemin et al., 1997; Rinaldi et al., 2003) query expansion by means of paraphrases leads to increased retrieval efficiency. On the other hand, paraphrasing is used to control the generation process within NLP applications. It may help produce the best-suited utterance in a given situation (Iordanskaja et al., 1991; Robin, 1994; Dras, 1999). In this paper we describe an approach to corpusbased generation within an MT framework in which paraphrasing is used as a verifying instrument and a means to improve the performance of the system. The approach developed in this paper is a contribution to METIS-II. In the EU-project METIS-II, a foll"
2005.eamt-1.10,C90-3048,0,0.114635,"Missing"
2005.eamt-1.10,C92-2117,0,0.287759,"ion within an MT framework in which paraphrasing is used as a verifying instrument and a means to improve the performance of the system. The approach developed in this paper is a contribution to METIS-II. In the EU-project METIS-II, a follow-up to METIS-I 1 (Dologlou et al., 2003), the aim is to investigate the possibilities to develop a data-driven MT system using a huge monolingual target language (TL) corpus and a bilingual dictionary. While the dictionary is used to map SL items onto the TL, the corpus serves as a model to generate the TL sentences. This parallels with shake & bake (S&B) (Whitelock, 1992). In S&B the bilin1 66 http://www.ilsp.gr/metis2/ gual knowledge is exhausted by the equivalence of basic expressions and TL generation is under direct control of the TL grammar. This makes large scale structural reorganisation of the TL possible and overcomes the inherent problems in conventional thirdgeneration transfer-based MT. In these latter systems, TL generation is merely a matter of traversing and printing out intermediate representations which are defined by the structure of the SL text (Whitelock, 1991). The S&B approach also entails that the transfer component and the generation co"
2005.eamt-1.10,C92-2092,0,\N,Missing
2005.eamt-1.10,W98-1231,1,\N,Missing
2006.eamt-1.7,2005.mtsummit-ebmt.1,0,0.270238,"METIS-II MT system. METISII1 (Dologlou et al., 2003) is a research prototype of a hybrid statistical machine translation system, financed under the EU STREP programme. Hand-crafted bilingual dictionaries are used to transfer lexical tokens (words, multi-word units and phrases) into the target language. A large target language corpus is consulted to adjust the transferred token according to the target language syntax and/or to rank the generated translation candidates. Within METIS-II, a number of modules have been proposed and developed for re-ordering and ranking the translation candidates (Badia, Boleda, Melero, & Oliver, 2005; Carl, Rascu, & Schmidt, 2005; Dirix, Schuurman, & Vandeghinste, 2005; Markantonatou, Sofianopoulos, Spilioti, & Tambouratzis, 2005). The general layout of the architecture is shown in figure 1. Translation of discontinuous phrases is a major challenge when translating from German into another language. In German 1 http://www.ilsp.gr/metis2/ there are not only detachable (verbal) prefixes that produce ‘non-monotonic’ translations (Turcato & Popowich, 2003) but also a large number of light and semantically weak verbs that participate in support verb constructions (SVCs). In such constructions,"
2006.eamt-1.7,2005.eamt-1.10,1,0.887977,"Missing"
2006.eamt-1.7,2005.mtsummit-ebmt.3,0,0.375632,"Missing"
2006.eamt-1.7,2005.mtsummit-ebmt.6,0,0.32918,"rototype of a hybrid statistical machine translation system, financed under the EU STREP programme. Hand-crafted bilingual dictionaries are used to transfer lexical tokens (words, multi-word units and phrases) into the target language. A large target language corpus is consulted to adjust the transferred token according to the target language syntax and/or to rank the generated translation candidates. Within METIS-II, a number of modules have been proposed and developed for re-ordering and ranking the translation candidates (Badia, Boleda, Melero, & Oliver, 2005; Carl, Rascu, & Schmidt, 2005; Dirix, Schuurman, & Vandeghinste, 2005; Markantonatou, Sofianopoulos, Spilioti, & Tambouratzis, 2005). The general layout of the architecture is shown in figure 1. Translation of discontinuous phrases is a major challenge when translating from German into another language. In German 1 http://www.ilsp.gr/metis2/ there are not only detachable (verbal) prefixes that produce ‘non-monotonic’ translations (Turcato & Popowich, 2003) but also a large number of light and semantically weak verbs that participate in support verb constructions (SVCs). In such constructions, (e.g. in Gefahr bringen = in danger bring = endanger) the verb is sem"
2006.eamt-1.7,2003.eamt-1.7,0,0.0261542,"ext. Mapping is controlled through so-called contextual rejection, i.e. inappropriate mappings are discarded if they fail to satisfy a predefined set of constraints. We present various dictionary preprocessing steps to transform the entries into a suitable and more effective format for lookup. Then we describe the dictionary matching of discontinuous phrases. We illustrate this process on German verbs with detachable prefixes and support verb constructions. 1 Introduction This paper describes a dictionary lookup strategy for the German to English component of the METIS-II MT system. METISII1 (Dologlou et al., 2003) is a research prototype of a hybrid statistical machine translation system, financed under the EU STREP programme. Hand-crafted bilingual dictionaries are used to transfer lexical tokens (words, multi-word units and phrases) into the target language. A large target language corpus is consulted to adjust the transferred token according to the target language syntax and/or to rank the generated translation candidates. Within METIS-II, a number of modules have been proposed and developed for re-ordering and ranking the translation candidates (Badia, Boleda, Melero, & Oliver, 2005; Carl, Rascu, &"
2006.eamt-1.7,2005.mtsummit-ebmt.12,0,0.0132878,"translation system, financed under the EU STREP programme. Hand-crafted bilingual dictionaries are used to transfer lexical tokens (words, multi-word units and phrases) into the target language. A large target language corpus is consulted to adjust the transferred token according to the target language syntax and/or to rank the generated translation candidates. Within METIS-II, a number of modules have been proposed and developed for re-ordering and ranking the translation candidates (Badia, Boleda, Melero, & Oliver, 2005; Carl, Rascu, & Schmidt, 2005; Dirix, Schuurman, & Vandeghinste, 2005; Markantonatou, Sofianopoulos, Spilioti, & Tambouratzis, 2005). The general layout of the architecture is shown in figure 1. Translation of discontinuous phrases is a major challenge when translating from German into another language. In German 1 http://www.ilsp.gr/metis2/ there are not only detachable (verbal) prefixes that produce ‘non-monotonic’ translations (Turcato & Popowich, 2003) but also a large number of light and semantically weak verbs that participate in support verb constructions (SVCs). In such constructions, (e.g. in Gefahr bringen = in danger bring = endanger) the verb is semantically empty while the noun carries the information. Homony"
2007.mtsummit-papers.10,2005.mtsummit-ebmt.1,0,0.0293564,"e seen in the table (19), NIST values decreased slightly. The public version of Systran (Babelfish), however, largely outperforms our efforts. Their results on the same test set can be seen in the last line in table (19). 7 Related work and outlook We have described a machine translation system within the METIS-II project which joins a transfer dictionary with simple reordering rules and a statistical ranker. A general overview of the METIS-II project is given in (Dirix et al., 2005) and in (Vandeghinste et al., 2006). More detailed descriptions of the various realisations of METIS-II are in (Badia et al., 2005; Markantonatou et al., 2006; Vandeghinste et al., 2007). An approach related to METIS-II has been suggested by (Carbonell et al., 2006). Like METIS-II their so-called “Context-based machine translation” also makes use of a transfer dictionary and a target language corpus. The dictionary provides basic word (and phrase) translations which are used to retrieve chunks from the target language corpus. From the best sequence of overlapping chunks the translation is generated. As in so-called “generation-heavy” translation (Habash, 2004), our expander rules tackle some of 6 On a 1GB/2.8GHz, single"
2007.mtsummit-papers.10,1995.tmi-1.17,0,0.0929239,"s “symbolic overgeneration” is then constrained by a statistical ranker making use of several statistical feature functions. A similar idea for generation was suggested by (Langkilde and Knight, 1998) who use 2-gram language models to find the best path in a word lattice. Recently, the LOGON-project (Oepen et al., 2007) use statistical feature functions to select best rule-induced structures at various stages during processing. Basically, the common idea of these approaches would be to use statistics for closing “knowledge gaps” during processing. The core idea of our work is also similar to (Brown and Frederking, 1995) who use a statistical English Language Model (ELM) to select between alternate partial translations produced by three symbolic MT system from the PANGLOSS Mark III system. In contrast to their approach we build a search graph with flat reordering rules. In the future we plan to further enhance the various modules of our METIS implementation. In particular revise and add more Expander rules so as to caputre as yet unprocessed translation divergences. We also plan to add further feature functions, to take into account lexical weights (which may be trained on parallel texts). We also plan to eva"
2007.mtsummit-papers.10,2006.amta-papers.3,0,0.0572341,"ur efforts. Their results on the same test set can be seen in the last line in table (19). 7 Related work and outlook We have described a machine translation system within the METIS-II project which joins a transfer dictionary with simple reordering rules and a statistical ranker. A general overview of the METIS-II project is given in (Dirix et al., 2005) and in (Vandeghinste et al., 2006). More detailed descriptions of the various realisations of METIS-II are in (Badia et al., 2005; Markantonatou et al., 2006; Vandeghinste et al., 2007). An approach related to METIS-II has been suggested by (Carbonell et al., 2006). Like METIS-II their so-called “Context-based machine translation” also makes use of a transfer dictionary and a target language corpus. The dictionary provides basic word (and phrase) translations which are used to retrieve chunks from the target language corpus. From the best sequence of overlapping chunks the translation is generated. As in so-called “generation-heavy” translation (Habash, 2004), our expander rules tackle some of 6 On a 1GB/2.8GHz, single core Linux machine it takes less than 4 minutes to translate the 200 sentences. Most of the time is spent for SL Analyser and loading LM"
2007.mtsummit-papers.10,2006.eamt-1.7,1,0.797583,"f length m on a sentence of length n may lead to a huge  num n ber of retrieved entries in the order of O , m while for continuous phrases there is a maximum of (n − m + 1) matches. Thus, there are more than 3000 possible ways to match a discontinuous phrase of 5 words on a 15-word sentence while a continuous phrase may lead to only 11 possible matches. In our current implementation, we only allow discontinuous matches for verbal and nominal entries. All other types of dictionary entries, such as adjectives, adverbs, prepositions, idioms etc. are not eligible for discontinuous matching. In (Carl and Rascu, 2006) we have described various strategies to reject matched entries if they don’t obey a predefined set of criteria. For nominal entries, the head of the term e.g. Ozonschicht in (3) can be modified in the matched sentence, for instance by adjectives as in example (4). While we would like to validate the entry despite the intervening adjective arktischen, we want to reject the entry if the words co-occur ‘by accident’ in the same sentence and are actually unrelated. This would be the case if the words occurred in different noun phrases. (3) (4) Abbau der Ozonschicht ↔ ozone depletion Abbau der ark"
2007.mtsummit-papers.10,2005.mtsummit-ebmt.3,0,0.36317,", moves and permutes items or chunks according to TL syntax. It is called Expander because it expands the search space through the word- and phrase translations retrieved from the lexicon. The Expander relies on a rule-based device. We give some examples in section 4 4. The Ranker relies on a beam search algorithm that iteratively traverses the graph and computes the most likely translations in a log-linear fashion (Och and Ney, 2002). The Ranker is explained in section 5. 5. A Token Generator generates surface wordforms from the lemmas and PoS tags. The Token Generator has been described in (Carl et al., 2005) and will be omitted here. 2 The Analyser The Analyser reads the SL sentence and produces a flat sequence of feature bundles which contain chunking and topological information of the sentence (M¨ uller, 2004). For instance, from the German SL sentence (1a) the representation (1b) would be generated. Among other things, the analysis in (1b) comprises of a unique word number wnrr, the lemma lu and part-of-speech c, sc of the word, as well as morphological and syntactic information. It also contain chunking and topological information. 1a Das Haus wurde von Hans gekauft (The house was purchased b"
2007.mtsummit-papers.10,P02-1004,0,0.0236329,"everal languages. 1 Finally word tokens are generated for the n-best translations. This paper gives an overview on the steps 1 to 4. 1. The Analyser lemmatises and morphologically analyses the SL sentence. It produces a (flat) grammatical analysis of the sentence, detecting phrases and clauses and potential subject candidates. An outline of the Analyser is given in section 2. Introduction Recent machine translation techniques integrate rule-based knowledge and statistics: (Groves and Way, 2006) integrate rule-induced chunk translations with a statistical decoder; for (Richardson et al., 2001; Gamon et al., 2002), or (Ringger et al., 2004), linguistic rules describe what possible transformations a parse tree can undergo, but statistics decides under which conditions a particular rule is applied and (Quirk and Menezes, 2006) decide the combination of derivation trees by statistical means. This paper outlines an MT architecture which uses rule-based devices to generate sets of partial translation hypotheses and a statistical Ranker to evaluate and retrieve the best hypotheses in their context. The rule-based device generates an acyclic AND/OR graph which allows for compact representation of many differe"
2007.mtsummit-papers.10,P01-1030,0,0.0791133,"s a particular rule is applied and (Quirk and Menezes, 2006) decide the combination of derivation trees by statistical means. This paper outlines an MT architecture which uses rule-based devices to generate sets of partial translation hypotheses and a statistical Ranker to evaluate and retrieve the best hypotheses in their context. The rule-based device generates an acyclic AND/OR graph which allows for compact representation of many different translations while the Ranker is a beam search algorithm which tries to find most likely paths in the AND/OR graph. Unlike a usual statistical decoder (Germann et al., 2001; Koehn, 2004), our Ranker traverses the search graph to grade alternative paths and outputs a list of the n-best translations. The Ranker itself does not modify the graph. It does not permute chunks or items and it does not generate additional paths which are not already contained in the graph. The construction of the search graph and its evaluation are thus separated as two distinct tasks. Starting from a SL sentence, the graph is incrementally constructed in three rule-based steps. The graph is then traversed and translations are ranked. 1 http://www.ilsp.gr/metis2/ 2. During Dictionary Loo"
2007.mtsummit-papers.10,koen-2004-pharaoh,0,0.063238,"applied and (Quirk and Menezes, 2006) decide the combination of derivation trees by statistical means. This paper outlines an MT architecture which uses rule-based devices to generate sets of partial translation hypotheses and a statistical Ranker to evaluate and retrieve the best hypotheses in their context. The rule-based device generates an acyclic AND/OR graph which allows for compact representation of many different translations while the Ranker is a beam search algorithm which tries to find most likely paths in the AND/OR graph. Unlike a usual statistical decoder (Germann et al., 2001; Koehn, 2004), our Ranker traverses the search graph to grade alternative paths and outputs a list of the n-best translations. The Ranker itself does not modify the graph. It does not permute chunks or items and it does not generate additional paths which are not already contained in the graph. The construction of the search graph and its evaluation are thus separated as two distinct tasks. Starting from a SL sentence, the graph is incrementally constructed in three rule-based steps. The graph is then traversed and translations are ranked. 1 http://www.ilsp.gr/metis2/ 2. During Dictionary Lookup analyzed S"
2007.mtsummit-papers.10,W98-1426,0,0.115909,"anslation (Habash, 2004), our expander rules tackle some of 6 On a 1GB/2.8GHz, single core Linux machine it takes less than 4 minutes to translate the 200 sentences. Most of the time is spent for SL Analyser and loading LMs into the Ranker. Expander, Dictionary Lookup and Token Generation only needs a small fraction of the total time. the translation divergences thereby producing numerous partial translation hypotheses. This “symbolic overgeneration” is then constrained by a statistical ranker making use of several statistical feature functions. A similar idea for generation was suggested by (Langkilde and Knight, 1998) who use 2-gram language models to find the best path in a word lattice. Recently, the LOGON-project (Oepen et al., 2007) use statistical feature functions to select best rule-induced structures at various stages during processing. Basically, the common idea of these approaches would be to use statistics for closing “knowledge gaps” during processing. The core idea of our work is also similar to (Brown and Frederking, 1995) who use a statistical English Language Model (ELM) to select between alternate partial translations produced by three symbolic MT system from the PANGLOSS Mark III system."
2007.mtsummit-papers.10,2006.eamt-1.30,0,0.0656823,"(19), NIST values decreased slightly. The public version of Systran (Babelfish), however, largely outperforms our efforts. Their results on the same test set can be seen in the last line in table (19). 7 Related work and outlook We have described a machine translation system within the METIS-II project which joins a transfer dictionary with simple reordering rules and a statistical ranker. A general overview of the METIS-II project is given in (Dirix et al., 2005) and in (Vandeghinste et al., 2006). More detailed descriptions of the various realisations of METIS-II are in (Badia et al., 2005; Markantonatou et al., 2006; Vandeghinste et al., 2007). An approach related to METIS-II has been suggested by (Carbonell et al., 2006). Like METIS-II their so-called “Context-based machine translation” also makes use of a transfer dictionary and a target language corpus. The dictionary provides basic word (and phrase) translations which are used to retrieve chunks from the target language corpus. From the best sequence of overlapping chunks the translation is generated. As in so-called “generation-heavy” translation (Habash, 2004), our expander rules tackle some of 6 On a 1GB/2.8GHz, single core Linux machine it takes"
2007.mtsummit-papers.10,P02-1038,0,0.590487,"SL sentence are matched on the transfer dictionary and TL equivalences are retrieved. We will give a review of the essential features in section 3. 3. The Expander inserts, deletes, moves and permutes items or chunks according to TL syntax. It is called Expander because it expands the search space through the word- and phrase translations retrieved from the lexicon. The Expander relies on a rule-based device. We give some examples in section 4 4. The Ranker relies on a beam search algorithm that iteratively traverses the graph and computes the most likely translations in a log-linear fashion (Och and Ney, 2002). The Ranker is explained in section 5. 5. A Token Generator generates surface wordforms from the lemmas and PoS tags. The Token Generator has been described in (Carl et al., 2005) and will be omitted here. 2 The Analyser The Analyser reads the SL sentence and produces a flat sequence of feature bundles which contain chunking and topological information of the sentence (M¨ uller, 2004). For instance, from the German SL sentence (1a) the representation (1b) would be generated. Among other things, the analysis in (1b) comprises of a unique word number wnrr, the lemma lu and part-of-speech c, sc"
2007.mtsummit-papers.10,2001.mtsummit-papers.53,0,0.0308906,"ation of the system for several languages. 1 Finally word tokens are generated for the n-best translations. This paper gives an overview on the steps 1 to 4. 1. The Analyser lemmatises and morphologically analyses the SL sentence. It produces a (flat) grammatical analysis of the sentence, detecting phrases and clauses and potential subject candidates. An outline of the Analyser is given in section 2. Introduction Recent machine translation techniques integrate rule-based knowledge and statistics: (Groves and Way, 2006) integrate rule-induced chunk translations with a statistical decoder; for (Richardson et al., 2001; Gamon et al., 2002), or (Ringger et al., 2004), linguistic rules describe what possible transformations a parse tree can undergo, but statistics decides under which conditions a particular rule is applied and (Quirk and Menezes, 2006) decide the combination of derivation trees by statistical means. This paper outlines an MT architecture which uses rule-based devices to generate sets of partial translation hypotheses and a statistical Ranker to evaluate and retrieve the best hypotheses in their context. The rule-based device generates an acyclic AND/OR graph which allows for compact represent"
2007.mtsummit-papers.10,C04-1097,0,0.0618573,"ly word tokens are generated for the n-best translations. This paper gives an overview on the steps 1 to 4. 1. The Analyser lemmatises and morphologically analyses the SL sentence. It produces a (flat) grammatical analysis of the sentence, detecting phrases and clauses and potential subject candidates. An outline of the Analyser is given in section 2. Introduction Recent machine translation techniques integrate rule-based knowledge and statistics: (Groves and Way, 2006) integrate rule-induced chunk translations with a statistical decoder; for (Richardson et al., 2001; Gamon et al., 2002), or (Ringger et al., 2004), linguistic rules describe what possible transformations a parse tree can undergo, but statistics decides under which conditions a particular rule is applied and (Quirk and Menezes, 2006) decide the combination of derivation trees by statistical means. This paper outlines an MT architecture which uses rule-based devices to generate sets of partial translation hypotheses and a statistical Ranker to evaluate and retrieve the best hypotheses in their context. The rule-based device generates an acyclic AND/OR graph which allows for compact representation of many different translations while the R"
2007.mtsummit-papers.10,vandeghinste-etal-2006-metis,1,0.751569,"as a development set and tested on a set of 200 sentences. The BLEU score increased to 0.2231. As can be seen in the table (19), NIST values decreased slightly. The public version of Systran (Babelfish), however, largely outperforms our efforts. Their results on the same test set can be seen in the last line in table (19). 7 Related work and outlook We have described a machine translation system within the METIS-II project which joins a transfer dictionary with simple reordering rules and a statistical ranker. A general overview of the METIS-II project is given in (Dirix et al., 2005) and in (Vandeghinste et al., 2006). More detailed descriptions of the various realisations of METIS-II are in (Badia et al., 2005; Markantonatou et al., 2006; Vandeghinste et al., 2007). An approach related to METIS-II has been suggested by (Carbonell et al., 2006). Like METIS-II their so-called “Context-based machine translation” also makes use of a transfer dictionary and a target language corpus. The dictionary provides basic word (and phrase) translations which are used to retrieve chunks from the target language corpus. From the best sequence of overlapping chunks the translation is generated. As in so-called “generation-"
2007.mtsummit-papers.10,1994.amta-1.18,0,\N,Missing
2007.tmi-papers.5,2005.mtsummit-ebmt.3,1,0.813198,"Missing"
2007.tmi-papers.5,2007.mtsummit-papers.10,1,0.765098,"Missing"
2007.tmi-papers.5,1994.amta-1.18,0,0.239838,"onolingual target language corpus makes METIS-II a datadriven MT system. However, parallel corpora as in SMT/EBMT are not required. For our German-toEnglish METIS-II system we have designed and implemented an architecture which uses rule-based devices to generate sets of partial translation hypotheses and a statistical Ranker to evaluate and retrieve the best hypotheses in their context1 . Similar architectures have already been suggested as EBMT systems (Sato and Nagao, 1990), for instance with their MBT2 system. Methods to integrate knowledge bases and statistics have also been explored in (Knight et al., 1994) and recently in the LOGONproject (Oepen et al., 2007) which uses statistical feature functions to select the best rule-induced structures at various stages during processing. In the German-to-English METIS-II system, rulebased devices generate an acyclic AND/OR graph which allows for compact representation of many different translations while the Ranker is a beam search algorithm which tries to find most likely paths through the AND/OR graph. The architecture consists of the following five steps: 1A 2007). full description of the system is provided in (Carl, 1. The Analyser lemmatises and mor"
2007.tmi-papers.5,koen-2004-pharaoh,0,0.036094,"with further partial translation hypotheses. It is called Expander because it expands the search space with additional paths. The operations of the Expander and its modifications on the graph are such that each path through the graph consumes exactly once the translation(s) of each word of the source language sentence. For our German-toEnglish implementation we have currently ca. 50 rules. 4. The Ranker is a beam search algorithm that iteratively traverses the AND/OR graph and computes the most likely translations in a loglinear fashion (Och and Ney, 2002). Unlike a usual statistical decoder (Koehn, 2004) — but similar to the method suggested by (Knight et al., 1994) — our Ranker traverses the search graph to grade alternative paths and outputs a list of the n-best translations. The Ranker itself does not modify the graph. It does not permute chunks or items and it does not generate additional paths which are not already contained in 41 the graph. 5. A Token Generator generates surface wordforms from the lemmas and PoS tags. The Token Generator has been described in (Carl et al., 2005). The Ranker and the Token Generator are trained on the British National Corpus (BNC2 ). It is a collection of"
2007.tmi-papers.5,P02-1038,0,0.0617274,"der is a rule-based device and extends the AND/OR graph with further partial translation hypotheses. It is called Expander because it expands the search space with additional paths. The operations of the Expander and its modifications on the graph are such that each path through the graph consumes exactly once the translation(s) of each word of the source language sentence. For our German-toEnglish implementation we have currently ca. 50 rules. 4. The Ranker is a beam search algorithm that iteratively traverses the AND/OR graph and computes the most likely translations in a loglinear fashion (Och and Ney, 2002). Unlike a usual statistical decoder (Koehn, 2004) — but similar to the method suggested by (Knight et al., 1994) — our Ranker traverses the search graph to grade alternative paths and outputs a list of the n-best translations. The Ranker itself does not modify the graph. It does not permute chunks or items and it does not generate additional paths which are not already contained in 41 the graph. 5. A Token Generator generates surface wordforms from the lemmas and PoS tags. The Token Generator has been described in (Carl et al., 2005). The Ranker and the Token Generator are trained on the Brit"
2007.tmi-papers.5,2007.tmi-papers.18,0,0.0125111,"driven MT system. However, parallel corpora as in SMT/EBMT are not required. For our German-toEnglish METIS-II system we have designed and implemented an architecture which uses rule-based devices to generate sets of partial translation hypotheses and a statistical Ranker to evaluate and retrieve the best hypotheses in their context1 . Similar architectures have already been suggested as EBMT systems (Sato and Nagao, 1990), for instance with their MBT2 system. Methods to integrate knowledge bases and statistics have also been explored in (Knight et al., 1994) and recently in the LOGONproject (Oepen et al., 2007) which uses statistical feature functions to select the best rule-induced structures at various stages during processing. In the German-to-English METIS-II system, rulebased devices generate an acyclic AND/OR graph which allows for compact representation of many different translations while the Ranker is a beam search algorithm which tries to find most likely paths through the AND/OR graph. The architecture consists of the following five steps: 1A 2007). full description of the system is provided in (Carl, 1. The Analyser lemmatises and morphologically analyses the SL sentence. It produces a ("
2008.eamt-1.5,abekawa-kageura-2008-constructing,0,0.0310634,", and bind together the functional, executional features of an action and the sensory characteristics that are perceived during action execution [11]. BPCs can be regarded as cognitive tools for the execution of actions, such as those observed in highly skilled people and professional activities of experts, but also in everyday actions. BPCs serve the purpose of reducing the degrees of freedom involved in action execution and thereby the cognitive effort necessary for controlling the action. 22 12th EAMT conference, 22-23 September 2008, Hamburg, Germany In a recent study, Takeshi and Kageura [5] seek to elaborate processing concepts for the task of human postediting. In line with Schack [11] they find that the process of human postediting (and translation) consists of mainly unconscious states. However, they are able to elaborate a four-level structured representation of postediting processing concepts: 1. Reasons for draft modification: From a set of 181 reasons, they filter out six basic classes why a draft translation was modified. The draft translation may be: (a) wrong, (b) confusing, (c) original meaning is not clear (d) unnatural or awkward (e) violating style guidelines 2. Ai"
2009.mtsummit-btm.4,2009.mtsummit-posters.5,0,0.0331913,"Missing"
2009.mtsummit-btm.4,2009.mtsummit-papers.8,0,0.0234898,"e is due to unknown terminology (in which case the presentation of a term translation might be an appropriate solution), or for instance, as in figure 4, whether it is due to a more complicated understanding (and translating) problems? Will it also be possible to present appropriate help in the latter case, or would the automated help be distracting? How should this help be presented? Should a translator be provided with translation completion (`a la TransType2) or should he be offered a selection of (phrase) translations which s/he could compose into a translation (e.g. via key shortcuts, as Koehn and Haddow (2009) suggest). How much information should be there, how should the information be structured and how can information overkill be avoided? Instead of (or in addition to) contemplating Figure 5: The figure shows the fixation pattern from the translation progression graph in figure 3 between seconds 120-128. Above: a graphical representation of the fixation pattern together with the sequence of fixated source text. Bold lines represent progressions and light lines regressions. Below: Process data of the same fixation pattern shows time of fixation, average pupil dilation, fixation duration, cursor p"
2010.eamt-1.14,P04-1077,0,0.0248189,"rs, but only half as much time on post-editing. The average translation, skimming and post-editing time is given in Table 1. 3 Correlating Process and Product Data In this section, we measure the quality of the 24 human translations and compare with a machine translation produced by Google Translate. We study the impact of the number of reference translations on the BLEU score and the correlation of BLEU with accuracy, fluency, and translation time. 3.1 BLEU Evaluation The BLEU score is a metric to evaluate machine translation quality, and is widely used to tune the development of MT systems (Lin and Och, 2004). Based on the assumption that a good translation will share more lexical items with a set of (human generated) references than a bad translation, BLEU compares a test translation with a number of reference translations. In order to estimate the impact of the number of the reference translations on the BLEU scores, we translated the A and B texts with Google Translate into Danish and evaluated the translations on 5×24 different subsets of the 24 reference translations. Table 2 shows the results of this experiment where the column #RS indicates the number of used reference translations, the max"
2010.tc-1.10,2010.eamt-1.37,0,0.0232987,"gaze data, discuss possibilities for their classification and visualization and elaborate how a translation model can be grounded and trained in the empirical data. The insights gained from such a computational translation model does not only enlarge our knowledge about human translation processes, but has also the potential to enhance the design of interactive MT systems and help interpret user activity data in human-MT system interaction. 1 Introduction In the past years MT has become widely available, covering many language pairs. 1 Development for new language pairs are increasingly short [1] and the quality of the translation product increases based on the available resources and the similarity of the source and target languages. However, to obtain high quality translations as e.g. for dissemination some kind of human intervention is necessary. In order to ensure the required translations quality and simultaneously increase translation production time, numerous technologies exist or are experimentally implemented that ease human-machine interaction. A Machine Translation (MT) system may either work in a batch process as is the case in MT 1 At the time of writing this paper the go"
2010.tc-1.10,macklovitch-2004-contribution,0,0.0233151,"languages, which amounts to more than 3000 different language pairs. post- or pre-editing (e.g. controlled language translation) or in an interactive modus. In the case of interactive rule-based MT, the user interfaces of some MT systems (e.g. Systran, ProMT) allow the translator to extend or modify the lexical databases of the system at translation time; other systems interactively ask for disambiguation information [2] which may be stored in a ”companion” file for late reuse [3]. Recent implementations of interactive data-driven MT systems experiment with translation completion (TransType2, [4]) and translation options [5]. Whereas interactive rule-based MT systems ask for assistance to disambiguate the source text analyzes by providing linguistic knowledge of the SL, interactive data-driven MT systems ask the translator to provide or to disambiguate the TL, thereby putting the user into the center of the translation process [4]. However, non of the approaches has yet lead to all-satisfying approaches of human computer interaction. In this paper we investigate the human translator who is supposed to work with the machine to produce a translation. Current models of human translation"
2010.tc-1.10,2009.mtsummit-papers.8,0,0.0249232,"ore than 3000 different language pairs. post- or pre-editing (e.g. controlled language translation) or in an interactive modus. In the case of interactive rule-based MT, the user interfaces of some MT systems (e.g. Systran, ProMT) allow the translator to extend or modify the lexical databases of the system at translation time; other systems interactively ask for disambiguation information [2] which may be stored in a ”companion” file for late reuse [3]. Recent implementations of interactive data-driven MT systems experiment with translation completion (TransType2, [4]) and translation options [5]. Whereas interactive rule-based MT systems ask for assistance to disambiguate the source text analyzes by providing linguistic knowledge of the SL, interactive data-driven MT systems ask the translator to provide or to disambiguate the TL, thereby putting the user into the center of the translation process [4]. However, non of the approaches has yet lead to all-satisfying approaches of human computer interaction. In this paper we investigate the human translator who is supposed to work with the machine to produce a translation. Current models of human translation processes describe elements o"
2012.amta-wptp.1,1983.tc-1.13,0,0.63133,"Missing"
2013.mtsummit-user.9,2012.eamt-1.5,1,0.872324,"Missing"
2013.mtsummit-user.9,J09-1002,1,0.930598,"Missing"
2013.mtsummit-user.9,N10-1078,0,0.0353669,"Missing"
2013.mtsummit-user.9,J10-4005,0,0.0567722,"Missing"
2013.mtsummit-user.9,2012.tc-1.7,1,0.791077,"Missing"
2013.mtsummit-user.9,J93-2003,0,0.0199596,"the suggested translation. 3.4 Search and Replace Most of the computer-assisted translation tools provide the user with intelligent search and replace functions for fast text revision. The C AS M AC AT workbench also features a straightforward function to run search and replacement rules on the fly. Whenever a new replacement rule is created, it is automatically populated to the forthcoming predictions made by the system, so that the user only needs to specify them once. 3.5 Word Alignment Information Alignment of source and target information is an important part of the translation process (Brown et al., 1993). In order to display the correspondences between both the source and target words, this feature was implemented in a way that every time the user places the mouse (yellow) or the text cursor (cyan) on a word, the alignments made by the system are highlighted. ............................................. 3.6 Prediction Rejection With the purpose of easing user interaction, our prototype also supports a mouse wheel rejection feature (Sanchis-Trilles et al., 2008). By scrolling Figure 1: Screenshot of our workbench with all its features enabled. the mouse wheel over a word, the system invalidat"
2013.mtsummit-user.9,2010.eamt-1.19,0,0.0609977,"Missing"
2013.mtsummit-user.9,2010.eamt-1.18,1,0.86052,"Missing"
2013.mtsummit-user.9,D08-1051,1,0.805921,"Missing"
2013.mtsummit-user.9,J85-2003,0,0.371196,"Missing"
2013.mtsummit-user.9,W00-0507,0,\N,Missing
2013.mtsummit-wptp.7,2005.mtsummit-papers.19,1,0.838299,"Missing"
2013.mtsummit-wptp.7,2011.eamt-1.2,0,0.108581,"Missing"
2013.mtsummit-wptp.7,D08-1051,1,0.880745,"Missing"
2013.mtsummit-wptp.7,2011.eamt-1.7,0,0.022484,"Missing"
2013.mtsummit-wptp.7,2012.eamt-1.5,1,0.870892,"Missing"
2013.mtsummit-wptp.7,J09-1002,1,0.927174,"Missing"
2013.mtsummit-wptp.7,J93-2003,0,0.0316225,"user with intelligent search and replace functions for fast text revision. Our workbench features a straightforward function to run search and replacement rules on the fly. Whenever a new replacement rule is created, it is automatically populated to the forthcoming predictions made by the system, so that the Javascript ............................................ PHP HTTP GUI web server Figure 5: Visualization of Word Alignment HTTP web socket user only needs to specify them once. Word Alignment Information Alignment of source and target words is an important part of the translation process (Brown et al., 1993). In order to display the correspondences between both the source and target words, this feature was implemented in a way that every time the user places the mouse (yellow) or the text cursor (cyan) on a word, the alignments made by the system are highlighted. See Figure 5 for a screenshot. Prediction Rejection With the purpose of easing user interaction, our workbench also supports a one-click rejection feature (Sanchis-Trilles et al., 2008). This invalidates the current prediction for the sentence that is being translated, and provides the user with an alternate one, in which the first new w"
2013.mtsummit-wptp.7,2012.amta-papers.22,0,0.266531,"Missing"
2013.mtsummit-wptp.7,2010.eamt-1.18,1,0.875303,"Missing"
2013.mtsummit-wptp.7,N10-1078,1,0.886215,"Missing"
2013.mtsummit-wptp.7,P07-2045,1,0.00695691,"swapped out workbench may be use partially, for instance in the following fashion: • As part of a larger localization workflow with existing editing facilities, only the capabilities of the CASMACAT CAT server and CAS MACAT MT server are used. A legacy editing tool is extended to make calls to the CAT server and thus benefit from additional functionality. • If an existing customized MT translation solution is already in place, then the CASMACAT front-end and CAT server can connect to it. Already, the currently implemented CASMACAT workbench supports two different MT server components, Moses (Koehn et al., 2007) and Thot (Ortiz-Mart´ınez et al., 2005). 3.1 CAT Server The CAT server is implemented in Python with the Tornadio library. It uses socket.io to keep a web socket connection with the Javascript GUI. Keep in mind that especially interactive translation prediction requires very quick responses from the server. Establishing an HTTP connection through an Ajax call every time the user presses a key would cause significant overhead. A typical session with interactive translation prediction takes place as follows: • The user moves to a new segment in the GUI. • The GUI sends a startSession request to"
2013.mtsummit-wptp.7,W00-0507,0,0.528068,"Missing"
2014.amta-workshop.1,J09-1002,1,0.892052,"Missing"
2014.amta-workshop.1,2013.mtsummit-papers.5,0,0.0291651,"entence has been correctly translated. The C AS M AC AT workbench further extends the ITP approach by introducing two new features, namely, online and active learning. These two new features are designed to allow the system to take further advantage from user feedback. Specifically, the SMT models are updated in real time from the target translations validated by the user, preventing the system from repeating errors in the translation of similar sentences. Despite the strong potential of these features to improve the user experience (Ortiz-Mart´ınez et al., 2010; Gonz´alez-Rubio et al., 2012; Bertoldi et al., 2013; Denkowski et al., 2014), they are still not widely implemented in CAT systems. To the best of our knowledge, the only exception is (Ortiz-Mart´ınez et al., 2011) where the authors describe the implementation of online learning within an ITP system. The present study reports on the results and user evaluation of the C AS M AC AT workbench under three different conditions: 1) basic ITP, 2) ITP with online learning, and 3) ITP with active learning. The ultimate aim of testing these different configurations was to assess their potential in real world post-editing scenarios and decide which of th"
2014.amta-workshop.1,E14-1042,0,0.0148376,"tly translated. The C AS M AC AT workbench further extends the ITP approach by introducing two new features, namely, online and active learning. These two new features are designed to allow the system to take further advantage from user feedback. Specifically, the SMT models are updated in real time from the target translations validated by the user, preventing the system from repeating errors in the translation of similar sentences. Despite the strong potential of these features to improve the user experience (Ortiz-Mart´ınez et al., 2010; Gonz´alez-Rubio et al., 2012; Bertoldi et al., 2013; Denkowski et al., 2014), they are still not widely implemented in CAT systems. To the best of our knowledge, the only exception is (Ortiz-Mart´ınez et al., 2011) where the authors describe the implementation of online learning within an ITP system. The present study reports on the results and user evaluation of the C AS M AC AT workbench under three different conditions: 1) basic ITP, 2) ITP with online learning, and 3) ITP with active learning. The ultimate aim of testing these different configurations was to assess their potential in real world post-editing scenarios and decide which of them can be successfully in"
2014.amta-workshop.1,E12-1025,1,0.893795,"Missing"
2014.amta-workshop.1,E14-2012,1,0.760176,"Missing"
2014.amta-workshop.1,N10-1079,1,0.890321,"Missing"
2014.amta-workshop.1,P11-4012,1,0.887221,"Missing"
2014.eamt-1.18,P11-2068,0,0.0632133,"Missing"
2014.eamt-1.18,H90-1045,0,0.844434,"e for text production and they seem to be the easiest input method when only minor changes are needed. However, in the context of post-editing, when the text requires major changes (e.g. editing larger segments of text), typing could be optimized using other input modalities. Moreover, if the posteditor is not a touch typist, then she has to switch visual attention back and forth between the screen and the keyboard making the task more complex. A possible solution for this profile of users could be the use of other input methods, such as ASR or hand-writing, in addition to traditional typing (Hauptmann and Rudnicky, 1990). Introduction The comparison between ASR and typing as input methods can be done based on task duration, i.e. measuring the time needed to type against the ASR rate including possible corrections to fix recognition inaccuracies. Studies on input durations have shown that ASR input can be faster (Chen, 2006; Vidal et al., 2006). Human-aided machine translation is gradually becoming a common practice for language service providers (LSPs) as opposed to machine-aided human translation. Depending on the nature of the text, more and more LSPs pre-translate the source text using existing translation"
2014.eamt-1.18,P06-2061,0,0.0118359,"t the translation process, but will also help to improve the output provided by the MT server base in gaze information coming from the user. the ASR server for the recognition of the speech signal uttered by the user. The C AS M AC AT logging functions have been extended with the information coming from ASR in order to be able to check when the ASR input starts and finishes. Figure 5 describes how the SEECAT components interact. 4 Experiments and results This section presents experimental data using the current version of the SEECAT workbench. 4.1 Integration of ASR and MT MT can improve ASR (Khadivi et al., 2006; Lecouteux et al., 2006) in a computer-assisted translation scenario. The same technique used to improve ASR through MT can be used with semantic information (Tammewar et al., 2013). In SEECAT, the hypotheses produced by ASR and MT are converted into lattices and are then composed using Edit Machine with the help of OpenFst toolkit (Allauzen et al., 2007). The synset information from WordNet is used while composing for the semantic matching of words. According to the edit distance scores, ASR hypotheses are rescored. We further extend this approach for the two language pairs Hindi-English and"
2014.eamt-1.18,2012.tc-1.7,1,0.783026,"Missing"
2021.motra-1.8,J10-3002,0,0.0469738,"ther gold standard word alignment, assigning errors when the hypothesis alignment’s links differ from those of the gold standard (Och and Ney, 2003). It is a normalized score with values between 0–1 for entire segments where a score of 0 indicates identical word alignments and a score of 1 indicates completely different sets of alignment links. When reported, AER scores are usually multiplied by 100 Michael Carl CRITT mcarl6@kent.edu for readability. Usually an average AER score over many segments is reported, and automatic alignment systems have ranged between average AER scores of 3.7–50.6 (Liu et al., 2010) and 14.5–33.2 specifically for the English-to-Spanish language pair (Lambert, 2008). We have conducted alignment experiments with six different alignments of the same English-to-Spanish translations (a total of 1045 segments, 25936 tokens, translated by 31 participants), two manual alignments (M1, M2) and four automatic alignments (A1–A4).1 M1 is the original manual alignment (MesaLao, 2014) which was later amended by another group of researchers. M2 is a realignment done by a group of researchers with very specific alignment criteria and, above all, the stipulation that only one aligner woul"
2021.motra-1.8,N13-1073,0,0.0311153,"incomplete’ phrase alignment with missing alignment links. Assume, for instance, the phrase translation {have bread ↔ Tengo pan} (see Figures 1 and 2). This should result in a set of alignment links {(1,0),(1,1),(2,0),(2,1)}. However, without further postprocessing, MOSES’ phrase-based system grow-diag-final(and) may produce ’incomplete’ phrase alignments in which one of the four alignment links may be missing, resulting in five possible alignment configurations for this phrase translation. decrease global averaged AER (GIZA++, Och and Ney (2003); S IM A LIGN, Sabet et al. (2020); FASTA LIGN, Dyer et al. (2013); UALIGN, Hermjakob (2009); etc.), we posit that the agreement— as well as the disagreement—about alignment relations on the level of individual words carries crucial information about translation difficulties. While some words may be ‘easy’ to align—i.e., with little or no discrepancies between different alignment methods—translational equivalents for other words may be disputable or ‘controversial,’ resulting in differences between different methods. In statistical MT, alignment links carry information about an underlying, contextualized bilingual dictionary. Along this line of thinking, dif"
2021.motra-1.8,D09-1024,0,0.0481348,"with missing alignment links. Assume, for instance, the phrase translation {have bread ↔ Tengo pan} (see Figures 1 and 2). This should result in a set of alignment links {(1,0),(1,1),(2,0),(2,1)}. However, without further postprocessing, MOSES’ phrase-based system grow-diag-final(and) may produce ’incomplete’ phrase alignments in which one of the four alignment links may be missing, resulting in five possible alignment configurations for this phrase translation. decrease global averaged AER (GIZA++, Och and Ney (2003); S IM A LIGN, Sabet et al. (2020); FASTA LIGN, Dyer et al. (2013); UALIGN, Hermjakob (2009); etc.), we posit that the agreement— as well as the disagreement—about alignment relations on the level of individual words carries crucial information about translation difficulties. While some words may be ‘easy’ to align—i.e., with little or no discrepancies between different alignment methods—translational equivalents for other words may be disputable or ‘controversial,’ resulting in differences between different methods. In statistical MT, alignment links carry information about an underlying, contextualized bilingual dictionary. Along this line of thinking, differing alignments of the s"
2021.motra-1.8,J03-1002,0,0.0684937,"production duration and insertions, as well as a moderate correlation between WADI and word translation entropy. This shows that differences in alignment decisions reflect on variation in translation decisions and demonstrates that aggregate WADI score could be used as a word-level feature to estimate post-editing difficulty. 1 Introduction Alignment error rate (AER) is a segment-based metric that compares one alignment (usually automatically generated) against another gold standard word alignment, assigning errors when the hypothesis alignment’s links differ from those of the gold standard (Och and Ney, 2003). It is a normalized score with values between 0–1 for entire segments where a score of 0 indicates identical word alignments and a score of 1 indicates completely different sets of alignment links. When reported, AER scores are usually multiplied by 100 Michael Carl CRITT mcarl6@kent.edu for readability. Usually an average AER score over many segments is reported, and automatic alignment systems have ranged between average AER scores of 3.7–50.6 (Liu et al., 2010) and 14.5–33.2 specifically for the English-to-Spanish language pair (Lambert, 2008). We have conducted alignment experiments with"
2021.motra-1.8,2020.findings-emnlp.147,0,0.0432165,"Missing"
C00-2145,1999.mtsummit-1.19,0,0.117771,"anslation Michael Carl Institut fur Angewandte Informationsforschung, Martin-Luther-Strae 14, 66111 Saarbrucken, Germany, carl@iai.uni-sb.de Abstract In this paper I elaborate a model of competence for corpus-based machine translation (CBMT) along the lines of the representations used in the translation system. Representations in CBMT-systems can be rich or austere, molecular or holistic and they can be ne-grained or coarse-grained. The paper shows that di erent CBMT architectures are required dependent on whether a better translation quality or a broader coverage is preferred according to Boitet (1999)&apos;s formula: Coverage * Quality = K&quot;. 1 Introduction In the machine translation (MT) literature, it has often been argued that translations of natural language texts are valid if and only if the source language text and the target language text have the same meaning cf. e.g. (Nagao, 1989). If we assume that MT systems produce meaningful translations to a certain extent, we must assume that such systems have a notion of the source text meaning to a similar extent. Hence, the translation algorithm together with the data it uses encode a formal model of meaning. Despite 50 years of intense resear"
C00-2145,J90-2002,0,0.801531,"In addition to this, a shallow linguistic formalism is used to percolate features in derivation trees. Sato and Nagao (1990) proposed still richer representations where syntactically analyzed phrases and sentences are stored in a database. In the translation phase, most similar derivation trees are retrieved from the database and a target language derivation tree is composed from the translated parts. By means of a thesaurus semantically similar lexical items may be exchanged in the derivation trees. Statistics based MT (SBMT) approaches implement austere theories of meaning. For instance, in Brown et al. (1990) a couple of models are presented starting with simple stochastic translation models getting incrementally more complex and rich by introducing more random variables. No linguistic Richness of Representation Richness of Representation Granularity of Representation sem syn mor gra sem syn mor gra sent. 1 6 2;3 4 5 6 7 8;9 molecular mixed holistic Atomicity of Representation - 1 : 4 : 7 : Sato and Nagao (1990) ZERES Zer (1997) Brown (1997) 2: 5: 8: 6 1 2;3 8 6 7 phrase 4 9;5 word word phrase sentence Granularity of Representation - EDGAR Carl (1999) TRADOS Heyn (1996) Brown e"
C00-2145,1999.mtsummit-1.37,1,0.870507,"ed by ZERES (Zer, 1997) follows a richer approach. The reference translations and the input sentence to be translated are lemmatized and part-of-speech tagged. The source language sentence is mapped against the reference translations on a surface string level, on a lemma level and on a part-of-speech level. Those example translations which show greatest similarity to the input sentence with respect to the three levels of description are returned as the best available translation. Example Based Machine Translation (EBMT) systems (Sato and Nagao, 1990; Collins, 1998; Guvenir and Cicekli, 1998; Carl, 1999; Brown, 1997) are richer systems. Translation examples are stored as feature and tree structures. Translation templates are generated which contain - sometimes weighted - connections in those positions where the source language and the target language equivalences are strong. In the translation phase, a multi-layered mapping from the source language into the target language takes place on the level of templates and on the level of llers. The ReVerb EBMT system (Collins, 1998) performs sub-sentential chunking and seeks to link constituents with the same function in the source and the target la"
C00-2145,1996.eamt-1.12,0,0.0340174,"ins (1998) distinguishes between MemoryBased MT, i.e. memory heavy, linguistic light and Example-Based MT i.e. memory light and linguistic heavy. While the former systems implement an austere theory of meaning, the latter make use of rich representations. The most super cial theory of understanding is implemented in purely memory-based MT approaches where learning takes place only by extending the reference text. No abstraction or generalization of the reference examples takes place. Translation Memories (TMs) are such purely memory based MT-systems. A TM e.g. TRADOS&apos;s Translator&apos;s Workbench (Heyn, 1996), and STAR&apos;s TRANSIT calculates the graphemic similarity of the input text and the source side of the reference translations and return the target string of the most similar translation examples as output. TMs make use of a set of reference translation examples and a (knn) retrieval algorithm. They implement an austere theory of meaning because they cannot justify the use of a word other than by looking up all contexts in which the word occurs. They can, however, enumerate all occurrences of a word in the reference text. The TM distributed by ZERES (Zer, 1997) follows a richer approach. The re"
C00-2145,1992.tmi-1.4,0,0.0149877,"ning and the target language meaning other than by means of global considerations concerning frequencies of occurrence in the reference text. In order to compute the most probable translations, each pair of items of the source language and the target language is associated with a certain probability. This prior probability is derived from the reference text. In the translation phase, several target language sequences are considered and the one with the highest posterior probability is then taken to be the translation of the source language string. Similarly, neural network based CBMT systems (McLean, 1992) are holistic approaches. The training of the weights and the minimization of the classi cation error relies on the reference text as a whole. Temptations to extract rules from the trained neural networks seek to isolate and make explicit aspects on how the net successfully classi es new sequences. The training process, however, remains holistic. TMs implement the molecular CBMT approach as they rely on a static distance metric which is independent from the size and content of the case base. TMs are molecular because they rely on a xed and limited set of graphic symbols. Adding further example"
C00-2145,C90-3044,0,\N,Missing
C04-1118,W98-1231,1,\N,Missing
carl-2000-combining,A94-1016,0,\N,Missing
carl-2000-combining,C96-1030,0,\N,Missing
carl-2000-combining,1995.tmi-1.28,0,\N,Missing
carl-2000-combining,1999.mtsummit-1.37,1,\N,Missing
carl-2000-combining,P98-2139,0,\N,Missing
carl-2000-combining,C98-2134,0,\N,Missing
carl-2000-combining,W98-1231,1,\N,Missing
carl-etal-2002-toward,A94-1016,0,\N,Missing
carl-etal-2002-toward,W01-1406,0,\N,Missing
carl-etal-2002-toward,2001.mtsummit-ebmt.4,0,\N,Missing
carl-etal-2002-toward,W01-1401,0,\N,Missing
carl-etal-2002-toward,C92-2090,0,\N,Missing
carl-etal-2002-toward,langlais-simard-2002-merging,0,\N,Missing
carl-etal-2002-toward,1999.mtsummit-1.92,1,\N,Missing
carl-etal-2014-cft13,P08-4006,0,\N,Missing
carl-etal-2014-cft13,W14-0306,1,\N,Missing
carl-etal-2014-cft13,underwood-etal-2014-evaluating,1,\N,Missing
carl-etal-2014-cft13,L12-1000,0,\N,Missing
carl-etal-2014-cft13,2013.mtsummit-european.3,1,\N,Missing
E14-2007,J93-2003,0,0.0320766,"Missing"
E14-2007,2010.eamt-1.18,1,0.868591,"Missing"
E14-2007,2005.mtsummit-papers.19,1,0.793548,"Missing"
E14-2007,D08-1051,1,0.931323,"Missing"
E14-2007,J09-1002,1,\N,Missing
E14-2007,P07-2045,1,\N,Missing
E14-2007,2012.eamt-1.5,1,\N,Missing
L16-1635,2014.amta-wptp.6,0,0.640881,"Missing"
L16-1635,W15-1825,0,0.030624,"nterpretation, where the interpreter hears a text and speaks out the translation (e.g., during conference interpreting) and conventional translation by which a written source text is translated mainly using the keyboard. It is close to sight translation, but while sight translation is usually done in the moment; there are – in principle - no time constraints in translation dictation. Translation dictation was used in some translation bureaus in the 1960s and 1970s (Gingold, 1978) but it has been used less frequently since the mid-80s, as professional translators started using micro-computers (Zapata and Kirkedal, 2015). Already the ALPAC report (Pierce et al., 1966) mentioned that “productivity of human translators might be as much as four times higher when dictating” as compared to writing. Others (e.g. Reddy and Rose, 2010, Rodriguez et al., 2012) are less optimistic about the time efficiency of dictation, but with increasing quality of voice recognition this mode of translation is becoming a valid alternative to ‘conventional’ translation typing (Ciobanu, 2014) and even to machine translation post-editing. See also Martinez et al, (2014) who experiment with integrating speech recognition into an online C"
L18-1603,L16-1635,1,0.748165,"ng for language pairs that are different in terms of semantic and syntactic remoteness. We use data from the CRITT TPR database, comparing translation and post-editing from English to Japanese and from English to Spanish, and study the interaction of pause-word ratio for short pauses ranging between 300 and 500ms with syntactic remoteness, measured by the CrossS feature, semantic remoteness, measured by HTra, and syntactic and semantic remoteness, measured by Literality. Keywords: pause-word ratio, Literality, cognitive effort 1. Introduction The Multiling subset of the CRITT TPR-DB database (Carl et al., 2016a) provides a large corpus of translation process data that facilitates comparisons across different languages and different translation modalities. It assembles user activity data obtained from translation tasks into several languages using a common set of six short English source texts. In particular, keystroke and eye tracking data were recorded during from-scratch translation sessions and during post-editing of machine translations. In this paper, we focus on translation and post-editing data from the BML12 study for English-to-Spanish (Mesa-Lao, 2014) and the ENJA15 study for English to J"
L18-1603,2012.amta-wptp.3,1,0.768014,"Missing"
L18-1603,2014.amta-wptp.6,1,0.905154,"s and different translation modalities. It assembles user activity data obtained from translation tasks into several languages using a common set of six short English source texts. In particular, keystroke and eye tracking data were recorded during from-scratch translation sessions and during post-editing of machine translations. In this paper, we focus on translation and post-editing data from the BML12 study for English-to-Spanish (Mesa-Lao, 2014) and the ENJA15 study for English to Japanese (Carl et al., 2016b). By introducing refinements of the pauseword ratio measure of cognitive effort (Lacruz and Shreve, 2014) given by different ranges of pause lengths, we identify different patterns of cognitive effort for the two language pairs. These point to possible differences in the translation process when languages are more or less remote from each other that merit systematic investigation. These differences are potentially of interest to researchers in Natural Language Processing and Textto-Speech synthesis. In terms of language structure, Spanish is much closer to English than Japanese is to English. It is therefore to be expected that translation related tasks will be more effortful for English&gt;Japanese"
L18-1603,W16-3419,1,0.941378,"Processing and Textto-Speech synthesis. In terms of language structure, Spanish is much closer to English than Japanese is to English. It is therefore to be expected that translation related tasks will be more effortful for English&gt;Japanese than for English&gt;Spanish. In addition, typed production of Japanese using an input method editor (IME) is more complex, and so more effortful, than typed production of Spanish. The expected extra effort involved in English&gt;Japanese translation tasks as compared to English&gt;Spanish translation tasks has been confirmed, for example in Carl et al. (2016b) and Schaeffer et al. (2016). Linguistic complexity, as opposed to typing complexity, is a factor that contributes to increased cognitive effort expended on translation tasks (Dragsted, 2011). One type of complexity arises from translation entropy, which is computed by HTra in the CRITT TPR database. Translation entropy of a source text word is derived from the number of different translation choices made by different translators. For example, English seat could be rendered in several ways in both Spanish and Japanese. Examples include asiento or silla in Spanish, and or in Japanese. The actual value of HTra for a source"
P13-2062,carl-2012-translog,1,0.827281,"were strongly correlated, we would have rather opted “time taken to translate” for the measurement of TDI. The reason is that “time taken to translate” is relatively easy to compute and does not require expensive setup for conducting “eye-tracking” experiments. But our experiments show that there is a weak correlation (coefficient = 0.12) between “time taken to translate” and Tp . This makes us believe that Tp is still the best option for TDI measurement. Computing TDI using eye-tracking database We obtained TDIs for a set of sentences from the Translation Process Research Database (TPR 1.0)(Carl, 2012). The database contains translation studies for which gaze data is recorded through the Translog software1 (Carl, 2012). Figure 2 presents a screendump of Translog. Out of the 57 available sessions, we selected 40 translation sessions comprising 80 sentence translations2 . Each of these 80 sentences was translated from English to three different languages, viz. Spanish, Danish and Hindi by at least 2 translators. The translators were young professional linguists or students pursuing PhD in linguistics. The eye-tracking data is noisy and often exhibits systematic errors (Hornof and Halverson, 2"
P13-2062,C96-2123,0,0.697064,"Missing"
P13-2062,W12-4906,1,0.831553,"ded through the Translog software1 (Carl, 2012). Figure 2 presents a screendump of Translog. Out of the 57 available sessions, we selected 40 translation sessions comprising 80 sentence translations2 . Each of these 80 sentences was translated from English to three different languages, viz. Spanish, Danish and Hindi by at least 2 translators. The translators were young professional linguists or students pursuing PhD in linguistics. The eye-tracking data is noisy and often exhibits systematic errors (Hornof and Halverson, 2002). To correct this, we applied automatic error correction technique (Mishra et al., 2012) followed by manually correcting incorrect gaze-toword mapping using Translog. Note that, gaze and saccadic durations may also depend on the translator’s reading speed. We tried to rule out this effect by sampling out translations for which the variance in participant’s reading speed is minimum. Variance in reading speed was calculated after taking a samples of source text for each participant and measuring the time taken to read the text. After preprocessing the data, TDI was computed for each sentence by using (2) and (3).The observed unnormalized TDI score3 ranges from 0.12 to 0.86. We norm"
P13-2062,W12-4904,0,0.0369175,"Missing"
underwood-etal-2014-evaluating,J09-1002,1,\N,Missing
underwood-etal-2014-evaluating,N10-1078,0,\N,Missing
underwood-etal-2014-evaluating,W08-0309,0,\N,Missing
underwood-etal-2014-evaluating,carl-etal-2014-cft13,1,\N,Missing
underwood-etal-2014-evaluating,aziz-etal-2012-pet,0,\N,Missing
underwood-etal-2014-evaluating,2012.eamt-1.31,0,\N,Missing
underwood-etal-2014-evaluating,2012.tc-1.5,0,\N,Missing
vandeghinste-etal-2006-metis,oostdijk-etal-2002-experiences,0,\N,Missing
vandeghinste-etal-2006-metis,boutsis-etal-2000-robust,0,\N,Missing
vandeghinste-etal-2006-metis,2005.mtsummit-ebmt.12,1,\N,Missing
vandeghinste-etal-2006-metis,P02-1040,0,\N,Missing
vandeghinste-etal-2006-metis,alsina-etal-2002-catcg,1,\N,Missing
vandeghinste-etal-2006-metis,W98-1231,1,\N,Missing
vandeghinste-etal-2008-evaluation,habash-dorr-2002-handling,0,\N,Missing
vandeghinste-etal-2008-evaluation,P02-1040,0,\N,Missing
vandeghinste-etal-2008-evaluation,A00-1031,0,\N,Missing
vandeghinste-etal-2008-evaluation,N03-1017,0,\N,Missing
vandeghinste-etal-2008-evaluation,N03-1013,0,\N,Missing
vandeghinste-etal-2008-evaluation,2003.mtsummit-systems.9,0,\N,Missing
vandeghinste-etal-2008-evaluation,2005.mtsummit-papers.11,0,\N,Missing
vandeghinste-etal-2008-evaluation,2003.eamt-1.7,1,\N,Missing
vandeghinste-etal-2008-evaluation,2007.mtsummit-papers.74,0,\N,Missing
vandeghinste-etal-2008-evaluation,vandeghinste-etal-2006-metis,1,\N,Missing
W01-0718,C00-2139,0,\N,Missing
W01-0718,1995.tmi-1.28,0,\N,Missing
W01-0718,C96-2211,0,\N,Missing
W01-0718,C00-2131,0,\N,Missing
W01-0718,C96-1078,0,\N,Missing
W01-0718,P98-2223,0,\N,Missing
W01-0718,C98-2218,0,\N,Missing
W01-0718,W98-1231,1,\N,Missing
W02-1402,C00-2163,0,\N,Missing
W02-1402,H93-1039,0,\N,Missing
W03-0307,C00-2163,0,\N,Missing
W12-4906,2012.amta-wptp.1,1,0.81987,"Missing"
W14-0306,2012.amta-wptp.1,1,0.901868,"(c). In this paper we assess this hypothesis by Killer 11 nurse Operationalizing literal translation receives 15 four asesino 7 el_enfermero recibe 28 6 el_asesino 5 enfermero_asesino 3 es_condenado 3 el_enfermero 4 enfermero 3 condenado_a 2 enfermero_asesino 4 asesino 2 recibe_a 3 un_enfermero 2 enfermera cuatro live sentences 12 perpetuas 13 cadenas 12 cadenas 11 perpetuas 2 asesino Figure 1: Translation choices and numbers of occurrences as retrieved from 31 En -&gt; ES translations in the TPR-DB analyzing the gazing behavior of translators. As a basis for our investigation we use the TPR-DB (Carl, 2012), which currently contains more than 940 text production sessions (translation, postediting, editing and copying) in more than 10 different languages1. For each translation and post-editing session keystroke and gaze data was collected and stored, and translations were manually aligned. The TPR-DB is therefore ideally suited for answering aspects of the cognitive processes during translation which are shared across individuals and language combinations. 2.1 Translation Choices A source word can often be translated in many different ways. In order to quantify such translation choices, Choice Ne"
W14-0306,carl-etal-2014-cft13,1,0.784288,"000) argues that translations by different translators of the same source text can be used to draw inferences about the cognitive processes during translation. In section 2 we operationalize literal translation from a process point of view. We describe a transducer to measure the similarity of word order in the source and target language strings, to account for criteria (a) and (b). We introduce the In line with these considerations, to estimate the translation effort for lexical selection, we count the number of different translation realizations for each word. We use the TPR-DB (Carl, 2012, Carl et al. 2014) which contains (among others) a large number of different translations for the same source text. For instance, Figure 1 shows the number of Spanish translation choices 1 The figures relate to TPR-DBv1.4 which can be downloaded from: http://bridge.cbs.dk/platform/?q=CRITT_TPR-db 30 produced by 31 different translators for the same English source sentence. Figure 1 only shows translations which occur at least twice. Figure 2 shows one of the realized translations. Cross value of 2. Since the second source word (“nurse”) emits two adjacent TT words, no further ST word has to be consumed to produ"
W98-1230,C96-1030,0,\N,Missing
W98-1230,C90-3044,0,\N,Missing
W98-1230,J90-2002,0,\N,Missing
W98-1230,W98-1231,1,\N,Missing
W98-1231,C90-3030,0,0.242444,"lysis should be involved. For instance, whether a certain task reqnizes a full parse or whether some &apos;shallow&apos; operations may be sufficient is often difficult to determine. The choice of tools can be guided by the data or the requirements and the prerequisites of the goal to be reached. These considerations may depend on the availability of a grammatical model, the required standard of the results, and processing time constraints. However, the optimization of this task remains an unresolved area until now. The interest of the NLP community for &apos;shallow&apos; processing has grown recently (cf. (Karlsson, 1990),(Abney, 1996), (Deelerek and Klein, 1997)). In this paper, we describe a simple formalism ( K U R D x) that is designed to perform some XKURD is a n acronym representing the ftrst letters of the implemented actions: K(ill)-U(nify)-R(¢place)D(elete) Carl and Schmidt-Wigger 257 • Tagging (disarnbiguation of multiple morphological analyses) Often a set of simple rules that runs in a set order over the results of the morphological analyses is sufficient to disambiguate multiple analysis of a word due to its morphosyntactic context. • Syntax checking Grammatically erroneous sentences are detected"
W98-1231,W98-1230,1,\N,Missing
