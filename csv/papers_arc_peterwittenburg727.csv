P14-2061,Unsupervised Feature Learning for Visual Sign Language Identification,2014,25,4,3,1,36475,binyam gebre,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Prior research on language identification focused primarily on text and speech. In this paper, we focus on the visual modality and present a method for identifying sign languages solely from short video samples. The method is trained on unlabelled video data (unsupervised feature learning) and using these features, it is trained to discriminate between six sign languages (supervised learning). We ran experiments on short video samples involving 30 signers (about 6 hours in total). Using leave-one-signer-out cross-validation, our evaluation shows an average best accuracy of 84%. Given that sign languages are underresourced, unsupervised feature learning techniques are the right tools and our results indicate that this is realistic for sign language identification."
W13-1728,Improving Native Language Identification with {TF}-{IDF} Weighting,2013,19,27,3,1,36475,binyam gebre,Proceedings of the Eighth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"This paper presents a Native Language Identification (NLI) system based on TF-IDF weighting schemes and using linear classifiers - support vector machines, logistic regressions and perceptrons. The system was one of the participants of the 2013 NLI Shared Task in the closed-training track, achieving 0.814 overall accuracy for a set of 11 native languages. This accuracy was only 2.2 percentage points lower than the winnerxe2x80x99s performance. Furthermore, with subsequent evaluations using 10-fold cross-validation (as given by the organizers) on the combined training and development data, the best average accuracy obtained is 0.8455 and the features that contributed to this accuracy are the TF-IDF of the combined unigrams and bigrams of words."
gebre-etal-2012-towards,Towards Automatic Gesture Stroke Detection,2012,6,11,2,1,36475,binyam gebre,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Automatic annotation of gesture strokes is important for many gesture and sign language researchers. The unpredictable diversity of human gestures and video recording conditions require that we adopt a more adaptive case-by-case annotation model. In this paper, we present a work-in progress annotation model that allows a user to a) track hands/face b) extract features c) distinguish strokes from non-strokes. The hands/face tracking is done with color matching algorithms and is initialized by the user. The initialization process is supported with immediate visual feedback. Sliders are also provided to support a user-friendly adjustment of skin color ranges. After successful initialization, features related to positions, orientations and speeds of tracked hands/face are extracted using unique identifiable features (corners) from a window of frames and are used for training a learning algorithm. Our preliminary results for stroke detection under non-ideal video conditions are promising and show the potential applicability of our methodology."
drude-etal-2012-language,The Language Archive {---} a new hub for language resources,2012,2,1,4,0,39141,sebastian drude,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This contribution presents ÂThe Language ArchiveÂ (TLA), a new unit at the MPI for Psycholinguistics, discussing the current developments in management of scientific data, considering the need for new data research infrastructures. Although several initiatives worldwide in the realm of language resources aim at the integration, preservation and mobilization of research data, the state of such scientific data is still often problematic. Data are often not well organized and archived and not described by metadata â even unique data such as field-work observational data on endangered languages is still mostly on perishable carriers. New data centres are needed that provide trusted, quality-reviewed, persistent services and suitable tools and that take legal and ethical issues seriously. The CLARIN initiative has established criteria for suitable centres. TLA is in a good position to be one of such centres. It is based on three essential pillars: (1) A data archive; (2) management, access and annotation tools; (3) archiving and software expertise for collaborative projects. The archive hosts mostly observational data on small languages worldwide and language acquisition data, but also data resulting from experiments."
W11-4113,{AVAT}ec{H}: Audio/Video Technology for Humanities Research,2011,6,3,6,0,42937,sebastian tschopel,Proceedings of the Workshop on Language Technologies for Digital Humanities and Cultural Heritage,0,In the AVATecH project the Max-Planck Institute for Psycholinguistics (MPI) and the Fraunhofer institutes HHI and IAIS aim to significantly speed up the process of creating annotations of audio-visual data for humanities research. For this we integrate state-of-theart audio and video pattern recognition algorithms into the widely used ELAN annotation tool. To address the problem of heterogeneous annotation tasks and recordings we provide modular components extended by adaptation and feedback mechanisms to achieve competitive annotation quality within significantly less annotation time. Currently we are designing a large-scale end-user evaluation of the project.
zinn-etal-2010-evolving,An Evolving e{S}cience Environment for Research Data in Linguistics,2010,11,0,2,1,29525,claus zinn,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The amount of research data in the Humanities is increasing at fast speed. Metadata helps describing and making accessible this data to interested researchers within and across institutions. While metadata interoperability is an issue that is being recognised and addressed, the systematic and user-driven provision of annotations and the linking together of resources into new organisational layers have received much less attention. This paper gives an overview of our evolving technological eScience environment to support such functionality. It describes two tools, ADDIT and ViCoS, which enable researchers, rather than archive managers, to organise and reorganise research data to fit their particular needs. The two tools, which are embedded into our institute's existing software landscape, are an initial step towards an eScience environment that gives our scientists easy access to (multimodal) research data of their interest, and empowers them to structure, enrich, link together, and share such data as they wish."
broeder-etal-2010-data,A Data Category Registry- and Component-based Metadata Framework,2010,13,50,6,1,18402,daan broeder,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We describe our computer-supported framework to overcome the rule of metadata schism. It combines the use of controlled vocabularies, managed by a data category registry, with a component-based approach, where the categories can be combined to yield complex metadata structures. A metadata scheme devised in this way will thus be grounded in its use of categories. Schema designers will profit from existing prefabricated larger building blocks, motivating re-use at a larger scale. The common base of any two metadata schemes within this framework will solve, at least to a good extent, the semantic interoperability problem, and consequently, further promote systematic use of metadata for existing resources and tools to be shared."
auer-etal-2010-elan,{ELAN} as Flexible Annotation Framework for Sound and Image Processing Detectors,2010,6,19,4,0,43064,eric auer,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Annotation of digital recordings in humanities research still is, to a large extend, a process that is performed manually. This paper describes the first pattern recognition based software components developed in the AVATecH project and their integration in the annotation tool ELAN. AVATecH (Advancing Video/Audio Technology in Humanities Research) is a project that involves two Max Planck Institutes (Max Planck Institute for Psycholinguistics, Nijmegen, Max Planck Institute for Social Anthropology, Halle) and two Fraunhofer Institutes (Fraunhofer-Institut f{\""u}r Intelligente Analyse- und Informationssysteme IAIS, Sankt Augustin, Fraunhofer Heinrich-Hertz-Institute, Berlin) and that aims to develop and implement audio and video technology for semi-automatic annotation of heterogeneous media collections as they occur in multimedia based research. The highly diverse nature of the digital recordings stored in the archives of both Max Planck Institutes, poses a huge challenge to most of the existing pattern recognition solutions and is a motivation to make such technology available to researchers in the humanities."
van-uytvanck-etal-2010-virtual,Virtual Language Observatory: The Portal to the Language Resources and Technology Universe,2010,11,13,4,0,17555,dieter uytvanck,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Over the years, the field of Language Resources and Technology (LRT) has developed a tremendous amount of resources and tools. However, there is no ready-to-use map that researchers could use to gain a good overview and steadfast orientation when searching for, say corpora or software tools to support their studies. It is rather the case that information is scattered across project- or organisation-specific sites, which makes it hard if not impossible for less-experienced researchers to gather all relevant material. Clearly, the provision of metadata is central to resource and software exploration. However, in the LRT field, metadata comes in many forms, tastes and qualities, and therefore substantial harmonization and curation efforts are required to provide researchers with metadata-based guidance. To address this issue a broad alliance of LRT providers (CLARIN, the Linguist List, DOBES, DELAMAN, DFKI, ELRA) have initiated the Virtual Language Observatory portal to provide a low-barrier, easy-to-follow entry point to language resources and tools; it can be accessed via http://www.clarin.eu/vlo"
wittenburg-etal-2010-resource,Resource and Service Centres as the Backbone for a Sustainable Service Infrastructure,2010,0,12,1,1,39140,peter wittenburg,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Currently, research infrastructures are being designed and established in many disciplines since they all suffer from an enormous fragmentation of their resources and tools. In the domain of language resources and tools the CLARIN initiative has been funded since 2008 to overcome many of the integration and interoperability hurdles. CLARIN can build on knowledge and work from many projects that were carried out during the last years and wants to build stable and robust services that can be used by researchers. Here service centres will play an important role that have the potential of being persistent and that adhere to criteria as they have been established by CLARIN. In the last year of the so-called preparatory phase these centres are currently developing four use cases that can demonstrate how the various pillars CLARIN has been working on can be integrated. All four use cases fulfil the criteria of being cross-national."
varadi-etal-2008-clarin,{CLARIN}: Common Language Resources and Technology Infrastructure,2008,0,56,3,0,17457,tamas varadi,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The paper provides a general introduction to the CLARIN project, a large-scale European research infrastructure project designed to establish an integrated and interoperable infrastructure of language resources and technologies. The goal is to make language resources and technology much more accessible to all researchers working with language material, particularly non-expert users in the Humanities and Social Sciences. CLARIN intends to build a virtual, distributed infrastructure consisting of a federation of trusted digital archives and repositories where language resources and tools are accessible through web services. The CLARIN project consists of 32 partners from 22 countries and is currently engaged in the preparatory phase of developing the infrastructure. The paper describes the objectives of the project in terms of its technical, legal, linguistic and user dimensions."
sloetjes-wittenburg-2008-annotation,Annotation by Category: {ELAN} and {ISO} {DCR},2008,2,162,2,0.833333,39709,han sloetjes,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The Data Category Registry is one of the ISO initiatives towards the establishment of standards for Language Resource management, creation and coding. Successful application of the DCR depends on the availability of tools that can interact with it. This paper describes the first steps that have been taken to provide users of the multimedia annotation tool ELAN, with the means to create references from tiers and annotations to data categories defined in the ISO Data Category Registry. It first gives a brief description of the capabilities of ELAN and the structure of the documents it creates. After a concise overview of the goals and current state of the ISO DCR infrastructure, a description is given of how the preliminary connectivity with the DCR is implemented in ELAN."
kemps-snijders-etal-2008-exploring,Exploring and Enriching a Language Resource Archive via the Web,2008,7,0,6,1,35127,marc kempssnijders,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The Âdownload first, then process paradigmÂ is still the predominant working method amongst the research community. The web-based paradigm, however, offers many advantages from a tool development and data management perspective as they allow a quick adaptation to changing research environments. Moreover, new ways of combining tools and data are increasingly becoming available and will eventually enable a true web-based workflow approach, thus challenging the Âdownload first, then processÂ paradigm. The necessary infrastructure for managing, exploring and enriching language resources via the Web will need to be delivered by projects like CLARIN and DARIAH."
broeder-etal-2008-foundation,Foundation of a Component-based Flexible Registry for Language Resources and Technology,2008,0,7,7,1,18402,daan broeder,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Within the CLARIN e-science infrastructure project it is foreseen to develop a component-based registry for metadata for Language Resources and Language Technology. With this registry it is hoped to overcome the problems of the current available systems with respect to inflexible fixed schema, unsuitable terminology and interoperability problems. The registry will address interoperability needs by refering to a shared vocabulary registered in data category registries as they are suggested by ISO."
trilsbeek-etal-2008-grid,A Grid of Regional Language Archives,2008,3,2,4,0,17499,paul trilsbeek,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"About two years ago, the Max Planck Institute for Psycholinguistics in Nijmegen, The Netherlands, started an initiative to install regional language archives in various places around the world, particularly in places where a large number of endangered languages exist and are being documented. These digital archives make use of the LAT archiving framework that the MPI has developed over the past nine years. This framework consists of a number of web-based tools for depositing, organizing and utilizing linguistic resources in a digital archive. The regional archives are in principle autonomous archives, but they can decide to share metadata descriptions and language resources with the MPI archive in Nijmegen and become part of a grid of linked LAT archives. By doing so, they will also take advantage of the long-term preservation strategy of the MPI archive. This paper describes the reasoning behind this initiative and how in practice such an archive is set up."
kemps-snijders-etal-2008-isocat,{ISO}cat: Corralling Data Categories in the Wild,2008,5,40,3,1,35127,marc kempssnijders,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"To achieve true interoperability for valuable linguistic resources different levels of variation need to be addressed. ISO Technical Committee 37, Terminology and other language and content resources, is developing a Data Category Registry. This registry will provide a reusable set of data categories. A new implementation, dubbed ISOcat, of the registry is currently under construction. This paper shortly describes the new data model for data categories that will be introduced in this implementation. It goes on with a sketch of the standardization process. Completed data categories can be reused by the community. This is done by either making a selection of data categories using the ISOcat web interface, or by other tools which interact with the ISOcat system using one of its various Application Programming Interfaces. Linguistic resources that use data categories from the registry should include persistent references, e.g. in the metadata or schemata of the resource, which point back to their origin. These data category references can then be used to determine if two or more resources share common semantics, thus providing a level of interoperability close to the source data and a promising layer for semantic alignment on higher levels."
broeder-etal-2006-lamus,{LAMUS}: the Language Archive Management and Upload System,2006,3,5,6,1,18402,daan broeder,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Language Archiving, Resource Management LAMUS is a web-based service that allows researchers to deposit their language resources into a language resources archive. It was developed at the MPI for Psycholinguistics for stricter control of the archive coherence and consistency and allowing wider use of the archiving facilities without increasing the workload for archive and corpus managers. LAMUS is based on the use of IMDI metadata standard for language resources and offers metadata search and browsing over the archive."
broeder-etal-2006-technologies,Technologies for a Federation of Language Resource Archives,2006,0,1,3,1,18402,daan broeder,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The DAM-LR project aims at virtually integrating various European language resource archives that allow users to navigate and operate in a single unified domain of language resources. This type of integration introduces Grid technology to the humanities disciplines and forms a federation of archives. It is the basis for establishing a research infrastructure for language resources which will finally enable eHumanities. Currently, the complete architecture is designed based on a few well-known components and some components are already tested. Based on the technological insights gathered and due to discussions within the international DELAMAN network the ethical and organizational basis for such a federation is defined."
kemps-snijders-etal-2006-api,An {API} for accessing the Data Category Registry,2006,0,4,4,1,35127,marc kempssnijders,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,Central Ontologies are increasingly important to manage interoperability between different types of language resources. This was the reason for ISO to set up a new committee ISO TC37/SC4 taking care of language resource management issues. Central to the work of this committee is the definition of a framework for a central registry of data categories that are important in the domain of language resources. This paper describes an application programming interface that was designed to request services from this data category registry. The DCR is operational and the described API has already been tested from a lexicon application.
wittenburg-etal-2006-foundations,Foundations of Modern Language Resource Archives,2006,0,1,1,1,39140,peter wittenburg,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"A number of serious reasons will convince an increasing amount of researchers to store their relevant material in centers which we will call ``language resource archives''. They combine the duty of taking care of long-term preservation as well as the task to give access to their material to different user groups. Access here is meant in the sense that an active interaction with the data will be made possible to support the integration of new data, new versions or commentaries of all sorts. Modern Language Resource Archives will have to adhere to a number of basic principles to fulfill all requirements and they will have to be involved in federations to create joint language resource domains making it even simpler for the researchers to access the data. This paper makes an attempt to formulate the essential pillars language resource archives have to adhere to."
offenga-etal-2006-metadata,Metadata Profile in the {ISO} Data Category Registry,2006,0,2,3,0,50169,freddy offenga,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Metadata descriptions of language resources become an increasing necessity since the shear amount of language resources is increasing rapidly and especially since we are now creating infrastuctures to access these resources via the web through integrated domains of language resource archives. Yet, the metadata frameworks offered for the domain of language resources (IMDI and OLAC), although mature, are not as widely accepted as necessary. The lack of confidence in the stability and persistence of the concepts and formats introduced by these metadata sets seems to be one argument for people to not invest the time needed for metadata creation. The introduction of these concepts into an ISO standardization process may convince contributors to make use of the terminology. The availability of the ISO Data Category Registry that includes a metadata profile will also offer the opportunity for researchers to construct their own metadata set tailored to the needs of the project at hand, but nevertheless supporting interoperability."
kemps-snijders-etal-2006-lexus,"{LEXUS}, a web-based tool for manipulating lexical resources lexicon",2006,0,0,3,1,35127,marc kempssnijders,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"LEXUS provides a flexible framework for the maintaining lexical structure and content. It is the first implementation of the Lexical Markup Framework model currently being developed at ISO TC37/SC4. Amongst its capabilities are the possibility to create lexicon structures, manipulate content and use of typed relations. Integration of well established Data Category Registries is supported to further promote interoperability by allowing access to well established linguistic concepts. Advanced linguistic functionality is offered to assist users in cross lexica operations such as search and comparison and merging of lexica. To enable use within various user groups the look and feel of each lexicon may be customized. In the near future more functionality will be added including integration with other tools accessing lexical content."
wittenburg-etal-2006-elan,{ELAN}: a Professional Framework for Multimodality Research,2006,3,476,1,1,39140,peter wittenburg,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Utilization of computer tools in linguistic research has gained importance with the maturation of media frameworks for the handling of digital audio and video. The increased use of these tools in gesture, sign language and multimodal interaction studies has led to stronger requirements on the flexibility, the efficiency and in particular the time accuracy of annotation tools. This paper describes the efforts made to make ELAN a tool that meets these requirements, with special attention to the developments in the area of time accuracy. In subsequent sections an overview will be given of other enhancements in the latest versions of ELAN that makes it a useful tool in multimodality research."
berck-etal-2006-ontology,Ontology-based Language Archive Utilization,2006,0,0,5,0,32113,peter berck,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"At the MPI for Psycholinguistics a large archive with language resources has been created with contributions from many different individual researchers and research projects. All of these resources, in particular annotated media streams and multimedia lexica, are accessible via the web and can be utilized with the help of web-based utilization frameworks. Therefore, the archive lends itself to motivate users to operate across the boundaries of single corpora and to support cross-language work. This, however, can only be done when the problems of interoperability, in particular at the level of linguistic encoding, can be solved in an efficient way. Two Max-Planck-Institutes are cooperating to build a framework that allows users to easily create their own practical ontologies and if wanted to relate their concepts to central ontologies."
klassmann-etal-2006-comparison,Comparison of Resource Discovery Methods,2006,2,3,5,0,48010,alex klassmann,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,It is an ongoing debate whether categorical systems created by some experts are an appropriate way to help users finding useful resources in the internet. However for the much more restricted domain of language documentation such a category system might still prove reasonable if not indispensable. This article gives an overview over the particular IMDI category set and presents a rough evaluation of its practical use at the Max-Planck-Institute Nijmegen.
W04-0602,Towards Metadata Interoperability,2004,2,4,1,1,39140,peter wittenburg,Proceeedings of the Workshop on {NLP} and {XML} ({NLPXML}-2004): {RDF}/{RDFS} and {OWL} in Language Technology,0,"Within two European projects metadata interoperability is one of the central topics. While the INTERA project has as one of its goals to achieve an interoperability between two widely used metadata sets for the domain of language resources, the ECHO project created an integrated metadata domain of in total nine data providers from five different disciplines from the humanities. In both projects ad hoc techniques are used to achieve results. In the INTERA project, however, machine readable and ISO compliant concept definitions are created as a first step towards the Semantic Web. In the ECHO project a complex ontology was realized purely relying on XML. It is argued that concept definitions should be registered in open Data Category Repositories and that relations between them should be described as RDF assertions. Yet we are missing standards that would allow us to overcome the ad hoc solutions."
wittenburg-etal-2004-architecture,Architecture for Distributed Language Resource Management and Archiving,2004,0,0,1,1,39140,peter wittenburg,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"An architecture is presented that provides an integrated framework for managing, archiving and accessing language resources. This architecture was discussed in the DELAMAN network {--} a world-wide network of archives holding material about endangered languages. Such a framework will be built upon a metadata infrastructure, a mechanism to resolve unique resource identifiers, user and access rights management components. These components are closely related and have to be based on redundant and distributed services. For all these components existing middleware seems to be available, however, it has to be checked how they can interact with each other."
wittenburg-etal-2004-cross,Cross-Disciplinary Integration of Metadata Descriptions,2004,0,0,1,1,39140,peter wittenburg,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Within the ECHO (European Cultural Heritage Online) project an integrated domain of metadata repositories was created covering data from 5 different humanities disciplines. The integration required intensive work on encoding, syntactical and especially the semantic level, since interoperability is still difficult to be achieved. An ontology was created and a search engine that makes use of the knowledge components. This work within ECHO is seen as one of the practical contributions on the way towards the Semantic Web."
dalli-etal-2004-web,Web Services Architecture for Language Resources,2004,7,5,7,0,49824,angelo dalli,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Abstract A web services based architecture for Language Resources utilizing existing technology such as XML, SOAP, WSDL and UDDI is presented. The web services architecture creates a pervasive information infrastructure that enables straightforward access to two kinds of Language Resources: traditional information sources and language processing resources. Details bout two practical aimplementations of this web services architecture are given. Web Services and databases with minimal means, if any, of The concept of web services as being lightweight components that offer an elegant means of integrating different information repositories and services across the Internet has always been a main objective in developing a standard, interoperable system of web services. Industrial and academic support for web services is increasingly gaining strength and the future looks promising for their widespread adoption (Narsu and Murphy, 2002; Conner, 2001; Gates, 2003). The idea of using web services for Computational Linguistics is also gaining acceptance with the increasing availability of various useful services permitting researchers unprecented access to huge amounts of information and advanced search services like Google (Google, 2002). Linguistic resources are prime candidates for web services applications to enable increased collaboration between research groups and avoid reduplication of resources and effort. Fortunately, current web services technology can be used to provide effective solutions to common problems faced by researchers (Dalli, 2001; Dalli, 2002). We propose a web services architecture for Language Resources that uses a combination of Extensible Markup Language (XML), Simple Object Access Protocol (SOAP), Web Services Description Language (WSDL) and Universal Discovery Description Integration (UDDI) to achieve maximum benefit from these technologies in a Computational Linguistics context (Box et al., 2000; Christensen, et al., 2001; UDDI, 2001). The web services architecture creates a pervasive information infrastructure that enables straightforward access to two kinds of Language Resources: traditional resources such as lexicons, corpora, semantic networks, etc. and language processing resources. The use of standard technology ensures that there is wide support for developers working with minimal knowledge of web services, and also guarantees compatibility with legacy applications, while keeping compatibility with major development frameworks such as Sunxe2x80x99s Java, IBMxe2x80x99s WebSphere, and Microsoftxe2x80x99s .NET."
broeder-etal-2004-large,A Large Metadata Domain of Language Resources,2004,0,7,6,1,18402,daan broeder,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The INTERA and ECHO projects were partly intended to create a critical mass of open and linked metadata descriptions of language resources, helping researchers to understand the benefits of an increased visibility of language resources in the Internet and motivating them to participate. The work was based on the new IMDI version 3.0.3 which is a result of experiences with the earlier versions and new requirements coming from the involved partners. While in INTERA major data centers in Europe are participating, the ECHO project focuses on resources that can be seen as part of cultural heritage. Currently, 27 institutions and projects are active with the goal of having a large browsable and searchable domain by the summer of 2004. Experience shows that the creation of high quality metadata is not trivial and asks for a considerable amount of effort and skills, since manual work alone is too time consumin (Less)"
broeder-etal-2004-using,Using Profiles for {IMDI} Metadata Creation,2004,3,4,2,1,18402,daan broeder,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"In this paper a system to support the creation of extended IMDI metadata records is presented. It is based on bundling definitions of the in the IMDI system user definable key-name/value pairs in a profile. The possibility of using inheritance of profiles in a corpus structure is explored. Profiles Can be created and used by the IMDI Editor, a tool specially designed to create IMDI metadata records."
E03-2014,"Event-Coreference across Multiple, Multi-lingual Sources in the Mumis Project",2003,5,4,5,0,5986,horacio saggion,Demonstrations,0,"We present our work on information extraction from multiple, multi-lingual sources for the Multimedia Indexing and Searching Environment (MUMIS), a project aiming at developing technology to produce formal annotations about essential events in multimedia programme material. The novelty of our approach consists on the use of a merging or cross-document coreference algorithm that aims at combining the output delivered by the information extraction systems."
broeder-etal-2002-lrep,{LREP}: A Language Repository Exchange Protocol,2002,3,0,2,1,18402,daan broeder,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,The recent increase in the number and complexity of the language resources available on the Internet is followed by a similar increase of available tools for linguistic analysis. Ideally the user does not need to be confronted with the question in how to match tools with resources. If resource repositories and tool repositories offer adequate metadata information and a suitable exchange protocol is developed this matching process could be performed (semi-) automatically.
W01-1508,Multimedia Language Resources,2001,-1,-1,2,1,18402,daan broeder,Proceedings of the {ACL} 2001 Workshop on Sharing Tools and Resources,0,None
W01-1017,The Automatic Generation of Formal Annotations in a Multimedia Indexing and Searching Environment,2001,11,20,2,0.571731,2109,thierry declerck,Proceedings of the {ACL} 2001 Workshop on Human Language Technology and Knowledge Management,0,"We describe in this paper the MU-MIS Project (Multimedia Indexing and Searching Environment), which is concerned with the development and integration of base technologies, demonstrated within a laboratory prototype, to support automated multimedia indexing and to facilitate search and retrieval from multimedia databases. We stress the role linguistically motivated annotations, coupled with domain-specific information, can play within this environment. The project will demonstrate that innovative technology components can operate on multilingual, multisource, and multimedia information and create a meaningful and queryable database."
W00-1503,An Experiment in Unifying Audio-Visual and Textual Infrastructures for Language Processing Research and Development,2000,2,4,5,0,11076,kalina bontcheva,Proceedings of the {COLING}-2000 Workshop on Using Toolsets and Architectures To Build {NLP} Systems,0,"This paper describes an experimental integration of two infrastructures (Eudico and GATE) which were developed independently of each other; for different media (video/speech vs. text) and applications. The integration resulted into gaining an in-depth understanding of the functionality and operation of each of the two systems in isolation, and the benefits of their combined use. It also highlighted some issues (e.g., distributed access) which need to be addressed in future work. The experiment also showed clearly the advantages of modularity and generality adopted in both systems."
russel-etal-2000-eudico,"The {EUDICO} Project, Multi Media Annotation over the {I}nternet",2000,4,1,4,0,45951,albert russel,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,In this paper we dsecribe a software environment that facilitates media annotation and analysis of media related corpora over the internet. We will describe the general architecture of this environment and we will introduce our Abstract Corpus Model with which we isolate corpora specific formats from the annotation and analysis tools. The main set of tools is described by giving examples of their usage. Finally we will discuss features regarding the distributed character of this environment.
