2021.findings-emnlp.355,Written Justifications are Key to Aggregate Crowdsourced Forecasts,2021,-1,-1,2,0,7291,saketh kotamraju,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"This paper demonstrates that aggregating crowdsourced forecasts benefits from modeling the written justifications provided by forecasters. Our experiments show that the majority and weighted vote baselines are competitive, and that the written justifications are beneficial to call a question throughout its life except in the last quarter. We also conduct an error analysis shedding light into the characteristics that make a justification unreliable."
2020.lrec-1.140,{W}iki{P}ossessions: Possession Timeline Generation as an Evaluation Benchmark for Machine Reading Comprehension of Long Texts,2020,-1,-1,3,1,5344,dhivya chinnappa,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper presents WikiPossessions, a new benchmark corpus for the task of temporally-oriented possession (TOP), or tracking objects as they change hands over time. We annotate Wikipedia articles for 90 different well-known artifacts paintings, diamonds, and archaeological artifacts), producing 799 artifact-possessor relations with associated attributes. For each article, we also produce a full possession timeline. The full version of the task combines straightforward entity-relation extraction with complex temporal reasoning, as well as verification of textual support for the relevant types of knowledge. Specifically, to complete the full TOP task for a given article, a system must do the following: a) identify possessors; b) anchor possessors to times/events; c) identify temporal relations between each temporal anchor and the possession relation it corresponds to; d) assign certainty scores to each possessor and each temporal relation; and e) assemble individual possession events into a global possession timeline. In addition to the corpus, we release evaluation scripts and a baseline model for the task."
2020.lrec-1.853,Detecting Negation Cues and Scopes in {S}panish,2020,-1,-1,3,0,18300,salud jimenezzafra,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this work we address the processing of negation in Spanish. We first present a machine learning system that processes negation in Spanish. Specifically, we focus on two tasks: i) negation cue detection and ii) scope identification. The corpus used in the experimental framework is the SFU Corpus. The results for cue detection outperform state-of-the-art results, whereas for scope detection this is the first system that performs the task for Spanish. Moreover, we provide a qualitative error analysis aimed at understanding the limitations of the system and showing which negation cues and scopes are straightforward to predict automatically, and which ones are challenging."
2020.findings-emnlp.214,"Helpful or Hierarchical? Predicting the Communicative Strategies of Chat Participants, and their Impact on Success",2020,-1,-1,4,1,19701,farzana rashid,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"When interacting with each other, we motivate, advise, inform, show love or power towards our peers. However, the way we interact may also hold some indication on how successful we are, as people often try to help each other to achieve their goals. We study the chat interactions of thousands of aspiring entrepreneurs who discuss and develop business models. We manually annotate a set of about 5,500 chat interactions with four dimensions of interaction styles (motivation, cooperation, equality, advice). We find that these styles can be reliably predicted, and that the communication styles can be used to predict a number of indices of business success. Our findings indicate that successful communicators are also successful in other domains."
2020.findings-emnlp.345,It{'}s not a Non-Issue: Negation as a Source of Error in Machine Translation,2020,-1,-1,3,0,1841,md hossain,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"As machine translation (MT) systems progress at a rapid pace, questions of their adequacy linger. In this study we focus on negation, a universal, core property of human language that significantly affects the semantics of an utterance. We investigate whether translating negation is an issue for modern MT systems using 17 translation directions as test bed. Through thorough analysis, we find that indeed the presence of negation can significantly impact downstream quality, in some cases resulting in quality reductions of more than 60{\%}. We also provide a linguistically motivated analysis that directly explains the majority of our findings. We release our annotations and code to replicate our analysis here: https://github.com/mosharafhossain/negation-mt."
2020.findings-emnlp.359,Determining Event Outcomes: The Case of {\\#}fail,2020,-1,-1,3,0,19880,srikala murugan,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"This paper targets the task of determining event outcomes in social media. We work with tweets containing either {\#}cookingFail or {\#}bakingFail, and show that many of the events described in them resulted in something edible. Tweets that contain images are more likely to result in edible albeit imperfect outcomes. Experimental results show that edibility is easier to predict than outcome quality."
2020.emnlp-main.732,An Analysis of Natural Language Inference Benchmarks through the Lens of Negation,2020,-1,-1,6,0,1841,md hossain,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Negation is underrepresented in existing natural language inference benchmarks. Additionally, one can often ignore the few negations in existing benchmarks and still make the right inference judgments. In this paper, we present a new benchmark for natural language inference in which negation plays a critical role. We also show that state-of-the-art transformers struggle making inference judgments with the new pairs."
2020.coling-main.60,Extracting Adherence Information from Electronic Health Records,2020,-1,-1,6,0,21112,jordan sanders,Proceedings of the 28th International Conference on Computational Linguistics,0,"Patient adherence is a critical factor in health outcomes. We present a framework to extract adherence information from electronic health records, including both sentence-level information indicating general adherence information (full, partial, none, etc.) and span-level information providing additional information such as adherence type (medication or nonmedication), reasons and outcomes. We annotate and make publicly available a new corpus of 3,000 de-identified sentences, and discuss the language physicians use to document adherence information. We also explore models based on state-of-the-art transformers to automate both tasks."
2020.acl-main.739,Beyond Possession Existence: Duration and Co-Possession,2020,-1,-1,3,1,5344,dhivya chinnappa,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"This paper introduces two tasks: determining (a) the duration of possession relations and (b) co-possessions, i.e., whether multiple possessors possess a possessee at the same time. We present new annotations on top of corpora annotating possession existence and experimental results. Regarding possession duration, we derive the time spans we work with empirically from annotations indicating lower and upper bounds. Regarding co-possessions, we use a binary label. Cohen{'}s kappa coefficients indicate substantial agreement, and experimental results show that text is more useful than the image for solving these tasks."
2020.acl-main.743,Predicting the Focus of Negation: Model and Error Analysis,2020,-1,-1,4,0,1841,md hossain,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"The focus of a negation is the set of tokens intended to be negated, and a key component for revealing affirmative alternatives to negated utterances. In this paper, we experiment with neural networks to predict the focus of negation. Our main novelty is leveraging a scope detector to introduce the scope of negation as an additional input to the network. Experimental results show that doing so obtains the best results to date. Additionally, we perform a detailed error analysis providing insights into the main error categories, and analyze errors depending on whether the model takes into account scope and context information."
S19-1017,A Corpus of Negations and their Underlying Positive Interpretations,2019,0,0,3,1,25227,zahra sarabi,Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019),0,"Negation often conveys implicit positive meaning. In this paper, we present a corpus of negations and their underlying positive interpretations. We work with negations from Simple Wikipedia, automatically generate potential positive interpretations, and then collect manual annotations that effectively rewrite the negation in positive terms. This procedure yields positive interpretations for approximately 77{\%} of negations, and the final corpus includes over 5,700 negations and over 5,900 positive interpretations. We also present baseline results using seq2seq neural models."
N19-1214,Incorporating Emoji Descriptions Improves Tweet Classification,2019,0,3,2,0,6340,abhishek singh,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Tweets are short messages that often include specialized language such as hashtags and emojis. In this paper, we present a simple strategy to process emojis: replace them with their natural language description and use pretrained word embeddings as normally done with standard words. We show that this strategy is more effective than using pretrained emoji embeddings for tweet classification. Specifically, we obtain new state-of-the-art results in irony detection and sentiment analysis despite our neural network is simpler than previous proposals."
D19-1061,Extracting Possessions from Social Media: Images Complement Language,2019,0,0,3,1,5344,dhivya chinnappa,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"This paper describes a new dataset and experiments to determine whether authors of tweets possess the objects they tweet about. We work with 5,000 tweets and show that both humans and neural networks benefit from images in addition to text. We also introduce a simple yet effective strategy to incorporate visual information into any neural network beyond weights from pretrained networks. Specifically, we consider the tags identified in an image as an additional textual input, and leverage pretrained word embeddings as usually done with regular text. Experimental results show this novel strategy is beneficial."
N18-2026,Determining Event Durations: Models and Error Analysis,2018,0,4,2,1,25700,alakananda vempala,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"This paper presents models to predict event durations. We introduce aspectual features that capture deeper linguistic information than previous work, and experiment with neural networks. Our analysis shows that tense, aspect and temporal structure of the clause provide useful clues, and that an LSTM ensemble captures relevant context around the event."
N18-1046,"Mining Possessions: Existence, Type and Temporal Anchors",2018,0,0,2,1,5344,dhivya chinnappa,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"This paper presents a corpus and experiments to mine possession relations from text. Specifically, we target alienable and control possessions, and assign temporal anchors indicating when the possession holds between possessor and possessee. We present new annotations for this task, and experimental results using both traditional classifiers and neural networks. Results show that the three subtasks (predicting possession existence, possession type and temporal anchors) can be automated."
L18-1052,Annotating Temporally-Anchored Spatial Knowledge by Leveraging Syntactic Dependencies,2018,0,1,2,1,25700,alakananda vempala,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1280,Annotating If the Authors of a Tweet are Located at the Locations They Tweet About,2018,0,0,3,0,29822,vivek doudagiri,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
D18-1251,Possessors Change Over Time: A Case Study with Artworks,2018,0,0,2,1,5344,dhivya chinnappa,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a corpus and experimental results to extract possession relations over time. We work with Wikipedia articles about artworks, and extract possession relations along with temporal information indicating when these relations are true. The annotation scheme yields many possessors over time for a given artwork, and experimental results show that an LSTM ensemble can automate the task."
D18-1470,Characterizing Interactions and Relationships between People,2018,0,1,2,1,19701,farzana rashid,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a set of dimensions to characterize the association between two people. We distinguish between interactions (when somebody refers to somebody in a conversation) and relationships (a sequence of interactions). We work with dialogue scripts from the TV show Friends, and do not impose any restrictions on the interactions and relationships. We introduce and analyze a new corpus, and present experimental results showing that the task can be automated."
P17-2101,Determining Whether and When People Participate in the Events They Tweet About,2017,11,4,3,0,32589,krishna sanagavarapu,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"This paper describes an approach to determine whether people participate in the events they tweet about. Specifically, we determine whether people are participants in events with respect to the tweet timestamp. We target all events expressed by verbs in tweets, including past, present and events that may occur in the future. We present new annotations using 1,096 event mentions, and experimental results showing that the task is challenging."
E17-1081,"If No Media Were Allowed inside the Venue, Was Anybody Allowed?",2017,23,0,2,1,25227,zahra sarabi,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"This paper presents a framework to understand negation in positive terms. Specifically, we extract positive meaning from negation when the negation cue syntactically modifies a noun or adjective. Our approach is grounded on generating potential positive interpretations automatically, and then scoring them. Experimental results show that interpretations scored high can be reliably identified."
D17-1244,Dimensions of Interpersonal Relationships: Corpus and Experiments,2017,0,0,2,1,19701,farzana rashid,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a corpus and experiments to determine dimensions of interpersonal relationships. We define a set of dimensions heavily inspired by work in social science. We create a corpus by retrieving pairs of people, and then annotating dimensions for their relationships. A corpus analysis shows that dimensions can be annotated reliably. Experimental results show that given a pair of people, values to dimensions can be assigned automatically."
P16-1142,"Beyond Plain Spatial Knowledge: Determining Where Entities Are and Are Not Located, and For How Long",2016,23,2,2,1,25700,alakananda vempala,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,This paper complements semantic role representations with spatial knowledge beyond indicating plain locations.
N16-1169,Automatic Generation and Scoring of Positive Interpretations from Negated Statements,2016,35,2,1,1,7292,eduardo blanco,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,This paper presents a methodology to extract positive interpretations from negated statements.
L16-1604,Annotating Temporally-Anchored Spatial Knowledge on Top of {O}nto{N}otes Semantic Roles,2016,21,1,2,1,25700,alakananda vempala,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents a two-step methodology to annotate spatial knowledge on top of OntoNotes semantic roles. First, we manipulate semantic roles to automatically generate potential additional spatial knowledge. Second, we crowdsource annotations with Amazon Mechanical Turk to either validate or discard the potential additional spatial knowledge. The resulting annotations indicate whether entities are or are not located somewhere with a degree of certainty, and temporally anchor this spatial information. Crowdsourcing experiments show that the additional spatial knowledge is ubiquitous and intuitive to humans, and experimental results show that it can be inferred automatically using standard supervised machine learning techniques."
D16-1118,Automatic Extraction of Implicit Interpretations from Modal Constructions,2016,26,0,2,0,21112,jordan sanders,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
D16-1119,Understanding Negation in Positive Terms Using Syntactic Dependencies,2016,34,0,2,1,25227,zahra sarabi,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
N15-1048,Inferring Temporally-Anchored Spatial Knowledge from Semantic Roles,2015,24,5,1,1,7292,eduardo blanco,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"This paper presents a framework to infer spatial knowledge from verbal semantic role representations. First, we generate potential spatial knowledge deterministically. Second, we determine whether it can be inferred and a degree of certainty. Inferences capture that something is located or is not located somewhere, and temporally anchor this information. An annotation effort shows that inferences are ubiquitous and intuitive to humans."
E14-1016,Leveraging Verb-Argument Structures to Infer Semantic Relations,2014,32,6,1,1,7292,eduardo blanco,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,This paper presents a methodology to infer implicit semantic relations from verbargument structures. An annotation effort shows implicit relations boost the amount of meaning explicitly encoded for verbs. Experimental results with automatically obtained parse trees and verb-argument structures demonstrate that inferring implicit relations is a doable task.
S13-1042,Choosing the Right Words: Characterizing and Reducing Error of the Word Count Approach,2013,25,9,3,0,40127,hansen schwartz,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity",0,"Social scientists are increasingly using the vast amount of text available on social media to measure variation in happiness and other psychological states. Such studies count words deemed to be indicators of happiness and track how the word frequencies change across locations or time. This word count approach is simple and scalable, yet often picks up false signals, as words can appear in different contexts and take on different meanings. We characterize the types of errors that occur using the word count approach, and find lexical ambiguity to be the most prevalent. We then show that one can reduce error with a simple refinement to such lexica by automatically eliminating highly ambiguous words. The resulting refined lexica improve precision as measured by human judgments of word occurrences in Facebook posts."
D13-1123,A Semantically Enhanced Approach to Determine Textual Similarity,2013,39,2,1,1,7292,eduardo blanco,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a novel approach to determine textual similarity. A layered methodology to transform text into logic forms is proposed, and semantic features are derived from a logic prover. Experimental results show that incorporating the semantic structure of sentences is beneficial. When training data is unavailable, scores obtained from the logic prover in an unsupervised manner outperform supervised methods."
S12-1035,*{SEM} 2012 Shared Task: Resolving the Scope and Focus of Negation,2012,23,69,2,0.074569,5465,roser morante,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"The Joint Conference on Lexical and Computational Semantics (*SEM) each year hosts a shared task on semantic related topics. In its first edition held in 2012, the shared task was dedicated to resolving the scope and focus of negation. This paper presents the specifications, datasets and evaluation criteria of the task. An overview of participating systems is provided and their results are summarized."
N12-1050,Fine-Grained Focus for Pinpointing Positive Implicit Meaning from Negated Statements,2012,29,2,1,1,7292,eduardo blanco,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Negated statements often carry positive implicit meaning. Regardless of the semantic representation one adopts, pinpointing the positive concepts within a negated statement is needed in order to encode the statement's meaning. In this paper, novel ideas to reveal positive implicit meaning using focus of negation are presented. The concept of granularity of focus is introduced and justified. New annotation and features to detect fine-grained focus are discussed and results reported."
moldovan-blanco-2012-polaris,{P}olaris: Lymba{'}s Semantic Parser,2012,18,16,2,0,16607,dan moldovan,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Semantic representation of text is key to text understanding and reasoning. In this paper, we present Polaris, Lymba's semantic parser. Polaris is a supervised semantic parser that given text extracts semantic relations. It extracts relations from a wide variety of lexico-syntactic patterns, including verb-argument structures, noun compounds and others. The output can be provided in several formats: XML, RDF triples, logic forms or plain text, facilitating interoperability with other tools. Polaris is implemented using eight separate modules. Each module is explained and a detailed example of processing using a sample sentence is provided. Overall results using a benchmark are discussed. Per module performance, including errors made and pruned by each module are also analyzed."
W11-0106,A Model for Composing Semantic Relations,2011,18,7,1,1,7292,eduardo blanco,Proceedings of the Ninth International Conference on Computational Semantics ({IWCS} 2011),0,"This paper presents a model to compose semantic relations. The model is independent of any particular set of relations and uses an extended definition for semantic relations. This extended definition includes restrictions on the domain and range of relations and utilizes semantic primitives to characterize them. Primitives capture elementary properties between the arguments of a relation. An algebra for composing semantic primitives is used to automatically identify the resulting relation of composing a pair of compatible relations. Inference axioms are obtained. Axioms take as input a pair of semantic relations and output a new, previously ignored relation. The usefulness of this proposed model is shown using PropBank relations. Eight inference axioms are obtained and their accuracy and productivity are evaluated. The model offers an unsupervised way of accurately extracting additional semantics from text."
P11-1059,Semantic Representation of Negation Using Focus Detection,2011,23,34,1,1,7292,eduardo blanco,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"Negation is present in all human languages and it is used to reverse the polarity of part of statements that are otherwise affirmative by default. A negated statement often carries positive implicit meaning, but to pinpoint the positive part from the negative part is rather difficult. This paper aims at thoroughly representing the semantics of negation by revealing implicit positive meaning. The proposed representation relies on focus of negation detection. For this, new annotation over PropBank and a learning algorithm are proposed."
P11-1146,Unsupervised Learning of Semantic Relation Composition,2011,25,16,1,1,7292,eduardo blanco,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,This paper presents an unsupervised method for deriving inference axioms by composing semantic relations. The method is independent of any particular relation inventory. It relies on describing semantic relations using primitives and manipulating these primitives according to an algebra. The method was tested using a set of eight semantic relations yielding 78 inference axioms which were evaluated over PropBank.
D10-1031,Automatic Discovery of Manner Relations and its Applications,2010,23,2,1,1,7292,eduardo blanco,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a method for the automatic discovery of MANNER relations from text. An extended definition of MANNER is proposed, including restrictions on the sorts of concepts that can be part of its domain and range. The connections with other relations and the lexico-syntactic patterns that encode MANNER are analyzed. A new feature set specialized on MANNER detection is depicted and justified. Experimental results show improvement over previous attempts to extract MANNER. Combinations of MANNER with other semantic relations are also discussed."
C10-2009,Composition of Semantic Relations: Model and Applications,2010,24,5,1,1,7292,eduardo blanco,Coling 2010: Posters,0,"This paper presents a framework for combining semantic relations extracted from text to reveal even more semantics that otherwise would be missed. A set of 26 relations is introduced, with their arguments defined on an ontology of sorts. A semantic parser is used to extract these relations from noun phrases and verb argument structures. The method was successfully used in two applications: rapid customization of semantic relations to arbitrary domains and recognizing entailments."
blanco-etal-2008-causal,Causal Relation Extraction,2008,24,58,1,1,7292,eduardo blanco,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper presents a supervised method for the detection and extraction of Causal Relations from open domain text. First we give a brief outline of the definition of causation and how it relates to other Semantic Relations, as well as a characterization of their encoding. In this work, we only consider marked and explicit causations. Our approach first identifies the syntactic patterns that may encode a causation, then we use Machine Learning techniques to decide whether or not a pattern instance encodes a causation. We focus on the most productive pattern, a verb phrase followed by a relator and a clause, and its reverse version, a relator followed by a clause and a verb phrase. As relators we consider the words as, after, because and since. We present a set of lexical, syntactic and semantic features for the classification task, their rationale and some examples. The results obtained are discussed and the errors analyzed."
