2020.lrec-1.568,C18-1139,0,0.283146,"ddings are part of a set of language modeling techniques that aim to provide mathematical representations of natural language as multidimensional vector spaces. These vector spaces enable the use of mathematical abstractions to determine conceptual relations between the words of a language. Finally, since they can be trained in an unsupervised manner simply by feeding them a large raw text input, they are very simple to create. Another Neural Network-based approach that deserves to be investigated for use in most Natural Language Processing task is the Flair Embeddings (Flair) language model (Akbik et al., 2018). Based on the same ideas first presented in the context of Word Embeddings, Flair Embeddings take into account not only word sequences, but also the character sequence distribution. It also incorporates training in both the forward (that is, left-to-right word and character sequences) and backward (right-to-left word and character sequences) directions. These innovations led Flair authors to call their models contextual string embeddings, in order to highlight the fact that they take sentencelevel context and polysemy into account when calculating word vectors. Our work focuses on Named Entit"
2020.lrec-1.568,Q17-1010,0,0.0421158,"esults, as reported by studies into several deep learning algorithms (Tshitoyan et al., 2019; Young et al., 2018; Camacho-Collados and Pilehvar, 2018; Goldberg, 2016). With that in mind, we selected the best performing Word Embeddings model from Santos et al. (2019) as our general-domain model. This was the 300-dimensional Word2Vec Skip-Gram model from Interinstitutional Center for Computational Linguistics - S˜ao Paulo University (NILC-USP), available on their website2 . 3.2. Oil and Gas Word Embeddings Despite some public pre-trained embedding vectors being already available for Portuguese (Bojanowski et al., 2017; Hartmann et al., 2017; Santos et al., 2019), the highly technical oil and gas vocabulary presents a challenge to Natural Lan-guage Processing applications, in which some terms may assume a completely different meaning compared to the general-context domain. Therefore, there are consistent evidences that generating embedding models from a domain-specific corpus can significantly increase the quality of their semantic representation and, hence, the performance of NLP applications on specialized downstream tasks on the same domain (Gomes et al., 2018; Nooralahzadeh et al., 2018; Lai et al., 201"
2020.lrec-1.568,N19-1423,0,0.055217,"Missing"
2020.lrec-1.568,W15-3904,0,0.0378941,"Missing"
2020.lrec-1.568,L18-1105,1,0.833125,"ector representations suitable for the Geology domain-specific vocabulary in Portuguese, we used the public set of Word Embeddings provided by Gomes et al. (2018)3 . Considering the results as reported by the authors, we focused on the word2vec 100-dimensional skip-gram models, which presented the most consistent results in their qualitative evaluations. 2 http://nilc.icmc.usp.br/embeddings https://github.com/diogosmg/ wordEmbeddingsOG 3 4626 3.3. Flair Embedding Models In this work, we used the FlairBBP (Santos et al., 2019) pre-trained model. It was trained on three corpora: BlogSet-BR (dos Santos et al., 2018), a Brazilian Portuguese web blog text corpus with 2.7 billion tokens; brWaC (Filho et al., 2018), comprising 3 billion tokens from Brazilian Portuguese texts retrieved through a web crawling process; and ptwiki-201903014 , a Wikimedia Foundation data dump in Portuguese with about 162 million tokens. We further trained this model with about 95,454 Portuguese sentences (for a total of 2,276,554 tokens) belonging to the Oil and Gas domain (of which the sedimentary basins subdomain is a part of), from Petrobras’ Geoscience bulletins5 . The goal was to test the effect of the addition of a more foc"
2020.lrec-1.568,L18-1686,0,0.0233371,"he public set of Word Embeddings provided by Gomes et al. (2018)3 . Considering the results as reported by the authors, we focused on the word2vec 100-dimensional skip-gram models, which presented the most consistent results in their qualitative evaluations. 2 http://nilc.icmc.usp.br/embeddings https://github.com/diogosmg/ wordEmbeddingsOG 3 4626 3.3. Flair Embedding Models In this work, we used the FlairBBP (Santos et al., 2019) pre-trained model. It was trained on three corpora: BlogSet-BR (dos Santos et al., 2018), a Brazilian Portuguese web blog text corpus with 2.7 billion tokens; brWaC (Filho et al., 2018), comprising 3 billion tokens from Brazilian Portuguese texts retrieved through a web crawling process; and ptwiki-201903014 , a Wikimedia Foundation data dump in Portuguese with about 162 million tokens. We further trained this model with about 95,454 Portuguese sentences (for a total of 2,276,554 tokens) belonging to the Oil and Gas domain (of which the sedimentary basins subdomain is a part of), from Petrobras’ Geoscience bulletins5 . The goal was to test the effect of the addition of a more focused domain vocabulary to a generalised domain model in a domain-specific Named Entity Recognitio"
2020.lrec-1.568,W17-6615,0,0.0357537,"Missing"
2020.lrec-1.568,N16-1030,0,0.0311526,"such texts. There is still a scarcity of research focusing on this domain, on the other hand the domain has a potentially large quantity of non-conventional Named Entities categories, in fact, yet to be defined. There is little consensus in literature as to what these categories should be to represent the core of this domain. In this work we consider the subdomain of Brazilian Sedimentary Basins, and defined the categories accordingly. For the Named Entity Recognition problem, in general, Neural Networks (NN) coupled with Word Embeddings (WE) are usually present in the best evaluated systems (Lample et al., 2016; dos Santos and Guimar˜aes, 2015; Santos et al., 2019). Word Embeddings are part of a set of language modeling techniques that aim to provide mathematical representations of natural language as multidimensional vector spaces. These vector spaces enable the use of mathematical abstractions to determine conceptual relations between the words of a language. Finally, since they can be trained in an unsupervised manner simply by feeding them a large raw text input, they are very simple to create. Another Neural Network-based approach that deserves to be investigated for use in most Natural Languag"
2020.lrec-1.568,L18-1228,0,0.0179222,"ble for Portuguese (Bojanowski et al., 2017; Hartmann et al., 2017; Santos et al., 2019), the highly technical oil and gas vocabulary presents a challenge to Natural Lan-guage Processing applications, in which some terms may assume a completely different meaning compared to the general-context domain. Therefore, there are consistent evidences that generating embedding models from a domain-specific corpus can significantly increase the quality of their semantic representation and, hence, the performance of NLP applications on specialized downstream tasks on the same domain (Gomes et al., 2018; Nooralahzadeh et al., 2018; Lai et al., 2016). As stated by Tshitoyan et al. (2019), the domain-specificity of the corpus is crucial to determine the quality of the embeddings and their utility for domain-specific tasks. In order to provide neural networks with word vector representations suitable for the Geology domain-specific vocabulary in Portuguese, we used the public set of Word Embeddings provided by Gomes et al. (2018)3 . Considering the results as reported by the authors, we focused on the word2vec 100-dimensional skip-gram models, which presented the most consistent results in their qualitative evaluations. 2"
2020.lrec-1.568,N18-1202,0,0.11238,"Missing"
2020.lrec-1.568,W02-2024,0,0.0579767,"d models. The embedding for each token is inputted separately into the Sequence Labeling Model layer, which adds word-level and character-level features to it, resulting in newly created vectors. These vectors are then used by the Conditional Random Fields in the Sequence Labeling layer to tag each individual token. The version trained for Portuguese comes from Santos et al. (2019), which is available on GitHub 6 . 5. Experiments We organized the experiments into eight tests, each involving a different solo embedding or stacked embedding. We evaluated all these tests by the CoNNL-2002 script (Sang, 2002). First, we extrinsically evaluated the performance of both the general-domain (W2V-SKPG) and the Geology domain (GeoWE) Word Embeddings model using them as the language model for the BiLSTM-CRF NN. We did the same for the general-domain Flair model (called FlairBBP), and for the Geology-enhanced Flair model (called FlairBBPGeoF T ). Finally, the last experiment involved the stacking of each Flair model with each Word Embeddings model, which resulted in four more embeddings models, and thus four more tests. Table 2 presents the results for each of these experiments. According to the results, t"
2020.lrec-1.594,C18-1139,0,0.130507,"ip-gram W2V model with a 2.2 billion token corpus which combined European Portuguese texts and Brazilian Portuguese texts. This corpus is an expansion on the corpus produced by Rodrigues et al. (2016). The model was evaluated on two new benchmarks proposed in the work, as well as the one described in Rodrigues et al. (2016). Santos et al. (2019) trained W2V and FastText WE models using a 4.9 billion token corpus with texts in European and Brazilian Portuguese. NER was used for an extrinsic evaluation, but tests were performed stacked embeddings which joined WEs with Contextualized Embeddings (Akbik et al., 2018). That is, the evaluation was not representative of the quality of the WEs, but rather that of the stacked embeddings. Furthermore, no intrinsic evaluations were performed. In general, the works that involve creating and evaluating Word Embeddings differ both in the corpora used to train the model, and, mainly, in the evaluation method. Of the studied works, only (Hartmann et al., 2017) evaluated its WE intrinsically and extrinsically. 3. Word Embeddings Models Many NLP tasks benefit greatly from the addition of pretrained WE models. These are usualy loaded into an NN’s embedding layer that tr"
2020.lrec-1.594,N19-4010,0,0.0253742,"Missing"
2020.lrec-1.594,W15-3904,0,0.0668038,"Missing"
2020.lrec-1.594,L18-1105,1,0.806374,"were trained with the Gensim framework and, to minimize the use of RAM, we divided the corpus into batches of 10 million tokens. That is, each batch of text is loaded into memory (RAM) only when necessary and removed when Gensim requestes a new batch. An experimental FT model was also trained with the entire corpus at once, that is, we loaded the entire corpus of 4.9 billion tokens into RAM, making Gensim understand that there is only a single text file. The training corpus was composed of 4.9 billion tokens and is composed of three corpora: BrWaC (Wagner Filho et al., 2018), BlogSet-Br (dos Santos et al., 2018) and ptwiki-201903013 . • BrWaC: is a Brazilian Portuguese language corpus composed of the collection of .br domain webpages. It has, in total, 3.53 million documents, or 2.6 billion tokens (Wagner Filho et al., 2018). After pre-processing, the corpus had 2.9 billion tokens. • BlogSet-Br: is a Brazilian Portuguese language corpus composed of blog pages. It has, in total, 7.4 million posts, or 2.7 billion tokens (dos Santos et al., 2018). After pre-processing, the corpus had 1.8 billion tokens. • ptwiki-201903014 : is the Portuguese Wikipedia dump from March 2019, with a total of 162 million to"
2020.lrec-1.594,E17-2068,0,0.0352321,"corpora usually have over a billion tokens in total. According to Mikolov et al. (2013c), WEs are capable of abstracting semantic and syntactic structures. As an example, 1 represents a vector operation between the vectors for the words Norway, Oslo and Havana. The result of this operation should be the word vector for Cuba. In other words, equation 1 can also be read as a pair of country-capital type semantic relations: (Oslo, N orway) and (Havana, Cuba). [N orway] − [Oslo] + [Havana] ' [Cuba] (1) There are many NNs that generate WEs beyond W2V. The most well known alternatives are FastText (Grave et al., 2017), Glove (Pennington et al., 2014) and Wang2Vec (Ling et al., 2015). Word2Vec (W2V) (Mikolov et al., 2013a) is, as previously mentioned, a recurrent NN capable of learning vector space representations of words, as well as capturing semantic and syntactic information, from a textual training corpus. That is, it is meant to produce WEs. It has two training architectures: Continuous Bag-of-Words (CBOW) and Skip-gram. The former seeks to predict a word given a context while the latter seeks to predict a context given a word. FastText (FT) (Grave et al., 2017) is very similar to W2V, also being divi"
2020.lrec-1.594,W17-6615,0,0.0462287,"Missing"
2020.lrec-1.594,N15-1142,0,0.017083,"ikolov et al. (2013c), WEs are capable of abstracting semantic and syntactic structures. As an example, 1 represents a vector operation between the vectors for the words Norway, Oslo and Havana. The result of this operation should be the word vector for Cuba. In other words, equation 1 can also be read as a pair of country-capital type semantic relations: (Oslo, N orway) and (Havana, Cuba). [N orway] − [Oslo] + [Havana] ' [Cuba] (1) There are many NNs that generate WEs beyond W2V. The most well known alternatives are FastText (Grave et al., 2017), Glove (Pennington et al., 2014) and Wang2Vec (Ling et al., 2015). Word2Vec (W2V) (Mikolov et al., 2013a) is, as previously mentioned, a recurrent NN capable of learning vector space representations of words, as well as capturing semantic and syntactic information, from a textual training corpus. That is, it is meant to produce WEs. It has two training architectures: Continuous Bag-of-Words (CBOW) and Skip-gram. The former seeks to predict a word given a context while the latter seeks to predict a context given a word. FastText (FT) (Grave et al., 2017) is very similar to W2V, also being divided into the CBOW and Skip-gram architectures. The main difference"
2020.lrec-1.594,N13-1090,0,0.793656,"ls, or Statistical LMs (Jing and Xu, 2019). Yet another advancement occurred based on the work of Xu and Rudnicky (2000), which suggests the usage of Neural Networks (NN), more specifically Feedforward NNs, for LMs. The work of Bengio et al. (2003), based on this new advancement, presented a solution to the area’s perennial problem: the curse of dimensionality. From there, the usage of Recurrent Neural Networks started becoming more prevalent, which resulted in the adoption of vector space models for word representation, called Word Embeddings (WE) (Mikolov et al., 2009; Mikolov et al., 2010; Mikolov et al., 2013b). WEs can thus be described as a vector space representing words learned through the non-supervised training of NN. These vector spaces can also be called embeddings. Each embedding is the result of successive mathematical operations that happen in the Hidden Layers of the NN, and add semantic meaning to the embeddings. WEs have been successfully applied to NLP solutions, but the degree of success is heavily dependent on the quality of the learned vectors. Bakarov (2018) discusses the lack of consensus on which WE evaluation method yields the most accurate results when attempting to measure"
2020.lrec-1.594,D14-1162,0,0.105258,"Missing"
2020.lrec-1.594,L18-1382,0,0.0128229,". Rodrigues et al. (2016) trained a Skip-gram W2V model with a 1.7 billion token corpus which combined European Portuguese texts and Brazilian Portuguese texts. The authors only performed intrinsic evaluations, and created the first intrinsic benchmark questionnaire for the Portuguese language. Hartmann et al. (2017) trained a total of 35 WE models for the Portuguese language or a corpus of 1.3 billion tokens. The authors evaluated them on the same benchmark questionnaire as Rodrigues et al. (2016). They also performed extrinsic evaluations with Part-of-Speech tagging and semantic similarity. Rodrigues and Branco (2018) trained a Skip-gram W2V model with a 2.2 billion token corpus which combined European Portuguese texts and Brazilian Portuguese texts. This corpus is an expansion on the corpus produced by Rodrigues et al. (2016). The model was evaluated on two new benchmarks proposed in the work, as well as the one described in Rodrigues et al. (2016). Santos et al. (2019) trained W2V and FastText WE models using a 4.9 billion token corpus with texts in European and Brazilian Portuguese. NER was used for an extrinsic evaluation, but tests were performed stacked embeddings which joined WEs with Contextualized"
2020.lrec-1.594,L18-1686,0,0.0132043,"p-gram and CBOW trained with FT. They were trained with the Gensim framework and, to minimize the use of RAM, we divided the corpus into batches of 10 million tokens. That is, each batch of text is loaded into memory (RAM) only when necessary and removed when Gensim requestes a new batch. An experimental FT model was also trained with the entire corpus at once, that is, we loaded the entire corpus of 4.9 billion tokens into RAM, making Gensim understand that there is only a single text file. The training corpus was composed of 4.9 billion tokens and is composed of three corpora: BrWaC (Wagner Filho et al., 2018), BlogSet-Br (dos Santos et al., 2018) and ptwiki-201903013 . • BrWaC: is a Brazilian Portuguese language corpus composed of the collection of .br domain webpages. It has, in total, 3.53 million documents, or 2.6 billion tokens (Wagner Filho et al., 2018). After pre-processing, the corpus had 2.9 billion tokens. • BlogSet-Br: is a Brazilian Portuguese language corpus composed of blog pages. It has, in total, 7.4 million posts, or 2.7 billion tokens (dos Santos et al., 2018). After pre-processing, the corpus had 1.8 billion tokens. • ptwiki-201903014 : is the Portuguese Wikipedia dump from Marc"
2021.hackashop-1.2,L16-1301,1,0.785281,"ecifically, has been little explored in the literature. The authors at (Zhou and Zhang, 2018) created a corpus collecting 3000 sentence records manually from the main news sites, which was used to recognize the entity and extract relations such as learning and training as a whole. Most studies present RE solutions for English texts, and, in this way, it is also possible to identify a larger number of data sets in this language. There are few data sets available in the Portuguese language, such as the Golden Collection HAREM, which is widely used in the literature (Chaves, 2008; Cardoso, 2008; Collovini et al., 2016). HAREM is a joint assessment event for the Portuguese language, organized by Linguateca 9 (Santos and Cardoso, 2007). Its objective is to evaluate recognizing systems of NE (Santos and Cabral, 2009). The Golden Collection (GC) is a subset of the HAREM collection, being used for the task of evaluating the systems that deal with Recognition of Named Entities. The lack of this type of resource forces researchers to develop their own research corpus. In most cases, it is necessary to first create a set with the sentences and write them down when the classification is supervised to proceed with th"
2021.hackashop-1.2,2020.emnlp-demos.6,0,0.0620667,"Missing"
amaral-etal-2014-comparative,santos-etal-2006-harem,0,\N,Missing
amaral-etal-2014-comparative,padro-etal-2010-freeling,0,\N,Missing
amaral-etal-2014-comparative,N03-1033,0,\N,Missing
amaral-etal-2014-comparative,P05-1045,0,\N,Missing
C00-2130,P99-1048,0,0.0316569,"s calls these ‘unexplanatory modifiers’; Loebner (1987) showed how these predicates may license the use of definite descriptions in an account of definite descriptions based on functionality); – a head noun taking a complement such as the fact that there is life on Earth (Hawkins calls this subclass ‘NP complements’);  the presence of restrictive modification, as in the inequities of the current land-ownership system. Our system attempts to recognize these syntactic patterns; in addition, it considers as unfamiliar some definites occurring in 4 This list was developed by hand; more recently, Bean and Riloff (1999) proposed methods for automatically extracting from a corpus such special predicates, i.e., heads that correlate well with discourse novelty.  appositive constructions (e.g., Glenn Cox, the president of Phillips Petroleum Co.);  copular constructions (e.g.,the man most likely to gain custody of all this is a career politician named David Dinkins). In our corpus study (Poesio and Vieira, 1998) we found that our subjects did better at identifying discourse-new descriptions all together (K=.68) than they did at distinguish ‘unfamiliar’ from ‘larger situation’ (Hawkins, 1978) cases (K = .63). Th"
C00-2130,J96-2004,0,0.0229313,"Missing"
C00-2130,J86-3001,0,0.270788,"Missing"
C00-2130,J97-1003,0,0.096954,"Missing"
C00-2130,M98-1007,0,0.0271505,"f the problems observed in our previous study concerning agreement between annotators, we evaluated the system both by measuring precision/recall against a ‘gold standard’ and by measuring the agreement between the annotation it produces and the annotators. 2 General Overview At the moment, the only systems engaged in semantic interpretation whose performance can be evaluated on fairly unrestricted text such as the Wall Street Journal articles are based on a shallowprocessing approach, i.e., that do not rely on extensive amounts of hand-coded commonsense knowledge (Carter, 1987; Appelt, 1995; Humphreys et al., 1998).1 Our system is of this type: it only relies on structural information, on the information provided by pre-existing lexical sources such as WordNet (Fellbaum, 1998), on minimal amounts of general hand-coded information, and on information that can be acquired automatically from a corpus. Although we believe that quantitative evaluations of the performance of a system on a large number of examples are the only true assessment of its performance, and therefore a shallow processing approach is virtually unavoidable for implemented systems until better sources of commonsense knowledge become avai"
C00-2130,P99-1047,0,0.127096,"ximate segments, generally by means of lexical density measures (Hearst, 1997) . In fact, the methods to limit the lifespan of discourse entity we considered for our system were even simpler. One type of heuristics we looked at are window-based techniques, i.e., considering as potential antecedents only the discourse entities within fixed-size windows of previous sentences, allowing however for some discourse entities to take a longer life span: we call this method LOOSE SEG MENTATION . More specifically, a discourse entity is considered as potential antecedent for a definite 2 See, however, (Marcu, 1999). description when the antecedent’s head is identical to the description’s head, and soning; for the moment, we only developed heuristic solutions to the problem, including:  the potential antecedent’s distance from the description is within the established window, or else  allowing an antecedent to match with a definite description if the premodifiers of the description are a subset of the premodifiers of the antecedent. This heuristic deals with definites which contain less information than the antecedent, such as an old Victorian house... the house, and prevents matches such as the busine"
C00-2130,E99-1001,0,0.0257662,"Missing"
C00-2130,J98-2001,1,0.832431,"tions. The system is based on the results of a corpus analysis previously reported, which showed how common discourse-new descriptions are in newspaper corpora, and identified several problems to be dealt with when developing computational methods for interpreting bridging descriptions. The annotated corpus produced in this earlier work was used to extensively evaluate the proposed techniques for matching definite descriptions with their antecedents, discourse segmentation, recognizing discourse-new descriptions, and suggesting anchors for bridging descriptions. 1 Motivation In previous work (Poesio and Vieira, 1998) we reported the results of corpus annotation experiments in which the subjects were asked to classify the uses of definite descriptions in Wall Stree Journal articles according to a scheme derived from work by Hawkins (1978) and Prince (1981) and including three classes: DIRECT ANAPHORA, DISCOURSE NEW , and BRIDGING DESCRIPTION (Clark, 1977). This study showed that about half of the time, definite descriptions are used to introduce a new entity in the discourse, rather than to refer to an object already mentioned. We also observed that our subjects didn’t always agree on the classification of"
C00-2130,M95-1017,0,\N,Missing
castilho-etal-2012-corpus,C00-1059,0,\N,Missing
castilho-etal-2012-corpus,schafer-2006-ontonerdie,0,\N,Missing
hilgert-etal-2014-building,ha-etal-2008-mutual,0,\N,Missing
hilgert-etal-2014-building,moore-2002-fast,0,\N,Missing
hilgert-etal-2014-building,J03-1002,0,\N,Missing
hilgert-etal-2014-building,I11-2003,0,\N,Missing
J00-4003,P95-1017,0,0.0946297,"Missing"
J00-4003,P98-1011,0,0.0199669,"Missing"
J00-4003,P99-1048,0,0.350022,"Missing"
J00-4003,A97-1029,0,0.0254698,"to entities introduced by proper names (such as Pinkerton Inc ... the company) are very common in newspaper articles. Processing such descriptions requires determining an entity type for each name in the text, that is, if we recognize Pinkerton Inc. as an entity of type company, we can then resolve the subsequent description the company, or even a description such as the firm by finding a synonymy relation between company and firm using WordNet. This so-called named entity recognition task has received considerable attention recently (Mani and MacMillan 1996; McDonald 1996; Paik et al. 1996; Bikel et al. 1997; Palmer and Day 1997; Wacholder and Ravin 1997; Mikheev, Moens, and Grover 1999) and was one of the tasks evaluated in the Sixth and Seventh Message Understanding Conferences. In MUC-6, 15 different systems participated in the competition (Sundheim 1995). For the version of the system discussed and evaluated here, we implemented a preliminary algorithm for named entity recognition that we developed ourselves; a more recent version of the system (Ishikawa 1998) uses the named entity recognition software developed by HCRC for the MUC-7 competition (Mikheev, Moens, and Grover 1999). WordNet cont"
J00-4003,C88-1021,0,0.0244603,"herefore either mainly theoretical or d o m a i n dependent), and systems that can be quantitatively evaluated, such as those competing on the coreference task in the Sixth and Seventh Message Understanding Conference (Sundheim 1995). We discuss these two types of work in turn. 7.1 Models Based On Commonsense Reasoning The crucial characteristic of these proposals is that they exploit hand-coded commonsense knowledge, and cannot therefore be tested on just any arbitrary text. Some of them are simply tested on texts that were especially built for the purpose of testing the system (Carter 1987; Carbonell and Brown 1988); systems like the Core Language Engine are more robust, but they have to be applied to a d o m a i n restricted enough that all relevant knowledge can be encoded by hand. 32 This p r o b l e m is also a central concern in the w o r k b y Bean a n d Riloff (1999). 584 Vieira a n d Poesio Processing Definite Descriptions Sidner's Theory of Definite Anaphora Comprehension. In her dissertation, Sidner (1979) proposed a complete theory of definite NP resolution, including detailed algorithms for resolving pronouns, anaphoric definite descriptions, and bridging descriptions. She also proposed metho"
J00-4003,J96-2004,0,0.0117352,"identity to an entity already introduced in the discourse; 7 • discourse-new: first-mention definite descriptions that denote objects not related b y shared associative k n o w l e d g e to entities already introduced in the discourse. In the second experiment w e treated all anaphoric definite descriptions as part of one class (direct anaphora + bridging (i)), and all inferrables as part of a different class (bridging (ii)), w i t h o u t significant changes in the agreement results. A g r e e m e n t a m o n g annotators was m e a s u r e d using the K statistic (Siegel and Castellan 1988; Carletta 1996). K measures agreement a m o n g k annotators over and above chance agreement (Siegel and Castellan 1988). The K coefficient of agreement is defined as: K -- P(a) - P(E) 1 - w h e r e P(A) is the p r o p o r t i o n of times the annotators agree, and P(E) the p r o p o r t i o n of times that we w o u l d expect t h e m to agree b y chance. The interpretation of K figures is an o p e n question, but in the field of content analysis, where reliability has long been an issue (Krippendorff 1980), K > 0.8 is generally taken to indicate good reliability, whereas 0.68 < K < 0.8 allows tentative conc"
J00-4003,J97-1002,0,0.0306696,"Missing"
J00-4003,M95-1004,0,0.0931765,"Missing"
J00-4003,M95-1017,0,0.0911069,"Missing"
J00-4003,P83-1007,0,0.0490437,"Missing"
J00-4003,J95-2003,0,0.660798,"Missing"
J00-4003,J97-4002,0,0.0138162,"e, the architecture of our system is motivated by the results concerning definite description use in our corpus, discussed in Poesio and Vieira (1998). In this section we briefly review the results presented in that paper. 2 In fact, it is precisely because we are interested in identifying the types of commonsense reasoning actually used in language processing that we focused on definite descriptions rather than on other types of anaphoric expressions (such as pronouns and ellipsis) that can be processed much more effectively on the basis of syntactic information alone (Lappin and Leass 1994; Hardt 1997). 540 Vieira and Poesio Processing Definite Descriptions 2.1 The Corpus We used a subset of the Penn Treebank I corpus (Marcus, Santorini, and Marcinkiewicz 1993) from the A C L / D C I CD-ROM, containing n e w s p a p e r articles from the Wall Street Journal. We divided the corpus into two parts: one, containing about 1,000 definite descriptions, was used as a source during the d e v e l o p m e n t of the system; we will refer to these texts as Corpus 1.3 The other part, containing about 400 definite descriptions, was kept aside during d e v e l o p m e n t and used for testing; we will ref"
J00-4003,P93-1023,0,0.00945209,"nding coreference chain is c h e c k e d - - t h a t is, the system's indexes and the annotated indexes do not need to be exactly the same as long as they belong to the same coreference chain. In this way, both (40a) and (40b) w o u l d be evaluated as correct answers if the corpus is annotated with the links s h o w n in (39). (39) A house1°6... The house135... The house154... coder: corer(135,106). coder: corer(154,135). (40) a. system: corer (154,135). b. system: corer(154,106). 26 An alternative method is to give fractional values to a classification depending on the number of agreements (Hatzivassiloglou and McKeown (1993). 562 Vieira and Poesio Processing Definite Descriptions In the end, we still need to check the results manually, because our annotated coreference chains are not complete: our annotators did not annotate all types of anaphoric expressions, so it may happen that the system indicates as antecedent an element outside an annotated coreference chain, such as a bare noun or possessive. In (41), for example, suppose that all references to the house are coreferential: A house1°6... The house135... His house14°... The house154... corer ( 154,140). (41) If NP 135 is indicated as the antecedent for NP 1"
J00-4003,J97-1003,0,0.0985138,"(Fox 1987; Grosz 1977; Grosz and Sidner 1986; Reichman 1985), whereas the antecedents introduced in a prior segment at the same level may be. Later in (8), for example, the housej in sentence 50 becomes inaccessible again, and in sentence 65, the text starts referring again to the house introduced in sentence 2. Automatically recognizing the hierarchical structure of texts is an unresolved problem, as it involves reasoning about intentions;14 better results have been achieved on the simpler task of ""chunking"" the text into sequences of segments, generally by means of lexical density measures (Hearst 1997; Richmond, Smith, and Amitay 1997). The methods for limiting the life span of discourse entities that we considered for our system are even simpler. One type of heuristic we looked at are windowbased techniques, i.e., considering only the antecedents within fixed-size windows of previous sentences, although we allow some discourse entities to have a longer life span: we call this method loose segmentation. More specifically, a discourse entity is considered a potential antecedent for a definite description when the antecedent's head is identical to the description's head, and • the potential"
J00-4003,M98-1007,0,0.0509034,"Missing"
J00-4003,W97-1307,0,0.0409179,"Missing"
J00-4003,J94-4002,0,0.354156,"Work As mentioned above, the architecture of our system is motivated by the results concerning definite description use in our corpus, discussed in Poesio and Vieira (1998). In this section we briefly review the results presented in that paper. 2 In fact, it is precisely because we are interested in identifying the types of commonsense reasoning actually used in language processing that we focused on definite descriptions rather than on other types of anaphoric expressions (such as pronouns and ellipsis) that can be processed much more effectively on the basis of syntactic information alone (Lappin and Leass 1994; Hardt 1997). 540 Vieira and Poesio Processing Definite Descriptions 2.1 The Corpus We used a subset of the Penn Treebank I corpus (Marcus, Santorini, and Marcinkiewicz 1993) from the A C L / D C I CD-ROM, containing n e w s p a p e r articles from the Wall Street Journal. We divided the corpus into two parts: one, containing about 1,000 definite descriptions, was used as a source during the d e v e l o p m e n t of the system; we will refer to these texts as Corpus 1.3 The other part, containing about 400 definite descriptions, was kept aside during d e v e l o p m e n t and used for testing"
J00-4003,P99-1047,0,0.0115776,"er, when matching a definite description with a potential antecedent the information provided by the prenominal and the postnominal part of the noun phrases also has to be taken into account. For example, a blue car cannot serve as the antecedent for the red car, or the house on the left for the house on the right. In our corpus, cases of antecedents that would incorrectly match by simply matching heads without regarding premodification include: (10) a. the business community ... the younger, more activist black political community; b. the population.., the voting population. 14 See, however, Marcu (1999). 550 Vieira and Poesio Processing Definite Descriptions Again, taking p r o p e r account of the semantic contribution of these premodifiers would, in general, require c o m m o n s e n s e reasoning. For the m o m e n t , w e only d e v e l o p e d heuristic solutions to the p r o b l e m , including: • allowing an antecedent to m a t c h with a definite description if the premodifiers of the description are a subset of the premodifiers of the antecedent. This heuristic deals with definites that contain less information than the antecedent, such as an old Victorian house ... the house, a n d"
J00-4003,J93-2004,0,0.0338035,"Missing"
J00-4003,E99-1001,0,0.0127753,"Missing"
J00-4003,mitkov-2000-towards,0,0.0263593,"Missing"
J00-4003,A97-1028,0,0.00783675,"uced by proper names (such as Pinkerton Inc ... the company) are very common in newspaper articles. Processing such descriptions requires determining an entity type for each name in the text, that is, if we recognize Pinkerton Inc. as an entity of type company, we can then resolve the subsequent description the company, or even a description such as the firm by finding a synonymy relation between company and firm using WordNet. This so-called named entity recognition task has received considerable attention recently (Mani and MacMillan 1996; McDonald 1996; Paik et al. 1996; Bikel et al. 1997; Palmer and Day 1997; Wacholder and Ravin 1997; Mikheev, Moens, and Grover 1999) and was one of the tasks evaluated in the Sixth and Seventh Message Understanding Conferences. In MUC-6, 15 different systems participated in the competition (Sundheim 1995). For the version of the system discussed and evaluated here, we implemented a preliminary algorithm for named entity recognition that we developed ourselves; a more recent version of the system (Ishikawa 1998) uses the named entity recognition software developed by HCRC for the MUC-7 competition (Mikheev, Moens, and Grover 1999). WordNet contains the types of a f"
J00-4003,J98-2001,1,0.0740713,"e-new descriptions in newspaper corpora. The annotated corpus was used to extensively evaluate the proposed techniquesfor matching definite descriptions with their antecedents, discourse segmentation, recognizing discourse-new descriptions, and suggesting anchorsfor bridging descriptions. 1. Introduction Most models of definite description processing p r o p o s e d in the literature tend to emphasise the anaphoric role of these elements. 1 (Heim [1982] is perhaps the best formalization of this type of theory). This approach is challenged b y the results of experiments we reported previously (Poesio and Vieira 1998), in which subjects were asked to classify the uses of definite descriptions in Wall Street Journal articles according to schemes derived from proposals b y Hawkins (1978) and Prince (1981). The results of these experiments indicated that definite descriptions are not primarily anaphoric; about half of the time they are used to introduce a new entity in the discourse. In this paper, we present an i m p l e m e n t e d system for processing definite descriptions based on the results of that earlier study. In our system, techniques for recognizing discourse-new descriptions play a role as import"
J00-4003,W97-1301,1,0.662839,"Missing"
J00-4003,W97-0305,0,0.0293658,"Missing"
J00-4003,M95-1002,0,0.11034,"ac.uk 1 We use the term definite description (Russell 1905) to indicate definite noun phrases with the definite article the, such as the car. We are not concerned with other types of definite noun phrases such as pronouns, demonstratives, or possessive descriptions. Anaphoric expressions are those linguistic expressions used to signal, evoke, or refer to previously mentioned entities. (~) 2001 Association for Computational Linguistics Computational Linguistics Volume 26, Number 4 interpretation as well, for example, at the Sixth and Seventh Message Understanding Conferences (MUC-6 and MUC-7) (Sundheim 1995; Chinchor 1997), which also included evaluations of systems on the so-called coreference task, a subtask of which is the resolution of definite descriptions. The system we present was developed to be evaluated in a quantitative fashion, as well, but because of the problems concerning agreement between annotators observed in our previous study, we evaluated the system both by measuring precision/recall against a ""gold standard,"" as done in MUC, and by measuring agreement between the annotations produced by the system and those proposed by the annotators. The decision to develop a system that c"
J00-4003,J94-2006,0,0.0489412,"Missing"
J00-4003,P99-1079,0,0.0113123,"ith Sidner's theory of local focus, as well as others such as Centering Theory (Grosz, Joshi, and Weinstein 1995), is the lack of a precise characterization of how to deal with complex sentences. Revisions and extensions of Sidner's proposal related to these problems have been proposed in Suri and McCoy (1994), and include algorithms for updating focus in complex sentences containing adjunct clauses such as before- and after-clauses. We plan to incorporate simpler focus-tracking mechanisms in future versions of the system, possibly along the lines of Azzam, Humphreys, and Gaizauskas (1998) or Tetreault (1999). 8.3.3 Theoretical Developments. We defended the importance of developing methods for identifying discourse-new descriptions, and we believe that there is still need for research into the semantics of this class; that is, what, exactly, licenses the use of a definite description to refer to a discourse-new entity? The role of premodification and postmodification should also be further examined. Postmodification is one of the most frequent features of discourse-new descriptions; additional empirical studies considering a detailed subclassification of discourse-new descriptions would give us a"
J00-4003,P97-1072,1,0.907568,"icult to decide what the intended anchor and the intended link are (Poesio and Vieira 1998). For all these reasons, this class has been the most challenging problem we have dealt with in the development of our system, and the results we have obtained so far can only be considered very preliminary. Nevertheless, we feel that trying to process these definite descriptions is the only way to discover which types of commonsense knowledge are actually needed. 4.4 Types of Bridging Descriptions Our work on bridging descriptions began with the development of a classification of bridging descriptions (Vieira and Teufel 1997) according to the kind of information needed to resolve them, rather than on the basis of the possible relations between descriptions and their anchors as is typical in the literature. This allowed us to get an estimate of what types of bridging descriptions we might expect our system to resolve. The classification is as follows: • cases based on well-defined lexical relations, such as synonymy, hypernymy, and meronymy, that can be found in a lexical database such as WordNet (Fellbaum 1998), as in theyqat . . . the living room; • bridging descriptions in which the antecedent is a proper name a"
J00-4003,M95-1005,0,0.192359,"ed by the automatic evaluation, even though all of these NPs refer to the same entity. A second consequence of the fact that the coreference chains in our standard annotation are not complete is that in the evaluation of direct anaphora resolution, we only verify if the antecedents indicated are correct; we do not evaluate how complete the coreferential chains produced by the system are. By contrast, in the evaluation of the MUC coreference task, where all types of referring expressions are considered, the resulting co-reference chains are evaluated, rather than just the indicated antecedent (Vilain et al. 1995). Even our limited notion of coreference chain was, nevertheless, very helpful in the automatic evaluation, considerably reducing the number of cases to be checked manually. 5.1.3 Measuring the Agreement of the System with the Annotators. Because the agreement between our annotators in Poesio and Vieira (1998) was often only partial, in addition to precision and recall measures, we evaluated the system's performance by measuring its agreement with the annotators using the K statistic we used in Poesio and Vieira (1998) to measure agreement among annotators. Because the proper interpretation of"
J00-4003,A97-1030,0,0.0172891,"rton Inc ... the company) are very common in newspaper articles. Processing such descriptions requires determining an entity type for each name in the text, that is, if we recognize Pinkerton Inc. as an entity of type company, we can then resolve the subsequent description the company, or even a description such as the firm by finding a synonymy relation between company and firm using WordNet. This so-called named entity recognition task has received considerable attention recently (Mani and MacMillan 1996; McDonald 1996; Paik et al. 1996; Bikel et al. 1997; Palmer and Day 1997; Wacholder and Ravin 1997; Mikheev, Moens, and Grover 1999) and was one of the tasks evaluated in the Sixth and Seventh Message Understanding Conferences. In MUC-6, 15 different systems participated in the competition (Sundheim 1995). For the version of the system discussed and evaluated here, we implemented a preliminary algorithm for named entity recognition that we developed ourselves; a more recent version of the system (Ishikawa 1998) uses the named entity recognition software developed by HCRC for the MUC-7 competition (Mikheev, Moens, and Grover 1999). WordNet contains the types of a few names--typically, of fa"
J00-4003,J90-3001,0,\N,Missing
J00-4003,C96-1084,0,\N,Missing
J00-4003,J86-3001,0,\N,Missing
J00-4003,P98-1090,1,\N,Missing
J00-4003,C98-1087,1,\N,Missing
J00-4003,C98-1011,0,\N,Missing
J00-4003,M98-1001,0,\N,Missing
J98-2001,J96-2004,0,0.679644,"ch took into account our intention of having naive speakers p e r f o r m the classification. Our experiments were also designed to assess the feasibility of a system to process definite descriptions on unrestricted text and to collect data that could be used for this implementation. For both of these reasons, the classification schemes that we tried differ in several respects from those a d o p t e d in prior corpus-based studies such as Prince (1981) and Fraurud (1990). Our study is also different from these previous ones in that measuring the agreement a m o n g annotators became an issue (Carletta 1996). For the experiments, we used a set of r a n d o m l y selected articles from the Wall Street Journal contained in the A C L / D C I CD-ROM, rather than a corpus of transcripts of spoken language corpora such as the HCRC MapTask corpus (Anderson et al. 1991) or the TRAINS corpus ( H e e m a n and Allen 1995). The main reason for this choice was 2 We will not be concerned with other cases of definite noun phrases such as pronouns, or possessive descriptions; hence the term definite description rather than the more general term definite NP. 3 The word the is by far the most common word in the B"
J98-2001,J97-1002,0,0.0489454,"Missing"
J98-2001,J86-3001,0,0.144008,"of definite description interpretation should include methods for recognizing such definites. The architecture of our own classifier (see below) is also consistent with Fraurud's hypothesis that these methods are not just used when no suitable antecedent can be found, but more extensive investigations will be needed before we can conclude that this architecture significantly outperforms other ones. The presence of such a large number of discourse-new definite descriptions is also problematic for the idea that definite descriptions are interpreted with respect to the global focus (Grosz 1977; Grosz and Sidner 1986). A significant percentage of the larger situation definite descriptions encountered in our corpus cannot be said to be in the globai focus in any significant sense: as we observed above, in many of these cases the writer seems to rely on the reader's capability to add a new object such as the Illinois Commerce Commission to her or his model of the world, rather than expecting that object to be already present. 5.2 A (Semi)Automatic Classifier As already mentioned, we are in the course of implementing a system capable of performing the classification task semiautomatically (Vieira 1998). This"
J98-2001,T87-1035,0,0.134807,"scuss our two classification experiments in Sections 3 and 4. 2. Towards a Classification Scheme: Linguistic Theories of Definite Descriptions When looking for an annotation scheme for definite descriptions, one is faced with a wide range of options. At one end of the spectrum there are mostly descriptive lists of definite description uses, such as those in Christophersen (1939) and Hawkins (1978), whose only goal is to assign a classification to all uses of definite descriptions. At the other end, there are highly developed formal analyses, such as Russell (1905), Heim (1982), L6bner (1985), Kadmon (1987), Neale (1990), Barker (1991), and Kamp and Reyle (1993), in which the compositional contribution of definite descriptions to the meaning of an utterance, as well as their truth-conditional properties, are spelled out in detail. These more formal analyses are concerned with questions such as the quantificational or nonquantificational status of definite descriptions and the proper treatment of presuppositions, but tend to concentrate on a subset of the full range of definite description use. Among the more developed semantic analyses, some identify uniqueness as the defining property of defini"
J98-2001,J93-2004,0,0.0304668,"Missing"
J98-2001,W97-1301,1,0.503317,"Missing"
L16-1023,J14-4004,0,0.0528176,"Missing"
L16-1023,freitas-etal-2010-second,0,0.0679096,"Missing"
L16-1023,C14-1070,0,0.0283788,"Missing"
L16-1023,garcia-gamallo-2014-multilingual,0,0.0453706,"Missing"
L16-1023,D14-1222,0,0.0528434,"Missing"
L16-1023,J13-4004,0,0.0766431,"Missing"
L16-1023,Q15-1029,0,0.0292082,"Missing"
L16-1023,W11-1901,0,0.0769348,"Missing"
L16-1023,S10-1001,0,0.064241,"Missing"
L16-1023,M95-1005,0,0.25822,"Missing"
L16-1301,P08-1004,0,0.450153,"ess of getting structured data from unstructured information in the text (Bach and Badaskar, 2007; Jurafsky and Martin, 2009). After this structured information can be used by a wide range of NLP applications. Usually, IE can be regarded as a pipeline process, in which some type of information is extracted at each step. Relation Extraction (RE) is one of the stages of IE, which aims to identify and classify semantic relations that occur between entities recognized in a given text (Bach and Badaskar, 2007; Jurafsky and Martin, 2009). The two major types of RE are closed domain and open domain (Banko and Etzioni, 2008): closeddomain RE systems consider only a closed set of relations between two arguments, while open-domain RE systems do not need a pre-specified definition of the relation. Currently, there are plenty of systems for RE from unstructured data and there are different methods for dealing with this task. Among supervised methods stands Conditional Random Fields (CRF), which are very powerful for segmenting and labeling sequential data (Lafferty et al., 2001). CRF have now become almost a standard for the task of Named Entity Recognition (NER) (McCallum and Li, 2003), and have more recently been a"
L16-1301,P07-1073,0,0.121072,"Missing"
L16-1301,N06-1038,0,0.170669,"nly a closed set of relations between two arguments, while open-domain RE systems do not need a pre-specified definition of the relation. Currently, there are plenty of systems for RE from unstructured data and there are different methods for dealing with this task. Among supervised methods stands Conditional Random Fields (CRF), which are very powerful for segmenting and labeling sequential data (Lafferty et al., 2001). CRF have now become almost a standard for the task of Named Entity Recognition (NER) (McCallum and Li, 2003), and have more recently been applied to the task of RE from text (Culotta et al., 2006; Banko and Etzioni, 2008; Wu and Weld, 2010; Li et al., 2011; Collovini et al., 2014). In this paper, we evaluated a CRF classifier in two scenarios: the extraction of any relation descriptor occurring between named entities (Organisation, Person and Place categories), and the extraction of relation descriptors expressing pre-defined types of relations between these entities (“affiliation” and “placement” relations). We define a relation descriptor as the text chunks that describe the explicit relation, occurring between a pair of named entities in the sentence. For example, we have the relat"
L16-1301,D11-1142,0,0.0404103,"lation types from Portuguese Wikipedia, such as “locatedin”, “successor-of”, and others. For all Portuguese works above, the set of relations was previously defined (closed-domain RE). There are few RE systems which apply Open IE for Portuguese language. A multilingual dependency-based Open IE system (DepOE) has been proposed in (Gamallo et al., 2012), it was used to extract triples from the Wikipedia in four languages: Portuguese, Spanish, Galician and English. In (Santos and Pinheiro, 2015), the RePort system is presented, it is a method of Open IE for Portuguese based on the ReVerb system (Fader et al., 2011) for English. In previous research (Collovini et al., 2014), we extract relations between named entities (NEs) in the Organization domain, using CRF for Portuguese. We evaluated different feature configurations for CRF based of lexical, syntactic and semantic information. In this work, we test the same CRF on open and closed RE tasks for Portuguese. We extract any relation descriptors that express any type of relation between the NEs, and two pre-defined types of relations (“employment” and “placement”) between these entities. 3. Words Hugo Dom´ech , professor de o Universidade Jaume de Castel"
L16-1301,W12-0702,0,0.0598985,"Missing"
L16-1301,I11-1044,0,0.087439,"main RE systems do not need a pre-specified definition of the relation. Currently, there are plenty of systems for RE from unstructured data and there are different methods for dealing with this task. Among supervised methods stands Conditional Random Fields (CRF), which are very powerful for segmenting and labeling sequential data (Lafferty et al., 2001). CRF have now become almost a standard for the task of Named Entity Recognition (NER) (McCallum and Li, 2003), and have more recently been applied to the task of RE from text (Culotta et al., 2006; Banko and Etzioni, 2008; Wu and Weld, 2010; Li et al., 2011; Collovini et al., 2014). In this paper, we evaluated a CRF classifier in two scenarios: the extraction of any relation descriptor occurring between named entities (Organisation, Person and Place categories), and the extraction of relation descriptors expressing pre-defined types of relations between these entities (“affiliation” and “placement” relations). We define a relation descriptor as the text chunks that describe the explicit relation, occurring between a pair of named entities in the sentence. For example, we have the relation descriptor “professor at” between the Person named entity"
L16-1301,W03-0430,0,0.0131248,"osed domain and open domain (Banko and Etzioni, 2008): closeddomain RE systems consider only a closed set of relations between two arguments, while open-domain RE systems do not need a pre-specified definition of the relation. Currently, there are plenty of systems for RE from unstructured data and there are different methods for dealing with this task. Among supervised methods stands Conditional Random Fields (CRF), which are very powerful for segmenting and labeling sequential data (Lafferty et al., 2001). CRF have now become almost a standard for the task of Named Entity Recognition (NER) (McCallum and Li, 2003), and have more recently been applied to the task of RE from text (Culotta et al., 2006; Banko and Etzioni, 2008; Wu and Weld, 2010; Li et al., 2011; Collovini et al., 2014). In this paper, we evaluated a CRF classifier in two scenarios: the extraction of any relation descriptor occurring between named entities (Organisation, Person and Place categories), and the extraction of relation descriptors expressing pre-defined types of relations between these entities (“affiliation” and “placement” relations). We define a relation descriptor as the text chunks that describe the explicit relation, occ"
L16-1301,P10-1013,0,0.504283,"ents, while open-domain RE systems do not need a pre-specified definition of the relation. Currently, there are plenty of systems for RE from unstructured data and there are different methods for dealing with this task. Among supervised methods stands Conditional Random Fields (CRF), which are very powerful for segmenting and labeling sequential data (Lafferty et al., 2001). CRF have now become almost a standard for the task of Named Entity Recognition (NER) (McCallum and Li, 2003), and have more recently been applied to the task of RE from text (Culotta et al., 2006; Banko and Etzioni, 2008; Wu and Weld, 2010; Li et al., 2011; Collovini et al., 2014). In this paper, we evaluated a CRF classifier in two scenarios: the extraction of any relation descriptor occurring between named entities (Organisation, Person and Place categories), and the extraction of relation descriptors expressing pre-defined types of relations between these entities (“affiliation” and “placement” relations). We define a relation descriptor as the text chunks that describe the explicit relation, occurring between a pair of named entities in the sentence. For example, we have the relation descriptor “professor at” between the Pe"
L16-1324,freitas-etal-2010-second,0,0.192793,"br), renata.vieira@pucrs.br Abstract This paper presents Summ-it++, an enriched version the Summ-it corpus. In this new version, the corpus has received new semantic layers, named entity categories and relations between named entities, adding to the previous coreference annotation. In addition, we change the original Summ-it format to SemEval. Keywords: Coreference, Named entities, Semantic relations 1. Introduction 2. Coreference resolution is an important challenge for language processing. Currently for Portuguese there are three main corpora with some kind of coreference annotation: HAREM (Freitas et al., 2010), Garcia’s corpus (Garcia and Gamallo, 2014) and Summ-it (Collovini et al., 2007). HAREM contains annotation of named entities and their identity relations, its main purpose was the evaluation of Named Entity Recognition (NER) systems. The corpus contains manually annotated named entities distributed in ten semantic categories. Relations between these named entities have also been annotated manually, in four types: identity, inclusion, placement and other. Garcia’s corpus contains coreference annotation for person entities. Summ-it contains noun phrase coreference annotation, being thus the co"
L16-1324,P11-2050,0,0.0187703,"as the CoNLL scorer1 might be used. This tool generates widely used coreference metrics, as described in (Pradhan et al., 2011). 2.5. ID: Token ID in sentence order; Token: the word or multiword; Relation Extraction (RE) is the task of identifying and classifying semantic relations that occur between entities in a given text (Jurafsky and Martin, 2009). Relation extraction can be useful in many NLP tasks, in particular, for Coreference Resolution, the focus of which is to determine antecedent chains. The identification of these chains in a text can improve the process of relation extraction (Gabbard et al., 2011). In the proposed corpus, we include relations of any type (as in open RE) occurring between named entities of the following categories: Organization, Person and Place. For that, we use the CRF classifier, proposed in (Collovini et al., 2014). The annotations were provided automatically, but manually revised. We define a relation descriptor as the text chunks that describe the explicit relation occurring between a pair of named entities in the sentence. For example: in sentence (a), we have the relation descriptor “de” (of ) that occurs between the named entities “Miguel Guerra” and “UFSC”, in"
L16-1324,garcia-gamallo-2014-multilingual,0,0.0190512,"s paper presents Summ-it++, an enriched version the Summ-it corpus. In this new version, the corpus has received new semantic layers, named entity categories and relations between named entities, adding to the previous coreference annotation. In addition, we change the original Summ-it format to SemEval. Keywords: Coreference, Named entities, Semantic relations 1. Introduction 2. Coreference resolution is an important challenge for language processing. Currently for Portuguese there are three main corpora with some kind of coreference annotation: HAREM (Freitas et al., 2010), Garcia’s corpus (Garcia and Gamallo, 2014) and Summ-it (Collovini et al., 2007). HAREM contains annotation of named entities and their identity relations, its main purpose was the evaluation of Named Entity Recognition (NER) systems. The corpus contains manually annotated named entities distributed in ten semantic categories. Relations between these named entities have also been annotated manually, in four types: identity, inclusion, placement and other. Garcia’s corpus contains coreference annotation for person entities. Summ-it contains noun phrase coreference annotation, being thus the corpus with the most complete coreference chai"
L16-1324,W11-1901,0,0.0734916,"mber) of each word; Coreference Coreference basically consists of finding different references to a same entity in a text. In (a) the noun phrases “o agrônomo ” “the agronomist ” and “Miguel Guerra” “ Guerra” are considered coreferent, in other words, they belong to the same coreference chain. The proposed corpus presents the manual annotation of coreference previously provided by Summ-it now in the SemEval format, which is more adequate for evaluation purposes, since available tools such as the CoNLL scorer1 might be used. This tool generates widely used coreference metrics, as described in (Pradhan et al., 2011). 2.5. ID: Token ID in sentence order; Token: the word or multiword; Relation Extraction (RE) is the task of identifying and classifying semantic relations that occur between entities in a given text (Jurafsky and Martin, 2009). Relation extraction can be useful in many NLP tasks, in particular, for Coreference Resolution, the focus of which is to determine antecedent chains. The identification of these chains in a text can improve the process of relation extraction (Gabbard et al., 2011). In the proposed corpus, we include relations of any type (as in open RE) occurring between named entities"
L16-1324,S10-1001,0,0.40525,"hrase coreference annotation, being thus the corpus with the most complete coreference chains. It was semi-automatically annotated with morphosyntactic information, and manually annotated with coreference. Besides coreference the texts were also manually annotated with rhetorical relations. Also, for each text, there are manual and automatically generated summaries. In this paper we describe Summ-it++, an enriched Version of Summ-it. The proposed new version adds two new annotation layers: named entities and relations between named entities. In addition, the format was changed to the SemEval (Recasens et al., 2010), a wellknown and widely used format. Therefore we provide a corpus that integrates different annotation layers, in a format that can be evaluated according to usual evaluation metrics for coreference, making use of available tools that compute such metrics. So, with this resource we aim to contribute to further Portuguese NLP research. The paper is organized as follows: Section 2 describes the new Summ-it++ corpus, as well as its annotation scheme; Section 3 presents the process of the corpus generation; Section 4 describes the conversion from corpus to SemEval form; and finally, Section 5 pr"
L18-1105,buck-etal-2014-n,0,0.069345,"Missing"
L18-1105,D09-1150,0,0.0347056,",461,799 1,257,109 1,133,302 723,995 145,325 98,633 65,303 19,162 Sentences 86,803,291 79,182,754 180,688 145,370,673 45,457,774 1,988,621 83,509 37,419 44,381 8,752 4,931 9,329 653 Avg W/S 24.72 4.31 19.50 19.01 21.97 16.32 15.05 30.28 16.31 16.60 20.00 7.00 29.34 Authorship Yes Yes Yes No No No No No No No No No No Table 1: Brazilian Portuguese Corpora and has been used in many research works. The work of (Mishne and others, 2005) collected more than 815.494 posts regarding their authors’ mood classification, where 10 posts for each of the 40 most frequent moods were annotated. Quan’s work (Quan and Ren, 2009) created a finegrained annotation scheme of emotions in a Chinese corpus containing 1,487 blogs. To the best of our knowledge, there is no previous work addressing a Portuguese corpora containing an extensible information about the authors based on internet blogs. The BlogSet-BR collection is the first large corpus with information about the profile of the authors for the Portuguese language. Additionally, the dataset contains information that allows analyzing the social network structure. In the next Section, we present the process of developing BlogSetBR. 3. Corpus Construction The corpus co"
L18-1105,L16-1443,0,0.0118384,"survey conducted with authors; section 6. presents the conclusions and suggestions for further work. 2. Background Extract content from the web is a constant effort by academic and industry researchers. Such data sets allow the accomplishment of many different tasks, such as relevance ranking for online documents and several other machine learning tasks(Woloszyn et al., 2016; Woloszyn et al., 2017). For instance, the Common Crawl project maintains an open repository of web crawl data that can be accessed and analyzed by any research group2 . This corpus has been used to build language models (Roziewski and Stokowiec, 2016), and to analyze word frequencies (Buck et al., 2014). However, this project does not contain structured information to allow a social network analyses about the authors. This gap is filled by datasets built with blog content, enabling analyses of web data together with user relation and temporal characteristics. The TREC Conference organizers built a blog corpus for research purposes (Macdonald and Ounis, 2006) making 100,649 blogs in the English language available for TREC shared tasks. The ICWSM 2009 Spinn3r dataset (Burton et al., 2009) is another example of corpora extracted from blogs. I"
L18-1105,hartmann-etal-2014-large,0,0.0240281,"Missing"
P97-1072,J98-2001,1,\N,Missing
poesio-etal-2002-acquiring,J98-2001,1,\N,Missing
poesio-etal-2002-acquiring,W97-1301,1,\N,Missing
poesio-etal-2002-acquiring,E99-1001,0,\N,Missing
poesio-etal-2002-acquiring,P00-1051,0,\N,Missing
poesio-etal-2002-acquiring,P00-1023,0,\N,Missing
poesio-etal-2002-acquiring,J93-2002,0,\N,Missing
poesio-etal-2002-acquiring,J92-4003,0,\N,Missing
poesio-etal-2002-acquiring,P93-1032,0,\N,Missing
poesio-etal-2002-acquiring,J94-4002,0,\N,Missing
poesio-etal-2002-acquiring,P97-1072,1,\N,Missing
poesio-etal-2002-acquiring,J01-4003,0,\N,Missing
poesio-etal-2002-acquiring,P99-1008,0,\N,Missing
poesio-etal-2002-acquiring,J00-4003,1,\N,Missing
poesio-etal-2002-acquiring,P98-2143,0,\N,Missing
poesio-etal-2002-acquiring,C98-2138,0,\N,Missing
salmon-alt-vieira-2002-nominal,isard-etal-2000-mate,0,\N,Missing
salmon-alt-vieira-2002-nominal,J98-2001,1,\N,Missing
salmon-alt-vieira-2002-nominal,J90-3001,0,\N,Missing
salmon-alt-vieira-2002-nominal,J00-4005,0,\N,Missing
salmon-alt-vieira-2002-nominal,C88-1021,0,\N,Missing
salmon-alt-vieira-2002-nominal,T78-1012,0,\N,Missing
salmon-alt-vieira-2002-nominal,J78-3018,0,\N,Missing
salmon-alt-vieira-2002-nominal,A00-1020,0,\N,Missing
salmon-alt-vieira-2002-nominal,J95-2003,0,\N,Missing
salmon-alt-vieira-2002-nominal,J94-4002,0,\N,Missing
salmon-alt-vieira-2002-nominal,P97-1072,1,\N,Missing
salmon-alt-vieira-2002-nominal,J96-2004,0,\N,Missing
salmon-alt-vieira-2002-nominal,J00-4003,1,\N,Missing
salmon-alt-vieira-2002-nominal,M98-1029,0,\N,Missing
trojahn-etal-2010-api,trojahn-etal-2008-framework,1,\N,Missing
W03-1902,P01-1040,0,0.350762,"and Strube, 2001), for manual annotation of coreference, and we are developing a tool for automatic coreference resolution. Our tool deals with XML encoding provided by MMAX and syntactic information for Portuguese and French encoded in XML. In order to be able to share the resources being built, we are relating our model with proposed standards. In Section 2 we present previous annotation formats that we dealt with. In Section 3 we give an overview of the work in COMMOn-REFs. Section 4 relates our current model with the standards recently proposed (Ide and Romary, 2002; Ide and Romary, 2003; Ide and Romary, 2001). Section 5 describes our tool for coreference resolution. A discussion on the problems we face with our annotation model is presented in Section 6. 2 Previous work Our first annotation schemes were Prolog lists of treebank sentences and their noun phrases (NPs), as shown in Figure 1. The lists were extracted from Lisp lists of the Penn Treebank. These lists were manipulated in our experiments on coreference annotation and resolution. The results of coreference annotation were lists of Prolog facts dcc(Index1,Index2,Code) as shown in Figure 2. Index1 refers to the sequential numbering of defin"
W03-1902,ide-romary-2002-standards,0,0.430356,"ol for multimodal annotation in XML (Müller and Strube, 2001), for manual annotation of coreference, and we are developing a tool for automatic coreference resolution. Our tool deals with XML encoding provided by MMAX and syntactic information for Portuguese and French encoded in XML. In order to be able to share the resources being built, we are relating our model with proposed standards. In Section 2 we present previous annotation formats that we dealt with. In Section 3 we give an overview of the work in COMMOn-REFs. Section 4 relates our current model with the standards recently proposed (Ide and Romary, 2002; Ide and Romary, 2003; Ide and Romary, 2001). Section 5 describes our tool for coreference resolution. A discussion on the problems we face with our annotation model is presented in Section 6. 2 Previous work Our first annotation schemes were Prolog lists of treebank sentences and their noun phrases (NPs), as shown in Figure 1. The lists were extracted from Lisp lists of the Penn Treebank. These lists were manipulated in our experiments on coreference annotation and resolution. The results of coreference annotation were lists of Prolog facts dcc(Index1,Index2,Code) as shown in Figure 2. Index"
W03-1902,J94-4002,0,0.0105037,"rd_3&quot;/&gt; &lt;struct id=&quot;s8&quot; type=&quot;v&quot; rel=&quot;h&quot; ref=&quot;word_4&quot;/&gt; &lt;/struct&gt; &lt;struct id=&quot;s9&quot; type=&quot;NP&quot; rel=&quot;acc&quot; ref=&quot;word_5..word_6&quot;&gt; &lt;struct id=&quot;s10&quot; type=&quot;art&quot; rel=&quot;n-mod&quot; ref=&quot;word_5&quot;/&gt; &lt;struct id=&quot;s11&quot; type=&quot;n&quot; rel=&quot;h&quot; ref=&quot;word_6&quot;/&gt; &lt;/struct&gt; &lt;/struct&gt; ... &lt;/struct&gt; (b) Figure 7: Chunks file. POS Words Chunks A B Anaphor selection Candidates selection R1 R2 ure 10(a). Figure 10(b) represents the corresponding VAML encoding for the &lt;anaphor&gt; elements. The heuristics to be applied to resolve coreference are based on previous studies about resolution of referring expressions (Vieira and Poesio, 2000; Lappin and Leass, 1994; Strube et al., 2002) and they are not discussed here. The output is the last step in the process and it is also played by a stylesheet that translates the &lt;anaphor&gt; nodes into &lt;markable&gt; ones, so the results can be visualized using the MMAX tool. 6 Discussion Rn RHB C Markables generation Markables Figure 8: Anaphora resolution design. al., 1995), and all heuristics can access the input files when necessary. Our tool strategy follows four main steps: anaphor selection, candidates selection, resolution, and output generation. Two new intermediate annotation levels are generated: the anaphor e"
W03-1902,J98-2001,1,0.832912,"2 Previous work Our first annotation schemes were Prolog lists of treebank sentences and their noun phrases (NPs), as shown in Figure 1. The lists were extracted from Lisp lists of the Penn Treebank. These lists were manipulated in our experiments on coreference annotation and resolution. The results of coreference annotation were lists of Prolog facts dcc(Index1,Index2,Code) as shown in Figure 2. Index1 refers to the sequential numbering of definite descriptions; Index2 refers to the sequential numbering of noun phrases; and Code refers to their classification, according to discourse status (Poesio and Vieira, 1998). For some of them there were also facts [S,[NP,the,squabbling,[PP,within,[NP,the, Organization,[PP,of,[NP,Petroleum,Exporting, Countries]]]]],[VP,seems,[PP,under, [NP,control]],[PP,for,now]].]. STA:fcl P:v-fin(’ser’ PR 3P IND) São SC:adj(’remoto’ F P) remotas SUBJ:np =&gt;N:art(’o’ &lt;artd&gt; F P) as [NP,Petroleum,Exporting,Countries]. =H:n(’chance’ F P) chances =N&lt;:pp [NP,the,Organization, ==H:prp(’de’) de [PP,of,[NP,Petroleum,Exporting,Countries]]]. ==P&lt;:np ===H:n(’aprovação’ F S) aprovação [NP,the,squabbling,[PP,within, .... [NP,the,Organization... [NP,as,[N,chances],[PP,de, [NP,[N,aprovacao]]]]"
W03-1902,P97-1072,1,0.823336,"Missing"
W03-1902,salmon-alt-vieira-2002-nominal,1,0.824556,"obtained for English. However, the genericity of the Portuguese resolver and annotated data still raised the same re-usability problems as for English, since the encoding format had not evolved. ddsr(Index1,Index2,Code,Antecedent) 3 COMMOn-REFs [NP,[N,aprovacao]] Figure 3: PALAVRAS output. and Portuguese). Therefore, we have to share corpora and tools, initially available under different formats. We adopted MMAX3 as our manual annotation tool. With MMAX we could annotate our corpus according to our theoretical principles. The following corpus studies were developed with the aid of the tool: (Salmon-Alt and Vieira, 2002; Vieira et al., 2002b; Vieira et al., 2002a). In these studies, our annotation targets were manually marked and coreference information was added to them according to subjects’ analysis of the texts. We are currently developing a coreference resolution tool on the basis of XML files and XSL scripts. The tool manipulates several levels of linguistic information. Parsing information has been provided by the PALAVRAS parser. The parser output is transformed into two XML files: one with POS and another with syntactic information (chunks). Coreference information, manually annotated with MMAX (mar"
W03-1902,W02-1040,0,0.021334,"type=&quot;v&quot; rel=&quot;h&quot; ref=&quot;word_4&quot;/&gt; &lt;/struct&gt; &lt;struct id=&quot;s9&quot; type=&quot;NP&quot; rel=&quot;acc&quot; ref=&quot;word_5..word_6&quot;&gt; &lt;struct id=&quot;s10&quot; type=&quot;art&quot; rel=&quot;n-mod&quot; ref=&quot;word_5&quot;/&gt; &lt;struct id=&quot;s11&quot; type=&quot;n&quot; rel=&quot;h&quot; ref=&quot;word_6&quot;/&gt; &lt;/struct&gt; &lt;/struct&gt; ... &lt;/struct&gt; (b) Figure 7: Chunks file. POS Words Chunks A B Anaphor selection Candidates selection R1 R2 ure 10(a). Figure 10(b) represents the corresponding VAML encoding for the &lt;anaphor&gt; elements. The heuristics to be applied to resolve coreference are based on previous studies about resolution of referring expressions (Vieira and Poesio, 2000; Lappin and Leass, 1994; Strube et al., 2002) and they are not discussed here. The output is the last step in the process and it is also played by a stylesheet that translates the &lt;anaphor&gt; nodes into &lt;markable&gt; ones, so the results can be visualized using the MMAX tool. 6 Discussion Rn RHB C Markables generation Markables Figure 8: Anaphora resolution design. al., 1995), and all heuristics can access the input files when necessary. Our tool strategy follows four main steps: anaphor selection, candidates selection, resolution, and output generation. Two new intermediate annotation levels are generated: the anaphor entities (represented b"
W03-1902,J00-4003,1,0.833609,"ype=&quot;v&quot; rel=&quot;aux&quot; ref=&quot;word_3&quot;/&gt; &lt;struct id=&quot;s8&quot; type=&quot;v&quot; rel=&quot;h&quot; ref=&quot;word_4&quot;/&gt; &lt;/struct&gt; &lt;struct id=&quot;s9&quot; type=&quot;NP&quot; rel=&quot;acc&quot; ref=&quot;word_5..word_6&quot;&gt; &lt;struct id=&quot;s10&quot; type=&quot;art&quot; rel=&quot;n-mod&quot; ref=&quot;word_5&quot;/&gt; &lt;struct id=&quot;s11&quot; type=&quot;n&quot; rel=&quot;h&quot; ref=&quot;word_6&quot;/&gt; &lt;/struct&gt; &lt;/struct&gt; ... &lt;/struct&gt; (b) Figure 7: Chunks file. POS Words Chunks A B Anaphor selection Candidates selection R1 R2 ure 10(a). Figure 10(b) represents the corresponding VAML encoding for the &lt;anaphor&gt; elements. The heuristics to be applied to resolve coreference are based on previous studies about resolution of referring expressions (Vieira and Poesio, 2000; Lappin and Leass, 1994; Strube et al., 2002) and they are not discussed here. The output is the last step in the process and it is also played by a stylesheet that translates the &lt;anaphor&gt; nodes into &lt;markable&gt; ones, so the results can be visualized using the MMAX tool. 6 Discussion Rn RHB C Markables generation Markables Figure 8: Anaphora resolution design. al., 1995), and all heuristics can access the input files when necessary. Our tool strategy follows four main steps: anaphor selection, candidates selection, resolution, and output generation. Two new intermediate annotation levels are"
W03-1902,W97-1301,1,\N,Missing
W04-0706,P99-1048,0,0.0168001,"are a proper name. 6 Implementing heuristics for indirect anaphora in ART Our heuristics were implemented as an XSL stylesheet on the basis of the Anaphora Resolution Tool (ART) (Vieira et al., 2003). The tool integrates a set of heuristics corresponding to one or more stylesheets to resolve different sorts of anaphora. The heuristics may be applied in a sequence defined by the user. As resolving direct anaphoric descriptions (the ones where anaphor and antecedent have the same head noun) is a much simpler problem with high performance rates as shown in previous results (Vieira et al., 2000; Bean and Riloff, 1999), these heuristics should be applied first in a system that resolves definite descriptions. In this work, however, we decided to consider for the experiments just the anaphoras that were previously annotated as indirect and check if the proposed heuristic is able to find the correct antecedent. ART allows the user to define the set of anaphors to be resolved, in our case they are selected from previously classified definite descriptions. The stylesheet for indirect anaphora takes as input this list of indirect anaphors, a list of the candidates and the similarity lists. We consider all NPs in"
W04-0706,W03-2607,0,0.49821,"s have semantically related head nouns (instead of same head nouns), which we call indirect anaphora. We applied a lexical acquisition technique (Gasperin, 2001) over Portuguese parsed corpora to automatically identify semantically similar words. After that, we made use of this lexical knowledge to resolve the coreferent definite descriptions where the head-noun of the anaphor is different from the head-noun of its antecedent. Previous work on anaphoric resolution of English texts has used acquired lexical knowledge in different ways, examples are (Poesio et al., 2002; Schulte im Walde, 1997; Bunescu, 2003). This paper is organised as follows. The next section explain our notion of indirect anaphora. Section 3 details the tools and techniques used to the construction of our lexical resource. Section 4 presents our heuristic for solving the indirect anaphors on the basis of such resource. Section 5 details the corpus we are using for evaluating the proposed heuristics. Section 6 reports the implementation of the heuristic and in Section 7 we present our experiments over Portuguese annotated corpora. In Section 8 we discuss our results and compare them to previous works. Finally, Section 9 present"
W04-0706,J98-2001,1,0.790207,"nouns in written discourse. On the other hand, it might be just coreferent, in the sense that the entity has been mentioned before in the text. In this work, we focus on the expressions that are anaphoric and coreferent, and restricting even more, just the indirect cases, when the antecedent headnoun and the anaphor head-noun are not same but semantically related. To clarify what we mean by indirect anaphora, we detail the classification we adopted in our previous work (Vieira et al., 2002; Vieira et al., 2003). Our classes of analyses were based on the analyses of English texts presented in (Poesio and Vieira, 1998), with the difference that we divided the Bridging class of their analyses into two different classes, separating coreferent (Indirect Anaphora) and noncoreferent (Other Anaphora) cases. Each definite description (d) is classified into one of the following four classes: 1. Direct anaphora: d corefers with a previous expression a; d and a have the same nominal head: a. A Comissão tem conhecimento do livro... (the Commission knows the book) d. a Comissão constata ainda que o livro não se debruça sobre a actividade das várias... (the Commission remarks that the book ignores the activity of variou"
W04-0706,poesio-etal-2002-acquiring,1,0.927218,"lly the cases where the coreferent expressions have semantically related head nouns (instead of same head nouns), which we call indirect anaphora. We applied a lexical acquisition technique (Gasperin, 2001) over Portuguese parsed corpora to automatically identify semantically similar words. After that, we made use of this lexical knowledge to resolve the coreferent definite descriptions where the head-noun of the anaphor is different from the head-noun of its antecedent. Previous work on anaphoric resolution of English texts has used acquired lexical knowledge in different ways, examples are (Poesio et al., 2002; Schulte im Walde, 1997; Bunescu, 2003). This paper is organised as follows. The next section explain our notion of indirect anaphora. Section 3 details the tools and techniques used to the construction of our lexical resource. Section 4 presents our heuristic for solving the indirect anaphors on the basis of such resource. Section 5 details the corpus we are using for evaluating the proposed heuristics. Section 6 reports the implementation of the heuristic and in Section 7 we present our experiments over Portuguese annotated corpora. In Section 8 we discuss our results and compare them to pr"
W04-0706,salmon-alt-vieira-2002-nominal,1,0.894415,"Missing"
W04-0706,J00-4005,0,0.0247854,"Missing"
W04-0707,P99-1048,0,0.632695,"Missing"
W04-0707,J94-4002,0,0.487605,"role, but we feel that evaluating DN detectors in conjunction with highperforming systems would give a better idea of the improvements that one may hope to achieve. 3 Do Discourse-New Detectors Help? Preliminary Evaluations Vieira and Poesio did not test their system without DN-detection, but Ng and Cardie’s results indicate that DN detection does improve results, if not dramatically, provided that the same_head test is run first–although their DN detector does not appear to improve results for pronouns, the one category for which detection of non-anaphoricity has been shown to be essential (Lappin and Leass, 1994). In order to evaluate how much improvement can we expect by just improving the DN detector, we did a few preliminary evaluations both with a reimplementation of Vieira and Poesio’s algorithm which does not include a discourse-new detector, running over treebank text as the original algorithm, and with a simple statistical coreference resolver attempting to resolve all anaphoric expressions and running over unparsed text, using Uryupina’s features for discourse-new detection, and over the same corpus used by Ng and Cardie (MUC-7). 3.1 How much does DN-detection help the Vieira / Poesio algorit"
W04-0707,J93-2004,0,0.0243492,"Missing"
W04-0707,P98-2143,0,0.162133,"detector, running over treebank text as the original algorithm, and with a simple statistical coreference resolver attempting to resolve all anaphoric expressions and running over unparsed text, using Uryupina’s features for discourse-new detection, and over the same corpus used by Ng and Cardie (MUC-7). 3.1 How much does DN-detection help the Vieira / Poesio algorithm? GUITAR (Poesio and Alexandrov-Kabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkov’s algorithm for pronoun resolution (Mitkov, 1998). It is implemented in Java, takes its input in XML format and returns as output its input augmented with the anaphoric relations it has discovered. GUITAR has been implemented in such a way as to be fully modular, making it possible, for example, to replace the DD resolution method with alternative implementations. It includes a pre-processor incorporating a chunker so that it can run over both hand-parsed and raw text. A version of GUITAR without the DN detection aspects of the Vieira / Poesio algorithm was evaluated on the GNOME corpus (Poesio, 2000; Poesio et al., 2004), which contains 554"
W04-0707,mitkov-2000-towards,0,0.0225374,"systems do not achieve very good results on pronoun and definite description resolution in comparison with specialized algorithms: e.g., although Ng and Cardie’s best version achieves F=65.8 on all anaphoric expressions, it only achieves F=29.6 for definite descriptions (cfr. Vieira and Poesio’s best result of F=77), and F=28.2 for pronouns (as opposed to results as high as F=80 obtained by the pronoun resolution algorithms evaluated in (Tetreault, 2001)). Clearly these systems can only be properly compared by evaluating them all on the same corpora and the same data, and discussion such as (Mitkov, 2000) suggest caution in interpreting some of the results discussed in the literature as pre- and postprocessing often plays a crucial role, but we feel that evaluating DN detectors in conjunction with highperforming systems would give a better idea of the improvements that one may hope to achieve. 3 Do Discourse-New Detectors Help? Preliminary Evaluations Vieira and Poesio did not test their system without DN-detection, but Ng and Cardie’s results indicate that DN detection does improve results, if not dramatically, provided that the same_head test is run first–although their DN detector does not"
W04-0707,C02-1139,0,0.645786,"Missing"
W04-0707,P02-1014,0,0.337227,"Missing"
W04-0707,J98-2001,1,0.872377,"Missing"
W04-0707,J04-3003,1,0.833733,"Missing"
W04-0707,poesio-2000-annotating,1,0.842899,"tkov’s algorithm for pronoun resolution (Mitkov, 1998). It is implemented in Java, takes its input in XML format and returns as output its input augmented with the anaphoric relations it has discovered. GUITAR has been implemented in such a way as to be fully modular, making it possible, for example, to replace the DD resolution method with alternative implementations. It includes a pre-processor incorporating a chunker so that it can run over both hand-parsed and raw text. A version of GUITAR without the DN detection aspects of the Vieira / Poesio algorithm was evaluated on the GNOME corpus (Poesio, 2000; Poesio et al., 2004), which contains 554 definite descriptions, of which 180 anaphoric, and 305 third-person pronouns, of which 217 anaphoric. The results for definite descriptions over hand-parsed text are shown in Table 6. Total 180 Res 182 Corr 121 NM 43 WM 16 SM 45 R 67.2 P 66.5 F 66.8 Table 6: Evaluation of the GUITAR system without DN detection over a hand-annotated treebank GUITAR without a DN recognizer takes 182 DD s (Res) as anaphoric, resolving 121 of them correctly (Corr); of the 182 DDs it attempts to resolve, only 16 are incorrectly resolved (WM); almost three times that number"
W04-0707,J01-4003,0,0.0318996,"isolated from anaphoric resolution (witness the Ng and Cardie results). One problem with some of the machine learning approaches to coreference is that these systems do not achieve very good results on pronoun and definite description resolution in comparison with specialized algorithms: e.g., although Ng and Cardie’s best version achieves F=65.8 on all anaphoric expressions, it only achieves F=29.6 for definite descriptions (cfr. Vieira and Poesio’s best result of F=77), and F=28.2 for pronouns (as opposed to results as high as F=80 obtained by the pronoun resolution algorithms evaluated in (Tetreault, 2001)). Clearly these systems can only be properly compared by evaluating them all on the same corpora and the same data, and discussion such as (Mitkov, 2000) suggest caution in interpreting some of the results discussed in the literature as pre- and postprocessing often plays a crucial role, but we feel that evaluating DN detectors in conjunction with highperforming systems would give a better idea of the improvements that one may hope to achieve. 3 Do Discourse-New Detectors Help? Preliminary Evaluations Vieira and Poesio did not test their system without DN-detection, but Ng and Cardie’s result"
W04-0707,P03-2012,1,0.896322,"98), but whereas the inclusion of detectors for non-anaphoric pronouns in algorithms such as Lappin and Leass’ (1994) leads to clear improvements in precision, the improvements in anaphoric DD resolution (as opposed to classification) brought about by the detectors were rather small. In fact, Ng and Cardie (2002a) challenged the motivation for the inclusion of such detectors, reporting no improvements, or even worse performance. We re-examine the literature on the topic in detail, and propose a revised algorithm, taking advantage of the improved discourse-new detection techniques developed by Uryupina (2003). Vieira and Poesio (2000) proposed an algorithm for definite description resolution that incorporates a number of heuristics for detecting discourse-new (henceforth: DN) descriptions. But whereas the inclusion of detectors for non-anaphoric pronouns (e.g., It in It’s raining) in algorithms such as Lappin and Leass’ (1994) leads to clear improvements in precision, the improvements in anaphoric DD resolution (as opposed to classification) brought about by the detectors were rather small. In fact, Ng and Cardie (2002a) challenged the motivation for the inclusion of such detectors, reporting no i"
W04-0707,J00-4003,1,0.933692,"Missing"
W04-0707,C98-2138,0,\N,Missing
W11-4507,baccianella-etal-2010-sentiwordnet,0,0.0110982,".google.com/. Human-related adjectives are defined by being characterized as co-occurring with a human subject [Silva et al. 2010] 7 63 Table 2. Results of the review classification Lexicon Precision Recall Corpus 0.468 0.275 Thesaurus 0.520 0.956 Translation 0.656 0.513 Corpus + thesaurus 0.526 0.963 Conjoined 0.745 0.769 SentLex 0.586 0.725 F-measure Accuracy 0.346 0.247 0.674 0.522 0.576 0.613 0.680 0.528 0.757 0.741 0.648 0.591 the terms are presented outside a given context and polarity is highly dependent of it, we decided to compare the polarity of terms using the SentiWordNet Lexicon [Baccianella and Sebastiani 2010], which differs from the others because it does not list nor annotate words, but their senses - given by the synsets they belong to in WordNet. This analysis was made in 2 steps. First it was necessary to translate the words from Portuguese to English, since SentiWordNet was crafted for the English language. Then, by using the online interface of the lexicon8 we searched the polarity of the words. Given the different senses of a lexical unit, sometimes they can be classified into positive, objective and also negative. It happens because some words can have both meanings, it depends on the sem"
W11-4507,P97-1023,0,0.270074,". Important to this problem is the identification and the determination of polarity (or semantic orientation) of individual terms and words. In such a task, an opinion lexicon has an important role in documenting already known terms and their semantic orientation within a certain context. Work on word or term orientation detection usually fall on three approaches: a corpus-based approach, a lexicon or dictionary-based approach or a multilingual/translation approach. The first uses the relations encountered in large-corpora between words and expressions to determinate their polarity. Works as [Hatzivassiloglou and McKeown 1997, Turney 2002, Riloff and Shepherd 1997] fall in this category. Their advantage is the pos59 Proceedings of the 8th Brazilian Symposium in Information and Human Language Technology, pages 59–66, c Cuiab´ a, MT, Brazil, October 24–26, 2011. 2011 Sociedade Brasileira de Computa¸c˜ ao sibility to identify multi-word opinion-bearing expressions such as ”pain in the ass”1 and identify neutral expressions such as ”great deal of” which do not have any evaluative connotation, expressions with evaluative connotations based on social usage, but not directly accessible through their lexicographic sense,"
W11-4507,E09-1046,0,0.0105053,"the exploration of synonymy relations. The hypothesis of these works bring the idea that synonyms share the same semantic orientation. Mihalcea et al [Mihalcea et al. 2007] use translation-based approach to explore existing opinion lexicons for languages as English to others in which linguistic resources such as WordNet are not available. They translate the opinion lexicon using bilingual dictionaries. The use of such resources imposes great restrictions to the work, as opinion lexicons usually contain multi-word expressions that are not contemplated in the dictionaries. JijKoun and Hofmann [Jijkoun and Hofmann 2009] explore this methodology further by applying an online automatic translation system and the WordNet to improve the results. An opinion lexicon for Portuguese language has been recently developed for the domain of social judgment [Silva et al. 2010].Their work, however, focuses in the domain-specific characteristics of the lexicon and the choice of listing only adjectives, while we crafted a domain-free lexicon composed by polar words (adjectives, verbs and nouns) and expressions. It has been argued that the usage of domain-independent lexicons is unsatisfactory and domain-specific lexicons s"
W11-4507,kamps-etal-2004-using,0,0.040913,"Missing"
W11-4507,P07-1123,0,0.186204,"notes a negative evaluation, similar to ”annoying”. Which connotes a positive evaluation, similar to ”awesome”. 60 based in PMI statistics, Latent Semantic Analysis and Association Rules. Many works use the semantic relations of the WordNet [Fellbaum 1998] to identify the polarity of adjectives [Kamps et al. 2004, Riloff and Shepherd 1997]. Kamps et al [Kamps et al. 2004] use an initial set of polar words - a seed set - that is expanded through the exploration of synonymy relations. The hypothesis of these works bring the idea that synonyms share the same semantic orientation. Mihalcea et al [Mihalcea et al. 2007] use translation-based approach to explore existing opinion lexicons for languages as English to others in which linguistic resources such as WordNet are not available. They translate the opinion lexicon using bilingual dictionaries. The use of such resources imposes great restrictions to the work, as opinion lexicons usually contain multi-word expressions that are not contemplated in the dictionaries. JijKoun and Hofmann [Jijkoun and Hofmann 2009] explore this methodology further by applying an online automatic translation system and the WordNet to improve the results. An opinion lexicon for"
W11-4507,W97-0313,0,0.20361,"n and the determination of polarity (or semantic orientation) of individual terms and words. In such a task, an opinion lexicon has an important role in documenting already known terms and their semantic orientation within a certain context. Work on word or term orientation detection usually fall on three approaches: a corpus-based approach, a lexicon or dictionary-based approach or a multilingual/translation approach. The first uses the relations encountered in large-corpora between words and expressions to determinate their polarity. Works as [Hatzivassiloglou and McKeown 1997, Turney 2002, Riloff and Shepherd 1997] fall in this category. Their advantage is the pos59 Proceedings of the 8th Brazilian Symposium in Information and Human Language Technology, pages 59–66, c Cuiab´ a, MT, Brazil, October 24–26, 2011. 2011 Sociedade Brasileira de Computa¸c˜ ao sibility to identify multi-word opinion-bearing expressions such as ”pain in the ass”1 and identify neutral expressions such as ”great deal of” which do not have any evaluative connotation, expressions with evaluative connotations based on social usage, but not directly accessible through their lexicographic sense, and not always reported in lexicons or"
W11-4507,P02-1053,0,0.112489,"identification and the determination of polarity (or semantic orientation) of individual terms and words. In such a task, an opinion lexicon has an important role in documenting already known terms and their semantic orientation within a certain context. Work on word or term orientation detection usually fall on three approaches: a corpus-based approach, a lexicon or dictionary-based approach or a multilingual/translation approach. The first uses the relations encountered in large-corpora between words and expressions to determinate their polarity. Works as [Hatzivassiloglou and McKeown 1997, Turney 2002, Riloff and Shepherd 1997] fall in this category. Their advantage is the pos59 Proceedings of the 8th Brazilian Symposium in Information and Human Language Technology, pages 59–66, c Cuiab´ a, MT, Brazil, October 24–26, 2011. 2011 Sociedade Brasileira de Computa¸c˜ ao sibility to identify multi-word opinion-bearing expressions such as ”pain in the ass”1 and identify neutral expressions such as ”great deal of” which do not have any evaluative connotation, expressions with evaluative connotations based on social usage, but not directly accessible through their lexicographic sense, and not alway"
W12-3904,baroni-bernardini-2004-bootcat,0,0.0329397,"set of seven ontologies that cover the different aspects of the domain of organizing scientific conferences. We have used this dataset as the basis for generating our corpora. 3 Methodology The main contribution of this paper is the proposal of the methodology to build corpora. This section describes the proposed methodology presenting our own corpus crawler, but also its application to construct three corpora, in English, Portuguese, and French. These corpora are constructed from the MultiFarm dataset. 3.1 Tools and Resources Instead of using an off-the-shelf web corpus tool such as BootCaT (Baroni and Bernardini, 2004), we implemented our own corpus crawler. This allowed us to have more control on query and corpus construction process. Even though our corpus construc4 www.cs.vu.nl/˜laurah/oaei/2009 oaei.ontologymatching.org/2008/ mldirectory 6 web.informatik.uni-mannheim.de/ multifarm 5 tion strategy is similar to the one implemented in BootCaT, there are some significant practical issues to take into account, such as: • The predominance of multiword keywords; • The use of the fixed keyword conference; • The expert tuning of the cleaning process; • The use of a long term support search AP[b]. Besides, BootC"
W12-3904,1999.tc-1.8,0,0.095455,"the resulting corpora are evaluated (§4) and discussed 25 Proceedings of the First Workshop on Multilingual Modeling, pages 25–31, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics (§5). We conclude by outlining their future applications (§ 6). 2 Related Work Web as corpus (WAC) approaches have been successfully adopted in many cases where data sparseness plays a major limiting role, either in specific linguistic constructions and words in a language (e.g. compounds and multiword expressions), or for less resourced languages in general1 . For instance, Grefenstette (1999) uses WAC for machine translation of compounds from French into English, Keller et al. (2002) for adjective-noun, noun-noun and verb-object bigram discovery, and Kim and Nakov (2011) for compound interpretation. Although a corpus derived from the web may contain noise, the sheer size of data available should compensate for that. Baroni and Ueyama (2006) discuss in details the process of corpus construction from web pages for both generic and domainspecific corpora. In particular, they focus on the cleaning process applied to filter the crawled web pages. Much of the methodology applied in our"
W12-3904,W11-1217,0,0.028453,"Computational Linguistics (§5). We conclude by outlining their future applications (§ 6). 2 Related Work Web as corpus (WAC) approaches have been successfully adopted in many cases where data sparseness plays a major limiting role, either in specific linguistic constructions and words in a language (e.g. compounds and multiword expressions), or for less resourced languages in general1 . For instance, Grefenstette (1999) uses WAC for machine translation of compounds from French into English, Keller et al. (2002) for adjective-noun, noun-noun and verb-object bigram discovery, and Kim and Nakov (2011) for compound interpretation. Although a corpus derived from the web may contain noise, the sheer size of data available should compensate for that. Baroni and Ueyama (2006) discuss in details the process of corpus construction from web pages for both generic and domainspecific corpora. In particular, they focus on the cleaning process applied to filter the crawled web pages. Much of the methodology applied in our work is similar to their proposed approach (see §3). Moreover, when access to parallel corpora is limited, comparable corpora can minimize data sparseness, as discussed by Skadina et"
W12-3904,W02-1030,0,0.0693583,"Missing"
W12-3904,D11-1060,0,0.0852301,"ssociation for Computational Linguistics (§5). We conclude by outlining their future applications (§ 6). 2 Related Work Web as corpus (WAC) approaches have been successfully adopted in many cases where data sparseness plays a major limiting role, either in specific linguistic constructions and words in a language (e.g. compounds and multiword expressions), or for less resourced languages in general1 . For instance, Grefenstette (1999) uses WAC for machine translation of compounds from French into English, Keller et al. (2002) for adjective-noun, noun-noun and verb-object bigram discovery, and Kim and Nakov (2011) for compound interpretation. Although a corpus derived from the web may contain noise, the sheer size of data available should compensate for that. Baroni and Ueyama (2006) discuss in details the process of corpus construction from web pages for both generic and domainspecific corpora. In particular, they focus on the cleaning process applied to filter the crawled web pages. Much of the methodology applied in our work is similar to their proposed approach (see §3). Moreover, when access to parallel corpora is limited, comparable corpora can minimize data sparseness, as discussed by Skadina et"
W12-3904,P03-1054,0,0.00322028,"pplied to remove very short sentences (less than 3 words), email addresses, URLs and dates, since the main purpose of the corpus is related to concept, instance and relations extraction. Finally, heuristics to filter out page menus and footnotes are included, leaving only the text of the body of the page. The raw version of the text still contains those expressions in case they are needed for other purposes. In the second step, the text undergoes linguistic annotation, where sentences are automatically lemmatized, POS tagged and parsed. Three well-known parsers were employed: Stanford parser (Klein and Manning, 2003) for texts in English, PALAVRAS (Bick, 2000) for texts in Portuguese, and Berkeley parser (Petrov et al., 2006) for texts in French. 4 Evaluation The characteristics of the resulting corpora are summarized in tables 2 and 3. Column D of table 2 shows that the number of documents retrieved is much higher in en than in pt and fr, and this is not proportional to the number of queries (Q). Indeed, if we look in table 3 at the average ratio of documents retrieved per query (D/Q), the en queries return much more documents than queries in other languages. This indicates that the search engine returns"
W12-3904,W11-1205,0,0.0292069,". Comparable corpora is a very active research subject, being in the core of several European projects (e.g. TTC2 , Accurat3 ). Nonetheless, to date most of 1 Kilgarriff (2007) warns about the dangers of statistics heavily based on a search engine. However, since we use the downloaded texts of web pages instead of search engine count estimators, this does not affect the results obtained in this work. 2 www.ttc-project.eu 3 www.accurat-project.eu 26 the research on comparable corpora seems to focus on lexicographic tasks (Forsyth and Sharoff, 2011; Sharoff, 2006), bilingual lexicon extraction (Morin and Prochasson, 2011), and more generally on machine translation and related applications (Ion et al., 2011). Likewise, there is much to be gained from the potential mutual benefits of comparable corpora and ontology-related tasks. Regarding multilingually aligned ontologies, very few data sets have been made available for use in the research community. Examples include the vlcr4 and the mldirectory5 datasets. The former contains a reduced set of alignments between the thesaurus of the Netherlands Institute for Sound and Vision and two other resources, English WordNet and DBpedia. The latter consists of a set of a"
W12-3904,P06-1055,0,0.016967,"of the corpus is related to concept, instance and relations extraction. Finally, heuristics to filter out page menus and footnotes are included, leaving only the text of the body of the page. The raw version of the text still contains those expressions in case they are needed for other purposes. In the second step, the text undergoes linguistic annotation, where sentences are automatically lemmatized, POS tagged and parsed. Three well-known parsers were employed: Stanford parser (Klein and Manning, 2003) for texts in English, PALAVRAS (Bick, 2000) for texts in Portuguese, and Berkeley parser (Petrov et al., 2006) for texts in French. 4 Evaluation The characteristics of the resulting corpora are summarized in tables 2 and 3. Column D of table 2 shows that the number of documents retrieved is much higher in en than in pt and fr, and this is not proportional to the number of queries (Q). Indeed, if we look in table 3 at the average ratio of documents retrieved per query (D/Q), the en queries return much more documents than queries in other languages. This indicates that the search engine returns more distinct results in en and more duplicate URLs in fr and in pt. The high discrepancy in 7 research.google"
W13-4807,M98-1014,0,0.120269,"Missing"
W13-4807,W11-1902,0,0.0949171,"Missing"
W13-4807,I08-5007,0,0.0606444,"Missing"
W13-4807,W09-1119,0,0.0805402,"Missing"
W13-4809,W10-1505,0,0.0176172,"os futuros. 2. Conceitos B´asicos Nessa sec¸a˜ o apresenta-se trˆes tipos distintos de pontos de corte: Pontos de corte absolutos; Pontos de corte por limiar; e Pontos de corte relativos. Apresenta-se em seguida a definic¸a˜ o formal das m´etricas de qualidade em recuperac¸a˜ o de informac¸a˜ o: Precis˜ao, Abrangˆencia e Medida F. 2.1. Pontos de Corte Absolutos A maneira mais simples de se aplicar pontos de corte e´ escolher um n´umero arbitr´ario de termos que ser˜ao considerados. Por´em, e´ importante salientar que em muitos trabalhos da literatura [Yang and Callan 2008, Lopes et al. 2009b, Evert 2010, Ding et al. 2011], as listas geradas separam os termos segundo o n´umero de palavras que os comp˜oem, ou seja, trata-se separadamente listas de unigramas, bigramas, trigramas, etc. Essa an´alise em separado faz sentido, uma vez que os termos tendem a apresentar variac¸o˜ es distintas para os ´ındices, segundo o n´umero de palavras que os comp˜oem. Dessa forma, o estudo de pontos de corte ser´a feito escolhendo um ponto de corte para unigramas, outro para bigramas, e assim por diante. 2.2. Pontos de Corte por Limiar Uma forma popular de descartar termos e´ o uso de pontos de corte atrav´es da"
W13-4809,N04-4005,0,0.0301471,"erica e´ a m´edia harmˆonica entre os valores de P e R. Os valores da medida F s˜ao valores situados entre P e R, e quanto maior for a diferenc¸a entre esses valores, mais pr´oxima a medida F ser´a do menor valor entre eles. F = 2×P ×R P +R O uso desses ´ındices de qualidade e´ bastante difundido em diversas a´ reas, e.g. [Boreczky and Rowe 1996, Thomas et al. 2000, Fernandes et al. 2010]. Na a´ rea de PLN, e em especial nas tarefas de extrac¸a˜ o de termos, diversos trabalhos justificam a sua validade baseados em seus resultados num´ericos, e.g., [Manning and Sch¨utze 1999, Bell et al. 1999, Hulth 2004, Lopes et al. 2010b]. 3. Resultados Pr´aticos Os resultados pr´aticos desse artigo foram obtidos extraindo bigramas e trigramas do corpus de Pediatria [Coulthard 2005], um corpus formado por 281 textos do Jornal de Pediatria que possui 835.412 palavras, distribu´ıdas em 27.724 frases. Para este corpus existe uma lista de referˆencia com 1.534 bigramas e 2.660 trigramas gerada por uma equipe de lingu´ıstas e especialistas do dom´ınio de forma semi-autom´atica e cuidadosamente revisada [Finatto 2011]. O ponto de partida de todas as experiˆencias com pontos de corte s˜ao listas de bigramas e tri"
W13-4809,U09-1013,0,0.167095,"quentes [Maedche and Staab 2001, Cimiano 2006, Lopes 2012]. Uma parte importante da tarefa de identificac¸a˜ o de termos relevantes e´ a extrac¸a˜ o de termos empregados em um dom´ınio e o c´alculo de um ´ındice de relevˆancia para cada termo extra´ıdo. Para a extrac¸a˜ o de termos, diversas ferramentas [Banerjee and Pedersen 2003, Lopes et al. 2009a] fornecem opc¸o˜ es qualificadas para extrair termos de corpora de dom´ınio. Igualmente, o c´alculo de um ´ındice de relevˆancia para cada termo extra´ıdo tamb´em possui diversas opc¸o˜ es [Manning and Sch¨utze 1999, Chung 2003, Kit and Liu 2008, Kim et al. 2009] que fornecem a possibilidade de ordenac¸o˜ es de termos de acordo com sua relevˆancia para o dom´ınio. No entanto, mesmo assumindo uma lista de termos extra´ıdos, devidamente ordenados segundo um ´ındice de relevˆancia, resta o problema de quantos termos considerar suficientemente relevantes para serem representativos do dom´ınio. Todo processo de 79 Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology, pages 79–87, c Fortaleza, CE, Brazil, October 21–23, 2013. 2013 Sociedade Brasileira de Computa¸ca ˜o extrac¸a˜ o est´a sujeito a fornecer alguns termos que"
W13-4809,H05-1106,0,0.0334805,"s, corresponde a` escolha de um ponto de corte baseado em limiar, ou seja, organizar a lista de termos extra´ıdos segundo um ´ındice e considerar apenas os termos nos quais o seu ´ındice possui um valor acima do limiar escolhido. No caso de Bourigault e Lame [Bourigault and Lame 2002], o ´ındice escolhido foi a frequˆencia absoluta de termos, por´em qualquer ´ındice poderia ser escolhido. O uso de pontos de corte por limiar baseados na frequˆencia absoluta e´ adotado com base em um racioc´ınio intuitivo, que sugere uma relac¸a˜ o direta entre o tamanho do corpus e o ponto de corte a escolher [Wermter and Hahn 2005]. Esta intuic¸a˜ o, ainda que verdadeira, n˜ao e´ uma relac¸a˜ o linear, pois o n´umero de ocorrˆencias de termos em um corpus decresce exponencialmente [Sp¨arck-Jones 1972]. O formato da curva de decr´escimo exponencial pode variar bastante segundo o m´etodo de extrac¸a˜ o, por exemplo, para palavras extra´ıdas segundo um processo puramente estat´ıstico, o decr´escimo segue a lei de Zipf1 [Zipf 1935]. No entanto, para processos lingu´ısticos de extrac¸a˜ o de termos, n˜ao se observa esta mesma lei, como poder´a ser verificado pelo n´umero de ocorrˆencia dos 10 termos mais frequentes do corpu"
W13-4818,W11-1901,0,0.0556786,"Missing"
W13-4818,J01-4004,0,0.0607006,"construção dos pares para treino e outro na avaliação do sistema. Para a construção dos pares, utilizou-se o corpus Summ-it (Collovini (2007)). O Summ-it é um corpus composto por cinquenta textos jornalísticos do caderno de Ciências da Folha de São Paulo. A parte de avaliação será realizada utilizando medidas como abrangência e precisão, sob o corpus do Harem (Freitas et al. (2010)), pelo fato de esse possuir marcação de diversas categorias de entidades e de correferência. 4. Seleção de Features A seleção de features deu-se com base no estudo das features do atual estado da arte. Além disso, Soon et al. (2001) realizaram um experimento com o propósito de verificar o impacto de determinadas features na correta classificação de pares correferentes. Como resultado, os autores constataram que as features String_Match, Alias e Aposto/Appositive apresentam um retorno significativo na correta classificação dos pares. Por meio dessas premissas, podemos visualizar as features selecionadas na tabela1. Tabela 1: Descrição das features String_Match Se um SN está contido no outro. Alias Se uma das palavras de SN1 é sigla de SN2. Aposto Se um SN é aposto do outro. M_Gênero Se os sintagmas concordam em gênero (ma"
W13-4821,C10-1031,0,0.0188469,"k on entity-centric sentiment analysis, i.e. to associate opinions with its referent, fall over three major approaches: those which use the context of an entity - as a fixed window of words around the entity or its syntactic context - to identify an opinion about the entity [Grefenstette et al. 2004, Hu and Liu 2004]; those which use pre-defined rules and linguistics resources - such as FrameNet - to identify the opinion reference as [Ding et al. 2008, Kim and Hovy 2006, Wu et al. 2009]; and those which relies on machine learning techniques as [Popescu and Etzioni 2005, Kobayashi et al. 2007, Ding and Liu 2010]. More related to our work, however, are the work of Jansen et al. [Jansen et al. 2009] and Silva et al. [Silva and TEAM 2011]. Jansen et al. use out-of-the-box commercial tool - no longer available - to perform Entity-centric subsentential sentiment analysis on Twitter. They apply their strategy on brand names for word-of-mouth detection. 173 Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology, pages 173–177, c Fortaleza, CE, Brazil, October 21–23, 2013. 2013 Sociedade Brasileira de Computa¸c˜ ao Silva et al. [Silva and TEAM 2011] describe the construction"
W13-4821,W06-0301,0,0.0222814,"our methods (Section 4). 2. Related Work While multiple solutions have been proposed for identification of opinionated expressions in text, work on entity-centric sentiment analysis, i.e. to associate opinions with its referent, fall over three major approaches: those which use the context of an entity - as a fixed window of words around the entity or its syntactic context - to identify an opinion about the entity [Grefenstette et al. 2004, Hu and Liu 2004]; those which use pre-defined rules and linguistics resources - such as FrameNet - to identify the opinion reference as [Ding et al. 2008, Kim and Hovy 2006, Wu et al. 2009]; and those which relies on machine learning techniques as [Popescu and Etzioni 2005, Kobayashi et al. 2007, Ding and Liu 2010]. More related to our work, however, are the work of Jansen et al. [Jansen et al. 2009] and Silva et al. [Silva and TEAM 2011]. Jansen et al. use out-of-the-box commercial tool - no longer available - to perform Entity-centric subsentential sentiment analysis on Twitter. They apply their strategy on brand names for word-of-mouth detection. 173 Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology, pages 173–177, c Fort"
W13-4821,D07-1114,0,0.0159479,"xpressions in text, work on entity-centric sentiment analysis, i.e. to associate opinions with its referent, fall over three major approaches: those which use the context of an entity - as a fixed window of words around the entity or its syntactic context - to identify an opinion about the entity [Grefenstette et al. 2004, Hu and Liu 2004]; those which use pre-defined rules and linguistics resources - such as FrameNet - to identify the opinion reference as [Ding et al. 2008, Kim and Hovy 2006, Wu et al. 2009]; and those which relies on machine learning techniques as [Popescu and Etzioni 2005, Kobayashi et al. 2007, Ding and Liu 2010]. More related to our work, however, are the work of Jansen et al. [Jansen et al. 2009] and Silva et al. [Silva and TEAM 2011]. Jansen et al. use out-of-the-box commercial tool - no longer available - to perform Entity-centric subsentential sentiment analysis on Twitter. They apply their strategy on brand names for word-of-mouth detection. 173 Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology, pages 173–177, c Fortaleza, CE, Brazil, October 21–23, 2013. 2013 Sociedade Brasileira de Computa¸c˜ ao Silva et al. [Silva and TEAM 2011] descri"
W13-4821,P11-1037,0,0.0285223,"e summarized by searching the opinion expression of the lexicon in the tweet. Since many words on the lexicon are in the canonical form, we apply a Stemmer and search for the words in the tweet if there is a polarized word with the same stem in the lexicon. The polarity is determined by the lexicon and the presence of a negation particle in the vicinity of the opinion expression. As opinion lexicon, we employ the OpLexicon [Souza et al. 2011] which already contains polarized emoticon and hastags - Twitter user-generated metadata. 3.2. Named entity recognition Following the work of Liu et al. [Liu et al. 2011] for NER on Twitter data and the Ratinov and Roth [Ratinov and Roth 2009], we developed a NER system based on a Conditional Random Fields tagger. As features for the NER system, we provide Ratinov and Roth’s [Ratinov and Roth 2009] lexical and morphological features and external information features - based on Repentino name gazetteer [Sarmento et al. 2006]. 3.3. Opinion reference resolution To identify which opinion-bearing expressions reference which named entity, we apply a opinion reference resolution method. In this phase, those opinion expressions that do not refer to a mentioned entity"
W13-4821,H05-1043,0,0.00624099,"ification of opinionated expressions in text, work on entity-centric sentiment analysis, i.e. to associate opinions with its referent, fall over three major approaches: those which use the context of an entity - as a fixed window of words around the entity or its syntactic context - to identify an opinion about the entity [Grefenstette et al. 2004, Hu and Liu 2004]; those which use pre-defined rules and linguistics resources - such as FrameNet - to identify the opinion reference as [Ding et al. 2008, Kim and Hovy 2006, Wu et al. 2009]; and those which relies on machine learning techniques as [Popescu and Etzioni 2005, Kobayashi et al. 2007, Ding and Liu 2010]. More related to our work, however, are the work of Jansen et al. [Jansen et al. 2009] and Silva et al. [Silva and TEAM 2011]. Jansen et al. use out-of-the-box commercial tool - no longer available - to perform Entity-centric subsentential sentiment analysis on Twitter. They apply their strategy on brand names for word-of-mouth detection. 173 Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology, pages 173–177, c Fortaleza, CE, Brazil, October 21–23, 2013. 2013 Sociedade Brasileira de Computa¸c˜ ao Silva et al. [Silv"
W13-4821,W09-1119,0,0.0347398,"the tweet. Since many words on the lexicon are in the canonical form, we apply a Stemmer and search for the words in the tweet if there is a polarized word with the same stem in the lexicon. The polarity is determined by the lexicon and the presence of a negation particle in the vicinity of the opinion expression. As opinion lexicon, we employ the OpLexicon [Souza et al. 2011] which already contains polarized emoticon and hastags - Twitter user-generated metadata. 3.2. Named entity recognition Following the work of Liu et al. [Liu et al. 2011] for NER on Twitter data and the Ratinov and Roth [Ratinov and Roth 2009], we developed a NER system based on a Conditional Random Fields tagger. As features for the NER system, we provide Ratinov and Roth’s [Ratinov and Roth 2009] lexical and morphological features and external information features - based on Repentino name gazetteer [Sarmento et al. 2006]. 3.3. Opinion reference resolution To identify which opinion-bearing expressions reference which named entity, we apply a opinion reference resolution method. In this phase, those opinion expressions that do not refer to a mentioned entity will be discarded. The results of this phase is then the annotated text."
W13-4821,W11-4507,1,0.841069,"l sentiment analysis In the opinion identification and polarity classification, we rely on a dictionary-based approach, similar to [Souza and Vieira 2012]. The method may be summarized by searching the opinion expression of the lexicon in the tweet. Since many words on the lexicon are in the canonical form, we apply a Stemmer and search for the words in the tweet if there is a polarized word with the same stem in the lexicon. The polarity is determined by the lexicon and the presence of a negation particle in the vicinity of the opinion expression. As opinion lexicon, we employ the OpLexicon [Souza et al. 2011] which already contains polarized emoticon and hastags - Twitter user-generated metadata. 3.2. Named entity recognition Following the work of Liu et al. [Liu et al. 2011] for NER on Twitter data and the Ratinov and Roth [Ratinov and Roth 2009], we developed a NER system based on a Conditional Random Fields tagger. As features for the NER system, we provide Ratinov and Roth’s [Ratinov and Roth 2009] lexical and morphological features and external information features - based on Repentino name gazetteer [Sarmento et al. 2006]. 3.3. Opinion reference resolution To identify which opinion-bearing"
W13-4821,D09-1159,0,0.0161304,"n 4). 2. Related Work While multiple solutions have been proposed for identification of opinionated expressions in text, work on entity-centric sentiment analysis, i.e. to associate opinions with its referent, fall over three major approaches: those which use the context of an entity - as a fixed window of words around the entity or its syntactic context - to identify an opinion about the entity [Grefenstette et al. 2004, Hu and Liu 2004]; those which use pre-defined rules and linguistics resources - such as FrameNet - to identify the opinion reference as [Ding et al. 2008, Kim and Hovy 2006, Wu et al. 2009]; and those which relies on machine learning techniques as [Popescu and Etzioni 2005, Kobayashi et al. 2007, Ding and Liu 2010]. More related to our work, however, are the work of Jansen et al. [Jansen et al. 2009] and Silva et al. [Silva and TEAM 2011]. Jansen et al. use out-of-the-box commercial tool - no longer available - to perform Entity-centric subsentential sentiment analysis on Twitter. They apply their strategy on brand names for word-of-mouth detection. 173 Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology, pages 173–177, c Fortaleza, CE, Brazi"
W13-4821,H05-2017,0,\N,Missing
W13-4825,ha-etal-2008-mutual,0,0.0227443,"lus˜oes e trabalhos futuros. 2. Corpus Um corpus, no contexto deste trabalho, pode ser definido com um conjunto de documentos constru´ıdo de acordo com um objetivo espec´ıfico (extrac¸a˜ o de vocabul´ario 194 Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology, pages 194–198, c Fortaleza, CE, Brazil, October 21–23, 2013. 2013 Sociedade Brasileira de Computa¸c˜ ao Figure 1. Processo proposto bil´ıngue, por exemplo). Corpus paralelo, por sua vez, consiste em um corpus formado por documentos acompanhados de suas respectivas traduc¸o˜ es para um segundo idioma [Ha et al. 2008]. O corpus utilizado no decorrer deste trabalho foi constru´ıdo de forma manual a partir de manuais de softwares de projetos de c´odigo livre (open source), tendo o s´ıtio desses como reposit´orio. O corpus constru´ıdo foi composto por 553.333 palavras (29.770 sentenc¸as) para o portuguˆes e 556.027 palavras (28.619 sentenc¸as) para inglˆes, sendo considerado como de tamanho mediano de acordo com padr˜oes lingu´ısticos. 3. Processo Proposto O processo proposto (baseado em [Caseli and Nunes 2007] [Tiedemann 2012] [Ha et al. 2008] e [Zhang 2009]) e´ apresentado na Figura 1 e descrito a seguir."
W13-4825,moore-2002-fast,0,0.0389286,"ilustrac¸o˜ es) e filtrados para a remoc¸a˜ o de s´ımbolos considerados como sujeira (marcadores, caracteres n˜ao codific´aveis, etc.). Posteriormente, os documentos foram organizados no formato de uma sentenc¸a por linha, como exigido pelas ferramentas de alinhamento sentencial (discutido na pr´oxima sec¸a˜ o). 3.2. Alinhamento Sentencial O alinhamento sentencial consiste na identificac¸a˜ o de sentenc¸as equivalentes entre os documentos paralelos do corpus, ou seja, em identificar poss´ıveis traduc¸o˜ es para essas. Dentre as ferramentas de alinhamento sentencial encontradas ([Caseli 2003] [Moore 2002] e [Varga et al. 2005]), optou-se pela utilizac¸a˜ o do Bilingual Sentence Aligner [Moore 2002] (melhor desempenho em testes anteriores) para a realizac¸a˜ o dos alinhamentos. 195 3.3. An´alise Morfol´ogica A etapa de an´alise morfol´ogica consiste na atribuic¸a˜ o de informac¸o˜ es morfol´ogicas (classe gramatical, flex˜oes de n´umero e gˆenero, etc.) a` s palavras formadoras dos documentos, tendo como objetivo a eliminac¸a˜ o de ambiguidades. Durante esta etapa e´ conduzida, ainda, a identificac¸a˜ o de express˜oes multipalavras (conjunto de palavras) [Ramisch et al. 2010] e a unificac¸a˜ o"
W13-4825,J03-1002,0,0.00458068,"uguˆes) e TTC TermSuite [Rocheteau and Daille 2011] (inglˆes). Essas, al´em de fornecerem as informac¸o˜ es morfol´ogicas necess´arias, realizam a identificac¸a˜ o das palavras mais relevantes de um determinado dom´ınio, permitindo a especializac¸a˜ o do vocabul´ario. 3.4. Alinhamento Lexical O alinhamento lexical consiste na identificac¸a˜ o de equivalˆencias entre palavras e express˜oes multipalavras de sentenc¸as consideradas paralelas (previamente alinhadas), logo, na definic¸a˜ o de traduc¸o˜ es para essas. Para a realizac¸a˜ o desta etapa foi utilizada a ferramenta Giza++ (vers˜ao 2.0) [Och and Ney 2003]. O alinhamento foi conduzido em ambos os sentidos (portuguˆesinglˆes e inglˆes-portuguˆes) e os resultados desses foram unidos utilizando o algoritmo de uni˜ao (em conjunto com heur´ısticas) proposto em [Och and Ney 2003]. 3.5. Induc¸a˜ o do Vocabul´ario Bil´ıngue Por fim, a partir dos resultados dos alinhamentos anteriores, foram induzidos os vocabul´arios bil´ıngues mediante a utilizac¸a˜ o da ferramenta ReTraTos [Caseli and Nunes 2007]. O ReTraTos extrai, a partir da lista de equivalˆencias gerada na etapa anterior, uma segunda lista, composta pelas entradas consideradas como mais relevan"
W13-4825,ramisch-etal-2010-mwetoolkit,0,0.0268541,"encontradas ([Caseli 2003] [Moore 2002] e [Varga et al. 2005]), optou-se pela utilizac¸a˜ o do Bilingual Sentence Aligner [Moore 2002] (melhor desempenho em testes anteriores) para a realizac¸a˜ o dos alinhamentos. 195 3.3. An´alise Morfol´ogica A etapa de an´alise morfol´ogica consiste na atribuic¸a˜ o de informac¸o˜ es morfol´ogicas (classe gramatical, flex˜oes de n´umero e gˆenero, etc.) a` s palavras formadoras dos documentos, tendo como objetivo a eliminac¸a˜ o de ambiguidades. Durante esta etapa e´ conduzida, ainda, a identificac¸a˜ o de express˜oes multipalavras (conjunto de palavras) [Ramisch et al. 2010] e a unificac¸a˜ o de seus componentes (mediante inserc¸a˜ o do s´ımbolo “ ”). Esta unificac¸a˜ o se faz necess´aria durante o alinhamento lexical. Nesta etapa foram utilizadas ferramentas da plataforma de traduc¸a˜ o Apertium [Forcada et al. 2011] que, para um maior desempenho tanto na identificac¸a˜ o de express˜oes multipalavras quanto na atribuic¸a˜ o dos r´otulos morfol´ogicos, tiveram seus dicion´arios morfol´ogicos ampliados. Esta ampliac¸a˜ o foi realizada a partir das listas de palavras (e express˜oes multipalavras) extra´ıdas pelas ferramentas de extrac¸a˜ o terminol´ogica ExATOlp ["
W13-4825,I11-2003,0,0.0167027,"inserc¸a˜ o do s´ımbolo “ ”). Esta unificac¸a˜ o se faz necess´aria durante o alinhamento lexical. Nesta etapa foram utilizadas ferramentas da plataforma de traduc¸a˜ o Apertium [Forcada et al. 2011] que, para um maior desempenho tanto na identificac¸a˜ o de express˜oes multipalavras quanto na atribuic¸a˜ o dos r´otulos morfol´ogicos, tiveram seus dicion´arios morfol´ogicos ampliados. Esta ampliac¸a˜ o foi realizada a partir das listas de palavras (e express˜oes multipalavras) extra´ıdas pelas ferramentas de extrac¸a˜ o terminol´ogica ExATOlp [Lopes et al. 2012] (portuguˆes) e TTC TermSuite [Rocheteau and Daille 2011] (inglˆes). Essas, al´em de fornecerem as informac¸o˜ es morfol´ogicas necess´arias, realizam a identificac¸a˜ o das palavras mais relevantes de um determinado dom´ınio, permitindo a especializac¸a˜ o do vocabul´ario. 3.4. Alinhamento Lexical O alinhamento lexical consiste na identificac¸a˜ o de equivalˆencias entre palavras e express˜oes multipalavras de sentenc¸as consideradas paralelas (previamente alinhadas), logo, na definic¸a˜ o de traduc¸o˜ es para essas. Para a realizac¸a˜ o desta etapa foi utilizada a ferramenta Giza++ (vers˜ao 2.0) [Och and Ney 2003]. O alinhamento foi conduzido em"
W13-4825,tiedemann-2012-parallel,0,0.0120046,"r documentos acompanhados de suas respectivas traduc¸o˜ es para um segundo idioma [Ha et al. 2008]. O corpus utilizado no decorrer deste trabalho foi constru´ıdo de forma manual a partir de manuais de softwares de projetos de c´odigo livre (open source), tendo o s´ıtio desses como reposit´orio. O corpus constru´ıdo foi composto por 553.333 palavras (29.770 sentenc¸as) para o portuguˆes e 556.027 palavras (28.619 sentenc¸as) para inglˆes, sendo considerado como de tamanho mediano de acordo com padr˜oes lingu´ısticos. 3. Processo Proposto O processo proposto (baseado em [Caseli and Nunes 2007] [Tiedemann 2012] [Ha et al. 2008] e [Zhang 2009]) e´ apresentado na Figura 1 e descrito a seguir. 3.1. Pr´e-Processamento Durante o pr´e-processamento os documentos componentes do corpus foram convertidos para texto puro (sem formatac¸a˜ o e ilustrac¸o˜ es) e filtrados para a remoc¸a˜ o de s´ımbolos considerados como sujeira (marcadores, caracteres n˜ao codific´aveis, etc.). Posteriormente, os documentos foram organizados no formato de uma sentenc¸a por linha, como exigido pelas ferramentas de alinhamento sentencial (discutido na pr´oxima sec¸a˜ o). 3.2. Alinhamento Sentencial O alinhamento sentencial consis"
W15-5603,P05-1045,0,0.00527055,"through different 27 Comparative Analysis between Notations to Classify Named Entities using Conditional Random Fields types of notations. In [Ratinov and Roth 2009], for example, were applied two popular notations in the literature, BILOU and BIO, in their experiments for NER with the use of CRF. Another interesting notation was applied in [Weber and Vieira 2014] using Stanford NER model [Sobhana et al. 2010]. Words that were not recognized as NEs were labeled as O (Outside). Words identified as NEs, in turn, received the classification Person, Place or Organization. Similarly, the study by [Finkel et al. 2005] implemented a model based on the algorithm Gibbs sampling, in which specific labels were applied to the domain used, such as Person, Place and Organization, as well as consistent features extracted to generate the CRF model. For this work, the employee corpus was the The Golden Collection (GC) HAREM [Santos and Cardoso 2007]. The NEs identified and classified by NERP-CRF received one of the ten categories established by HAREM: Abstraction, Event, Thing, Place, Work, Organization, Person, Time, Value and Other. Thus, our study differs from others due to the focus we give to our system, once t"
W15-5603,freitas-etal-2010-second,0,0.0278468,"areas, such as Natural Language Processing (NLP), image processing, computer vision, and bioinformatics. In this paper we analyse two different notations for identifying the words that compose a Named Entity (NE): BILOU and IO. We found out that IO notation presents better results in F-measure than BILOU notation in all categories of HAREM corpus. 1. Introduction NER is the task of identifying Named Entities (NEs), mostly proper nouns, from free texts and to classify them within a set of pre-defined categories that includes Person, such as “Carlos Ribeiro”; and Place, such as “Porto Alegre” [Freitas et al. 2010]. NER has been largely applied in texts through methods such as supervised learning to classify addition to the above categories, also, diseases and genes in the abstracts of the medical field [Ray et al. 2014]. Labeled data and a set of automatically extracted features are used to train models, such as Maximum Entropy Markov Models (MEMMs) [McCallum et al. 2000] or CRF [Pinto et al. 2003]. The key difference between CRF and MMEMs is that MMEMs use exponential models by states for conditional probabilities of upcoming states, considering the current state. Within this context, the method chos"
W15-5603,W09-1119,0,0.052865,"014]. Labeled data and a set of automatically extracted features are used to train models, such as Maximum Entropy Markov Models (MEMMs) [McCallum et al. 2000] or CRF [Pinto et al. 2003]. The key difference between CRF and MMEMs is that MMEMs use exponential models by states for conditional probabilities of upcoming states, considering the current state. Within this context, the method chosen for this study was CRF, that was evaluated in previous studies for this task [Amaral and Vieira 2014b]. Different notations are used to annotate data for the NER task. In previous studies, we used BILOU [Ratinov and Roth 2009]. This notation demarcates the NEs as follows: B (Begin), I (Inside), L (Last), O (Outside) and U (Unit), indicating the beginning, continuation and end of a compound NE, or whether the word does not refer to a NE or refers to an unit NE. The IO notation [Tjong Kim Sang and De Meulder 2003] is a simpler alternative. It defines whether a word is a NE or not I (Inside) or O (Outside), respectively. Therefore, this paper presents a comparative study, which consists in two different notations for identifying the words that compose a Named Entity (NE): BILOU and IO. This article is structured as f"
W15-5603,W03-0419,0,0.100755,"Missing"
W17-5225,W13-4829,0,0.0317385,"SVR and SVR with linear kernel, all with default parameters. All three algorithms are highlighted in Table 2 be• Linguistic Dimensions and Other Grammar • Affective, Social, Cognitive, Perceptual and Biological processes • Drives, Time orientations and Relativity • Personal concerns and Informal language These categories are then specialized in other sub-categories, as in Affective processes subcategorized as Positive and Negative Emotions, Anxiety, Anger and Sadness. Some examples of words in such categories can be found in Table 1. These categories were translated to other languages (Balage Filho et al., 2013), and have been used to compare writing styles between languages and countries (Afroz et al., 2012). In this paper we use this dictionary for emotion prediction. 3 Psycholinguistic Features Related Work There has been a lot of research seeking text classification in the scope of social media. Here we focus on the works that use LIWC psycholinguistic features to solve some of those problems. Nguyen et al. (2013) use the LIWC psychological lexicon to distinguish blog posts of the 190 Algorithm SVR k=Linear Linear SVR Gradient Boosting SVR k=RBF SVR k=Sigmoid joy 0.431 0.428 0.420 0.399 -0.016 an"
W17-5225,W16-0316,0,0.0635712,"Missing"
W17-5225,P14-1105,0,0.0204718,"Missing"
W17-5225,S17-1007,0,0.0156938,"the main source of data to extract sentiment information in social media because of its data characteristics: huge amount of small sentences distributed in a timeline, which are easily gathered. In Twitter, sentiment classification intends to extract polarity or emotion with regards to a specific subject. The polarity defines a positive or negative valency and the emotion usually is modeled over Ekman’s six basic emotions: joy, anger, sadness, happiness, surprise, fear and disgust (Ekman, 1992). This work intends to score tweets for emotion intensities, by giving a real value for each tweet (Mohammad and Bravo-Marquez, 2017a), as part of the EmoInt-2017 task. The goal of the task is, given a tweet, to predict the intensity of a specific emotion expressed in it (Mohammad and BravoMarquez, 2017b). The intensity score is a real2 LIWC Categories Linguistic inquiry and word count (LIWC), besides being a software, is a psycholinguistic lexicon created by psychologists with focus on studying the various emotional, cognitive, and structural components present in individuals’ verbal and written speech samples (Pennebaker et al., 2015). This resource allows non-specialists to retrieve psychological statistics in text, and"
W17-5225,W17-5205,0,0.0161635,"the main source of data to extract sentiment information in social media because of its data characteristics: huge amount of small sentences distributed in a timeline, which are easily gathered. In Twitter, sentiment classification intends to extract polarity or emotion with regards to a specific subject. The polarity defines a positive or negative valency and the emotion usually is modeled over Ekman’s six basic emotions: joy, anger, sadness, happiness, surprise, fear and disgust (Ekman, 1992). This work intends to score tweets for emotion intensities, by giving a real value for each tweet (Mohammad and Bravo-Marquez, 2017a), as part of the EmoInt-2017 task. The goal of the task is, given a tweet, to predict the intensity of a specific emotion expressed in it (Mohammad and BravoMarquez, 2017b). The intensity score is a real2 LIWC Categories Linguistic inquiry and word count (LIWC), besides being a software, is a psycholinguistic lexicon created by psychologists with focus on studying the various emotional, cognitive, and structural components present in individuals’ verbal and written speech samples (Pennebaker et al., 2015). This resource allows non-specialists to retrieve psychological statistics in text, and"
W17-6606,W13-4829,0,\N,Missing
W17-6609,W14-1103,0,0.0297524,", prote´ınas [Cohen and Demner-Fushman 2014] e as doenc¸as. Neste trabalho, o dom´ınio em foco e´ o da Geologia, em que as ENs de interesse s˜ao as Entidades Geol´ogicas (EG). As EG, consideradas neste estudo, consistem em termos espec´ıficos no texto, desde que esses fac¸am parte das classes definidas de acordo com a sub´area Bacia Sedimentar Brasileira. A escolha do dom´ınio geol´ogico deve-se ao fato de que o REN para Geologia e´ pouco encontrado na literatura. Enquanto REN para Medicina, Biomedicina e Biologia apresenta uma gama bem maior de trabalhos [Zaccara 2012] [Akhondi et al. 2015] [Collier et al. 2014] [D´anger et al. 2014] [Majumder and Ekbal 2015] [Ohta et al. 2002]. 63 Processo de construc¸a˜ o de um corpus anotado com Entidades Geol´ogicas visando REN Destaca-se que a adequada identificac¸a˜ o e classificac¸a˜ o de ENs sob dom´ınios espec´ıficos como o de Geologia, representa um grande desafio aos pesquisadores de PLN. Em especial, devido a` carˆencia de bases textuais nesse dom´ınio, em Portuguˆes, e de ferramentas autom´aticas para captur´a-las. Logo, o trabalho apresentado aqui descreve o processo de anotac¸a˜ o manual de entidades geol´ogicas visando a construc¸a˜ o do GeoCorpus pa"
W97-1301,J86-3001,0,0.127727,"Missing"
W97-1301,P97-1072,1,0.3529,"Missing"
