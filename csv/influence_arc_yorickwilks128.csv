1978.tc-1.2,T75-2023,0,0.124236,"k in the box), according to whether there actually was a block under a pyramid, or already in the box, in the small blocks scene that it understood. Winograd&apos;s program could be called pure AI, in that it was motivated by classic problems of AI: plans (how to pick up the blocks) and theorem proving (how to show which is under the pyramid at a given moment), rather than being motivated by problems left over from the 1966 failure of machine translation, such as word-sense ambiguity, and correctly referring pronouns in discourse. Another group of AI language programs, the work of Charniak (1973), Schank (1975) and myself (1973, 1975) was directed more at those questions: at meaning representation, and the use of inference rules, not about microworlds of blocks, but about the more general world in which we live. MACHINE TRANSLATION AND ARTIFICIAL INTELLIGENCE 31 Consider a simple sentence like ""The soldiers fired at the women and I saw several fall"", where we may be sure that any native speaker of English will understand that sentence (out of any further context, which may change matters, so let us leave it to one side) in such a way that ""several"" refers to the women and not to the soldiers. That c"
1978.tc-1.2,H89-1033,0,0.0706481,"at a teletype or video screen. As can be seen, machine translation is by no means the typical AI language program, but no difference of principle arises between the different sorts of task, especially if we accept a slogan like Steiner&apos;s that, in some sense, all acts of understanding are acts of translation (1975). What almost all AI language programs have in common - though they differ widely over other assumptions - is strong emphasis on the role of knowledge in understanding, and on the presentation of a theory as a possible process. In some programs - like a well known one constructed by Winograd (1972) - this last assumption leads to writing the syntactic analysis part of the program in a special ""grammar programming language"" PROGRAMMAR, rather than as the normal battery of grammar rules like S → NP + VP. This rule appears in all grammars and simply means that a noun phrase (NP) followed by a verb phrase (VP) is a well-formed sentence (S). In Winograd&apos;s system that grammar rule exists only as a tiny program in PROGRAMMAR. Winograd&apos;s program accepted dialogue and commands about a miniature world consisting only of a few blocks and a box, which it could appear to move about on the video scre"
1978.tc-1.2,C69-1701,0,\N,Missing
1988.tc-1.17,J88-1004,0,0.0284407,"Missing"
1991.mtsummit-papers.3,P85-1022,0,0.0595598,"Missing"
1991.mtsummit-papers.3,W89-0242,1,0.831972,"Missing"
1991.mtsummit-papers.3,J85-2001,0,0.0761278,"Missing"
1993.mtsummit-1.12,J90-2002,0,0.0512576,"Missing"
1993.mtsummit-1.12,P91-1022,0,0.0418409,"Missing"
1993.mtsummit-1.12,H90-1056,0,0.0287865,"Missing"
1993.mtsummit-1.12,1983.tc-1.13,0,0.032906,"Missing"
1993.tc-1.1,J90-2002,0,0.0714048,"Missing"
1993.tc-1.1,P91-1022,0,0.0263158,"Missing"
1993.tc-1.1,H90-1056,0,0.0661812,"Missing"
1993.tc-1.1,1983.tc-1.13,0,0.0557408,"Missing"
1994.bcs-1.2,C88-1016,0,0.0607524,"Missing"
1994.bcs-1.2,H89-2011,0,0.0187587,"languages to, say, Spanish or German, whose speakers tend to believe their language rule governed. Most commentators on recent MT developments contrast as radically opposed the IBM statistical methods to those earlier AI methods explored in the US. But that contrast can disguise the closeness of Meaning-Knowledge systems to statistical systems: both rest on quantifiable notions of information or knowledge. AI systems for MT like “preference semantics” (Wilks, 1977) can be seen as quantitative systems that, at the time, lacked the empirical data, since provided by more recent approaches like (Grishman and Sterling, 1989). Systems that emphasise the core role of verb meaning (all those going back to Fillmore and case in AI and computational linguistics generally, and beyond him to the verb centred tradition of classical logic) have to deal, in the end, with the vacuity of much verb meaning (“Kakeru” in Japanese or “Make” in English are classic examples) and the reliance for understanding their use on the types of things you can do with, say, keys and locks, or scrolls and branches (in the case of Kakeru). Similar situations for English arise when only the object (bed, versus book, versus point etc.) of the ver"
1994.bcs-1.2,H92-1052,0,0.0381973,"Missing"
1994.bcs-1.2,J85-2005,0,0.221097,"pite of the above, at least in Japan and the US. * Evaluation continues to drive MT, and helps keep old systems alive. The last ARPA evaluations showed SYSTRAN still very much in the game, but with small commercial upstarts beating the research systems, and much closer to the old, established, and more expensive ones than the latter find comfortable. * Thanks to IBM, resource driven systems are here to stay, at least for the foreseeable future and Big-Data-Small-Program may still be a good ideal, from SYSTRAN to IBM. Here one can take for contrast theoretically motivated systems like EUROTRA (Johnson et al. 1985). Let us now turn to some issues at the junction of resources, evaluation and interlinguas. 3 Modalities of international cross-language co-operation Co-operation is now crucial to MT because resource creation demands it, and resources are now considered crucial to MT by all except those still firmly committed to formal linguistic methods, and who have therefore effectively withdrawn from empirical and evaluation-driven MT. 2-2 Machine Translation Ten Years On Yorick Wilks Keynote Address: Some notes on the state of the art Obvious types of co-operation are: * between monolingual groups within"
1994.bcs-1.2,C90-3030,0,0.0111846,"ne, produced the first full descriptive linguistic grammar for English. The recent morpholympics competition was, I think, won by a Finnish analyser of German which beat all the groups from Germany. Genuine co-operation, on the other hand, can include offers such as the free availability of JUMAN, the Japanese segmenter from Kyoto University, which is of the “I’ll help you do my language” type, and which is quite different from “I’ll do mine and you do yours”, an attitude which drastically limits possible forms of co-operation. On the other hand, the new Finnish constraint parser for English (Karlsson, 1990) is “I’ll help you do yours”. If one doubts the need for this kind of thing, I can cite from personal experience the project at CRL-NMSU which built a Spanish lexicon from an English one largely because we could not find a Spanish machinereadable lexicon at all. Consider, as part of this issue, the problem of the mutual perceptions of Japanese and English speakers: each group sees their own language as mysterious and hard to specify by rules. The proof of this, for English speakers, is that vast numbers of foreigners speak English but find it so hard to get the language right, as opposed to co"
1994.bcs-1.2,C94-2175,0,0.0151425,"utes above. And we would probably want to add a safety clause that the evaluation of any module into or out of an interlingua based on language X should be done by the speakers of language Y. 2-5 Machine Translation Ten Years On Yorick Wilks Keynote Address: Some notes on the state of the art If there are also to be rules going between the interlinguas we shall have what some Japanese groups are calling semantic transfer. Whatever that is, it is quite distinct from syntactic transfer, which is right or wrong and capable of extraction from data, as in the work of Matsumoto and colleagues (e.g. Utsuro et al. 1994). This relativist notion of an interlingua, explicitly dependent on actual natural languages, is one quite separate from the classical notion, of the sort once advocated by Schank (1973) where there could not be more than one interlingua, almost by definition. The tradition being explored in this paper (cf. Wilks et al. 1995) is that if interlinguas in fact have characteristics of natural languages, then the relativist tradition may be the only one with a future. 5 Relativism and interlinguas in MT I would suggest that one can no longer continue to say, as many still do with straight faces, th"
A97-1035,C96-2187,1,0.703341,", morphological analysers, discourse planning modules, etc, - be readily available for experimentation and reuse. But the pressure towards theoretical diversity means that there is no point attempting to gain agreement, in the short term, on what set of component technologies should be developed or on the informational content or syntax of representations that these components should require or produce. Our response to these considerations has been to design and implement a software environment called GATE - a General Architecture for Text Engineering (Cunningham, Gaizauskas, and Wilks, 1995; Cunningham, Wilks, and Gaizauskas, 1996) - which attempts to meet the following objectives: 1. support information interchange between LE modules at the highest common level possible without prescribing theoretical approach (though it allows modules which share theoretical presuppositions to pass data in a mutually accepted common form); • maturing NLP technology which is now able, for some tasks, to achieve high levels of accuracy repeatedly on real data. Aside from the host of fundamental theoretical problems that remain to be answered in NLP, language engineering faces a variety of problems of its own. Two features of the curren"
A97-1035,C96-1082,0,0.0553257,"in SGML for processing by LT-NSL tools, and convert the SGML results back into native format. Work is underway to integrate the LT-NSL API with G A T E and provide SGML I / O for TIPS T E R (and we acknowledge valuable assistance from colleagues at Edinburgh in this task). 2.6 ICE ICE, the Intarc Communication Environment (Amtrup, 1995), is an 'environment for the development of distributed AI systems'. As part of the Verbmobil real-time speech-to-speech translation project ICE has addressed two key problems for this type of system, viz. distributed processing and incremental interpretation (Gorz et al., 1996): distribution to contribute to processing speed in what is a very compute-intensive application area; incremental interpretation both for speed reasons and to facilitate feedback of results from downstream modules to upstream ones (e.g. to inform the selection of word interpretations from phone lattices using partof-speech information). ICE provides a distribution and communication layer based on PVM (Parallel Virtual Machine). The infrastructure that ICE delivers doesn't fit into our tripartite classification because the communication channels do not use data structures specific to NLP needs"
A97-1035,C96-1079,0,0.0690796,"action-based: A fourth category might be added to cater for those systems that provide communication and control infrastructure without addressing the text-specific needs of NLP (e.g. Verbmobil's ICE architecture (Amtrup, 1995)). We begin by reviewing examples of the three approaches we sketched above (and a system that falls into the fourth category). Next we discuss current trends in the field and motivate a set of requirements that have formed the design brief for G A T E , which is then described. The initial distribution of the system includes a MUC-6 (Message Understanding Conference 6 (Grishman and Sundheim, 1996)) style information extraction (IE) system and an overview 1These texts may sometimes be the results of automatic speech recognition - see section 2.6. 237 of these modules is given. G A T E is now available for research purposes - see http ://ul;w.dcs. shef. ac. u_k/research/groups/ nlp/gate/ for details of how to obtain the system. It is written in C + + and T c l / T k and currently runs on UNIX (SunOS, Solaris, Irix, Linux and AIX are known to work); a Windows N T version is in preparation. 2 2.1 Managing Abstraction Information about Text Approaches T h e abstraction-based approach to man"
A97-1035,A97-1034,0,0.137842,"Missing"
A97-1035,J92-2002,0,0.010504,"UNIX (SunOS, Solaris, Irix, Linux and AIX are known to work); a Windows N T version is in preparation. 2 2.1 Managing Abstraction Information about Text Approaches T h e abstraction-based approach to managing information a b o u t texts is primarily motivated by theories of the nature of the information to be represented. One such position is t h a t declarative, constraint-based representations using featurestructure matrices manipulated under unification are an appropriate vehicle by which &quot;many technical problems in language description and computer manipulation of language can be solved&quot; (Shieber, 1992). Information in these models may be characterised as abstract in our present context as there is no requirement to tie d a t a elements back to the original text - these models represent abstractions from the text. One recent example of an infrastructure project based on abstraction is A L E P - the Advanced Language Engineering Platform (Simkins, 1994). A L E P aims to provide &quot;the NLP research and engineering community in Europe with an open, versatile, and general-purpose development environment&quot;. ALEP, while in principle open, is primarily an advanced system for developing and manipulatin"
A97-1035,A97-1036,0,0.074113,"al access to data (McKelvie, Brew, and Thompson, 1997). 5. T I P S T E R can easily support multi-level access control via a database's protection mechanisms - this is again not straightforward in SGML. 6. Distributed control is easy to implement in a database-centred system like T I P S T E R - the DB can act as a blackboard, and implementations can take advantage of well-understood access control (locking) technology. How to do distributed control in LT-NSL is not obvious. We plan to provide this type of control in G A T E via collaboration with the Corelli project at CRL, New Mexico - see (Zajac, 1997) for more details. 2.5 Combining Addition and Reference We believe the above comparison demonstrates that there are significant advantages to the T I P S T E R model and it is this model that we have chosen for GATE. We also believe that SGML and the T E I must remain central to any serious text processing strategy. 240 The points above do not contradict this view, but indicate that SGML should not form the central representation format of every text processing system. Input from SGML text and T E I conformant output are becoming increasingly necessary for LE applications as more and more publ"
A97-1035,M95-1017,0,\N,Missing
A97-1035,A97-2017,1,\N,Missing
A97-2017,A97-1035,1,0.70965,"s the best practical support that can be given to advance the field? Clearly, the pressure to build on the efforts of others demands that LE tools or component technologies be readily available for experimentation and reuse. But the pressure towards theoretical diversity means that there is no point attempting to gain agreement, in the short term, on what set of component technologies should be developed or on the informational content or syntax of representations that these components should require or produce. Our response has been to design and implement a software environment called GATE (Cunninham et al., 1997), which we will demonstrate at ANLP. GATE attempts to meet the following objectives: 29 ing modules are active buttons: clicking on them will, if conditions are right, cause the module to be executed. The paths through the graph indicate the dependencies amongst the various modules making up this subsystem. At any point in time, the state of execution of the system, or, more accurately, the availability of data from various modules, is depicted through colour-coding of the module boxes. After execution, the results of completed modules are available for viewing by clicking again on the module"
A97-2017,M95-1017,0,0.0521059,"escribed above. In addition, modules can be &apos;reset&apos;, i.e. their results removed from the GDM, to allow the user to pick another path through the graph, or re-execute having altered some tailorable data-resource (such as a grammar or lexicon) interpreted by the module at run-time. (Modules running as external executables might also be recompiled between runs.) To illustrate the process of converting pre-existing LE systems into GATE-compatible C R E O L E sets we use as an example the creation of VIE (Vanilla Information Extraction system) from LaSIE (LargeScale Information Extraction system) (Gaizauskas et al., 1995), Sheffield&apos;s entry in the MUC-6 system evaluations. LaSIE module interfaces were not standardised when originally produced and its CREOLEization gives a good indication of the ease of integrating other LE tools into GATE. The work took around 2 person-months. The resulting system, VIE, is distributed with GATE. developed from scratch for the architecture - in either case the object provides a standardised API to the underlying resources which allows access via GGI and I / O via GDM. Tile CREOLE APIs may also be used for programming new objects. When the user initiates a particular C R E O L E"
A97-2017,J93-2004,0,\N,Missing
A97-2017,C94-1070,0,\N,Missing
A97-2017,A97-1034,0,\N,Missing
A97-2017,A97-1036,0,\N,Missing
A97-2017,A97-1051,0,\N,Missing
A97-2017,C96-1079,0,\N,Missing
brewster-etal-2004-data,P93-1024,0,\N,Missing
C04-1143,W97-0703,0,0.098237,"Missing"
C04-1143,C00-1031,0,0.0686903,"Missing"
C04-1143,P98-2143,0,0.0994234,"Missing"
C04-1143,C86-1061,0,0.204087,"03; Barzilay and Elhadad, 1997; Azzam et al., 1998), lexical occurrence/structural statistics (Mathis et al., 1973), discourse structure (Marcu, 1998), cue phrases (Luhn, 1958; Paice, 1990; Rau et al., 1994), positional indicators (Edmunson, 1964) and other extraction methods (Kuipec et al., 1995). Non-extractive systems are less common – previous related work included reformulation of extracted models (McKeown et al., 1999), gist extraction (Berger and Mittal, 2000), machine translation-like approaches (Witbrock and Mittal, 1999) and generative models (De Jong, 1982; Radev and McKeown, 1998; Fum et al., 1986; Reihmer and Hahn, 1988; Rau et al., 1989). A sentence-extraction system was decided for the FASiL summariser, with the capability to have phraselevel extraction in the future. Non-extractive systems were not likely to work as robustly and give the high quality results needed by the VPA to work as required. Another advantage that extractive systems still pose is that in general they are more applicable to a wider range of arbitrary domains and are more reliable than nonextractive systems (Teufel, 2003). The FASiL summariser uses named entities as an indication of the importance of every sente"
C04-1143,W00-0403,0,0.0805362,"Missing"
C04-1143,A00-1040,0,0.0381387,"Missing"
C04-1143,J98-3005,0,\N,Missing
C04-1143,E03-2013,0,\N,Missing
C04-1143,C98-2138,0,\N,Missing
C88-2153,J87-3002,0,0.113521,"se. Recently, interest in the book approach has greatly expanded because a number of MRDs have become available, each causing a flurry of research interest, e.g., The Merriam-WebsterNew Pocket Dict/onary (Amsler and White 1979; Amsler 1980, 1981), Webster&apos;s Seventh New Collegiate Dictionary (Evens and Smith 1983; Chodorow, Byrd, and Heidom 1985; Markowitz, Ahlswede, and Evens 1986; Binot and lensen 1987), and The Longman Dictionary of Contemporary English (Michiels, Mullenders, and Noel 1980; Michiels and Noel 1982; Walker and Amsler 1986; Boguraev, .Briscoe, Carroll, Carter, and Grover 1987; Boguraev and Briscoe 1987; Wilks, Fass, Guo, McDonald, Plate, and Slator 1987). The big advantage of MRDs is that now both theoretical and practical concerns are investigable by large-scale computational methods. Some o f the above research has been into the underlying semantic structure of dictionaries (e.g., Amsler and White 1979; Arnsler 1980, 1981; Chodorow, Byrd, and Heidom 1985). The remainder of the research has been seeking to develop praodeal large-scale methods to extract syntactic information from MRD entries (e.g., Boguraev and Briscoe 1987) and transform that information into a format suitable for other u"
C88-2153,P85-1037,0,0.130153,"Missing"
C88-2153,C82-1036,0,0.0439159,"Missing"
C88-2153,P85-1038,0,0.0524978,"Missing"
C88-2153,C80-1057,0,\N,Missing
C88-2153,P86-1018,0,\N,Missing
C88-2153,P81-1030,0,\N,Missing
C88-2153,P87-1027,0,\N,Missing
C88-2153,E85-1025,0,\N,Missing
C90-3025,C88-2098,0,0.112328,"rentia, serves to differentiate the * ~Pnis research was supported by the New Mexico State University Computing Research Laboratory through NSF Grant No. 1RI-8811108 - - Grateful acknowledgement is accorded to all the members of file CRL Natural Language Group for their comments and suggestions. ** Prc~cnt address: Department of Computer Science, North Dakota State University, Fargo, ND 58105 138 -1o headword from other headwords with the same genus. For example, (from LDOCE): tirst noun phrase. Amsler and White (1979) kept a list of these words, referring to them as partives and collectives. Nakamura & Nagao (1988) call them Function Nouns. Chodorow et al., (1985) refer to a subset of these as &quot;empty heads&quot;. Since we diSAgree with certain elements of these characterizations, we will use the terminology &quot;disturbed heads&quot;. The question at issue is: what to do with these cases? knife - a blade fixed in a handle, used for cutting as a tool or weapon. Here &quot;blade&quot; is the genus term of the headword &quot;knife&quot; and &quot;fixed in a handle, used for cutting as a tool or weapon&quot; yields differentia. In other words, a &quot;knife&quot; IS-A &quot;blade&quot; (genus) distinguished from other blades by the features of its differentia. In order"
C90-3025,C88-2153,1,\N,Missing
C90-3025,P85-1037,0,\N,Missing
C90-3025,P86-1018,0,\N,Missing
C92-2081,C90-3025,1,0.882963,"Missing"
C92-2081,J85-2001,0,0.0494505,"Missing"
C92-2081,C86-1045,0,\N,Missing
C92-2081,P87-1027,0,\N,Missing
C94-1019,H94-1019,0,0.0600941,"Missing"
C94-1019,1992.tmi-1.12,0,0.10997,"Missing"
C94-1019,J85-1002,0,0.0514431,"Missing"
C94-1019,1992.tmi-1.14,0,0.0240526,".,ricnted and do not aim ill advltnch]g our knowledge itl&apos;Joul either basic tnechaI l i S l l l S o f text coralschess;on and production O f C O I l l ] ) t l l e l + models shnHhlling stich i11e.challiSlllS. Tile lwo lllOSl recently popular techncd o~,{ical parndit, ms ill machine t r a n s l a t i o n - - - e×ample-I&apos;~ased Iranslalion (EBMT) and stalisliCSdlased transhlthm (SIIM&apos;f) - - - r e quire linguistic knowledge only :is an aflerlhollghl. While the represenlatives of the above paradigms are still al lhc stage, of e.ilher building toy systems (e.g., Furuse and litht, 1992; McLean, 1992,Jones, 1992, Maruyama and Wltlan,aim, 1992) or struggling with tile natural constraints olal&gt; proaches that eschew the Sttldy ol"" langual.,e ;is such (e.g., Brown et at., 1990), .it number of llropi`&apos;sals have come up lor some hybridization oF M&apos;I: [n some such .aplnO&apos;,tches, tJ I( Corl)llS analysis is tised (&apos;Ill"" ltlllhl]:{ analysis ;lid Ii.{uIsfcr grammars (e.t;., Su and (&apos;hang, 1992). Ill olhcrs, a standlu&apos;d tr:msfcx-I&apos;~L~ed aPl/rtmch (TBMT) is followed usiny, hadilh/nal analysis and generalhm technhlueS bul havin!,, a IranslEr component Imscd on aligned I,ilingual corp(ira ((lrishnmn and Kosnka, I"")"
C94-1019,1992.tmi-1.21,0,0.0239964,"Missing"
C94-1019,1992.tmi-1.15,0,0.0217843,"Missing"
C94-1019,1992.tmi-1.4,0,0.0189808,"Missing"
C94-1019,1992.tmi-1.22,0,0.0307214,"Missing"
C94-1019,C88-1016,0,\N,Missing
C94-1019,J90-2002,0,\N,Missing
C94-1019,1992.tmi-1.23,0,\N,Missing
C96-1071,J93-2004,0,\N,Missing
C96-1071,M95-1017,0,\N,Missing
C96-2118,M95-1017,0,\N,Missing
C96-2118,P85-1007,0,\N,Missing
C96-2187,C94-1070,0,0.025987,"s of the M U L T E X T project. G D M provides a central repository or server t h a t stores all the information an LE system generates about the texts it processes. All communication between the components of an LE system goes through GDM, insulating parts fi&apos;om each other and providing a uniform A P I (applications p r o g r a m m e r interface) for manipulating the data produced by the system. 3 Benefits of this approach include the ability to exploit the maturity and efficiency of database technology, easy modelling of blackboard-type distributed control regimes (of the type proposed by: (Boitet and Seligman, 1994) and in the section on control in (Black ed., 1991)) and reduced interdependence of components. G G I is in development at Sheffield. It is a graphical launchpad for LE subsystems, and provides various facilities for viewing and testing results and playing software lego with LE components - interactively assembling objects into different system configurations. All the real work of analysing texts (and m a y b e producing summaries of them, or translations, or SQL statements, etc.) in a GATE-based LE system is done by C R E O L E modules. Note that we use the terms module and object rather loos"
C96-2187,J93-2004,0,0.0245392,"nefficency have been extensively studied, and a number of solutions are now available (Prieto-Diaz and t~h&apos;eeman, 1987; Prieto-Diaz, 1993). Similarly, the Natural Language Engineering (NLE l) community has identified the potential benefits of reducing repetition, and work has been flmded to promote reuse. This work concerns either reusable resources which are primarily data or those which are primarily algorithmic (i.e. processing &apos;tools&apos;, or programs, or code libraries). Successflfl examples of reuse of data resources include: the WordNet thesaurus (Miller el; al., 1993); the Penn Tree Bank (Marcus et al., 1993); the Longmans Dictionary of Contemporary English (Summers, 1995). A large number of papers report results relative to these and other resources, and these successes have spawned a numOur view is that succesful algorithmic reuse in NLE will require the provision of support software for NLE in the form of a general architecture and development environment which is specifically designed for text processing systems. Under EPSRC 2 grant GR/K25267 the NLP group at, the University of Sheffield are developing a system that aims to implement this new approach. The system is called GATE - the General A"
C98-1111,P97-1021,0,0.0298271,"Missing"
C98-1111,P96-1025,0,0.0388392,"Missing"
C98-1111,P98-1115,1,0.0540771,"Missing"
C98-1111,H94-1020,0,0.0262288,"art-of-speech tags), we may be able to achieve parsing performance similar to the best results in the field obtained in (Collins, 1996). 2 Growth of the Rule Set One could investigate whether there is a finite g r a m m a r that should account for any text within a class of related texts (i.e. a domain oriented sub-grammar of English). If there is, the number of extracted rules will approach a limit as more sentences are processed, i.e. as the rule n u m b e r approaches the size of such an underlying and finite grammar. We had hoped that some approach to a limit would be seen using P T B II (Marcus et al., 1994), which larger and more consistent for bracketting than P T B I. As shown in Figure 1, however, the rule number growth continues unabated even after more t h a n 1 million part-ofspeech tokens have been processed. 700 Rule Growth and Partial Bracketting Why should the set of rules continue to grow in this way? P u t t i n g aside the possibility that natural languages do not have finite rule sets, we can think of two possible answers. First, it may be that the full ""underlying g r a m m a r "" is much larger than the rule set that has so far been produced, requiring a much larger tree-banked co"
C98-1111,1995.iwpt-1.26,0,0.0914475,"Missing"
C98-1111,J95-2002,0,0.0866185,"Missing"
C98-2223,C92-4189,0,0.185678,"senses for adjectives list the type which they expect for the noun they modify, senses for adverbs the type they expect of their modifier and verbs list between one and three types (depending on their transitivity) which are the expected semantic types of the verb's subject, direct object and indirect object. G r a m m a t i c a l links between verbs, adjectives and adverbs and the head noun of their arguments arer identified using a specially constructed shallow syntactic analyser (Stevenson, 1998). The semantic classes in L D O C E are not provided with a hierarchy, but, Bruce and Guthrie (Bruce and Guthrie, 1992) manually identified hierarchical relations between tile semantic classes, constructing them into a hierarchy which we use to resolve the restrictions. We resolve the restrictions by returning, for each word, the set of sense which do not break them (that is, those whose semantic category is at the same, or a lower, level in the hierarchy). 4 Combining Knowledge Sources Since each of our partial taggers suggests only possible senses for each word it is necessary to have some method to combine their results. We trained decision lists (Clark and Niblett, 1989) using a supervised learning approac"
C98-2223,H92-1045,0,0.0134226,"d that the new evaluation function led to an improvement in the algorithm's effectiveness. 3.4 Pragmatic Codes Our next partial tagger makes use of the hierarchy of L D O C E pragmatic codes which indicate the likely subject area for a sense. Disambiguation is carried out using a modified version of the simulated annealing algorithm, and a t t e m p t s to optimise the number of pragmatic codes of the same type in the sen~ tence. Rather than processing over single sentences we optimise over entire paragraphs and only for the sense of nouns. We chose this strategy since there is good evidence (Gale et al., 1992) that nouns are best disambiguated by broad contextual considerations, while other parts of speech are resolved by more local factors. 3.5 Seleetional Restrictions L D O C E senses contain simple selectional restrictions for each content word in the dictionary. A set of 35 semantic classes are used, such as H = Hu~ man, M = H u m a n male, P = Plant, S = Solid and so on. Each word sense for a noun is given one of these semantic types, senses for adjectives list the type which they expect for the noun they modify, senses for adverbs the type they expect of their modifier and verbs list between"
C98-2223,W97-0212,0,0.0361733,"p e d onto two or three L D O C E senses when the WordNet sense does not distinguish between them. Tile mapping also contained significant gaps (words and senses not in the translation). S E M C O R contains 91,808 words tagged with WordNet synsets, 6,071 of which are proper nmnes which we ignore, leaving 85,737 words which could potentially be translated. The translation contains only 36,869 words tagged with L D O C E senses, although this is a reasonable size for an evaluation corpus given this type of task (it is several orders of magnitude larger than those used by (Cowie et al., 1992) (Harley and Glennon, 1997) (Mahesh et al., 1997)). This corpus was also constructed without the excessive cost of additional hand-tagging and does not introduce any inconsistencies which may occur with a poorly controlled tagging strategy. 6 Results 2['0 date we have tested our system on only a portion of the text we derived from SEMCOR, which consisted of 2021 words tagged with L D O C E senses (and 12,208 words in total). The 2021 word occuranees are made up from 1068 different types, with an average t)olyselny of 7.65. As a baseline against which to compare results we computed the t)ereentage of words which are corr"
C98-2223,1997.tmi-1.18,0,0.0202849,"D O C E senses when the WordNet sense does not distinguish between them. Tile mapping also contained significant gaps (words and senses not in the translation). S E M C O R contains 91,808 words tagged with WordNet synsets, 6,071 of which are proper nmnes which we ignore, leaving 85,737 words which could potentially be translated. The translation contains only 36,869 words tagged with L D O C E senses, although this is a reasonable size for an evaluation corpus given this type of task (it is several orders of magnitude larger than those used by (Cowie et al., 1992) (Harley and Glennon, 1997) (Mahesh et al., 1997)). This corpus was also constructed without the excessive cost of additional hand-tagging and does not introduce any inconsistencies which may occur with a poorly controlled tagging strategy. 6 Results 2['0 date we have tested our system on only a portion of the text we derived from SEMCOR, which consisted of 2021 words tagged with L D O C E senses (and 12,208 words in total). The 2021 word occuranees are made up from 1068 different types, with an average t)olyselny of 7.65. As a baseline against which to compare results we computed the t)ereentage of words which are correctly tagged if we cho"
C98-2223,J92-1001,0,0.0242673,"ues to a single phenomenon, WSD? This is a situation quite unlike syntactic parsing or part-of-speech tagging: in the latter case, for example, one can write a Cherry-style rule tagger or an HMM learning model, but there is no reason the believe these represent different types of information, just different ways of conceptualising and coding it. T h a t seems not to tie the case, at first sight, with the many forms of information for WSD. It ix odd that this has not been much discussed in the field. In this work, we shall adopt the methodology first explicitly noted in connection with WSD by (McRoy, 1992), and more recently (Ng and Lee, 1996), namely t h a t of bringing together a number of partial sources of infbrmation about a phenomenon and combining them in a tn'inciI)led manner. Tiffs ix in the AI tradition of combining ""weak"" me.thods for strong results (usually ascribed to Newell (Newell, 1973)) and used in the CRL-NMSU lexical work on the Eighties (Wilks et al., 1990). We shall, in this paper, offer a system that combines the three types of ilffornlation listed above (plus part-of-speech illtering) and, more importantly, applies a learning algorithm to determine the optimal combination"
C98-2223,P96-1006,0,0.13304,"This is a situation quite unlike syntactic parsing or part-of-speech tagging: in the latter case, for example, one can write a Cherry-style rule tagger or an HMM learning model, but there is no reason the believe these represent different types of information, just different ways of conceptualising and coding it. T h a t seems not to tie the case, at first sight, with the many forms of information for WSD. It ix odd that this has not been much discussed in the field. In this work, we shall adopt the methodology first explicitly noted in connection with WSD by (McRoy, 1992), and more recently (Ng and Lee, 1996), namely t h a t of bringing together a number of partial sources of infbrmation about a phenomenon and combining them in a tn'inciI)led manner. Tiffs ix in the AI tradition of combining ""weak"" me.thods for strong results (usually ascribed to Newell (Newell, 1973)) and used in the CRL-NMSU lexical work on the Eighties (Wilks et al., 1990). We shall, in this paper, offer a system that combines the three types of ilffornlation listed above (plus part-of-speech illtering) and, more importantly, applies a learning algorithm to determine the optimal combination of such modules for a given word dist"
C98-2223,C90-2067,0,0.0198715,"Missing"
C98-2223,P95-1026,0,0.0495222,"into a hierarchy which we use to resolve the restrictions. We resolve the restrictions by returning, for each word, the set of sense which do not break them (that is, those whose semantic category is at the same, or a lower, level in the hierarchy). 4 Combining Knowledge Sources Since each of our partial taggers suggests only possible senses for each word it is necessary to have some method to combine their results. We trained decision lists (Clark and Niblett, 1989) using a supervised learning approach. Decision lists have already been successfully applied to lexical ambiguity resolution by (Yarowsky, 1995) where they perfi'omed well. We present the decision list system with a number of training words for which the correct sense 1400 is known. For each of the words we supply each of its possible senses (apart fi'om those removed from consideration by the part-of-speech filter (Section 3.2)) within a context consisting of the results from each of the partial taggers, frequency information and 10 simple collocations (first n o u n / v e r b / p r e p o s i t i o n to the left/right and first/second word to the left/right). Each sense is marked as either a p p r o p r i a t e (if it is tile correct"
C98-2223,H93-1052,0,\N,Missing
C98-2223,W97-0208,1,\N,Missing
catizone-etal-2006-evaluating,wayne-2000-multilingual,0,\N,Missing
catizone-etal-2006-evaluating,C96-1079,0,\N,Missing
catizone-etal-2006-evaluating,W04-1013,0,\N,Missing
catizone-etal-2008-information,W03-2705,1,\N,Missing
catizone-etal-2012-lie,webb-etal-2008-cross,1,\N,Missing
catizone-etal-2012-lie,A97-2017,1,\N,Missing
cunningham-etal-2000-software,C92-2123,0,\N,Missing
cunningham-etal-2000-software,bird-etal-2000-atlas,0,\N,Missing
cunningham-etal-2000-software,W99-0301,0,\N,Missing
cunningham-etal-2000-software,C96-1082,0,\N,Missing
cunningham-etal-2000-software,C94-1070,0,\N,Missing
cunningham-etal-2000-software,A97-1034,0,\N,Missing
cunningham-etal-2000-software,W94-0319,0,\N,Missing
cunningham-etal-2000-software,A97-1035,1,\N,Missing
cunningham-etal-2000-software,W98-1310,0,\N,Missing
cunningham-etal-2000-software,A97-1054,0,\N,Missing
cunningham-etal-2000-software,P98-2126,0,\N,Missing
cunningham-etal-2000-software,C98-2121,0,\N,Missing
cunningham-etal-2000-software,P98-1099,0,\N,Missing
cunningham-etal-2000-software,C98-1096,0,\N,Missing
cunningham-etal-2000-software,P98-1024,0,\N,Missing
cunningham-etal-2000-software,C98-1024,0,\N,Missing
cunningham-etal-2000-software,C98-2126,0,\N,Missing
cunningham-etal-2000-software,W97-1500,0,\N,Missing
cunningham-etal-2000-software,W98-1102,0,\N,Missing
cunningham-etal-2000-software,M93-1009,0,\N,Missing
cunningham-etal-2000-software,A97-2017,1,\N,Missing
dalli-etal-2004-web,A97-2017,1,\N,Missing
dalli-etal-2004-web,dalli-2002-creation,1,\N,Missing
E03-2014,J98-3005,0,0.0411612,"e definitions; and template generation and filling component that uses the domain lexicon and linguistic output of the first step as a guidance to fill-in the templates. The systems takes advantage of the information extracted from formal texts (e.g., lists of players) in order to carry out the analysis of tickers. 3 Merging or Cross-document Event Coreference The merging component in MUMIS combines the partial information as extracted from various sources, such that more complete annotations can be obtained. Information extraction and merging from multiple sources has been tried in the past (Radev and McKeown, 1998) but only for single events, the novelty of our approach consists on applying merging to multiple-events extracted from multiple sources. As an example consider the following situation (Netherlands-Yugoslavia match): One of the IE components extracted from document A that in the 30th minute of the match a free-kick was taken, but did not discover who took it. It did find the names of two players, though: Mihajlovic (a Yugoslavian player) and Van der Sar (the Dutch keeper). From document B a save in the 31st minute was extracted by the IE component, and the names of the same two players were re"
E85-1013,J83-3004,1,0.889961,"Missing"
E85-1013,1984.bcs-1.17,0,0.0341989,"Missing"
E85-1013,P84-1054,0,0.0330649,"Missing"
E85-1013,J76-4007,1,0.790405,"Missing"
E85-1013,H89-1033,0,0.0352825,"uine ambiguity and did not seem to mind much whether attachment or lexicalization of NAMED AFTER was preferred. Again, information vacuity tells against the syntactic attachment (the example is on the model of : which comes under (i) and there is JOE BROUGHT (AT A WEDDING) case, informants continue to attach to M E T , seemingly discounting both the syntactic indication and the information vacuity of M A R R I E D A T A WEDDING. CARS RACED AT MONTE CARLO FETCH HIGH PRICES AS COLLECTOR&apos;S ITEMS but that is not because readers know of any particular cars raced at Monte Carlo. Hirst accepts from (Winograd 1972) a general Principle of Referential Success (i.e. to actual existent entities), hut the general unsatisfactoriness of restricting a system to actual entities has long been known, for so much of our discourse is about possible and virtual ontologies (for a full discussion of this aspect of Winograd. see Ritchie 1978). H A I R E D GIRL F R O M DANCE) (AT A t Here our informants attach the phrase resolutely to M E T as cornmonsense dictates (i.e.they ignore or are able to discount the built-in distance effect of the very long NP). A more difficultand interesting case arises if the last phrase is"
E85-1013,P83-1017,0,\N,Missing
guthrie-etal-2006-closer,A88-1019,0,\N,Missing
guthrie-etal-2006-closer,J90-2002,0,\N,Missing
H89-1029,J83-3004,1,\N,Missing
H89-1029,C86-1031,0,\N,Missing
H89-1029,C86-1080,0,\N,Missing
H89-2030,P85-1007,0,0.0157336,"xplicitly here, and his treatment of them may well be compatible with our own general approach. ViewGen: The basic belief engine A computational model of belief ascription is described in detail elsewhere (Wilks & Bien, 1979, 1983; Ballim, 1987; Wilks & Balfim, 1987; Ballim & Wilks, forthcoming) and is embodied in a program called ViewGen, two versions of which have been written in prolog by Afzal Ballim. The basic algorithm of this model uses the notion of default reasoning to ascribe beliefs to other agents unless there is evidence to prevent the ascription. Perrault (1987, forthcoming) and Cohen & Levesque (1985) have also recently explored a belief and speech act logic based on a single explicit default axiom. As our previous work has shown for some years, the default ascription is basically correct, but the phenomena are more complex (see below) than are normally captured by an axiomatic approach. ViewGen&apos;s belief space is divided into a number of topic specific partitions (topic environments). These environmcnLs can be thought of as a les s permanent version of frames (Minsky, 1975; Charniak, 1978) or more suitably in terms of Wilks (1978) as pseudo-texts (henceforth PTs). In effect, a PT is a set"
H89-2030,C88-1036,0,0.0678304,"Missing"
H89-2030,1984.bcs-1.17,0,0.0264616,"low) from the robust parser PREMO, to the MGR, the generator of alternative scenarios/models, to ViewGen the point-of-view shell that considers the possible points of view in terms of the environments of other agents (e.g. Blue Generals view of Red General&apos;s view of a particular tank division). Both MGR and ViewGen also act as filters of possible but inapplicable models of the situation. PREMO: A ROBUST PARSER OF MESSAGES PREMO: the PREference Machine Organization is a knowledge-based Preference Semantics parser (Wilks 1972, 1975, 1978; Boguraev 1979; Carter 1984, 1987; Fass 1986, 1987, 1988; Huang 1984, 1988; Slator 1988a, 1988c) due to Brian Slator, with access to the large, text-specific, lexical semantic knowledge base created by the lexicon-provider of the CRL project on large scale lexical extraction from machine readable dictionaries (Wilks et al. in press). A fuller description of the relationship of PREMO to that project appears in (Slator & Wilks 1989). PREMO is the parser we intend to use initially for initial processing of military reports (sightings, casualties etc.) that have been generated raapidiy under adverse 220 conditions. Preference Semantics is a theory of language in w"
H89-2030,J80-3003,0,0.0458969,"Missing"
H89-2030,W89-0242,1,0.709505,"pplicable models of the situation. PREMO: A ROBUST PARSER OF MESSAGES PREMO: the PREference Machine Organization is a knowledge-based Preference Semantics parser (Wilks 1972, 1975, 1978; Boguraev 1979; Carter 1984, 1987; Fass 1986, 1987, 1988; Huang 1984, 1988; Slator 1988a, 1988c) due to Brian Slator, with access to the large, text-specific, lexical semantic knowledge base created by the lexicon-provider of the CRL project on large scale lexical extraction from machine readable dictionaries (Wilks et al. in press). A fuller description of the relationship of PREMO to that project appears in (Slator & Wilks 1989). PREMO is the parser we intend to use initially for initial processing of military reports (sightings, casualties etc.) that have been generated raapidiy under adverse 220 conditions. Preference Semantics is a theory of language in which the meaning for a text is represented by a complex semantic structure that is built up out of smaller semantic components; this composifionality is a fairly typical feature of semantic theories. The principal difference between Preference Semantics and other semantic theories is in the explicit and computational accounting of ambiguous, metaphorical, and ling"
H89-2030,C88-2153,1,\N,Missing
iria-etal-2006-incremental,1993.eamt-1.4,0,\N,Missing
iria-etal-2006-incremental,brewster-etal-2004-data,1,\N,Missing
iria-etal-2006-incremental,C00-2136,0,\N,Missing
iria-etal-2006-incremental,C92-2082,0,\N,Missing
J01-3001,J95-4004,0,0.015163,"Missing"
J01-3001,P91-1034,0,0.178797,"iguate all content words. 1 In addition to avoiding the problems inherent in restricted vocabulary systems, wide coverage systems are more likely to be useful for NLP applications, as discussed by Wilks et al. (1990). A third difference concerns the granularity of WSD attempted, which one can illustrate in terms of the two levels of semantic distinctions found in many dictionaries: homograph and sense (see Section 3.1). Like Cowie, Guthrie, and Guthrie (1992), we shall give results at both levels, but it is worth pointing out that the targets of, say, work using translation equivalents (e.g., Brown et al. 1991; Gale, Church, and Yarowsky 1992c; and see Section 2.3) and Roget categories (Yarowsky 1992; Masterman 1957) correspond broadly to the wider, homograph, distinctions. In this paper we attempt to show that the high level of results more typical of systems trained on many instances of a restricted vocabulary can also be obtained by large vocabulary systems, and that the best results are to be obtained from an optimization of a combination of types of lexical knowledge (see Section 2). 1.1 Lexical Knowledge and WSD Syntactic, semantic, and pragmatic information are all potentially useful for WSD"
J01-3001,P94-1020,0,0.0231778,"the best approach to WSD. Currently, machine learning methods (Yarowsky 1995; Rigau, Atserias, and Agirre 1997) and combinations of classifiers (McRoy 1992) have been popular. This paper reports a WSD system employing elements of both approaches. Another source of difference in approach is the proportion of the vocabulary disambiguated. Some researchers have concentrated on producing WSD systems that base results on a limited number of words, for example Yarowsky (1995) and Schtitze (1992) who quoted results for 12 words, and a second group, including Leacock, Towell, and Voorhees (1993) and Bruce and Wiebe (1994), who gave results for just one, namely interest. But limiting the vocabulary on which a system is evaluated can have two serious drawbacks. First, the words used were not chosen by frequency-based sampling techniques and so we have no way of knowing whether or not they are special cases, a point emphasised by Kilgarriff (1997). Secondly, there is no guarantee • Department of Computer Science, 211 Regent Court, Portobello Street, Sheffield $1 4DP, UK (~) 2001 Association for Computational Linguistics Computational Linguistics Volume 27, Number 3 that the techniques employed will be applicable"
J01-3001,H92-1046,0,0.048092,"Missing"
J01-3001,W96-0102,0,0.0347084,"ns and surface form combine to represent the context of each ambiguous word. 4.7 Combining Disambiguation Modules The results from the disambiguation modules (filter, partial taggers, and feature extractor) are then presented to a machine learning algorithm to combine their results. The algorithm we chose was the TIMBLmemory-based learning algorithm (Daelemans et al. 1999). Memory-based learning is another name for exemplar-based learning, as employed by Ng and Lee (Section 2.3). The TiMBLalgorithm has already been used for various NLP tasks including part-of-speech tagging and PP-attachment (Daelemans et al. 1996; Zavrel, Daelemans, and Veenstra 1997). 337 Computational Linguistics Volume 27, Number 3 Like PEBLS, which formed the core of Ng and Lee&apos;s LEXAS system, TiMBLclassifies new examples by comparing them against previously seen cases. The class of the most similar example is assigned. At the heart of this approach is the distance metric A(X, Y) which computes the similarity between instances X and Y. This measure is calculated using the weighted overlap metric shown in (8), which calculates the total distance by computing the sum of the distance between each position in the feature vector. n A(X"
J01-3001,P92-1032,0,0.0950738,"Missing"
J01-3001,H92-1045,0,0.101688,"Missing"
J01-3001,W97-0212,0,0.225792,"s likely that mark-up for a restricted vocabulary can be carried out more rapidly since the subject has to learn the possible senses of fewer words. Among the researchers mentioned above, one must distinguish between, on the one hand, supervised approaches that are inherently limited in performance to the words over which they evaluate because of limited training data and, on the other hand, approaches whose unsupervised learning methodology is applied to only small numbers of words for evaluation, but which could in principle have been used to tag all content words in a text. Others, such as Harley and Glennon (1997) and ourselves Wilks and Stevenson (1998a, 1998b; Stevenson and Wilks 1999), have concentrated on approaches that disambiguate all content words. 1 In addition to avoiding the problems inherent in restricted vocabulary systems, wide coverage systems are more likely to be useful for NLP applications, as discussed by Wilks et al. (1990). A third difference concerns the granularity of WSD attempted, which one can illustrate in terms of the two levels of semantic distinctions found in many dictionaries: homograph and sense (see Section 3.1). Like Cowie, Guthrie, and Guthrie (1992), we shall give r"
J01-3001,J98-1001,0,0.0270454,"Missing"
J01-3001,H93-1051,0,0.192722,"Missing"
J01-3001,1997.tmi-1.18,0,0.0474687,"Missing"
J01-3001,J93-2004,0,0.0487215,"Missing"
J01-3001,J92-1001,0,0.786067,"e are the choice of computational paradigm, the proportion of text words disambiguated, the granularity of the meanings assigned to them, and the knowledge sources used. We will discuss each in turn. Resnik and Yarowsky (1997) noted that, for the most part, part-of-speech tagging is tackled using the noisy channel model, although transformation rules and grammaticostatistical methods have also had some success. There has been far less consensus as to the best approach to WSD. Currently, machine learning methods (Yarowsky 1995; Rigau, Atserias, and Agirre 1997) and combinations of classifiers (McRoy 1992) have been popular. This paper reports a WSD system employing elements of both approaches. Another source of difference in approach is the proportion of the vocabulary disambiguated. Some researchers have concentrated on producing WSD systems that base results on a limited number of words, for example Yarowsky (1995) and Schtitze (1992) who quoted results for 12 words, and a second group, including Leacock, Towell, and Voorhees (1993) and Bruce and Wiebe (1994), who gave results for just one, namely interest. But limiting the vocabulary on which a system is evaluated can have two serious drawb"
J01-3001,P96-1006,0,0.140732,"extremely brief and has not covered large areas of research into WSD. For example, we have not discussed connectionist approaches, as used by Waltz and Pollack (1985), V6ronis and Ide (1990), Hirst (1987), and Cottrell (1984), However, we have attempted to discuss some of the approaches to combining diverse types of linguistic knowledge for WSD and have concentrated on those which are related to the techniques used in our own disambiguation system. Of central interest to our research is the relative contribution of the various knowledge sources which have been applied to the WSD problem. Both Ng and Lee (1996) and Yarowsky (1993) reported some results in the area. However, Ng and Lee reported results for only a single word and Yarowsky considers only words with two possible senses. This paper is an attempt to increase the scope of this research by discussing a disambiguation algorithm which operates over all content words and combines a varied set of linguistic knowledge sources. In addition, we examine the relative effect of each knowledge source to gauge which are the most important, and under what circumstances. We first report an in-depth study of a particular knowledge source, namely partof-sp"
J01-3001,W97-0808,0,0.165911,"Missing"
J01-3001,P97-1007,0,0.0862017,"Missing"
J01-3001,C90-2067,0,0.245305,"Missing"
J01-3001,J96-3009,0,0.0150266,"Missing"
J01-3001,C92-2070,0,0.710194,"on to avoiding the problems inherent in restricted vocabulary systems, wide coverage systems are more likely to be useful for NLP applications, as discussed by Wilks et al. (1990). A third difference concerns the granularity of WSD attempted, which one can illustrate in terms of the two levels of semantic distinctions found in many dictionaries: homograph and sense (see Section 3.1). Like Cowie, Guthrie, and Guthrie (1992), we shall give results at both levels, but it is worth pointing out that the targets of, say, work using translation equivalents (e.g., Brown et al. 1991; Gale, Church, and Yarowsky 1992c; and see Section 2.3) and Roget categories (Yarowsky 1992; Masterman 1957) correspond broadly to the wider, homograph, distinctions. In this paper we attempt to show that the high level of results more typical of systems trained on many instances of a restricted vocabulary can also be obtained by large vocabulary systems, and that the best results are to be obtained from an optimization of a combination of types of lexical knowledge (see Section 2). 1.1 Lexical Knowledge and WSD Syntactic, semantic, and pragmatic information are all potentially useful for WSD, as can be demonstrated by consi"
J01-3001,H93-1052,0,0.108222,"Missing"
J01-3001,P95-1026,0,0.281949,"although it has yet to achieve that aim completely. The main sources of divergence are the choice of computational paradigm, the proportion of text words disambiguated, the granularity of the meanings assigned to them, and the knowledge sources used. We will discuss each in turn. Resnik and Yarowsky (1997) noted that, for the most part, part-of-speech tagging is tackled using the noisy channel model, although transformation rules and grammaticostatistical methods have also had some success. There has been far less consensus as to the best approach to WSD. Currently, machine learning methods (Yarowsky 1995; Rigau, Atserias, and Agirre 1997) and combinations of classifiers (McRoy 1992) have been popular. This paper reports a WSD system employing elements of both approaches. Another source of difference in approach is the proportion of the vocabulary disambiguated. Some researchers have concentrated on producing WSD systems that base results on a limited number of words, for example Yarowsky (1995) and Schtitze (1992) who quoted results for 12 words, and a second group, including Leacock, Towell, and Voorhees (1993) and Bruce and Wiebe (1994), who gave results for just one, namely interest. But l"
J01-3001,W97-1016,0,0.0544813,"Missing"
J01-3001,C92-4189,0,\N,Missing
J01-3001,M95-1017,0,\N,Missing
J08-4001,iria-etal-2006-incremental,1,0.819156,"d their meanings over 30 years of coding, but there was no way of describing that fact within the system, so as to guarantee consistency. In Nirenburg and Wilks (2000), Nirenburg and I debate this issue in depth, and I defend the position that one cannot simply maintain the meanings of such terms by ﬁat and independent of their usage—they look like words and they function like words because, in the end, they are words. The SW offers a way out of this classic AI dilemma by building up the hierarchy of annotations with empirical processes like ontology induction from corpora (e.g., ABRAXAS; see Iria et al. 2006); in this way the meanings of higher level terms are connected back directly to text usage. Braithwaite, my thesis advisor, described in his classic “Scientiﬁc explanation” (Braithwaite 1953) a process in the philosophy of science he 481 Computational Linguistics Volume 34, Number 4 called “semantic ascent” by which the abstract high-level terms in a scientiﬁc theory, seen as a logical hierarchy of deductive processes—terms such as “neutron,“ possibly corresponding to unobservables—acquired meaning by an ascent of semantic interpretation up the theory hierarchy from meanings grounded in experi"
J08-4001,J01-3001,1,0.854391,"Missing"
J08-4001,H89-1033,0,0.325812,"Fred’s father but rather the system’s point of view of their directional amalgamation: Joe-as-Fred’s-father (which might contain different propositions from the result of Fred’s-father-as-Joe). More natural, and fundable, scenarios were constructed for this technique in those days, such as knowledge representations for Navy ships’ captains genuinely uncertain as to whether ship-in-my-viewﬁnder-now was or was not to be identiﬁed with the stored representation for enemy-ship-number-X. The important underlying notion was one going back to Frege, and which ﬁrst had an outing in Winograd’s thesis (Winograd 1972), where he showed you could have representations for blocks that did not in fact exist on the Blocks World table. A semantics must be able to represent things without knowing whether they exist or not; that is a basic requirement. Later, and working with John Barnden and Afzal Ballim, this same underlying process of conﬂating two belief objects was extended to the representation of “metaphorical objects,” which could be described, quite traditionally in the literature, as A-viewed-as-B (e.g., an atom viewed as a billiard ball). The metaphorical object atom-as-billiard-ball was again created by"
J76-1007,C02-1113,0,0.0298296,"Missing"
J78-3032,T75-2006,0,\N,Missing
J78-3032,T75-2009,1,\N,Missing
M92-1031,C90-2002,0,0.187357,"Missing"
M92-1031,H92-1047,0,\N,Missing
O98-4001,P91-1034,0,0.108947,"Missing"
O98-4001,P94-1020,0,0.0264693,"Missing"
O98-4001,W91-0209,0,0.0305799,"f the definitions and how specific they are. I suspect no one has ever held a simple-minded version of the BM, except possibly Fodor and Katz, who, whatever their virtues, had no interest at all in lexicography. The real problem with Kilgarriff's analysis of sense types is that he conflates: a) text usage different from that shown in a whole list of stored senses for a given word e.g. in a dictionary, (which is what his later experiment will be about) with b) text usage divergent from some &quot;core&quot; sense in the lexicon. Only the second is properly in the area of metaphor/metonymy or &quot;grinding&quot; [Copestake and Briscoe, 1991] work of the group in which he places himself, and it is this phenomenon to which his classification of sense distinctions summarized above properly belongs. This notion requires some idea of sense development; of senses of a word extending in time in a non-random manner, and is a linguistic tradition of analysis going back to Givon [1967]. However, the straw-man BM and the experiment he then does on hand-tagging of senses in text, all attach to the first, unrelated, notion which does not normally imply the presence of metonymy or metaphor at all, but simply an inadequate sense list. Of cours"
O98-4001,H92-1046,0,0.140172,"ics and Chinese Language Processing vol. 3, no. 2, August 1998, pp. 1-16 Computational Linguistics Society of R.O.C. 1 Senses and Texts Yorick Wilks* Abstract This paper addresses the question of whether it is possible to sense-tag systematically, and on a large scale, and how we should assess progress so far. That is to say, how to attach each occurrence of a word in a text to one and only one sense in a dictionary---a particular dictionary of course, and that is part of the problem. The paper does not propose a solution to the question, though we have reported empirical findings elsewhere [Cowie et al. 1992 and Wilks et al. 1996], and intend to continue and refine that work. The point of this paper is to examine two well-known contributions critically, one [Kilgarriff 1993] which is widely taken as showing that the task, as defined, cannot be carried out systematically by humans, and secondly [Yarowsky 1995] which claims strikingly good results at doing exactly that. 1. Introduction Empirical, corpus-based, computational linguistics reached by now into almost every crevice of the subject, and perhaps pragmatics will soon succumb. Semantics, if we may assume the sense-tagging task is semantic, ta"
O98-4001,J94-4003,0,0.0564895,"Missing"
O98-4001,H92-1045,0,0.0538411,"Missing"
O98-4001,H89-1033,0,0.0582683,"Missing"
O98-4001,H93-1052,0,0.0188359,"fifty-four contexts for a word in a single encyclopaedia article (repeated for eight other words) are in the same sense. Is this significant? I suspect not very, and nothing at all follows to support the myth of discovery that has grown round the paper: the team and data are tiny and not disinterested. The Grolier articles are mini-texts where the hypothesis would, if true, surprise one least. Much more testing is needed before a universal hypothesis about text polysemy enters our beliefs. Of course, they may in the end be right, and all the dogma of the field so far be wrong. More recently, Yarowsky (1993, 1995) has extended this methodology in two ways: first, he has established a separate claim he calls &quot;one sense per collocation&quot;, which is quite independent of local discourse context (which was the separate &quot;one-sense-per-discourse&quot; claim) and could be expressed crudely by saying that it is highly unlikely that the following two sentences (with the &quot;same&quot; collocations for &quot;plants&quot;) can both be attested in a corpus: Plastic plants can fool you if really well made (=organic) Plastic plants can contaminate whole regions (=factory) One's first reaction may be to counter-cite examples like &quot;Un g"
O98-4001,P95-1026,0,0.127758,"Missing"
O98-4002,C92-4200,0,0.0182789,"Missing"
O98-4002,J81-4005,0,0.374817,"Missing"
O98-4002,A92-1024,0,0.0239485,"Missing"
O98-4002,A83-1020,0,0.775815,"Missing"
O98-4002,A83-1024,0,0.851833,"Missing"
O98-4002,X93-1016,0,0.0717482,"Missing"
O98-4002,M95-1005,0,0.0195094,"Missing"
O98-4002,M93-1008,0,0.0919055,"Missing"
O98-4002,M93-1009,0,0.0652359,"Missing"
O98-4002,A97-1035,1,0.697843,"Missing"
O98-4002,H92-1022,0,0.0203744,"Missing"
O98-4002,J93-2004,0,0.0415785,"Missing"
O98-4002,C96-1071,1,0.812755,"Missing"
O98-4002,M91-1030,0,0.0570721,"Missing"
O98-4002,M92-1036,0,0.0555612,"Missing"
O98-4002,M93-1019,0,0.00831222,"Missing"
O98-4002,M95-1012,0,0.0136154,"Missing"
O98-4002,M95-1018,0,0.0850266,"Missing"
O98-4002,M95-1010,0,0.0242138,"Missing"
O98-4002,M95-1006,0,0.0568592,"Missing"
O98-4002,A83-1009,0,\N,Missing
O98-4002,C96-1079,0,\N,Missing
O98-4002,M92-1024,0,\N,Missing
P02-1020,P91-1022,0,0.0252695,"ave been suggested for aligning multilingual parallel corpora (Wu, 2000). These algorithms have been used to map translation equivalents across di erent languages. In this speci c case, we investigate whether alignment can map derived texts (or parts of them) to their source texts. PA copy may be subject to various changes during text reuse, e.g. a single sentence may derive from parts of several source sentences. Therefore, strong correlations of sentence length between the derived and source sentences cannot be guaranteed. As a result, sentence-length based statistical alignment algorithms (Brown et al., 1991; Gale and Church, 1993) are not appropriate for this case. On the other hand, cognate-based algorithms (Simard et al., 1992; Melamed, 1999) are more eÆcient for coping with change of text format. Therefore, a cognate-based approach is adopted for the METER task. Here cognates are de ned as pairs of terms that are identical, share the same stems, or are substitutable in the given context. The algorithm consists of two principal components: a comparison strategy and a scoring function. In brief, the comparison works as follows (more details may be found in Piao (2001)). For each sentence in the"
P02-1020,1996.amta-1.36,0,0.0913455,"n the production of daily newspapers. The question is not just whether agency copy has been reused, but to what extent and subject to what transformations. Using existing approaches from computational text analysis, we investigate their ability to classify newspapers articles into categories indicating their dependency on agency copy. 2 Journalistic reuse of a newswire The process of gathering, editing and publishing newspaper stories is a complex and specialised task often operating within speci c publishing constraints such as: 1) short deadlines; 2) prescriptive writing practice (see, e.g. Evans (1972)); 3) limits of physical size; 4) readability and audience comprehension, e.g. a tabloid&apos;s vocabulary limitations; 5) journalistic bias, e.g. political and 6) a newspaper&apos;s house style. Often newsworkers, such as the reporter and editor, will rely upon news agency copy as the basis of a news story or to verify facts and assess the Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, July 2002, pp. 152-159. importance of a story in the context of all those appearing on the newswire. Because of the nature of journalistic text reuse, di eren"
P02-1020,W01-0515,0,0.213735,"uality papers (e.g. Daily Telegraph, The Guardian, The Independent and The Times). to the text reuse issues we are investigating. Finally, alignment (treating the derived text as a 	ranslation&quot; of the rst) seemed an intriguing idea, and contrasts, certainly with the ngram approach, by focusing more on local, as opposed to global measures of similarity. 4.1 Ngram Overlap An initial, straightforward approach to assessing the reuse between two texts is to measure the number of shared word ngrams. This method underlies many of the approaches used in copy detection including the approach taken by Lyon et al. (2001). They measure similarity using the settheoretic measures of containment and resemblance of shared trigrams to separate texts written independently and those with suÆcient similarity to indicate some form of copying. We treat each document as a set of overlapping n-word sequences (initially considering only n-word types) and compute a similarity score from this. Given two sets of ngrams, we use the set-theoretic containment score to measure similarity between the documents for ngrams of length 1 to 10 words. For a source text A and a possibly derived text B represented by sets of ngrams Sn (A)"
P02-1020,J99-1003,0,0.0119568,"di erent languages. In this speci c case, we investigate whether alignment can map derived texts (or parts of them) to their source texts. PA copy may be subject to various changes during text reuse, e.g. a single sentence may derive from parts of several source sentences. Therefore, strong correlations of sentence length between the derived and source sentences cannot be guaranteed. As a result, sentence-length based statistical alignment algorithms (Brown et al., 1991; Gale and Church, 1993) are not appropriate for this case. On the other hand, cognate-based algorithms (Simard et al., 1992; Melamed, 1999) are more eÆcient for coping with change of text format. Therefore, a cognate-based approach is adopted for the METER task. Here cognates are de ned as pairs of terms that are identical, share the same stems, or are substitutable in the given context. The algorithm consists of two principal components: a comparison strategy and a scoring function. In brief, the comparison works as follows (more details may be found in Piao (2001)). For each sentence in the candidate derived text DT the sentences in the candidate source text ST are compared in order to nd the best match. A DT sentence is allowe"
P02-1020,1992.tmi-1.7,0,0.0605392,"n equivalents across di erent languages. In this speci c case, we investigate whether alignment can map derived texts (or parts of them) to their source texts. PA copy may be subject to various changes during text reuse, e.g. a single sentence may derive from parts of several source sentences. Therefore, strong correlations of sentence length between the derived and source sentences cannot be guaranteed. As a result, sentence-length based statistical alignment algorithms (Brown et al., 1991; Gale and Church, 1993) are not appropriate for this case. On the other hand, cognate-based algorithms (Simard et al., 1992; Melamed, 1999) are more eÆcient for coping with change of text format. Therefore, a cognate-based approach is adopted for the METER task. Here cognates are de ned as pairs of terms that are identical, share the same stems, or are substitutable in the given context. The algorithm consists of two principal components: a comparison strategy and a scoring function. In brief, the comparison works as follows (more details may be found in Piao (2001)). For each sentence in the candidate derived text DT the sentences in the candidate source text ST are compared in order to nd the best match. A DT se"
P02-1020,J93-1004,0,\N,Missing
P10-4013,A97-2017,1,0.497135,"an easyto-use high-level interface for general DAF designers to code associated tests and actions as well as a low level interface for advanced DAFs. It also provides the communication link between DAFs and the internal system and enables DAFs to access system functionalities. Following is a brief summary of modules grouped into Application Services. 4. Dialogue understanding and inference Every utterance is passed through the Natural Language Understanding (NLU) module for processing. This module uses a set of wellestablished natural language processing tools such as those found in the GATE (Cunningham, et al., 1997) system. The basic processes carried out by GATE are: tokenizing, sentence splitting, POS tagging, parsing and Named Entity Recognition. These components have been further enhanced for the SC system by adding 1) new and improved gazetteers including family relations and 2) accompanying extraction rules .The Named Entity (NE) recognizer is a key part of the NLU module and recognizes the significant entities required to process dialogue in the photo domain: PERSON NAMES, LOCATION NAMES, FAMILY RELATIONS and DATES. Although GATE recognizes basic entities, more complex entities are not handled. Ap"
P10-4013,traum-etal-2004-evaluation,0,0.0307279,"either in reminiscing conversations, nor in the elicitation of the content of photos, that can be assessed in standard ways, since there is no clear point at which an informal dialogue need stop, having been completed. Conventional dialogue evaluations often use measures like “stickiness” to determine how much a user will stay with or stick with a dialogue system and not leave it, presumably because they are disappointed or find it lacking in some feature. But it is hard to separate that feature out from a task rapidly and effectively completed, where stickiness would be low not high. Traum (Traum et al., 2004) has developed a methodology for dialogue evaluation based on “appropriateness” of responses and the Companions project has developed a model of evaluation for the SC based on that (Benyon et al., 2008). Once the type of information is identified, the NLU can use various predefined strategies: In the case of LOCATIONS, one of the strategies used is to seek for information in Wiki-Travel or Virtual Tourists. The system already knows how to query these sites and interpret their output by using predefined wrappers. This is then used to extract relevant information from the mentioned sites webpage"
P10-4013,D09-1020,0,\N,Missing
P91-1019,H90-1052,0,0.0122866,"cooccurrence links between words of the defining vocabulary to construct these &quot;neighborhoods&quot;. Here, we describe the application of these neighborhoods to information retrieval, and present a method of word sense disambiguation based on these co-occurrences, an extension of previous work. INTRODUCTION Word associations have been studied for some time in the fields of psycholinguistics (by testing human subjects on words), linguistics (where meaning is often based on how words co-occur with each other), and more recently, by researchers in natural language processing (Church and Hanks, 1990; Hindle and Rooth, 1990; Dagan, 1990; McDonald et al., 1990; Wilks et al., 1990) using statistical measures to identify sets of associated words for use in various natural language processing tasks. One of the tasks where the statistical data on associated words has been used with some success is lexical disambiguation. However, associated word sets gathered * Present address: Mathematics Department, University of Texas at k-:lPaso, El Paso, Tx 79968 from a general corpus may contain words that are associated with many different senses. For example, vocabulary associated with the word &quot;bank&quot; includes &quot;money&quot;, &quot;rob&quot;,"
P91-1019,J90-1003,0,\N,Missing
P91-1019,C90-3063,0,\N,Missing
P91-1019,C90-2067,0,\N,Missing
P98-1115,P97-1021,0,0.136357,"Missing"
P98-1115,P96-1025,0,0.0607813,"Missing"
P98-1115,P98-1115,1,0.0512067,"Missing"
P98-1115,H94-1020,0,0.0495892,"ay be able to achieve parsing performance similar to the best results in the field obtained in (Collins, 1996). 2 Rule Growth and Partial Bracketting Growth of the Rule Set One could investigate whether there is a finite grammar that should account for any text within a class of related texts (i.e. a domain oriented sub-grammar of English). If there is, the number of extracted rules will approach a limit as more sentences are processed, i.e. as the rule number approaches the size of such an underlying and finite grammar. We had hoped that some approach to a limit would be seen using P T B II (Marcus et al., 1994), which larger and more consistent for bracketting than P T B I. As shown in Figure 1, however, the rule number growth continues unabated even after more than 1 million part-ofspeech tokens have been processed. 700 Why should the set of rules continue to grow in this way? P u t t i n g aside the possibility that natural languages do not have finite rule sets, we can think of two possible answers. First, it may be that the full &quot;underlying grammar&quot; is much larger than the rule set that has so far been produced, requiring a much larger tree-banked corpus than is now available for its extraction."
P98-1115,1995.iwpt-1.26,0,0.255817,"Missing"
P98-1115,J95-2002,0,0.140312,"Missing"
P98-2228,H92-1022,0,0.0104855,"filters and partial taggers. A filter removes senses from consideration, thereby reducing the complexity of the disambiguation task. Each partial tagger makes use of a different knowledge source from the lexicon and uses it to suggest a set of possible senses for each ambiguous word in context. None of these modules performs the disambiguation alone but they are combined to make use of all of their results. 3.1 Preprocessing Before the filters or partial taggers are applied the text is tokenised, lemmatised, split into sentences and part-of-speech tagged using the Brill part-ofspeech tagger (Brill, 1992). Our system disambiguates only the content words in the text 1 (the part-of-speech tags assigned by 1We define content words as nouns, verbs, adjectives and adverbs, prepositions are not included in this class. 1399 Brill&apos;s tagger are used to decide which are content words). 3.2 Part-of-speech Previous work (Wilks and Stevenson, 1998) showed that part-of-speech tags can play an important role in the disambiguation of word senses. A small experimentwas carried out on a 1700 word corpus taken from the Wall Street Journal and, using only part-ofspeech tags, an attempt was made to find the correc"
P98-2228,C92-4189,0,0.173559,"emantic types, senses for adjectives list the type which they expect for the noun they modify, senses for adverbs the type they expect of their modifier and verbs list between one and three types (depending on their transitivity) which are the expected semantic types of the verb&apos;s subject, direct object and indirect object. Grammatical links between verbs, adjectives and adverbs and the head noun of their arguments arer identified using a specially constructed shallow syntactic analyser (Stevenson, 1998). The semantic classes in LDOCE are not provided with a hierarchy, but, Bruce and Guthrie (Bruce and Guthrie, 1992) manually identified hierarchical relations between the semantic classes, constructing them into a hierarchy which we use to resolve the restrictions. We resolve the restrictions by returning, for each word, the set of sense which do not break them (that is, those whose semantic category is at the same, or a lower, level in the hierarchy). 4 Combining Knowledge Sources Since each of our partial taggers suggests only possible senses for each word it is necessary to have some method to combine their results. We trained decision lists (Clark and Niblett, 1989) using a supervised learning approach"
P98-2228,H92-1046,0,0.0457272,"e, and some WordNet senses are mapped onto two or three LDOCE senses when the WordNet sense does not distinguish between them. The mapping also contained significant gaps (words and senses not in the translation). SEMCOR contains 91,808 words tagged with WordNet synsets, 6,071 of which are proper names which we ignore, leaving 85,737 words which could potentially be translated. The translation contains only 36,869 words tagged with L D O C E senses, although this is a reasonable size for an evaluation corpus given this type of task (it is several orders of magnitude larger than those used by (Cowie et al., 1992) (Harley and Glennon, 1997) (Mahesh et al., 1997)). This corpus was also constructed without the excessive cost of additional hand-tagging and does not introduce any inconsistencies which may occur with a poorly controlled tagging strategy. 6 Results To date we have tested our system on only a portion of the text we derived from SEMCOR, which consisted of 2021 words tagged with LDOCE senses (and 12,208 words in total). The 2021 word occurances are made up from 1068 different types, with an average polysemy of 7.65. As a baseline against which to compare results we computed the percentage of wo"
P98-2228,H92-1045,0,0.0134167,"nd that the new evaluation function led to an improvement in the algorithm&apos;s effectiveness. 3.4 P r a g m a t i c C o d e s Our next partial tagger makes use of the hierarchy of LDOCE pragmatic codes which indicate the likely subject area for a sense. Disambiguation is carried out using a modified version of the simulated annealing algorithm, and attempts to optimise the number of pragmatic codes of the same type in the sentence. Rather than processing over single sentences we optimise over entire paragraphs and only for the sense of nouns. We chose this strategy since there is good evidence (Gale et al., 1992) that nouns are best disambiguated by broad contextual considerations, while other parts of speech are resolved by more local factors. 3.5 S e l e c t i o n a l R e s t r i c t i o n s LDOCE senses contain simple selectional restrictions for each content word in the dictionary. A set of 35 semantic classes are used, such as S = Human, M = Human male, P = Plant, S -- Solid and so on. Each word sense for a noun is given one of these semantic types, senses for adjectives list the type which they expect for the noun they modify, senses for adverbs the type they expect of their modifier and verbs l"
P98-2228,W97-0212,0,0.0356721,"enses are mapped onto two or three LDOCE senses when the WordNet sense does not distinguish between them. The mapping also contained significant gaps (words and senses not in the translation). SEMCOR contains 91,808 words tagged with WordNet synsets, 6,071 of which are proper names which we ignore, leaving 85,737 words which could potentially be translated. The translation contains only 36,869 words tagged with L D O C E senses, although this is a reasonable size for an evaluation corpus given this type of task (it is several orders of magnitude larger than those used by (Cowie et al., 1992) (Harley and Glennon, 1997) (Mahesh et al., 1997)). This corpus was also constructed without the excessive cost of additional hand-tagging and does not introduce any inconsistencies which may occur with a poorly controlled tagging strategy. 6 Results To date we have tested our system on only a portion of the text we derived from SEMCOR, which consisted of 2021 words tagged with LDOCE senses (and 12,208 words in total). The 2021 word occurances are made up from 1068 different types, with an average polysemy of 7.65. As a baseline against which to compare results we computed the percentage of words which are correctly tag"
P98-2228,1997.tmi-1.18,0,0.0614336,"r three LDOCE senses when the WordNet sense does not distinguish between them. The mapping also contained significant gaps (words and senses not in the translation). SEMCOR contains 91,808 words tagged with WordNet synsets, 6,071 of which are proper names which we ignore, leaving 85,737 words which could potentially be translated. The translation contains only 36,869 words tagged with L D O C E senses, although this is a reasonable size for an evaluation corpus given this type of task (it is several orders of magnitude larger than those used by (Cowie et al., 1992) (Harley and Glennon, 1997) (Mahesh et al., 1997)). This corpus was also constructed without the excessive cost of additional hand-tagging and does not introduce any inconsistencies which may occur with a poorly controlled tagging strategy. 6 Results To date we have tested our system on only a portion of the text we derived from SEMCOR, which consisted of 2021 words tagged with LDOCE senses (and 12,208 words in total). The 2021 word occurances are made up from 1068 different types, with an average polysemy of 7.65. As a baseline against which to compare results we computed the percentage of words which are correctly tagged if we chose the fi"
P98-2228,J92-1001,0,0.0656518,"lues to a single phenomenon, WSD? This is a situation quite unlike syntactic parsing or part-of-speech tagging: in the latter case, for example, one can write a Cherry-style rule tagger or an HMM learning model, but there is no reason the believe these represent different types of information, just different ways of conceptualising and coding it. T h a t seems not to be the case, at first sight, with the many forms of information for WSD. It is odd that this has not been much discussed in the field. In this work, we shall adopt the methodology first explicitly noted in connection with WSD by (McRoy, 1992), and more recently (Ng and Lee, 1996), namely that of bringing together a number of partial sources of information about a phenomenon and combining them in a principled manner. This is in the AI tradition of combining ""weak"" methods for strong results (usually ascribed to Newell (Newell, 1973)) and used in the CRL-NMSU lexical work on the Eighties (Wilks et al., 1990). We shall, in this paper, offer a system that combines the three types of information listed above (plus part-of-speech filtering) and, more importantly, applies a learning algorithm to determine the optimal combination of such"
P98-2228,P96-1006,0,0.331348,"This is a situation quite unlike syntactic parsing or part-of-speech tagging: in the latter case, for example, one can write a Cherry-style rule tagger or an HMM learning model, but there is no reason the believe these represent different types of information, just different ways of conceptualising and coding it. T h a t seems not to be the case, at first sight, with the many forms of information for WSD. It is odd that this has not been much discussed in the field. In this work, we shall adopt the methodology first explicitly noted in connection with WSD by (McRoy, 1992), and more recently (Ng and Lee, 1996), namely that of bringing together a number of partial sources of information about a phenomenon and combining them in a principled manner. This is in the AI tradition of combining ""weak"" methods for strong results (usually ascribed to Newell (Newell, 1973)) and used in the CRL-NMSU lexical work on the Eighties (Wilks et al., 1990). We shall, in this paper, offer a system that combines the three types of information listed above (plus part-of-speech filtering) and, more importantly, applies a learning algorithm to determine the optimal combination of such modules for a given word distribution;"
P98-2228,C90-2067,0,0.0168567,"Missing"
P98-2228,P95-1026,0,0.0429719,"into a hierarchy which we use to resolve the restrictions. We resolve the restrictions by returning, for each word, the set of sense which do not break them (that is, those whose semantic category is at the same, or a lower, level in the hierarchy). 4 Combining Knowledge Sources Since each of our partial taggers suggests only possible senses for each word it is necessary to have some method to combine their results. We trained decision lists (Clark and Niblett, 1989) using a supervised learning approach. Decision lists have already been successfully applied to lexical ambiguity resolution by (Yarowsky, 1995) where they perfromed well. We present the decision list system with a number of training words for which the correct sense 1400 is known. For each of the words we supply each of its possible senses (apart from those removed from consideration by the part-of-speech filter (Section 3.2)) within a context consisting of the results from each of the partial taggers, frequency information and 10 simple collocations (first noun/verb/preposition to the left/right and first/second word to the left/right). Each sense is marked as either a p p r o p r i a t e (if it is the correct sense given the contex"
P98-2228,H93-1052,0,\N,Missing
P98-2228,W97-0208,1,\N,Missing
pastra-wilks-2004-image,martin-kipp-2002-annotating,0,\N,Missing
S15-1009,P98-1013,0,0.149614,"the syntactic head of the text passage describing the proposition). We do not propose to develop our own semantic representation, but instead we will look to using existing relation and event representations based on the ACE program (Doddington et al., 2004). These have the advantage that there are offthe-shelf computational tools available for detecting ACE relations and events; they have the disadvantage that they do not cover all propositions we may be interested in. An alternative would be the use of a shallower semantic representation such as PropBank (Kingsbury et al., 2002), FrameNet (Baker et al., 1998), or AMR (Banarescu et al., 2013). 7.3 Entities as Targets In Section 6, we discussed an initial evaluation of a belief being about an entity. In this section we discuss further guidelines for identifying belief targets, i.e., when one can say that someone’s belief is about 89 a certain entity. In general, the notion of belief “aboutness” is fairly fuzzy and it may be difficult to circumscribe precisely without some additional constraints. Suppose then that one of the ultimate objectives of belief extraction is to populate a knowledge base with beliefs held about specific entities: individuals"
S15-1009,baker-etal-2010-modality,0,0.0482113,"Missing"
S15-1009,W13-2322,0,0.0158937,"xt passage describing the proposition). We do not propose to develop our own semantic representation, but instead we will look to using existing relation and event representations based on the ACE program (Doddington et al., 2004). These have the advantage that there are offthe-shelf computational tools available for detecting ACE relations and events; they have the disadvantage that they do not cover all propositions we may be interested in. An alternative would be the use of a shallower semantic representation such as PropBank (Kingsbury et al., 2002), FrameNet (Baker et al., 1998), or AMR (Banarescu et al., 2013). 7.3 Entities as Targets In Section 6, we discussed an initial evaluation of a belief being about an entity. In this section we discuss further guidelines for identifying belief targets, i.e., when one can say that someone’s belief is about 89 a certain entity. In general, the notion of belief “aboutness” is fairly fuzzy and it may be difficult to circumscribe precisely without some additional constraints. Suppose then that one of the ultimate objectives of belief extraction is to populate a knowledge base with beliefs held about specific entities: individuals, groups, artifacts, etc., which"
S15-1009,W09-3012,1,0.690346,"space we do not provide an overview over all definitions. While at first the terms “belief” and “factuality” appear to relate to rather different things (a subjective state versus truth), in the NLP community they in fact refer to the same phenomenon, while having rather different connotations. The phenomenon is the communicative intention of a writer1 to present propositional content as something that she firmly believes is true, weakly believes is true, or has some other attitude towards, namely a wish or a reported belief. The term “belief” here describes the cognitive state of the writer (Diab et al., 2009), and comes from artificial intelligence and cognitive science, as in the Belief-Desire-Intention model of Bratman (1999 1987). The term “factuality” describes the communicative intention of the writer (Saur´ı and Pustejovsky, 2012, p. 263) (our emphasis): The fact that an eventuality is depicted as holding or not does not mean that this is the case in the world, but that this is how it is characterized by its informant. Similarly, it does not mean that this is the real knowledge that informant has (his true cognitive state regarding that event) but what he wants us to believe it is. We would"
S15-1009,doddington-etal-2004-automatic,1,0.834711,"sity/George Washington University, the Florida Institute for Human and Machine Cognition, and the University of Albany. The goal of our research project is not linguistic annotation, but the identification of meaning which is expressed in a non-linguistic manner. Such a meaning representation is useful for many applications; in our project we are specifically interested in knowledge base population. A different part of the DEFT program is concerned with the representation of propositional meaning, following the tradition of the ACE program in representing entities, relations and events (ERE) (Doddington et al., 2004). The work presented here is concerned with the attitude of agents towards propositional content: do the agents express a committed belief or a non-committed belief in the propositional content? Our work has several characteristics that set it apart from other work: we are interested in annotation which can be done fairly quickly; we are not interested in annotating linguistic elements (such as trigger words); and we are planning an integration with sentiment annotation. The structure of the paper is as follows: we start out by situating our notion of “belief” with respect to other notions of"
S15-1009,W10-3001,0,0.293703,"Missing"
S15-1009,P11-2102,0,0.0364363,"rotates around the earth, as was his (presumably) honest communicative intention. Therefore, to us as researchers interested in describing how language 2 Sarcasm and irony differ from lying in that the communicative intention and the cognitive state are aligned, but they do not align with the standard interpretation of the utterance. Here, the intention is that the reader recognizes that the form of the utterance does not literally express the cognitive state. We leave aside sarcasm and irony in this paper; for current computational work on sarcasm detection, see for example (Gonz´alez-Ib´an˜ ez et al., 2011). is used to communicate, it does not matter that astronomers now believe that Ptolemy was wrong, it does not change our account of communication and it does not change the communication that happened two millennia ago. And since we do not need to make the assumption that the writer knows what she is talking about, we choose not to make this assumption. In the case of Ptolemy, we leave this determination – what is actually true – to astronomers. In other cases, we typically have models of trustworthiness: if a writer sends her spouse a text message saying she is hungry, the spouse has no reaso"
S15-1009,P09-2078,0,0.0256017,"d, we could assume that the writer knows what is true (assumption of truth). In this paper, we do not make this second assumption. We discuss these two assumptions in turn. We start with the assumption of truthfulness. In the quote above, Saur´ı and Pustejovsky (2012) (apart from distinguishing factuality from truth) also make the point that the writer’s communicative intention of making the reader believe she has a specific belief state does not mean that she actually has that cognitive state, since she may be lying. Lying is clearly an important phenomenon that researchers have looked into (Mihalcea and Strapparava, 2009; Ott et al., 2011).2 However, we (as linguists interested in understanding how language enables communication) feel that assuming the writer is truthful is a standard assumption about communication which we should in general make. This is because if we do not make this assumption, we cannot explain why communication is possible at all, since discourse participants would have no motivation to ever adopt another discourse participant’s belief as their own. We therefore do claim that we can infer belief from utterances, while assuming that the writer is not lying, and knowing that this assumptio"
S15-1009,P11-1032,0,0.0145471,"er knows what is true (assumption of truth). In this paper, we do not make this second assumption. We discuss these two assumptions in turn. We start with the assumption of truthfulness. In the quote above, Saur´ı and Pustejovsky (2012) (apart from distinguishing factuality from truth) also make the point that the writer’s communicative intention of making the reader believe she has a specific belief state does not mean that she actually has that cognitive state, since she may be lying. Lying is clearly an important phenomenon that researchers have looked into (Mihalcea and Strapparava, 2009; Ott et al., 2011).2 However, we (as linguists interested in understanding how language enables communication) feel that assuming the writer is truthful is a standard assumption about communication which we should in general make. This is because if we do not make this assumption, we cannot explain why communication is possible at all, since discourse participants would have no motivation to ever adopt another discourse participant’s belief as their own. We therefore do claim that we can infer belief from utterances, while assuming that the writer is not lying, and knowing that this assumption may be false in c"
S15-1009,C10-2117,1,0.747479,"on-committed belief in the annotations, the heuristic rules (mainly based on the presence of modal auxiliaries) that we added for the purpose of classifying the beliefs (CB, NCB, ROB, NA) did not work reliably in all cases. 4.3 System C System C uses a supervised learning approach to identify tokens denoting the heads of propositions that denote author’s expressed beliefs. It approaches this problem as a 5-way (CB, NCB, ROB, NA, nil) multi-class classification task at the word level. System C is adapted from a previous system which uses an earlier, simpler definition and annotation of belief (Prabhakaran et al., 2010). The system uses lexical and syntactic features for this task, which are extracted using the part-of-speech tags and dependency parses obtained from the Stanford CoreNLP system. In addition to the features described in (Prabhakaran et al., 2010), System C uses a set of new features including features based on a dictionary of hedge-words (Prokofieva and Hirschberg, 2014). The hedge features improved the NCB Fmeasure by around 2.2 percentage points (an overall F-measure improvement of 0.25 percentage points) in experiments conducted on a separate development set. It uses a quadratic kernel SVM"
S15-1009,W12-3807,1,0.915772,"Missing"
S15-1009,J12-2002,0,0.157236,"Missing"
S15-1009,W15-1304,1,0.70443,"ore, the FactBank annotation is basically compatible with ours. Our annotation is much simpler than that of FactBank in order to allow for a quicker annotation. We summarize the main points of simplification here. • We have taken the source always to be the writer. As we will discuss in Section 7.1, we will adopt the FactBank annotation in the next iteration of our annotation. • We do not distinguish between possible and probable; this distinction may be hard to annotate and not too valuable. • We ignore negation. If present, we simply assume it is part of the proposition which is the target. Werner et al. (2015) study the relation between belief and factuality in more detail. They provide an automatic way of mapping the annotations in FactBank to the 4-way distinction of speaker/writer’s belief that we present in this paper. 3.3 Corpus and Annotation Results The annotation effort for this phase of belief annotation for DEFT produced a training corpus of 852,836 words and an evaluation corpus of 100,037 words. All annotated data consisted of English text from discussion forum threads. The discussion forum threads were originally collected for the DARPA BOLT program, and were harvested from a wide vari"
S15-1009,C98-1013,0,\N,Missing
saggion-etal-2002-extracting,X98-1004,0,\N,Missing
saggion-etal-2002-extracting,P00-1036,0,\N,Missing
saggion-etal-2002-extracting,J95-4004,0,\N,Missing
saggion-etal-2002-extracting,W01-1017,1,\N,Missing
saggion-etal-2002-extracting,O98-4002,1,\N,Missing
T78-1025,T75-2006,0,\N,Missing
T78-1025,T75-2009,1,\N,Missing
W00-1501,gamback-olsson-2000-experiences,0,\N,Missing
W00-1501,A97-1034,0,\N,Missing
W00-1501,A97-1035,1,\N,Missing
W00-1501,A97-1051,0,\N,Missing
W00-1501,E99-1035,0,\N,Missing
W00-1501,cunningham-etal-2000-software,1,\N,Missing
W00-1501,C96-1079,0,\N,Missing
W01-1004,J92-4003,0,0.0165778,"Missing"
W01-1004,M98-1007,0,0.0295886,"Missing"
W01-1004,W01-1002,0,0.0327066,"Missing"
W01-1004,J96-2003,0,0.0220405,"Missing"
W01-1004,C00-2136,0,0.0501815,"Missing"
W01-1013,2000.iwpt-1.7,0,0.155609,"Missing"
W01-1013,P00-1064,0,0.0912682,"Missing"
W01-1013,O98-4002,1,0.865745,"Missing"
W01-1013,W98-0705,0,0.144557,"Missing"
W01-1013,M95-1017,0,\N,Missing
W03-2705,P79-1002,0,0.151303,"ystems because, unlike IE, there is little or no benchmarked performance with which to decide which modules and theoretical features aid robust dialogue performance. The lack of an established evaluation methodology is, by common consent, one of the main features holding back robust dialogue development methodology. We cannot even appeal to some accepted progression of systems towards an agreed level of maturity, as one can in some areas on NLP: even very primitive dialogue systems from long ago contain features which many would associate with very sophisticated systems: Carbonell’s POLITICS (Carbonell, 1979) seems to be just a series of questions and answers to a complex knowledge base, Speech Recognition Fusion Gesture Recognition Dialogue & Action Management Speech Generation Bathroom Application Fission Avatar Figure 1: Simplified COMIC architecture and might therefore be deemed a very simple dialogue grammar, lacking even a global structure of greetings and goodbyes. But it is clear that he considers the system to deploy coded forms of goals, beliefs and plans, which one might take as a sufficient property for a more developed class of systems. Again, PARRY (Colby, 1971) the most developed an"
W03-2705,M93-1009,0,0.0372143,"els, including facial expressions, gaze, lip movements, and whole-head gestures such as nodding; and other visual channels, including drawings and graphics. The output processing module consist of three sub-modules reflecting these output channels. Speech Generation realises the verbal channel, the avatar is the vehicle for the head, and the ViSoft 3 3.1 Designing the Dialogue and Action Management Module in COMIC Initial Considerations Any survey of this field right now might suggest that we may be in something of the same position as the field of Information Extraction (IE) when Jerry Hobbs(Hobbs, 1993) wrote his brief note on a generic IE systems, on the assumption that all functioning IE systems contained roughly the same modules doing the same tasks, and that the claimed differences were largely matters of advertising, plus dubious claims to special theories with trademarked names. However, we may be in a worse position with dialogue systems because, unlike IE, there is little or no benchmarked performance with which to decide which modules and theoretical features aid robust dialogue performance. The lack of an established evaluation methodology is, by common consent, one of the main fea"
W06-0903,W01-1313,0,0.0492531,"Missing"
W06-0903,P00-1010,0,0.101254,"Missing"
W06-0903,N03-2019,0,0.0841644,"s and Setzer, 2002; Pustejovsky et al., 2003; Ferro et al., 2004), TDRL (Aramburu and Berlanga, 1998) and their associated evaluations such as the ACE TERN competition (Sundheim et al. 2004). Temporal analysis has also been applied in Question-Answering systems (Pustejovsky et al., 2004; Schilder and Habel, 2003; Prager et al., 2003), email classification (Kiritchenko et al., 2004), aiding the precision of Information Retrieval results (Berlanga et al., 2001), document summarisation (Mani and Wilson, 2000), time stamping of event clauses (Filatova and Hovy, 2001), temporal ordering of events (Mani et al., 2003) and temporal reasoning from text (Boguraev and Ando, 2005; Moldovan et al., 2005). A growing body of related work related to the computational treatment of time in language has also been building up largely since 2000 (COLING 2000; ACL 2001; LREC 2002; TERQAS 2002; TANGO 2003, Dagstuhl 2005). There is also a large body of work on time series analysis and temporal logic in Physics, Economics and Mathematics, providing important techniques and general background information. In particular, this work uses techniques adapted from Seasonal ARIMA (auto-regressive integrated moving average) models ("
W06-0903,P94-1013,0,0.0283258,"extracted from the documents itself is also useful in dating the documents – for example, if a document contains many references to the year 2006, it is quite likely that the document was written in 2006 (or in the last few weeks of December 2005). These notions have been used implicitly by researchers and historians when validating the authenticity of documents, but have not been utilised much in automated systems. Similar applications have so far been largely confined to authorship identification, such as (Mosteller and Wallace, 1964; Fung, 2003) and the identification of association rules (Yarowsky, 1994; Silverstein et al., 1997). Temporal information is presently underutilised for automated document classification purposes, especially when it comes to guessing at the document creation date automatically. This work presents a method of using periodical temporal-frequency information present in documents to create temporal-association rules that can be used for automatic document dating. Past and ongoing related research work has largely focused on the identification and tagging of temporal expressions, with the creation of tagging methodologies such as TimeML/TIMEX (Gaizauskas and Setzer, 20"
W13-0905,W08-2227,1,0.746753,"Missing"
W13-0905,de-marneffe-etal-2006-generating,0,0.0037551,"Missing"
W13-0905,J83-3004,1,0.534234,"ct and so again trigger a metaphor. The preference notion was not initially intended to detect metaphor but to semantically disambiguate candidates at those sites by preferring those conceptual entities that did not violate such restrictions. In early work, preferences were largely derived by intuition and sometimes ordered by salience. Later (e.g. Resnik, 1997) there was a range of work on deriving such preferences from corpora; however, in VN the semantic preferences of verbs were again largely intuitive in origin. Early work linking preference violation to metaphor detection (summarised in Fass and Wilks, 1983, also Martin 1990) worked with handcrafted resources, but by 1995 Dolan had noted (Dolan, 1995) that large-scale lexical resources would have implications for metaphor detection, and WN was used in conjunction with corpora, by 37 (Peters and Wilks, 2003) using symbolic methods and by Mason (2004) and Krishnakumaran and Zhu (2007) using a combination of WN and statistical methods. Mason also acquires preferences automatically from corpora, and the latter two papers treat metaphor as a form of anomaly based on rare combinations of surface words and of WNderived hypernyms, a notion that appears"
W13-0905,P05-1045,0,0.00991608,". VN includes classes of verbs that map members to specific WN senses. VN also provides a hierarchy of verb object/subject inclusions, which we use for assessing whether one sentence object/subject type appears below another in this simple inclusion hierarchy, and so can be said to be semantically included in it. The selectional restrictions, however, are not linked to any lexicons so a mapping was constructed in order to allow for automated detection of preference violations. Our first experiment utilizes WN, VN, and the Stanford Parser (de Marneffe et al., 2006) and Named Entity Recognizer (Finkel et al., 2005). The Stanford Parser identifies the verbs, as well as their corresponding subjects and direct objects. The Stanford Named Entity Recognizer was used to replace sequences of text representing names with WN senses whose hypernyms exist in the selectional restriction hierarchy. The first step in determining whether a sentence contains a metaphor is to extract all verbs along with the subject and direct object arguments for each verb. The Stanford Parser dependencies used to describe the relationships between verbs and 38 their arguments include agent, nsubj, and xsubj for subjects and dobj and n"
W13-0905,W07-0103,0,0.110031,"Missing"
W13-0905,C10-2078,0,0.0448363,"the original preference violation insight can be combined with large-scale investigations, using notions of machine learning and large-scale resources like WN. Our approach is smaller scale and does not involve machine learning: it simply seeks access to implicit metaphors built into the structure of WN by its creators, and which a preference-violation detection criterion cannot, by definition, access. Thus, we view our contribution as complementary to larger efforts on metaphor and interpretation detection, rather than a competing approach. We have not made comparisons here with the work of (Li and Sporleder, 2010), which is explicitly concerned with idioms, nor with (Markert and Nissim, 2009) which is focused on metonymy. 3 The Conventional Metaphor Detection Hypotheses Where WN codes conventionalized metaphors as senses, as in the initial cases described, then the senses expressing these will NOT violate preferences and so will not be detected by any metaphoras-violation hypothesis. For example, in “Jane married a brick” this will not be a preference violation against WN senses because WN explicitly codes brick as a reliable person, though we would almost certainly want to say this sentence contains a"
W13-0905,J04-1002,0,0.403161,"d sometimes ordered by salience. Later (e.g. Resnik, 1997) there was a range of work on deriving such preferences from corpora; however, in VN the semantic preferences of verbs were again largely intuitive in origin. Early work linking preference violation to metaphor detection (summarised in Fass and Wilks, 1983, also Martin 1990) worked with handcrafted resources, but by 1995 Dolan had noted (Dolan, 1995) that large-scale lexical resources would have implications for metaphor detection, and WN was used in conjunction with corpora, by 37 (Peters and Wilks, 2003) using symbolic methods and by Mason (2004) and Krishnakumaran and Zhu (2007) using a combination of WN and statistical methods. Mason also acquires preferences automatically from corpora, and the latter two papers treat metaphor as a form of anomaly based on rare combinations of surface words and of WNderived hypernyms, a notion that appears in (Guthrie et al., 2007) but based only on corpus sparsity and not WN codings. Other work on the automatic acquisition of preferences (McCarthy and Carrol, 2003) for WSD has also its considered extension to the detection of classes of metaphor. More recently, work by Shutova (Shutova et al., 2010"
W13-0905,J03-4004,0,0.0103056,"d have implications for metaphor detection, and WN was used in conjunction with corpora, by 37 (Peters and Wilks, 2003) using symbolic methods and by Mason (2004) and Krishnakumaran and Zhu (2007) using a combination of WN and statistical methods. Mason also acquires preferences automatically from corpora, and the latter two papers treat metaphor as a form of anomaly based on rare combinations of surface words and of WNderived hypernyms, a notion that appears in (Guthrie et al., 2007) but based only on corpus sparsity and not WN codings. Other work on the automatic acquisition of preferences (McCarthy and Carrol, 2003) for WSD has also its considered extension to the detection of classes of metaphor. More recently, work by Shutova (Shutova et al., 2010) has shown that the original preference violation insight can be combined with large-scale investigations, using notions of machine learning and large-scale resources like WN. Our approach is smaller scale and does not involve machine learning: it simply seeks access to implicit metaphors built into the structure of WN by its creators, and which a preference-violation detection criterion cannot, by definition, access. Thus, we view our contribution as complem"
W13-0905,P04-1036,0,0.0273827,"TRIPS lexicon and ontology to dynamically build lexical entries with approximate semantic and syntactic structures for words not in the core lexicon. This process may produce a range of different possibilities based on the different senses and possible subcategorization frames for the verbs that share the same TRIPS type. We feed all of these to the parser and let it determine the entries that best match the definition and examples. While WordNet may have multiple fine-grained senses for a given word, we set a parameter that has the system use only the most frequent sense(s) of the word (cf. McCarthy et al. 2004). We use TRIPS to parse the definitions and glosses into a logical form. Figure 3 shows the logical form produced for the definition cause to die. We then search the logical form for structures that signal a potential argument that would fill a role. Besides looking for gaps, we found some other devices that serve the same purpose and occur frequently in WordNet: • • • • elided arguments (an IMPRO in the logical form); indefinite pronouns (e.g., something, someone); prepositional/adverbial forms containing an IMPRO or an indefinite pronoun (e.g., give a benediction to); a noun phrase in parent"
W13-0905,J05-1004,0,0.00318773,"very broad WN sense sets those that are actually conventionalized metaphors: we determine that only the first sense, hopefully literal, should be able to satisfy any restriction. If a lower sense satisfies a verb, but the primary sense does not, we classify the satisfaction as being conventionalized, but a metaphor nonetheless. 6 Deriving Preferences and an Ontology from WordNet To date, VerbNet is the most extensive resource for verb roles and restrictions. It provides a rich semantic role taxonomy with some selectional restrictions. Still, VN has entries for less than 4000 verbs. PropBank (Palmer et al., 2005) has addi40 tional coverage, but uses a more surface oriented role set with no selectional restrictions. On the other hand, WordNet has many more verb entries but they lack semantic role information. However, we believe it is possible to extract automatically a comprehensive lexicon of verbs with semantic roles and selectional restrictions from WN by processing definitions in WN using deep understanding techniques. Specifically, each verb in WN comes with a gloss that defines the verb sense, and there we can find clues about the semantic roles and their selectional restrictions. Thus, we are t"
W13-0905,W97-0209,0,0.184674,"nomic value”, and muscle is not an abstract entity. There was discussion in those early days of syntactic-semantic interface cases like “John ran a mile” where a mile might be said to violate the preference of the (intransitive) verb for a zero object and so again trigger a metaphor. The preference notion was not initially intended to detect metaphor but to semantically disambiguate candidates at those sites by preferring those conceptual entities that did not violate such restrictions. In early work, preferences were largely derived by intuition and sometimes ordered by salience. Later (e.g. Resnik, 1997) there was a range of work on deriving such preferences from corpora; however, in VN the semantic preferences of verbs were again largely intuitive in origin. Early work linking preference violation to metaphor detection (summarised in Fass and Wilks, 1983, also Martin 1990) worked with handcrafted resources, but by 1995 Dolan had noted (Dolan, 1995) that large-scale lexical resources would have implications for metaphor detection, and WN was used in conjunction with corpora, by 37 (Peters and Wilks, 2003) using symbolic methods and by Mason (2004) and Krishnakumaran and Zhu (2007) using a com"
W13-0905,C10-1113,0,0.0788153,"and by Mason (2004) and Krishnakumaran and Zhu (2007) using a combination of WN and statistical methods. Mason also acquires preferences automatically from corpora, and the latter two papers treat metaphor as a form of anomaly based on rare combinations of surface words and of WNderived hypernyms, a notion that appears in (Guthrie et al., 2007) but based only on corpus sparsity and not WN codings. Other work on the automatic acquisition of preferences (McCarthy and Carrol, 2003) for WSD has also its considered extension to the detection of classes of metaphor. More recently, work by Shutova (Shutova et al., 2010) has shown that the original preference violation insight can be combined with large-scale investigations, using notions of machine learning and large-scale resources like WN. Our approach is smaller scale and does not involve machine learning: it simply seeks access to implicit metaphors built into the structure of WN by its creators, and which a preference-violation detection criterion cannot, by definition, access. Thus, we view our contribution as complementary to larger efforts on metaphor and interpretation detection, rather than a competing approach. We have not made comparisons here wi"
W97-0208,H92-1022,0,0.184011,"e chosen to use the machine readable version of LDOCE as our lexicon. This has been 49 used extensively in NLP research and provides a broad set of senses for sense tagging. The text is initially stemmed, leaving only morphological roots, and split into sentences. Then words belonging to a list of stop words (prepositions, pronouns etc.) are removed. For each of the remaining words, e ~ of its senses are extracted from LDOCE and stored with that word. The textual definitions in each sense is processed to remove stop words and stem remaining words. 2. The text is tagged using the Brill tagger (Brill, 1992) and a translation is carried out using a manually defined mapping from the syntactic tags assigned by Briil (Penn Tree Bank tags (Marcus, Santorini, and Marcinkiewicz, 1993)) onto the simpler part-of-speech categories associated with LDOCE senses. We then remove all senses whose part-of-speech is not consistent with the one assigned by the tagger, if none of the senses are consistent with the part-of-speech we assume the tagger has made an error and do not remove any senses. 3. The final stage is to use the simulated annealing algorithm to optimise the dictionary deftnition overlap for the re"
W97-0208,C92-4189,0,0.312739,"ord sense disambiguation (WSD) algorithms. By WSD algorithm we mean any procedure which carries out semantic disambignation on words, these may not necessarily be tagging algorithms, in that they do 2 Recent Word Sense Disambiguation algorithms Recent word sense disambignation (WSD) algorithms can be categorised into two broad types: 1. WSD using information in an explicit lexicon. This is usually a Machine Readable Dictionary (MRD) such as the Longman Dictionary o] Contemporary English (LDOCE) (Procter, 1978), WordNet (Miller (Ed.), 1990) or handcrafted. Recent examples of this work include (Bruce and Guthrie, 1992), (Bruce and Wiebe, 1994), (McRoy, 1992). 2. WSD using information gained from training on some corpus. This approach can be further subIOften loosened to each content word in a text. 47 m m classified: (a) Supervised training, where information is gathered from corpora which have already been semantically disambiguated. As such corpora are hard to obtain, usually requiring expensive hand-tagging, researchin this area has concentrated on other forms of lexical ambiguities, eg. (Gale, Church, and Yarowsky, 1992). (b) Unsupervised training, where information is gathered from raw corpora which ha"
W97-0208,P94-1020,0,0.0475901,"SD) algorithms. By WSD algorithm we mean any procedure which carries out semantic disambignation on words, these may not necessarily be tagging algorithms, in that they do 2 Recent Word Sense Disambiguation algorithms Recent word sense disambignation (WSD) algorithms can be categorised into two broad types: 1. WSD using information in an explicit lexicon. This is usually a Machine Readable Dictionary (MRD) such as the Longman Dictionary o] Contemporary English (LDOCE) (Procter, 1978), WordNet (Miller (Ed.), 1990) or handcrafted. Recent examples of this work include (Bruce and Guthrie, 1992), (Bruce and Wiebe, 1994), (McRoy, 1992). 2. WSD using information gained from training on some corpus. This approach can be further subIOften loosened to each content word in a text. 47 m m classified: (a) Supervised training, where information is gathered from corpora which have already been semantically disambiguated. As such corpora are hard to obtain, usually requiring expensive hand-tagging, researchin this area has concentrated on other forms of lexical ambiguities, eg. (Gale, Church, and Yarowsky, 1992). (b) Unsupervised training, where information is gathered from raw corpora which has not been semantically d"
W97-0208,H92-1046,0,0.146275,"Missing"
W97-0208,C96-1055,0,0.0132282,"can be used to disambiguate (usually nominal) senses, as was shown by (Bruce and Guthrie, 1992) and (Yarowsky, 1992). Our intuition here is that disambiguation evidence can be gained by choosing senses which are closest in a thesanral hierarchy. Closeness in such a hierarchy can be effectively expressed as the number of nodes between concepts. We are implementing a simple algorithm which prefers close senses in our domain hierarchy which was derived from LDOCE (Bruce and Guthrie, 1992). 5.3 Collocates Recent work has been done using collocations as semantic disambiguators, (Yarowsky, 1993), (Dorr, 1996), particularly for verbs. We are attempting to derive disambiguation information by examining the prepositions as given in the subcategorization frames of verbs, and in the example sentences in LDOCE. 5.4 6 A Basic Tagger We have recently implemented a basic version of this tagger, initially incorporating only the part-ofspeech (5.1) and dictionary definition (5.5) stages in the process, with further stages to be added later. Our tagger currently consists of three modules: Selectionai Preferences • Dictionary look-up module There has been a long tradition in NLP of using selectional preference"
W97-0208,H92-1045,0,0.212931,"r, 1978), WordNet (Miller (Ed.), 1990) or handcrafted. Recent examples of this work include (Bruce and Guthrie, 1992), (Bruce and Wiebe, 1994), (McRoy, 1992). 2. WSD using information gained from training on some corpus. This approach can be further subIOften loosened to each content word in a text. 47 m m classified: (a) Supervised training, where information is gathered from corpora which have already been semantically disambiguated. As such corpora are hard to obtain, usually requiring expensive hand-tagging, researchin this area has concentrated on other forms of lexical ambiguities, eg. (Gale, Church, and Yarowsky, 1992). (b) Unsupervised training, where information is gathered from raw corpora which has not been semantically disambiguated. The best examples of this approach has been the resent work of Yarowsky - (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995). These approaches are not mutually exclusive and there are, of course, some hybrid cases, for example Luk (Luk, 1995) uses information in MRD definitions (approach 1) and statistical information from untagged corpora (approach 2b). 3 Comparing Different Approaches Approach 2a is the least promising since text tagged with word senses is practically"
W97-0208,P95-1025,0,0.0128418,"ich have already been semantically disambiguated. As such corpora are hard to obtain, usually requiring expensive hand-tagging, researchin this area has concentrated on other forms of lexical ambiguities, eg. (Gale, Church, and Yarowsky, 1992). (b) Unsupervised training, where information is gathered from raw corpora which has not been semantically disambiguated. The best examples of this approach has been the resent work of Yarowsky - (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995). These approaches are not mutually exclusive and there are, of course, some hybrid cases, for example Luk (Luk, 1995) uses information in MRD definitions (approach 1) and statistical information from untagged corpora (approach 2b). 3 Comparing Different Approaches Approach 2a is the least promising since text tagged with word senses is practically non-existent and is both time consuming and difficnlt to produce manually. Much of the research in this area has been compromised by the fact that researchers have focussed on lexical ambiguities that are not true word sense distinctions, such as words translated differently across two languages (Gale, Church, and Yarowsky, 1992) or homophones ~ (Yarowsky, 1993). E"
W97-0208,J93-2004,0,0.0269029,"t of senses for sense tagging. The text is initially stemmed, leaving only morphological roots, and split into sentences. Then words belonging to a list of stop words (prepositions, pronouns etc.) are removed. For each of the remaining words, e ~ of its senses are extracted from LDOCE and stored with that word. The textual definitions in each sense is processed to remove stop words and stem remaining words. 2. The text is tagged using the Brill tagger (Brill, 1992) and a translation is carried out using a manually defined mapping from the syntactic tags assigned by Briil (Penn Tree Bank tags (Marcus, Santorini, and Marcinkiewicz, 1993)) onto the simpler part-of-speech categories associated with LDOCE senses. We then remove all senses whose part-of-speech is not consistent with the one assigned by the tagger, if none of the senses are consistent with the part-of-speech we assume the tagger has made an error and do not remove any senses. 3. The final stage is to use the simulated annealing algorithm to optimise the dictionary deftnition overlap for the remaining senses. This algorithm assigns a single sense to each token which is the tag assodated with that token. 7 Example Output Below is an example of the senses assigned b"
W97-0208,J92-1001,0,0.754777,"gorithm we mean any procedure which carries out semantic disambignation on words, these may not necessarily be tagging algorithms, in that they do 2 Recent Word Sense Disambiguation algorithms Recent word sense disambignation (WSD) algorithms can be categorised into two broad types: 1. WSD using information in an explicit lexicon. This is usually a Machine Readable Dictionary (MRD) such as the Longman Dictionary o] Contemporary English (LDOCE) (Procter, 1978), WordNet (Miller (Ed.), 1990) or handcrafted. Recent examples of this work include (Bruce and Guthrie, 1992), (Bruce and Wiebe, 1994), (McRoy, 1992). 2. WSD using information gained from training on some corpus. This approach can be further subIOften loosened to each content word in a text. 47 m m classified: (a) Supervised training, where information is gathered from corpora which have already been semantically disambiguated. As such corpora are hard to obtain, usually requiring expensive hand-tagging, researchin this area has concentrated on other forms of lexical ambiguities, eg. (Gale, Church, and Yarowsky, 1992). (b) Unsupervised training, where information is gathered from raw corpora which has not been semantically disambiguated. T"
W97-0208,C92-2070,0,0.0639846,"(Miller (Ed.), 1990) or handcrafted. Recent examples of this work include (Bruce and Guthrie, 1992), (Bruce and Wiebe, 1994), (McRoy, 1992). 2. WSD using information gained from training on some corpus. This approach can be further subIOften loosened to each content word in a text. 47 m m classified: (a) Supervised training, where information is gathered from corpora which have already been semantically disambiguated. As such corpora are hard to obtain, usually requiring expensive hand-tagging, researchin this area has concentrated on other forms of lexical ambiguities, eg. (Gale, Church, and Yarowsky, 1992). (b) Unsupervised training, where information is gathered from raw corpora which has not been semantically disambiguated. The best examples of this approach has been the resent work of Yarowsky - (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995). These approaches are not mutually exclusive and there are, of course, some hybrid cases, for example Luk (Luk, 1995) uses information in MRD definitions (approach 1) and statistical information from untagged corpora (approach 2b). 3 Comparing Different Approaches Approach 2a is the least promising since text tagged with word senses is practically"
W97-0208,H93-1052,0,0.688258,"subIOften loosened to each content word in a text. 47 m m classified: (a) Supervised training, where information is gathered from corpora which have already been semantically disambiguated. As such corpora are hard to obtain, usually requiring expensive hand-tagging, researchin this area has concentrated on other forms of lexical ambiguities, eg. (Gale, Church, and Yarowsky, 1992). (b) Unsupervised training, where information is gathered from raw corpora which has not been semantically disambiguated. The best examples of this approach has been the resent work of Yarowsky - (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995). These approaches are not mutually exclusive and there are, of course, some hybrid cases, for example Luk (Luk, 1995) uses information in MRD definitions (approach 1) and statistical information from untagged corpora (approach 2b). 3 Comparing Different Approaches Approach 2a is the least promising since text tagged with word senses is practically non-existent and is both time consuming and difficnlt to produce manually. Much of the research in this area has been compromised by the fact that researchers have focussed on lexical ambiguities that are not true word sense distin"
W97-0208,P95-1026,0,0.166945,"d to each content word in a text. 47 m m classified: (a) Supervised training, where information is gathered from corpora which have already been semantically disambiguated. As such corpora are hard to obtain, usually requiring expensive hand-tagging, researchin this area has concentrated on other forms of lexical ambiguities, eg. (Gale, Church, and Yarowsky, 1992). (b) Unsupervised training, where information is gathered from raw corpora which has not been semantically disambiguated. The best examples of this approach has been the resent work of Yarowsky - (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995). These approaches are not mutually exclusive and there are, of course, some hybrid cases, for example Luk (Luk, 1995) uses information in MRD definitions (approach 1) and statistical information from untagged corpora (approach 2b). 3 Comparing Different Approaches Approach 2a is the least promising since text tagged with word senses is practically non-existent and is both time consuming and difficnlt to produce manually. Much of the research in this area has been compromised by the fact that researchers have focussed on lexical ambiguities that are not true word sense distinctions, such as wo"
W98-1208,W97-0211,0,0.040889,"Missing"
W98-1208,H92-1022,0,0.0159555,"en words belonging to a list of stop words s are removed. The words which have not been identified as part of a named entity or removed because it is a stop word are considered by the system to be ambiguous words and those are the words which are disambignated. For each of the ambiguous words, its set of possible senses is extracted from LDOCE and stored. Each sense in LDOCE contains a short textual definition (such as those shown in figure 5) which, when extracted from the dictionary, is processed to remove stop words and stem the remaining words. . The text is tagged using the Brill tagger (Brill, 1992) and a translation is carried out using a manually defined mapping from the syntactic tags assigned by Brill (Penn Tree Bank tags (Marcus, Santorini, and Marcinkiewicz, 1993)) onto the simpler part-of-speech categories associated with LDOCE senses 6. We then remove from consideration any of the senses whose partof-speech is not consistent with the one assigned by the tagger, if none of the senses are consistent with the part-of-speech we assume the tagger has made an error and leave the set of senses for that word unaltered. Preprocessing • Named-entity identification • Dictionary look-up Disa"
W98-1208,C92-4189,0,0.0422652,"Missing"
W98-1208,1997.tmi-1.18,0,0.0520242,"Missing"
W98-1208,J93-2004,0,0.0296192,"it is a stop word are considered by the system to be ambiguous words and those are the words which are disambignated. For each of the ambiguous words, its set of possible senses is extracted from LDOCE and stored. Each sense in LDOCE contains a short textual definition (such as those shown in figure 5) which, when extracted from the dictionary, is processed to remove stop words and stem the remaining words. . The text is tagged using the Brill tagger (Brill, 1992) and a translation is carried out using a manually defined mapping from the syntactic tags assigned by Brill (Penn Tree Bank tags (Marcus, Santorini, and Marcinkiewicz, 1993)) onto the simpler part-of-speech categories associated with LDOCE senses 6. We then remove from consideration any of the senses whose partof-speech is not consistent with the one assigned by the tagger, if none of the senses are consistent with the part-of-speech we assume the tagger has made an error and leave the set of senses for that word unaltered. Preprocessing • Named-entity identification • Dictionary look-up Disarnbiguation • Part-of-speech filtering • Dictionary definition overlap 4. Our next module is based on a proposal by Lesk (Lesk, 1986) that words in a sentence could be disam"
W98-1208,J92-1001,0,0.0322514,"case means 4LDOCE senses have additional information such as subject categories, subcategorisation information and selectional restrictions which we do not show here. Implementing a Sense Tagger m m m m m m m m m II senses in texts. A natural extension to this observation is to create a disambiguation system which makes use of several of these independent knowledge sources and combines their results in an intelligent way. Our system is based on a set of partial taggers, each of which uses a different knowledge source, with their results being combined. Our system is in the tradition of McRoy (McRoy, 1992), who also made use of several knowledge sources for word sense disambiguation, although the information sources she used were not independent, making it difficult to evaluate the contribution of each component. Our system makes use of strictly independent knowledge sources and is implemented within GATE whose plug-and-play architecture makes the evaluation of individual components more straightforward. At the moment the sense tagger consists of six stages (shown in figure 6), the first two preprocess the text which is to be disambiguated while the remaining four carry out the disambiguation."
W98-1208,P96-1006,0,0.0345721,"Missing"
W98-1208,W97-0322,0,0.0781595,"Missing"
W98-1208,C96-1071,1,0.873626,"Missing"
W98-1208,W97-0208,1,0.780338,"Missing"
W98-1208,H93-1052,0,0.0544604,"Missing"
W98-1208,P95-1026,0,0.0366988,"Missing"
W98-1208,A97-1036,0,0.0262743,"for the task graphs, and the diffculty of managing these graphs as the number of modules in the system grows. The graphs currently make two main contributions to the system: they give a graphical representation of control flow, and allow the user to manipulate execution of modules; they give a graphical entry point to results visualisation. These benefits will have to be balanced against their disadvantages in future versions of the Cunningham, Stevenson and Wilks II 69 system. Another problem may arise when the architecture includes facilities for distributed processing (Zajac et al., 1997; Zajac, 1997), as it is not obvious how the linear model currently embodied in the graphs could be extended to support non-linear control strucures. 8 Conclusion The previous section indicates that GATE version 1 goes a long way to meeting it's design goals (noted in section 2). The reuse of components we have experienced in the sense tagging project and a number of other local and collaborative projects is in itself justification of the development effort spent on the system, and, hopefully, these savings will be multiplied accross other users of the system. Future versions will address the problems we un"
W98-1208,A97-1035,1,\N,Missing
W98-1208,P94-1020,0,\N,Missing
W98-1208,H92-1045,0,\N,Missing
W98-1208,C96-1079,0,\N,Missing
W98-1208,A97-2017,1,\N,Missing
W99-0701,J93-2004,0,0.0635051,"Missing"
W99-0701,W93-0231,0,0.105862,"Missing"
W99-0701,H89-2010,0,0.0452752,"Missing"
webb-etal-2008-cross,W04-2319,0,\N,Missing
webb-etal-2008-cross,J93-3003,0,\N,Missing
webb-etal-2008-cross,N06-1036,0,\N,Missing
webb-etal-2008-cross,J00-3003,0,\N,Missing
webb-etal-2008-cross,J96-2004,0,\N,Missing
webb-etal-2008-cross,J86-3001,0,\N,Missing
webb-etal-2008-cross,P98-2188,0,\N,Missing
webb-etal-2008-cross,C98-2183,0,\N,Missing
webb-etal-2008-cross,H01-1073,0,\N,Missing
wilks-etal-2004-human,J00-3003,0,\N,Missing
wilks-etal-2004-human,P98-2188,0,\N,Missing
wilks-etal-2004-human,C98-2183,0,\N,Missing
wilks-etal-2008-dialogue,strauss-etal-2006-wizard,0,\N,Missing
X93-1021,C92-2099,0,0.0526046,"Missing"
X93-1021,J91-4003,1,0.918749,"ticular role of a tie-up (the newly formed venturein particular) are also recognized and resolved. For example, a phrase which refers to the child entity, such as &apos;the new company&apos; or &apos;the venture&apos;, will be recognized ann merged with the child of the tie-up event in focus. A stack of entities found in the text is maintained. f(time,[after,&apos;B50i&apos;],wj), f(entity_relationship,l,inf), f(entity_relationship,3,inf)]). final_entity(9, &apos;UNSPEC&apos;), f(entiCy_type,~COMPANY&apos;,&apos;UNSPEC&apos;), f(name,[~&apos;,&apos;~,&apos;,&apos;~&apos;,~Jz&apos;],&apos;UNSPEC&apos;), f(entity_relationship,l,inf), f(entity_relationship,3,inf)]). f i n a l _ r e l ( 1, [9,2], &apos;U N S P E C &apos;, &apos;P A R T N E R &apos;, &apos;U B S P E C &apos; ). Definite noun phrases can only be used for local reference. So they can only be used to refer to entities involved in the tie-up event which is in focus. On the contrary, names can be used for both local and global reference, so they can refer to any entity referred to before in the t e x t . When a reference relation between two entities is resolved they are merged to create one single entity which contains all the information about that particular entity. Since a tie-up is generally referenced by an entire sentence rather than a single no"
X93-1021,H92-1047,1,0.896541,"Missing"
X93-1021,J93-2005,1,0.842458,"Missing"
X93-1021,P92-1022,0,0.0224668,"Missing"
X93-1021,P85-1022,0,0.0572839,"Missing"
X96-1059,M93-1014,0,0.03054,"~ Takahiro Wakaot Hiroshi Yamada$ Robert Gaizauskast YorickWilkst U n i v e r s i t y of Sheffield C o m p u t e r Science D e p a r t m e n t t N E C C o r p o r a t i o n , I n f o r m a t i o n T e c h n o l o g y R e s e a r c h Laboratories.~ { takemoto, wakao, h-yamada} @hum. cl.nec, co.jp { R. Gaizauskas, Y. Wilks} @dcs.shef. ac. uk 1 Introduction Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing ([1] [2]). It has also been studied in the framework of Japanese information extraction ([3]) in recent years. Our approach to the Multi-lingual Evaluation Task (MET) for Japanese text is to consider the given task as a morphological analysis problem in Japanese. Our morphological analyzer has done all the necessary work for the recognition and classification of proper names, numerical and temporal expressions, i.e. Named Entity (NE) items in the Japanese text. The analyzer is called &quot;Amorph&quot;. Amorph recognizes NE items in two stages: dictionary lookup and rule application. First, it uses several kinds of dictionaries to segment and tag Japanese character strings. Second, based on th"
X96-1059,M95-1017,0,\N,Missing
X96-1059,M93-1010,0,\N,Missing
