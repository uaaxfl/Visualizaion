2021.findings-emnlp.194,Attribute Alignment: Controlling Text Generation from Pre-trained Language Models,2021,-1,-1,3,0.380248,3415,dian yu,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Large language models benefit from training with a large amount of unlabeled text, which gives them increasingly fluent and diverse generation capabilities. However, using these models for text generation that takes into account target attributes, such as sentiment polarity or specific topics, remains a challenge. We propose a simple and flexible method for controlling text generation by aligning disentangled attribute representations. In contrast to recent efforts on training a discriminator to perturb the token level distribution for an attribute, we use the same data to learn an alignment function to guide the pre-trained, non-controlled language model to generate texts with the target attribute without changing the original language model parameters. We evaluate our method on sentiment- and topic-controlled generation, and show large performance gains over previous methods while retaining fluency and diversity."
2021.emnlp-main.37,Automatically Exposing Problems with Neural Dialog Models,2021,-1,-1,2,0.380248,3415,dian yu,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Neural dialog models are known to suffer from problems such as generating unsafe and inconsistent responses. Even though these problems are crucial and prevalent, they are mostly manually identified by model designers through interactions. Recently, some research instructs crowdworkers to goad the bots into triggering such problems. However, humans leverage superficial clues such as hate speech, while leaving systematic problems undercover. In this paper, we propose two methods including reinforcement learning to automatically trigger a dialog model into generating problematic responses. We show the effect of our methods in exposing safety and contradiction issues with state-of-the-art dialog models."
2021.acl-long.560,Language Embeddings for Typology and Cross-lingual Transfer Learning,2021,-1,-1,3,0.380248,3415,dian yu,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Cross-lingual language tasks typically require a substantial amount of annotated data or parallel translation data. We explore whether language representations that capture relationships among languages can be learned and subsequently leveraged in cross-lingual tasks without the use of parallel data. We generate dense embeddings for 29 languages using a denoising autoencoder, and evaluate the embeddings using the World Atlas of Language Structures (WALS) and two extrinsic tasks in a zero-shot setting: cross-lingual dependency parsing and cross-lingual natural language inference."
2020.lrec-1.894,Developing {NLP} Tools with a New Corpus of Learner {S}panish,2020,-1,-1,6,0,233,sam davidson,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The development of effective NLP tools for the L2 classroom depends largely on the availability of large annotated corpora of language learner text. While annotated learner corpora of English are widely available, large learner corpora of Spanish are less common. Those Spanish corpora that are available do not contain the annotations needed to facilitate the development of tools beneficial to language learners, such as grammatical error correction. As a result, the field has seen little research in NLP tools designed to benefit Spanish language learners and teachers. We introduce COWS-L2H, a freely available corpus of Spanish learner data which includes error annotations and parallel corrected text to help researchers better understand L2 development, to examine teaching practices empirically, and to develop NLP tools to better serve the Spanish teaching community. We demonstrate the utility of this corpus by developing a neural-network based grammatical error correction system for Spanish learner writing."
2020.bea-1.9,Tracking the Evolution of Written Language Competence in {L}2 {S}panish Learners,2020,-1,-1,5,0,789,alessio miaschi,Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications,0,"In this paper we present an NLP-based approach for tracking the evolution of written language competence in L2 Spanish learners using a wide range of linguistic features automatically extracted from students{'} written productions. Beyond reporting classification results for different scenarios, we explore the connection between the most predictive features and the teaching curriculum, finding that our set of linguistic features often reflect the explicit instructions that students receive during each course."
S19-2017,{UC} {D}avis at {S}em{E}val-2019 Task 1: {DAG} Semantic Parsing with Attention-based Decoder,2019,0,1,2,0.380248,3415,dian yu,Proceedings of the 13th International Workshop on Semantic Evaluation,0,We present an encoder-decoder model for semantic parsing with UCCA SemEval 2019 Task 1. The encoder is a Bi-LSTM and the decoder uses recursive self-attention. The proposed model alleviates challenges and feature engineering in traditional transition-based and graph-based parsers. The resulting parser is simple and proved to effective on the semantic parsing task.
Q16-1014,Efficient Structured Inference for Transition-Based Parsing with Neural Networks and Error States,2016,36,5,2,0,843,ashish vaswani,Transactions of the Association for Computational Linguistics,0,"Transition-based approaches based on local classification are attractive for dependency parsing due to their simplicity and speed, despite producing results slightly below the state-of-the-art. In this paper, we propose a new approach for approximate structured inference for transition-based parsing that produces scores suitable for global scoring using local models. This is accomplished with the introduction of error states in local training, which add information about incorrect derivation paths typically left out completely in locally-trained models. Using neural networks for our local classifiers, our approach achieves 93.61{\%} accuracy for transition-based dependency parsing in English."
N16-1027,Supertagging With {LSTM}s,2016,13,34,3,0,843,ashish vaswani,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
W15-1513,Combining Distributed Vector Representations for Words,2015,11,18,2,0,37038,justin garten,Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing,0,"Recent interest in distributed vector representations for words has resulted in an increased diversity of approaches, each with strengths and weaknesses. We demonstrate how diverse vector representations may be inexpensively composed into hybrid representations, effectively leveraging strengths of individual components, as evidenced by substantial improvements on a standard word analogy task. We further compare these results over different sizes of training sets and find these advantages are more pronounced when training data is limited. Finally, we explore the relative impacts of the differences in the learning methods themselves and the size of the contexts they access."
W14-5908,Verbal Behaviors and Persuasiveness in Online Multimedia Content,2014,-1,-1,4,0,38208,moitreya chatterjee,Proceedings of the Second Workshop on Natural Language Processing for Social Media ({S}ocial{NLP}),0,None
W14-4309,Improving Classification-Based Natural Language Understanding with Non-Expert Annotation,2014,10,2,3,1,33320,fabrizio morbini,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,"Although data-driven techniques are commonly used for Natural Language Understanding in dialogue systems, their efficacy is often hampered by the lack of appropriate annotated training data in sufficient amounts. We present an approach for rapid and cost-effective annotation of training data for classification-based language understanding in conversational dialogue systems. Experiments using a webaccessible conversational character that interacts with a varied user population show that a dramatic improvement in natural language understanding and a substantial reduction in expert annotation effort can be achieved by leveraging non-expert annotation."
C14-1203,Data-driven Measurement of Child Language Development with Simple Syntactic Templates,2014,20,3,2,0,40312,shannon lubetich,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"When assessing child language development, researchers have traditionally had to choose between easily computable metrics focused on superficial aspects of language, and more expressive metrics that are carefully designed to cover specific syntactic structures and require substantial and tedious labor. Recent work has shown that existing expressive metrics for child language development can be automated and produce accurate results. We go a step further and propose that measurement of syntactic development can be performed automatically in a completely data-driven way without the need for definition of language-specific inventories of grammatical structures. As a crucial step in that direction, we show that four simple feature templates are as expressive of language development as a carefully crafted standard inventory of grammatical structures that is commonly used and has been validated empirically."
W13-4061,{R}oundtable: An Online Framework for Building Web-based Conversational Agents,2013,1,3,5,0,38438,eric forbell,Proceedings of the {SIGDIAL} 2013 Conference,0,None
W13-4064,Which {ASR} should {I} choose for my dialogue system?,2013,36,36,3,1,33320,fabrizio morbini,Proceedings of the {SIGDIAL} 2013 Conference,0,"We present an analysis of several publicly available automatic speech recognizers (ASRs) in terms of their suitability for use in different types of dialogue systems. We focus in particular on cloud based ASRs that recently have become available to the community. We include features of ASR systems and desiderata and requirements for different dialogue systems, taking into account the dialogue genre, type of user, and other features. We then present speech recognition results for six different dialogue systems. The most interesting result is that different ASR systems perform best on the data sets. We also show that there is an improvement over a previous generation of recognizers on some of these data sets. We also investigate language understanding (NLU) on the ASR output, and explore the relationship between ASR and NLU performance."
W12-1620,A Mixed-Initiative Conversational Dialogue System for Healthcare,2012,6,17,4,1,33320,fabrizio morbini,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We present a mixed initiative conversational dialogue system designed to address primarily mental health care concerns related to military deployment. It is supported by a new information-state based dialogue manager, FLoReS (Forward-Looking, Reward Seeking dialogue manager), that allows both advanced, flexible, mixed initiative interaction, and efficient policy creation by domain experts. To easily reach its target population this dialogue system is accessible as a web application."
georgila-etal-2012-practical,Practical Evaluation of Human and Synthesized Speech for Virtual Human Dialogue Systems,2012,14,10,3,0.263644,16796,kallirroi georgila,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The current practice in virtual human dialogue systems is to use professional human recordings or limited-domain speech synthesis. Both approaches lead to good performance but at a high cost. To determine the best trade-off between performance and cost, we perform a systematic evaluation of human and synthesized voices with regard to naturalness, conversational aspect, and likability. We vary the type (in-domain vs. out-of-domain), length, and content of utterances, and take into account the age and native language of raters as well as their familiarity with speech synthesis. We present detailed results from two studies, a pilot one and one run on Amazon's Mechanical Turk. Our results suggest that a professional human voice can supersede both an amateur human voice and synthesized voices. Also, a high-quality general-purpose voice or a good limited-domain voice can perform better than amateur human recordings. We do not find any significant differences between the performance of a high-quality general-purpose voice and a limited-domain voice, both trained with speech recorded by actors. As expected, the high-quality general-purpose voice is rated higher than the limited-domain voice for out-of-domain sentences and lower for in-domain sentences. There is also a trend for long or negative-content utterances to receive lower ratings."
W11-2006,Toward Learning and Evaluation of Dialogue Policies with Text Examples,2011,14,12,3,0.9375,31518,david devault,Proceedings of the {SIGDIAL} 2011 Conference,0,"We present a dialogue collection and enrichment framework that is designed to explore the learning and evaluation of dialogue policies for simple conversational characters using textual training data. To facilitate learning and evaluation, our framework enriches a collection of role-play dialogues with additional training data, including paraphrases of user utterances, and multiple independent judgments by external referees about the best policy response for the character at each point. As a case study, we use this framework to train a policy for a limited domain tactical questioning character, reaching promising performance. We also introduce an automatic policy evaluation metric that recognizes the validity of multiple conversational responses at each point in a dialogue. We use this metric to explore the variability in human opinion about optimal policy decisions, and to automatically evaluate several learned policies in our example domain."
P11-2017,Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems,2011,7,6,2,1,33320,fabrizio morbini,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"Individual utterances often serve multiple communicative purposes in dialogue. We present a data-driven approach for identification of multiple dialogue acts in single utterances in the context of dialogue systems with limited training data. Our approach results in significantly increased understanding of user intent, compared to two strong baselines."
I11-1150,An Evaluation of Alternative Strategies for Implementing Dialogue Policies Using Statistical Classification and Hand-Authored Rules,2011,13,2,3,0.9375,31518,david devault,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"We present and evaluate a set of architectures for conversational dialogue systems, exploring rule-based and statistical classification approaches. In a case study, we show that while a rule-based dialogue policy is capable of high performance if perfect natural language understanding is assumed, a direct classification approach that combines the dialogue policy with NLU has practical advantages."
W10-2606,Self-Training without Reranking for Parser Domain Adaptation and Its Impact on Semantic Role Labeling,2010,17,29,1,1,6910,kenji sagae,Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Processing,0,"We compare self-training with and without reranking for parser domain adaptation, and examine the impact of syntactic parser adaptation on a semantic role labeling system. Although self-training without reranking has been found not to improve in-domain accuracy for parsers trained on the WSJ Penn Treebank, we show that it is surprisingly effective for parser domain adaptation. We also show that simple self-training of a syntactic parser improves out-of-domain accuracy of a semantic role labeler."
W10-0906,Open-domain Commonsense Reasoning Using Discourse Relations from a Corpus of Weblog Stories,2010,16,9,3,0,37464,matthew gerber,Proceedings of the {NAACL} {HLT} 2010 First International Workshop on Formalisms and Methodology for Learning by Reading,0,"We present a method of extracting open-domain commonsense knowledge by applying discourse parsing to a large corpus of personal stories written by Internet authors. We demonstrate the use of a linear-time, joint syntax/discourse dependency parser for this purpose, and we show how the extracted discourse relations can be used to generate open-domain textual inferences. Our evaluations of the discourse parser and inference models show some success, but also identify a number of interesting directions for future work."
P10-1110,Dynamic Programming for Linear-Time Incremental Parsing,2010,29,181,2,0,8438,liang huang,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"Incremental parsing techniques such as shift-reduce have gained popularity thanks to their efficiency, but there remains a major problem: the search is greedy and only explores a tiny fraction of the whole space (even with beam search) as opposed to dynamic programming. We show that, surprisingly, dynamic programming is in fact possible for many shift-reduce parsers, by merging equivalent stacks based on feature values. Empirically, our algorithm yields up to a five-fold speedup over a state-of-the-art shift-reduce dependency parser with no loss in accuracy. Better search also leads to better learning, and our final parser outperforms all previously reported dependency parsers for English and Chinese, yet is much faster."
N10-2009,Interpretation of Partial Utterances in Virtual Human Dialogue Systems,2010,8,6,1,1,6910,kenji sagae,Proceedings of the {NAACL} {HLT} 2010 Demonstration Session,0,"Dialogue systems typically follow a rigid pace of interaction where the system waits until the user has finished speaking before producing a response. Interpreting user utterances before they are completed allows a system to display more sophisticated conversational behavior, such as rapid turn-taking and appropriate use of backchannels and interruptions. We demonstrate a natural language understanding approach for partial utterances, and its use in a virtual human dialogue system that can often complete a user's utterances in real time."
yao-etal-2010-practical,Practical Evaluation of Speech Recognizers for Virtual Human Dialogue Systems,2010,15,8,4,0,37412,xuchen yao,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We perform a large-scale evaluation of multiple off-the-shelf speech recognizers across diverse domains for virtual human dialogue systems. Our evaluation is aimed at speech recognition consumers and potential consumers with limited experience with readily available recognizers. We focus on practical factors to determine what levels of performance can be expected from different available recognizers in various projects featuring different types of conversational utterances. Our results show that there is no single recognizer that outperforms all other recognizers in all domains. The performance of each recognizer may vary significantly depending on the domain, the size and perplexity of the corpus, the out-of-vocabulary rate, and whether acoustic and language model adaptation has been used or not. We expect that our evaluation will prove useful to other speech recognition consumers, especially in the dialogue community, and will shed some light on the key problem in spoken dialogue systems of selecting the most suitable available speech recognition system for a particular application, and what impact training will have."
C10-1097,Latent Mixture of Discriminative Experts for Multimodal Prediction Modeling,2010,33,12,2,0,44612,derya ozkan,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"During face-to-face conversation, people naturally integrate speech, gestures and higher level language interpretations to predict the right time to start talking or to give backchannel feedback. In this paper we introduce a new model called Latent Mixture of Discriminative Experts which addresses some of the key issues with multimodal language processing: (1) temporal synchrony/asynchrony between modalities, (2) micro dynamics and (3) integration of different levels of interpretation. We present an empirical evaluation on listener nonverbal feedback prediction (e.g., head nod), based on observable behaviors of the speaker. We confirm the importance of combining four types of multimodal features: lexical, syntactic structure, eye gaze, and prosody. We show that our Latent Mixture of Discriminative Experts model outperforms previous approaches based on Conditional Random Fields (CRFs) and Latent-Dynamic CRFs."
W09-3902,Can {I} Finish? Learning When to Respond to Incremental Interpretation Results in Interactive Dialogue,2009,20,60,2,0.9375,31518,david devault,Proceedings of the {SIGDIAL} 2009 Conference,0,"We investigate novel approaches to responsive overlap behaviors in dialogue systems, opening possibilities for systems to interrupt, acknowledge or complete a user's utterance while it is still in progress. Our specific contributions are a method for determining when a system has reached a point of maximal understanding of an ongoing user utterance, and a prototype implementation that shows how systems can use this ability to strategically initiate system completions of user utterances. More broadly, this framework facilitates the implementation of a range of overlap behaviors that are common in human dialogue, but have been largely absent in dialogue systems."
W09-3813,Analysis of Discourse Structure with Syntactic Dependencies and Data-Driven Shift-Reduce Parsing,2009,16,43,1,1,6910,kenji sagae,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,"We present an efficient approach for discourse parsing within and across sentences, where the unit of processing is an entire document, and not a single sentence. We apply shift-reduce algorithms for dependency and constituent parsing to determine syntactic dependencies for the sentences in a document, and subsequently a Rhetorical Structure Theory (RST) tree for the entire document. Our results show that our linear-time shift-reduce framework achieves high accuracy and a large improvement in efficiency compared to a state-of-the-art approach based on chart parsing with dynamic programming."
W09-3829,Clustering Words by Syntactic Similarity improves Dependency Parsing of Predicate-argument Structures,2009,32,24,1,1,6910,kenji sagae,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,"We present an approach for deriving syntactic word clusters from parsed text, grouping words according to their unlexicalized syntactic contexts. We then explore the use of these syntactic clusters in leveraging a large corpus of trees generated by a high-accuracy parser to improve the accuracy of another parser based on a different formalism for representing a different level of sentence structure. In our experiments, we use phrase-structure trees to produce syntactic word clusters that are used by a predicate-argument dependency parser, significantly improving its accuracy."
N09-2014,Towards Natural Language Understanding of Partial Speech Recognition Results in Dialogue Systems,2009,6,37,1,1,6910,kenji sagae,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,We investigate natural language understanding of partial speech recognition results to equip a dialogue system with incremental language processing capabilities for more realistic human-computer conversations. We show that relatively high accuracy can be achieved in understanding of spontaneous utterances before utterances are completed.
W08-0504,Evaluating the Effects of Treebank Size in a Practical Application for Parsing,2008,14,2,1,1,6910,kenji sagae,"Software Engineering, Testing, and Quality Assurance for Natural Language Processing",0,"Natural language processing modules such as part-of-speech taggers, named-entity recognizers and syntactic parsers are commonly evaluated in isolation, under the assumption that artificial evaluation metrics for individual parts are predictive of practical performance of more complex language technology systems that perform practical tasks. Although this is an important issue in the design and engineering of systems that use natural language input, it is often unclear how the accuracy of an end-user application is affected by parameters that affect individual NLP modules. We explore this issue in the context of a specific task by examining the relationship between the accuracy of a syntactic parser and the overall performance of an information extraction system for biomedical text that includes the parser as one of its components. We present an empirical investigation of the relationship between factors that affect the accuracy of syntactic analysis, and how the difference in parse accuracy affects the overall system."
P08-1006,Task-oriented Evaluation of Syntactic Parsers and Their Representations,2008,41,71,3,0,5928,yusuke miyao,Proceedings of ACL-08: HLT,1,"This paper presents a comparative evaluation of several state-of-the-art English parsers based on different frameworks. Our approach is to measure the impact of each parser when it is used as a component of an information extraction system that performs protein-protein interaction (PPI) identification in biomedical papers. We evaluate eight parsers (based on dependency parsing, phrase structure parsing, or deep parsing) using five different parse representations. We run a PPI system with several combinations of parser and parse representation, and examine their impact on PPI identification accuracy. Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data."
tateisi-etal-2008-genia,{GENIA}-{GR}: a Grammatical Relation Corpus for Parser Evaluation in the Biomedical Domain,2008,21,5,3,0,35318,yuka tateisi,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We report the construction of a corpus for parser evaluation in the biomedical domain. A 50-abstract subset (492 sentences) of the GENIA corpus (Kim et al., 2003) is annotated with labeled head-dependent relations using the grammatical relations (GR) evaluation scheme (Carroll et al., 1998) ,which has been used for parser evaluation in the newswire domain."
C08-1095,Shift-Reduce Dependency {DAG} Parsing,2008,18,61,1,1,6910,kenji sagae,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"Most data-driven dependency parsing approaches assume that sentence structure is represented as trees. Although trees have several desirable properties from both computational and linguistic perspectives, the structure of linguistic phenomena that goes beyond shallow syntax often cannot be fully captured by tree representations. We present a parsing approach that is nearly as simple as current data-driven transition-based dependency parsing frameworks, but outputs directed acyclic graphs (DAGs). We demonstrate the benefits of DAG parsing in two experiments where its advantages over dependency tree parsing can be clearly observed: predicate-argument analysis of English and syntactic analysis of Danish with a representation that includes long-distance dependencies and anaphoric reference links."
W07-0604,High-accuracy Annotation and Parsing of {CHILDES} Transcripts,2007,14,45,1,1,6910,kenji sagae,Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition,0,"Corpora of child language are essential for psycholinguistic research. Linguistic annotation of the corpora provides researchers with better means for exploring the development of grammatical constructions and their usage. We describe an ongoing project that aims to annotate the English section of the CHILDES database with grammatical relations in the form of labeled dependency structures. To date, we have produced a corpus of over 65,000 words with manually curated gold-standard grammatical relation annotations. Using this corpus, we have developed a highly accurate data-driven parser for English CHILDES data. The parser and the manually annotated data are freely available for research purposes."
P07-1079,{HPSG} Parsing with Shallow Dependency Constraints,2007,23,38,1,1,6910,kenji sagae,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"We present a novel framework that combines strengths from surface syntactic parsing and deep syntactic parsing to increase deep parsing accuracy, specifically by combining dependency and HPSG parsing. We show that by using surface dependencies to constrain the application of wide-coverage HPSG rules, we can benefit from a number of parsing techniques designed for highaccuracy dependency parsing, while actually performing deep syntactic analysis. Our framework results in a 1.4% absolute improvement over a state-of-the-art approach for wide coverage HPSG parsing."
D07-1111,Dependency Parsing and Domain Adaptation with {LR} Models and Parser Ensembles,2007,29,212,1,1,6910,kenji sagae,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"We present a data-driven variant of the LR algorithm for dependency parsing, and extend it with a best-first search for probabilistic generalized LR dependency parsing. Parser actions are determined by a classifier, based on features that represent the current state of the parser. We apply this parsing framework to both tracks of the CoNLL 2007 shared task, in each case taking advantage of multiple models trained with different learners. In the multilingual track, we train three LR models for each of the ten languages, and combine the analyses obtained with each individual model with a maximum spanning tree voting scheme. In the domain adaptation track, we use two models to parse unlabeled data in the target domain to supplement the labeled out-ofdomain training set, in a scheme similar to one iteration of co-training."
P06-2089,A Best-First Probabilistic Shift-Reduce Parser,2006,21,58,1,1,6910,kenji sagae,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"Recently proposed deterministic classifier-based parsers (Nivre and Scholz, 2004; Sagae and Lavie, 2005; Yamada and Mat-sumoto, 2003) offer attractive alternatives to generative statistical parsers. Deterministic parsers are fast, efficient, and simple to implement, but generally less accurate than optimal (or nearly optimal) statistical parsers. We present a statistical shift-reduce parser that bridges the gap between deterministic and probabilistic parsers. The parsing model is essentially the same as one previously used for deterministic parsing, but the parser performs a best-first search instead of a greedy search. Using the standard sections of the WSJ corpus of the Penn Treebank for training and testing, our parser has 88.1% precision and 87.8% recall (using automatically assigned part-of-speech tags). Perhaps more interestingly, the parsing model is significantly different from the generative models used by other well-known accurate parsers, allowing for a simple combination that produces precision and recall of 90.9% and 90.7%, respectively."
P06-1054,"A Fast, Accurate Deterministic Parser for {C}hinese",2006,26,48,2,0,39074,mengqiu wang,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We present a novel classifier-based deterministic parser for Chinese constituency parsing. Our parser computes parse trees from bottom up in one pass, and uses classifiers to make shift-reduce decisions. Trained and evaluated on the standard training and test sets, our best model (using stacked classifiers) runs in linear time and has labeled precision and recall above 88% using gold-standard part-of-speech tags, surpassing the best published results. Our SVM parser is 2-13 times faster than state-of-the-art parsers, while producing more accurate results. Our Maxent and DTree parsers run at speeds 40-270 times faster than state-of-the-art parsers, but with 5-6% losses in accuracy."
N06-2033,Parser Combination by Reparsing,2006,11,154,1,1,6910,kenji sagae,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Short Papers",0,"We present a novel parser combination scheme that works by reparsing input sentences once they have already been parsed by several different parsers. We apply this idea to dependency and constituent parsing, generating results that surpass state-of-the-art accuracy levels for individual parsers."
W05-1513,A Classifier-Based Parser with Linear Run-Time Complexity,2005,16,92,1,1,6910,kenji sagae,Proceedings of the Ninth International Workshop on Parsing Technology,0,"We present a classifier-based parser that produces constituent trees in linear time. The parser uses a basic bottom-up shift-reduce algorithm, but employs a classifier to determine parser actions instead of a grammar. This can be seen as an extension of the deterministic dependency parser of Nivre and Scholz (2004) to full constituent parsing. We show that, with an appropriate feature set used in classification, a very simple one-path greedy parser can perform at the same level of accuracy as more complex parsers. We evaluate our parser on section 23 of the WSJ section of the Penn Treebank, and obtain precision and recall of 87.54% and 87.61%, respectively."
P05-1025,Automatic Measurement of Syntactic Development in Child Language,2005,16,58,1,1,6910,kenji sagae,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"To facilitate the use of syntactic information in the study of child language acquisition, a coding scheme for Grammatical Relations (GRs) in transcripts of parent-child dialogs has been proposed by Sagae, MacWhinney and Lavie (2004). We discuss the use of current NLP techniques to produce the GRs in this annotation scheme. By using a statistical parser (Charniak, 2000) and memory-based learning tools for classification (Daelemans et al., 2004), we obtain high precision and recall of several GRs. We demonstrate the usefulness of this approach by performing automatic measurements of syntactic development with the Index of Productive Syntax (Scarborough, 1990) at similar levels to what child language researchers compute manually."
sagae-etal-2004-adding,Adding Syntactic Annotations to Transcripts of Parent-Child Dialogs,2004,17,17,1,1,6910,kenji sagae,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"We describe an annotation scheme for syntactic information in the CHILDES database (MacWhinney, 2000), which contains several megabytes of transcribed dialogs between parents and children. The annotation scheme is based on grammatical relations (GRs) that are composed of bilexical dependencies (between a head and a dependent) labeled with the name of the relation involving the two words (such as subject, object and adjunct). We also discuss automatic annotation using our syntactic annotation scheme."
lavie-etal-2004-significance,The significance of recall in automatic metrics for {MT} evaluation,2004,11,66,2,0,13539,alon lavie,Proceedings of the 6th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"Recent research has shown that a balanced harmonic mean (F1 measure) of unigram precision and recall outperforms the widely used BLEU and NIST metrics for Machine Translation evaluation in terms of correlation with human judgments of translation quality. We show that significantly better correlations can be achieved by placing more weight on recall than on precision. While this may seem unexpected, since BLEU and NIST focus on n-gram precision and disregard recall, our experiments show that correlation with human judgments is highest when almost all of the weight is assigned to recall. We also show that stemming is significantly beneficial not just to simpler unigram precision and recall based metrics, but also to BLEU and NIST."
W03-3019,Combining Rule-based and Data-driven Techniques for Grammatical Relation Extraction in Spoken Language,2003,14,6,1,1,6910,kenji sagae,Proceedings of the Eighth International Conference on Parsing Technologies,0,"We investigate an aspect of the relationship between parsing and corpus-based methods in NLP that has received relatively little attention: coverage augmentation in rule-based parsers. In the specific task of determining grammatical relations (such as subjects and objects) in transcribed spoken language, we show that a combination of rule-based and corpus-based approaches, where a rule-based system is used as the teacher (or an automatic data annotator) to a corpus-based system, outperforms either system in isolation."
W01-1816,Parsing the {CHILDES} Database: Methodology and Lessons Learned,2001,15,6,1,1,6910,kenji sagae,Proceedings of the Seventh International Workshop on Parsing Technologies,0,"This paper discusses the process of parsing adult utterances directed to a child, in an effort to produce a syntactically annotated corpus of the verbal input to a human language learner. In parsing the Eve corpus of the CHILDES database, we encountered several challenges relating to parser coverage and ambiguity, for which we describe solutions that result in a system capable of analyzing almost 80% of the adult utterances in the corpus correctly. We describe characteristics of the language in the corpus that make this task unique, and present specific ways to deal with the analysis of this type of language. We discuss each step of the corpus analysis in detail, focusing on how selected techniques, such as part-of-speech tagging, rule-based robust parsing and statistical disambiguation, affect the trade-off between coverage and accuracy. Finally, we present a detailed evaluation of the performance of our system. A parsed corpus resulting from the research described in this paper is available to the research community."
