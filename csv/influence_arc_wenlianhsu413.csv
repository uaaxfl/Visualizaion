2019.rocling-1.23,I17-2014,1,0.608338,"Missing"
2019.rocling-1.23,W03-1726,0,0.184057,"Missing"
C02-1089,O90-1010,0,0.805096,"Missing"
C02-1089,O97-1015,0,0.234472,"Missing"
C02-1089,O02-1002,1,0.796401,"g2/shi3/ (/{車形,車型}/{使,始,史,駛,矢,屎, 豕}/) and /che1/xing2 shi3/ (/{車,硨,? }/{行駛, 行使}/), respectively. In this case, if the system has the information that “車-行駛(car, move)” is a permissible NVEF word-pair and its corresponding syllable-pair “che1-xing2shi3” has been collected, then the correct segmentation and word-pair “車 - 行駛 (che1-xing2shi3)” of this syllable sequence can be determined simultaneously. Since NVEF word-pairs are usually the key features of a sentence, if identified correctly, they become good reference words for the n-gram models to predict the remaining unconverted syllables. We [15] showed that the knowledge of NVEF sense-pairs and their corresponding NVEF word-pairs (NVEF knowledge) are useful for effectively resolving word sense ambiguity and getting highly accurate word-segmentation for those ambiguous NVEF word-pairs in Chinese. In this paper, we shall show that the NVEF knowledge can be used effectively in the STW conversion for Chinese. Section 2 describes our approach. The experimental result is presented in Section 3. Directions for future research will be discussed in section 4. Chinese lexicon (in which the top 60,000 words are selected from the list of 252,307"
C02-1089,O03-1009,1,\N,Missing
C02-1089,O03-1011,1,\N,Missing
C02-2013,bredenkamp-etal-2000-looking,0,0.0561434,"Missing"
C02-2013,C92-2082,0,0.036896,"(QA), knowledge management and organization memory (KM/OM), information retrieval, machine translation (Guarino 1998), and grammar checking systems (Bredenkamp 2000). With the help of domain ontology, software systems can perform better in understanding natural language. However, building domain ontology is laborious and time consuming. Previous works suggest that ontology acquisition is an iterative process which includes keyword collection as well as structure reorganization. The ontology will be revised, refined, and filled in detail during iteration. (Noy and McGuinness 2001) For example (Hearst 1992), in order to find a hyponym of a keyword, the human editor must observe sentences containing this keyword and its related hyponyms. The editor then deduces rules for finding more hyponyms of this keyword. As such cycle iterates, the editor refines the rules to obtain better quality pairs of keyword-hyponyms. In this work we try to speed up the above labor-intensive approach by designing acquisition rules that can be applied recursively. Wen-Lian HSU Institute of Information Science Academia Sinica Nankang, Taipei, Taiwan, R.O.C. hsu@iis.sinica.edu.tw A human editor only has to verify the resu"
C02-2013,W99-0621,0,0.0187516,"ot） Nc+VC 中國（Nc）建設（VC） 銀行（Nc Root） Nc+Nc+Na 中國（Nc）國際（Nc） 商業（Na）銀行（Nc Root） Nc+Nc+VC 中國（Nc）國際（Nc） 開 發 （ VC ） 銀 行 （ Nc Root） Table 4. Attribute extraction rules of an Nc noun Extraction rule Extraction Example target Nc（root）+Na Na 中央研究院（Nc）院長 （Na） Nc（root）+Nc Nc 中央研究院（Nc）停車場 （Nc） 中央研究院（Nc）語言所 Nc （ root ） Nc+Nc +Nc+Nc （Nc）語音實驗室（Nc） 中央研究院（Nc）的(DE) Nc （ root ） Na +DE+Na 出版品（Na） 4. Discussion Li and Thompson (1981) describe Mandarin Chinese as a Topic-prominent language in which the subject or the object is not as obvious as in other languages. Therefore, the highly precise shallow parsing result (Munoz et al. 1999) on NN and SV pairs in English is probably not applicable to Chinese. 4.1 The Experiment of Extraction Rate To test the qualitative and quantitative performance of SOAT, we design two experiments. We construct three domain ontology prototypes for three different domains and corpora. Table 5 shows the result in which the frequently asked questions (FAQs) for stocks are taken from test sentences of the financial QA system. The university and bank corpora are University Bank 4.2 Results from Different Corpora We select three different corpora from different information resources in the “network”"
C02-2013,O02-1002,1,0.81846,"Missing"
D14-1156,H91-1057,0,0.152474,"Missing"
D14-1156,P07-1085,0,0.0519061,"Missing"
D14-1156,P11-5003,0,0.0325849,"aneous (or in-domain) corpus. Finally, the enhanced query model (that is P(w|H) in speech recognition) can be estimated by RM, SMM, RSMM or QMM, and further combined with the background n-gram (e.g., trigram) language model to form an adaptive language model to guide the speech recognition process. 4.2 Speech Summarization On the other hand, extractive speech summarization aims at producing a concise summary by selecting salient sentences or paragraphs from the original spoken document according to a predefined target summarization ratio (Carbonell and Goldstein, 1998; Mani and Maybury, 1999; Nenkova and McKeown, 2011; Liu and Hakkani-Tur, 2011). Intuitively, this task could be framed as an ad-hoc IR problem, where the spoken document is treated as an information need and each sentence of the document is regarded as a candidate information unit to be retrieved according to its relevance to the information need. Therefore, KLM can be used to quantify how close the document D and one of its sentences S are: the closer the sentence model P(w|S) to the document model P(w|D), the more PRM ( w |Q )   D r DTop P( w |Dr )  DrDTop P(Q |Dr ) P( Dr )   L    P ( w |D r ) P ( Dr |Q )    wV  Dr D"
D14-1156,W01-0100,0,\N,Missing
I05-2046,W96-0102,0,\N,Missing
I05-2046,W00-0729,0,\N,Missing
I05-2046,W04-1216,0,\N,Missing
I05-2046,J96-1002,0,\N,Missing
I05-2046,W04-1220,0,\N,Missing
I05-2046,W02-0301,0,\N,Missing
I08-1037,P02-1051,0,0.273485,"Missing"
I08-1037,P98-1036,0,0.110925,"ries cannot update their contents frequently. Therefore, it is necessary to construct a named entity translation (NET) system. Economic ties between China and Korea have become closer as China has opened its markets further, and demand for the latest news and information from China continues to grow rapidly in Korea. One key way to meet this demand is to retrieve information written in Chinese by using Korean queries, referred to as Korean-Chinese cross-language information retrieval (KCIR). The main challenge involves translating NEs because they are usually the main concepts of queries. In (Chen et al., 1998), the authors romanized Chinese NEs and selected their English transliterations from English NEs extracted from the Web by comparing their phonetic similarities with Chinese NEs. Yaser Al-Onaizan (Al-Onaizan and Knight, 2002) 281 transliterated an NE in Arabic into several candidates in English and ranked the candidates by comparing their counts in several English corpora. Unlike the above works, whose target languages are alphabetic, in K-C translation, the target language is Chinese, which uses an ideographic writing system. Korean-Chinese NET is much more diﬃcult than NET considered in prev"
I08-1037,C98-1036,0,\N,Missing
I11-1095,N09-1018,0,0.0410004,"Missing"
I11-1095,N09-1037,0,0.0155525,"more easily. Unfortunately, a separate NILfiltering stage may filter out the entity mention “MIRL” because it is listed as an abbreviation of organization names, such as Mineral Industry Research Laboratory. With a joint inference process we can carry out both tasks simultaneously to avoid this type of error propagation (Poon and Domingos 2007). Joint inference has become popular recently, because they make it possible for features and constraints to be shared among tasks. For example, Che and Liu (2010) created a joint model for word sense disambiguation (WSD) and semantic role labeling, and Finkel and Manning (2009) integrated parsing and named entity recognition in a joint model. In this paper, we use the Markov Logic Network (MLN) (Richardson and Domingos 2006), a joint model which combines first order logic (FOL) and Markov networks, to unify the NIL-filtering and entity disambiguation stages. The model captures the contextual information of the recognized entities for entity disambiguation as well as the constraints when linking an entity mention to a KB entry—for example, an entity mention can only be linked to a database entry when the mention has not been recognized as an NIL. Another advantage of"
I11-1095,C10-1032,0,\N,Missing
I11-1095,E06-1002,0,\N,Missing
I11-1095,C10-1019,0,\N,Missing
I11-1095,C10-1145,0,\N,Missing
I11-1157,C92-2082,0,0.0921688,"es use contextual similarity to model the instances of a given class. Following the distributional hypothesis (Harris, 1970), these methods take a small set of seed instances and generate new instances from noun phrases that are most similar to the seeds in terms of the distributions of surrounding words (Sarmento et al., 2007; Pantel et al., 2009). The pattern-based approaches use text patterns to extract instances of a given semantic class (Riloff and Shepherd, 1997; Riloff and Jones, 1999; Banko et al., 2007; Pas¸ca, 2007). The most representative study is the group of patterns proposed by Hearst (1992). For example, patterns like ‘X such as Y’ and ‘X including Y’ can be applied to extract instances from ‘actors such as Tom Hanks’ and ‘countries including Japan’. In these approaches, semantic classes are specified by providing small sets of seed instances or seed patterns such as (Kozareva et al., 2008) which utilized a single hyponym pattern combined with graph structure to extract semantic lexicons from the Web. In addition to natural language patterns, Wang and Cohen (2007) demonstrated an approach that learns the pattern of specific metastructure of the document (e.g., tags in HTML) auto"
I11-1157,P08-1119,0,0.0222018,"ng words (Sarmento et al., 2007; Pantel et al., 2009). The pattern-based approaches use text patterns to extract instances of a given semantic class (Riloff and Shepherd, 1997; Riloff and Jones, 1999; Banko et al., 2007; Pas¸ca, 2007). The most representative study is the group of patterns proposed by Hearst (1992). For example, patterns like ‘X such as Y’ and ‘X including Y’ can be applied to extract instances from ‘actors such as Tom Hanks’ and ‘countries including Japan’. In these approaches, semantic classes are specified by providing small sets of seed instances or seed patterns such as (Kozareva et al., 2008) which utilized a single hyponym pattern combined with graph structure to extract semantic lexicons from the Web. In addition to natural language patterns, Wang and Cohen (2007) demonstrated an approach that learns the pattern of specific metastructure of the document (e.g., tags in HTML) automatically from seed instances. In this paper, we propose a method similar to (Kozareva et al., 2008) and (Wang and Cohen, 2007) in that it also employs graph ranking algorithm to assess the reliability of the extracted candidates and uses the Web as the source of extraction. Different from them, the wrapp"
I11-1157,P09-1045,0,0.0167902,"either a wrapper or a mention, and an edge denotes a captured-by or produced-by relationship. The vertices in G are then ranked by graph ranking algorithm. In this work, we adopt RageRank with Prior (White and Smyth, 2003). Finally, we obtain a list of mentions according to the vertices ranking in G. 5 Experiment Settings and Results In this work, the experiments are designed to evaluate the effectiveness of the proposed filtering strategy in learning semantic classes. The proposed approach is compared with a baseline counterpart which runs without the filtering mechanism. A noted impediment (McIntosh and Curran, 2009) to a fair evaluation is that the same seeds used to initiate the algorithms can cause different algorithms to generate diverse lexicons which vary greatly in precision. This makes evaluation unreliable — seeds which perform well on one algorithm can perform poorly on another. To conduct a fair comparison, we adopt a bagging approach which resembles to the one used by McIntosh and Curran (2009) to aggregate the results over 30 runs for each algorithm. In each run, our system uses three seeds randomly selected from a set of ten prepared instances. The resulting 30 lexicons are then merged by a"
I11-1157,W97-0313,0,0.0495317,"2009). Most of the approaches for this task can be roughly classified into two categories: distributional and pattern-based. The distributional approaches use contextual similarity to model the instances of a given class. Following the distributional hypothesis (Harris, 1970), these methods take a small set of seed instances and generate new instances from noun phrases that are most similar to the seeds in terms of the distributions of surrounding words (Sarmento et al., 2007; Pantel et al., 2009). The pattern-based approaches use text patterns to extract instances of a given semantic class (Riloff and Shepherd, 1997; Riloff and Jones, 1999; Banko et al., 2007; Pas¸ca, 2007). The most representative study is the group of patterns proposed by Hearst (1992). For example, patterns like ‘X such as Y’ and ‘X including Y’ can be applied to extract instances from ‘actors such as Tom Hanks’ and ‘countries including Japan’. In these approaches, semantic classes are specified by providing small sets of seed instances or seed patterns such as (Kozareva et al., 2008) which utilized a single hyponym pattern combined with graph structure to extract semantic lexicons from the Web. In addition to natural language pattern"
I11-1157,P07-1074,0,0.046462,"Missing"
I11-1157,D09-1098,0,\N,Missing
I17-2014,D15-1166,0,0.0393386,"coder model with attention mechanism. Character embeddings C1 to Cn of the input sentence is sequentially fed into the bidirectional LSTM, and the concatenated output is multiplied by attention weights and sent to the decoder for predicting the tag sequence T1 to Tn . For simplicity, multiple layers of encoder and decoder as well as dropout layers between them are omitted. 2 Methods clude Wi,f,o,c and Ui,f,o,c . They are defined as: it = σ(Wi xt + Ui ht−1 ) Figure 1 illustrates the overview of our model, which in essence is an encoder-decoder (Sutskever et al., 2014) with attention mechanism (Luong et al., 2015). The input is a sequence of Chinese characters that may contain named entities, and the output is a sequence of POS tags and possibly NEs in the form of BIES tags. Our model mainly consists of: embedding layer, recurrent encoder layers, attention layer, and decoder layers. Detailed description of these layers are as follows. ft = σ(Wf xt + Uf ht−1 ) ot = σ(Wo xt + Uo ht−1 ) ˜ ct = tanh(Wc xt + Uc ht−1 ) ct = ft ◦ ct−1 + it ◦ ˜ ct ht = ot ◦ tanh(ct ) where “◦” denotes the element-wise product of vectors and σ represents the sigmoid function. We employ a straightforward extension named Bidirect"
I17-2014,I08-4018,0,0.0603074,"Missing"
I17-2014,W03-1726,0,0.469435,"Missing"
I17-2014,I05-3019,0,0.0963274,"Missing"
I17-2014,I08-4013,0,0.0887314,"Missing"
I17-2014,J05-4005,0,0.040148,"Missing"
I17-2014,C04-1081,0,0.0664675,"Missing"
I17-2014,D15-1211,0,0.147579,"POS) labels and named entity recognition (NER). Moreover, for languages that do not have an obvious word boundary such as Chinese and Japanese, segmentation is another major issue. Approaches that attempt to jointly resolve two of these tasks have received much attention in recent years. For example, Ferraro et al. (2013) proposed that joint solutions usually lead to the improvement in accuracy over pipelined systems by exploiting POS information to assist word segmentation and avoiding error propagation. Recent researches (Sun, 2011; Qian and Liu, 2012; Zheng et al., 2013; Zeng et al., 2013; Qian et al., 2015) also focus on the development of a joint model to perform Chinese word 1 http://sighan.cs.uchicago.edu/ Please visit http://monpa.iis.sinica.edu. tw:9000/chunk 2 80 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 80–85, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP FW BW C1 ◦ ◦ ▵▵ ⊗ C2 ◦ ◦ ▵▵ ⊗ ⋮ ▵▵ ⊗ Cn ◦ ◦ attention weights Bidirectional LSTM Encoder ●● softmax T1 ●● softmax T2 ⋮ ●● softmax Tn LSTM Decoder Figure 1: Overview of the encoder-decoder model with attention mechanism. Character embeddings C1 to Cn of the input sentence"
I17-2014,D12-1046,0,0.0272792,"cessing (NLP) tasks often rely on accurate part-of-speech (POS) labels and named entity recognition (NER). Moreover, for languages that do not have an obvious word boundary such as Chinese and Japanese, segmentation is another major issue. Approaches that attempt to jointly resolve two of these tasks have received much attention in recent years. For example, Ferraro et al. (2013) proposed that joint solutions usually lead to the improvement in accuracy over pipelined systems by exploiting POS information to assist word segmentation and avoiding error propagation. Recent researches (Sun, 2011; Qian and Liu, 2012; Zheng et al., 2013; Zeng et al., 2013; Qian et al., 2015) also focus on the development of a joint model to perform Chinese word 1 http://sighan.cs.uchicago.edu/ Please visit http://monpa.iis.sinica.edu. tw:9000/chunk 2 80 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 80–85, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP FW BW C1 ◦ ◦ ▵▵ ⊗ C2 ◦ ◦ ▵▵ ⊗ ⋮ ▵▵ ⊗ Cn ◦ ◦ attention weights Bidirectional LSTM Encoder ●● softmax T1 ●● softmax T2 ⋮ ●● softmax Tn LSTM Decoder Figure 1: Overview of the encoder-decoder model with attention mec"
I17-2014,W12-6338,0,0.0126646,"has a dimension of 300, identical to that of word embeddings. There are three layers for both encoder and decoder. Dropout layers exist between each of the recurrent layers. The training lasts for at most 100 epochs or when the accuracy of the validation set starts to drop. Experiments Test corpora from five previous SIGHAN shared tasks, which have been widely adopted for Traditional Chinese word segmentation and NER, were used to evaluate the proposed system. Besides the participating systems in the above shared tasks, we also compare with existing word segmentation toolkits Jieba and CKIP (Hsieh et al., 2012). The word segmentation datasets were taken from SIGHAN shared tasks of years 2003–2008, and NER dataset is from 2006. We follow the standard train/test split of the provided data, where 10,000 sentences of the training set are used as the validation set. Details of the word segmentation and NER datasets are shown in Table 1 and 2, respectively. Three metrics are used for evaluation: precision (P), recall (R) and F1 -score (F), defined by F = 2×P ×R P +R For word segmentation, a token is considered to be correct if both the left and right boundaries match those of a word in the gold standard."
I17-2014,W06-0133,0,0.0667507,"Missing"
I17-2014,P11-1139,0,0.0566624,"Missing"
I17-2014,W06-0124,0,0.0272562,"training data, which is processed using an external tool focused on texts from a different linguistic context. It is also reported by (Wu et al., 2006) that segmentation criteria in AS and CU datasets are not very consistent. However, by fusing two corpora, the RNNCU06+YA can even surpass the performances of CKIP. Finally, comparison with Jieba validates that the RNN model can serve as a very effective toolkit for NLP researchers as well as the general public. Table 4: Results from the 2006 SIGHAN NER shared task (open track). Bold numbers indicate the best performance in that column. System Yu et al. (2006) RNNCU06 RNNYA RNNCU06+YA Table 4 lists the performances of proposed models and the only system that participated in the open track of the 2006 SIGHAN NER shared task. We can see that RNNCU06 outperforms the model from Yu et al. (2006), confirming RNN’s capability on jointly learning to segment and recognize NEs. Interestingly, RNNYA obtains a much lower F-score for all NE types. And RNNCU06+YA can only obtain a slightly better F-score for person recognition but not the overall performance of RNNCU06 , even with the combined corpus. We 5 F-score PER LOC ORG Overall 80.98 81.13 70.54 83.01 86.0"
I17-2014,P13-1076,0,0.0198737,"te part-of-speech (POS) labels and named entity recognition (NER). Moreover, for languages that do not have an obvious word boundary such as Chinese and Japanese, segmentation is another major issue. Approaches that attempt to jointly resolve two of these tasks have received much attention in recent years. For example, Ferraro et al. (2013) proposed that joint solutions usually lead to the improvement in accuracy over pipelined systems by exploiting POS information to assist word segmentation and avoiding error propagation. Recent researches (Sun, 2011; Qian and Liu, 2012; Zheng et al., 2013; Zeng et al., 2013; Qian et al., 2015) also focus on the development of a joint model to perform Chinese word 1 http://sighan.cs.uchicago.edu/ Please visit http://monpa.iis.sinica.edu. tw:9000/chunk 2 80 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 80–85, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP FW BW C1 ◦ ◦ ▵▵ ⊗ C2 ◦ ◦ ▵▵ ⊗ ⋮ ▵▵ ⊗ Cn ◦ ◦ attention weights Bidirectional LSTM Encoder ●● softmax T1 ●● softmax T2 ⋮ ●● softmax Tn LSTM Decoder Figure 1: Overview of the encoder-decoder model with attention mechanism. Character embeddings C1 to Cn o"
I17-2014,W06-0121,0,0.0918662,"Missing"
I17-2014,W06-0127,0,0.083326,"Missing"
I17-2014,W06-0122,1,0.832064,"ned as the averaged cross-entropy between a output sequence and true label sequence. 3 3.1 In order to obtain multi-objective labels of the training data, we first merge datasets from the 2006 SIGHAN word segmentation and NER shared tasks. Since rich context information is able to benefit deep learning-based approach, we augment the training set by collecting online news articles3 . There are three steps for annotating the newly-created dataset. We first collect a list of NEs from Wikipedia and use it to search for NEs in the corpus, where longer NEs have higher priorities. Then, an NER tool (Wu et al., 2006) is utilized to label NEs. Finally, CKIP is utilized to segment and label the remaining words with POS tags. Three variants of the proposed model are tested, labeled as RNNCU06 , RNNYA , and RNNCU06+YA . RNNCU06 is trained using only word segmentation and NER datasets from the 2006 City University (CU) corpus; RNNYA is trained using only online news corpus, and RNNCU06+YA is trained on a combination of the above corpora. We implemented the RNN model using pytorch4 . The maximum sentence length is set to 80, where longer sentences were truncated and shorter sentences were padded with zeros. The"
I17-2014,D13-1061,0,0.0283682,"Missing"
I17-2014,W03-1729,0,0.144455,"Missing"
I17-2014,I05-3025,0,\N,Missing
I17-2041,H05-1091,0,0.105201,"Missing"
I17-2041,W16-2922,0,0.00646378,"Missing"
I17-2041,P15-1033,0,0.00741477,"Missing"
I17-2041,P15-1150,0,0.00601022,"Missing"
I17-2041,N16-1030,0,0.0392269,"Missing"
I17-2041,P16-1105,0,0.0156042,"Missing"
I17-2041,W17-2304,0,0.0744271,"Missing"
I17-4015,W11-3704,0,0.017708,"he degree of excitement. According to the twodimensional representation, any affective state can be represented as a point in the valence-arousal space by determining the degrees of valence and arousal of given words (Wei et al., 2011; Yu et al., 2015) or texts (Kim et al., 2010). Dimen95 Proceedings of the 8th International Joint Conference on Natural Language Processing, Shared Tasks, pages 95–99, c Taipei, Taiwan, November 27 – December 1, 2017. 2017 AFNLP sional sentiment analysis is an increasingly active research field with potential applications including antisocial behavior detection (Munezero et al., 2011) and mood analysis (De Choudhury et al., 2012). In light of this, the objective of the Dimensional Sentiment Analysis for Chinese Words (DSAW) shared task at the 21th International Conference on Asian Language Processing is to automatically acquire the valence-arousal ratings of Chinese affective words and phrases for compiling Chinese valence-arousal lexicons. The expected output of this task is to predict a real-valued score from 1 to 9 for both valence and arousal dimensions of the given 750 test words and phrases. The score indicates the degree from most negative to most positive for valen"
I17-4015,N16-1066,0,0.0132557,"rch suggested that it is possible to improve the performance by aggregating the results of a number of valence-arousal methods (Yu et al., 2015). Thus, we use two sets of methods for the prediction of valence: (1) prediction based on WVA and CVA, and (2) a kNN valence prediction method. The results of these two methods are averaged as the final valence score. Valence Prediction Using WVA Valence Prediction Using CVA 完成 完成 V:7.0 通 V:5.8 通知 通知 V:unknown 知 V:5.4 average 通知 V:5.6 Figure 3: Word Valence prediction method based on WVA and CVA. Method This study takes 2,802 single words in CVAW 2.0 (Yu et al., 2016) and 2,250 multi-word phrases, both annotated with valence-arousal ratings, as training material. At word level, we use EHowNet (Chen et al., 2005), a system that is designed for the purpose of automatic semantic composition and decomposition, to extract synonyms of the words from CVAW 2.0, and expand it to 19,611 words with valence-arousal ratings, called WVA. Fig. 2 illustrates the proposed framework. In order to cope with the problem of unknown First, we describe the prediction of valence values. As shown in Fig. 3, the “完成” of the test data exists in the WVA, so we can directly obtain its"
I17-4015,P15-2129,0,0.124049,"l means to understand the opinion of the masses, which is a major issue for businesses. However, they exist in the forms of comments in a live webcast, opinion sites, or social media, and often contain considerable amount of noise. Such characteristics pose obstacles to those who intend to collect this type of information efficiently. It is the reason why opinion mining has recently become a topic of interest in both academia and business institutions. Sentiment analysis is a type of opinion mining where affective states are represented categorically or by multi-dimensional continuous values (Yu et al., 2015). The categorical approach aims at classifying the sentiment into polarity classes (such as positive, neutral, and negative,) or Ekman’s six basic emotions, i.e., anger, happiness, fear, sadness, disgust, and surprise (EkTense high Angry Excited Delighted Happy Frustrated negative neutral positive Depressed Valence Content Relaxed Bored II Low-Arousal Negative-Valence I High-Arousal Positive-Valence Tired low Calm IV Low-Arousal Positive-Valence Figure 1: Two-dimensional valence-arousal space. gree of pleasant and unpleasant (i.e., positive and negative) feelings, while the arousal represents"
I17-4015,I05-7001,0,0.0193842,"Thus, we use two sets of methods for the prediction of valence: (1) prediction based on WVA and CVA, and (2) a kNN valence prediction method. The results of these two methods are averaged as the final valence score. Valence Prediction Using WVA Valence Prediction Using CVA 完成 完成 V:7.0 通 V:5.8 通知 通知 V:unknown 知 V:5.4 average 通知 V:5.6 Figure 3: Word Valence prediction method based on WVA and CVA. Method This study takes 2,802 single words in CVAW 2.0 (Yu et al., 2016) and 2,250 multi-word phrases, both annotated with valence-arousal ratings, as training material. At word level, we use EHowNet (Chen et al., 2005), a system that is designed for the purpose of automatic semantic composition and decomposition, to extract synonyms of the words from CVAW 2.0, and expand it to 19,611 words with valence-arousal ratings, called WVA. Fig. 2 illustrates the proposed framework. In order to cope with the problem of unknown First, we describe the prediction of valence values. As shown in Fig. 3, the “完成” of the test data exists in the WVA, so we can directly obtain its valence value of 7.0. However, another word “通知” does not exist in the WVA, so we search in CVA and calculate a valence value of 5.6. Additionally,"
O02-1002,O02-1002,1,0.0512826,"Missing"
O03-1009,C02-1089,1,0.74347,"Missing"
O03-1009,O02-1002,1,\N,Missing
O03-1009,J96-3004,0,\N,Missing
O03-1009,C02-1012,0,\N,Missing
O03-1009,C02-1049,0,\N,Missing
O03-1009,J00-3004,0,\N,Missing
O03-1009,O97-4005,0,\N,Missing
O03-1011,J96-3004,0,\N,Missing
O03-1011,J93-1007,0,\N,Missing
O03-1011,C00-1027,0,\N,Missing
O03-1011,C02-1025,0,\N,Missing
O03-1011,C02-1012,0,\N,Missing
O03-1011,C02-1049,0,\N,Missing
O03-1011,P99-1022,0,\N,Missing
O03-1011,C92-1019,0,\N,Missing
O03-1011,O97-4003,0,\N,Missing
O03-1011,O97-4005,0,\N,Missing
O03-1012,C02-1012,0,0.0539335,"Missing"
O03-1012,M98-1018,0,0.0768205,"Missing"
O03-1012,M98-1016,0,0.115914,"Missing"
O03-1012,J96-1002,0,0.0159547,"Missing"
O03-1012,M98-1004,0,\N,Missing
O03-1012,M98-1012,0,\N,Missing
O03-1012,M98-1014,0,\N,Missing
O03-1012,M98-1021,0,\N,Missing
O03-1012,M98-1017,0,\N,Missing
O03-1012,M98-1009,0,\N,Missing
O04-1009,O97-1015,0,0.0738158,"Missing"
O04-1009,O90-1010,0,0.157988,"Missing"
O04-1009,C02-1089,1,0.390133,"Missing"
O04-1009,O03-1009,1,0.887161,"Missing"
O04-1009,O03-1011,1,0.884531,"Missing"
O04-1032,A97-1029,0,0.080643,"Missing"
O04-1032,W98-1118,0,0.0432005,"Missing"
O04-1032,W98-1120,0,0.06186,"Missing"
O04-1032,W02-2024,0,0.0575095,"Missing"
O04-1032,W03-0419,0,0.0519798,"Missing"
O04-1032,C96-1079,0,0.104601,"Missing"
O04-1032,O04-2004,1,0.884319,"Missing"
O04-1032,N03-1002,0,\N,Missing
O04-1032,M98-1028,0,\N,Missing
O04-2003,C02-1049,0,0.0282989,"Missing"
O04-2003,O03-1006,0,0.028129,"Missing"
O04-2003,C00-2148,0,0.0285171,"Missing"
O04-2003,O03-2003,0,0.0368718,"Missing"
O04-2003,J96-3004,0,0.122463,"Missing"
O04-2003,J00-3004,0,0.0521257,"Missing"
O04-2003,O02-1002,1,0.825977,"Missing"
O04-2003,C02-1089,1,0.862998,"Missing"
O04-2003,O03-1011,1,0.850894,"Missing"
O04-2003,W03-1118,1,0.883218,"Missing"
O04-2003,J96-1001,0,\N,Missing
O04-2003,J93-1007,0,\N,Missing
O04-2003,C02-1012,0,\N,Missing
O04-2003,I05-1029,0,\N,Missing
O04-2003,O97-4005,0,\N,Missing
O04-2004,M98-1018,0,0.0853448,"Missing"
O04-2004,M98-1028,0,0.0611186,"Missing"
O04-2004,M98-1025,0,0.272439,"Missing"
O04-2004,M98-1026,0,0.164703,"Missing"
O04-2004,M98-1017,0,0.0753656,"Missing"
O04-2004,M98-1021,0,0.0552534,"Missing"
O04-2004,M98-1009,0,0.0725893,"Missing"
O04-2004,C02-1012,0,0.123883,"Missing"
O04-2004,M98-1016,0,0.0397731,"Missing"
O04-2004,M98-1004,0,\N,Missing
O04-2004,M98-1012,0,\N,Missing
O04-2004,M98-1014,0,\N,Missing
O04-2004,J96-1002,0,\N,Missing
O05-1017,W03-1705,0,0.0705084,"Missing"
O05-1017,C02-1131,0,0.0226017,"Missing"
O05-1017,W95-0107,0,0.181464,"Missing"
O05-1017,W96-0202,0,0.0855969,"Missing"
O05-1017,W04-1114,0,0.0517487,"Missing"
O05-1017,W00-1212,0,0.0514526,"Missing"
O05-1017,W00-1320,0,\N,Missing
O05-1017,W00-1211,0,\N,Missing
O05-1017,A88-1019,0,\N,Missing
O05-1017,J96-1002,0,\N,Missing
O08-3001,W06-2201,0,0.0191748,"ep approaches for some languages due to the lack of knowledge resources or tools. In contrast, approaches with shallow features are much more flexible when QA languages are changed. The following are some commonly used shallow approaches. Surface patterns [Soubbotin and Soubbotin 2001] have been successful in the TREC QA Track, which uses string patterns to match questions with correct answers. However, from our perspective, if surface patterns are manually created, the method can not be regarded as “shallow”, because it is likely labor intensive. Although there are some “shallow” variations [Geleijnse and Korst 2006; Ravichandran and Hovy 2002] that attempt to create surface patterns automatically/semi-automatically, they usually suffer from the low coverage problem, which means they can only be applied to a few questions. Some approaches focus on local information, thus only take the similarity between a passage and the question into account when finding relevant answers. The simplest way to measure the similarity is by counting the ratio of question terms occurring in the answer passage, as has been reported [Cooper and Ruger 2000; Molla and Gardiner 2005; Zhao et al. 2005]. Kwok [Kwok and Deng 2006] a"
O08-3001,U04-1002,0,0.052823,"Missing"
O08-3001,P06-1112,0,0.121407,"form of the question, the logic form of the sentence that supports the answer, and background knowledge from WordNet. The logic-based approach has achieved the best QA performance in TREC for several years. 4 Cheng-Wei Lee et al. Dependency-parser-based methods have also performed quite well on TREC tasks. The National University of Singapore team [Cui et al. 2005] used dependency relations identified by a dependency parser to select answer nuggets for factoid and list questions. The similarity between the question and the supporting passage is calculated by machine translation models. Shen [Shen et al. 2006] also used dependency relations, but incorporated them into a Maximum Entropy-based ranking model. Although these deep approaches perform well on monolingual QA (about 0.7 accuracy), they are quite demanding in terms of linguistic resources and computational complexity. In cross-lingual or multilingual QA, it is usually impossible to employ deep approaches for some languages due to the lack of knowledge resources or tools. In contrast, approaches with shallow features are much more flexible when QA languages are changed. The following are some commonly used shallow approaches. Surface pattern"
O10-1010,W03-1726,0,0.0328049,"exts [2]. The design of data set is challenging particularly. The domain-specific training corpora remain unlabeled, and two of the test corpora keep domains unknown before releasing, therefore it is not easy to apply ordinary machine learning approaches, especially for the closed training evaluations. 143 Proceedings of the 22nd Conference on Computational Linguistics and Speech Processing (ROCLING 2010), Pages 143-156, Puli, Nantou,Taiwan, September 2010. Traditional approach for Chinese word segmentation problem is adopted dictionary along with lots of rules to segment the unlabelled texts [3]. Recent years, the statistical machine learning models, such as Hidden Markov Model (HMM) [4], Maximum Entropy Markov Model (MEMM) [5] and Conditional Random Field (CRF) [6], show the moderate performance for sequential labeling problem, especially CRF achieves better outcome. In this paper we propose a novel feature named term contributed boundary (TCB) for CRF model training. Since term contributed boundary extraction [10] is unsupervised, it is suitable for closed training task that any external resource or extra knowledge is not allowed. Without proper knowledge, the closed task of word s"
O10-1010,N06-2049,0,0.0517673,"rpus. “ENQUIRIES” follows “RAIL” with a very high probability when it is preceded by “BRITISH.” However, when “RAIL” is preceded by words other than “BRITISH,” “ENQUIRIES” does not occur, but words like “TICKET” or “JOURNEY” may. Thus, the bigram “RAIL ENQUIRIES” gives a misleading probability that “RAIL” is followed by “ENQUIRIES” irrespective of what precedes it. This problem happens not only with word-token corpora but also with corpora in which all the compounds are tagged as units since overlapping N-grams still appear, therefore corresponding solutions such as Zhang et al. were proposed [9]. 145 We uses suffix array algorithm to calculate exact boundaries of phrase and their frequencies [10], called term contributed boundaries (TCB) and term contributed frequencies (TCF), respectively, to analogize similarities and differences with the term frequencies (TF). For example, in Vodis Corpus, the original TF of the term “RAIL ENQUIRIES” is 73. However, the actual TCF of “RAIL ENQUIRIES” is 0, since all of the frequency values are contributed by the term “BRITISH RAIL ENQUIRIES”. In this case, we can see that ‘BRITISH RAIL ENQUIRIES’ is really a more frequent term in the corpus, where"
O10-1010,C04-1081,0,0.0400361,"ng task that any external resource or extra knowledge is not allowed. Without proper knowledge, the closed task of word segmentation can be hard when out-of-vocabulary (OOV) sequences occurred, where TCB extracted from test data directly may help. We also compare different character based label scheme “BI”, “BIO” and “BIEO” for model training. “B,” “I,” “E” and “O” mean the beginning of word, the internal of word, the end of word and the single character word, respectively. The character-based “BIO” tagging of Conditional Random Field has been widely used in Chinese word segmentation recently [11, 12, 13]. From the experiments, “BIEO” labeling shows the better performance than “BI” and “BIO”. The layout of this paper is as follows. We briefly introduce of CRF in Section 2. The novel feature term contributed boundary will be given in Section 3. Section 4 describes the data set and experimental results with error analysis. The conclusion is in Section 5. 2. Conditional Random Fields Conditional random fields (CRF) are undirected graphical models trained to maximize a conditional probability of random variables X and Y , and the concept is well established for sequential labeling problem [6]. Giv"
O10-1010,I05-3027,0,0.0246304,"ng task that any external resource or extra knowledge is not allowed. Without proper knowledge, the closed task of word segmentation can be hard when out-of-vocabulary (OOV) sequences occurred, where TCB extracted from test data directly may help. We also compare different character based label scheme “BI”, “BIO” and “BIEO” for model training. “B,” “I,” “E” and “O” mean the beginning of word, the internal of word, the end of word and the single character word, respectively. The character-based “BIO” tagging of Conditional Random Field has been widely used in Chinese word segmentation recently [11, 12, 13]. From the experiments, “BIEO” labeling shows the better performance than “BI” and “BIO”. The layout of this paper is as follows. We briefly introduce of CRF in Section 2. The novel feature term contributed boundary will be given in Section 3. Section 4 describes the data set and experimental results with error analysis. The conclusion is in Section 5. 2. Conditional Random Fields Conditional random fields (CRF) are undirected graphical models trained to maximize a conditional probability of random variables X and Y , and the concept is well established for sequential labeling problem [6]. Giv"
O10-1010,W03-1728,0,0.0280911,"ng task that any external resource or extra knowledge is not allowed. Without proper knowledge, the closed task of word segmentation can be hard when out-of-vocabulary (OOV) sequences occurred, where TCB extracted from test data directly may help. We also compare different character based label scheme “BI”, “BIO” and “BIEO” for model training. “B,” “I,” “E” and “O” mean the beginning of word, the internal of word, the end of word and the single character word, respectively. The character-based “BIO” tagging of Conditional Random Field has been widely used in Chinese word segmentation recently [11, 12, 13]. From the experiments, “BIEO” labeling shows the better performance than “BI” and “BIO”. The layout of this paper is as follows. We briefly introduce of CRF in Section 2. The novel feature term contributed boundary will be given in Section 3. Section 4 describes the data set and experimental results with error analysis. The conclusion is in Section 5. 2. Conditional Random Fields Conditional random fields (CRF) are undirected graphical models trained to maximize a conditional probability of random variables X and Y , and the concept is well established for sequential labeling problem [6]. Giv"
O10-1010,O04-2007,0,\N,Missing
O11-1007,O97-4005,0,0.676962,"Missing"
O11-1007,W03-1701,0,0.361387,"Missing"
O11-1007,W03-1719,0,0.27383,"Missing"
O11-1007,W03-1726,0,0.197122,"Missing"
O11-1007,J04-1004,0,0.663135,"Missing"
O11-1007,O05-2002,0,0.275958,"Missing"
O11-1007,I05-3017,0,0.525514,"Missing"
O11-1007,W06-0115,0,0.596159,"Missing"
O11-1007,P06-2123,0,0.541354,"Missing"
O11-1007,W10-4126,0,0.456062,"Missing"
O11-1007,I08-4010,0,\N,Missing
O11-1007,W10-4138,1,\N,Missing
O12-4003,I05-3017,0,0.0722342,"Missing"
O12-4003,J04-1004,0,0.0710601,"Missing"
O12-4003,O05-2002,0,0.0454183,"Missing"
O12-4003,Y03-1017,0,0.0850059,"Missing"
O12-4003,O11-1007,1,0.222658,"Missing"
O12-4003,W99-0701,0,0.149609,"Missing"
O12-4003,W96-0213,0,0.570636,"Missing"
O12-4003,W03-1719,0,0.050688,"Missing"
O12-4003,D11-1090,0,0.0591669,"Missing"
O12-4003,I05-1009,0,0.0679627,"Missing"
O12-4003,P06-2123,0,0.0482026,"Missing"
O12-4003,O97-4005,0,\N,Missing
O12-4003,W03-1701,0,\N,Missing
O12-4003,W03-1726,0,\N,Missing
O12-4003,W06-0115,0,\N,Missing
O12-4003,I08-4010,0,\N,Missing
O12-4003,W10-4138,1,\N,Missing
O13-1001,W97-0703,0,0.473494,"Missing"
O13-1001,P04-1085,0,0.0956261,"Missing"
O13-1001,P08-1054,0,0.0388536,"Missing"
O13-1001,N07-2054,0,0.0562749,"Missing"
O14-1002,N10-1134,0,0.08846,"Missing"
O14-1002,P11-5003,0,0.0392463,"Missing"
O14-1002,P08-1054,0,0.0612,"Missing"
O14-1002,C10-1111,0,0.0751714,"Missing"
O14-1002,N07-2054,0,0.0711078,"Missing"
O14-2002,E06-1002,0,0.0452926,"Missing"
O14-2002,D07-1074,0,0.192564,"Missing"
O14-2002,C10-1032,0,0.0572712,"Missing"
O14-2002,N09-1037,0,0.0666793,"Missing"
O14-2002,P12-1055,0,0.0542655,"Missing"
O14-2002,P05-1012,0,0.0883921,"Missing"
O14-2002,C10-1145,0,0.055367,"Missing"
O14-2002,mcnamee-etal-2010-evaluation,0,\N,Missing
O14-2002,W09-1401,0,\N,Missing
O14-2002,J95-2003,0,\N,Missing
O16-1012,P11-5003,0,0.123639,"Missing"
O16-1012,D15-1229,0,0.0740231,"Missing"
O16-1012,D15-1044,0,0.0889799,"Missing"
O16-1012,K16-1028,0,0.0360188,"Missing"
O16-1012,D14-1179,0,0.0116194,"Missing"
O16-1012,D15-1166,0,0.0695141,"Missing"
O16-2002,I05-7001,0,0.0300601,"Missing"
O16-2002,C10-1021,0,0.0816003,"Missing"
O16-2002,P09-2038,0,0.0606874,"Missing"
O16-2002,C10-3014,0,0.0615439,"Missing"
O16-2002,P05-2008,0,0.0692739,"Missing"
O16-2002,D10-1021,0,0.0559243,"Missing"
O16-2002,E12-1049,0,0.0607075,"Missing"
O16-2002,D09-1150,0,0.0510959,"Missing"
O16-2002,tang-chen-2012-mining,0,0.0315183,"Missing"
O16-2002,P07-2034,0,0.0754706,"Missing"
O16-2002,C10-2167,0,0.0854333,"Missing"
O16-2002,W06-2501,0,\N,Missing
O17-2001,P04-1085,0,0.107934,"Missing"
O17-2001,N10-1134,0,0.105237,"Missing"
P15-2127,I05-7001,0,0.0117322,"n readers after exploiting these templates, demonstrating the capability of PBA in extracting templates with high interpretability. 2 (1) (Presidents of the United States)”. Suppose “美国总统 (Presidents of the United States)” has more out-going links, we will label “奥巴马 (Obama)” as “[美国总统] (Presidents of the United States)”. We also annotate those NEs not found in Wikipedia with their category tags. In this manner, we can transform plain NEs to a more general class and increase the coverage of each label. Finally, to incorporate richer semantic context, we exploit the Extended HowNet (E-HowNet) (Chen et al., 2005) after the above processes to tag the remaining text with sense labels. Figure 1 illustrates crucial element labeling process. Consider the clause Cn = “奥巴马又代表民主党赢得美国总统选举 (Obama, representing the Democratic Party, won the U.S. Presidential election)”. First, “奥巴马 (Obama)” is found in the emotion keyword list and tagged. Then, NEs like “民主党 (Democratic Party)” and “总统选举 (Presidential election)” are recognized and tagged as “{政党 (Party)}” and “{总统选举 (Presidential election)}”. Subsequently, other terms such as “代表 (represent)” and “赢得 (won)” are labeled with their corresponding E-HowNet senses. F"
P15-2127,E12-1049,0,0.0614548,"inguistic Template Extraction for Recognizing Reader-Emotion and Emotional Resonance Writing Assistance ∗ Yung-Chun Chang1,2 , Cen-Chieh Chen1,3 , Yu-Lun Hsieh1,3 , Chien Chin Chen2 , Wen-Lian Hsu1 1 Institute of Information Science, Academia Sinica, Taipei, Taiwan 2 Department of Information Management, National Taiwan University, Taipei, Taiwan 3 Department of Computer Science, National Chengchi University, Taipei, Taiwan 1 {changyc,can,morphe,hsu}@iis.sinica.edu.tw, 2 patonchen@ntu.edu.tw Abstract emotion classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment words. By contrast, reader-emotio"
P15-2127,C10-1021,0,0.386056,"Missing"
P15-2127,D09-1150,0,0.438086,"ieh Chen1,3 , Yu-Lun Hsieh1,3 , Chien Chin Chen2 , Wen-Lian Hsu1 1 Institute of Information Science, Academia Sinica, Taipei, Taiwan 2 Department of Information Management, National Taiwan University, Taipei, Taiwan 3 Department of Computer Science, National Chengchi University, Taipei, Taiwan 1 {changyc,can,morphe,hsu}@iis.sinica.edu.tw, 2 patonchen@ntu.edu.tw Abstract emotion classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment words. By contrast, reader-emotion possesses a more perplexing nature, as even common words can invoke different types of reader-emotions depending on the re"
P15-2127,P09-2038,0,0.161331,"Hsieh1,3 , Chien Chin Chen2 , Wen-Lian Hsu1 1 Institute of Information Science, Academia Sinica, Taipei, Taiwan 2 Department of Information Management, National Taiwan University, Taipei, Taiwan 3 Department of Computer Science, National Chengchi University, Taipei, Taiwan 1 {changyc,can,morphe,hsu}@iis.sinica.edu.tw, 2 patonchen@ntu.edu.tw Abstract emotion classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment words. By contrast, reader-emotion possesses a more perplexing nature, as even common words can invoke different types of reader-emotions depending on the reader’s personal experiences an"
P15-2127,tang-chen-2012-mining,0,0.0365946,"on classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment words. By contrast, reader-emotion possesses a more perplexing nature, as even common words can invoke different types of reader-emotions depending on the reader’s personal experiences and knowledge (Lin et al., 2007). For instance, a sentence like “Kenya survivors describe deadly attack at Garissa University” is simply stating the facts without any emotion, but may invoke emotions such as angry or worried in its readers. In light of this rationale, we propose a principlebased approach (PBA) for reader-emotion classification. It is"
P15-2127,P02-1053,0,0.0112547,"ional resonance in articles under the assistance of the generated emotion templates. These templates have been proven to be highly interpretable, which is an attribute that is difficult to accomplish in traditional statistical methods. 1 Introduction The Internet has rapidly grown into a powerful medium for disseminating information. People can easily share experiences and emotions anytime and anywhere on social media websites. Human feelings can be quickly collected through emotion classification, as these emotions reflect an individual’s feelings and experiences toward some subject matters (Turney, 2002; Wilson et al., 2009). Moreover, people can obtain more sponsorship opportunities from manufacturers if their articles about a certain product are able to create more emotional resonance in the readers. Therefore, ∗ Corresponding author 775 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 775–780, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics −2log h p(w)N (w∧E) (1−p(w))N (E)−N (w∧E) p(w)N (w∧¬E) (1−p(w))N (¬E)−N (w∧¬E) p(w"
P15-2127,J09-3003,0,0.0335376,"e in articles under the assistance of the generated emotion templates. These templates have been proven to be highly interpretable, which is an attribute that is difficult to accomplish in traditional statistical methods. 1 Introduction The Internet has rapidly grown into a powerful medium for disseminating information. People can easily share experiences and emotions anytime and anywhere on social media websites. Human feelings can be quickly collected through emotion classification, as these emotions reflect an individual’s feelings and experiences toward some subject matters (Turney, 2002; Wilson et al., 2009). Moreover, people can obtain more sponsorship opportunities from manufacturers if their articles about a certain product are able to create more emotional resonance in the readers. Therefore, ∗ Corresponding author 775 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 775–780, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics −2log h p(w)N (w∧E) (1−p(w))N (E)−N (w∧E) p(w)N (w∧¬E) (1−p(w))N (¬E)−N (w∧¬E) p(w|E)N (w∧E) (1−p(w|E))N"
P19-1147,N19-1423,0,0.239001,"hat, compared to recurrent neural models, self-attentive models are more robust against adversarial perturbation. In addition, we provide theoretical explanations for their superior robustness to support our claims. 1 Introduction Self-attentive neural models have recently become a prominent component that achieves state-of-theart performances on many natural language processing (NLP) tasks such as text classification and machine translation (MT). This type of models, including Transformer (Vaswani et al., 2017) and “Bidirectional Encoder Representations from Transformers,” shortened as BERT (Devlin et al., 2019), rely on the attention mechanism (Luong et al., 2015) to learn a context-dependent representation; compared to recurrent neural networks (RNN), these self-attention-based models have faster encoding speed and the capacity of modeling a wider context. Particularly, BERT is recently proposed to extend the directionality of the Transformer model, and “pre-trained” using multiple objectives to strengthen its encoding capability. Then, this pre-trained model can be fine-tuned for various downstream tasks. BERT achieves state-of-the-art performance on several NLP tasks including classification and"
P19-1147,P18-2006,0,0.085596,"Related Work Robustness of neural network models has been a prominent research topic since Szegedy et al. (2013) discovered that CNN-based image classification models are vulnerable to adversarial examples. However, attempts to examine the robustness of NLP models are relatively few and far between. Previous work on attacking neural NLP models include using Fast Gradient Sign Method (Goodfellow et al., 2015) to perturb the embedding of RNN-based classifiers (Papernot et al., 2016; Liang et al., 2017), but they have difficulties mapping from continuous embedding space to discrete input space. Ebrahimi et al. (2018) propose the ‘HotFilp’ method that replaces the word or character with the largest difference in the Jacobian matrix. Li et al. (2016) employ reinforcement learning to find the optimal words to delete in order to fool the classifier. More recently, Yang et al. (2018) propose a greedy method to construct adversarial examples by solving a discrete optimization problem. They show superior performance than previous work in terms of attack success rate, but the greedy edits usually degrade the readability or significantly change the semantics. Zhao et al. (2018) utilize generative adversarial netwo"
P19-1147,D18-1316,0,0.799355,"Despite the superior performance, it remains unclear whether the self-attentive structure deployed by Transformer or BERT is robust to adversarial attacks compared with other neural networks. Adversarial attack refers to applying a small perturbation on the model input to craft an adversarial example, ideally imperceptible by humans, and cause the model to make an incorrect prediction (Goodfellow et al., 2015). Unlike computer vision models, generating an effective, textual adversarial example that misleads a model but can go unnoticed by humans is a challenging and thriving research problem (Alzantot et al., 2018). Therefore, the goal of this paper is to answer the following questions: “Are self-attentive models more robust to adversarial examples compared with recurrent models? If so, why?” “Do attention scores expose vulnerability in these selfattentive models?” This work verifies the robustness of selfattentive models through performing adversarial attacks and analyzing their effects on the model prediction. In addition, we investigate the feasibility of utilizing the context-dependent embeddings in these models to maximize semantic similarity between real and adversarial sentences. We conduct exper"
P19-1147,N18-1170,0,0.0604157,"s. We thus include the latest greedy and list-based approaches in our comparisons. In addition, the concept of adversarial attacks has also been explored in more complex NLP tasks. For example, Jia and Liang (2017) attempt to craft adversarial input to a question answering system by inserting irrelevant sentences at the end of a paragraph. Cheng et al. (2018) develop an algorithm for attacking seq2seq models with specific constraints on the content of the adversarial examples. Belinkov and Bisk (2018) compare typos and artificial noise as adversarial input to machine translation models. Also, Iyyer et al. (2018) propose a paraphrase generator model learned from back-translation data to generate legitimate paraphrases of a sentence as adversaries. However, the semantic similarity is not guaranteed. In terms of comparisons between LSTM and Transformers, Tang et al. (2018) show that multiheaded attention is a critical factor in Transformer when learning long distance linguistic relations. This work is unique in a number of aspects. First, we examine the robustness of uni- and bidirectional self-attentive model as compared to recurrent neural networks. And, we devise novel attack methods that take advant"
P19-1147,D17-1215,0,0.0607379,"the semantics. Zhao et al. (2018) utilize generative adversarial networks (GAN) to generate adversarial attacks against black-box models for applications including image classification, textual entailment, and machine translation. Alzantot et al. (2018) propose to use a pre-compiled list of semantically similar words to alleviate this issue, but leads to lower successful rate as shown in our experiments. We thus include the latest greedy and list-based approaches in our comparisons. In addition, the concept of adversarial attacks has also been explored in more complex NLP tasks. For example, Jia and Liang (2017) attempt to craft adversarial input to a question answering system by inserting irrelevant sentences at the end of a paragraph. Cheng et al. (2018) develop an algorithm for attacking seq2seq models with specific constraints on the content of the adversarial examples. Belinkov and Bisk (2018) compare typos and artificial noise as adversarial input to machine translation models. Also, Iyyer et al. (2018) propose a paraphrase generator model learned from back-translation data to generate legitimate paraphrases of a sentence as adversaries. However, the semantic similarity is not guaranteed. In te"
P19-1147,D15-1166,0,0.060656,"e models are more robust against adversarial perturbation. In addition, we provide theoretical explanations for their superior robustness to support our claims. 1 Introduction Self-attentive neural models have recently become a prominent component that achieves state-of-theart performances on many natural language processing (NLP) tasks such as text classification and machine translation (MT). This type of models, including Transformer (Vaswani et al., 2017) and “Bidirectional Encoder Representations from Transformers,” shortened as BERT (Devlin et al., 2019), rely on the attention mechanism (Luong et al., 2015) to learn a context-dependent representation; compared to recurrent neural networks (RNN), these self-attention-based models have faster encoding speed and the capacity of modeling a wider context. Particularly, BERT is recently proposed to extend the directionality of the Transformer model, and “pre-trained” using multiple objectives to strengthen its encoding capability. Then, this pre-trained model can be fine-tuned for various downstream tasks. BERT achieves state-of-the-art performance on several NLP tasks including classification and sequence-to-sequence problems, often outperforming tas"
P19-1147,N18-1101,0,0.112614,"Missing"
P19-1147,P02-1040,0,0.103542,"Missing"
P19-1147,D18-1458,0,0.0216186,"answering system by inserting irrelevant sentences at the end of a paragraph. Cheng et al. (2018) develop an algorithm for attacking seq2seq models with specific constraints on the content of the adversarial examples. Belinkov and Bisk (2018) compare typos and artificial noise as adversarial input to machine translation models. Also, Iyyer et al. (2018) propose a paraphrase generator model learned from back-translation data to generate legitimate paraphrases of a sentence as adversaries. However, the semantic similarity is not guaranteed. In terms of comparisons between LSTM and Transformers, Tang et al. (2018) show that multiheaded attention is a critical factor in Transformer when learning long distance linguistic relations. This work is unique in a number of aspects. First, we examine the robustness of uni- and bidirectional self-attentive model as compared to recurrent neural networks. And, we devise novel attack methods that take advantage of the embedding distance to maximize semantic similarity between real and adversarial examples. Last but not least, we provide detail observations of the inter1527 nal variations of different models under attack and theoretical analysis regarding their level"
W03-1118,C92-2082,0,0.00648027,"is to compile the concepts within documents in a training set and use these concepts to understand documents in a testing set. However, building rigorous domain ontology is laborious and time-consuming. Previous works suggest that ontology acquisition is an iterative process, which includes keyword collection and structure reorganization. The ontology is revised, refined, and accumulated by a human editor at each iteration (Noy and McGuinness, 2001). For example, in order to find a hyponym of a keyword, the human editor must observe sentences containing this keyword and its related hyponyms (Hearst, 1992). The editor then deduces rules for finding more hyponyms of this keyword. At each iteration the editor refines the rules to obtain better quality pairs of keyword-hyponyms. To speed up the above labor-intensive approach, semiautomatic approaches have been designed in which a human editor only has to verify the results of the acquisition (Maedche and Staab, 2000). A knowledge representation framework, Information Map (InfoMap) in our previous work (Hsu et al., 2001), has been designed to integrate various linguistic, common-sense and domain knowledge. InfoMap is designed to perform natural lan"
W03-1118,C02-1089,1,\N,Missing
W03-1118,C02-2013,1,\N,Missing
W03-1118,Y96-1018,0,\N,Missing
W03-1118,O98-4003,1,\N,Missing
W05-0638,A00-2018,0,0.308869,"Missing"
W05-0638,W05-0639,0,0.161713,"Missing"
W05-0638,C04-1197,0,0.148534,"ities that represent A0 and its reference type R-A0 are: k ∀m ∈{1,..., M } : ∑ ziA0 ≥ zmR −A0 . Integer Linear Programming (ILP) To represent full parsing information as features, there are still several syntactic constraints on a parsing tree in the SRL problem. For example, on a path of the parsing tree, there can be only one constituent annotated as a non-null argument. However, it is difficult to encode this constraint in the argument classification models. Therefore, we apply integer linear programming to resolve inconsistencies produced in the argument classification stage. According to Punyakanok et al. (2004), given a set of constituents, S, and a set of semantic role labels, A, the SRL problem can be formulated as an ILP as follows: Let zia be the indicator variable that represents whether or not an argument, a, is assigned to any Si ∈ S; and let pia = score(Si = a). The scoring matrix P composed of all pia is calculated by the argument classification models. The goal of this ILP is to find a set of assignments for all zia that maximizes the following function: ∑∑ pia zia . i =1 Constraint IV: C-XXX arguments The continued argument XXX has to occur before C-XXX. The linear inequalities for A0 are"
W05-0638,W04-3212,0,0.128552,"Missing"
W05-0638,J03-4003,0,\N,Missing
W05-0638,W05-0620,0,\N,Missing
W06-0122,W03-0428,0,0.0381044,"feature sets. In this paper, we use two ensemble methods to combine the results of the classifiers. We also combine the results generated by two machine learning models: maximum entropy (ME) [1] and CRF. One ensemble method is based on the majority vote [3], and the other is the memory based learner [7]. Although the ensemble methods have been applied in some sequence labeling tasks [2],[3], similar work in Chinese named entity recognition is scarce. Our Chinese named entity tagger uses a character-based model. For English named entity tasks, a character-based NER model proposed by Dan Klein [4] proves the usefulness of substrings within words. In Chinese NER, the characterbased model is more straightforward, since there are no spaces between Chinese words and each Chinese character is actually meaningful. Another reason for using a character-based model is that it can avoid the errors sometimes made by a Chinese word segmentor. The remainder of this paper is organized as follows. In the Section 2, we introduce the machine learning models, the features we apply in the machine learning models, and the ensemble methods. In Section 3, we briefly describe the experimental data and the ex"
W06-0122,J01-2002,0,0.0305322,"ered, because, unlike HMM, it does not make a dependence assumption. However, the obvious drawback of the CRF model is that it needs more computing resources, so we can not apply all the features of the model. One possible way to resolve this problem is to effectively combine the results of various individual classifiers trained with different feature sets. In this paper, we use two ensemble methods to combine the results of the classifiers. We also combine the results generated by two machine learning models: maximum entropy (ME) [1] and CRF. One ensemble method is based on the majority vote [3], and the other is the memory based learner [7]. Although the ensemble methods have been applied in some sequence labeling tasks [2],[3], similar work in Chinese named entity recognition is scarce. Our Chinese named entity tagger uses a character-based model. For English named entity tasks, a character-based NER model proposed by Dan Klein [4] proves the usefulness of substrings within words. In Chinese NER, the characterbased model is more straightforward, since there are no spaces between Chinese words and each Chinese character is actually meaningful. Another reason for using a character-ba"
W06-0122,P97-1056,0,0.0675049,"Missing"
W06-0122,J96-1002,0,0.0220881,"tage of the CRF model is that richer feature sets can be considered, because, unlike HMM, it does not make a dependence assumption. However, the obvious drawback of the CRF model is that it needs more computing resources, so we can not apply all the features of the model. One possible way to resolve this problem is to effectively combine the results of various individual classifiers trained with different feature sets. In this paper, we use two ensemble methods to combine the results of the classifiers. We also combine the results generated by two machine learning models: maximum entropy (ME) [1] and CRF. One ensemble method is based on the majority vote [3], and the other is the memory based learner [7]. Although the ensemble methods have been applied in some sequence labeling tasks [2],[3], similar work in Chinese named entity recognition is scarce. Our Chinese named entity tagger uses a character-based model. For English named entity tasks, a character-based NER model proposed by Dan Klein [4] proves the usefulness of substrings within words. In Chinese NER, the characterbased model is more straightforward, since there are no spaces between Chinese words and each Chinese character"
W06-0122,W03-0425,0,0.0160393,"more computing resources, so we can not apply all the features of the model. One possible way to resolve this problem is to effectively combine the results of various individual classifiers trained with different feature sets. In this paper, we use two ensemble methods to combine the results of the classifiers. We also combine the results generated by two machine learning models: maximum entropy (ME) [1] and CRF. One ensemble method is based on the majority vote [3], and the other is the memory based learner [7]. Although the ensemble methods have been applied in some sequence labeling tasks [2],[3], similar work in Chinese named entity recognition is scarce. Our Chinese named entity tagger uses a character-based model. For English named entity tasks, a character-based NER model proposed by Dan Klein [4] proves the usefulness of substrings within words. In Chinese NER, the characterbased model is more straightforward, since there are no spaces between Chinese words and each Chinese character is actually meaningful. Another reason for using a character-based model is that it can avoid the errors sometimes made by a Chinese word segmentor. The remainder of this paper is organized as fo"
W06-0602,H94-1020,0,0.0537987,"Missing"
W06-0602,J93-2004,0,0.0301737,"Missing"
W06-0602,N03-4009,0,0.079393,"fashion. In addition, users can customize the tag set of arguments. Other linguistic information can also be integrated and displayed in Figure 3. The percentage of the 30 biomedical verbs and other verbs in BioProp 3 3.1 Annotation of BioProp Annotation Process After choosing 30 verbs as predicates, we adopted a semi-automatic method to annotate BioProp. The annotation process consists of the following steps: (1) identifying predicate candidates; (2) automatically annotating the biomedical semantic roles with our WSJ SRL system; (3) transforming the automatic tagging results into WordFreak (Morton and LaCivita, 2003) format; and (4) manually correcting the annotation results with the WordFreak annotation tool. We now describe these steps in detail: 8 WordFreak, which is a convenient annotation tool. 4. In the last step, annotators check the predicted semantic roles using WordFreak and then correct or add semantic roles if the predicted arguments are incorrect or missing, respectively. Three biologists with sufficient biological knowledge in our laboratory performed the annotation task after receiving computational linguistic training for approximately three months. Figure 4 illustrates an example of BioPr"
W06-0602,J05-1004,0,0.12019,"Missing"
W06-0602,C04-1197,0,0.0103882,"ystem (called a BIOmedical SeMantIc roLe labEler, BIOSMILE) that is trained on BioProp and employs all the features used in our WSJ SRL system (Tsai et al., 2006). As with POS tagging, chunking, and named entity recognition, SRL can also be formulated as a sentence tagging problem. A sentence can be represented by a sequence of words, a sequence of phrases, or a parsing tree; the basic units of a sentence in these representations are words, phrases, and constituents, respectively. Hacioglu et al. (2004) showed that tagging phrase-byphrase (P-by-P) is better than word-by-word (Wby-W). However, Punyakanok et al. (2004) showed that constituent-by-constituent (C-by-C) tagging is better than P-by-P. Therefore, we use C-by-C tagging for SRL in our BIOSMILE. SRL can be divided into two steps. First, we identify all the predicates. This can be easily accomplished by finding all instances of verbs of interest and checking their part-of-speech (POS) tags. Second, we label all arguments corresponding to each predicate. This is a difficult problem, since the number of arguments and their positions vary according to a verb’s voice (active/passive) and sense, along with many other factors. In BIOSMILE, we employ the ma"
W06-0602,tateisi-tsujii-2004-part,0,0.0163253,"Missing"
W06-0602,W04-3212,0,0.0234413,"Missing"
W06-0602,W05-0620,0,0.0339564,"Missing"
W06-0602,W04-2416,0,0.0459367,"compare the performance of systems trained on BioProp and PropBank in different domains. We construct a new SRL system (called a BIOmedical SeMantIc roLe labEler, BIOSMILE) that is trained on BioProp and employs all the features used in our WSJ SRL system (Tsai et al., 2006). As with POS tagging, chunking, and named entity recognition, SRL can also be formulated as a sentence tagging problem. A sentence can be represented by a sequence of words, a sequence of phrases, or a parsing tree; the basic units of a sentence in these representations are words, phrases, and constituents, respectively. Hacioglu et al. (2004) showed that tagging phrase-byphrase (P-by-P) is better than word-by-word (Wby-W). However, Punyakanok et al. (2004) showed that constituent-by-constituent (C-by-C) tagging is better than P-by-P. Therefore, we use C-by-C tagging for SRL in our BIOSMILE. SRL can be divided into two steps. First, we identify all the predicates. This can be easily accomplished by finding all instances of verbs of interest and checking their part-of-speech (POS) tags. Second, we label all arguments corresponding to each predicate. This is a difficult problem, since the number of arguments and their positions vary"
W06-0602,I05-2038,0,\N,Missing
W06-0602,J03-4003,0,\N,Missing
W06-3308,W04-2416,0,0.0279478,"for argument classification. Then, we illustrate basic features as well as specialized features such as biomedical named entities and argument templates. AM-LOC Semantic Role Labeling on BioProp In this section, we introduce our BIOmedical SeMantIc roLe labEler, BIOSMILE. Like POS tagging, chunking, and named entity recognition, SRL can be formulated as a sentence tagging problem. A sentence can be represented by a sequence of words, a sequence of phrases, or a parsing tree; the basic units of a sentence are words, phrases, and constituents arranged in the above representations, respectively. Hacioglu et al. (2004) showed that tagging phrase by phrase (P-by-P) is better than word by word (W-by-W). Punyakanok et al., (2004) further showed that constituent-by-constituent (Cby-C) tagging is better than P-by-P. Therefore, we choose C-by-C tagging for SRL. The gold standard SRL corpus, PropBank, was designed as an additional layer of annotation on top of the syntactic structures of the Penn Treebank. 59 Maximum Entropy Model The maximum entropy model (ME) is a flexible statistical model that assigns an outcome for each instance based on the instance’s history, which is all the conditioning data that enables"
W06-3308,W04-1204,0,0.0496523,"Missing"
W06-3308,J05-1004,0,0.0276531,"the biomedical domain exists. In this paper, we aim to build such a biomedical SRL system. To achieve this goal we roughly implement the following three steps as proposed by Wattarujeekrit et al., (2004): (1) create semantic roles for each biomedical verb; (2) construct a biomedical corpus annotated with verbs and their corresponding semantic roles (following definitions created in (1) as a reference resource;) (3) build an automatic semantic interpretation model using the annotated text as a training corpus for machine learning. In the first step, we adopt the definitions found in PropBank (Palmer et al., 2005), defining our own framesets for verbs not in PropBank, such as “phosphorylate”. In the second step, we first use an SRL system (Tsai et al., 2005) trained on the Wall Street Journal (WSJ) to automatically tag our corpus. We then have the results double-checked by human annotators. Finally, we add automatically-generated template features to our SRL system to identify adjunct (modifier) arguments, especially those highly relevant to the biomedical domain. 2 Biomedical Proposition Bank As proposition banks are semantically annotated versions of a Penn-style treebank, they provide consistent sem"
W06-3308,C04-1197,0,0.0217708,"medical named entities and argument templates. AM-LOC Semantic Role Labeling on BioProp In this section, we introduce our BIOmedical SeMantIc roLe labEler, BIOSMILE. Like POS tagging, chunking, and named entity recognition, SRL can be formulated as a sentence tagging problem. A sentence can be represented by a sequence of words, a sequence of phrases, or a parsing tree; the basic units of a sentence are words, phrases, and constituents arranged in the above representations, respectively. Hacioglu et al. (2004) showed that tagging phrase by phrase (P-by-P) is better than word by word (W-by-W). Punyakanok et al., (2004) further showed that constituent-by-constituent (Cby-C) tagging is better than P-by-P. Therefore, we choose C-by-C tagging for SRL. The gold standard SRL corpus, PropBank, was designed as an additional layer of annotation on top of the syntactic structures of the Penn Treebank. 59 Maximum Entropy Model The maximum entropy model (ME) is a flexible statistical model that assigns an outcome for each instance based on the instance’s history, which is all the conditioning data that enables one to assign probabilities to the space of all outcomes. In SRL, a history can be viewed as all the informati"
W06-3308,P03-1002,0,0.0987388,"Missing"
W06-3308,tateisi-tsujii-2004-part,0,0.0717963,"Missing"
W06-3308,I05-2038,0,0.0172,"collection of MEDLINE abstracts selected from the search results with the following keywords: human, blood cells, and transcription factors. In the GENIA corpus, the abstracts are encoded in XML format, where each abstract also contains a MEDLINE UID, and the title and content of the abstract. The text of the title and content is segmented into sentences, in which biological terms are annotated with their semantic classes. The GENIA corpus is also annotated with part-ofspeech (POS) tags (Tateisi et al., 2004), and coreferences (Yang et al., 2004). The Penn-style treebank for GENIA, created by Tateisi et al. (2005), currently contains 500 abstracts. The annotation scheme of the GENIA Treebank (GTB), which basically follows the Penn Treebank II (PTB) scheme (Bies et al., 1995), is encoded in XML. However, in contrast to the WSJ corpus, GENIA lacks a proposition bank. We therefore use its 500 abstracts with GTB as our corpus. To develop our biomedical proposition bank, BioProp, we add the proposition bank annotation on top of the GTB annotation. 2.1 Important Argument Types In the biomedical domain, relations are often dependent upon locative and temporal factors (Kholodenko, 2006). Therefore, locative (A"
W06-3308,W04-3212,0,0.0417507,"Missing"
W10-4138,C04-1081,0,0.0601332,"Missing"
W10-4138,I05-3027,0,0.0463771,"Missing"
W10-4138,N06-2049,0,0.0968471,"for such a small corpus. “ENQUIRIES” follows “RAIL” with a very high probability when it is preceded by “BRITISH.” However, when “RAIL” is preceded by words other than “BRITISH,” “ENQUIRIES” does not occur, but words like “TICKET” or “JOURNEY” may. Thus, the bigram “RAIL ENQUIRIES” gives a misleading probability that “RAIL” is followed by “ENQUIRIES” irrespective of what precedes it. This problem happens not only with word-token corpora but also with corpora in which all the compounds are tagged as units since overlapping Ngrams still appear, therefore corresponding solutions such as those of Zhang et al. (2006) were proposed. We uses suffix array algorithm to calculate exact boundaries of phrase and their frequencies (Sung et al., 2008), called term contributed boundaries (TCB) and term contributed frequencies (TCF), respectively, to analogize similarities and differences with the term frequencies (TF). For example, in Vodis Corpus, the original TF of the term “RAIL ENQUIRIES” is 73. However, the actual TCF of “RAIL ENQUIRIES” is 0, since all of the frequency values are contributed by the term “BRITISH RAIL EN QUIRIES”. In this case, we can see that ‘BRITISH RAIL ENQUIRIES’ is really a more frequent"
W10-4138,W03-1728,0,\N,Missing
W11-3213,P04-1021,0,0.393823,"Missing"
W11-3213,O97-4005,0,0.02312,"E2C transliteration, that the training data comprised pairs of names written in source and target scripts lacks explicit grapheme-level alignment. This work uses M2Maligner as an unsupervised method for generating alignments of the training data, which provide hypotheses of DOM without null graphemes. 2.3 . 3 Accessor Variety 3.1 Feng et al. (2004) proposed accessor variety (AV) to measure how likely a character substring is a Chinese word. Another similar measurement of English and Chinese words called boundary entropy or branching entropy (BE) was used in several works (Tung and Lee, 1994; Chang and Su, 1997; Cohen and Adams, 2001; Transliteration using EM and CRF CRF Alignment Labeling In the work, M2M-aligner first maximizes the probability of the observed source-target word pairs using the EM algorithm and subsequently sets the grapheme alignments via maximum a posteriori estimation. CRF is then conditioned on the grapheme alignments to produce globally 87 optimal solutions. However, the performance of the EM algorithm is frequently affected by the initialization. To obtain better alignment results of M2M-aligner, this work empirically sets the “maxX” parameter for the maximum size of subalign"
W11-3213,J03-1002,0,0.00331536,"del for direct orthographical mapping (DOM) machine transliteration, in which the first CRF segments a source word into chunks and the second CRF maps the chunks to a word in the target language. Reddy and Waxmonsky (2009) presented a phrase-based translation system that characters are grouped into substrings to be mapped atomically into the target language, which showed how substring representation can be incorporated into a CRF model with local context and phonemic information. Shishtla et al. (2009) adopted a statistical transliteration technique that consists of alignment model of GIZA++ (Och and Ney, 2003) and CRF model. 86 Proceedings of the 2011 Named Entities Workshop, IJCNLP 2011, pages 86–90, Chiang Mai, Thailand, November 12, 2011. The approach of this work is similar to the technique of Shishtla et al., yet this work focuses on the additional AV feature of CRF and uses M2M-aligner, which will be described in Section 2.2, instead of GIZA++. 2.2 Cohen et al., 2002; Huang and Powers, 2003; Tanaka-Ishii, 2005; Jin and Tanaka-Ishii, 2006; Cohen et al., 2007). The basic idea behind these measurements is closely related to one particular perspective of n-gram and information theory of cross ent"
W11-3213,W09-3520,0,0.0893668,"into comparable phonemes so that the phonetic similarity between the two names can be measured easily. The grapheme-based approach, which treats the transliteration as a statistical machine translation problem under monotonic constraint, has also attracted much attention (Li et al., 2004). This approach aims to 2 2.1 Related Works CRF-based Transliteration Yang et al. (2009) proposed a two-step CRF model for direct orthographical mapping (DOM) machine transliteration, in which the first CRF segments a source word into chunks and the second CRF maps the chunks to a word in the target language. Reddy and Waxmonsky (2009) presented a phrase-based translation system that characters are grouped into substrings to be mapped atomically into the target language, which showed how substring representation can be incorporated into a CRF model with local context and phonemic information. Shishtla et al. (2009) adopted a statistical transliteration technique that consists of alignment model of GIZA++ (Och and Ney, 2003) and CRF model. 86 Proceedings of the 2011 Named Entities Workshop, IJCNLP 2011, pages 86–90, Chiang Mai, Thailand, November 12, 2011. The approach of this work is similar to the technique of Shishtla et"
W11-3213,W09-3507,0,0.230791,". This approach aims to 2 2.1 Related Works CRF-based Transliteration Yang et al. (2009) proposed a two-step CRF model for direct orthographical mapping (DOM) machine transliteration, in which the first CRF segments a source word into chunks and the second CRF maps the chunks to a word in the target language. Reddy and Waxmonsky (2009) presented a phrase-based translation system that characters are grouped into substrings to be mapped atomically into the target language, which showed how substring representation can be incorporated into a CRF model with local context and phonemic information. Shishtla et al. (2009) adopted a statistical transliteration technique that consists of alignment model of GIZA++ (Och and Ney, 2003) and CRF model. 86 Proceedings of the 2011 Named Entities Workshop, IJCNLP 2011, pages 86–90, Chiang Mai, Thailand, November 12, 2011. The approach of this work is similar to the technique of Shishtla et al., yet this work focuses on the additional AV feature of CRF and uses M2M-aligner, which will be described in Section 2.2, instead of GIZA++. 2.2 Cohen et al., 2002; Huang and Powers, 2003; Tanaka-Ishii, 2005; Jin and Tanaka-Ishii, 2006; Cohen et al., 2007). The basic idea behind th"
W11-3213,J04-1004,0,0.427408,"bilingual orthographical correspondence directly to reduce the possible errors introduced in multiple conversions. The hybrid approach attempts to utilize both phoneme and grapheme information for transliteration. Oh and Choi (2006) proposed a strategy to include both phoneme and grapheme features in a single learning process. This work presents a grapheme-based approach of English-to-Chinese (E2C) transliteration using many-to-many alignment (M2Maligner) (Jiampojamarn et al., 2007) and conditional random fields (CRF) (Lafferty et al., 2001) with additional features of accessor variety (AV) (Feng et al., 2004). The remainder of this article is organized as follows. Section 2 briefly introduces related works involving M2M-aligner, CRF, and AV. The concept of this work for transliteration using M2M-aligner, CRF, and AV are explained in Section 3. Section 4 describes the experiment results and discussion. Finally, the conclusion is presented in Section 5. Abstract This work presents a grapheme-based approach of English-to-Chinese (E2C) transliteration, which consists of many-to-many (M2M) alignment and conditional random fields (CRF) using accessor variety (AV) as an additional feature to approximate"
W11-3213,I05-1009,0,0.0321307,"rporated into a CRF model with local context and phonemic information. Shishtla et al. (2009) adopted a statistical transliteration technique that consists of alignment model of GIZA++ (Och and Ney, 2003) and CRF model. 86 Proceedings of the 2011 Named Entities Workshop, IJCNLP 2011, pages 86–90, Chiang Mai, Thailand, November 12, 2011. The approach of this work is similar to the technique of Shishtla et al., yet this work focuses on the additional AV feature of CRF and uses M2M-aligner, which will be described in Section 2.2, instead of GIZA++. 2.2 Cohen et al., 2002; Huang and Powers, 2003; Tanaka-Ishii, 2005; Jin and Tanaka-Ishii, 2006; Cohen et al., 2007). The basic idea behind these measurements is closely related to one particular perspective of n-gram and information theory of cross entropy or perplexity. Zhao and Kit (2007) induced that AV and BE both assume that the border of a potential word is located where the uncertainty of successive characters increases, where AV and BE are regarded as the discrete and continuous versions, respectively, of the fundamental work of Harris (1970), and then chose to adopt AV as the additional feature of CRF-based Chinese Word Segmentation (CWS). The AV of"
W11-3213,Y03-1017,0,0.0288556,"presentation can be incorporated into a CRF model with local context and phonemic information. Shishtla et al. (2009) adopted a statistical transliteration technique that consists of alignment model of GIZA++ (Och and Ney, 2003) and CRF model. 86 Proceedings of the 2011 Named Entities Workshop, IJCNLP 2011, pages 86–90, Chiang Mai, Thailand, November 12, 2011. The approach of this work is similar to the technique of Shishtla et al., yet this work focuses on the additional AV feature of CRF and uses M2M-aligner, which will be described in Section 2.2, instead of GIZA++. 2.2 Cohen et al., 2002; Huang and Powers, 2003; Tanaka-Ishii, 2005; Jin and Tanaka-Ishii, 2006; Cohen et al., 2007). The basic idea behind these measurements is closely related to one particular perspective of n-gram and information theory of cross entropy or perplexity. Zhao and Kit (2007) induced that AV and BE both assume that the border of a potential word is located where the uncertainty of successive characters increases, where AV and BE are regarded as the discrete and continuous versions, respectively, of the fundamental work of Harris (1970), and then chose to adopt AV as the additional feature of CRF-based Chinese Word Segmentat"
W11-3213,W03-1508,0,0.258718,"iveness of E2C transliteration. 1 Introduction Transliteration is a subfield of computation linguistics, and is defined as the phonetic translation of names across languages. Transliteration of named entities is essential in numerous applications, such as machine translation, corpus alignment, cross-language information retrieval, information extraction, and automatic lexicon acquisition. The transliteration modeling approaches can be classified as phoneme-based, grapheme-based, and a hybrid of phoneme and grapheme. Numerous studies focus on the phonemebased approach (Knight and Graehl, 1998; Virga and Khudanpur, 2003). Suppose that E is an English name and C is its Chinese transliteration, the phoneme-based approach first converts E into an intermediate phonemic representation p, and then converts p into its Chinese counterpart C. The idea is to transform both the source and target names into comparable phonemes so that the phonetic similarity between the two names can be measured easily. The grapheme-based approach, which treats the transliteration as a statistical machine translation problem under monotonic constraint, has also attracted much attention (Li et al., 2004). This approach aims to 2 2.1 Relat"
W11-3213,I08-4017,0,0.0608214,"CRF features along with their abbreviated notations for E2C transliteration, as shown in Table 3, where Ci represents the input graphemes bound individually to the prediction label at its current position i. Take Table 2 as an example, if the current position is at the label “B 迪”, features generated by C-1, C0 and C1 are “A” “D” and “I” respectively. Note that a prediction label may either comprise a positioning tag and a Chinese grapheme, or just be the positioning tag itself. Source Target ABBADIE 阿巴迪 Function Table 3. Conventional CRF Features 3.2 CRF with AV This work extends the work of Zhao and Kit (2008) into a unified representation for AV features of English graphemes. The representation accommodates both the position of a string and the string’s likelihood ranking by the logarithm. Formally, the ranking function for a string, s, with a score, x, counted by AV is defined as: f (s) = r, if 2r ≤ x &lt; 2r +1 (2) . The logarithm ranking mechanism in Eq. (2) is inspired by Zipf’s law to alleviate the potential data sparseness of infrequent strings. The rank r and the corresponding positions of a string are then concatenated as feature tokens. To provide readers with a clearer picture of the appear"
W11-3213,P10-1052,0,0.0548376,"ntioned in Section 2.2. Notably, this work follows the definition of grapheme described by Oh and Choi (2005) to prevent from confusion of phoneme, grapheme, character, and letter, that graphemes refer to the basic units (or the smallest contrastive units) of written language: for example, English has 26 graphemes or letters or characters, Korean has 24, and German has 30. Table 1 is an example of M2M-aligner results. With aligned training data, a transliteration model can be then trained by CRF to generate names in the target language from names in the source language. This work uses Wapiti (Lavergne et al., 2010) as CRF toolkit. Table 2 is an example of training data for a CRF alignment labeling, where the tags B and I indicate whether the grapheme is in the starting position of the sub-alignment. This work tests several combinations of conventional CRF features along with their abbreviated notations for E2C transliteration, as shown in Table 3, where Ci represents the input graphemes bound individually to the prediction label at its current position i. Take Table 2 as an example, if the current position is at the label “B 迪”, features generated by C-1, C0 and C1 are “A” “D” and “I” respectively. Note"
W11-3213,W10-2405,0,\N,Missing
W11-3213,W09-3516,0,\N,Missing
W11-3213,W09-3505,0,\N,Missing
W11-3213,J96-1002,0,\N,Missing
W11-3213,W09-3526,0,\N,Missing
W11-3213,P05-1002,0,\N,Missing
W11-3213,N07-1047,0,\N,Missing
W11-3213,W09-3511,0,\N,Missing
W11-3213,W09-3537,0,\N,Missing
W11-3213,W09-3501,0,\N,Missing
W11-3213,W10-2401,0,\N,Missing
W11-3213,W09-3515,0,\N,Missing
W11-3213,W09-3521,0,\N,Missing
W11-3213,W09-3513,0,\N,Missing
W11-3213,W09-3519,0,\N,Missing
W11-3213,W09-3506,0,\N,Missing
W11-3213,W10-2409,0,\N,Missing
W11-3213,W10-4138,1,\N,Missing
W11-3213,J98-4003,0,\N,Missing
W11-3213,W09-3504,0,\N,Missing
W11-3509,H05-1034,0,0.124796,"he communication possibilities 53 Proceedings of the Workshop on Advances in Text Input Methods (WTIM 2011), pages 53–61, Chiang Mai, Thailand, November 13, 2011. probabilities. Developers of IMs, however, are expected to pay more attention to the increasing needs on personalization1 and new word supplements via search engine logs 2 or social networks3. Only a handful of research papers to our knowledge explore adaptive language modeling of IM for Asian languages. Tanaka-Ishii et al. (2003) have examined corpus for vocabulary acquisition for Japanese in terms of reused words and unused words; Suzuki and Gao (2005) have proposed an error ratio corresponding to the number of newly introduced errors per each improvement after new training text was supplied. These two studies reflect a common expectation of IM users—backward compatibility—which means a word prediction that was previously correct should remain correct with new words recognized simultaneously. This work intends to expand the approach towards backward compatibility using novel evaluation methods for Chinese predictive phoneticbased IM, by comparing text entry performance before and after user corrections of predictive IM-generated errors. Onc"
W11-3509,Y96-1018,0,0.0173489,"on) influence accuracy of adaptively predictive IMs. The γ values stand for components of ρ at certain decision point. For instance, γi,herror represents the chance of human error occurred during the process of input. In order to test and demonstrate the ability of proposed evaluation methodology, this work conducts a simulation of three IM products. 3 Simulation Three products of adaptively predictive IMs, named IM-A, IM-B, and IM-C, are used in the simulation. The presented text P consists of 4,000 sentences, containing 39,469 words retrieved from the Academia Sinica Balanced Corpus (ASBC) (Chen et al., 1996). Two independent variables are simulated: context length in terms of character and ρhcorrection. The context length k is for different strategies of word-level correction. Since there is not yet a consensus on the Chinese word-hood debate, the number of words is calculated by characters as context length k in this work. It is interesting to observe how IMs are influenced by these different strategies. The simulation is designed so that if |T |is shorter than k, errors occurring in T will not change. Otherwise, the simulation will chop the first k characters of T to form a substring, denoted a"
W11-3509,P03-1052,0,0.0617266,"is pressed. Ambiguous keyboards gain attentions because of mobile computing, which has limited space. Also, such keyboards expand the communication possibilities 53 Proceedings of the Workshop on Advances in Text Input Methods (WTIM 2011), pages 53–61, Chiang Mai, Thailand, November 13, 2011. probabilities. Developers of IMs, however, are expected to pay more attention to the increasing needs on personalization1 and new word supplements via search engine logs 2 or social networks3. Only a handful of research papers to our knowledge explore adaptive language modeling of IM for Asian languages. Tanaka-Ishii et al. (2003) have examined corpus for vocabulary acquisition for Japanese in terms of reused words and unused words; Suzuki and Gao (2005) have proposed an error ratio corresponding to the number of newly introduced errors per each improvement after new training text was supplied. These two studies reflect a common expectation of IM users—backward compatibility—which means a word prediction that was previously correct should remain correct with new words recognized simultaneously. This work intends to expand the approach towards backward compatibility using novel evaluation methods for Chinese predictive"
W11-3509,O07-5006,0,0.0397523,"Missing"
W12-4412,W11-3213,1,0.778384,"Missing"
W12-4412,P04-1021,0,0.46359,"etrieval/extraction, and automatic lexicon acquisition (Li et al., 2009). It can be either phoneme-based, grapheme-based, or a hybrid of the above. The phoneme-based approach transforms source and target names into comparable phonemes for an intuitive phonetic similarity measurement between two names (Knight and Graehl, 1998; Virga and Khudanpur, 2003). The grapheme-based approach, which treats transliteration as statistical machine translation problem under monotonic constraint, aims to obtain a direct orthographical mapping (DOM) to reduce possible errors introduced in multiple conversions (Li et al., 2004). The hybrid approach attempts to utilize both phoneme and grapheme information (Oh and Choi, 2006). Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations (Li et al., 2004). The state-of-theart of transliteration approach is bilingual DOMs without intermediate phonetic projections (Yang et al., 2010). Due to the success of CRF on sequential labeling problem (Lafferty et al., 2001), numerous machine transliteration systems applied it. Some of them treat transliteration as a two-"
W12-4412,J04-1004,0,0.0399979,"ang et al., 2010; Qin and Chen, 2011). Dramatically de-creasing the cost of training with complex features is the major advantage of two-stage methods, but their downside is, compared to one-stage methods, features of target language are not directly applied in the first stage. Richer context generally gains better results of sequential labeling, but squeezed performance always comes with a price of computational complexity. To balance cost and benefit for English-to-Chinese (E2C) transliteration, this work compares the one-stage method with the two-stage one, using additional features of AV (Feng et al., 2004) and M2M-aligner as an initial alignment (Jiampojamarn et al., 2007), to explore where the best investment reward is. The remainder of this paper is organized as follows. Section 2 briefly introduces related works, including two-stage methods and AV. The machine transliteration system using M2M-aligner, CRF models, and AV features in this work is explained in Section 3. Section 4 describes 76 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 76–80, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics experiment r"
W12-4412,J03-1002,0,0.00318286,", pages 76–80, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics experiment results along with a discussion in Section 5. Finally, Section 6 draws a conclusion. 2 Related Works Reddy and Waxmonsky (2009) presented a phrasebased transliteration system that groups characters into substrings mapping onto target names, to demonstrate how a substring representation can be incorporated into CRF models with local context and phonemic information. Shishtla et al. (2009) adopted a statistical transliteration technique that consists of alignment models of GIZA++ (Och and Ney, 2003) and CRF models. Jiang et al. (2011) used M2M-aligner instead of GIZA++ and applied source grapheme’s AV in a CRF-based transliteration. A two-stage CRF-based transliteration was first designed to pipeline two independent processes (Yang et al., 2009). To recover from error propagations of the pipeline, a joint optimization of two-stage CRF method is then proposed to utilize n-best candidates of source name segmentations (Yang et al. 2010). Another approach to resist errors from the first stage is split training data into pools to lessen computation cost of sophisticated CRF models for the sec"
W12-4412,W09-3520,0,0.0502222,"Missing"
W12-4412,W03-1508,0,0.0596648,"eatures and finer grained labels than the latter. 1 Introduction Machine transliteration is the phonetic transcription of names across languages and is essential in numerous natural language processing applications, such as machine translation, crosslanguage information retrieval/extraction, and automatic lexicon acquisition (Li et al., 2009). It can be either phoneme-based, grapheme-based, or a hybrid of the above. The phoneme-based approach transforms source and target names into comparable phonemes for an intuitive phonetic similarity measurement between two names (Knight and Graehl, 1998; Virga and Khudanpur, 2003). The grapheme-based approach, which treats transliteration as statistical machine translation problem under monotonic constraint, aims to obtain a direct orthographical mapping (DOM) to reduce possible errors introduced in multiple conversions (Li et al., 2004). The hybrid approach attempts to utilize both phoneme and grapheme information (Oh and Choi, 2006). Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations (Li et al., 2004). The state-of-theart of transliteration approac"
W12-4412,W09-3515,0,0.0445223,"Missing"
W12-4412,P10-2051,0,0.0362662,"Missing"
W12-4412,I08-4017,0,0.0449712,"Missing"
W12-4412,N07-1047,0,\N,Missing
W12-4412,W09-3501,0,\N,Missing
W12-4412,J98-4003,0,\N,Missing
W12-4412,W09-3507,0,\N,Missing
W12-4412,P10-1052,0,\N,Missing
W13-4417,W03-1726,0,0.0698079,"Missing"
W13-4417,W10-4107,0,\N,Missing
W16-6211,P15-2127,1,0.866362,"escribed the task of reader-emotion classification on news articles and classified Yahoo! News articles into 8 emotion classes (e.g. happy, angry, or depressing) from the readers’ perspectives. They combined unigram, bigram, metadata, and emotion categories to train a classifier for the reader-emotions toward news. Yang et al. (2009) automatically annotated reader-emotions on a writeremotion corpus with a reader-emotion classifier, and studied the interactions between them. Furthermore, applications of reader-emotion categorization include learning linguistic templates for writing assistance (Chang et al., 2015). One can also collect public opinions toward political issues through emotion classification. Sarmento et al. (2009) used a rule-based method to collect a corpus of online comments for political opinion mining. Fang et al. (2012) extract contents from multiple sources on the same topic and quantify the differences within. An opinion formation framework was developed for content analysis of social media to conduct political opinion forecast (Sobkowicz et al., 2012). What distinguishes this work from others is that we attempt to test the possibility of inferring publicity, or “likability”, of a"
W16-6211,C10-1021,0,0.0164306,"ms other text categorization and reader-emotion classification methods; in turn, these results can be used to conduct publicity mining for propaganda and other public relations purposes. 2 Related Work Articles are one of the most common medium for persons to convey their feelings. Identifying essential factors that affect emotion transition is important for human language understanding. With the rapid growth of computer mediated communication applications, such as social websites and micro-blogs, research on emotion classification has recently been attracting more attention from enterprises (Chen et al., 2010; Purver and Battersby, 2012). In general, a single piece of text may possess two types of emotions: writer-emotion and reader-emotion. The research of writer-emotion investigates the emotion expressed by the writer when writing the text. For example, Pang et al. (2002) pioneered the use of machine learning technique on sentiment classification of movie reviews into positive and negative emotions. Mishne (2005), and Yang and Chen (2006) used emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at the document or sentence level, respectively. In their studies, emoticons are take"
W16-6211,P09-2038,0,0.0360763,"Missing"
W16-6211,W12-6338,0,0.0472296,"Missing"
W16-6211,W02-1011,0,0.0181803,"eir feelings. Identifying essential factors that affect emotion transition is important for human language understanding. With the rapid growth of computer mediated communication applications, such as social websites and micro-blogs, research on emotion classification has recently been attracting more attention from enterprises (Chen et al., 2010; Purver and Battersby, 2012). In general, a single piece of text may possess two types of emotions: writer-emotion and reader-emotion. The research of writer-emotion investigates the emotion expressed by the writer when writing the text. For example, Pang et al. (2002) pioneered the use of machine learning technique on sentiment classification of movie reviews into positive and negative emotions. Mishne (2005), and Yang and Chen (2006) used emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at the document or sentence level, respectively. In their studies, emoticons are taken as the answer, and textual keywords are considered as features. Wu et al. (2006) propose a sentence level emotion recognition method using dialogs as their corpus, in which “Happy”, “Unhappy”, or “Neutral” are assigned to each sentence as its emotion category. Yang et"
W16-6211,E12-1049,0,0.0125089,"orization and reader-emotion classification methods; in turn, these results can be used to conduct publicity mining for propaganda and other public relations purposes. 2 Related Work Articles are one of the most common medium for persons to convey their feelings. Identifying essential factors that affect emotion transition is important for human language understanding. With the rapid growth of computer mediated communication applications, such as social websites and micro-blogs, research on emotion classification has recently been attracting more attention from enterprises (Chen et al., 2010; Purver and Battersby, 2012). In general, a single piece of text may possess two types of emotions: writer-emotion and reader-emotion. The research of writer-emotion investigates the emotion expressed by the writer when writing the text. For example, Pang et al. (2002) pioneered the use of machine learning technique on sentiment classification of movie reviews into positive and negative emotions. Mishne (2005), and Yang and Chen (2006) used emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at the document or sentence level, respectively. In their studies, emoticons are taken as the answer, and textual"
W16-6211,D09-1150,0,0.0483977,"Missing"
W16-6211,P05-2008,0,0.0330752,"ed emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at the document or sentence level, respectively. In their studies, emoticons are taken as the answer, and textual keywords are considered as features. Wu et al. (2006) propose a sentence level emotion recognition method using dialogs as their corpus, in which “Happy”, “Unhappy”, or “Neutral” are assigned to each sentence as its emotion category. Yang et al. (2006) adopted Thayer’s model (Thayer, 1989) to classify music emotions. Each music segment can be classified into four classes of moods. As for sentiment 75 analysis, Read (2005) used emoticons in newsgroup articles to extract relevant instances for training polarity classifiers. On the other hand, the research of reader-emotion concerns the emotions expressed by a reader after reading the text. The writer and readers may view the same text from different perspectives, hence they do not always share the same emotion. Since the recent increase in the popularity of Internet, certain news websites, such as Yahoo! Kimo News, incorporate the Web 2.0 technologies that allow readers to express their emotions toward news articles. Classifying emotions from the readers’ point"
W16-6211,tang-chen-2012-mining,0,0.0358871,"Missing"
W16-6211,P02-1053,0,0.0126583,"Missing"
W16-6211,J09-3003,0,0.122551,"Missing"
W16-6211,O06-1017,0,0.0474837,"munication applications, such as social websites and micro-blogs, research on emotion classification has recently been attracting more attention from enterprises (Chen et al., 2010; Purver and Battersby, 2012). In general, a single piece of text may possess two types of emotions: writer-emotion and reader-emotion. The research of writer-emotion investigates the emotion expressed by the writer when writing the text. For example, Pang et al. (2002) pioneered the use of machine learning technique on sentiment classification of movie reviews into positive and negative emotions. Mishne (2005), and Yang and Chen (2006) used emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at the document or sentence level, respectively. In their studies, emoticons are taken as the answer, and textual keywords are considered as features. Wu et al. (2006) propose a sentence level emotion recognition method using dialogs as their corpus, in which “Happy”, “Unhappy”, or “Neutral” are assigned to each sentence as its emotion category. Yang et al. (2006) adopted Thayer’s model (Thayer, 1989) to classify music emotions. Each music segment can be classified into four classes of moods. As for sentiment 75 analysi"
W17-5804,W17-2316,0,0.0610712,"Missing"
W17-5804,P15-4004,0,0.0284883,"Missing"
W17-5804,P02-1034,0,0.039245,"hat tree fragments can be matched by applying word embedding similarity σ. Even those tree fragments are not identical but are semantically related. (1) where N T1 and N T2 denote the sets of nodes in T1 and T2, respectively. The function ∆(n1, n2) is equal to the number of common fragments rooted in the n1 and n2 nodes. Since the number of different sub-trees is exponential with the parse tree size, it is computationally infeasible to directly use the feature vector. In recent years, multiple tree kernels have been proposed for resolving this computation issue, such as syntactic tree kernel (Collins and Duffy, 2002), partial tree kernel (Moschitti, 2006), and lexical semantic kernel (Basili et al., 2005). However, the lexical in these tree kernels must belong to the leaf nodes of exactly the same structures limits its applications. Trivially, it cannot work on dependency trees. Croce et al. (2011) proposed a much more general smoothed tree kernel (i.e. smoothing partial tree kernel, SPTK) that can be applied to any tree and exploit any combination of lexical similarities, respecting the syntax enforced by the tree. Therefore, we adopt SPTK to capture the syntactic similarity between the above high dimens"
W17-5804,D11-1096,0,0.139825,"ahoo Answers dataset. They observed that the convolution tree kernel function can effectively utilize the syntactic structure of a sentence. On the other hand, Agarwal (2011) applied partial tree kernel (PTK) to classify sentiment polarity of twitter data and achieved remarkable performance. The kernel provides the ability to analyze additional semantic information by considering the contribution of shared subsequences containing all children of nodes. PTK compares words by the order of alphabets to determine word similarity for ameliorating the weak point of convolution tree kernel. Later on Croce et al. (2011) proposed smoothing partial tree kernel (SPTK) and improved the calculation method of word similarity by using singular value decomposition (SVD) to transform all words into vectors for determining the cosine similarity between them. In this paper, we built models based on SPTK and three kinds of tree structures. Besides part-ofspeech (POS) tags, the new tree structures incorporate dependency tree and grammatical relations for extracting more useful features. Furthermore, we used word embedding to substitute the vectors generated by SVD. Many studies have demonstrated that word embedding is re"
W17-5804,W05-0601,0,0.031982,"gments are not identical but are semantically related. (1) where N T1 and N T2 denote the sets of nodes in T1 and T2, respectively. The function ∆(n1, n2) is equal to the number of common fragments rooted in the n1 and n2 nodes. Since the number of different sub-trees is exponential with the parse tree size, it is computationally infeasible to directly use the feature vector. In recent years, multiple tree kernels have been proposed for resolving this computation issue, such as syntactic tree kernel (Collins and Duffy, 2002), partial tree kernel (Moschitti, 2006), and lexical semantic kernel (Basili et al., 2005). However, the lexical in these tree kernels must belong to the leaf nodes of exactly the same structures limits its applications. Trivially, it cannot work on dependency trees. Croce et al. (2011) proposed a much more general smoothed tree kernel (i.e. smoothing partial tree kernel, SPTK) that can be applied to any tree and exploit any combination of lexical similarities, respecting the syntax enforced by the tree. Therefore, we adopt SPTK to capture the syntactic similarity between the above high dimensional vectors implicitly, as well as partial lexical similarity of trees. The ∆ SPTK (n1,"
W17-5804,P04-1043,0,0.189029,"Missing"
W17-5804,P04-1054,0,0.1434,", 2014). However, employing rule based detection can lead to many false positives since it doesn’t consider context or sentiment embedded in the tweet. Often, the tweets recognised by rule based methods seem to be sarcastic. For example, consider the tweet “I look like I’m 6 months pregnant”. This tweet is a sarcastic tweet and the user actually is not pregnant. Thus, in order to overcome this issue, we propose to use a tree kernel-based approach to detect pregnant woman more effectively. Tree kernel-based approaches have been applied to many different researches, such as relation extraction (Culotta and Sorensen, 2004), question classification (Zhang and Lee, 2003) and protein interaction detection (Miwa et al., 2010). In recent years, tree kernel-based models were used to analyze Twitter data, but most of those studies were focused on opinion mining and sentiment classification (Agarwal et al., 2011; Alicante et al., 2016). In this study, we investigate the effectiveness of applying the approach on the task of determining whether a tweet is posted by a pregnant woman or not. 2 tween two trees, Moschitti (2006) proposed convolution tree kernel and developed a toolkit for public. Wang et al. (2009) adopted c"
W17-5809,P04-1043,0,0.101881,"i, j ) = ⎨ 1∀ i = j ⎪λ (i, j ) ≈ − 1 ∀ i ≠ j ⎪ ⎪ sim(i − 1, j ) + ⎪⎩ λ (i, _) ≈ −2 tures (both simple and complex). Each phrase structure is characterized with an “ID”, and the feature vector maintains the count of corresponding phrase structures per instance. A combination of the parse tree and feature vector is used in developing and testing the model. To classify the phrase structures according to the similarity index, Convolution Tree Kernel is employed to compare the substructures across parsed instances. SVM-Light-TK-1.54 toolkit was used in both the learning and classification modules (Moschitti 2004, 2006). Algorithm 1: Invariance Pattern Generation INPUT: contextP : PRelation|Chemical|Disease(x0....xn)k triplet pattern for all candidate instances orderedI(P): Invariant functional score I(P)k for all candidate instances in descending order BEGIN 1: set seedI(P) = orderedI(P)0 2: set seedP = contextP 0 3: FOR k=0 : size(orderedI(P)) 4: currI(P) = orderedI(P)k 5: currP = contextP k 6: invarQuotient = ( seedI(P)/ currI(P)) 7: IF invarQuotient == 1.0 8: reset seedP = align seedP with currP 9: remove( orderedI(P)k ) & k = k-1 |k!= 0 10: ELSE 11: IF seedP exists in InvariancePatterns 12: remov"
W17-5809,W04-3111,0,0.0719459,"Missing"
W17-5809,D14-1082,0,\N,Missing
Y07-1051,P02-1051,0,0.0396549,"s to grow rapidly in Korea. One key way to meet this demand is to retrieve information written in Chinese by ∗ Copyright 2007 by Yu-Chun Wang, Yi-Hsun Lee, Chu-Cheng Lin, Richard Tzong-Han Tsa, Wen-Lian Hsu 489 using Korean queries, referred to as Korean-Chinese cross-language information retrieval (KCIR). The main challenge involves translating NEs because they are usually the main concepts of queries. In Chen (1998), the authors romanized Chinese NEs and selected their English transliterations from English NEs extracted from the Web by comparing their phonetic similarities with Chinese NEs. Al-Onaizan and Knight (2002) transliterated an NE in Arabic into several candidates in English and ranked the candidates by comparing their occurrences in several English corpora. In the above works, the target languages are alphabetic; however, in KC translation, the target language is Chinese, which uses an ideographic writing system. KoreanChinese NET is much more difficult than NET considered in previous works because, in Chinese, one syllable may map to tens or hundreds of characters. For example, if an NE written in Korean comprises three syllables, there may be thousands of translation candidates in Chinese. In th"
Y07-1051,P98-1036,0,0.0341321,"Missing"
Y07-1051,C98-1036,0,\N,Missing
Y11-1011,O92-1003,0,0.182742,"ven an utterance “[[meta][data]] / is / the / data / of / data” as standard in five boundaries, seven morphemes (notice the case of [[meta][data]]), six words, and five lexicon types, one possible segmentation “meta / data / is / the / data / of / data” results in one boundary error, zero morpheme error, two word errors, and one lexicon type error. Ando and Lee (2003) proposed a constituent-based metric called compatible bracket error, which counts reasonable combinations of morphemes, estimate “[meta][data]” and “[metadata]” as interchangeable. Previous studies also counted word error rates (Chiang et al., 1992; Teahan et al. 2000; Wong and Chan, 1996) and sentence accuracy (Chiang et al., 1992) as complementary metrics of word-based recall and precision. Several other constituent-based metrics exist, and are usually close related to IR. For example, Liu et al. (2008) proposed an evaluation measure “RankPrecision” based on Kendalltau distance, which compared the similarity between the predicted rankings of “Internal Association Strength (IAS)” and the ideally sorted rankings of IAS in descending order. Methodologies resemble IAS, which may be seen as constituent-based measurements, are “Phrase Insep"
Y11-1011,W10-4101,0,0.062982,"Missing"
Y11-1011,I05-3017,0,0.0173179,"tly has become a focus of research during the past two decades. Numerous researchers have urged the application of various algorithms to produce “accurate” tokenized text in which the segmentations are performed to match one of the standards of Chinese corpora, such as Academia Sinica Balanced Corpus (Huang et al., 1997) and Chinese Treebank of University of Pennsylvania (Xia, 1999), and evaluated using various metrics, such as word-based precision (P), recall (R) and their harmonic average, termed F1 measure score (Fscore), popularized by SIGHAN Chinese WS bakeoffs (Sproat and Emerson, 2003; Emerson, 2005; Levow, 2006; Jin and Chen, 2007; Zhao and Liu, 2010). Subsequently, WS systems that ∗ This research was supported in part by the National Science Council under grant NSC 100-2631-S-001-001, and the research center for Humanities and Social Sciences under grant IIS-50-23. Ted Kony is appreciated for his editorial assistance. The authors would like to thank anonymous reviewers for their constructive criticisms. Copyright 2011 by Mike Tian-Jian Jiang, Cheng-Wei Shih, Chan-Hung Kuo, Richard Tzong-Han Tsai, and Wen-Lian Hsu 25th Pacific Asia Conference on Language, Information and Computation, pa"
Y11-1011,P08-1016,0,0.0128341,"native metrics were proposed and discussed, including geometric mean average precision (Robertson, 2006) or other popularity-based measurements (Mizzaro, 2008; Yilmaz and Aslam, 2006), but have not been adopted widely. 2.2 Evaluation of Chinese Word Segmentation This study classifies known evaluation metrics of WS into three categories: boundary-based, token-based and constituent-based. Boundary recall is defined as the percentage of correct boundaries identified, while boundary precision is defined as the percentage of identified boundaries that are correct, discounting utterance boundaries (Fleck, 2008; Goldwater et al., 2009; Palmer and Burger, 1997). Token-based recall (R) and precision (P) are defined 101 analogously to their boundary-based counterparts, except the unit of measurement is tokens rather than boundaries, where tokens can be treated as morpheme instances (Ando and Lee, 2003), lexicon types (Fleck, 2008; Goldwater et al., 2009), or word instances. For example, given an utterance “[[meta][data]] / is / the / data / of / data” as standard in five boundaries, seven morphemes (notice the case of [[meta][data]]), six words, and five lexicon types, one possible segmentation “meta /"
Y11-1011,J05-4005,0,0.0184316,"AN Chinese WS bakeoff traditionally apply word-based evaluation metrics such as recall (R), precision (P), and F1-score (F) to both in-vocabulary and 103 out-of-vocabulary data to measure participating system performance. Although these measurements are intuitive and uncomplicated, they still suffer the weakness of not considering incorrect segments that variously influence applications such as web search or text retrieval. This section presents qualitative analysis between word-based WS evaluation metrics and the proposed metrics. Notably, this study follows the naming convention proposed by Gao et al. (2005) and uses “segmentation unit” (segment in short, hereafter) rather than “word” as the conceptual element of qualitative analysis. An input sequence “XYX” and its four possible segmentation gold standards G1, G2, G3 and G4 are “X/Y/X,” “X/YX,” “XY/X” and “XYX”, respectively. Furthermore, four different systems S1, S2, S3, and S4 output “X/Y/X,” “X/YX,” “XY/X,” and “XYX,” respectively. Table 1 lists their recall (R) and precision (P). Table 1: Performance Evaluation Samples of SIGHAN’s Metrics G1: X/Y/X G2: X/YX G3: XY/X G4: XYX S1: X/Y/X R P 3/3 3/3 1/2 1/3 1/2 1/3 0/1 0/3 S2: X/YX R P 1/3 1/2"
Y11-1011,W02-1804,0,0.214166,"ion that WS accuracy is directly related to the effectiveness of follow-up applications. However, this perspective has sometimes failed to win significant support, particularly in the Chinese IR area, because of the absence of strong evidence confirming the causation. As described later in Section 2.3, some previous studies demonstrated a non-monotonic relationship between the performances of WS and IR for Mandarin Chinese, implying that better WS results do not necessarily yield better IR outcomes (Foo and Li, 2004; Kwok, 2000; Peng et al., 2002), while other studies have shown the opposite (He et al., 2002; Nie et al., 2000; Palmer and Burger, 1997). Although these investigations provide valuable information, they remain unable to reach consensus regarding the principles or metrics involved in selecting a proper WS system for IR applications. Developing a credible method of measuring Chinese WS system requires error analysis. However, the mainstream of WS literature overlooked how incorrect identification of segments based on particular standards affects certain type of applications, and instead focused on improving segmentation accuracy. Consequently, this study annotates negative segment (NS)"
Y11-1011,O97-4003,0,0.0754867,"stics demonstrate that TNR and NPV are generally more closely correlated with MAP than are P and R. Keywords: 1 Word segmentation, information retrieval, true negative rate. Introduction Word segmentation (WS) is an essential preparatory work for Chinese text processing applications and consequently has become a focus of research during the past two decades. Numerous researchers have urged the application of various algorithms to produce “accurate” tokenized text in which the segmentations are performed to match one of the standards of Chinese corpora, such as Academia Sinica Balanced Corpus (Huang et al., 1997) and Chinese Treebank of University of Pennsylvania (Xia, 1999), and evaluated using various metrics, such as word-based precision (P), recall (R) and their harmonic average, termed F1 measure score (Fscore), popularized by SIGHAN Chinese WS bakeoffs (Sproat and Emerson, 2003; Emerson, 2005; Levow, 2006; Jin and Chen, 2007; Zhao and Liu, 2010). Subsequently, WS systems that ∗ This research was supported in part by the National Science Council under grant NSC 100-2631-S-001-001, and the research center for Humanities and Social Sciences under grant IIS-50-23. Ted Kony is appreciated for his edi"
Y11-1011,D08-1111,0,0.0207896,"one boundary error, zero morpheme error, two word errors, and one lexicon type error. Ando and Lee (2003) proposed a constituent-based metric called compatible bracket error, which counts reasonable combinations of morphemes, estimate “[meta][data]” and “[metadata]” as interchangeable. Previous studies also counted word error rates (Chiang et al., 1992; Teahan et al. 2000; Wong and Chan, 1996) and sentence accuracy (Chiang et al., 1992) as complementary metrics of word-based recall and precision. Several other constituent-based metrics exist, and are usually close related to IR. For example, Liu et al. (2008) proposed an evaluation measure “RankPrecision” based on Kendalltau distance, which compared the similarity between the predicted rankings of “Internal Association Strength (IAS)” and the ideally sorted rankings of IAS in descending order. Methodologies resemble IAS, which may be seen as constituent-based measurements, are “Phrase Inseparability” (Shi and Nie, 2009) and the “Tightness Continuum Measure” (Xu et al. 2010). 2.3 WS-to-IR Performance Relationship The influence of different Chinese WS methods on IR has attracted extensive research attention (Foo and Li, 2004; He et al. 2002; Kwok, 2"
Y11-1011,C02-1148,0,0.147956,"d are selected as the preprocessors for the commonly accepted notion that WS accuracy is directly related to the effectiveness of follow-up applications. However, this perspective has sometimes failed to win significant support, particularly in the Chinese IR area, because of the absence of strong evidence confirming the causation. As described later in Section 2.3, some previous studies demonstrated a non-monotonic relationship between the performances of WS and IR for Mandarin Chinese, implying that better WS results do not necessarily yield better IR outcomes (Foo and Li, 2004; Kwok, 2000; Peng et al., 2002), while other studies have shown the opposite (He et al., 2002; Nie et al., 2000; Palmer and Burger, 1997). Although these investigations provide valuable information, they remain unable to reach consensus regarding the principles or metrics involved in selecting a proper WS system for IR applications. Developing a credible method of measuring Chinese WS system requires error analysis. However, the mainstream of WS literature overlooked how incorrect identification of segments based on particular standards affects certain type of applications, and instead focused on improving segmentation accu"
Y11-1011,W03-1719,0,0.456166,"applications and consequently has become a focus of research during the past two decades. Numerous researchers have urged the application of various algorithms to produce “accurate” tokenized text in which the segmentations are performed to match one of the standards of Chinese corpora, such as Academia Sinica Balanced Corpus (Huang et al., 1997) and Chinese Treebank of University of Pennsylvania (Xia, 1999), and evaluated using various metrics, such as word-based precision (P), recall (R) and their harmonic average, termed F1 measure score (Fscore), popularized by SIGHAN Chinese WS bakeoffs (Sproat and Emerson, 2003; Emerson, 2005; Levow, 2006; Jin and Chen, 2007; Zhao and Liu, 2010). Subsequently, WS systems that ∗ This research was supported in part by the National Science Council under grant NSC 100-2631-S-001-001, and the research center for Humanities and Social Sciences under grant IIS-50-23. Ted Kony is appreciated for his editorial assistance. The authors would like to thank anonymous reviewers for their constructive criticisms. Copyright 2011 by Mike Tian-Jian Jiang, Cheng-Wei Shih, Chan-Hung Kuo, Richard Tzong-Han Tsai, and Wen-Lian Hsu 25th Pacific Asia Conference on Language, Information and"
Y11-1011,I05-3001,0,0.0200073,"nces of accuracy-controlled WS systems in terms of TPR, TNR, PPV, and NPV. The MAP values of the search results retrieved by the original and segmented queries are illustrated in Figure 5. Finally, Table 4 compares correlation coefficients. Table 4: Correlation between search similarities and WS metrics TPR TNR PPV NPV 5 AS 0.742 0.836 0.788 0.800 CityU 0.916 0.944 0.931 0.940 MSR 0.933 0.649 0.901 0.819 PKU 0.615 0.870 0.634 0.692 Discussion Table 4 shows that TNR and NPV are more closely correlated than TPR and PPV, except in the case of MSR. Notably, since Corpus quality assurance process (Sun et al., 2005) and analysis for out-of-vocabulary issue (Li et al., 2005) of MSR use similar definitions of NS, they provide a good demonstration that considering both the PS and NS oriented metric can identify differences between WS systems trained using different standards of corpora. For example, a Sogou query “上海滩” (shang-hai-tan; The bund of Shanghai) were segmented into “上海滩,” “上 海 / 滩” (Shanghai / bund), or “上 / 海 / 滩” (up / sea / bund) using the accuracy-controlled system MSR, while the same query were segmented into “上海滩,” “上海 / 滩,” or “上 / 海滩” (go to / beach) using the accuracy-controlled system P"
Y11-1011,J00-3004,0,0.0558046,"eta][data]] / is / the / data / of / data” as standard in five boundaries, seven morphemes (notice the case of [[meta][data]]), six words, and five lexicon types, one possible segmentation “meta / data / is / the / data / of / data” results in one boundary error, zero morpheme error, two word errors, and one lexicon type error. Ando and Lee (2003) proposed a constituent-based metric called compatible bracket error, which counts reasonable combinations of morphemes, estimate “[meta][data]” and “[metadata]” as interchangeable. Previous studies also counted word error rates (Chiang et al., 1992; Teahan et al. 2000; Wong and Chan, 1996) and sentence accuracy (Chiang et al., 1992) as complementary metrics of word-based recall and precision. Several other constituent-based metrics exist, and are usually close related to IR. For example, Liu et al. (2008) proposed an evaluation measure “RankPrecision” based on Kendalltau distance, which compared the similarity between the predicted rankings of “Internal Association Strength (IAS)” and the ideally sorted rankings of IAS in descending order. Methodologies resemble IAS, which may be seen as constituent-based measurements, are “Phrase Inseparability” (Shi and"
Y11-1011,C96-1035,0,0.107234,"he / data / of / data” as standard in five boundaries, seven morphemes (notice the case of [[meta][data]]), six words, and five lexicon types, one possible segmentation “meta / data / is / the / data / of / data” results in one boundary error, zero morpheme error, two word errors, and one lexicon type error. Ando and Lee (2003) proposed a constituent-based metric called compatible bracket error, which counts reasonable combinations of morphemes, estimate “[meta][data]” and “[metadata]” as interchangeable. Previous studies also counted word error rates (Chiang et al., 1992; Teahan et al. 2000; Wong and Chan, 1996) and sentence accuracy (Chiang et al., 1992) as complementary metrics of word-based recall and precision. Several other constituent-based metrics exist, and are usually close related to IR. For example, Liu et al. (2008) proposed an evaluation measure “RankPrecision” based on Kendalltau distance, which compared the similarity between the predicted rankings of “Internal Association Strength (IAS)” and the ideally sorted rankings of IAS in descending order. Methodologies resemble IAS, which may be seen as constituent-based measurements, are “Phrase Inseparability” (Shi and Nie, 2009) and the “Ti"
Y11-1011,O03-4001,0,0.0441309,"Missing"
Y11-1011,W10-3708,0,0.0820369,"tion, while Section 5 discusses these same results. Finally, Section 6 presents conclusions, along with recommendations for future research. 2 2.1 Related Works Evaluation of Chinese Information Retrieval For various open evaluation tasks of Chinese IR, the test collections of TREC-5, TREC-6, and TREC-9 comprise 28, 26, and 25 queries in simplified Chinese, respectively, while NTCIR-2 comprises 50 queries in traditional Chinese. One problem is that the number of queries is small. Another problem with the TREC data is that the Chinese queries (topic titles) have too many keywords. According to Xu et al. (2010), the Chinese queries have an average length of 12.2 words; in contrast, the average length of English ad-hoc queries in TREC (English topics 251350) is 4.7 words. Even the length of Chinese queries is measured using English translations, the average length still exceeds 7 words. Long queries introduce complex effects whose interactions are difficult to understand. These problems are part of a more general issue of sample pooling bias (Webber and Park, 2009). Common metrics for evaluating IR effectiveness include precision of top-k retrieval results (P@k), mean reciprocal recall (MRR), mean av"
Y11-1011,zhao-etal-2010-large,0,0.0130046,"tional random fields with a 6-tag labeling scheme in bi-directional unigram, bi-gram and pair contexts (Zhao et al., 2006). Four gold standards involving Chinese WS corpus from SIGHAN 2005 WS bakeoffs, including Academia Sinica (AS), City University of Hong Kong (CityU), Microsoft Research (MSR), and Peking University (PKU), are adopted as training data (cf. footnote). By randomly dividing the training data into exponentially smaller parts ranging from 1/2 to 1/16384, WS systems trained using corresponding parts perform with linearly decreasing accuracy in TPR and PPV, just as demonstrated by Zhao et al. (2010). 4.3 Simulation Design For traditional Chinese, NTCIR queries are segmented by the accuracy-controlled WS systems AS and CityU. For simplified Chinese, Sogou queries are segmented by the accuracy-controlled WS systems MSR and PKU. The average segment numbers of segmented NTCIR and Sogou queries are 5.8 and 3.1, respectively. All the segmented tokens of a query are quoted, adhered by white space, and formed a segmented query. The original query and all the segmented queries from different WS systems are forwarded to Google to retrieve the top-100 search results. Search results of original quer"
Y11-1011,W06-0127,0,0.0157467,"contains multiple query strings in a single query, 105 representing academic samples of queries; meanwhile, query logs arranged by a commercial search engine company “Sogou” (Sogou query as in short, hereafter), written in simplified Chinese, comprising 432 consecutive query strings with an average length of 4.36 characters, provide a practical view of end users. 4.2 Accuracy-controlled WS Systems This study implements several WS systems based on the-state-of-the-art approach that uses conditional random fields with a 6-tag labeling scheme in bi-directional unigram, bi-gram and pair contexts (Zhao et al., 2006). Four gold standards involving Chinese WS corpus from SIGHAN 2005 WS bakeoffs, including Academia Sinica (AS), City University of Hong Kong (CityU), Microsoft Research (MSR), and Peking University (PKU), are adopted as training data (cf. footnote). By randomly dividing the training data into exponentially smaller parts ranging from 1/2 to 1/16384, WS systems trained using corresponding parts perform with linearly decreasing accuracy in TPR and PPV, just as demonstrated by Zhao et al. (2010). 4.3 Simulation Design For traditional Chinese, NTCIR queries are segmented by the accuracy-controlled"
Y11-1011,W06-0115,0,\N,Missing
Y11-1011,I08-4010,0,\N,Missing
Y11-1011,W03-1726,0,\N,Missing
Y11-1040,P06-2002,0,0.0160376,"ns, which are syntactic patterns that connect two entities in one relationship. Surface text patterns are widely used for information extraction. For example, &lt;Person&gt; was born in &lt;Year&gt; is an intuitive pattern for matching the birth year of someone. This pattern connect the person and the corresponding year as a semantic relation (birth year) and thus can be used to eﬀectively extract the information. For binary relation extraction, such as the above example of &lt;Person, Birth Year&gt;, the ﬁrst term is often called the hook term(e.g. Person), and the second one the target term(e.g. Birth Year) (Alfonseca et al., 2006; Mann and Yarowsky, 2005; Ravichandran and Hovy, 2002). Most pattern-based approaches for relation extraction are implemented as follows. First, a set of seed instances are prepared in the form of pairs of hook and target terms serving as examples of the intended relation type. For instance, &lt;Kobe Bryant, 1978&gt; could be one of the seed instances that fed into a relation extraction system for learning how to extract the birth year of someone. The seed instances are then used as queries for retrieving sentences containing both the hook and the target terms, most popularly from the Web. The retr"
Y11-1040,N10-1087,0,0.0265053,"rpus, the magnitude and noisy natural of the Web has prohibited analytical approaches to be eﬀective. Consequently, most of the systems that took this challenge proceed in a semi-supervised fashion with a human-provided starting point, such as a few instances of the desired extraction(Mann and Yarowsky, 2005; Muslea, 1999; Ravichandran and Hovy, 2002; Pantel and Pennacchiotti, 2006). In this paper, we focus on the extraction of relation instances. In this scenario, the system needs to be fed with prepared pairs, such as &lt;Barack Obama, Auguest 4th&gt;, or initial extraction patterns to bootstrap. Kozareva and Hovy (2010) mentioned that seed selection plays an important role in this kind of semi-supervised approaches. Therefore, how to select high quality seeds in the initial stage is a critical issue. Most researchers select seeds manually to avoid this problem, but the scalability of such manual selection is not promising. Then, these approaches utilize the given instances, called seeds, and generate extraction patterns that has the potential to locate more instances of the desired type in the text. For example, Ravichandran and Hovy (2002) use surface text patterns like &lt;Person&gt; was born on &lt;Date&gt; to answer"
Y11-1040,P05-1060,0,0.0970361,"tency estimation, relation extraction, semi-supervised approach, seed quality 1 Introduction The rapid growth of the World Wide Web has attracted a lot of research eﬀort on designing methods that automatically extract knowledge or useful information from large, unstructured text. Diﬀerent from the conventional corpus, the magnitude and noisy natural of the Web has prohibited analytical approaches to be eﬀective. Consequently, most of the systems that took this challenge proceed in a semi-supervised fashion with a human-provided starting point, such as a few instances of the desired extraction(Mann and Yarowsky, 2005; Muslea, 1999; Ravichandran and Hovy, 2002; Pantel and Pennacchiotti, 2006). In this paper, we focus on the extraction of relation instances. In this scenario, the system needs to be fed with prepared pairs, such as &lt;Barack Obama, Auguest 4th&gt;, or initial extraction patterns to bootstrap. Kozareva and Hovy (2010) mentioned that seed selection plays an important role in this kind of semi-supervised approaches. Therefore, how to select high quality seeds in the initial stage is a critical issue. Most researchers select seeds manually to avoid this problem, but the scalability of such manual sel"
Y11-1040,P06-1015,0,0.21093,"d quality 1 Introduction The rapid growth of the World Wide Web has attracted a lot of research eﬀort on designing methods that automatically extract knowledge or useful information from large, unstructured text. Diﬀerent from the conventional corpus, the magnitude and noisy natural of the Web has prohibited analytical approaches to be eﬀective. Consequently, most of the systems that took this challenge proceed in a semi-supervised fashion with a human-provided starting point, such as a few instances of the desired extraction(Mann and Yarowsky, 2005; Muslea, 1999; Ravichandran and Hovy, 2002; Pantel and Pennacchiotti, 2006). In this paper, we focus on the extraction of relation instances. In this scenario, the system needs to be fed with prepared pairs, such as &lt;Barack Obama, Auguest 4th&gt;, or initial extraction patterns to bootstrap. Kozareva and Hovy (2010) mentioned that seed selection plays an important role in this kind of semi-supervised approaches. Therefore, how to select high quality seeds in the initial stage is a critical issue. Most researchers select seeds manually to avoid this problem, but the scalability of such manual selection is not promising. Then, these approaches utilize the given instances,"
Y11-1040,P02-1006,0,0.396034,"semi-supervised approach, seed quality 1 Introduction The rapid growth of the World Wide Web has attracted a lot of research eﬀort on designing methods that automatically extract knowledge or useful information from large, unstructured text. Diﬀerent from the conventional corpus, the magnitude and noisy natural of the Web has prohibited analytical approaches to be eﬀective. Consequently, most of the systems that took this challenge proceed in a semi-supervised fashion with a human-provided starting point, such as a few instances of the desired extraction(Mann and Yarowsky, 2005; Muslea, 1999; Ravichandran and Hovy, 2002; Pantel and Pennacchiotti, 2006). In this paper, we focus on the extraction of relation instances. In this scenario, the system needs to be fed with prepared pairs, such as &lt;Barack Obama, Auguest 4th&gt;, or initial extraction patterns to bootstrap. Kozareva and Hovy (2010) mentioned that seed selection plays an important role in this kind of semi-supervised approaches. Therefore, how to select high quality seeds in the initial stage is a critical issue. Most researchers select seeds manually to avoid this problem, but the scalability of such manual selection is not promising. Then, these approa"
Y11-1040,P07-1074,0,0.154938,"es in the pair for forming the query. One factor behind such imperfection is that the open and voluntary nature of Wikipedia allows editors to ﬁll in information of diﬀerent speciﬁcity. For example, the birth place ﬁeld of some people contains only less detailed information such as the country instead of more speciﬁc description like county or city. Moreover, as can be seen in Table 1, the relevance ratio is not consistent among diﬀerent relation types and may be surprisingly low such as the type of death place. Such a situation will aﬀect the performance of semi-supervised approaches greatly(Xu et al., 2007). Fortunately, having abundant seed instances oﬀers us an opportunity to mitigate such a problem. In this paper, we propose a mechanism that iteratively assesses both the quality of seed instances and induced extraction patterns. Our strategy is to estimate the reliability of an extraction pattern by the consistency of its extractions, and alternately, reevaluate the usefulness of seed instances based on estimated pattern reliability. The resulting system works best when it is fed with a large number of seeds, so that the reliability of the induced pattern can be better estimated. In the next"
Y14-1011,I05-7001,0,0.01089,"page titled ““⇤⌫-y∆Ø(LeBron James)”, and within this page, there are a number of category tags such as “Å?∆±kä⇤·(Miami Heat players)” and “é↵C⇤K’·(American basketball players)”. For these two category tags, there are five and nine topic paths, respectively. Suppose “é↵C⇤K’·(American basketball players)” is the category with the most topic paths, our system will label ““⇤⌫-y∆Ø(LeBron James)” with the tag “[é↵C⇤K’·(American basketball players)]”. In this way, we can transform plain NEs to a more general class, and increase the coverage of each label. In addition, we further integrated E-HowNet (Chen et al., 2005) to capture even richer semantic context. It is an extension of the HowNet (Dong et al., 2010) with the purpose of creating a structured representation of knowledge and semantics. It connects approximately 90 thousand words of the CKIP Chinese Lexical Knowledge Base and HowNet, and included extra frequent words that are specific to Traditional Chinese. It also contains a different formulation of each word to betRecognizing named entities from text can facilitate document comprehension and improve the performance of identifying topics (Bashaddadh and Mohd, 2011). Therefore, we construct the Nam"
Y14-1011,C10-3014,0,0.0200541,"such as “Å?∆±kä⇤·(Miami Heat players)” and “é↵C⇤K’·(American basketball players)”. For these two category tags, there are five and nine topic paths, respectively. Suppose “é↵C⇤K’·(American basketball players)” is the category with the most topic paths, our system will label ““⇤⌫-y∆Ø(LeBron James)” with the tag “[é↵C⇤K’·(American basketball players)]”. In this way, we can transform plain NEs to a more general class, and increase the coverage of each label. In addition, we further integrated E-HowNet (Chen et al., 2005) to capture even richer semantic context. It is an extension of the HowNet (Dong et al., 2010) with the purpose of creating a structured representation of knowledge and semantics. It connects approximately 90 thousand words of the CKIP Chinese Lexical Knowledge Base and HowNet, and included extra frequent words that are specific to Traditional Chinese. It also contains a different formulation of each word to betRecognizing named entities from text can facilitate document comprehension and improve the performance of identifying topics (Bashaddadh and Mohd, 2011). Therefore, we construct the Named Entity Ontology semi-automatically by using Wikipedia for semantic class labeling. Wikipedi"
Y14-1011,N03-3001,0,0.0311307,"approach by reducing human effort through its highly automated pattern generation and summarization. Using Yahoo! Chinese news corpus containing about 140,000 news articles, we provide a comprehensive performance evaluation that demonstrates the effectiveness of FBA in detecting the topic of a document by exploiting the semantic association and the context within the text. Moreover, it outperforms common topic models like Na¨ıve Bayes, Vector Space Model, and LDA-SVM. 1 Linguistic information provides useful features to many natural language processing (NLP) tasks, including topic detection (Nallapati, 2003). Such information is usually represented as rules or templates. The main advantages of the rule-based approach are its high precision as well as the capability of knowledge accumulation. When confronting a new domain, they can be adapted by adding rules that exploit the missing knowledge. However, only a limited number of cases can be captured by a single rule, and increasing the number of rules could create undesired conflicts. Thus, the inflexibility of rulebased systems has put their competence for NLP tasks in doubt. On the other hand, there are several machine learning-based approaches."
Y14-1011,C10-1111,0,0.118659,"integrates similar knowledge and reduces the total number of patterns through pattern summarization. Furthermore, a matching mechanism allowing insertion, deletion, and substitution (IDS) of words and phrases is employed together with a statistical scoring mechanism. To create linguistic patterns with higher level of generality, we adopt the dominating set algorithm to reduce 350,000 patterns to a total of 500. Dominating set has been used extensively in network routing researches, e.g., Das and Bharghavan (1997), Du et al. (2013), and adopted in NLP related tasks such as text summarization (Shen and Li, 2010). In the training phase, we consider keywords, context, and semantic associations to automatically generate frames. Thus, the obtained frames can be acknowledged as the essential knowledge for each topic that is comprehensible for humans. Results demonstrated that our method is more effective than the following approaches: the word vector modelbased method (Li et al., 2010) and the latent Dirichlet allocation (LDA) method (Blei et al., 2003), a Bayesian networks-based topic model widely used to identify topics. The structure of this paper is as follows. We discuss some of the previous work tha"
