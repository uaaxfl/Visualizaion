2021.acl-long.164,{BERTAC}: Enhancing Transformer-based Language Models with Adversarially Pretrained Convolutional Neural Networks,2021,-1,-1,2,0,12929,jonghoon oh,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Transformer-based language models (TLMs), such as BERT, ALBERT and GPT-3, have shown strong performance in a wide range of NLP tasks and currently dominate the field of NLP. However, many researchers wonder whether these models can maintain their dominance forever. Of course, we do not have answers now, but, as an attempt to find better neural architectures and training schemes, we pretrain a simple CNN using a GAN-style learning scheme and Wikipedia data, and then integrate it with standard TLMs. We show that on the GLUE tasks, the combination of our pretrained CNN with ALBERT outperforms the original ALBERT and achieves a similar performance to that of SOTA. Furthermore, on open-domain QA (Quasar-T and SearchQA), the combination of the CNN with ALBERT or RoBERTa achieved stronger performance than SOTA and the original TLMs. We hope that this work provides a hint for developing a novel strong network architecture along with its training scheme. Our source code and models are available at https://github.com/nict-wisdom/bertac."
P19-1414,Open-Domain Why-Question Answering with Adversarial Learning to Encode Answer Texts,2019,0,0,4,0,12929,jonghoon oh,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"In this paper, we propose a method for why-question answering (why-QA) that uses an adversarial learning framework. Existing why-QA methods retrieve {``}answer passages{''} that usually consist of several sentences. These multi-sentence passages contain not only the reason sought by a why-question and its connection to the why-question, but also redundant and/or unrelated parts. We use our proposed {``}Adversarial networks for Generating compact-answer Representation{''} (AGR) to generate from a passage a vector representation of the non-redundant reason sought by a why-question and exploit the representation for judging whether the passage actually answers the why-question. Through a series of experiments using Japanese why-QA datasets, we show that these representations improve the performance of our why-QA neural model as well as that of a BERT-based why-QA model. We show that they also improve a state-of-the-art distantly supervised open-domain QA (DS-QA) method on publicly available English datasets, even though the target task is not a why-QA."
D19-1590,Event Causality Recognition Exploiting Multiple Annotators{'} Judgments and Background Knowledge,2019,0,0,2,0,16770,kazuma kadowaki,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"We propose new BERT-based methods for recognizing event causality such as {``}smoke cigarettes{''} {--}{\textgreater} {``}die of lung cancer{''} written in web texts. In our methods, we grasp each annotator{'}s policy by training multiple classifiers, each of which predicts the labels given by a single annotator, and combine the resulting classifiers{'} outputs to predict the final labels determined by majority vote. Furthermore, we investigate the effect of supplying background knowledge to our classifiers. Since BERT models are pre-trained with a large corpus, some sort of background knowledge for event causality may be learned during pre-training. Our experiments with a Japanese dataset suggest that this is actually the case: Performance improved when we pre-trained the BERT models with web texts containing a large number of event causalities instead of Wikipedia articles or randomly sampled web texts. However, this effect was limited. Therefore, we further improved performance by simply adding texts related to an input causality candidate as background knowledge to the input of the BERT models. We believe these findings indicate a promising future research direction."
L18-1556,Annotating Zero Anaphora for Question Answering,2018,0,0,2,0,16767,yoshihiko asao,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
D16-1132,Intra-Sentential Subject Zero Anaphora Resolution using Multi-Column Convolutional Neural Network,2016,26,13,1,1,12930,ryu iida,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
N15-1031,Incrementally Tracking Reference in Human/Human Dialogue Using Linguistic and Extra-Linguistic Information,2015,35,6,2,0,821,casey kennington,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"A large part of human communication involves referring to entities in the world and often these entities are objects that are visually present for the interlocutors. A system that aims to resolve such references needs to tackle a complex task: objects and their visual features need to be determined, the referring expressions must be recognised, and extra-linguistic information such as eye gaze or pointing gestures need to be incorporated. Systems that can make use of such information sources exist, but have so far only been tested under very constrained settings, such as WOz interactions. In this paper, we apply to a more complex domain a reference resolution model that works incrementally (i.e., word by word), grounds words with visually present properties of objects (such as shape and size), and can incorporate extra-linguistic information. We find that the model works well compared to previous work on the same data, despite using fewer features. We conclude that the model shows potential for use in a realtime interactive dialogue system."
D15-1260,Intra-sentential Zero Anaphora Resolution using Subject Sharing Recognition,2015,31,12,1,1,12930,ryu iida,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"In this work, we improve the performance of intra-sentential zero anaphora resolution in Japanese using a novel method of recognizing subject sharing relations. In Japanese, a large portion of intrasentential zero anaphora can be regarded as subject sharing relations between predicates, that is, the subject of some predicate is also the unrealized subject of other predicates. We develop an accurate recognizer of subject sharing relations for pairs of predicates in a single sentence, and then construct a subject shared predicate network, which is a set of predicates that are linked by the subject sharing relations recognized by our recognizer. We finally combine our zero anaphora resolution method exploiting the subject shared predicate network and a state-ofthe-art ILP-based zero anaphora resolution method. Our combined method achieved a significant improvement over the the ILPbased method alone on intra-sentential zero anaphora resolution in Japanese. To the best of our knowledge, this is the first work to explicitly use an independent subject sharing recognizer in zero anaphora resolution."
iida-tokunaga-2014-building,Building a Corpus of Manually Revised Texts from Discourse Perspective,2014,13,1,1,1,12930,ryu iida,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper presents building a corpus of manually revised texts which includes both before and after-revision information. In order to create such a corpus, we propose a procedure for revising a text from a discourse perspective, consisting of dividing a text to discourse units, organising and reordering groups of discourse units and finally modifying referring and connective expressions, each of which imposes limits on freedom of revision. Following the procedure, six revisers who have enough experience in either teaching Japanese or scoring Japanese essays revised 120 Japanese essays written by Japanese native speakers. Comparing the original and revised texts, we found some specific manual revisions frequently occurred between the original and revised texts, e.g. ÂthesisÂ statements were frequently placed at the beginning of a text. We also evaluate text coherence using the original and revised texts on the task of pairwise information ordering, identifying a more coherent text. The experimental results using two text coherence models demonstrated that the two models did not outperform the random baseline."
W13-4303,Detecting Missing Annotation Disagreement using Eye Gaze Information,2013,22,3,2,0,17976,koh mitsuda,Proceedings of the 11th Workshop on {A}sian Language Resources,0,"This paper discusses the detection of missing annotation disagreements (MADs), in which an annotator misses annotating an annotation instance while her counterpart correctly annotates it. We employ annotator eye gaze as a clue for detecting this type of disagreement together with linguistic information. More precisely, we extract highly frequent gaze patterns from the pre-extracted gaze sequences related to the annotation target, and then use the gaze patterns as features for detecting the MADs. Through the empirical evaluation using the data set collected in our previous study, we investigated the effectiveness of each type of information. The results showed that both eye gaze and linguistic information contributed to improving performance of our MAD detection model compared with the baseline model. Furthermore, our additional investigation revealed that some specific gaze patterns could be a good indicator for detecting the MADs."
W13-2326,Investigation of annotator{'}s behaviour using eye-tracking data,2013,19,1,1,1,12930,ryu iida,Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,0,"This paper presents an analysis of an annotatorxe2x80x99s behaviour during her/his annotation process for eliciting useful information for natural language processing (NLP) tasks. Text annotation is essential for machine learning-based NLP where annotated texts are used for both training and evaluating supervised systems. Since an annotatorxe2x80x99s behaviour during annotation can be seen as reflecting her/his cognitive process during her/his attempt to understand the text for annotation, analysing the process of text annotation has potential to reveal useful information for NLP tasks, in particular semantic and discourse processing that require deeper language understanding. We conducted an experiment for collecting annotator actions and eye gaze during the annotation of predicate-argument relations in Japanese texts. Our analysis of the collected data suggests that obtained insight into human annotation behaviour is useful for exploring effective linguistic features in machine learning-based approaches."
W13-2118,Automatic Voice Selection in {J}apanese based on Various Linguistic Information,2013,13,0,1,1,12930,ryu iida,Proceedings of the 14th {E}uropean Workshop on Natural Language Generation,0,"This paper focuses on a subtask of natural language generation (NLG), voice selection, which decides whether a clause is realised in the active or passive voice according to its contextual information. Automatic voice selection is essential for realising more sophisticated MT and summarisation systems, because it impacts the readability of generated texts. However, to the best of our knowledge, the NLG community has been less concerned with explicit voice selection. In this paper, we propose an automatic voice selection model based on various linguistic information, ranging from lexical to discourse information. Our empirical evaluation using a manually annotated corpus in Japanese demonstrates that the proposed model achieved 0.758 in F-score, outperforming the two baseline models."
W13-0508,Annotation for annotation - Toward eliciting implicit linguistic knowledge through annotation - (Project Note),2013,17,0,2,0,301,takenobu tokunaga,Proceedings of the 9th Joint {ISO} - {ACL} {SIGSEM} Workshop on Interoperable Semantic Annotation,0,"The last two decades witnessed a great success of revived empiricism in NLP research. However, there are still several NLP tasks that are not successful enough. As one of many directions for going beyond the revived empiricism, this paper introduces a project for annotating annotations with annotatorsxe2x80x99 rationales behind them. As a first step of this enterprise, the paper particularly focuses on data collection during the annotation and discusses their potential uses. Finally a preliminary experiment for data collection is described with the data analysis."
W12-1633,A Unified Probabilistic Approach to Referring Expressions,2012,29,12,4,0,10700,kotaro funakoshi,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This paper proposes a probabilistic approach to the resolution of referring expressions for task-oriented dialogue systems. The approach resolves descriptions, anaphora, and deixis in a unified manner. In this approach, the notion of reference domains serves an important role to handle context-dependent attributes of entities and references to sets. The evaluation with the REX-J corpus shows promising results."
P12-2068,Sentence Compression with Semantic Role Constraints,2012,12,17,2,0,32762,katsumasa yoshikawa,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"For sentence compression, we propose new semantic constraints to directly capture the relations between a predicate and its arguments, whereas the existing approaches have focused on relatively shallow linguistic properties, such as lexical and syntactic information. These constraints are based on semantic roles and superior to the constraints of syntactic dependencies. Our empirical evaluation on the Written News Compression Corpus (Clarke and Lapata, 2008) demonstrates that our system achieves results comparable to other state-of-the-art techniques."
tokunaga-etal-2012-rex,The {REX} corpora: A collection of multimodal corpora of referring expressions in collaborative problem solving dialogues,2012,19,12,2,0,301,takenobu tokunaga,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper describes a collection of multimodal corpora of referring expressions, the REX corpora. The corpora have two notable features, namely (1) they include time-aligned extra-linguistic information such as participant actions and eye-gaze on top of linguistic information, (2) dialogues were collected with various configurations in terms of the puzzle type, hinting and language. After describing how the corpora were constructed and sketching out each, we present an analysis of various statistics for the corpora with respect to the various configurations mentioned above. The analysis showed that the corpora have different characteristics in the number of utterances and referring expressions in a dialogue, the task completion time and the attributes used in the referring expressions. In this respect, we succeeded in constructing a collection of corpora that included a variety of characteristics by changing the configurations for each set of dialogues, as originally planned. The corpora are now under preparation for publication, to be used for research on human reference behaviour."
C12-2048,A Metric for Evaluating Discourse Coherence based on Coreference Resolution,2012,25,5,1,1,12930,ryu iida,Proceedings of {COLING} 2012: Posters,0,"We propose a simple and effective metric for automatically evaluating discourse coherence of a text using the outputs of a coreference resolution model. According to the idea that a writer tends to appropriately utilise coreference relations when writing a coherent text, we introduce a metric of discourse coherence based on automatically identified coreference relations. We empirically evaluated our metric by comparing it to the entity grid modelling by Barzilay and Lapata (2008) using Japanese newspaper articles as a target data set. The results indicate that our metric better reflects discourse coherence of texts than the existing model."
C12-2134,Identifying Temporal Relations by Sentence and Document Optimizations,2012,17,0,3,0,32762,katsumasa yoshikawa,Proceedings of {COLING} 2012: Posters,0,"This paper presents a temporal relation identification method optimizing relations at sentence and document levels. Temporal relation identification is to identify temporal orders between events and time expressions. Various approaches of this task have been studied through the shared tasks TempEval (Verhagen et al., 2007, 2010). Not only identifying each temporal relation independently, some works also try to find multiple temporal relations jointly by logical constraints in Integer Linear Programming (Chambers and Jurafsky, 2008; Do et al., 2012) or Markov Logic Networks (Yoshikawa et al., 2009; Ling and Weld, 2010; Ha et al., 2010). Though previous joint approaches optimize temporal relations in an entire document, we first optimize our model at sentence level and then extend it to document level. We consider that different types of temporal relations require different types of optimizations. By evaluating our sentence and document optimized model on the TempEval-2 data, we show that our approaches can achieve competitive performance in comparison to other state-of-the-art systems. We find that the sentence and document optimized model has strong tasks in TempEval-2, respectively."
P11-1081,A Cross-Lingual {ILP} Solution to Zero Anaphora Resolution,2011,25,45,1,1,12930,ryu iida,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We present an ILP-based model of zero anaphora detection and resolution that builds on the joint determination of anaphoricity and coreference model proposed by Denis and Baldridge (2007), but revises it and extends it into a three-way ILP problem also incorporating subject detection. We show that this new model outperforms several baselines and competing models, as well as a direct translation of the Denis/Baldridge model, for both Italian and Japanese zero anaphora. We incorporate our model in complete anaphoric resolvers for both Italian and Japanese, showing that our approach leads to improved performance also when not used in isolation, provided that separate classifiers are used for zeros and for explicitly realized anaphors."
I11-1010,Multi-modal Reference Resolution in Situated Dialogue by Integrating Linguistic and Extra-Linguistic Clues,2011,37,14,1,1,12930,ryu iida,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"This paper focuses on examining the effect of extra-linguistic information, such as eye gaze, integrated with linguistic information on multi-modal reference resolution. In our evaluation, we employ eye gaze information together with other linguistic factors in machine learning, while in prior work such as Kelleher (2006) and Prasov and Chai (2008) the incorporation of eye gaze and linguistic clues was heuristically realised. Conducting our empirical evaluation using a data set extended the REX-J corpus (Spanger et al., 2010) including eye gaze information, we examine which types of clues are useful on these three data sets, which consist largely of pronouns, nonpronouns and both respectively. Our results demonstrate that a dynamically moving visible indicator within the computer display (e.g. a mouse cursor) contributes to reference resolution for pronouns, while eye gaze information is more useful for the resolution of non-pronouns."
W10-4214,Towards an Extrinsic Evaluation of Referring Expressions in Situated Dialogs,2010,25,3,2,1,45121,philipp spanger,Proceedings of the 6th International Natural Language Generation Conference,0,"In the field of referring expression generation, while in the static domain both intrinsic and extrinsic evaluations have been considered, extrinsic evaluation in the dynamic domain, such as in a situated collaborative dialog, has not been discussed in depth. In a dynamic domain, a crucial problem is that referring expressions do not make sense without an appropriate preceding dialog context. It is unrealistic for an evaluation to simply show a human evaluator the whole period from the beginning of a dialog up to the time point at which a referring expression is used. Hence, to make evaluation feasible it is indispensable to determine an appropriate shorter context. In order to investigate the context necessary to understand a referring expression in a situated collaborative dialog, we carried out an experiment with 33 evaluators and a Japanese referring expression corpus. The results contribute to finding the proper contexts for extrinsic evalution in dynamic domains."
W10-3206,Construction of bilingual multimodal corpora of referring expressions in collaborative problem solving,2010,20,2,2,0,301,takenobu tokunaga,Proceedings of the Eighth Workshop on {A}sian Language Resouces,0,"This paper presents on-going work on constructing bilingual multimodal corpora of referring expressions in collaborative problem solving for English and Japanese. The corpora were collected from dialogues in which two participants collaboratively solved Tangram puzzles with a puzzle simulator. Extra-linguistic information such as operations on puzzle pieces, mouse cursor position and piece positions were recorded in synchronisation with utterances. The speech data was transcribed and time-aligned with the extra-linguistic information. Referring expressions in utterances that refer to puzzle pieces were annotated in terms of their spans, their referents and their other attributes. The Japanese corpus has already been completed, but the English counterpart is still undergoing annotation. We have conducted a preliminary comparative analysis of both corpora, mainly with respect to task completion time, task success rates and attributes of referring expressions. These corpora showed significant differences in task completion time and success rate."
P10-1128,Incorporating Extra-Linguistic Information into Reference Resolution in Collaborative Task Dialogue,2010,25,11,1,1,12930,ryu iida,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"This paper proposes an approach to reference resolution in situated dialogues by exploiting extra-linguistic information. Recently, investigations of referential behaviours involved in situations in the real world have received increasing attention by researchers (Di Eugenio et al., 2000; Byron, 2005; van Deemter, 2007; Spanger et al., 2009). In order to create an accurate reference resolution model, we need to handle extra-linguistic information as well as textual information examined by existing approaches (Soon et al., 2001; Ng and Cardie, 2002, etc.). In this paper, we incorporate extra-linguistic information into an existing corpus-based reference resolution model, and investigate its effects on reference resolution problems within a corpus of Japanese dialogues. The results demonstrate that our proposed model achieves an accuracy of 79.0% for this task."
kaplan-etal-2010-annotation,Annotation Process Management Revisited,2010,14,7,2,1,20637,dain kaplan,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Proper annotation process management is crucial to the construction of corpora, which are in turn indispensable to the data-driven techniques that have come to the forefront in NLP during the last two decades. It is still common to see ad-hoc tools created for a specific annotation project, but it is time this changed; creation of such tools is labor and time expensive, and is secondary to corpus creation. In addition, such tools likely lack proper annotation process management, increasingly more important as corpora sizes grow in size and complexity. This paper first raises a list of ten needs that any general purpose annotation system should address moving forward, such as user {\&} role management, delegation {\&} monitoring of work, diffing {\&} merging annotatorsÂ work, versioning of corpora, multilingual support, import/export format flexibility, and so on. A framework to address these needs is then proposed, and how having proper annotation process management can be beneficial to the creation and maintenance of corpora explained. The paper then introduces SLATE (Segment and Link-based Annotation Tool Enhanced), the second iteration of a web-based annotation tool, which is being rewritten to implement the proposed framework."
W09-3611,Automatic Extraction of Citation Contexts for Research Paper Summarization: A Coreference-chain based Approach,2009,21,38,2,1,20637,dain kaplan,Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries ({NLPIR}4{DL}),0,"This paper proposes a new method based on coreference-chains for extracting citations from research papers. To evaluate our method we created a corpus of citations comprised of citing papers for 4 cited papers. We analyze some phenomena of citations that are present in our corpus, and then evaluate our method against a cue-phrase-based technique. Our method demonstrates higher precision by 7--10%."
W09-0618,A {J}apanese Corpus of Referring Expressions Used in a Situated Collaboration Task,2009,8,6,3,1,45121,philipp spanger,Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009),0,"In order to pursue research on generating referring expressions in a situated collaboration task, we set up a data-collection experiment based on the Tangram puzzle. For a pair of participants we recorded every utterance in synchronisation with the current state of the puzzle as well as all operations by the participants. Referring expressions were annotated with their referents in order to build a referring expression corpus in Japanese. We provide preliminary results on the analysis of the corpus from various standpoints, focussing on action-mentioning expressions."
P09-1073,Capturing Salience with a Trainable Cache Model for Zero-anaphora Resolution,2009,28,11,1,1,12930,ryu iida,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,This paper explores how to apply the notion of caching introduced by Walker (1996) to the task of zero-anaphora resolution. We propose a machine learning-based implementation of a cache model to reduce the computational cost of identifying an antecedent. Our empirical evaluation with Japanese newspaper articles shows that the number of candidate antecedents for each zero-pronoun can be dramatically reduced while preserving the accuracy of resolving it.
I08-1073,Gloss-Based Semantic Similarity Metrics for Predominant Sense Acquisition,2008,20,9,1,1,12930,ryu iida,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,None
W07-1522,Annotating a {J}apanese Text Corpus with Predicate-Argument and Coreference Relations,2007,13,66,1,1,12930,ryu iida,Proceedings of the Linguistic Annotation Workshop,0,"In this paper, we discuss how to annotate coreference and predicate-argument relations in Japanese written text. There have been research activities for building Japanese text corpora annotated with coreference and predicate-argument relations as are done in the Kyoto Text Corpus version 4.0 (Kawahara et al., 2002) and the GDA-Tagged Corpus (Hasida, 2005). However, there is still much room for refining their specifications. For this reason, we discuss issues in annotating these two types of relations, and propose a new specification for each. In accordance with the specification, we built a large-scaled annotated corpus, and examined its reliability. As a result of our current work, we have released an annotated corpus named the NAIST Text Corpus1, which is used as the evaluation data set in the coreference and zero-anaphora resolution tasks in Iida et al. (2005) and Iida et al. (2006)."
P06-1079,Exploiting Syntactic Patterns as Clues in Zero-Anaphora Resolution,2006,26,40,1,1,12930,ryu iida,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We approach the zero-anaphora resolution problem by decomposing it into intra-sentential and inter-sentential zero-anaphora resolution. For the former problem, syntactic patterns of the appearance of zero-pronouns and their antecedents are useful clues. Taking Japanese as a target language, we empirically demonstrate that incorporating rich syntactic pattern features in a state-of-the-art learning-based anaphora resolution model dramatically improves the accuracy of intra-sentential zero-anaphora, which consequently improves the overall performance of zero-anaphora resolution."
inui-etal-2006-augmenting,Augmenting a Semantic Verb Lexicon with a Large Scale Collection of Example Sentences,2006,0,0,3,0.582129,4154,kentaro inui,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"One of the crucial issues in semantic parsing is how to reduce costs of collecting a sufficiently large amount of labeled data. This paper presents a new approach to cost-saving annotation of example sentences with predicate-argument structure information, taking Japanese as a target language. In this scheme, a large collection of unlabeled examples are first clustered and selectively sampled, and for each sampled cluster, only one representative example is given a label by a human annotator. The advantages of this approach are empirically supported by the results of our preliminary experiments, where we use an existing similarity function and naive sampling strategy."
I05-2030,Opinion Extraction Using a Learning-Based Anaphora Resolution Technique,2005,9,35,2,0,40256,nozomi kobayashi,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"This paper addresses the task of extracting opinions from a given document collection. Assuming that an opinion can be represented as a tuple xe3x80x88Subject, Attribute, Valuexe3x80x89, we propose a computational method to extract such tuples from texts. In this method, the main task is decomposed into (a) the process of extracting Attribute-Value pairs from a given text and (b) the process of judging whether an extracted pair expresses an opinion of the author. We apply machine-learning techniques to both subtasks. We also report on the results of our experiments and discuss future directions."
W03-2604,Incorporating Contextual Cues in Trainable Models for Coreference Resolution,2003,-1,-1,1,1,12930,ryu iida,Proceedings of the 2003 {EACL} Workshop on The Computational Treatment of Anaphora,0,None
W03-1602,Text Simplification for Reading Assistance: A Project Note,2003,19,79,4,0,4154,kentaro inui,Proceedings of the Second International Workshop on Paraphrasing,0,"This paper describes our ongoing research project on text simplification for congenitally deaf people. Text simplification we are aiming at is the task of offering a deaf reader a syntactic and lexical paraphrase of a given text for assisting her/him to understand what it means. In this paper, we discuss the issues we should address to realize text simplification and report on the present results in three different aspects of this task: readability assessment, paraphrase representation and post-transfer error detection."
