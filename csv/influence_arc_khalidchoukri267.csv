2005.mtsummit-papers.16,babych-etal-2004-calibrating,0,0.0278993,"Missing"
2005.mtsummit-papers.16,babych-hartley-2004-modelling,0,0.0609235,"th a positive weighting, NIST computes the arithmetic mean of n-grams precision taking into account a comparison of the length of segments. BLEU/NIST is in the most widespread use nowadays in the MT community. BLEU scores 3 4 Part of the MLCC corpus, available at ELDA. “Arabic Data Set” corpus, available at ELDA. 119 proved to correlate with human judgements about the fluency (Thompson and Brew, 1994) of the evaluated translation (Zhang et al., 2004). 2.5.2 WNM The Weighted N-gram Model, or WNM (Babych, 2004), is a combination of BLEU and the Legitimate Translation Variation, or LTV, metrics (Babych and Hartley, 2004a, 2004b). For a given source text, more than one correct translation is possible. BLEU tries to cope with this by multiplying the number of reference translations to be compared to the evaluated one. But still, the fact that some n-gram does not occur in any reference does not mean that it is an erroneous translation, providing the meaning is the same. Babych and Hartley’s proposal is to extend BLEU and the computation of proximity scores (i.e. the distance measure between the evaluated translation and the references) by introducing weights coming from the statistical relevance of the words i"
2005.mtsummit-papers.16,P04-1079,0,0.532761,"th a positive weighting, NIST computes the arithmetic mean of n-grams precision taking into account a comparison of the length of segments. BLEU/NIST is in the most widespread use nowadays in the MT community. BLEU scores 3 4 Part of the MLCC corpus, available at ELDA. “Arabic Data Set” corpus, available at ELDA. 119 proved to correlate with human judgements about the fluency (Thompson and Brew, 1994) of the evaluated translation (Zhang et al., 2004). 2.5.2 WNM The Weighted N-gram Model, or WNM (Babych, 2004), is a combination of BLEU and the Legitimate Translation Variation, or LTV, metrics (Babych and Hartley, 2004a, 2004b). For a given source text, more than one correct translation is possible. BLEU tries to cope with this by multiplying the number of reference translations to be compared to the evaluated one. But still, the fact that some n-gram does not occur in any reference does not mean that it is an erroneous translation, providing the meaning is the same. Babych and Hartley’s proposal is to extend BLEU and the computation of proximity scores (i.e. the distance measure between the evaluated translation and the references) by introducing weights coming from the statistical relevance of the words i"
2005.mtsummit-papers.16,2001.mtsummit-eval.4,1,0.835476,"Missing"
2005.mtsummit-papers.16,dabbadie-etal-2002-terminological,1,0.893742,"Missing"
2005.mtsummit-papers.16,P02-1040,0,0.0734272,"Missing"
2005.mtsummit-papers.16,2001.mtsummit-eval.6,1,0.926205,"sually used in Information Retrieval, plus a normalisation according to the words’ relative frequency (Babych et al., 2003). Typically, words such as names, events, terminological lexemes, are statistically more salient. They can be translated in a unique way only, whereas function words or expressions can have several possible correct translations. A preliminary experiment (Babych et al., 2004) proved that WNM results for recall were well correlated (even better than BLEU) to human judgements about adequacy. This was confirmed by (Babych and Hartley, 2004b). 2.5.3 X-Score The X-Score metric (Rajman and Hartley, 2001) is based on the distribution of elementary linguistic information within a text, such as morphosyntactic categories, or syntactic relationships. The authors’ hypothesis is that this distribution of linguistic information is similar from one text to another within a given language. Depending on the nature of the linguistic information selected to work with, the metric’s precision will vary. For instance, working with syntactic dependencies will be much more precise that working with morphosyntactic categories only. Whichever type of information is selected, the XScore measures the grammaticali"
2005.mtsummit-papers.16,zhang-etal-2004-interpreting,0,0.0536417,"ntly from that of the reference translations. The NIST metric is an alternative to BLEU. Whereas BLEU computes the geometric mean of n-grams precision (1  n  N) with a positive weighting, NIST computes the arithmetic mean of n-grams precision taking into account a comparison of the length of segments. BLEU/NIST is in the most widespread use nowadays in the MT community. BLEU scores 3 4 Part of the MLCC corpus, available at ELDA. “Arabic Data Set” corpus, available at ELDA. 119 proved to correlate with human judgements about the fluency (Thompson and Brew, 1994) of the evaluated translation (Zhang et al., 2004). 2.5.2 WNM The Weighted N-gram Model, or WNM (Babych, 2004), is a combination of BLEU and the Legitimate Translation Variation, or LTV, metrics (Babych and Hartley, 2004a, 2004b). For a given source text, more than one correct translation is possible. BLEU tries to cope with this by multiplying the number of reference translations to be compared to the evaluated one. But still, the fact that some n-gram does not occur in any reference does not mean that it is an erroneous translation, providing the meaning is the same. Babych and Hartley’s proposal is to extend BLEU and the computation of pro"
2007.mtsummit-papers.30,banchs-etal-2006-acceptance,0,0.0827667,"but no modifications on the different outputs are made and so the system can be considered as fully automatic. Protocol We try in this experiment to have a different approach regarding the already reported works. In (Somers and Sugita, 2003), judges were asked to paraphrase what they had understood or heard and were informed that the audio was synthesized. The answers were judged on a sevenpoint scale. This evaluation was applied to SLT and TTS outputs, while a morpheme error rate (MER) was applied to the ASR output. The seven-point scale evaluation was taken over within the LC-STAR project (Banchs et al., 2006) for an utterance-based evaluation. In both cases, judges produced and evaluated audio outputs, taking into account that no judge evaluated the output produced by him/herself. Our approach here is slightly different. In machine translation, the two basic concepts for human evaluation are usually adequacy and fluency based on a five-point scale. Rather than checking these criteria with expert translators, we decided to use adequacy and fluency questionnaires, filled in by human judges who are not particularly familiar with the speech-to-speech domain and who are not bilingual. Since the target"
2007.mtsummit-papers.30,mostefa-etal-2006-evaluation,1,0.662531,"Missing"
2007.mtsummit-papers.30,niessen-etal-2000-evaluation,0,0.0465817,"matic Speech Recognizer (ASR) chained to a Spoken Language Translation (SLT) module and to a Text-To-Speech (TTS) component in order to produce the speech in the target language. Evaluations of individual components (ASR, SLT and TTS) have been done many times in the past and are also evaluated in TC-STAR. Methods, protocols and metrics for the evaluation of independent ASR, SLT and TTS modules have already been established. Performance of speech recognition systems is typically described in terms of word error rate (WER). For SLT automatic metrics such as BLEU (Papineni et al. 2001) or mWER (Nießen et al., 2000) are used. Performance of SLT systems can also be measured by human judges who can usually measure fluency, adequacy, etc. of the translations. A numerical indication of the perceived quality of TTS synthesized audio data is provided by Mean Opinion Scores (ITU-T, 1993). The MOS is generated by averaging the results of a set of standard subjective tests. To evaluate the performance of a complete speech-tospeech translation system, we need to compare the source speech used as input to the translated output speech in the target language. The proposed methodology enables to measure the fluency an"
2007.mtsummit-papers.30,2001.mtsummit-papers.68,0,0.104637,"Missing"
2007.mtsummit-papers.30,2003.mtsummit-papers.49,0,0.0453577,"ora built from the EPPS recordings. For each audio sample in English an ASR output is produced, then the ASR output is automatically translated into Spanish and finally, the SLT output is synthesized in Spanish by the TTS module using the alignment between SLT and ASR to get the prosodic features from the source language. The transit from one component to another is done manually but no modifications on the different outputs are made and so the system can be considered as fully automatic. Protocol We try in this experiment to have a different approach regarding the already reported works. In (Somers and Sugita, 2003), judges were asked to paraphrase what they had understood or heard and were informed that the audio was synthesized. The answers were judged on a sevenpoint scale. This evaluation was applied to SLT and TTS outputs, while a morpheme error rate (MER) was applied to the ASR output. The seven-point scale evaluation was taken over within the LC-STAR project (Banchs et al., 2006) for an utterance-based evaluation. In both cases, judges produced and evaluated audio outputs, taking into account that no judge evaluated the output produced by him/herself. Our approach here is slightly different. In ma"
2007.mtsummit-papers.30,1994.amta-1.25,0,0.24022,"Missing"
2007.mtsummit-papers.31,2005.mtsummit-posters.13,1,0.855467,"Missing"
2007.mtsummit-papers.31,C04-1016,1,0.902404,"Missing"
2007.mtsummit-papers.31,P04-1079,0,0.030327,"Missing"
2007.mtsummit-papers.31,hamon-etal-2006-cesta,0,0.0721614,"Missing"
2007.mtsummit-papers.31,hamon-rajman-2006-x,0,0.0228193,"Missing"
2007.mtsummit-papers.31,2001.mtsummit-papers.68,0,0.074963,"Missing"
2007.mtsummit-papers.31,2005.mtsummit-papers.16,1,0.863637,"Missing"
2007.mtsummit-papers.31,2001.mtsummit-eval.10,0,0.108512,"Missing"
2007.mtsummit-papers.31,1994.amta-1.25,0,0.240679,"Missing"
2007.mtsummit-papers.31,zhang-etal-2004-interpreting,0,0.0229871,"Missing"
2007.mtsummit-papers.31,P02-1040,0,\N,Missing
2020.eamt-1.57,N19-1423,0,0.00800429,"of the project, a connection to eTranslation,8 an online machine translation service provided by the European Commission, will be established to foster the provision of multilingual datasets by public administrations that may in turn improve the coverage and quality of machine translation systems. 2 Approach At its core, the MAPA anonymisation toolkit will rely on Named Entity Recognition and Classification (NERC) techniques using neural networks and deep learning techniques. The latest deep learning architectures and the availability of pre-trained multilingual language models, such as BERT (Devlin et al., 2019) have pushed the state of the art in NERC to new levels of performance. In addition, thanks to the transfer learning capabilities shown by this type of deep learning models, new systems can be trained using smaller datasets of manually labelled data, and the knowledge acquired for a given domain or language can be reused in a cross-domain or cross-language setting (Garc´ıa-Pablos et al., 2020). MAPA will leverage the most innovative technology to provide robust models for the 24 official European languages, trained to detect named entities that involve sensitive information, depending on the a"
2020.eamt-1.57,2020.lrec-1.552,1,0.874506,"Missing"
2020.iwltp-1.6,W16-3412,1,0.809538,"The contents of the input files in different formats are first extracted, followed by automated language identification which allows the different text files to be grouped by language.14 Within each file, the text is then split into separate sentences, to allow further processes to apply. Each sentence is then pre-processed, which mainly includes tokenisation and truecasing; these operations are performed with scripts that are part of the Moses toolkit15 (Koehn et al., 2007). All document pairs with content in different languages are then automatically aligned with the DOCAL document aligner (Etchegoyhen and Azpeitia, 2016). For all document pairs whose alignment score indicates that the documents are a translation of each other, sentence alignment is then performed on the content, retrieving translations at the sentence level.16 From the aligned sentences a translation memory in TMX format 1.4b is then gener• NationalOrganisations: This group includes all registered users of the NRS from a specific country and resources shared with this group are accessible to all registered users of the NRS based in that Member State. • NationalOrganisations+EuropeanCommission: This group includes all registered users of the N"
2020.iwltp-1.6,P07-2045,0,0.00526572,"le documents containing translations in two or more languages. This is the most complex scenario and its main steps are summarised below.13 The contents of the input files in different formats are first extracted, followed by automated language identification which allows the different text files to be grouped by language.14 Within each file, the text is then split into separate sentences, to allow further processes to apply. Each sentence is then pre-processed, which mainly includes tokenisation and truecasing; these operations are performed with scripts that are part of the Moses toolkit15 (Koehn et al., 2007). All document pairs with content in different languages are then automatically aligned with the DOCAL document aligner (Etchegoyhen and Azpeitia, 2016). For all document pairs whose alignment score indicates that the documents are a translation of each other, sentence alignment is then performed on the content, retrieving translations at the sentence level.16 From the aligned sentences a translation memory in TMX format 1.4b is then gener• NationalOrganisations: This group includes all registered users of the NRS from a specific country and resources shared with this group are accessible to a"
2020.iwltp-1.6,L18-1213,1,0.837898,"Missing"
2020.lrec-1.407,gavrilidou-etal-2012-meta,1,0.919419,"Missing"
2020.lrec-1.407,2020.lrec-1.420,1,0.860379,"Missing"
2020.lrec-1.407,L18-1213,1,0.894888,"Missing"
2020.lrec-1.407,piperidis-etal-2014-meta,1,0.824391,"ween 2010 and 2017, supported through the EU projects T4ME, CESAR, METANET4U, META-NORD and CRACKER. One of its main goals is technology support for all European languages as well as fostering innovative research by providing strategic recommendations with regard to key research topics (Rehm and Uszkoreit, 2013). META-SHARE3 is an infrastructure that brings together providers and consumers of language data, tools and services. It is a network of repositories that store resources, documented with high-quality metadata aggregated in central inventories (Piperidis, 2012; Gavrilidou et al., 2012; Piperidis et al., 2014). CLARIN ERIC The CLARIN European Research Infrastructure for Language Resources and Technology is a legal entity set up in 2012, with 20 member countries at present.4 CLARIN makes language resources available to scholars, researchers, and students from all disciplines with a focus on the humanities and social sciences. CLARIN offers solutions and services for deploying, connecting, analyzing and sustaining digital language data and tools. Call ICT-17-2014 – “Cracking the Language Barrier” The EU call ICT-17-2014, which was informed by key META-NET results (Rehm and Uszkoreit, 2012), funded a"
2020.lrec-1.407,piperidis-2012-meta,1,0.92358,"n 34 European countries. META-NET was, between 2010 and 2017, supported through the EU projects T4ME, CESAR, METANET4U, META-NORD and CRACKER. One of its main goals is technology support for all European languages as well as fostering innovative research by providing strategic recommendations with regard to key research topics (Rehm and Uszkoreit, 2013). META-SHARE3 is an infrastructure that brings together providers and consumers of language data, tools and services. It is a network of repositories that store resources, documented with high-quality metadata aggregated in central inventories (Piperidis, 2012; Gavrilidou et al., 2012; Piperidis et al., 2014). CLARIN ERIC The CLARIN European Research Infrastructure for Language Resources and Technology is a legal entity set up in 2012, with 20 member countries at present.4 CLARIN makes language resources available to scholars, researchers, and students from all disciplines with a focus on the humanities and social sciences. CLARIN offers solutions and services for deploying, connecting, analyzing and sustaining digital language data and tools. Call ICT-17-2014 – “Cracking the Language Barrier” The EU call ICT-17-2014, which was informed by key META"
2020.lrec-1.407,L16-1251,1,0.865781,"Missing"
2020.lrec-1.407,2020.lrec-1.413,1,0.785764,"Missing"
2020.lrec-1.413,cassidy-etal-2014-alveo,0,0.0760054,"Missing"
2020.lrec-1.413,W03-0810,0,0.137563,"Missing"
2020.lrec-1.413,gavrilidou-etal-2012-meta,1,0.915791,"Missing"
2020.lrec-1.413,hinrichs-krauwer-2014-clarin,0,0.182909,"Missing"
2020.lrec-1.413,P10-4005,0,0.0528445,"Missing"
2020.lrec-1.413,2020.lrec-1.420,1,0.821941,"Missing"
2020.lrec-1.413,L18-1213,1,0.812955,"0b) and plan to integrate experimental workflow functionality into ELG. SHARE metadata schemas and a set of resources has already been ingested from each of them into ELG (Table 3). ELRA ELRC-SHARE META-SHARE Corpora Lexicons Models 20 180 52 2 7 12 – – 7 3.5. Data Sets and Language Resources The ELG consortium has defined an LR identification and sharing strategy. It starts by liaising with and capitalizing on existing activities to ingest LRs into the ELG. We have started by focusing on providers who are part of the consortium (ELDA/ELRA and ELG) and on recent activities such as ELRC-SHARE (Lösch et al., 2018; Piperidis et al., 2018) and META-SHARE (Piperidis, 2012; Piperidis et al., 2014). Table 2 provides an overview of what has been identified in these repositories and what is planned to be ingested into ELG, if their access and licensing conditions allow it. Corpora Lexicons Models Total ELRA ELRC-SHARE META-SHARE ELG 848 396 1580 78 1084 132 1261 109 0 0 18 76 1932 528 2859 263 Total 2902 2586 94 5582 Table 2: Identified LRs in the ELG consortium LR modalities covered are text (corpora, lexicons, etc.), speech/audio, video/audiovisual, images/OCR, sign language, and others. About 220 addition"
2020.lrec-1.413,2020.iwltp-1.12,1,0.789706,"ercial services, written in disparate programming languages (Java/Spring, .NET, Python) with just a few days work in the first iteration, falling to a few hours once developers became more familiar with the infrastructure and required formats. 14 These requests are received and handled by the LT Service Execution Server (Section 3.1). 3370 The composition of individual services offered by ELG directly or other cloud platforms is not addressed by ELG itself. However, we experiment with workflow composition and platform interoperability in other contexts (Rehm et al., 2020a; Rehm et al., 2020b; Moreno-Schneider et al., 2020a; Moreno-Schneider et al., 2020b) and plan to integrate experimental workflow functionality into ELG. SHARE metadata schemas and a set of resources has already been ingested from each of them into ELG (Table 3). ELRA ELRC-SHARE META-SHARE Corpora Lexicons Models 20 180 52 2 7 12 – – 7 3.5. Data Sets and Language Resources The ELG consortium has defined an LR identification and sharing strategy. It starts by liaising with and capitalizing on existing activities to ingest LRs into the ELG. We have started by focusing on providers who are part of the consortium (ELDA/ELRA and ELG) and on recent"
2020.lrec-1.413,2020.lrec-1.284,1,0.363908,"Missing"
2020.lrec-1.413,piperidis-etal-2014-meta,1,0.89681,"metadata schemas and a set of resources has already been ingested from each of them into ELG (Table 3). ELRA ELRC-SHARE META-SHARE Corpora Lexicons Models 20 180 52 2 7 12 – – 7 3.5. Data Sets and Language Resources The ELG consortium has defined an LR identification and sharing strategy. It starts by liaising with and capitalizing on existing activities to ingest LRs into the ELG. We have started by focusing on providers who are part of the consortium (ELDA/ELRA and ELG) and on recent activities such as ELRC-SHARE (Lösch et al., 2018; Piperidis et al., 2018) and META-SHARE (Piperidis, 2012; Piperidis et al., 2014). Table 2 provides an overview of what has been identified in these repositories and what is planned to be ingested into ELG, if their access and licensing conditions allow it. Corpora Lexicons Models Total ELRA ELRC-SHARE META-SHARE ELG 848 396 1580 78 1084 132 1261 109 0 0 18 76 1932 528 2859 263 Total 2902 2586 94 5582 Table 2: Identified LRs in the ELG consortium LR modalities covered are text (corpora, lexicons, etc.), speech/audio, video/audiovisual, images/OCR, sign language, and others. About 220 additional repositories have been located so far, which will increase the numbers in Table"
2020.lrec-1.413,L18-1205,1,0.945027,"tities of interest to users (Section 3.6), appropriately indexed and described so that they can easily search, find and select the resources that meet their requirements and deploy them, as well as visualise the LT domain activities, stakeholders and resources with specific criteria (e. g., service type, language, etc.). All entities are described in compliance with the ELG-SHARE metadata schema (Labropoulou et al., 2019; Labropoulou et al., 2020).7 The schema builds upon, consolidates and updates previous activities, especially the META-SHARE schema and its profiles (Gavrilidou et al., 2012; Piperidis et al., 2018; Labropoulou et al., 2018), taking into account the ELG user requirements (Melnika et al., 2019a), recent developments in the (meta)data domain (e. g., FAIR8 , data and software citation recommendations9 , Open Science movement, etc.), and the need for establishing a common pool of resources through exchange mechanisms with collaborating projects and initiatives (Rehm et al., 2020c), cf. Section 3.6. The schema caters for the description of the ELG core entities (Figure 2), i. e., Language Technologies (tools/services), including functional services and nonfunctional ones (e. g., downloadable"
2020.lrec-1.413,piperidis-2012-meta,1,0.90149,"y into ELG. SHARE metadata schemas and a set of resources has already been ingested from each of them into ELG (Table 3). ELRA ELRC-SHARE META-SHARE Corpora Lexicons Models 20 180 52 2 7 12 – – 7 3.5. Data Sets and Language Resources The ELG consortium has defined an LR identification and sharing strategy. It starts by liaising with and capitalizing on existing activities to ingest LRs into the ELG. We have started by focusing on providers who are part of the consortium (ELDA/ELRA and ELG) and on recent activities such as ELRC-SHARE (Lösch et al., 2018; Piperidis et al., 2018) and META-SHARE (Piperidis, 2012; Piperidis et al., 2014). Table 2 provides an overview of what has been identified in these repositories and what is planned to be ingested into ELG, if their access and licensing conditions allow it. Corpora Lexicons Models Total ELRA ELRC-SHARE META-SHARE ELG 848 396 1580 78 1084 132 1261 109 0 0 18 76 1932 528 2859 263 Total 2902 2586 94 5582 Table 2: Identified LRs in the ELG consortium LR modalities covered are text (corpora, lexicons, etc.), speech/audio, video/audiovisual, images/OCR, sign language, and others. About 220 additional repositories have been located so far, which will incr"
2020.lrec-1.413,L18-1519,1,0.634981,"any are world-class, with technologies that outperform the global players. However, European LT business is also fragmented – by nation states, languages, domains and sectors (Vasiljevs et al., 2019) –, significantly holding back its impact. In addition, many European languages are severely under-resourced and, thus, in danger of digital language exinction (Rehm and Uszkoreit, 2012; Kornai, 2013; Rehm et al., 2014; Rehm et al., 2016a), which is why there is an enormous need for a European LT platform as a unifying umbrella (Rehm and Uszkoreit, 2013; Rehm et al., 2016b; STOA, 2017; Rehm, 2017; Rehm and Hegele, 2018; European Parliament, 2018). The project European Language Grid (ELG; 2019-2021) addresses this fragmentation by establishing the ELG as the primary platform and marketplace for the European LT community, both industry and research.1 The ELG is developed to be a scalable cloud platform, providing, in an easy-to-integrate way, access to hundreds of commercial and non-commercial LTs for all European languages, including running tools and services as well as data sets and 1 https://www.european-language-grid.eu resources. Once fully operational, it will enable the commercial and non-commercial E"
2020.lrec-1.413,L16-1251,1,0.856739,"Missing"
2020.lrec-1.413,P14-5010,0,\N,Missing
2020.lrec-1.420,broeder-etal-2012-standardizing,0,0.0591638,"Missing"
2020.lrec-1.420,gavrilidou-etal-2012-meta,1,0.80935,"Missing"
2020.lrec-1.420,jorg-etal-2010-lt,0,0.0940319,"Missing"
2020.lrec-1.420,P15-4017,1,0.844943,"functionalities of the ELG platform as well as for future extensions and collaborations with other platforms(Rehm et al., 2020b). Thus, format and language can be used to match together tools/services with candidate input resources and initiate their processing; for instance, a tool that takes as input PDF files can be matched with datasets in PDF format. Similar information can also be used to semi-automatically compose workflows of tools and/or match together tools with compatible ancillary resources (annotation resources, ontologies, ML models) to create services and end-user applications (Piperidis et al., 2015; Labropoulou et al., 2018). Figure 3 shows a simplified subset of the metadata schema with its structuring layers and optionality status. Figure 3: Simplified subset of the ELG metadata schema 4.3. Describing LT-related entities ELG intends to offer the who is who of actors and projects in LT. Thus, the module for actors and projects, in comparison to META-SHARE profiles, has been enriched. Besides identification and descriptive metadata elements, such as name/title, identifier(s), contact information, etc., of particular importance are features related to and/or promoting LT activities, prod"
2020.lrec-1.420,L18-1205,1,0.686988,"). Its main source is META-SHARE, a wellestablished and widely used schema catering for the description of LRTs in the LT domain, together with its application profiles6 , which adapt the core properties and re6 It should be noted that META-SHARE is also registered in the CLARIN Component Registry (https://catalog.clarin.eu/ ds/ComponentRegistry) and used in the Greek CLARIN (https: //www.clarin.gr/) and various META-SHARE nodes harvested by the Virtual Language Observatory (https://vlo.clarin.eu/). 3429 lations to the needs of specific platforms (Gavrilidou et al., 2012; McCrae et al., 2015; Piperidis et al., 2018; Labropoulou et al., 2018). META-SHARE was based on an extensive study of related metadata schemas and catalogues, focusing mainly on LRTs but also taking into account general trends in the metadata domain (Desipri et al., 2012). In the course of time, its principles and implementation policies have been updated to reflect advancements in the metadata area. In ELG, modifications, updates and extensions in the contents (metadata elements and values) are made in response to user requirements (Melnika et al., 2019a) and new descriptive needs, such as: • integration and deployment of functional s"
2020.lrec-1.420,piperidis-2012-meta,1,0.867004,") are described with mainly bibliographic metadata and, optionally, a category of the LT area to which they belong. Licences and terms of use are described by a set of mainly administrative metadata (e.g., licence name, access URL) and elements facilitating human users to understand the main access conditions (Rodriguez-Doncel and Labropoulou, 2015). The module will also include a set of information for billing requirements of commercial services (currently work in progress). 3432 5. Language Technology Taxonomy For standardization purposes, the ELG schema, in line with META-SHARE principles (Piperidis, 2012), favours controlled vocabularies over free-text fields, especially when these are associated with internationally acknowledged standards, best practices or widespread vocabularies (e.g., ISO 3166 for region codes, RFC 5646 for languages, etc.). Specially devised vocabularies are used for various metadata elements, mainly for features specific to the LT sector. One such prominent case is the LT application area. The ’LT application area’ element is the main linking bridge between all entities in the ELG catalogue. It is used, for instance, to classify LTs by the function/task they perform (’se"
2020.lrec-1.420,L18-1519,1,0.401448,"-to-integrate way, access to hundreds of commercial and non-commercial LTs for all European languages, including running tools and services as well as data resources. Discovery of and access to these resources can only be achieved through an appropriate metadata schema. We present here the ELG-SHARE schema, which is used for the description of LT-related resources shared through the ELG platform and its contribution to the project goals. 2. Objectives The ELG project (Rehm et al., 2020a) aims to foster European LT by addressing the fragmentation that hinders its development; see indicatively (Rehm and Hegele, 2018; Rehm et al., 2016). To this end, it builds a platform dedicated to the distribution and deployment of Language Resources and Technologies (LRT), aspiring to establish it as the primary platform and marketplace for industry-relevant LT in Europe. The promotion of LT stakeholders and activities and growth of their visibility and outreach is also one of its goals. Together with complementary material in the portal (e.g., training material, information on events, job offerings, etc.), ELG offers a comprehensive picture of the European LT sector. The ELG platform5 will offer access to hundreds of"
2020.lrec-1.420,L16-1251,1,0.79915,"Missing"
2020.lrec-1.420,2020.lrec-1.413,1,0.821544,"Missing"
2020.lrec-1.420,2020.iwltp-1.15,1,0.820346,"Missing"
2021.eacl-demos.26,hinrichs-krauwer-2014-clarin,0,0.0190659,"arts in February 2021 with a duration of 912 months. In the first call, 110 proposals were accepted for evaluation with applicants from 29 countries. We received more proposals from SMEs (62) than re search organisations (48). While 79 proposals fo 2.10 Legal Entity 3 Related Work ELG builds upon previous work of the ELG con sortium and the wider European LT community, es pecially METANET/META and ELRC. In addition, we have collected more than 30 plat forms, projects or initiatives that can be considered relevant for ELG including, among others, UIMA (Ferrucci and Lally, 2003), CLARIN (Hinrichs and Krauwer, 2014), DKPro (Gurevych et al., 2007); Rehm et al. (2020a) provide an exhaustive com parison. They share at least one of the following goals with ELG, i. e., they provide: 1) a collec tion of LT/NLP tools or data sets; 2) a platform, which harvests metadata records from distributed sources, 3) a platform for the sharing of tools or data sets. While related projects do exist, the ap proach of ELG is unique. The platform that most closely resembles ELG is the National Platform for LT, operated by the Ministry of Electronics and In formation Technology in India.16 Several global technology enterpri"
2021.eacl-demos.26,2020.iwltp-1.12,1,0.888601,"Missing"
2021.eacl-demos.26,piperidis-2012-meta,1,0.736597,"four TTS and two text categori sation services. Further services are being added on a regular basis with 200+ additional IE and text analysis services, 21 MT, eight ASR and nine TTS scheduled to be included by the time of ELG Re lease 2 in February 2021. We aim to make it as simple as possible for LT providers to integrate their services, but in a Already now ELG provides access to more than 2700 language resources. We ingested substan tial resources from existing repositories, especially ELDA/ELRA, ELRCSHARE (Lösch et al., 2018; Piperidis et al., 2018; Smal et al., 2020) and META SHARE (Piperidis, 2012; Piperidis et al., 2014). We have also been working on ‘external’ reposito ries, about 220 of which have been identified so far. Some (e. g., Zenodo, Quantum Stat) are al ready being ingested together with two reposito ries related to ELG, LINDAT/CLARIAHCZ and ELRASHARELRs (LRs published at LREC). 2.6 Access Methods and User Interfaces Our main groups of users are: (1) LT/LR providers – companies or research organisations with tools, services or data that can be provided through the ELG; (2) Developers and integrators – companies and research institutions interested in using LT; (3) Gen"
2021.eacl-demos.26,L18-1205,1,0.930475,"ps://www.postgresql.org 8 https://www.keycloak.org 9 https://prometheus.io 10 https://helm.sh 5 2.3 Catalogue The metadata records stored in the catalogue en able access to services and data resources. They are described using the ELG metadata schema (Labropoulou et al., 2020) and can be browsed and explored. The catalogue also includes a registry of stakeholders who develop LT services or products, and relevant projects, thus providing an overview of the whole European LT landscape. The ELG metadata schema builds upon, consolidates and updates the METASHARE schema (Gavrilidou et al., 2012; Piperidis et al., 2018; Labropoulou et al., 2018), taking into account ELG’s require ments, recent developments in the metadata do main (e. g., FAIR11 ), and the need for creating a common pool of resources through exchange mechanisms with collaborating initiatives. The metadata schema caters for the descrip tion of the ELG core entities, i. e., Language Technologies (tools/services), including functional services and nonfunctional ones, and Data Lan guage Resources, comprising data sets (corpora), language descriptions (i. e., models) and lexical/ conceptual resources (e. g., gazetteers, ontologies, etc.). I"
2021.eacl-demos.26,piperidis-etal-2014-meta,1,0.869104,"text categori sation services. Further services are being added on a regular basis with 200+ additional IE and text analysis services, 21 MT, eight ASR and nine TTS scheduled to be included by the time of ELG Re lease 2 in February 2021. We aim to make it as simple as possible for LT providers to integrate their services, but in a Already now ELG provides access to more than 2700 language resources. We ingested substan tial resources from existing repositories, especially ELDA/ELRA, ELRCSHARE (Lösch et al., 2018; Piperidis et al., 2018; Smal et al., 2020) and META SHARE (Piperidis, 2012; Piperidis et al., 2014). We have also been working on ‘external’ reposito ries, about 220 of which have been identified so far. Some (e. g., Zenodo, Quantum Stat) are al ready being ingested together with two reposito ries related to ELG, LINDAT/CLARIAHCZ and ELRASHARELRs (LRs published at LREC). 2.6 Access Methods and User Interfaces Our main groups of users are: (1) LT/LR providers – companies or research organisations with tools, services or data that can be provided through the ELG; (2) Developers and integrators – companies and research institutions interested in using LT; (3) General LT information seeke"
2021.eacl-demos.26,L16-1251,1,0.869271,"Missing"
2021.eacl-demos.26,L18-1519,1,0.849444,"et al., 2019; Rehm et al., 2020d). We describe Release 2 of the European Lan guage Grid (ELG) cloud platform.1 This scal able system is targeted to evolve into the primary 1 https://www.europeanlanguagegrid.eu. We provide a screencast demo video at https://youtu.be/LD6QadkkZiM. platform for LT in Europe. It will provide one umbrella platform for all LTs developed by the European LT landscape, including research and industry, addressing a gap that has been repeat edly raised by the European LT community for many years (Rehm and Uszkoreit, 2013; Rehm et al., 2016b; STOA, 2017; Rehm, 2017; Rehm and Hegele, 2018; European Parliament, 2018). ELG is meant to be a virtual home and marketplace for all products, services and organisations active in the LT space in Europe (Rehm et al., 2020a). The platform can be used by all stakeholders to show case, share and distribute their products, services, tools and resources. At the end of the EU project ELG (20192022), which will establish a legal en tity in early 2022, the platform will provide access to approx. 1300 commercial and noncommercial tools and services for all European languages, as well as thousands of language resources (LRs). ELG will enable t"
2021.eacl-demos.26,2020.lrec-1.422,0,0.0498058,"Missing"
arranz-etal-2014-elras,calzolari-etal-2010-lrec,1,\N,Missing
arranz-etal-2014-elras,mostefa-etal-2012-new,1,\N,Missing
arranz-etal-2014-elras,choukri-etal-2012-using,1,\N,Missing
arranz-etal-2014-elras,poch-etal-2012-towards,0,\N,Missing
calzolari-etal-2004-enabler,binnenpoorte-etal-2002-field,0,\N,Missing
choukri-etal-2012-using,calzolari-etal-2010-lrec,1,\N,Missing
choukri-etal-2012-using,W11-3310,1,\N,Missing
cresti-etal-2004-c,danieli-etal-2004-evaluation,0,\N,Missing
cresti-etal-2004-c,cresti-etal-2002-c,1,\N,Missing
devillers-etal-2004-french,H92-1003,0,\N,Missing
devillers-etal-2004-french,P01-1066,0,\N,Missing
devillers-etal-2004-french,antoine-etal-2002-predictive,1,\N,Missing
devillers-etal-2004-french,antoine-etal-2000-obtaining,1,\N,Missing
E09-1040,niessen-etal-2000-evaluation,0,0.0495925,"ion, to evaluate the performance of a complete speech-to-speech translation system, we need to compare the source speech used as input to the translated output speech in the target language. To that aim, we reused a large part of the evaluation protocol from the TC-STAR project(Hamon et al., 2007). 4.2 Evaluation Protocol 4 Evaluation Tasks SLT evaluation. For the SLT evaluation, the automatically translated text from the ASR output is compared with two manual reference translations by means of automatic and human metrics. Two automatic metrics are used: BLEU (Papineni et al., 2001) and mWER (Niessen et al., 2000). For the human evaluation, each segment is evaluated in relation to adequacy and fluency (White and O’Connell, 1994). For the evaluation of adequacy, the target segment is compared to a reference segment. For the evaluation of fluency, the quality of the language is evaluated. The two types of evaluation are done independently, but each evaluator did both evaluations (first that of fluency, then that of adequacy) for a certain number of segments. For the evaluation of fluency, evaluators had to answer the question: “Is the text written in good Spanish?”. For the evaluation of adequacy, evalua"
E09-1040,H01-1048,1,0.755703,"ial hypotheses produced by the ASR module are collected in the resegmentation component, for merging and re-splitting at appropriate “semantic” boundaries. The resegmented hypotheses are then transferred to one or more machine translation components (MT), at least one per language pair. Different output technologies may be used for presenting the translations to the audience. For a detailed description of the components as well as the client-server framework used for connecting the components please refer to (Fügen et al., 2006b; Fügen et al., 2006a; Kolss et al., 2006; Fügen and Kolss, 2007; Fügen et al., 2001). 3 Automatic Simultaneous Translation Given the explanations above on human interpretation, one has to weigh two factors when considering the use of simultaneous translation systems: translation quality and cost. The major disadvantage of an automatic system compared to human interpretation is its translation quality, as we will see in the following sections. Current state-of-the-art systems may reach satisfactory quality for people not understanding the lecturer at all, but are still worse than human interpretation. Nevertheless, an automatic system may have considerable advantages. One such"
E09-1040,1997.mtsummit-papers.22,0,0.0534507,"ssary. In addition, human in3.2 End-to-End Evaluation The evaluation in speech-to-speech translation jeopardises many concepts and implies a lot of subjectivity. Three components are involved and an overall system may grow the difficulty of estimating the output quality. However, two criteria are mainly accepted in the community: measuring the information preservation and determining how much of the translation is understandable. Several end-to-end evaluations in speech-tospeech translation have been carried out in the last few years, in projects such as JANUS (Gates et al., 1996), Verbmobil (Nübel, 1997) or TC-STAR (Hamon et al., 2007). Those projects use the main criteria depicted above, and protocols differ in terms of data preparation, rating, procedure, etc. 346 Source Acoustic Source Language Source Boundary Translation Target Language Model Model Model Model Model Audio Stream Speech Recognition Hypothesis Resegmen− Translatable Machine tation Segment Translation Source Translation Dictionary Vocabulary Translated Output Spoken (Synthesis) Output Text (Subtitles) Figure 1: Schematic overview and information flow of the simultaneous translation system. The main components of the system a"
E09-1040,2001.mtsummit-papers.68,0,0.0274216,"ted by rounded boxes. To our opinion, to evaluate the performance of a complete speech-to-speech translation system, we need to compare the source speech used as input to the translated output speech in the target language. To that aim, we reused a large part of the evaluation protocol from the TC-STAR project(Hamon et al., 2007). 4.2 Evaluation Protocol 4 Evaluation Tasks SLT evaluation. For the SLT evaluation, the automatically translated text from the ASR output is compared with two manual reference translations by means of automatic and human metrics. Two automatic metrics are used: BLEU (Papineni et al., 2001) and mWER (Niessen et al., 2000). For the human evaluation, each segment is evaluated in relation to adequacy and fluency (White and O’Connell, 1994). For the evaluation of adequacy, the target segment is compared to a reference segment. For the evaluation of fluency, the quality of the language is evaluated. The two types of evaluation are done independently, but each evaluator did both evaluations (first that of fluency, then that of adequacy) for a certain number of segments. For the evaluation of fluency, evaluators had to answer the question: “Is the text written in good Spanish?”. For th"
E09-1040,2007.mtsummit-papers.30,1,0.793882,"in3.2 End-to-End Evaluation The evaluation in speech-to-speech translation jeopardises many concepts and implies a lot of subjectivity. Three components are involved and an overall system may grow the difficulty of estimating the output quality. However, two criteria are mainly accepted in the community: measuring the information preservation and determining how much of the translation is understandable. Several end-to-end evaluations in speech-tospeech translation have been carried out in the last few years, in projects such as JANUS (Gates et al., 1996), Verbmobil (Nübel, 1997) or TC-STAR (Hamon et al., 2007). Those projects use the main criteria depicted above, and protocols differ in terms of data preparation, rating, procedure, etc. 346 Source Acoustic Source Language Source Boundary Translation Target Language Model Model Model Model Model Audio Stream Speech Recognition Hypothesis Resegmen− Translatable Machine tation Segment Translation Source Translation Dictionary Vocabulary Translated Output Spoken (Synthesis) Output Text (Subtitles) Figure 1: Schematic overview and information flow of the simultaneous translation system. The main components of the system are represented by cornered boxes"
E09-1040,H94-1024,0,\N,Missing
E09-1040,P02-1040,0,\N,Missing
el-hadi-etal-2006-terminological,W01-0907,1,\N,Missing
galibert-etal-2014-etape,W11-0411,1,\N,Missing
galibert-etal-2014-etape,ben-jannet-etal-2014-eter,1,\N,Missing
galibert-etal-2014-etape,I11-1058,1,\N,Missing
galibert-etal-2014-etape,gravier-etal-2012-etape,1,\N,Missing
gavrilidou-etal-2006-language,J03-3002,0,\N,Missing
gavrilidou-etal-2006-language,calzolari-etal-2004-enabler,1,\N,Missing
gavrilidou-etal-2006-language,erjavec-2004-multext,0,\N,Missing
gavrilidou-etal-2006-language,J03-3001,0,\N,Missing
iskra-etal-2004-orientel,van-den-heuvel-etal-2004-slr,1,\N,Missing
L16-1074,L16-1718,1,0.909884,"Resource Impact Factor” (LRIF). As a first benefit, the merits of LR producers can be better recognized through the use of such an identifier. Moreover, identifying unique LRs will help analyse the LR field evolution in a more efficient way by reducing the duplicated information which may give a wrong idea of the real situation. With the objective to associate LRs to a unique identification number, ELRA has been promoting the use of the International Standard Language Resource Number (ISLRN). The ISLRN portal was launched in 2014 and its use is increasing since then. Its promotion continues (Choukri et al., 2016). Up to March 2016, 2100 LRs were allocated an ISLRN number, not only ELRA’s and LDC’s catalogued Language Resources, but also the ones from other important organisations like the Joint Research Centre (JRC) and the Resource Management Agency (RMA) who expressed their strong support to this initiative. ELRA is also encouraging the idea of using a BibTeX entry for bibliographical references that would take into account Language Resources items. A stripped-down form of ELRA’s BibTex proposal is already being used for the LREC 2016 conference papers. 3.4. ELRA License Wizard From the very beginni"
L16-1074,L16-1254,1,0.831394,"Missing"
L16-1254,choukri-etal-2012-using,1,0.791866,"a LR-oriented bibliographical reference is thus part of the objective. The idea is to make use of a BibTeX entry that would take into account Language Resources items, including ISLRN. The ISLRN being a requested field within the LREC 2016 submission, we expect that several other LRs will be allocated an ISLRN number by the conference date. With this expansion, this number aims to be a spreadlyused LR citation instrument within works referring to LRs. Keywords: ISLRN, unique identifier, Language Resource citation portal2. Details on the overall ISLRN infrastructure were already described in (Park et al., 2012). 1. Principle and setting up The International Standard Language Resource Number (ISLRN) was set up with the aim of providing a universal and unique identification schema, dedicated specifically to Language Resources (LRs) within the Human Language Technology (HLT) field, and under a free service for the HLT Community. This to ensure that LRs are correctly identified, and consequently, recognized with proper references for their usage in applications within R&D projects, product evaluation and benchmarking, as well as in documents and scientific papers. After having reviewed a number of exist"
L16-1254,W11-3310,1,0.497544,"e and setting up The International Standard Language Resource Number (ISLRN) was set up with the aim of providing a universal and unique identification schema, dedicated specifically to Language Resources (LRs) within the Human Language Technology (HLT) field, and under a free service for the HLT Community. This to ensure that LRs are correctly identified, and consequently, recognized with proper references for their usage in applications within R&D projects, product evaluation and benchmarking, as well as in documents and scientific papers. After having reviewed a number of existing schemas (Choukri et al., 2011), the ISLRN identifier was implemented as a 12-digit random number as the new LR identifier, followed by 1 digit for a checksum number (see figure below). 2. Submission process In association to this identification number, a metadata schema was built in order to delegate semantics of the LR content to metadata which can easily and richly describe it, instead of integrating it within the number itself. Inspired by the broadly known OLAC schema, this metadata targeted on simple, easy and quick to fill in, fields to avoid any misunderstanding, and thus offers a minimal set of information describi"
L16-1716,calzolari-etal-2010-lrec,1,0.773441,"ng menus for faceted search, modal conference metadata display, etc. 3. 3.1. New Database Architecture General Context The LRE Map is a user interface and a database. The user interface is embedded in the START 10 article submission system, used for LREC. The START user interface gathers the information on the used/cited resources and connects them to the paper and its authors. A communication protocol settled between ILC and START is responsible for feeding and updating the database with the information gathered with the user interface. Since its first appearance in the LREC 2010 conference (Calzolari et al., 2010), the LRE Map underwent many changes in its internal structure to address specific requirements of the referenced community. For example, the number of slots dedicated to the languages changed from 3 to 6 after the pioneering work on language matrices (Mariani and Francopoulo, 2012), and some additional details such as size and unit of the described language resource have been added to keep track of the amount of information a LR can provide to the community. All these changes caused variations in the record tracks and, consequently, in the database structure. Moreover, the LREC 2016 database"
L16-1721,2007.mtsummit-papers.1,0,0.0551449,"Missing"
L16-1721,N10-1064,0,0.0154845,"lone pre-processing phase for defining correction rules targeting features of UGC negatively impacting SMT (e.g. use of slang, unconventional punctuation, ungrammaticality). Manually defined correction rules based on regular expressions can be either automatically applied (c.f. Jachmann et al., 2014) or they may require some form of intervention. Another strategy is to refine the SMT system by including a pre-processing step in which potential spelling errors are modelled (through a Confusion Network) and subsequently recovered by the decoder on the basis of a character n-gram language model (Bertoldi et al., 2010). However, both approaches have drawbacks. Whereas the first one requires manual intervention and is thus potentially slow and costly in terms of human resources, the second one entails high computational costs related to spelling-error modelling (Bertoldi et al., 2010: 418). Beyond the structural particularities of UG text, further difficulties have to do with the translation of pragmatic nuances usually present in subjective and evaluative discourse. If those nuances are not accurately translated, the opinion contained in the original text may not be recoverable, or, worse, might yield, simi"
L16-1721,C12-1135,1,0.89057,"Missing"
L16-1721,P90-1013,0,0.48575,"spelling-error modelling (Bertoldi et al., 2010: 418). Beyond the structural particularities of UG text, further difficulties have to do with the translation of pragmatic nuances usually present in subjective and evaluative discourse. If those nuances are not accurately translated, the opinion contained in the original text may not be recoverable, or, worse, might yield, similar to lying, false implicatures, with significant consequences on the perlocutionary effects on the readers of the translated text (see e.g. Mejbauer, 2004, for an account on lying in relation with false implicatures, or Reiter, 1990, for a computational approach to avoiding conversational 4 4551 http://accept-project.eu/ implicatures in computer-generated content). In this case, the translation would fail to meet users&apos; expectations in an e-commerce context. The literature on social media analytics has proposed several techniques to leverage pragmatic content from online user interaction. The proposed solutions often rely on deep linguistic processing creating a semantic representation of text (e.g. Delmonte & Pallotta, 2011) and modelling argumentative structure (Pallotta et al., 2011) to capture meaning distributed ove"
L16-1721,seretan-etal-2014-large,0,0.0268506,"matical constraints, and high dependence on the individuals’ writing style, give rise to data sparsity issues affecting the performance of SMT systems, which present a poorer performance with informal genres (van der Wees et al., 2015a). This is why text pre-processing (i.e. text normalisation) is used as a method for improving SMT performance. Different strategies have been deployed so far to enable automatic or semi-automatic text pre-processing for MT. The issue has been deeply studied in the framework of the ACCEPT project,4 aimed at enhancing the translation of UGC in online communities. Seretan et al. (2014), for instance, describe a standalone pre-processing phase for defining correction rules targeting features of UGC negatively impacting SMT (e.g. use of slang, unconventional punctuation, ungrammaticality). Manually defined correction rules based on regular expressions can be either automatically applied (c.f. Jachmann et al., 2014) or they may require some form of intervention. Another strategy is to refine the SMT system by including a pre-processing step in which potential spelling errors are modelled (through a Confusion Network) and subsequently recovered by the decoder on the basis of a"
L16-1721,W15-4304,0,0.0427304,"Missing"
L16-1721,P15-2092,0,0.0419402,"Missing"
L16-1721,N13-1069,0,0.0526415,"Missing"
L18-1021,L16-1074,1,0.899592,"Missing"
L18-1213,L18-1599,1,0.756254,"/Licence Ouverte, for France). LRs provided can be classified and viewed depending on the licence available: public domain, open under PSI, open licenses, standard licenses, and non-standard licenses. Validation of Language Resources within ELRC Validation Guidelines Implementation Validation can be understood as the quality control of a LR against a list of relevant criteria (Schneller et al., 2017). Due to the high number of LRs required within the project, the ELRC consortium decided to complement the donated LRs with additional LRs produced from scratch through a website crawling process (Papavassiliou et al, 2018). Web crawling was conducted using ILSP-FC, a comprehensive end-to-end solution for the acquisition of domain-specific monolingual and bilingual corpora from the web. Data Processing Each LR is analysed and processed by ELRC experts to ensure compliance with the Language Resources Data 12 https://www.maxprograms.com/products/tmxvalidator.html https://www.microsoft.com/en-us/download/ details.aspx?id=52608 14 https://github.com/aboSamoor/pycld2 13 10 11 http://lr-coordination.eu/helpdesk http://helpdesk.lr-coordination.eu/overview 1341 The ELRC partners (the National Anchor Points) initially id"
L18-1213,W12-0102,0,0.040596,"Missing"
L18-1213,L18-1391,1,0.797927,"eHealth Business Registers Interconnection System Safer Internet Cybersecurity Public Open Data Europeana Domain Consumers’ rights Social security, insurance Public procurement, contractual agreements Justice, Law Health, Medicine Business, market ICT ICT Multiple domains Culture Table 1: CEF Digital Service Infrastructures (DSIs) and their domains Even though the PSI Directive is an important instrument to open up public sector data, there are many challenges in collecting LRs from public services, such as lack of awareness, lack of technical or legal competence, poor data management, etc. (Vasiļjevs et al., 2018). 1.3 Setting up a European Language Resource Coordination (ELRC) European, national and regional public administrations deal with a huge amount of multilingual textual information in original and translated form. By sharing this linguistic data and turning it into language resources (LRs), they can improve the quality, coverage and performance of CEF eTranslation that needs multilingual LRs to train MT systems. In April 2015, the ELRC Consortium was set up through EC’s Connecting Europe Facility SMART 2014/1074 programme to initiate a number of actions with the aim to support the collection o"
L18-1575,W16-4809,1,0.807382,"of Dialectal Arabic). In the continuation of AIDA, the authors of (Elfardy and Diab, 2013) presented a supervised approach for the identification of dialectal sentences. They also studied the effects of preprocessing techniques on the accuracy of the developed classifiers. As far as we know, there are few tools for automatically processing Arabizi. Works presented in (Darwish, 2014) and (Eskander et al., 2014), aimed at distinguishing English from Arabizi, resulting in a transliteration of texts from Arabizi to Arabic, which allows to process these texts with NLP systems dedicated to Arabic. (Adouane et al., 2016) considered the task of automatic identification of dialects as a classification problem and used supervised machine learning techniques to recognize Arabized Berber and Arabic dialects. A review of methods and obtained results for the processing of Arabic dialects was presented in (Shoufan and AlAmeri, 2015). Four types of tasks are described: basic analyzes, resource building, semantic analysis and identification of dialects. We can see that the approaches are generally divided into two main categories: dialectal systems built from dedicated resources and systems made by adaptation of availa"
L18-1575,al-sabbagh-girju-2012-yadac,0,0.0252355,"elated Work The creation of resources and development of methods to deal with Arabic dialects have attracted the attention of many researchers in the last few years. The aim is to compensate the lack of resources for dialectal Arabic, which are crucial for the development of adequate NLP tools. In (Zaidan and Callison-Burch, 2011) the authors collected a corpus based on texts available on the web, from three Arabic newspapers of Levantine, Gulf and Egyptian dialects. Articles and their comments were extracted to build the corpus. We can find several other corpora for Arabic dialects, such as (Al-Sabbagh and Girju, 2012) who created an annotated corpus of Egyptian, but only a small subset of it was manually annotated to build a classifier, the rest of the corpus being automatically annotated. Other initiatives aimed to create a dialectal Arabic dataset to address the lack of dedicated resources such as (Cotterell and Callison-Burch, 2014), where the authors collected a significant amount of dialectal data from comments, online journals and Twitter for Egyptian, Gulf, Levantine, Algerian and Iraqi. 3639 The work presented in (Elfardy and Diab, 2012b) suggests guidelines for the foundation of large corpora of m"
L18-1575,I13-1048,0,0.0283062,"same schema. For example, the  - inside  &apos; P rbaH  word l&apos;.QK l - yirbaH “to win” follows the .  . JºK - I. J» ktab- yakALG –pattern-I-aa; the word I tab, “to write” follows the ALG-I-aa.We remark that the two verbs came from the same class but they have not the same imperfect marks. This is why we propose to extend the ALG patternI-au in order to define for the pattern-I more  -sub patterns. To get this goal, we attribute to l&apos;.QK l&apos;.P  I. J» ktab- ya-ktab the scheme ALG-I-aa-a.  I. JºK - This approach was also followed by (Shaalan et al., 2007) for Egyptian dialect and (Boujelbane et al., 2013) for Tunisian dialect. Table 2 gives some statistics about the final lexicons per dialect. 5. 5.1. EG 34859 • Lang2: Dialect word &lt;AD&gt; in Arabic or Arabizi script and information for Arabic text: &lt;DZ&gt; (Algerian),&lt;TN&gt; (Tunisian), &lt;MA&gt; (Moroccan) or &lt;EG&gt; (Egyptian). This information is added in the arabizi script after their transliteration. • Pattern’s second consonant vowel oriented classification: In Arabic, the vowel of the pattern’s second consonant is one of the basic deterministic elements of the verbal morphology. According to (Ouerhani, 2009), this vowel is considered as the first crite"
L18-1575,cotterell-callison-burch-2014-multi,0,0.0157564,"son-Burch, 2011) the authors collected a corpus based on texts available on the web, from three Arabic newspapers of Levantine, Gulf and Egyptian dialects. Articles and their comments were extracted to build the corpus. We can find several other corpora for Arabic dialects, such as (Al-Sabbagh and Girju, 2012) who created an annotated corpus of Egyptian, but only a small subset of it was manually annotated to build a classifier, the rest of the corpus being automatically annotated. Other initiatives aimed to create a dialectal Arabic dataset to address the lack of dedicated resources such as (Cotterell and Callison-Burch, 2014), where the authors collected a significant amount of dialectal data from comments, online journals and Twitter for Egyptian, Gulf, Levantine, Algerian and Iraqi. 3639 The work presented in (Elfardy and Diab, 2012b) suggests guidelines for the foundation of large corpora of mixed Arabic resources with switching code. In addition to the former work, an identification, interpretation and classification system for dialects was introduced in (Elfardy and Diab, 2012a) called AIDA (Automatic Identification and Glossing of Dialectal Arabic). In the continuation of AIDA, the authors of (Elfardy and Di"
L18-1575,W14-3629,0,0.0206647,"sources with switching code. In addition to the former work, an identification, interpretation and classification system for dialects was introduced in (Elfardy and Diab, 2012a) called AIDA (Automatic Identification and Glossing of Dialectal Arabic). In the continuation of AIDA, the authors of (Elfardy and Diab, 2013) presented a supervised approach for the identification of dialectal sentences. They also studied the effects of preprocessing techniques on the accuracy of the developed classifiers. As far as we know, there are few tools for automatically processing Arabizi. Works presented in (Darwish, 2014) and (Eskander et al., 2014), aimed at distinguishing English from Arabizi, resulting in a transliteration of texts from Arabizi to Arabic, which allows to process these texts with NLP systems dedicated to Arabic. (Adouane et al., 2016) considered the task of automatic identification of dialects as a classification problem and used supervised machine learning techniques to recognize Arabized Berber and Arabic dialects. A review of methods and obtained results for the processing of Arabic dialects was presented in (Shoufan and AlAmeri, 2015). Four types of tasks are described: basic analyzes, r"
L18-1575,2012.eamt-1.18,0,0.039558,"find several other corpora for Arabic dialects, such as (Al-Sabbagh and Girju, 2012) who created an annotated corpus of Egyptian, but only a small subset of it was manually annotated to build a classifier, the rest of the corpus being automatically annotated. Other initiatives aimed to create a dialectal Arabic dataset to address the lack of dedicated resources such as (Cotterell and Callison-Burch, 2014), where the authors collected a significant amount of dialectal data from comments, online journals and Twitter for Egyptian, Gulf, Levantine, Algerian and Iraqi. 3639 The work presented in (Elfardy and Diab, 2012b) suggests guidelines for the foundation of large corpora of mixed Arabic resources with switching code. In addition to the former work, an identification, interpretation and classification system for dialects was introduced in (Elfardy and Diab, 2012a) called AIDA (Automatic Identification and Glossing of Dialectal Arabic). In the continuation of AIDA, the authors of (Elfardy and Diab, 2013) presented a supervised approach for the identification of dialectal sentences. They also studied the effects of preprocessing techniques on the accuracy of the developed classifiers. As far as we know, t"
L18-1575,elfardy-diab-2012-simplified,0,0.0321153,"find several other corpora for Arabic dialects, such as (Al-Sabbagh and Girju, 2012) who created an annotated corpus of Egyptian, but only a small subset of it was manually annotated to build a classifier, the rest of the corpus being automatically annotated. Other initiatives aimed to create a dialectal Arabic dataset to address the lack of dedicated resources such as (Cotterell and Callison-Burch, 2014), where the authors collected a significant amount of dialectal data from comments, online journals and Twitter for Egyptian, Gulf, Levantine, Algerian and Iraqi. 3639 The work presented in (Elfardy and Diab, 2012b) suggests guidelines for the foundation of large corpora of mixed Arabic resources with switching code. In addition to the former work, an identification, interpretation and classification system for dialects was introduced in (Elfardy and Diab, 2012a) called AIDA (Automatic Identification and Glossing of Dialectal Arabic). In the continuation of AIDA, the authors of (Elfardy and Diab, 2013) presented a supervised approach for the identification of dialectal sentences. They also studied the effects of preprocessing techniques on the accuracy of the developed classifiers. As far as we know, t"
L18-1575,P13-2081,0,0.0175971,"n-Burch, 2014), where the authors collected a significant amount of dialectal data from comments, online journals and Twitter for Egyptian, Gulf, Levantine, Algerian and Iraqi. 3639 The work presented in (Elfardy and Diab, 2012b) suggests guidelines for the foundation of large corpora of mixed Arabic resources with switching code. In addition to the former work, an identification, interpretation and classification system for dialects was introduced in (Elfardy and Diab, 2012a) called AIDA (Automatic Identification and Glossing of Dialectal Arabic). In the continuation of AIDA, the authors of (Elfardy and Diab, 2013) presented a supervised approach for the identification of dialectal sentences. They also studied the effects of preprocessing techniques on the accuracy of the developed classifiers. As far as we know, there are few tools for automatically processing Arabizi. Works presented in (Darwish, 2014) and (Eskander et al., 2014), aimed at distinguishing English from Arabizi, resulting in a transliteration of texts from Arabizi to Arabic, which allows to process these texts with NLP systems dedicated to Arabic. (Adouane et al., 2016) considered the task of automatic identification of dialects as a cla"
L18-1575,W14-3911,0,0.017151,"ic Hadi 3afsa chaba bezzef Dialect DZ,MA,TN DZ MSA,DZ DZ ø X Aë é ® « éK . A • Combination: The combining step is used to aggregate multiple components, including dictionaries of named entities and language templates, in order to perform the recognition and the identification of named entities and language. Each word of the input sentence can be tagged with different labels from the previous steps. Thereby the combining step, based on the generated labels, uses a set of decision rules to assign the final tag to each word in the analyzed sentence. The decision rules used are presented in (Elfardy et al., 2014; Saˆadane, 2015), and summarized as follows: ¬@ Q K . Table 3: Filtering of the best candidate using a morphological analyze The generated list is then filtered using a morphological analyzer to predict whether the word belongs to one of the studied dialects (Table 3). The conversion of Arabizi into Arabic script is an important step, but this article focuses on the identification of dialects and due to lack of space we cannot detail this part of the processing. Note, however, that this process adds a crucial information to identify the dialect: the presence of vowels in Arabizi makes it pos"
L18-1575,W14-3901,0,0.0169306,"ng code. In addition to the former work, an identification, interpretation and classification system for dialects was introduced in (Elfardy and Diab, 2012a) called AIDA (Automatic Identification and Glossing of Dialectal Arabic). In the continuation of AIDA, the authors of (Elfardy and Diab, 2013) presented a supervised approach for the identification of dialectal sentences. They also studied the effects of preprocessing techniques on the accuracy of the developed classifiers. As far as we know, there are few tools for automatically processing Arabizi. Works presented in (Darwish, 2014) and (Eskander et al., 2014), aimed at distinguishing English from Arabizi, resulting in a transliteration of texts from Arabizi to Arabic, which allows to process these texts with NLP systems dedicated to Arabic. (Adouane et al., 2016) considered the task of automatic identification of dialects as a classification problem and used supervised machine learning techniques to recognize Arabized Berber and Arabic dialects. A review of methods and obtained results for the processing of Arabic dialects was presented in (Shoufan and AlAmeri, 2015). Four types of tasks are described: basic analyzes, resource building, semantic a"
L18-1575,habash-etal-2012-conventional,0,0.137238,"asis of many methods of dialect detection. • Orthographic: Unlike MSA, dialects do not have an orthographic standard. We find many orthographic variations in the writing of words. These variations are mainly due to phonological differences between MSA and Arabic dialects . In some cases, phonology or underlying morphology results in regular phonological YªK. man bac¸d assimilation writing, for example, áÓ “after” also written Õ× YªK. mam bac¸d. To remedy this lack of norm, work has been carried out to propose a Conventional Orthography for Dialectal Arabic (CODA), first proposed for Egyptian (Habash et al., 2012), then extended to other dialects such as Tunisian (Zribi et al., 2014), Algerian (Saˆadane and Habash, 2015), Maghrebi Arabic (Turki et al., 2016) and Palestinian (Habash et al., 2016). • Morphology: There are many morphological differences between dialects and MSA. These differences can be seen through several aspects. One of these aspects is the future particle which appears as +  sa sawfa in MSA, which is expressed in: (i) + ¬ñ h+ Ha + or hP raH in the Levantine dialects, (ii) è+ ha + in Egyptian dialect, (iii) + ka + in Moroccan + or 1 Arabic transliteration is presented in the Habash-"
L18-1575,W15-3208,1,0.908253,"Missing"
L18-1575,W15-3205,0,0.0281412,"Missing"
L18-1575,D13-1007,0,0.0208059,"other hand, a large number of dialects are used as mother tongues for many Arabic-speaking populations. In fact, they are the main communication tool spoken in everyday life through informal conversations, exchanges on SMS, forums and social networks, even in e-mails. These dialects vary from one country to another, one region to another, or even from one city to another. In addition, they differ from each other by important phonological, morphological, lexical and syntactic characteristics. The processing of informal texts has become an extremely popular field of research among researchers (Yang and Eisenstein, 2013). For Arabic NLP, the identification of dialects is very important and considered as a prepossessing step for any natural language application dealing with Arabic language, such as machine translation, information retrieval for social media. It is sometimes considered as a difficult case of language identification where, according to (Zaidan and Callison-Burch, 2011) it is applied to a group of closely related languages that share a common character set. This identification is made even more complex by the absence of orthographic conventions, by the transliteration of Arabic dialects into Lati"
L18-1575,P11-2007,0,0.467975,"to another. In addition, they differ from each other by important phonological, morphological, lexical and syntactic characteristics. The processing of informal texts has become an extremely popular field of research among researchers (Yang and Eisenstein, 2013). For Arabic NLP, the identification of dialects is very important and considered as a prepossessing step for any natural language application dealing with Arabic language, such as machine translation, information retrieval for social media. It is sometimes considered as a difficult case of language identification where, according to (Zaidan and Callison-Burch, 2011) it is applied to a group of closely related languages that share a common character set. This identification is made even more complex by the absence of orthographic conventions, by the transliteration of Arabic dialects into Latin script (Arabizi) and also the use of code-switching. Recent works have proposed both supervised and unsupervised statistical approaches to language identification. However, current methods are based on the assumption that dedicated resources exist, such as large corpora and dictionaries. Unfortunately, these resources are rarely available for certain languages and"
L18-1575,zribi-etal-2014-conventional,0,0.0236344,"ialects do not have an orthographic standard. We find many orthographic variations in the writing of words. These variations are mainly due to phonological differences between MSA and Arabic dialects . In some cases, phonology or underlying morphology results in regular phonological YªK. man bac¸d assimilation writing, for example, áÓ “after” also written Õ× YªK. mam bac¸d. To remedy this lack of norm, work has been carried out to propose a Conventional Orthography for Dialectal Arabic (CODA), first proposed for Egyptian (Habash et al., 2012), then extended to other dialects such as Tunisian (Zribi et al., 2014), Algerian (Saˆadane and Habash, 2015), Maghrebi Arabic (Turki et al., 2016) and Palestinian (Habash et al., 2016). • Morphology: There are many morphological differences between dialects and MSA. These differences can be seen through several aspects. One of these aspects is the future particle which appears as +  sa sawfa in MSA, which is expressed in: (i) + ¬ñ h+ Ha + or hP raH in the Levantine dialects, (ii) è+ ha + in Egyptian dialect, (iii) + ka + in Moroccan + or 1 Arabic transliteration is presented in the Habash-SoudiBuckwalter (HSB) scheme (Habash et al., 2007).  dilwaqtiy, øñK t"
maegaard-etal-2006-blark,binnenpoorte-etal-2002-field,0,\N,Missing
maegaard-etal-2006-blark,yaseen-etal-2006-building,0,\N,Missing
maegaard-etal-2006-blark,maegaard-2004-nemlar-arabic,1,\N,Missing
maegaard-etal-2006-blark,2004.eamt-1.15,1,\N,Missing
maegaard-etal-2008-medar,hamon-etal-2006-cesta,0,\N,Missing
maegaard-etal-2008-medar,yaseen-etal-2006-building,0,\N,Missing
maegaard-etal-2008-medar,maegaard-2004-nemlar-arabic,1,\N,Missing
maegaard-etal-2008-medar,2004.eamt-1.15,1,\N,Missing
maegaard-etal-2008-medar,maegaard-etal-2006-blark,1,\N,Missing
maegaard-etal-2010-cooperation,yaseen-etal-2006-building,0,\N,Missing
maegaard-etal-2010-cooperation,maegaard-etal-2006-blark,1,\N,Missing
mapelli-etal-2012-elra,calzolari-etal-2010-lrec,1,\N,Missing
mapelli-etal-2012-elra,choukri-etal-2012-using,1,\N,Missing
mapelli-etal-2012-elra,arranz-etal-2008-guide,1,\N,Missing
monachini-etal-2006-unified,monachini-etal-2004-unifying,1,\N,Missing
monachini-etal-2006-unified,ruimy-etal-2002-clips,1,\N,Missing
moreau-etal-2008-data,mostefa-etal-2006-evaluation-multimodal,1,\N,Missing
moreau-etal-2010-evaluation,gravier-etal-2004-ester,0,\N,Missing
moreau-etal-2010-evaluation,mostefa-etal-2006-evaluation,1,\N,Missing
moreau-etal-2010-evaluation,galliano-etal-2006-corpus,0,\N,Missing
moreno-etal-2004-collection,van-den-heuvel-etal-2004-slr,1,\N,Missing
mostefa-etal-2006-evaluation,P02-1040,0,\N,Missing
mostefa-etal-2006-evaluation,babych-hartley-2004-modelling,0,\N,Missing
mostefa-etal-2012-new,N10-1077,0,\N,Missing
mostefa-etal-2012-new,W10-3212,0,\N,Missing
pinto-etal-2004-development,iskra-etal-2002-speecon,0,\N,Missing
pinto-etal-2004-development,francois-boeffard-2002-greedy,1,\N,Missing
piperidis-etal-2014-meta,wittenburg-etal-2010-resource,1,\N,Missing
piperidis-etal-2014-meta,choukri-etal-2012-using,1,\N,Missing
piperidis-etal-2014-meta,piperidis-2012-meta,1,\N,Missing
piperidis-etal-2014-meta,gavrilidou-etal-2012-meta,1,\N,Missing
piperidis-etal-2014-meta,broeder-etal-2010-data,0,\N,Missing
piperidis-etal-2014-meta,soria-etal-2012-flarenet,1,\N,Missing
piperidis-etal-2014-meta,federmann-etal-2012-meta,1,\N,Missing
siemund-etal-2002-orientel,moreno-etal-2000-sala,1,\N,Missing
siemund-etal-2002-orientel,siemund-etal-2000-speecon,1,\N,Missing
siemund-etal-2002-orientel,moreno-etal-2000-speechdat,1,\N,Missing
van-den-heuvel-etal-2000-slr,moreno-etal-2000-sala,1,\N,Missing
van-den-heuvel-etal-2002-give,van-den-heuvel-etal-2000-slr,1,\N,Missing
W03-2810,X98-1031,0,\N,Missing
W11-3310,C08-2030,0,\N,Missing
W11-3310,calzolari-etal-2010-lrec,1,\N,Missing
W11-3310,2005.mtsummit-papers.11,0,\N,Missing
