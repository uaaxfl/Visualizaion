2021.wnut-1.27,{S}pan{A}lign: Efficient Sequence Tagging Annotation Projection into Translated Data applied to Cross-Lingual Opinion Mining,2021,-1,-1,6,0,183,leo jacqmin,Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021),0,"Following the increasing performance of neural machine translation systems, the paradigm of using automatically translated data for cross-lingual adaptation is now studied in several applicative domains. The capacity to accurately project annotations remains however an issue for sequence tagging tasks where annotation must be projected with correct spans. Additionally, when the task implies noisy user-generated text, the quality of translation and annotation projection can be affected. In this paper we propose to tackle multilingual sequence tagging with a new span alignment method and apply it to opinion target extraction from customer reviews. We show that provided suitable heuristics, translated data with automatic span-level annotation projection can yield improvements both for cross-lingual adaptation compared to zero-shot transfer, and data augmentation compared to a multilingual baseline."
2020.lrec-1.529,"A Multimodal Educational Corpus of Oral Courses: Annotation, Analysis and Case Study",2020,0,0,7,0,5782,salima mdhaffar,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This corpus is part of the PASTEL (Performing Automated Speech Transcription for Enhancing Learning) project aiming to explore the potential of synchronous speech transcription and application in specific teaching situations. It includes 10 hours of different lectures, manually transcribed and segmented. The main interest of this corpus lies in its multimodal aspect: in addition to speech, the courses were filmed and the written presentation supports (slides) are made available. The dataset may then serve researches in multiple fields, from speech and language to image and video processing. The dataset will be freely available to the research community. In this paper, we first describe in details the annotation protocol, including a detailed analysis of the manually labeled data. Then, we propose some possible use cases of the corpus with baseline results. The use cases concern scientific fields from both speech and text processing, with language model adaptation, thematic segmentation and transcription to slide alignment."
2020.lrec-1.674,Cross-lingual and Cross-domain Evaluation of Machine Reading Comprehension with Squad and {CALOR}-Quest Corpora,2020,-1,-1,2,1,17730,delphine charlet,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Machine Reading received recently a lot of attention thanks to both the availability of very large corpora such as SQuAD or MS MARCO containing triplets (document, question, answer), and the introduction of Transformer Language Models such as BERT which obtain excellent results, even matching human performance according to the SQuAD leaderboard. One of the key features of Transformer Models is their ability to be jointly trained across multiple languages, using a shared subword vocabulary, leading to the construction of cross-lingual lexical representations. This feature has been used recently to perform zero-shot cross-lingual experiments where a multilingual BERT model fine-tuned on a machine reading comprehension task exclusively for English was directly applied to Chinese and French documents with interesting performance. In this paper we study the cross-language and cross-domain capabilities of BERT on a Machine Reading Comprehension task on two corpora: SQuAD and a new French Machine Reading dataset, called CALOR-QUEST. The semantic annotation available on CALOR-QUEST allows us to give a detailed analysis on the kinds of questions that are properly handled through the cross-language process. We will try to answer this question: which factor between language mismatch and domain mismatch has the strongest influence on the performances of a Machine Reading Comprehension task?"
2020.jeptalnrecital-taln.28,Analyse automatique en cadres s{\\'e}mantiques pour l{'}apprentissage de mod{\\`e}les de compr{\\'e}hension de texte (Semantic Frame Parsing for training Machine Reading Comprehension models),2020,-1,-1,3,1,184,gabriel marzinotto,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",0,"Dans le cadre de la compr{\'e}hension automatique de documents, cet article propose une {\'e}valuation intrins{\`e}que et extrins{\`e}que d{'}un mod{\`e}le d{'}analyse automatique en cadres s{\'e}mantiques (Frames). Le mod{\`e}le propos{\'e} est un mod{\`e}le {\'e}tat de l{'}art {\`a} base de GRU bi-directionnel, enrichi par l{'}utilisation d{'}embeddings contextuels. Nous montrons qu{'}un mod{\`e}le de compr{\'e}hension de documents appris sur un corpus de triplets g{\'e}n{\'e}r{\'e}s {\`a} partir d{'}un corpus analys{\'e} automatiquement avec l{'}analyseur en cadre s{\'e}mantique pr{\'e}sente des performances inf{\'e}rieures de seulement 2.5{\%} en relatif par rapport {\`a} un mod{\`e}le appris sur un corpus de triplets g{\'e}n{\'e}r{\'e}s {\`a} partir d{'}un corpus analys{\'e} manuellement."
2020.jeptalnrecital-demos.19,Analyse s{\\'e}mantique robuste par apprentissage antagoniste pour la g{\\'e}n{\\'e}ralisation de domaine (Robust Semantic Parsing with Adversarial Learning for Domain Generalization ),2020,-1,-1,2,1,184,gabriel marzinotto,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 4 : D{\\'e}monstrations et r{\\'e}sum{\\'e}s d'articles internationaux",0,"Nous pr{\'e}sentons des r{\'e}sum{\'e}s en fran{\c{c}}ais et en anglais de l{'}article (Marzinotto et al., 2019) pr{\'e}sent{\'e} {\`a} la conf{\'e}rence North American Chapter of the Association for Computational Linguistics : Human Language Technologies en 2019."
W19-5914,Spoken Conversational Search for General Knowledge,2019,9,0,9,0,8200,lina barahona,Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue,0,We present a spoken conversational question answering proof of concept that is able to answer questions about general knowledge from Wikidata. The dialogue agent does not only orchestrate various agents but also solve coreferences and ellipsis.
W19-5121,The Impact of Word Representations on Sequential Neural {MWE} Identification,2019,0,0,3,0,23917,nicolas zampieri,Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019),0,"Recent initiatives such as the PARSEME shared task allowed the rapid development of MWE identification systems. Many of those are based on recent NLP advances, using neural sequence models that take continuous word representations as input. We study two related questions in neural MWE identification: (a) the use of lemmas and/or surface forms as input features, and (b) the use of word-based or character-based embeddings to represent them. Our experiments on Basque, French, and Polish show that character-based representations yield systematically better results than word-based ones. In some cases, character-based representations of surface forms can be used as a proxy for lemmas, depending on the morphological complexity of the language."
S19-2015,{M}ask{P}arse@Deskin at {S}em{E}val-2019 Task 1: Cross-lingual {UCCA} Semantic Parsing using Recursive Masked Sequence Tagging,2019,0,0,3,1,184,gabriel marzinotto,Proceedings of the 13th International Workshop on Semantic Evaluation,0,"This paper describes our recursive system for SemEval-2019 Task 1: Cross-lingual Semantic Parsing with UCCA. Each recursive step consists of two parts. We first perform semantic parsing using a sequence tagger to estimate the probabilities of the UCCA categories in the sentence. Then, we apply a decoding policy which interprets these probabilities and builds the graph nodes. Parsing is done recursively, we perform a first inference on the sentence to extract the main scenes and links and then we recursively apply our model on the sentence using a masking features that reflects the decisions made in previous steps. Process continues until the terminal nodes are reached. We chose a standard neural tagger and we focus on our recursive parsing strategy and on the cross lingual transfer problem to develop a robust model for the French language, using only few training samples"
N19-2021,Robust Semantic Parsing with Adversarial Learning for Domain Generalization,2019,22,3,2,1,184,gabriel marzinotto,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",0,"This paper addresses the issue of generalization for Semantic Parsing in an adversarial framework. Building models that are more robust to inter-document variability is crucial for the integration of Semantic Parsing technologies in real applications. The underlying question throughout this study is whether adversarial learning can be used to train models on a higher level of abstraction in order to increase their robustness to lexical and stylistic variations. We propose to perform Semantic Parsing with a domain classification adversarial task, covering various use-cases with or without explicit knowledge of the domain. The strategy is first evaluated on a French corpus of encyclopedic documents, annotated with FrameNet, in an information retrieval perspective. This corpus constitutes a new public benchmark, gathering documents from various thematic domains and various sources. We show that adversarial learning yields improved results when using explicit domain classification as the adversarial task. We also propose an unsupervised domain discovery approach that yields equivalent improvements. The latter is also evaluated on a PropBank Semantic Role Labeling task on the CoNLL-2005 benchmark and is shown to increase the model{'}s generalization capabilities on out-of-domain data."
D19-5803,{CALOR}-{QUEST} : generating a training corpus for Machine Reading Comprehension models from shallow semantic annotations,2019,0,0,4,0,17997,frederic bechet,Proceedings of the 2nd Workshop on Machine Reading for Question Answering,0,"Machine reading comprehension is a task related to Question-Answering where questions are not generic in scope but are related to a particular document. Recently very large corpora (SQuAD, MS MARCO) containing triplets (document, question, answer) were made available to the scientific community to develop supervised methods based on deep neural networks with promising results. These methods need very large training corpus to be efficient, however such kind of data only exists for English and Chinese at the moment. The aim of this study is the development of such resources for other languages by proposing to generate in a semi-automatic way questions from the semantic Frame analysis of large corpora. The collect of natural questions is reduced to a validation/test set. We applied this method on the CALOR-Frame French corpus to develop the CALOR-QUEST resource presented in this paper."
2019.jeptalnrecital-court.4,{CALOR}-{QUEST} : un corpus d{'}entra{\\^\\i}nement et d{'}{\\'e}valuation pour la compr{\\'e}hension automatique de textes (Machine reading comprehension is a task related to Question-Answering where questions are not generic in scope but are related to a particular document),2019,-1,-1,4,0,17997,frederic bechet,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume II : Articles courts,0,"La compr{\'e}hension automatique de texte est une t{\^a}che faisant partie de la famille des syst{\`e}mes de Question/R{\'e}ponse o{\`u} les questions ne sont pas {\`a} port{\'e}e g{\'e}n{\'e}rale mais sont li{\'e}es {\`a} un document particulier. R{\'e}cemment de tr{\`e}s grand corpus (SQuAD, MS MARCO) contenant des triplets (document, question, r{\'e}ponse) ont {\'e}t{\'e} mis {\`a} la disposition de la communaut{\'e} scientifique afin de d{\'e}velopper des m{\'e}thodes supervis{\'e}es {\`a} base de r{\'e}seaux de neurones profonds en obtenant des r{\'e}sultats prometteurs. Ces m{\'e}thodes sont cependant tr{\`e}s gourmandes en donn{\'e}es d{'}apprentissage, donn{\'e}es qui n{'}existent pour le moment que pour la langue anglaise. Le but de cette {\'e}tude est de permettre le d{\'e}veloppement de telles ressources pour d{'}autres langues {\`a} moindre co{\^u}t en proposant une m{\'e}thode g{\'e}n{\'e}rant de mani{\`e}re semi-automatique des questions {\`a} partir d{'}une analyse s{\'e}mantique d{'}un grand corpus. La collecte de questions naturelle est r{\'e}duite {\`a} un ensemble de validation/test. L{'}application de cette m{\'e}thode sur le corpus CALOR-Frame a permis de d{\'e}velopper la ressource CALOR-QUEST pr{\'e}sent{\'e}e dans cet article."
L18-1014,Handling Normalization Issues for Part-of-Speech Tagging of Online Conversational Text,2018,0,1,1,1,188,geraldine damnati,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"For the purpose of POS tagging noisy user-generated text, should normalization be handled as a preliminary task or is it possiblen to handle misspelled words directly in the POS tagging model? We propose in this paper a combined approach where some errorsn are normalized before tagging, while a Gated Recurrent Unit deep neural network based tagger handles the remaining errors. Wordn embeddings are trained on a large corpus in order to address both normalization and POS tagging. Experiments are run on Contactn Center chat conversations, a particular type of formal Computer Mediated Communication data."
L18-1159,Semantic Frame Parsing for Information Extraction : the {CALOR} corpus,2018,0,4,4,1,184,gabriel marzinotto,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"This paper presents a publicly available corpus of French encyclopedic history texts annotated according to the Berkeley FrameNet formalism. The main difference in our approach compared to previous works on semantic parsing with FrameNet is that we are not interested here in full text parsing but rather on partial parsing. The goal is to select from the FrameNet resources the minimal set of frames that are going to be useful for the applicative framework targeted, in our case Information Extraction from encyclopedic documents. Such an approach leverages the manual annotation of larger corpora than those obtained through full text parsing and therefore opens the door to alternative methods for Frame parsing than those used so far on the FrameNet 1.5 benchmark corpus. The approaches compared in this study rely on an integrated sequence labeling model which jointly optimizes frame identification and semantic role segmentation and identification. The models compared are CRFs and multitasks bi-LSTMs."
L18-1329,{F}r{N}ews{L}ink : a corpus linking {TV} Broadcast News Segments and Press Articles,2018,0,0,2,0.527559,17732,nathalie camelin,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
2018.jeptalnrecital-court.4,Evaluation automatique de la satisfaction client {\\`a} partir de conversations de type {``}chat{''} par r{\\'e}seaux de neurones r{\\'e}currents avec m{\\'e}canisme d{'}attention (Customer satisfaction prediction with attention-based {RNN}s from a chat contact center corpus),2018,-1,-1,3,0,27341,jeremy auguste,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,Cet article pr{\'e}sente des m{\'e}thodes permettant l{'}{\'e}valuation de la satisfaction client {\`a} partir de tr{\`e}s vastes corpus de conversation de type {``}chat{''} entre des clients et des op{\'e}rateurs. Extraire des connaissances dans ce contexte demeure un d{\'e}fi pour les m{\'e}thodes de traitement automatique des langues de par la dimension interactive et les propri{\'e}t{\'e}s de ce nouveau type de langage {\`a} l{'}intersection du langage {\'e}crit et parl{\'e}. Nous pr{\'e}sentons une {\'e}tude utilisant des r{\'e}ponses {\`a} des sondages utilisateurs comme supervision faible permettant de pr{\'e}dire la satisfaction des usagers d{'}un service en ligne d{'}assistance technique et commerciale.
2018.jeptalnrecital-court.23,Predicting failure of a mediated conversation in the context of asymetric role dialogues,2018,-1,-1,3,0,23748,romain carbou,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"In a human-to-human conversation between a user and his interlocutor in an assistance center, we suppose a context where the conclusion of the dialog can characterize a notion of success or failure, explicitly annotated or deduced. The study involves different approaches expected to have an influence on predictive classification model of failures. On the one hand, we will aim at taking into account the asymmetry of the speakers{'} roles in the modelling of the lexical distribution. On the other hand, we will determine whether the part of the lexicon most closely relating to the domain of customer assistance studied here, modifies the quality of the prediction. We will eventually assess the perspectives of generalization to morphologically comparable corpora."
S17-2051,{S}im{B}ow at {S}em{E}val-2017 Task 3: Soft-Cosine Semantic Similarity between Questions for Community Question Answering,2017,0,19,2,1,17730,delphine charlet,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper describes the SimBow system submitted at SemEval2017-Task3, for the question-question similarity subtask B. The proposed approach is a supervised combination of different unsupervised textual similarities. These textual similarities rely on the introduction of a relation matrix in the classical cosine similarity between bag-of-words, so as to get a soft-cosine that takes into account relations between words. According to the type of relation matrix embedded in the soft-cosine, semantic or lexical relations can be considered. Our system ranked first among the official submissions of subtask B."
2017.jeptalnrecital-demo.5,Apprentissage d{'}agents conversationnels pour la gestion de relations clients (Training chatbots for customer relation management),2017,-1,-1,3,0,14954,benoit favre,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 3 - D{\\'e}monstrations,0,"Ce travail d{\'e}montre la faisabilit{\'e} d{'}entra{\^\i}ner des chatbots sur des traces de conversations dans le domaine de la relation client. Des syst{\`e}mes {\`a} base de mod{\`e}les de langage, de recherche d{'}information et de traduction sont compar{\'e}s pour la t{\^a}che."
2017.jeptalnrecital-court.6,Analyse automatique {F}rame{N}et : une {\\'e}tude sur un corpus fran{\\c{c}}ais de textes encyclop{\\'e}diques ({F}rame{N}et automatic analysis : a study on a {F}rench corpus of encyclopedic texts),2017,-1,-1,2,1,184,gabriel marzinotto,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 2 - Articles courts,0,"Cet article pr{\'e}sente un syst{\`e}me d{'}analyse automatique en cadres s{\'e}mantiques {\'e}valu{\'e} sur un corpus de textes encyclop{\'e}diques d{'}histoire annot{\'e}s selon le formalisme FrameNet. L{'}approche choisie repose sur un mod{\`e}le int{\'e}gr{\'e} d{'}{\'e}tiquetage de s{\'e}quence qui optimise conjointement l{'}identification des cadres, la segmentation et l{'}identification des r{\^o}les s{\'e}mantiques associ{\'e}s. Nous cherchons dans cette {\'e}tude {\`a} analyser la complexit{\'e} de la t{\^a}che selon plusieurs dimensions. Une analyse d{\'e}taill{\'e}e des performances du syst{\`e}me est ainsi propos{\'e}e, {\`a} la fois selon l{'}angle des param{\`e}tres du mod{\`e}le et de la nature des donn{\'e}es."
2017.jeptalnrecital-court.16,Simbow : une mesure de similarit{\\'e} s{\\'e}mantique entre textes (Simbow : a semantic similarity metric between texts),2017,-1,-1,2,1,17730,delphine charlet,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 2 - Articles courts,0,"Cet article d{\'e}crit une mesure de similarit{\'e} s{\'e}mantique non-supervis{\'e}e qui repose sur l{'}introduction d{'}une matrice de relations entre mots, dans un paradigme de mesure cosinus entre sacs de mots. La m{\'e}trique obtenue, apparent{\'e}e {\`a} soft-cosinus, tient compte des relations entre mots qui peuvent {\^e}tre d{'}ordre lexical ou s{\'e}mantique selon la matrice consid{\'e}r{\'e}e. La mise en {\oe}uvre de cette m{\'e}trique sur la t{\^a}che qui consiste {\`a} mesurer des similarit{\'e}s s{\'e}mantiques entre questions pos{\'e}es sur un forum, a remport{\'e} la campagne d{'}{\'e}valuation SemEval2017. Si l{'}approche soumise {\`a} la campagne est une combinaison supervis{\'e}e de diff{\'e}rentes mesures non-supervis{\'e}es, nous pr{\'e}sentons dans cet article en d{\'e}tail les m{\'e}triques non-supervis{\'e}es, qui pr{\'e}sentent l{'}avantage de produire de bons r{\'e}sultats sans n{\'e}cessiter de ressources sp{\'e}cifiques autres que des donn{\'e}es non annot{\'e}es du domaine consid{\'e}r{\'e}."
W16-3621,Syntactic parsing of chat language in contact center conversation corpus,2016,12,3,2,0,5812,alexis nasr,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Chat language is often referred to as Computer-mediated communication (CMC). Most of the previous studies on chat language has been dedicated to collecting  chat room  data as it is the kind of data which is the most accessible on the WEB. This kind of data falls under the informal register whereas we are interested in this paper in understanding the mechanisms of a more formal kind of CMC: dialog chat in contact centers. The particularities of this type of dialogs and the type of language used by customers and agents is the focus of this paper towards understanding this new kind of CMC data. The challenges for processing chat data comes from the fact that Natural Language Processing tools such as syntactic parsers and part of speech taggers are typically trained on mismatched conditions, we describe in this study the impact of such a mismatch for a syntactic parsing task."
L16-1319,Web Chat Conversations from Contact Centers: a Descriptive Study,2016,0,2,1,1,188,geraldine damnati,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this article we propose a descriptive study of a chat conversations corpus from an assistance contact center. Conversations are described from several view points, including interaction analysis, language deviation analysis and typographic expressivity marks analysis. We provide in particular a detailed analysis of language deviations that are encountered in our corpus of 230 conversations, corresponding to 6879 messages and 76839 words. These deviations may be challenging for further syntactic and semantic parsing. Analysis is performed with a distinction between Customer messages and Agent messages. On the overall only 4{\%} of the observed words are misspelled but 26{\%} of the messages contain at least one erroneous word (rising to 40{\%} when focused on Customer messages). Transcriptions of telephone conversations from an assistance call center are also studied, allowing comparisons between these two interaction modes to be drawn. The study reveals significant differences in terms of conversation flow, with an increased efficiency for chat conversations in spite of longer temporal span."
2016.jeptalnrecital-demo.7,Exploration de collections d{'}archives multim{\\'e}dia dans le contexte des Humanit{\\'e}s Num{\\'e}riques : revisiter {TALN}{'}2015 ? (Exploring multimedia archives in the context of Digital Humanities: browsing {TALN}{'}2015?),2016,-1,-1,1,1,188,geraldine damnati,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 5 : D{\\'e}monstrations,0,"Cette d{\'e}monstration pr{\'e}sente un prototype d{'}exploration de contenus multim{\'e}dias d{\'e}velopp{\'e} dans le but de faciliter l{'}acc{\`e}s aux contenus de la Connaissance. Apr{\`e}s une extraction automatique de m{\'e}tadonn{\'e}es, les contenus sont index{\'e}s et accessibles via un moteur de recherche sp{\'e}cifique. Des fonctionnalit{\'e}s innovantes de navigation {\`a} l{'}int{\'e}rieur des contenus sont {\'e}galement pr{\'e}sent{\'e}es. La collection des enregistrements vid{\'e}o de TALN{'}2015 sert de support privil{\'e}gi{\'e} {\`a} cette d{\'e}monstration."
2015.jeptalnrecital-court.26,Entre {\\'e}crit et oral ? Analyse compar{\\'e}e de conversations de type tchat et de conversations t{\\'e}l{\\'e}phoniques dans un centre de contact client,2015,-1,-1,1,1,188,geraldine damnati,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Dans cet article nous proposons une premi{\`e}re {\'e}tude descriptive d{'}un corpus de conversations de type tchat issues d{'}un centre de contact d{'}assistance. Les dimensions lexicales, syntaxiques et interactionnelles sont analys{\'e}es. L{'}{\'e}tude parall{\`e}le de transcriptions de conversations t{\'e}l{\'e}phoniques issues d{'}un centre d{'}appel dans le m{\^e}me domaine de l{'}assistance permet d{'}{\'e}tablir des comparaisons entre ces deux modes d{'}interaction. L{'}analyse r{\'e}v{\`e}le des diff{\'e}rences marqu{\'e}es en termes de d{\'e}roulement de la conversation, avec une plus grande efficacit{\'e} pour les conversations de type tchat malgr{\'e} un plus grand {\'e}talement temporel. L{'}analyse lexicale et syntaxique r{\'e}v{\`e}le {\'e}galement des diff{\'e}rences de niveaux de langage avec une plus grande proximit{\'e} entre le client et le t{\'e}l{\'e}conseiller {\`a} l{'}oral que pour les tchats o{\`u} le d{\'e}calage entre le style adopt{\'e} par le t{\'e}l{\'e}conseiller et l{'}expression du client est plus important."
2015.jeptalnrecital-court.33,Segmentation et Titrage Automatique de Journaux T{\\'e}l{\\'e}vis{\\'e}s,2015,-1,-1,2,1,24123,abdessalam bouchekif,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Dans cet article, nous nous int{\'e}ressons au titrage automatique des segments issus de la segmentation th{\'e}matique de journaux t{\'e}l{\'e}vis{\'e}s. Nous proposons d{'}associer un segment {\`a} un article de presse {\'e}crite collect{\'e} le jour m{\^e}me de la diffusion du journal. La t{\^a}che consiste {\`a} apparier un segment {\`a} un article de presse {\`a} l{'}aide d{'}une mesure de similarit{\'e}. Cette approche soul{\`e}ve plusieurs probl{\`e}mes, comme la s{\'e}lection des articles candidats, une bonne repr{\'e}sentation du segment et des articles, le choix d{'}une mesure de similarit{\'e} robuste aux impr{\'e}cisions de la segmentation. Des exp{\'e}riences sont men{\'e}es sur un corpus vari{\'e} de journaux t{\'e}l{\'e}vis{\'e}s fran{\c{c}}ais collect{\'e}s pendant une semaine, conjointement avec des articles aspir{\'e}s {\`a} partir de la page d{'}accueil de Google Actualit{\'e}s. Nous introduisons une m{\'e}trique d{'}{\'e}valuation refl{\'e}tant la qualit{\'e} de la segmentation, du titrage ainsi que la qualit{\'e} conjointe de la segmentation et du titrage. L{'}approche donne de bonnes performances et se r{\'e}v{\`e}le robuste {\`a} la segmentation th{\'e}matique."
F13-2030,An iterative topic segmentation algorithm with intra-content term weighting (Segmentation th{\\'e}matique : processus it{\\'e}ratif de pond{\\'e}ration intra-contenu) [in {F}rench],2013,0,0,2,1,24123,abdessalam bouchekif,Proceedings of TALN 2013 (Volume 2: Short Papers),0,None
F12-5002,Interfaces de navigation dans des contenus audio et vid{\\'e}o (Navigation interfaces through audio and video contents) [in {F}rench],2012,0,0,1,1,188,geraldine damnati,"Proceedings of the Joint Conference {JEP}-{TALN}-{RECITAL} 2012, volume 5: Software Demonstrations",0,None
F12-1070,Percol0 - un syst{\\`e}me multimodal de d{\\'e}tection de personnes dans des documents vid{\\'e}o (Percol0 - A multimodal person detection system in video documents) [in {F}rench],2012,-1,-1,5,0,17997,frederic bechet,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 1: JEP",0,None
F12-1102,D{\\'e}tection et caract{\\'e}risation des r{\\'e}gions d{'}erreurs dans des transcriptions de contenus multim{\\'e}dia : application {\\`a} la recherche des noms de personnes (Error region detection and characterization in transcriptions of multimedia documents : application to person name search) [in {F}rench],2012,-1,-1,2,0,16966,richard dufour,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 1: JEP",0,None
C08-1056,Normalizing {SMS}: are Two Metaphors Better than One ?,2008,17,124,3,0,27334,catherine kobus,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"Electronic written texts used in computermediated interactions (e-mails, blogs, chats, etc) present major deviations from the norm of the language. This paper presents an comparative study of systems aiming at normalizing the orthography of French SMS messages: after discussing the linguistic peculiarities of these messages, and possible approaches to their automatic normalization, we present, evaluate and contrast two systems, one drawing inspiration from the Machine Translation task; the other using techniques that are commonly used in automatic speech recognition devices. Combining both approaches, our best normalization system achieves about 11% Word Error Rate on a test set of about 3000 unseen messages."
2008.jeptalnrecital-long.13,Transcrire les {SMS} comme on reconna{\\^\\i}t la parole,2008,-1,-1,3,0,27334,catherine kobus,Actes de la 15{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente une architecture inspir{\'e}e des syst{\`e}mes de reconnaissance vocale pour effectuer une normalisation orthographique de messages en Â« langage SMS Â». Nous d{\'e}crivons notre syst{\`e}me de base, ainsi que diverses {\'e}volutions de ce syst{\`e}me, qui permettent d{'}am{\'e}liorer sensiblement la qualit{\'e} des normalisations produites."
W07-0307,Experiments on the {F}rance Telecom 3000 Voice Agency corpus: academic research on an industrial spoken dialog system,2007,11,1,1,1,188,geraldine damnati,Proceedings of the Workshop on Bridging the Gap: Academic and Industrial Research in Dialog Technologies,0,"The recent advances in speech recognition technologies, and the experience acquired in the development of WEB or Interactive Voice Response interfaces, have facilitated the integration of speech modules in robust Spoken Dialog Systems (SDS), leading to the deployment on a large scale of speech-enabled services. With these services it is possible to obtain very large corpora of human-machine interactions by collecting system logs. This new kinds of systems and dialogue corpora offer new opportunities for academic research while raising two issues: How can academic research take profit of the system logs of deployed SDS in order to build the next generation of SDS, although the dialogues collected have a dialogue flow constrained by the previous SDS generation? On the other side, what immediate benefits can academic research offer for the improvement of deployed system? This paper addresses these aspects in the framework of the deployed France Telecom 3000 Voice Agency service."
2007.jeptalnrecital-poster.6,Analyse automatique de sondages t{\\'e}l{\\'e}phoniques d{'}opinion,2007,-1,-1,3,0.527559,17732,nathalie camelin,Actes de la 14{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Cette {\'e}tude pr{\'e}sente la probl{\'e}matique de l{'}analyse automatique de sondages t{\'e}l{\'e}phoniques d{'}opinion. Cette analyse se fait en deux {\'e}tapes : tout d{'}abord extraire des messages oraux les expressions subjectives relatives aux opinions de utilisateurs sur une dimension particuli{\`e}re (efficacit{\'e}, accueil, etc.) ; puis s{\'e}lectionner les messages fiables, selon un ensemble de mesures de confiance, et estimer la distribution des diverses opinions sur le corpus de test. Le but est d{'}estimer une distribution aussi proche que possible de la distribution de r{\'e}f{\'e}rence. Cette {\'e}tude est men{\'e}e sur un corpus de messages provenant de vrais utilisateurs fournis par France T{\'e}l{\'e}com R{\&}D."
W04-2321,On the Use of Confidence for Statistical Decision in Dialogue Strategies,2004,9,8,4,0,27857,christian raymond,Proceedings of the 5th {SIG}dial Workshop on Discourse and Dialogue at {HLT}-{NAACL} 2004,0,"This paper describes an interpretation and decision strategy that minimizes interpretation errors and perform dialogue actions which may not depend on the hypothesized concepts only, but also on confidence of what has been recognized. The concepts introduced here are applied in a system which integrates language and interpretation models into Stochastic Finite State Transducers (SFST). Furthermore, acoustic, linguistic and semantic confidence measures on the hypothesized word sequences are made available to the dialogue strategy. By evaluating predicates related to these confidence measures, a decision tree automatically learn a decision strategy for rescoring a n-best list of candidates representing a userxe2x80x99s utterance. The different actions that can be then performed are chosen according to the confidence scores given by the tree."
