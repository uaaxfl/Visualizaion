2020.cl-4.4,K18-2017,0,0.0579845,"Missing"
2020.cl-4.4,D07-1022,0,0.121604,"Missing"
2020.cl-4.4,P18-1128,0,0.0769783,"Missing"
2020.cl-4.4,N18-1033,0,0.162037,"1998; LeCun et al. 2007). In the lattice structure, the candidate links only to its adjacent nodes in an exhaustive segmentation. We also generate edge vectors for the dummy nodes that act as the start and end markers in the lattice. We use the PRA vectors as the edge vectors for the model. During prediction, we have to find the best path from the lattice that minimizes the sentence score. Here, we consider two variants of Lattice-EBM. VL-EBM uses the discriminative forward training approach (Collobert et al. 2011) with the standard hinge loss. The second variant BL-EBM uses multimargin loss (Edunov et al. 2018) instead of the hinge loss. Here, we employ beam search to generate multiple candidates as required by the loss. Prim-EBM-P. This is also a configuration of the EBM, where the model uses the input graph X from SHR, PRA vectors for the edges, and modified Prim’s algorithm as the inference. The inference procedure searches for a Steiner Tree (Takahashi 1980) from the input graph X. Prim’s algorithm acts as an approximation algorithm to find the Directed Steiner tree (Voss 1993). The Steiner tree essentially spans over a subset of nodes, and by graph construction it is guaranteed that the inferen"
2020.cl-4.4,D15-1173,0,0.0748112,"Missing"
2020.cl-4.4,N10-1115,0,0.0658644,"e case markers of the nominals and the valency of the verb to infer the structural information of the sentence (Kiparsky and Staal 1969; Ramkrishnamacharyulu 2009). Figure 4 shows the dependency analysis for the reference sentence. For presentational clarity, the figure uses the prose word ordering (anvaya of the verse) rather than the original verse order. The sentences in prose 9 https://bit.ly/3hKLZT9. 793 Computational Linguistics Volume 46, Number 4 Figure 4 Dependency analysis for the reference sentence. The k¯araka tags as per the dependency tagging scheme of Kulkarni, Pokar, and Shukl (2010) are shown as the edge labels in the figure. For presentational clarity, the figure uses the word ordering from the anvaya of the verse. The numbers in the boxes indicate the position of the word (from left) in the original word order in the verse. The corresponding English translation for the tags are: Hetuh. – Cause; Karma – Object; Kart¯a – Subject; Nis.edhah. – Negation; Sambandhah. – Relation; Samuccitam – Conjunction; Sas.t˙ h¯ısamsambandhah. – Genitive or possessive relation; Vi`ses.an.am – Adjectival modifier.10 in Sanskrit tend to follow weak non-projectivity in their dependency analy"
2020.cl-4.4,P08-1043,0,0.054453,"(Yang, Zhang, and Liang 2019) and in morphological parsing of morphologically rich ˘ 2015; More 2016; More et al. 2019). languages (Seeker and C ¸ etinoglu ¨ Transition-based approaches (Kubler, McDonald, and Nivre 2009) and graph-based approaches (McDonald et al. 2005b) are primarily two approaches adopted for DP. The majority of the methods proposed for joint morphosyntactic parsing also fall into one of these categories. Such approaches have proven to be effective for a host of morphologically rich languages such as Hebrew, Turkish, Czech, Finnish, Arabic, and so on. (Cohen and Smith 2007; Goldberg and Tsarfaty 2008; Bohnet et al. 2013). Hatori et al. (2012) formulated the problem of joint word segmentation, POS tagging, and DP in ˘ (2015) performed Chinese using a transition-based framework. Seeker and C ¸ etinoglu the joint morphological segmentation and analysis along with DP for Hebrew and Turkish. The approach constructs a sentence-level graph with word-level morphological lattices and performs a dual decomposition wherein the predicted dependency tree and the morphological paths need to be arrived at an agreement for the final solution. Recently, More et al. (2019) proposed a transition-based frame"
2020.cl-4.4,J01-2001,0,0.0989715,"considered the word segmentation as a multitask problem, using a common encoder with two decoders, where one decoder predicts the split location and the other is used to generate the characters in the split word. Both word segmentation and morphological parsing are low-level, yet non-trivial tasks for multiple languages and are extensively researched in NLP. Traditionally, solutions for these tasks were proposed using (Probabilistic/Weighted) finite-state transducers (Kaplan and Kay 1981; Sproat et al. 1996; Mohri 1997; Beesley et al. 2003) and using unsupervised pattern discovery approaches (Goldsmith 2001; Argamon et al. 2004; Johnson and Goldwater 2009). Broadly, these approaches could be categorized as lexicon driven (Huet 2003; Chen and Liu 1992), purely statistical (Eisner 2002; Sproat et al. 1994), or both (Sproat et al. 1996). Sequence labeling approaches such as HMMs (Hakkani-Tur, Oflazer, and Tur 2000) and CRFs (Smith, Smith, and Tromble 2005; Xue 2003) were later proposed for these tasks. Further, lattice parsing-based approaches, where the input search space was represented as word-level lattices, were incorporated into CRFs (Smith, Smith, and Tromble 2005) for joint modeling of thes"
2020.cl-4.4,C00-1042,0,0.475461,"Missing"
2020.cl-4.4,P12-1110,0,0.0655918,"Missing"
2020.cl-4.4,P09-1091,0,0.0402347,"o and Cohen 2010), a random walk based approach for learning horn clauses across a heterogeneous information network (HIN). The type of horn clauses mentioned in PRA is widely known as metapaths (Sun 2010) in HINs (Shi et al. 2017). Traditionally, metapaths, like feature engineering, were manually constructed. But, recent approaches such as PRA and FSPG (Meng et al. 2015) automate the generation of metapaths. Word linearization has been used in various Natural Language Generation tasks for the past three decades. Linearization tasks are generally solved by incorporating syntactic information (He et al. 2009), semantic information (Puduppully, Zhang, and Shrivastava 2017), or by using language models (Hasler et al. 2017). Syntactic linearization can further be categorized into full tree linearizaton (Zhang and Clark 2015; He et al. 2009) or partial tree linearization (Zhang 2013) depending on the amount of syntactic information used in the method. In language model-based linearization approaches, purely distributional information is used for the task. Recently, such approaches have been shown to outperform syntax-based linearization approaches in English (Schmaltz, Rush, and Shieber 2016; Wiseman"
2020.cl-4.4,D18-1295,0,0.235107,"valid segmentations for the reference sentence based on the analysis from SHR. The candidate segments are color coded by SHR based on their lexical categories. Blue for substantives, red for finite verb-forms, mauve for indeclinables, and yellow for all the non-final components of a compound. Cyan is used for those inflected-forms that can only be used as the final component of a compound (Goyal and Huet 2016). The numbered boxes indicate the morphological analysis as per SHR for the inflected forms ya`sa¯ h. and pituh.. segmentation, similar to previous word segmentation models in Sanskrit (Hellwig and Nehrdich 2018; Reddy et al. 2018). The knowledge of the individual components of a compound will help in its analysis in downstream tasks, and hence is important for processing Sanskrit corpora abundant with multicomponent compounds. The analysis of a sequence with fused words can lead to ambiguity in identifying the original words in the sequence. Goyal and Huet (2016) propose Sanskrit Heritage Reader (SHR), a lexicon driven shallow parser that encodes all the rules of sandhi as per traditional Sanskrit grammar.6 SHR can enumerate all possible lexically valid segmentations for a given sequence. Figure 3 s"
2020.cl-4.4,E14-3010,0,0.0221797,"f pretrained word embeddings (Kiela, Wang, and Cho 2018); and, second, a component for generating multiple ordering hypotheses (Wang, Chang, and Mansur 2018) to be used as input to the seq2seq component. The model currently reports the state-of-the-art results for syntactic linearization in Sanskrit. EBM-Based Configurations (Beam-EBM-F/ATSP-EBM-F). Here, for both the syntax-level and prosody-level linearization tasks, we use the exact same EBM configurations. The only difference will be in the input graph representation. For the tasks, we experimented with two different inference procedures. Horvat and Byrne (2014) proposed to solve the task of linearization as that of solving the Asymmetric Traveling Salesman Problem (ATSP) over a graph. We incorporate the same as our inference procedure in the ATSPEBM-F configuration. Inspired from the works of Schmaltz, Rush, and Shieber (2016) along with Wiseman and Rush (2016), we use beam search as the approximate inference in the Beam-EBM-F procedure. We also report the performance score for Beam-EBM*F, which incorporates the language-specific augmentations as discussed in Section 3.4. This configuration is used only for the syntactic linearization task. 4.2.5 Ed"
2020.cl-4.4,C14-2011,0,0.0509572,"Missing"
2020.cl-4.4,K18-2013,0,0.0690857,"ions in morphologically rich languages (MRLs), such as Sanskrit, generally rely on morphological markers to encode the grammatical information (Tsarfaty, Sima’an, and Scha 2009). This makes Sanskrit a relatively free word order language (Staal 1967; Gillon and Shaer 2005). In fact, the same sentence follows a different word order when written as a verse, as compared to the word order in prose (Tubb and Boose 2007). However, the sentence will still maintain the same syntactic analysis, irrespective of its varying word orders (Scharf et al. 2015; Gillon and Shaer 2005). Recently, Krishna et al. (2018) have shown that approaches for non-sequential processing of Sanskrit sentences result in better system performance even for lowlevel tasks such as word-segmentation and morphological parsing. In this work, we extend the energy-based model (EBM) for joint modeling of word segmentation and morphological parsing proposed by Krishna et al. (2018) into a general graph-based parsing framework for multiple structured prediction tasks in Sanskrit. We extend the framework to include two downstream syntax-level tasks, dependency parsing and syntactic linearization. We also introduce the prosodification"
2020.cl-4.4,D18-1176,0,0.0222894,"Missing"
2020.cl-4.4,Q16-1023,0,0.0733723,"g. The parsing procedure is initialized with all the words in a sentence. The system iteratively forms partial structures by merging existing partial structures, where only the head partial structure is retained in the list of structures available for merging. The procedure terminates when there is exactly one structure remaining, which corresponds to the root of the sentence. Neural Graph-Based Dependency Parsers (NeurDP). We experiment with two neural dependency parsers, the deep biaffine attention-based model of Dozat and Manning (2017) and the neural graph-based dependency parser based on Kiperwasser and Goldberg (2016a). Both the models rely on LSTM-based feature extractors for the parsing. EBM Configurations. Our EBM configurations are basically graph-based parsing framework for dependency parsing. Here, similar to McDonald et al. (2005b), we use Edmond-Chu-Liu’s algorithm for finding arborescence (directed spanning tree) of minimum weight.30 We experiment with three variations: Tree-EBM-P, Tree-EBM-F, and Tree-EBM*-F. Tree-EBM-P uses PRA vectors as the edge vectors, and Tree-EBM-F uses the edge vectors using FSPG. Here, Tree-EBM*-F incorporates the language-specific 30 While McDonald et al. (2005b) used"
2020.cl-4.4,W19-4203,0,0.0597012,"Missing"
2020.cl-4.4,D18-1276,1,0.0660607,"tence constructions in morphologically rich languages (MRLs), such as Sanskrit, generally rely on morphological markers to encode the grammatical information (Tsarfaty, Sima’an, and Scha 2009). This makes Sanskrit a relatively free word order language (Staal 1967; Gillon and Shaer 2005). In fact, the same sentence follows a different word order when written as a verse, as compared to the word order in prose (Tubb and Boose 2007). However, the sentence will still maintain the same syntactic analysis, irrespective of its varying word orders (Scharf et al. 2015; Gillon and Shaer 2005). Recently, Krishna et al. (2018) have shown that approaches for non-sequential processing of Sanskrit sentences result in better system performance even for lowlevel tasks such as word-segmentation and morphological parsing. In this work, we extend the energy-based model (EBM) for joint modeling of word segmentation and morphological parsing proposed by Krishna et al. (2018) into a general graph-based parsing framework for multiple structured prediction tasks in Sanskrit. We extend the framework to include two downstream syntax-level tasks, dependency parsing and syntactic linearization. We also introduce the prosodification"
2020.cl-4.4,W17-2214,1,0.766976,"Missing"
2020.cl-4.4,W13-3718,0,0.719486,"e experiment with EBM configurations where we incorporate such language-specific constraints for the dependency parsing and syntactic linearization. The linguistic information is made to use both in pruning the search space and in filtering the candidates during the inference. Essentially, these constraints can be seen as higher order features that capture constraints that span beyond a pair of words. For dependency parsing we rely on the linguistic information from rule-based dependency analyzers proposed for Sanskrit (Kulkarni, Pokar, and Shukl 2010; Kulkarni and Ramakrishnamacharyulu 2013; Kulkarni 2013). In the language-agnostic version of dependency parsing we form a complete graph as input. However, several of these edges might not be valid as per the traditional Sanskrit grammar. Such invalid edges can be determined and pruned using the linguistic information from the grammar, already used in the aforementioned rule-based dependency parsers. For several MRLs, including Sanskrit, morphological markers are indicative of the presence and also the type of syntactic dependency between the words in a sentence (Nichols 1986; Seeker and Kuhn 2013). Further, morphological markers may also be indic"
2020.cl-4.4,W19-7724,0,0.139566,"tion. The word order divergences between the verse and the corresponding anvaya at a syntactic level can be assessed using the following three aspects. First, Sanskrit sentences in their prose order tend to follow SOV typology (Hock 2015). In the reference sentence, as shown in Figure 4, 10 “Sambandhah.” translates to relation. This coarse-level tag is included in the tagging scheme, to assign to those cases which require extra-syntactic factors for resolving the exact fine-grained relation. For a more detailed understanding of the tagging scheme and k¯araka theory in general, please refer to Kulkarni and Sharma (2019) or Kulkarni, Pokar, and Shukl (2010). 11 We use the terms anvaya and prose order interchangeably in this work. 794 Krishna et al. A Graph-Based Framework for Structured Prediction Tasks in Sanskrit Figure 5 Instances of syntactic linearization and prosodification from a BoW input. In prosodification, sandhi may be essential at specific word boundaries to adhere to metrical constraints. However, sandhi is purely optional in sentences in prose order. Figure 6 Syllable-level segmentation, along with the syllable weights for (a) verse in its original form; (b) verse with segmented word boundaries"
2020.cl-4.4,E17-1117,0,0.0198716,"k 2011), which encompasses a joint transition system, training objective, and inference for the morphological processing and syntactic parsing tasks. The system outperforms their previous standalone transition-based system for morphological analysis (More and Tsarfaty 2016), emphasizing their benefits of joint morphosyntactic parsing. For dependency parsing, Kiperwasser and Goldberg (2016a) proposed replacing the traditional feature engineering approach with vector representations of tokens obtained from BiLSTM-based neural architectures. Several neural parsing models have extended this idea (Kuncoro et al. 2017; Dozat and Manning 2017) and report competitive results for languages such as English. Nevertheless these models have shown to be of limited effectiveness as compared to feature engineered models for morphologically rich languages (More et al. 2019). In our framework, we do not use any hand-crafted features. Instead, we automate the learning of the feature function and formulate it as learning of horn clauses (Lao and Cohen 2010; Gardner and Mitchell 2015). The task of obtaining the features for the edge vector is similar to obtaining a distributional composition between two words (Weir et al"
2020.cl-4.4,N16-1030,0,0.0474109,"he sequence, where a label is a set of tags, one for each of the grammatical category. Here, co-temporal factors are defined to capture the dependencies between various tags of the same word. To capture the dependencies across the words, there exist factors between tags of the same type for the adjacent words, thereby forming a linear chain. Sequence Generation Model (SeqGen). The model, proposed in Tkachenko and Sirts (2018), also treats the label as a composite label. Here, a char-BiLSTM is used to obtain wordembeddings, which are then passed on to a word-level BiLSTM as the input features (Lample et al. 2016; Heigold, Neumann, and van Genabith 2017). The model, inspired from seq2seq models, uses an LSTM decoder to predict the grammatical categories one after the other, based on the previous predictions for each word. Energy-Based and CRF-Based Configurations. All the configurations of the EBMs, in addition to Edge Graph CRF, which is used for the word segmentation task (Section 4.2.1), are used in the morphological parsing task as well. These models predict all the morphemes of a given word, including the stem of a word. But the aforementioned neural baselines only predict the morphological label"
2020.cl-4.4,W19-4226,0,0.0489001,"Missing"
2020.cl-4.4,J97-2003,0,0.351829,"alikatte et al. (2018) proposed seq2seq models for the task. Aralikatte et al. (2018) considered the word segmentation as a multitask problem, using a common encoder with two decoders, where one decoder predicts the split location and the other is used to generate the characters in the split word. Both word segmentation and morphological parsing are low-level, yet non-trivial tasks for multiple languages and are extensively researched in NLP. Traditionally, solutions for these tasks were proposed using (Probabilistic/Weighted) finite-state transducers (Kaplan and Kay 1981; Sproat et al. 1996; Mohri 1997; Beesley et al. 2003) and using unsupervised pattern discovery approaches (Goldsmith 2001; Argamon et al. 2004; Johnson and Goldwater 2009). Broadly, these approaches could be categorized as lexicon driven (Huet 2003; Chen and Liu 1992), purely statistical (Eisner 2002; Sproat et al. 1994), or both (Sproat et al. 1996). Sequence labeling approaches such as HMMs (Hakkani-Tur, Oflazer, and Tur 2000) and CRFs (Smith, Smith, and Tromble 2005; Xue 2003) were later proposed for these tasks. Further, lattice parsing-based approaches, where the input search space was represented as word-level lattice"
2020.cl-4.4,Q19-1003,0,0.0979296,"(Krishna, Satuluri, and Goyal 2017). Assuming the latter is correct, nagar¯an.i is a plural form of the neuter gender stem nagara, which can either be in nominative, vocative, or accusative case. Assuming the inflection to be in nominative-case, this information enables the nominal to form one of the two possible syntactic relations with the main verb in the sentence, namely, kart¯a (subject) or karma (object)2 , in the syntactic analysis of the sentence. The cyclic dependency between morphological and syntax-level tasks is well known (Tsarfaty 2006), and these tasks are often solved jointly (More et al. 2019). Similarly, the potential error propagation from word segmentation to its downstream tasks in pipeline models is also well established for multiple languages (Hatori et al. 2012; Zhang and Yang 2018). Taking this into consideration, our proposed framework is designed to perform joint training of such related tasks. We propose a search-based structured prediction framework for numerous NLP tasks in a free word order language like Sanskrit. The framework we propose is an arcfactored model, similar to graph-based parsing frameworks (McDonald et al. 2005b; Ishikawa 2011). Here, the system expects"
2020.cl-4.4,C16-1033,0,0.0437717,"Missing"
2020.cl-4.4,D13-1032,0,0.0238462,"h, Smith, and Tromble 2005; Xue 2003) were later proposed for these tasks. Further, lattice parsing-based approaches, where the input search space was represented as word-level lattices, were incorporated into CRFs (Smith, Smith, and Tromble 2005) for joint modeling of these tasks (Kudo, Yamamoto, and Matsumoto 2004). Neural sequence labeling approaches currently achieve state-of-the-art performance in word segmentation, especially for Chinese, Korean, Japanese, and so forth (Wang, Voigt, and Manning 2014; Shao, Hardmeier, ¨ ¨ and Nivre 2018). Similarly, higher-order CRFs (Muller, Schmid, and Schutze 2013) and neural morphological taggers (Malaviya, Gormley, and Neubig 2018; Tkachenko and Sirts 2018) are widely used for morphological parsing. Interestingly, lattice based 833 Computational Linguistics Volume 46, Number 4 structures and lattice-parsing techniques remain hugely popular for word segmentation (Yang, Zhang, and Liang 2019) and in morphological parsing of morphologically rich ˘ 2015; More 2016; More et al. 2019). languages (Seeker and C ¸ etinoglu ¨ Transition-based approaches (Kubler, McDonald, and Nivre 2009) and graph-based approaches (McDonald et al. 2005b) are primarily two appro"
2020.cl-4.4,P02-1040,0,0.109746,"s discount is 1, that is, when no discount is applied. Keeping the hidden layer size to 750 leads to a 0.5 UAS and 0.4 LAS improvement for Tree-EBM*-F for dependency parsing, though no particular trend could be observed in varying the hidden layer size. Similarly, setting the dropout to 0.2 leads to an improvement 0.9 F-Score for the joint WS+MP+DP task. Evaluation Metrics. For the standalone tasks, we report the standard metrics. For dependency parsing, we use UAS and LAS. Similarly for linearization tasks, we follow Krishna et al. (2019) and report the performance of the systems using BLEU (Papineni et al. 2002), Kendall’s Tau (τ) score (Lapata 2003), and perfect match score, namely, the percentage of sentences with exact match to the input. For WS, MP, and the joint task of WS and MP, we use macro-averaged Precision, Recall, and F-Score (Krishna et al. 2018). We adopt the same metric for the joint task of WS, MP, and dependency parsing. As 816 Krishna et al. A Graph-Based Framework for Structured Prediction Tasks in Sanskrit Table 7 Hyperparameter settings for all the EBM models, based on which the results in Tables 8–15 are reported. The hyper parameter settings are tuned for the task word segmenta"
2020.cl-4.4,L18-1264,1,0.930348,"e reference sentence based on the analysis from SHR. The candidate segments are color coded by SHR based on their lexical categories. Blue for substantives, red for finite verb-forms, mauve for indeclinables, and yellow for all the non-final components of a compound. Cyan is used for those inflected-forms that can only be used as the final component of a compound (Goyal and Huet 2016). The numbered boxes indicate the morphological analysis as per SHR for the inflected forms ya`sa¯ h. and pituh.. segmentation, similar to previous word segmentation models in Sanskrit (Hellwig and Nehrdich 2018; Reddy et al. 2018). The knowledge of the individual components of a compound will help in its analysis in downstream tasks, and hence is important for processing Sanskrit corpora abundant with multicomponent compounds. The analysis of a sequence with fused words can lead to ambiguity in identifying the original words in the sequence. Goyal and Huet (2016) propose Sanskrit Heritage Reader (SHR), a lexicon driven shallow parser that encodes all the rules of sandhi as per traditional Sanskrit grammar.6 SHR can enumerate all possible lexically valid segmentations for a given sequence. Figure 3 shows the possible an"
2020.cl-4.4,D18-1545,0,0.0566504,"Missing"
2020.cl-4.4,D16-1255,0,0.0373503,"Missing"
2020.cl-4.4,K18-2021,0,0.0486591,"Missing"
2020.cl-4.4,Q18-1030,0,0.022106,"Missing"
2020.cl-4.4,H05-1060,0,0.37834,"austive segmentation.” For the sentence under consideration, the correct solution is one among the 59,616 possible exhaustive segmentations (Section 2.1). Given the possible word splits, our task can be formalized as one that finds the semantically most valid exhaustive segmentation among the candidate solutions. Morphological Parsing. Morphological parsing is the task of identifying the morphemes of the words in a sentence. Specifically, our task focuses on obtaining the correct stem and the morphological tag of the inflected forms in a sentence. Sanskrit, similar to Czech (Smith, Smith, and Tromble 2005), is a fusional language where a morpheme encodes multiple grammatical categories. Morphological parsing in Sanskrit is challenging primarily because of two factors. First, Sanskrit has a rich tagset of about 1,635 possible tags. Table 2 shows the lexical categories in Sanskrit and the grammatical categories they comprise of. Second, an inflected form in Sanskrit may lead to multiple morphological analyzes, due to syncretism and homonymy. For instance, Table 3 shows the candidate morphological analyzes produced by SHR for the inflected-forms pituh. and ya`sa¯ h..8 6 https://sanskrit.inria.fr/D"
2020.cl-4.4,P94-1010,0,0.681509,"the split word. Both word segmentation and morphological parsing are low-level, yet non-trivial tasks for multiple languages and are extensively researched in NLP. Traditionally, solutions for these tasks were proposed using (Probabilistic/Weighted) finite-state transducers (Kaplan and Kay 1981; Sproat et al. 1996; Mohri 1997; Beesley et al. 2003) and using unsupervised pattern discovery approaches (Goldsmith 2001; Argamon et al. 2004; Johnson and Goldwater 2009). Broadly, these approaches could be categorized as lexicon driven (Huet 2003; Chen and Liu 1992), purely statistical (Eisner 2002; Sproat et al. 1994), or both (Sproat et al. 1996). Sequence labeling approaches such as HMMs (Hakkani-Tur, Oflazer, and Tur 2000) and CRFs (Smith, Smith, and Tromble 2005; Xue 2003) were later proposed for these tasks. Further, lattice parsing-based approaches, where the input search space was represented as word-level lattices, were incorporated into CRFs (Smith, Smith, and Tromble 2005) for joint modeling of these tasks (Kudo, Yamamoto, and Matsumoto 2004). Neural sequence labeling approaches currently achieve state-of-the-art performance in word segmentation, especially for Chinese, Korean, Japanese, and so f"
2020.cl-4.4,P17-1173,0,0.0152196,"ese models have shown to be of limited effectiveness as compared to feature engineered models for morphologically rich languages (More et al. 2019). In our framework, we do not use any hand-crafted features. Instead, we automate the learning of the feature function and formulate it as learning of horn clauses (Lao and Cohen 2010; Gardner and Mitchell 2015). The task of obtaining the features for the edge vector is similar to obtaining a distributional composition between two words (Weir et al. 2016). Our work stands close to the attempts such as algebraic formulation for feature extraction by Srikumar (2017) or the Monte Carlo Tree Search-based feature selection approach by Gaudel and Sebag (2010). In Krishna et al. (2018) we used the Path Ranking Algorithm (Lao and Cohen 2010), a random walk based approach for learning horn clauses across a heterogeneous information network (HIN). The type of horn clauses mentioned in PRA is widely known as metapaths (Sun 2010) in HINs (Shi et al. 2017). Traditionally, metapaths, like feature engineering, were manually constructed. But, recent approaches such as PRA and FSPG (Meng et al. 2015) automate the generation of metapaths. Word linearization has been use"
2020.cl-4.4,K17-3009,0,0.0364598,"Missing"
2020.cl-4.4,P14-5003,0,0.0633386,"Missing"
2020.cl-4.4,P06-3009,0,0.670993,"Missing"
2020.cl-4.4,P08-1040,0,0.057717,"Missing"
2020.cl-4.4,O03-4002,0,0.0753852,"onally, solutions for these tasks were proposed using (Probabilistic/Weighted) finite-state transducers (Kaplan and Kay 1981; Sproat et al. 1996; Mohri 1997; Beesley et al. 2003) and using unsupervised pattern discovery approaches (Goldsmith 2001; Argamon et al. 2004; Johnson and Goldwater 2009). Broadly, these approaches could be categorized as lexicon driven (Huet 2003; Chen and Liu 1992), purely statistical (Eisner 2002; Sproat et al. 1994), or both (Sproat et al. 1996). Sequence labeling approaches such as HMMs (Hakkani-Tur, Oflazer, and Tur 2000) and CRFs (Smith, Smith, and Tromble 2005; Xue 2003) were later proposed for these tasks. Further, lattice parsing-based approaches, where the input search space was represented as word-level lattices, were incorporated into CRFs (Smith, Smith, and Tromble 2005) for joint modeling of these tasks (Kudo, Yamamoto, and Matsumoto 2004). Neural sequence labeling approaches currently achieve state-of-the-art performance in word segmentation, especially for Chinese, Korean, Japanese, and so forth (Wang, Voigt, and Manning 2014; Shao, Hardmeier, ¨ ¨ and Nivre 2018). Similarly, higher-order CRFs (Muller, Schmid, and Schutze 2013) and neural morphologica"
2020.cl-4.4,N19-1278,0,0.0373007,"Missing"
2020.cl-4.4,K18-2001,0,0.14169,"; Kiparsky 1995). The oral tradition and these 3 All the experiments were performed on the Czech-PDT UD treebank. 789 Computational Linguistics Volume 46, Number 4 Table 1 List of most commonly used abbreviations in this work. SHR DCS PCRW FSPG Sanskrit Heritage Reader Digital Corpus of Sanskrit Path Constrained Random Walk Forward Stagewise Path Generation Abbreviations WS MP DP SL PRA Path Ranking Algorithm Raw2UD EBM Energy-Based Model Joint T1 + T2 BoW MRL Bag of Words Morphologically Rich Language MIT SoTA Word Segmentation Morphological Parsing Dependency Parsing Syntactic Linearization CoNLL 2018 shared task on Raw Text to Universal Dependencies Joint modeling of the tasks T1 and T2 Metre Identification Tool State of the Art later developments have shaped the characteristics of the language and its usage in multiple ways. First, the words in a sentence often undergo phonetic transformations at the juncture of their boundaries, similar to what one expects in connected speech. These transformations obscure the word boundaries and often result in the modification and the fusion of the sounds at the word boundaries (Matthews 2007, p. 353). Such transformations, called sandhi, are reflecte"
2020.coling-main.88,P19-1424,0,0.0592388,"hese facts are encoded and attentively used to predict these attributes and charges as multi-task learning. For identifying the relevant law articles, Wang et al. (2018) propose DPAM, which exploits the fact that some articles co-occur frequently due to high semantic similarity in their textual descriptions. Whereas, Wang et al. (2019) use the tree-like hierarchies that exist among law articles to first identify the parent-laws and then the children-laws. Better representations are learnt for rare children-laws by considering the semantics of the siblings. In one of the rare works on English, Chalkidis et al. (2019) try out different methods, such as Bi-GRU with Attention, Hierarchical Attention Network and BERT for 1012 identifying charges in judgment cases from the European Court of Human Rights (ECHR). We consider all the above mentioned neural models as baselines in our work. Modeling multiple legal tasks: Recently, a few large legal datasets such as the CAIL Judgment Prediction dataset (Xiao et al., 2018) have become available which contains judgments from the Supreme People’s Court of China, and annotations for three sub-tasks – predicting legal articles, charges and prison terms. Some works have u"
2020.coling-main.88,C18-1041,0,0.184126,"offence), which one must consider before establishing a particular charge in a given situation. Charge identification is a tedious and time-consuming task requiring legal expertise, since the written laws are often described abstractly to encompass the wide-ranging scenarios in which a charge can apply. Thus automating the charge identification task can benefit the police and law practitioners. The task of Automatic Charge Identification (ACI, also referred to as ‘charge prediction’) aims to determine the possible charges that might have occurred in a given situation, using automated methods (Hu et al., 2018; Wang et al., 2018; Wang et al., 2019). A method for ACI takes as input (i) a document containing a textual description of a situation, called ‘fact-document’ or ‘facts’, and, (ii) textual descriptions of the charges/charges, available as written laws (statutes) in the legal statues of a country. The method outputs the set of charges/charges committed in the given situation. Most efforts in this task have been devoted towards distinguishing between rare and confusing charges, or learning better representations of the charge descriptions. For instance, Hu et al. (2018) designed 10 discriminati"
2020.coling-main.88,O12-5004,0,0.0676217,"Missing"
2020.coling-main.88,D17-1289,0,0.253573,"prove classification efficiency, while Aletras et al. (2016) use n-gram bag-of-words vectors with Linear Support Vector Classifier. Lin et al. (2012) use machine learning approaches to label documents, classify the category of the case and predict the judgment. Attentive Deep Learning Models: The early methods use manually designed, shallow textual features, which require substantial human effort, as well as domain knowledge. The success of neural models in various legal NLP tasks (Zhong et al., 2020) has motivated the use of attention-based deep learning models for ACI as well. For instance, Luo et al. (2017) dynamically generate representations for charge texts attentively, based on the fact representations. Hu et al. (2018) design 10 discriminative legal attributes, such as whether the charge is intentional, whether there is some physical injury, etc. These facts are encoded and attentively used to predict these attributes and charges as multi-task learning. For identifying the relevant law articles, Wang et al. (2018) propose DPAM, which exploits the fact that some articles co-occur frequently due to high semantic similarity in their textual descriptions. Whereas, Wang et al. (2019) use the tre"
2020.coling-main.88,2020.acl-main.280,0,0.062274,"tly, a few large legal datasets such as the CAIL Judgment Prediction dataset (Xiao et al., 2018) have become available which contains judgments from the Supreme People’s Court of China, and annotations for three sub-tasks – predicting legal articles, charges and prison terms. Some works have utilized correlations between these sub-tasks. For instance, Zhong et al. (2018) note that an acyclic dependency exists between the sub-tasks, while Yang et al. (2019) introduce a multi-perspective forward prediction and backward verification framework to utilize result dependencies between the sub-tasks. Xu et al. (2020) use graph-based methods to group statutory articles into communities, and use distinguishable features from each community to attentively encode facts. Since these methods are geared toward utilizing the correlations between the related sub-tasks (and need training data pertaining to all these tasks), we do not consider them as baselines, since our main focus is only charge identification. 3 Proposed model for Automatic Charge Identification Problem Definition: The ACI task takes as input (i) a textual description of the facts (of a situation), and (ii) textual descriptions of a set of charge"
2020.coling-main.88,N16-1174,0,0.390187,"ACI (that we consider in this work) is to identify zero or more charges given each xi and Y . Proposed model: Figure 1 gives an overview of our proposed model. We first obtain a fact-side representation (which can be either a representation of the whole fact, or of each sentence in the fact). Then we use this fact-side representation to dynamically generate the charge-side representation, and then pass these through a fully connected layer to obtain the final predictions. Below, we describe each of these components. Fact Encoding Layer: We use a modified Hierarchical Attention Network (HAN) (Yang et al., 2016) to encode facts, as shown in Figure 1a. A HAN contains two Bi-GRU + Attention sequence encoders: a sentence-level encoder that produces a sentence embedding from words, and a document-level encoder that produces a document embedding from sentences. Thus, in our case, each fact sentence xi is encoded to return a single embedding si for the entire sentence, using a trainable global context vector uf w to calculate attention weights (Yang et al., 2016). The fact text, now a sequence of sentence embeddings [s1 , s2 , . . . , sn ], is passed through the document-level encoder with a trainable glob"
2020.ecnlp-1.5,P17-4017,0,0.0623861,"Missing"
2020.ecnlp-1.5,C18-1186,0,0.0282635,"nally, the softmax layer gives the relevance score. BERT and XLNet : The architecture we use for fine-tuning BERT and XLNet is the same. We begin with the pre-trained BERTBase and XLNetBase model. To adapt the models for our task, we introduce a fully-connected layer over the final hidden state corresponding to the [CLS] input token. During fine-tuning, we optimize the entire model end-to-end, with the additional softmax classifier parameters W ∈ RK×H , where H is the dimenBackground and Related Work In recent years, e-commerce product question answering (PQA) has received a lot of attention. Yu et al. (2018) present a framework to answer product related questions by retrieving a ranked list of reviews and they employ the Positional Language Model (PLM) to create the training data. Chen et al. (2019) apply a multi-task attentive model to identify plausible answers. Lai et al. (2018) propose a Siamese deep learning model for answering questions regarding product specifications. The model returns a score for a question and specification pair. McAuley and Yang (2016) exploit product reviews for answer prediction via a Mixture of Expert (MoE) model. This MoE model makes use of a review relevance funct"
2020.ecnlp-1.5,N19-1423,0,0.0734961,"Missing"
2020.ecnlp-1.5,N19-3001,0,0.0349196,"Missing"
2020.ecnlp-1.5,W18-3105,0,0.328581,"e answers to the user queries. While certain questions can only be answered after using the product, there are many questions which can be answered from the product specification itself. Our work takes a first step in this direction by finding out the relevant product specifications, that can help answering the user questions. We propose an approach to automatically create a training dataset for this problem. We utilize recently proposed XLNet and BERT architectures for this problem and find that they provide much better performance than the Siamese model, previously applied for this problem (Lai et al., 2018). Our model gives a good performance even when trained on one vertical and tested across different verticals. 1 Figure 1: Snapshot of a product with its specifications. the corresponding product. Consider a question “What is the fabric of this bag?” This new question can be easily answered by retrieving the specification “Material” as the response. Fig. 1 depicts this scenario. Most of the recent works on product related queries on e-commerce leverage the product reviews to answer the questions (Gao et al., 2019; Zhao et al., 2019; McAuley and Yang, 2016). Although reviews are a rich source of"
2020.emnlp-main.388,D12-1133,0,0.0721129,"Missing"
2020.emnlp-main.388,Q13-1034,0,0.0596583,"Missing"
2020.emnlp-main.388,2020.sigmorphon-1.23,1,0.825234,"dels are YAP (More et al., 2019): a transition based parser for MRLs, BiAff (Dozat and Manning, 2017): a neural biaffine classifier, DCST (Rotman and Reichart, 2019): a self-training based neural classifier, and two variants of EBM: T-EBM and T-EBM*. For MP, we use the current SOTA model, C-EBM, an EBM variant as the baseline. The EBM variants and the impact of these variations would be elaborated in Section 5. For the joint morphosyntactic setting, we propose DCST++ as a neural baseline. DCST++ is our augmentation over DCST which integrates encoder outputs from a neural morphological tagger (Gupta et al., 2020) by a gating mechanism (Sato et al., 2017).5 Metric: All the results we report are macro averaged at a sentence level. For DP, we use UAS and LAS and for MP, we use F-Score. For joint MP and DP, all the EBM models other than MG-EBM may predict a tree that has a different vertex set than that of the ground truth. Since UAS cannot be used here, we use (unlabelled and labelled) F-Score for those systems. For MG-EBM UAS/LAS and Unlabelled/Labelled F-Score would be the same. Dataset6 : We use a test set of 1,300 sentences, 5 Refer to the supplementary material §2 for more experiments with this mode"
2020.emnlp-main.388,H05-1066,0,0.433647,"Missing"
2020.emnlp-main.388,D18-1276,1,0.836565,"Missing"
2020.emnlp-main.388,2020.cl-4.4,1,0.817049,"ience and Technology, University of Cambridge 2 School of Computing, University of Utah 3 Independent Researcher 4 School of Linguistics & Literary Studies, Chinmaya Vishwavidyapeeth 5 Department of Computer Science and Engineering, IIT Kharagpur ak2329@cam.ac.uk, ashim@cs.utah.edu, pawang@cse.iitkgp.ac.in Abstract Morphologically rich languages seem to benefit from joint processing of morphology and syntax, as compared to pipeline architectures. We propose a graph-based model for joint morphological parsing and dependency parsing in Sanskrit. Here, we extend the Energy based model framework (Krishna et al., 2020), proposed for several structured prediction tasks in Sanskrit, in 2 simple yet significant ways. First, the framework’s default input graph generation method is modified to generate a multigraph, which enables the use of an exact search inference. Second, we prune the input search space using a linguistically motivated approach, rooted in the traditional grammatical analysis of Sanskrit. Our experiments show that the morphological parsing from our joint model outperforms standalone morphological parsers. We report state of the art results in morphological parsing, and in dependency parsing, b"
2020.emnlp-main.388,W17-2214,1,0.894755,"Missing"
2020.emnlp-main.388,W13-3718,0,0.309241,"entence level. For DP, we use UAS and LAS and for MP, we use F-Score. For joint MP and DP, all the EBM models other than MG-EBM may predict a tree that has a different vertex set than that of the ground truth. Since UAS cannot be used here, we use (unlabelled and labelled) F-Score for those systems. For MG-EBM UAS/LAS and Unlabelled/Labelled F-Score would be the same. Dataset6 : We use a test set of 1,300 sentences, 5 Refer to the supplementary material §2 for more experiments with this model 6 The dataset can be downloaded from http://bit. where 1,000 come from the Sanskrit Tree Bank Corpus (Kulkarni, 2013, STBC) and 300 from Sisup¯ala-vadha, a work from classical Sanskrit poetry (Ryali, 2016). 1,500 and 1,000 sentences from STBC, other than the ones in test data, were used as the training and validation data respectively for DCST, DCST++, and BiAFF. However all the EBM models and YAP were trained on 12,320 sentences obtained by augmenting the training data in STBC (Krishna et al., 2020, §4.1).7 5 Results MG-EBM achieves the state of the art (SOTA) results in MP and in DP, both in standalone (with gold morphological tags as input) and joint morphosyntactic parsing setting. Table 1a shows that M"
2020.emnlp-main.388,W19-7502,0,0.0674969,"Missing"
2020.emnlp-main.388,W07-2216,0,0.0530507,"nal representation. The design of our feature function guarantees that every edge will have a unique feature vector. With this formulation, we simplify the search problem for the joint MP and DP task to that of searching for the spanning tree with minimum energy. This enables the use of the exact search Edmonds-ChuLiu MST algorithm (Edmonds, 1967), rather than an approximation algorithm, for inference. It is straightforward to extend the algorithm to multigraph, as we just need to retain only the minimum energy edge and prune out all the other edges between a pair of nodes in the input graph (McDonald and Satta, 2007). Case Multigraph-EBM (MG-EBM) extends the EBM framework in two simple yet significant ways. Dependency Relations Figure 2: Case information and possible dependency relations that a case is indicative of. assigned at least one label as per the rules of the grammar, it will be considered a valid candidate. Finally, all the edges which are not part of even one valid candidate-tree will be pruned from the input graph. This pruned unlabelled directed graph serves as the input for the inference procedure. This linguistically informed pruning can at best be seen as a rule-based deterministic delexic"
2020.emnlp-main.388,Q19-1003,0,0.336696,"e traditional grammatical analysis of Sanskrit. Our experiments show that the morphological parsing from our joint model outperforms standalone morphological parsers. We report state of the art results in morphological parsing, and in dependency parsing, both in standalone (with gold morphological tags) and joint morphosyntactic parsing setting. 1 Introduction Morphology and syntax are often inextricably intertwined for morphologically rich languages (MRLs). For such languages, it might be unrealistic to design dependency parsers that expect correct morphological tags to be provided as input (More et al., 2019; Bohnet et al., 2013). Jointly modelling morphological parsing (MP) with dependency parsing (DP) has shown to be effective for several MRLs (More et al., 2019). In this work, we present multigraphEBM (MG-EBM), a joint model for morphosyntactic parsing, i.e. joint MP and DP, in Sanskrit. Morphosyntactic parsing has been successfully applied to several MRLs. Bohnet et al. (2013) proposed a transition based joint parser, extending the ∗ Work done while at IIT Kharagpur joint POS tagger and dependency parser of Bohnet and Nivre (2012). Similarly Seeker and C¸etino˘glu (2015) proposed a joint grap"
2020.emnlp-main.388,L16-1262,0,0.0306472,"Missing"
2020.emnlp-main.388,Q19-1044,0,0.0254212,"JP-EBM-Prune and pipeline models are reported in F-Score. tem followed for Sanskrit (P¯an.ini, 500 BCE). The use of the relations from the P¯an.inian grammar, instead of other dependency tagsets such as Universal Dependencies (Nivre et al., 2016), enables us to incorporate the linguistic constraints for the pruning. 4 Experimental Framework Systems: For DP, with gold morphology tags as input, we compare the performance of MGEBM with 5 other parsers. The models are YAP (More et al., 2019): a transition based parser for MRLs, BiAff (Dozat and Manning, 2017): a neural biaffine classifier, DCST (Rotman and Reichart, 2019): a self-training based neural classifier, and two variants of EBM: T-EBM and T-EBM*. For MP, we use the current SOTA model, C-EBM, an EBM variant as the baseline. The EBM variants and the impact of these variations would be elaborated in Section 5. For the joint morphosyntactic setting, we propose DCST++ as a neural baseline. DCST++ is our augmentation over DCST which integrates encoder outputs from a neural morphological tagger (Gupta et al., 2020) by a gating mechanism (Sato et al., 2017).5 Metric: All the results we report are macro averaged at a sentence level. For DP, we use UAS and LAS"
2020.emnlp-main.388,K17-3007,0,0.0276948,"ion based parser for MRLs, BiAff (Dozat and Manning, 2017): a neural biaffine classifier, DCST (Rotman and Reichart, 2019): a self-training based neural classifier, and two variants of EBM: T-EBM and T-EBM*. For MP, we use the current SOTA model, C-EBM, an EBM variant as the baseline. The EBM variants and the impact of these variations would be elaborated in Section 5. For the joint morphosyntactic setting, we propose DCST++ as a neural baseline. DCST++ is our augmentation over DCST which integrates encoder outputs from a neural morphological tagger (Gupta et al., 2020) by a gating mechanism (Sato et al., 2017).5 Metric: All the results we report are macro averaged at a sentence level. For DP, we use UAS and LAS and for MP, we use F-Score. For joint MP and DP, all the EBM models other than MG-EBM may predict a tree that has a different vertex set than that of the ground truth. Since UAS cannot be used here, we use (unlabelled and labelled) F-Score for those systems. For MG-EBM UAS/LAS and Unlabelled/Labelled F-Score would be the same. Dataset6 : We use a test set of 1,300 sentences, 5 Refer to the supplementary material §2 for more experiments with this model 6 The dataset can be downloaded from htt"
2020.emnlp-main.388,Q15-1026,0,0.051344,"Missing"
2020.emnlp-main.388,J13-1004,0,0.0256196,"ex the properties of the word itself, but it may also index the agreement between its head or dependants (Nichols, 1986). The agreement between the subject and verb in terms of the number and person respectively is one such case. Similarly, the case, number, and gender agreement between the words in an adjectival modifier (vi´ses.an.a) relation is another example of this in Sanskrit. Further, morphological markers are indicative not only of the presence of syntactic dependency between the words in a sentence, but also of the type of the syntactic dependency shared between them (Nichols, 1986; Seeker and Kuhn, 2013). In Sanskrit, the case information of a nominal narrows down the possible relations it can have with a verb as the head. This is shown in Figure 2. We form constraints based on these morphosyntactic information and use it for pruning the edges.4 The dependency relations shown in Figure 2 are rooted in the P¯an.inian grammar, i.e. traditional grammatical sys4793 4 Refer to supplementary material §1 for example cases System YAP BiAff DCST T-EBM T-EBM* MG-EBM UAS 76.99 82.35 84.36 82.65 85.32 87.46 LAS 73.02 75.65 76.8 79.28 83.93 84.70 (a) Standalone dependency parsing results Standalone MP Pip"
2020.emnlp-main.388,P06-3009,0,0.0379994,"2020) by 1) incorporating a linguistically motivated pruning approach resulting in a substantial reduction in the input search space, and 2) modifying the input graph formation to a multigraph resulting in the use of Edmonds-Chu-Liu algorithm (Edmonds, 1967), an exact search algorithm, as inference. While the multigraph formulation is language agnostic the linguistically motivated pruning is rooted on the grammatical tradition of Sanskrit. Experiments validate that the joint morphosyntacticparsing hypothesis, i.e., morphological information can benefit syntactic disambiguation and vice versa (Tsarfaty, 2006), holds true for Sanskrit. We find that the MG-EBM reports state of the art results (SOTA) for morphological parsing, outperforming standalone morphological parsing models, similar to what is observed for Hebrew (More et al., 2019). Further, all the joint morphological parsing and DP variants of EBM, we experimented here, result in a superior performance than the pipeline morphological parsing and DP EBM model. We also establish SOTA results in Sanskrit for DP, both in standalone and joint setting. Acknowledgements We thank Dr Amba Kulkarni for helpful comments and discussions regarding the wo"
2020.icon-main.38,2019.icon-1.16,0,0.0319936,"marily in English (Chen et al., 2015), (Nguyen et al., 2016) and Chinese (Lin et al., 2018), (Yang et al., 2018). While there have been efforts to extend this task to a limited number of languages like Spanish and Arabic (Akbik et al., 2016), (Subburathinam et al., 2019), the task has been hardly explored in Indian languages. In this paper, we make an effort to explore five out of the twenty two commonly spoken languages of India. The existing literature for Indian languages for this task are minimal and have either extracted arguments from unstructured text irrespective of their event links (Ahmad et al., 2019), or have jointly extracted event and argument mentions with rule based approaches (Patel et al., 2019). Each of these works are modelled to focus at an intra-sentence local scope and do not capture inter sentence dependencies. While the sentence level extraction mechanisms outlined by prior works present a promising preface for this task in low-resource languages, the results are indicative of a huge scope of improvement - especially for arguments like Reason 288 which are scant on annotations. In our work, we try to address this gap and extract sentence level events and arguments by infusing"
2020.icon-main.38,C16-2056,0,0.0201226,"occur because of an event are noted under the Casualties argument whereas all other effects of an event are covered under the After Effects argument . • Entity : Words or phrases which specifically refer to terms that represent real-world objects like people, places, organizations are known as entities. 2 Related Work Event Argument Extraction is a well researched domain, primarily in English (Chen et al., 2015), (Nguyen et al., 2016) and Chinese (Lin et al., 2018), (Yang et al., 2018). While there have been efforts to extend this task to a limited number of languages like Spanish and Arabic (Akbik et al., 2016), (Subburathinam et al., 2019), the task has been hardly explored in Indian languages. In this paper, we make an effort to explore five out of the twenty two commonly spoken languages of India. The existing literature for Indian languages for this task are minimal and have either extracted arguments from unstructured text irrespective of their event links (Ahmad et al., 2019), or have jointly extracted event and argument mentions with rule based approaches (Patel et al., 2019). Each of these works are modelled to focus at an intra-sentence local scope and do not capture inter sentence dependen"
2020.icon-main.38,P15-1017,0,0.16859,"ing causal attribute from the structure. Context has always been of paramount importance for the task of event argument extraction. Existing literature outlines different paradigms of modeling the contextual scope for this task. The 287 Proceedings of the 17th International Conference on Natural Language Processing, pages 287–296 Patna, India, December 18 - 21, 2020. ©2020 NLP Association of India (NLPAI) traditional sentence level event argument extraction tasks performed on popular datasets like ACE 2005 and TAC-KBP 2017 largely restrict their contextual scope to within sentence boundaries (Chen et al., 2015; Subburathinam et al., 2019). However, some researchers identified the need to mine global contextual features to enhance the argument extraction capabilities and modelled the task at a multisentence or paragraph level (Yang and Mitchell, 2016; Duan et al., 2017; Zhao et al., 2018), and at a document level (Yang et al., 2018; Zheng et al., 2019). In our work, we also identify the need to explore cross-sentence contextual scope to aid accurate extraction of events and argument spans. For example as illustrated in Figure 1, the sentence ”The Brahmaputra is flowing above the danger mark in six d"
2020.icon-main.38,N19-1423,0,0.0109198,"ach, the rule vector was appended with each sentence token representations and fed to a single layer Bi-LSTM model. 2. Patel-Parallel : In this approach of (Patel et al., 2019), the rule vector and word embeddings were fed to two parallel single layer Bi-LSTM models. Their learnt hidden layer representations were concatenated to learn a joint representation of words and rules. 3. Patel-KD: In this approach of (Patel et al., 2019), the knowledge of rules is distilled to the Bi-LSTM network by using the rule vector to bias the weights of the neural network. 4. mBERT: We adopt the BERT-NER from (Devlin et al., 2019) and fine-tune the mBERT Token Classifier to extract event-argument spans and compare it with our feature based mBERT argument extractor. 5. JETAE: We adapt the mBERT Token Classifier for Joint Event Trigger and Argument Extraction task as defined in (Patel et al., 2019) and report it’s argument extraction capabilities as compared to our approach. 6. EA (Event Augmentation): Instead of augmenting the event causal feature, we augment the event type at both ends of the document and compare it’s results against our’s. We compare the overall performance in Table 3 for English. For the Indian langu"
2020.icon-main.38,I17-1036,0,0.0186538,"ternational Conference on Natural Language Processing, pages 287–296 Patna, India, December 18 - 21, 2020. ©2020 NLP Association of India (NLPAI) traditional sentence level event argument extraction tasks performed on popular datasets like ACE 2005 and TAC-KBP 2017 largely restrict their contextual scope to within sentence boundaries (Chen et al., 2015; Subburathinam et al., 2019). However, some researchers identified the need to mine global contextual features to enhance the argument extraction capabilities and modelled the task at a multisentence or paragraph level (Yang and Mitchell, 2016; Duan et al., 2017; Zhao et al., 2018), and at a document level (Yang et al., 2018; Zheng et al., 2019). In our work, we also identify the need to explore cross-sentence contextual scope to aid accurate extraction of events and argument spans. For example as illustrated in Figure 1, the sentence ”The Brahmaputra is flowing above the danger mark in six districts.” could refer to a Reason or an After-Effect argument in different contexts. But on reading the document, one can understand that the document talks about a Flood event, and that the sentence can be tagged as Reason argument with considerable confidence."
2020.icon-main.38,P18-1145,0,0.0403466,"Missing"
2020.icon-main.38,N16-1034,0,0.0266658,"y a particular event happened whereas After Effects argument details information about the after-math of an event. It is of importance to note here that the deaths and injuries that occur because of an event are noted under the Casualties argument whereas all other effects of an event are covered under the After Effects argument . • Entity : Words or phrases which specifically refer to terms that represent real-world objects like people, places, organizations are known as entities. 2 Related Work Event Argument Extraction is a well researched domain, primarily in English (Chen et al., 2015), (Nguyen et al., 2016) and Chinese (Lin et al., 2018), (Yang et al., 2018). While there have been efforts to extend this task to a limited number of languages like Spanish and Arabic (Akbik et al., 2016), (Subburathinam et al., 2019), the task has been hardly explored in Indian languages. In this paper, we make an effort to explore five out of the twenty two commonly spoken languages of India. The existing literature for Indian languages for this task are minimal and have either extracted arguments from unstructured text irrespective of their event links (Ahmad et al., 2019), or have jointly extracted event and arg"
2020.icon-main.38,D19-1030,0,0.0498836,"Missing"
2020.icon-main.38,D19-1585,0,0.0197913,"d works. The work by (Zhang et al., 2020) studies the eventargument extraction task by infusing contextual information from the five sentences surrounding an event trigger. Their work highlights the fact that learnt architectures usually capture arguments from sentences containing event triggers better than from non-event-trigger sentences. Addressing this gap, we adopt a trigger-less event detection approach in our work, similar to (Zheng et al., 2019) and use document-level event information to mitigate the dependence on local event clues obtained from event triggers. The method adopted by (Wadden et al., 2019) uses a graphical span enumeration approach with a document input to model cross-task and inter-sentence dependencies. We model our work to include inter-sentential context to extract event-argument spans from input documents with greater accuracy. 3 Dataset We have curated an event argument annotated dataset for English and four Indian languages, namely Bengali, Hindi, Marathi and Tamil as part of a collaborative effort. The dataset comprises of documents with sentence-level annotations of events and argument mentions. The data set caters specifically to the disaster domain and covers 32 even"
2020.icon-main.38,N16-1033,0,0.0244092,"roceedings of the 17th International Conference on Natural Language Processing, pages 287–296 Patna, India, December 18 - 21, 2020. ©2020 NLP Association of India (NLPAI) traditional sentence level event argument extraction tasks performed on popular datasets like ACE 2005 and TAC-KBP 2017 largely restrict their contextual scope to within sentence boundaries (Chen et al., 2015; Subburathinam et al., 2019). However, some researchers identified the need to mine global contextual features to enhance the argument extraction capabilities and modelled the task at a multisentence or paragraph level (Yang and Mitchell, 2016; Duan et al., 2017; Zhao et al., 2018), and at a document level (Yang et al., 2018; Zheng et al., 2019). In our work, we also identify the need to explore cross-sentence contextual scope to aid accurate extraction of events and argument spans. For example as illustrated in Figure 1, the sentence ”The Brahmaputra is flowing above the danger mark in six districts.” could refer to a Reason or an After-Effect argument in different contexts. But on reading the document, one can understand that the document talks about a Flood event, and that the sentence can be tagged as Reason argument with consi"
2020.icon-main.38,P18-4009,0,0.113089,"–296 Patna, India, December 18 - 21, 2020. ©2020 NLP Association of India (NLPAI) traditional sentence level event argument extraction tasks performed on popular datasets like ACE 2005 and TAC-KBP 2017 largely restrict their contextual scope to within sentence boundaries (Chen et al., 2015; Subburathinam et al., 2019). However, some researchers identified the need to mine global contextual features to enhance the argument extraction capabilities and modelled the task at a multisentence or paragraph level (Yang and Mitchell, 2016; Duan et al., 2017; Zhao et al., 2018), and at a document level (Yang et al., 2018; Zheng et al., 2019). In our work, we also identify the need to explore cross-sentence contextual scope to aid accurate extraction of events and argument spans. For example as illustrated in Figure 1, the sentence ”The Brahmaputra is flowing above the danger mark in six districts.” could refer to a Reason or an After-Effect argument in different contexts. But on reading the document, one can understand that the document talks about a Flood event, and that the sentence can be tagged as Reason argument with considerable confidence. Event arguments do not necessarily co-occur in the sentence con"
2020.icon-main.38,2020.acl-main.667,0,0.0290256,"e and do not capture inter sentence dependencies. While the sentence level extraction mechanisms outlined by prior works present a promising preface for this task in low-resource languages, the results are indicative of a huge scope of improvement - especially for arguments like Reason 288 which are scant on annotations. In our work, we try to address this gap and extract sentence level events and arguments by infusing document level context. Infusing cross-sentence or global context to extract sentence level information has already shown great improvements in many related works. The work by (Zhang et al., 2020) studies the eventargument extraction task by infusing contextual information from the five sentences surrounding an event trigger. Their work highlights the fact that learnt architectures usually capture arguments from sentences containing event triggers better than from non-event-trigger sentences. Addressing this gap, we adopt a trigger-less event detection approach in our work, similar to (Zheng et al., 2019) and use document-level event information to mitigate the dependence on local event clues obtained from event triggers. The method adopted by (Wadden et al., 2019) uses a graphical spa"
2020.icon-main.38,P18-2066,0,0.0184568,"nce on Natural Language Processing, pages 287–296 Patna, India, December 18 - 21, 2020. ©2020 NLP Association of India (NLPAI) traditional sentence level event argument extraction tasks performed on popular datasets like ACE 2005 and TAC-KBP 2017 largely restrict their contextual scope to within sentence boundaries (Chen et al., 2015; Subburathinam et al., 2019). However, some researchers identified the need to mine global contextual features to enhance the argument extraction capabilities and modelled the task at a multisentence or paragraph level (Yang and Mitchell, 2016; Duan et al., 2017; Zhao et al., 2018), and at a document level (Yang et al., 2018; Zheng et al., 2019). In our work, we also identify the need to explore cross-sentence contextual scope to aid accurate extraction of events and argument spans. For example as illustrated in Figure 1, the sentence ”The Brahmaputra is flowing above the danger mark in six districts.” could refer to a Reason or an After-Effect argument in different contexts. But on reading the document, one can understand that the document talks about a Flood event, and that the sentence can be tagged as Reason argument with considerable confidence. Event arguments do"
2020.icon-main.38,D19-1032,0,0.0289809,"Missing"
2020.lrec-1.707,W11-2501,0,0.488203,"han some threshold p The relation between word pair holds if the lin similarity (Lin, 1998) of the word vectors is greater than some threshold p Table 1: Descriptions of the baseline models as described in (Weeds et al., 2014) Model svmDIFF svmMULT svmADD svmCAT svmSING knnDIFF cosineP linP Accuracy 0.62 0.39 0.41 0.40 0.40 0.58 0.79 0.78 Table 2: Accuracy scores on a ten-fold cross validation for cohyponymBLESS dataset of all the baseline models described in (Weeds et al., 2014) 3.1. Experiment-1 (Weeds et al., 2014) Weeds et al. (2014) prepared cohyponymBLESS dataset from the BLESS dataset (Baroni and Lenci, 2011). cohyponymBLESS contains 5,835 labeled pair of nouns; divided evenly into pairs having co-hyponymy relations and others (having hypernymy, meronymy relations along with random word pairs). In their work, Weeds et al. (2014) represent each word as positive pointwise mutual information (PPMI) based feature vector and propose (Weeds et al., 2014) (Jana and Goyal, 2018b) Our models Model svmDIFF cosineP svmSS SVM CC SVM ADD RF CC RF ADD Accuracy 0.62 0.79 0.84 0.84 0.9 0.97 0.95 Table 3: Accuracy scores on a ten-fold cross validation for cohyponymBLESS dataset of our models along with the top two"
2020.lrec-1.707,P99-1008,0,0.207928,"on distributional semantic models (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006) along with some recent works exploring the possibility of using distributional semantic models (MorlaneHond`ere, 2015). Similarly, for co-hyponymy detection, researchers have investigated the usefulness of several distributional semantic models. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for the classification of hypernymy and co-hyponymy. Santus et al. (2016) proposed a supervised method based on a Random Forest algorithm to learn taxonomical se"
2020.lrec-1.707,I17-1028,0,0.023344,"c relations and they have shown that the model performs well for co-hyponymy detection. In another attempt, Jana and Goyal (2018b) proposed various complex network measures which can be used as features to build a supervised classifier model for co-hyponymy detection, and showed improvements over other baseline approaches. Recently, with the emergence of various network representation learning methods (Perozzi et al., 2014; Tang et al., 2015; Grover and Leskovec, 2016; Ribeiro et al., 2017), attempts have been made to convert distributional thesauri network into low dimensional vector space. (Ferret, 2017) apply distributional thesaurus embedding for synonym extraction and expansion tasks whereas Jana and Goyal (2018a) use it to improve the state-of-theart performance of word similarity/relatedness tasks, word analogy task etc. Thus, a natural question arises as to whether network embeddings should be more effective than the handcrafted network features used by Jana and Goyal (2018b) for cohyponymy detection. Being motivated by this connection, we investigate how the information captured by network representation learning methodologies on distributional thesaurus can be used in discriminating w"
2020.lrec-1.707,P14-1113,0,0.032162,"n etc. Both supervised and unsupervised methods have been proposed by the researchers to identify lexical relations like hypernymy, co-hyponymy, meronymy etc. over the years. Recent attempts to solve this task deal with proposing similarity measures based on distributional semantic models (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006) along with some recent works exploring the possibility of using distributional semantic models (MorlaneHond`ere, 2015). Similarly, for co-hyponymy detection, researchers have investigated the usefulness of several distributional semantic models. One such attempt is made by Weeds"
2020.lrec-1.707,P05-1014,0,0.0610631,"s one such fundamental task which can be leveraged in applications like paraphrasing, ontology building, metaphor detection etc. Both supervised and unsupervised methods have been proposed by the researchers to identify lexical relations like hypernymy, co-hyponymy, meronymy etc. over the years. Recent attempts to solve this task deal with proposing similarity measures based on distributional semantic models (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006) along with some recent works exploring the possibility of using distributional semantic models (MorlaneHond`ere, 2015). Similarly, for co-hyponymy detection, researc"
2020.lrec-1.707,J06-1005,0,0.0430684,"odels (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006) along with some recent works exploring the possibility of using distributional semantic models (MorlaneHond`ere, 2015). Similarly, for co-hyponymy detection, researchers have investigated the usefulness of several distributional semantic models. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for the classification of hypernymy and co-hyponymy. Santus et al. (2016) proposed a supervised method based on a Random Forest algorithm to learn taxonomical semantic relations and"
2020.lrec-1.707,N18-1043,1,0.820165,"sing distributional semantic models (MorlaneHond`ere, 2015). Similarly, for co-hyponymy detection, researchers have investigated the usefulness of several distributional semantic models. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for the classification of hypernymy and co-hyponymy. Santus et al. (2016) proposed a supervised method based on a Random Forest algorithm to learn taxonomical semantic relations and they have shown that the model performs well for co-hyponymy detection. In another attempt, Jana and Goyal (2018b) proposed various complex network measures which can be used as features to build a supervised classifier model for co-hyponymy detection, and showed improvements over other baseline approaches. Recently, with the emergence of various network representation learning methods (Perozzi et al., 2014; Tang et al., 2015; Grover and Leskovec, 2016; Ribeiro et al., 2017), attempts have been made to convert distributional thesauri network into low dimensional vector space. (Ferret, 2017) apply distributional thesaurus embedding for synonym extraction and expansion tasks whereas Jana and Goyal (2018a)"
2020.lrec-1.707,L18-1006,1,0.105016,"sing distributional semantic models (MorlaneHond`ere, 2015). Similarly, for co-hyponymy detection, researchers have investigated the usefulness of several distributional semantic models. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for the classification of hypernymy and co-hyponymy. Santus et al. (2016) proposed a supervised method based on a Random Forest algorithm to learn taxonomical semantic relations and they have shown that the model performs well for co-hyponymy detection. In another attempt, Jana and Goyal (2018b) proposed various complex network measures which can be used as features to build a supervised classifier model for co-hyponymy detection, and showed improvements over other baseline approaches. Recently, with the emergence of various network representation learning methods (Perozzi et al., 2014; Tang et al., 2015; Grover and Leskovec, 2016; Ribeiro et al., 2017), attempts have been made to convert distributional thesauri network into low dimensional vector space. (Ferret, 2017) apply distributional thesaurus embedding for synonym extraction and expansion tasks whereas Jana and Goyal (2018a)"
2020.lrec-1.707,P15-2020,0,0.0196976,"elations like hypernymy, co-hyponymy, meronymy etc. over the years. Recent attempts to solve this task deal with proposing similarity measures based on distributional semantic models (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006) along with some recent works exploring the possibility of using distributional semantic models (MorlaneHond`ere, 2015). Similarly, for co-hyponymy detection, researchers have investigated the usefulness of several distributional semantic models. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for t"
2020.lrec-1.707,P98-2127,0,0.733693,"Goyal (2018b). Baseline Model svmDIFF svmMULT svmADD svmCAT svmSING knnDIFF cosineP linP Description A linear SVM trained on the vector difference A linear SVM trained on the pointwise product vector A linear SVM trained on the vector sum A linear SVM trained on the vector concatenation A linear SVM trained on the vector of the second word in the given word pair k nearest neighbours (knn) trained on the vector difference The relation between word pair holds if the cosine similarity of the word vectors is greater than some threshold p The relation between word pair holds if the lin similarity (Lin, 1998) of the word vectors is greater than some threshold p Table 1: Descriptions of the baseline models as described in (Weeds et al., 2014) Model svmDIFF svmMULT svmADD svmCAT svmSING knnDIFF cosineP linP Accuracy 0.62 0.39 0.41 0.40 0.40 0.58 0.79 0.78 Table 2: Accuracy scores on a ten-fold cross validation for cohyponymBLESS dataset of all the baseline models described in (Weeds et al., 2014) 3.1. Experiment-1 (Weeds et al., 2014) Weeds et al. (2014) prepared cohyponymBLESS dataset from the BLESS dataset (Baroni and Lenci, 2011). cohyponymBLESS contains 5,835 labeled pair of nouns; divided evenl"
2020.lrec-1.707,D17-1022,0,0.372909,"Missing"
2020.lrec-1.707,P06-1015,0,0.037974,", 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006) along with some recent works exploring the possibility of using distributional semantic models (MorlaneHond`ere, 2015). Similarly, for co-hyponymy detection, researchers have investigated the usefulness of several distributional semantic models. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for the classification of hypernymy and co-hyponymy. Santus et al. (2016) proposed a supervised method based on a Random Forest algorithm to learn taxonomical semantic relations and they have shown that the model p"
2020.lrec-1.707,D13-1089,0,0.0979959,"similarity/relatedness tasks, word analogy task etc. Thus, a natural question arises as to whether network embeddings should be more effective than the handcrafted network features used by Jana and Goyal (2018b) for cohyponymy detection. Being motivated by this connection, we investigate how the information captured by network representation learning methodologies on distributional thesaurus can be used in discriminating word pairs having co-hyponymy relation from the word pairs having hypernymy, meronymy relation or any random pair of words. We use the distributional thesaurus (DT) network (Riedl and Biemann, 2013) built using Google books syntactic n-grams. As a network representation learning method, we apply node2vec (Grover and Leskovec, 2016) which is an algorithmic framework for learning continuous feature representations for nodes in networks that maximizes the likelihood of preserving network neighborhoods of nodes. Thus obtained vectors are then used as feature vectors and plugged into the classifiers according to the state-of-the-art experimental setup. Classification model: To distinguish the word pairs having co-hyponymy relation from the word pairs having hypernymy or meronymy relation, or"
2020.lrec-1.707,D16-1234,0,0.0151262,"e disambiguation, predicting semantic compositionality, etc. Automatic detection of lexical relations is one such fundamental task which can be leveraged in applications like paraphrasing, ontology building, metaphor detection etc. Both supervised and unsupervised methods have been proposed by the researchers to identify lexical relations like hypernymy, co-hyponymy, meronymy etc. over the years. Recent attempts to solve this task deal with proposing similarity measures based on distributional semantic models (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006) along with some recent works exploring the possibility of us"
2020.lrec-1.707,C14-1097,0,0.165202,"mantic models are used in a wide variety of tasks like sentiment analysis, word sense disambiguation, predicting semantic compositionality, etc. Automatic detection of lexical relations is one such fundamental task which can be leveraged in applications like paraphrasing, ontology building, metaphor detection etc. Both supervised and unsupervised methods have been proposed by the researchers to identify lexical relations like hypernymy, co-hyponymy, meronymy etc. over the years. Recent attempts to solve this task deal with proposing similarity measures based on distributional semantic models (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel"
2020.lrec-1.707,E14-4008,0,0.0234451,"ons like paraphrasing, ontology building, metaphor detection etc. Both supervised and unsupervised methods have been proposed by the researchers to identify lexical relations like hypernymy, co-hyponymy, meronymy etc. over the years. Recent attempts to solve this task deal with proposing similarity measures based on distributional semantic models (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006) along with some recent works exploring the possibility of using distributional semantic models (MorlaneHond`ere, 2015). Similarly, for co-hyponymy detection, researchers have investigated the usefulness of several distributio"
2020.lrec-1.707,W15-4208,0,0.0283324,"Missing"
2020.lrec-1.707,L16-1722,0,0.146615,"of tasks like sentiment analysis, word sense disambiguation, predicting semantic compositionality, etc. Automatic detection of lexical relations is one such fundamental task which can be leveraged in applications like paraphrasing, ontology building, metaphor detection etc. Both supervised and unsupervised methods have been proposed by the researchers to identify lexical relations like hypernymy, co-hyponymy, meronymy etc. over the years. Recent attempts to solve this task deal with proposing similarity measures based on distributional semantic models (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006) along with some"
2020.lrec-1.707,E17-1007,0,0.214956,"nt analysis, word sense disambiguation, predicting semantic compositionality, etc. Automatic detection of lexical relations is one such fundamental task which can be leveraged in applications like paraphrasing, ontology building, metaphor detection etc. Both supervised and unsupervised methods have been proposed by the researchers to identify lexical relations like hypernymy, co-hyponymy, meronymy etc. over the years. Recent attempts to solve this task deal with proposing similarity measures based on distributional semantic models (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006) along with some recent works explorin"
2020.lrec-1.707,C14-1212,0,0.0654113,"d in a wide variety of tasks like sentiment analysis, word sense disambiguation, predicting semantic compositionality, etc. Automatic detection of lexical relations is one such fundamental task which can be leveraged in applications like paraphrasing, ontology building, metaphor detection etc. Both supervised and unsupervised methods have been proposed by the researchers to identify lexical relations like hypernymy, co-hyponymy, meronymy etc. over the years. Recent attempts to solve this task deal with proposing similarity measures based on distributional semantic models (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). For hypernymy detection, several works use distributional inclusion hypothesis (Geffet and Dagan, 2005), entropy-based distributional measure (Santus et al., 2014) as well as several embedding schemes (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017). Image generality for lexical entailment detection (Kiela et al., 2015) has also been tried out for the same purpose. As far as meronymy detection is concerned, most of the attempts are pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti,"
2020.lrec-1.707,S13-1035,0,0.0282564,"uate the usefulness of DT embeddings against three benchmark datasets for cohyponymy detection (Weeds et al., 2014; Santus et al., 2016; Jana and Goyal, 2018b), following their experimental setup. We show that the network embeddings outperform the baselines by a huge margin throughout all the experiments, except for co-hyponyms vs. random pairs, where the baselines already have very high accuracy and network embeddings are able to match the results. 5766 2. Methodology We take the distributional thesaurus (DT) (Riedl and Biemann, 2013) constructed from the Google books syntactic n-grams data (Goldberg and Orwant, 2013) spanning from 1520 to 2008 as the underlying network where each word’s neighborhood is represented by a list of top 200 words that are similar with respect to their bi-gram distribution (Riedl and Biemann, 2013). communities. We use the default setup of node2vec; having walk-length 80, walks per node 10, window size 10 and dimension of vector 128. In order to do a qualitative analysis of the obtained vectors, we plot some sample words using t-SNE (Maaten and Hinton, 2008) in Figure 2. We observe that the relative distance between the co-hyponymy pairs is much smaller than those having hyperny"
2020.lrec-1.707,C98-2122,0,\N,Missing
2020.lrec-1.874,D18-1530,0,0.0161729,"ation phase with and without the segmentation suggestion component. The white dot in the middle denotes the median value and the thick black bar in the centre represents the interquartile range. number of characters are decided as per the SLP1 encoding scheme (Scharf and Hyman, 2011). https://sanskrit.inria.fr/DICO/reader.fr. html 7074 plans to extend the functionalities of SHR++ in the future. Currently the segmentation suggestion component utilises the segmenter only from Krishna et al. (2018). We plan to extend this to other word segmentation tools for Sanskrit (Hellwig and Nehrdich, 2018; Aralikatte et al., 2018; Reddy et al., 2018). Similar in spirit to CROWDTREE (Tratz and Phan, 2018), the annotation framework can be used for developing a human in the loop machine learning system, where the annotations and feedback from the annotators can be used as inputs to an active learning framework or more specifically, to a co-active learning framework (Shivaswamy and Joachims, 2012). This enables us to leverage the use of logical constraints from the traditional grammatical framework of Sanskrit, the wisdom of the crowd and the statistical inference power of machine learning. 6. Conclusion In this work, we"
2020.lrec-1.874,I08-2099,0,0.0467349,"annotation in both SHR and SHR++. The second phase of annotation in SHR++, expects the human annotator to annotate the morphological information and the syntactic (dependency) relations jointly. This decision of ours is motivated in principle from the traditional grammatical treatise on Sanskrit, Asht¯adhy¯ay¯ı. Asht¯adhy¯ay¯ı, written by P¯an.ini about 2500 years ago, treats the morphology and syntax as a single subsystem (Kiparsky, 1994). It uses the K¯araka framework for the analysis of a sentence, which stands close to the dependency analysis of sentences followed in western linguistics (Begum et al., 2008; Bharati et al., 2019). The K¯araka relations, formed between various word pairs in a sentence, are syntacticosemantico relations between the verbals and other related constituents in a sentence, with the analysis resulting in a dependency tree (Bharati and Sangal, 1993). K¯araka relations are pivotal in the assignment of case and other morphological elements for the words in a sentence. “The key principle is that every K¯araka relation must be expressed by a morphological relation, and none can be expressed by more than one” (Kiparsky, 1994). 3. System Our system, SHR++, has a client-server"
2020.lrec-1.874,P93-1015,0,0.474687,"grammatical treatise on Sanskrit, Asht¯adhy¯ay¯ı. Asht¯adhy¯ay¯ı, written by P¯an.ini about 2500 years ago, treats the morphology and syntax as a single subsystem (Kiparsky, 1994). It uses the K¯araka framework for the analysis of a sentence, which stands close to the dependency analysis of sentences followed in western linguistics (Begum et al., 2008; Bharati et al., 2019). The K¯araka relations, formed between various word pairs in a sentence, are syntacticosemantico relations between the verbals and other related constituents in a sentence, with the analysis resulting in a dependency tree (Bharati and Sangal, 1993). K¯araka relations are pivotal in the assignment of case and other morphological elements for the words in a sentence. “The key principle is that every K¯araka relation must be expressed by a morphological relation, and none can be expressed by more than one” (Kiparsky, 1994). 3. System Our system, SHR++, has a client-server architecture, where the server component is completely built using Django4 , a python framework. The client-side uses a web-based front-end (HTML+CSS+JS). Figure 2 shows the overview of SHR++ and the various modules it contains. Our system is designed to work in two diffe"
2020.lrec-1.874,W19-7724,0,0.0280662,"Missing"
2020.lrec-1.874,C12-1062,1,0.787593,"tem elsewhere, is hosted at https://github.com/iamdsc/smart-sanskrit-annotator. Keywords: low-resource languages, Sanskrit, annotation, dependency trees, morphological analysis, word segmentation, visualization, GUI, crowd-sourcing, treebanking 1. Introduction Sanskrit is a classical language (Coulson, 1992; Sapir, 2004), and used to be the ‘lingua franca’ for the scientific, literary and philosophical discourse in the Indian subcontinent for more than 3 millennia. The language has over 30 million extant manuscripts potent for digitisation, one hundred times those in Greek and Latin combined (Goyal et al., 2012). However, a major source of concern for the processing of texts in a low-resource language like Sanskrit is the lack of availability of labelled data. Acquiring task-specific annotations can be linguistically involved and time consuming, making it a challenge in itself. In this work, we present ‘SHR++’, a web-based annotation framework that would assist a professional annotator1 to perform annotations for three different tasks, ranging from word-segmentation, morphological parsing and dependency parsing. Word-segmentation is a challenging task in Sanskrit, as the writings in Sanskrit follow a"
2020.lrec-1.874,P12-1110,0,0.046734,"Missing"
2020.lrec-1.874,D18-1295,0,0.235943,"g in change of ‘¯a’ to ‘a + a¯ ’, ‘a + a + a’ and ‘a + a’ respectively. Figure 1a, shows the various candidate segments for the given sentence and the sentence can have 2446 different segmentation solutions.2 The correct solution, along with the splits for the compound components (shown in yellow), are shown in Figure 1b. Given the extensive use of multi component compounds and the use of compounds in place of the syntactic co- and sub-ordination in Sanskrit (Lowe, 2015), word segmentation in Sanskrit typically involves splitting of compounds into its components as well (Goyal and Huet, 2016; Hellwig and Nehrdich, 2018). The word-splits in Figure 1a are obtained based on the analysis from SHR. SHR uses finite state methods in the form of a lexical juncture system to obtain the possible segments for a given sentence. Following definitions from Goyal and Huet (2016)3 , a lexical juncture system can be formalised as follows. It is composed of a finite alphabet Σ, a finite set of words L ⊆ Σ∗ and a finite set R of rewrite rules of the form u|v → f /x__ (Kaplan and Kay, 1994), with x, v, f ∈ Σ∗ and u ∈ Σ+ . Here, Σ forms the set of phonemes, R is the set of Sandhi rewrite rules, and L is the vocabulary which is a"
2020.lrec-1.874,W16-3715,0,0.0145252,"0 Corpus Mode SHR Standalone Mode Datastore SHR Extractor Datastore Explorer Morpho-syntactic Annotator Segmentation Annotator Segmentation Suggestion Word Editor Figure 2: Overview of the modules in SHR++ and their interactions within the system. that are proposed as alternatives to each other, and hence cannot co-exist in a single solution, are called as ‘conflicting’ word-pairs. The words ‘śrama’, ‘¯aśrama’, ‘aśram’ are conflicting to each other. Sanskrit is a morphologically rich language and consists of a rich tag-set of 1,635 possible tags for its inflectional morphology (Krishna, 2019; Hellwig, 2016). Further, cases of syncretism and homonymy are prevalent for the fusional language (Krishna et al., 2018; Hellwig, 2015b). SHR, similar to its segmentation analysis, also performs the possible morphological analyses for each of the candidate words. For a compact representation of the candidate words, both SHR and SHR++ display only the unique inflected forms in the segmentation analysis and then incorporate all the valid morphological analyses for the surface-form within the surface form itself. This information for each word is shown to the user on hovering the mouse pointer over the corresp"
2020.lrec-1.874,J94-3001,0,0.40293,"we, 2015), word segmentation in Sanskrit typically involves splitting of compounds into its components as well (Goyal and Huet, 2016; Hellwig and Nehrdich, 2018). The word-splits in Figure 1a are obtained based on the analysis from SHR. SHR uses finite state methods in the form of a lexical juncture system to obtain the possible segments for a given sentence. Following definitions from Goyal and Huet (2016)3 , a lexical juncture system can be formalised as follows. It is composed of a finite alphabet Σ, a finite set of words L ⊆ Σ∗ and a finite set R of rewrite rules of the form u|v → f /x__ (Kaplan and Kay, 1994), with x, v, f ∈ Σ∗ and u ∈ Σ+ . Here, Σ forms the set of phonemes, R is the set of Sandhi rewrite rules, and L is the vocabulary which is a set of lexical entries. Each entry z ∈ L is defined as a tuple (l, m, w). Here l denotes the lemma of the word, m denotes the morphological class of the word, w denotes the inflected surface-form generated from l and m. The sandhi analysis Si for a string s can be seen as a sequence hz1 , σ1 , k1 i; ...hzp , σp , kp i. Here, hzj , σj , kj i is a segment with zj ∈ L, kj denotes the position at which the word wj begins in the sentence s and σj = xj uj |vj →"
2020.lrec-1.874,W17-2214,1,0.939335,"hown in Figure 1a. Currently, this feature is intended to be used only in the corpus mode, where the predictions from the automated segmenters are obtained offline and stored in our datastore. This is primarily due to the time constraints required for obtaining the predictions in real-time using the inference procedure of the word-segmentation tools. Word Editor: It is possible that SHR may not produce an analysis for certain substring-spans of the input string. It can also be possible that the analyses provided by SHR for some of the candidate words might be erroneous and require correction (Krishna et al., 2017). Taking into consideration such cases, we add a provision for the annotators to modify the candidate word analyses. On hovering the mouse over a candidate word, an edit option appears below it. It can be used by the human annotator to edit the details of the word. As shown in Figure 4b, the annotator can edit the surface form, the lemma as well as the morphological tags associated with the words. In case of missing analysis for a span of the input, a dummy candidate word is provided beneath the span, which the annotator can edit to add the appropriate words. All the modifications made by the"
2020.lrec-1.874,D18-1276,1,0.894396,"ator Segmentation Annotator Segmentation Suggestion Word Editor Figure 2: Overview of the modules in SHR++ and their interactions within the system. that are proposed as alternatives to each other, and hence cannot co-exist in a single solution, are called as ‘conflicting’ word-pairs. The words ‘śrama’, ‘¯aśrama’, ‘aśram’ are conflicting to each other. Sanskrit is a morphologically rich language and consists of a rich tag-set of 1,635 possible tags for its inflectional morphology (Krishna, 2019; Hellwig, 2016). Further, cases of syncretism and homonymy are prevalent for the fusional language (Krishna et al., 2018; Hellwig, 2015b). SHR, similar to its segmentation analysis, also performs the possible morphological analyses for each of the candidate words. For a compact representation of the candidate words, both SHR and SHR++ display only the unique inflected forms in the segmentation analysis and then incorporate all the valid morphological analyses for the surface-form within the surface form itself. This information for each word is shown to the user on hovering the mouse pointer over the corresponding word. The morphological analysis for the word ‘aśram’ is shown in Figure 1a. Here, the surface-for"
2020.lrec-1.874,W04-3230,0,0.133401,"ect.com/ Figure 3: Interface for the morpho-syntactic annotator and the overlay ‘lightbox’ interface for labelling the relations candidates can exponentially increase with the length of the string and aligning these candidates to fit in a screen can be a challenge in itself (Goyal and Huet, 2016). Here, we faithfully follow the design scheme adopted by SHR to represent the candidate word-splits. SHR uses the term ‘shared forest’ (Goyal and Huet, 2016) to refer to such an arrangement. However, this is similar to that of a ‘lattice’ used in the lattice based morpho-syntactic parsing approaches (Kudo et al., 2004; More et al., 2018; Seeker and Çetinoğlu, 2015) proposed for languages such as Korean, Hebrew, Turkish etc. The segmentation annotator forms first phase of annotation, where only the unique inflected word-forms are shown to annotators. Among the candidate words, the longer ones are placed in the topmost row, provided none of them conflict with each other. This policy is followed for every subsequent row and leads to a compact display. When a user clicks on the word, its corresponding conflicting candidates are eliminated automatically. Clicking back on the word would undo this selection, and"
2020.lrec-1.874,L18-1608,0,0.0221311,"Interface for the morpho-syntactic annotator and the overlay ‘lightbox’ interface for labelling the relations candidates can exponentially increase with the length of the string and aligning these candidates to fit in a screen can be a challenge in itself (Goyal and Huet, 2016). Here, we faithfully follow the design scheme adopted by SHR to represent the candidate word-splits. SHR uses the term ‘shared forest’ (Goyal and Huet, 2016) to refer to such an arrangement. However, this is similar to that of a ‘lattice’ used in the lattice based morpho-syntactic parsing approaches (Kudo et al., 2004; More et al., 2018; Seeker and Çetinoğlu, 2015) proposed for languages such as Korean, Hebrew, Turkish etc. The segmentation annotator forms first phase of annotation, where only the unique inflected word-forms are shown to annotators. Among the candidate words, the longer ones are placed in the topmost row, provided none of them conflict with each other. This policy is followed for every subsequent row and leads to a compact display. When a user clicks on the word, its corresponding conflicting candidates are eliminated automatically. Clicking back on the word would undo this selection, and previously eliminat"
2020.lrec-1.874,Q19-1003,0,0.0437971,"Missing"
2020.lrec-1.874,L18-1264,1,0.851218,"out the segmentation suggestion component. The white dot in the middle denotes the median value and the thick black bar in the centre represents the interquartile range. number of characters are decided as per the SLP1 encoding scheme (Scharf and Hyman, 2011). https://sanskrit.inria.fr/DICO/reader.fr. html 7074 plans to extend the functionalities of SHR++ in the future. Currently the segmentation suggestion component utilises the segmenter only from Krishna et al. (2018). We plan to extend this to other word segmentation tools for Sanskrit (Hellwig and Nehrdich, 2018; Aralikatte et al., 2018; Reddy et al., 2018). Similar in spirit to CROWDTREE (Tratz and Phan, 2018), the annotation framework can be used for developing a human in the loop machine learning system, where the annotations and feedback from the annotators can be used as inputs to an active learning framework or more specifically, to a co-active learning framework (Shivaswamy and Joachims, 2012). This enables us to leverage the use of logical constraints from the traditional grammatical framework of Sanskrit, the wisdom of the crowd and the statistical inference power of machine learning. 6. Conclusion In this work, we propose an online ann"
2020.lrec-1.874,Q15-1026,0,0.0269684,"orpho-syntactic annotator and the overlay ‘lightbox’ interface for labelling the relations candidates can exponentially increase with the length of the string and aligning these candidates to fit in a screen can be a challenge in itself (Goyal and Huet, 2016). Here, we faithfully follow the design scheme adopted by SHR to represent the candidate word-splits. SHR uses the term ‘shared forest’ (Goyal and Huet, 2016) to refer to such an arrangement. However, this is similar to that of a ‘lattice’ used in the lattice based morpho-syntactic parsing approaches (Kudo et al., 2004; More et al., 2018; Seeker and Çetinoğlu, 2015) proposed for languages such as Korean, Hebrew, Turkish etc. The segmentation annotator forms first phase of annotation, where only the unique inflected word-forms are shown to annotators. Among the candidate words, the longer ones are placed in the topmost row, provided none of them conflict with each other. This policy is followed for every subsequent row and leads to a compact display. When a user clicks on the word, its corresponding conflicting candidates are eliminated automatically. Clicking back on the word would undo this selection, and previously eliminated conflicting words are disp"
2020.lrec-1.874,H05-1060,0,0.148181,"Missing"
2020.lrec-1.874,W19-7506,0,0.037429,"Missing"
2020.lrec-1.874,L18-1346,0,0.0211536,"dot in the middle denotes the median value and the thick black bar in the centre represents the interquartile range. number of characters are decided as per the SLP1 encoding scheme (Scharf and Hyman, 2011). https://sanskrit.inria.fr/DICO/reader.fr. html 7074 plans to extend the functionalities of SHR++ in the future. Currently the segmentation suggestion component utilises the segmenter only from Krishna et al. (2018). We plan to extend this to other word segmentation tools for Sanskrit (Hellwig and Nehrdich, 2018; Aralikatte et al., 2018; Reddy et al., 2018). Similar in spirit to CROWDTREE (Tratz and Phan, 2018), the annotation framework can be used for developing a human in the loop machine learning system, where the annotations and feedback from the annotators can be used as inputs to an active learning framework or more specifically, to a co-active learning framework (Shivaswamy and Joachims, 2012). This enables us to leverage the use of logical constraints from the traditional grammatical framework of Sanskrit, the wisdom of the crowd and the statistical inference power of machine learning. 6. Conclusion In this work, we propose an online annotation tool for annotating sentences in Sanskrit for t"
2020.sigmorphon-1.23,D17-1206,0,0.0432151,"Missing"
2020.sigmorphon-1.23,E17-1048,0,0.0604766,"Missing"
2020.sigmorphon-1.23,W16-3715,1,0.926025,"e more suited for the task, because of their ability to generalise to labels not seen during training. We find that although some neural models perform better than others, one of the common causes for error for all of these models is mispredictions due to syncretism.1 1 Introduction Sanskrit is a fusional Indo-European language with rich morphology, both at the inflectional and derivational level. The language relies heavily on morphological markers to determine the syntactic, and to some extent the semantic roles, of words in a sentence. There exist limited and partly incompatible solutions (Hellwig, 2016; Goyal and Huet, 2016; Krishna et al., 2018) for morphological tagging of Sanskrit that heavily rely on lexicon driven shallow parsers and other linguistic knowledge. However recently, neural sequential labelling models have achieved competitive results in morphological tagging for multiple languages (Cotterell and Heigold, 2017; Tkachenko and Sirts, 2018; Malaviya et al., 2018). We therefore explore the efficacy of such models in performing morphological tagging for Sanskrit without access to extensive linguistic information. Most recent research treats morphological tagging as a structured"
2020.sigmorphon-1.23,P16-1184,0,0.0592273,"Missing"
2020.sigmorphon-1.23,W13-3704,0,0.0501854,"Missing"
2020.sigmorphon-1.23,D17-1078,0,0.0176,"ean language with rich morphology, both at the inflectional and derivational level. The language relies heavily on morphological markers to determine the syntactic, and to some extent the semantic roles, of words in a sentence. There exist limited and partly incompatible solutions (Hellwig, 2016; Goyal and Huet, 2016; Krishna et al., 2018) for morphological tagging of Sanskrit that heavily rely on lexicon driven shallow parsers and other linguistic knowledge. However recently, neural sequential labelling models have achieved competitive results in morphological tagging for multiple languages (Cotterell and Heigold, 2017; Tkachenko and Sirts, 2018; Malaviya et al., 2018). We therefore explore the efficacy of such models in performing morphological tagging for Sanskrit without access to extensive linguistic information. Most recent research treats morphological tagging as a structured prediction problem where the morphological class of a word is either treated as 1 Code and data available at https://github.com/ ashim95/sanskrit-morphological-taggers a monolithic label or as a composite label with multiple features (M¨uller et al., 2013; Cotterell and Heigold, 2017). Schmid and Laws (2008); Hakkani-T¨ur et al."
2020.sigmorphon-1.23,K17-1042,0,0.0470719,"Missing"
2020.sigmorphon-1.23,D18-1276,1,0.730022,"f their ability to generalise to labels not seen during training. We find that although some neural models perform better than others, one of the common causes for error for all of these models is mispredictions due to syncretism.1 1 Introduction Sanskrit is a fusional Indo-European language with rich morphology, both at the inflectional and derivational level. The language relies heavily on morphological markers to determine the syntactic, and to some extent the semantic roles, of words in a sentence. There exist limited and partly incompatible solutions (Hellwig, 2016; Goyal and Huet, 2016; Krishna et al., 2018) for morphological tagging of Sanskrit that heavily rely on lexicon driven shallow parsers and other linguistic knowledge. However recently, neural sequential labelling models have achieved competitive results in morphological tagging for multiple languages (Cotterell and Heigold, 2017; Tkachenko and Sirts, 2018; Malaviya et al., 2018). We therefore explore the efficacy of such models in performing morphological tagging for Sanskrit without access to extensive linguistic information. Most recent research treats morphological tagging as a structured prediction problem where the morphological cl"
2020.sigmorphon-1.23,N16-1030,0,0.220355,"17). Malaviya et al. (2018) use a neural factorial CRF to model inter-dependence between individual categories of the composite morphological label. However, as the decision for monolithic vs. composite labels is one of the central design choices when tagging morphologically rich languages, we use Sanskrit as a test case for a systematic evaluation for this choice. For this evaluation, we consider several neural architectures with different modelling principles. For the monolithic tag model, the neural architecture is based on a bidirectional LSTM with a linear CRF layer stacked on top of it (Lample et al., 2016; Huang et al., 2015). For composite labels, we explored a neural generation model that generates a sequence of morphological features for each word in the input sequence. In order to explicitly capture the interdependencies between the morphological features, we use a model based on a factorial Conditional 198 Proceedings of the Seventeenth SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 198–203 c Online, July 10, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 3 3 3 3 3 Others 3 Compound Participle 3 3 3 Fin. v"
2020.sigmorphon-1.23,P18-1247,0,0.341701,"nal and derivational level. The language relies heavily on morphological markers to determine the syntactic, and to some extent the semantic roles, of words in a sentence. There exist limited and partly incompatible solutions (Hellwig, 2016; Goyal and Huet, 2016; Krishna et al., 2018) for morphological tagging of Sanskrit that heavily rely on lexicon driven shallow parsers and other linguistic knowledge. However recently, neural sequential labelling models have achieved competitive results in morphological tagging for multiple languages (Cotterell and Heigold, 2017; Tkachenko and Sirts, 2018; Malaviya et al., 2018). We therefore explore the efficacy of such models in performing morphological tagging for Sanskrit without access to extensive linguistic information. Most recent research treats morphological tagging as a structured prediction problem where the morphological class of a word is either treated as 1 Code and data available at https://github.com/ ashim95/sanskrit-morphological-taggers a monolithic label or as a composite label with multiple features (M¨uller et al., 2013; Cotterell and Heigold, 2017). Schmid and Laws (2008); Hakkani-T¨ur et al. (2002) model the morphological tags as a sequence o"
2020.sigmorphon-1.23,D13-1032,0,0.0624423,"Missing"
2020.sigmorphon-1.23,C08-1098,0,0.0405495,"tiple languages (Cotterell and Heigold, 2017; Tkachenko and Sirts, 2018; Malaviya et al., 2018). We therefore explore the efficacy of such models in performing morphological tagging for Sanskrit without access to extensive linguistic information. Most recent research treats morphological tagging as a structured prediction problem where the morphological class of a word is either treated as 1 Code and data available at https://github.com/ ashim95/sanskrit-morphological-taggers a monolithic label or as a composite label with multiple features (M¨uller et al., 2013; Cotterell and Heigold, 2017). Schmid and Laws (2008); Hakkani-T¨ur et al. (2002) model the morphological tags as a sequence of individual morphological features. Recently, Tkachenko and Sirts (2018) proposed to generate this sequence of morphological features using a neural encoder-decoder architecture. Hellwig (2016) shows a significant improvement in performance for morphological tagging in Sanskrit by using a monolithic tagset with recurrent neural network based tagging model. In systems using monolithic labels, multiple feature values pertaining to a word are combined to form a single label (M¨uller et al., 2013; Heigold et al., 2017), whic"
2020.sigmorphon-1.23,P16-2038,0,0.09925,"onal grammatical analysis of Sanskrit (Apte, 1885).2 As the declensional type of a noun in Sanskrit is determined by the last character in the non-inflected stem of the word, we add the last character of the stem as a morphological feature in our predictions. Table 1: Grammatical features and their distribution over inflectional classes. ‘Others’ include forms such as infinitives, absolutives, Indeclinables, etc. Random Field (CRF) (Malaviya et al., 2018). Additionally, independent classifiers trained under a multi-task setting with sharing of parameters are also explored (Inoue et al., 2017; Søgaard and Goldberg, 2016). Our experiments specifically focus on the following problems and questions: • Syncretism: We will show that syncretism, i.e., inflected forms of a lemma that share the same surface form for multiple morphological tags, is the major source of mispredictions. We evaluate if and how models with monolithic and composite labels deal with this phenomenon. • Performance on unseen tags: For models with composite labels, it should be possible to predict morphological classes which were not seen in the training data. Our experiments show that the performance of the systems remains more or less the sam"
2020.sigmorphon-1.23,K18-1036,0,0.410653,"logy, both at the inflectional and derivational level. The language relies heavily on morphological markers to determine the syntactic, and to some extent the semantic roles, of words in a sentence. There exist limited and partly incompatible solutions (Hellwig, 2016; Goyal and Huet, 2016; Krishna et al., 2018) for morphological tagging of Sanskrit that heavily rely on lexicon driven shallow parsers and other linguistic knowledge. However recently, neural sequential labelling models have achieved competitive results in morphological tagging for multiple languages (Cotterell and Heigold, 2017; Tkachenko and Sirts, 2018; Malaviya et al., 2018). We therefore explore the efficacy of such models in performing morphological tagging for Sanskrit without access to extensive linguistic information. Most recent research treats morphological tagging as a structured prediction problem where the morphological class of a word is either treated as 1 Code and data available at https://github.com/ ashim95/sanskrit-morphological-taggers a monolithic label or as a composite label with multiple features (M¨uller et al., 2013; Cotterell and Heigold, 2017). Schmid and Laws (2008); Hakkani-T¨ur et al. (2002) model the morphologi"
2020.sigmorphon-1.23,D17-1073,0,0.0169385,"6) shows a significant improvement in performance for morphological tagging in Sanskrit by using a monolithic tagset with recurrent neural network based tagging model. In systems using monolithic labels, multiple feature values pertaining to a word are combined to form a single label (M¨uller et al., 2013; Heigold et al., 2017), which leads to data sparsity for morphologically rich languages such as Czech, Turkish and Sanskrit. The sparsity issue can be addressed by using composite labels which model the internal structure of a class as a set of individual features (Tkachenko and Sirts, 2018; Zalmout and Habash, 2017). Malaviya et al. (2018) use a neural factorial CRF to model inter-dependence between individual categories of the composite morphological label. However, as the decision for monolithic vs. composite labels is one of the central design choices when tagging morphologically rich languages, we use Sanskrit as a test case for a systematic evaluation for this choice. For this evaluation, we consider several neural architectures with different modelling principles. For the monolithic tag model, the neural architecture is based on a bidirectional LSTM with a linear CRF layer stacked on top of it (Lam"
2020.sigmorphon-1.23,R13-1099,0,0.0116429,"word embedding with a sub-word character embedding obtained from a bidirectional LSTM similar to Lample et al. (2016). These word representations are passed through a word level Bi-LSTM to obtain hidden state hi for each token in the sequence. This raises an important point: Models that perform marginally better in terms of evaluation metrics are supposedly not superior, since we see similar performances on special test sets targeting particular statistical phenomenon (unseen tags) and linguistic phenomenon (syncretism). 2 Problem Formulation and Models Tagset: Sanskrit, similar to Hungarian (Zsibrita et al., 2013) and Turkish (C ¸ etino˘glu and Kuhn, 2013), relies on suffixes for marking inflectional information. As Sanskrit has a rich inflectional system, the size of the tagset plays a relevant role. Hellwig (2016) uses a tagset with 86 possible labels that merges some grammatical features based 199 Monolithic Sequence Model (MonSeq): This is a standard neural sequence labelling model with a neural-CRF tagger (Lample et al., 2016; Huang et al., 2015). A linear chain CRF is used as the output layer for the monolithic labels used. Neural Factorial CRF (FCRF): The model proposed by Malaviya et al. (2018)"
2021.case-1.5,N19-1423,0,0.00624409,"adopt the following rules: Once all the sentence-level arguments of a document have been processed through the above described modules, a precise document-level information frame is rendered. 5 Experiments & Results In this section we shall detail the execution details of the experiments and analyse the results obtained. 5.1 Experiments We have experimented with different encodings and classifiers in our work. For the Sentence Level Event-Argument Extraction task we have encoded the text using Huggingface’s (Wolf et al., 2020) bert-base-multilingual-cased model pre-trained on 104 languages2 (Devlin et al., 2019). For encoding text in the relevance filter, the pretrained robertabase- model3 (Liu et al., 2019) was used while for the redundancy filter, the pretrained bert-basemodel4 was used. The ROBERTA-based relevance filter was trained for 3 epochs on 500 training samples while the redundancy filter was trained for 15 epochs after retrieving required annotations from 5 epochs of active learning. The batch size for our experiments was 8. All our experiments were performed on a Tesla K40-C server. 1. If an argument type contains a single argument mention extracted at the sentence level, the argument is"
2021.case-1.5,W04-3252,0,0.199416,"does not explore the task of aggregation in particular, where, given a set of arguments referring to the same concept, the most informative argument is selected to represent that knowledge. We propose a novel task and present an end-to-end baseline solution to extract and aggregate document-level arguments which presents a complete overview of the document without minimal loss of information. In our work, we employ ranking strategies as part of our aggregation process. Some of the classic works related to the task of ranking text snippets are that of PageRank (Page et al., 1998) and TextRank (Mihalcea and Tarau, 2004). 3 have gained attention in recent times but there are hardly any document-level event argument annotated datasets. We discuss two recent works that include document-level event argument or entity mention annotations here; the RAMS (Ebner et al., 2020) and the SciREX (Jain et al., 2020) dataset. The RAMS dataset is not particularly documentlevel, but explores the task of extracting argument roles beyond sentences. In a 5-sentence window of a news article around each event trigger, they annotate the closest span for each argument role. Their ontology consists of 139 event types and 65 argument"
2021.case-1.5,2020.acl-main.718,0,0.0827499,"Missing"
2021.case-1.5,W15-0809,0,0.0287117,"good domain knowledge. We report the statistics of our dataset in Figures 2 and 3. In figure 2 we can observe the amount of redundancy and irrelevance prevalent in the extracted sentence-level information. In figure 3, we observe that although a number of arExisting Document-Level IE Datasets Information Extraction (IE) is a well-researched domain albeit mostly at the sentence-level. EventArgument Extraction, the IE task most related to the task of aggregation has a number of welldocumented and reliable datasets annotated at the sentence level in different languages like ACE 2005 and TAC KBP (Mitamura et al., 2015) datasets. IE tasks with a document-level focus 22 gument roles in a document constitute of a single relevant argument mention (referred to as Singles), a significant number of argument roles constitute of multiple number of relevant argument mentions (referred to as Multiples). This highlights the fact that the number of relevant arguments for a particular argument role or type can be flexible and the model should be able to accommodate that flexibility. We release the manually annotated test set along with the annotation guidelines to further research prospects in this novel task.1 Figure 4:"
2021.case-1.5,N16-1034,0,0.178684,"accurate systems, in real life, annotating a large corpus can be both very expensive and time consuming. In order to surmount the existing shortcomings coupled with the challenging scenario of data scarcity, we propose our model ArgFuse. ArgFuse focuses on extraction of relevant and non-redundant event arguments at a document DebanjanaKar/ArgFuse 1 Introduction Extraction of event argument information at a document level is an important non-trivial task that requires a system to have advanced natural language understanding capabilities. Most of the existing event-argument extraction systems (Nguyen et al., 2016; Luan et al., 2019; Wadden et al., 2019; Veyseh et al., 2020) pertain to a sentence-level focus, 20 Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE) , pages 20–30 August 5–6, 2021, ©2021 Association for Computational Linguistics level scope. The task of document level event argument extraction typically focuses on extracting argument mentions associated with an event type or event trigger from a document. It does not involve checking extracted arguments for irrelevant and redundant mentions. Through our work, we"
2021.case-1.5,2020.acl-main.670,0,0.0406994,"Missing"
2021.case-1.5,P08-1030,0,0.127597,"Missing"
2021.case-1.5,2020.coling-main.144,0,0.0651375,"Missing"
2021.case-1.5,2020.findings-emnlp.326,0,0.14698,"n be both very expensive and time consuming. In order to surmount the existing shortcomings coupled with the challenging scenario of data scarcity, we propose our model ArgFuse. ArgFuse focuses on extraction of relevant and non-redundant event arguments at a document DebanjanaKar/ArgFuse 1 Introduction Extraction of event argument information at a document level is an important non-trivial task that requires a system to have advanced natural language understanding capabilities. Most of the existing event-argument extraction systems (Nguyen et al., 2016; Luan et al., 2019; Wadden et al., 2019; Veyseh et al., 2020) pertain to a sentence-level focus, 20 Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE) , pages 20–30 August 5–6, 2021, ©2021 Association for Computational Linguistics level scope. The task of document level event argument extraction typically focuses on extracting argument mentions associated with an event type or event trigger from a document. It does not involve checking extracted arguments for irrelevant and redundant mentions. Through our work, we also propose the related task of Argument Aggregation which fo"
2021.case-1.5,D19-1585,0,0.105184,"ing a large corpus can be both very expensive and time consuming. In order to surmount the existing shortcomings coupled with the challenging scenario of data scarcity, we propose our model ArgFuse. ArgFuse focuses on extraction of relevant and non-redundant event arguments at a document DebanjanaKar/ArgFuse 1 Introduction Extraction of event argument information at a document level is an important non-trivial task that requires a system to have advanced natural language understanding capabilities. Most of the existing event-argument extraction systems (Nguyen et al., 2016; Luan et al., 2019; Wadden et al., 2019; Veyseh et al., 2020) pertain to a sentence-level focus, 20 Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE) , pages 20–30 August 5–6, 2021, ©2021 Association for Computational Linguistics level scope. The task of document level event argument extraction typically focuses on extracting argument mentions associated with an event type or event trigger from a document. It does not involve checking extracted arguments for irrelevant and redundant mentions. Through our work, we also propose the related task of Argumen"
2021.case-1.5,N19-1308,0,0.135554,"real life, annotating a large corpus can be both very expensive and time consuming. In order to surmount the existing shortcomings coupled with the challenging scenario of data scarcity, we propose our model ArgFuse. ArgFuse focuses on extraction of relevant and non-redundant event arguments at a document DebanjanaKar/ArgFuse 1 Introduction Extraction of event argument information at a document level is an important non-trivial task that requires a system to have advanced natural language understanding capabilities. Most of the existing event-argument extraction systems (Nguyen et al., 2016; Luan et al., 2019; Wadden et al., 2019; Veyseh et al., 2020) pertain to a sentence-level focus, 20 Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE) , pages 20–30 August 5–6, 2021, ©2021 Association for Computational Linguistics level scope. The task of document level event argument extraction typically focuses on extracting argument mentions associated with an event type or event trigger from a document. It does not involve checking extracted arguments for irrelevant and redundant mentions. Through our work, we also propose the re"
2021.case-1.5,P18-4009,0,0.29901,"Veyseh et al., 2020) focus on sentence-level tasks and are hardly able to capture the consolidated information from a given document. In our endeavour to generate precise document-level information frames from lengthy textual records, we introduce the task of Information Aggregation or Argument Aggregation. More specifically, our aim is to filter irrelevant and redundant argument mentions that were extracted at a sentence level and render a document level information frame. Majority of the existing works have been observed to resolve related tasks of document-level event argument extraction (Yang et al., 2018; Zheng et al., 2019) and salient entity identification (Jain et al., 2020) using supervised techniques. To remove dependency from large amounts of labeled data , we explore the task of information aggregation using weakly-supervised techniques. In particular, we present an extractive algorithm with multiple sieves which adopts active learning strategies to work efficiently in low-resource settings. For this task, we have annotated our own test dataset comprising of 131 document information frames and have released the code and dataset to further research prospects in this new domain. To the b"
2021.case-1.5,D19-1032,0,0.0363882,"Missing"
2021.eacl-srw.16,K17-3002,0,0.0551209,"Missing"
2021.eacl-srw.16,P18-1128,0,0.0258754,"Missing"
2021.eacl-srw.16,P15-1033,0,0.0802722,"Missing"
2021.eacl-srw.16,D17-1169,0,0.0646223,"Missing"
2021.eacl-srw.16,L18-1550,0,0.0637568,"Missing"
2021.eacl-srw.16,2020.sigmorphon-1.23,1,0.88535,"Missing"
2021.eacl-srw.16,P18-1031,0,0.0352711,"Missing"
2021.eacl-srw.16,2020.acl-main.560,0,0.0233397,"Missing"
2021.eacl-srw.16,Q16-1023,0,0.065827,"Missing"
2021.eacl-srw.16,D19-1279,0,0.0526929,"Missing"
2021.eacl-srw.16,2020.cl-4.4,1,0.851004,"Missing"
2021.eacl-srw.16,W19-7724,0,0.0612385,"Missing"
2021.eacl-srw.16,D19-1277,0,0.0216705,"Missing"
2021.eacl-srw.16,P18-1130,0,0.051236,"Missing"
2021.eacl-srw.16,P13-2017,0,0.0782404,"Missing"
2021.eacl-srw.16,Q19-1003,0,0.0609113,"Missing"
2021.eacl-srw.16,K18-2008,0,0.0263261,"Missing"
2021.eacl-srw.16,N18-1202,0,0.023371,"Missing"
2021.eacl-srw.16,Q19-1044,0,0.0341017,"Missing"
2021.eacl-srw.16,K17-3007,0,0.0567352,"Missing"
2021.eacl-srw.16,D18-1278,0,0.0497799,"Missing"
2021.eacl-srw.16,D19-1102,0,0.0393819,"Missing"
2021.eacl-srw.16,P18-4013,0,0.0506837,"Missing"
2021.eacl-srw.16,K18-2001,0,0.0493618,"Missing"
2021.ecnlp-1.2,D10-1098,0,0.0384609,"alues. However, attribute information is often sparse, noisy and incomplete with missing values. For example, Figure 1 shows a product with its description and attribute value pairs available on the website. It contains attribute values for Brand Name, Type etc., but there are missing attributes, such as “Dual-coil” for Pickup Type, “6” for Strings etc. Given the wide diversity of products and new products constantly emerging, it is important that attribute value extraction works with the open world assumption, i.e., values for the attributes not seen before. Earlier work (Ghani et al., 2006; Chiticariu et al., 2010; Gopalakrishnan et al., 2012) for attribute value extraction use a rule based approach with the help of a domain specific seed dictionary to identify the key phrases. Other work have formulated this as named entity recognition (NER) problem (Putthividhya and Hu, 2011; More, 2016). However, these approaches do not work under the open world assumption. More recently, various neural network based approaches have been proposed and applied to sequence tagging model for attribute value extraction. Huang et al. (2015) is the first to apply the BiLSTM-CRF model for sequence tagging. Zheng et al. (201"
2021.ecnlp-1.2,2020.acl-main.225,0,0.0284899,"t extractive or classification based approaches, we have taken a generative approach to identify attribute values. Text generation using language models has several applications in real-world tasks such as text-editing, article writing, sentence completion, etc. Text infilling aims to fill the missing part of a given sentence. Motivated by their success as well as to leverage the large scale pretraining of the language models, we formulate the attribute value extraction as an instance of text infilling task as well as an answer generation task. We utilize Infilling by Language Modeling (ILM) (Donahue et al., 2020) for the infilling approach and we fine-tune Text-to-Text Transfer Transformer (T5) (Raffel et al., 2020) as an answer generation task. We summarize the main contribution of this work as follows: • We propose a language modeling approach for attribute value extraction. • We empirically demonstrate that this approach achieves state-of-the-art results on discovering new attribute values. 2 Train 76,970 7,969 2,824 735 662 Valid 10,996 1,095 373 112 86 test 21,991 2,348 752 197 206 Table 1: Statistics of the AV-109K dataset and its four frequent attributes tributes Type and Fingerboard Material."
2021.ecnlp-1.2,P19-1514,0,0.0803979,"t catalogue often with new at13 Proceedings of the 4th Workshop on e-Commerce and NLP (ECNLP 4), pages 13–17 August 5, 2021. ©2021 Association for Computational Linguistics Attributes All Brand Name Material Color Category tionary or hand-crafted features. Most of these approaches create separate models for different attributes. Also, for each attribute a, they have one set of tags to denote beginning (Ba ) and inside (Ia ) of that attribute. Hence, these methods are not scalable for large set of attributes and these models can not identify emerging values for unseen attributes. Recent works (Xu et al., 2019; Wang et al., 2020) have set up this task as question answering (QA) task. Question answering in machine reading comprehension (MRC) selects a span of text from the given context to answer the question. Xu et al. (2019) considers product title as context, attribute as query, and proposes to find the attribute value using only global set of BIO tags. Although the sequence tagging models (Zheng et al., 2018; Xu et al., 2019) achieve promising result, they do not work well for discovering new attributes values. In contrast to past extractive or classification based approaches, we have taken a ge"
2021.ecnlp-1.2,D11-1144,0,0.0423449,"t there are missing attributes, such as “Dual-coil” for Pickup Type, “6” for Strings etc. Given the wide diversity of products and new products constantly emerging, it is important that attribute value extraction works with the open world assumption, i.e., values for the attributes not seen before. Earlier work (Ghani et al., 2006; Chiticariu et al., 2010; Gopalakrishnan et al., 2012) for attribute value extraction use a rule based approach with the help of a domain specific seed dictionary to identify the key phrases. Other work have formulated this as named entity recognition (NER) problem (Putthividhya and Hu, 2011; More, 2016). However, these approaches do not work under the open world assumption. More recently, various neural network based approaches have been proposed and applied to sequence tagging model for attribute value extraction. Huang et al. (2015) is the first to apply the BiLSTM-CRF model for sequence tagging. Zheng et al. (2018) propose an end-to-end tagging model using BiLSTM, CRF and attention without any dicIntroduction Product attributes and their values play an important role in e-commerce platforms. There are hundreds of thousands of products sold online and each type of product has"
2021.emnlp-main.731,2021.naacl-main.453,0,0.0672995,"mitation by proposing a novel grid tagging scheme-based approach. However, they end up predicting the relationship between every possible word pair, irrespective of how they are syntactically connected, thereby impacting the span-level sentiment consistency guarantees. Different from all these tagging-based methods, 1 we propose to investigate the utility of a taggingfree scheme for the task. Our innovation lies in formulating ASTE as a structured prediction problem. Taking motivation from similar sequenceto-sequence approaches proposed for joint entityrelation extraction (Nayak and Ng, 2020; Chen et al., 2021), semantic role labeling (Fei et al., 2021) etc., we propose PASTE, a Pointer Networkbased encoder-decoder architecture for the task of ASTE. The pointer network effectively captures the aspect-opinion interdependence while detecting their respective spans. The decoder then learns to model the span-level interactions while predicting the connecting sentiment. An entire opinion triplet is thus decoded at every time step, thereby making our solution end-to-end. We note here however, that the aspect and opinion spans can be of varying lengths, which makes the triplet decoding process challenging."
2021.emnlp-main.731,2020.acl-main.340,0,0.0255464,"r ; gloomy ; negative (2) food ; tasty ; positive Table 1: Examples of Aspect-Opinion-Sentiment triplets (opinion triplets) present in review sentences. automatically extracting the opinion targets or aspects being discussed in review sentences, along with the sentiments expressed towards them. Early efforts on Aspect-level Sentiment Classification (Tay et al., 2018; Li et al., 2018a; Xue and Li, 2018) focus on predicting the sentiment polarities for given aspects. However, in a real-world scenario, aspects may not be known a-priori. Works on End-to-End ABSA (Li et al., 2019; He et al., 2019; Chen and Qian, 2020) thus focus on extracting the aspects as well as the corresponding sentiments simultaneously. These methods do not however capture the reasons behind the expressed sentiments, which could otherwise provide valuable clues for more effective extraction of aspect-sentiment pairs. Consider the two examples shown in Table 1. For the first sentence, the sentiment associated with the aspect film, changes depending on the connecting opinion phrases; good suggesting a positive sentiment, and could have been better indicating a negative sentiment. Hence, simply extracting the pairs film-positive, and fi"
2021.emnlp-main.731,P19-1520,0,0.0134258,"d) of the Bi-LSTM-based encoder are set to 150 each. dp is set to 300. For our BERT experiments, uncased version of pre-trained BERT-base (Devlin et al., 2019) is fine-tuned to encode each sentence. All our model variants are trained end-to-end on Tesla P100-PCIE 16GB GPU with Adam optimizer (learning rate: 10−3 , weight decay: 10−5 ). A dropout rate of 0.5 is applied on the embeddings to avoid overfitting3 . We make our codes and datasets publicly available4 . 3 4 Please refer to the appendix for more details. https://github.com/rajdeep345/PASTE/ 3.3 Baselines • Wang et al. (2017) (CMLA) and Dai and Song (2019) (RINANTE) propose different methods to co-extract aspects and opinion terms from review sentences. Li et al. (2019) propose a unified tagging scheme-based method for extracting opinion target-sentiment pairs. Peng et al. (2020) modifies these methods to jointly extract targets with sentiment, and opinion spans. It then applies an MLP-based classifier to determine the validity of all possible generated triplets. These modified versions are referred to as CMLA+ , RINANTE+ , and Li-unified-R, respectively. • Peng et al. (2020) propose a BiLSTM+GCNbased approach to co-extract aspect-sentiment pai"
2021.emnlp-main.731,N19-1423,0,0.0894146,"ut sentences. All three features are concatenated to obtain the input vector representation xi ∈ Rdw +dpos +ddep corresponding to the ith word in the given sentence S = {w1 , w2 , ..., wn }. The vectors are passed through the Bi-LSTM to dh obain the contextualized representations hE i ∈R . Here, dh represents the hidden state dimension of the triplet generating LSTM decoder as detailed in the next section. Accordingly, the hidden state dimension of both the forward and backward LSTM of the Bi-LSTM encoder are set to dh /2. For the BERT-based variant of our model, BiLSTM gets replaced by BERT (Devlin et al., 2019) as the sentence encoder. The pre-trained word vectors are accordingly replaced by BERT token embeddings. We now append the POS and DEP features vectors to the 768-dim. token-level outputs from the final layer of BERT. 2.3.2 Pointer Network-based Decoder Span Detection with Pointer Networks Our pointer network consists of a Bi-LSTM, with hidden dimension dp , followed by two feedforward layers (FFN) on top to respectively predict the start and end locations of an entity span. We use two such pointer networks to produce a tuple of hidden vectors corresponding to the aspect and opinion spans of"
2021.emnlp-main.731,N19-1259,0,0.0354518,"Missing"
2021.emnlp-main.731,P19-1048,0,0.0167926,"asty . (1) weather ; gloomy ; negative (2) food ; tasty ; positive Table 1: Examples of Aspect-Opinion-Sentiment triplets (opinion triplets) present in review sentences. automatically extracting the opinion targets or aspects being discussed in review sentences, along with the sentiments expressed towards them. Early efforts on Aspect-level Sentiment Classification (Tay et al., 2018; Li et al., 2018a; Xue and Li, 2018) focus on predicting the sentiment polarities for given aspects. However, in a real-world scenario, aspects may not be known a-priori. Works on End-to-End ABSA (Li et al., 2019; He et al., 2019; Chen and Qian, 2020) thus focus on extracting the aspects as well as the corresponding sentiments simultaneously. These methods do not however capture the reasons behind the expressed sentiments, which could otherwise provide valuable clues for more effective extraction of aspect-sentiment pairs. Consider the two examples shown in Table 1. For the first sentence, the sentiment associated with the aspect film, changes depending on the connecting opinion phrases; good suggesting a positive sentiment, and could have been better indicating a negative sentiment. Hence, simply extracting the pairs"
2021.emnlp-main.731,2020.acl-main.703,0,0.0737195,"Missing"
2021.emnlp-main.731,2020.acl-main.631,0,0.0214763,"Missing"
2021.emnlp-main.731,P18-1087,0,0.0160069,"Sent 2: Triplets The film was good , but could have been better . [Aspect ; Opinion ; Sentiment] (1) film ; good ; positive (2) film ; could have been better ; negative The weather was gloomy , but the food was tasty . (1) weather ; gloomy ; negative (2) food ; tasty ; positive Table 1: Examples of Aspect-Opinion-Sentiment triplets (opinion triplets) present in review sentences. automatically extracting the opinion targets or aspects being discussed in review sentences, along with the sentiments expressed towards them. Early efforts on Aspect-level Sentiment Classification (Tay et al., 2018; Li et al., 2018a; Xue and Li, 2018) focus on predicting the sentiment polarities for given aspects. However, in a real-world scenario, aspects may not be known a-priori. Works on End-to-End ABSA (Li et al., 2019; He et al., 2019; Chen and Qian, 2020) thus focus on extracting the aspects as well as the corresponding sentiments simultaneously. These methods do not however capture the reasons behind the expressed sentiments, which could otherwise provide valuable clues for more effective extraction of aspect-sentiment pairs. Consider the two examples shown in Table 1. For the first sentence, the sentiment assoc"
2021.emnlp-main.731,2020.findings-emnlp.234,0,0.148033,"traction process. While the former additionally suffers from error propagation problem, the latter, relying on word-level sentiment dependencies, cannot guarantee sentiment consistency over multi-word aspect/opinion spans. Xu et al. (2020b) propose a novel position-aware tagging scheme (extending BIEOS tags) to better capture the interactions among the three opinion factors. One of their model variants however cannot detect aspect-overlapped triplets, while the other cannot identify opinion-overlapped triplets. Hence, they need an ensemble of two variants to be trained for handling all cases. Wu et al. (2020) try to address this limitation by proposing a novel grid tagging scheme-based approach. However, they end up predicting the relationship between every possible word pair, irrespective of how they are syntactically connected, thereby impacting the span-level sentiment consistency guarantees. Different from all these tagging-based methods, 1 we propose to investigate the utility of a taggingfree scheme for the task. Our innovation lies in formulating ASTE as a structured prediction problem. Taking motivation from similar sequenceto-sequence approaches proposed for joint entityrelation extractio"
2021.emnlp-main.731,D14-1162,0,0.0868277,"esults on the individual datasets. Additionally, we also conduct experiments on the combined restaurant dataset, henceforth referred to as the Restaurant. Tables 3 and 4 present the dataset statistics. We consider precision, recall, and micro-F1 as our evaluation metrics for the triplet extraction task. A predicted triplet is considered a true positive only if all three predicted elements exactly match with those of a ground-truth opinion triplet. 3.2 Experimental Setup For our non-BERT experiments, word embeddings are initialized (and kept trainable) using pre-trained 300-dim. Glove vectors (Pennington et al., 2014), and accordingly dw is set to 300. dpos and ddep are set to 50 each. dh is set to 300, and accordingly the hidden state dimensions of both the LSTMs (backward and forward) of the Bi-LSTM-based encoder are set to 150 each. dp is set to 300. For our BERT experiments, uncased version of pre-trained BERT-base (Devlin et al., 2019) is fine-tuned to encode each sentence. All our model variants are trained end-to-end on Tesla P100-PCIE 16GB GPU with Adam optimizer (learning rate: 10−3 , weight decay: 10−5 ). A dropout rate of 0.5 is applied on the embeddings to avoid overfitting3 . We make our codes"
2021.emnlp-main.731,N19-1242,0,0.0485002,"Missing"
2021.emnlp-main.731,S14-2004,0,0.10441,"Missing"
2021.emnlp-main.731,2020.findings-emnlp.156,0,0.0210928,"Missing"
2021.emnlp-main.731,P18-2094,0,0.020851,"sed on F1 scores on the development set. We report our median scores over 5 runs of the 15Rest, and 16Rest (both w/ and w/o BERT). Howexperiment. Performance comparisons on the Lap- ever, owing to resource constraints and known optimization issues with their codes, we could not replitop (14Lap) and combined Restaurant datasets are cate their results on the Restaurant dataset beyond reported in Table 5, whereas the same on individual M = 4 (for both w/ and w/o BERT). GTS uses dourestaurant datasets are reported in Table 6. Both the tables are divided into two sections; the for- ble embeddings (Xu et al., 2018) (general Glove vectors + domain-specific embeddings trained with mer comparing the results without BERT, and the fastText). For fair comparison, we replicate their latter comparing those with BERT. The scores for + + results without using the domain-specific embedCMLA , RINANTE , Li-unified-R, and (Peng dings (DE). For both w/ and w/o BERT, we report et al., 2020) are taken from Xu et al. (2020b). We replicate the results for OTE-MTL on ASTE-Data- their median scores over 5 runs of the experiment. We also report the F1 scores on the development V2 and report their average scores over 10 runs"
2021.emnlp-main.731,2020.emnlp-main.183,0,0.0673148,"Missing"
2021.emnlp-main.731,P18-1234,0,0.0206484,"The film was good , but could have been better . [Aspect ; Opinion ; Sentiment] (1) film ; good ; positive (2) film ; could have been better ; negative The weather was gloomy , but the food was tasty . (1) weather ; gloomy ; negative (2) food ; tasty ; positive Table 1: Examples of Aspect-Opinion-Sentiment triplets (opinion triplets) present in review sentences. automatically extracting the opinion targets or aspects being discussed in review sentences, along with the sentiments expressed towards them. Early efforts on Aspect-level Sentiment Classification (Tay et al., 2018; Li et al., 2018a; Xue and Li, 2018) focus on predicting the sentiment polarities for given aspects. However, in a real-world scenario, aspects may not be known a-priori. Works on End-to-End ABSA (Li et al., 2019; He et al., 2019; Chen and Qian, 2020) thus focus on extracting the aspects as well as the corresponding sentiments simultaneously. These methods do not however capture the reasons behind the expressed sentiments, which could otherwise provide valuable clues for more effective extraction of aspect-sentiment pairs. Consider the two examples shown in Table 1. For the first sentence, the sentiment associated with the aspec"
2021.emnlp-main.731,2020.findings-emnlp.72,0,0.135526,"Sent. 1 in Table 1 share the aspect film). An efficient solution for the task must therefore be able to handle such challenging data points. Peng et al. (2020) propose a two-stage pipeline framework. In the first stage, they extract aspectsentiment pairs and opinion spans using two separate sequence-tagging tasks, the former leveraging a unified tagging scheme proposed by (Li et al., 2019), and the later based on BIEOS1 tagging scheme. In the second stage, they pair up the extracted aspect and opinion spans, and use an MLP-based classifier to determine the validity of each generated triplet. Zhang et al. (2020) propose a multi-task framework to jointly detect aspects, opinions, and sentiment dependencies. Although they decouple the sentiment prediction task from aspect extraction, they use two separate sequence taggers (BIEOS-based) to detect the aspect and opinion spans in isolation before predicting the connecting sentiment. Both these methods however break the interaction between aspects and opinions during the extraction process. While the former additionally suffers from error propagation problem, the latter, relying on word-level sentiment dependencies, cannot guarantee sentiment consistency o"
2021.findings-acl.447,D18-1276,1,0.786097,"s compared to ASR systems that use native scripts.1 1 Introduction Sanskrit is a language with fairly advanced disciplines of phonetics (Śiksā),  prosody (Chandas), and grammar (Vyākaran a). The language has a rich oral tradition and it tends to follow a phonemic-orthography resulting in systematic ∗ Joint first author Dataset and code can be accessed from www.cse.iitb.ac.in/~asr and https://github. com/cyfer0618/Vaksanca.git. 1 grapheme-phoneme correspondences. Connected speech leads to phonemic transformations in utteracnes, and in Sanskrit this is faithfully preserved in writing as well (Krishna et al., 2018). This is called as Sandhi and is defined as the euphonic assimilation of sounds, i.e., modification and fusion of sounds, at or across the boundaries of grammatical units (Matthews, 2007, p. 353). Phonemic orthography is beneficial for a language, when it comes to designing automatic speech recognition Systems (ASR), specifically for unit selection at both the Acoustic Model (AM) and Language Model (LM) levels. Regardless of the aforementioned commonalities preserved in both the speech and text in Sanskrit, designing a large scale ASR system raises several challenges. The Unicode encoding for"
2021.findings-acl.447,P19-1111,1,0.830009,"then output += ci ; else if ci+1 is C and ci+2 is V and ci+2 is first vowel of the word then output += ci ; else if ci+1 is C and ci+2 is V then output += ci + “ ”; BPE-based Word Segmentation Byte pair encoding (BPE) is a simple data compression algorithm that iteratively replaces the frequently occurring subword units with a single unused byte (Gage, 1994). This technique was first adopted to model rare words using subword units in neural machine translation (Sennrich et al., 2016). Interestingly, BPE has been explored for learning new vocabulary for poetry to prose conversion in Sanskrit (Krishna et al., 2019). We consider the benefits of using BPE as a subword unit for Sanskrit ASR. While BPE is a purely data-driven segmentation strategy, we next present a linguistically motivated segmentation approach that might be aligned with finding syllable units for ASR that are more phonetically compliant. We refer to this technique as vowel segmentation. 3.2.2 Vowel Segmentation Splitting the tokens based on vowels and adjacent consonants is inspired by the identification of metres in Sanskrit prosody, where the metre of a verse is identified by using syllable segmentation, followed by identification of sy"
2021.findings-acl.447,2020.lrec-1.874,1,0.673818,"re possible in utterance of long text sequences where multiple lexical items are fused together via Sandhi. These segmentations are accompanied with the corresponding Sandhi based transformations, resulting in a new phonetic sequence different from the original sequence. Finally, Sanskrit might be one of those rare natural languages where the number of non-native proficient speakers are 5039 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 5039–5050 August 1–6, 2021. ©2021 Association for Computational Linguistics manifold in comparison to the native speakers (Krishna et al., 2020). This makes the ASR task further challenging, as the speakers are prone to carry their influence from their corresponding mother tongues into the Sanskrit utterances as well. While there exist several computational models for processing Sanskrit texts (Kulkarni, 2013; Kumar et al., 2010; Shukla et al., 2010; Kulkarni et al., 2010a; Goyal et al., 2012; Kulkarni et al., 2010c; Mishra et al., 2013; Saluja et al., 2017; Anoop and Ramakrishnan, 2019; Krishna et al., 2021), large scale systems for processing of speech in Sanskrit, are almost non-existent. First, we present a new dataset, with 78 ho"
2021.findings-acl.447,W13-3718,0,0.0212995,"ally, Sanskrit might be one of those rare natural languages where the number of non-native proficient speakers are 5039 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 5039–5050 August 1–6, 2021. ©2021 Association for Computational Linguistics manifold in comparison to the native speakers (Krishna et al., 2020). This makes the ASR task further challenging, as the speakers are prone to carry their influence from their corresponding mother tongues into the Sanskrit utterances as well. While there exist several computational models for processing Sanskrit texts (Kulkarni, 2013; Kumar et al., 2010; Shukla et al., 2010; Kulkarni et al., 2010a; Goyal et al., 2012; Kulkarni et al., 2010c; Mishra et al., 2013; Saluja et al., 2017; Anoop and Ramakrishnan, 2019; Krishna et al., 2021), large scale systems for processing of speech in Sanskrit, are almost non-existent. First, we present a new dataset, with 78 hours of speech covering about 46,000 sentences, for ASR in Sanskrit. Keeping the rich and long cultural heritage the language carries, we prepare our dataset to be diverse both chronologically and in terms of the domain coverage. Further, the dataset contains utterance"
2021.findings-acl.447,D13-1019,0,0.0131228,"”. In prior work involving Indian languages for TTS, Kishore et al. (2002) proposed various syllabification rules for words. Herein (with a few exceptions), if a vowel is followed by 3 or more consonants, only the first following vowel is grouped with the preceding vowel to form the subword unit. Our proposed algorithm for vowel segmentation (VS) is outlined in Algorithm 1. We propose segmenting words at vowel boundaries to extract the units for which alignment with speech is learnt within the ASR system. For acoustic models, an effective unit of a word for ASR would arguably be the syllable (Lee et al., 2013). Representing a word in terms of syllables demands the mapping of a word from graphemes to phonemes. To create syllable units, phonemes are then combined together based on the sonority sequencing principle (Clements, 1990). Absence of accurate syllabifiers for Indian languages restricts the use of syllables as units for learning alignment. Our approach produces units which can be viewed as a rough approximation to a syllable. A syllable is composed of three parts viz., onset, nucleus and coda, where nucleus has the highest sonority and is always a vowel. In our approach, the onset is always o"
2021.findings-acl.447,P16-1162,0,0.00864625,"= ci ; else if ci+1 is C and ci+2 is V then output += ci + “ ”; else if ci+1 is V then output += ci ; else if ci+1 is C and ci+2 is C then output += ci ; else if ci+1 is C and ci+2 is V and ci+2 is first vowel of the word then output += ci ; else if ci+1 is C and ci+2 is V then output += ci + “ ”; BPE-based Word Segmentation Byte pair encoding (BPE) is a simple data compression algorithm that iteratively replaces the frequently occurring subword units with a single unused byte (Gage, 1994). This technique was first adopted to model rare words using subword units in neural machine translation (Sennrich et al., 2016). Interestingly, BPE has been explored for learning new vocabulary for poetry to prose conversion in Sanskrit (Krishna et al., 2019). We consider the benefits of using BPE as a subword unit for Sanskrit ASR. While BPE is a purely data-driven segmentation strategy, we next present a linguistically motivated segmentation approach that might be aligned with finding syllable units for ASR that are more phonetically compliant. We refer to this technique as vowel segmentation. 3.2.2 Vowel Segmentation Splitting the tokens based on vowels and adjacent consonants is inspired by the identification of m"
2021.findings-emnlp.392,2020.emnlp-main.394,0,0.121785,"uestion. We use an unsupervised IR method that accepts a question and all sections of the E-Manual as input and provides similarity scores for each question-section as output (details in suppl.) The flow of the entire EMQAP is depicted in Fig. 2. The steps are also presented as Algorithm in suppl.. gies to efficiently capture both the generic and domain-specific knowledge required to answer a question. (a). Using a learning rate that linearly decreases by a constant factor (LRD) from one layer to the next, with the outermost language modeling head layer having the maximum learning rate, as in Arumae et al. (2020). This enforces a constraint that outer layers adapt more to the E-Manual domain, while the inner layers’ weights do not change much, thus restricting them to retain the knowledge of the generic domain primarily. (b). Using elastic weight consolidation (EWC) (Kirkpatrick et al., 2017; Arumae et al., 2020) to mitigate catastrophic forgetting while switching from the generic domain on which original ""RoBERTa"" was pre-trained to the domain of E-Manuals. A batch size of 64 is used. Since our corpus size (11GB) is quite small compared to the datasets used for pre-training in Liu et al. (2019), we u"
2021.findings-emnlp.392,D19-1371,0,0.0224298,"device. This often poses a challenge in building a question answering system because the answer to a question may come from multiple disjointed portions within a section of the E-Manual. Due to the instructional nature of EManuals, we also find that often adjacent instructions are not related to each other but may be related to a parental instruction leading to long-range dependencies in context. This, therefore, deems a domain-specific natural language understanding which may, in turn, suffer from lack of domainspecific labeled data (Araci, 2019) and presence of formal syntax in the corpus (Beltagy et al., 2019; Chalkidis et al., 2020). These challenges have led recent works to pre-train the state-of-the-art transformer models on unlabelled domain-specific corpora (Lee et al., 2020; Araci, 2019; Beltagy et al., 2019; Chalkidis et al., 2020). Inspired by such works, we painstakingly collect E-Manual Corpus: a huge corpus of 307,957 E-manuals1 and pre-train the transformer-based language model, RoBERTa_BASE2 on the corpus (Section 3.1). A question answering system needs to select the relevant section of the E-Manual, which contains the answer to the given question (section retrieval (SR)) and subseque"
2021.findings-emnlp.392,2020.acl-main.117,0,0.187677,"e an unsupervised IR method that accepts a question and all sections of the E-Manual as input and provides similarity scores for each question-section as output (details in suppl.) The flow of the entire EMQAP is depicted in Fig. 2. The steps are also presented as Algorithm in suppl.. gies to efficiently capture both the generic and domain-specific knowledge required to answer a question. (a). Using a learning rate that linearly decreases by a constant factor (LRD) from one layer to the next, with the outermost language modeling head layer having the maximum learning rate, as in Arumae et al. (2020). This enforces a constraint that outer layers adapt more to the E-Manual domain, while the inner layers’ weights do not change much, thus restricting them to retain the knowledge of the generic domain primarily. (b). Using elastic weight consolidation (EWC) (Kirkpatrick et al., 2017; Arumae et al., 2020) to mitigate catastrophic forgetting while switching from the generic domain on which original ""RoBERTa"" was pre-trained to the domain of E-Manuals. A batch size of 64 is used. Since our corpus size (11GB) is quite small compared to the datasets used for pre-training in Liu et al. (2019), we u"
2021.findings-emnlp.392,P17-1171,0,0.0238404,"t al., 2019; Chalkidis et al., 2020). Inspired by such works, we painstakingly collect E-Manual Corpus: a huge corpus of 307,957 E-manuals1 and pre-train the transformer-based language model, RoBERTa_BASE2 on the corpus (Section 3.1). A question answering system needs to select the relevant section of the E-Manual, which contains the answer to the given question (section retrieval (SR)) and subsequently, extract the answer from that relevant section (answer retrieval (AR)). There are currently four main types of approaches in state-of-the-art literature that utilize the SR and AR systems (1). Chen et al. (2017) uses a two-stage training pipeline where the SR model consists of an unsupervised Information Retrieval (IR) method like TF-IDF or BM25, followed by an An E-Manual, or Electronic Manual, is a document that provides technical support to the consumers of a product by giving instructions and procedures to operate the device along with know-how of its 1 www.manualsonline.com 2 specifications. It is often difficult to find the relNote that, in this paper, unless otherwise specified, evant instructions from an E-manual; hence, an ‘RoBERTa’ would just mean ‘RoBERTa_BASE’ 4600 Findings of the Associa"
2021.findings-emnlp.392,P19-1264,0,0.0262501,"Missing"
2021.findings-emnlp.392,N19-1423,0,0.00892788,"raging the GloVe word Embeddings) are weighted by the sentence lengths, and a bag of words and sentence embeddings is created. To obtain the similarity value, a linear programming solution is used to measure the distance a predicted answer’s embedding has to be moved to match the actual answer. 4.3 Evaluating MTL framework Baselines: We compare EMQAP with other baselines such as To assess the efficiency of EMQAP, we first evalu- (A) Method based on efficient passage retrieval Dense Passage Retrieval (DPR) (Karpukhin et al., ate the performance of the unsupervised retrieval 2020): A dual BERT (Devlin et al., 2019) encoder algorithm followed by the MTL Framework on the datasets specifically curated in Sections 2.2 – 2.4. framework is used for retrieving relevant sections, and after retrieving the relevant sections, it assigns The experimental results of unsupervised algorithm a passage selection score to each passage. Finally, is detailed in suppl. We found that the proposed a span selection method selects the span from the algorithm TF-IDF + T5 performs the best. section with the highest score as the answer. We 4.1 Experimental Setup fine-tune the dual-encoder framework and the span We set the unsuperv"
2021.findings-emnlp.392,2020.emnlp-main.550,0,0.029779,"Missing"
2021.findings-emnlp.392,P19-1612,0,0.0199912,"upport to the consumers of a product by giving instructions and procedures to operate the device along with know-how of its 1 www.manualsonline.com 2 specifications. It is often difficult to find the relNote that, in this paper, unless otherwise specified, evant instructions from an E-manual; hence, an ‘RoBERTa’ would just mean ‘RoBERTa_BASE’ 4600 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 4600–4609 November 7–11, 2021. ©2021 Association for Computational Linguistics extractive AR model; (2) an end-to-end learning setup of SR cascaded by AR (Guu et al., 2020; Lee et al., 2019); (3) single-span (Rajpurkar et al., 2016) or multi-span (Zhu et al., 2020; Segal et al., 2020) answers given questions and corresponding candidate contexts as inputs and (4) a Multi-task Learning (MTL) Framework, where SR and AR are the two underlying tasks (Nishida et al., 2018); Nishida et al. (2018) performs MTL using separate SR and AR pipelines sharing feature extraction layers. The simultaneous training of SR and AR using MTL helps the model build a combined and hierarchical understanding of Question Answering at a global (section) and a local (sentence/token) level. However, these meth"
2021.findings-emnlp.392,W04-1013,0,0.0271932,"Missing"
2021.findings-emnlp.392,2021.ccl-1.108,0,0.0628453,"Missing"
2021.findings-emnlp.392,D14-1162,0,0.0890474,"Missing"
2021.findings-emnlp.392,2020.emnlp-main.248,0,0.172224,"ice along with know-how of its 1 www.manualsonline.com 2 specifications. It is often difficult to find the relNote that, in this paper, unless otherwise specified, evant instructions from an E-manual; hence, an ‘RoBERTa’ would just mean ‘RoBERTa_BASE’ 4600 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 4600–4609 November 7–11, 2021. ©2021 Association for Computational Linguistics extractive AR model; (2) an end-to-end learning setup of SR cascaded by AR (Guu et al., 2020; Lee et al., 2019); (3) single-span (Rajpurkar et al., 2016) or multi-span (Zhu et al., 2020; Segal et al., 2020) answers given questions and corresponding candidate contexts as inputs and (4) a Multi-task Learning (MTL) Framework, where SR and AR are the two underlying tasks (Nishida et al., 2018); Nishida et al. (2018) performs MTL using separate SR and AR pipelines sharing feature extraction layers. The simultaneous training of SR and AR using MTL helps the model build a combined and hierarchical understanding of Question Answering at a global (section) and a local (sentence/token) level. However, these methods apply a span-based selection approach for extracting answers, whereas the answers to questi"
2021.findings-emnlp.392,2020.findings-emnlp.342,0,0.0282077,"to operate the device along with know-how of its 1 www.manualsonline.com 2 specifications. It is often difficult to find the relNote that, in this paper, unless otherwise specified, evant instructions from an E-manual; hence, an ‘RoBERTa’ would just mean ‘RoBERTa_BASE’ 4600 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 4600–4609 November 7–11, 2021. ©2021 Association for Computational Linguistics extractive AR model; (2) an end-to-end learning setup of SR cascaded by AR (Guu et al., 2020; Lee et al., 2019); (3) single-span (Rajpurkar et al., 2016) or multi-span (Zhu et al., 2020; Segal et al., 2020) answers given questions and corresponding candidate contexts as inputs and (4) a Multi-task Learning (MTL) Framework, where SR and AR are the two underlying tasks (Nishida et al., 2018); Nishida et al. (2018) performs MTL using separate SR and AR pipelines sharing feature extraction layers. The simultaneous training of SR and AR using MTL helps the model build a combined and hierarchical understanding of Question Answering at a global (section) and a local (sentence/token) level. However, these methods apply a span-based selection approach for extracting answers, whereas"
2021.naacl-main.449,D19-5602,0,0.0309276,"Missing"
2021.naacl-main.449,D18-1547,0,0.0496098,"Missing"
2021.naacl-main.449,P19-1360,0,0.33672,"o shown that sitional encodings. We demonstrate that Hihierarchy is an important aspect of human convererarchical Encoding helps achieve better natsation (Jurafsky, 2000). But, most previous works ural language understanding of the contexts in based on transformer have focused on training modtransformer-based models for task-oriented dialog systems through a wide range of experiels either as language models (Budzianowski and ments. The code and data for all experiments Vuli´c, 2019; Zhang et al., 2020b) or as standard in this paper has been open-sourced1 2 . (non-hierarchical) Seq2Seq models (Chen et al., 2019; Zhang et al., 2020a; Wang et al., 2020) with 1 Introduction certain task specific extensions. Although arguably, the self-attention mechanism might automatically Dialog systems are concerned with replicating the human ability to make conversation. In a genera- learn such a scheme during the training process, our empirical results show that forcing this inductive dialog system, the model aims at generating tive bias by manual design as proposed here leads coherent and informative responses given a dialog to better performing models. ∗ Equal Contributions 1 Experiments in this paper: https://g"
2021.naacl-main.449,P18-1207,0,0.0278869,"g an Hierarchical LSTM and dialog features detected by an NLU module. network. Serban et al. (2016) extended this work to However, such models had the usual drawback of open domain dialog generation problems and proany pipelined approaches, error propagation. Wen posed the HRED network. HRED captures the high et al. (2017) proposed using neural networks for ex- level features of the conversation in a context RNN. tracting features like intent, belief states, etc. and Several models have adopted this approach later on, 5656 e.g. VHRED (Serban et al., 2017), CVAE (Zhao et al., 2017), DialogWAE (Gu et al., 2018), etc. Another area in which researchers have proposed the use of hierarchical encoder is for processing of paragraph or long documents. Li et al. (2015) used a hierarchical LSTM network for training an autoencoder that can encode and decode long paragraphs and documents. Zhang et al. (2019) proposed HIBERT where they introduced hierarchy into the BERT architecture to remove the limitation on length of input sequence. HIBERT samples a single vector for each sentence or document segment (usually contextual embedding of CLS or EOS token) from the sentence encoder to be passed onto the higher lev"
2021.naacl-main.449,P15-1107,0,0.0189744,"ual drawback of open domain dialog generation problems and proany pipelined approaches, error propagation. Wen posed the HRED network. HRED captures the high et al. (2017) proposed using neural networks for ex- level features of the conversation in a context RNN. tracting features like intent, belief states, etc. and Several models have adopted this approach later on, 5656 e.g. VHRED (Serban et al., 2017), CVAE (Zhao et al., 2017), DialogWAE (Gu et al., 2018), etc. Another area in which researchers have proposed the use of hierarchical encoder is for processing of paragraph or long documents. Li et al. (2015) used a hierarchical LSTM network for training an autoencoder that can encode and decode long paragraphs and documents. Zhang et al. (2019) proposed HIBERT where they introduced hierarchy into the BERT architecture to remove the limitation on length of input sequence. HIBERT samples a single vector for each sentence or document segment (usually contextual embedding of CLS or EOS token) from the sentence encoder to be passed onto the higher level transformer encoder. Liu and Lapata (2019) applies a similar approach for encoding documents in a multi-document summarization task. 6 Conclusion This"
2021.naacl-main.449,P19-1500,0,0.0211946,"hich researchers have proposed the use of hierarchical encoder is for processing of paragraph or long documents. Li et al. (2015) used a hierarchical LSTM network for training an autoencoder that can encode and decode long paragraphs and documents. Zhang et al. (2019) proposed HIBERT where they introduced hierarchy into the BERT architecture to remove the limitation on length of input sequence. HIBERT samples a single vector for each sentence or document segment (usually contextual embedding of CLS or EOS token) from the sentence encoder to be passed onto the higher level transformer encoder. Liu and Lapata (2019) applies a similar approach for encoding documents in a multi-document summarization task. 6 Conclusion This paper explored the use of hierarchy in transformer-based models for task-oriented dialog system. We started by proposing a generalized framework for Hierarchical Transformer Encoders (HT-Encoders). Using that, we implemented two models, one new model called HIER, and another HIER-CLS model by adapting the existing HIBERT architecture into our framework. We thoroughly experimented with these models in four different response generation tasks of the MultiWOZ dataset. We compared the propo"
2021.naacl-main.449,N15-1020,0,0.0710846,"Missing"
2021.naacl-main.449,2020.acl-main.638,0,0.0871396,"nstrate that Hihierarchy is an important aspect of human convererarchical Encoding helps achieve better natsation (Jurafsky, 2000). But, most previous works ural language understanding of the contexts in based on transformer have focused on training modtransformer-based models for task-oriented dialog systems through a wide range of experiels either as language models (Budzianowski and ments. The code and data for all experiments Vuli´c, 2019; Zhang et al., 2020b) or as standard in this paper has been open-sourced1 2 . (non-hierarchical) Seq2Seq models (Chen et al., 2019; Zhang et al., 2020a; Wang et al., 2020) with 1 Introduction certain task specific extensions. Although arguably, the self-attention mechanism might automatically Dialog systems are concerned with replicating the human ability to make conversation. In a genera- learn such a scheme during the training process, our empirical results show that forcing this inductive dialog system, the model aims at generating tive bias by manual design as proposed here leads coherent and informative responses given a dialog to better performing models. ∗ Equal Contributions 1 Experiments in this paper: https://github.com/ This paper bridges these two p"
2021.naacl-main.449,E17-1042,0,0.0753309,"Missing"
2021.naacl-main.449,P19-1499,0,0.159565,"tional Linguistics: Human Language Technologies, pages 5649–5658 June 6–11, 2021. ©2021 Association for Computational Linguistics attention mechanism of standard encoders might automatically learn such a scheme during the training process, our empirical results show that forcing this inductive bias by manual design as proposed here leads to better performing models. Our contributions in this paper include: • We propose a generalized framework for hierarchical encoders in transformer based models that covers a broader range of architectures including existing encoding schemes like HRED/HIBERT (Zhang et al., 2019) and possibly other novel variants. We call members of this family of hierarchical transformer encoders as an HT-Encoder. • Then, we formulate a straightforward algorithm for converting an implementation of standard transformer encoder into an HTEncoder by changing the attention mask and the positional encoding. • Building upon that, we show how an HRED/HIBERT like hierarchical encoder (HIER-CLS) can be implemented using our HT-Encoder framework. • We also showcase a novel HT-Encoder based model, called HIER, with a context encoding mechanism different from HRED. We show that these simple HT-E"
2021.naacl-main.449,2020.acl-demos.30,0,0.247201,"former-based dialog models. ing specially designed attention masks and poPast research and user-studies have also shown that sitional encodings. We demonstrate that Hihierarchy is an important aspect of human convererarchical Encoding helps achieve better natsation (Jurafsky, 2000). But, most previous works ural language understanding of the contexts in based on transformer have focused on training modtransformer-based models for task-oriented dialog systems through a wide range of experiels either as language models (Budzianowski and ments. The code and data for all experiments Vuli´c, 2019; Zhang et al., 2020b) or as standard in this paper has been open-sourced1 2 . (non-hierarchical) Seq2Seq models (Chen et al., 2019; Zhang et al., 2020a; Wang et al., 2020) with 1 Introduction certain task specific extensions. Although arguably, the self-attention mechanism might automatically Dialog systems are concerned with replicating the human ability to make conversation. In a genera- learn such a scheme during the training process, our empirical results show that forcing this inductive dialog system, the model aims at generating tive bias by manual design as proposed here leads coherent and informative res"
2021.naacl-main.449,P17-1061,0,0.0176224,"rance ing multiple queries using an Hierarchical LSTM and dialog features detected by an NLU module. network. Serban et al. (2016) extended this work to However, such models had the usual drawback of open domain dialog generation problems and proany pipelined approaches, error propagation. Wen posed the HRED network. HRED captures the high et al. (2017) proposed using neural networks for ex- level features of the conversation in a context RNN. tracting features like intent, belief states, etc. and Several models have adopted this approach later on, 5656 e.g. VHRED (Serban et al., 2017), CVAE (Zhao et al., 2017), DialogWAE (Gu et al., 2018), etc. Another area in which researchers have proposed the use of hierarchical encoder is for processing of paragraph or long documents. Li et al. (2015) used a hierarchical LSTM network for training an autoencoder that can encode and decode long paragraphs and documents. Zhang et al. (2019) proposed HIBERT where they introduced hierarchy into the BERT architecture to remove the limitation on length of input sequence. HIBERT samples a single vector for each sentence or document segment (usually contextual embedding of CLS or EOS token) from the sentence encoder to"
C12-1062,J95-3006,0,0.364085,"s and Information Technology provided a strong impetus for computational processing of Indian languages beginning at the turn of the century with its Technology Development for Indian Languages program (TDIL). Several periodic conferences were launched to foster research in computational linguistics, such as the International Conference on Natural Language Processing (ICON), and the Language Engineering Conference (LEC). The Akshar Bharati group developed “Anus¯araka”, a language accessor, for accessing texts in other languages that employed techniques inspired by P¯an.ini’s As..ta¯ dhy¯ay¯ı (Bharati et al., 1995). K. V. Ramakrishnacaryulu introduced natural language processing programs specifically for Sanskrit at the ´ abdabodha Systems and Language Technology” Rashtriya Sanskrit Vidyapeetha, Tirupati, such as “S¯ in 2005. In 2002, under the guidance of Amba Kulkarni, the toy morphological analyser developed at Melkote was enriched with the MW lexicon and the Dh¯atu-ratn¯akara database resulting in a wide coverage morphological analyser. Amba Kulkarni developed prototypes of several other analytic tools for Sanksrit when she began teaching specialized courses in the subject at Tirupati. Her appointme"
C12-1062,W04-2102,1,0.913395,"Missing"
C12-1062,C92-3145,0,0.182918,"resent active verbal paradigm contains six slots: three for first, second and third person times two for singular and plural number. Yet the forms that fill these slots number just two, for example, go and goes for the verb ‘to go’. Description of the abstract grammatical structure requires mentioning five items while description of the forms directly requires mentioning only two. Grammatical description is therefore more prolix than listing. It is nearly as efficient to describe English morphology with reference to individual forms as it is to describe it in abstract grammatical structures. (Karp et al., 1992) create a hash table of just 317,477 forms from 90,196 lexical entries, a ratio of 3.5:1. The reverse is true for Sanskrit. In Sanskrit full 1013 verb paradigms number hundreds of unique forms in as many as sixteen hundred slots. The modest full-form lexicon created by (Scharf and Hyman, 2009a) from a lexicon of 170,000 entries numbers more than eleven million forms, a ratio of 64.7:1. It is by far more economical to describe such forms in abstract grammatical categories than it is to list them. The implication of the brevity of grammatical description of Sanskrit in comparison to listing form"
C12-1062,de-marneffe-etal-2006-generating,0,0.136087,"Missing"
C12-1062,P10-3015,0,0.154808,"Missing"
C12-1062,W03-2401,0,\N,Missing
C14-1173,W09-3036,0,0.183781,"p://creativecommons.org/licenses/by/4.0/ 1834 Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 1834–1843, Dublin, Ireland, August 23-29 2014. introduced links to handle long-distance phenomena such as wh-movement, topicalization, expletives and gapping (Johansson and Nugues, 2007). Their conversion procedure made use of this extended structure in Penn Treebank. De et al. described a system for generating typed dependency parsed from the phrase structure parses (De Marneffe et al., 2006). (Palmer et al., 2009; Xia et al., 2009; Bhatt et al., 2009) discuss a multi-layered representation framework for Hindi and Urdu, where the information from syntactic as well as dependency parse is presented together. In this work, we explore the relationship between enriched constituency structures and dependency structures for Sanskrit language, with main emphasis on the conversion from constituency to dependency structures. This work aims not only at designing an algorithm to convert Treebanks from one type of representation to the other, but also to judge the adequacy of the enriched constituency structure from parsing point of view. This paper has"
C14-1173,P04-1054,0,0.0650486,"an.inian grammar, the oldest dependency grammar, provides a formalism for annotation of the sentences. While the Sanskrit consortium has annotated a few thousand sentences following the dependency grammar, we also came across a very valuable source of annotation of Sanskrit sentences following the constituency structure (Gillon, 1996). The constituency structure was enriched to suite the requirements of Sanskrit. This aroused our curiosity to study the equivalence of the two annotation schemes. The importance of dependency structure has been well recognised by several computational linguists (Culotta and Sorensen, 2004; Haghighi et al., 2005; Quirk et al., 2005) in the recent past. The dependency format is preferred over the constituency not only from evaluation point of view (Lin, 1998) but also because of its suitability (Marneffe et al., 2006) for a wide range of NLP tasks such as Machine Translation (MT), information extraction, question answering etc.. This has upsurged several works on converting a constituency structure into dependency. The parsers for English now produce the dependency parse as well. Xia and Palmer discuss three different algorithms to convert dependency structures to phrase structu"
C14-1173,de-marneffe-etal-2006-generating,0,0.101667,"Missing"
C14-1173,C12-1062,1,0.826917,"s and argumentations on various aspects of language analysis ranging from phonetics (´siks.a¯ ), grammar (vy¯akaran.a), logic (ny¯aya), ritual exegesis (karmam¯ım¯am . s¯a), and literary theory (alam . k¯ara´sa¯ stra) which is not only useful for analysing Sanskrit but it also has much to offer computational linguistics in these areas. The series of symposia in Sanskrit Computational Linguistics (Huet et al., 2009; Kulkarni and Huet, 2009), the consortium project sponsored by the Technology Development for Indian Languages (TDIL) and the research of individual scholars and the collaborations (Goyal et al., 2012) among them resulted into a) development of several tools ranging from segmenters (Huet, 2009), morphological analysers (Kulkarni and Shukl, 2009), parsers (Goyal et al., 2009; Hellwig, 2009; Kumar, 2012; Kulkarni, 2013) to discourse annotators, b) lexical resources ranging from dictionaries, WordNet (Kulkarni et al., 2010) to Knowledge-Nets (Nair, 2011), and c) annotated corpora [http://sanskrit.uohyd.ernet.in/scl]. P¯an.inian grammar, the oldest dependency grammar, provides a formalism for annotation of the sentences. While the Sanskrit consortium has annotated a few thousand sentences follo"
C14-1173,H05-1049,0,0.0218073,"dependency grammar, provides a formalism for annotation of the sentences. While the Sanskrit consortium has annotated a few thousand sentences following the dependency grammar, we also came across a very valuable source of annotation of Sanskrit sentences following the constituency structure (Gillon, 1996). The constituency structure was enriched to suite the requirements of Sanskrit. This aroused our curiosity to study the equivalence of the two annotation schemes. The importance of dependency structure has been well recognised by several computational linguists (Culotta and Sorensen, 2004; Haghighi et al., 2005; Quirk et al., 2005) in the recent past. The dependency format is preferred over the constituency not only from evaluation point of view (Lin, 1998) but also because of its suitability (Marneffe et al., 2006) for a wide range of NLP tasks such as Machine Translation (MT), information extraction, question answering etc.. This has upsurged several works on converting a constituency structure into dependency. The parsers for English now produce the dependency parse as well. Xia and Palmer discuss three different algorithms to convert dependency structures to phrase structures for English (Xia an"
C14-1173,W07-2416,0,0.0280634,"ls in the dependency tree produced (Nivre, 2006). Johansson and Nugues used a richer set of edge labels and This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 1834 Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 1834–1843, Dublin, Ireland, August 23-29 2014. introduced links to handle long-distance phenomena such as wh-movement, topicalization, expletives and gapping (Johansson and Nugues, 2007). Their conversion procedure made use of this extended structure in Penn Treebank. De et al. described a system for generating typed dependency parsed from the phrase structure parses (De Marneffe et al., 2006). (Palmer et al., 2009; Xia et al., 2009; Bhatt et al., 2009) discuss a multi-layered representation framework for Hindi and Urdu, where the information from syntactic as well as dependency parse is presented together. In this work, we explore the relationship between enriched constituency structures and dependency structures for Sanskrit language, with main emphasis on the conversion fr"
C14-1173,W12-4701,1,0.868368,"Missing"
C14-1173,W13-3718,1,0.852088,"is not only useful for analysing Sanskrit but it also has much to offer computational linguistics in these areas. The series of symposia in Sanskrit Computational Linguistics (Huet et al., 2009; Kulkarni and Huet, 2009), the consortium project sponsored by the Technology Development for Indian Languages (TDIL) and the research of individual scholars and the collaborations (Goyal et al., 2012) among them resulted into a) development of several tools ranging from segmenters (Huet, 2009), morphological analysers (Kulkarni and Shukl, 2009), parsers (Goyal et al., 2009; Hellwig, 2009; Kumar, 2012; Kulkarni, 2013) to discourse annotators, b) lexical resources ranging from dictionaries, WordNet (Kulkarni et al., 2010) to Knowledge-Nets (Nair, 2011), and c) annotated corpora [http://sanskrit.uohyd.ernet.in/scl]. P¯an.inian grammar, the oldest dependency grammar, provides a formalism for annotation of the sentences. While the Sanskrit consortium has annotated a few thousand sentences following the dependency grammar, we also came across a very valuable source of annotation of Sanskrit sentences following the constituency structure (Gillon, 1996). The constituency structure was enriched to suite the requir"
C14-1173,P05-1034,0,0.0575151,"ovides a formalism for annotation of the sentences. While the Sanskrit consortium has annotated a few thousand sentences following the dependency grammar, we also came across a very valuable source of annotation of Sanskrit sentences following the constituency structure (Gillon, 1996). The constituency structure was enriched to suite the requirements of Sanskrit. This aroused our curiosity to study the equivalence of the two annotation schemes. The importance of dependency structure has been well recognised by several computational linguists (Culotta and Sorensen, 2004; Haghighi et al., 2005; Quirk et al., 2005) in the recent past. The dependency format is preferred over the constituency not only from evaluation point of view (Lin, 1998) but also because of its suitability (Marneffe et al., 2006) for a wide range of NLP tasks such as Machine Translation (MT), information extraction, question answering etc.. This has upsurged several works on converting a constituency structure into dependency. The parsers for English now produce the dependency parse as well. Xia and Palmer discuss three different algorithms to convert dependency structures to phrase structures for English (Xia and Palmer, 2001). Mage"
C14-1173,H01-1014,0,0.0510339,", 2005; Quirk et al., 2005) in the recent past. The dependency format is preferred over the constituency not only from evaluation point of view (Lin, 1998) but also because of its suitability (Marneffe et al., 2006) for a wide range of NLP tasks such as Machine Translation (MT), information extraction, question answering etc.. This has upsurged several works on converting a constituency structure into dependency. The parsers for English now produce the dependency parse as well. Xia and Palmer discuss three different algorithms to convert dependency structures to phrase structures for English (Xia and Palmer, 2001). Magerman gave a set of priority lists, in the form of a head percolation table to find heads of constituents (Magerman, 1994). Yamada and Matsumoto modified these head percolation rules further (Yamada and Matsumoto, 2003). Their method was reimplemented by Nivre, who also defined certain heuristics to infer the arc labels in the dependency tree produced (Nivre, 2006). Johansson and Nugues used a richer set of edge labels and This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details:"
C14-1173,W03-3023,0,0.0509688,"r a wide range of NLP tasks such as Machine Translation (MT), information extraction, question answering etc.. This has upsurged several works on converting a constituency structure into dependency. The parsers for English now produce the dependency parse as well. Xia and Palmer discuss three different algorithms to convert dependency structures to phrase structures for English (Xia and Palmer, 2001). Magerman gave a set of priority lists, in the form of a head percolation table to find heads of constituents (Magerman, 1994). Yamada and Matsumoto modified these head percolation rules further (Yamada and Matsumoto, 2003). Their method was reimplemented by Nivre, who also defined certain heuristics to infer the arc labels in the dependency tree produced (Nivre, 2006). Johansson and Nugues used a richer set of edge labels and This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 1834 Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 1834–1843, Dublin, Ireland, August 23-29 2014. introduced l"
C16-1048,C92-1019,0,0.231692,"Missing"
C16-1048,P06-1085,0,0.41288,"Missing"
C16-1048,C12-1062,1,0.921882,"Missing"
C16-1048,D11-1049,0,0.048659,"Missing"
C16-1048,P10-3015,0,0.46263,"Missing"
C16-1048,P09-1012,0,0.0789218,"Missing"
C16-1048,D10-1001,0,0.0876733,"Missing"
C16-1048,P14-2032,0,0.035636,"Missing"
C16-1048,O03-4002,0,0.349157,"Missing"
C16-1320,councill-etal-2008-parscit,0,0.18574,"Missing"
C18-1032,S15-1011,0,0.0282501,"Missing"
C18-1032,D15-1075,0,0.0260257,"Missing"
C18-1032,D17-1070,0,0.0259956,"Missing"
C18-1032,D07-1074,0,0.0435848,"Missing"
C18-1032,D11-1072,0,0.0725278,"Missing"
C18-1032,Q14-1019,0,0.0704768,"Missing"
C18-1032,P09-1024,0,0.105121,"Missing"
C18-1032,P10-1013,0,0.0161168,"Missing"
D18-1276,W03-1019,0,0.0833438,"tal energy of a maximal clique, Ti = (VTi , ETi ), is decomposed as the summation of energies of its 6 Our graph construction approach is explained using finite state methods in §1 of the supplementary material 2552 edges (Ishikawa, 2011). S(Ti ) = X S(~epq ) epq ∈ETi where, VTi ⊆ V, ETi ⊆ E. The edges are featurised. For an edge epq ∈ E, the features are represented as a vector, denoted by ~epq . For a given edge, the energy function, S(·) : [0, ∞)|~e |→ (−∞, ∞), takes the edge feature vector and produces a scalar value as the energy assignment. Loss Function and Training: We use Hinge Loss (Altun et al., 2003; Taskar et al., 2003) as our loss function. The hinge loss is formulated such that it increasingly penalises those cliques, sampled by our inference algorithm, with increasingly more number of wrong segmentation candidates. We minimise the hinge loss L which is defined as L = max(0, S(TGT ) − argmin(S(Ti ) − ∆(Ti )) Ti ∈AQ Here, AQ denotes the set of all the unique maximal cliques and TGT denotes the maximal clique corresponding to the ground truth. The margin ∆(Ti ) is defined as ∆(Ti ) = |VTi − VGT |2 . We minimise the given loss function using gradient descent method. The network parameter"
D18-1276,P16-1231,0,0.0509005,"Missing"
D18-1276,N18-1033,0,0.0412454,"pecial case of Graph Transformer Networks (LeCun et al., 1998, 2007). In the lattice structure, the candidate links only to its adjacent nodes in an exhaustive segmentation. We also generate edge vectors for the dummy nodes that act as the start and end markers in the lattice. During prediction, we have to find the best path from the lattice which minimises the sentence score. Here, we consider two variants of LatticeEBM. L-EBM-Vanilla uses the discriminative forward training approach (Collobert et al., 2011) with the standard hinge loss. The second variant L-EBM-Beam, uses multi-margin loss (Edunov et al., 2018), instead of the hinge loss. Here, we employ beam search to generate multiple candidates as required by the loss. Tree-EBM: The baseline model works exactly the same as the proposed model where the only difference between both is in the inference algorithm used. Tree-EBM has an inference that searches for a Steiner Tree (Takahashi, 1980) from the input graph G(V, E), the structure of which is described in §2.9 The inference procedure outputs a spanning tree that covers a subset of the nodes from G. This raises a challenge while estimating the loss as, unlike in the case of a clique, there can"
D18-1276,D15-1173,0,0.0915287,"features for a directed edge connecting two different nodes in G can be generated in 3 × |M C|×3 ways. We automate the process of feature generation and feature selection using the framework of Path Ranking Algorithm (Lao and Cohen, 2010). Formalising our approach using PRA leads to an efficient and scalable implementation of our scheme. In PRA, enumerating and generating all the possible features needs to be performed only for a sampled set of data pairs from the corpus. By using a supervised feature selection approach, a relevant sub-set of features is filtered. This is a one-time process (Gardner and Mitchell, 2015). During inference, the feature values are computed only for the filtered features. 7 7 The edge vector formation is explained in terms of Metapaths (Sun, 2010) in §3 of the Supplementary. Morphological Constraints: M C is defined as the set of grammatical category combinations, each combination falling into one of the following two descriptions. a) Complete combination, i.e., a morphological class – In Sanskrit, similar to Czech (Smith et al., 2005), a morphological class represents a certain combination of grammatical categories. For instance, a noun is represented by case, gender and number"
D18-1276,P08-1043,0,0.0797868,"on a common set of rules for works across the different time spans, and the enormous effort in categorising constructions based on their writing styles, motivated us to use this graph construction scheme which is agnostic to word order. Figure 2: Architecture for the proposed model. Wordsplits for ‘satyamapriyam’, a sub-sequence of the sentence in Figure 1a are considered here. The nodes are numbered from 1 to 10 and are marked with the same in Figure 1a. For simplicity, we assume that words in nodes 4 to 10 have only one morphological analysis each. a popular approach for fusional languages (Goldberg and Tsarfaty, 2008; Cohen and Smith, 2007; Hatori et al., 2012). In a lattice, there will be edges only between the adjacent word splits of an exhaustive segmentation. We deviate from this norm in a minor yet fundamental way. In the search space, we choose to add edges between every pair of word splits that are part of a single exhaustive segmentation. Henceforth, we will refer this structure as the sentence graph G. We then employ our minimum cost maximal clique finding energy based model on the sentence graph G. Figure 2 shows the proposed architecture of the model. It shows the sentence graph G for ‘satyamap"
D18-1276,N03-2002,0,0.0844224,"l time BronKerbosch algorithm (Tomita et al., 2006; Bron and Kerbosch, 1973) for clique enumeration (McDonald et al., 2005a). We further improve the run time of our inference procedure by paralleling the clique selection procedure for each node on a separate thread. 3 Feature Generation for the Edges Given two non-conflicting nodes in G, there exists a pair of directed edges, one each in either direc2553 tion. For every edge in the sentence graph G, we need to generate features that capture the distributional information between the candidate nodes that the edge connects. Similar in spirit to Bilmes and Kirchhoff (2003) and Krishna et al. (2016), we condition the distributional information based on different morphological constraints to enrich the context. The distributional information is obtained from a morphologically tagged corpus C. Let Vw , Vm and Vr be the vocabulary of the inflected word forms, morphological classes and the roots respectively in the corpus. Let V = Vw ∪ Vm ∪ Vr . For each ni , nj ∈ V, the conditional probability count(nj ,ni ) is calculated as Pco (nj |ni ) = count(n . Here i) count(·) represents the count of co-occurrence between the entries in the corpus. Also, let M C be the set o"
D18-1276,Q17-1010,0,0.0384568,"th the following systems: SupervisedPCRW: Proposed in Krishna et al. (2016), this model also uses the graph output from SHR. Using PCRW (Lao and Cohen, 2010; Meng et al., 2015), feature vectors for edges are generated using hand-crafted morphological constraints. Starting with the longest word in the graph, the prediction is performed by greedily selecting the candidates as per the edge weights. EdgeGraphCRF: This is a second order CRF Model (M¨uller and Behnke, 2014; Ishikawa, 2011) which uses the sentence graph structure G as the input to the system. Every node is represented with fastText (Bojanowski et al., 2017) word embeddings trained under default settings. The edges are featurised with the PRA vectors (§3). We used 1-slack structured SVM for training. For the binary class problem, QPBO (Rother et al., 2007) inference approach provided the best results. Seq2Seq - Reddy et al. (2018) uses an EncoderDecoder framework with LSTM cells for the segmentation task. We consider two models from the work, namely, ‘segSeq2Seq’ and ‘attnSegSeq2seq’ as our baselines. The later which uses attention (Bahdanau et al., 2015) is the current state of the art in Sanskrit word segmentation. Lattice-EBM: An energy based"
D18-1276,D07-1101,0,0.0607769,"d is used only in forming the nodes for the sentence graph. During the inference, we consider all the pairwise potentials as contexts for each of the prediction made in the search space. The edges in our model should capture the likeliness of two nodes to co-occur in the final solution. Hence, every pair of nodes that can co-occur in an ‘exhaustive segmentation’ forms two directed edges, one each at either of the directions. Energy Based Model (EBM) Architecture: Our approach is inspired from the graph based parsing approaches employed generally for dependency parsing (McDonald et al., 2005b; Carreras, 2007) and follows a likewise structured prediction paradigm (Taskar et al., 2005). Specifically, we use an EBM where we model our joint task as search for a maximal clique with minimum energy. Learning consists of finding an energy function that associates lower energies to cliques with increasing similarity to the correct clique. The correct clique configuration will have the lowest energy (LeCun et al., 2006). The inference policy, a maximal clique selection algorithm, is used to make the predictions. We follow an approach similar to the arcfactored approaches in graphs (McDonald et al., 2005b; C"
D18-1276,D07-1022,0,0.145458,"works across the different time spans, and the enormous effort in categorising constructions based on their writing styles, motivated us to use this graph construction scheme which is agnostic to word order. Figure 2: Architecture for the proposed model. Wordsplits for ‘satyamapriyam’, a sub-sequence of the sentence in Figure 1a are considered here. The nodes are numbered from 1 to 10 and are marked with the same in Figure 1a. For simplicity, we assume that words in nodes 4 to 10 have only one morphological analysis each. a popular approach for fusional languages (Goldberg and Tsarfaty, 2008; Cohen and Smith, 2007; Hatori et al., 2012). In a lattice, there will be edges only between the adjacent word splits of an exhaustive segmentation. We deviate from this norm in a minor yet fundamental way. In the search space, we choose to add edges between every pair of word splits that are part of a single exhaustive segmentation. Henceforth, we will refer this structure as the sentence graph G. We then employ our minimum cost maximal clique finding energy based model on the sentence graph G. Figure 2 shows the proposed architecture of the model. It shows the sentence graph G for ‘satyamapriyam’, a sub-sequence"
D18-1276,C12-1062,1,0.900656,"Missing"
D18-1276,P12-1110,0,0.18234,"ent time spans, and the enormous effort in categorising constructions based on their writing styles, motivated us to use this graph construction scheme which is agnostic to word order. Figure 2: Architecture for the proposed model. Wordsplits for ‘satyamapriyam’, a sub-sequence of the sentence in Figure 1a are considered here. The nodes are numbered from 1 to 10 and are marked with the same in Figure 1a. For simplicity, we assume that words in nodes 4 to 10 have only one morphological analysis each. a popular approach for fusional languages (Goldberg and Tsarfaty, 2008; Cohen and Smith, 2007; Hatori et al., 2012). In a lattice, there will be edges only between the adjacent word splits of an exhaustive segmentation. We deviate from this norm in a minor yet fundamental way. In the search space, we choose to add edges between every pair of word splits that are part of a single exhaustive segmentation. Henceforth, we will refer this structure as the sentence graph G. We then employ our minimum cost maximal clique finding energy based model on the sentence graph G. Figure 2 shows the proposed architecture of the model. It shows the sentence graph G for ‘satyamapriyam’, a sub-sequence of the sentence in Fig"
D18-1276,P07-1077,0,0.083292,"posses from that of the original sentence. Sanskrit is rich with syncretisms (Crystal, 2011) and homonyms. For example, the surface form ‘sat¯ı’, prefixed with numbers 6 and 10, are homonyms, while the root ‘satya’ generates identical surface form for three different morphological classes leading to syncretism (1 to 3 in Figure 1a). Hence, in addition to segmentation, the morphological analysis of the segmented word forms will be critical for reducing the ambiguity in further downstream tasks such as syntactic analysis. The sentence construction in the language follows weak non-projectivity (Havelka, 2007) permitting the words to have a relatively free word order structure (Kulkarni et al., 2015). The language is all the more lenient for poetic constructions (Scharf et al., 2015; Kulkarni et al., 2015), where arranging the words to adhere to metri2 A saying from subh¯as.itam text: One should tell the truth, one should say kind words; one should neither tell harsh truths, nor flattering lies; this is a rule for all times. 2550 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2550–2561 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Associatio"
D18-1276,C16-1028,0,0.0308536,"phological constraints. A filtered set of 1500 features (out of 4752) is used in our model. Mutual Information Regression (Kraskov et al., 2004) with the word to word co-occurrence probability as label is used for feature selection.8 4 Experiments Dataset: We use the Digital Corpus of Sanskrit (DCS) (Hellwig, 2010-2016), a morphologically tagged corpus of Sanskrit, for all our experiments. DCS contains digitised works from periods that span over 3000 years and contain constructions written in prose or poetry. Identifying sentence boundaries in Sanskrit constructions is a challenge of its own (Hellwig, 2016). DCS currently has split the corpus into more than 560,000 text lines, all of which need not be following explicit sentence boundaries. Krishna et al. (2016) identify 350,000 constructions from the DCS fit for the segmentation task. They use a separate set of 9,577 constructions from the DCS, called as ‘DCS10k’, and use it as the test set. They ignore the remaining text lines from DCS due to ambiguities either in the provided tagging or alignment with SHR (Krishna et al., 2017). We use the 350,000 constructions used in Krishna et al. 8 For different settings we experimented with, for the vect"
D18-1276,P05-1061,0,0.117121,"o our proposed system and is used only in forming the nodes for the sentence graph. During the inference, we consider all the pairwise potentials as contexts for each of the prediction made in the search space. The edges in our model should capture the likeliness of two nodes to co-occur in the final solution. Hence, every pair of nodes that can co-occur in an ‘exhaustive segmentation’ forms two directed edges, one each at either of the directions. Energy Based Model (EBM) Architecture: Our approach is inspired from the graph based parsing approaches employed generally for dependency parsing (McDonald et al., 2005b; Carreras, 2007) and follows a likewise structured prediction paradigm (Taskar et al., 2005). Specifically, we use an EBM where we model our joint task as search for a maximal clique with minimum energy. Learning consists of finding an energy function that associates lower energies to cliques with increasing similarity to the correct clique. The correct clique configuration will have the lowest energy (LeCun et al., 2006). The inference policy, a maximal clique selection algorithm, is used to make the predictions. We follow an approach similar to the arcfactored approaches in graphs (McDonal"
D18-1276,W17-2214,1,0.596059,"structions written in prose or poetry. Identifying sentence boundaries in Sanskrit constructions is a challenge of its own (Hellwig, 2016). DCS currently has split the corpus into more than 560,000 text lines, all of which need not be following explicit sentence boundaries. Krishna et al. (2016) identify 350,000 constructions from the DCS fit for the segmentation task. They use a separate set of 9,577 constructions from the DCS, called as ‘DCS10k’, and use it as the test set. They ignore the remaining text lines from DCS due to ambiguities either in the provided tagging or alignment with SHR (Krishna et al., 2017). We use the 350,000 constructions used in Krishna et al. 8 For different settings we experimented with, for the vector generation, refer to §4 of the supplementary material. 2554 (2016) as the corpus C (§3) for the generation of our edge vectors. ‘DCS10k’ was neither used in the training of our model, nor in the generation of edge vectors. Reddy et al. (2018) report their results on a subset of DCS10k containing 4,200 sentences, which we will refer to as ‘DCS4k’. We experiment with the following systems: SupervisedPCRW: Proposed in Krishna et al. (2016), this model also uses the graph output"
D18-1276,H05-1066,0,0.661917,"o our proposed system and is used only in forming the nodes for the sentence graph. During the inference, we consider all the pairwise potentials as contexts for each of the prediction made in the search space. The edges in our model should capture the likeliness of two nodes to co-occur in the final solution. Hence, every pair of nodes that can co-occur in an ‘exhaustive segmentation’ forms two directed edges, one each at either of the directions. Energy Based Model (EBM) Architecture: Our approach is inspired from the graph based parsing approaches employed generally for dependency parsing (McDonald et al., 2005b; Carreras, 2007) and follows a likewise structured prediction paradigm (Taskar et al., 2005). Specifically, we use an EBM where we model our joint task as search for a maximal clique with minimum energy. Learning consists of finding an energy function that associates lower energies to cliques with increasing similarity to the correct clique. The correct clique configuration will have the lowest energy (LeCun et al., 2006). The inference policy, a maximal clique selection algorithm, is used to make the predictions. We follow an approach similar to the arcfactored approaches in graphs (McDonal"
D18-1276,L18-1264,1,0.761559,"vember 4, 2018. 2018 Association for Computational Linguistics Figure 1: a) All the phonetically valid segmentations (link) for ‘satyam . br¯uy¯atpriyam . br¯uy¯annabr¯uy¯atsatyamapriyam . priyam . can¯anr.tambr¯uy¯ades.adharmah.san¯atanah.’ from (subh¯as.itam) as output by Sanskrit Heritage Reader (SHR) and b) correct segmentation selected from the candidate space. cal constraints is a bigger concern (Melnad et al., 2013). Hence, the whole input context is desirable when making each prediction at the output (Bahdanau et al., 2015), even for preliminary tasks such as segmentation in Sanskrit (Reddy et al., 2018). The word splits in Figure 1 are based on the analysis by a lexicon driven analyser, Sanskrit Heritage Reader (SHR)3 . A total of 1,056 combinations can be formed from the word splits, such that each of those combinations is a solution which covers the entire input. We call such a solution as an ‘exhaustive segmentation’. Out task is to find an ‘exhaustive segmentation’, which is also semantically valid. Figure 1b shows the semantically valid solution for the sentence. We propose our structured prediction framework as an energy based model (LeCun et al., 2006). Considering the free word-order"
D18-1276,C10-2139,0,0.0278348,"the framework of Path Ranking Algorithm (Lao and Cohen, 2010). Formalising our approach using PRA leads to an efficient and scalable implementation of our scheme. In PRA, enumerating and generating all the possible features needs to be performed only for a sampled set of data pairs from the corpus. By using a supervised feature selection approach, a relevant sub-set of features is filtered. This is a one-time process (Gardner and Mitchell, 2015). During inference, the feature values are computed only for the filtered features. 7 7 The edge vector formation is explained in terms of Metapaths (Sun, 2010) in §3 of the Supplementary. Morphological Constraints: M C is defined as the set of grammatical category combinations, each combination falling into one of the following two descriptions. a) Complete combination, i.e., a morphological class – In Sanskrit, similar to Czech (Smith et al., 2005), a morphological class represents a certain combination of grammatical categories. For instance, a noun is represented by case, gender and number. Hence, the combination ‘genitive-masculine-singular’ forms a morphological class. b) Partial combination - A combination of grammatical categories, which can"
D18-1276,P17-1078,0,0.0239124,", 2012). The free word order nature of the language motivated us to consider the input to be a graph so as to avoid the sequential processing of input. For the EBM we use, there is no requirement of proper normalisation (LeCun et al., 2006). We benefit from this as we perform a search in the space of complete outputs and there is a combinatorial explosion in the output space for a linear increase in the input space (Doppa et al., 2014). The pretraining of the edge vectors with external knowledge in the form of morphological constraints is effective in reducing the task specific training size (Yang et al., 2017; Andor et al., 2016). Acknowledgements We are grateful to Oliver Hellwig for providing the DCS Corpus and G´erard Huet for providing the Sanskrit Heritage Engine, to be installed at local systems. We extend our gratitude to Amba Kulkarni and Rogers Mathew, along with G´erard for helpful comments and discussions regarding the work. We thank the anonymous reviewers for their constructive and helpful comments, which greatly improved the paper. We are indebted to Unni Krishnan T A for his contributions towards implementation of the framework. Details in §4 of the Supplementary material 2558 Refer"
D18-1276,Q15-1026,0,0.183498,"Missing"
D18-1276,N03-1029,0,0.0781262,"authors were at IIT Kharagpur 1 The code and the pretrained edge vectors (§3) used in this work are available at https://zenodo.org/record/ 1035413#.W35s8hjhUUs † between speech recognition and the analysis of written text (Huet, 2005). For instance, consider Figure 1a which shows all the phonetically valid word splits for a Sanskrit poetic verse2 . The written representation in Sanskrit is actually a phonemic stream (Huet, 2005). The constructions often undergo phonetic transformations at the juncture of successive words, similar to what one observes in connected speech (Morris et al., 2004; Shieber and Tao, 2003). These transformations obscure the word boundaries and often modify the phones at these word boundaries. In Sanskrit, these transformations get reflected in writing as well. This is primarily due to the presence of an advanced discipline of phonetics in Sanskrit which explicitly described euphonic assimilation as sandhi (Goyal and Huet, 2016). For instance, words prefixed with numbers 14 and 15 in Figure 1a are valid candidates in spite of the phonetic differences they posses from that of the original sentence. Sanskrit is rich with syncretisms (Crystal, 2011) and homonyms. For example, the s"
D18-1276,H05-1060,0,0.793231,"hm (Lao and Cohen, 2010) to automate the feature selection and the feature vector generation for the edges. This eliminates the need for manual feature engineering. 2 Proposed Architecture Given an input construction, we obtain our search space of possible word splits using SHR as shown in Figure 1. The search space represents all the possible exhaustive segmentations with possible gaps and overlaps between the word splits in each of the exhaustive segmentation (Kudo, 2006; Oerder and Ney, 1993; Wolf and Woods, 1977).5 In such a setting, representing the search space as a lattice (Kudo, 2006; Smith et al., 2005) has been 5 The word splits in an exhaustive segmentation often overlap and sometimes leave gaps by virtue of Sandhi. For examples, please refer the §1 supplementary material. 2551 perts on a common set of rules for works across the different time spans, and the enormous effort in categorising constructions based on their writing styles, motivated us to use this graph construction scheme which is agnostic to word order. Figure 2: Architecture for the proposed model. Wordsplits for ‘satyamapriyam’, a sub-sequence of the sentence in Figure 1a are considered here. The nodes are numbered from 1 to"
D19-1631,Q17-1010,0,0.0347612,"ge-enchanced inference composition components. Another line of solution tries to bring in the extra domain knowledge from sources like Unified Medical Language System (UMLS) (Bodenreider, 2004). Romanov and Shivade (2018) used the knowledge-directed attention based methods in (Chen et al., 2018) for Medical NLI. Another such attempt is made by Lu et al. (2019), where they incorporate domain knowledge in terms of the definitions of medical concepts from UMLS with the state-of-the-art NLI model ESIM (Chen et al., 2017) and vanilla word embeddings of Glove (Pennington et al., 2014) and fastText (Bojanowski et al., 2017). Even though, the authors achieve significant improvement by incorporating only concept definitions from UMLS, the features of this clinical knowledge graph are yet to be fully utilized. Motivated by the emerging trend of embedding knowledge graphs to encode useful information in a high dimensional vector space, we propose the idea of applying state-of-the-art knowledge graph embedding algorithm on UMLS and use these embeddings as a representative of additional domain knowledge with the state-of-the-art medical NLI models like BioELMo, to investigate the performance improvement on this task."
D19-1631,D15-1075,0,0.0213849,"task, which mainly rely on contextual word embeddings. We also experiment with fusing the domain-specific sentiment information for the task. Experiments conducted on MedNLI dataset clearly show that this strategy improves the baseline BioELMo architecture for the Medical NLI task1 . 1 Introduction Natural language inference (NLI) is one of the basic natural language understanding tasks which deals with detecting inferential relationship such as entailment or contradiction, between a given premise and a hypothesis. In recent years, with the availability of large annotated datasets like SNLI (Bowman et al., 2015), MultiNLI (Williams et al., 2018), researchers have come up with several neural network based models which could be trained with these large annotated datasets and are able to produce state-of-the-art performances (Bowman et al., 2015, 2016; Munkhdalai and Yu, 2017; Sha et al., 2016; Chen et al., 2017; ∗ equal contribution https://github.com/soummyaah/ KGMedNLI/ 1 Tay et al., 2018). With these attempts, even though NLI in domains like fiction, travel etc. has progressed a lot, NLI in medical domain is yet to be explored extensively. With the introduction of MedNLI (Romanov and Shivade, 2018),"
D19-1631,P16-1139,0,0.0231798,"Missing"
D19-1631,P18-1224,0,0.0304022,"al. (2019) introduce BioBERT, which is a BERT model pretrained on English Wikipedia, BooksCorpus and fine-tuned on PubMed (7.8B tokens in total) corpus, PMC full-text articles. Jin et al. (2019) propose BioELMo which is a domain-specific version of ELMo trained on 10M PubMed abstracts, and attempt to solve medical NLI problem with these domain specific embeddings, leading to state-ofthe-art performance. These two attempts show a direction towards solving medical NLI problem where the pretrained embeddings are fine-tuned on medical corpus and are used in the state-of-the-art NLI architecture. Chen et al. (2018) proposed the use of external knowledge to help enrich neural-network based NLI models by applying Knowledge-enriched coattention, Local inference collection with Exter6092 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 6092–6097, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics nal Knowledge, and Knowledge-enchanced inference composition components. Another line of solution tries to bring in the extra domain knowledge from sources like"
D19-1631,P17-1152,0,0.26033,"al language inference (NLI) is one of the basic natural language understanding tasks which deals with detecting inferential relationship such as entailment or contradiction, between a given premise and a hypothesis. In recent years, with the availability of large annotated datasets like SNLI (Bowman et al., 2015), MultiNLI (Williams et al., 2018), researchers have come up with several neural network based models which could be trained with these large annotated datasets and are able to produce state-of-the-art performances (Bowman et al., 2015, 2016; Munkhdalai and Yu, 2017; Sha et al., 2016; Chen et al., 2017; ∗ equal contribution https://github.com/soummyaah/ KGMedNLI/ 1 Tay et al., 2018). With these attempts, even though NLI in domains like fiction, travel etc. has progressed a lot, NLI in medical domain is yet to be explored extensively. With the introduction of MedNLI (Romanov and Shivade, 2018), an expert annotated dataset for NLI in the clinical domain, researchers have started pursuing the problem of clinical NLI. Modeling informal inference is one of the basic tasks towards achieving natural language understanding, and is considered very challenging. MedNLI is a dataset that assists in ass"
D19-1631,W19-2011,0,0.326426,"red very challenging. MedNLI is a dataset that assists in assessing how good a sentence or word embedding method is for downstream uses in medical domain. Recently, with the emergence of advanced contextual word embedding methods like ELMo (Peters et al., 2018) and BERT (Devlin et al., 2018), performances of many NLP tasks have improved, setting state-of-the-art performances. Following this stream of literature, Lee et al. (2019) introduce BioBERT, which is a BERT model pretrained on English Wikipedia, BooksCorpus and fine-tuned on PubMed (7.8B tokens in total) corpus, PMC full-text articles. Jin et al. (2019) propose BioELMo which is a domain-specific version of ELMo trained on 10M PubMed abstracts, and attempt to solve medical NLI problem with these domain specific embeddings, leading to state-ofthe-art performance. These two attempts show a direction towards solving medical NLI problem where the pretrained embeddings are fine-tuned on medical corpus and are used in the state-of-the-art NLI architecture. Chen et al. (2018) proposed the use of external knowledge to help enrich neural-network based NLI models by applying Knowledge-enriched coattention, Local inference collection with Exter6092 Proc"
D19-1631,E17-1002,0,0.0137833,"he Medical NLI task1 . 1 Introduction Natural language inference (NLI) is one of the basic natural language understanding tasks which deals with detecting inferential relationship such as entailment or contradiction, between a given premise and a hypothesis. In recent years, with the availability of large annotated datasets like SNLI (Bowman et al., 2015), MultiNLI (Williams et al., 2018), researchers have come up with several neural network based models which could be trained with these large annotated datasets and are able to produce state-of-the-art performances (Bowman et al., 2015, 2016; Munkhdalai and Yu, 2017; Sha et al., 2016; Chen et al., 2017; ∗ equal contribution https://github.com/soummyaah/ KGMedNLI/ 1 Tay et al., 2018). With these attempts, even though NLI in domains like fiction, travel etc. has progressed a lot, NLI in medical domain is yet to be explored extensively. With the introduction of MedNLI (Romanov and Shivade, 2018), an expert annotated dataset for NLI in the clinical domain, researchers have started pursuing the problem of clinical NLI. Modeling informal inference is one of the basic tasks towards achieving natural language understanding, and is considered very challenging. Me"
D19-1631,D14-1162,0,0.0838182,"Linguistics nal Knowledge, and Knowledge-enchanced inference composition components. Another line of solution tries to bring in the extra domain knowledge from sources like Unified Medical Language System (UMLS) (Bodenreider, 2004). Romanov and Shivade (2018) used the knowledge-directed attention based methods in (Chen et al., 2018) for Medical NLI. Another such attempt is made by Lu et al. (2019), where they incorporate domain knowledge in terms of the definitions of medical concepts from UMLS with the state-of-the-art NLI model ESIM (Chen et al., 2017) and vanilla word embeddings of Glove (Pennington et al., 2014) and fastText (Bojanowski et al., 2017). Even though, the authors achieve significant improvement by incorporating only concept definitions from UMLS, the features of this clinical knowledge graph are yet to be fully utilized. Motivated by the emerging trend of embedding knowledge graphs to encode useful information in a high dimensional vector space, we propose the idea of applying state-of-the-art knowledge graph embedding algorithm on UMLS and use these embeddings as a representative of additional domain knowledge with the state-of-the-art medical NLI models like BioELMo, to investigate the"
D19-1631,N18-1202,0,0.026472,"NLI in medical domain is yet to be explored extensively. With the introduction of MedNLI (Romanov and Shivade, 2018), an expert annotated dataset for NLI in the clinical domain, researchers have started pursuing the problem of clinical NLI. Modeling informal inference is one of the basic tasks towards achieving natural language understanding, and is considered very challenging. MedNLI is a dataset that assists in assessing how good a sentence or word embedding method is for downstream uses in medical domain. Recently, with the emergence of advanced contextual word embedding methods like ELMo (Peters et al., 2018) and BERT (Devlin et al., 2018), performances of many NLP tasks have improved, setting state-of-the-art performances. Following this stream of literature, Lee et al. (2019) introduce BioBERT, which is a BERT model pretrained on English Wikipedia, BooksCorpus and fine-tuned on PubMed (7.8B tokens in total) corpus, PMC full-text articles. Jin et al. (2019) propose BioELMo which is a domain-specific version of ELMo trained on 10M PubMed abstracts, and attempt to solve medical NLI problem with these domain specific embeddings, leading to state-ofthe-art performance. These two attempts show a direc"
D19-1631,D18-1187,0,0.172605,"Missing"
D19-1631,C16-1270,0,0.0159988,"Introduction Natural language inference (NLI) is one of the basic natural language understanding tasks which deals with detecting inferential relationship such as entailment or contradiction, between a given premise and a hypothesis. In recent years, with the availability of large annotated datasets like SNLI (Bowman et al., 2015), MultiNLI (Williams et al., 2018), researchers have come up with several neural network based models which could be trained with these large annotated datasets and are able to produce state-of-the-art performances (Bowman et al., 2015, 2016; Munkhdalai and Yu, 2017; Sha et al., 2016; Chen et al., 2017; ∗ equal contribution https://github.com/soummyaah/ KGMedNLI/ 1 Tay et al., 2018). With these attempts, even though NLI in domains like fiction, travel etc. has progressed a lot, NLI in medical domain is yet to be explored extensively. With the introduction of MedNLI (Romanov and Shivade, 2018), an expert annotated dataset for NLI in the clinical domain, researchers have started pursuing the problem of clinical NLI. Modeling informal inference is one of the basic tasks towards achieving natural language understanding, and is considered very challenging. MedNLI is a dataset"
D19-1631,D18-1185,0,0.0247412,"Missing"
D19-1631,N18-1101,0,0.0199074,"extual word embeddings. We also experiment with fusing the domain-specific sentiment information for the task. Experiments conducted on MedNLI dataset clearly show that this strategy improves the baseline BioELMo architecture for the Medical NLI task1 . 1 Introduction Natural language inference (NLI) is one of the basic natural language understanding tasks which deals with detecting inferential relationship such as entailment or contradiction, between a given premise and a hypothesis. In recent years, with the availability of large annotated datasets like SNLI (Bowman et al., 2015), MultiNLI (Williams et al., 2018), researchers have come up with several neural network based models which could be trained with these large annotated datasets and are able to produce state-of-the-art performances (Bowman et al., 2015, 2016; Munkhdalai and Yu, 2017; Sha et al., 2016; Chen et al., 2017; ∗ equal contribution https://github.com/soummyaah/ KGMedNLI/ 1 Tay et al., 2018). With these attempts, even though NLI in domains like fiction, travel etc. has progressed a lot, NLI in medical domain is yet to be explored extensively. With the introduction of MedNLI (Romanov and Shivade, 2018), an expert annotated dataset for N"
D19-1631,W17-2609,0,0.0303358,"e graph. The relations in our knowledge graph come from two sources: The Metathesaurus and the Semantic Network of UMLS. Using relations extracted from these two sources, we connect the filtered medical concepts from UMLS to build a smaller Knowledge Graph (subgraph of UMLS). We get 117,467 triples from the Metathesaurus and 23,824,105 triples from the Semantic Network, which constitute the edgelists in the prepared knowledge graph. Knolwedge Graph Embeddings: To obtain the embedding from this graph, we use state-ofthe-art DistMult model (Bishan Yang and Deng, 2015). The choice is inspired by Kadlec et al. (2017), which reports that an appropriately tuned DistMult model can produce similar or better performance while compared with the competing knowledge graph embedding models. DistMult model embeds entities (nodes) and relations (edges) as vectors. It uses a matrix dot product to measure compatibility between head (h) and tail (t) entities, connected by a relation (r). Logistic loss is used for training the model. σDistM ult (h, r, t) = rT (h · t) (1) Combining Knolwedge Graph Embeddings with BioELMo: As explained in Figure 1, each sentence (p or h) is tokenized using the simple module of NLTK2 as we"
D19-6210,D16-1046,0,0.0312006,"st between various entity types like protein-protein, drug-drug, chemical-protein etc. Detecting relationships is a fundamental sub-task for automatic Information Extraction to overcome efforts of manual inspection, especially for growing biomedical articles. However, existing supervised systems are highly data-driven. This poses a challenge since manual labelling is a costly and timeconsuming process and there is a dearth of labelled data in the biomedical domain covering all tasks and for new datasets. A system trained on a specific dataset1 may perform poorly on another, for the same task (Mou et al., 2016), due to dataset variance which can arise owing to sample selection bias (Rios et al., 2018). 1 Note: We use the terms dataset and domain interchangeably. 75 Proceedings of the 10th International Workshop on Health Text Mining and Information Analysis (LOUHI 2019), pages 75–80 c Hong Kong, November 3, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/D19-62 1) We show that using a shared-private model along with adversarial training improves SSST adaptation compared to neural network baselines. When multiple source corpora from similar domains are used it leads t"
D19-6210,N18-1111,0,0.0314528,"le target (MSST) adaptation to incorporate more richness in the knowledge transferred by using additional smaller corpora for protein-protein relation and multiple labels for chemical-protein relation respectively. Given an unlabeled target domain, we transfer common useful features from related labelled source domains using adversarial training (Goodfellow et al., 2014). It helps to overcome the sampling bias and learn common indistinguishable features, promoting generalization, using min-max optimization. We adopt the Multinomial Adversarial Network integrated with the Shared-Private model (Chen and Cardie, 2018) which was originally proposed for the task of Multi-Domain Text Classification. It can handle multiple source domains at a time which is in contrast to traditional binomial adversarial networks. The Shared-Private model (Bousmalis et al., 2016) consists of a split representation where the private space learns specific features related to a particular domain while a shared space learns features common to all the domains. Such representation promotes non-contamination of the two spaces preserving their uniqueness. The contributions of our approach are as follows: Relation classification is cruc"
D19-6210,W15-1506,0,0.216895,"75–80 c Hong Kong, November 3, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/D19-62 1) We show that using a shared-private model along with adversarial training improves SSST adaptation compared to neural network baselines. When multiple source corpora from similar domains are used it leads to further performance enhancement. Moreover, use of contextualized sentential embeddings leads to better performance than exisitng baseline methods for both MSST and SSST. 2) We explore the generalizability of our framework using two prominent neural architectures: CNN (Nguyen and Grishman, 2015) and BiLSTM (Kavuluru et al., 2017), where we find the former to be more robust across our experiments. 2 Figure 1: MAN for Domain Adaptation of Binary Relation Classification. The figure shows the training flow given a sentence from a labeled source domain. D is trained separately than rest of the network Methodology from single corpus as different sources, 2) We use additional smaller corpora from a similar domain as multi-source. The Shared F eature space (Fs ) learns domain agnostic representations and P rivate F eature space (Fdi ) learns domain specific features for every ith labeled dom"
D19-6210,W19-5004,0,0.0548541,"Missing"
K18-1034,C16-1048,1,0.897224,"Missing"
K18-1034,W16-3701,1,0.897611,"Missing"
K18-1034,W16-6108,0,0.0659728,"Missing"
K18-1034,P16-1154,0,0.174312,"ework that takes in a character sequence as input and the model finds embeddings at a sub-word level both at the encoder and decoder side. Here the OCR output forms input to the model. Keeping the task in mind we make two design decisions for the model. One is the use of copying mechanism (Gu et al., 2016) and other is the use of Byte Pair Encoding (BPE) (Sennrich et al., 2016) to learn a new vocabulary for the model. CopyNet (Gu et al., 2016): Since it is possible that there will be reasonable overlap between the input and output strings, we use the copying mechanism as mentioned in CopyNet (Gu et al., 2016). The model essentially learns two probability distributions, one for generating an entry at the decoder and the other for copying the entry from the encoder. The final prediction is based on the sum of both the probabilities for the class. Given an input sequence X = (x1 , ..., xN ) we define X , for all the unique entries in the input sequence. We also define the vocabulary V = {v1 , ..., vN }. Let the out-of-vocabulary (OOV) words be represented with UNK. The probability of the generate mode g and copy mode c are given by  1 ψg (yt ) ,  yt ∈ V   Ze 0, yt ∈ X − V p(yt , g|·)=    1 eψg"
K18-1034,N16-1030,0,0.0300783,"en to the score. The higher the score, the more acceptable the sentence is. 3.3 Baselines Character Tagger - Sequence Labelling using BiLSTMs This is a sequence labelling model which uses BiLSTM cells and input is a character sequence (Saluja et al.). We use categorical crossentropy as the loss function and softmax as the activation function. For dropout, we employ spatial dropout in our architecture. The model consists of 3 layers with each layer having 128 cells. Embeddings of size 100 are randomly initialised and the learnt representations are stored in a character look-up table similar to Lample et al. (2016). In addition to every phoneme in Sanskrit as a class, we add an additional class ‘no change’ which signifies that the character remains as is. We also experimented with a variant where the final layer is a CRF layer (Lafferty et al., 2001). We henceforth refer to both the systems as BiLSTM and BiLSTMCRF, respectively. Pruned CRFs (Schnober et al., 2016): They Evaluation Metrics We use three different metrics for evaluating all our models. We use Character Recognition Rate (CRR) and Word Recognition Rate (WRR) averaged over each of the sentences in the 430 lines in the test dataset (Sankaran 1"
K18-1034,P15-1156,0,0.155759,"form our Post-OCR text correction on the text. We hypothesise that this will improve the segmentation process and other downstream tasks for Sanskrit in a typical NLP pipeline. Our major contributions are: 3. Through a human judgement experiment, we asked the participants to correct the mistakes from a predicted output from the competing systems. We find that participants were able to correct predictions from our system more frequently and the corrections were done much faster than the CRF model by Schnober et al. (2016). We observe that predictions from our model score high on acceptability (Lau et al., 2015) than other methods as well. 2 Model Architecture In principle, the output from any OCR which recognises Romanised Sanskrit can be used as the input to our model. Currently, there exist limited options for recognising Romanised Sanskrit texts from scanned documents. Possibly, the commercial OCR offering by Google as part of their proprietary cloud vision API and SanskritOCR3 might be the only two viable options. SanskritOCR provides an online interface to the Tesseract OCR, an open source multilingual OCR (Smith, 2007; Smith et al., 2009; Smith, 1987), trained specifically for recognising Roma"
K18-1034,L18-1264,1,0.822492,"arly well for the Post-OCR text correction in Sanskrit. In the case of providing a text line as input, we are essentially providing more context about the input in comparison to the word level models and the RNN (or LSTM) cells are powerful enough to capture the long-term dependencies. Particularly for Indian languages, this decision is beyond a question of performance. In Sanskrit, the word boundaries are often obscured due to phonetic transformations at the word boundaries known as Sandhi. Word segmentation of Sanskrit constructions is a matter of research on its own (Krishna et al., 2016a; Reddy et al., 2018). However, none of the existing systems are equipped for incorrect spellings and hence these systems may be brittle (Belinkov and Bisk, 2018) when it comes to handling spelling variations in the input. Hence, in our case, we assume an unsegmented sequence as our input and then we perform our Post-OCR text correction on the text. We hypothesise that this will improve the segmentation process and other downstream tasks for Sanskrit in a typical NLP pipeline. Our major contributions are: 3. Through a human judgement experiment, we asked the participants to correct the mistakes from a predicted ou"
K18-1034,C16-1160,0,0.343021,", and Pawan Goyal# # Dept. of Computer Science and Engineering, IIT Kharagpur, * Dept. of Computer Science, University of California, San Diego ** Walmart Labs, India amrith@iitkgp.ac.in, bmajumde@eng.ucsd.edu, rajeshbhatpesit@gmail.com, pawang@cse.iitkgp.ernet.in Abstract has been a surge in digitising printed Sanskrit manuscripts written in Roman such as the ones currently digitised by the ‘Krishna Path’ project2 . In this work, we propose a model for postOCR text correction for Sanskrit written in Roman. Post-OCR text correction, which can be seen as a special case of spelling correction (Schnober et al., 2016), is the task of correcting errors that tend to appear in the output of the OCR in the process of converting an image to text. The errors incurred from OCR can be quite high due to numerous factors including typefaces, paper quality, scan quality, etc. The text can often be eroded, can contain noises and the paper can be bleached or tainted as well (Schnober et al., 2016). Figure 1 shows the sample images we have collected for the task. Hence it is beneficial to perform a post-processing on the OCR output to obtain an improved text. We propose a post-OCR text correction approach for digitising"
K18-1034,P16-1162,0,0.148063,"ary material 346 row-normalised proportion of predictions7 . of Tesseract are trained on 400,000 text-lines spanning about 4500 fonts5 . 2.1 System Descriptions We formalise the task as a monotone seq2seq model. We use an encoder-decoder framework that takes in a character sequence as input and the model finds embeddings at a sub-word level both at the encoder and decoder side. Here the OCR output forms input to the model. Keeping the task in mind we make two design decisions for the model. One is the use of copying mechanism (Gu et al., 2016) and other is the use of Byte Pair Encoding (BPE) (Sennrich et al., 2016) to learn a new vocabulary for the model. CopyNet (Gu et al., 2016): Since it is possible that there will be reasonable overlap between the input and output strings, we use the copying mechanism as mentioned in CopyNet (Gu et al., 2016). The model essentially learns two probability distributions, one for generating an entry at the decoder and the other for copying the entry from the encoder. The final prediction is based on the sum of both the probabilities for the class. Given an input sequence X = (x1 , ..., xN ) we define X , for all the unique entries in the input sequence. We also define"
L18-1006,P14-1113,0,0.136002,"using Distributional Semantic Models (DSM) and have come up with several directional measures (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). Specifically for hypernymy detection, researchers also used a variant of distributional hypothesis, i.e., distributional inclusion hypothesis (Geffet and Dagan, 2005) according to which the contexts of a narrow term are also shared by the broad term. Recently, entropy-based distributional measure (Santus et al., 2014) has also been tried out for the same purpose. In some of the recent attempts (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017), people have tried several embed39 distributional thesauri (DT) network (Riedl and Biemann, 2013) built using Google books syntactic n-grams. We hypothesize that, if two words are having ‘co-hyponymy’ relationship, then those words are distributionally more similar compared to the words having hypernymy, meronymy relationship or any random pair of words. In order to capture the distributional similarity between two words in the DT network, we are proposing the following five network measures for each word pair: (i) structural similarity (SS), (ii) shorte"
L18-1006,P05-1014,0,0.127024,"afted patterns or patterns learnt from the corpus (Cederberg and Widdows, 2003; Yamada et al., 2009). With the emergence of the trend of applying distributional hypothesis (Firth, 1957) to solve this relation classification task, researchers have started using Distributional Semantic Models (DSM) and have come up with several directional measures (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). Specifically for hypernymy detection, researchers also used a variant of distributional hypothesis, i.e., distributional inclusion hypothesis (Geffet and Dagan, 2005) according to which the contexts of a narrow term are also shared by the broad term. Recently, entropy-based distributional measure (Santus et al., 2014) has also been tried out for the same purpose. In some of the recent attempts (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017), people have tried several embed39 distributional thesauri (DT) network (Riedl and Biemann, 2013) built using Google books syntactic n-grams. We hypothesize that, if two words are having ‘co-hyponymy’ relationship, then those words are distributionally more similar compared to the words having hypernymy, meronym"
L18-1006,J06-1005,0,0.410267,"In this paper, we are proposing a novel supervised model where various network measures have been utilized to identify co-hyponymy relation with high accuracy performing better or at par with the state-of-the-art models. Keywords: Co-hyponymy detection, Distributional thesaurus network, Complex network measures. 1. Introduction ding schemes for hypernymy detection. One interesting attempt was made by Kiela et al. (2015), where they exploited image generality for lexical entailment detection. Most of the attempts made for meronymy detection are mainly pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006). Later, investigations have been made for the possibility of using distributional semantic models for part-of relations detection (Morlane-Hond`ere, 2015). As far as co-hyponymy detection is concerned, researchers have tried with several DSMs and measures for distinguishing hypernyms from cohyponyms but the number of attempts is very small. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for the classification of hypernymy and co-hyponymy. In one of the recent work (Sant"
L18-1006,C92-2082,0,0.575131,"and ‘lot’ are (co-)hyponyms for the concept ‘large indefinite amount’ as per WordNet (Miller, 1995). Lexical relations are of variety of types like hyponyms, hypernyms, co-hyponyms, meronyms etc. Among these, some relations are symmetric (co-hyponymy) and some are asymmetric (hypernymy, meronymy). With the advancement of distributional semantics representation of words, researchers have attempted to identify lexical relations in both supervised and unsupervised ways. One of the oldest attempt for detection of hypernymy extraction dealt with finding out ‘lexico-syntactic patterns’ proposed by Hearst (1992). A lot of attempts have been made for hypernymy extraction using knowledge bases like Wordnet, Wikipedia and hand crafted patterns or patterns learnt from the corpus (Cederberg and Widdows, 2003; Yamada et al., 2009). With the emergence of the trend of applying distributional hypothesis (Firth, 1957) to solve this relation classification task, researchers have started using Distributional Semantic Models (DSM) and have come up with several directional measures (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). Specifically for hypernymy"
L18-1006,P15-2020,0,0.168365,"being used extensively in some form or the other. Even though a lot of efforts have been made for detecting hypernymy relation, the problem of co-hyponymy detection has been rarely investigated. In this paper, we are proposing a novel supervised model where various network measures have been utilized to identify co-hyponymy relation with high accuracy performing better or at par with the state-of-the-art models. Keywords: Co-hyponymy detection, Distributional thesaurus network, Complex network measures. 1. Introduction ding schemes for hypernymy detection. One interesting attempt was made by Kiela et al. (2015), where they exploited image generality for lexical entailment detection. Most of the attempts made for meronymy detection are mainly pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006). Later, investigations have been made for the possibility of using distributional semantic models for part-of relations detection (Morlane-Hond`ere, 2015). As far as co-hyponymy detection is concerned, researchers have tried with several DSMs and measures for distinguishing hypernyms from cohyponyms but the number of attempts is very small. One such attempt is made by"
L18-1006,P98-2127,0,0.341805,"rs of word. 3. Baseline Model svmDIFF Description A linear SVM trained on the vector difference svmMULT A linear SVM trained on the pointwise product vector svmADD A linear SVM trained on the vector sum svmCAT A linear SVM trained on the vector concatenation svmSING A linear SVM trained on the vector of the second word in the given word pair knnDIFF k nearest neighbours (knn) trained on the vector difference cosineP The relation between word pair holds if the cosine similarity of the word vectors is greater than some threshold p linP The relation between word pair holds if the lin similarity (Lin, 1998) of the word vectors is greater than some threshold p most freq The most frequent label in the training data is assigned to every test point. Experimental Results and Analysis As our main focus is classification of co-hyponymy relation, one of the key challenges has been to construct a dataset. Most of the gold standard datasets used for evaluation of the systems discriminating lexical relations, do not contain word pairs having co-hyponymy relation. We find two baseline systems (Weeds et al., 2014; Santus et al., 2016) where the authors use gold standard datasets which contain co-hyponymy pai"
L18-1006,D17-1022,0,0.405493,"Missing"
L18-1006,P06-1015,0,0.303503,"e proposing a novel supervised model where various network measures have been utilized to identify co-hyponymy relation with high accuracy performing better or at par with the state-of-the-art models. Keywords: Co-hyponymy detection, Distributional thesaurus network, Complex network measures. 1. Introduction ding schemes for hypernymy detection. One interesting attempt was made by Kiela et al. (2015), where they exploited image generality for lexical entailment detection. Most of the attempts made for meronymy detection are mainly pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006). Later, investigations have been made for the possibility of using distributional semantic models for part-of relations detection (Morlane-Hond`ere, 2015). As far as co-hyponymy detection is concerned, researchers have tried with several DSMs and measures for distinguishing hypernyms from cohyponyms but the number of attempts is very small. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for the classification of hypernymy and co-hyponymy. In one of the recent work (Santus et al., 2016), a supervised me"
L18-1006,D13-1089,0,0.692144,", 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). Specifically for hypernymy detection, researchers also used a variant of distributional hypothesis, i.e., distributional inclusion hypothesis (Geffet and Dagan, 2005) according to which the contexts of a narrow term are also shared by the broad term. Recently, entropy-based distributional measure (Santus et al., 2014) has also been tried out for the same purpose. In some of the recent attempts (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017), people have tried several embed39 distributional thesauri (DT) network (Riedl and Biemann, 2013) built using Google books syntactic n-grams. We hypothesize that, if two words are having ‘co-hyponymy’ relationship, then those words are distributionally more similar compared to the words having hypernymy, meronymy relationship or any random pair of words. In order to capture the distributional similarity between two words in the DT network, we are proposing the following five network measures for each word pair: (i) structural similarity (SS), (ii) shortest path (SP ), (iii) weighted shortest path (SP W ), (iv) edge density among the intersection of neighborhoods(EDin ), (v) edge density a"
L18-1006,W11-2501,0,0.623657,"distinguish the word pairs having co-hyponymy relation from the word pairs having hypernymy or meronymy relation, or from any random pair of words. Evaluation results: We evaluate our approach by three experiments. In the first two experiments, taking two different baselines (Weeds et al., 2014; Santus et al., 2016), we follow their experimental setup as well as their publicly available dataset and show that using our proposed network features, we are able to improve the accuracy of the cohyponymy detection task. In the third experiment, we prepare three datasets extracted from BLESS dataset (Baroni and Lenci, 2011) for three binary classification tasks: Cohyponymy vs Random, Co-hyponymy vs Meronymy, Cohyponymy vs Hypernymy and show that we get consistent performance as the previous two experiments, achieving accuracy in the range of 0.73-0.97. We have made these three datasets publicly available1 . 2. Figure 1: A sample snapshot of Distributional Thesaurus Network where each node represents a word and the weight of edge between two words is defined as the number of context features that these two words share in common. Here the word ‘cat’ shares more context features with its co-hyponym ‘dog’ compared t"
L18-1006,P99-1008,0,0.285074,"s been rarely investigated. In this paper, we are proposing a novel supervised model where various network measures have been utilized to identify co-hyponymy relation with high accuracy performing better or at par with the state-of-the-art models. Keywords: Co-hyponymy detection, Distributional thesaurus network, Complex network measures. 1. Introduction ding schemes for hypernymy detection. One interesting attempt was made by Kiela et al. (2015), where they exploited image generality for lexical entailment detection. Most of the attempts made for meronymy detection are mainly pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006). Later, investigations have been made for the possibility of using distributional semantic models for part-of relations detection (Morlane-Hond`ere, 2015). As far as co-hyponymy detection is concerned, researchers have tried with several DSMs and measures for distinguishing hypernyms from cohyponyms but the number of attempts is very small. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for the classification of hypernymy and co-hyponymy. In one of t"
L18-1006,W03-0415,0,0.0687804,", meronyms etc. Among these, some relations are symmetric (co-hyponymy) and some are asymmetric (hypernymy, meronymy). With the advancement of distributional semantics representation of words, researchers have attempted to identify lexical relations in both supervised and unsupervised ways. One of the oldest attempt for detection of hypernymy extraction dealt with finding out ‘lexico-syntactic patterns’ proposed by Hearst (1992). A lot of attempts have been made for hypernymy extraction using knowledge bases like Wordnet, Wikipedia and hand crafted patterns or patterns learnt from the corpus (Cederberg and Widdows, 2003; Yamada et al., 2009). With the emergence of the trend of applying distributional hypothesis (Firth, 1957) to solve this relation classification task, researchers have started using Distributional Semantic Models (DSM) and have come up with several directional measures (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). Specifically for hypernymy detection, researchers also used a variant of distributional hypothesis, i.e., distributional inclusion hypothesis (Geffet and Dagan, 2005) according to which the contexts of a narrow term are a"
L18-1006,C14-1097,0,0.131883,"the oldest attempt for detection of hypernymy extraction dealt with finding out ‘lexico-syntactic patterns’ proposed by Hearst (1992). A lot of attempts have been made for hypernymy extraction using knowledge bases like Wordnet, Wikipedia and hand crafted patterns or patterns learnt from the corpus (Cederberg and Widdows, 2003; Yamada et al., 2009). With the emergence of the trend of applying distributional hypothesis (Firth, 1957) to solve this relation classification task, researchers have started using Distributional Semantic Models (DSM) and have come up with several directional measures (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). Specifically for hypernymy detection, researchers also used a variant of distributional hypothesis, i.e., distributional inclusion hypothesis (Geffet and Dagan, 2005) according to which the contexts of a narrow term are also shared by the broad term. Recently, entropy-based distributional measure (Santus et al., 2014) has also been tried out for the same purpose. In some of the recent attempts (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017), people have tried several embed39 distributional thesauri"
L18-1006,E14-4008,0,0.132311,"onal hypothesis (Firth, 1957) to solve this relation classification task, researchers have started using Distributional Semantic Models (DSM) and have come up with several directional measures (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). Specifically for hypernymy detection, researchers also used a variant of distributional hypothesis, i.e., distributional inclusion hypothesis (Geffet and Dagan, 2005) according to which the contexts of a narrow term are also shared by the broad term. Recently, entropy-based distributional measure (Santus et al., 2014) has also been tried out for the same purpose. In some of the recent attempts (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017), people have tried several embed39 distributional thesauri (DT) network (Riedl and Biemann, 2013) built using Google books syntactic n-grams. We hypothesize that, if two words are having ‘co-hyponymy’ relationship, then those words are distributionally more similar compared to the words having hypernymy, meronymy relationship or any random pair of words. In order to capture the distributional similarity between two words in the DT network, we are proposing the f"
L18-1006,L16-1722,0,0.120838,"2006; Pantel and Pennacchiotti, 2006). Later, investigations have been made for the possibility of using distributional semantic models for part-of relations detection (Morlane-Hond`ere, 2015). As far as co-hyponymy detection is concerned, researchers have tried with several DSMs and measures for distinguishing hypernyms from cohyponyms but the number of attempts is very small. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for the classification of hypernymy and co-hyponymy. In one of the recent work (Santus et al., 2016), a supervised method based on a Random Forest algorithm has been proposed to learn taxonomical semantic relations and they have shown that the model performs good for co-hyponymy detection. It is evident from the literature that, most of the efforts are made for hypernymy or lexical entailment detection; very few attempts have been made for co-hyponymy detection. In this paper, we are proposing a supervised framework for co-hyponymy detection where complex network measures are used as features. Network science has always been proved to be very effective in addressing problems including the st"
L18-1006,E17-1007,0,0.111215,"with finding out ‘lexico-syntactic patterns’ proposed by Hearst (1992). A lot of attempts have been made for hypernymy extraction using knowledge bases like Wordnet, Wikipedia and hand crafted patterns or patterns learnt from the corpus (Cederberg and Widdows, 2003; Yamada et al., 2009). With the emergence of the trend of applying distributional hypothesis (Firth, 1957) to solve this relation classification task, researchers have started using Distributional Semantic Models (DSM) and have come up with several directional measures (Roller et al., 2014; Weeds et al., 2014; Santus et al., 2016; Shwartz et al., 2017; Roller and Erk, 2016). Specifically for hypernymy detection, researchers also used a variant of distributional hypothesis, i.e., distributional inclusion hypothesis (Geffet and Dagan, 2005) according to which the contexts of a narrow term are also shared by the broad term. Recently, entropy-based distributional measure (Santus et al., 2014) has also been tried out for the same purpose. In some of the recent attempts (Fu et al., 2014; Yu et al., 2015; Nguyen et al., 2017), people have tried several embed39 distributional thesauri (DT) network (Riedl and Biemann, 2013) built using Google books"
L18-1006,C14-1212,0,0.25569,", where they exploited image generality for lexical entailment detection. Most of the attempts made for meronymy detection are mainly pattern based (Berland and Charniak, 1999; Girju et al., 2006; Pantel and Pennacchiotti, 2006). Later, investigations have been made for the possibility of using distributional semantic models for part-of relations detection (Morlane-Hond`ere, 2015). As far as co-hyponymy detection is concerned, researchers have tried with several DSMs and measures for distinguishing hypernyms from cohyponyms but the number of attempts is very small. One such attempt is made by Weeds et al. (2014), where they proposed a supervised framework and used several vector operations as features for the classification of hypernymy and co-hyponymy. In one of the recent work (Santus et al., 2016), a supervised method based on a Random Forest algorithm has been proposed to learn taxonomical semantic relations and they have shown that the model performs good for co-hyponymy detection. It is evident from the literature that, most of the efforts are made for hypernymy or lexical entailment detection; very few attempts have been made for co-hyponymy detection. In this paper, we are proposing a supervi"
L18-1006,D09-1097,0,0.0339584,"Missing"
L18-1006,S13-1035,0,0.166966,"nsity among the intersection of neighborhoods (EDin ), (v) edge density among the union of neighborhoods (EDun ). Let (wi , wj ) be the pair of words for which we compute the following network measures Structural Similarity (SS): The structural similarity SS(wi , wj ) is computed as: SS(wi , wj ) = p (1) where Nc denotes the number of common neighbors of wi and wj and deg(wk ) denotes the degree of wk in the DT graph, for k = i, j. Methodology As a graph representation of words, we use distributional thesauri (DT) network (Riedl and Biemann, 2013) from the Google books syntactic n-grams data (Goldberg and Orwant, 2013) spanning from 1520 to 2008. In a graph structure, the DT contains for each word a list of words that are similar with respect to their bi-gram distribution (Riedl and Biemann, 2013). In the network, each word is a node and there is a weighted edge between a pair of words where the weight of the edge is defined as the number of features that these two words share in common. A snapshot of the DT is shown in Figure 1. Our hypothesis is that the word pairs having co-hyponymy relation are distributionally more similar than the words having hypernymy or meronymy relation or any random pair of words"
L18-1006,W15-4208,0,0.309039,"Missing"
L18-1264,D14-1179,0,0.0117991,"Missing"
L18-1264,P06-1085,0,0.0532766,"Missing"
L18-1264,C12-1062,1,0.8619,"on, Sanskrit, Low-Resource Languages, Sequence to sequence, seq2seq, Deep Learning 1. Introduction Sanskrit had profound influence as the knowledge preserving language for centuries in India. The tradition of learning and teaching Sanskrit, though limited, still exists in India. There have been tremendous advancements in digitisation of ancient manuscripts in Sanskrit in the last decade. Numerous initiatives such as the Digital Corpus of Sanskrit1 , GRETIL2 , The Sanskrit Library3 and others from the Sanskrit Linguistic and Computational Linguistic community is a fine example of such efforts (Goyal et al., 2012; Krishna et al., 2017). The digitisation efforts have made the Sanskrit manuscripts easily available in the public domain. However, the accessibility of such digitised manuscripts is still limited. Numerous technical challenges in indexing and retrieval of such resources in a digital repository arise due to the linguistic peculiarities posed by the language. Word Segmentation in Sanskrit is an important yet non-trivial prerequisite for facilitating efficient processing of Sanskrit texts. Sanskrit has been primarily communicated orally. Due to its oral tradition, the phonemes in Sanskrit under"
L18-1264,C16-1048,1,0.954025,"e not at word-level, as is the standard with word segmentation systems in general, a direct comparison with the other systems is not meaningful. Mittal (2010) proposed a method based on Finite State Transducers by incorporating rules of sandhi. The system generates all possible splits and then provides a ranking of various splits, based on probabilistic ranking inferred from a dataset of 25000 split points. Using the same dataset, Natarajan and Charniak (2011) proposed a sandhi splitter for Sanskrit. The method is an extension of Bayesian word segmentation approach by Goldwater et al. (2006). Krishna et al. (2016) is currently the state of the art in Sanskrit word segmentation. The system treats the problem as an iterative query expansion problem. Using a shallow parser for Sanskrit (Goyal et al., 2012), an input sentence is first converted to a graph of possible candidates and desirable nodes are iteratively selected using Path Constrained Random Walks (Lao and Cohen, 2010). To further catalyse the research in word segmentation for Sanskrit, Krishna et al. (2017) has released a dataset for the word segmentation task. The work releases a dataset of 119,000 sentences in Sanskrit along with the lexical a"
L18-1264,W17-2214,1,0.29925,"source Languages, Sequence to sequence, seq2seq, Deep Learning 1. Introduction Sanskrit had profound influence as the knowledge preserving language for centuries in India. The tradition of learning and teaching Sanskrit, though limited, still exists in India. There have been tremendous advancements in digitisation of ancient manuscripts in Sanskrit in the last decade. Numerous initiatives such as the Digital Corpus of Sanskrit1 , GRETIL2 , The Sanskrit Library3 and others from the Sanskrit Linguistic and Computational Linguistic community is a fine example of such efforts (Goyal et al., 2012; Krishna et al., 2017). The digitisation efforts have made the Sanskrit manuscripts easily available in the public domain. However, the accessibility of such digitised manuscripts is still limited. Numerous technical challenges in indexing and retrieval of such resources in a digital repository arise due to the linguistic peculiarities posed by the language. Word Segmentation in Sanskrit is an important yet non-trivial prerequisite for facilitating efficient processing of Sanskrit texts. Sanskrit has been primarily communicated orally. Due to its oral tradition, the phonemes in Sanskrit undergo euphonic assimilatio"
L18-1264,P10-3015,0,0.338649,"ultimate) and ¯svarah.’ (god). Now, a search for instances of the word ‘i´ ¯svarah.’ might lead to missing search results without ‘i´ proper indexing. String matching approaches often result in low precision results. Using a lexicon driven system might alleviate the said issues, but can lead to possible splits which are not semantically compatible. For parame´svarah.’, it can be split as ‘parama’ (ultimate), ‘´sva’ (dog) and ‘rah.’ (to facilitate). Though this is not semantically meaningful it is lexically valid. Such tools are put to use by some of the existing systems (Krishna et al., 2016; Mittal, 2010) to obtain additional morphological or syntactic information about the sentences. This limits the scalability of those systems, as they cannot handle out of vocabulary words. Scalability of such systems is further restricted as the sentences often need to undergo linguistically involved preprocessing steps that lead to human in the loop processing. The systems by Krishna et al. (2016) and Krishna et al. (2017) assume that the parser by Goyal et al. (2012), identifies all the possible candidate chunks. Our proposed model is built with precisely one purpose in mind, which is to predict the final"
L18-1264,P15-1129,0,0.0601488,"Missing"
L18-1264,O03-4002,0,0.323112,"n of the writer. While the Sandhi formation is deterministic, the analysis of Sandhi is non-deterministic and leads to high level of ambiguity. For example, the chunk ‘gardabhas.c¯as´va´sca’ (the ass and the horse) has 625 possible phonetically and lexically valid splits (Hellwig, 2015). Now, the correct split relies on the semantic compatibility between the split words. The word segmentation problem is a well studied problem across various languages where the segmentation is nontrivial. For languages such as Chinese and Japanese, where there is no explicit boundary markers between the words (Xue, 2003), numerous sequence labelling approaches have been proposed. In Sanskrit, it can be seen that the merging of word boundaries is the discretion of the writer. In this work, we propose a purely engineering based pipeline for segmentation of Sanskrit sentences. The word segmentation problem is a structured prediction problem and we propose a deep sequence to sequence (seq2seq) model to solve the task. We use an encoder-decoder framework where the sandhied (unsegmented) and the unsandhied (segmented) sequences are treated as the input at the encoder and the output at the decoder, respectively. We"
L18-1264,Q15-1026,0,\N,Missing
N18-1043,J06-1003,0,0.435342,"Missing"
N18-1043,W02-0908,0,0.462171,"d model like GloVe (Pennington et al., 2014) which are computationally efficient as well. Another stream of representation talks about network like structure where two words are considered neighbors if they both occur in the same context above a certain number of times. The words are finally represented using these neighbors. Distributional Thesaurus is one such instance of this type, which gets automatically produced from a text corpus and identifies words that occur in similar contexts; the notion of which was used in early work about distributional semantics (Grefenstette, 2012; Lin, 1998; Curran and Moens, 2002). One such representation is JoBimText proposed by Biemann and Riedl (2013) that contains, for each word, a list of words that are similar with respect to their bigram distribution, thus producing a network representation. Later, Riedl and Biemann (2013) introduced a highly scalable approach for computing this network. We mention this representation as a DT network throughout this article. With the emergence of recent trend of embedding large networks into dense low-dimensional vector space efficiently (Perozzi et al., 2014; Tang et al., 2015; Grover and Leskovec, 2016) which are focused on ca"
N18-1043,N15-1184,0,0.122421,"t (Miller, 1995), FreeBase (Bollacker et al., 2008), PPDB (Ganitkevitch et al., 2013), ConceptNet (Speer et al., 2017), whereas others use ImageNet (Frome et al., 2013; Kiela and Bottou, 2014; Both et al., 2017; Thoma et al., 2017) for capturing visual representation of lexical items. There are various ways of combining multiple representations. Some of the works extract lists of relations from knowledge bases and use those to either modify the learning algorithms (Halawi et al., 2012; Wang et al., 2014; Tian et al., 2016; Rastogi et al., 2015) or postprocess pre-trained word representations (Faruqui et al., 2015). Another line of literature prepares dense vector representation from each of the modes (text, knowledge bases, visual etc.) and tries to combine the vectors using various methods like concatenation, centroid computation, principal component analysis (Jolliffe, 1986), canonical correlation analysis (Faruqui and Dyer, 2014) etc. One such recent attempt is made by Goikoetxea et al. (2016) where they prepare vector representation from WordNet following the method proposed by Goikoetxea et al. (2015), which combines random walks over knowledge bases and neural network language model, and tries to"
N18-1043,E14-1049,0,0.0378417,"ultiple representations. Some of the works extract lists of relations from knowledge bases and use those to either modify the learning algorithms (Halawi et al., 2012; Wang et al., 2014; Tian et al., 2016; Rastogi et al., 2015) or postprocess pre-trained word representations (Faruqui et al., 2015). Another line of literature prepares dense vector representation from each of the modes (text, knowledge bases, visual etc.) and tries to combine the vectors using various methods like concatenation, centroid computation, principal component analysis (Jolliffe, 1986), canonical correlation analysis (Faruqui and Dyer, 2014) etc. One such recent attempt is made by Goikoetxea et al. (2016) where they prepare vector representation from WordNet following the method proposed by Goikoetxea et al. (2015), which combines random walks over knowledge bases and neural network language model, and tries to improve the vector representation constructed from text using this. As in lexical knowledge bases, the number of lexical items involved is much less than the raw text and preparing such resources is a cumbersome task, our goal is to see whether we can use DT network instead of some knowledge bases like WordNet and achieve"
N18-1043,N09-1003,0,0.169412,"Missing"
N18-1043,P14-1023,0,0.330259,"word embeddings represent words as dense unit vectors of real numbers, where vectors that are close together in euclidean space are considered to be semantically related. In this genre of representation, one of the captivating attempt is made by Mikolov et al. (2013), where they propose Word2vec, basically a set of two predictive models for neural embedding whereas Pennington et al. (2014) propose GloVe, which utilizes a dense count based model to come up with word embeddings that approximate this. Comparisons have also been made between count-based and prediction-based distributional models (Baroni et al., 2014) upon various tasks like relatedness, analogy, concept categorization etc., where researchers show that prediction-based word embeddings outperform sparse count-based methods used for computing distributional semantic models. In other study, Levy and Goldberg (2014) show that dense count-based methods, using PPMI weighted co-occurrences and SVD, approximates neural word embeddings. Later, Levy et al. (2015) show the impact of various parameters and the best performing parameters for these methods. All these approaches are completely text based; no external knowledge source has been used. Relat"
N18-1043,N13-1092,0,0.0598104,"Missing"
N18-1043,N15-1165,0,0.0226649,"al., 2014; Tian et al., 2016; Rastogi et al., 2015) or postprocess pre-trained word representations (Faruqui et al., 2015). Another line of literature prepares dense vector representation from each of the modes (text, knowledge bases, visual etc.) and tries to combine the vectors using various methods like concatenation, centroid computation, principal component analysis (Jolliffe, 1986), canonical correlation analysis (Faruqui and Dyer, 2014) etc. One such recent attempt is made by Goikoetxea et al. (2016) where they prepare vector representation from WordNet following the method proposed by Goikoetxea et al. (2015), which combines random walks over knowledge bases and neural network language model, and tries to improve the vector representation constructed from text using this. As in lexical knowledge bases, the number of lexical items involved is much less than the raw text and preparing such resources is a cumbersome task, our goal is to see whether we can use DT network instead of some knowledge bases like WordNet and achieve comparable performance on NLP tasks like word similarity and word relatedness. In order to prepare vector representation from DT network, we attempt to use various network embed"
N18-1043,S13-1035,0,0.101742,"DeepWalk (Perozzi et al., 2014), LINE (Tang et al., 2015), struc2vec (Ribeiro et al., 2017), node2vec (Grover and Leskovec, 2016) etc. Some of those try to capture the neighbourhood or community structure in the network while others attempt to capture structural similarity between nodes, second order proximity, etc. 3 3.1 Distributional Thesaurus (DT) Network Riedl and Biemann (2013) use the Google books corpus, consisting of texts from over 3.4 million digitized English books published between 1520 and 2008 and construct a distributional thesauri (DT) network using the syntactic n-gram data (Goldberg and Orwant, 2013). The authors first compute the lexicographer’s mutual information (LMI) (Kilgarriff et al., 2004) for each bigram, which gives a measure of the collocational strength of a bigram. Each bigram is broken into a word and a feature, where the feature consists of the bigram relation and the related word. Then the top 1000 ranked features for each word are taken and for each word pair, intersection of their corresponding feature set is obtained. The word pairs having number of overlapping features above a threshold are retained in the network. In a nutshell, the DT network contains, for each word,"
N18-1043,D14-1162,0,0.094187,"eddings on synonym detection and analogy detection as well. In both the tasks, combined representation of GloVe and DT embeddings shows promising performance gain over state-of-the-art embeddings. 2 In another stream of literature, word embeddings represent words as dense unit vectors of real numbers, where vectors that are close together in euclidean space are considered to be semantically related. In this genre of representation, one of the captivating attempt is made by Mikolov et al. (2013), where they propose Word2vec, basically a set of two predictive models for neural embedding whereas Pennington et al. (2014) propose GloVe, which utilizes a dense count based model to come up with word embeddings that approximate this. Comparisons have also been made between count-based and prediction-based distributional models (Baroni et al., 2014) upon various tasks like relatedness, analogy, concept categorization etc., where researchers show that prediction-based word embeddings outperform sparse count-based methods used for computing distributional semantic models. In other study, Levy and Goldberg (2014) show that dense count-based methods, using PPMI weighted co-occurrences and SVD, approximates neural word"
N18-1043,N15-1058,0,0.0344914,"Missing"
N18-1043,D14-1005,0,0.0259126,"g to combine knowledge extracted from knowledge bases, images with distributed word representations prepared from text with the expectation of getting better representation. Some use 464 tional Thesaurus (DT) network applying network representation learning model. Next we combine this thesaurus embedding with state-of-theart vector representations prepared using GloVe and Word2vec model for analysis. Knowledge bases like WordNet (Miller, 1995), FreeBase (Bollacker et al., 2008), PPDB (Ganitkevitch et al., 2013), ConceptNet (Speer et al., 2017), whereas others use ImageNet (Frome et al., 2013; Kiela and Bottou, 2014; Both et al., 2017; Thoma et al., 2017) for capturing visual representation of lexical items. There are various ways of combining multiple representations. Some of the works extract lists of relations from knowledge bases and use those to either modify the learning algorithms (Halawi et al., 2012; Wang et al., 2014; Tian et al., 2016; Rastogi et al., 2015) or postprocess pre-trained word representations (Faruqui et al., 2015). Another line of literature prepares dense vector representation from each of the modes (text, knowledge bases, visual etc.) and tries to combine the vectors using vario"
N18-1043,D13-1089,0,0.800798,"number of times. The words are finally represented using these neighbors. Distributional Thesaurus is one such instance of this type, which gets automatically produced from a text corpus and identifies words that occur in similar contexts; the notion of which was used in early work about distributional semantics (Grefenstette, 2012; Lin, 1998; Curran and Moens, 2002). One such representation is JoBimText proposed by Biemann and Riedl (2013) that contains, for each word, a list of words that are similar with respect to their bigram distribution, thus producing a network representation. Later, Riedl and Biemann (2013) introduced a highly scalable approach for computing this network. We mention this representation as a DT network throughout this article. With the emergence of recent trend of embedding large networks into dense low-dimensional vector space efficiently (Perozzi et al., 2014; Tang et al., 2015; Grover and Leskovec, 2016) which are focused on capturing different properties of the network like neighborhood structure, community structure, etc., we explore representing DT network in a dense vector space and evaluate its useful application in various NLP tasks. There has been attempt (Ferret, 2017)"
N18-1043,Q15-1016,0,0.0407318,"h utilizes a dense count based model to come up with word embeddings that approximate this. Comparisons have also been made between count-based and prediction-based distributional models (Baroni et al., 2014) upon various tasks like relatedness, analogy, concept categorization etc., where researchers show that prediction-based word embeddings outperform sparse count-based methods used for computing distributional semantic models. In other study, Levy and Goldberg (2014) show that dense count-based methods, using PPMI weighted co-occurrences and SVD, approximates neural word embeddings. Later, Levy et al. (2015) show the impact of various parameters and the best performing parameters for these methods. All these approaches are completely text based; no external knowledge source has been used. Related Work The core idea behind the construction of distributional thesauri is the distributional hypothesis (Firth, 1957): “You should know a word by the company it keeps”. The semantic neighbors of a target word are words whose contexts overlap with the context of a target word above a certain threshold. Some of the initial attempts for preparing distributional thesaurus are made by Lin (1998), Curran and Mo"
N18-1043,P98-2127,0,0.906567,"count-based model like GloVe (Pennington et al., 2014) which are computationally efficient as well. Another stream of representation talks about network like structure where two words are considered neighbors if they both occur in the same context above a certain number of times. The words are finally represented using these neighbors. Distributional Thesaurus is one such instance of this type, which gets automatically produced from a text corpus and identifies words that occur in similar contexts; the notion of which was used in early work about distributional semantics (Grefenstette, 2012; Lin, 1998; Curran and Moens, 2002). One such representation is JoBimText proposed by Biemann and Riedl (2013) that contains, for each word, a list of words that are similar with respect to their bigram distribution, thus producing a network representation. Later, Riedl and Biemann (2013) introduced a highly scalable approach for computing this network. We mention this representation as a DT network throughout this article. With the emergence of recent trend of embedding large networks into dense low-dimensional vector space efficiently (Perozzi et al., 2014; Tang et al., 2015; Grover and Leskovec, 2016"
N18-1043,D14-1167,0,0.0279131,"eart vector representations prepared using GloVe and Word2vec model for analysis. Knowledge bases like WordNet (Miller, 1995), FreeBase (Bollacker et al., 2008), PPDB (Ganitkevitch et al., 2013), ConceptNet (Speer et al., 2017), whereas others use ImageNet (Frome et al., 2013; Kiela and Bottou, 2014; Both et al., 2017; Thoma et al., 2017) for capturing visual representation of lexical items. There are various ways of combining multiple representations. Some of the works extract lists of relations from knowledge bases and use those to either modify the learning algorithms (Halawi et al., 2012; Wang et al., 2014; Tian et al., 2016; Rastogi et al., 2015) or postprocess pre-trained word representations (Faruqui et al., 2015). Another line of literature prepares dense vector representation from each of the modes (text, knowledge bases, visual etc.) and tries to combine the vectors using various methods like concatenation, centroid computation, principal component analysis (Jolliffe, 1986), canonical correlation analysis (Faruqui and Dyer, 2014) etc. One such recent attempt is made by Goikoetxea et al. (2016) where they prepare vector representation from WordNet following the method proposed by Goikoetxe"
N18-1043,J15-4004,0,\N,Missing
N18-1043,C98-2122,0,\N,Missing
N18-1043,I17-1028,0,\N,Missing
N18-5004,C16-1320,1,0.902908,"Missing"
N18-5004,bird-etal-2008-acl,0,0.0901378,"Missing"
N18-5004,councill-etal-2008-parscit,0,0.0239063,".in Abstract 1.1 Owing to above limitations, ACL anthology remained an archival repository for quite a long time. Bird et al. (2008) developed the ACL Anthology Reference Corpus (ACL ARC) as a collaborative attempt to provide a standardized testbed reference corpus based on the ACL Anthology. Later, Radev et al. (2009) have invested humongous manual efforts to construct The ACL Anthology Network Corpus (AAN). AAN consists of a manually curated database of citations, collaborations, and summaries and statistics about the network. They have utilized two OCR processing tools PDFBox2 and ParsCit (Councill et al., 2008) for curation. AAN was continuously updated till 2013 (Radev et al., 2013). Recently, this project has been moved to Yale University as part of the new LILY group3 . We present CL Scholar, the ACL Anthology knowledge graph miner to facilitate highquality search and exploration of current research progress in the computational linguistics community. In contrast to previous works, periodically crawling, indexing and processing of new incoming articles is completely automated in the current system. CL Scholar utilizes both textual and network information for knowledge graph construction. As an ad"
N18-5004,C08-1087,0,0.123774,"aded in a plain text format. Figure 6 shows a snapshot of the CL Scholar landing page. publication and citation count, 2-year impact factor, recently held year and list of collaborating venues. Table 5 shows three representative venue specific queries. Table 5: Representative entity specific queries. Paper specific Author specific Venue specific OCR Deep learning Word embeddings Chris Singh Aravind Joshi NAACL SIGDAT ACL 5.3 Additional insights We provide two additional insights by analyzing incoming citation contexts. First, we present a summary generated from incoming the citation contexts (Qazvinian and Radev, 2008). Currently, we show five summary sentences against each paper. Second, we also compute sentiment score of each citation context by leveraging a standard sentiment analyzer (Athar and Teufel, 2012). We aggregate by averaging over the sentiment score of all the incoming citation contexts. 5.4 Figure 6: Snapshot of CL Scholar landing page. The current system is still under development. Currently, we assume that spellings are correct for NLQ. We do not support instant query search. We also do not support query recommendations. 6 In this paper, we propose a fully automatic approach for the develop"
N18-5004,W09-3607,0,0.0255093,"lar: The ACL Anthology Knowledge Graph Miner Mayank Singh, Pradeep Dogga∗, Sohan Patro∗, Dhiraj Barnwal∗, Ritam Dutt∗, Rajarshi Haldar, Pawan Goyal and Animesh Mukherjee Department of Computer Science and Engineering Indian Institute of Technology, Kharagpur, WB, India mayank.singh@cse.iitkgp.ernet.in Abstract 1.1 Owing to above limitations, ACL anthology remained an archival repository for quite a long time. Bird et al. (2008) developed the ACL Anthology Reference Corpus (ACL ARC) as a collaborative attempt to provide a standardized testbed reference corpus based on the ACL Anthology. Later, Radev et al. (2009) have invested humongous manual efforts to construct The ACL Anthology Network Corpus (AAN). AAN consists of a manually curated database of citations, collaborations, and summaries and statistics about the network. They have utilized two OCR processing tools PDFBox2 and ParsCit (Councill et al., 2008) for curation. AAN was continuously updated till 2013 (Radev et al., 2013). Recently, this project has been moved to Yale University as part of the new LILY group3 . We present CL Scholar, the ACL Anthology knowledge graph miner to facilitate highquality search and exploration of current research"
P14-1096,W06-3812,1,0.756833,"ected by comparing its senses obtained from two different time periods. Since we aim to detect this change automatically, we require distributional representations corresponding to word senses for different time periods. We, therefore, utilize the basic hypothesis of unsupervised sense induction to induce the sense clusters over various time periods and then compare these clusters to detect sense change. The basic premises of the ‘unsupervised sense induction’ are briefly described below. 4.1 Unsupervised sense induction We use the co-occurrence based graph clustering framework introduced in (Biemann, 2006). The algorithm proceeds in three basic steps. Firstly, a co-occurrence graph is created for every target word found in DT. Next, the neighbourhood/ego graph is clustered using the Chinese Whispers (CW) algorithm (see (McAuley and Leskovec, 2012) for similar approaches). The algorithm, in particular, produces a set of clusters for each target word by decomposing its open neighborhood. We hypothesize that each different cluster corresponds to a particular sense of the target word. For a detailed description, the reader is referred to (Biemann, 2011). If a word undergoes sense change, this can b"
P14-1096,W09-3401,0,0.0195066,"ouns, verbs and adjectives as opposed to events that are characterized mostly by named entities. Other similar works on dynamic topic modelling can be found in (Blei and Lafferty, 2006; Wang and McCallum, 2006). Google books n-gram viewer1 is a phrase-usage graphing tool which charts the yearly count of selected letter combinations, words, or phrases as found in over 5.2 million digitized books. It only reports frequency of word usage over the years, but does not give any correlation among them as e.g., in (Heyer et al., 2009), and does not analyze their senses. A few approaches suggested by (Bond et al., 2009; P¨aa¨ kk¨o and Lind´en, 2012) attempt to augment WordNet synsets primarily using methods of annotation. Another recent work by Cook et al. (2013) attempts to induce word senses and then identify novel senses by comparing two different corpora: the “focus corpora” (i.e., a recent version of the corpora) and the “reference corpora” (older version of the corpora). However, this method is limited as it only considers two time points to 1021 1 https://books.google.com/ngrams identify sense changes as opposed to our approach which is over a much larger timescale, thereby, effectively allowing us t"
P14-1096,P12-2051,0,0.245702,"Missing"
P14-1096,D13-1089,1,0.848106,"ized books made available through the Google Book project (Goldberg and Orwant, 2013). The Google Book syntactic n-grams dataset provides dependency fragment counts by the years. However, instead of using the plain syntactic n-grams, we use a far richer representation of the data in the form of a distributional thesaurus (Lin, 1997; Rychl´y and Kilgarriff, 2007). In specific, we prepare a distributional thesaurus (DT) for each of the time periods separately and subsequently construct the required networks. We briefly outline the procedure of thesauri construction here referring the reader to (Riedl and Biemann, 2013) for further details. In this approach, we first extract each word and a set of its context features, which are formed by labeled and directed dependency parse edges as provided in the dataset. Following this, we compute the frequencies of the word, the context and the words along with their context. Next we calculate the lexicographer’s mutual information LMI (Kilgarriff, 2004) between a word and its features and retain only the top 1000 ranked features for every word. Finally, we construct the DT network as follows: each word is a node in the network and the edge weight between two nodes is"
P14-1096,S13-1035,0,0.0544826,"ncial institution” and the “shore of a river.” Automatic discovery and disambiguation of word senses from a given text is an important and challenging problem which has been extensively studied in the literature (Jones, 1986; Ide and Veronis, 1998; Sch¨utze, 1998; Navigli, 2009). However, another equally important aspect that has not been so far well investigated corresponds to one or more changes that a word might undergo in its sense. This particular aspect is getting increasingly attainable as more and more time-varying text data become available in the form of millions of digitized books (Goldberg and Orwant, 2013) gathered over the last centuries. As a motivating example one could consider the word “sick” – while according to the standard English dictionaries the word is normally used to refer to some sort of illness, a new meaning of “sick” referring to something that is “crazy” or “cool” is currently getting popular in the English vernacular. This change is further interesting because while traditionally “sick” has been associated to something negative in general, the current meaning associates positivity with it. In fact, a rock band by the name of “Sick Puppies” has been founded which probably is i"
P14-1096,riedl-etal-2014-distributed,1,0.877385,"Missing"
P14-1096,J98-1001,0,0.0387463,"scribe the datasets and outline the process of co-occurrence graph construction. In Section 4 we present an approach based on graph clustering to identify the time-varying sense clusters and in Section 5 we present the split-merge based approach for tracking word sense changes. Evaluation methods are summarized in Section 6. Finally, conclusions and further research directions are outlined in Section 7. 2 Related work Word sense disambiguation as well as word sense discovery have both remained key areas of research right from the very early initiatives in natural language processing research. Ide and Veronis (1998) present a very concise survey of the history of ideas used in word sense disambiguation; for a recent survey of the state-of-the-art one can refer to (Navigli, 2009). Some of the first attempts to automatic word sense discovery were made by Karen Sp¨arck Jones (1986); later in lexicography, it has been extensively used as a pre-processing step for preparing mono- and multi-lingual dictionaries (Kilgarriff and Tugwell, 2001; Kilgarriff, 2004). However, as we have already pointed out that none of these works consider the temporal aspect of the problem. In contrast, the current study, is inspire"
P14-1096,P97-1009,0,0.0334398,"hm in order to test its overall accuracy and performance. 3 Datasets and graph construction In this section, we outline a brief description of the dataset used for our experiments and the graph construction procedure. The primary source of data have been the millions of digitized books made available through the Google Book project (Goldberg and Orwant, 2013). The Google Book syntactic n-grams dataset provides dependency fragment counts by the years. However, instead of using the plain syntactic n-grams, we use a far richer representation of the data in the form of a distributional thesaurus (Lin, 1997; Rychl´y and Kilgarriff, 2007). In specific, we prepare a distributional thesaurus (DT) for each of the time periods separately and subsequently construct the required networks. We briefly outline the procedure of thesauri construction here referring the reader to (Riedl and Biemann, 2013) for further details. In this approach, we first extract each word and a set of its context features, which are formed by labeled and directed dependency parse edges as provided in the dataset. Following this, we compute the frequencies of the word, the context and the words along with their context. Next we"
P14-1096,P07-2011,0,0.138454,"Missing"
P14-1096,J98-1004,0,0.084685,"Missing"
P19-1111,Q17-1010,0,0.0722673,"Missing"
P19-1111,N18-1033,0,0.246772,"q2seq task (Gu et al., 2018).1 Hence, we formulate our task as that of a word linearisation task (He et al., 2009). In linearisation, we arrange a bag of words into a grammatical and fluent sentence (Liu et al., 2015). This eliminates the need for parallel data, as the poetry order is not anymore relevant at the input. A neural-LM based model from Schmaltz et al. (2016) and a seq2seq model form Wiseman and Rush (2016) are the current state of the art (SOTA) models in the linearisation task. We first show that a seq2seq model with gated CNNs (Gehring et al., 2017), using a sequence level loss (Edunov et al., 2018) can outperform both the SOTA models for the Sanskrit poetry linearisation task. But using a seq2seq model brings non-determinism to the model as the final prediction of the system is dependent on the order at which the words are input to the encoder (Vinyals et al., 2016). We resolve this, by using a pretraining approach (Wang et al., 2018) to obtain an initial ordering of the words, to be fed to the final model. This approach consistently performs better than using the original poetry order as input. Further, we find that generating multiple hypotheses2 using this component (Wang et al., 201"
P19-1111,N18-1032,0,0.012969,"f et al., 2015). As a result, the configurational information of the words in a verse is not aligned with its verbal cognition (Bhatta, 1990; Dennis, 2005). Obtaining the proper word ordering, called as the prose ordering, from a verse is often considered a task which requires linguistic expertise (Shukla et al., 2016; Kulkarni et al., 2015). ∗ Work done while the author was at IIT Kharagpur In this work, we use neural sequence generation models for automatic conversion of poetry to prose. Lack of sufficient poetry-prose parallel data is an impediment in framing the problem as a seq2seq task (Gu et al., 2018).1 Hence, we formulate our task as that of a word linearisation task (He et al., 2009). In linearisation, we arrange a bag of words into a grammatical and fluent sentence (Liu et al., 2015). This eliminates the need for parallel data, as the poetry order is not anymore relevant at the input. A neural-LM based model from Schmaltz et al. (2016) and a seq2seq model form Wiseman and Rush (2016) are the current state of the art (SOTA) models in the linearisation task. We first show that a seq2seq model with gated CNNs (Gehring et al., 2017), using a sequence level loss (Edunov et al., 2018) can out"
P19-1111,D18-1295,0,0.0473754,"Missing"
P19-1111,D18-1176,0,0.215435,"are input to the encoder (Vinyals et al., 2016). We resolve this, by using a pretraining approach (Wang et al., 2018) to obtain an initial ordering of the words, to be fed to the final model. This approach consistently performs better than using the original poetry order as input. Further, we find that generating multiple hypotheses2 using this component (Wang et al., 2018), to be fed to the final seq2seq component, results in improving the results by about 8 BLEU points. Additionally, we use a pretraining approach to learn task specific word embeddings by combining multiple word embeddings (Kiela et al., 2018). We call our final configuration as k¯avya guru. ‘k¯avya guru’ is a compound word in Sanskrit, which roughly translates to ‘an expert in prosody’. 1 Refer to Appendix A for details on our preliminary experiments in this direction. 2 Empirically shown to be 10 1160 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1160–1166 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics Figure 1: Configuration for k¯avya guru, demonstrated for a 3 word sentence with a prose order ‘r¯amah. vidy¯alayam gacchati’. English tr"
P19-1111,W17-2214,1,0.898611,"Missing"
P19-1111,P03-1069,0,0.150277,"Missing"
P19-1111,J06-4002,0,0.128912,"Missing"
P19-1111,N15-1012,0,0.0260953,"ing, called as the prose ordering, from a verse is often considered a task which requires linguistic expertise (Shukla et al., 2016; Kulkarni et al., 2015). ∗ Work done while the author was at IIT Kharagpur In this work, we use neural sequence generation models for automatic conversion of poetry to prose. Lack of sufficient poetry-prose parallel data is an impediment in framing the problem as a seq2seq task (Gu et al., 2018).1 Hence, we formulate our task as that of a word linearisation task (He et al., 2009). In linearisation, we arrange a bag of words into a grammatical and fluent sentence (Liu et al., 2015). This eliminates the need for parallel data, as the poetry order is not anymore relevant at the input. A neural-LM based model from Schmaltz et al. (2016) and a seq2seq model form Wiseman and Rush (2016) are the current state of the art (SOTA) models in the linearisation task. We first show that a seq2seq model with gated CNNs (Gehring et al., 2017), using a sequence level loss (Edunov et al., 2018) can outperform both the SOTA models for the Sanskrit poetry linearisation task. But using a seq2seq model brings non-determinism to the model as the final prediction of the system is dependent on"
P19-1111,P02-1040,0,0.103549,"e constrain the prediction of tokens to those available at the input during testing. Majority Vote Policy: For an input verse, SAWO generates multiple hypotheses and seq2seq then predicts a sequence corresponding to each of these, of the same size as the input. To get a single final output, we use a ‘Majority Vote’ policy. For each position, starting from left, we find the token which was predicted the most number of times at that position among all the seq2seq outputs, and choose it as the token in the final output. 3 Evaluation Metrics: Linearisation tasks are generally reported using BLEU (Papineni et al., 2002) score (Hasler et al., 2017; Belz et al., 2011). Additionally, we report Kendall’s Tau (τ ) and perfect match scores for the models. Perfect match is the fraction of sentences where the prediction matches exactly with the ground truth. Kendall’s Tau (τ ) is calculated based on the number of inversions needed to transform a predicted sequence to the ordering in the reference sequence. τ is used as a metric in sentence ordering tasks (La1 Pm pata, 2006), and is defined as m i=1 1 − 2 ×  inversions count/ n2 (Logeswaran et al., 2018; Lapata, 2003). In all these three metrics, a higher score alwa"
P19-1111,D16-1255,0,0.244047,"2015). ∗ Work done while the author was at IIT Kharagpur In this work, we use neural sequence generation models for automatic conversion of poetry to prose. Lack of sufficient poetry-prose parallel data is an impediment in framing the problem as a seq2seq task (Gu et al., 2018).1 Hence, we formulate our task as that of a word linearisation task (He et al., 2009). In linearisation, we arrange a bag of words into a grammatical and fluent sentence (Liu et al., 2015). This eliminates the need for parallel data, as the poetry order is not anymore relevant at the input. A neural-LM based model from Schmaltz et al. (2016) and a seq2seq model form Wiseman and Rush (2016) are the current state of the art (SOTA) models in the linearisation task. We first show that a seq2seq model with gated CNNs (Gehring et al., 2017), using a sequence level loss (Edunov et al., 2018) can outperform both the SOTA models for the Sanskrit poetry linearisation task. But using a seq2seq model brings non-determinism to the model as the final prediction of the system is dependent on the order at which the words are input to the encoder (Vinyals et al., 2016). We resolve this, by using a pretraining approach (Wang et al., 2018) to obtai"
P19-1111,P16-1162,0,0.112747,"Missing"
P19-1111,D18-1311,0,0.247723,"se order. Conversion of the verse to its corresponding prose helps in better comprehension of the construction. Owing to the resource constraints, we formulate this task as a word ordering (linearisation) task. In doing so, we completely ignore the word arrangement at the verse side. k¯avya guru, the approach we propose, essentially consists of a pipeline of two pretraining steps followed by a seq2seq model. The first pretraining step learns task specific token embeddings from pretrained embeddings. In the next step, we generate multiple hypotheses for possible word arrangements of the input (Wang et al., 2018). We then use them as inputs to a neural seq2seq model for the final prediction. We empirically show that the hypotheses generated by our pretraining step result in predictions that consistently outperform predictions based on the original order in the verse. Overall, k¯avya guru outperforms current state of the art models in linearisation for the poetry to prose conversion task in Sanskrit. 1 Introduction Prosody plays a key role in the word arrangement in Sanskrit Poetry. The word arrangement in a verse should result in a sequence of syllables which adhere to one of the prescribed meters in"
P19-1111,D16-1137,0,0.0310815,"Missing"
P19-1111,J15-3005,0,0.0591712,"Missing"
P19-1316,P19-1474,1,0.87498,"Missing"
P19-1316,W03-1812,0,0.478278,"meaning of the phrase can be derived from the meanings of its constituent words. To motivate its importance, e.g., in machine translation, noncompositional phrases must be translated as a unit; in word sense disambiguation, assigning one of the constituent word’s senses to the whole phrase should be avoided for idiomatic phrases; semantic parsing also requires to correctly identify complex predicates and their arguments in this way. A significant amount of effort has gone into operationalizing dense-vector distributional semantic models (DSMs) of different flavors such as count-based models (Baldwin et al. (2003); Venkatapathy and Joshi (2005); McCarthy et al. (2007)), word embeddings based on word2vec (both CBOW and SkipGram) and similar (Reddy et al. (2011); Salehi et al. (2014); Cordeiro et al. (2016, 2019)), and multi-sense skip-gram models for compositionality prediction (Salehi et al., 2015). All these attempts are based on the hypothesis that the composition of the representation of constituent words will be closer to the representation of the entire phrase in case of compositional phrases as compared to the non-compositional ones (Choueka, 1988). Observing that the distributional information 3"
P19-1316,W11-1304,1,0.776988,"tion more effectively than the commonly used additive and multiplicative functions. Kiela and Clark (2013) detect non-compositionality using concepts of mutual information. Lioma et al. (2015) replace the context vectors with language models and compute their Kullback–Leibler divergence to approximate their semantic distance. In another stream, researchers have also attempted to classify idiomatic vs. non-idiomatic expressions in different languages considering the context of the expressions (Flor and Klebanov, 2018; Bizzoni et al., 2018; Peng et al., 2018), see also a respective shared task (Biemann and Giesbrecht, 2011). In one of the recent attempts, Cordeiro et al. (2016) conduct an analysis of several DSMs (word2vec, GloVe, PPMI) with variations of hyper-parameters and produce the state-of-the-art results in the compositionality prediction task, which is extended further for different languages by Cordeiro et al. (2019). We take their work as our baseline and carry forward our investigation to improve the state-of-the-art performance by introducing the 3264 hyponymy-hypernymy information in the form of Poincar´e embeddings. Le et al. (2019) and Aly et al. (2019) also showed usefulness the use of Poincar´e"
P19-1316,W07-1106,0,0.0524878,"mprovements on benchmark datasets in unsupervised and supervised settings. 3. We publicly release our Poincar´e embeddings trained on pattern extractions on a very large corpus. 2 Related Work Some of the initial efforts on compositionality prediction were undertaken by Baldwin et al. (2003), who use LSA to calculate the similarity between a phrase and its components, whereas Venkatapathy and Joshi (2005) extend this idea with collocation features (e.g., phrase frequency, point-wise mutual information). Researchers also tried to identify non-compositionality in verb-noun phrases using syntax (Cook et al., 2007) and selectional preferences (McCarthy et al., 2007). Attempts to examine the possibility to derive the semantics of a compound or multiword expression from its parts have been researched extensively (McCarthy et al., 2003; Mitchell and Lapata, 2008; Tratz and Hovy, 2010). Reddy et al. (2011) define a compositionality score and use different vector operations to estimate the semantic distance between a phrase and its individual components. Some of the investigations are made for compositionality detection using representation learning of word embeddings (Socher et al., 2012; Salehi et al., 201"
P19-1316,P13-4006,0,0.017524,"ls as provided, with the vector dimension size of 750 (PPMI-SVD, W2V) and 500 (GloVe)2 . PPMI-SVD baseline: For each word, its neighboring nouns and verbs in a symmetric sliding window of w words in both directions, using a linear decay weighting scheme with respect to its distance d to the target (Levy et al., 2015) are extracted. The representation of a word is a vector containing the positive pointwise mutual information (PPMI) association scores between the word and its contexts. Note that, for each target word, contexts that appear less than 1000 times are discarded. The Dissect toolkit (Dinu et al., 2013) is then used in order to build a PPMI matrix and its dimensionality is reduced using singular value decomposition (SVD) to factorize the matrix. word2vec baseline: This DSM is prepared using the well-known word2vec (Mikolov et al., 2013) in both variants CBOW (W2V-CBOW) and Skip-Gram (W2V-SG), using default configurations except for the following: no hierarchical softmax; negative sampling of 25; frequent-word downsampling weight of 10−6 ; runs 15 training iterations; minimum word count threshold of 5. GloVe baseline: The count-based DSM of Pennington et al. (2014), implementing a factorizati"
P19-1316,W15-0904,0,0.0132577,"s a recently introduced resource created for evaluation (Ramisch et al., 2016) that extends the Reddy dataset with an additional 90 English nominal compounds, amounting to a total of 180 nominal compounds. Consistent with RD, the scores range from 0 (idiomatic) to 5 (compositional) and are annotated through Mechanical Turk and averaged over the annotators. The additional 90 entries are adjective-noun pairs, balanced with respect to compositionality. Farahmand (FD): This dataset contains 1042 English compounds extracted from Wikipedia with binary non-compositionality judgments by four experts (Farahmand et al., 2015). In evaluations we use the sum of all the judgments to have a single numeral compositionality score, ranging from 0 (compositional) to 4 (idiomatic). We optimize our method on subsets of the datasets for pairs and constituents with available Poincar´e embeddings in order to measure the direct impact of our method, which comprises 79, 146 and 780 datapoints for the three sets RD-R, RD++-R and FD-R, respectively. We subsequently report scores on the full datasets RD-F (90), RD++-F (180) and FD-F (1042) for the sake of fair comparison to previous works. In cases where no Poincar´e embeddings are"
P19-1316,W18-0905,0,0.0128343,"ds that complex functions such as polynomial projection and neural networks can model semantic composition more effectively than the commonly used additive and multiplicative functions. Kiela and Clark (2013) detect non-compositionality using concepts of mutual information. Lioma et al. (2015) replace the context vectors with language models and compute their Kullback–Leibler divergence to approximate their semantic distance. In another stream, researchers have also attempted to classify idiomatic vs. non-idiomatic expressions in different languages considering the context of the expressions (Flor and Klebanov, 2018; Bizzoni et al., 2018; Peng et al., 2018), see also a respective shared task (Biemann and Giesbrecht, 2011). In one of the recent attempts, Cordeiro et al. (2016) conduct an analysis of several DSMs (word2vec, GloVe, PPMI) with variations of hyper-parameters and produce the state-of-the-art results in the compositionality prediction task, which is extended further for different languages by Cordeiro et al. (2019). We take their work as our baseline and carry forward our investigation to improve the state-of-the-art performance by introducing the 3264 hyponymy-hypernymy information in the form"
P19-1316,goldhahn-etal-2012-building,0,0.0259866,"ous representations of symbolic data by simultaneously capturing hierarchy and similarity. As per this proposed Poincar´e ball model, let β d = {x ∈ R : kxk &lt; 1} (3) be the open d-dimensional unit ball, where k.k denotes the Euclidean norm. The list of hyponym-hypernym pairs was obtained by applying lexical-syntactic patterns described by Hearst (1992) on the corpus prepared by Panchenko et al. (2016). This corpus is a concatenation of the English Wikipedia (2016 dump), Gigaword (Parker et al., 2009), ukWaC (Ferraresi et al., 2008) and English news corpora from the Leipzig Corpora Collection (Goldhahn et al., 2012). The lexical-syntactic patterns proposed by Hearst (1992) and further extended and implemented in the form of FSTs by Panchenko et al. (2012)1 for extracting (noisy) hyponym-hypernym pairs are given as follows – (i) such NP as NP, NP[,] and/or NP; (ii) NP such as NP, NP[,] and/or NP; (iii) NP, NP [,] or other NP; (iv) NP, NP [,] and other NP; (v) NP, including NP, NP [,] and/or NP; (vi) NP, especially NP, NP [,] and/or NP. Pattern extraction on the corpus yields a list of 27.6 million hyponym-hypernym pairs along with the frequency of their occurrence in the corpus. We normalize the frequency"
P19-1316,C92-2082,0,0.530466,"example, ‘art school’ and ‘school’ have one common hypernym ‘educational institution’ whereas ‘hot dog’ has no common hypernym with ‘hot’ or ‘dog’, apart from very abstract concepts such as ‘physical entity’. Of course, this only holds for noun phrases, where taxonomic relations between nouns apply. To represent hypernymy information we use Poincar´e embeddings (Nickel and Kiela, 2017) for learning hierarchical representations of symbolic data by embedding them into a hyperbolic space. To this end, we extract hyponym-hypernym pairs by applying well-known lexical-syntactic patterns proposed by Hearst (1992) on a large corpus and train Poincar´e embeddings on a list of hyponymhypernym pairs. Relying on two types of representations, i.e., dense vectors in the Euclidean space and the novel hyperbolic Poincar´e embeddings, we interpolate their similarity predictions in a novel compositionality score metric that takes both distributional and hypernymy information into account. We evaluate our proposed metric on three well-accepted English datasets, i.e., Reddy (Reddy et al., 2011), Reddy++ (Ramisch et al., 2016) and Farahmand (Farahmand et al., 2015), demonstrating a performance boost when including"
P19-1316,P16-1187,0,0.0999607,"in word sense disambiguation, assigning one of the constituent word’s senses to the whole phrase should be avoided for idiomatic phrases; semantic parsing also requires to correctly identify complex predicates and their arguments in this way. A significant amount of effort has gone into operationalizing dense-vector distributional semantic models (DSMs) of different flavors such as count-based models (Baldwin et al. (2003); Venkatapathy and Joshi (2005); McCarthy et al. (2007)), word embeddings based on word2vec (both CBOW and SkipGram) and similar (Reddy et al. (2011); Salehi et al. (2014); Cordeiro et al. (2016, 2019)), and multi-sense skip-gram models for compositionality prediction (Salehi et al., 2015). All these attempts are based on the hypothesis that the composition of the representation of constituent words will be closer to the representation of the entire phrase in case of compositional phrases as compared to the non-compositional ones (Choueka, 1988). Observing that the distributional information 3263 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3263–3274 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Lingu"
P19-1316,D13-1147,0,0.0203407,"ual components. Some of the investigations are made for compositionality detection using representation learning of word embeddings (Socher et al., 2012; Salehi et al., 2015). Salehi et al. (2014) also show that distributional similarity over multiple languages can help in improving the quality of compositionality prediction. In a recent attempt, Yazdani et al. (2015) tries to learn semantic composition and finds that complex functions such as polynomial projection and neural networks can model semantic composition more effectively than the commonly used additive and multiplicative functions. Kiela and Clark (2013) detect non-compositionality using concepts of mutual information. Lioma et al. (2015) replace the context vectors with language models and compute their Kullback–Leibler divergence to approximate their semantic distance. In another stream, researchers have also attempted to classify idiomatic vs. non-idiomatic expressions in different languages considering the context of the expressions (Flor and Klebanov, 2018; Bizzoni et al., 2018; Peng et al., 2018), see also a respective shared task (Biemann and Giesbrecht, 2011). In one of the recent attempts, Cordeiro et al. (2016) conduct an analysis o"
P19-1316,J19-1001,0,0.0209654,"c distance. In another stream, researchers have also attempted to classify idiomatic vs. non-idiomatic expressions in different languages considering the context of the expressions (Flor and Klebanov, 2018; Bizzoni et al., 2018; Peng et al., 2018), see also a respective shared task (Biemann and Giesbrecht, 2011). In one of the recent attempts, Cordeiro et al. (2016) conduct an analysis of several DSMs (word2vec, GloVe, PPMI) with variations of hyper-parameters and produce the state-of-the-art results in the compositionality prediction task, which is extended further for different languages by Cordeiro et al. (2019). We take their work as our baseline and carry forward our investigation to improve the state-of-the-art performance by introducing the 3264 hyponymy-hypernymy information in the form of Poincar´e embeddings. Le et al. (2019) and Aly et al. (2019) also showed usefulness the use of Poincar´e embeddings: in their case for inducing taxonomies from the text. In both works, hyperbolic embeddings are trained using relations harvested using Hearst patterns, like in our work. The usefulness of hyperbolic embeddings was also shown beyond text processing: Khrulkov et al. (2019) successfully applied them"
P19-1316,P19-1313,0,0.0240964,"ng et al., 2018), see also a respective shared task (Biemann and Giesbrecht, 2011). In one of the recent attempts, Cordeiro et al. (2016) conduct an analysis of several DSMs (word2vec, GloVe, PPMI) with variations of hyper-parameters and produce the state-of-the-art results in the compositionality prediction task, which is extended further for different languages by Cordeiro et al. (2019). We take their work as our baseline and carry forward our investigation to improve the state-of-the-art performance by introducing the 3264 hyponymy-hypernymy information in the form of Poincar´e embeddings. Le et al. (2019) and Aly et al. (2019) also showed usefulness the use of Poincar´e embeddings: in their case for inducing taxonomies from the text. In both works, hyperbolic embeddings are trained using relations harvested using Hearst patterns, like in our work. The usefulness of hyperbolic embeddings was also shown beyond text processing: Khrulkov et al. (2019) successfully applied them for hierarchical relations in image classification tasks. 3 Methodology Our aim is to produce a compositionality score for a given two-word noun phrase w1 w2 . As per our hypothesis, the proposed compositionality score metri"
P19-1316,Q15-1016,0,0.0481565,"seline, where authors apply several distributional semantic models and their variants by tuning hyperparameters like the dimension of vectors, the window-size during training and others. We resort to PPMI-SVD, two variants of word2vec (CBOW and SkipGram) and GloVe as our baselines. We use these models as provided, with the vector dimension size of 750 (PPMI-SVD, W2V) and 500 (GloVe)2 . PPMI-SVD baseline: For each word, its neighboring nouns and verbs in a symmetric sliding window of w words in both directions, using a linear decay weighting scheme with respect to its distance d to the target (Levy et al., 2015) are extracted. The representation of a word is a vector containing the positive pointwise mutual information (PPMI) association scores between the word and its contexts. Note that, for each target word, contexts that appear less than 1000 times are discarded. The Dissect toolkit (Dinu et al., 2013) is then used in order to build a PPMI matrix and its dimensionality is reduced using singular value decomposition (SVD) to factorize the matrix. word2vec baseline: This DSM is prepared using the well-known word2vec (Mikolov et al., 2013) in both variants CBOW (W2V-CBOW) and Skip-Gram (W2V-SG), usin"
P19-1316,W03-1810,0,0.149849,"s on compositionality prediction were undertaken by Baldwin et al. (2003), who use LSA to calculate the similarity between a phrase and its components, whereas Venkatapathy and Joshi (2005) extend this idea with collocation features (e.g., phrase frequency, point-wise mutual information). Researchers also tried to identify non-compositionality in verb-noun phrases using syntax (Cook et al., 2007) and selectional preferences (McCarthy et al., 2007). Attempts to examine the possibility to derive the semantics of a compound or multiword expression from its parts have been researched extensively (McCarthy et al., 2003; Mitchell and Lapata, 2008; Tratz and Hovy, 2010). Reddy et al. (2011) define a compositionality score and use different vector operations to estimate the semantic distance between a phrase and its individual components. Some of the investigations are made for compositionality detection using representation learning of word embeddings (Socher et al., 2012; Salehi et al., 2015). Salehi et al. (2014) also show that distributional similarity over multiple languages can help in improving the quality of compositionality prediction. In a recent attempt, Yazdani et al. (2015) tries to learn semantic"
P19-1316,D07-1039,0,0.108452,"Missing"
P19-1316,P08-1028,0,0.0877299,"rediction were undertaken by Baldwin et al. (2003), who use LSA to calculate the similarity between a phrase and its components, whereas Venkatapathy and Joshi (2005) extend this idea with collocation features (e.g., phrase frequency, point-wise mutual information). Researchers also tried to identify non-compositionality in verb-noun phrases using syntax (Cook et al., 2007) and selectional preferences (McCarthy et al., 2007). Attempts to examine the possibility to derive the semantics of a compound or multiword expression from its parts have been researched extensively (McCarthy et al., 2003; Mitchell and Lapata, 2008; Tratz and Hovy, 2010). Reddy et al. (2011) define a compositionality score and use different vector operations to estimate the semantic distance between a phrase and its individual components. Some of the investigations are made for compositionality detection using representation learning of word embeddings (Socher et al., 2012; Salehi et al., 2015). Salehi et al. (2014) also show that distributional similarity over multiple languages can help in improving the quality of compositionality prediction. In a recent attempt, Yazdani et al. (2015) tries to learn semantic composition and finds that"
P19-1316,S16-1206,1,0.884605,"Missing"
P19-1316,D14-1162,0,0.0900465,"e discarded. The Dissect toolkit (Dinu et al., 2013) is then used in order to build a PPMI matrix and its dimensionality is reduced using singular value decomposition (SVD) to factorize the matrix. word2vec baseline: This DSM is prepared using the well-known word2vec (Mikolov et al., 2013) in both variants CBOW (W2V-CBOW) and Skip-Gram (W2V-SG), using default configurations except for the following: no hierarchical softmax; negative sampling of 25; frequent-word downsampling weight of 10−6 ; runs 15 training iterations; minimum word count threshold of 5. GloVe baseline: The count-based DSM of Pennington et al. (2014), implementing a factorization of the co-occurrence count matrix is used for the task. The configurations are the default ones, except for the following: internal cutoff parameter xmax = 75; builds co-occurrence matrix in 15 iterations; minimum word count threshold of 5. Other baseline models proposed by Reddy et al. (2011), Salehi et al. (2014), Salehi et al. (2015) report results only on Reddy dataset (since the other two datasets have been introduced later) whereas Yazdani et al. (2015) perform their evaluation only on the Farahmand dataset for their supervised model. In addition, this supe"
P19-1316,P16-2026,0,0.0142342,"Datasets To evaluate our proposed models (both supervised and unsupervised) we use three gold standard datasets for English on compositionality detection and describe them in the following. 3266 Reddy (RD): This dataset contains compositionality judgments for 90 compounds in a scale of literality from 0 (idiomatic) to 5 (compositional), obtained by averaging crowdsourced judgments on these pairs (Reddy et al., 2011). For evaluation, we use only the global compositionality score, ignoring individual word judgments. Reddy++ (RD++): This is a recently introduced resource created for evaluation (Ramisch et al., 2016) that extends the Reddy dataset with an additional 90 English nominal compounds, amounting to a total of 180 nominal compounds. Consistent with RD, the scores range from 0 (idiomatic) to 5 (compositional) and are annotated through Mechanical Turk and averaged over the annotators. The additional 90 entries are adjective-noun pairs, balanced with respect to compositionality. Farahmand (FD): This dataset contains 1042 English compounds extracted from Wikipedia with binary non-compositionality judgments by four experts (Farahmand et al., 2015). In evaluations we use the sum of all the judgments to"
P19-1316,I11-1024,0,0.337019,"ional phrases must be translated as a unit; in word sense disambiguation, assigning one of the constituent word’s senses to the whole phrase should be avoided for idiomatic phrases; semantic parsing also requires to correctly identify complex predicates and their arguments in this way. A significant amount of effort has gone into operationalizing dense-vector distributional semantic models (DSMs) of different flavors such as count-based models (Baldwin et al. (2003); Venkatapathy and Joshi (2005); McCarthy et al. (2007)), word embeddings based on word2vec (both CBOW and SkipGram) and similar (Reddy et al. (2011); Salehi et al. (2014); Cordeiro et al. (2016, 2019)), and multi-sense skip-gram models for compositionality prediction (Salehi et al., 2015). All these attempts are based on the hypothesis that the composition of the representation of constituent words will be closer to the representation of the entire phrase in case of compositional phrases as compared to the non-compositional ones (Choueka, 1988). Observing that the distributional information 3263 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3263–3274 c Florence, Italy, July 28 - August 2, 2"
P19-1316,E14-1050,0,0.261156,"translated as a unit; in word sense disambiguation, assigning one of the constituent word’s senses to the whole phrase should be avoided for idiomatic phrases; semantic parsing also requires to correctly identify complex predicates and their arguments in this way. A significant amount of effort has gone into operationalizing dense-vector distributional semantic models (DSMs) of different flavors such as count-based models (Baldwin et al. (2003); Venkatapathy and Joshi (2005); McCarthy et al. (2007)), word embeddings based on word2vec (both CBOW and SkipGram) and similar (Reddy et al. (2011); Salehi et al. (2014); Cordeiro et al. (2016, 2019)), and multi-sense skip-gram models for compositionality prediction (Salehi et al., 2015). All these attempts are based on the hypothesis that the composition of the representation of constituent words will be closer to the representation of the entire phrase in case of compositional phrases as compared to the non-compositional ones (Choueka, 1988). Observing that the distributional information 3263 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3263–3274 c Florence, Italy, July 28 - August 2, 2019. 2019 Association"
P19-1316,N15-1099,0,0.0363598,"Missing"
P19-1316,D12-1110,0,0.0529303,"hrases using syntax (Cook et al., 2007) and selectional preferences (McCarthy et al., 2007). Attempts to examine the possibility to derive the semantics of a compound or multiword expression from its parts have been researched extensively (McCarthy et al., 2003; Mitchell and Lapata, 2008; Tratz and Hovy, 2010). Reddy et al. (2011) define a compositionality score and use different vector operations to estimate the semantic distance between a phrase and its individual components. Some of the investigations are made for compositionality detection using representation learning of word embeddings (Socher et al., 2012; Salehi et al., 2015). Salehi et al. (2014) also show that distributional similarity over multiple languages can help in improving the quality of compositionality prediction. In a recent attempt, Yazdani et al. (2015) tries to learn semantic composition and finds that complex functions such as polynomial projection and neural networks can model semantic composition more effectively than the commonly used additive and multiplicative functions. Kiela and Clark (2013) detect non-compositionality using concepts of mutual information. Lioma et al. (2015) replace the context vectors with language m"
P19-1316,S10-1049,0,0.0130872,"y Baldwin et al. (2003), who use LSA to calculate the similarity between a phrase and its components, whereas Venkatapathy and Joshi (2005) extend this idea with collocation features (e.g., phrase frequency, point-wise mutual information). Researchers also tried to identify non-compositionality in verb-noun phrases using syntax (Cook et al., 2007) and selectional preferences (McCarthy et al., 2007). Attempts to examine the possibility to derive the semantics of a compound or multiword expression from its parts have been researched extensively (McCarthy et al., 2003; Mitchell and Lapata, 2008; Tratz and Hovy, 2010). Reddy et al. (2011) define a compositionality score and use different vector operations to estimate the semantic distance between a phrase and its individual components. Some of the investigations are made for compositionality detection using representation learning of word embeddings (Socher et al., 2012; Salehi et al., 2015). Salehi et al. (2014) also show that distributional similarity over multiple languages can help in improving the quality of compositionality prediction. In a recent attempt, Yazdani et al. (2015) tries to learn semantic composition and finds that complex functions such"
P19-1316,H05-1113,0,0.269682,"can be derived from the meanings of its constituent words. To motivate its importance, e.g., in machine translation, noncompositional phrases must be translated as a unit; in word sense disambiguation, assigning one of the constituent word’s senses to the whole phrase should be avoided for idiomatic phrases; semantic parsing also requires to correctly identify complex predicates and their arguments in this way. A significant amount of effort has gone into operationalizing dense-vector distributional semantic models (DSMs) of different flavors such as count-based models (Baldwin et al. (2003); Venkatapathy and Joshi (2005); McCarthy et al. (2007)), word embeddings based on word2vec (both CBOW and SkipGram) and similar (Reddy et al. (2011); Salehi et al. (2014); Cordeiro et al. (2016, 2019)), and multi-sense skip-gram models for compositionality prediction (Salehi et al., 2015). All these attempts are based on the hypothesis that the composition of the representation of constituent words will be closer to the representation of the entire phrase in case of compositional phrases as compared to the non-compositional ones (Choueka, 1988). Observing that the distributional information 3263 Proceedings of the 57th Ann"
P19-1316,D15-1201,0,0.200919,"researched extensively (McCarthy et al., 2003; Mitchell and Lapata, 2008; Tratz and Hovy, 2010). Reddy et al. (2011) define a compositionality score and use different vector operations to estimate the semantic distance between a phrase and its individual components. Some of the investigations are made for compositionality detection using representation learning of word embeddings (Socher et al., 2012; Salehi et al., 2015). Salehi et al. (2014) also show that distributional similarity over multiple languages can help in improving the quality of compositionality prediction. In a recent attempt, Yazdani et al. (2015) tries to learn semantic composition and finds that complex functions such as polynomial projection and neural networks can model semantic composition more effectively than the commonly used additive and multiplicative functions. Kiela and Clark (2013) detect non-compositionality using concepts of mutual information. Lioma et al. (2015) replace the context vectors with language models and compute their Kullback–Leibler divergence to approximate their semantic distance. In another stream, researchers have also attempted to classify idiomatic vs. non-idiomatic expressions in different languages"
W14-3704,balahur-etal-2010-sentiment,0,0.0785923,"Missing"
W14-3704,C12-2017,0,0.157779,"s (Balahur et al., 2013) and thus finding opinionated sentences itself remains a major obstacle. Our work mainly focus on classifying a sentence in a news article as opinionated or factual. There have been works on sentiment classification (Wiebe and Riloff, 2005) but the task of finding opinionated sentences is different from finding sentiments, because sentiments mainly convey the emotions and not the opinions. There has been research on finding opinionated sentences from various information sources. Some of these works utilize a dictionary-based (Fei et al., 2012) or regular pattern based (Brun, 2012) approach to identify aspects in the sentences. (Kim and Hovy, 2006) utilize the presence of a single strong valence wors as well as the total valence score of all words in a sentence to identify opinion-bearing sentences. (Zhai et al., 2011) work on finding ‘evaluative’ sentences in online discussions. They exploit the inter-relationship of aspects, evaluation words and emotion words to reinforce each other. 3.1 Na¨ıve Bayes Classifier The Na¨ıve Bayes classifier assigns the probability for each sentence being opinionated. The classifier is trained on 70 News articles from politics domain, se"
W14-3704,H05-1045,0,0.0487137,"pages 25–33, c October 29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics 3 opinions from various information sources such as blogs (Conrad and Schilder, 2007; Harb et al., 2008), product reviews (Hu and Liu, 2004; Qadir, 2009; Dave et al., 2003), news articles (Kim and Hovy, 2006; Hu and Liu, 2006) etc. Various aspects in opinion mining have been explored over the years (Ku et al., 2006). One important dimension is to identify the opinion holders as well as opinion targets. (Lu, 2010) used dependency parser to identify the opinion holders and targets in Chinese news text. (Choi et al., 2005) use Conditional Random Fields to identify the sources of opinions from the sentences. (Kobayashi et al., 2005) propose a learning based anaphora resolution technique to extract the opinion tuple &lt; Subject, Attribute, V alue &gt;. Opinion summarization has been another important aspect (Kim et al., 2013). Our Approach Figure 1 gives a flowchart of the proposed two-stage method for extracting opinionated sentences from news articles. First, each news article is pre-processed to get the dependency parse as well as the TF-IDF vector corresponding to each of the sentences present in the article. Then"
W14-3704,I05-2030,0,0.0352086,"om various information sources such as blogs (Conrad and Schilder, 2007; Harb et al., 2008), product reviews (Hu and Liu, 2004; Qadir, 2009; Dave et al., 2003), news articles (Kim and Hovy, 2006; Hu and Liu, 2006) etc. Various aspects in opinion mining have been explored over the years (Ku et al., 2006). One important dimension is to identify the opinion holders as well as opinion targets. (Lu, 2010) used dependency parser to identify the opinion holders and targets in Chinese news text. (Choi et al., 2005) use Conditional Random Fields to identify the sources of opinions from the sentences. (Kobayashi et al., 2005) propose a learning based anaphora resolution technique to extract the opinion tuple &lt; Subject, Attribute, V alue &gt;. Opinion summarization has been another important aspect (Kim et al., 2013). Our Approach Figure 1 gives a flowchart of the proposed two-stage method for extracting opinionated sentences from news articles. First, each news article is pre-processed to get the dependency parse as well as the TF-IDF vector corresponding to each of the sentences present in the article. Then, various features are extracted from these sentences which are used as input to the Na¨ıve Bayes classifier, a"
W14-3704,de-marneffe-etal-2006-generating,0,0.0594084,"Missing"
W14-3704,C12-2031,0,0.0291779,"t all parts of news articles present opinions (Balahur et al., 2013) and thus finding opinionated sentences itself remains a major obstacle. Our work mainly focus on classifying a sentence in a news article as opinionated or factual. There have been works on sentiment classification (Wiebe and Riloff, 2005) but the task of finding opinionated sentences is different from finding sentiments, because sentiments mainly convey the emotions and not the opinions. There has been research on finding opinionated sentences from various information sources. Some of these works utilize a dictionary-based (Fei et al., 2012) or regular pattern based (Brun, 2012) approach to identify aspects in the sentences. (Kim and Hovy, 2006) utilize the presence of a single strong valence wors as well as the total valence score of all words in a sentence to identify opinion-bearing sentences. (Zhai et al., 2011) work on finding ‘evaluative’ sentences in online discussions. They exploit the inter-relationship of aspects, evaluation words and emotion words to reinforce each other. 3.1 Na¨ıve Bayes Classifier The Na¨ıve Bayes classifier assigns the probability for each sentence being opinionated. The classifier is trained on 70"
W14-3704,N10-3009,0,0.0176192,"5 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 25–33, c October 29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics 3 opinions from various information sources such as blogs (Conrad and Schilder, 2007; Harb et al., 2008), product reviews (Hu and Liu, 2004; Qadir, 2009; Dave et al., 2003), news articles (Kim and Hovy, 2006; Hu and Liu, 2006) etc. Various aspects in opinion mining have been explored over the years (Ku et al., 2006). One important dimension is to identify the opinion holders as well as opinion targets. (Lu, 2010) used dependency parser to identify the opinion holders and targets in Chinese news text. (Choi et al., 2005) use Conditional Random Fields to identify the sources of opinions from the sentences. (Kobayashi et al., 2005) propose a learning based anaphora resolution technique to extract the opinion tuple &lt; Subject, Attribute, V alue &gt;. Opinion summarization has been another important aspect (Kim et al., 2013). Our Approach Figure 1 gives a flowchart of the proposed two-stage method for extracting opinionated sentences from news articles. First, each news article is pre-processed to get the depe"
W14-3704,W09-4306,0,0.361476,"ld also direct the users into thinking about a spectrum of various points that the article covers and encourage users to share their unique, personal, 2 Related Work Opinion mining has drawn a lot of attention in recent years. Research works have focused on mining 25 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 25–33, c October 29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics 3 opinions from various information sources such as blogs (Conrad and Schilder, 2007; Harb et al., 2008), product reviews (Hu and Liu, 2004; Qadir, 2009; Dave et al., 2003), news articles (Kim and Hovy, 2006; Hu and Liu, 2006) etc. Various aspects in opinion mining have been explored over the years (Ku et al., 2006). One important dimension is to identify the opinion holders as well as opinion targets. (Lu, 2010) used dependency parser to identify the opinion holders and targets in Chinese news text. (Choi et al., 2005) use Conditional Random Fields to identify the sources of opinions from the sentences. (Kobayashi et al., 2005) propose a learning based anaphora resolution technique to extract the opinion tuple &lt; Subject, Attribute, V alue &gt;."
W14-3704,P13-1073,0,0.0204869,"ture of the comments posted by readers of 105 articles posted at any moment on its website. A lot of users engage in discussions in the comments section of the articles. Each user has a different perspective and thus comments in that genre - this many a times, results in a situation where the discussions in the comment section wander far away from the articles topic. In order to assist users to discuss relevant points in the comments section, a possible methodology can be to generate questions from the article’s content that seek user’s opinions about various opinions conveyed in the article (Rokhlenko and Szpektor, 2013). It would also direct the users into thinking about a spectrum of various points that the article covers and encourage users to share their unique, personal, 2 Related Work Opinion mining has drawn a lot of attention in recent years. Research works have focused on mining 25 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 25–33, c October 29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics 3 opinions from various information sources such as blogs (Conrad and Schilder, 2007; Harb et al., 2008), product reviews (Hu and Liu"
W14-3704,W03-1017,0,0.332629,"pects, evaluation words and emotion words to reinforce each other. 3.1 Na¨ıve Bayes Classifier The Na¨ıve Bayes classifier assigns the probability for each sentence being opinionated. The classifier is trained on 70 News articles from politics domain, sentences of which were marked by a group of annotators as being opinionated or factual. Each sentence was marked by two annotators. The inter-annotator agreement using Cohen’s kappa coefficient was found to be 0.71. The features utilized for the classifier are detailed in Table 1. These features were adapted from those reported in (Qadir, 2009; Yu and Hatzivassiloglou, 2003). A list of positive and negative polar words, further expanded using wordnet synsets was taken from (Kim and Hovy, 2005). Stanford dependency parser (De Marneffe et al., 2006) was utilized to compute the dependencies for each sentence within the news article. After the features are extracted from the sentences, we used the Weka implementation of Na¨ıve Bayes to train the classifier1 . Table 1: Features List for the Na¨ıve Bayes Classifier Thus, while ours is not the first attempt at opinion extraction from news articles, to the best of our knowledge, none of the previous works has exploited t"
W14-3704,I05-2011,0,0.0163589,"he probability for each sentence being opinionated. The classifier is trained on 70 News articles from politics domain, sentences of which were marked by a group of annotators as being opinionated or factual. Each sentence was marked by two annotators. The inter-annotator agreement using Cohen’s kappa coefficient was found to be 0.71. The features utilized for the classifier are detailed in Table 1. These features were adapted from those reported in (Qadir, 2009; Yu and Hatzivassiloglou, 2003). A list of positive and negative polar words, further expanded using wordnet synsets was taken from (Kim and Hovy, 2005). Stanford dependency parser (De Marneffe et al., 2006) was utilized to compute the dependencies for each sentence within the news article. After the features are extracted from the sentences, we used the Weka implementation of Na¨ıve Bayes to train the classifier1 . Table 1: Features List for the Na¨ıve Bayes Classifier Thus, while ours is not the first attempt at opinion extraction from news articles, to the best of our knowledge, none of the previous works has exploited the global structure of a news article to classify a sentence as opinionated/factual. Though summarization algorithms (Erk"
W14-3704,W06-0301,0,0.410984,"pectrum of various points that the article covers and encourage users to share their unique, personal, 2 Related Work Opinion mining has drawn a lot of attention in recent years. Research works have focused on mining 25 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 25–33, c October 29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics 3 opinions from various information sources such as blogs (Conrad and Schilder, 2007; Harb et al., 2008), product reviews (Hu and Liu, 2004; Qadir, 2009; Dave et al., 2003), news articles (Kim and Hovy, 2006; Hu and Liu, 2006) etc. Various aspects in opinion mining have been explored over the years (Ku et al., 2006). One important dimension is to identify the opinion holders as well as opinion targets. (Lu, 2010) used dependency parser to identify the opinion holders and targets in Chinese news text. (Choi et al., 2005) use Conditional Random Fields to identify the sources of opinions from the sentences. (Kobayashi et al., 2005) propose a learning based anaphora resolution technique to extract the opinion tuple &lt; Subject, Attribute, V alue &gt;. Opinion summarization has been another important aspec"
W16-3701,C02-1096,0,0.152335,"Missing"
W16-3701,C12-1022,0,0.0307703,"win, 2013). S´eaghdha (2009) defines wordnet kernel functions for identifying the relational similarity between the components. Works like S´eaghdha and Copestake (2013) use corpus-based approaches where co-occurrence measures between the components are utilised. Nastase et al. (2006) combine both the corpus-based approaches and lexical database based approaches for semantic analysis of compounds. Ziering and van der Plas (2016) presents a corpus-based approach for splitting of German compounds The authors augment the model by incorporating distributional information in Ziering et al. (2016). Botha et al. (2012) builds a language model by using a hierarchical Bayesian model where the models for head word and the other component are conditioned differently. The samarth¯ahnika (Joshi, 1968) gives a detailed account of the discussion involved in the Indian tradition on the semantic compatibility of constituents and the compositionality of the meaning of a compound. Pataskar (1996) has discussed the use of the Dvandva compounds in relation to their case endings and how P¯an.ini dealt with the s¯utras in As..ta¯ dhy¯ay¯ı. Bhandare (1995) has discussed the structural and semantic aspects of Dvandva compoun"
W16-3701,I05-1082,0,0.433932,"an ensemble based approach, specifically designed for handling skewed datasets and we achieve an overall accuracy of 0.77 using random forest classifiers. 1 Introduction Compounding is a productive process of vocabulary expansion in languages where two or more nouns are used together to generate a new lexeme. Compound analysis is computationally challenging primarily due to three factors: i). compounds are highly productive in nature, ii). the relation between the components is implicit and iii). the correct interpretation of a compound is often dependent on contextual or pragmatic features (Kim and Baldwin, 2005). For example, ‘houseboat’ and ‘boathouse’1 are compounds formed from the same pair of nouns, ‘house’ and ‘boat’, but do not mean the same. Similarly, the relation between ‘olive’ and ‘oil’ in ‘olive oil’ does not hold between ‘baby’ and ‘oil’ in ‘baby oil’. Identifying the head of a compound can lead to significant improvements in semantic analysis tasks like Machine Translation, Question Answering etc. (Weller et al., 2014; Tiedemann, 2005). The head of a compound, in general is indicative of the referent(s) of the compound, in addition to determining the syntactic properties of the compound"
W16-3701,P06-2064,0,0.0305344,"the aforementioned cases, the majority of the data samples got correctly classified. 5 Related Work Semantic analysis of compounds has attracted much traction from the computational linguistics community, especially on languages like English, German, Italian, Afrikaans and Dutch (Verhoeven et al., 2014). Lexical databases like Wordnet (Kim and Baldwin, 2005) and Wikipedia (Strube and Ponzetto, 2006) were extensively used to infer semantic relations between the components in a compound. Effectiveness of verb-semantics and word sense disambiguation of the components involved were also studied (Kim and Baldwin, 2006; Kim and Baldwin, 2013). S´eaghdha (2009) defines wordnet kernel functions for identifying the relational similarity between the components. Works like S´eaghdha and Copestake (2013) use corpus-based approaches where co-occurrence measures between the components are utilised. Nastase et al. (2006) combine both the corpus-based approaches and lexical database based approaches for semantic analysis of compounds. Ziering and van der Plas (2016) presents a corpus-based approach for splitting of German compounds The authors augment the model by incorporating distributional information in Ziering e"
W16-3701,N09-2060,0,0.0772252,"Missing"
W16-3701,W14-5703,0,0.0418274,"Missing"
W16-3701,W14-5709,0,0.0504688,"Missing"
W16-3701,Q14-1036,0,0.133488,"ar obtained from the Adaptor Grammar (AG) is a probabilistic context free grammar, where 4 the productions form a set of fixed non-terminals and the probabilities for the productions to be invoked are learnt from the data. In Adaptor Grammar, a skeletal context free grammar is defined as shown in Listing 1a, where the set of non-terminals to be adapted is fixed a priori and will be a subset of the entire set of non-terminals in the skeletal grammar. For each of the adapted non-terminal, marked with a ‘@’, the grammar learns a distribution over trees rooted at each of the adapted non-terminal (Zhai et al., 2014). We learn grammars G1, G2 and G3 with the same skeletal structure in Listing 1a, but with different data samples belonging to Tatpurus.a, Bahuvr¯ıhi and Dvandva respectively. We did not learn a grammar for Avyay¯ıbh¯ava, due to insufficient data samples for learning the patterns. We use a ‘$’ marker to indicate the word boundary between the components and a ‘#’ symbol to mark the beginning and ending of the first and the final components respectively. We also learn a grammar G4, where the entire dataset is taken together along with additional 4000 random pair of words from the DCS corpus, whe"
W16-3701,N16-1078,0,0.0302698,"Missing"
W16-3701,W16-1807,0,0.0271451,"Missing"
W16-3716,I08-6009,0,0.122245,"to a single word and task relatedness is 153 derived from co-occurence statistics in bilingual parallel data, with word alignments available. 2.3 Cross-Language Information Retrieval Hull and Grefenstette (1996), Pirkola (1998), Ballesteros and Croft (1996) perform Cross-Language Information Retrieval through dictionary-based approaches. Littman et al. (1998) performs Latent Semantic Indexing on the term-document matrix. Statistical Machine Translations have also been tried out in (Schamoni et al., 2014; T¨ure et al., 2012b; T¨ure et al., 2012a; Sokolov et al., 2014). (Padariya et al., 2008; Chinnakotla et al., 2008) use transliteration for Out-of-Vocabulary words. In this method the dictionary-based technique is combined with a transliteration scheme in to a pageRank algorithm. We report their work as one of the baselines. Herbert et al. (2011) uses Wikipedia concepts along with Google Translate to translate the queries. By mining the cross-lingual links from the Wikipedia articles, a translation table is built. This is now coupled with translations from Google. Franco-Salvador et. al. (2014) leverages BabelNet, a multilingual semantic network for CLIR. Hosseinzadeh Vahid et al. (2015) uses Google and Bi"
W16-3716,E14-1049,0,0.0335068,"the Continuous Bag-of-Words (CBOW) model that combines the representations of the surrounding words to predict the word in the middle. The second is the Skip-gram model that predicts the context of the target word in the same sentence. GloVe or Global Vectors (Pennington et al., 2014) is another unsupervised learning algorithm for obtaining word vectors. 2.2 Cross-lingual Vector Representations The two major ways to learn word representations in the cross-lingual domain are to either first train the embeddings of the words separately for the languages and then project them to a common space (Faruqui and Dyer, 2014; Mikolov et al., 2013b) or co-learn the embeddings jointly for both monolingual and cross-lingual domains (Gouws et al., 2015; Luong et al., 2015). Faruqui and Dyer (2014) uses Canonical Correlation Analysis (CCA) that maps words from two different languages in to a common, shared space. (Mikolov et al., 2013a) builds a translation matrix using linear regression that transforms the source language word vectors to the target language space. Huang et. al (2015) constructs translation invariant word embeddings by building on (Faruqui and Dyer, 2014). It performs matrix factorization where the ma"
W16-3716,E14-1044,0,0.0347224,"Missing"
W16-3716,N15-1157,0,0.0248957,"gual domains (Gouws et al., 2015; Luong et al., 2015). Faruqui and Dyer (2014) uses Canonical Correlation Analysis (CCA) that maps words from two different languages in to a common, shared space. (Mikolov et al., 2013a) builds a translation matrix using linear regression that transforms the source language word vectors to the target language space. Huang et. al (2015) constructs translation invariant word embeddings by building on (Faruqui and Dyer, 2014). It performs matrix factorization where the matrices include a multilingual co-occurence matrix and other matrices based on the dictionary. Gouws and Søgaard (2015) uses a task-specific dictionary, i.e., a list of word pairs that are equivalent in some respect, depending on the task. Using a non-parallel corpora, given a sentence in one language, for each word in the sentence, equivalent words are substituted in its place. Then the CBOW model of the word2vec tool is employed. Bilingual Bag-of-Words without Alignment (BilBOWA) (Gouws et al., 2015) uses monolingual datasets coupled with sentence aligned parallel data to learn word embeddings. They utilize the SkipGram model of word2vec to learn the monolingual features and a sampled bag-of-words technique"
W16-3716,C12-1089,0,0.0906065,"Missing"
W16-3716,W15-1521,0,0.115085,"the Skip-gram model that predicts the context of the target word in the same sentence. GloVe or Global Vectors (Pennington et al., 2014) is another unsupervised learning algorithm for obtaining word vectors. 2.2 Cross-lingual Vector Representations The two major ways to learn word representations in the cross-lingual domain are to either first train the embeddings of the words separately for the languages and then project them to a common space (Faruqui and Dyer, 2014; Mikolov et al., 2013b) or co-learn the embeddings jointly for both monolingual and cross-lingual domains (Gouws et al., 2015; Luong et al., 2015). Faruqui and Dyer (2014) uses Canonical Correlation Analysis (CCA) that maps words from two different languages in to a common, shared space. (Mikolov et al., 2013a) builds a translation matrix using linear regression that transforms the source language word vectors to the target language space. Huang et. al (2015) constructs translation invariant word embeddings by building on (Faruqui and Dyer, 2014). It performs matrix factorization where the matrices include a multilingual co-occurence matrix and other matrices based on the dictionary. Gouws and Søgaard (2015) uses a task-specific diction"
W16-3716,D14-1162,0,0.0807554,"settings and results have been covered in Section 4. Finally, we conclude in Section 5. 2 2.1 Related Work Word Embeddings Mikolov et. al (2013a) proposed a neural architecture that learns word representations by predicting neighbouring words. There are two main methods by which the distributed word representations can be learnt. One is the Continuous Bag-of-Words (CBOW) model that combines the representations of the surrounding words to predict the word in the middle. The second is the Skip-gram model that predicts the context of the target word in the same sentence. GloVe or Global Vectors (Pennington et al., 2014) is another unsupervised learning algorithm for obtaining word vectors. 2.2 Cross-lingual Vector Representations The two major ways to learn word representations in the cross-lingual domain are to either first train the embeddings of the words separately for the languages and then project them to a common space (Faruqui and Dyer, 2014; Mikolov et al., 2013b) or co-learn the embeddings jointly for both monolingual and cross-lingual domains (Gouws et al., 2015; Luong et al., 2015). Faruqui and Dyer (2014) uses Canonical Correlation Analysis (CCA) that maps words from two different languages in t"
W16-3716,D10-1025,0,0.0318598,"adeh Vahid et al. (2015) uses Google and Bing to translate the queries and shows how the performances vary with translations from two different online systems. Bhattacharya et. al (2016) uses word embeddings for Cross-Language Information Retrieval, learning word vectors from the document set. They also propose methods such that the query can be represented by a vector. We present their work as a baseline. Discriminative projection approaches for documents have also been applied to CLIR using Oriented Principal Component Analysis (OPCA), Coupled Probabilistic Latent Semantic Analysis (CPLSA) (Platt et al., 2010) and learning by Siamese Neural Network (S2Net) (Yih et al., 2011). Vuli´c and Moens (2015) uses word embeddings for CLIR. They collect document-aligned corpora and randomly merge and shuffle the pairs and feed them to the Skip-Gram architecture of word2vec. This way, they obtain cross-lingual word vectors, which they combine to obtain query vectors and document vectors. They perform IR by computing the cosine similarity between the query and the document vectors and ranking the documents according to the similarity. 3 Proposed Framework We follow the query translation based approach towards C"
W16-3716,P14-2080,0,0.0225678,"tions for a pair of languages jointly. They treat it as a multitask learning problem where each task corresponds to a single word and task relatedness is 153 derived from co-occurence statistics in bilingual parallel data, with word alignments available. 2.3 Cross-Language Information Retrieval Hull and Grefenstette (1996), Pirkola (1998), Ballesteros and Croft (1996) perform Cross-Language Information Retrieval through dictionary-based approaches. Littman et al. (1998) performs Latent Semantic Indexing on the term-document matrix. Statistical Machine Translations have also been tried out in (Schamoni et al., 2014; T¨ure et al., 2012b; T¨ure et al., 2012a; Sokolov et al., 2014). (Padariya et al., 2008; Chinnakotla et al., 2008) use transliteration for Out-of-Vocabulary words. In this method the dictionary-based technique is combined with a transliteration scheme in to a pageRank algorithm. We report their work as one of the baselines. Herbert et al. (2011) uses Wikipedia concepts along with Google Translate to translate the queries. By mining the cross-lingual links from the Wikipedia articles, a translation table is built. This is now coupled with translations from Google. Franco-Salvador et. al. (201"
W16-3716,C12-1164,0,0.0651573,"Missing"
W16-3716,W11-0329,0,0.0176767,"es and shows how the performances vary with translations from two different online systems. Bhattacharya et. al (2016) uses word embeddings for Cross-Language Information Retrieval, learning word vectors from the document set. They also propose methods such that the query can be represented by a vector. We present their work as a baseline. Discriminative projection approaches for documents have also been applied to CLIR using Oriented Principal Component Analysis (OPCA), Coupled Probabilistic Latent Semantic Analysis (CPLSA) (Platt et al., 2010) and learning by Siamese Neural Network (S2Net) (Yih et al., 2011). Vuli´c and Moens (2015) uses word embeddings for CLIR. They collect document-aligned corpora and randomly merge and shuffle the pairs and feed them to the Skip-Gram architecture of word2vec. This way, they obtain cross-lingual word vectors, which they combine to obtain query vectors and document vectors. They perform IR by computing the cosine similarity between the query and the document vectors and ranking the documents according to the similarity. 3 Proposed Framework We follow the query translation based approach towards Cross-Language Information Retrieval from Hindi to English and Beng"
W16-4305,de-marneffe-etal-2006-generating,0,0.0143377,"Missing"
W16-4305,W06-0301,0,0.0563953,"cover multiple such categories. Some examples of these categories are provided below: 1) Report : e.g., Christie’s staffs have denied Zimmer’s allegation. 2) Judgment : e.g., McGreevey’s lover was being paid 11000 Dollar even though he was wildly unqualified for the position. 3) Advise : e.g., Let’s shoot at the opposition not our own troops, one Insider pleaded. 4) Sentimental : e.g., So why do so many people enjoy ridiculing my New Jersey One word Jealousy? Opinion analysis has been a major field of study in natural language processing and data mining for many years. Several works such as (Kim and Hovy, 2006; Qadir, 2009; Scholz and Conrad, 2013; Yu and Hatzivassiloglou, 2003) focus on opinion mining. Opinion mining is very similar to subjectivity classification where subjective nature indicates the tendency of expressing one’s thoughts and opinions. Work has been done in the past for developing classifiers (Wiebe and Riloff, 2005) which separate subjective sentences from objective ones, using several features present in the sentences. (Soni et al., 2014) describes how to predict certainty (factuality) of text (e.g., tweet) by using keywords collected from source introducing predicates (cues) and"
W16-4305,W09-4306,0,0.162131,"categories. Some examples of these categories are provided below: 1) Report : e.g., Christie’s staffs have denied Zimmer’s allegation. 2) Judgment : e.g., McGreevey’s lover was being paid 11000 Dollar even though he was wildly unqualified for the position. 3) Advise : e.g., Let’s shoot at the opposition not our own troops, one Insider pleaded. 4) Sentimental : e.g., So why do so many people enjoy ridiculing my New Jersey One word Jealousy? Opinion analysis has been a major field of study in natural language processing and data mining for many years. Several works such as (Kim and Hovy, 2006; Qadir, 2009; Scholz and Conrad, 2013; Yu and Hatzivassiloglou, 2003) focus on opinion mining. Opinion mining is very similar to subjectivity classification where subjective nature indicates the tendency of expressing one’s thoughts and opinions. Work has been done in the past for developing classifiers (Wiebe and Riloff, 2005) which separate subjective sentences from objective ones, using several features present in the sentences. (Soni et al., 2014) describes how to predict certainty (factuality) of text (e.g., tweet) by using keywords collected from source introducing predicates (cues) and groups (Saur"
W16-4305,W14-3704,1,0.909398,"o This work is licenced under a Creative Commons Attribution 4.0 International Licence. //creativecommons.org/licenses/by/4.0/ Licence details: http: 40 Proceedings of the Workshop on Computational Modeling of People’s Opinions, Personality, and Emotions in Social Media, pages 40–49, Osaka, Japan, December 12 2016. build this graph. While some of the approaches use PageRank to model each node in a similar manner (Erkan and Radev, 2004), HITS framework has also been used that establishes a relationship between opinions and supporting facts by modeling opinions as hubs and facts as authorities (Rajkumar et al., 2014). None of these works, however, focus on finding diverse opinions from an article. Experiments on MPQA and Yahoo datasets (both are English datasets) show that this leads to a sub-optimal performance, while trying to extract the most opinionated sentences in a news article. The graphical models end up choosing similar sentences - which is not ideal to enable wide-ranging user engagement. We, therefore, attempt to modify a variant of graphical model proposed in (Rajkumar et al., 2014) to introduce diversity. The basic idea of our approach is that once a node (sentence) is selected as an opinion"
W16-4305,saggion-funk-2010-interpreting,0,0.0292202,"(Carbonell and Goldstein, 1998; Munson et al., 2009; Zhu et al., 2007; Mei et al., 2010) in that we introduce diversity in a model with two different kinds of nodes in the document graph, as opposed to the other algorithms, which treat all the sentences equally. Further, to understand the distribution of extracted opinions from online news in various categories, e.g., Report, Judgment, Advise and Sentiment etc. (Asher et al., 2009), we develop an opinion classification model. While classification of opinions into various sentiment levels such as positive, negative and neutral has been tried (Saggionα and Funk, 2010; Yu et al., 2008), automated classification of opinions into various categories is not available. Analysis using the opinion classification model shows that our algorithm (OP-D) actually adds diversity even at the category level by selecting opinions from different opinion categories. 2 Extracting Diverse Opinions: OP-D The proposed algorithm for extracting diverse opinions from news articles comprises of three steps: (i) Extracting features and assigning a score to indicate opinionatedness of a sentence. (ii) Building up the fact-opinion graph, applying HITS algorithm and identifying highly"
W16-4305,D13-1188,0,0.0238143,"Some examples of these categories are provided below: 1) Report : e.g., Christie’s staffs have denied Zimmer’s allegation. 2) Judgment : e.g., McGreevey’s lover was being paid 11000 Dollar even though he was wildly unqualified for the position. 3) Advise : e.g., Let’s shoot at the opposition not our own troops, one Insider pleaded. 4) Sentimental : e.g., So why do so many people enjoy ridiculing my New Jersey One word Jealousy? Opinion analysis has been a major field of study in natural language processing and data mining for many years. Several works such as (Kim and Hovy, 2006; Qadir, 2009; Scholz and Conrad, 2013; Yu and Hatzivassiloglou, 2003) focus on opinion mining. Opinion mining is very similar to subjectivity classification where subjective nature indicates the tendency of expressing one’s thoughts and opinions. Work has been done in the past for developing classifiers (Wiebe and Riloff, 2005) which separate subjective sentences from objective ones, using several features present in the sentences. (Soni et al., 2014) describes how to predict certainty (factuality) of text (e.g., tweet) by using keywords collected from source introducing predicates (cues) and groups (Saur´ı, 2008). These models f"
W16-4305,P14-2068,0,0.12377,"ealousy? Opinion analysis has been a major field of study in natural language processing and data mining for many years. Several works such as (Kim and Hovy, 2006; Qadir, 2009; Scholz and Conrad, 2013; Yu and Hatzivassiloglou, 2003) focus on opinion mining. Opinion mining is very similar to subjectivity classification where subjective nature indicates the tendency of expressing one’s thoughts and opinions. Work has been done in the past for developing classifiers (Wiebe and Riloff, 2005) which separate subjective sentences from objective ones, using several features present in the sentences. (Soni et al., 2014) describes how to predict certainty (factuality) of text (e.g., tweet) by using keywords collected from source introducing predicates (cues) and groups (Saur´ı, 2008). These models focus only on the local context (takes no global context into account) from a sentence to measure its subjectivity. Side by side, there have been works where graphical models have been proposed to capture the global context, where the sentences are treated as nodes in the graph and a similarity measure between sentences is defined to This work is licenced under a Creative Commons Attribution 4.0 International Licenc"
W16-4305,P99-1032,0,0.12005,"Missing"
W16-4305,W03-1017,0,0.0849997,"tegories are provided below: 1) Report : e.g., Christie’s staffs have denied Zimmer’s allegation. 2) Judgment : e.g., McGreevey’s lover was being paid 11000 Dollar even though he was wildly unqualified for the position. 3) Advise : e.g., Let’s shoot at the opposition not our own troops, one Insider pleaded. 4) Sentimental : e.g., So why do so many people enjoy ridiculing my New Jersey One word Jealousy? Opinion analysis has been a major field of study in natural language processing and data mining for many years. Several works such as (Kim and Hovy, 2006; Qadir, 2009; Scholz and Conrad, 2013; Yu and Hatzivassiloglou, 2003) focus on opinion mining. Opinion mining is very similar to subjectivity classification where subjective nature indicates the tendency of expressing one’s thoughts and opinions. Work has been done in the past for developing classifiers (Wiebe and Riloff, 2005) which separate subjective sentences from objective ones, using several features present in the sentences. (Soni et al., 2014) describes how to predict certainty (factuality) of text (e.g., tweet) by using keywords collected from source introducing predicates (cues) and groups (Saur´ı, 2008). These models focus only on the local context ("
W16-4305,N07-1013,0,0.115149,"Missing"
W16-4903,P12-2041,0,0.0146148,", is a baseline which randomly chooses any tree structure over the given set of nodes. It can be shown that the expected value of the SimScore(Ti , T ) for a given tree T is equal to 1/n where n is the number of nodes in T . For the second baseline, EDITS, we use the state-of-theart RTE software package EDITS (Kouylekov and Negri, 2010), instead of the classifiers we proposed, for scoring the edges. However, the metric for scoring structures remains the same as the sum of edge scores. In this case, the entailment relation corresponds to Support relation. EDITS has also been used previously by Cabrio and Villata (2012) in the context of argumentation mining. Nodes Arguments 2 3 4 5 6 7 8 9 10 Any 10 187 85 62 72 58 41 19 23 557 type-1 SVM 0.9 0.564 0.529 0.446 0.363 0.369 0.230 0.351 0.217 0.459 SimScore type-2 SVM type-2 MLP 0.8 0.8 0.566 0.625 0.552 0.482 0.399 0.435 0.341 0.322 0.323 0.309 0.19 0.199 0.28 0.222 0.188 0.115 0.442 0.447 EDITS 0.7 0.363 0.250 0.231 0.263 0.231 0.205 0.265 0.212 0.289 Random 0.5 0.333 0.250 0.2 0.166 0.142 0.125 0.111 0.1 0.234 Table 2: Structure Prediction Performance: Mean of SimScore for the arguments grouped by the number of nodes in the argument. EDITS and Random are ba"
W16-4903,D15-1267,0,0.0274903,"(2009) discusses the features used for the NLI task in detail. However, some of the frequently used features like POS n-grams, the length of propositions, POS of the main verb, etc., are not included in the set of features because they showed insignificant effect on the overall performance in our experiments. We suspect this is due to the fact that many attributes of these features are already captured in the features we have chosen. Discourse Markers: These are the words that are indicative of argumentative discourse. Discourse markers have persistently been used for both RTE and NLI tasks. Eckle-Kohler et al. (2015) have also discussed the role of discourse markers in the context of argumentation mining. However, we observed that the presence of such words are rare in the AraucariaDB dataset. We have used i). counts of the following words in Text: as, or, and, roughly, then, since, and ii). counts of the following words in Hypothesis: therefore, however, though, but, quite. This feature set gives rise to 11 (6+5) features. Modal Features: These are similar to discourse markers but they do not inherently belong to either one of Text or Hypothesis. Therefore, we take the counts of these as features for bot"
W16-4903,P10-4008,0,0.0148115,"s like the graph edit distance (Sanfeliu and Fu, 1983). Since our problem formulation is new, it is difficult to compare the results with existing literature for Structure Prediction in argumentation mining. However, we compare our performance to two baselines. The first baseline, Random, is a baseline which randomly chooses any tree structure over the given set of nodes. It can be shown that the expected value of the SimScore(Ti , T ) for a given tree T is equal to 1/n where n is the number of nodes in T . For the second baseline, EDITS, we use the state-of-theart RTE software package EDITS (Kouylekov and Negri, 2010), instead of the classifiers we proposed, for scoring the edges. However, the metric for scoring structures remains the same as the sum of edge scores. In this case, the entailment relation corresponds to Support relation. EDITS has also been used previously by Cabrio and Villata (2012) in the context of argumentation mining. Nodes Arguments 2 3 4 5 6 7 8 9 10 Any 10 187 85 62 72 58 41 19 23 557 type-1 SVM 0.9 0.564 0.529 0.446 0.363 0.369 0.230 0.351 0.217 0.459 SimScore type-2 SVM type-2 MLP 0.8 0.8 0.566 0.625 0.552 0.482 0.399 0.435 0.341 0.322 0.323 0.309 0.19 0.199 0.28 0.222 0.188 0.115"
W16-4903,W14-2111,0,0.063033,"Missing"
W16-4903,D15-1110,0,0.0418996,"Missing"
W16-4903,N16-1164,0,0.0393302,"Missing"
W17-2214,C12-1062,1,0.919444,"each sentence in the dataset we include the input character sequence, ground truth segmentation, and additionally lexical and morphological information about all the phonetically possible segments for the given sentence. In this work, we also discuss the linguistic considerations made while generating the candidate space of the possible segments. 1 Introduction Sanskrit was the prevalent medium of knowledge transfer in the demographic of Indian Subcontinent for over four millennia. The culture bearing language of India has about 30 million extant manuscripts that are potent for digitisation (Goyal et al., 2012). The last decade witnessed tremendous excitement in digitisation attempts of ancient manuscripts in Sanskrit. The Digital Corpus of Sanskrit1 , The Sanskrit Library2 and GRETIL3 are some such laudable efforts. These attempts aim to preserve the cultural heritage of the subcontinent embedded in the works written in Sanskrit. The writings in Sanskrit follow a ‘scriptio continua’ (Hellwig, 2016), thereby making Word Segmentation in Sanskrit a challenging task. Lack of visible markers in written scripts is a prevalent feature observed in numerous Asian languages. Additionally, the sentence constr"
W17-2214,J94-3001,0,0.23391,"vicitram, it shows that the lemma for the word is ‘vicitra’, and the given word-form can belong to three possible morphological classes, namely accusative case singular with masculine or neuter, or it can be nominative case singular neuter class. Similar to the case of Sandhi, while the generation of word form for a given morphological class is deterministic, the analysis of given word form is not deterministic and can lead to ambiguities. 3 A lexical juncture system on a finite alphabet Σ is composed of a finite set of words L ⊆ Σ∗ and a finite set R of rewrite rules of the form u|v → f /x (Kaplan and Kay, 1994) , with x, v, f ∈ Σ∗ and u ∈ Σ+ . In this formalization, Σ is the set of phonemes, R is the set of sandhi rules, and L is the vocabulary as a set of lexical items. We define, zi ∈ L as a 3-tuple (l, m, w), where l denotes the lemma of the word, m denotes the morphological class of the word and w denotes the inflected word form for the lemma l with morphological class m. Given a sentence s, a sandhi analysis for s, Si can be seen as a sequence hz1 , σ1 , k1 i; ...hzp , σp , kp i. Here, hzj , σj , kj i is a segment with zj ∈ L, kj ∈ N denotes the posiSanskrit Word Segmentation Task Given an inpu"
W17-2214,W16-3701,1,0.879949,"Missing"
W17-2214,P06-1085,0,0.118483,"ined as identification of the semantically most valid split of the input sentence. There have been commendable efforts to tackle the word segmentation task in Sanskrit. Mittal (2010) designed Finite State Transducers (FST) incorporating the rules of sandhi obtained from documented grammatical tradition. With the defined FSTs, Mittal (2010) generates all possible splits followed by a probabilistic scoring procedure to select the ideal split. Natarajan and Charniak (2011) proposed ‘S3 - Statistical Sandhi Splitter’, a Bayesian word segmentation approach for Sanskrit. The work is an extension of Goldwater et al. (2006) and was adapted to handle sandhi formations. Hellwig (2015) proposed a neural model that jointly solves the problem of 1 http://kjc-sv013.kjc.uni-heidelberg. de/dcs/ 2 http://sanskritlibrary.org/ 3 http://gretil.sub.uni-goettingen.de/ gretil.htm 105 Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature. c Proceedings, pages 105–114, Vancouver, BC, August 4, 2017. 2017 Association for Computational Linguistics Figure 1: Example instances of sandhi formation in Sanskrit. a) Phonetic transformation of ‘u’ and ‘¯a’ to ‘v¯a’ in the joi"
W17-2214,I11-1034,0,0.0184988,"of the aforementioned properties makes the segmentation in Sanskrit a complex task. Given an input Sanskrit sentence, the word segmentation task can be defined as identification of the semantically most valid split of the input sentence. There have been commendable efforts to tackle the word segmentation task in Sanskrit. Mittal (2010) designed Finite State Transducers (FST) incorporating the rules of sandhi obtained from documented grammatical tradition. With the defined FSTs, Mittal (2010) generates all possible splits followed by a probabilistic scoring procedure to select the ideal split. Natarajan and Charniak (2011) proposed ‘S3 - Statistical Sandhi Splitter’, a Bayesian word segmentation approach for Sanskrit. The work is an extension of Goldwater et al. (2006) and was adapted to handle sandhi formations. Hellwig (2015) proposed a neural model that jointly solves the problem of 1 http://kjc-sv013.kjc.uni-heidelberg. de/dcs/ 2 http://sanskritlibrary.org/ 3 http://gretil.sub.uni-goettingen.de/ gretil.htm 105 Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature. c Proceedings, pages 105–114, Vancouver, BC, August 4, 2017. 2017 Association for"
W17-2214,P10-3015,0,0.3399,"degree of inflection (Scharf and Hyman, 2011), phonemes at the word boundary undergo phonetic transformations called as ‘sandhi’ (Goyal and Huet, 2016), and the sentence constructs in Sanskrit follow a loose word order (Hellwig, 2016; Kulkarni et al., 2015). The combination of the aforementioned properties makes the segmentation in Sanskrit a complex task. Given an input Sanskrit sentence, the word segmentation task can be defined as identification of the semantically most valid split of the input sentence. There have been commendable efforts to tackle the word segmentation task in Sanskrit. Mittal (2010) designed Finite State Transducers (FST) incorporating the rules of sandhi obtained from documented grammatical tradition. With the defined FSTs, Mittal (2010) generates all possible splits followed by a probabilistic scoring procedure to select the ideal split. Natarajan and Charniak (2011) proposed ‘S3 - Statistical Sandhi Splitter’, a Bayesian word segmentation approach for Sanskrit. The work is an extension of Goldwater et al. (2006) and was adapted to handle sandhi formations. Hellwig (2015) proposed a neural model that jointly solves the problem of 1 http://kjc-sv013.kjc.uni-heidelberg."
W17-2214,C16-1028,0,\N,Missing
W17-2402,E03-1020,0,0.14547,"ve sense cluster for a word in the time period 1987-1995, (iii) Mitra et al. (2014) is able to identify sense differences more accurately in comparison to the other methods, (iv) considering both the aspects together, McCarthy et al. (2004) performs the best, (v) for The code and evaluation results are available at: http: //tinyurl.com/h4onyww 12 senses in a newspaper corpus containing articles between 1785 and 1985. Phani et al. (2012) study 11 years worth Bengali newswire that allows them to extract trajectories of salient words that are of importance in contemporary West Bengal. Few works (Dorow and Widdows, 2003; McCarthy et al., 2004) have focused on corpus-specific sense identification. Our work differs from these works in that we capture the cross corpus-specific sense differences by comparing the senses of a particular word obtained across two different corpora. We adapt three state-of-the-art novel and predominant sense discovery algorithms and extensively compare their performances for this task. the common results produced by Lau et al. (2014) and Mitra et al. (2014), the former does better sense differentiation while the latter does better overall. 2 Related Work Automatic discovery and disam"
W17-2402,W06-3812,0,0.356167,"Missing"
W17-2402,P04-1036,0,0.17114,"Missing"
W17-2402,J98-1004,0,0.398734,"Missing"
W17-2402,E12-1060,0,0.255888,"Missing"
W17-2402,P14-1025,0,0.0395926,"Missing"
W17-2402,cook-stevenson-2010-automatically,0,0.0255949,"ances for this task. the common results produced by Lau et al. (2014) and Mitra et al. (2014), the former does better sense differentiation while the latter does better overall. 2 Related Work Automatic discovery and disambiguation of word senses from a given text is an important and challenging problem, which has been extensively studied in the literature (Jones, 1986; Ide and Veronis, 1998; Sch¨utze, 1998; Navigli, 2009; Kilgarriff and Tugwell, 2001; Kilgarriff, 2004). Only recently, with the availability of enormous amounts of data, researchers are exploring temporal scopes of word senses. Cook and Stevenson (2010) use corpora from different time periods to study the change in the semantic orientation of words. Gulordava and Baroni (2011) use two different time periods in the Google n-grams corpus and detect semantic change based on distributional similarity between word vectors. Kulkarni et al. (2015) propose a computation model for tracking and detecting statistically significant linguistic shifts in the meaning and usage of words. Jatowt and Duh (2014) propose a framework for exploring semantic change of words over time on Google n-grams and COHA dataset. Lau et al. (2014) propose a fully unsupervise"
W17-2402,W16-1620,0,0.196415,"Missing"
W17-2402,E09-1013,0,0.0713465,"Missing"
W17-2402,P14-1096,1,0.939321,"identify corpora specific senses. Key observations: For manual evaluation of the candidate corpus-specific senses, we focused on two aspects – a) sense representation, which tells if the word cluster obtained from a method is a good representative of the target word, and b) sense difference, which tells whether the sense represented by the corpus-specific cluster is different from all the senses of the word in the other corpus. Some of our important findings from this study are: (i) the number of candidate senses produced by McCarthy et al. (2004) is far less than the two other methods, (ii) Mitra et al. (2014) produces the best representative sense cluster for a word in the time period 2006-2008 and McCarthy et al. (2004) produces the best representative sense cluster for a word in the time period 1987-1995, (iii) Mitra et al. (2014) is able to identify sense differences more accurately in comparison to the other methods, (iv) considering both the aspects together, McCarthy et al. (2004) performs the best, (v) for The code and evaluation results are available at: http: //tinyurl.com/h4onyww 12 senses in a newspaper corpus containing articles between 1785 and 1985. Phani et al. (2012) study 11 years"
W17-2402,W11-1102,0,0.0448493,"Missing"
W17-2402,S13-1035,0,0.0259661,"recent version of the corpora) and the ‘reference corpora’ (older version of the corpora). Tahmasebi et al. (2011), propose a framework for tracking 3 Dataset Description To study corpora-specific senses, we consider books and newspaper articles as two different corpora sources. We compare these corpora for the same time-periods to ensure that the sense differences are obtained only because of the change in corpus and not due to the difference in time. A brief description of these datasets is given below. Books dataset: The books dataset is based on the Google Books Syntactic n-grams corpus (Goldberg and Orwant, 2013), consisting of timestamped texts from over 3.4 million digitized English books, published between 1520 and 2008. For our study, we consider Google books data for the two time periods 1987−1995 and 2006−2008. Newspaper dataset: For the Newspaper dataset, we consider two different data sources. The first dataset from 1987 − 1995 contains articles of various newspapers2 . The other dataset from 2006 − 2008 is gathered from the archives of The New York Times. 4 Proposed framework To identify corpus-specific word senses, we aim at adapting some of the existing algorithms, which have been utilized"
W17-2409,D16-1047,0,0.0144201,"82 micro averaged over the 66 predictions. 5 Related Work Computational analysis of derivational word forms is gaining some traction in the NLP community. Lazaridou et al. (2013) used CDSM (Mitchell and Lapata, 2010) for derivational nouns, originally designed to learn representation for phrases. Cotterell and Sch¨utze (2017), extended the concept of CDSM for derivational word forms with neural models. The authors put forward the idea of jointly handling the segmentation of words into morphemes and semantic synthesis of the word forms to improve the performance of a system for both the tasks. Bhatia et al. (2016), does not make a distinction of inflected word-forms or derivational affixes, but their work can be employed to learn embeddings for a word-form from its morphemes. Soricut and Och (2015) introduced an unsupervised method of inducing affixal transformations between words using word embeddings. Faruqui et al. (2016) further propose a semi supervised graph based approach for morpho-syntactic lexicon induction. The authors show the effectiveness of their model for inflectional morphology over multiple languages. In Sanskrit, Krishna and Goyal (2015) automated the derivation of Taddhita, where th"
W17-2409,P13-1149,0,0.176126,"the meaning for the word nauratian as “a person residing in nauratia”, in spite of never hearing the derived word previously. Similarly, It is desirable to identify a derived word and link it to its corresponding source word computationally. It is of great practical value if we can obtain a semantic word representation for a derived word from the semantic word representation of its source word. It is often the case that corpus evidence for the source word might be abundant, but the corpus evidence for all the possible derived words need not be available readily (Cotterell and Sch¨utze, 2017). Lazaridou et al. (2013) proposed multiple approaches, all being modifications of Compositional Distributional Semantic Model (CDSM) (Mitchell and Lapata, 2010), for obtaining the semantic word representations for a derived word by combining the representations for source word representation and the representation of the affix . Identifying derived words from a corpus is challenging. Usage of pattern matching approaches in strings are often inept for the task. Tasks that rely on string matching approaches alone, often result in a large number of false positives. For example, while the word ‘postal’ is generated from"
W17-2409,Q16-1001,0,0.307075,"eans of vocabulary expansion used in natural languages. Derivational affixes are non meaning preserving affixes, that when applied to a word induce a new word. The affixes signify one or possibly more than one semantic senses that is passed onto the new derived word (Marchand, 1969). For example, the noun ‘driver’ is derived from the verb ‘drive’ and the adverb ‘boldly’ is derived from ‘bold’, where the derivational affixes ‘-er’ and ‘ly’ are used. However, affixes that modify only the morphological or syntactic role of a word in its usage are not considered derivational, but as inflectional (Faruqui et al., 2016). Whenever a new word comes into existence in a language, all of its derived forms are potent to be part of the language’s vocabulary as well. But, 66 Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing, ACL 2017, pages 66–75, c Vancouver, Canada, August 3, 2017. 2017 Association for Computational Linguistics tern we can narrow down the possible affixes for a pair to a maximum of 4 candidates from a set of 137 possible affixes. cently proposed an approach for analysis and induction of morphology in words using word embeddings. But, the authors find"
W17-2409,C12-1062,1,0.82022,"3 directly, but find the cosine similarity between the embeddings of the words and perform a weighted sum with the similarity score obtained from the similarity obtained from the combined feature vector. Experiments We explain the experimental settings and evaluation parameters for our model in this section. 4.1 Dataset We use multiple lexicons and corpora to obtain our vocabulary C. We use IndoWordNet (Kulkarni et al., 2010), the Digital Corpus of Sanskrit2 , a digitised version of the Monier Williams3 Sanskrit-English dictionary, a digitised version of the Apte Sanskrit-Sanskrit Dictionary (Goyal et al., 2012) and we also utiilise the lexicon employed in the Sanskrit Heritage Engine (Goyal and Huet, 2016). We obtained close to 170,000 unique word lemmas from the combined resources. 2 3 2. M ADB1i - We report the performance of the system M ADB1i = {M ADi1 (Gi1 , Si )}, where we define the network structure only based on the Phase 1 in Section 3 3. M ADB2i - We report the performance of the system M ADB2i = {M ADi1 (Gi1 , Si )| M ADi2 (Gi2 , Vi1 )}, where we define the settings for M ADi1 , M ADi2 based on the dehttp://kjc-sv013.kjc.uni-heidelberg.de/dcs/ http://www.sanskrit-lexicon.uni-koeln.de/mon"
W17-2409,N15-1186,0,0.0716566,"ge of pattern matching approaches in strings are often inept for the task. Tasks that rely on string matching approaches alone, often result in a large number of false positives. For example, while the word ‘postal’ is generated from ‘post’, the word ‘canal’ is not generated from ‘can’. String matching approaches often result in low recall as well, due to the variations in patterns in the derived and source word pairs, even for the same affix. Both ‘postal’ and ‘minimal’ are derived using the affix ‘al’, but the source word for postal is ‘post’, while the source word for minimal is ‘minimum’. Soricut and Och (2015), reDerivational nouns are widely used in Sanskrit corpora and is a prevalent means of productivity in the language. Currently there exists no analyser that identifies the derivational nouns. We propose a semi supervised approach for identification of derivational nouns in Sanskrit. We not only identify the derivational words, but also link them to their corresponding source words. The novelty of our work is primarily in its design of the network structure for the task. The edge weights are featurised based on the phonetic, morphological, syntactic and the semantic similarity shared between th"
W17-2409,Q14-1036,0,0.016393,"epresented as the node vk ∈ Vi and ak1 is part of the tuple tk . A source word might satisfy multiple rules and only one of the rules will emerge as the final rule that gets 70 Rule No 4.1.95 4.1.112 4.1.128 4.2.16 Rule ata i˜n s´iv¯adibhyo’n. catak¯aya airak sam . skr.tam . bhaks.a¯ h. Semantic Relation Patronym Patronym Patronym Processed Source Word da´saratha s´iva catak¯a kala´sa Derived Word d¯as´arathi s´aiva c¯atakaira k¯ala´sa¯ h. Table 3: conditional rules related to selection of suitable affix for derivational nouns from As..ta¯ dhy¯ay¯ı. rooted at each of the adapted non-terminal (Zhai et al., 2014; Krishna et al., 2016). In Listing 1, ‘Word’ and ‘Stem’ are non-terminals, which are adapted. The non-terminal ‘Suffix‘ consists of the set of various end-patterns. In this formalism, the grammar can only capture sequential aspects in the words and hence attributes like vr.ddhi that happen at the internal of the word, non-sequental to rest of the modified pattern, need not be effectively captured in the system. applied (Scharf, 2009). Rules that carry different affixes might find the eligibility for a given pair. For example, consider the rules ‘A.4.1.95’ ´ and ‘A.4.1.112’. For the word ‘Siva"
W17-2409,W16-3701,1,0.897333,"Missing"
W19-1912,Q17-1010,0,0.0755225,", it has been observed that the same disease name may occur in multiple variant forms such as. synonyms replacement (e.g.“lung cancer”, “lung carcinoma”), spelling variation (“Acetolysis”, “acetolisis”), a short description modifier precedes the disease name (e.g. “massive heart attack”), different word orderings (eg. “alpha-galactosidase deficiency”, “deficiency of alpha-galactosidase”). In this paper, we have formulated the task of learning mention-candidate pair similarity using Triplet Networks (Hoffer and Ailon, 2015). Furthermore, we have explored in-domain word1 and subword embeddings (Bojanowski et al., 2017) as input representations. We find that sub-word information boosts up the performance due to gained information for out-of-vocabulary terms and word compositionality of the disease mentions. The primary contributions of this paper are three-fold: 1) By identifying positive and negative candidates concerning a disease mention, we optimize the Triplet Network with a loss function that influences the relative distance constraint 2) We have explored the capability of inIntroduction A disease is an abnormal medical condition that poses a negative impact on the organisms and enabling access to dise"
W19-1912,D16-1245,0,0.0313364,"e mention. 2) Candidate ranking: (See section 3.2) Rank those potential candidates corresponding to a disease mention. 3.1 Mention: “bacteremic infections due to Neisseria” Candidate Set 1, {C1 } = {“bacterial neisseria infections”} Candidate Set 2, {C2 } = {“bacterial neisseria infections” , “DNA-virus infections” , “ScrewWorm Infections” } 3.2 Assume that there are n candidates represented by {c1 , c2 , . . . , cn } for an entity mention m, we use a Triplet Network which has proven to perform well in many Computer Vision (Hoffer and Ailon, 2015) as well as Natural Language Processing tasks (Clark and Manning, 2016) . As such given a triplet, the idea is to leverage the notion of reducing the distance between the mention and its positive candidate while increasing the distance between the mention and its negative candidate. Candidate generation In this section, we discuss the algorithm which generates the potential candidates to which the disease mentions might be referring. In this study, the Knowledge Base entries were sampled from 2 Candidate Ranking https://github.com/ncbi-nlp/BioSentVec.git 96 Figure 1: Pictorial Representation of the training Data Generation Process 3.2.1 Triplet data generation In"
W19-1912,P15-2049,0,0.249183,"Missing"
W19-1912,W18-2307,0,0.0123166,"d + abb the dissimilarities should be. Thereafter, by using this loss function, we calculate the gradients and update the parameters of the network based on these gradient values. For training the network, we take mention m and randomly sample qp and qni and compute their loss function and update their gradients. We use 200-dimensional word2vec (Mikolov et al., 2013) embeddings trained on Wikipedia and Pubmed PMC-Corpus (Pyysalo et al., 2013) as input to Conv. To deal with the huge number of out-of- vocabulary terms in the medical domain, we have used the f astT ext based sub-word embeddings (Galea et al., 2018). f astT ext (Bojanowski et al., 2017) has been applied on PubMed and MIMIC-III (Johnson et al., 2016) to generate 200- dimensional word embeddings, the window size being 20, learning rate 0.05, sampling threshold 1e-4, and negative examples 10 (yijia zhang et al., 2018). 3.2.3 Table 2: The table shows the accuracy of our system in comparison with the baseline systems. We choose the evaluation measure as accuracy. Since, the highest similar candidate is of primary interest in the task of entity linking, so we choose the top-K ( Where K = 1). T P = It signifies that the highest ranked candidate"
W19-7503,D17-1209,0,0.0459781,"Missing"
W19-7503,Q17-1010,0,0.0275554,"Sanskrit character recognition system (Dineshkumar and Suganthi, 2015). Krishna et al. (2018c) proposed energy-based framework for jointly solving the word segmentation and morphological tagging tasks in Sanskrit. The pretrained word embeddings proposed by Mikolov (2013) and Pennington (2014) had a great impact in the field of Natural Language Processing (NLP). However, these token based embeddings were unable to generate embeddings for out-of-vocabulary (OOV) words. To overcome this shortcoming, subword level information was integrated into recent approaches, where character-n-gram features (Bojanowski et al., 2017) have shown good performance over the compositional function of individual characters (Wieting et al., 2015). Another interesting approach (Zhang et al., 2015) is the use of character level input for word-level predictions. 6 Conclusion For resource-rich languages, deep learning based models have helped in improving the state of the art for most of the NLP tasks, and have now replaced the need for feature engineering with the choice of a good model architecture. In this work, we systematically investigated the following research question: Can the recent advances in neural network outperform tr"
W19-7503,D14-1162,0,0.0820934,"ding (BPE) (Sennrich et al., 2016) from corpus data). 3) Character level: s v a m ¯ a n a s a m. We learned word embeddings of these components of the compound from our Sanskrit corpus (Section 4.1). Word embeddings map a word x from a vocabulary V to a real-valued vector x of dimensionality D in a feature space (Schnabel et al., 2015). The idea based on distributional hypothesis (Harris, 1954), and the learning objective attempts to put similar words closer in the vector space.We used FastText for learning word-level embedding, BPE along with Word2Vec (w2v) (Mikolov et al., 2013) and Glove (Pennington et al., 2014) for learning subword level embedding, and character level embedding learned using CharCNN (Zhang et al., 2015). Note that we learned embeddings for the individual components, and finally concatenated vectors corresponding to each component and fed as input to the classifier. We also integrated our system with task-specific end-to-end training for text classification (Kim, 2014). This approach facilitates pre-trained initialized vector to be updated during the task-specific training process. Performance of the classifier, with and without end-to-end training, is reported in Appendix I. In all"
W19-7503,W16-6336,0,0.0258734,"proposed a similar statistical approach which combined lexical and distributional information by using information from the lexical network Amarakos.a (Nair and Kulkarni, 2010) and variable length n-grams learned from data using Adaptor grammar (Johnson et al., 2007). Here, the authors also adopted rules from As..t¯ adhy¯ ay¯ı as potentially discriminative features for compound type identification (Kulkarni and Kumar, 2013). While this model has shown to be eﬀective for the task, it nevertheless is a linguistically involved model. Recently, Dima and Hinrichs (2015), Cordeiro et al. (2016) and Ponkiya et al. (2016) have shown that use of word embedding as the sole features can produce models with competitive results as compared to other feature-rich models. Inspired from these observations, we attempt to build similar models which use only embeddings as features for the compound type identification task. Compounds in Sanskrit can be categorized into 30 possible classes based on how granular categorizations one would like to have (Lowe, 2015). There are slightly altered set of categorizations considered by Gillon (2009), Olsen (2000), Bisetto and Scalise (2005) and Tubb and Boose (2007). Semantically As."
W19-7503,L18-1264,1,0.878742,"Missing"
W19-7503,S10-1057,0,0.103425,"Missing"
W19-7503,W14-5703,0,0.0685449,"Missing"
