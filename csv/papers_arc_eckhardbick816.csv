2020.lrec-1.630,Syntax and Semantics in a Treebank for {E}speranto,2020,-1,-1,1,1,17909,eckhard bick,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this paper we describe and evaluate syntactic and semantic aspects of Arbobanko, a treebank for the artificial language Esperanto, as well as tools and methods used in the production of the treebank. In addition to classical morphosyntax and dependency structure, the treebank was enriched with a lexical-semantic layer covering named entities, a semantic type ontology for nouns and adjectives and a framenet-inspired semantic classification of verbs. For an under-resourced language, the quality of automatic syntactic and semantic pre-annotation is of obvious importance, and by evaluating the underlying parser and the coverage of its semantic ontologies, we try to answer the question whether the language{'}s extremely regular morphology and transparent semantic affixes translate into a more regular syntax and higher parsing accuracy. On the linguistic side, the treebank allows us to address and quantify typological issues such as the question of word order, auxiliary constructions, lexical transparency and semantic type ambiguity in Esperanto."
2020.lrec-1.752,An Annotated Social Media Corpus for {G}erman,2020,-1,-1,1,1,17909,eckhard bick,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper presents the German Twitter section of a large (2 billion word) bilingual Social Media corpus for Hate Speech research, discussing the compilation, pseudonymization and grammatical annotation of the corpus, as well as special linguistic features and peculiarities encountered in the data. Among other things, compounding, accidental and intentional orthographic variation, gendering and the use of emoticons/emojis are addressed in a genre-specific fashion. We present the different layers of linguistic annotation (morphosyntactic, dependencies and semantic types) and explain how a general parser (GerGram) can be made to work on Social Media data, pointing out necessary adaptations and extensions. In an evaluation run on a random cross-section of tweets, the modified parser achieved F-scores of 97{\%} for morphology (fine-grained POS) and 92{\%} for syntax (labeled attachment score). Predictably, performance was twice as good in tweets with standard orthography than in tweets with spelling/casing irregularities or lack of sentence separation, the effect being more marked for morphology than for syntax."
W19-6302,Automatic Generation and Semantic Grading of {E}speranto Sentences in a Teaching Context,2019,-1,-1,1,1,17909,eckhard bick,Proceedings of the 8th Workshop on NLP for Computer Assisted Language Learning,0,None
W19-0406,A Semantic Ontology of {D}anish Adjectives,2019,-1,-1,1,1,17909,eckhard bick,Proceedings of the 13th International Conference on Computational Semantics - Long Papers,0,"This paper presents a semantic annotation scheme for Danish adjectives, focusing both on prototypical semantic content and semantic collocational restrictions on an adjective{'}s head noun. The core type set comprises about 110 categories ordered in a shallow hierarchy with 14 primary and 25 secondary umbrella categories. In addition, domain information and binary sentiment tags are provided, as well as VerbNet-derived frames and semantic roles for those adjectives governing arguments. The scheme has been almost fully implemented on the lexicon of the Danish VISL parser, DanGram, containing 14,000 adjectives. We discuss the annotation scheme and its applicational perspectives, and present a statistical breakdown and coverage evaluation for three Danish reference corpora."
W17-6902,{P}ropbank Annotation of {D}anish Noun Frames,2017,3,0,1,1,17909,eckhard bick,{IWCS} 2017 {---} 12th International Conference on Computational Semantics {---} Short papers,0,None
W17-6523,{U}niversal {D}ependencies for {P}ortuguese,2017,9,5,5,0,1261,alexandre rademaker,Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017),0,None
W17-0223,From Treebank to {P}ropbank: A Semantic-Role and {V}erb{N}et Corpus for {D}anish,2017,0,0,1,1,17909,eckhard bick,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W16-6314,Constraint Grammar-based conversion of Dependency Treebanks,2016,0,1,1,1,17909,eckhard bick,Proceedings of the 13th International Conference on Natural Language Processing,0,None
L16-1171,A Morphological Lexicon of {E}speranto with Morpheme Frequencies,2016,0,0,1,1,17909,eckhard bick,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper discusses the internal structure of complex Esperanto words (CWs). Using a morphological analyzer, possible affixation and compounding is checked for over 50,000 Esperanto lexemes against a list of 17,000 root words. Morpheme boundaries in the resulting analyses were then checked manually, creating a CW dictionary of 28,000 words, representing 56.4{\%} of the lexicon, or 19.4{\%} of corpus tokens. The error percentage of the EspGram morphological analyzer for new corpus CWs was 4.3{\%} for types and 6.4{\%} for tokens, with a recall of almost 100{\%}, and wrong/spurious boundaries being more common than missing ones. For pedagogical purposes a morpheme frequency dictionary was constructed for a 16 million word corpus, confirming the importance of agglutinative derivational morphemes in the Esperanto lexicon. Finally, as a means to reduce the morphological ambiguity of CWs, we provide POS likelihoods for Esperanto suffixes."
W15-5406,{W}iki{T}rans: {S}wedish-{D}anish Machine Translation in a Constraint Grammar Framework,2015,-1,-1,1,1,17909,eckhard bick,"Proceedings of the Joint Workshop on Language Technology for Closely Related Languages, Varieties and Dialects",0,None
W15-1807,{CG}-3 {---} Beyond Classical Constraint Grammar,2015,7,5,1,1,17909,eckhard bick,Proceedings of the 20th Nordic Conference of Computational Linguistics ({NODALIDA} 2015),0,"This paper discusses methodological strengths and shortcomings of the Constraint Grammar paradigm (CG), showingxc2xa0howxc2xa0thexc2xa0classicalxc2xa0CGxc2xa0formalism can be extended to achieve greater expressive power and how it can be enhancedxc2xa0andxc2xa0hybridizedxc2xa0withxc2xa0techniques fromxc2xa0otherxc2xa0parsingxc2xa0paradigms.xc2xa0Wexc2xa0present a new, largely theoryxc2xadindependent CG frameworkxc2xa0andxc2xa0rulexc2xa0compilerxc2xa0(CGxc2xad3),xc2xa0that allows the linguist to write CG rules incorporatingxc2xa0differentxc2xa0typesxc2xa0ofxc2xa0linguistic informationxc2xa0andxc2xa0methodologyxc2xa0fromxc2xa0axc2xa0wide rangexc2xa0ofxc2xa0parsingxc2xa0approaches,xc2xa0coveringxc2xa0not only CG's native topological technique, but also dependency grammar, phrase structure grammar and unification grammar. In addition, we allow the integration of statisticalxc2xadnumerical constraintsxc2xa0andxc2xa0nonxc2xaddiscretexc2xa0tagxc2xa0andxc2xa0string sets."
R15-1008,{D}an{P}roof: Pedagogical Spell and Grammar Checking for {D}anish,2015,5,3,1,1,17909,eckhard bick,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"This paper presents a Constraint Grammarbased pedagogical proofing tool for Danish. The system recognizes not only spelling errors, but also grammatical errors in otherwise correctly spelled words, and categorizes errors for WORD-integrated pedagogical comments. Possible spelling corrections are prioritized from context, and grammatical corrections generated by a morphological module. The system uses both phonetic similarity measures and traditional Levenshtein-distances, and has a special focus on compounding/splitting errors common in modern Danish. As a classical spell-checker DanProof achieves F-Scores over 95, and F=88 if compounding correction is included. With the maximal set of error types, 2/3 of all errors are found in school essays, and precision is 91.7%."
bick-2014-ml,{ML}-Optimization of Ported Constraint Grammars,2014,6,1,1,1,17909,eckhard bick,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we describe how a Constraint Grammar with linguist-written rules can be optimized and ported to another language using a Machine Learning technique. The effects of rule movements, sorting, grammar-sectioning and systematic rule modifications are discussed and quantitatively evaluated. Statistical information is used to provide a baseline and to enhance the core of manual rules. The best-performing parameter combinations achieved part-of-speech F-scores of over 92 for a grammar ported from English to Danish, a considerable advance over both the statistical baseline (85.7), and the raw ported grammar (86.1). When the same technique was applied to an existing native Danish CG, error reduction was 10{\%} (F=96.94)."
Y13-1046,{ML}-Tuned Constraint Grammars,2013,7,5,1,1,17909,eckhard bick,"Proceedings of the 27th Pacific Asia Conference on Language, Information, and Computation ({PACLIC} 27)",0,"In this paper we present a new method for machine learning-based optimization of linguist-written Constraint Grammars. The effect of rule ordering/sorting, grammarsectioning and systematic rule changes is discussed and quantitatively evaluated. The F-score improvement was 0.41 percentage points for a mature (Danish) tagging grammar, and 1.36 percentage points for a half-size grammar, translating into a 7-15% error reduction relative to the performance of the untuned grammars."
W13-5607,Using Constraint Grammar for Chunking,2013,7,2,1,1,17909,eckhard bick,Proceedings of the 19th Nordic Conference of Computational Linguistics ({NODALIDA} 2013),0,"This paper presents and evaluates a novel and flexible chunking method using Constraint Grammar (CG) rules to introduce chunk edges in corpus annotation. Our method exploits preexisting (non-constituent) morphosyntactic annotation such as part-of-speech or function tags, but can also be made to work on raw text, integrated with other CG modules. The first version of the chunker was developed for German CG-annotated interview data, with a parallel English version derived from the German one, indicating a high degree of language-independence of the rules in the presence of generalized syntactic-functional tags (e.g. subject, object, modifier). Two different approaches are discussed, one for minimal, flat chunking, the other for deep, nested chunking. The system has a reasonable performance and robustness for both, achieving F-scores of 89.1 and 97.4 for nested and minimal chunking, respectively. Xml markup is supported, and with a full set of rules, the tool can be used to convert CG annotation into complete constituent trees in VISL or TIGER format."
Y12-1006,Towards a Semantic Annotation of {E}nglish Television News - Building and Evaluating a Constraint Grammar {F}rame{N}et,2012,0,0,1,1,17909,eckhard bick,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,None
bick-etal-2012-annotation,The annotation of the {C}-{ORAL}-{BRASIL} oral through the implementation of the Palavras Parser,2012,3,4,1,1,17909,eckhard bick,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This article describes the morphosyntactic annotation of the C-ORAL-BRASIL speech corpus, using an adapted version of the Palavras parser. In order to achieve compatibility with annotation rules designed for standard written Portuguese, transcribed words were orthographically normalized, and the parsing lexicon augmented with speech-specific material, phonetically spelled abbreviations etc. Using a two-level annotation approach, speech flow markers like overlaps, retractions and non-verbal productions were separated from running, annotatable text. In the absence of punctuation, syntactic segmentation was achieved by exploiting prosodic break markers, enhanced by a rule-based distinctions between pause and break functions. Under optimal conditions, the modified parsing system achieved correctness rates (F-scores) of 98.6{\%} for part of speech, 95{\%} for syntactic function and 99{\%} for lemmatization. Especially at the syntactic level, a clear connection between accessibility of prosodic break markers and annotation performance could be documented."
C12-1073,Tailored Feature Extraction for Lexical Disambiguation of {E}nglish Verbs Based on Corpus Pattern Analysis,2012,8,3,4,0,31585,martin holub,Proceedings of {COLING} 2012,0,"We give a report on a detailed study of automatic lexical disambiguation of 30 sample English verbs. We were drawing on a lexicon of English verb patterns based on the Corpus Pattern Analysis (CPA), which is a novel lexicographic method that seeks to cluster verb uses according to the morpho-syntactic, lexical and semantic/pragmatic similarity of their contexts rather than to associate them with abstract semantic definitions. We have trained several statistical classifiers to recognize these patterns, using morpho-syntactic as well as semantic features. In this paper we mainly concentrate on the procedures for feature extraction and feature selection and their evaluation. We show that tailoring the features to the verbs respectively, as they are implicitly contained in the pattern definitions (explicitly described in the lexicon), has the potential to significantly improve the accuracy of supervised statistical classifiers. TITLE AND ABSTRACT IN CZECH Rysy site na miru anglickxc3xbdm slovesxc5xafm pro automatickou lexikalni disambiguaci pomoci Corpus Pattern Analysis Pxc5x99edkladame detailni studii automaticke lexikalni disambiguace na pilotnim vzorku xc5xa5riceti anglickxc3xbdch sloves za pouxc5xbeiti lexikonu vzorxc5xaf slovesnxc3xbdch uxc5xbeiti (patterns), kterxc3xbd vychazi z Corpus Pattern Analysis (CPA). Tato inovatorska lexikograficka metoda namisto na abstraktnich definicich jednotlivxc3xbdch vxc3xbdznamxc5xaf stavi na souhxc5x99e morfosyntakticke, lexikalni a semanticke/pragmaticke podobnosti slovesnxc3xbdch uxc5xbeiti. Natrenovali jsme nxc4x9bkolik statistickxc3xbdch klasifikatorxc5xaf na rozpoznavani txc4x9bchto vzorxc5xaf. Klasifikatory vyuxc5xbeivaji jak morfosyntaktickxc3xbdch, tak semantickxc3xbdch rysxc5xaf. V nasi studii se sousxc5xa5redime na procedury pro extrakci rysxc5xaf, jejich vxc3xbdbxc4x9br a jejich evaluaci. Ukazujeme, xc5xbee rysy na miru uzpxc5xafsobene jednotlivxc3xbdm slovesxc5xafm, jexc5xbe jsou implicitnxc4x9b obsaxc5xbeeny v definici kaxc5xbedeho vzoru v lexikonu, maji potencial vxc3xbdznamnxc4x9b zvxc3xbdsit pxc5x99esnost statistickxc3xbdch klasifikatorxc5xaf s ucitelem."
Y11-1024,A Bare-bones Constraint Grammar,2011,7,2,1,1,17909,eckhard bick,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"This paper presents a solution for overcoming the lexical resource gap when mounting rule-based Constraint Grammar systems for minor languages, or in the face of licensing and financing limitations. We investigate how the performance of a CG disambiguation grammar responds to shifting input parameters, among them lexicon limitations of various degrees, the lack a morphological analyzer or both. We propose solutions for a bare-bones system, introducing endings heuristics and so-called morphological APPEND rules. For English, even with an unadapted disambiguation grammar, our bare-bones tagger achieved F-scores of 90-96% for part of speech, and 9497% for lemmatization, depending on the modules and mini-lexica used."
W11-4606,A {F}rame{N}et for {D}anish,2011,14,4,1,1,17909,eckhard bick,Proceedings of the 18th Nordic Conference of Computational Linguistics ({NODALIDA} 2011),0,"This paper presents work on a comprehensive FrameNet for Danish (cf. www.framenet.dk), with over 12.000 frames, and an almost complete coverage of Danish verb lemmas. We discuss design principles and frame roles as well as the distinctional use of valency, syntactic function and semantic noun classes. By converting frame distinctors into Constraint Grammar rules, we were able to build a robust frame tagger for running Danish text, using DanGram parses as input. The combined context-informed coverage of the parser-frametagger was 94.3%, with an overall F-score for frame senses of 85.12."
Y10-1084,Degrees of Orality in Speech-like Corpora: Comparative Annotation of Chat and {E}-mail Corpora,2010,4,2,1,1,17909,eckhard bick,"Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation",0,"This paper describes and evaluates the automatic grammatical annotation of a chat and an e-mail corpus of together 117 million words, using a modular Constraint Grammar system. We discuss a number of genre-specific issues, such as emoticons and personal pronouns, and offer a linguistic comparison of the two corpora with corresponding annotations of the Europarl corpus and the spoken and written subsections of the BNC corpus, with a focus on orality markers such as linguistic complexity and word class distribution."
bick-2010-frag,"{F}r{AG}, a Hybrid Constraint Grammar Parser for {F}rench",2010,6,2,1,1,17909,eckhard bick,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper describes a hybrid system (FrAG) for tagging / parsing French text, and presents results from ongoing development work, corpus annotation and evaluation. The core of the system is a sentence scope Constraint Grammar (CG), with linguist-written rules. However, unlike traditional CG, the system uses hybrid techniques on both its morphological input side and its syntactic output side. Thus, FrAG draws on a pre-existing probabilistic Decision Tree Tagger (DTT) before and in parallel with its own lexical stage, and feeds its output into a Phrase Structure Grammar (PSG) that uses CG syntactic function tags rather than ordinary terminals in its rewriting rules. As an alternative architecture, dependency tree structures are also supported. In the newest version, dependencies are assigned within the CG-framework itself, and can interact with other rules. To provide semantic context, a semantic prototype ontology for nouns is used, covering a large part of the lexicon. In a recent test run on Parliamentary debate transcripts, FrAG achieved F-scores of 98.7 {\%} for part of speech (PoS) and between 93.1 {\%} and 96.2 {\%} for syntactic function tags. Dependency links were correct in 95.9 {\%}."
W09-4630,Automatic Semantic Role Annotation for {S}panish,2009,12,2,1,1,17909,eckhard bick,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,"This paper describes and evaluates the automatic annotation of clause-level complements with semantic roles in a Spanish Web corpus, using a rule- and dependency-based approach. In all, 52 different role tags, like agent (xc2xa7AG), experiencer (xc2xa7EXP), location (xc2xa7LOC) etc. are distinguished. The annotator uses a role grammar of 568 hand-written Constraint Grammar rules that take as input the syntactic analysis of the HISPAL parser. A rough evaluation of 5000 running words was performed, where the role annotation achieved an F 1 of 81,6% on raw text and 90,0% on syntactically revised input. A Spanish Internet corpus of 11.2 million words has been compiled and automatically annotated with our semantic role grammar, allowing us to provide some linguistic and statistical interpretations about the relationship between semantic roles on the one hand and syntactic functions, part of speech and semantic prototypes on the other."
W09-4642,{D}eep{D}ict{--}A Graphical Corpus-based Dictionary of Word Relations,2009,6,10,1,1,17909,eckhard bick,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,"In our demonstration, we will present a new type of lexical resource, built from grammatically analysed corpus data. Co-occurrence strength between mother-daughter dependency pairs is used to automatically produce dictionary entries of typical complementation patterns and collocations, in the fashion of an instant monolingual Advanced Learner's dictionary. Entries are supplied to the user in a graphical interface with various thresholds for lexical frequencies as well as absolute and relative co-occurrence frequencies. DeepDict draws its data from Constraint Grammar-analysed corpora, ranging between tens and hundreds of millions of words, covering the major Germanic and Romance languages. Apart from its obvious lexicographical uses, DeepDict also targets teaching environments and translators."
W07-2405,Using {D}anish as a {CG} Interlingua: A Wide-Coverage {N}orwegian-{E}nglish Machine Translation System,2007,-1,-1,1,1,17909,eckhard bick,Proceedings of the 16th Nordic Conference of Computational Linguistics ({NODALIDA} 2007),0,None
D07-1120,Hybrid Ways to Improve Domain Independence in an {ML} Dependency Parser,2007,7,3,1,1,17909,eckhard bick,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"This paper reports a hybridization experixc2xad ment,xc2xa0where a baseline ML dependencyxc2xa0parsxc2xad er, LingPars, was allowed access to Conxc2xad straint Grammar analyses provided by a rulexc2xad based parser (EngGram) for the same data. Descriptive compatibility issues and their inxc2xad fluence on performance are discussed. The hybrid system performed considerably better than its ML baseline, and proved more roxc2xad bust than the latter in the domain adaptation task, where it was the bestxc2xadscoring system in the open class for the chemical test data, and the best overall system for the CHILDES test data."
W06-2923,"{L}ing{P}ars, a Linguistically Inspired, Language-Independent Machine Learner for Dependency Treebanks",2006,11,9,1,1,17909,eckhard bick,Proceedings of the Tenth Conference on Computational Natural Language Learning ({C}o{NLL}-X),0,"This paper presents a Constraint Grammar-inspired machine learner and parser, LingPars, that assigns dependencies to morphologically annotated treebanks in a function-centred way. The system not only bases attachment probabilities for PoS, case, mood, lemma on those features' function probabilities, but also uses topological features like function/PoS n-grams, barrier tags and daughter-sequences. In the CoNLL shared task, performance was below average on attachment scores, but a relatively higher score for function tags/deprels in isolation suggests that the system's strengths were not fully exploited in the current architecture."
bick-2006-turning,Turning a Dependency Treebank into a {PSG}-style Constituent Treebank,2006,5,2,1,1,17909,eckhard bick,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In this paper, we present and evaluate a new method to convert Constraint Grammar (CG) parses of running text into Constituent Treebanks. The conversion is two-step - first a grammar-based method is used to bridge the gap between raw CG annotation and full dependency structure, then phrase structure bracketing and non-terminal nodes are introduced by clustering sister dependents, effectively building one syntactic treebank on top of another. The method is compared with another approach (Bick 2003-2), where constituent structures are arrived at by employing a function-tag based Phrase Structure Grammar (PSG). Results are evaluated on a small reference corpus for both raw and revised CG input, with bracketing F-Scores of 87.5{\%} for raw text and 97.1{\%} for revised CG input, and a raw text edge label accuracy of 95.9{\%} for forms and 86{\%} for functions, or 99.7{\%} and 99.4{\%}, respectively, for revised CG. By applying the tools to the CG-only part of the Danish Arboretum treebank we were able to increase the size of the treebank by 86{\%}, from 197.400 to 367.500 words."
bick-2004-named,A Named Entity Recognizer for {D}anish,2004,3,30,1,1,17909,eckhard bick,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper describes how a preexisting Constraint Grammar based parser for Danish (DanGram, Bick 2002) has been adapted and semantically enhanced in order to accommodate for named entity recognition (NER), using rule based and lexical, rather than probabilistic methodology. The project is part of a multi-lingual Nordic initiative, Nomen Nescio, which targets 6 primary name types (human, organisation, place, event, title/semantic product and brand/object). Training data, examples and statistical text data specifics were taken from the Korpus90/2000 annotation initiative (Bick 2003-1). The NER task is addressed following the progressive multi-level parsing architecture of DanGram, delegating different NER-subtasks to different specialised levels. Thus named entities are successively treated as first strings, words, types, and then as contextual units at the morphological, syntactic and semantic levels, consecutively. While lower levels mainly use pattern matching tools, the higher levels make increasing use of context based Constraint Grammar rules on the one hand, and lexical information, both morphological and semantic, on the other hand. Levels are implemented as a sequential chain of Perl-programs and CG-grammars. Two evaluation runs on Korpus90/2000 data showed about 2% chunking errors and false positive/false negative proper noun readings (originating at the lower levels), while the NER-typer as such had a 5% error rate with 0.1 0.5% remaining ambiguity, if measured only for correctly chunked proper nouns."
2004.jeptalnrecital-long.31,La {FREEBANK} : vers une base libre de corpus annot{\\'e}s,2004,-1,-1,2,0,50134,susanne salmonalt,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Les corpus fran{\c{c}}ais librement accessibles annot{\'e}s {\`a} d{'}autres niveaux linguistiques que morpho-syntaxique sont insuffisants {\`a} la fois quantitativement et qualitativement. Partant de ce constat, la FREEBANK {--} construite sur la base d{'}outils d{'}analyse automatique dont la sortie est r{\'e}vis{\'e}e manuellement {--} se veut une base de corpus du fran{\c{c}}ais annot{\'e}s {\`a} plusieurs niveaux (structurel, morphologique, syntaxique, cor{\'e}f{\'e}rentiel) et {\`a} diff{\'e}rents degr{\'e}s de finesse linguistique qui soit libre d{'}acc{\`e}s, cod{\'e}e selon des sch{\'e}mas normalis{\'e}s, int{\'e}grant des ressources existantes et ouverte {\`a} l{'}enrichissement progressif."
afonso-etal-2002-floresta,Floresta Sint{\\'a}(c)tica: A treebank for {P}ortuguese,2002,10,130,2,0,53294,susana afonso,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper reviews the first year of the creation of a publicly available treebank for Portuguese, Floresta Sinta(c)tica, a collaboration project between the VISL and the Computational Processing of Portuguese projects. After briefly describing the main goals and the organization of the project, the creation of the annotated objects is presented in detail: preparing the text to be annotated, applying the Constraint Grammar based PALAVRAS parser, revising its output manually in a two-stage process, and carefully documenting the linguistic options. Some examples of the kind of interesting problems dealt with are presented, and the paper ends with a brief description of the tools developed, the project results so far, and a mention to a preliminary inter-annotator test and what was learned from it."
W01-1702,The {VISL} System: Research and applicative aspects of {IT}-based learning,2001,0,8,1,1,17909,eckhard bick,Proceedings of the 13th Nordic Conference of Computational Linguistics ({NODALIDA} 2001),0,None
santos-bick-2000-providing,Providing {I}nternet Access to {P}ortuguese Corpora: the {AC}/{DC} Project,2000,6,46,2,0,35407,diana santos,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"In this paper we report on the activity of the project Computational Processing of Portuguese (Processamento computacional do portugues) in what concerns providing access to Portuguese corpora through the Internet. One of its activities, the AC/DC project (Acesso a corpora/Disponibilizacao de Corpora, roughly Access and Availability of Corpora) allows a user to query around 40 million words of Portuguese text. After describing the aims of the service, which is still being subject to regular improvements, we focus on the process of tagging and parsing the underlying corpora, using a Constraint Grammar parser for Portuguese."
W98-1605,Structural Lexical Heuristics in the Automatic Analysis of {P}ortuguese,1998,6,3,1,1,17909,eckhard bick,Proceedings of the 11th Nordic Conference of Computational Linguistics ({NODALIDA} 1998),0,None
