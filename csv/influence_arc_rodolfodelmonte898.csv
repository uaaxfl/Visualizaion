delmonte-2000-shallow,J93-2004,0,\N,Missing
delmonte-2000-shallow,W95-0201,0,\N,Missing
delmonte-2000-shallow,A92-1018,0,\N,Missing
delmonte-2000-shallow,E93-1046,0,\N,Missing
delmonte-2000-shallow,E93-1069,0,\N,Missing
delmonte-2000-shallow,P91-1032,0,\N,Missing
delmonte-2000-shallow,E95-1021,0,\N,Missing
delmonte-2000-shallow,A94-1008,0,\N,Missing
delmonte-etal-2010-deep,E06-1007,0,\N,Missing
delmonte-etal-2010-deep,W08-2223,1,\N,Missing
delmonte-etal-2010-deep,W07-1207,0,\N,Missing
delmonte-etal-2010-deep,N03-2012,0,\N,Missing
delmonte-etal-2010-deep,P03-1071,0,\N,Missing
delmonte-etal-2010-deep,P03-1022,0,\N,Missing
delmonte-etal-2010-deep,P07-1103,0,\N,Missing
delmonte-etal-2010-deep,W06-2302,1,\N,Missing
delmonte-etal-2010-deep,W04-2328,0,\N,Missing
delmonte-etal-2010-deep,P07-2027,0,\N,Missing
E14-2019,W12-2502,0,0.155919,"Missing"
E14-2019,H05-1073,0,0.124274,"Missing"
E85-1020,1985.tmi-1.11,0,0.0299088,"Missing"
E85-1020,E83-1005,1,0.83453,"Missing"
E85-1020,P80-1024,0,0.0640041,"Missing"
E85-1020,J83-1005,0,0.220707,"Missing"
S10-1065,P98-1013,0,0.298433,"we will discuss how we mapped the VENSES analysis to the representation of frame information in order to identify null instantiations in the text. 1 Introduction The SemEval-2010 task for linking events and their participants in discourse (Ruppenhofer et al., 2009) introduced a new issue w.r.t. the SemEval-2007 task “Frame Semantic Structure Extraction” (Baker et al., 2007), in that it focused on linking local semantic argument structures across sentence boundaries. Specifically, the task included first the identification of frames and frame elements in a text following the FrameNet paradigm (Baker et al., 1998), then the identification of locally uninstantiated roles (NIs). If these roles are indefinite (INI), they have to be marked as such and no antecedent has to be found. On the contrary, if they are definite (DNI), their coreferents have to be found in the wider discourse context. The challenge comprised two tasks, namely the full task (semantic role recognition and labelling + NI linking) and the NIs only task, i.e. the identification of null instantiations and their referents given a test set with gold standard local semantic argument structure. We took part to the NIs only task by modifying t"
S10-1065,W06-2302,1,0.839869,"at this stage of computation may not be effective. 296 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 296–299, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics 2.2 The anaphora resolution module The AHDS structure is passed to and used by a full-fledged module for pronominal and anaphora resolution, which is in turn split into two submodules. The resolution procedure takes care only of third person pronouns of all kinds – reciprocals, reflexives, possessive and personal. Its mechanisms are quite complex, as described in (Delmonte et al., 2006). The first submodule basically treats all pronouns at sentence level – that is, taking into account their position – and if they are left free, they receive the annotation “external”. If they are bound, they are associated to an antecedent’s index; else they might also be interpreted as expletives, i.e. they receive a label that prevents the following submodule to consider them for further computation. The second submodule receives as input the external pronouns, and tries to find an antecedent in the previous stretch of text or discourse. To do that, the systems computes a topic hierarchy th"
S10-1065,J86-3001,0,0.291777,"Missing"
S10-1065,W09-2417,0,0.263895,"azione Bruno Kessler Trento, Italy. satonelli@fbk.eu Abstract The system to spot INIs, DNIs and their antecedents is an adaptation of VENSES, a system for semantic evaluation that has been used for RTE challenges in the last 6 years. In the following we will briefly describe the system and then the additions we made to cope with the new task. In particular, we will discuss how we mapped the VENSES analysis to the representation of frame information in order to identify null instantiations in the text. 1 Introduction The SemEval-2010 task for linking events and their participants in discourse (Ruppenhofer et al., 2009) introduced a new issue w.r.t. the SemEval-2007 task “Frame Semantic Structure Extraction” (Baker et al., 2007), in that it focused on linking local semantic argument structures across sentence boundaries. Specifically, the task included first the identification of frames and frame elements in a text following the FrameNet paradigm (Baker et al., 1998), then the identification of locally uninstantiated roles (NIs). If these roles are indefinite (INI), they have to be marked as such and no antecedent has to be found. On the contrary, if they are definite (DNI), their coreferents have to be foun"
S10-1065,S10-1008,0,\N,Missing
S10-1065,C98-1013,0,\N,Missing
S16-1123,S15-2045,0,0.0392157,"Missing"
S16-1123,W04-3205,0,0.188685,"Missing"
S16-1123,P13-2080,0,0.0721446,"Missing"
tonelli-etal-2008-enriching,J03-4003,0,\N,Missing
tonelli-etal-2010-venpro,W09-0714,0,\N,Missing
tonelli-etal-2010-venpro,pianta-etal-2008-textpro,1,\N,Missing
U10-1001,U10-1001,1,0.0513221,"Missing"
W00-2034,E95-1021,0,0.0426062,"Missing"
W00-2034,J99-2004,0,0.0770895,"Missing"
W00-2034,J93-2004,0,\N,Missing
W00-2034,W95-0201,0,\N,Missing
W00-2034,E93-1046,0,\N,Missing
W00-2034,E93-1069,0,\N,Missing
W00-2034,H92-1022,0,\N,Missing
W00-2034,A92-1021,0,\N,Missing
W00-2034,P91-1032,0,\N,Missing
W00-2034,A94-1008,0,\N,Missing
W02-2212,H90-1052,0,0.0448662,"Missing"
W02-2212,P84-1054,0,0.102658,"Missing"
W02-2212,J93-1005,0,\N,Missing
W02-2212,1991.iwpt-1.8,0,\N,Missing
W04-0913,2000.bcs-1.25,1,0.836894,"s the bucket covered? (to keep rain and snow out) Another possible « Why » question could have been the following : « why is the tree called a &quot;sugar&quot; maple tree », which would have received the appropriate answer seen that the corresponding sentence has received an appropriate grammatical and semantic analysis. In particular, the discourse deictic pronoun « This » has been bound to the previous main relation « use » and its arguments, so that they can be used to answer the « Why » question appropriately. There is not enough space here to comment in detail the parse and the semantics (but see Delmonte 2000d); however, as far as anaphora resolution is concerned, the Higher Module computes the appropriate antecedent for the big Pro, i.e. the empty SUBject of the infinitive in sentence n. 7, where the collecting action would have been left without an agent. This resolution of anaphora is triggered by the parser decision to treat the big Pro as an arbitrary pronominal and this information is stored at lexical level in the subcategorization frame for the name « time ». With question n.4 the text only makes available information related to « maple syrup ». As said above, we start looking for relation"
W04-0913,E03-1025,0,0.0488248,"Missing"
W04-0913,P99-1042,0,0.0715629,"Missing"
W04-2005,W95-0201,0,0.0423459,"Missing"
W04-2005,E03-1025,0,0.127666,"than they were to the Jacksonian Democrats. (ncsubj be Jeffersonian _) (xcomp _ be atune) (iobj to atune Whig) (ncsubj be they _) **(iobj to be democrat) From the search in COMLEX of the remaining 127 predicates governing IOBJ relations, we derived 20 predicates missing the preposition required for the complement discriminative choice. In more than one case the choice of complement (iobj) vs. adjunct (ncmod) is highly disputable. This situation makes the comparison and evaluation of IOBJs very uncertain and bound to low scoring as happened with the parsers included in the test reported under (Preis, 2003). As an additional remark, from the definition it would appear that OBLiques are treated as DOBJ of a preposition particle which is in turn treated itself as ncmod. To better clarify the issue we partially report the annotation of example 244 from the corpus, where we italicize the relevant relations, (4) Meanwhile, the experts speak of wars triggered by false pre-emption, escalation, unauthorized behavior and other terms that will be discussed in this report. ncsubj(speak, expert, _) dobj(speak, war, _) ncsubj(trigger, war, obj) arg_mod(by, trigger, pre-emption, subj) arg_mod(by, trigger, esc"
W04-2005,A94-1008,0,0.0330792,"nd FSA One of the important differences we would like to highlight is the use of topdown lookahead based parsing strategies. The following list of preterminal 14 symbols is used: 1. v=verb-auxiliary-modal-clitic-cliticized verb 2. n=noun – common, proper; 3. c=complementizer 4. s=subordinator; 5. e=conjunction 6. p=preposition-particle 7. a=adjective; 8. q=participle/gerund 9. i=interjection 10. g=negation 11.d=article-quantifier-number-intensifier-focalizer 12. r=pronoun 13. av=adverb 14. x=punctuation Tab. 1: Preterminal symbols used for lookahead As has been reported in the literature (see Tapanainen and Voutilainen 1994; Brants and Samuelsson 1995), English is a language with a high level of homography: readings per word are around 2 (i.e. each word can be assigned in average two different tags depending on the tagset). Lookahead in our system copes with most cases of ambiguity: however, we also had to introduce a disambiguating tool before the input string could be safely passed to the parser. Disambiguation is applied to the lookahead stack and is operated by means of Finite State Automata. The reason why we use FSA is simply due to the fact that for some important categories, English has unambiguous tags"
W06-0802,P03-1054,0,0.00302686,"dicate logic constructs: but we must remember that FOPL is as such insufficient to describe natural language texts. Ternary expressions(T-expressions), &lt;subject relation object&gt;. Certain other parameters (adjectives, possessive nouns, prepositional phrases, etc.) are used to create additional T-expressions in which prepositions and several special words may serve as relations. For instance, the following simple sentence 1. Introduction Although full syntactic and semantic analysis of opendomain natural language text is beyond current technology, a number of papers have been recently published [1,2,3] showing that, by using probabilistic or symbolic methods, it is possible to obtain dependencybased representations of unlimited texts with good recall and precision. Consequently, we believe it should be possible to augment the manual-annotation-based approach with automatically built annotations by extracting a limited subset of semantic relations from unstructured text. In short, shallow/partial text understanding on the level of semantic relations, an extended label including Predicate-Argument Structures and other syntactically and semantically derivable head modifiers and adjuncts. This"
W06-0802,1993.iwpt-1.22,0,0.00925856,"dicate logic constructs: but we must remember that FOPL is as such insufficient to describe natural language texts. Ternary expressions(T-expressions), &lt;subject relation object&gt;. Certain other parameters (adjectives, possessive nouns, prepositional phrases, etc.) are used to create additional T-expressions in which prepositions and several special words may serve as relations. For instance, the following simple sentence 1. Introduction Although full syntactic and semantic analysis of opendomain natural language text is beyond current technology, a number of papers have been recently published [1,2,3] showing that, by using probabilistic or symbolic methods, it is possible to obtain dependencybased representations of unlimited texts with good recall and precision. Consequently, we believe it should be possible to augment the manual-annotation-based approach with automatically built annotations by extracting a limited subset of semantic relations from unstructured text. In short, shallow/partial text understanding on the level of semantic relations, an extended label including Predicate-Argument Structures and other syntactically and semantically derivable head modifiers and adjuncts. This"
W06-0802,W04-2005,1,0.794745,"Missing"
W06-2302,W04-2005,1,0.82968,"Missing"
W06-2302,C90-2047,0,0.060047,"Missing"
W06-2302,C96-1021,0,0.112441,"Missing"
W06-2302,qiu-etal-2004-public,0,0.0349918,"Missing"
W06-2302,P98-2143,0,0.0565723,"Missing"
W06-2302,J98-2001,0,0.0795361,"Missing"
W06-2302,poesio-kabadjov-2004-general,0,0.0286773,"Missing"
W06-2302,J86-3001,0,\N,Missing
W06-2302,C98-2138,0,\N,Missing
W06-2302,1991.iwpt-1.8,0,\N,Missing
W07-1408,C04-1180,0,\N,Missing
W07-1408,W04-0913,1,\N,Missing
W07-1408,J86-3001,0,\N,Missing
W07-1408,W06-2302,1,\N,Missing
W08-2223,W08-2220,0,0.0980537,"s to all data structures contemporarily and pass the resolved pair, anaphor-antecedent to the following modules. Semantic Mapping is performed in two steps: at first a Logical Form is produced which is a structural mapping from DAGs onto unscoped well-formed formulas. These are then turned into situational semantics informational units, infons which may become facts or sits. Each unit has a relation, a list of arguments which in our case receive their semantic roles from lower processing — a polarity, a temporal and a spatial location index. 3 The Text The text we present for the shared task (Bos, 2008) is a “psychological statement” text, i.e. it includes a sentence (namely sentence 4) that represents a psychological statement, i.e. it expresses the feelings and is viewed from the point of view of one of the participants in the story. The relevance of the sentence is its role in the assignment of the antecedent to the pronominal expressions contained in the following sentence. Without such a sentence the anaphora resolution module would have no way of computing “John” as the legitimate antecedent of “He/his”. On the contrary, in a system like ours that computes Point of View and Discourse D"
W09-1506,W07-1207,0,0.0607926,"Missing"
W11-0908,P98-1013,0,0.371949,"or not, and on the other hand to precision problems, i.e. if an implicit entity is accessible to the reader from the discourse or its context, an appropriate antecedent has to be found. However, a system able to derive the presence of IEs may be a determining factor in improving performance of QA systems and, in general, in Informations Retrieval and Extraction systems. The current computational scene has witnessed an increased interest in the creation and use of semantically annotated computational lexica and their associated annotated corpora, like PropBank (Palmer et al., 2005), FrameNet (Baker et al., 1998) and NomBank (Meyers, 2007), where the proposed annotation scheme has been applied in real contexts. In all these cases, what has been addressed is a basic semantic issue, i.e. labeling PAS associated to semantic predicates like adjectives, verbs and nouns. However, what these corpora have not made available is information related to IEs. For example, in the case of eventive deverbal nominals, information about the subject/object of the nominal predicate is often implicit and has to be understood from the previous 54 Proceedings of the ACL 2011 Workshop on Relational Models of Semantics (RELMS"
W11-0908,S07-1018,0,0.0315457,"ent identification over a common test set and considering different kinds of predicates was made by Ruppenhofer et al. (2010). Further details are given in the following section. Data set Train Test Sentences 438 525 Frame inst. 1,370 1,703 Frame types 317 452 Overt FEs 2,526 3,141 DNIs (resolved) 303 (245) 349 (259) INIs 277 361 Table 1: Data set statistics from SemEval task 10 3 SemEval 2010 task 10 The SemEval-2010 task for linking events and their participants in discourse (Ruppenhofer et al., 2010) introduced a new issue w.r.t. the SemEval-2007 task ‘Frame Semantic Structure Extraction’ (Baker et al., 2007), in that it focused on linking local semantic argument structures across sentence boundaries. Specifically, the task included first the identification of frames and frame elements in a text following the FrameNet paradigm (Baker et al., 1998), then the identification of locally uninstantiated roles (NIs). If these roles are indefinite (INI), they have to be marked as such and no antecedent has to be found. On the contrary, if they are definite (DNI), their coreferents have to be found in the wider discourse context. The challenge comprised two tasks, namely the full task (semantic role recogn"
W11-0908,S10-1059,0,0.463373,"d with gold standard frame information. The participants had to i) assess if a local argument is implicit; ii) decide whether it is an INI or a DNI and iii) in the second case, find the antecedent of the implicit argument. We report in Table 1 some statistics about the provided data sets from Ruppenhofer et al. (2010). Note that overt FEs are the explicit frame elements annotated in the data set. Although 26 teams downloaded the data sets, there were only two submissions, probably depending on the intrinsic difficulties of the task (see dis57 cussion in Section 5). The best performing system (Chen et al., 2010) is based on a supervised learning approach using, among others, distributional semantic similarity between the heads of candidate referents and role fillers in the training data, but its performance is strongly affected by data sparseness. Indeed, only 438 sentences with annotated NIs were made available in the training set, which is clearly insufficient to capture such a multifaceted phenomenon with a supervised approach. The second system participating in the task (Tonelli and Delmonte, 2010) was an adaptation of an existing LFG-based system for deep semantic analysis (Delmonte, 2009), whos"
W11-0908,P10-1160,0,0.217117,"aluated on a data set, so we cannot directly compare its performance with other approaches. Furthermore, it is strongly domain-dependent. In a case study, Burchardt et al. (2005) propose to identify implicit arguments exploiting contextual relations from deep-parsing and lexico-semantic frame relations encoded in FrameNet. In particular, they suggest converting a text into a network of lexico-semantic predicate-argument relations connected through frame-to-frame relations and recurrent anaphoric linking patterns. However, the authors do not implement and evaluate this approach. Most recently, Gerber and Chai (2010) have presented a supervised classification model for the recovery of implicit arguments of nominal predicates in NomBank. The model features are quite different from those usually considered in standard SRL tasks and include among others information from VerbNet classes, pointwise mutual information between semantic arguments, collocation and frequency information about the predicates, information about parent nodes and siblings of the predicates and discourse information. The authors show the feasibility of their approach, which however relies on a selected group of nominal predicates with a"
W11-0908,P86-1004,0,0.882878,"gent is licensed by the passive construction: (3) One of them was suddenly shut off ∅. (4) I am reckoned fleet of foot ∅. Cases of INI were annotated by the organizers of the SemEval task 10 also with nominal predicates, as shown in the example below, where the perceiver of the odour is left unspecified: (5) Rank reeds and lush, slimy water-plants sent an odour ∅ of decay and a heavy miasmatic vapour. Few attempts have been done so far to automatically deal with the recovery of implicit information 56 in text. One of the earliest systems for identifying extra-sentential arguments is PUNDIT by Palmer et al. (1986). This Prolog-based system comprises a syntactic component for parsing, a semantic component, which decomposes predicates into component meanings and fills their semantic roles with syntactic constituents based on a domain-specific model, and a reference resolution component, which is called both for explicit constituents and for obligatory implicit constituents. The reference resolution process is based on a focus list with all potential pronominal referents identified by the semantic component. The approach, however, has not been evaluated on a data set, so we cannot directly compare its per"
W11-0908,J05-1004,0,0.120682,"ding whether an item is implicit or not, and on the other hand to precision problems, i.e. if an implicit entity is accessible to the reader from the discourse or its context, an appropriate antecedent has to be found. However, a system able to derive the presence of IEs may be a determining factor in improving performance of QA systems and, in general, in Informations Retrieval and Extraction systems. The current computational scene has witnessed an increased interest in the creation and use of semantically annotated computational lexica and their associated annotated corpora, like PropBank (Palmer et al., 2005), FrameNet (Baker et al., 1998) and NomBank (Meyers, 2007), where the proposed annotation scheme has been applied in real contexts. In all these cases, what has been addressed is a basic semantic issue, i.e. labeling PAS associated to semantic predicates like adjectives, verbs and nouns. However, what these corpora have not made available is information related to IEs. For example, in the case of eventive deverbal nominals, information about the subject/object of the nominal predicate is often implicit and has to be understood from the previous 54 Proceedings of the ACL 2011 Workshop on Relati"
W11-0908,S10-1008,0,0.738999,"ommitment, for example “I can promise ∅ that one of you will be troubled [→ unexpressed Addressee]” and “I dare swear ∅ that before tomorrow night he will be fluttering in our net [→ unexpressed Addressee]”. In this paper we discuss the issues related to the identification of implicit entities in text, focussing in particular on omissions of core arguments of predicates. We investigate the topic from the perspective proposed by (Fillmore, 1986) and base our observations on null instantiated arguments annotated for the SemEval 2010 Task 10, ‘Linking Events and Their Participants in Discourse’ (Ruppenhofer et al., 2010)2 . The paper is structured as follows: in Section 2 we detail the task of identifying null instantiated arguments from a theoretical perspective and describe related work. In Section 3 we briefly introduce the SemEval task 10 for identifying implicit arguments in text, while in Section 4 we detail our proposal for NI identification and binding. In Section 5 we give a thorough description of the types of null instantiations annotated in the SemEval data set and we explain the behavior of our algorithm w.r.t. such cases. We also compare our results with the output of the systems participating t"
W11-0908,S10-1065,1,0.681685,"ding on the intrinsic difficulties of the task (see dis57 cussion in Section 5). The best performing system (Chen et al., 2010) is based on a supervised learning approach using, among others, distributional semantic similarity between the heads of candidate referents and role fillers in the training data, but its performance is strongly affected by data sparseness. Indeed, only 438 sentences with annotated NIs were made available in the training set, which is clearly insufficient to capture such a multifaceted phenomenon with a supervised approach. The second system participating in the task (Tonelli and Delmonte, 2010) was an adaptation of an existing LFG-based system for deep semantic analysis (Delmonte, 2009), whose output was mapped to FrameNet-style annotation. In this case, the major challenge was to cope with the classification of some NI phenomena which are very much dependent on frame specific information, and can hardly be generalized in the LFG framework. 4 A linguistically motivated proposal for NI identification and binding In this section, we describe our proposal for dealing with INI/DNI identification and evaluate our output against SemEval gold standard data. As discussed in the previous sec"
W11-0908,H86-1011,0,\N,Missing
W11-0908,C98-1013,0,\N,Missing
W13-1201,W11-0103,0,0.0466959,"Missing"
W13-1201,I05-2035,0,0.0433561,"Missing"
W13-1201,W02-1502,0,0.0315673,"Missing"
W13-1201,W08-2205,0,0.0606685,"Missing"
W13-1201,E09-1001,0,0.0539298,"Missing"
W13-1201,W07-1408,1,0.656893,"Missing"
W13-1201,N06-1024,0,0.0292872,"Missing"
W13-1201,W07-2416,0,0.0270569,"Missing"
W13-1201,P01-1042,0,0.0267835,"Missing"
W13-1201,H94-1020,0,0.114953,"Missing"
W13-1201,C08-1095,0,0.050421,"Missing"
W13-1201,C10-2158,0,0.0355089,"Missing"
W13-1201,W11-0908,1,0.799174,"Missing"
W13-1201,W08-2223,1,\N,Missing
W13-1201,P11-2037,0,\N,Missing
W13-1201,1991.iwpt-1.8,0,\N,Missing
W13-1201,W06-2302,1,\N,Missing
W13-1201,W99-0501,0,\N,Missing
W15-0708,P85-1034,0,0.773304,"Missing"
W15-0708,E14-2019,1,0.707132,"ey consonances or assonances; it may attract our attention for its structure of meaning, organized on a coherent lattice of anaphoric and coreferential links or suggested and extracted from inferential and metaphorical links to symbolic meanings obtained by a variety of rhetorical devices. Most if not all of these facets of a poem are derived from the analysis of SPARSAR, the system for poetry analysis which has been presented to a number of international conferences (Delmonte 2013a; 2013b; 2014) - and to Demo sessions in its TextToSpeech “expressive reading” version (Delmonte & Bacalu, 2012; Delmonte & Prati, 2014; Delmonte, 2015). Most of a poem&apos;s content can be captured considering three basic views on the poem itself: one that covers what can be called the overall sound pattern of the poem - and this is related to the phonetics and the phonology of the words contained in the poem - Phonetic Relational View. Another view is the one that captures the main poetic devices related to rhythm, that is the rhyme structure and the metrical structure - this view will be called Poetic Relational View. Finally, the semantic and pragmatic contents of the poem which are related to relations entertained by predica"
W15-0708,D10-1016,0,0.0481156,"Missing"
W15-0708,W10-0304,0,0.0681859,"Missing"
W15-0708,D10-1051,0,0.0550409,"Missing"
W15-0708,W12-2502,0,0.0379015,"Missing"
W15-0708,W11-0611,0,0.0579043,"Missing"
W15-0708,P11-2064,0,0.0715711,"Missing"
W15-0708,P11-2014,0,0.0251978,"rs quote the first line of what could be a normal limerick but totally misinterpret the metrical structure. In limericks, what we are dealing with are not dactyls - TAtata but anapests, tataTA, that is a sequence of two unstressed plus a closing stressed syllable. This is a well known characteristic feature of limericks and the typical rhythm is usually preceded and introduced by a iamb ""there ONCE"", and followed by two anapests, ""was a MAN"", ""from maDRAS"". Here in particular it is the syntactic-semantic phrase that determines the choice of foot, and not the scansion provided by the authors5. Reddy & Knight (2011) produce an unsupervised machine learning algorithm for finding rhyme schemes which is intended to be language-independent. It works on the intuition that ""a collection of rhyming poetry inevitably contains repetition of rhyming pairs. ... This is partly due to sparsity of rhymes – many words that have no rhymes at all, and many others have only a handful, forcing poets to reuse rhyming pairs."" The authors harness this repetition to build an unsupervised algorithm to infer rhyme schemes, based on a model of stanza generation. ""We test the algorithm on rhyming poetry in English and French.” The"
W15-0708,W13-2121,0,\N,Missing
W15-2704,J90-3003,0,0.534599,"Missing"
W15-2704,P98-1024,0,0.123253,"Missing"
W15-2704,W04-2005,1,0.589023,"Missing"
W15-2704,W07-1408,1,0.861322,"Missing"
W15-2704,S10-1065,1,0.896135,"Missing"
W15-2704,W11-0908,1,0.869796,"Missing"
W15-2704,W13-1201,1,0.904696,"Missing"
W15-2704,P98-2155,0,0.0245062,"Missing"
W15-2704,E14-2019,1,0.891157,"Missing"
W15-2704,W15-0708,1,0.879841,"Missing"
W15-2704,W97-1204,0,0.221163,"Missing"
W15-2704,P98-2165,0,0.260141,"Missing"
W15-2704,W99-0619,0,0.0732632,"Missing"
W15-2704,C98-2160,0,\N,Missing
W15-2704,C98-2150,0,\N,Missing
W16-4108,W01-0521,0,0.0613082,"processing is thus highly flawed by the grammatically incomplete structures produced by data-driven dependency parsers. An important factor that determines levels of complexity in linguistic data are presence of noncanonical structures which in some languages and some domains are almost negligible, as for instance English in the corpus constituted by WSJ news – see below. But when we move to the BROWN corpus the presence of such structures is important and determines a decrease in accuracy and a drop in performance that can range from 6 to 8 points (See McClosky et al. 2010, Hara et al. 2010, Gildea 2001). Italian on the contrary is very rich on such non-canonical structures including discontinuities of all sorts, but as before some genre or domain has more than others. The paper is organized into two main sections, the following one, section 2 devoted to performance related cases of complexity where we take the stance to use LFG theory and Parsing Strategies to explain ambiguity in the data. We will then present results of a study carried out on non-canonical Italian sentences as they have been treated by most well-known parsers of Italian. In this section we will then show results from an ex"
W16-4108,P15-1038,0,0.0437229,"Missing"
W16-4108,W13-3720,0,0.0604217,"Missing"
W16-4108,J93-2004,0,0.054629,"Missing"
W16-4108,W07-2202,0,\N,Missing
W16-4108,N10-1004,0,\N,Missing
W17-6906,W17-7402,1,0.461814,"gh level features, the meta-tags, are uncertainty, subjectivity and judgement. Additionally, we annotated with the element negative all negative forms in the novel. Table 3 illustrates the hierarchy of the various features, with the attributes represented in italics and the values in normal text. 4 . 3 The 1st Workshop on EVENTS: Definition, Detection, Coreference, and Representation, HLT-NAACL, Atlanta We omit comments on the features because all detailed information about semantic features annotation are reported in a companion paper by the same authors in a workshop in this conference (see Delmonte and Marchesini (2017)) 4 Uncertainty Non-factual Seeming Gnomic Concessive Conditional DefDesire Will Possibility Ability Obligation Assumption Subjectivity Psychology Perception Precognition Cognition PerformWill Affect-emot Positive/Negative Affect-inclin Positive/Negative Affect-secur Positive/Negative Affect-satisf Positive/Negative Judgement Social-esteem Positive/Negative Social-sanction Positive/Negative Table 3: Hierarchy of deep semantic features used in the annotation Narreme length and number of annotations are both markers signaling importance. Even without a complex analysis, it is apparent that some"
W17-6906,D10-1008,0,0.0864806,"Missing"
W17-6906,J95-2003,0,0.333562,"ashbacks. The module looking for narremes tries to individuate their boundaries, taking as input the analysis of the text at a syntactic and semantic level. To evaluate results, it makes use of the ranges of all narremes as they were manually identified through start and sentence numbers. More in detail, the input is made of the following semantic information: - the list of entities evaluated as main, secondary and potential topics of discourse by the specialized centering algorithm with Topic Hierarchy, which works on the output of the anaphora resolution modules (see Grosz and Sidner (1986) Grosz et al. (1995)); - the list of discourse structures computed one for each clause, containing information on discourse moves, relations and main predicates in each clause. At first the algorithm creates clusters of clauses around each entity in a sequence; it then keeps only the ones constituting frequently mentioned entities, or characters of the story. It eventually extracts another subset of clauses, this time characterized by the fact that the main predicate is included in a list of speech acts – verbs like ""decide"", ""discover"" etc., and those introducing direct discourse like ""say"", ""ask"", ""tell"" etc. C"
W17-6906,J86-3001,0,0.520714,"l coordinates through flashbacks. The module looking for narremes tries to individuate their boundaries, taking as input the analysis of the text at a syntactic and semantic level. To evaluate results, it makes use of the ranges of all narremes as they were manually identified through start and sentence numbers. More in detail, the input is made of the following semantic information: - the list of entities evaluated as main, secondary and potential topics of discourse by the specialized centering algorithm with Topic Hierarchy, which works on the output of the anaphora resolution modules (see Grosz and Sidner (1986) Grosz et al. (1995)); - the list of discourse structures computed one for each clause, containing information on discourse moves, relations and main predicates in each clause. At first the algorithm creates clusters of clauses around each entity in a sequence; it then keeps only the ones constituting frequently mentioned entities, or characters of the story. It eventually extracts another subset of clauses, this time characterized by the fact that the main predicate is included in a list of speech acts – verbs like ""decide"", ""discover"" etc., and those introducing direct discourse like ""say"","
W17-6906,J97-1003,0,0.415733,"by loading system output for a given section of the novel and then the sentence range associated to each narreme as computed manually in order to make evaluation possible. Then it loads the structures of each clause computed at discourse level which are made up 6 Our method is different from previous attempts at text segmentation, but is also similar in some aspects. It is different from plot-units segmentation proposed by Lehnert (1995) and lately by Goyal et al. (2010) which is solely based on affect and mental states of characters. It is different from Topic based segmentation purported by Hearst (1997) in its TextTiling system, and lately attempted in literary texts by Kazantseva and Szpakowicz (2012), because topics alone are not sufficient cue for our novel. It is also different from the approach proposed in Swanson et al. (2014) where the authors elaborate an annotation scheme at clause-level with an analysis based on Labov (1997) which distinguishes three types of clauses for narrative labeling: Action, Orientation and Evaluation. These are then used to create plot units by a SentenceNumber, a ClauseNumber, the main verbal predicate, the Relevance computed and the Discourse Move. As a s"
W17-6906,W14-4323,0,0.272041,"t discourse level which are made up 6 Our method is different from previous attempts at text segmentation, but is also similar in some aspects. It is different from plot-units segmentation proposed by Lehnert (1995) and lately by Goyal et al. (2010) which is solely based on affect and mental states of characters. It is different from Topic based segmentation purported by Hearst (1997) in its TextTiling system, and lately attempted in literary texts by Kazantseva and Szpakowicz (2012), because topics alone are not sufficient cue for our novel. It is also different from the approach proposed in Swanson et al. (2014) where the authors elaborate an annotation scheme at clause-level with an analysis based on Labov (1997) which distinguishes three types of clauses for narrative labeling: Action, Orientation and Evaluation. These are then used to create plot units by a SentenceNumber, a ClauseNumber, the main verbal predicate, the Relevance computed and the Discourse Move. As a second element of the computation, the algorithm loads all topics as they have been computed by the coreference module and the topic hierarchy module. Topics are collected by their Semantic unique Identifier in the Discourse Model, the"
W17-7402,W17-6906,1,0.481838,"on scheme. ""The Solid Mandala"" is a particularly interesting sample for analysis because of the peculiarity of its structure and of its style. It is in fact divided into four distinct sections, each written as if through the eyes of one of the main characters. Using such a narrative as a starting point, we aim in the future to expand the limitations of the current annotation system, which is now partly tailored to the novel, to include many other kinds of narrative texts. This will be made possible by the collected annotations in a lexicon where head words are associated to their lemmata (see Delmonte and Marchesini (2017)). In our case, White’s style always maintains internal consistency, but it does so adapting its qualifying linguistic elements according to the lens of the narrating point of view – there are three main characters, and each of them is tasked with narrating a portion of the same story. Other elements impacting linguistic features are the nature of the relationships between the characters and the specificity of the events in their lives, and all of them are considered in the evaluation of the annotation. As for the elements chosen for analysis, we started from semantic features connected to psy"
W17-7402,W12-2502,0,0.185317,"and Grieve (2004)). This theory emphasizes the relevance of impressions and judgements in the formation of feelings, emotions, and complex thoughts. Environment and psychology are here understood as being in a relation of mutual dependency, with the reactions of each individual to stimuli evoking different responses. Since we are talking about a novel, this system is of course artificial and created by the author. From a general standpoint we can say that judgement and the above-mentioned affect have a lot in common, both dealing with indices of emotion and sentiment (see Kim and Hovy (2004), Kao and Jurafsky (2012). In this specific study, however, it was decided to annotate judgement as an independent element for two main reasons: firstly in order to stress our interest in evaluative language, and secondly in order to allow a more detailed internal differentiation between the attributes of social-esteem (personal dimension, e.g. appreciated/unappreciated) and socialsanction (social dimension, e.g. allowed/forbidden). A more detailed description of attributes and values follows. 2.2 Features in Detail: Uncertainty <uncertnty non-factual= ""seeming""&gt; Seeming is the probably the most representative of all"
W17-7402,C04-1200,0,0.101837,"rrol (2012), Taboada and Grieve (2004)). This theory emphasizes the relevance of impressions and judgements in the formation of feelings, emotions, and complex thoughts. Environment and psychology are here understood as being in a relation of mutual dependency, with the reactions of each individual to stimuli evoking different responses. Since we are talking about a novel, this system is of course artificial and created by the author. From a general standpoint we can say that judgement and the above-mentioned affect have a lot in common, both dealing with indices of emotion and sentiment (see Kim and Hovy (2004), Kao and Jurafsky (2012). In this specific study, however, it was decided to annotate judgement as an independent element for two main reasons: firstly in order to stress our interest in evaluative language, and secondly in order to allow a more detailed internal differentiation between the attributes of social-esteem (personal dimension, e.g. appreciated/unappreciated) and socialsanction (social dimension, e.g. allowed/forbidden). A more detailed description of attributes and values follows. 2.2 Features in Detail: Uncertainty <uncertnty non-factual= ""seeming""&gt; Seeming is the probably the mo"
W17-7402,P04-1035,0,0.0133989,"tive Affect-secur Positive/Negative Affect-satisf Positive/Negative Judgement Social-esteem Positive/Negative Social-sanction Positive/Negative Table 2: Hierarchy of deep semantic features used in the annotation as uncertnty in the annotation, has only one obligatory attribute: non-factual (see Sauri and Pustejovsky (2012)). It is in fact crucial in this case to establish the annotated expression as non-real, non-factual, as something that is only going on in the character’s mind and which does not have an equivalent in the ’real world’ of the story. ""Subjectivity"" (see Taboada et al. (2011), Pang and Lee (2004)) focuses instead on various facets of character psychology. The main difference between uncertainty and subjectivity lies in the fact that the first category is about how the protagonists rationalize their reality, while the second marks the modalities in which they actively and subjectively contribute to the narrative. The former is non-factual in nature, but the latter always has consequences. Subjectivity includes active psychological processes both conscious and unconscious as studied by the cognitive sciences, as well as expressions of emotion and different kinds of feelings. These sub-c"
W17-7402,J12-2002,0,0.015977,"eventually we passed from 124 narremes of Collier to 131 Uncertainty Non-factual Seeming Gnomic Concessive Conditional DefDesire Will Possibility Ability Obligation Assumption Subjectivity Psychology Perception Precognition Cognition PerformWill Affect-emot Positive/Negative Affect-inclin Positive/Negative Affect-secur Positive/Negative Affect-satisf Positive/Negative Judgement Social-esteem Positive/Negative Social-sanction Positive/Negative Table 2: Hierarchy of deep semantic features used in the annotation as uncertnty in the annotation, has only one obligatory attribute: non-factual (see Sauri and Pustejovsky (2012)). It is in fact crucial in this case to establish the annotated expression as non-real, non-factual, as something that is only going on in the character’s mind and which does not have an equivalent in the ’real world’ of the story. ""Subjectivity"" (see Taboada et al. (2011), Pang and Lee (2004)) focuses instead on various facets of character psychology. The main difference between uncertainty and subjectivity lies in the fact that the first category is about how the protagonists rationalize their reality, while the second marks the modalities in which they actively and subjectively contribute"
W17-7402,J11-2001,0,0.0169781,"ct-inclin Positive/Negative Affect-secur Positive/Negative Affect-satisf Positive/Negative Judgement Social-esteem Positive/Negative Social-sanction Positive/Negative Table 2: Hierarchy of deep semantic features used in the annotation as uncertnty in the annotation, has only one obligatory attribute: non-factual (see Sauri and Pustejovsky (2012)). It is in fact crucial in this case to establish the annotated expression as non-real, non-factual, as something that is only going on in the character’s mind and which does not have an equivalent in the ’real world’ of the story. ""Subjectivity"" (see Taboada et al. (2011), Pang and Lee (2004)) focuses instead on various facets of character psychology. The main difference between uncertainty and subjectivity lies in the fact that the first category is about how the protagonists rationalize their reality, while the second marks the modalities in which they actively and subjectively contribute to the narrative. The former is non-factual in nature, but the latter always has consequences. Subjectivity includes active psychological processes both conscious and unconscious as studied by the cognitive sciences, as well as expressions of emotion and different kinds of"
