2021.wanlp-1.10,"The Interplay of Variant, Size, and Task Type in {A}rabic Pre-trained Language Models",2021,-1,-1,4,0,513,go inoue,Proceedings of the Sixth Arabic Natural Language Processing Workshop,0,"In this paper, we explore the effects of language variants, data sizes, and fine-tuning task types in Arabic pre-trained language models. To do so, we build three pre-trained language models across three variants of Arabic: Modern Standard Arabic (MSA), dialectal Arabic, and classical Arabic, in addition to a fourth language model which is pre-trained on a mix of the three. We also examine the importance of pre-training data size by building additional models that are pre-trained on a scaled-down set of the MSA variant. We compare our different models to each other, as well as to eight publicly available models by fine-tuning them on five NLP tasks spanning 12 datasets. Our results suggest that the variant proximity of pre-training data to fine-tuning data is more important than the pre-training data size. We exploit this insight in defining an optimized system selection model for the studied tasks."
2021.wanlp-1.28,{NADI} 2021: The Second Nuanced {A}rabic Dialect Identification Shared Task,2021,-1,-1,4,0.119269,487,muhammad abdulmageed,Proceedings of the Sixth Arabic Natural Language Processing Workshop,0,"We present the findings and results of theSecond Nuanced Arabic Dialect IdentificationShared Task (NADI 2021). This Shared Taskincludes four subtasks: country-level ModernStandard Arabic (MSA) identification (Subtask1.1), country-level dialect identification (Subtask1.2), province-level MSA identification (Subtask2.1), and province-level sub-dialect identifica-tion (Subtask 2.2). The shared task dataset cov-ers a total of 100 provinces from 21 Arab coun-tries, collected from the Twitter domain. A totalof 53 teams from 23 countries registered to par-ticipate in the tasks, thus reflecting the interestof the community in this area. We received 16submissions for Subtask 1.1 from five teams, 27submissions for Subtask 1.2 from eight teams,12 submissions for Subtask 2.1 from four teams,and 13 Submissions for subtask 2.2 from fourteams."
2021.finnlp-1.1,An Exploration of Automatic Text Summarization of Financial Reports,2021,-1,-1,2,0,6353,samir abdaljalil,Proceedings of the Third Workshop on Financial Technology and Natural Language Processing,0,None
2020.wanlp-1.9,{NADI} 2020: The First Nuanced {A}rabic Dialect Identification Shared Task,2020,-1,-1,3,0.119269,487,muhammad abdulmageed,Proceedings of the Fifth Arabic Natural Language Processing Workshop,0,"We present the results and findings of the First Nuanced Arabic Dialect Identification Shared Task (NADI). This Shared Task includes two subtasks: country-level dialect identification (Subtask 1) and province-level sub-dialect identification (Subtask 2). The data for the shared task covers a total of 100 provinces from 21 Arab countries and is collected from the Twitter domain. As such, NADI is the first shared task to target naturally-occurring fine-grained dialectal text at the sub-country level. A total of 61 teams from 25 countries registered to participate in the tasks, thus reflecting the interest of the community in this area. We received 47 submissions for Subtask 1 from 18 teams and 9 submissions for Subtask 2 from 9 teams."
2020.lrec-1.508,A Spelling Correction Corpus for Multiple {A}rabic Dialects,2020,-1,-1,3,0.882353,544,fadhl eryani,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Arabic dialects are the non-standard varieties of Arabic commonly spoken {--} and increasingly written on social media {--} across the Arab world. Arabic dialects do not have standard orthographies, a challenge for natural language processing applications. In this paper, we present the MADAR CODA Corpus, a collection of 10,000 sentences from five Arabic city dialects (Beirut, Cairo, Doha, Rabat, and Tunis) represented in the Conventional Orthography for Dialectal Arabic (CODA) in parallel with their raw original form. The sentences come from the Multi-Arabic Dialect Applications and Resources (MADAR) Project and are in parallel across the cities (2,000 sentences from each city). This publicly available resource is intended to support research on spelling correction and text normalization for Arabic dialects. We present results on a bootstrapping technique we use to speed up the CODA annotation, as well as on the degree of similarity across the dialects before and after CODA annotation."
2020.gebnlp-1.12,Gender-Aware Reinflection using Linguistically Enhanced Neural Models,2020,-1,-1,3,0,514,bashar alhafni,Proceedings of the Second Workshop on Gender Bias in Natural Language Processing,0,"In this paper, we present an approach for sentence-level gender reinflection using linguistically enhanced sequence-to-sequence models. Our system takes an Arabic sentence and a given target gender as input and generates a gender-reinflected sentence based on the target gender. We formulate the problem as a user-aware grammatical error correction task and build an encoder-decoder architecture to jointly model reinflection for both masculine and feminine grammatical genders. We also show that adding linguistic features to our model leads to better reinflection results. The results on a blind test set using our best system show improvements over previous work, with a 3.6{\%} absolute increase in M2 F0.5."
W19-5512,The {F}in{SBD}-2019 Shared Task: Sentence Boundary Detection in {PDF} Noisy Text in the Financial Domain,2019,-1,-1,2,0,6348,abderrahim azzi,Proceedings of the First Workshop on Financial Technology and Natural Language Processing,0,None
W19-4622,The {MADAR} Shared Task on {A}rabic Fine-Grained Dialect Identification,2019,0,3,1,1,516,houda bouamor,Proceedings of the Fourth Arabic Natural Language Processing Workshop,0,"In this paper, we present the results and findings of the MADAR Shared Task on Arabic Fine-Grained Dialect Identification. This shared task was organized as part of The Fourth Arabic Natural Language Processing Workshop, collocated with ACL 2019. The shared task includes two subtasks: the MADAR Travel Domain Dialect Identification subtask (Subtask 1) and the MADAR Twitter User Dialect Identification subtask (Subtask 2). This shared task is the first to target a large set of dialect labels at the city and country levels. The data for the shared task was created or collected under the Multi-Arabic Dialect Applications and Resources (MADAR) project. A total of 21 teams from 15 countries participated in the shared task."
W19-4214,A Little Linguistics Goes a Long Way: Unsupervised Segmentation with Limited Language Specific Guidance,2019,0,0,5,0,1306,alexander erdmann,"Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"We present de-lexical segmentation, a linguistically motivated alternative to greedy or other unsupervised methods, requiring only minimal language specific input. Our technique involves creating a small grammar of closed-class affixes which can be written in a few hours. The grammar over generates analyses for word forms attested in a raw corpus which are disambiguated based on features of the linguistic base proposed for each form. Extending the grammar to cover orthographic, morpho-syntactic or lexical variation is simple, making it an ideal solution for challenging corpora with noisy, dialect-inconsistent, or otherwise non-standard content. In two evaluations, we consistently outperform competitive unsupervised baselines and approach the performance of state-of-the-art supervised models trained on large amounts of data, providing evidence for the value of linguistic input during preprocessing."
W19-3822,Automatic Gender Identification and Reinflection in {A}rabic,2019,0,2,2,0,517,nizar habash,Proceedings of the First Workshop on Gender Bias in Natural Language Processing,0,"The impressive progress in many Natural Language Processing (NLP) applications has increased the awareness of some of the biases these NLP systems have with regards to gender identities. In this paper, we propose an approach to extend biased single-output gender-blind NLP systems with gender-specific alternative reinflections. We focus on Arabic, a gender-marking morphologically rich language, in the context of machine translation (MT) from English, and for first-person-singular constructions only. Our contributions are the development of a system-independent gender-awareness wrapper, and the building of a corpus for training and evaluating first-person-singular gender identification and reinflection in Arabic. Our results successfully demonstrate the viability of this approach with 8{\%} relative increase in Bleu score for first-person-singular feminine, and 5.3{\%} comparable increase for first-person-singular masculine on top of a state-of-the-art gender-blind MT system on a held-out test set."
N19-4002,{ADIDA}: Automatic Dialect Identification for {A}rabic,2019,0,0,3,1,18329,ossama obeid,Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations),0,"This demo paper describes ADIDA, a web-based system for automatic dialect identification for Arabic text. The system distinguishes among the dialects of 25 Arab cities (from Rabat to Muscat) in addition to Modern Standard Arabic. The results are presented with either a point map or a heat map visualizing the automatic identification probabilities over a geographical map of the Arab World."
L18-1415,{MADAR}i: A Web Interface for Joint {A}rabic Morphological Annotation and Spelling Correction,2018,0,0,4,1,18329,ossama obeid,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1535,The {MADAR} {A}rabic Dialect Corpus and Lexicon,2018,0,9,1,1,516,houda bouamor,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1574,Unified Guidelines and Resources for {A}rabic Dialect Orthography,2018,-1,-1,9,0,517,nizar habash,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-1113,Fine-Grained {A}rabic Dialect Identification,2018,0,5,2,1,25950,mohammad salameh,Proceedings of the 27th International Conference on Computational Linguistics,0,"Previous work on the problem of Arabic Dialect Identification typically targeted coarse-grained five dialect classes plus Standard Arabic (6-way classification). This paper presents the first results on a fine-grained dialect classification task covering 25 specific cities from across the Arab World, in addition to Standard Arabic {--} a very challenging task. We build several classification systems and explore a large space of features. Our results show that we can identify the exact city of a speaker at an accuracy of 67.9{\%} for sentences with an average length of 7 words (a 9{\%} relative error reduction over the state-of-the-art technique for Arabic dialect identification) and reach more than 90{\%} when we consider 16 words. We also report on additional insights from a data analysis of similarity and difference across Arabic dialects."
W16-4115,Using Ambiguity Detection to Streamline Linguistic Annotation,2016,0,1,4,0.745439,579,wajdi zaghouani,Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity ({CL}4{LC}),0,"Arabic writing is typically underspecified for short vowels and other markups, referred to as diacritics. In addition to the lexical ambiguity exhibited in most languages, the lack of diacritics in written Arabic adds another layer of ambiguity which is an artifact of the orthography. In this paper, we present the details of three annotation experimental conditions designed to study the impact of automatic ambiguity detection, on annotation speed and quality in a large scale annotation project."
N16-1125,Eyes Don{'}t Lie: Predicting Machine Translation Quality Using Eye Movement,2016,17,3,5,0,3156,hassan sajjad,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
L16-1175,{DALILA}: The Dialectal {A}rabic Linguistic Learning Assistant,2016,20,0,2,0.530303,1362,salam khalifa,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Dialectal Arabic (DA) poses serious challenges for Natural Language Processing (NLP). The number and sophistication of tools and datasets in DA are very limited in comparison to Modern Standard Arabic (MSA) and other languages. MSA tools do not effectively model DA which makes the direct use of MSA NLP tools for handling dialects impractical. This is particularly a challenge for the creation of tools to support learning Arabic as a living language on the web, where authentic material can be found in both MSA and DA. In this paper, we present the Dialectal Arabic Linguistic Learning Assistant (DALILA), a Chrome extension that utilizes cutting-edge Arabic dialect NLP research to assist learners and non-native speakers in understanding text written in either MSA or DA. DALILA provides dialectal word analysis and English gloss corresponding to each word."
L16-1295,Building an {A}rabic Machine Translation Post-Edited Corpus: Guidelines and Annotation,2016,0,5,5,0.745439,579,wajdi zaghouani,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We present our guidelines and annotation procedure to create a human corrected machine translated post-edited corpus for the Modern Standard Arabic. Our overarching goal is to use the annotated corpus to develop automatic machine translation post-editing systems for Arabic that can be used to help accelerate the human revision process of translated texts. The creation of any manually annotated corpus usually presents many challenges. In order to address these challenges, we created comprehensive and simplified annotation guidelines which were used by a team of five annotators and one lead annotator. In order to ensure a high annotation agreement between the annotators, multiple training sessions were held and regular inter-annotator agreement measures were performed to check the annotation quality. The created corpus of manual post-edited translations of English to Arabic articles is the largest to date for this language pair."
L16-1577,Guidelines and Framework for a Large Scale {A}rabic Diacritized Corpus,2016,19,6,2,0.745439,579,wajdi zaghouani,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents the annotation guidelines developed as part of an effort to create a large scale manually diacritized corpus for various Arabic text genres. The target size of the annotated corpus is 2 million words. We summarize the guidelines and describe issues encountered during the training of the annotators. We also discuss the challenges posed by the complexity of the Arabic language and how they are addressed. Finally, we present the diacritization annotation procedure and detail the quality of the resulting annotations."
C16-1132,Machine Translation Evaluation for {A}rabic using Morphologically-enriched Embeddings,2016,31,2,2,0,7331,francisco guzman,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Evaluation of machine translation (MT) into morphologically rich languages (MRL) has not been well studied despite posing many challenges. In this paper, we explore the use of embeddings obtained from different levels of lexical and morpho-syntactic linguistic analysis and show that they improve MT evaluation into an MRL. Specifically we report on Arabic, a language with complex and rich morphology. Our results show that using a neural-network model with different input representations produces results that clearly outperform the state-of-the-art for MT evaluation into Arabic, by almost over 75{\%} increase in correlation with human judgments on pairwise MT evaluation quality task. More importantly, we demonstrate the usefulness of morpho-syntactic representations to model sentence similarity for MT evaluation and address complex linguistic phenomena of Arabic."
W15-3204,The Second {QALB} Shared Task on Automatic Text Correction for {A}rabic,2015,-1,-1,2,0,8356,alla rozovskaya,Proceedings of the Second Workshop on {A}rabic Natural Language Processing,0,None
W15-3209,A Pilot Study on {A}rabic Multi-Genre Corpus Diacritization,2015,13,6,1,1,516,houda bouamor,Proceedings of the Second Workshop on {A}rabic Natural Language Processing,0,"Arabic script writing is typically underspecified for short vowels and other mark up, referred to as diacritics. Apart from the lexical ambiguity found in words, similar to that exhibited in other languages, the lack of diacritics in written Arabic script adds another layer of ambiguity which is an artifact of the orthography. Diacritization of written text has a significant impact on Arabic NLP applications. In this paper, we present a pilot study on building a diacritized multi-genre corpus in Arabic. We annotate a sample of nondiacritized words extracted from five text genres. We explore different annotation strategies: Basic where we present only the bare undiacritized forms to the annotators, Intermediate (Basic formstheir POS tags), and Advanced (automatically diacritized words). We present the impact of the annotation strategy on annotation quality. Moreover, we study different diacritization schemes in the process."
W15-3217,{QCMUQ}@{QALB}-2015 Shared Task: Combining Character level {MT} and Error-tolerant Finite-State Recognition for {A}rabic Spelling Correction,2015,23,3,1,1,516,houda bouamor,Proceedings of the Second Workshop on {A}rabic Natural Language Processing,0,"We describe the CMU-Q and QCRIxe2x80x99s joint efforts in building a spelling correction system for Arabic in the QALB 2015 Shared Task. Our system is based on a hybrid pipeline that combines rule-based linguistic techniques with statistical methods using language modeling and machine translation, as well as an error-tolerant finite-state automata method. We trained and tested our spelling corrector using the dataset provided by the shared task organizers. Our system outperforms the baseline system and yeilds better correction quality with an F-score of 68.12 on L1test-2015 testset and 38.90 on the L2-test2015. This ranks us 2nd in the L2 subtask and 5th in the L1 subtask."
W15-3221,{UMMU}@{QALB}-2015 Shared Task: Character and Word level {SMT} pipeline for Automatic Error Correction of {A}rabic Text,2015,22,4,2,0,13777,fethi bougares,Proceedings of the Second Workshop on {A}rabic Natural Language Processing,0,"In this paper we present the LIUM (Laboratoire dxe2x80x99Informatique de lxe2x80x99Universit du Maine) and CMU-Q (Carnegie Mellon University in Qatar) joint submission in the Arabic shared task on automatic spelling error correction. Our best system is a sequential combination of two statistical machine translation systems (SMT) trained on top of the MADAMIRA output. The first is a Character-based one, used to produce a first correction at the character level. Characters are then glued to form the input to the second system working at the Word level. This sequential combination achieves an F1 score of (69.42) that is better than the best F1 score reported on the 2014 test set (67.91). The UMMU best submission to the QALB-15 shared task is ranked first over 10 submission on the L2 test condition and second over 12 submission on the L1 testsset."
W15-1614,Correction Annotation for Non-Native {A}rabic Texts: Guidelines and Corpus,2015,30,15,3,0.745439,579,wajdi zaghouani,Proceedings of The 9th Linguistic Annotation Workshop,0,"We present our correction annotation guidelines to create a manually corrected nonnative (L2) Arabic corpus. We develop our approach by extending an L1 large-scale Arabic corpus and its manual corrections, to include manually corrected non-native Arabic learner essays. Our overarching goal is to use the annotated corpus to develop components for automatic detection and correction of language errors that can be used to help Standard Arabic learners (native and non-native) improve the quality of the Arabic text they produce. The created corpus of L2 text manual corrections is the largest to date. We evaluate our guidelines using inter-annotator agreement and show a high degree of consistency."
W14-3618,{CMUQ}@{QALB}-2014: An {SMT}-based System for Automatic {A}rabic Error Correction,2014,22,5,2,0,23961,serena jeblee,Proceedings of the {EMNLP} 2014 Workshop on {A}rabic Natural Language Processing ({ANLP}),0,"In this paper, we describe the CMUQ system we submitted to The ANLP-QALB 2014 Shared Task on Automatic Text Correction for Arabic. Our system combines rule-based linguistic techniques with statistical language modeling techniques and machine translationbased methods. Our system outperforms the baseline and reaches an F-score of 65.42% on the test set of QALB corpus. This ranks us 3rd in the competition."
W14-3627,Domain and Dialect Adaptation for Machine Translation into {E}gyptian {A}rabic,2014,31,8,3,0,23961,serena jeblee,Proceedings of the {EMNLP} 2014 Workshop on {A}rabic Natural Language Processing ({ANLP}),0,"In this paper, we present a statistical machine translation system for English to Dialectal Arabic (DA), using Modern Standard Arabic (MSA) as a pivot. We create a core system to translate from English to MSA using a large bilingual parallel corpus. Then, we design two separate pathways for translation from MSA into DA: a two-step domain and dialect adaptation system and a one-step simultaneous domain and dialect adaptation system. Both variants of the adaptation systems are trained on a 100k sentence tri-parallel corpus of English, MSA, and Egyptian Arabic generated by a rule-based transformation. We test our systems on a held-out Egyptian Arabic test set from the 100k sentence corpus and we achieve our best performance using the two-step domain and dialect adaptation system with a BLEU score of 42.9."
S14-2028,{CMUQ}-Hybrid: Sentiment Classification By Feature Engineering and Parameter Tuning,2014,14,0,5,0,37814,kamla almannai,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,This paper describes the system we submitted to the SemEval-2014 shared task on sentiment analysis in Twitter. Our system is a hybrid combination of two system developed for a course project at CMUQatar. We use an SVM classifier and couple a set of features from one system with feature and parameter optimization framework from the second system. Most of the tuning and feature selection efforts were originally aimed at task-A of the shared task. We achieve an F-score of 84.4% for task-A and 62.71% for task-B and the systems are ranked 3rd and 29th respectively.
S14-2029,{CMUQ}@{Q}atar:Using Rich Lexical Features for Sentiment Analysis on {T}witter,2014,14,5,3,0,38957,sabih wasi,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"In this paper, we describe our system for the Sentiment Analysis of Twitter shared task in SemEval 2014. Our system uses an SVM classifier along with rich set of lexical features to detect the sentiment of a phrase within a tweet (Task-A) and also the sentiment of the whole tweet (TaskB). We start from the lexical features that were used in the 2013 shared tasks, we enhance the underlying lexicon and also introduce new features. We focus our feature engineering effort mainly on TaskA. Moreover, we adapt our initial framework and introduce new features for TaskB. Our system reaches weighted score of 87.11% in Task-A and 64.52% in Task-B. This places us in the 4th rank in the TaskA and 15th in the Task-B."
bouamor-etal-2014-multidialectal,A Multidialectal Parallel Corpus of {A}rabic,2014,23,39,1,1,516,houda bouamor,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The daily spoken variety of Arabic is often termed the colloquial or dialect form of Arabic. There are many Arabic dialects across the Arab World and within other Arabic speaking communities. These dialects vary widely from region to region and to a lesser extent from city to city in each region. The dialects are not standardized, they are not taught, and they do not have official status. However they are the primary vehicles of communication (face-to-face and recently, online) and have a large presence in the arts as well. In this paper, we present the first multidialectal Arabic parallel corpus, a collection of 2,000 sentences in Standard Arabic, Egyptian, Tunisian, Jordanian, Palestinian and Syrian Arabic, in addition to English. Such parallel data does not exist naturally, which makes this corpus a very valuable resource that has many potential applications such as Arabic dialect identification and machine translation."
salama-etal-2014-youdacc,{Y}ou{DACC}: the {Y}outube Dialectal {A}rabic Comment Corpus,2014,14,4,2,0,39708,ahmed salama,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper presents YOUDACC, an automatically annotated large-scale multi-dialectal Arabic corpus collected from user comments on Youtube videos. Our corpus covers different groups of dialects: Egyptian (EG), Gulf (GU), Iraqi (IQ), Maghrebi (MG) and Levantine (LV). We perform an empirical analysis on the crawled corpus and demonstrate that our location-based proposed method is effective for the task of dialect labeling."
D14-1026,A Human Judgement Corpus and a Metric for {A}rabic {MT} Evaluation,2014,25,5,1,1,516,houda bouamor,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We present a human judgments datasetand an adapted metric for evaluation ofArabic machine translation. Our mediumscaledataset is the first of its kind for Arabicwith high annotation quality. We usethe dataset to adapt the BLEU score forArabic. Our score (AL-BLEU) providespartial credits for stem and morphologicalmatchings of hypothesis and referencewords. We evaluate BLEU, METEOR andAL-BLEU on our human judgments corpusand show that AL-BLEU has the highestcorrelation with human judgments. Weare releasing the dataset and software tothe research community."
N13-1046,{D}udley {N}orth visits {N}orth {L}ondon: Learning When to Transliterate to {A}rabic,2013,16,7,2,0,17745,mahmoud azab,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We report the results of our work on automating the transliteration decision of named entities for English to Arabic machine translation. We construct a classification-based framework to automate this decision, evaluate our classifier both in the limited news and the diverse Wikipedia domains, and achieve promising accuracy. Moreover, we demonstrate a reduction of translation error and an improvement in the performance of an English-to-Arabic machine translation system."
I13-1031,{S}u{MT}: A Framework of Summarization and {MT},2013,21,1,1,1,516,houda bouamor,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We present a novel system combination of machine translation and text summarization which provides high quality summary translations superior to the baseline translation of the entire document. We first use supervised learning and build a classifier that predicts if the translation of a sentence has high or low translation quality. This is a reference-free estimation of MT quality which helps us to distinguish the subset of sentences which have better translation quality. We pair this classifier with a stateof-the-art summarization system to build an MT-aware summarization system. To evaluate summarization quality, we build a test set by summarizing a bilingual corpus. We evaluate the performance of our system with respect to both MT and summarization quality and, demonstrate that we can balance between improving MT quality and maintaining a decent summarization quality."
bouamor-etal-2012-contrastive,A contrastive review of paraphrase acquisition techniques,2012,20,3,1,1,516,houda bouamor,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper addresses the issue of what approach should be used for building a corpus of sententential paraphrases depending on one's requirements. Six strategies are studied: (1) multiple translations into a single language from another language; (2) multiple translations into a single language from different other languages; (3) multiple descriptions of short videos; (4) multiple subtitles for the same language; (5) headlines for similar news articles; and (6) sub-sentential paraphrasing in the context of a Web-based game. We report results on French for 50 paraphrase pairs collected for all these strategies, where corpora were manually aligned at the finest possible level to define oracle performance in terms of accessible sub-sentential paraphrases. The differences observed will be used as criteria for motivating the choice of a given approach before attempting to build a new paraphrase corpus."
F12-2015,Validation sur le Web de reformulations locales: application {\\`a} la Wikip{\\'e}dia (Assisted Rephrasing for {W}ikipedia Contributors through Web-based Validation) [in {F}rench],2012,0,0,1,1,516,houda bouamor,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
F12-2020,"Une {\\'e}tude en 3{D} de la paraphrase: types de corpus, langues et techniques (A Study of Paraphrase along 3 Dimensions : Corpus Types, Languages and Techniques) [in {F}rench]",2012,-1,-1,1,1,516,houda bouamor,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
E12-1073,Validation of sub-sentential paraphrases acquired from parallel monolingual corpora,2012,28,4,1,1,516,houda bouamor,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"The task of paraphrase acquisition from related sentences can be tackled by a variety of techniques making use of various types of knowledge. In this work, we make the hypothesis that their performance can be increased if candidate paraphrases can be validated using information that characterizes paraphrases independently of the set of techniques that proposed them. We implement this as a bi-class classification problem (i.e. paraphrase vs. not paraphrase), allowing any paraphrase acquisition technique to be easily integrated into the combination system. We report experiments on two languages, English and French, with 5 individual techniques on parallel monolingual parallel corpora obtained via multiple translation, and a large set of classification features including surface to contextual similarity measures. Relative improvements in F-measure close to 18% are obtained on both languages over the best performing techniques."
D12-1066,Generalizing Sub-sentential Paraphrase Acquisition across Original Signal Type of Text Pairs,2012,39,7,2,0,28247,aurelien max,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"This paper describes a study on the impact of the original signal (text, speech, visual scene, event) of a text pair on the task of both manual and automatic sub-sentential paraphrase acquisition. A corpus of 2,500 annotated sentences in English and French is described, and performance on this corpus is reported for an efficient system combination exploiting a large set of features for paraphrase recognition. A detailed quantified typology of sub-sentential paraphrases found in our corpus types is given."
W11-1602,Web-based Validation for Contextual Targeted Paraphrasing,2011,39,4,1,1,516,houda bouamor,Proceedings of the Workshop on Monolingual Text-To-Text Generation,0,"In this work, we present a scenario where contextual targeted paraphrasing of sub-sentential phrases is performed automatically to support the task of text revision. Candidate paraphrases are obtained from a preexisting repertoire and validated in the context of the original sentence using information derived from the Web. We report on experiments on French, where the original sentences to be rewritten are taken from a rewriting memory automatically extracted from the edit history of Wikipedia."
P11-2069,Monolingual Alignment by Edit Rate Computation on Sentential Paraphrase Pairs,2011,17,6,1,1,516,houda bouamor,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"In this paper, we present a novel way of tackling the monolingual alignment problem on pairs of sentential paraphrases by means of edit rate computation. In order to inform the edit rate, information in the form of subsentential paraphrases is provided by a range of techniques built for different purposes. We show that the tunable TER-PLUS metric from Machine Translation evaluation can achieve good performance on this task and that it can effectively exploit information coming from complementary sources."
2011.jeptalnrecital-long.33,Paraphrases et modifications locales dans l{'}historique des r{\\'e}visions de Wikip{\\'e}dia (Paraphrases and local changes in the revision history of {W}ikipedia),2011,-1,-1,2,0,35957,camille dutrey,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous analysons les modifications locales disponibles dans l{'}historique des r{\'e}visions de la version fran{\c{c}}aise de Wikip{\'e}dia. Nous d{\'e}finissons tout d{'}abord une typologie des modifications fond{\'e}e sur une {\'e}tude d{\'e}taill{\'e}e d{'}un large corpus de modifications. Puis, nous d{\'e}taillons l{'}annotation manuelle d{'}une partie de ce corpus afin d{'}{\'e}valuer le degr{\'e} de complexit{\'e} de la t{\^a}che d{'}identification automatique de paraphrases dans ce genre de corpus. Enfin, nous {\'e}valuons un outil d{'}identification de paraphrases {\`a} base de r{\`e}gles sur un sous-ensemble de notre corpus."
2011.jeptalnrecital-long.38,Combinaison d{'}informations pour l{'}alignement monolingue (Information combination for monolingual alignment),2011,-1,-1,1,1,516,houda bouamor,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous d{\'e}crivons une nouvelle m{\'e}thode d{'}alignement automatique de paraphrases d{'}{\'e}nonc{\'e}s. Nous utilisons des m{\'e}thodes d{\'e}velopp{\'e}es pr{\'e}c{\'e}demment afin de produire diff{\'e}rentes approches hybrides (hybridations). Ces diff{\'e}rentes m{\'e}thodes permettent d{'}acqu{\'e}rir des {\'e}quivalences textuelles {\`a} partir d{'}un corpus monolingue parall{\`e}le. L{'}hybridation combine des informations obtenues par diverses techniques : alignements statistiques, approche symbolique, fusion d{'}arbres syntaxiques et alignement bas{\'e} sur des distances d{'}{\'e}dition. Nous avons {\'e}valu{\'e} l{'}ensemble de ces r{\'e}sultats et nous constatons une am{\'e}lioration sur l{'}acquisition de paraphrases sous-phrastiques."
2010.jeptalnrecital-recital.5,Construction d{'}un corpus de paraphrases d{'}{\\'e}nonc{\\'e}s par traduction multiple multilingue,2010,-1,-1,1,1,516,houda bouamor,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. REncontres jeunes Chercheurs en Informatique pour le Traitement Automatique des Langues,0,"Les corpus de paraphrases {\`a} large {\'e}chelle sont importants dans de nombreuses applications de TAL. Dans cet article nous pr{\'e}sentons une m{\'e}thode visant {\`a} obtenir un corpus parall{\`e}le de paraphrases d{'}{\'e}nonc{\'e}s en fran{\c{c}}ais. Elle vise {\`a} collecter des traductions multiples propos{\'e}es par des contributeurs volontaires francophones {\`a} partir de plusieurs langues europ{\'e}ennes. Nous formulons l{'}hypoth{\`e}se que deux traductions soumises ind{\'e}pendamment par deux participants conservent g{\'e}n{\'e}ralement le sens de la phrase d{'}origine, quelle que soit la langue {\`a} partir de laquelle la traduction est effectu{\'e}e. L{'}analyse des r{\'e}sultats nous permet de discuter cette hypoth{\`e}se."
2010.jeptalnrecital-court.18,Acquisition de paraphrases sous-phrastiques depuis des paraphrases d{'}{\\'e}nonc{\\'e}s,2010,-1,-1,1,1,516,houda bouamor,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Dans cet article, nous pr{\'e}sentons la t{\^a}che d{'}acquisition de paraphrases sous-phrastiques (impliquant des paires de mots ou de groupes de mots), et d{\'e}crivons plusieurs techniques op{\'e}rant {\`a} diff{\'e}rents niveaux. Nous d{\'e}crivons une {\'e}valuation visant {\`a} comparer ces techniques et leurs combinaisons sur deux corpus de paraphrases d{'}{\'e}nonc{\'e}s obtenus par traduction multiple. Les conclusions que nous tirons peuvent servir de guide pour am{\'e}liorer des techniques existantes."
2009.jeptalnrecital-demonstration.2,Amener des utilisateurs {\\`a} cr{\\'e}er et {\\'e}valuer des paraphrases par le jeu,2009,-1,-1,1,1,516,houda bouamor,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,"Dans cet article, nous pr{\'e}sentons une application sur le web pour l{'}acquisition de paraphrases phrastiques et sous-phrastiques sous forme de jeu. L{'}application permet l{'}acquisition {\`a} la fois de paraphrases et de jugements humains multiples sur ces paraphrases, ce qui constitue des donn{\'e}es particuli{\`e}rement utiles pour les applications du TAL bas{\'e}es sur les ph{\'e}nom{\`e}nes paraphrastiques."
