2021.emnlp-demo.8,{E}xcavator{C}ovid: Extracting Events and Relations from Text Corpora for Temporal and Causal Analysis for {COVID}-19,2021,-1,-1,5,0.244823,1264,bonan min,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,0,"Timely responses from policy makers to mitigate the impact of the COVID-19 pandemic rely on a comprehensive grasp of events, their causes, and their impacts. These events are reported at such a speed and scale as to be overwhelming. In this paper, we present ExcavatorCovid, a machine reading system that ingests open-source text documents (e.g., news and scientific publications), extracts COVID-19 related events and relations between them, and builds a Temporal and Causal Analysis Graph (TCAG). Excavator will help government agencies alleviate the information overload, understand likely downstream effects of political and economic decisions and events related to the pandemic, and respond in a timely manner to mitigate the impact of COVID-19. We expect the utility of Excavator to outlive the COVID-19 pandemic: analysts and decision makers will be empowered by Excavator to better understand and solve complex problems in the future. A demonstration video is available at https://vimeo.com/528619007."
2021.emnlp-demo.19,{UMR}-Writer: A Web Application for Annotating Uniform Meaning Representations,2021,-1,-1,2,0,8111,jin zhao,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,0,"We present UMR-Writer, a web-based application for annotating Uniform Meaning Representations (UMR), a graph-based, cross-linguistically applicable semantic representation developed recently to support the development of interpretable natural language applications that require deep semantic analysis of texts. We present the functionalities of UMR-Writer and discuss the challenges in developing such a tool and how they are addressed."
2021.acl-long.122,Factuality Assessment as Modal Dependency Parsing,2021,-1,-1,5,0,12873,jiarui yao,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"As the sources of information that we consume everyday rapidly diversify, it is becoming increasingly important to develop NLP tools that help to evaluate the credibility of the information we receive. A critical step towards this goal is to determine the factuality of events in text. In this paper, we frame factuality assessment as a modal dependency parsing task that identifies the events and their sources, formally known as conceivers, and then determine the level of certainty that the sources are asserting with respect to the events. We crowdsource the first large-scale data set annotated with modal dependency structures that consists of 353 Covid-19 related news articles, 24,016 events, and 2,938 conceivers. We also develop the first modal dependency parser that jointly extracts events, conceivers and constructs the modal dependency structure of a text. We evaluate the joint model against a pipeline model and demonstrate the advantage of the joint model in conceiver extraction and modal dependency structure construction when events and conceivers are automatically extracted. We believe the dataset and the models will be a valuable resource for a whole host of NLP applications such as fact checking and rumor detection."
2021.acl-long.138,A Joint Model for Dropped Pronoun Recovery and Conversational Discourse Parsing in {C}hinese Conversational Speech,2021,-1,-1,7,1,12896,jingxuan yang,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"In this paper, we present a neural model for joint dropped pronoun recovery (DPR) and conversational discourse parsing (CDP) in Chinese conversational speech. We show that DPR and CDP are closely related, and a joint model benefits both tasks. We refer to our model as DiscProReco, and it first encodes the tokens in each utterance in a conversation with a directed Graph Convolutional Network (GCN). The token states for an utterance are then aggregated to produce a single state for each utterance. The utterance states are then fed into a biaffine classifier to construct a conversational discourse graph. A second (multi-relational) GCN is then applied to the utterance states to produce a discourse relation-augmented representation for the utterances, which are then fused together with token states in each utterance as input to a dropped pronoun recovery layer. The joint model is trained and evaluated on a new Structure Parsing-enhanced Dropped Pronoun Recovery (SPDPR) data set that we annotated with both two types of information. Experimental results on the SPDPR dataset and other benchmarks show that DiscProReco significantly outperforms the state-of-the-art baselines of both tasks."
2020.paclic-1.65,{A}bstract {M}eaning {R}epresentation for {MWE}: A study of the mapping of aspectuality based on {M}andarin light verb jiayi,2020,-1,-1,2,0,15927,lu lu,"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation",0,None
2020.findings-emnlp.13,Transformer-{GCRF}: Recovering {C}hinese Dropped Pronouns with General Conditional Random Fields,2020,-1,-1,8,1,12896,jingxuan yang,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"Pronouns are often dropped in Chinese conversations and recovering the dropped pronouns is important for NLP applications such as Machine Translation. Existing approaches usually formulate this as a sequence labeling task of predicting whether there is a dropped pronoun before each token and its type. Each utterance is considered to be a sequence and labeled independently. Although these approaches have shown promise, labeling each utterance independently ignores the dependencies between pronouns in neighboring utterances. Modeling these dependencies is critical to improving the performance of dropped pronoun recovery. In this paper, we present a novel framework that combines the strength of Transformer network with General Conditional Random Fields (GCRF) to model the dependencies between pronouns in neighboring utterances. Results on three Chinese conversation datasets show that the Transformer-GCRF model outperforms the state-of-the-art dropped pronoun recovery models. Exploratory analysis also demonstrates that the GCRF did help to capture the dependencies between pronouns in neighboring utterances, thus contributes to the performance improvements."
2020.emnlp-main.432,{A}nnotating {T}emporal {D}ependency {G}raphs via {C}rowdsourcing,2020,-1,-1,4,0,12873,jiarui yao,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"We present the construction of a corpus of 500 Wikinews articles annotated with temporal dependency graphs (TDGs) that can be used to train systems to understand temporal relations in text. We argue that temporal dependency graphs, built on previous research on narrative times and temporal anaphora, provide a representation scheme that achieves a good trade-off between completeness and practicality in temporal annotation. We also provide a crowdsourcing strategy to annotate TDGs, and demonstrate the feasibility of this approach with an evaluation of the quality of the annotation, and the utility of the resulting data set by training a machine learning model on this data set. The data set is publicly available."
2020.conll-shared.1,{MRP} 2020: The Second Shared Task on Cross-Framework and Cross-Lingual Meaning Representation Parsing,2020,-1,-1,9,0,2623,stephan oepen,Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing,0,"The 2020 Shared Task at the Conference for Computational Language Learning (CoNLL) was devoted to Meaning Representation Parsing (MRP) across frameworks and languages. Extending a similar setup from the previous year, five distinct approaches to the representation of sentence meaning in the form of directed graphs were represented in the English training and evaluation data for the task, packaged in a uniform graph abstraction and serialization; for four of these representation frameworks, additional training and evaluation data was provided for one additional language per framework. The task received submissions from eight teams, of which two do not participate in the official ranking because they arrived after the closing deadline or made use of additional training data. All technical information regarding the task, including system submissions, official results, and links to supporting resources and software are available from the task web site at: http://mrp.nlpl.eu"
W19-3303,Modeling Quantification and Scope in {A}bstract {M}eaning {R}epresentations,2019,0,0,3,0,993,james pustejovsky,Proceedings of the First International Workshop on Designing Meaning Representations,0,"In this paper, we propose an extension to Abstract Meaning Representations (AMRs) to encode scope information of quantifiers and negation, in a way that overcomes the semantic gaps of the schema while maintaining its cognitive simplicity. Specifically, we address three phenomena not previously part of the AMR specification: quantification, negation (generally), and modality. The resulting representation, which we call {``}Uniform Meaning Representation{''} (UMR), adopts the predicative core of AMR and embeds it under a {``}scope{''} graph when appropriate. UMR representations differ from other treatments of quantification and modal scope phenomena in two ways: (a) they are more transparent; and (b) they specify default scope when possible.{`}"
W19-3304,Parsing Meaning Representations: Is Easier Always Better?,2019,0,0,2,0,21,zi lin,Proceedings of the First International Workshop on Designing Meaning Representations,0,"The parsing accuracy varies a great deal for different meaning representations. In this paper, we compare the parsing performances between Abstract Meaning Representation (AMR) and Minimal Recursion Semantics (MRS), and provide an in-depth analysis of what factors contributed to the discrepancy in their parsing accuracy. By crystalizing the trade-off between representation expressiveness and ease of automatic parsing, we hope our results can help inform the design of the next-generation meaning representations."
S19-1019,Acquiring Structured Temporal Representation via Crowdsourcing: A Feasibility Study,2019,0,1,2,1,13106,yuchen zhang,Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019),0,"Temporal Dependency Trees are a structured temporal representation that represents temporal relations among time expressions and events in a text as a dependency tree structure. Compared to traditional pair-wise temporal relation representations, temporal dependency trees facilitate efficient annotations, higher inter-annotator agreement, and efficient computations. However, annotations on temporal dependency trees so far have only been done by expert annotators, which is costly and time-consuming. In this paper, we introduce a method to crowdsource temporal dependency tree annotations, and show that this representation is intuitive and can be collected with high accuracy and agreement through crowdsourcing. We produce a corpus of temporal dependency trees, and present a baseline temporal dependency parser, trained and evaluated on this new corpus."
N19-1095,Recovering dropped pronouns in {C}hinese conversations via modeling their referents,2019,30,1,6,1,12896,jingxuan yang,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Pronouns are often dropped in Chinese sentences, and this happens more frequently in conversational genres as their referents can be easily understood from context. Recovering dropped pronouns is essential to applications such as Information Extraction where the referents of these dropped pronouns need to be resolved, or Machine Translation when Chinese is the source language. In this work, we present a novel end-to-end neural network model to recover dropped pronouns in conversational data. Our model is based on a structured attention mechanism that models the referents of dropped pronouns utilizing both sentence-level and word-level information. Results on three different conversational genres show that our approach achieves a significant improvement over the current state of the art."
K19-2001,{MRP} 2019: Cross-Framework Meaning Representation Parsing,2019,0,4,7,0,2623,stephan oepen,Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning,0,"The 2019 Shared Task at the Conference for Computational Language Learning (CoNLL) was devoted to Meaning Representation Parsing (MRP) across frameworks. Five distinct approaches to the representation of sentence meaning in the form of directed graph were represented in the training and evaluation data for the task, packaged in a uniform abstract graph representation and serialization. The task received submissions from eighteen teams, of which five do not participate in the official ranking because they arrived after the closing deadline, made use of additional training data, or involved one of the task co-organizers. All technical information regarding the task, including system submissions, official results, and links to supporting resources and software are available from the task web site at: http://mrp.nlpl.eu"
2019.lilt-18.2,Building a {C}hinese {AMR} Bank with Concept and Relation Alignments,2019,0,0,5,1,11696,bin li,"Linguistic Issues in Language Technology, Volume 18, 2019 - Exploiting Parsed Corpora: Applications in Research, Pedagogy, and Processing",0,"Abstract Meaning Representation (AMR) is a meaning representation framework in which the meaning of a full sentence is represented as a single-rooted, acyclic, directed graph. In this article, we describe an on-going project to build a Chinese AMR (CAMR) corpus, which currently includes 10,149 sentences from the newsgroup and weblog portion of the Chinese TreeBank (CTB). We describe the annotation specifications for the CAMR corpus, which follow the annotation principles of English AMR but make adaptations where needed to accommodate the linguistic facts of Chinese. The CAMR specifications also include a systematic treatment of sentence-internal discourse relations. One significant change we have made to the AMR annotation methodology is the inclusion of the alignment between word tokens in the sentence and the concepts/relations in the CAMR annotation to make it easier for automatic parsers to model the correspondence between a sentence and its meaning representation. We develop an annotation tool for CAMR, and the inter-agreement as measured by the Smatch score between the two annotators is 0.83, indicating reliable annotation. We also present some quantitative analysis of the CAMR corpus. 46.71{\%} of the AMRs of the sentences are non-tree graphs. Moreover, the AMR of 88.95{\%} of the sentences has concepts inferred from the context of the sentence but do not correspond to a specific word."
N18-2040,Transition-Based {C}hinese {AMR} Parsing,2018,0,1,3,1,24166,chuan wang,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"This paper presents the first AMR parser built on the Chinese AMR bank. By applying a transition-based AMR parsing framework to Chinese, we first investigate how well the transitions first designed for English AMR parsing generalize to Chinese and provide a comparative analysis between the transitions for English and Chinese. We then perform a detailed error analysis to identify the major challenges in Chinese AMR parsing that we hope will inform future research in this area."
L18-1490,Structured Interpretation of Temporal Relations,2018,17,2,2,1,13106,yuchen zhang,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"Temporal relations between events and time expressions in a document are often modeled in an unstructured manner where relations between individual pairs of time expressions and events are considered in isolation. This often results in inconsistent and incomplete annotation and computational modeling. We propose a novel annotation approach where events and time expressions in a document form a dependency tree in which each dependency relation corresponds to an instance of temporal anaphora where the antecedent is the parent and the anaphor is the child. We annotate a corpus of 235 documents using this approach in the two genres of news and narratives, with 48 documents doubly annotated. We report a stable and high inter-annotator agreement on the doubly annotated subset, validating our approach, and perform a quantitative comparison between the two genres of the entire corpus. We make this corpus publicly available."
D18-1371,Neural Ranking Models for Temporal Dependency Structure Parsing,2018,0,0,2,1,13106,yuchen zhang,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We design and build the first neural temporal dependency parser. It utilizes a neural ranking model with minimal feature engineering, and parses time expressions and events in a text into a temporal dependency tree structure. We evaluate our parser on two domains: news reports and narrative stories. In a parsing-only evaluation setup where gold time expressions and events are provided, our parser reaches 0.81 and 0.70 f-score on unlabeled and labeled parsing respectively, a result that is very competitive against alternative approaches. In an end-to-end evaluation setup where time expressions and events are automatically recognized, our parser beats two strong baselines on both data domains. Our experimental results and discussions shed light on the nature of temporal dependency structures in different domains and provide insights that we believe will be valuable to future research in this area."
W17-3610,Discourse Segmentation for Building a {RST} {C}hinese Treebank,2017,0,1,2,0,21802,shuyuan cao,Proceedings of the 6th Workshop on Recent Advances in {RST} and Related Formalisms,0,None
J17-3002,Translation Divergences in {C}hinese{--}{E}nglish Machine Translation: An Empirical Investigation,2017,64,3,2,1,32780,dun deng,Computational Linguistics,0,"In this article, we conduct an empirical investigation of translation divergences between Chinese and English relying on a parallel treebank. To do this, we first devise a hierarchical alignment scheme where Chinese and English parse trees are aligned in a way that eliminates conflicts and redundancies between word alignments and syntactic parses to prevent the generation of spurious translation divergences. Using this Hierarchically Aligned Chinese{--}English Parallel Treebank (HACEPT), we are able to semi-automatically identify and categorize the translation divergences between the two languages and quantify each type of translation divergence. Our results show that the translation divergences are much broader than described in previous studies that are largely based on anecdotal evidence and linguistic knowledge. The distribution of the translation divergences also shows that some high-profile translation divergences that motivate previous research are actually very rare in our data, whereas other translation divergences that have previously received little attention actually exist in large quantities. We also show that HACEPT allows the extraction of syntax-based translation rules, most of which are expressive enough to capture the translation divergences, and point out that the syntactic annotation in existing treebanks is not optimal for extracting such translation rules. We also discuss the implications of our study for attempts to bridge translation divergences by devising shared semantic representations across languages. Our quantitative results lend further support to the observation that although it is possible to bridge some translation divergences with semantic representations, other translation divergences are open-ended, thus building a semantic representation that captures all possible translation divergences may be impractical."
E17-1027,A Systematic Study of Neural Discourse Models for Implicit Discourse Relation,2017,36,11,3,1,21496,attapol rutherford,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"Inferring implicit discourse relations in natural language text is the most difficult subtask in discourse parsing. Many neural network models have been proposed to tackle this problem. However, the comparison for this task is not unified, so we could hardly draw clear conclusions about the effectiveness of various architectures. Here, we propose neural network models that are based on feedforward and long-short term memory architecture and systematically study the effects of varying structures. To our surprise, the best-configured feedforward architecture outperforms LSTM-based model in most cases despite thorough tuning. Further, we compare our best feedforward system with competitive convolutional and recurrent networks and find that feedforward can actually be more effective. For the first time for this task, we compile and publish outputs from previous neural and non-neural systems to establish the standard for further comparison."
E17-1035,Addressing the Data Sparsity Issue in Neural {AMR} Parsing,2017,17,20,4,0,24422,xiaochang peng,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"Neural attention models have achieved great success in different NLP tasks. However, they have not fulfilled their promise on the AMR parsing task due to the data sparsity issue. In this paper, we describe a sequence-to-sequence model for AMR parsing and present different ways to tackle the data sparsity problem. We show that our methods achieve significant improvement over a baseline neural attention model and our results are also competitive against state-of-the-art systems that do not use extra linguistic resources."
D17-1129,Getting the Most out of {AMR} Parsing,2017,28,11,2,1,24166,chuan wang,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,This paper proposes to tackle the AMR parsing bottleneck by improving two components of an AMR parser: concept identification and alignment. We first build a Bidirectional LSTM based concept identifier that is able to incorporate richer contextual information to learn sparse AMR concept labels. We then extend an HMM-based word-to-concept alignment model with graph distance distortion and a rescoring method during decoding to incorporate the structural information in the AMR graph. We show integrating the two components into an existing AMR parser results in consistently better performance over the state of the art on various datasets.
W16-1702,Annotating the Little Prince with {C}hinese {AMR}s,2016,16,5,5,1,11696,bin li,Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with {ACL} 2016 ({LAW}-X 2016),0,None
W16-1703,Converting {S}yn{T}ag{R}us Dependency Treebank into {P}enn {T}reebank Style,2016,6,2,3,0,18515,alex luu,Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with {ACL} 2016 ({LAW}-X 2016),0,None
W16-1720,Annotating the discourse and dialogue structure of {SMS} message conversations,2016,4,1,1,1,10294,nianwen xue,Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with {ACL} 2016 ({LAW}-X 2016),0,None
S16-1181,{CAMR} at {S}em{E}val-2016 Task 8: An Extended Transition-based {AMR} Parser,2016,10,24,5,1,24166,chuan wang,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
L16-1145,"Large Multi-lingual, Multi-level and Multi-genre Annotation Corpus",2016,9,1,3,0.769231,30118,xuansong li,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"High accuracy for automated translation and information retrieval calls for linguistic annotations at various language levels. The plethora of informal internet content sparked the demand for porting state-of-art natural language processing (NLP) applications to new social media as well as diverse language adaptation. Effort launched by the BOLT (Broad Operational Language Translation) program at DARPA (Defense Advanced Research Projects Agency) successfully addressed the internet information with enhanced NLP systems. BOLT aims for automated translation and linguistic analysis for informal genres of text and speech in online and in-person communication. As a part of this program, the Linguistic Data Consortium (LDC) developed valuable linguistic resources in support of the training and evaluation of such new technologies. This paper focuses on methodologies, infrastructure, and procedure for developing linguistic annotation at various language levels, including Treebank (TB), word alignment (WA), PropBank (PB), and co-reference (CoRef). Inspired by the OntoNotes approach with adaptations to the tasks to reflect the goals and scope of the BOLT project, this effort has introduced more annotation types of informal and free-style genres in English, Chinese and Egyptian Arabic. The corpus produced is by far the largest multi-lingual, multi-level and multi-genre annotation corpus of informal text and speech."
K16-2001,{C}o{NLL} 2016 Shared Task on Multilingual Shallow Discourse Parsing,2016,35,36,1,1,10294,nianwen xue,Proceedings of the {C}o{NLL}-16 shared task,0,"The CoNLL-2016 Shared Task is the second edition of the CoNLL-2015 Shared Task, now on Multilingual Shallow discourse parsing. Similar to the 2015 task, the goal of the shared task is to identify individual discourse relations that are present in natural language text. Given a natural language text, participating teams are asked to locate the discourse connectives (explicit or implicit) and their arguments as well as predicting the sense of the discourse connectives. Based on the success of the previous year, we continued to ask participants to deploy their systems on TIRA, a web-based platform on which participants can run their systems on the test data for evaluation. This evaluation methodology preserves the integrity of the shared task. We have also made a few changes and additions in the 2016 shared task based on the feedback from 2015. The first is that teams could choose to carry out the task on Chinese texts, or English texts, or both. We have also allowed participants to focus on parts of the shared task (rather than the whole thing) as a typical system requires substantial investment of effort. Finally, we have modified the scorer so that it can report results based on partial matches of the arguments. 23 teams participated in this yearxe2x80x99s shared task, using a wide variety of approaches. In this overview paper, we present the task definition, the training and test sets, and the evaluation protocol and metric used during this shared task. We also summarize the different approaches adopted by the participating teams, and present the evaluation results. The evaluation data sets and the scorer will serve as a benchmark for future research on shallow discourse parsing."
K16-2007,Robust Non-Explicit Neural Discourse Parser in {E}nglish and {C}hinese,2016,12,10,2,1,21496,attapol rutherford,Proceedings of the {C}o{NLL}-16 shared task,0,"Neural discourse models proposed so far are very sophisticated and tuned specifically to certain label sets. These are effective, but unwieldy to deploy or repurpose for different label sets or languages. Here, we propose a robust neural classifier for non-explicit discourse relations for both English and Chinese in CoNLL 2016 Shared Task datasets. Our model only requires word vectors and simple feed-forward training procedure, which we have previously shown to work better than some of the more sophisticated neural architecture such as long-short term memory model. Our Chinese model outperforms feature-based model and performs competitively against other teams. Our model obtains the state-of-the-art results on the English blind test set, which is used as the main criteria in this competition."
W15-1001,Harmonizing word alignments and syntactic structures for extracting phrasal translation equivalents,2015,20,2,2,1,32780,dun deng,"Proceedings of the Ninth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"Accurate identification of phrasal translation equivalents is critical to both phrase-based and syntax-basedmachine translation systems. We show that the extraction of many phrasal translation equivalents is made impossible by word alignments done without taking syntactic structures into consideration. To address the problem, we propose a new annotation scheme where word alignment and the alignment of non-terminal nodes (i.e., phrases) are done simultaneously to avoid conflicts between word alignments and syntactic structures. Relying on this new alignment approach, we construct a Hierarchically Aligned Chinese-English Parallel Treebank (HACEPT), and show that all phrasal translation equivalents can be automatically extracted based on the phrase alignments in HACEPT."
P15-2051,Recovering dropped pronouns from {C}hinese text messages,2015,13,10,3,1,37422,yaqin yang,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Pronouns are frequently dropped in Chinese sentences, especially in informal data such as text messages. In this work we propose a solution to recover dropped pronouns in SMS data. We manually annotate dropped pronouns in 684 SMS files and apply machine learning algorithms to recover them, leveraging lexical, contextual and syntactic information as features. We believe this is the first work on recovering dropped pronouns in Chinese text messages."
P15-2141,Boosting Transition-based {AMR} Parsing with Refined Actions and Auxiliary Analyzers,2015,19,27,2,1,24166,chuan wang,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,We report improved AMR parsing results by adding a new action to a transitionbased AMR parser to infer abstract concepts and by incorporating richer features produced by auxiliary analyzers such as a semantic role labeler and a coreference resolver. We report final AMR parsing results that show an improvement of 7% absolute in F1 score over the best previously reported result. Our parser is available at: https://github.com/ Juicechuan/AMRParsing
P15-1110,Feature Optimization for Constituent Parsing via Neural Networks,2015,28,14,3,1,10548,zhiguo wang,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"The performance of discriminative constituent parsing relies crucially on feature engineering, and effective features usually have to be carefully selected through a painful manual process. In this paper, we propose to automatically learn a set of effective features via neural networks. Specifically, we build a feedforward neural network model, which takes as input a few primitive units (words, POS tags and certain contextual tokens) from the local context, induces the feature representation in the hidden layer and makes parsing predictions in the output layer. The network simultaneously learns the feature representation and the prediction model parameters using a back propagation algorithm. By pre-training the model on a large amount of automatically parsed data, and then fine-tuning on the manually annotated Treebank data, our parser achieves the highest F1 score at 86.6% on Chinese Treebank 5.1, and a competitive F1 score at 90.7% on English Treebank. More importantly, our parser generalizes well on cross-domain test sets, where we significantly outperform Berkeley parser by 3.4 points on average for Chinese and 2.5 points for English."
N15-1040,A Transition-based Algorithm for {AMR} Parsing,2015,16,64,2,1,24166,chuan wang,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present a two-stage framework to parse a sentence into its Abstract Meaning Representation (AMR). We first use a dependency parser to generate a dependency tree for the sentence. In the second stage, we design a novel transition-based algorithm that transforms the dependency tree to an AMR graph. There are several advantages with this approach. First, the dependency parser can be trained on a training set much larger than the training set for the tree-to-graph algorithm, resulting in a more accurate AMR parser overall. Our parser yields an improvement of 5% absolute in F-measure over the best previous result. Second, the actions that we design are linguistically intuitive and capture the regularities in the mapping between the dependency structure and the AMR of a sentence. Third, our parser runs in nearly linear time in practice in spite of a worst-case complexity ofO(n 2 )."
N15-1081,Improving the Inference of Implicit Discourse Relations via Classifying Explicit Discourse Connectives,2015,26,49,2,1,21496,attapol rutherford,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Discourse relation classification is an important component for automatic discourse parsing and natural language understanding. The performance bottleneck of a discourse parser comes from implicit discourse relations, whose discourse connectives are not overtly present. Explicit discourse connectives can potentially be exploited to collect more training data to collect more data and boost the performance. However, using them indiscriminately has been shown to hurt the performance because not all discourse connectives can be dropped arbitrarily. Based on this insight, we investigate the interaction between discourse connectives and the discourse relations and propose the criteria for selecting the discourse connectives that can be dropped independently of the context without changing the interpretation of the discourse. Extra training data collected only by the freely omissible connectives improve the performance of the system without additional features."
K15-2001,The {C}o{NLL}-2015 Shared Task on Shallow Discourse Parsing,2015,42,69,1,1,10294,nianwen xue,Proceedings of the Nineteenth Conference on Computational Natural Language Learning - Shared Task,0,"The CoNLL-2015 Shared Task is on Shallow Discourse Parsing, a task focusing on identifying individual discourse relations that are present in a natural language text. A discourse relation can be expressed explicitly or implicitly, and takes two arguments realized as sentences, clauses, or in some rare cases, phrases. Sixteen teams from three continents participated in this task. For the first time in the history of the CoNLL shared tasks, participating teams, instead of running their systems on the test set and submitting the output, were asked to deploy their systems on a remote virtual machine and use a web-based evaluation platform to run their systems on the test set. This meant they were unable to actually see the data set, thus preserving its integrity and ensuring its replicability. In this paper, we present the task definition, the training and test sets, and the evaluation protocol and metric used during this shared task. We also summarize the different approaches adopted by the participating teams, and present the evaluation results. The evaluation data sets and the scorer will serve as a benchmark for future research on shallow discourse parsing."
W14-4904,Aligning {C}hinese-{E}nglish Parallel Parse Trees: Is it Feasible?,2014,9,2,2,1,32780,dun deng,Proceedings of {LAW} {VIII} - The 8th Linguistic Annotation Workshop,0,We investigate the feasibility of aligning Chinese and English parse trees by examining cases of incompatibility between Chinese-English parallel parse trees. This work is done in the context of an annotation project wherewe construct a parallel treebank by doingword and phrase alignments simultaneously. We discuss the most common incompatibility patterns identified within VPs and NPs and show that most cases of incompatibility are caused by divergent syntactic annotation standards rather than inherent cross-linguistic differences in language itself. This suggests that in principle it is feasible to align the parallel parse trees with somemodification of existing syntactic annotation guidelines. We believe this has implications for the use of parallel parse trees as an important resource for Machine Translation models.
P14-2033,Effective Document-Level Features for {C}hinese Patent Word Segmentation,2014,25,7,2,0.833333,6891,si li,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"A patent is a property right for an invention granted by the government to the inventor. Patents often have a high concentration of scientific and technical terms that are rare in everyday language. However, some scientific and technical terms usually appear with high frequency only in one specific patent. In this paper, we propose a pragmatic approach to Chinese word segmentation on patents where we train a sequence labeling model based on a group of novel document-level features. Experiments show that the accuracy of our model reached 96.3% (F1 score) on the development set and 95.0% on a held-out test set."
P14-1069,Joint {POS} Tagging and Transition-based Constituent Parsing in {C}hinese with Non-local Features,2014,21,35,2,1,10548,zhiguo wang,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We propose three improvements to address the drawbacks of state-of-the-art transition-based constituent parsers. First, to resolve the error propagation problem of the traditional pipeline approach, we incorporate POS tagging into the syntactic parsing process. Second, to alleviate the negative influence of size differences among competing action sequences, we align parser states during beam-search decoding. Third, to enhance the power of parsing models, we enlarge the feature set with non-local features and semisupervised word cluster features. Experimental results show that these modifications improve parsing performance significantly. Evaluated on the Chinese TreeBank (CTB), our final performance reaches 86.3% (F1) when trained on CTB 5.1, and 87.1% when trained on CTB 6.0, and these results outperform all state-of-the-art parsers."
xue-zhang-2014-buy,"Buy one get one free: Distant annotation of {C}hinese tense, event type and modality",2014,12,4,1,1,10294,nianwen xue,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We describe a {``}distant annotation{''} method where we mark up the semantic tense, event type, and modality of Chinese events via a word-aligned parallel corpus. We first map Chinese verbs to their English counterparts via word alignment, and then annotate the resulting English text spans with coarse-grained categories for semantic tense, event type, and modality that we believe apply to both English and Chinese. Because English has richer morpho-syntactic indicators for semantic tense, event type and modality than Chinese, our intuition is that this distant annotation approach will yield more consistent annotation than if we annotate the Chinese side directly. We report experimental results that show stable annotation agreement statistics and that event type and modality have significant influence on tense prediction. We also report the size of the annotated corpus that we have obtained, and how different domains impact annotation consistency."
xue-etal-2014-interlingua,"Not an Interlingua, But Close: Comparison of {E}nglish {AMR}s to {C}hinese and {C}zech",2014,18,10,1,1,10294,nianwen xue,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Abstract Meaning Representations (AMRs) are rooted, directional and labeled graphs that abstract away from morpho-syntactic idiosyncrasies such as word category (verbs and nouns), word order, and function words (determiners, some prepositions). Because these syntactic idiosyncrasies account for many of the cross-lingual differences, it would be interesting to see if this representation can serve, e.g., as a useful, minimally divergent transfer layer in machine translation. To answer this question, we have translated 100 English sentences that have existing AMRs into Chinese and Czech to create AMRs for them. A cross-linguistic comparison of English to Chinese and Czech AMRs reveals both cases where the AMRs for the language pairs align well structurally and cases of linguistic divergence. We found that the level of compatibility of AMR between English and Chinese is higher than between English and Czech. We believe this kind of comparison is beneficial to further refining the annotation standards for each of the three languages and will lead to more compatible annotation guidelines between the languages."
E14-1068,Discovering Implicit Discourse Relations Through Brown Cluster Pair Representation and Coreference Patterns,2014,32,80,2,1,21496,attapol rutherford,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Sentences form coherent relations in a discourse without discourse connectives more frequently than with connectives. Senses of these implicit discourse relations that hold between a sentence pair, however, are challenging to infer. Here, we employ Brown cluster pairs to represent discourse relation and incorporate coreference patterns to identify senses of implicit discourse relations in naturally occurring text. Our system improves the baseline performance by as much as 25%. Feature analyses suggest that Brown cluster pairs and coreference patterns can reveal many key linguistic characteristics of each type of discourse relation."
D14-1204,Automatic Inference of the Tense of {C}hinese Events Using Implicit Linguistic Information,2014,11,2,2,1,13106,yuchen zhang,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We address the problem of automatically inferring the tense of events in Chinese text. We use a new corpus annotated with Chinese semantic tense information and other implicit Chinese linguistic information using a xe2x80x9cdistant annotationxe2x80x9d method. We propose three improvements over a relatively strong baseline method xe2x80x90 a statistical learning method with extensive feature engineering. First, we add two sources of implicit linguistic information as features xe2x80x90 eventuality type and modality of an event, which are also inferred automatically. Second, we perform joint learning on semantic tense, eventuality type, and modality of an event. Third, we train artificial neural network models for this problem and compare its performance with feature-based approaches. Experimental results show considerable improvements on Chinese tense inference. Our best performance reaches 68.6% in accuracy, outperforming a strong baseline method."
C14-1143,Building a Hierarchically Aligned {C}hinese-{E}nglish Parallel Treebank,2014,26,2,2,1,32780,dun deng,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"We construct a hierarchically aligned Chinese-English parallel treebank by manually doing word alignments and phrase alignments simultaneously on parallel phrase-based parse trees. The main innovation of our approach is that we leave words without a translation counterpart (which are mostly language-particular function words) unaligned on the word level, and locate and align the appropriate phrases which encapsulate them. In doing so, we harmonize word-level and phraselevel alignments. We show that this type of annotation can be performedwith high inter-annotator consistency and have both linguistic and engineering potentials."
W13-3516,Towards Robust Linguistic Analysis using {O}nto{N}otes,2013,41,68,3,1,11322,sameer pradhan,Proceedings of the Seventeenth Conference on Computational Natural Language Learning,0,"Large-scale linguistically annotated corpora have played a crucial role in advancing the state of the art of key natural language technologies such as syntactic, semantic and discourse analyzers, and they serve as training data as well as evaluation benchmarks. Up till now, however, most of the evaluation has been done on monolithic corpora such as the Penn Treebank, the Proposition Bank. As a result, it is still unclear how the state-of-the-art analyzers perform in general on data from a variety of genres or domains. The completion of the OntoNotes corpus, a large-scale, multi-genre, multilingual corpus manually annotated with syntactic, semantic and discourse information, makes it possible to perform such an evaluation. This paper presents an analysis of the performance of publicly available, state-of-the-art tools on all layers and languages in the OntoNotes v5.0 corpus. This should set the benchmark for future development of various NLP components in syntax and semantics, and possibly encourage research towards an integrated system that makes use of the various layers jointly to improve overall performance."
W13-0307,Distant annotation of {C}hinese tense and modality,2013,13,1,1,1,10294,nianwen xue,Proceedings of the {IWCS} 2013 Workshop on Annotation of Modal Meanings in Natural Language ({WAMM}),0,"In this paper we describe a xe2x80x9cdistant annotationxe2x80x9d method by which we mark up tense and modality of Chinese eventualities via a wordaligned parallel corpus. We first map Chinese verbs to their English counterpart via word alignment, and then annotate the resulting English text spans with coarse-grained tense and modality categories that we believe apply to both English and Chinese. Because English has richer morpho-syntactic indicators for tense and modality than Chinese, we hope this distant annotation approach will yield more consistent annotation than if we annotate the Chinese side directly. We report experimental results that show this expectation is largely borne out."
P13-2110,"A Lattice-based Framework for Joint {C}hinese Word Segmentation, {POS} Tagging and Parsing",2013,17,14,3,1,10548,zhiguo wang,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"For the cascaded task of Chinese word segmentation, POS tagging and parsing, the pipeline approach suffers from error propagation while the joint learning approach suffers from inefficient decoding due to the large combined search space. In this paper, we present a novel lattice-based framework in which a Chinese sentence is first segmented into a word lattice, and then a lattice-based POS tagger and a lattice-based parser are used to process the lattice from two different viewpoints: sequential POS tagging and hierarchical tree building. A strategy is designed to exploit the complementary strengths of the tagger and parser, and encourage them to predict agreed structures. Experimental results on Chinese Treebank show that our lattice-based framework significantly improves the accuracy of the three sub-tasks."
N13-1125,Dependency-based empty category detection via phrase structure trees,2013,21,17,1,1,10294,nianwen xue,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We describe a novel approach to detecting empty categories (EC) as represented in dependency trees as well as a new metric for measuring EC detection accuracy. The new metric takes into account not only the position and type of an EC, but also the head it is a dependent of in a dependency tree. We also introduce a variety of new features that are more suited for this approach. Tested on a subset of the Chinese Treebank, our system improved significantly over the best previously reported results even when evaluated with this more stringent metric."
W12-6305,Building a {C}hinese Lexical Taxonomy,2012,10,0,2,0,31446,xiaopeng bai,Proceedings of the Second {CIPS}-{SIGHAN} Joint Conference on {C}hinese Language Processing,0,"In this paper, we present a Chinese lexical taxonomy, a hierarchically organization of Chinese lexical classes of nouns, verbs and adjectives. We first describe the structure of this taxonomy and then present the methods we used to build it. The distinctive characteristics of this lexical taxonomy are: 1) we use definition frame to describe each lexical class, as well as its members, 2) the lexical classes for nouns, verbs and adjectives are inter-connected. We also compare this taxonomy with the Chinese Proposition Bank, to look for possible ways to link these two independently developed language resources."
W12-6306,Extending and Scaling up the {C}hinese Treebank Annotation,2012,13,4,2,0,39603,xiuhong zhang,Proceedings of the Second {CIPS}-{SIGHAN} Joint Conference on {C}hinese Language Processing,0,"We discuss on-going efforts to scale up the Chinese Treebank annotation and extending Chinese treebanking to informal genres like conversational speech, news groups and weblogs, as well as discussion forums. The original Chinese Treebank annotation scheme was designed for formal genres such as newswire and magazine articles, where the language is very formal and each document is carefully edited. When moving to informal genres, we can no longer assume that the data is error-free and we have to extend the annotation scheme to account for disfluencies. We show that the disfluencies can be characterized into a finite set of categories, consistent with what has been reported in theoretical linguistic literature. Treebanking is also a timeconsuming process that requires extensive linguistic training from annotators, and the limited pool of qualified treebankers is a major obstacle for largescale treebanking efforts. To address bottleneck, we implemented a procedure that decomposes the treebanking process into five self-contained steps. In so doing, we reduced the cognitive load on the annotators at each step and thus enlarged the annotator pool, and we show that we are able to increase the throughput by 30%."
W12-4501,{C}o{NLL}-2012 Shared Task: Modeling Multilingual Unrestricted Coreference in {O}nto{N}otes,2012,63,255,3,1,11322,sameer pradhan,Joint Conference on {EMNLP} and {C}o{NLL} - Shared Task,0,"The CoNLL-2012 shared task involved predicting coreference in three languages -- English, Chinese and Arabic -- using OntoNotes data. It was a follow-on to the English-only task organized in 2011. Until the creation of the OntoNotes corpus, resources in this subfield of language processing have tended to be limited to noun phrase coreference, often on a restricted set of entities, such as ACE entities. OntoNotes provides a large-scale corpus of general anaphoric coreference not restricted to noun phrases or to a specified set of entity types and covering multiple languages. OntoNotes also provides additional layers of integrated annotation, capturing additional shallow semantic structure. This paper briefly describes the OntoNotes annotation (coreference and other layers) and then describes the parameters of the shared task including the format, pre-processing information, evaluation criteria, and presents and discusses the results achieved by the participating systems. Being a task that has a complex evaluation history, and multiple evalation conditions, it has, in the past, been difficult to judge the improvement in new algorithms over previously reported results. Having a standard test set and evaluation parameters, all based on a resource that provides multiple integrated annotation layers (parses, semantic roles, word senses, named entities and coreference) that could support joint models, should help to energize ongoing research in the task of entity and event coreference."
W12-3616,Exploring Temporal Vagueness with {M}echanical {T}urk,2012,11,0,2,1,42207,yuping zhou,Proceedings of the Sixth Linguistic Annotation Workshop,0,"This paper proposes schematic changes to the TempEval framework that target the temporal vagueness problem. Specifically, two elements of vagueness are singled out for special treatment: vague time expressions, and explicit/implicit temporal modification of events. As proof of concept, an annotation experiment on explicit/implicit modification is conducted on Amazon's Mechanical Turk. Results show that the quality of a considerable segment of the annotation is comparable to annotation obtained in the traditional double-blind setting, only with higher coverage. This approach offers additional flexibility in how the temporal annotation data can be used."
P12-1008,{PDTB}-style Discourse Annotation of {C}hinese Text,2012,8,53,2,1,42207,yuping zhou,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We describe a discourse annotation scheme for Chinese and report on the preliminary results. Our scheme, inspired by the Penn Discourse TreeBank (PDTB), adopts the lexically grounded approach; at the same time, it makes adaptations based on the linguistic and statistical characteristics of Chinese text. Annotation results show that these adaptations work well in practice. Our scheme, taken together with other PDTB-style schemes (e.g. for English, Turkish, Hindi, and Czech), affords a broader perspective on how the generalized lexically grounded approach can flesh itself out in the context of cross-linguistic annotation of discourse relations."
P12-1083,{C}hinese Comma Disambiguation for Discourse Analysis,2012,14,24,2,1,37422,yaqin yang,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"The Chinese comma signals the boundary of discourse units and also anchors discourse relations between adjacent text spans. In this work, we propose a discourse structure-oriented classification of the comma that can be automatically extracted from the Chinese Treebank based on syntactic patterns. We then experimented with two supervised learning methods that automatically disambiguate the Chinese comma based on this classification. The first method integrates comma classification into parsing, and the second method adopts a post-processing approach that extracts features from automatic parses to train a classifier. The experimental results show that the second approach compares favorably against the first approach."
li-etal-2012-parallel,Parallel Aligned Treebanks at {LDC}: New Challenges Interfacing Existing Infrastructures,2012,13,10,7,0.769231,30118,xuansong li,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Parallel aligned treebanks (PAT) are linguistic corpora annotated with morphological and syntactic structures that are aligned at sentence as well as sub-sentence levels. They are valuable resources for improving machine translation (MT) quality. Recently, there has been an increasing demand for such data, especially for divergent language pairs. The Linguistic Data Consortium (LDC) and its academic partners have been developing Arabic-English and Chinese-English PATs for several years. This paper describes the PAT corpus creation effort for the program GALE (Global Autonomous Language Exploitation) and introduces the potential issues of scaling up this PAT effort for the program BOLT (Broad Operational Language Translation). Based on existing infrastructures and in the light of current annotation process, challenges and approaches, we are exploring new methodologies to address emerging challenges in constructing PATs, including data volume bottlenecks, dialect issues of Arabic languages, and new genre features related to rapidly changing social media. Preliminary experimental results are presented to show the feasibility of the approaches proposed."
baran-etal-2012-annotating,Annotating dropped pronouns in {C}hinese newswire text,2012,3,7,3,0,42956,elizabeth baran,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We propose an annotation framework to explicitly identify dropped subject pronouns in Chinese. We acknowledge and specify 10 concrete pronouns that exist as words in Chinese and 4 abstract pronouns that do not correspond to Chinese words, but that are recognized conceptually, to native Chinese speakers. These abstract pronouns are identified as ''''''``unspecified'''''''', ''''''``pleonastic'''''''', ''''''``event'''''''', and ''''''``existential'''''''' and are argued to exist cross-linguistically. We trained two annotators, fluent in Chinese, and adjudicated their annotations to form a gold standard. We achieved an inter-annotator agreement kappa of .6 and an observed agreement of .7. We found that annotators had the most difficulty with the abstract pronouns, such as ''''''``unspecified'''''''' and ''''''``event'''''''', but we posit that further specification and training has the potential to significantly improve these results. We believe that this annotated data will serve to help improve Machine Translation models that translate from Chinese to a non pro-drop language, like English, that requires all subject pronouns to be explicit."
W11-1901,{C}o{NLL}-2011 Shared Task: Modeling Unrestricted Coreference in {O}nto{N}otes,2011,44,200,6,1,11322,sameer pradhan,Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,0,"The CoNLL-2011 shared task involved predicting coreference using OntoNotes data. Resources in this field have tended to be limited to noun phrase coreference, often on a restricted set of entities, such as ace entities. OntoNotes provides a large-scale corpus of general anaphoric coreference not restricted to noun phrases or to a specified set of entity types. OntoNotes also provides additional layers of integrated annotation, capturing additional shallow semantic structure. This paper briefly describes the OntoNotes annotation (coreference and other layers) and then describes the parameters of the shared task including the format, pre-processing information, and evaluation criteria, and presents and discusses the results achieved by the participating systems. Having a standard test set and evaluation parameters, all based on a new resource that provides multiple integrated annotation layers (parses, semantic roles, word senses, named entities and coreference) that could support joint models, should help to energize ongoing research in the task of entity and event coreference."
W11-1919,A Machine Learning-Based Coreference Detection System for {O}nto{N}otes,2011,2,3,2,1,37422,yaqin yang,Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,0,"In this paper, we describe the algorithms and experimental results of Brandeis University in the participation of the CoNLL Task 2011 closed track. We report the features used in our system, and describe a novel cluster-based chaining algorithm to improve performance of coreference identification. We evaluate the system using the OntoNotes data set and describe our results."
W11-1010,Improving {MT} Word Alignment Using Aligned Multi-Stage Parses,2011,31,1,4,0,3082,adam meyers,"Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,We use hand-coded rules and graph-aligned logical dependencies to reorder English text towards Chinese word order. We obtain a 1.5% higher F-score for Giza compared to running with unprocessed text. We describe this research and its implications for SMT.
W11-0420,Discourse-constrained Temporal Annotation,2011,13,4,2,1,42207,yuping zhou,Proceedings of the 5th Linguistic Annotation Workshop,0,"We describe an experiment on a temporal ordering task in this paper. We show that by selecting event pairs based on discourse structure and by modifying the pre-existent temporal classification scheme to fit the data better, we significantly improve inter-annotator agreement, as well as broaden the coverage of the task. We also present analysis of the current temporal classification scheme and propose ways to improve it in future work."
P11-2111,{C}hinese sentence segmentation as comma classification,2011,8,32,1,1,10294,nianwen xue,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"We describe a method for disambiguating Chinese commas that is central to Chinese sentence segmentation. Chinese sentence segmentation is viewed as the detection of loosely coordinated clauses separated by commas. Trained and tested on data derived from the Chinese Treebank, our model achieves a classification accuracy of close to 90% overall, which translates to an F1 score of 70% for detecting commas that signal sentence boundaries."
2011.mtsummit-papers.22,Singular or Plural? Exploiting Parallel Corpora for {C}hinese Number Prediction,2011,-1,-1,2,0,42956,elizabeth baran,Proceedings of Machine Translation Summit XIII: Papers,0,None
W10-1810,{P}rop{B}ank Annotation of Multilingual Light Verb Constructions,2010,15,24,6,0,7749,jena hwang,Proceedings of the Fourth Linguistic Annotation Workshop,0,"In this paper, we have addressed the task of PropBank annotation of light verb constructions, which like multi-word expressions pose special problems. To arrive at a solution, we have evaluated 3 different possible methods of annotation. The final method involves three passes: (1) manual identification of a light verb construction, (2) annotation based on the light verb construction's Frame File, and (3) a deterministic merging of the first two passes. We also discuss how in various languages the light verb constructions are identified and can be distinguished from the non-light verb word groupings."
C10-2156,"Applying Syntactic, Semantic and Discourse Constraints in {C}hinese Temporal Annotation",2010,16,9,1,1,10294,nianwen xue,Coling 2010: Posters,0,"We describe a Chinese temporal annotation experiment that produced a sizable data set for the TempEval-2 evaluation campaign. We show that while we have achieved high inter-annotator agreement for simpler tasks such as identification of events and time expressions, temporal relation annotation proves to be much more challenging. We show that in order to improve the inter-annotator agreement it is important to strategically select the annotation targets, and the selection of annotation targets should be subject to syntactic, semantic and discourse constraints."
C10-2158,Chasing the ghost: recovering empty categories in the {C}hinese Treebank,2010,17,31,2,1,37422,yaqin yang,Coling 2010: Posters,0,"Empty categories represent an important source of information in syntactic parses annotated in the generative linguistic tradition, but empty category recovery has only started to receive serious attention until very recently, after substantial progress in statistical parsing. This paper describes a unified framework in recovering empty categories in the Chinese Tree-bank. Our results show that given skeletal gold standard parses, the empty categories can be detected with very high accuracy. We report very promising results for empty category recovery for automatic parses as well."
W09-3019,Transducing Logical Relations from Automatic and Manual {GLARF},2009,16,1,4,0,3082,adam meyers,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"GLARF relations are generated from treebank and parses for English, Chinese and Japanese. Our evaluation of system output for these input types requires consideration of multiple correct answers."
W09-3020,Using Parallel Propbanks to enhance Word-alignments,2009,5,7,3,0,1137,jinho choi,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"This short paper describes the use of the linguistic annotation available in parallel PropBanks (Chinese and English) for the enhancement of automatically derived word alignments. Specifically, we suggest ways to refine and expand word alignments for verb-predicates by using predicate-argument structures. Evaluations demonstrate improved alignment accuracies that vary by corpus type."
W09-2423,"Automatic Recognition of Logical Relations for {E}nglish, {C}hinese and {J}apanese in the {GLARF} Framework",2009,30,6,3,0,3082,adam meyers,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"We present GLARF, a framework for representing three linguistic levels and systems for generating this representation. We focus on a logical level, like LFG's F-structure, but compatible with Penn Treebanks. While less finegrained than typical semantic role labeling approaches, our logical structure has several advantages: (1) it includes all words in all sentences, regardless of part of speech or semantic domain; and (2) it is easier to produce accurately. Our systems achieve 90% for English/Japanese News and 74.5% for Chinese News -- these F-scores are nearly the same as those achieved for treebank-based parsing."
W09-1201,The {C}o{NLL}-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages,2009,26,269,13,0,17503,jan hajivc,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL} 2009): Shared Task,0,"For the 11th straight year, the Conference on Computational Natural Language Learning has been accompanied by a shared task whose purpose is to promote natural language processing applications and evaluate them in a standard setting. In 2009, the shared task was dedicated to the joint parsing of syntactic and semantic dependencies in multiple languages. This shared task combines the shared tasks of the previous five years under a unique dependency-based formalism similar to the 2008 task. In this paper, we define the shared task, describe how the data sets were created and show their quantitative properties, report the results and summarize the approaches of the participating systems."
N09-4006,{O}nto{N}otes: The 90{\\%} Solution,2009,0,12,2,1,11322,sameer pradhan,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Tutorial Abstracts",0,"OntoNotes is a five year multi-site collaboration between BBN Technologies, Information Sciences Institute of University of Southern California, University of Colorado, University of Pennsylvania and Brandeis University. The goal of the OntoNotes project is to provide linguistic data annotated with a skeletal representation of the literal meaning of sentences including syntactic parse, predicate-argument structure, coreference, and word senses linked to an ontology, allowing a new generation of language understanding technologies to be developed with new functional capabilities."
xue-etal-2008-annotating,Annotating {``}tense{''} in a Tense-less Language,2008,8,2,1,1,10294,nianwen xue,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In the context of Natural Language Processing, annotation is about recovering implicit information that is useful for natural language applications. In this paper we describe a ÂtenseÂ annotation task for Chinese - a language that does not have grammatical tense - that is designed to infer the temporal location of a situation in relation to the temporal deixis, the moment of speech. If successful, this would be a highly rewarding endeavor as it has application in many natural language systems. Our preliminary experiments show that while this is a very challenging annotation task for which high annotation consistency is very difficult but not impossible to achieve. We show that guidelines that provide a conceptually intuitive framework will be crucial to the success of this annotation effort."
J08-2004,Labeling {C}hinese Predicates with Semantic Roles,2008,63,118,1,1,10294,nianwen xue,Computational Linguistics,0,"In this article we report work on Chinese semantic role labeling, taking advantage of two recently completed corpora, the Chinese PropBank, a semantically annotated corpus of Chinese verbs, and the Chinese Nombank, a companion corpus that annotates the predicate-argument structure of nominalized predicates. Because the semantic role labels are assigned to the constituents in a parse tree, we first report experiments in which semantic role labels are automatically assigned to hand-crafted parses in the Chinese Treebank. This gives us a measure of the extent to which semantic role labels can be bootstrapped from the syntactic annotation provided in the treebank. We then report experiments using automatic parses with decreasing levels of human annotation in the input to the syntactic parser: parses that use gold-standard segmentation and POS-tagging, parses that use only gold-standard segmentation, and fully automatic parses. These experiments gauge how successful semantic role labeling for Chinese can be in more realistic situations. Our results show that when hand-crafted parses are used, semantic role labeling accuracy for Chinese is comparable to what has been reported for the state-of-the-art English semantic role labeling systems trained and tested on the English PropBank, even though the Chinese PropBank is significantly smaller in size. When an automatic parser is used, however, the accuracy of our system is significantly lower than the English state of the art. This indicates that an improvement in Chinese parsing is critical to high-performance semantic role labeling for Chinese."
D08-1074,Automatic Inference of the Temporal Location of Situations in {C}hinese Text,2008,6,7,1,1,10294,nianwen xue,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"Chinese is a language that does not have morphological tense markers that provide explicit grammaticalization of the temporal location of situations (events or states). However, in many NLP applications such as Machine Translation, Information Extraction and Question Answering, it is desirable to make the temporal location of the situations explicit. We describe a machine learning framework where different sources of information can be combined to predict the temporal location of situations in Chinese text. Our experiments show that this approach significantly outperforms the most frequent tense baseline. More importantly, the high training accuracy shows promise that this challenging problem is solvable to a level where it can be used in practical NLP applications with more training data, better modeling techniques and more informative and generalizable features."
P06-2118,Aligning Features with Sense Distinction Dimensions,2006,20,10,1,1,10294,nianwen xue,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"In this paper we present word sense disambiguation (WSD) experiments on ten highly polysemous verbs in Chinese, where significant performance improvements are achieved using rich linguistic features. Our system performs significantly better, and in some cases substantially better, than the baseline on all ten verbs. Our results also demonstrate that features extracted from the output of an automatic Chinese semantic role labeling system in general benefited the WSD system, even though the amount of improvement was not consistent across the verbs. For a few verbs, semantic role information actually hurt WSD performance. The inconsistency of feature performance is a general characteristic of the WSD task, as has been observed by others. We argue that this result can be explained by the fact that word senses are partitioned along different dimensions for different verbs and the features therefore need to be tailored to particular verbs in order to achieve adequate accuracy on verb sense disambiguation."
N06-1055,Semantic role labeling of nominalized predicates in {C}hinese,2006,20,24,1,1,10294,nianwen xue,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,"Recent work on semantic role labeling (SRL) has focused almost exclusively on the analysis of the predicate-argument structure of verbs, largely due to the lack of human-annotated resources for other types of predicates that can serve as training and test data for the semantic role labeling systems. However, it is well-known that verbs are not the only type of predicates that can take arguments. Most notably, nouns that are nominalized forms of verbs and relational nouns generally are also considered to have their own predicate-argument structure. In this paper we report results of SRL experiments on nominalized predicates in Chinese, using a newly completed corpus, the Chinese Nombank. We also discuss the impact of using publicly available manually annotated verb data to improve the SRL accuracy of nouns, exploiting a widely-held assumption that verbs and their nominalizations share the same predicate-argument structure. Finally, we discuss the results of applying reranking techniques to improve SRL accuracy for nominalized predicates, which showed insignificant improvement."
xue-2006-annotating,Annotating the Predicate-Argument Structure of {C}hinese Nominalizations,2006,4,15,1,1,10294,nianwen xue,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper describes the Chinese NomBank Project, the goal of which is to annotate the predicate-argument structure of nominalized predicates in Chinese. The Chinese Nombank extends the general framework of the English and Chinese Proposition Banks to the annotation of nominalized predicates and adds a layer of semantic annotation to the Chinese Treebank. We first outline the scope of the work by discussing the markability of the nominalized predicates and their arguments. We then attempt to provide a categorization of the distribution of the arguments of nominalized predicates. We also discuss the relevance of the event/result distinction to the annotation of nominalized predicates and the phenomenon of incorporation. Finally we discuss some cross-linguistic differences between English and Chinese."
W05-0309,A Parallel {P}roposition {B}ank {II} for {C}hinese and {E}nglish,2005,14,15,2,0,4859,martha palmer,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"The Proposition Bank (PropBank) project is aimed at creating a corpus of text annotated with information about semantic propositions. The second phase of the project, PropBank II adds additional levels of semantic annotation which include eventuality variables, co-reference, coarse-grained sense tags, and discourse connectives. This paper presents the results of the parallel PropBank II project, which adds these richer layers of semantic annotation to the first 100K of the Chinese Treebank and its English translation. Our preliminary analysis supports the hypothesis that this additional annotation reconciles many of the surface differences between the two languages."
W05-0312,Annotating Discourse Connectives in the {C}hinese Treebank,2005,8,31,1,1,10294,nianwen xue,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"In this paper we examine the issues that arise from the annotation of the discourse connectives for the Chinese Discourse Treebank Project. This project is based on the same principles as the PDTB, a project that annotates the English discourse connectives in the Perm Treebank. The paper begins by outlining range of discourse connectives under consideration in this project and examines the distribution of the explicit discourse connectives. We then examine the types of syntactic units that can be arguments to the discourse connectives. We show that one of the most challenging issues in this type of discourse annotation is determining the textual spans of the arguments and this is partly due to the hierarchical nature of discourse relations. Finally, we discuss sense discrimination of the discourse connectives, which involves separating discourse connective from non-discourse connective senses and teasing apart the different discourse connective senses, and discourse connective variation, the use of different connectives to represent the same discourse relation."
W04-3212,Calibrating Features for Semantic Role Labeling,2004,16,277,1,1,10294,nianwen xue,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,"This paper takes a critical look at the features used in the semantic role tagging literature and show that the information in the input, generally a syntactic parse tree, has yet to be fully exploited. We propose an additional set of features and our experiments show that these features lead to fairly significant improvements in the tasks we performed. We further show that different features are needed for different subtasks. Finally, we show that by using a Maximum Entropy classifier and fewer features, we achieved results comparable with the best previously reported results obtained with SVM models. We believe this is a clear indication that developing features that capture the right kind of information is crucial to advancing the stateof-the-art in semantic analysis."
W04-2704,{P}roposition {B}ank {II}: Delving Deeper,2004,19,13,3,0,43023,olga babkomalaya,Proceedings of the Workshop Frontiers in Corpus Annotation at {HLT}-{NAACL} 2004,0,"The PropBank project is creating a corpus of text annotated with information about basic semantic propositions. PropBank I (Kingsbury & Palmer, 2002) added a layer of predicateargument information, or semantic roles, to the syntactic structures of the English Penn Treebank. This paper presents an overview of the second phase of PropBank Annotation, PropBank II, which is being applied to English and Chinese, and includes (Neodavidsonian) eventuality variables, nominal references, sense tagging, and connections to the Penn Discourse Treebank (PDTB), a project for annotating discourse connectives and their arguments."
W03-1707,Annotating the Propositions in the {P}enn {C}hinese Treebank,2003,9,65,1,1,10294,nianwen xue,Proceedings of the Second {SIGHAN} Workshop on {C}hinese Language Processing,0,"In this paper, we describe an approach to annotate the propositions in the Penn Chinese Treebank. We describe how diathesis alternation patterns can be used to make coarse sense distinctions for Chinese verbs as a necessary step in annotating the predicate-structure of Chinese verbs. We then discuss the representation scheme we use to label the semantic arguments and adjuncts of the predicates. We discuss several complications for this type of annotation and describe our solutions. We then discuss how a lexical database with predicate-argument structure information can be used to ensure consistent annotation. Finally, we discuss possible applications for this resource."
W03-1728,{C}hinese Word Segmentation as {LMR} Tagging,2003,10,111,1,1,10294,nianwen xue,Proceedings of the Second {SIGHAN} Workshop on {C}hinese Language Processing,0,In this paper we present Chinese word segmentation algorithms based on the so-called LMR tagging. Our LMR taggers are implemented with the Maximum Entropy Markov Model and we then use Transformation-Based Learning to combine the results of the two LMR taggers that scan the input in opposite directions. Our system achieves F-scores of 95.9% and 91.6% on the Academia Sinica corpus and the Hong Kong City University corpus respectively.
O03-4002,{C}hinese Word Segmentation as Character Tagging,2003,20,299,1,1,10294,nianwen xue,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 8, Number 1, {F}ebruary 2003: Special Issue on Word Formation and {C}hinese Language Processing",0,"In this paper we report results of a supervised machine-learning approach to Chinese word segmentation. A maximum entropy tagger is trained on manually annotated data to automatically assign to Chinese characters, or hanzi, tags that indicate the position of a hanzi within a word. The tagged output is then converted into segmented text for evaluation. Preliminary results show that this approach is competitive against other supervised machine-learning segmenters reported in previous studies, achieving precision and recall rates of 95.01% and 94.94% respectively, trained on a 237K-word training set."
2003.mtsummit-papers.55,Automatic predicate argument structure analysis of the {P}enn {C}hinese Treebank,2003,-1,-1,1,1,10294,nianwen xue,Proceedings of Machine Translation Summit IX: Papers,0,"Recent work in machine translation and information extraction has demonstrated the utility of a level that represents the predicate-argument structure. It would be especially useful for machine translation to have two such Proposition Banks, one for each language under consideration. A Proposition Bank for English has been developed over the last few years, and we describe here our development of a tool for facilitating the development of a Chinese Proposition Bank. We also discuss some issues specific to the Chinese Treebank that complicate the matter of mapping syntactic representation to a predicate-argument level, and report on some preliminary evaluation of the accuracy of the semantic tagging tool."
W02-1815,Combining Classifiers for {C}hinese Word Segmentation,2002,7,28,1,1,10294,nianwen xue,{COLING}-02: The First {SIGHAN} Workshop on {C}hinese Language Processing,0,"In this paper we report results of a supervised machine-learning approach to Chinese word segmentation. First, a maximum entropy tagger is trained on manually annotated data to automatically labels the characters with tags that indicate the position of character within a word. An error-driven transformation-based tagger is then trained to clean up the tagging inconsistencies of the first tagger. The tagged output is then converted into segmented text. The preliminary results show that this approach is competitive compared with other supervised machine-learning segmenters reported in previous studies."
C02-1145,Building a Large-Scale Annotated {C}hinese Corpus,2002,7,126,1,1,10294,nianwen xue,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"In this paper we address issues related to building a large-scale Chinese corpus. We try to answer four questions: (i) how to speed up annotation, (ii) how to maintain high annotation quality, (iii) for what purposes is the corpus applicable, and finally (iv) what future work we anticipate."
xia-etal-2000-developing,Developing Guidelines and Ensuring Consistency for {C}hinese Text Annotation,2000,-1,-1,3,0,16067,fei xia,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,None
