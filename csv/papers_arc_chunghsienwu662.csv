W13-4420,Candidate Scoring Using Web-Based Measure for {C}hinese Spelling Error Correction,2013,13,6,3,1,2441,liangchih yu,Proceedings of the Seventh {SIGHAN} Workshop on {C}hinese Language Processing,0,"Chinese character correction involves two major steps: 1) Providing candidate corrections for all or partially identified characters in a sentence, and 2) Scoring all altered sentences and identifying which is the best corrected sentence. In this paper a web-based measure is used to score candidate sentences, in which there exists one continuous error character in a sentence in almost all sentences in the Bakeoff corpora. The approach of using a web-based measure can be applied directly to sentences with multiple error characters, either consecutive or not, and is not optimized for one-character error correction of Chinese sentences. The results show that the approach achieved a fair precision score whereas the recall is low compared to results reported in this Bakeoff."
O13-5005,{HMM}-based {M}andarin Singing Voice Synthesis Using Tailored Synthesis Units and Question Sets,2013,7,0,3,0,41523,juyun cheng,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 18, Number 4, {D}ecember 2013-Special Issue on Selected Papers from {ROCLING} {XXV}",0,None
O13-1008,"åæå®å\
èåé¡éä¹å®ç¾©æ¼é±èå¼é¦¬å¯å¤«æ¨¡åä¸­ææ­è²åæç³»çµ±ä¹å»ºç« (Synthesis Unit and Question Set Definition for {M}andarin {HMM}-based Singing Voice Synthesis)",2013,7,0,3,0,41523,juyun cheng,Proceedings of the 25th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2013),0,None
P11-2106,Semantic Information and Derivation Rules for Robust Dialogue Act Detection in a Spoken Dialogue System,2011,13,3,2,0,44633,weibin liang,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"In this study, a novel approach to robust dialogue act detection for error-prone speech recognition in a spoken dialogue system is proposed. First, partial sentence trees are proposed to represent a speech recognition output sentence. Semantic information and the derivation rules of the partial sentence trees are extracted and used to model the relationship between the dialogue acts and the derivation rules. The constructed model is then used to generate a semantic score for dialogue act detection given an input speech utterance. The proposed approach is implemented and evaluated in a Mandarin spoken dialogue system for tour-guiding service. Combined with scores derived from the ASR recognition probability and the dialogue history, the proposed approach achieves 84.3% detection accuracy, an absolute improvement of 34.7% over the baseline of the semantic slot-based method with 49.6% detection accuracy."
O10-5002,Word Sense Disambiguation Using Multiple Contextual Features,2010,33,0,2,1,2441,liangchih yu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 15, Number 3-4, September/{D}ecember 2010",0,"Word sense disambiguation (WSD) is a technique used to identify the correct sense of polysemous words, and it is useful for many applications, such as machine translation (MT), lexical substitution, information retrieval (IR), and biomedical applications. In this paper, we propose the use of multiple contextual features, including the predicate-argument structure and named entities, to train two commonly used classifiers, Naive Bayes (NB) and Maximum Entropy (ME), for word sense disambiguation. Experiments are conducted to evaluate the classifiers' performance on the OntoNotes corpus and are compared with classifiers trained using a set of baseline features, such as the bag-of-words, n-grams, and part-of-speech (POS) tags. Experimental results show that incorporating both predicate-argument structure and named entities yields higher classification accuracy for both classifiers than does the use of the baseline features, resulting in accuracy as high as 81.6% and 87.4%, respectively, for NB and ME."
O10-1004,ç¼é³äºä»¶é©è­æ¼å¤èªè¾¨è­ç¼é³è®ç°æ¨¡åä¹ç¢ç (Pronunciation Variation Model Generation based on Pronunciation Event Verification for Multi-Lingual Speech Recognition) [In {C}hinese],2010,0,0,3,0,45747,peishan tsai,Proceedings of the 22nd Conference on Computational Linguistics and Speech Processing ({ROCLING} 2010),0,None
C10-1141,Discriminative Training for Near-Synonym Substitution,2010,20,8,5,1,2441,liangchih yu,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"Near-synonyms are useful knowledge resources for many natural language applications such as query expansion for information retrieval (IR) and paraphrasing for text generation. However, near-synonyms are not necessarily interchangeable in contexts due to their specific usage and syntactic constraints. Accordingly, it is worth to develop algorithms to verify whether near-synonyms do match the given contexts. In this paper, we consider the near-synonym substitution task as a classification task, where a classifier is trained for each near-synonym set to classify test examples into one of the near-synonyms in the set. We also propose the use of discriminative training to improve classifiers by distinguishing positive and negative features for each near-synonym. Experimental results show that the proposed method achieves higher accuracy than both pointwise mutual information (PMI) and n-gram-based methods that have been used in previous studies."
P09-2051,Mining Association Language Patterns for Negative Life Event Classification,2009,11,9,3,1,2441,liangchih yu,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"Negative life events, such as death of a family member, argument with a spouse and loss of a job, play an important role in triggering depressive episodes. Therefore, it is worth to develop psychiatric services that can automatically identify such events. In this paper, we propose the use of association language patterns, i.e., meaningful combinations of words (e.g., ), as features to classify sentences with negative life events into predefined categories (e.g., Family, Love, Work). The language patterns are discovered using a data mining algorithm, called association pattern mining, by incrementally associating frequently co-occurred words in the sentences annotated with negative life events. The discovered patterns are then combined with single words to train classifiers. Experimental results show that association language patterns are significant features, thus yielding better performance than the baseline system using single words alone."
O09-1017,æç¨å¥åçµæ§èé¨ä»½æ¨£æ¬æ¨¹æ¼å°è©±è¡çºä¹åµæ¸¬ (Dialogue Act Detection Using Sentence Structure and Partial Pattern Trees) [In {C}hinese],2009,0,0,3,0,44633,weibin liang,Proceedings of the 21st Conference on Computational Linguistics and Speech Processing,0,None
O08-6002,Corpus Cleanup of Mistaken Agreement Using Word Sense Disambiguation,2008,30,0,2,1,2441,liangchih yu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 13, Number 4, {D}ecember 2008",0,"Word sense annotated corpora are useful resources for many text mining applications. Such corpora are only useful if their annotations are consistent. Most large-scale annotation efforts take special measures to reconcile inter-annotator disagreement. To date, however, nobody has investigated how to automatically determine exemplars in which the annotators agree but are wrong. In this paper, we use OntoNotes, a large-scale corpus of semantic annotations, including word senses, predicate-argument structure, ontology linking, and coreference. To determine the mistaken agreements in word sense annotation, we employ word sense disambiguation (WSD) to select a set of suspicious candidates for human evaluation. Experiments are conducted from three aspects (precision, cost-effectiveness ratio, and entropy) to examine the performance of WSD. The experimental results show that WSD is most effective in identifying erroneous annotations for highly-ambiguous words, while a baseline is better for other cases. The two methods can be combined to improve the cleanup process. This procedure allows us to find approximately 2% of the remaining erroneous agreements in the OntoNotes corpus. A similar procedure can be easily defined to check other annotated corpora."
O08-1011,Propositional Term Extraction over Short Text using Word Cohesiveness and Conditional Random Fields with Multi-Level Features,2008,17,0,2,0,2297,ruyng chang,Proceedings of the 20th Conference on Computational Linguistics and Speech Processing,0,"Propositional terms in a research abstract (RA) generally convey the most important information for readers to quickly glean the contribution of a research article. This paper considers propositional term extraction from RAs as a sequence labeling task using the IOB (Inside, Outside, Beginning) encoding scheme. In this study, conditional random fields (CRFs) are used to initially detect the propositional terms, and the combined association measure (CAM) is applied to further adjust the term boundaries. This method can extract beyond simply NP-based propositional terms by combining multi-level features and inner lexical cohesion. Experimental results show that CRFs can significantly increase the recall rate of imperfect boundary term extraction and the CAM can further effectively improve the term boundaries."
C08-1133,{O}nto{N}otes: Corpus Cleanup of Mistaken Agreement Using Word Sense Disambiguation,2008,20,5,2,1,2441,liangchih yu,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"Annotated corpora are only useful if their annotations are consistent. Most large-scale annotation efforts take special measures to reconcile inter-annotator disagreement. To date, however, no-one has investigated how to automatically determine exemplars in which the annotators agree but are wrong. In this paper, we use OntoNotes, a large-scale corpus of semantic annotations, including word senses, predicate-argument structure, ontology linking, and coreference. To determine the mistaken agreements in word sense annotation, we employ word sense disambiguation (WSD) to select a set of suspicious candidates for human evaluation. Experiments are conducted from three aspects (precision, cost-effectiveness ratio, and entropy) to examine the performance of WSD. The experimental results show that WSD is most effective on identifying erroneous annotations for highly-ambiguous words, while a baseline is better for other cases. The two methods can be combined to improve the cleanup process. This procedure allows us to find approximately 2% remaining erroneous agreements in the OntoNotes corpus. A similar procedure can be easily defined to check other annotated corpora."
P07-1129,Topic Analysis for Psychiatric Document Retrieval,2007,14,3,2,1,2441,liangchih yu,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"Psychiatric document retrieval attempts to help people to efficiently and effectively locate the consultation documents relevant to their depressive problems. Individuals can understand how to alleviate their symptoms according to recommendations in the relevant documents. This work proposes the use of high-level topic information extracted from consultation documents to improve the precision of retrieval results. The topic information adopted herein includes negative life events, depressive symptoms and semantic relations between symptoms, which are beneficial for better understanding of users' queries. Experimental results show that the proposed approach achieves higher precision than the word-based retrieval models, namely the vector space model (VSM) and Okapi model, adopting word-level information alone."
O07-3005,Emotion Recognition from Speech Using {IG}-Based Feature Compensation,2007,-1,-1,1,1,40687,chunghsien wu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 12, Number 1, March 2007: Special Issue on Affective Speech Processing",0,None
P06-2120,Stochastic Discourse Modeling in Spoken Dialogue Systems Using Semantic Dependency Graphs,2006,17,6,2,1,31442,juifeng yeh,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"This investigation proposes an approach to modeling the discourse of spoken dialogue using semantic dependency graphs. By characterizing the discourse as a sequence of speech acts, discourse modeling becomes the identification of the speech act sequence. A statistical approach is adopted to model the relations between words in the user's utterance using the semantic dependency graphs. Dependency relation between the headword and other words in a sentence is detected using the semantic dependency grammar. In order to evaluate the proposed method, a dialogue system for medical service is developed. Experimental results show that the rates for speech act detection and task-completion are 95.6% and 85.24%, respectively, and the average number of turns of each dialogue is 8.3. Compared with the Bayes' classifier and the Partial-Pattern Tree based approaches, we obtain 14.9% and 12.47% improvements in accuracy for speech act identification, respectively."
P06-2121,{HAL}-Based Cascaded Model for Variable-Length Semantic Pattern Induction from Psychiatry Web Resources,2006,16,1,2,1,2441,liangchih yu,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"Negative life events play an important role in triggering depressive episodes. Developing psychiatric services that can automatically identify such events is beneficial for mental health care and prevention. Before these services can be provided, some meaningful semantic patterns, such as , have to be extracted. In this work, we present a text mining framework capable of inducing variable-length semantic patterns from unannotated psychiatry web resources. This framework integrates a cognitive motivated model, Hyperspace Analog to Language (HAL), to represent words as well as combinations of words. Then, a cascaded induction process (CIP) bootstraps with a small set of seed patterns and incorporates relevance feedback to iteratively induce more relevant patterns. The experimental results show that by combining the HAL model and relevance feedback, the CIP can induce semantic patterns from the unannotated web corpora so as to reduce the reliance on annotated corpora."
O06-1010,"å©ç¨è²å­¸èæèåææ¼å¤èªèªé³è¾¨è­å®å\
ä¹ç¢ç (Generation of Phonetic Units for Multilingual Speech Recognition Based on Acoustic and Contextual Analysis) [In {C}hinese]",2006,0,0,3,0,50031,shihhao wang,Proceedings of the 18th Conference on Computational Linguistics and Speech Processing,0,None
O06-1012,æç¨ä¸å®é·åº¦ç¹å¾µä¹æ¢ä»¶é¨æ©åæ¼å£èªä¸æµæ¢èªæµä¿®æ­£ (Disfluency Correction of Spontaneous Speech using Conditional Random Fields with Variable Length Features) [In {C}hinese],2006,12,0,3,1,31442,juifeng yeh,Proceedings of the 18th Conference on Computational Linguistics and Speech Processing,0,None
O05-3005,{TAICAR} {--} The Collection and Annotation of an In-Car Speech Database Created in {T}aiwan,2005,9,8,4,0,50925,hsienchang wang,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 10, Number 2, June 2005: Special Issue on Annotated Speech Corpora",0,"This paper describes a project that aims to create a Mandarin speech database for the automobile setting (TAICAR). A group of researchers from several universities and research institutes in Taiwan have participated in the project. The goal is to generate a corpus for the development and testing of various speech-processing techniques. There are six recording sites in this project. Various words, sentences, and spontaneously queries uttered in the vehicular navigation setting have been collected in this project. A preliminary corpus of utterances from 192 speakers was created from utterances generated in different vehicles. The database contains more than 163,000 files, occupying 16.8 gigabytes of disk space."
O05-2003,Automated Alignment and Extraction of a Bilingual Ontology for Cross-Language Domain-Specific Applications,2005,0,3,2,1,31442,juifeng yeh,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 10, Number 1, March 2005",0,None
O05-1011,"æç¨é¯èª¤åæ\
åææ¼è±èªç¼é³è¼å©å­¸ç¿ ({E}nglish pronunciation assisted learning using error type analysis) [In {C}hinese]",2005,0,0,3,0,50954,sheming tang,Proceedings of the 17th Conference on Computational Linguistics and Speech Processing,0,None
W04-1110,Automated Alignment and Extraction of Bilingual Domain Ontology for Medical Domain Web Search,2004,15,2,2,1,31442,juifeng yeh,Proceedings of the Third {SIGHAN} Workshop on {C}hinese Language Processing,0,"This paper proposes an approach to automated ontology alignment and domain ontology extraction from two knowledge bases. First, WordNet and HowNet knowledge bases are aligned to construct a bilingual universal ontology based on the co-occurrence of the words in a parallel corpus. The bilingual universal ontology has the merit that it contains more structural and semantic information coverage from two complementary knowledge bases, WordNet and HowNet. For domain-specific applications, a medical domain ontology is further extracted from the universal ontology using the islanddriven algorithm and a medical domain corpus. Finally, the domain-dependent terms and some axioms between medical terms based on a medical encyclopaedia are added into the ontology. For ontology evaluation, experiments on web search were conducted using the constructed ontology. The experimental results show that the proposed approach can automatically align and extract the domain-specific ontology. In addition, the extracted ontology also shows its promising ability for medical web search."
O04-3004,Multi-Modal Emotion Recognition from Speech and Text,2004,11,86,2,1,47260,zejing chuang,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 9, Number 2, August 2004: Special Issue on New Trends of Speech and Language Processing",0,"This paper presents an approach to emotion recognition from speech signals and textual content. In the analysis of speech signals, thirty-three acoustic features are extracted from the speech input. After Principle Component Analysis (PCA) is performed, 14 principle components are selected for discriminative representation. In this representation, each principle component is the combination of the 33 original acoustic features and forms a feature subspace. Support Vector Machines (SVMs) are adopted to classify the emotional states. In text analysis, all emotional keywords and emotion modification words are manually defined. The emotion intensity levels of emotional keywords and emotion modification words are estimated based on a collected emotion corpus. The final emotional state is determined based on the emotion outputs from the acoustic and textual analyses. Experimental results show that the emotion recognition accuracy of the integrated system is better than that of either of the two individual approaches."
O04-1021,æç¨èªæåº«åèªæç¸ä¾æ³åæ¼ä¸­æèªé³æä»¶ä¹æè¦ (Spoken Document Summarization Using Topic-Related Corpus and Semantic Dependency Grammar) [In {C}hinese],2004,0,0,3,1,41938,chienlin huang,Proceedings of the 16th Conference on Computational Linguistics and Speech Processing,0,None
O04-1033,"æç¨æ©çå¼å¥æ³çµæ§èé±å«å¼èªæç´¢å¼æ¼æ\
ç·èªé³åæä¹å®å\
é¸å (Unit Selection for Corpus-Based Emotional Speech Synthesis Using {PCFG} and {LSI}) [In {C}hinese]",2004,0,0,3,0,51807,jiunfu chen,Proceedings of the 16th Conference on Computational Linguistics and Speech Processing,0,None
C04-1164,Automated Alignment and Extraction of Bilingual Domain Ontology for Cross-Language Domain-Specific Applications,2004,14,15,2,1,31442,juifeng yeh,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"In this paper we propose a novel approach for ontology alignment and domain ontology extraction from the existing knowledge bases, WordNet and HowNet. These two knowledge bases are aligned to construct a bilingual ontology based on the cooccurrence of the words in the sentence pairs of a parallel corpus. The bilingual ontology has the merit that it contains more structural and semantic information coverage from these two complementary knowledge bases. For domainspecific applications, the domain specific ontology is further extracted from the bilingual ontology by the island-driven algorithm and the domain-specific corpus. Finally, the domain-dependent terminologies and some axioms between domain terminologies are integrated into the ontology. For ontology evaluation, experiments were conducted by comparing the benchmark constructed by the ontology engineers or experts. The experimental results show that the proposed approach can extract an aligned bilingual domain-specific ontology."
O03-1015,ä»¥ç¥è­æ¦å¿µæ¨¡åçºåºç¤ä¹å¤ä¸»é¡å°è©±ç®¡çç³»çµ± (Ontology-Based Dialog Management for Multiple Service Integration) [In {C}hinese],2003,0,0,3,0,50933,mingjun chen,Proceedings of Research on Computational Linguistics Conference {XV},0,None
W02-1904,{FAQ} Mining via List Detection,2002,9,17,3,1,53142,yusheng lai,{COLING}-02: Multilingual Summarization and Question Answering,0,"This paper presents an approach to FAQ mining via a list detection algorithm. List detection is very important for data collection since list has been widely used for representing data and information on the Web. By analyzing the rendering of FAQs on the Web, we found a fact that all FAQs are always fully/partially represented in a list-like form. There are two ways to author a list on the Web. One is to use some specific tags, e.g. tag for HTML. The lists authored in this way can be easily detected by parsing those special tags. Another way uses other tags instead of the special tags. Unfortunately, many lists are authored in the second way. To detect lists, therefore, we present an algorithm, which is independent of Web languages. By combining the algorithm with some domain knowledge, we detect and collect FAQs from the Web. The mining task achieved a performance of 72.54% recall and 80.16% precision rates."
O01-1005,Using Chi-Square Testing in Modeling Confusion Characteristics for Robust Phonetic Set Generation,2001,7,0,2,0,53890,yeoujiunn chen,Proceedings of Research on Computational Linguistics Conference {XIV},0,"A phonetic representation of a language is used to describe the corresponding pronunciation and synthesize the acoustic model of any vocabulary. In order to obtain better phonetic representation, context-dependent units are used to model co-articulation effects between phones and have been broadly in speech recognition. However, this representation generally increases the number of recognition units. A phonetic representation with smaller phonetic units such as SAMPA-C for Mandarin Chinese can be applied to reduce the number of recognition units. Nevertheless, smaller phonetic units such as SAMPA-C will contain confusion characters and generally degrade the recognition performance. In this paper, a statistical method based on chi-square testing is used to investigate the confusion characteristics among phonetic units and develop a more reliable phonetic set, named modified SAMPA-C. Finally, experiments on continuous Mandarin telephone speech recognition were conducted. Experimental results show an encouraging improvement on recognition performance can be obtained. In addition, the proposed approaches represent a good compromise between the demands of accurate acoustic modeling."
O00-1007,ç¶²éç¶²è·¯{FAQ} æª¢ç´¢ä¸­æåèåèèªææ¯å°ä¹ç ç©¶ (Intention Extraction and Semantic Matching for {I}nternet {FAQ} Retrieval Using Spoken Language Query) [In {C}hinese],2000,0,2,3,1,53142,yusheng lai,Proceedings of Research on Computational Linguistics Conference {XIII},0,None
O00-1012,{PC}-Based å°ç£æèªè½èªé³æºéè¼å©ç³»çµ± ({PC}-based {T}aiwanese Sign Language to Speech Communication Aided System)[In {C}hinese],2000,0,0,2,0,54376,yuhsien chiu,Proceedings of Research on Computational Linguistics Conference {XIII},0,None
Y99-1035,Automatic Selection of Synthesis Units from a Large Speech Database,1999,7,0,2,0,53880,jauhung chen,"Proceedings of the 13th Pacific Asia Conference on Language, Information and Computation",0,"In this paper, a novel method for the selection of synthesis unit is proposed. The monosyllables are adopted as the basic synthesis units. A set of high-quality synthesis units is selected from a large continuous speech database based on four procedures: pitch period detection and smoothing, speech unit filtering, unit selection, and manual examination. Two cost functions are proposed for obtaining the synthesis units, which minimize the interand intra-syllable distortion. The cost functions estimate the parameters including the prosodic features, the LSP frequencies, and types of syllable concatenation. Experimental results showed that a match rate of 48.9% was achieved. It indicates that about half of the best synthesis units can be automatically obtained. Also, a replacement rate of 4.8% was obtained."
O99-2002,On Modeling Remote and Local Dependencies in Language,1999,0,0,2,1,53142,yusheng lai,{ROCLING} 1999 Short Papers,0,None
O99-1001,"å°èªå¤è²èª¿é³ç¯åæå®å\
è³æåº«æ¨æå­è½èªé³éå½¢ç³»çµ±ä¹ç¼å± (Establish {T}aiwanese 7-Tones Syllable-based Synthesis Units Database for the Prototype Development of Text-To-Speech System) [In {C}hinese]",1999,0,3,3,0,54948,yungji sher,Proceedings of Research on Computational Linguistics Conference {XII},0,None
O98-1010,æç¨é±èå¼é¦¬å¯å¤«æ¨¡åèå£è¿°å°è©±ç³»çµ±ä¹ç ç©¶ (Spoken Dialogue System Using Hidden {M}arkov Model) [In {C}hinese],1998,0,0,2,0,55382,gwolang yan,Proceedings of Research on Computational Linguistics Conference {XI},0,None
O97-2008,Prosody Generation in a {C}hinese {TTS} System Based on a Hierarchical Word Prosody Template Tree,1997,-1,-1,1,1,40687,chunghsien wu,{ROCLING} 1997 Poster Papers,0,None
Y96-1030,A {M}andarin Voice Organizer Based on a Template-Matching Speech Recognizer,1996,5,0,3,0.208618,15583,jhingfa wang,"Proceedings of the 11th Pacific Asia Conference on Language, Information and Computation",0,"On the observation of current available voice organizers, all of them accept only voice commands or word-based commands. Using natural spoken language to operate organizer is still a difficult problem. In this paper, a template-based speech recognizer which accepts near(constrained) spoken language is proposed. Since the template-based recognizer is a domain-dependent speech recognition system, representing and matching of sentence templates become the main tasks of the recognizer. We use finate state networks(FSNs) to represent the sentence templates and propose a vowel-based, syllable-scoring method to match a correct template. By replacing the template sets, this method can be easily applied to other domains. Besides, two main functions, voice recording and voice message query, are implemented on our organizer using a fast CELP encoder/decoder to compress/decompress the voice data in realtime. Experimental results shows that the collected 31 sentence templates can greatly improve the voice interface between the user and the voice organizer."
O96-1003,ä¸­è±ææå¥ç¿»èªé³ç³»çµ±ä¸­é£é³èçä¹ç ç©¶ (A Study on the Coarticulation Generation in {C}hinese-{E}nglish Text to Speech Synthesis) [In {C}hinese],1996,-1,-1,1,1,40687,chunghsien wu,Proceedings of Rocling {IX} Computational Linguistics Conference {IX},0,None
O95-1010,ä»¥{CELP}çºåºç¤ä¹æå¥ç¿»èªé³ä¸­é»å¾è¨æ¯ä¹ç¢çèèª¿æ´ (Prosodic Information Generation and Adjustment in Text to Speech Synthesis Based on {CELP}) [In {C}hinese],1995,0,0,1,1,40687,chunghsien wu,Proceedings of Rocling {VIII} Computational Linguistics Conference {VIII},0,None
