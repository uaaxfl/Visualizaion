2011.mtsummit-papers.23,W05-0909,0,0.167478,"Missing"
2011.mtsummit-papers.23,J93-2003,0,0.0408229,"Predicates (CPs) is absent, such complex predicates are considered as Multi Word Expressions (MWEs)(Baldwin and Kim, 2010, Sinha, 2009). The other types of predicates such as ĒĂĘĠĺñĊ niye gelo ‘take-go’ (took and went), ĒĀĘĠ ĺñĊ diye gelo ‘give-go’ (gave and went) follow the lexical pattern FV+LV, similar to Complex Predicates (CPs) but the Full Verb and Light Verb behave as independent syntactic entities. These verb patterns are nonComplex Predicates (non-CPs) and are also termed as Serial Verb (SV) (Mukherjee et al., 2006). Traditional approaches to word alignment follow the IBM Models (Brown et al., 1993). These approaches are unable to handle many-tomany alignments and hence do not work well with multi-word expressions, especially with NEs, reduplications and complex predicates. The alignment probabilities in the well-known Hidden Markov Model (HMM: Vogel et al., 1996) depend on the alignment position of the previous word. The HMM model does not explicitly consider many-to-many alignments. In this experiment, we address this many-tomany alignment problem indirectly. Our objective is to see how the identification of MWEs enhances the performance of the SMT system. In this work, several types o"
2011.mtsummit-papers.23,N10-1029,0,0.0315736,"ported a discriminative approach to use the compositionality information of verb-based multi-word expressions in order to improve the word alignment quality. Ren et al. (2009) presented a log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual MWEs. They investigated the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into the Moses decoder (Koehn et al., 2007). They observed the highest improvement with an additional feature that identifies whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010) who replaced the binary feature by a count feature representing the number of MWEs in the source language phrase. Intuitively, MWEs on the source and the target sides should be both aligned in the parallel corpus and translated as a whole. However, in the state-of-the-art PB-SMT systems, the constituents of an MWE are marked and aligned as parts of consecutive phrases, since PB-SMT (or any other approaches to SMT) does not generally treat MWEs as special tokens. Another problem with SMT systems is the wrong translation of verb phrases. Sometimes verb phrases are deleted in the output sentence"
2011.mtsummit-papers.23,C08-2007,0,0.0657892,"Missing"
2011.mtsummit-papers.23,W10-3710,1,0.919301,"fied on both sides of the parallel corpus. Das et al. (2010) analyzed and identified a category of compound verbs (Verb + Verb) and conjunct verbs (Noun /Adjective/Adverb + Verb) for Bengali. We adapted their strategy for identification of compound verbs as well as serial verbs (Verb + Verb + Verb) in Bengali. For the identification of Named-Entities and their alignment, we have adopted a similar technique as reported in Pal.et.al (2010). Reduplicated phrases do not occur very frequently in the English corpus; some of them (like correlatives, semantic reduplications) are not found in English (Chakraborty and Bandyopadhyay, 2010). But reduplication plays a crucial role on the target Bengali side as they occur with high frequency. These reduplicated phrases are considered as a single-token so that they may map to a single word on the source side. Phrasal prepositions and verb object combinations are also treated as single tokens. Once the compound verbs and the NEs are identified on both sides of the parallel corpus, they are assembled into single tokens. When converting these MWEs into single tokens, we replace the spaces with underscores (‘_’). Since there are already some hyphenated words in the corpus, we do not us"
2011.mtsummit-papers.23,C04-1114,0,0.022419,"ex predicates are identified on both sides of the parallel corpus. In the target side, identification of the Noun-noun MWEs and reduplicated phrases are carried out. We use simple rule-based and statistical approaches to identify these MWEs. Source and target language NEs are aligned using a statistical transliteration technique. We rely on these automatically aligned NEs and treat them as translation examples (Pal.et.al, 2010). Adding bilingual dictionaries, which in effect are instances of atomic translation pairs, to the parallel corpus is a well-known practice in domain adaptation in SMT (Eck et al., 2004; Wu et al., 2008). We modify the parallel corpus by converting the MWEs into single tokens and adding the aligned NEs and complex predicates in the parallel cor216 pus to improve the word alignment and hence the phrase alignment quality. The preprocessing of the parallel corpus results in improved MT quality in terms of automatic MT evaluation metrics. The remainder of the paper is organized as follows. Next section briefly elaborates the related work. The English-Bengali PBSMT system is described in Section 3. Section 4 states the tools and resources used for the various experiments. Section"
2011.mtsummit-papers.23,W09-3539,1,0.886048,"Missing"
2011.mtsummit-papers.23,W04-3248,0,0.021351,"tes the related work. The English-Bengali PBSMT system is described in Section 3. Section 4 states the tools and resources used for the various experiments. Section 5 includes the results obtained, together with some analysis. Section 6 concludes and provides avenues for further work. 2 Related Work Moore (2003) used capitalization cues for identifying NEs on the English side and then applied statistical techniques to decide which portion of the target language corresponds to the specified English NE. A Maximum Entropy model based approach for English—Chinese NE alignment has been proposed in Feng et al. (2004) which significantly outperforms IBM Model 4 and HMM. A method for automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization has been proposed in Huang et al. (2003). Venkatapathy and Joshi (2006) reported a discriminative approach to use the compositionality information of verb-based multi-word expressions in order to improve the word alignment quality. Ren et al. (2009) presented a log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual MWEs. They investigated the usefulness of these biling"
2011.mtsummit-papers.23,W03-1502,0,0.0222628,"n the parallel cor216 pus to improve the word alignment and hence the phrase alignment quality. The preprocessing of the parallel corpus results in improved MT quality in terms of automatic MT evaluation metrics. The remainder of the paper is organized as follows. Next section briefly elaborates the related work. The English-Bengali PBSMT system is described in Section 3. Section 4 states the tools and resources used for the various experiments. Section 5 includes the results obtained, together with some analysis. Section 6 concludes and provides avenues for further work. 2 Related Work Moore (2003) used capitalization cues for identifying NEs on the English side and then applied statistical techniques to decide which portion of the target language corresponds to the specified English NE. A Maximum Entropy model based approach for English—Chinese NE alignment has been proposed in Feng et al. (2004) which significantly outperforms IBM Model 4 and HMM. A method for automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization has been proposed in Huang et al. (2003). Venkatapathy and Joshi (2006) reported a discriminative approac"
2011.mtsummit-papers.23,N03-1017,0,0.055513,"rallel corpus. The sentences on the target side (Bengali) are POS-tagged by using the tools obtained from the consortium mode project “Development of Indian Language to Indian Language Machine Translation (IL-ILMT) System2”. NEs in Bengali are identified using the NER system of Ekbal and Bandyopadhyay (2008). We have used the Stanford Parser and the Bengali NER. The effectiveness of the MWE-aligned parallel corpus is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phrase-extraction heuristics described in (Koehn et al., 2003), minimumerror-rate training (Och, 2003) on a held-out development set, target language model trained using SRILM toolkit (Stolcke, 2002) with Knes2 The EILMT and ILILMT projects are funded by the Department of Information Technology (DIT), Ministry of Communications and Information Technology (MCIT), Government of India. 3 http://nlp.stanford.edu/software/lex-parser.shtml 4 http://crfchunker.sourceforge.net/ 5 http://wordnet.princeton.edu/ 220 er-Ney smoothing (Kneser and Ney, 1995) and the Moses decoder (Koehn et al., 2007). 5 Experiments and Results We have randomly identified 500 sentences"
2011.mtsummit-papers.23,P07-2045,0,0.0205942,"omatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization has been proposed in Huang et al. (2003). Venkatapathy and Joshi (2006) reported a discriminative approach to use the compositionality information of verb-based multi-word expressions in order to improve the word alignment quality. Ren et al. (2009) presented a log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual MWEs. They investigated the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into the Moses decoder (Koehn et al., 2007). They observed the highest improvement with an additional feature that identifies whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010) who replaced the binary feature by a count feature representing the number of MWEs in the source language phrase. Intuitively, MWEs on the source and the target sides should be both aligned in the parallel corpus and translated as a whole. However, in the state-of-the-art PB-SMT systems, the constituents of an MWE are marked and aligned as parts of consecutive phrases, since PB-SMT (or any other ap"
2011.mtsummit-papers.23,W04-3250,0,0.162084,"Missing"
2011.mtsummit-papers.23,W09-2906,0,0.047178,"Missing"
2011.mtsummit-papers.23,E03-1035,0,0.0223954,"ates in the parallel cor216 pus to improve the word alignment and hence the phrase alignment quality. The preprocessing of the parallel corpus results in improved MT quality in terms of automatic MT evaluation metrics. The remainder of the paper is organized as follows. Next section briefly elaborates the related work. The English-Bengali PBSMT system is described in Section 3. Section 4 states the tools and resources used for the various experiments. Section 5 includes the results obtained, together with some analysis. Section 6 concludes and provides avenues for further work. 2 Related Work Moore (2003) used capitalization cues for identifying NEs on the English side and then applied statistical techniques to decide which portion of the target language corresponds to the specified English NE. A Maximum Entropy model based approach for English—Chinese NE alignment has been proposed in Feng et al. (2004) which significantly outperforms IBM Model 4 and HMM. A method for automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization has been proposed in Huang et al. (2003). Venkatapathy and Joshi (2006) reported a discriminative approac"
2011.mtsummit-papers.23,P03-1021,0,0.0278586,"Bengali) are POS-tagged by using the tools obtained from the consortium mode project “Development of Indian Language to Indian Language Machine Translation (IL-ILMT) System2”. NEs in Bengali are identified using the NER system of Ekbal and Bandyopadhyay (2008). We have used the Stanford Parser and the Bengali NER. The effectiveness of the MWE-aligned parallel corpus is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phrase-extraction heuristics described in (Koehn et al., 2003), minimumerror-rate training (Och, 2003) on a held-out development set, target language model trained using SRILM toolkit (Stolcke, 2002) with Knes2 The EILMT and ILILMT projects are funded by the Department of Information Technology (DIT), Ministry of Communications and Information Technology (MCIT), Government of India. 3 http://nlp.stanford.edu/software/lex-parser.shtml 4 http://crfchunker.sourceforge.net/ 5 http://wordnet.princeton.edu/ 220 er-Ney smoothing (Kneser and Ney, 1995) and the Moses decoder (Koehn et al., 2007). 5 Experiments and Results We have randomly identified 500 sentences each for the development set and the te"
2011.mtsummit-papers.23,W10-3707,1,0.463916,"Missing"
2011.mtsummit-papers.23,P02-1040,0,0.092291,"Missing"
2011.mtsummit-papers.23,W09-2907,0,0.0191371,"on of the target language corresponds to the specified English NE. A Maximum Entropy model based approach for English—Chinese NE alignment has been proposed in Feng et al. (2004) which significantly outperforms IBM Model 4 and HMM. A method for automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization has been proposed in Huang et al. (2003). Venkatapathy and Joshi (2006) reported a discriminative approach to use the compositionality information of verb-based multi-word expressions in order to improve the word alignment quality. Ren et al. (2009) presented a log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual MWEs. They investigated the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into the Moses decoder (Koehn et al., 2007). They observed the highest improvement with an additional feature that identifies whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010) who replaced the binary feature by a count feature representing the number of MWEs in the source language phrase. Intuitively, MWEs on the source and t"
2011.mtsummit-papers.23,W06-1204,0,0.0606765,"Missing"
2011.mtsummit-papers.23,C96-2141,0,0.381653,"ollow the lexical pattern FV+LV, similar to Complex Predicates (CPs) but the Full Verb and Light Verb behave as independent syntactic entities. These verb patterns are nonComplex Predicates (non-CPs) and are also termed as Serial Verb (SV) (Mukherjee et al., 2006). Traditional approaches to word alignment follow the IBM Models (Brown et al., 1993). These approaches are unable to handle many-tomany alignments and hence do not work well with multi-word expressions, especially with NEs, reduplications and complex predicates. The alignment probabilities in the well-known Hidden Markov Model (HMM: Vogel et al., 1996) depend on the alignment position of the previous word. The HMM model does not explicitly consider many-to-many alignments. In this experiment, we address this many-tomany alignment problem indirectly. Our objective is to see how the identification of MWEs enhances the performance of the SMT system. In this work, several types of MWEs like phrasal prepositions and Verb-object combinations are automatically identified on the source side while named-entities and complex predicates are identified on both sides of the parallel corpus. In the target side, identification of the Noun-noun MWEs and re"
2011.mtsummit-papers.23,C08-1125,0,0.039656,"Missing"
2013.mtsummit-papers.8,W05-0909,0,0.502789,"Missing"
2013.mtsummit-papers.8,W12-5108,0,0.0173497,"y extract bilingual MWEs has been described in Ren et al. (2009). They examined the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into the Moses decoder (Koehn et al., 2007). They observed the highest improvement with an additional feature that identifies whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010) who replaced the binary feature by a count feature representing the number of MWEs in the source language phrase. A hybrid approach to identify MWEs from the English-French parallel corpus proposed by (Bouamor et al., 2012a), they aligned only many to many correspondences and deals with highly correlated MWE in a sentence pair, those are then integrated into the MOSES SMT System (Bouamor et al., 2012b). MWEs in SMT for Verbmobil corpus has also been proposed by (Lambert et al., 2005), the performance of the system evaluated in terms of alignment and translation quality. Instinctively, MWEs on the source and the target sides should be both aligned in the parallel corpus and translated as a whole. However, the constituents of an MWE are identified and aligned as parts of consecutive phrases in the state-of-the-ar"
2013.mtsummit-papers.8,bouamor-etal-2012-identifying,0,0.039193,"Missing"
2013.mtsummit-papers.8,J93-2003,0,0.0662809,"Missing"
2013.mtsummit-papers.8,N10-1029,0,0.0691116,"discriminative approach to use the compositionality information of verb-based multi-word expressions in order to improve the word alignment quality. A log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual MWEs has been described in Ren et al. (2009). They examined the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into the Moses decoder (Koehn et al., 2007). They observed the highest improvement with an additional feature that identifies whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010) who replaced the binary feature by a count feature representing the number of MWEs in the source language phrase. A hybrid approach to identify MWEs from the English-French parallel corpus proposed by (Bouamor et al., 2012a), they aligned only many to many correspondences and deals with highly correlated MWE in a sentence pair, those are then integrated into the MOSES SMT System (Bouamor et al., 2012b). MWEs in SMT for Verbmobil corpus has also been proposed by (Lambert et al., 2005), the performance of the system evaluated in terms of alignment and translation quality. Instinctively, MWEs on"
2013.mtsummit-papers.8,W10-3710,1,0.92874,"ailable. Furthermore, this is the first time when the identification of MWEs in Bengali language is used to enhance the performance of an EnglishBengali Machine Translation System. 3 3.1 System Description Preprocessing of the parallel corpus We considered several types of multi-word expressions: noun-noun MWEs, reduplicated phrases, complex predicates, phrasal prepositions, and verb-object combination. For the identification of complex predicates, we adopted a similar technique as reported in (Das et al., 2010). There are no frequent occurrences of reduplicated phrases in the English Corpus (Chakraborty and Bandyopadhyay, 2010) in comparison with the Bengali corpus, so this plays very crucial role in machine translation as they occur with high frequently in the Bengali corpus. Once the MWEs are identified, they are converted into single-tokens by replacing the spaces with underscores (‗_‘) so that we can establish 1to-1 alignments between the source and target MWEs. 63 3.2 MWE Identification Noun-Noun MWE Identification: When two or more nouns are united together to form a solo phrase such as ‗bed room‘ or ‗dining table‘ (Baldwin and Kim, 2010), these are termed as compound nouns or nominal compounds. Compound noun"
2013.mtsummit-papers.8,J90-1003,0,0.487629,"Missing"
2013.mtsummit-papers.8,J93-1003,0,0.47067,"Missing"
2013.mtsummit-papers.8,C04-1114,0,0.0325266,"unds are automatically extracted on the source side while noun-noun compounds, reduplicated phrases and complex predicates are identified on the target side of the parallel corpus. We use simple rule-based and statistical approaches to identify these MWEs. We have also extracted MWEs from comparable corpora which enhance not only MWE identification quality but also provide out-of-vocabulary words to SMT system. This also helps to accrue some knowledge of out of domain data. Source and target language MWEs are aligned using a Hybrid technique. A well-known practice in domain adaptation in SMT (Eck et al., 2004; Wu et al., 2008) is to incorporate bilingual dictionaries to the training corpus; which affects on the instances of atomic translation pairs. The work has been carried out into three direction (i) The parallel corpus has been modified by single tokenization of MWEs, (ii) The alignment of MWEs are added in the parallel corpus as additional data to improve the word alignment as well as the phrase alignment quality and (iii) The alignment of MWE has been directly incorporated into the word alignment model. The preprocessing of the parallel corpus results in improved MT quality in terms of autom"
2013.mtsummit-papers.8,N03-1017,0,0.0246219,"eline system: GIZA++ implementation of IBM word alignment 2 The EILMT project is funded by the Department of Electronics and Information Technology (DEITY), Ministry of Communications and Information Technology (MCIT), Government of India. 3 http://nlp.stanford.edu/software/lex-parser.shtml 4 http://crfchunker.sourceforge.net/ 5 http://wordnet.princeton.edu/ 6 The IL-ILMT project is funded by the Department of Electronics and Information Technology (DEITY), Ministry of Communications and Information Technology (MCIT), Government of India. 65 model 4, phrase-extraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model trained using SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing (Kneser and Ney, 1995) and the Moses decoder (Koehn et al., 2007) have been used in the present study. 5 Experiments and Evaluations We have randomly identified 500 sentences each for the development set and the test set from the initial parallel corpus. The rest are considered as the training corpus. The training corpus was filtered with the maximum allowable sentence length of 100 words and sentence length ratio of 1:2 (either wa"
2013.mtsummit-papers.8,P07-2045,0,0.016243,"eriments. Section 5 includes the results obtained, together with some analysis. Section 6 concludes and provides avenues for further work. 2 Related Work Venkatapathy and Joshi (2006) reported a discriminative approach to use the compositionality information of verb-based multi-word expressions in order to improve the word alignment quality. A log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual MWEs has been described in Ren et al. (2009). They examined the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into the Moses decoder (Koehn et al., 2007). They observed the highest improvement with an additional feature that identifies whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010) who replaced the binary feature by a count feature representing the number of MWEs in the source language phrase. A hybrid approach to identify MWEs from the English-French parallel corpus proposed by (Bouamor et al., 2012a), they aligned only many to many correspondences and deals with highly correlated MWE in a sentence pair, those are then integrated into the MOSES SMT System (Bouamor et al., 20"
2013.mtsummit-papers.8,W04-3250,0,0.388494,"Missing"
2013.mtsummit-papers.8,2005.mtsummit-posters.11,0,0.059502,"Missing"
2013.mtsummit-papers.8,P03-1021,0,0.0185684,"ignment 2 The EILMT project is funded by the Department of Electronics and Information Technology (DEITY), Ministry of Communications and Information Technology (MCIT), Government of India. 3 http://nlp.stanford.edu/software/lex-parser.shtml 4 http://crfchunker.sourceforge.net/ 5 http://wordnet.princeton.edu/ 6 The IL-ILMT project is funded by the Department of Electronics and Information Technology (DEITY), Ministry of Communications and Information Technology (MCIT), Government of India. 65 model 4, phrase-extraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model trained using SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing (Kneser and Ney, 1995) and the Moses decoder (Koehn et al., 2007) have been used in the present study. 5 Experiments and Evaluations We have randomly identified 500 sentences each for the development set and the test set from the initial parallel corpus. The rest are considered as the training corpus. The training corpus was filtered with the maximum allowable sentence length of 100 words and sentence length ratio of 1:2 (either way). Finally the training corpus contained"
2013.mtsummit-papers.8,W10-3707,1,0.735788,"Missing"
2013.mtsummit-papers.8,P02-1040,0,0.0918365,"s and 1,223 of noun-noun compounds. The experiments have been carried out in various experimental settings: (i) single tokenization of MWEs on both sides in the parallel corpus, (ii) single tokenized MWEs added with the parallel training data, (iii) single tokenized MWEs directly integrated into the word alignment model, and finally, (iv) bootstrapping with single iteration using the experimental setup (ii) and (iii) to examine how the parallel MWE alignment set can be increased. Extrinsic evaluation was carried out on the MT quality using the well-known automatic MT evaluation metrics: BLEU (Papineni et al., 2002) and NIST (Doddington, 2002) and the evaluation results are reported in Table 2. By considering single tokenization (experiment 2), the system achieves performance improvement to some extent. Use of comparable corpora (experiment 3) improves the MWE identification performance which in turn improves the translation quality. Training set CPs English T U 8142 388 9 55 15 Bengali T U 2017 7154 4 185 150 reduplicated word Noun-noun 892 711 489 300 compound Noun-noun 1792 981 889 700 compound with Comparable corpora Phrasal prep- 1782 137 osition 9 Verb-object 231 145 combination Phrasal verb 549 53"
2013.mtsummit-papers.8,W09-2907,0,0.0230463,"work. The English-Bengali PB-SMT system is described in Section 3. Section 4 states the tools and resources used for the various experiments. Section 5 includes the results obtained, together with some analysis. Section 6 concludes and provides avenues for further work. 2 Related Work Venkatapathy and Joshi (2006) reported a discriminative approach to use the compositionality information of verb-based multi-word expressions in order to improve the word alignment quality. A log likelihood ratio based hierarchical reducing algorithm to automatically extract bilingual MWEs has been described in Ren et al. (2009). They examined the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into the Moses decoder (Koehn et al., 2007). They observed the highest improvement with an additional feature that identifies whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010) who replaced the binary feature by a count feature representing the number of MWEs in the source language phrase. A hybrid approach to identify MWEs from the English-French parallel corpus proposed by (Bouamor et al., 2012a), they aligned only many to many correspon"
2013.mtsummit-papers.8,W09-2906,0,0.0684193,"Missing"
2013.mtsummit-papers.8,W03-1803,0,0.101085,"Missing"
2013.mtsummit-papers.8,W06-1204,0,0.0428091,"Missing"
2013.mtsummit-papers.8,C08-1125,0,0.412897,"Missing"
2020.acl-demos.37,2014.amta-wptp.2,0,0.825123,"Missing"
2020.acl-demos.37,2020.acl-main.155,1,0.648575,"Missing"
2020.acl-demos.37,2014.eamt-1.18,0,0.31272,"Missing"
2020.acl-demos.37,W14-0315,0,0.384798,"Missing"
2020.acl-demos.37,2014.eamt-1.33,0,0.261952,"Missing"
2020.acl-demos.37,W19-6702,1,0.429507,"Missing"
2020.acl-demos.37,W14-0314,0,0.470262,"Missing"
2020.acl-main.155,2014.amta-wptp.2,0,0.676593,"Missing"
2020.acl-main.155,2015.tc-1.15,0,0.245536,"Missing"
2020.acl-main.155,C14-2028,0,0.442182,"Missing"
2020.acl-main.155,2014.amta-wptp.5,0,0.514741,"Missing"
2020.acl-main.155,D14-1130,0,0.536666,"Missing"
2020.acl-main.155,2020.acl-demos.37,1,0.648575,"Missing"
2020.acl-main.155,W12-3123,0,0.415474,"Missing"
2020.acl-main.155,2009.mtsummit-btm.8,0,0.911165,"Missing"
2020.acl-main.155,2013.mtsummit-wptp.10,0,0.275859,"Missing"
2020.acl-main.155,2014.eamt-1.18,0,0.377279,". 2.2 Multi-Modal Approaches The results of an elicitation study by Herbig et al. (2019a) indicate that pen, touch, and speech interaction should be combined with mouse and keyboard to improve PE of MT. In contrast, other modalities like eye tracking or gestures were seen as less promising. Dictating translations dates back to the time when secretaries transcribed dictaphone content on a typewriter (Theologitis, 1998); however, the use of automatic speech recognition also has a long history for translation (Dymetman et al., 1994; Brousseau et al., 1995). A more recent approach, called SEECAT (Martinez et al., 2014), investigates the use of automatic speech recognition (ASR) in PE and argues that its combination with typing could boost productivity. A survey regarding speech usage with PE trainees (Mesa-Lao, 2014) finds that they have a positive attitude towards In summary, previous research suggests that professional translators should switch to PE to increase productivity and reduce errors; however, translators themselves are not always eager to do so. It has been argued that the PE process might be better supported by using different modalities in addition to the common mouse and keyboard approaches,"
2020.acl-main.155,W14-0315,0,0.357216,"trast, other modalities like eye tracking or gestures were seen as less promising. Dictating translations dates back to the time when secretaries transcribed dictaphone content on a typewriter (Theologitis, 1998); however, the use of automatic speech recognition also has a long history for translation (Dymetman et al., 1994; Brousseau et al., 1995). A more recent approach, called SEECAT (Martinez et al., 2014), investigates the use of automatic speech recognition (ASR) in PE and argues that its combination with typing could boost productivity. A survey regarding speech usage with PE trainees (Mesa-Lao, 2014) finds that they have a positive attitude towards In summary, previous research suggests that professional translators should switch to PE to increase productivity and reduce errors; however, translators themselves are not always eager to do so. It has been argued that the PE process might be better supported by using different modalities in addition to the common mouse and keyboard approaches, and an elicitation study suggests concrete modalities that should be well suited for various editing tasks. A few of these modalities have already been explored in practice, showing promising results. H"
2020.acl-main.155,2016.eamt-2.6,0,0.351388,"Missing"
2020.acl-main.155,W19-6702,1,0.719118,"Missing"
2020.acl-main.155,W15-4910,0,0.308189,"Missing"
2020.acl-main.155,2014.eamt-1.33,0,0.29896,"Missing"
2020.acl-main.155,W14-0314,0,0.476867,"Missing"
2020.acl-main.155,2015.mtsummit-papers.15,0,0.752889,"Missing"
2020.acl-main.155,1998.tc-1.5,0,0.355325,"achieve within their implementation. In contrast, integrating dictation functionality using speech was shown to be quite useful and even preferred to mouse and keyboard by half of the participants. 2.2 Multi-Modal Approaches The results of an elicitation study by Herbig et al. (2019a) indicate that pen, touch, and speech interaction should be combined with mouse and keyboard to improve PE of MT. In contrast, other modalities like eye tracking or gestures were seen as less promising. Dictating translations dates back to the time when secretaries transcribed dictaphone content on a typewriter (Theologitis, 1998); however, the use of automatic speech recognition also has a long history for translation (Dymetman et al., 1994; Brousseau et al., 1995). A more recent approach, called SEECAT (Martinez et al., 2014), investigates the use of automatic speech recognition (ASR) in PE and argues that its combination with typing could boost productivity. A survey regarding speech usage with PE trainees (Mesa-Lao, 2014) finds that they have a positive attitude towards In summary, previous research suggests that professional translators should switch to PE to increase productivity and reduce errors; however, trans"
2020.amta-pemdt.7,2014.amta-wptp.2,0,0.0680404,"Missing"
2020.amta-pemdt.7,C14-2028,0,0.0610674,"Missing"
2020.amta-pemdt.7,2014.amta-wptp.5,0,0.0755146,"Missing"
2020.amta-pemdt.7,D14-1130,0,0.0739649,"Missing"
2020.amta-pemdt.7,2020.acl-main.155,1,0.329549,"Missing"
2020.amta-pemdt.7,2020.acl-demos.37,1,0.842769,"Missing"
2020.amta-pemdt.7,W12-3123,0,0.35611,"Missing"
2020.amta-pemdt.7,2009.mtsummit-btm.8,0,0.477679,"Missing"
2020.amta-pemdt.7,2013.mtsummit-wptp.10,0,0.0605326,"Missing"
2020.amta-pemdt.7,2014.eamt-1.18,0,0.0692014,"o mouse and keyboard, have been explored for PE, as we discuss in the next section. Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, 1st Workshop on Post-Editing in Modern-Day Translation Page 94 2.2 Multi-Modal Approaches Using automatic speech recognition has a long history for traditional translation from scratch (Dymetman et al., 1994; Brousseau et al., 1995), and dictating translations that are then manually transcribed by secretaries dates back even further (Theologitis, 1998). For PE, the more recent study of the SEECAT (Martinez et al., 2014) environment supporting automatic speech recognition (ASR) argues that its combination with typing could boost productivity. According to a survey by Mesa-Lao (2014), PE trainees have a positive attitude towards speech input and would consider adopting it, but only as a complement to other modalities. In a smallscale study, Zapata et al. (2017) found that ASR for PE was faster than ASR for translation from scratch. Nowadays, commercial CAT tools like memoQ and MateCat are also beginning to integrate ASR. The CASMACAT tool (Alabau et al., 2013) further allows users to input text by handwriting"
2020.amta-pemdt.7,W14-0315,0,0.0194339,"ricas October 6 - 9, 2020, 1st Workshop on Post-Editing in Modern-Day Translation Page 94 2.2 Multi-Modal Approaches Using automatic speech recognition has a long history for traditional translation from scratch (Dymetman et al., 1994; Brousseau et al., 1995), and dictating translations that are then manually transcribed by secretaries dates back even further (Theologitis, 1998). For PE, the more recent study of the SEECAT (Martinez et al., 2014) environment supporting automatic speech recognition (ASR) argues that its combination with typing could boost productivity. According to a survey by Mesa-Lao (2014), PE trainees have a positive attitude towards speech input and would consider adopting it, but only as a complement to other modalities. In a smallscale study, Zapata et al. (2017) found that ASR for PE was faster than ASR for translation from scratch. Nowadays, commercial CAT tools like memoQ and MateCat are also beginning to integrate ASR. The CASMACAT tool (Alabau et al., 2013) further allows users to input text by handwriting with an e-pen in a separate area, where the handwriting is recognized and placed at the cursor position. A vision paper by Alabau and Casacuberta (2012) proposes to"
2020.amta-pemdt.7,W15-4910,0,0.0436714,"Missing"
2020.amta-pemdt.7,2014.eamt-1.33,0,0.264769,"Missing"
2020.amta-pemdt.7,2015.mtsummit-papers.15,0,0.0915969,"Missing"
2020.amta-pemdt.7,1998.tc-1.5,0,0.0276983,"; Green et al., 2013). Therefore, other modalities, in addition to mouse and keyboard, have been explored for PE, as we discuss in the next section. Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, 1st Workshop on Post-Editing in Modern-Day Translation Page 94 2.2 Multi-Modal Approaches Using automatic speech recognition has a long history for traditional translation from scratch (Dymetman et al., 1994; Brousseau et al., 1995), and dictating translations that are then manually transcribed by secretaries dates back even further (Theologitis, 1998). For PE, the more recent study of the SEECAT (Martinez et al., 2014) environment supporting automatic speech recognition (ASR) argues that its combination with typing could boost productivity. According to a survey by Mesa-Lao (2014), PE trainees have a positive attitude towards speech input and would consider adopting it, but only as a complement to other modalities. In a smallscale study, Zapata et al. (2017) found that ASR for PE was faster than ASR for translation from scratch. Nowadays, commercial CAT tools like memoQ and MateCat are also beginning to integrate ASR. The CASMACAT tool (Al"
2020.amta-pemdt.7,2015.tc-1.15,0,0.428987,"Missing"
2020.amta-pemdt.7,2016.eamt-2.6,0,0.0213142,"Missing"
2020.amta-pemdt.7,W19-6702,1,0.807873,"Missing"
2020.amta-pemdt.7,W14-0314,0,0.025744,"Missing"
2020.coling-main.524,W19-5402,0,0.0122306,"E task. Apart from the multi-encoder transference architecture described above ({src, mt}tr → pe) and ensembling of this architecture, two simpler versions are also analyzed: first, a ‘mono-lingual’ (mt → pe) APE model using only parallel mt–pe data and therefore only a single encoder, and second, an identical single-encoder architecture, however, using the concatenated src and mt text as input ({src + mt} → pe) (Niehues et al., 2016). 5966 4.1 Data For our experiments, we use the English–German WMT 2016 (Bojar et al., 2016), 2017 (Bojar et al., 2017), 2018 (Chatterjee et al., 2018) and 2019 (Chatterjee et al., 2019) APE task data. All these released APE datasets consist of English–German triplets containing source English text (src) from the IT domain, the corresponding German translations (mt) from a 1st -stage MT system, and the corresponding human-post-edited version (pe). The sizes of the datasets (train; dev; test), in terms of number of sentences, are (12,000; 1,000; 2,000), (11,000; 0; 2,000), and (13,442; 1,000; 1,023), for the 2016 PBSMT, the 2017 PBSMT, and the 2018 NMT data, respectively. The 2019 version of the APE dataset released in WMT is the same as the WMT 2018 NMT data. It is to be note"
2020.coling-main.524,P18-1167,0,0.135825,"tion of encsrc→mt to produce the final translation). The paper makes the following contributions: (i) we propose a multi-encoder model for APE that consists only of standard transformer encoding and decoding blocks, (ii) by using a mix of self- and cross-attention we provide a representation of both src and mt for the decoder, allowing it to better capture errors in mt originating from src; this advances Junczys-Dowmunt and Grundkiewicz (2018) – the WMT 2018 best system (wmt18smt best ) in terms of BLEU and TER, (iii), we analyze the effect of varying the number of encoder and decoder layers (Domhan, 2018), indicating that the encoders contribute more than decoders in neural APE, and (iv) we present and evaluate an APE architecture inspired by a two-step approach professional translators often use during post-editing. In comparison to the shared task system description paper (Pal et al., 2019), this paper (i) provides more detailed explanations and reformation of different components of the transference architecture, (ii) compares it to a single encoder based transformer architecture where only mt or src concatenated with mt are used as an input, (iii) analyzes results when swapping mt and src"
2020.coling-main.524,W16-2378,0,0.11533,"yzes results when swapping mt and src in the multi-encoder setup, and (iv) investigates the importance of encoder and decoder by varying the amount of layers. The rest of the paper is organized as follows. In §2, we survey existing literature on APE. In §3, we describe the multi-encoder architecture. §4 describes our experimental setup. §5 reports the results of our approach against a number of baselines. Finally, §6 concludes the paper with future directions. 2 Related Research Recent advances in APE research are directed towards neural APE, which was first proposed by Pal et al. (2016b) and Junczys-Dowmunt and Grundkiewicz (2016) for the single-source APE scenario which does not consider src, i.e. mt → pe. Junczys-Dowmunt and Grundkiewicz (2016) also generated a large synthetic training dataset, which we also use as additional training data. Exploiting source information as an additional input can help neural APE to disambiguate corrections applied at each time step; this naturally leads to multi-source APE ({src, mt} → pe). A multi-source neural APE system can be configured either by using a single encoder that encodes the concatenation of src and mt (Niehues et al., 2016) or by using two separate encoders for src an"
2020.coling-main.524,W18-6467,0,0.245569,"n suggestion (similar to what our encsrc→mt is doing), then corrections to the MT output are applied based on the encountered errors (in the same way that our decpe uses the encoded representation of encsrc→mt to produce the final translation). The paper makes the following contributions: (i) we propose a multi-encoder model for APE that consists only of standard transformer encoding and decoding blocks, (ii) by using a mix of self- and cross-attention we provide a representation of both src and mt for the decoder, allowing it to better capture errors in mt originating from src; this advances Junczys-Dowmunt and Grundkiewicz (2018) – the WMT 2018 best system (wmt18smt best ) in terms of BLEU and TER, (iii), we analyze the effect of varying the number of encoder and decoder layers (Domhan, 2018), indicating that the encoders contribute more than decoders in neural APE, and (iv) we present and evaluate an APE architecture inspired by a two-step approach professional translators often use during post-editing. In comparison to the shared task system description paper (Pal et al., 2019), this paper (i) provides more detailed explanations and reformation of different components of the transference architecture, (ii) compares"
2020.coling-main.524,W19-5412,0,0.0268686,"stacks an additional cross-attention component for src → pe above the previous cross-attention for mt → pe. In contrast to other multi-encoder based approaches and Libovick´y et al. (2018)’s approach, where the authors focused on cross-attention of two encoders with respect to the decoder within the transformer architecture, we propose a novel architecture where the second encoder block is similar to the transformer decoder block but without masking. In the latest edition of WMT (2019), the submissions are mostly multi-source models extending the transformer implementation (Pal et al., 2019; Lee et al., 2019; Xu et al., 2019) and adapting BERT (Devlin et al., 2018) to the transformer-based framework (Lopes et al., 2019). The winner system (Lopes et al., 2019) (wmt19nmt best ) uses a single pre-trained BERT encoder that receives both the source src and mt strings and applies a BERT-based encoder-decoder model. Additionally, they add a conservativeness penalty factor during beam decoding to avoid over-corrections in APE. Our method outperforms the WMT 2016, 2017, and 2018 winners by 1 BLEU point, and yields comparable performance to the WMT 2019 winner, however, without using a BERT-based architect"
2020.coling-main.524,W16-2361,0,0.0519407,"Missing"
2020.coling-main.524,W18-6326,0,0.0506587,"Missing"
2020.coling-main.524,W19-5413,0,0.0245094,"Missing"
2020.coling-main.524,L18-1004,0,0.0133383,"The 2019 version of the APE dataset released in WMT is the same as the WMT 2018 NMT data. It is to be noted that for WMT 2018, we carried out experiments only for the NMT sub-task and ignored the data for the PBSMT task. Since the WMT APE datasets are small in size, we use ‘artificial training data’ (Junczys-Dowmunt and Grundkiewicz, 2016) containing 4.5M sentences as additional resources, 4M of which are weakly similar to the WMT 2016 training data, while 500K are very similar according to TER statistics. For experimenting on the NMT data, we additionally use the synthetic eScape APE corpus (Negri et al., 2018), consisting of ∼7M triples. For cleaning this noisy eScape dataset containing many unrelated language words (e.g. Chinese), (i) we use the cleaning process described in Tebbifakhr et al. (2018), and (ii) we use the Moses (Koehn et al., 2007) corpus cleaning scripts with minimum and maximum number of tokens set to 1 and 100, respectively. After cleaning, we perform punctuation normalization, and then use the Moses tokenizer (Koehn et al., 2007) to tokenize the eScape corpus with ‘no-escape’ option. Finally, we apply true-casing. The cleaned version of the eScape corpus contains ∼6.5M triplets."
2020.coling-main.524,C16-1172,0,0.0545641,"Missing"
2020.coling-main.524,C16-1241,1,0.89551,"Missing"
2020.coling-main.524,P16-2046,1,0.904948,"Missing"
2020.coling-main.524,W18-6468,1,0.880295,"Missing"
2020.coling-main.524,W19-5414,1,0.451809,"Missing"
2020.coling-main.524,P02-1040,0,0.107046,"T (we refer as 1st -stage MT) system to which APE is applied is either a phrase-based statistical machine translation (PBSMT) or a neural machine translation (NMT) model. For the PBSMT task, we compare against four baselines: the raw SMT output provided by the 1st stage PBSMT, the best-performing systems from WMT APE 2018 (wmt18smt best ), which are a single model and an ensemble model by Junczys-Dowmunt and Grundkiewicz (2018), as well as a transformer directly translating from src to pe (Transformer (src → pe)), thus performing translation instead of APE. We evaluate the systems using BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). For the NMT task, we consider three baselines: the raw NMT output provided by the 1st -stage NMT system, the best-performing system from the WMT 2018 (wmt18nmt best ) (Tebbifakhr et al., 2018) and nmt WMT 2019 (wmt19best ) (Lopes et al., 2019) NMT APE task. Apart from the multi-encoder transference architecture described above ({src, mt}tr → pe) and ensembling of this architecture, two simpler versions are also analyzed: first, a ‘mono-lingual’ (mt → pe) APE model using only parallel mt–pe data and therefore only a single encoder, and second, an identical single"
2020.coling-main.524,P16-1162,0,0.0126887,"e ) ft with {src, mt}smt tr → pe . Last, we analyze the importance of our second encoder (encsrc→mt ), compared to the source encoder 5967 (encsrc ) and the decoder (decpe ), by reducing and expanding the amount of layers in the encoders and the decoder. Our standard setup, which we use for fine-tuning, ensembling etc., is fixed to 6-6-6 for Nsrc -Nmt -Npe (cf. Figure 1). We investigate what happens in terms of APE performance if we change this setting to 6-6-4 and 6-4-6. To handle out-of-vocabulary words and reduce the vocabulary size, instead of considering words, we consider subword units (Sennrich et al., 2016) by using byte-pair encoding (BPE). In the preprocessing step, instead of learning an explicit mapping between BPEs in the src, mt and pe, we define BPE tokens by jointly processing all triplets. Thus, src, mt and pe derive a single BPE vocabulary. Since mt and pe belong to the same language (German) and src is a close language (English), they naturally share a good fraction of BPE tokens, which reduces the vocabulary size to 28k. We implemented our approach based on the Neutron implementation of the Transformer (Xu and Liu, 2019)1 . 4.3 Hyper-parameter Setup We follow a similar hyper-paramete"
2020.coling-main.524,W18-6470,0,0.0167713,"f src and mt sentences, and a second one using two character-level encoders for mt and src along with a character-level decoder. In the WMT 2018 APE shared task, several adaptations of the transformer architecture were presented for multi-source APE. Pal et al. (2018) introduced a joint encoder that attends over a combination of the two encoded sequences from mt and src. Tebbifakhr et al. (2018), the NMT-subtask winner of WMT 2018 (wmt18nmt best ), employed sequence-level loss functions in order to avoid exposure bias during training and to be consistent with the automatic evaluation metrics. Shin and Lee (2018) proposed a multi-source transformer where on the decoder side, they added two additional multi-head attention 5964 layers for src → mt and src → pe. Thereafter another multi-head attention between the output of those attention layers helps the decoder to capture common words in mt which should remain in pe. The APE PBSMT-subtask winner of WMT 2018 (wmt18smt best ) (Junczys-Dowmunt and Grundkiewicz, 2018) also presented another transformer-based multi-source APE which uses two encoders and stacks an additional cross-attention component for src → pe above the previous cross-attention for mt → p"
2020.coling-main.524,2006.amta-papers.25,0,0.0324129,"stem to which APE is applied is either a phrase-based statistical machine translation (PBSMT) or a neural machine translation (NMT) model. For the PBSMT task, we compare against four baselines: the raw SMT output provided by the 1st stage PBSMT, the best-performing systems from WMT APE 2018 (wmt18smt best ), which are a single model and an ensemble model by Junczys-Dowmunt and Grundkiewicz (2018), as well as a transformer directly translating from src to pe (Transformer (src → pe)), thus performing translation instead of APE. We evaluate the systems using BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). For the NMT task, we consider three baselines: the raw NMT output provided by the 1st -stage NMT system, the best-performing system from the WMT 2018 (wmt18nmt best ) (Tebbifakhr et al., 2018) and nmt WMT 2019 (wmt19best ) (Lopes et al., 2019) NMT APE task. Apart from the multi-encoder transference architecture described above ({src, mt}tr → pe) and ensembling of this architecture, two simpler versions are also analyzed: first, a ‘mono-lingual’ (mt → pe) APE model using only parallel mt–pe data and therefore only a single encoder, and second, an identical single-encoder architecture, however"
2020.coling-main.524,W18-6471,0,0.29825,"multi-source models (Libovick´y et al., 2016) by means of concatenating both weighted contexts of encoded src and mt. Varis and Bojar (2017) compared two multi-source models, one using a single encoder with the concatenation of src and mt sentences, and a second one using two character-level encoders for mt and src along with a character-level decoder. In the WMT 2018 APE shared task, several adaptations of the transformer architecture were presented for multi-source APE. Pal et al. (2018) introduced a joint encoder that attends over a combination of the two encoded sequences from mt and src. Tebbifakhr et al. (2018), the NMT-subtask winner of WMT 2018 (wmt18nmt best ), employed sequence-level loss functions in order to avoid exposure bias during training and to be consistent with the automatic evaluation metrics. Shin and Lee (2018) proposed a multi-source transformer where on the decoder side, they added two additional multi-head attention 5964 layers for src → mt and src → pe. Thereafter another multi-head attention between the output of those attention layers helps the decoder to capture common words in mt which should remain in pe. The APE PBSMT-subtask winner of WMT 2018 (wmt18smt best ) (Junczys-Do"
2020.coling-main.524,W17-4777,0,0.0128738,"src and mt and passing the concatenation of both encoders’ final states to the decoder (Libovick´y et al., 2016). A few approaches to multi-source neural APE were proposed in the WMT 2017 APE shared task. Junczys-Dowmunt and Grundkiewicz (2017) combine both mt and src in a single neural architecture, exploring different combinations of attention mechanisms including soft attention and hard monotonic attention. Chatterjee et al. (2017) built upon the two-encoder architecture of multi-source models (Libovick´y et al., 2016) by means of concatenating both weighted contexts of encoded src and mt. Varis and Bojar (2017) compared two multi-source models, one using a single encoder with the concatenation of src and mt sentences, and a second one using two character-level encoders for mt and src along with a character-level decoder. In the WMT 2018 APE shared task, several adaptations of the transformer architecture were presented for multi-source APE. Pal et al. (2018) introduced a joint encoder that attends over a combination of the two encoded sequences from mt and src. Tebbifakhr et al. (2018), the NMT-subtask winner of WMT 2018 (wmt18nmt best ), employed sequence-level loss functions in order to avoid expo"
2020.coling-main.524,W19-5417,1,0.887678,"Missing"
2020.wat-1.14,D18-1549,0,0.0394382,"Missing"
2020.wat-1.14,W14-3302,0,0.0417909,"Missing"
2020.wat-1.14,D10-1092,0,0.0458256,"ह। देश आता सामाईक परयतन करत आहेत. TO_MR देश एकल परयास से आगे बढ़ चुके ह। देश आता सामाईक परयतन करत आहेत. इस एमओयू पर फरवरी, 2016 म हसताकषर िकए हेत. The MoU was signed in February, 2016. TO_EN इस एमओयू पर फरवरी, 2016 म हसताकषर िकए हेत. The MoU was signed in February, 2016. The MoU was signed in February, 2016. इस एमओयू पर फरवरी, 2016 म हसताकषर िकए गए थे। TO_HI The MoU was signed in February, 2016. इस एमओयू पर फरवरी, 2016 म हसताकषर िकए गए थे। Table 2: Multilingual Processed data, indicating TO_XX as target language: with the released Test data. BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010) are used to evaluate the performance of our systems in the shared task. 4.2 Hyper-parameter Setup We follow a similar hyper-parameter setup for all reported systems. All encoders, and the decoder, are composed of a stack of NX = 6 identical layers followed by layer normalization. Each layer again consists of two sublayers and a residual connection (He et al., 2016) around each of the two sub-layers. We apply dropout (Srivastava et al., 2014) to the output of each sub-layer, before it is added to the sub-layer input and normalized. Furthermore, dropout is applied to the sums of the word embedd"
2020.wat-1.14,P07-2045,0,0.0150686,"Missing"
2020.wat-1.14,W15-5206,1,0.860826,"Missing"
2020.wat-1.14,W15-3017,1,0.851912,"Missing"
2020.wat-1.14,C16-2021,1,0.892451,"Missing"
2020.wat-1.14,P02-1040,0,0.107927,"get देश एकल परयास से आगे बढ़ चुके ह। देश आता सामाईक परयतन करत आहेत. TO_MR देश एकल परयास से आगे बढ़ चुके ह। देश आता सामाईक परयतन करत आहेत. इस एमओयू पर फरवरी, 2016 म हसताकषर िकए हेत. The MoU was signed in February, 2016. TO_EN इस एमओयू पर फरवरी, 2016 म हसताकषर िकए हेत. The MoU was signed in February, 2016. The MoU was signed in February, 2016. इस एमओयू पर फरवरी, 2016 म हसताकषर िकए गए थे। TO_HI The MoU was signed in February, 2016. इस एमओयू पर फरवरी, 2016 म हसताकषर िकए गए थे। Table 2: Multilingual Processed data, indicating TO_XX as target language: with the released Test data. BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010) are used to evaluate the performance of our systems in the shared task. 4.2 Hyper-parameter Setup We follow a similar hyper-parameter setup for all reported systems. All encoders, and the decoder, are composed of a stack of NX = 6 identical layers followed by layer normalization. Each layer again consists of two sublayers and a residual connection (He et al., 2016) around each of the two sub-layers. We apply dropout (Srivastava et al., 2014) to the output of each sub-layer, before it is added to the sub-layer input and normalized. Furthermore, dropout is appli"
2020.wat-1.14,P16-1009,0,0.134859,"arallel corpora and an efficient modeling of an NMT architecture. However, the upstream precess i.e., data scarcity can be a challenge for low resource language pairs. Therefore, existing SOTA NMT architecture like Transformer fails to produce quality translation output for low resource scenario. However, NMT systems have constantly ranked in the top positions in WMT (Bojar et al., 2016, 2017) and WAT (Nakazawa et al., 2016). Given the youth of the paradigm and while the main structure of encoder-decoder is still maintained. The research in NMT goes in many directions, including subword unit (Sennrich et al., 2016b) for translation of rare Words, back translation (Sennrich et al., 2016a)or transfer learning (Zoph et al., 2016) for low resource settings and recently unsupervised training for less or no resources (Artetxe et al., 2018). In this paper we describe the WIPRO-NMT submission to the WAT 2020 translation track (Nakazawa et al., 2020). Our WIPRO-NMT system is inspired from the model described in Johnson et al. (2017) and trained using transformer network. The system achieved best performance ranking 1st in English to Hindi and Hindi to English translation among all participants. The paper poses"
2020.wat-1.14,P16-1162,0,0.373375,"arallel corpora and an efficient modeling of an NMT architecture. However, the upstream precess i.e., data scarcity can be a challenge for low resource language pairs. Therefore, existing SOTA NMT architecture like Transformer fails to produce quality translation output for low resource scenario. However, NMT systems have constantly ranked in the top positions in WMT (Bojar et al., 2016, 2017) and WAT (Nakazawa et al., 2016). Given the youth of the paradigm and while the main structure of encoder-decoder is still maintained. The research in NMT goes in many directions, including subword unit (Sennrich et al., 2016b) for translation of rare Words, back translation (Sennrich et al., 2016a)or transfer learning (Zoph et al., 2016) for low resource settings and recently unsupervised training for less or no resources (Artetxe et al., 2018). In this paper we describe the WIPRO-NMT submission to the WAT 2020 translation track (Nakazawa et al., 2020). Our WIPRO-NMT system is inspired from the model described in Johnson et al. (2017) and trained using transformer network. The system achieved best performance ranking 1st in English to Hindi and Hindi to English translation among all participants. The paper poses"
2020.wat-1.14,2020.lrec-1.462,0,0.0210843,"m achieved best performance ranking 1st in English to Hindi and Hindi to English translation among all participants. The paper poses the following contributions: • How effective pre-processing help to improve performance. • How synthetic data through backtranslation from available monolingual data could help in overall translation performance. • How language similarity can aid more onto it. 2 Data For our experiments, we use the Hindi–English and English–Hindi workshop of Asian translation (WAT) 2020 translation data. We used a subset of the released parallel dataset, was collected from news (Siripragada et al., 2020), PMIndia (Haddow and Kirefu, 2020) and Indic 122 Proceedings of the 7th Workshop on Asian Translation, pages 122–126 c December 4, 2020. 2020 Association for Computational Linguistics Wordnet (Bhattacharyya, 2010; Kunchukuttan, 2020a) datasets. To augment our dataset, we use English–Hindi parallel data released in WMT 2014 (Bojar et al., 2014), consisting of more than 2M parallel sentences, is available as an additional resource. All dataset used to train our system are detailed in Table 1. Data Sources IITB WMT News PM India Total Remove duplicates Cleaning∗ #sentences 1,561,840 273,885 156,"
2020.wat-1.14,D16-1163,0,0.0314231,"n be a challenge for low resource language pairs. Therefore, existing SOTA NMT architecture like Transformer fails to produce quality translation output for low resource scenario. However, NMT systems have constantly ranked in the top positions in WMT (Bojar et al., 2016, 2017) and WAT (Nakazawa et al., 2016). Given the youth of the paradigm and while the main structure of encoder-decoder is still maintained. The research in NMT goes in many directions, including subword unit (Sennrich et al., 2016b) for translation of rare Words, back translation (Sennrich et al., 2016a)or transfer learning (Zoph et al., 2016) for low resource settings and recently unsupervised training for less or no resources (Artetxe et al., 2018). In this paper we describe the WIPRO-NMT submission to the WAT 2020 translation track (Nakazawa et al., 2020). Our WIPRO-NMT system is inspired from the model described in Johnson et al. (2017) and trained using transformer network. The system achieved best performance ranking 1st in English to Hindi and Hindi to English translation among all participants. The paper poses the following contributions: • How effective pre-processing help to improve performance. • How synthetic data throu"
2020.wmt-1.1,2020.nlpcovid19-2.5,1,0.796341,"tails of the evaluation. 4.1.1 Covid Test Suite TICO-19 The TICO-19 test suite was developed to evaluate how well can MT systems handle the newlyemerged topic of COVID-19. Accurate automatic translation can play an important role in facilitating communication in order to protect at-risk populations and combat the infodemic of misinformation, as described by the World Health Organization. The test suite has no corresponding paper so its authors provided an analysis of the outcomes directly here. The submitted systems were evaluated using the test set from the recently-released TICO-19 dataset (Anastasopoulos et al., 2020). The dataset provides manually created translations of COVID19 related data. The test set consists of PubMed articles (678 sentences from 5 scientific articles), patient-medical professional conversations (104 sentences), as well as related Wikipedia articles (411 sentences), announcements (98 sentences from Wikisource), and news items (67 sentences from Wikinews), for a total of 2100 sentences. Table 15 outlines the BLEU scores by each submitted system in the English-to-X directions, also breaking down the results per domain. The analysis shows that some systems are significantly more prepar"
2020.wmt-1.1,2020.wmt-1.6,0,0.0647231,"AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) SJTU-NICT (Li et al., 2020) Samsung Research Poland (Krubi´nski et al., 2020) TALP UPC (Escolano et al., 2020) Tencent Translation (Wu et al., 2020b) NLP Lab at Tsinghua Universit"
2020.wmt-1.1,2020.wmt-1.38,0,0.0746945,"Missing"
2020.wmt-1.1,2020.wmt-1.54,1,0.802974,"Missing"
2020.wmt-1.1,W07-0718,1,0.671054,"Missing"
2020.wmt-1.1,W08-0309,1,0.762341,"Missing"
2020.wmt-1.1,W12-3102,1,0.500805,"Missing"
2020.wmt-1.1,2020.lrec-1.461,0,0.0795779,"Missing"
2020.wmt-1.1,2012.eamt-1.60,0,0.124643,"tted systems, for those where the authors provided such details. The training corpus for Inuktitut↔English is the recently released Nunavut Hansard Inuktitut– English Parallel Corpus 3.0 (Joanis et al., 2020). For the Japanese↔English tasks, we added several freely available parallel corpora to the training data. It includes JParaCrawl v2.0 (Morishita et al., 2020), a large web-based parallel corpus, Japanese-English Subtitle Corpus (JESC) (Pryzant et al., 2017), the Kyoto Free Translation Task (KFTT) corpus (Neubig, 2011), constructed from the Kyoto-related Wikipedia articles, and TED Talks (Cettolo et al., 2012). The monolingual data we provided was similar to last year’s, with a 2019 news crawl added to all the news corpora. In addition, we provided versions of the news corpora for Czech, English and German, with both the document and paragraph structure retained. In other words, we did not apply sentence splitting to these corpora, and we retained the document boundaries and text ordering of the originals. Training, development, and test data for Pashto↔English and Khmer↔English are shared with the Parallel Corpus Filtering Shared Task (Koehn et al., 2020). The training data mostly comes from OPUS"
2020.wmt-1.1,2020.wmt-1.3,0,0.0731913,"on Machine Translation (WMT20)1 was held online with EMNLP 2020 and hosted a number of shared tasks on various aspects of machine translation. This conference built on 14 previous editions of WMT as workshops and conferences (Koehn and Monz, 2006; CallisonBurch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015, 2016, 2017, 2018; Barrault et al., 2019). This year we conducted several official tasks. We report in this paper on the news and similar translation tasks. Additional shared tasks are described in separate papers in these proceedings: • automatic post-editing (Chatterjee et al., 2020) • biomedical translation (Bawden et al., 2020b) • chat translation (Farajian et al., 2020) • lifelong learning (Barrault et al., 2020) 1 Makoto Morishita NTT Santanu Pal WIPRO AI Abstract 1 Philipp Koehn JHU http://www.statmt.org/wmt20/ 1 Proceedings of the 5th Conference on Machine Translation (WMT), pages 1–55 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics as “direct assessment”) that we explored in the previous years with convincing results in terms of the trade-off between annotation effort and reliable distinctions between systems. The primary objectives o"
2020.wmt-1.1,2020.wmt-1.8,0,0.0898111,"D D I D I -NLP DONG - NMT ENMT E T RANSLATION FACEBOOK AI G RONINGEN GTCOM H ELSINKI NLP H UAWEI TSC IIE M ICROSOFT STC I NDIA NICT-K YOTO NICT-RUI N IU T RANS NRC OPPO PROMT SJTU-NICT SRPOL TALP UPC T ENCENT T RANSLATION THUNLP T ILDE T OHOKU -AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Know"
2020.wmt-1.1,2009.freeopmt-1.3,0,0.088081,"ve (CONTRASTIVE) or primary (PRIMARY), and the BLEU, RIBES and TER results. The scores are sorted by BLEU. In general, primary systems tend to be better than contrastive systems, as expected, but there are some exceptions. This year we recived major number of participants for the case of Indo-Aryan language group NUST-FJWU NUST-FJWU system is an extension of state-of-the-art Transformer model with hierarchical attention networks to incorporate contextual information. During training the model used back-translation. Prompsit This team is participating with a rulebased system based on Apertium (Forcada et al., 2009-11). Apertium is a free/open-source platform for developing rule-based machine translation systems and language technology that was first released in 2005. Apertium is hosted in Github where both language data and code are licensed under the GNU GPL. It is a research and business platform with a very active community that loves small languages. Language pairs are at a very different level of development and output quality in the platform, depending on two main variables: how much funded or in-kind effort has 32 5.4 i.e. Hindi–Marathi (in both directions). We received 22 submissions from 14 te"
2020.wmt-1.1,2020.wmt-1.80,0,0.0933589,"airs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages. Chi-kiu Lo NRC Masaaki Nagata NTT Marcos Zampieri Rochester Institute of Technology metrics (Mathur et al., 2020) parallel corpus filtering (Koehn et al., 2020) quality estimation (Specia et al., 2020a) robustness (Specia et al., 2020b) unsupervised and very low-resource translation (Fraser, 2020) In the news translation task (Section 2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data (“constrained” condition). We included 22 translation directions this year, with translation between English and each of Chinese, Czech, German and Russian, as well as French to and from German being repeated from last year, and English to and from Inuktitut, Japanese, Polish and Tamil being new for this year. Furthermore, English to and from Khmer and Pashto were included, using the same test sets as in the corpus filtering task. Th"
2020.wmt-1.1,W19-5204,0,0.0543621,"Missing"
2020.wmt-1.1,2020.emnlp-main.5,0,0.0410594,"luation of out-ofEnglish translations, HITs were generated using the same method as described for the SR+DC evaluation of into-English translations in Section 3.2.1 with minor modifications. Source-based DA allows to include human references in the evaluation as another system to provide an estimate of human performance. Human references were added to the pull of system outputs prior to sampling documents for tasks generation. If multiple references are available, which is the case for English→German (3 alternative reference translations, including 1 generated using the paraphrasing method of Freitag et al. (2020)) and English→Chinese (2 translations), each reference is assessed individually. Since the annotations are made by researchers and professional translators who ensure a betTable 11: Amount of data collected in the WMT20 manual document- and segment-level evaluation campaigns for bilingual/source-based evaluation out of English and nonEnglish pairs. et al., 2020; Laubli et al., 2020). It differs from SR+DC DA introduced in WMT19 (Bojar et al., 2019), and still used in into-English human evaluation this year, where a single segment from a document is provided on a screen at a time, followed by s"
2020.wmt-1.1,W18-3931,1,0.874637,"ese improvements to increased capacity (which allows increased sensitivity to long-range relations) of the models. 5 Similar Language Translation Most shared tasks at WMT (e.g. News, Biomedical) have historically dealt with translating texts from and to English. In recent years, we observed a growing interest in training systems to translate between languages other than English. This includes a number of papers applying MT to translate between pairs of closely-related languages, national language varieties, and dialects 27 of the same language (Zhang, 1998; Marujo et al., 2011; Hassani, 2017; Costa-jussà et al., 2018; Popovi´c et al., 2020). To address this topic, the first Similar Language Translation (SLT) shared task at WMT 2019 has been organized. It featured data from three pairs of closely-related languages from different language families: Spanish - Portuguese (Romance languages), Czech - Polish (Slavic languages), and Hindi - Nepali (IndoAryan languages). Following the success of the first SLT shared task at WMT 2019 and the interest of the community in this topic, we organize, for the second time at WMT, this shared task to evaluate the performance of state-of-the-art translation systems on trans"
2020.wmt-1.1,2020.wmt-1.18,0,0.0913945,"2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) SJTU-NICT (Li et al., 2020) Samsung Research Poland (Krubi´nski et al., 2020) TALP UPC (Escolano et al., 2020) Tencent Translation (Wu et al., 2020b) NLP Lab at Tsinghua University (no associated paper) Tilde (Krišlauks and Pinnis, 2020) Tohoku-AIP-NTT (Kiyono et al., 2020) Ubiqus (Hernandez and Nguyen, 2020) University of Edinburgh (Bawden et al., 2020a; Germann, 2020) University of Edinburgh and Charles University (Germann et al., 2020) Université du Québec à Montréal (no associated paper) ByteDance AI Lab (Wu et al., 2020a) WeChat (Meng et al., 2020) Baseline System from Biomedical Task (Bawden et al., 2020b) American University of Beirut (no associated paper) Zoho Corporation (no associated paper) Table 6: Participants in the shared translation task. Not all teams participated in all language pairs. The translations from the online systems were not submitted by their respective companies but were obtained by us, and are therefore anonymized in a fashion"
2020.wmt-1.1,2020.wmt-1.43,0,0.0835067,"Missing"
2020.wmt-1.1,2020.wmt-1.9,0,0.0939415,"Missing"
2020.wmt-1.1,2020.wmt-1.19,0,0.0674131,"Missing"
2020.wmt-1.1,2009.mtsummit-btm.6,0,0.103443,"Missing"
2020.wmt-1.1,W13-2305,1,0.929934,"work which can be well applied to different translation. directions. Techniques used in the submitted systems include optional multilingual pre-training (mRASP) for low resource languages, very deep Transformer or dynamic convolution models up to 50 encoder layers, iterative backtranslation, knowledge distillation, model ensemble and development set fine-tuning. The key ingredient of the process seems the strong focus on diversification of the (synthetic) training data, using multiple scalings of the Transformer model 3.1 Direct Assessment Since running a comparison of direct assessments (DA, Graham et al., 2013, 2014, 2016) and relative ranking in 2016 (Bojar et al., 2016) and verifying a high correlation of system rankings for the two methods, as well as the advantages of DA, such as quality controlled crowd-sourcing and linear growth relative to numbers of submissions, we have employed DA as the primary mechanism for evaluating systems. With DA human evaluation, 15 human assessors are asked to rate a given translation by how adequately it expresses the meaning of the corresponding reference translation or source language input on an analogue scale, which corresponds to an underlying absolute 0–100"
2020.wmt-1.1,E14-1047,1,0.888167,"Missing"
2020.wmt-1.1,2020.lrec-1.312,1,0.804196,"A screenshot of OCELoT is shown in Figure 5. For presentation of the results, systems are treated as either constrained or unconstrained, depending on whether their models were trained only on the provided data. Since we do not know how they were built, the online systems are treated as unconstrained during the automatic and human evaluations. In the rest of this section, we provide brief details of the submitted systems, for those where the authors provided such details. The training corpus for Inuktitut↔English is the recently released Nunavut Hansard Inuktitut– English Parallel Corpus 3.0 (Joanis et al., 2020). For the Japanese↔English tasks, we added several freely available parallel corpora to the training data. It includes JParaCrawl v2.0 (Morishita et al., 2020), a large web-based parallel corpus, Japanese-English Subtitle Corpus (JESC) (Pryzant et al., 2017), the Kyoto Free Translation Task (KFTT) corpus (Neubig, 2011), constructed from the Kyoto-related Wikipedia articles, and TED Talks (Cettolo et al., 2012). The monolingual data we provided was similar to last year’s, with a 2019 news crawl added to all the news corpora. In addition, we provided versions of the news corpora for Czech, Engli"
2020.wmt-1.1,2020.emnlp-main.6,1,0.839606,"shown in Table 3, where the first and second are simple merges or splits, whereas the third is a rare case of more complex reordering. We leave a detailed analysis of the translators’ treatment of paragraph-split data for future work. development set is provided, it is a mixture of both “source-original” and “target-original” texts, in order to maximise its size, although the original language is always marked in the sgm file, except for Inuktitut↔English. The consequences of directionality in test sets has been discussed recently in the literature (Freitag et al., 2019; Laubli et al., 2020; Graham et al., 2020), and the conclusion is that it can have an effect on detrimental effect on the accuracy of system evaluation. We use “source-original” parallel sentences wherever possible, on the basis that it is the more realistic scenario for practical MT usage. Exception: the test sets for the two Inuktitut↔English translation directions contain the same data, without regard to original direction. For most news text in the test and development sets, English was the original language and Inuktitut the translation, while the parliamentary data mixes the two directions. The origins of the news test documents"
2020.wmt-1.1,2020.wmt-1.11,0,0.0940191,"N GTCOM H ELSINKI NLP H UAWEI TSC IIE M ICROSOFT STC I NDIA NICT-K YOTO NICT-RUI N IU T RANS NRC OPPO PROMT SJTU-NICT SRPOL TALP UPC T ENCENT T RANSLATION THUNLP T ILDE T OHOKU -AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) S"
2020.wmt-1.1,D19-1632,1,0.881933,"ent and paragraph structure retained. In other words, we did not apply sentence splitting to these corpora, and we retained the document boundaries and text ordering of the originals. Training, development, and test data for Pashto↔English and Khmer↔English are shared with the Parallel Corpus Filtering Shared Task (Koehn et al., 2020). The training data mostly comes from OPUS (software localization, Tatoeba, Global Voices), the Bible, and specialprepared corpora from TED Talks and the Jehova Witness web site (JW300). The development and test sets were created as part of the Flores initiative (Guzmán et al., 2019) by professional translation of Wikipedia content with careful vetting of the translations. Please refer the to the Parallel Corpus Filtering Shared Task overview paper for details on these corpora. 2.3.1 AFRL (Gwinnup and Anderson, 2020) AFRL - SYSCOMB 20 is a system combination consisting of two Marian transformer ensembles, one OpenNMT transformer system and a Moses phrase-based system. AFRL - FINETUNE is an OpenNMT transformer system fine-tuned on newstest2014-2017. 2.3.2 (Xv, 2020) ARIEL XV is a Transformer base model trained with the Sockeye sequence modeling toolkit usSome statistics ab"
2020.wmt-1.1,2020.wmt-1.12,1,0.754946,"Missing"
2020.wmt-1.1,2020.wmt-1.13,0,0.0737827,"2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) SJTU-NICT (Li et al., 2020) Samsung Research Poland (Krubi´nski et al., 2020) TALP UPC (Escolano et al., 2020) Tencent Translation (Wu et al., 2020b) NLP Lab at Tsinghua University (no associated paper) Tilde (Krišlauks and Pinnis, 2020) Tohoku-AIP-NTT (Kiyono et al., 2020) Ubiqus (Hernandez and Nguyen, 2020) University of Edinburgh (Bawden et al., 2020a; Germann, 2020) University of Edinburgh and Charles University (Germann et al., 2020) Université du Québec à Montréal (no associated paper) ByteDance AI Lab (Wu et al., 2020a) WeChat (Meng et al"
2020.wmt-1.1,2020.wmt-1.20,0,0.057602,"Missing"
2020.wmt-1.1,2020.wmt-1.14,1,0.820019,"set, and the origlang tag indicates the original source language. 9 Team AFRL ARIEL XV CUNI DCU D EEP M IND D I D I -NLP DONG - NMT ENMT E T RANSLATION FACEBOOK AI G RONINGEN GTCOM H ELSINKI NLP H UAWEI TSC IIE M ICROSOFT STC I NDIA NICT-K YOTO NICT-RUI N IU T RANS NRC OPPO PROMT SJTU-NICT SRPOL TALP UPC T ENCENT T RANSLATION THUNLP T ILDE T OHOKU -AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Mari"
2020.wmt-1.1,2020.wmt-1.39,1,0.812433,"kables was collected in the first phase of the annotation, which amounted to 4k assessments across the systems. The second annotation phase with 6.5k assessments compared markable translations, always checking outputs of all the 13 competing MT systems but still considering the document-level context of each of them. Among other things, the observations indicate that the better the system, the lower the variance in manual scores. Markables annotation then confirms that frequent errors like bad translation of a term need not be the most severe and conversely, 4.1.3 Gender Coreference and Bias (Kocmi et al., 2020) The test suite by Kocmi et al. (2020) focuses on the gender bias in professions (e.g. physician, teacher, secretary) for the translation from English into Czech, German, Polish and Russian. These nouns are ambiguous with respect to gender in English but exhibit gender in the examined target languages. The test suite is based on the fact that a pronoun referring to the ambiguous noun can reveal the gender of the noun in the English source sentence. Once disambiguated, the gender needs to be preserved in translation. To correctly translate the given noun, the translation system thus has to corr"
2020.wmt-1.1,2020.wmt-1.53,0,0.089538,"Missing"
2020.wmt-1.1,2020.wmt-1.78,1,0.815194,"rence on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages. Chi-kiu Lo NRC Masaaki Nagata NTT Marcos Zampieri Rochester Institute of Technology metrics (Mathur et al., 2020) parallel corpus filtering (Koehn et al., 2020) quality estimation (Specia et al., 2020a) robustness (Specia et al., 2020b) unsupervised and very low-resource translation (Fraser, 2020) In the news translation task (Section 2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data (“constrained” condition). We included 22 translation directions this year, with translation between English and each of Chinese, Czech, German and Russian, as well as French to and from German being repeated from last year, and English to and from Inuktitut, Japanese, Polish and Tamil being new fo"
2020.wmt-1.1,W17-1208,0,0.0524248,"ttribute all these improvements to increased capacity (which allows increased sensitivity to long-range relations) of the models. 5 Similar Language Translation Most shared tasks at WMT (e.g. News, Biomedical) have historically dealt with translating texts from and to English. In recent years, we observed a growing interest in training systems to translate between languages other than English. This includes a number of papers applying MT to translate between pairs of closely-related languages, national language varieties, and dialects 27 of the same language (Zhang, 1998; Marujo et al., 2011; Hassani, 2017; Costa-jussà et al., 2018; Popovi´c et al., 2020). To address this topic, the first Similar Language Translation (SLT) shared task at WMT 2019 has been organized. It featured data from three pairs of closely-related languages from different language families: Spanish - Portuguese (Romance languages), Czech - Polish (Slavic languages), and Hindi - Nepali (IndoAryan languages). Following the success of the first SLT shared task at WMT 2019 and the interest of the community in this topic, we organize, for the second time at WMT, this shared task to evaluate the performance of state-of-the-art tr"
2020.wmt-1.1,2020.wmt-1.21,0,0.0791885,"Missing"
2020.wmt-1.1,2020.wmt-1.23,0,0.0607352,"020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) SJTU-NICT (Li et al., 2020) Samsung Research Poland (Krubi´nski et al., 2020) TALP UPC (Escolano et al., 2020) Tencent Translation (Wu et al., 2020b) NLP Lab at Tsinghua University (no associated paper) Tilde (Krišlauks and Pinnis, 2020) Tohoku-AIP-NTT (Kiyono et al., 2020) Ubiqus (Hernandez and Nguyen, 2020) University of Edinburgh (Bawden et al., 2020a; Germann, 2020) University of Edinburgh and Charles University (Germann et al., 2"
2020.wmt-1.1,2020.wmt-1.77,1,0.84299,"slation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages. Chi-kiu Lo NRC Masaaki Nagata NTT Marcos Zampieri Rochester Institute of Technology metrics (Mathur et al., 2020) parallel corpus filtering (Koehn et al., 2020) quality estimation (Specia et al., 2020a) robustness (Specia et al., 2020b) unsupervised and very low-resource translation (Fraser, 2020) In the news translation task (Section 2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data (“constrained” condition). We included 22 translation directions this year, with translation between English and each of Chinese, Czech, German and Russian, as well as French to and from German being repeated from last year, and English to and from Inu"
2020.wmt-1.1,2020.wmt-1.24,0,0.0435945,"Missing"
2020.wmt-1.1,D18-1512,0,0.05415,"Missing"
2020.wmt-1.1,2020.wmt-1.47,1,0.740067,"Missing"
2020.wmt-1.1,W18-3601,1,0.891679,", we have employed DA as the primary mechanism for evaluating systems. With DA human evaluation, 15 human assessors are asked to rate a given translation by how adequately it expresses the meaning of the corresponding reference translation or source language input on an analogue scale, which corresponds to an underlying absolute 0–100 rating scale.5 No sentence or document length restriction is applied during manual evaluation. Direct Assessment is also employed for evaluation of video captioning systems at TRECvid (Graham et al., 2018; Awad et al., 2019) and multilingual surface realisation (Mille et al., 2018, 2019). 3.1.1 tion 2, most of our test sets do not include reversecreated sentence pairs, except when there were resource constraints on the creation of the test sets. 3.1.3 Prior to WMT19, the issue of including document context was raised within the community (Läubli et al., 2018; Toral et al., 2018) and at WMT19 a range of DA styles were subsequently tested that included document context. In WMT19, two options were run, firstly, an evaluation that included the document context “+DC” (with document context), and secondly, a variation that omitted document context “−DC” (without document con"
2020.wmt-1.1,2020.wmt-1.27,0,0.247738,"he original source language. 9 Team AFRL ARIEL XV CUNI DCU D EEP M IND D I D I -NLP DONG - NMT ENMT E T RANSLATION FACEBOOK AI G RONINGEN GTCOM H ELSINKI NLP H UAWEI TSC IIE M ICROSOFT STC I NDIA NICT-K YOTO NICT-RUI N IU T RANS NRC OPPO PROMT SJTU-NICT SRPOL TALP UPC T ENCENT T RANSLATION THUNLP T ILDE T OHOKU -AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans"
2020.wmt-1.1,D19-6301,1,0.888512,"Missing"
2020.wmt-1.1,W18-6424,0,0.0431841,"(Kocmi, 2020) combines transfer learning from a high-resource language pair Czech–English into the low-resource Inuktitut-English with an additional backtranslation step. Surprising behaviour is noticed when using synthetic data, which can be possibly attributed to a narrow domain of training and test data. The system is the Transformer model in a constrained submission. 2.3.3 Charles University (CUNI) CUNI-D OC T RANSFORMER (Popel, 2020) is similar to the sentence-level version (CUNI-T2T2018, CUBBITT), but trained on sequences with multiple sentences of up to 3000 characters. CUNI-T2T-2018 (Popel, 2018), also called CUBBITT, is exactly the same system as in WMT2018. It is the Transformer model trained according to Popel and Bojar (2018) plus a novel concat-regime backtranslation with checkpoint averaging (Popel et al., 2020), tuned separately for CZ-domain and non CZ-domain articles, possibly handling also translation-direction (“translationese”) issues. For cs→en also a coreference preprocessing was used adding the female-gender CUNI-T RANSFORMER (Popel, 2020) is similar to the WMT2018 version of CUBBITT, but with 12 encoder layers instead of 6 and trained on CzEng 2.0 instead of CzEng 1.7."
2020.wmt-1.1,2020.wmt-1.25,0,0.094349,"Missing"
2020.wmt-1.1,2020.wmt-1.28,0,0.0792624,"cument in the test set, and the origlang tag indicates the original source language. 9 Team AFRL ARIEL XV CUNI DCU D EEP M IND D I D I -NLP DONG - NMT ENMT E T RANSLATION FACEBOOK AI G RONINGEN GTCOM H ELSINKI NLP H UAWEI TSC IIE M ICROSOFT STC I NDIA NICT-K YOTO NICT-RUI N IU T RANS NRC OPPO PROMT SJTU-NICT SRPOL TALP UPC T ENCENT T RANSLATION THUNLP T ILDE T OHOKU -AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 20"
2020.wmt-1.1,2020.lrec-1.443,1,0.79707,"er their models were trained only on the provided data. Since we do not know how they were built, the online systems are treated as unconstrained during the automatic and human evaluations. In the rest of this section, we provide brief details of the submitted systems, for those where the authors provided such details. The training corpus for Inuktitut↔English is the recently released Nunavut Hansard Inuktitut– English Parallel Corpus 3.0 (Joanis et al., 2020). For the Japanese↔English tasks, we added several freely available parallel corpora to the training data. It includes JParaCrawl v2.0 (Morishita et al., 2020), a large web-based parallel corpus, Japanese-English Subtitle Corpus (JESC) (Pryzant et al., 2017), the Kyoto Free Translation Task (KFTT) corpus (Neubig, 2011), constructed from the Kyoto-related Wikipedia articles, and TED Talks (Cettolo et al., 2012). The monolingual data we provided was similar to last year’s, with a 2019 news crawl added to all the news corpora. In addition, we provided versions of the news corpora for Czech, English and German, with both the document and paragraph structure retained. In other words, we did not apply sentence splitting to these corpora, and we retained t"
2020.wmt-1.1,2020.wmt-1.48,0,0.090424,"Missing"
2020.wmt-1.1,2020.wmt-1.49,0,0.0519886,"Missing"
2020.wmt-1.1,W19-6712,0,0.0573476,"tly crawled multilingual parallel corpora from Indian government websites (Haddow and Kirefu, 2020; Siripragada et al., 2020), the Tanzil corpus (Tiedemann, 2009), the Pavlick dicParagraph-split Test Sets For the language pairs English↔Czech, English↔German and English→Chinese, we provided the translators with paragraph-split texts, instead of sentence-split texts. We did this in order to provide the translators with greater freedom and, hopefully, to improve the quality of the translation. Allowing translators to merge and split sentences removes one of the “translation shifts” identified by Popovic (2019), which can make translations create solely for MT evaluation different from translations produced for other purposes. We first show some descriptive statistics of the source texts, for Czech, English and German, in 3 Europarl Parallel Corpus Czech ↔ English German ↔ English Polish↔ English German ↔ French Sentences 645,241 1,825,745 632,435 1,801,076 Words 14,948,900 17,380,340 48,125,573 50,506,059 14,691,199 16,995,232 47,517,102 55,366,136 Distinct words 172,452 63,289 371,748 113,960 170,271 62,694 368,585 134,762 News Commentary Parallel Corpus Czech ↔ English 248,927 5,570,734 6,156,063"
2020.wmt-1.1,2020.wmt-1.26,0,0.0845151,"Missing"
2020.wmt-1.1,2020.vardial-1.10,0,0.0933804,"Missing"
2020.wmt-1.1,W18-6301,0,0.038239,"Missing"
2020.wmt-1.1,2020.wmt-1.51,0,0.0917045,"Missing"
2020.wmt-1.1,2020.wmt-1.50,1,0.78567,"Missing"
2020.wmt-1.1,2020.wmt-1.52,0,0.0485419,"Missing"
2020.wmt-1.1,P19-1164,0,0.0581517,"26 26.37 25.51 24.82 28.33 23.33 21.13 21.96 20.43 22.90 22.58 21.90 22.17 22.17 20.53 19.40 20.01 40.44 32.39 30.39 37.04 32.27 27.54 25.97 26.09 46.38 37.30 36.05 35.96 33.76 33.07 27.20 27.07 Table 15: TICO-19 test suite results on the English-to-X WMT20 translation directions. 26 4.1.5 antecedent (a less common direction of information flow), and then correctly express the noun in the target language. The success of the MT system in this test can be established automatically, whenever the gender of the target word can be automatically identified. Kocmi et al. (2020) build upon the WinoMT (Stanovsky et al., 2019) test set, which provides exactly the necessary type of sentences containing an ambiguous profession noun and a personal pronoun which unambiguously (for the human eye) refers to it based the situation described. When extending WinMT with Czech and Polish, Stanovsky et al. have to disregard some test patterns but the principle remains. The results indicate that all MT systems fail in this test, following gender bias (stereotypical patterns attributing the masculine gender to some professions and feminine gender to others) rather than the coreference link. Word Sense Disambiguation (Scherrer et"
2020.wmt-1.1,2020.wmt-1.31,0,0.0881792,"morphological segmentation of the polysynthetic Inuktitut, testing rule-based, supervised, semi-supervised as well as unsupervised word segmentation methods, (2) whether or not adding data from a related language (Greenlandic) helps, and (3) whether contextual word embeddings (XLM) improve translation. G RONINGEN - ENIU use Transformer implemented in Marian with the default setting, improving the performance also with tagged backtranslation, domain-specific data, ensembling and finetuning. 2.3.7 DONG - NMT (no associated paper) No description provided. 2.3.8 ENMT (Kim et al., 2020) Kim et al. (2020) base their approach on transferring knowledge of domain and linguistic characteristics by pre-training the encoder-decoder model with large amount of in-domain monolingual data through unsupervised and supervised prediction task. The model is then fine-tuned with parallel data and in-domain synthetic data, generated with iterative back-translation. For additional gain, final results are generated with an ensemble model and re-ranked with averaged models and language models. G RONINGEN - ENTAM (Dhar et al., 2020) study the effects of various techniques such as linguistically motivated segmenta"
2020.wmt-1.1,2020.wmt-1.32,0,0.0839317,"- NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) SJTU-NICT (Li et al., 2020) Samsung Research Poland (Krubi´nski et al., 2020) TALP UPC (Escolano et al., 2020) Tencent Translation (Wu et al., 2020b) NLP Lab at Tsinghua University (no associated paper) Tilde (Krišlauks and Pinnis, 2020) Tohoku-AIP-NTT (Kiyono et al., 2020) Ub"
2020.wmt-1.1,2020.wmt-1.33,0,0.080166,"Missing"
2020.wmt-1.1,2020.wmt-1.34,0,0.0803867,"Missing"
2020.wmt-1.1,2020.wmt-1.35,0,0.0951745,"ss web site (JW300). The development and test sets were created as part of the Flores initiative (Guzmán et al., 2019) by professional translation of Wikipedia content with careful vetting of the translations. Please refer the to the Parallel Corpus Filtering Shared Task overview paper for details on these corpora. 2.3.1 AFRL (Gwinnup and Anderson, 2020) AFRL - SYSCOMB 20 is a system combination consisting of two Marian transformer ensembles, one OpenNMT transformer system and a Moses phrase-based system. AFRL - FINETUNE is an OpenNMT transformer system fine-tuned on newstest2014-2017. 2.3.2 (Xv, 2020) ARIEL XV is a Transformer base model trained with the Sockeye sequence modeling toolkit usSome statistics about the training and test materials are given in Figures 1, 2, 3 and 4. 4 8 ARIEL XV https://github.com/AppraiseDev/OCELoT English I English II English III Chinese Czech German Inuktitut Japanese Polish Russian Tamil ABC News (2), All Africa (5), Brisbane Times (1), CBS LA (1), CBS News (1), CNBC (3), CNN (2), Daily Express (1), Daily Mail (2), Fox News (1), Gateway (1), Guardian (3), Huffington Post (2), London Evening Standard (2), Metro (2), NDTV (7), RTE (7), Reuters (4), STV (2), S"
2020.wmt-1.1,2020.wmt-1.55,0,0.0877526,"Missing"
2020.wmt-1.1,P17-4012,0,0.0273892,"o SJTU-NICT using large XLM model to improve NMT but the exact relation is unclear. 2.3.14 H UAWEI TSC (Wei et al., 2020a) H UAWEI TSC use Transformer-big with a further increased model size, focussing on standard techniques of careful pre-processing and filtering, back-translation and forward translation, including self-training, i.e. translating one of the sides of the original parallel data. Ensembling of individual training runs is used in the forward as well as backward translation, and single models are created from the ensembles using knowledge distillation. The submission uses THUNMT (Zhang et al., 2017) open-source engine. 2.3.19 N IU T RANS (Zhang et al., 2020) N IU T RANS gain their performance from focussed attention to six areas: (1) careful data preprocessing and filtering, (2) iterative back-translation to generate additional training data, (3) using different model architectures, such as wider and/or deeper models, relative position representation and relative length, to enhance the diversity of translations, (4) iterative knowledge distillation by in-domain monolingual data, (5) iterative finetuning for domain adaptation using small training batches, (6) rule-based post-processing of"
2020.wmt-1.1,P98-2238,0,0.590812,"and punctuation, and we tend to attribute all these improvements to increased capacity (which allows increased sensitivity to long-range relations) of the models. 5 Similar Language Translation Most shared tasks at WMT (e.g. News, Biomedical) have historically dealt with translating texts from and to English. In recent years, we observed a growing interest in training systems to translate between languages other than English. This includes a number of papers applying MT to translate between pairs of closely-related languages, national language varieties, and dialects 27 of the same language (Zhang, 1998; Marujo et al., 2011; Hassani, 2017; Costa-jussà et al., 2018; Popovi´c et al., 2020). To address this topic, the first Similar Language Translation (SLT) shared task at WMT 2019 has been organized. It featured data from three pairs of closely-related languages from different language families: Spanish - Portuguese (Romance languages), Czech - Polish (Slavic languages), and Hindi - Nepali (IndoAryan languages). Following the success of the first SLT shared task at WMT 2019 and the interest of the community in this topic, we organize, for the second time at WMT, this shared task to evaluate th"
2020.wmt-1.1,2020.wmt-1.41,1,0.814291,"Missing"
2020.wmt-1.50,W14-3302,0,0.219263,"In this paper we describe the WIPRO-RIT submission to the SLT 2020 Indo-Aryan track. Our WIPRO-RIT system is based on the model described in Johnson et al. (2017). WIPRORIT achieved competitive performance ranking 1st in Marathi to Hindi and 2nd in Hindi to Marathi translation among 22 systems. 424 Proceedings of the 5th Conference on Machine Translation (WMT), pages 424–429 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics 2 Related Work using a Hindi–English NMT system. The Hindi–English NMT system was trained on English–Hindi parallel data released in WMT 2014 (Bojar et al., 2014), IITB parallel corpus (Kunchukuttan et al., 2018), the parallel dataset was collected from news (Siripragada et al., 2020) and the PMIndia (Haddow and Kirefu, 2020) parallel corpus (see Table 1). With the substantial performance improvements brought to MT by neural approaches, a growing interest in translating between pairs of similar languages, language varieties, and dialects has been observed. Recent studies have addressed MT between Arabic dialects (Harrat et al., 2019; Shapiro and Duh, 2019) Catalan and Spanish, Croatian and Serbian (Popović et al., 2020), (Costa-jussà, 2017), Brazilian"
2020.wmt-1.50,W17-1207,0,0.0176905,"WMT 2014 (Bojar et al., 2014), IITB parallel corpus (Kunchukuttan et al., 2018), the parallel dataset was collected from news (Siripragada et al., 2020) and the PMIndia (Haddow and Kirefu, 2020) parallel corpus (see Table 1). With the substantial performance improvements brought to MT by neural approaches, a growing interest in translating between pairs of similar languages, language varieties, and dialects has been observed. Recent studies have addressed MT between Arabic dialects (Harrat et al., 2019; Shapiro and Duh, 2019) Catalan and Spanish, Croatian and Serbian (Popović et al., 2020), (Costa-jussà, 2017), Brazilian and European Portuguese (Costajussà et al., 2018), and several pairs of languages and language varieties such as Brazilian and European Portuguese, Canadian and European French, and similar languages such as Croatian and Serbian, and Indonesian and Malay (Lakew et al., 2018). The interest on diatopic language variation is evidenced by the recent iterations of the VarDial workshop in which papers on MT applied to similar languages varieties, and dialects (Shapiro and Duh, 2019; Myint Oo et al., 2019; Popović et al., 2020) have been presented along with evaluation campaigns featuring"
2020.wmt-1.50,W18-3931,1,0.817983,"Missing"
2020.wmt-1.50,2020.vardial-1.1,1,0.712774,"nguages such as Croatian and Serbian, and Indonesian and Malay (Lakew et al., 2018). The interest on diatopic language variation is evidenced by the recent iterations of the VarDial workshop in which papers on MT applied to similar languages varieties, and dialects (Shapiro and Duh, 2019; Myint Oo et al., 2019; Popović et al., 2020) have been presented along with evaluation campaigns featuring multiple shared tasks on a number of related topics such as cross-lingual morphological analysis, cross-lingual parsing, dialect identification, and morphosyntactic tagging (Zampieri et al., 2018, 2019; Găman et al., 2020). 3 Data Sources WMT News IITB PM India Total Remove duplicates Cleaning∗ #sentences 273,885 156,344 1,561,840 56,831 2,048,900 1,464,419 961,036 Table 1: English–Hindi parallel data statistics. ∗ Removing noisy mixed language sentences. We also back-translated 5 million Marathi monolingual sehments using our WIPRO-RIT CONTRASTIVE 1 system described in more detail Section 6. For Marathi–Hindi we did not use any back translation data in our CONTRASTIVE 2 and PRIMARY submissions. In the both cases 5 million English–Hindi backtranslation data provide significant (p < 0.01) improvements over CONTR"
2020.wmt-1.50,D10-1092,0,0.0410104,"der subword units (Sennrich et al., 2016) by using byte-pair encoding (BPE). In the preprocessing step, instead of learning an explicit mapping between BPEs in the English (EN), Hindi (HI) and Marathi (MR), we define BPE tokens by jointly processing all parallel data. Thus, all derive a single BPE vocabulary. Since HI and MR belong to the similar languages, they naturally share a good fraction of BPE tokens, which reduces the vocabulary size. We report evaluation results (evaluated by the shared task organizers) of our approach with the released Test data. BLEU (Papineni et al., 2002), RIBES (Isozaki et al., 2010) and TER (Snover et al., 2006) are used to evaluate the performance of all participating systems in the shared task. 1 https://github.com/anoopkunchukuttan/ indic_nlp_library/ 426 Parallel Data Filtered SLT Filtered EN–HI BT EN–HI BT HI–MR #sentences 33,923 961,036 5 million 5 million C1 ✓ ✓ ✓ C2 ✓ ✓ ✓ ✓ P ✓ ✓ ✓ ✓ Table 4: The training criteria data statistics of our submitted systems (C1 = Contrastive 1, C2 = Contrastive 2, P = Primary, and BT = Back-translated data). 5.2 Hyper-parameter Setup vocabulary size of 32K. After each epoch, the training data is shuffled. During decoding, we perform"
2020.wmt-1.50,P02-1040,0,0.114981,"anguages Santanu Pal1 , Marcos Zampieri2 1 Wipro AI Lab, India 2 Rochester Institute of Technology, USA santanu.pal2@wipro.com Abstract MT systems on translating between pairs of similar languages without English as a pivot language (Barrault et al., 2019). The organizers provided participants with training, development, and testing parallel data from three pairs of languages from three different language families: Spanish - Portuguese (Romance languages), Czech - Polish (Slavic languages), and Hindi - Nepali (Indo-Aryan languages). Systems were evaluated using automatic metrics, namely BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). In this paper we present the WIPRO-RIT systems submitted to the Similar Language Translation shared task at WMT 2020. The second edition of this shared task featured parallel data from pairs/groups of similar languages from three different language families: Indo-Aryan languages (Hindi and Marathi), Romance languages (Catalan, Portuguese, and Spanish), and South Slavic Languages (Croatian, Serbian, and Slovene). We report the results obtained by our systems in translating from Hindi to Marathi and from Marathi to Hindi. WIPRO-RIT achieved competitive performance"
2020.wmt-1.50,2020.vardial-1.10,0,0.146479,"arallel data released in WMT 2014 (Bojar et al., 2014), IITB parallel corpus (Kunchukuttan et al., 2018), the parallel dataset was collected from news (Siripragada et al., 2020) and the PMIndia (Haddow and Kirefu, 2020) parallel corpus (see Table 1). With the substantial performance improvements brought to MT by neural approaches, a growing interest in translating between pairs of similar languages, language varieties, and dialects has been observed. Recent studies have addressed MT between Arabic dialects (Harrat et al., 2019; Shapiro and Duh, 2019) Catalan and Spanish, Croatian and Serbian (Popović et al., 2020), (Costa-jussà, 2017), Brazilian and European Portuguese (Costajussà et al., 2018), and several pairs of languages and language varieties such as Brazilian and European Portuguese, Canadian and European French, and similar languages such as Croatian and Serbian, and Indonesian and Malay (Lakew et al., 2018). The interest on diatopic language variation is evidenced by the recent iterations of the VarDial workshop in which papers on MT applied to similar languages varieties, and dialects (Shapiro and Duh, 2019; Myint Oo et al., 2019; Popović et al., 2020) have been presented along with evaluatio"
2020.wmt-1.50,P16-1162,0,0.0392221,"e transformer architecture that can translate between multiple languages. To make use of multilingual data within a single NMT model, we perform one simple modification to the source side of the multilingual data, we use an additional token at the beginning of the each source sentence to indicate the target language by the NMT model would be translated as shown in Table 3. We train the model with all the processed multilingual data consisting of sen5.1 Experiment Setup To handle out-of-vocabulary words and to reduce the vocabulary size, instead of considering words, we consider subword units (Sennrich et al., 2016) by using byte-pair encoding (BPE). In the preprocessing step, instead of learning an explicit mapping between BPEs in the English (EN), Hindi (HI) and Marathi (MR), we define BPE tokens by jointly processing all parallel data. Thus, all derive a single BPE vocabulary. Since HI and MR belong to the similar languages, they naturally share a good fraction of BPE tokens, which reduces the vocabulary size. We report evaluation results (evaluated by the shared task organizers) of our approach with the released Test data. BLEU (Papineni et al., 2002), RIBES (Isozaki et al., 2010) and TER (Snover et"
2020.wmt-1.50,W19-1424,0,0.032189,"ystem. The Hindi–English NMT system was trained on English–Hindi parallel data released in WMT 2014 (Bojar et al., 2014), IITB parallel corpus (Kunchukuttan et al., 2018), the parallel dataset was collected from news (Siripragada et al., 2020) and the PMIndia (Haddow and Kirefu, 2020) parallel corpus (see Table 1). With the substantial performance improvements brought to MT by neural approaches, a growing interest in translating between pairs of similar languages, language varieties, and dialects has been observed. Recent studies have addressed MT between Arabic dialects (Harrat et al., 2019; Shapiro and Duh, 2019) Catalan and Spanish, Croatian and Serbian (Popović et al., 2020), (Costa-jussà, 2017), Brazilian and European Portuguese (Costajussà et al., 2018), and several pairs of languages and language varieties such as Brazilian and European Portuguese, Canadian and European French, and similar languages such as Croatian and Serbian, and Indonesian and Malay (Lakew et al., 2018). The interest on diatopic language variation is evidenced by the recent iterations of the VarDial workshop in which papers on MT applied to similar languages varieties, and dialects (Shapiro and Duh, 2019; Myint Oo et al., 201"
2020.wmt-1.50,P07-2045,0,0.0185268,"a subset 5 million Marathi monolingual data. We performed similar cleaning and pre-processing methods as we described in case of parallel data. The five million Hindi monolingual sentences were first back-translated to English Parallel News PM India Indic WordNet Total Filtered∗ #sentences 12,349 25,897 11,188 49,434 33923 Table 2: Data statistics of released SLT Data; ∗ Filtration methods: (i) remove duplicates and (ii) filtering noisy mixed language sentences. We performed the following two steps: (i) we use the cleaning process described in Pal et al. (2015), and (ii) we execute the Moses (Koehn et al., 2007) corpus cleaning scripts with minimum and maximum number of tokens set to 1 and 100, respectively. After cleaning and re425 Parallel Sentences L1 → L2 HI→MR MR→HI EN→HI Source Raw data Processed data Raw data Processed data Raw data Processed data Target देश एकल परयास से आगे बढ़ चुके ह। देश आता सामाईक परयतन करत आहेत. TO_MR देश एकल परयास से आगे बढ़ चुके ह। देश आता सामाईक परयतन करत आहेत. देश आता सामाईक परयतन करत आहेत. देश एकल परयास से आगे बढ़ चुके ह। TO_HI देश आता सामाईक परयतन करत आहेत. देश एकल परयास से आगे बढ़ चुके ह। The MoU was signed in February, 2016. इस एमओयू पर फरवरी, 2016 म हसता"
2020.wmt-1.50,2020.lrec-1.462,0,0.0599331,"the model described in Johnson et al. (2017). WIPRORIT achieved competitive performance ranking 1st in Marathi to Hindi and 2nd in Hindi to Marathi translation among 22 systems. 424 Proceedings of the 5th Conference on Machine Translation (WMT), pages 424–429 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics 2 Related Work using a Hindi–English NMT system. The Hindi–English NMT system was trained on English–Hindi parallel data released in WMT 2014 (Bojar et al., 2014), IITB parallel corpus (Kunchukuttan et al., 2018), the parallel dataset was collected from news (Siripragada et al., 2020) and the PMIndia (Haddow and Kirefu, 2020) parallel corpus (see Table 1). With the substantial performance improvements brought to MT by neural approaches, a growing interest in translating between pairs of similar languages, language varieties, and dialects has been observed. Recent studies have addressed MT between Arabic dialects (Harrat et al., 2019; Shapiro and Duh, 2019) Catalan and Spanish, Croatian and Serbian (Popović et al., 2020), (Costa-jussà, 2017), Brazilian and European Portuguese (Costajussà et al., 2018), and several pairs of languages and language varieties such as Brazilian"
2020.wmt-1.50,2006.amta-papers.25,0,0.338951,"ampieri2 1 Wipro AI Lab, India 2 Rochester Institute of Technology, USA santanu.pal2@wipro.com Abstract MT systems on translating between pairs of similar languages without English as a pivot language (Barrault et al., 2019). The organizers provided participants with training, development, and testing parallel data from three pairs of languages from three different language families: Spanish - Portuguese (Romance languages), Czech - Polish (Slavic languages), and Hindi - Nepali (Indo-Aryan languages). Systems were evaluated using automatic metrics, namely BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). In this paper we present the WIPRO-RIT systems submitted to the Similar Language Translation shared task at WMT 2020. The second edition of this shared task featured parallel data from pairs/groups of similar languages from three different language families: Indo-Aryan languages (Hindi and Marathi), Romance languages (Catalan, Portuguese, and Spanish), and South Slavic Languages (Croatian, Serbian, and Slovene). We report the results obtained by our systems in translating from Hindi to Marathi and from Marathi to Hindi. WIPRO-RIT achieved competitive performance ranking 1st in Marathi to Hin"
2020.wmt-1.50,L18-1548,0,0.0312343,"mission to the SLT 2020 Indo-Aryan track. Our WIPRO-RIT system is based on the model described in Johnson et al. (2017). WIPRORIT achieved competitive performance ranking 1st in Marathi to Hindi and 2nd in Hindi to Marathi translation among 22 systems. 424 Proceedings of the 5th Conference on Machine Translation (WMT), pages 424–429 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics 2 Related Work using a Hindi–English NMT system. The Hindi–English NMT system was trained on English–Hindi parallel data released in WMT 2014 (Bojar et al., 2014), IITB parallel corpus (Kunchukuttan et al., 2018), the parallel dataset was collected from news (Siripragada et al., 2020) and the PMIndia (Haddow and Kirefu, 2020) parallel corpus (see Table 1). With the substantial performance improvements brought to MT by neural approaches, a growing interest in translating between pairs of similar languages, language varieties, and dialects has been observed. Recent studies have addressed MT between Arabic dialects (Harrat et al., 2019; Shapiro and Duh, 2019) Catalan and Spanish, Croatian and Serbian (Popović et al., 2020), (Costa-jussà, 2017), Brazilian and European Portuguese (Costajussà et al., 2018),"
2020.wmt-1.50,W18-6316,0,0.0184966,"by neural approaches, a growing interest in translating between pairs of similar languages, language varieties, and dialects has been observed. Recent studies have addressed MT between Arabic dialects (Harrat et al., 2019; Shapiro and Duh, 2019) Catalan and Spanish, Croatian and Serbian (Popović et al., 2020), (Costa-jussà, 2017), Brazilian and European Portuguese (Costajussà et al., 2018), and several pairs of languages and language varieties such as Brazilian and European Portuguese, Canadian and European French, and similar languages such as Croatian and Serbian, and Indonesian and Malay (Lakew et al., 2018). The interest on diatopic language variation is evidenced by the recent iterations of the VarDial workshop in which papers on MT applied to similar languages varieties, and dialects (Shapiro and Duh, 2019; Myint Oo et al., 2019; Popović et al., 2020) have been presented along with evaluation campaigns featuring multiple shared tasks on a number of related topics such as cross-lingual morphological analysis, cross-lingual parsing, dialect identification, and morphosyntactic tagging (Zampieri et al., 2018, 2019; Găman et al., 2020). 3 Data Sources WMT News IITB PM India Total Remove duplicates"
2020.wmt-1.50,W19-1408,0,0.0313334,"and Duh, 2019) Catalan and Spanish, Croatian and Serbian (Popović et al., 2020), (Costa-jussà, 2017), Brazilian and European Portuguese (Costajussà et al., 2018), and several pairs of languages and language varieties such as Brazilian and European Portuguese, Canadian and European French, and similar languages such as Croatian and Serbian, and Indonesian and Malay (Lakew et al., 2018). The interest on diatopic language variation is evidenced by the recent iterations of the VarDial workshop in which papers on MT applied to similar languages varieties, and dialects (Shapiro and Duh, 2019; Myint Oo et al., 2019; Popović et al., 2020) have been presented along with evaluation campaigns featuring multiple shared tasks on a number of related topics such as cross-lingual morphological analysis, cross-lingual parsing, dialect identification, and morphosyntactic tagging (Zampieri et al., 2018, 2019; Găman et al., 2020). 3 Data Sources WMT News IITB PM India Total Remove duplicates Cleaning∗ #sentences 273,885 156,344 1,561,840 56,831 2,048,900 1,464,419 961,036 Table 1: English–Hindi parallel data statistics. ∗ Removing noisy mixed language sentences. We also back-translated 5 million Marathi monolingual"
2020.wmt-1.50,W15-5206,1,0.867989,"Missing"
2020.wmt-1.50,W15-3017,1,0.848858,"Missing"
2020.wmt-1.50,L16-1095,1,0.895951,"Missing"
C16-1241,2011.mtsummit-papers.35,1,0.926867,"Missing"
C16-1241,P15-2026,0,0.107171,"extracted a grammar for each input sentence and applied it to the model. Rosa et al. (2012) and Mareˇcek et al. (2011) applied a rule-based approach to APE of English–Czech MT outputs on the morphological level. They used 20 hand-written rules based on the most frequent errors encountered in translation. The method efficiently corrects morpho-syntactic categories of a word such as number, case, gender, person as well as dependency labels. The inclusion of source-language information in APE is also useful to improve the APE performance (B´echara et al., 2011). To overcome data sparsity issues, Chatterjee et al. (2015) proposed a pipeline where the best language model and pruned phrase table are selected through task-specific dense features. Recently, a bidirectional recurrent neural network model of APE using Tmt –Tpe was proposed by Pal et al. (2016) which consists of an encoder that encodes the MT output into a fixed-length vector from which a decoder provides a post-edited (PE) translation. They reported statistically significant improvement over a strong first stage MT system baseline. Various automatic or semi-automatic post-processing techniques to implement corrections of repetitive errors have been"
C16-1241,P05-1033,0,0.0631731,"n a different language. The same method was also applied to the monolingual Italian data. Next, the parallel corpus was further cleaned using the Gale-Church filtering method described in Tan and Pal (2014). We sorted the entire parallel training corpus based on sentence length and removed duplicates. We applied tokenization and punctuation normalization using the Moses scripts. 4.3 Experimental Settings In our APE experiments we first integrated the hybrid word alignment model (cf. Section 3.1) into the SAPE engines modelled with PB-SMT (Koehn et al., 2003) and hierarchical PB-SMT (HPB-SMT) (Chiang, 2005). For building our statistical APE system, we used maximum phrase length of 7 and a 5-gram language model trained using KenLM (Heafield, 2011). Model parameters were tuned using MERT (Och, 2003) on the held-out development set. 5 Evaluation During evaluation we take into consideration the output produced by all the three APE systems: PBSAPE with hybrid word alignment, HPB-SAPE with hybrid word alignment and the system combination system (SC-APE) which also includes the output from the first stage system Google MT. As a baseline APE system we use a PB-SAPE system with GIZA++ alignment. The eval"
C16-1241,P11-1043,0,0.137633,"ns in order to produce publishable quality translation (Roturier, 2009; TAUS/CNGL Report, 2010). Even though MT and APE output often need human PE, it is often faster and cheaper to post-edit MT and APE output than to perform human translation from scratch. System combination is a technology where multiple translation outputs from potentially very different MT systems are combined. System combination includes (i) hypothesis selection (Rosti et al., 2007a; Hildebrand and Vogel, 2010), (ii) confusion network based decoding (Matusov et al., 2006; Rosti et al., 2007b) and (iii) model combination (DeNero and Macherey, 2011). The confusion networks are built using backbone selection using either multiple hypotheses as backbones (Leusch and Ney, 2010) or a single backbone (Rosti et al., 2007b; Du et al., 2009) using TER (Snover et al., 2006) or BLEU (Papineni et al., 2002). These alignment metrics select the hypothesis that agrees most with the other hypotheses on average. System combination can improve translation quality significantly which motivated us to apply the strategy for the APE task. Some of the research mentioned above studied the impacts of various factors and methods in APE on productivity gains. How"
C16-1241,W11-2123,0,0.0161942,"g the Gale-Church filtering method described in Tan and Pal (2014). We sorted the entire parallel training corpus based on sentence length and removed duplicates. We applied tokenization and punctuation normalization using the Moses scripts. 4.3 Experimental Settings In our APE experiments we first integrated the hybrid word alignment model (cf. Section 3.1) into the SAPE engines modelled with PB-SMT (Koehn et al., 2003) and hierarchical PB-SMT (HPB-SMT) (Chiang, 2005). For building our statistical APE system, we used maximum phrase length of 7 and a 5-gram language model trained using KenLM (Heafield, 2011). Model parameters were tuned using MERT (Och, 2003) on the held-out development set. 5 Evaluation During evaluation we take into consideration the output produced by all the three APE systems: PBSAPE with hybrid word alignment, HPB-SAPE with hybrid word alignment and the system combination system (SC-APE) which also includes the output from the first stage system Google MT. As a baseline APE system we use a PB-SAPE system with GIZA++ alignment. The evaluation was carried out in two ways: (i) automatic evaluation and (ii) human evaluation of the 1,000 testset sentences automatically post-edite"
C16-1241,W10-1745,0,0.0277968,"f repetitive errors have been developed, although often the overall resulting MT output after APE still needs to be 2560 post-edited by humans in order to produce publishable quality translation (Roturier, 2009; TAUS/CNGL Report, 2010). Even though MT and APE output often need human PE, it is often faster and cheaper to post-edit MT and APE output than to perform human translation from scratch. System combination is a technology where multiple translation outputs from potentially very different MT systems are combined. System combination includes (i) hypothesis selection (Rosti et al., 2007a; Hildebrand and Vogel, 2010), (ii) confusion network based decoding (Matusov et al., 2006; Rosti et al., 2007b) and (iii) model combination (DeNero and Macherey, 2011). The confusion networks are built using backbone selection using either multiple hypotheses as backbones (Leusch and Ney, 2010) or a single backbone (Rosti et al., 2007b; Du et al., 2009) using TER (Snover et al., 2006) or BLEU (Papineni et al., 2002). These alignment metrics select the hypothesis that agrees most with the other hypotheses on average. System combination can improve translation quality significantly which motivated us to apply the strategy"
C16-1241,N03-1017,0,0.189052,"ased on a number of alignment approaches, (ii) PB-SAPE, (iii) HPB-SAPE, and (iv) a system combination module (also including the first stage MT system). The SAPE systems are trained monolingually with Italian Tmt generated by Google Translate (GT) and the manually post-edited translations Tpe . 3.1 A Hybrid Word Alignment Model for Target Side APE Previous research in MT demonstrates that a combination of information coming from multiple alignment models can improve translation quality. This can be achieved in different ways, e.g., by combining exactly two bidirectional alignments (Och, 2003; Koehn et al., 2003; DeNero and Macherey, 2011), combining an arbitrary number of alignments (Tu et al., 2012; Pal et al., 2013), by constructing weighted alignment matrices over 1-best alignments from multiple alignments generated by different models (Liu et al., 2009; Tu et al., 2011) etc. Below we apply an alignment combination model to APE. Our hybrid word alignment method combines word alignments produced by three different statistical word alignment methods: (i) GIZA++ (Och and Ney, 2003) word alignment with grow-diag-finaland (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006"
C16-1241,J10-4005,0,0.207854,"ly two bidirectional alignments (Och, 2003; Koehn et al., 2003; DeNero and Macherey, 2011), combining an arbitrary number of alignments (Tu et al., 2012; Pal et al., 2013), by constructing weighted alignment matrices over 1-best alignments from multiple alignments generated by different models (Liu et al., 2009; Tu et al., 2011) etc. Below we apply an alignment combination model to APE. Our hybrid word alignment method combines word alignments produced by three different statistical word alignment methods: (i) GIZA++ (Och and Ney, 2003) word alignment with grow-diag-finaland (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on TER (Translation Edit Rate) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow Pal et al. (2013) in combining word alignment tables, however, we additionally use 3-word consistent phrases to generate more alignment links (cf. Section 3.1.3). We integrate the word alignment obtained with this hybrid model into our PB-SAPE (Pal et al., 2015) and HPB-SAPE (Pal, 2015) models. 3.1.1 Statistica"
C16-1241,N04-1022,0,0.166533,"red as Sa . • Step 3: Delete all the alignment points aij ∈ Sc such that ∃aik ∈ a4 ∪ a5 where j 6= k. • Step 4: Update Sc as Sc = Sc ∪ a4 ∪ a5 . 3.3 System Combination for APE Our system combination framework selects the best hypothesis translation from multiple hypotheses produced by different systems. In order to apply the system combination framework on the translations produced by our SAPE systems and the baseline MT system (Google Translate) we implemented the Minimum Bayes Risk (MBR) coupled with the Confusion Network (MBRCN) framework as described in (Du et al., 2009). The MBR decoder (Kumar and Byrne, 2004) selects for each sentence the best system output from the three outputs by minimizing BLEU (Papineni et al., 2002) loss. This output is known as the backbone. A confusion network (Matusov et al., 2006) is built from the backbone while the remaining hypotheses are aligned against the backbone using the edit-distance based alignment methods (cf. Section 3.1.2). The features used to score each arc in the confusion network (CN) are word posterior probability, target language model and length penalties. Minimum Error Rate Training (MERT) (Och, 2003) is applied to tune the CN weights. In our experi"
C16-1241,W07-0734,0,0.071243,"generated by different models (Liu et al., 2009; Tu et al., 2011) etc. Below we apply an alignment combination model to APE. Our hybrid word alignment method combines word alignments produced by three different statistical word alignment methods: (i) GIZA++ (Och and Ney, 2003) word alignment with grow-diag-finaland (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on TER (Translation Edit Rate) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow Pal et al. (2013) in combining word alignment tables, however, we additionally use 3-word consistent phrases to generate more alignment links (cf. Section 3.1.3). We integrate the word alignment obtained with this hybrid model into our PB-SAPE (Pal et al., 2015) and HPB-SAPE (Pal, 2015) models. 3.1.1 Statistical Word Alignment GIZA++ is a statistical word alignment tool which implements IBM models 1–5, an HMM alignment model, as well as the IBM-6 model for covering many to many alignments. The Berkeley word aligner uses an extension of Cross Expectation Maximization and is jointly"
C16-1241,W10-1747,0,0.0191016,"need human PE, it is often faster and cheaper to post-edit MT and APE output than to perform human translation from scratch. System combination is a technology where multiple translation outputs from potentially very different MT systems are combined. System combination includes (i) hypothesis selection (Rosti et al., 2007a; Hildebrand and Vogel, 2010), (ii) confusion network based decoding (Matusov et al., 2006; Rosti et al., 2007b) and (iii) model combination (DeNero and Macherey, 2011). The confusion networks are built using backbone selection using either multiple hypotheses as backbones (Leusch and Ney, 2010) or a single backbone (Rosti et al., 2007b; Du et al., 2009) using TER (Snover et al., 2006) or BLEU (Papineni et al., 2002). These alignment metrics select the hypothesis that agrees most with the other hypotheses on average. System combination can improve translation quality significantly which motivated us to apply the strategy for the APE task. Some of the research mentioned above studied the impacts of various factors and methods in APE on productivity gains. However, those studies were not conducted to observe PE effort in commercial environments. The focus of our study is twofold - to e"
C16-1241,N06-1014,0,0.0609824,"Koehn et al., 2003; DeNero and Macherey, 2011), combining an arbitrary number of alignments (Tu et al., 2012; Pal et al., 2013), by constructing weighted alignment matrices over 1-best alignments from multiple alignments generated by different models (Liu et al., 2009; Tu et al., 2011) etc. Below we apply an alignment combination model to APE. Our hybrid word alignment method combines word alignments produced by three different statistical word alignment methods: (i) GIZA++ (Och and Ney, 2003) word alignment with grow-diag-finaland (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on TER (Translation Edit Rate) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow Pal et al. (2013) in combining word alignment tables, however, we additionally use 3-word consistent phrases to generate more alignment links (cf. Section 3.1.3). We integrate the word alignment obtained with this hybrid model into our PB-SAPE (Pal et al., 2015) and HPB-SAPE (Pal, 2015) models. 3.1.1 Statistical Word Alignment GIZA++ is a statistical word align"
C16-1241,D09-1106,0,0.0257389,"the manually post-edited translations Tpe . 3.1 A Hybrid Word Alignment Model for Target Side APE Previous research in MT demonstrates that a combination of information coming from multiple alignment models can improve translation quality. This can be achieved in different ways, e.g., by combining exactly two bidirectional alignments (Och, 2003; Koehn et al., 2003; DeNero and Macherey, 2011), combining an arbitrary number of alignments (Tu et al., 2012; Pal et al., 2013), by constructing weighted alignment matrices over 1-best alignments from multiple alignments generated by different models (Liu et al., 2009; Tu et al., 2011) etc. Below we apply an alignment combination model to APE. Our hybrid word alignment method combines word alignments produced by three different statistical word alignment methods: (i) GIZA++ (Och and Ney, 2003) word alignment with grow-diag-finaland (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on TER (Translation Edit Rate) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow Pal et al. ("
C16-1241,E06-1005,0,0.461663,"th International Conference on Computational Linguistics: Technical Papers, pages 2559–2570, Osaka, Japan, December 11-17 2016. without the availability of Sip using only sufficient amounts of parallel “target-side” Tmt –Tpe text within the statistical MT (SMT) framework. Usually APE tasks focus on systematic errors made by MT systems - the most frequent ones being incorrect lexical choices, incorrect word ordering, incorrect insertion or deletion of a word. The system presented in this paper explores the use of system combination in APE. System combination in MT has been studied extensively (Matusov et al., 2006; Du et al., 2009; Pal et al., 2014), except in the context of APE. Here we use system combination architectures on three different levels: (i) sequential combination between first-stage system and APE, (ii) parallel combination of alignment systems at the level of the APE and (iii) parallel combination of APE MT systems (including the first stage MT system). More precisely, our approach makes use of a hybrid implementation of multiple alignment combination within phrase-based SAPE (PB-SAPE) and hierarchical PB-SAPE (HPB-SAPE) and a system combination framework (a multi-engine pipeline) – that"
C16-1241,J03-1002,0,0.00748102,"on quality. This can be achieved in different ways, e.g., by combining exactly two bidirectional alignments (Och, 2003; Koehn et al., 2003; DeNero and Macherey, 2011), combining an arbitrary number of alignments (Tu et al., 2012; Pal et al., 2013), by constructing weighted alignment matrices over 1-best alignments from multiple alignments generated by different models (Liu et al., 2009; Tu et al., 2011) etc. Below we apply an alignment combination model to APE. Our hybrid word alignment method combines word alignments produced by three different statistical word alignment methods: (i) GIZA++ (Och and Ney, 2003) word alignment with grow-diag-finaland (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on TER (Translation Edit Rate) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow Pal et al. (2013) in combining word alignment tables, however, we additionally use 3-word consistent phrases to generate more alignment links (cf. Section 3.1.3). We integrate the word alignment obtained with this hybrid model into our PB-SAP"
C16-1241,P03-1021,0,0.385927,"ent model based on a number of alignment approaches, (ii) PB-SAPE, (iii) HPB-SAPE, and (iv) a system combination module (also including the first stage MT system). The SAPE systems are trained monolingually with Italian Tmt generated by Google Translate (GT) and the manually post-edited translations Tpe . 3.1 A Hybrid Word Alignment Model for Target Side APE Previous research in MT demonstrates that a combination of information coming from multiple alignment models can improve translation quality. This can be achieved in different ways, e.g., by combining exactly two bidirectional alignments (Och, 2003; Koehn et al., 2003; DeNero and Macherey, 2011), combining an arbitrary number of alignments (Tu et al., 2012; Pal et al., 2013), by constructing weighted alignment matrices over 1-best alignments from multiple alignments generated by different models (Liu et al., 2009; Tu et al., 2011) etc. Below we apply an alignment combination model to APE. Our hybrid word alignment method combines word alignments produced by three different statistical word alignment methods: (i) GIZA++ (Och and Ney, 2003) word alignment with grow-diag-finaland (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment"
C16-1241,W13-2814,1,0.950207,"Sip information. System combination and hybrid word alignment strategies are commonly used in MT, however to the best of our knowledge the work presented in this paper is the first approach to APE that uses system combination and hybrid word alignment methods within the APE engine. System combination has been found to be a very useful technique in MT where translation hypotheses from multiple MT engines are available. Motivated by the success of system combination in MT, we applied system combination in APE. Similarly, the use of multiple word alignments has been shown to improve MT results (Pal et al., 2013). For our APE, alignments have to be produced on “monolingual” target-side data (Tmt and Tpe ). A particular focus of our paper is to explore the performance of hybrid alignments based on combinations of statistical and edit-distance based aligners in this “monolingual” setting. The remainder of the paper is organized as follows. Section 2 gives an overview of the related work. Section 3 describes the components of our SAPE system. Section 4 outlines the data and data preprocessing and the experimental setup. Section 5 presents the results of automatic and human evaluation, followed by conclus"
C16-1241,W15-3026,1,0.8818,"Missing"
C16-1241,P16-2046,1,0.84354,"Missing"
C16-1241,P02-1040,0,0.0959305,". System combination is a technology where multiple translation outputs from potentially very different MT systems are combined. System combination includes (i) hypothesis selection (Rosti et al., 2007a; Hildebrand and Vogel, 2010), (ii) confusion network based decoding (Matusov et al., 2006; Rosti et al., 2007b) and (iii) model combination (DeNero and Macherey, 2011). The confusion networks are built using backbone selection using either multiple hypotheses as backbones (Leusch and Ney, 2010) or a single backbone (Rosti et al., 2007b; Du et al., 2009) using TER (Snover et al., 2006) or BLEU (Papineni et al., 2002). These alignment metrics select the hypothesis that agrees most with the other hypotheses on average. System combination can improve translation quality significantly which motivated us to apply the strategy for the APE task. Some of the research mentioned above studied the impacts of various factors and methods in APE on productivity gains. However, those studies were not conducted to observe PE effort in commercial environments. The focus of our study is twofold - to examine how existing word alignment techniques and a system combination framework can be intelligently used to improve monoli"
C16-1241,W12-3146,0,0.370811,"Missing"
C16-1241,N07-1029,0,0.0327304,"plement corrections of repetitive errors have been developed, although often the overall resulting MT output after APE still needs to be 2560 post-edited by humans in order to produce publishable quality translation (Roturier, 2009; TAUS/CNGL Report, 2010). Even though MT and APE output often need human PE, it is often faster and cheaper to post-edit MT and APE output than to perform human translation from scratch. System combination is a technology where multiple translation outputs from potentially very different MT systems are combined. System combination includes (i) hypothesis selection (Rosti et al., 2007a; Hildebrand and Vogel, 2010), (ii) confusion network based decoding (Matusov et al., 2006; Rosti et al., 2007b) and (iii) model combination (DeNero and Macherey, 2011). The confusion networks are built using backbone selection using either multiple hypotheses as backbones (Leusch and Ney, 2010) or a single backbone (Rosti et al., 2007b; Du et al., 2009) using TER (Snover et al., 2006) or BLEU (Papineni et al., 2002). These alignment metrics select the hypothesis that agrees most with the other hypotheses on average. System combination can improve translation quality significantly which motiv"
C16-1241,P07-1040,0,0.0305381,"plement corrections of repetitive errors have been developed, although often the overall resulting MT output after APE still needs to be 2560 post-edited by humans in order to produce publishable quality translation (Roturier, 2009; TAUS/CNGL Report, 2010). Even though MT and APE output often need human PE, it is often faster and cheaper to post-edit MT and APE output than to perform human translation from scratch. System combination is a technology where multiple translation outputs from potentially very different MT systems are combined. System combination includes (i) hypothesis selection (Rosti et al., 2007a; Hildebrand and Vogel, 2010), (ii) confusion network based decoding (Matusov et al., 2006; Rosti et al., 2007b) and (iii) model combination (DeNero and Macherey, 2011). The confusion networks are built using backbone selection using either multiple hypotheses as backbones (Leusch and Ney, 2010) or a single backbone (Rosti et al., 2007b; Du et al., 2009) using TER (Snover et al., 2006) or BLEU (Papineni et al., 2002). These alignment metrics select the hypothesis that agrees most with the other hypotheses on average. System combination can improve translation quality significantly which motiv"
C16-1241,N07-1064,0,0.171061,"paper is to explore the performance of hybrid alignments based on combinations of statistical and edit-distance based aligners in this “monolingual” setting. The remainder of the paper is organized as follows. Section 2 gives an overview of the related work. Section 3 describes the components of our SAPE system. Section 4 outlines the data and data preprocessing and the experimental setup. Section 5 presents the results of automatic and human evaluation, followed by conclusions and avenues for further research in Section 6. 2 Related Research APE approaches cover a wide methodological range. Simard et al. (2007a) and Simard et al. (2007b) applied phrase-based SMT (PB-SMT) for post-editing that handles the repetitive nature of errors typically made by rule-based MT (RBMT) systems. The APE system was trained on the output of the rule-based system as the source language and reference human translations as the target language. This APE system was able to correct systematic errors produced by the RBMT system and reduce the post-editing effort. The approach achieved large improvements in performance not only over the baseline rule-based system but also over a similar PB-SMT used in a standalone mode. Denk"
C16-1241,W07-0728,0,0.0686589,"paper is to explore the performance of hybrid alignments based on combinations of statistical and edit-distance based aligners in this “monolingual” setting. The remainder of the paper is organized as follows. Section 2 gives an overview of the related work. Section 3 describes the components of our SAPE system. Section 4 outlines the data and data preprocessing and the experimental setup. Section 5 presents the results of automatic and human evaluation, followed by conclusions and avenues for further research in Section 6. 2 Related Research APE approaches cover a wide methodological range. Simard et al. (2007a) and Simard et al. (2007b) applied phrase-based SMT (PB-SMT) for post-editing that handles the repetitive nature of errors typically made by rule-based MT (RBMT) systems. The APE system was trained on the output of the rule-based system as the source language and reference human translations as the target language. This APE system was able to correct systematic errors produced by the RBMT system and reduce the post-editing effort. The approach achieved large improvements in performance not only over the baseline rule-based system but also over a similar PB-SMT used in a standalone mode. Denk"
C16-1241,2006.amta-papers.25,0,0.54011,"human translation from scratch. System combination is a technology where multiple translation outputs from potentially very different MT systems are combined. System combination includes (i) hypothesis selection (Rosti et al., 2007a; Hildebrand and Vogel, 2010), (ii) confusion network based decoding (Matusov et al., 2006; Rosti et al., 2007b) and (iii) model combination (DeNero and Macherey, 2011). The confusion networks are built using backbone selection using either multiple hypotheses as backbones (Leusch and Ney, 2010) or a single backbone (Rosti et al., 2007b; Du et al., 2009) using TER (Snover et al., 2006) or BLEU (Papineni et al., 2002). These alignment metrics select the hypothesis that agrees most with the other hypotheses on average. System combination can improve translation quality significantly which motivated us to apply the strategy for the APE task. Some of the research mentioned above studied the impacts of various factors and methods in APE on productivity gains. However, those studies were not conducted to observe PE effort in commercial environments. The focus of our study is twofold - to examine how existing word alignment techniques and a system combination framework can be inte"
C16-1241,W14-3323,1,0.846697,"d a language identifier (Shuyo, 2010) on both bilingual English–Italian MT output and MT 2 3 Empirically best preforming aligner among the individual aligners (a1 , a2 or a3 ), is considered as Sa . https://www.matecat.com/ 2563 output–PE (Italian) parallel data. We discarded those sentence pairs from the bilingual training data which are considered as belonging to a different language or contain segment(s) in a different language. The same method was also applied to the monolingual Italian data. Next, the parallel corpus was further cleaned using the Gale-Church filtering method described in Tan and Pal (2014). We sorted the entire parallel training corpus based on sentence length and removed duplicates. We applied tokenization and punctuation normalization using the Moses scripts. 4.3 Experimental Settings In our APE experiments we first integrated the hybrid word alignment model (cf. Section 3.1) into the SAPE engines modelled with PB-SMT (Koehn et al., 2003) and hierarchical PB-SMT (HPB-SMT) (Chiang, 2005). For building our statistical APE system, we used maximum phrase length of 7 and a 5-gram language model trained using KenLM (Heafield, 2011). Model parameters were tuned using MERT (Och, 2003"
C16-1241,I11-1145,0,0.0155645,"edited translations Tpe . 3.1 A Hybrid Word Alignment Model for Target Side APE Previous research in MT demonstrates that a combination of information coming from multiple alignment models can improve translation quality. This can be achieved in different ways, e.g., by combining exactly two bidirectional alignments (Och, 2003; Koehn et al., 2003; DeNero and Macherey, 2011), combining an arbitrary number of alignments (Tu et al., 2012; Pal et al., 2013), by constructing weighted alignment matrices over 1-best alignments from multiple alignments generated by different models (Liu et al., 2009; Tu et al., 2011) etc. Below we apply an alignment combination model to APE. Our hybrid word alignment method combines word alignments produced by three different statistical word alignment methods: (i) GIZA++ (Och and Ney, 2003) word alignment with grow-diag-finaland (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on TER (Translation Edit Rate) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow Pal et al. (2013) in combining"
C16-1241,C12-2122,1,0.889141,"Missing"
C16-1241,W14-0314,0,0.0161135,"amount of manual effort (TAUS Report, 2010). While MT is often not perfect, post-editing MT can yield productivity gains as post-editing MT output may require less effort compared to translating the same input manually from scratch. MT outputs are often post-edited by professional translators and the use of MT has become an important part of the translation workflow. A number of studies confirm that post-editing MT output can improve translators’ performance in terms of productivity and it may positively impact on translation quality and consistency (Guerberof, 2009; Plitt and Masselot, 2010; Zampieri and Vela, 2014). The wide use of MT in modern translation workflows in the localization industry, in turn, has resulted in substantial quantities of PE data which can be used to develop APE systems. APE (Knight and Chander, 1994) has been proposed as an automatic method for improving raw MT output, before performing actual human post-editing on it. The approach is based on collecting human corrected output of a first stage MT system and using this to train a system to correct errors produced by the MT system, possibly resulting in a productivity increase in the translation process. The advantage of APE relie"
C16-1241,W09-0416,0,\N,Missing
C16-2021,C14-2028,0,0.0270396,"t post-editing MT output increases translators’ productivity and improves translation consistency (Guerberof, 2009; Plitt and Masselot, 2010; Zampieri and Vela, 2014). Alongside classical TM matches, computer-aided translation (CAT) Tools that integrate MT and TM output are a trend in the translation and localization industries providing translators more useful suggestions. Another important trend is the development of web-based CAT tools which require no local software installation and allow teams of translators to work on the same project simultaneously (e.g., WordFast Anywhere1 , MateCat2 (Federico et al., 2014), and Wordbee3 , Lilt4 etc.). This paper presents CATaLog Online, a web-based CAT tool that provides translators MT, TM and APE output and ensures data capture for APE development and translation process research. The MT and APE systems integrated in CATaLog Online are based on Pal et al. (2015) and Pal et al. (2016b), respectively. In this paper, we present the key features implemented in CATaLog Online and their importance to translation project managers, translators, and MT and APE developers. Compared to state-ofthe-art CAT tools (e.g., MateCat, Lilt) CATaLog Online offers the following ad"
C16-2021,W15-5206,1,0.763618,"Missing"
C16-2021,W15-3017,1,0.660709,"Missing"
C16-2021,L16-1095,1,0.88264,"Missing"
C16-2021,W16-2379,1,0.862937,"Missing"
C16-2021,W14-0314,1,0.843535,"th current state-of-the-art CAT tools, CATaLog Online provides an enhanced interface, an option to integrate APE and more informative logs to help translation process research. 1 Introduction Machine translation (MT) technology has improved substantially over the past few decades. MT output is no longer used just for gisting but also for post-editing by professional translators as an important part of the translation workflow. Several studies confirm that post-editing MT output increases translators’ productivity and improves translation consistency (Guerberof, 2009; Plitt and Masselot, 2010; Zampieri and Vela, 2014). Alongside classical TM matches, computer-aided translation (CAT) Tools that integrate MT and TM output are a trend in the translation and localization industries providing translators more useful suggestions. Another important trend is the development of web-based CAT tools which require no local software installation and allow teams of translators to work on the same project simultaneously (e.g., WordFast Anywhere1 , MateCat2 (Federico et al., 2014), and Wordbee3 , Lilt4 etc.). This paper presents CATaLog Online, a web-based CAT tool that provides translators MT, TM and APE output and ensur"
E17-2056,P15-2026,0,0.249424,"human post-editing (Knight and Chander, 1994). APE assumes the availability of source texts (src), corresponding MT output (mt) and the human postedited (pe) version of mt. However, APE systems can also be built without the availability of src, by using only sufficient amounts of target side “mono-lingual” parallel mt–pe data. Usually APE tasks focus on systematic errors made by first stage MT systems, acting as an effective remedy to some of the inaccuracies in raw MT output. APE approaches cover a wide methodological range such as SMT techniques (Simard et al., 2007a; Simard et al., 2007b; Chatterjee et al., 2015; Pal et al., 2015; Pal et al., 2016d) real time integration of post-editing in MT (Denkowski, 2015), rule-based approaches to APE (Mareˇcek et al., 2011; Rosa et al., 2012), neural APE (JunczysDowmunt and Grundkiewicz, 2016; Pal et al., 2016b), multi-engine and multi-alignment APE (Pal et al., 2016a), etc. We present a second-stage machine translation (MT) system based on a neural machine translation (NMT) approach to automatic post-editing (APE) that improves the translation quality provided by a firststage MT system. Our APE system (AP ESym ) is an extended version of an attention based NMT"
E17-2056,N16-1102,0,0.204776,"rate a corresponding aid based on the context swid appears in. The APE words are generated from aid by looking up the hybrid prior alignment look-up table (LUT). Neural MT jointly learns alignment and translation. Replacing the source and target words by swid and aid , respectively, implicitly integrates the prior alignment and lessens the burden of the attention model. Secondly, our approach bears a resemblance to the sense embedding approach (Li and Jurafsky, 2015) since an embedding is generated for each (swid , aid ) pair. quality. Our neural model of APE is based on the work described in Cohn et al. (2016) which implements structural alignment biases into an attention based bidirectional recurrent neural network (RNN) MT model (Bahdanau et al., 2015). Cohn et al. (2016) extends the attentional soft alignment model to traditional word alignment models (IBM models) and agreement over both translation directions (in our case mt → pe and pe → mt) to ensure better alignment consistency. We follow Cohn et al. (2016) in encouraging our alignment models to be symmetric (Och and Ney, 2003) in both translation directions with embedded prior alignments. Different from Cohn et al. (2016), we employed prior"
E17-2056,D15-1200,0,0.0129567,"unique identification number (aid ) and a vector representation is generated for each such aid . Given a swid , the neural APE model is trained to generate a corresponding aid based on the context swid appears in. The APE words are generated from aid by looking up the hybrid prior alignment look-up table (LUT). Neural MT jointly learns alignment and translation. Replacing the source and target words by swid and aid , respectively, implicitly integrates the prior alignment and lessens the burden of the attention model. Secondly, our approach bears a resemblance to the sense embedding approach (Li and Jurafsky, 2015) since an embedding is generated for each (swid , aid ) pair. quality. Our neural model of APE is based on the work described in Cohn et al. (2016) which implements structural alignment biases into an attention based bidirectional recurrent neural network (RNN) MT model (Bahdanau et al., 2015). Cohn et al. (2016) extends the attentional soft alignment model to traditional word alignment models (IBM models) and agreement over both translation directions (in our case mt → pe and pe → mt) to ensure better alignment consistency. We follow Cohn et al. (2016) in encouraging our alignment models to b"
E17-2056,W06-1607,0,0.0220804,"rd pairs from hybrid prior alignment (Section 2.1) between mt–pe (12K data) were used for the additional training data to build AP EB2 . The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both the source and target language. Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (1) in the PB-SMT framework. To compensate this shortcoming, we performed smoothing of the phrase table using the Good-Turing smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003). kx and ky correspond to the vocabulary sizes of source and target languages, respectively. The hidden state of the decoder at time t is computed as ηt = f (ηt−1 , yt−1 , ct ), where ct is the context vecP x tor computed as ct = Ti=1 αti hi . Here, αti is the weight of each hi and can be computed as in Equation 1 exp(eti ) αti = Pm (1) j=1 exp(etj ) where eti = a(ηt−1 , hi ) is a word alignment model. Based on the input (mt) and output (pe) sequence lengths, Tx and Ty , the alignment model is computed Tx × Ty"
E17-2056,N06-1014,0,0.513033,"corrected by human translators. This task is referred to as post-editing (PE). PE is often understood as the process of improving a translation provided by an MT system with the minimum In this paper we present a neural network based APE system to improve raw first-stage MT output 349 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 349–355, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics grow-diag-final-and (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on Translation Edit Rate (TER) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow the alignment strategy described in (Pal et al., 2013; Pal et al., 2016a). The aligned word pairs are added as additional training examples to train our symmetric neural APE model. Each word in the first stage MT output is assigned a unique id (swid ). Each mt–pe word alignment also gets a unique identification number (aid ) and a vector representation is gener"
E17-2056,D08-1089,0,0.0468216,"ata. For building our AP EB2 system, we set a maximum phrase length of 7 for the translation model, and a 5-gram language model was trained using KenLM (Heafield, 2011). Word alignments between the mt and pe (4.5M synthetic mt-pe data + 12K WMT APE data) were established using the Berkeley Aligner (Liang et al., 2006), while word pairs from hybrid prior alignment (Section 2.1) between mt–pe (12K data) were used for the additional training data to build AP EB2 . The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both the source and target language. Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (1) in the PB-SMT framework. To compensate this shortcoming, we performed smoothing of the phrase table using the Good-Turing smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003). kx and ky correspond to the vocabulary sizes of source and target languages, respectively. The hidden state of the decoder at time t is computed as ηt = f (ηt−1 , yt−1 , ct ), where ct is th"
E17-2056,W11-2123,0,0.0229802,"mt–pe symmetric model (AP ESym ) against the best performing system (W M TBest ) in the WMT 2016 APE task and the standard log-linear mt–pe PB-SMT model with hybrid prior alignment as described in Section 2.1 (AP EB2 ). AP EB2 and AP ESym models are trained on 4.55M (4.5M + 12K + pre-aligned word pairs) parallel mt–pe data. The pre-aligned word pairs are obtained from the hybrid prior word alignments (Section 2.1) of the 12K WMT APE training data. For building our AP EB2 system, we set a maximum phrase length of 7 for the translation model, and a 5-gram language model was trained using KenLM (Heafield, 2011). Word alignments between the mt and pe (4.5M synthetic mt-pe data + 12K WMT APE data) were established using the Berkeley Aligner (Liang et al., 2006), while word pairs from hybrid prior alignment (Section 2.1) between mt–pe (12K data) were used for the additional training data to build AP EB2 . The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both the source and target language. Phrase pairs that occur only once in the training data are assigned an unduly high pro"
E17-2056,J03-1002,0,0.0268,"edding is generated for each (swid , aid ) pair. quality. Our neural model of APE is based on the work described in Cohn et al. (2016) which implements structural alignment biases into an attention based bidirectional recurrent neural network (RNN) MT model (Bahdanau et al., 2015). Cohn et al. (2016) extends the attentional soft alignment model to traditional word alignment models (IBM models) and agreement over both translation directions (in our case mt → pe and pe → mt) to ensure better alignment consistency. We follow Cohn et al. (2016) in encouraging our alignment models to be symmetric (Och and Ney, 2003) in both translation directions with embedded prior alignments. Different from Cohn et al. (2016), we employed prior alignment computed by a hybrid multi-alignment approach. Evaluation results show consistent improvements over the raw firststage MT system output and over the previous best performing neural APE (Junczys-Dowmunt and Grundkiewicz, 2016) on the WMT 2016 APE test set. In addition we show that re-ranking n-best output from baseline and enhanced PB-SMT APE systems (Section 3) together with our neural APE output provides further statistically significant improvements over all the othe"
E17-2056,W16-2378,0,0.447981,"alignment model to traditional word alignment models (IBM models) and agreement over both translation directions (in our case mt → pe and pe → mt) to ensure better alignment consistency. We follow Cohn et al. (2016) in encouraging our alignment models to be symmetric (Och and Ney, 2003) in both translation directions with embedded prior alignments. Different from Cohn et al. (2016), we employed prior alignment computed by a hybrid multi-alignment approach. Evaluation results show consistent improvements over the raw firststage MT system output and over the previous best performing neural APE (Junczys-Dowmunt and Grundkiewicz, 2016) on the WMT 2016 APE test set. In addition we show that re-ranking n-best output from baseline and enhanced PB-SMT APE systems (Section 3) together with our neural APE output provides further statistically significant improvements over all the other systems. The main contributions of our research are (i) an application of bilingual symmetry of the bidirectional RNN for APE, (ii) using a hybrid multialignment based approach for the prior alignments, (iii) a smart way of embedding word alignment information in neural APE, and (iv) applying reranking for the APE task. The remainder of the paper i"
E17-2056,P03-1021,0,0.127663,"= σ(W r Ex is the word embedding matrix of the MT output, W r ∈ Rm×n and U r ∈ Rn×n are weight matrices, m is the word embedding dimensionality and n represents the number of hidden units. Symmetric Neural Automatic Post Editing Using Prior Alignment Below we describe bilingual symmetry of bidirectional RNN with embedded prior word alignment for APE. 2.1 Symmetric Neural APE Hybrid Prior Alignment The monolingual mt–pe parallel corpus is first word aligned using a hybrid word alignment method based on the alignment combination of three different statistical word alignment methods: (i) GIZA++ (Och, 2003) word alignment with 350 data described in Bojar et al. (2016) and for some experiments we also use the 4.5M artificially developed APE data described in Junczys-Dowmunt and Grundkiewicz (2016). The training data consists of English–German triplets containing source English text (src) from the IT domain, corresponding German translations (mt) from a firststage MT system and the corresponding human post-edited version (pe). Development and test data contain 1,000 and 2,000 triplets respectively. We considered two baselines: (i) the raw MT output provided by the first-stage MT system serves as B"
E17-2056,W13-2814,1,0.838103,"dings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 349–355, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics grow-diag-final-and (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on Translation Edit Rate (TER) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow the alignment strategy described in (Pal et al., 2013; Pal et al., 2016a). The aligned word pairs are added as additional training examples to train our symmetric neural APE model. Each word in the first stage MT output is assigned a unique id (swid ). Each mt–pe word alignment also gets a unique identification number (aid ) and a vector representation is generated for each such aid . Given a swid , the neural APE model is trained to generate a corresponding aid based on the context swid appears in. The APE words are generated from aid by looking up the hybrid prior alignment look-up table (LUT). Neural MT jointly learns alignment and translatio"
E17-2056,W15-3026,1,0.847079,"Missing"
E17-2056,W04-3250,0,0.0339845,"Missing"
E17-2056,J10-4005,0,0.0193819,"ions produced by MT systems often need to be corrected by human translators. This task is referred to as post-editing (PE). PE is often understood as the process of improving a translation provided by an MT system with the minimum In this paper we present a neural network based APE system to improve raw first-stage MT output 349 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 349–355, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics grow-diag-final-and (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on Translation Edit Rate (TER) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow the alignment strategy described in (Pal et al., 2013; Pal et al., 2016a). The aligned word pairs are added as additional training examples to train our symmetric neural APE model. Each word in the first stage MT output is assigned a unique id (swid ). Each mt–pe word alignment also gets a unique identification"
E17-2056,C16-1241,1,0.878149,"Missing"
E17-2056,W07-0734,0,0.0440759,"network based APE system to improve raw first-stage MT output 349 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 349–355, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics grow-diag-final-and (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on Translation Edit Rate (TER) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow the alignment strategy described in (Pal et al., 2013; Pal et al., 2016a). The aligned word pairs are added as additional training examples to train our symmetric neural APE model. Each word in the first stage MT output is assigned a unique id (swid ). Each mt–pe word alignment also gets a unique identification number (aid ) and a vector representation is generated for each such aid . Given a swid , the neural APE model is trained to generate a corresponding aid based on the context swid appears in. The APE words are generated from aid by looking up the hybrid prior alignment look-"
E17-2056,P16-2046,1,0.906567,"Missing"
E17-2056,C16-2021,1,0.88815,"Missing"
E17-2056,W16-2379,1,0.894217,"Missing"
E17-2056,P02-1040,0,0.0983167,"Missing"
E17-2056,W12-3146,0,0.137315,"Missing"
E17-2056,N07-1064,0,0.44034,"ving raw MT output, before performing actual human post-editing (Knight and Chander, 1994). APE assumes the availability of source texts (src), corresponding MT output (mt) and the human postedited (pe) version of mt. However, APE systems can also be built without the availability of src, by using only sufficient amounts of target side “mono-lingual” parallel mt–pe data. Usually APE tasks focus on systematic errors made by first stage MT systems, acting as an effective remedy to some of the inaccuracies in raw MT output. APE approaches cover a wide methodological range such as SMT techniques (Simard et al., 2007a; Simard et al., 2007b; Chatterjee et al., 2015; Pal et al., 2015; Pal et al., 2016d) real time integration of post-editing in MT (Denkowski, 2015), rule-based approaches to APE (Mareˇcek et al., 2011; Rosa et al., 2012), neural APE (JunczysDowmunt and Grundkiewicz, 2016; Pal et al., 2016b), multi-engine and multi-alignment APE (Pal et al., 2016a), etc. We present a second-stage machine translation (MT) system based on a neural machine translation (NMT) approach to automatic post-editing (APE) that improves the translation quality provided by a firststage MT system. Our APE system (AP ESym )"
E17-2056,W07-0728,0,0.0707865,"ving raw MT output, before performing actual human post-editing (Knight and Chander, 1994). APE assumes the availability of source texts (src), corresponding MT output (mt) and the human postedited (pe) version of mt. However, APE systems can also be built without the availability of src, by using only sufficient amounts of target side “mono-lingual” parallel mt–pe data. Usually APE tasks focus on systematic errors made by first stage MT systems, acting as an effective remedy to some of the inaccuracies in raw MT output. APE approaches cover a wide methodological range such as SMT techniques (Simard et al., 2007a; Simard et al., 2007b; Chatterjee et al., 2015; Pal et al., 2015; Pal et al., 2016d) real time integration of post-editing in MT (Denkowski, 2015), rule-based approaches to APE (Mareˇcek et al., 2011; Rosa et al., 2012), neural APE (JunczysDowmunt and Grundkiewicz, 2016; Pal et al., 2016b), multi-engine and multi-alignment APE (Pal et al., 2016a), etc. We present a second-stage machine translation (MT) system based on a neural machine translation (NMT) approach to automatic post-editing (APE) that improves the translation quality provided by a firststage MT system. Our APE system (AP ESym )"
E17-2056,2006.amta-papers.25,0,0.0951164,"In this paper we present a neural network based APE system to improve raw first-stage MT output 349 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 349–355, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics grow-diag-final-and (GDFA) heuristic (Koehn, 2010), (ii) Berkeley word alignment (Liang et al., 2006), and (iii) SymGiza++ (Junczys-Dowmunt and Szał, 2012) word alignment, as well as two different edit distance based word aligners based on Translation Edit Rate (TER) (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). We follow the alignment strategy described in (Pal et al., 2013; Pal et al., 2016a). The aligned word pairs are added as additional training examples to train our symmetric neural APE model. Each word in the first stage MT output is assigned a unique id (swid ). Each mt–pe word alignment also gets a unique identification number (aid ) and a vector representation is generated for each such aid . Given a swid , the neural APE model is trained to generate a corresponding aid based on the context swid appears in. The APE words are generated from aid by lookin"
E17-2056,C96-2141,0,0.645894,"α are alignment sumj i αi,j (attention) matrices of Tx × Ty dimensions. The advantage of symmetrical alignment cells is that they are normalized using softmax (values in between 0 and 1), therefore, the trace term is bounded above by min(Tx , Ty ), representing perfect one-to-one alignments in both directions. To train each directional attention model (mt → pe and pe → mt), we follow the work described in Cohn et al. (2016), where absolute positional bias between the MT and PE translation (as in IBM Model 2), fertility relative position bias (as in IBM Models 3, 4, 5) and HMM-based Alignment (Vogel et al., 1996) are incorporated with an attention based soft alignment model. 3 Experiments and Results We carried out our experiments on the 12K English–German WMT 2016 APE task training 1 351 http://www.statmt.org/moses/ For setting up our neural network, previous to training the AP ESym model, we performed a number of preprocessing steps on the mt–pe parallel training data. First, we prepare a LUT containing mt–pe hybrid prior word alignment above (Section 2.1) a certain lexical translation probability threshold (0.3). To ensure efficient use of the hybrid prior alignment we replaced each mt word by a un"
L16-1095,2013.mtsummit-wptp.13,0,0.0502028,"of the translation workflow. In recent years, commercial computer-aided translation (CAT) tools have started to provide not only the popular translation memory (TM) matches but also MT segments to be post-edited by translators. The use of MT output for post-editing is regarded to increase translator’s productivity and also to improve consistency in translation (Federico et al., 2012; Zampieri and Vela, 2014). In light of this, a recent trend in the field is to develop tools that integrate both MT and TM output providing translators a larger number of more useful and more accurate suggestions (Cettolo et al., 2013). Contributing in this direction, this paper presents a new web-based CAT tool called CATaLog online1 developed based on CATaLog, a recently-released desktop CAT tool (Nayek et al., 2015). The tool can be used to post-edit MT output as well as TM segments. CATaLog online records a wide range of logs that are not available in any commercial CAT tool making it a useful tool for project management and translation process research. We have observed a substantial increase in the number of online CAT tools available, both for commercial and non-commercial purposes. This includes tools such as WordFa"
L16-1095,2012.amta-papers.22,0,0.0455595,"lation process and translator’s productivity. Keywords: post-editing, machine translation, translation memories 1. Introduction With the improvement of machine translation (MT) software, post-editing tools have become an important part of the translation workflow. In recent years, commercial computer-aided translation (CAT) tools have started to provide not only the popular translation memory (TM) matches but also MT segments to be post-edited by translators. The use of MT output for post-editing is regarded to increase translator’s productivity and also to improve consistency in translation (Federico et al., 2012; Zampieri and Vela, 2014). In light of this, a recent trend in the field is to develop tools that integrate both MT and TM output providing translators a larger number of more useful and more accurate suggestions (Cettolo et al., 2013). Contributing in this direction, this paper presents a new web-based CAT tool called CATaLog online1 developed based on CATaLog, a recently-released desktop CAT tool (Nayek et al., 2015). The tool can be used to post-edit MT output as well as TM segments. CATaLog online records a wide range of logs that are not available in any commercial CAT tool making it a u"
L16-1095,C14-2028,0,0.467888,"rection, this paper presents a new web-based CAT tool called CATaLog online1 developed based on CATaLog, a recently-released desktop CAT tool (Nayek et al., 2015). The tool can be used to post-edit MT output as well as TM segments. CATaLog online records a wide range of logs that are not available in any commercial CAT tool making it a useful tool for project management and translation process research. We have observed a substantial increase in the number of online CAT tools available, both for commercial and non-commercial purposes. This includes tools such as WordFast Anywhere2 , MateCat3 (Federico et al., 2014), Wordbee4 , and many others. In our opinion, this is a trend in the translation industry and it motivated us to release CATaLog online. Online CAT tools have a number of advantages over desktop tools, most notably: they do not require local installation; they can be used from any computer; projects can be easily shared with multiple translators; project managers can track the progress of projects on the fly. This paper presents CATaLog online and summarizes the 1 The tool is available online. For more information, consult the following URL: http://ttg.uni-saarland.de/software/catalog 2 https:"
L16-1095,2014.eamt-1.2,0,0.038703,"Missing"
L16-1095,W15-4905,1,0.897711,"Missing"
L16-1095,P10-1064,1,0.894586,"Missing"
L16-1095,2010.jec-1.3,0,0.0197391,"f translated segments contained in the TM; 2) the quality of the TM matching and retrieval engine. To improve the latter, developers have been working on incorporating semantic knowledge to TMs by providing paraphrasing (Utiyama et al., 2011; Gupta and Or˘asan, 2014; Gupta et al., 2015), as well as incorporating syntactic information (Clark, 2002; Gotti et al., 2005; Vanallemeersch and Vandeghinste, 2014). To increase the number of suggestions presented to translators, a recent trend in state-of-the-art CAT tools is the aforementioned integration of TM segments and MT output (He et al., 2010; Kanavos and Kartsaklis, 2010). With the improvement of state-of-the-art MT systems, MT output is no 599 longer considered to be suitable just for gisting purposes and it has been used in real-world translation projects as well. CAT tools such as MateCat present MT output along segments retrieved from TMs in the list of suitable suggestions (Cettolo et al., 2013; Federico et al., 2014). Substantial work has been carried out on improving translation recommendation systems which recommends posteditors either to use TM output or MT output (He et al., 2010). To optimize performance these systems use classifier trained to predi"
L16-1095,2010.jec-1.4,0,0.0200997,"t al., 2010). To optimize performance these systems use classifier trained to predict which output (TM or MT) requires less effort to be used for post-editing. Work on integrating MT with TM has also been done to make TM output more suitable for post-editing aiming to diminishing translators’ effort (Kanavos and Kartsaklis, 2010). Simard and Isabelle (2009) present the integration of Phrase-based Statistical MT (PB-SMT) with translation memories in a computer-aided translation environment in which the PB-SMT system exploits the most similar matches by making use of TM-based feature functions. Koehn and Senellart (2010) present another MT-TM integration strategy. In this study an Statistical MT (SMT) system is used to fill in the gaps in retrieved TM segments. 3. The Tool CATaLog online is a language independent tool that enables users to upload their own translation memories on the platform of the tool. It provides three major functionalities: • It provides a novel and user-friendly online CAT environment to post-editors and translators to reduce postediting time and effort, as displayed in Figure 1. • It collects post-editing logs which are a fundamental source of information for the translation process re"
L16-1095,P07-2045,0,0.00699121,"Missing"
L16-1095,J10-4005,0,0.0159378,"to upload the translations produced by third-party MT systems. A new feature in both CATaLog and CATaLog online is the ranking of matched TM segments based on their similarity given by Translation Error Rate (TER) (Snover et al., 2006). The system finds the matched and unmatched parts between the input segment and the five most similar TM segments from the TER alignment. It also finds out the correspondences between the source and target tokens in the matched TM segments and their corresponding translations using GIZA++ (Och and Ney, 2003) word alignments with grow-diag-final-and heuristics (Koehn, 2010). Matched parts and unmatched parts, both in the source and the target text, are colourcoded for better visualisation and displayed in green and red respectively. CATaLog online provides facilities to translate either single sentences or in batch mode i.e., by uploading a file. As shown in Figure 1, for a given input sentence (English in this case), the current version of CATaLog online provides two alternative translation suggestions in the target language (German in this case): MT and TM. The TM suggestion is colour-coded. When the translator selects the colour-coded TM alternative (c.f., Fi"
L16-1095,2008.amta-srw.4,0,0.0371658,"ion 2 presents related studies focusing on the integration between TM matches and MT output to improve CAT tools; Section 3 describes in detail the main functions of CATaLog online; Section 4 presents the language pairs and data that are currently included in CATaLog online; Section 5 discusses the main functions of CATaLog online and their importance for translators, researchers and project managements; finally, Section 6 concludes this paper and presents avenues for future research. 2. Related Work CAT tools are regarded to increase translator’s productivity and improve translation quality (Lagoudaki, 2008). The core component of most commercial CAT tools are translation memories. TMs work under the assumption that previously translated segments are likely to be good examples for new translations. This is particularly true when translating documents from the same domain which share a similar structure and/or vocabulary. Two important aspects should be considered when working with TMs: 1) the quality and number of translated segments contained in the TM; 2) the quality of the TM matching and retrieval engine. To improve the latter, developers have been working on incorporating semantic knowledge"
L16-1095,W15-5206,1,0.787357,"Missing"
L16-1095,J03-1002,0,0.0059723,"e background MT system (Pal et al., 2015a) integrated in the CAT tool or to upload the translations produced by third-party MT systems. A new feature in both CATaLog and CATaLog online is the ranking of matched TM segments based on their similarity given by Translation Error Rate (TER) (Snover et al., 2006). The system finds the matched and unmatched parts between the input segment and the five most similar TM segments from the TER alignment. It also finds out the correspondences between the source and target tokens in the matched TM segments and their corresponding translations using GIZA++ (Och and Ney, 2003) word alignments with grow-diag-final-and heuristics (Koehn, 2010). Matched parts and unmatched parts, both in the source and the target text, are colourcoded for better visualisation and displayed in green and red respectively. CATaLog online provides facilities to translate either single sentences or in batch mode i.e., by uploading a file. As shown in Figure 1, for a given input sentence (English in this case), the current version of CATaLog online provides two alternative translation suggestions in the target language (German in this case): MT and TM. The TM suggestion is colour-coded. Whe"
L16-1095,W15-3017,1,0.667715,"Missing"
L16-1095,W15-3026,1,0.840277,"Missing"
L16-1095,W15-4916,1,0.889319,"Missing"
L16-1095,2009.mtsummit-papers.14,0,0.0528677,"egments retrieved from TMs in the list of suitable suggestions (Cettolo et al., 2013; Federico et al., 2014). Substantial work has been carried out on improving translation recommendation systems which recommends posteditors either to use TM output or MT output (He et al., 2010). To optimize performance these systems use classifier trained to predict which output (TM or MT) requires less effort to be used for post-editing. Work on integrating MT with TM has also been done to make TM output more suitable for post-editing aiming to diminishing translators’ effort (Kanavos and Kartsaklis, 2010). Simard and Isabelle (2009) present the integration of Phrase-based Statistical MT (PB-SMT) with translation memories in a computer-aided translation environment in which the PB-SMT system exploits the most similar matches by making use of TM-based feature functions. Koehn and Senellart (2010) present another MT-TM integration strategy. In this study an Statistical MT (SMT) system is used to fill in the gaps in retrieved TM segments. 3. The Tool CATaLog online is a language independent tool that enables users to upload their own translation memories on the platform of the tool. It provides three major functionalities: •"
L16-1095,2006.amta-papers.25,0,0.0723154,"y to compare various translation engines taking human evaluation into account. A more detailed description of these functionalities is given in the following sections. 3.1. A Novel CAT Environment In CATaLog online, users can choose between MT output and TM segments. The tool allows the user to choose either the background MT system (Pal et al., 2015a) integrated in the CAT tool or to upload the translations produced by third-party MT systems. A new feature in both CATaLog and CATaLog online is the ranking of matched TM segments based on their similarity given by Translation Error Rate (TER) (Snover et al., 2006). The system finds the matched and unmatched parts between the input segment and the five most similar TM segments from the TER alignment. It also finds out the correspondences between the source and target tokens in the matched TM segments and their corresponding translations using GIZA++ (Och and Ney, 2003) word alignments with grow-diag-final-and heuristics (Koehn, 2010). Matched parts and unmatched parts, both in the source and the target text, are colourcoded for better visualisation and displayed in green and red respectively. CATaLog online provides facilities to translate either single"
L16-1095,W14-3323,1,0.897115,"Missing"
L16-1095,2011.mtsummit-papers.37,0,0.027697,"rcial CAT tools are translation memories. TMs work under the assumption that previously translated segments are likely to be good examples for new translations. This is particularly true when translating documents from the same domain which share a similar structure and/or vocabulary. Two important aspects should be considered when working with TMs: 1) the quality and number of translated segments contained in the TM; 2) the quality of the TM matching and retrieval engine. To improve the latter, developers have been working on incorporating semantic knowledge to TMs by providing paraphrasing (Utiyama et al., 2011; Gupta and Or˘asan, 2014; Gupta et al., 2015), as well as incorporating syntactic information (Clark, 2002; Gotti et al., 2005; Vanallemeersch and Vandeghinste, 2014). To increase the number of suggestions presented to translators, a recent trend in state-of-the-art CAT tools is the aforementioned integration of TM segments and MT output (He et al., 2010; Kanavos and Kartsaklis, 2010). With the improvement of state-of-the-art MT systems, MT output is no 599 longer considered to be suitable just for gisting purposes and it has been used in real-world translation projects as well. CAT tools suc"
L16-1095,2014.tc-1.11,0,0.0129636,"anslations. This is particularly true when translating documents from the same domain which share a similar structure and/or vocabulary. Two important aspects should be considered when working with TMs: 1) the quality and number of translated segments contained in the TM; 2) the quality of the TM matching and retrieval engine. To improve the latter, developers have been working on incorporating semantic knowledge to TMs by providing paraphrasing (Utiyama et al., 2011; Gupta and Or˘asan, 2014; Gupta et al., 2015), as well as incorporating syntactic information (Clark, 2002; Gotti et al., 2005; Vanallemeersch and Vandeghinste, 2014). To increase the number of suggestions presented to translators, a recent trend in state-of-the-art CAT tools is the aforementioned integration of TM segments and MT output (He et al., 2010; Kanavos and Kartsaklis, 2010). With the improvement of state-of-the-art MT systems, MT output is no 599 longer considered to be suitable just for gisting purposes and it has been used in real-world translation projects as well. CAT tools such as MateCat present MT output along segments retrieved from TMs in the list of suitable suggestions (Cettolo et al., 2013; Federico et al., 2014). Substantial work ha"
L16-1095,W14-0314,1,0.846882,"slator’s productivity. Keywords: post-editing, machine translation, translation memories 1. Introduction With the improvement of machine translation (MT) software, post-editing tools have become an important part of the translation workflow. In recent years, commercial computer-aided translation (CAT) tools have started to provide not only the popular translation memory (TM) matches but also MT segments to be post-edited by translators. The use of MT output for post-editing is regarded to increase translator’s productivity and also to improve consistency in translation (Federico et al., 2012; Zampieri and Vela, 2014). In light of this, a recent trend in the field is to develop tools that integrate both MT and TM output providing translators a larger number of more useful and more accurate suggestions (Cettolo et al., 2013). Contributing in this direction, this paper presents a new web-based CAT tool called CATaLog online1 developed based on CATaLog, a recently-released desktop CAT tool (Nayek et al., 2015). The tool can be used to post-edit MT output as well as TM segments. CATaLog online records a wide range of logs that are not available in any commercial CAT tool making it a useful tool for project man"
L16-1095,2015.eamt-1.17,1,\N,Missing
L16-1095,2015.eamt-1.6,1,\N,Missing
P16-2046,W11-2107,0,0.0154085,"nt between the translators by computing Cohen’s κ coefficient (Cohen, 1960) reported in Table 2. The overall κ coefficient is 0.330. According to (Landis and Koch, 1977) this correlation coefficient can be interpreted as fair. Evaluation The performance of the NNAPE system was evaluated using both automatic and human evaluation methods, as described below. 5.1 BLEU 61.26 62.54a 63.87a,b 65.22a,b,c Automatic Evaluation The output of the NNAPE system on the 1000 sentences testset was evaluated using three MT evaluation metrics: BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and Meteor (Denkowski and Lavie, 2011). Table 1 provides a comparison of our neural system performance against the baseline phrase-based APE (S1 ), baseline hierarchical phrase-based APE (S2 ) and the original GT output. We use a, b, c, and d to indicate statistical significance over GT, S1 , S2 and our NNAPE system (NN), respectively. For example, the S2 BLEU score 63.87a,b in Table 1 means that the improvement provided by S2 in BLEU is statistically significant over Google Translator and phrase-based 284 Cohen’s κ T1 T2 T3 T4 T1 0.141 0.424 0.398 T2 0.141 0.232 0.540 T3 0.424 0.232 0.248 T4 0.398 0.540 0.248 - Union’s Framework"
P16-2046,W15-3026,1,0.893196,"Missing"
P16-2046,W11-2123,0,0.0755541,"Missing"
P16-2046,P02-1040,0,0.109086,"ncertain’ option. We measured pairwise inter-annotator agreement between the translators by computing Cohen’s κ coefficient (Cohen, 1960) reported in Table 2. The overall κ coefficient is 0.330. According to (Landis and Koch, 1977) this correlation coefficient can be interpreted as fair. Evaluation The performance of the NNAPE system was evaluated using both automatic and human evaluation methods, as described below. 5.1 BLEU 61.26 62.54a 63.87a,b 65.22a,b,c Automatic Evaluation The output of the NNAPE system on the 1000 sentences testset was evaluated using three MT evaluation metrics: BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and Meteor (Denkowski and Lavie, 2011). Table 1 provides a comparison of our neural system performance against the baseline phrase-based APE (S1 ), baseline hierarchical phrase-based APE (S2 ) and the original GT output. We use a, b, c, and d to indicate statistical significance over GT, S1 , S2 and our NNAPE system (NN), respectively. For example, the S2 BLEU score 63.87a,b in Table 1 means that the improvement provided by S2 in BLEU is statistically significant over Google Translator and phrase-based 284 Cohen’s κ T1 T2 T3 T4 T1 0.141 0.424 0.398 T2 0.141 0.232 0."
P16-2046,W12-3146,0,0.306803,"Missing"
P16-2046,D13-1176,0,0.320157,"be modelled as an MT system between SLIP T LM T and T LP E . However, if we do not have access to SLIP , but have sufficiently large amounts of parallel T LM T T LP E data, we can still build an APE model between T LM T and T LP E . Translations provided by state-of-the-art MT systems suffer from a number of errors including incorrect lexical choice, word ordering, word insertion, word deletion, etc. The APE work presented in this paper is an effort to improve the MT output by rectifying some of these errors. For this purpose we use a deep neural network (DNN) based approach. Neural MT (NMT) (Kalchbrenner and Blunsom, 2013; Cho et al., 2014a; Cho et al., 2014b) is a newly emerging approach to MT. On the one hand DNNs represent language in a continuous vector space which eases the modelling of semantic similarities (or distance) between phrases or sentences, and on the other hand it can also consider contextual information, e.g., We present a neural network based automatic post-editing (APE) system to improve raw machine translation (MT) output. Our neural model of APE (NNAPE) is based on a bidirectional recurrent neural network (RNN) model and consists of an encoder that encodes an MT output into a fixed-length"
P16-2046,N07-1064,0,0.752153,"On the other hand, given sufficient amounts of training data, LSTMs may lead to better results. Since our task is monolingual and we have more than 200K sentence pairs for training, we use a full LSTM (as the hidden units) to model our NNAPE system. The model takes T LM T as input and provides T LP E as output. To the best of our knowledge the work presented in this paper is the first approach to APE using neural networks. utilizing all available history information in deciding the next target word, which is not an easy task to model with standard APE systems. Unlike phrase-based APE systems (Simard et al., 2007a; Simard et al., 2007b; Pal, 2015; Pal et al., 2015), our NNAPE system builds and trains a single, large neural network that accepts a ‘draft’ translation (T LM T ) and outputs an improved translation (T LP E ). The remainder of the paper is organized as follows. Section 2 gives an overview of relevant related work. The proposed NNAPE system is described in detail in Section 3. We present the experimental setup in Section 4. Section 5 presents the results of automatic and human evaluation together with some analysis. Section 6 concludes the paper and provides avenues for future work. 2 Relate"
P16-2046,W07-0728,0,0.384103,"On the other hand, given sufficient amounts of training data, LSTMs may lead to better results. Since our task is monolingual and we have more than 200K sentence pairs for training, we use a full LSTM (as the hidden units) to model our NNAPE system. The model takes T LM T as input and provides T LP E as output. To the best of our knowledge the work presented in this paper is the first approach to APE using neural networks. utilizing all available history information in deciding the next target word, which is not an easy task to model with standard APE systems. Unlike phrase-based APE systems (Simard et al., 2007a; Simard et al., 2007b; Pal, 2015; Pal et al., 2015), our NNAPE system builds and trains a single, large neural network that accepts a ‘draft’ translation (T LM T ) and outputs an improved translation (T LP E ). The remainder of the paper is organized as follows. Section 2 gives an overview of relevant related work. The proposed NNAPE system is described in detail in Section 3. We present the experimental setup in Section 4. Section 5 presents the results of automatic and human evaluation together with some analysis. Section 6 concludes the paper and provides avenues for future work. 2 Relate"
P16-2046,2006.amta-papers.25,0,0.127359,"pairwise inter-annotator agreement between the translators by computing Cohen’s κ coefficient (Cohen, 1960) reported in Table 2. The overall κ coefficient is 0.330. According to (Landis and Koch, 1977) this correlation coefficient can be interpreted as fair. Evaluation The performance of the NNAPE system was evaluated using both automatic and human evaluation methods, as described below. 5.1 BLEU 61.26 62.54a 63.87a,b 65.22a,b,c Automatic Evaluation The output of the NNAPE system on the 1000 sentences testset was evaluated using three MT evaluation metrics: BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and Meteor (Denkowski and Lavie, 2011). Table 1 provides a comparison of our neural system performance against the baseline phrase-based APE (S1 ), baseline hierarchical phrase-based APE (S2 ) and the original GT output. We use a, b, c, and d to indicate statistical significance over GT, S1 , S2 and our NNAPE system (NN), respectively. For example, the S2 BLEU score 63.87a,b in Table 1 means that the improvement provided by S2 in BLEU is statistically significant over Google Translator and phrase-based 284 Cohen’s κ T1 T2 T3 T4 T1 0.141 0.424 0.398 T2 0.141 0.232 0.540 T3 0.424 0.232 0.248 T4"
P16-2046,N09-2055,0,0.646587,"Missing"
P16-2046,W14-0314,1,0.854431,"ms. Lagarda et al. (2009) used statistical information from the trained SMT models for post-editing of rule-based MT output. Rosa et al. (2012) and Mareˇcek et al. (2011) applied a rule-based approach to APE on the morphological level. Denkowski (2015) developed a method for real time integration of post-edited MT output into the translation model by extracting a grammar for each input sentence. Recent studies have even shown that the quality of MT plus PE can exceed the quality of human translation (Fiederer and OBrien, 2009; Koehn, 2009; DePalma and Kelly, 2009) as well as the productivity (Zampieri and Vela, 2014) in some cases. Recently, a number of papers have presented the application of neural networks in MT (Kalchbrenner and Blunsom, 2013; ?; Cho et al., 2014b; Bahdanau et al., 2014). These approaches typically consist of two components: an encoder encodes a source sentence and a decoder decodes into a target sentence. In this paper we present a neural network based approach to automatic PE (NNAPE). Our NNAPE model is inspired by the MT work of Bahdanau et al. (2014) which is based on bidirectional recurrent neural networks (RNN). Unlike Bah3 Neural Network based APE The NNAPE system is based on a"
P16-2046,P03-1021,0,0.320083,"Missing"
P16-2046,P07-2045,0,\N,Missing
pal-etal-2014-word,popovic-ney-2006-pos,0,\N,Missing
pal-etal-2014-word,W11-2127,0,\N,Missing
pal-etal-2014-word,holmqvist-etal-2012-alignment,0,\N,Missing
pal-etal-2014-word,J93-2003,0,\N,Missing
pal-etal-2014-word,D08-1089,0,\N,Missing
pal-etal-2014-word,P02-1040,0,\N,Missing
pal-etal-2014-word,W09-0435,0,\N,Missing
pal-etal-2014-word,N09-1028,0,\N,Missing
pal-etal-2014-word,W10-1735,0,\N,Missing
pal-etal-2014-word,W05-0909,0,\N,Missing
pal-etal-2014-word,P07-2045,0,\N,Missing
pal-etal-2014-word,P10-2033,0,\N,Missing
pal-etal-2014-word,W12-4207,0,\N,Missing
pal-etal-2014-word,C10-1043,0,\N,Missing
pal-etal-2014-word,E09-1011,0,\N,Missing
pal-etal-2014-word,N03-1017,0,\N,Missing
pal-etal-2014-word,J03-1002,0,\N,Missing
pal-etal-2014-word,P05-1066,0,\N,Missing
pal-etal-2014-word,N10-3010,0,\N,Missing
pal-etal-2014-word,2007.mtsummit-papers.28,0,\N,Missing
pal-etal-2014-word,2005.iwslt-1.8,0,\N,Missing
pal-etal-2014-word,P03-1021,0,\N,Missing
S10-1045,de-marneffe-etal-2006-generating,0,0.0564326,"Missing"
S10-1045,W09-2415,0,\N,Missing
W10-3706,W09-2906,0,0.745863,"Missing"
W10-3706,W06-1205,0,\N,Missing
W10-3706,C08-2007,0,\N,Missing
W10-3707,C04-1114,0,0.441408,"ither. We address this many-to-many alignment problem indirectly. Our objective is to see how to best handle the MWEs in SMT. In this work, two types of MWEs, namely NEs and compound verbs, are automatically identified on both sides of the parallel corpus. Then, source and target language NEs are aligned using a statistical transliteration method. We rely on these automatically aligned NEs and treat them as translation examples. Adding bilingual dictionaries, which in effect are instances of atomic translation pairs, to the parallel corpus is a well-known practice in domain adaptation in SMT (Eck et al., 2004; Wu et al., 2008). We modify the parallel corpus by converting the MWEs into single tokens and adding the aligned NEs in the parallel corpus in a bid to improve the word alignment, and hence the phrase alignment quality. This 46 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 46–54, Beijing, August 2010 preprocessing results in improved MT quality in terms of automatic MT evaluation metrics. The remainder of the paper is organized as follows. In section 2 we discuss related work. The System is described in Section 3. Section 4 includes the results obtai"
W10-3707,W09-3539,1,0.741895,"Missing"
W10-3707,W05-0909,0,0.209211,"Missing"
W10-3707,W04-3248,0,0.280025,"Missing"
W10-3707,J93-2003,0,0.0150925,"ed MWEs can bring about any further improvement on top of that. We carried out our experiments on an English—Bangla translation task, a relatively hard task with Bangla being a morphologically richer language. 3 System Description 3.1 PB-SMT Translation is modeled in SMT as a decision process, in which the translation e1I = e1 . . . ei . . . eI of a source sentence f1J = f1 . . . fj . . . fJ is chosen to maximize (1): (1) arg max P(e1I |f1J ) = arg max P( f1J |e1I ).P(e1I ) I ,e1I I ,e1I where P ( f1J |e1I ) and P (e1I ) denote respectively the translation model and the target language model (Brown et al., 1993). In log-linear phrase-based SMT, the posterior probability P( e1I |f1J ) is directly modeled as a log-linear combination of features (Och and Ney, 2002), that usually comprise M translational features, and the language model, as in (2): M log P(e1I |f 1J ) = ∑ λ m hm ( f 1J , e1I , s1K ) m =1 + λLM log P(e1I ) (2) where s = s1...sk denotes a segmentation of the source and target sentences respectively into the sequences of phrases (eˆ1 ,..., eˆk ) and ( fˆ1 ,..., fˆk ) such that (we set i0 = 0) (3): k 1 ∀1 ≤ k ≤ K , sk = (ik, bk, jk), eˆk = eik −1 +1...eik , fˆ = f ... f . k bk jk (3) and eac"
W10-3707,W03-1502,0,0.128214,"r simultaneous NE identification and translation. He uses capitalization cues for identifying NEs on the English side, and then he applies statistical techniques to decide which portion of the target language corresponds to the specified English NE. Feng et al. (2004) proposed a Maximum Entropy model based approach for English— Chinese NE alignment which significantly outperforms IBM Model4 and HMM. They considered 4 features: translation score, transliteration score, source NE and target NE's co-occurrence score, and the distortion score for distinguishing identical NEs in the same sentence. Huang et al. (2003) proposed a method for automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization. The costs considered are transliteration cost, word-based translation cost, and NE tagging cost. Venkatapathy and Joshi (2006) reported a discriminative approach of using the compositionality information about verb-based multi-word expressions to improve word alignment quality. (Ren et al., 2009) presented log likelihood ratiobased hierarchical reducing algorithm to automatically extract bilingual MWEs, and investigated the usefulness of these bilin"
W10-3707,N10-1029,0,0.108076,"reported a discriminative approach of using the compositionality information about verb-based multi-word expressions to improve word alignment quality. (Ren et al., 2009) presented log likelihood ratiobased hierarchical reducing algorithm to automatically extract bilingual MWEs, and investigated the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into Moses (Koehn et al., 2007) in three ways. They observed the highest improvement when they used an additional feature to represent whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010). In their work, the binary feature was replaced by a count feature representing the number of MWEs in the source language phrase. Intuitively, MWEs should be both aligned in the parallel corpus and translated as a whole. However, in the state-of-the-art PB-SMT, it could well be the case that constituents of an 47 MWE are marked and aligned as parts of consecutive phrases, since PB-SMT (or any other approaches to SMT) does not generally treat MWEs as special tokens. Another problem SMT suffers from is that verb phrases are often wrongly translated, or even sometimes deleted in the output in or"
W10-3707,C08-2007,0,0.104429,"Missing"
W10-3707,P07-2045,0,0.0291762,"gual equivalences between Chinese and English based on multi-feature cost minimization. The costs considered are transliteration cost, word-based translation cost, and NE tagging cost. Venkatapathy and Joshi (2006) reported a discriminative approach of using the compositionality information about verb-based multi-word expressions to improve word alignment quality. (Ren et al., 2009) presented log likelihood ratiobased hierarchical reducing algorithm to automatically extract bilingual MWEs, and investigated the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into Moses (Koehn et al., 2007) in three ways. They observed the highest improvement when they used an additional feature to represent whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010). In their work, the binary feature was replaced by a count feature representing the number of MWEs in the source language phrase. Intuitively, MWEs should be both aligned in the parallel corpus and translated as a whole. However, in the state-of-the-art PB-SMT, it could well be the case that constituents of an 47 MWE are marked and aligned as parts of consecutive phrases, since"
W10-3707,2006.amta-papers.25,0,0.0728121,"Missing"
W10-3707,C96-2141,0,0.388305,"(or spaces)” (Sag et al., 2002). Traditional approaches to word alignment following IBM Models (Brown et al., 1993) do not work well with multi-word expressions, especially with NEs, due to their inability to handle manyto-many alignments. Firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword NEs. Secondly, the IBM Models only allow at most one word in the source language to correspond to a word in the target language (Marcu, 2001, Koehn et al., 2003). In another well-known word alignment approach, Hidden Markov Model (HMM: Vogel et al., 1996), the alignment probabilities depend on the alignment position of the previous word. It does not explicitly consider many-to-many alignment either. We address this many-to-many alignment problem indirectly. Our objective is to see how to best handle the MWEs in SMT. In this work, two types of MWEs, namely NEs and compound verbs, are automatically identified on both sides of the parallel corpus. Then, source and target language NEs are aligned using a statistical transliteration method. We rely on these automatically aligned NEs and treat them as translation examples. Adding bilingual dictionar"
W10-3707,W04-3250,0,0.31373,"Missing"
W10-3707,W06-1204,0,0.435823,"Missing"
W10-3707,P01-1050,0,0.00961498,"pus. Multi-word expressions (MWE) are defined as “idiosyncratic interpretations that cross word boundaries (or spaces)” (Sag et al., 2002). Traditional approaches to word alignment following IBM Models (Brown et al., 1993) do not work well with multi-word expressions, especially with NEs, due to their inability to handle manyto-many alignments. Firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword NEs. Secondly, the IBM Models only allow at most one word in the source language to correspond to a word in the target language (Marcu, 2001, Koehn et al., 2003). In another well-known word alignment approach, Hidden Markov Model (HMM: Vogel et al., 1996), the alignment probabilities depend on the alignment position of the previous word. It does not explicitly consider many-to-many alignment either. We address this many-to-many alignment problem indirectly. Our objective is to see how to best handle the MWEs in SMT. In this work, two types of MWEs, namely NEs and compound verbs, are automatically identified on both sides of the parallel corpus. Then, source and target language NEs are aligned using a statistical transliteration me"
W10-3707,C08-1125,0,0.154066,"Missing"
W10-3707,E03-1035,0,0.114084,"igned NEs in the parallel corpus in a bid to improve the word alignment, and hence the phrase alignment quality. This 46 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 46–54, Beijing, August 2010 preprocessing results in improved MT quality in terms of automatic MT evaluation metrics. The remainder of the paper is organized as follows. In section 2 we discuss related work. The System is described in Section 3. Section 4 includes the results obtained, together with some analysis. Section 5 concludes, and provides avenues for further work. 2 Related Work Moore (2003) presented an approach for simultaneous NE identification and translation. He uses capitalization cues for identifying NEs on the English side, and then he applies statistical techniques to decide which portion of the target language corresponds to the specified English NE. Feng et al. (2004) proposed a Maximum Entropy model based approach for English— Chinese NE alignment which significantly outperforms IBM Model4 and HMM. They considered 4 features: translation score, transliteration score, source NE and target NE's co-occurrence score, and the distortion score for distinguishing identical N"
W10-3707,P03-1021,0,0.0160755,"guages to Indian Languages Machine Translation (ILILMT) System”. NEs in Bangla are identified using the NER system of Ekbal and Bandyopadhyay (2008). We use the Stanford Parser, Stanford NER and the NER for Bangla along with the default model files provided, i.e., with no additional training. The effectiveness of the MWE-aligned parallel corpus developed in the work is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phraseextraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model with Kneser-Ney smoothing (Kneser and 1 The EILMT and ILILMT projects are funded by the Department of Information Technology (DIT), Ministry of Communications and Information Technology (MCIT), Government of India. 2 http://nlp.stanford.edu/software/lex-parser.shtml 3 4 Ney, 1995) trained with SRILM (Stolcke, 2002), and Moses decoder (Koehn et al., 2007). http://crfchunker.sourceforge.net/ http://nlp.stanford.edu/software/CRF-NER.shtml 50 Experiments and Results We randomly extracted 500 sentences each for the development set and testset fr"
W10-3707,P02-1040,0,0.0819899,"Missing"
W10-3707,W09-2907,0,0.376728,"re, transliteration score, source NE and target NE's co-occurrence score, and the distortion score for distinguishing identical NEs in the same sentence. Huang et al. (2003) proposed a method for automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization. The costs considered are transliteration cost, word-based translation cost, and NE tagging cost. Venkatapathy and Joshi (2006) reported a discriminative approach of using the compositionality information about verb-based multi-word expressions to improve word alignment quality. (Ren et al., 2009) presented log likelihood ratiobased hierarchical reducing algorithm to automatically extract bilingual MWEs, and investigated the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into Moses (Koehn et al., 2007) in three ways. They observed the highest improvement when they used an additional feature to represent whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010). In their work, the binary feature was replaced by a count feature representing the number of MWEs in the source language phrase. Intuitively, MWE"
W10-3707,N03-1017,0,\N,Missing
W11-1307,P05-1068,0,0.0245996,"Missing"
W11-1307,W06-1201,0,0.0170536,"Statistical Methodologies Tanmoy Chakraborty, Santanu Pal, Tapabrata Mondal, Tanik Saikh, Sivaji Bandyopadhyay Department of Computer Science and Engineering Jadavpur University its_tanmoy@yahoo.co.in, santanu.pal.ju@gmail.com, tapabratamondal@gmail.com, tanik4u@gmail.com, sivaji_cse_ju@yahoo.com machine translation where the highly noncompositional collocations can be handled in a special way (Hwang and Sasaki, 2005). Multi-word expressions (MWEs) are sequences of words that tend to co-occur more frequently than chance and are either idiosyncratic or decomposable into multiple simple words (Baldwin, 2006). Deciding idiomaticity of MWEs is highly important for machine translation, information retrieval, question answering, lexical acquisition, parsing and language generation. Compositionality refers to the degree to which the meaning of a MWE can be predicted by combining the meanings of its components. Unlike syntactic compositionality (e.g. by and large), semantic compositionality is continuous (Baldwin, 2006). Several studies have been carried out for detecting compositionality of noun-noun MWEs using WordNet hypothesis (Baldwin et al., 2003), verb-particle constructions using statistical si"
W11-1307,W03-1809,0,0.26114,"diomaticity of MWEs is highly important for machine translation, information retrieval, question answering, lexical acquisition, parsing and language generation. Compositionality refers to the degree to which the meaning of a MWE can be predicted by combining the meanings of its components. Unlike syntactic compositionality (e.g. by and large), semantic compositionality is continuous (Baldwin, 2006). Several studies have been carried out for detecting compositionality of noun-noun MWEs using WordNet hypothesis (Baldwin et al., 2003), verb-particle constructions using statistical similarities (Bannard et al., 2003; McCarthy et al., 2003) and verb-noun pairs using Latent Semantic Analysis (Katz and Giesbrecht, 2006). Our contributions are two-fold: firstly, we experimentally show that collocation based statistical compositionality measurement can assist in identifying the continuum of compositionality of MWEs. Secondly, we show that supervised weighted parameter tuning results in accuracy that is comparable to the best manually selected combination of parameters. Abstract The measurement of relative compositionality of bigrams is crucial to identify Multi-word Expressions (MWEs) in Natural Language Proc"
W11-1307,W06-1203,0,0.130459,"answering, lexical acquisition, parsing and language generation. Compositionality refers to the degree to which the meaning of a MWE can be predicted by combining the meanings of its components. Unlike syntactic compositionality (e.g. by and large), semantic compositionality is continuous (Baldwin, 2006). Several studies have been carried out for detecting compositionality of noun-noun MWEs using WordNet hypothesis (Baldwin et al., 2003), verb-particle constructions using statistical similarities (Bannard et al., 2003; McCarthy et al., 2003) and verb-noun pairs using Latent Semantic Analysis (Katz and Giesbrecht, 2006). Our contributions are two-fold: firstly, we experimentally show that collocation based statistical compositionality measurement can assist in identifying the continuum of compositionality of MWEs. Secondly, we show that supervised weighted parameter tuning results in accuracy that is comparable to the best manually selected combination of parameters. Abstract The measurement of relative compositionality of bigrams is crucial to identify Multi-word Expressions (MWEs) in Natural Language Processing (NLP) tasks. The article presents the experiments carried out as part of the participation in th"
W11-1307,J90-1003,0,0.461841,"4  0123  … … … … . 3 The present task was to identify the numerical judgment of compositionality of individual phrase. The statistical co-occurrence features used in this experiment are described. Frequency: If two words occur together quite frequently, the lexical meaning of the composition may be different from the combination of their individual meanings. The frequency of an individual phrase is directly used in the following methods. Point-wise Information (PMI): An information-theoretic motivated measure for discovering interesting collocations is point-wise mutual information (Church and Hanks, 1990). It is originally defined as the mutual information between particular events X and Y and in our case the occurrence of particular words, as follows:   = log , . where H(X) is the cross-entropy of X. Here, X is the candidate bigram whose value is measured throughout the corpus. Perplexity is interpreted as the average “branching factor” of a word: the statistically weighted number of words that follow a given word. As we see from equation (4), Perplexity is equivalent to entropy. The only advantage of perplexity is that it results in numbers more comprehensible for human b"
W11-1307,W03-1812,0,\N,Missing
W11-2839,T75-2001,0,0.665317,"ropean language family, widely spoken on six continents. HOO shared task is organized to help authors with the writing tasks. Identifying grammatical and linguistic errors in a text of a language is an open challenge to the researchers. In recent times, researchers (Heidorn, 2000) have acquired quite a benchmark for spell checker and grammar checkers, which is commonly available. In this task it is aimed to correct errors beyond the scope of these commonly available checkers i.e. detection and correction of jarring errors at part-of-speech (POS) level, syntax level and semantic level. Earlier Heidorn, 1975) developed augmented phrase structure grammar. Tetreault et. 250 Proceedings of the 13th European Workshop on Natural Language Generation (ENLG), pages 250–253, c Nancy, France, September 2011. 2011 Association for Computational Linguistics al., 2008, has dealt with error pattern with preposition by non-native speakers. 3 System Description At the beginning of the work, we found that generation of list of rules to detect and correct the probable linguistic errors is a non-exhaustive set. So we have decided to list out the errors from the training corpus documents. We have listed the errors doc"
W11-2839,W10-4236,0,0.221341,"Missing"
W11-2839,C08-1109,0,0.156742,"Missing"
W12-0113,W10-3710,1,0.889358,"Missing"
W12-0113,Y04-1013,0,0.0812868,"Missing"
W12-0113,N03-1017,0,0.0314252,"Missing"
W12-0113,E03-1035,0,0.0882408,"Missing"
W12-0113,W03-1803,0,0.0914701,"Missing"
W12-0113,C04-1114,0,\N,Missing
W12-0113,P02-1040,0,\N,Missing
W12-0113,W05-0909,0,\N,Missing
W12-0113,P07-2045,0,\N,Missing
W12-0113,W09-3539,1,\N,Missing
W12-0113,W09-2907,0,\N,Missing
W12-0113,C08-1125,0,\N,Missing
W12-0113,N10-1029,0,\N,Missing
W12-0113,W04-3250,0,\N,Missing
W12-0113,P03-1021,0,\N,Missing
W12-2023,W11-2844,0,0.0398385,"Missing"
W12-2023,C10-2031,0,0.0205571,"benchmark for spell checker and grammar checkers, which is commonly available. In this task it is aimed to correct errors beyond the scope of these commonly available checkers i.e. detection and correction of jarring errors at part-ofspeech (POS) level, syntax level and semantic level. Earlier Heidorn (1975) developed augmented phrase structure grammar. (Tetreault et. al., 2008) has dealt with error pattern with preposition by non-native speakers. Meurers and Wunsch (2010) showed a surface based state-of-the-art machine learning technique, which deals with some frequently used prepositions. (Elghafari et al., 2010) worked on Data-Driven Prediction of Prepositions in English. Boyd et al. (2011) used an n-gram based machine-learning approach. Last year we have also participated in this shared task; our system report was reported in (Bhaskar et. al., 2011). 3 Corpus Statistics There are two sets of data, training set and test set provided by the organizer. The training set has 1000 documents, which are collected from the FCE dataset. The publicly available dataset was in the native FCE format. So, the organizer first converted it to the HOO data format. Then CUP annotators found the errors and marked them"
W12-2023,T75-2001,0,0.610787,", c Montr´eal, Canada, June 3-8, 2012. 2012 Association for Computational Linguistics shared task is organized to help authors with writing tasks. Identifying grammatical and linguistic errors in text is an open challenge to researchers. In recent times, researchers (Heidorn, 2000) have provided quite a benchmark for spell checker and grammar checkers, which is commonly available. In this task it is aimed to correct errors beyond the scope of these commonly available checkers i.e. detection and correction of jarring errors at part-ofspeech (POS) level, syntax level and semantic level. Earlier Heidorn (1975) developed augmented phrase structure grammar. (Tetreault et. al., 2008) has dealt with error pattern with preposition by non-native speakers. Meurers and Wunsch (2010) showed a surface based state-of-the-art machine learning technique, which deals with some frequently used prepositions. (Elghafari et al., 2010) worked on Data-Driven Prediction of Prepositions in English. Boyd et al. (2011) used an n-gram based machine-learning approach. Last year we have also participated in this shared task; our system report was reported in (Bhaskar et. al., 2011). 3 Corpus Statistics There are two sets of"
W12-2023,C08-1109,0,0.063479,"Missing"
W12-2023,W11-2839,1,0.834918,"Missing"
W12-2023,W10-4236,0,0.0126575,"writing, which makes the papers harder for the reviewer to understand the intentions of author. This kind of problem will be faced in any field where someone has to provide material in a language other than his/her first language. The mentoring service of Association for Computational Linguistics (ACL) is one part of a response. This service can address a wider range of problems than those related purely to writing. The aim of this service is that a research paper should be judged only on its research content. The organizer of “Help Our Own” (HOO) proposed and initiated a shared task in 2011 (Dale and Kilgarriff, 2010), which attempts to tackle the problem by developing tools or techniques for the non-native speaker of English, which will automatically correct the English prose of the papers so that they can be accepted. This tools and techniques may also help native English speakers. This task is simply expressed as text-to-text generation or Natural language Generation (NLG). In the 2011 shared task, all possible errors were covered which made the task enormously huge. In 2012, the task is more specific and only deals with determiners and prepositions as described in (Dale and Kilgarriff, 2011). For this"
W12-2023,W11-2838,0,0.0133864,"k in 2011 (Dale and Kilgarriff, 2010), which attempts to tackle the problem by developing tools or techniques for the non-native speaker of English, which will automatically correct the English prose of the papers so that they can be accepted. This tools and techniques may also help native English speakers. This task is simply expressed as text-to-text generation or Natural language Generation (NLG). In the 2011 shared task, all possible errors were covered which made the task enormously huge. In 2012, the task is more specific and only deals with determiners and prepositions as described in (Dale and Kilgarriff, 2011). For this shared task, HOO, we have developed two models, one is rule-based model and the other is the statistical model for both determiners and prepositions. Then we have combined both these models and developed our system for HOO 2012. 2 Related Work The English language belongs to the Germanic languages branch of the Indo-European language family, widely spoken on six continents. The HOO 201 The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 201–207, c Montr´eal, Canada, June 3-8, 2012. 2012 Association for Computational Linguistics shared task is o"
W12-2023,dale-narroway-2012-framework,0,0.0113787,"em elevates the accuracy. 5 6 Evaluation The system was evaluated for its performance in detecting, recognizing and correcting preposition and determiner errors in English documents. Separate scores were calculated for detection, recognition and correction for both the errors of preposition and determiner separately and then combined scores were also calculated. For all results, the organizer has provided three measures: Precision, Recall and F-Score. The precise definitions of these measures as implemented in the evaluation tool, and further details on the evaluation process are provided in (Dale and Narroway, 2012) and elaborated on at the HOO website.4 Each team was allowed to submit up to 10 separate runs over the test data, thus allowing them to have different configurations of their systems evalElement Preposition Determiner Combined uated. Teams were asked to indicate whether they had used only publicly available data to train their systems, or whether they had made use of privately held data. We have submitted only one run (JU_run1) which has demonstrated F-scores of 7.1, 6.46 and 2.58 for detection, recognition and correction respectively before revision. And after revision it has demonstrated F-"
W12-2023,W12-2006,0,0.027615,"Missing"
W13-2509,P07-2045,0,0.0161102,"ing such corpus is that it can be prepared easily unlike the one that is domain specific. The effectiveness of the parallel fragments of text developed from the comparable corpora in the present work is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phrase extraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model with Kneser-Ney smoothing (Kneser and Ney, 1995) trained with SRILM (Stolcke, 2002), and Moses decoder (Koehn et al., 2007). Related Work There has been a growing interest in approaches focused on extracting word translations from comparable corpora (Fung and McKeown, 1997; Fung and Yee, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002; Dejean et al., 2002; Kaji, 2005; Gamallo, 2007; Saralegui et al., 2008). Most of the strategies follow a standard method based on context similarity. The idea behind this method is as follows: A target word t is the translation of a source word s if the words with which t co-occurs are translations of words with which s co-occurs. The basis of the method is to find the target words th"
W13-2509,N03-1017,0,0.00632178,"the other details are discarded. It is evident that the corpus is not confined to any particular domain. The challenge is to exploit this kind of corpus to help machine translation systems improve. The advantage of using such corpus is that it can be prepared easily unlike the one that is domain specific. The effectiveness of the parallel fragments of text developed from the comparable corpora in the present work is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phrase extraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model with Kneser-Ney smoothing (Kneser and Ney, 1995) trained with SRILM (Stolcke, 2002), and Moses decoder (Koehn et al., 2007). Related Work There has been a growing interest in approaches focused on extracting word translations from comparable corpora (Fung and McKeown, 1997; Fung and Yee, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002; Dejean et al., 2002; Kaji, 2005; Gamallo, 2007; Saralegui et al., 2008). Most of the strategies follow a standard method based on context similarity. The idea behind thi"
W13-2509,P06-1011,0,0.288737,"tion of each other. And as a result, parallel fragments of text are rarely found in these document pairs. The bigger the size of the fragment the less probable it is to find its parallel version in the target side. Nevertheless, there is always chance of getting parallel phrase, tokens or even sentences in comparable documents. The challenge is to find those parallel texts which can be useful in increasing machine translation performance. In our present work, we have concentrated on finding small fragments of parallel text instead of rigidly looking for parallelism at entire sentential level. Munteanu and Marcu (2006) believed that comparable corpora tend to have parallel data at sub-sentential level. This approach is particularly useful for this type of corpus under consideration, because there is a very little chance of getting exact translation of bigger fragments of text in the target side. Instead, searching for parallel chunks would be more logical. If a sentence in the source side has a parallel sentence in the target side, then all of its chunks need to have their parallel translations in the target side as well. It is to be noted that, although we have document level alignment in our corpus, it is"
W13-2509,C02-2020,0,0.680158,"Missing"
W13-2509,P03-1021,0,0.023157,"at the corpus is not confined to any particular domain. The challenge is to exploit this kind of corpus to help machine translation systems improve. The advantage of using such corpus is that it can be prepared easily unlike the one that is domain specific. The effectiveness of the parallel fragments of text developed from the comparable corpora in the present work is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phrase extraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model with Kneser-Ney smoothing (Kneser and Ney, 1995) trained with SRILM (Stolcke, 2002), and Moses decoder (Koehn et al., 2007). Related Work There has been a growing interest in approaches focused on extracting word translations from comparable corpora (Fung and McKeown, 1997; Fung and Yee, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002; Dejean et al., 2002; Kaji, 2005; Gamallo, 2007; Saralegui et al., 2008). Most of the strategies follow a standard method based on context similarity. The idea behind this method is as follows: A target word t i"
W13-2509,2007.mtsummit-papers.26,0,0.920458,"Missing"
W13-2509,P02-1040,0,0.0925493,"Missing"
W13-2509,P99-1067,0,0.163851,"ent work is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phrase extraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model with Kneser-Ney smoothing (Kneser and Ney, 1995) trained with SRILM (Stolcke, 2002), and Moses decoder (Koehn et al., 2007). Related Work There has been a growing interest in approaches focused on extracting word translations from comparable corpora (Fung and McKeown, 1997; Fung and Yee, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002; Dejean et al., 2002; Kaji, 2005; Gamallo, 2007; Saralegui et al., 2008). Most of the strategies follow a standard method based on context similarity. The idea behind this method is as follows: A target word t is the translation of a source word s if the words with which t co-occurs are translations of words with which s co-occurs. The basis of the method is to find the target words that have the most similar distributions with a given source word. The starting point of this method is a list of bilingual expressions that are used to build the context vectors of al"
W13-2509,N10-1063,0,0.0933741,"Missing"
W13-2509,W97-0119,0,\N,Missing
W13-2509,P98-1069,0,\N,Missing
W13-2509,C98-1066,0,\N,Missing
W13-2814,P06-1097,0,0.019944,"re capitalization cues have been used for identifying NEs on the English side. Statistical techniques are applied to decide which portion of the target language corresponds to the specified English NE, for simultaneous NE identification and translation. To improve the learning process of unlabeled data using labeled data (Chapelle et al., 2006), the semi-supervised learning method is the most useful learning technique. Semi-supervised learning is a broader area of Machine Learning. Researchers have begun to explore semisupervised word alignment models that use both labeled and unlabeled data. Fraser and Marcu (2006) proposed a semi-supervised training algo95 guage resources in Bengali are not widely available. 3 ods. Our approach deals with the latter case. The supervised technique of Berkeley aligner helps us to align those words which could not be aligned by rule based word aligner. Hybrid Word Alignment Model The hybrid word alignment model is described as the combination of three word alignment models as follows: 3.1 3.3 The proposed Rule based aligner aligns Named Entities (NEs) and chunks. For NE alignment, we first identify NEs from the source side (i.e. English) using Stanford NER. The NEs on the"
W13-2814,J93-2003,0,0.05003,"Model for Phrase-Based Statistical Machine Translation Santanu Pal*, Sudip Kumar Naskar† and Sivaji Bandyopadhyay* * Department of Computer Science & Engineering Jadavpur University, Kolkata, India santanu.pal.ju@gmail.com, sivaji_cse_ju@yahoo.com † Department of Computer & System Sciences Visva-Bharati University, Santiniketan, India sudip.naskar@gmail.com tion of each other. Statistical machine translation usually suffers from many-to-many word links which existing statistical word alignment algorithms can not handle well. The unsupervised word alignment models are based on IBM models 1–5 (Brown et al., 1993) and the HMM model (Ney and Vogel, 1996; Och and Ney, 2003). Models 3, 4 and 5 are based on fertility based models which are asymmetric. To improve alignment quality, the Berkeley Aligner is based on the symmetric property by intersecting alignments induced in each translation direction. In the present work, we propose improvement of word alignment quality by combining three word alignment tables (i) GIZA++ alignment (ii) Berkeley Alignment and (iii) rule based alignment. Our objective is to perceive the effectiveness of the Hybrid model in word alignment by improving the quality of translatio"
W13-2814,P04-1023,0,0.0291512,"scribed in Section 3. Section 4 presents the tools and resources used for the various experiments. Section 5 includes the results obtained, together with some analysis. Section 6 concludes and provides avenues for further work. 2 rithm. The weighting parameters are learned from discriminative error training on labeled data, and the parameters are estimated by maximum-likelihood EM training on unlabeled data. They have also used a log-linear model which is trained on the available labeled data to improve performance. Interpolating human alignments with automatic alignments has been proposed by Callison-Burch et al. (2004), where the alignments of higher quality have gained much higher weight than the lower-quality alignments. Wu et al. (2006) have developed two separate models of standard EM algorithm which learn separately from both labeled and unlabeled data. Two models are then interpolated as a learner in the semisupervised Ada-Boost algorithm to improve word alignment. Ambati et al. (2010) proposed active learning query strategies to identify highly uncertain or most informative alignment links under an unsupervised word alignment model. Intuitively, multiword NEs on the source and the target sides should"
W13-2814,C04-1114,0,0.0277213,"ork, we have implemented a rule based alignment model by considering several types of chunks which are automatically extracted on the source side. Each individual source chunk is translated using a baseline PBSMT system and validated with the target chunks on the target side. The validated source-target chunks are added in the rule based alignment table. Work has been carried out into three directions: (i) three alignment tables are combined together by taking their union; (ii) extra alignment pairs are added into the alignment table. This is a well-known practice in domain adaptation in SMT (Eck et al., 2004; Wu et al., 2008); (iii) the alignment table is updated through semisupervised alignment technique. Abstract This paper proposes a hybrid word alignment model for Phrase-Based Statistical Machine translation (PB-SMT). The proposed hybrid alignment model provides most informative alignment links which are offered by both unsupervised and semi-supervised word alignment models. Two unsupervised word alignment models (GIZA++ and Berkeley aligner) and a rule based aligner are combined together. The rule based aligner only aligns named entities (NEs) and chunks. The NEs are aligned through translit"
W13-2814,W09-3539,1,0.819859,"re not widely available. 3 ods. Our approach deals with the latter case. The supervised technique of Berkeley aligner helps us to align those words which could not be aligned by rule based word aligner. Hybrid Word Alignment Model The hybrid word alignment model is described as the combination of three word alignment models as follows: 3.1 3.3 The proposed Rule based aligner aligns Named Entities (NEs) and chunks. For NE alignment, we first identify NEs from the source side (i.e. English) using Stanford NER. The NEs on the target side (i.e. Bengali) are identified using a method described in (Ekbal and Bandyopadhyay, 2009). The accuracy of the Bengali Named Entity recognizers (NER) is much poorer compared to that of English NER due to several reasons: (i) there is no capitalization cue for NEs in Bengali; (ii) most of the common nouns in Bengali are frequently used as proper nouns; (iii) suffixes (case markers, plural markers, emphasizers, specifiers) get attached to proper names as well in Bengali. Bengali shallow parser 1 has been used to improve the performance of NE identification by considering proper names as NE. Therefore, NER and shallow parser are jointly employed to detect NEs from the Bengali sentenc"
W13-2814,W04-3248,0,0.105861,"ou et. al., 2004). Pal et, al. (2012) proposed a bootstrapping method for chunk alignment; they used an SMT based model for chunk translation and then aligned the sourcetarget chunk pairs after validating the translated chunk. Ma et. al. (2007) simplified the task of automatic word alignment as several consecutive words together correspond to a single word in the opposite language by using the word aligner itself, i.e., by bootstrapping on its output. A Maximum Entropy model based approach for English—Chinese NE alignment which significantly outperforms IBM Model4 and HMM has been proposed by Feng et al. (2004). They considered 4 features: translation score, transliteration score, source NE and target NE&apos;s co-occurrence score and the distortion score for distinguishing identical NEs in the same sentence. Moore (2003) presented an approach where capitalization cues have been used for identifying NEs on the English side. Statistical techniques are applied to decide which portion of the target language corresponds to the specified English NE, for simultaneous NE identification and translation. To improve the learning process of unlabeled data using labeled data (Chapelle et al., 2006), the semi-supervi"
W13-2814,J03-1002,0,0.189531,"anu Pal*, Sudip Kumar Naskar† and Sivaji Bandyopadhyay* * Department of Computer Science & Engineering Jadavpur University, Kolkata, India santanu.pal.ju@gmail.com, sivaji_cse_ju@yahoo.com † Department of Computer & System Sciences Visva-Bharati University, Santiniketan, India sudip.naskar@gmail.com tion of each other. Statistical machine translation usually suffers from many-to-many word links which existing statistical word alignment algorithms can not handle well. The unsupervised word alignment models are based on IBM models 1–5 (Brown et al., 1993) and the HMM model (Ney and Vogel, 1996; Och and Ney, 2003). Models 3, 4 and 5 are based on fertility based models which are asymmetric. To improve alignment quality, the Berkeley Aligner is based on the symmetric property by intersecting alignments induced in each translation direction. In the present work, we propose improvement of word alignment quality by combining three word alignment tables (i) GIZA++ alignment (ii) Berkeley Alignment and (iii) rule based alignment. Our objective is to perceive the effectiveness of the Hybrid model in word alignment by improving the quality of translation in the SMT system. In the present work, we have implement"
W13-2814,W03-1502,0,0.0165294,"unk. Ma et. al. (2007) simplified the task of automatic word alignment as several consecutive words together correspond to a single word in the opposite language by using the word aligner itself, i.e., by bootstrapping on its output. A Maximum Entropy model based approach for English—Chinese NE alignment which significantly outperforms IBM Model4 and HMM has been proposed by Feng et al. (2004). They considered 4 features: translation score, transliteration score, source NE and target NE&apos;s co-occurrence score and the distortion score for distinguishing identical NEs in the same sentence. Moore (2003) presented an approach where capitalization cues have been used for identifying NEs on the English side. Statistical techniques are applied to decide which portion of the target language corresponds to the specified English NE, for simultaneous NE identification and translation. To improve the learning process of unlabeled data using labeled data (Chapelle et al., 2006), the semi-supervised learning method is the most useful learning technique. Semi-supervised learning is a broader area of Machine Learning. Researchers have begun to explore semisupervised word alignment models that use both la"
W13-2814,P06-2117,0,0.0375047,"Missing"
W13-2814,N03-1017,0,0.0334238,"e source chunks into the target language using a baseline PB-SMT system and subsequently validating the target chunks using a fuzzy matching technique against the target corpus. All the experiments are carried out after single-tokenizing the multi-word NEs. Our best system provided significant improvements over the baseline as measured by BLEU. 1 Introduction Word alignment is the backbone of PB-SMT system or any data driven approaches to Machine Translation (MT) and it has received a lot of attention in the area of statistical machine translation (SMT) (Brown et al., 1993; Och and Ney, 2003; Koehn et al., 2003). Word alignment is not an end task in itself and is usually used as an intermediate step in SMT. Word alignment is defined as the detection of corresponding alignment of words from parallel sentences that are transla94 Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 94–101, c Sofia, Bulgaria, August 8, 2013. 2013 Association for Computational Linguistics The remainder of the paper is organized as follows. Section 2 discusses related work. The proposed hybrid word alignment model is described in Section 3. Section 4 presents the tools and resources used for the va"
W13-2814,P07-2045,0,0.0140433,"alignment from A2 and A3 (using A2∩A3). Step 4: Add additional entries with SA. Figure 1: Establishing alignments through Rule based methods. The extracted chunks on the source side may not have a one to one correspondence with the target side chunks. The alignment validation process is focused on the proper identification of the head words and not between the translated source chunk and target chunk. The matching process has been carried out using a fuzzy 97 3.5 language model trained using SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing (Kneser and Ney, 1995) and the Moses decoder (Koehn et al., 2007) have been used in the present study. Berkeley Semi-supervised Alignment The correctness of the alignments is verified by manually checking the performance of the various alignment system. We start with the combined alignment table which is produced by Algorithm 1. Iinitially, we take a subset of the alignments by manually inspecting from the combined alignment table. Then we train the Barkley supervised aligner with this labeled data. A subset of the unlabeled data from the combined alignment table is tested with the supervised model. The output is then added as additional labeled training da"
W13-2814,W04-3250,0,0.170255,"Missing"
W13-2814,P03-1021,0,0.0597904,"Missing"
W13-2814,W12-0113,1,0.855575,"Missing"
W13-2814,W10-3707,1,0.62711,"engali; (ii) most of the common nouns in Bengali are frequently used as proper nouns; (iii) suffixes (case markers, plural markers, emphasizers, specifiers) get attached to proper names as well in Bengali. Bengali shallow parser 1 has been used to improve the performance of NE identification by considering proper names as NE. Therefore, NER and shallow parser are jointly employed to detect NEs from the Bengali sentences. The source NEs are then transliterated using a modified joint source-channel model (Ekbal et al., 2006) and aligned to their target side equivalents following the approach of Pal et al. (2010). The target side equivalents NEs are transformed into canonical form after omitting their ‗matras‘. Similarly Bengali NEs are also transformed into canonical forms as Bengali NEs may differ in their choice of matras (vowel modifiers). The transliterated NEs are then matched with the corresponding parallel target NEs and finally we align the NEs if match is found. After identification of multiword NEs on both sides, we pre-processed the corpus by replacing space with the underscore character (‗_‘). We have used underscore (‗_‘) instead of hyphen (‗‘) since there already exists some hyphenated"
W13-2814,P02-1040,0,0.0883936,"us respectively, of which 22,273 NEs are unique in English and 22,010 NEs in Bengali. A total of 14,023 NEs have been aligned through transliteration. The experiments have been carried out with various experimental settings: (i) single tokenization of NEs on both sides of the parallel corpus, (ii) using Berkeley Aligner with unsupervised training, (iii) union of the three alignment models: rule based, GIZA++ with GDFA and Berkeley Alignment, (iv) hybridization of the three alignment models and (v) supervised Berkeley Aligner. Eextrinsic evaluation was carried out on the MT quality using BLEU (Papineni et al., 2002) and NIST (Doddington, 2002). 3 The EILMT project is funded by the Department of Electronics and Information Technology (DEITY), Ministry of Communications and Information Technology (MCIT), Government of India. 4 http://nlp.stanford.edu/software/lex-parser.shtml 5 http://crfchunker.sourceforge.net/ 6 The IL-ILMT project is funded by the Department of Electronics and Information Technology (DEITY), Ministry of Communications and Information Technology (MCIT), Government of India. 98 Experiment BLEU NIST Baseline system using GIZA++ with GDFA Exp no. 1 10.92 4.13 PB-SMT system using Berkeley Al"
W13-2814,C96-2141,0,0.621907,"Missing"
W13-2814,C08-1125,0,0.0411533,"Missing"
W13-4305,P91-1022,0,0.475773,"Missing"
W13-4305,P93-1002,0,0.0841543,"correctness of the alignment of the rule based system. The remainder of the paper is organized as follows. Next section briefly elaborates the related work. The proposed system is described in Section 3. Section 4 states the tools and resources used for the various experiments. Section 5 includes the results obtained, together with some analysis. Section 6 concludes and provides avenues for further work. 2 Related Works The works related to alignment are mostly developed for machine translation task. Some works in sentence alignment can be found in (Brown, 1991) and (Gale and Church, 1993). (Chen, 1993) developed a method which was slower but more accurate than the sentencelength based Brown and Gale algorithm. (Wu, 1994) used an approach which was adopted from Gale and Church‘s method for Chinese. They used a small corpus-specific bilingual lexicon to improve alignment accuracy in texts containing multiple sentences of similar length. (Melamed 1996, 1997) also proposed a method based on word correspondences. (Plamondon, 1998) developed a two-pass approach, in which a method similar to the one proposed by Melamed identifies points of correspondence in the text that constrain a second-pass se"
W13-4305,P07-2045,0,0.00635855,"Missing"
W13-4305,R11-1084,1,0.828413,"Missing"
W13-4305,W04-3248,0,0.0288507,"words and sentences. In the hybrid model, they used the sentence pairs that are assigned the highest probability of alignment to train a modified version of IBM Translation Model 1 (Brown, 1993). (Fung, 1994) presented K-vec, an alternative alignment strategy, that starts by estimating the lexicon. Moore (2003) used capitalization cues for identifying NEs on the English side and then applied statistical techniques to decide which portion of the target language corresponds to the specified English NE. A Maximum Entropy model based approach for English—Chinese NE alignment has been proposed in Feng et al. (2004) which significantly outperforms IBM Model 4 and HMM. A method for 1 http://ltrc.iiit.ac.in/showfile.php?filename=downloads/shallow _parser.php 37 automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization has been proposed in Huang et al. (2003). 3 3.2 It has been observed from the detailed text analysis that almost all events are associated with some actors (―anything having existence (living or nonliving)”), either active or passive. More generally, event actions are associated with persons or organizations and sometimes with l"
W13-4305,W96-0201,0,0.202806,"Missing"
W13-4305,C94-2178,0,0.220366,"Missing"
W13-4305,P97-1039,0,0.121292,"Missing"
W13-4305,moore-2002-fast,0,0.042022,"rate than the sentencelength based Brown and Gale algorithm. (Wu, 1994) used an approach which was adopted from Gale and Church‘s method for Chinese. They used a small corpus-specific bilingual lexicon to improve alignment accuracy in texts containing multiple sentences of similar length. (Melamed 1996, 1997) also proposed a method based on word correspondences. (Plamondon, 1998) developed a two-pass approach, in which a method similar to the one proposed by Melamed identifies points of correspondence in the text that constrain a second-pass search based on the statistical translation model. (Moore, 2002) developed a hybrid sentence-alignment method using sentence length-based and word-correspondencebased models. This model is fast, very accurate, and requires that the corpus be separated into words and sentences. In the hybrid model, they used the sentence pairs that are assigned the highest probability of alignment to train a modified version of IBM Translation Model 1 (Brown, 1993). (Fung, 1994) presented K-vec, an alternative alignment strategy, that starts by estimating the lexicon. Moore (2003) used capitalization cues for identifying NEs on the English side and then applied statistical"
W13-4305,E03-1035,0,0.0393444,"e in the text that constrain a second-pass search based on the statistical translation model. (Moore, 2002) developed a hybrid sentence-alignment method using sentence length-based and word-correspondencebased models. This model is fast, very accurate, and requires that the corpus be separated into words and sentences. In the hybrid model, they used the sentence pairs that are assigned the highest probability of alignment to train a modified version of IBM Translation Model 1 (Brown, 1993). (Fung, 1994) presented K-vec, an alternative alignment strategy, that starts by estimating the lexicon. Moore (2003) used capitalization cues for identifying NEs on the English side and then applied statistical techniques to decide which portion of the target language corresponds to the specified English NE. A Maximum Entropy model based approach for English—Chinese NE alignment has been proposed in Feng et al. (2004) which significantly outperforms IBM Model 4 and HMM. A method for 1 http://ltrc.iiit.ac.in/showfile.php?filename=downloads/shallow _parser.php 37 automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization has been proposed in Huan"
W13-4305,J02-3001,0,0.248147,"Missing"
W13-4305,P03-1021,0,0.0329635,"Missing"
W13-4305,W03-1502,0,0.0389762,"he text that constrain a second-pass search based on the statistical translation model. (Moore, 2002) developed a hybrid sentence-alignment method using sentence length-based and word-correspondencebased models. This model is fast, very accurate, and requires that the corpus be separated into words and sentences. In the hybrid model, they used the sentence pairs that are assigned the highest probability of alignment to train a modified version of IBM Translation Model 1 (Brown, 1993). (Fung, 1994) presented K-vec, an alternative alignment strategy, that starts by estimating the lexicon. Moore (2003) used capitalization cues for identifying NEs on the English side and then applied statistical techniques to decide which portion of the target language corresponds to the specified English NE. A Maximum Entropy model based approach for English—Chinese NE alignment has been proposed in Feng et al. (2004) which significantly outperforms IBM Model 4 and HMM. A method for 1 http://ltrc.iiit.ac.in/showfile.php?filename=downloads/shallow _parser.php 37 automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization has been proposed in Huan"
W13-4305,N03-1017,0,0.010592,"Missing"
W13-4305,J93-1004,0,\N,Missing
W13-4305,de-marneffe-etal-2006-generating,0,\N,Missing
W13-4305,W09-1104,0,\N,Missing
W13-4305,J93-2003,0,\N,Missing
W13-4305,W09-3539,1,\N,Missing
W13-4305,W04-3250,0,\N,Missing
W14-1009,W97-0119,0,0.0495516,"agments using three steps: (i) mining comparable corpora form Wikipedia, (ii) sentence level alignment using two-way TE and a baseline Bengali−English SMT system, and finally (iii) clustering the parallel sentence aligned comparable corpora using textual entailment and then aligning parallel fragments of text by textual entailment and a baseline Bengali−English SMT system. Comparable corpora have been used in many research areas in NLP, especially in machine translation. Several earlier works have studied the use of comparable corpora in machine translation. However, most of these approaches (Fung and McKeown, 1997; Fung and Yee, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002; Dejean et al., 2002; Kaji, 2005; Otero, 2007; Saralegui et al., 2008; Gupta et al., 2013) are specifically focused on extracting word translations from comparable corpora. Most of the strategies follow a standard method based on the context vector similarity measure such as finding the target words that have the most similar distributions with a given source word. In most of the cases, a starting list contains the “seed expressions” and this list is required to build the context vectors of the words in both the languages. A bilingu"
W14-1009,P98-1069,0,0.065174,"s: (i) mining comparable corpora form Wikipedia, (ii) sentence level alignment using two-way TE and a baseline Bengali−English SMT system, and finally (iii) clustering the parallel sentence aligned comparable corpora using textual entailment and then aligning parallel fragments of text by textual entailment and a baseline Bengali−English SMT system. Comparable corpora have been used in many research areas in NLP, especially in machine translation. Several earlier works have studied the use of comparable corpora in machine translation. However, most of these approaches (Fung and McKeown, 1997; Fung and Yee, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002; Dejean et al., 2002; Kaji, 2005; Otero, 2007; Saralegui et al., 2008; Gupta et al., 2013) are specifically focused on extracting word translations from comparable corpora. Most of the strategies follow a standard method based on the context vector similarity measure such as finding the target words that have the most similar distributions with a given source word. In most of the cases, a starting list contains the “seed expressions” and this list is required to build the context vectors of the words in both the languages. A bilingual dictionary can be"
W14-1009,W13-2509,1,0.34305,"system, and finally (iii) clustering the parallel sentence aligned comparable corpora using textual entailment and then aligning parallel fragments of text by textual entailment and a baseline Bengali−English SMT system. Comparable corpora have been used in many research areas in NLP, especially in machine translation. Several earlier works have studied the use of comparable corpora in machine translation. However, most of these approaches (Fung and McKeown, 1997; Fung and Yee, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002; Dejean et al., 2002; Kaji, 2005; Otero, 2007; Saralegui et al., 2008; Gupta et al., 2013) are specifically focused on extracting word translations from comparable corpora. Most of the strategies follow a standard method based on the context vector similarity measure such as finding the target words that have the most similar distributions with a given source word. In most of the cases, a starting list contains the “seed expressions” and this list is required to build the context vectors of the words in both the languages. A bilingual dictionary can be used as a starting list. The bilingual list can also be prepared form parallel corpus using bilingual correlation method (Otero, 20"
W14-1009,W05-0909,0,0.0376082,"Missing"
W14-1009,C02-2020,0,0.157566,"form Wikipedia, (ii) sentence level alignment using two-way TE and a baseline Bengali−English SMT system, and finally (iii) clustering the parallel sentence aligned comparable corpora using textual entailment and then aligning parallel fragments of text by textual entailment and a baseline Bengali−English SMT system. Comparable corpora have been used in many research areas in NLP, especially in machine translation. Several earlier works have studied the use of comparable corpora in machine translation. However, most of these approaches (Fung and McKeown, 1997; Fung and Yee, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002; Dejean et al., 2002; Kaji, 2005; Otero, 2007; Saralegui et al., 2008; Gupta et al., 2013) are specifically focused on extracting word translations from comparable corpora. Most of the strategies follow a standard method based on the context vector similarity measure such as finding the target words that have the most similar distributions with a given source word. In most of the cases, a starting list contains the “seed expressions” and this list is required to build the context vectors of the words in both the languages. A bilingual dictionary can be used as a starting list. The bilingual l"
W14-1009,P02-1040,0,0.109035,"Missing"
W14-1009,N10-1045,0,0.0226969,"Missing"
W14-1009,P06-1011,0,0.0283236,"parable corpora. The two-way TE system architecture is described in section 4. Section 5 describes the automatic alignment technique of parallel fragment of texts. Section 6 describes the tools and resources used for this work. The In the NIST shared task on Recognizing Textual Entailment Challenge (RTE), several methods have been proposed to tackle the textual entailment problem. Most of these systems use some form of lexical matching, e.g., n-gram, word similarity, etc. and even simple word overlap. A number of systems represent the texts as parse trees (e.g., syntactic or dependency trees) Munteanu and Marcu (2006) suggested that comparable corpora tend to have parallel data at sub-sentential level. Hence, instead of finding sentence level parallel resource from comparable corpora, in the present work we mainly focus on finding parallel fragments of text. 49 before the actual task. Some of the systems use semantic features (e.g., logical inference, Semantic Role Labelling) for solving the text and hypothesis entailment problem. MacCartney et al. (2006) proposed a new architecture for textual inference in which finding a good alignment is separated from evaluating entailment. Agichtein et al. (2008) pres"
W14-1009,P99-1067,0,0.173641,"able corpora form Wikipedia, (ii) sentence level alignment using two-way TE and a baseline Bengali−English SMT system, and finally (iii) clustering the parallel sentence aligned comparable corpora using textual entailment and then aligning parallel fragments of text by textual entailment and a baseline Bengali−English SMT system. Comparable corpora have been used in many research areas in NLP, especially in machine translation. Several earlier works have studied the use of comparable corpora in machine translation. However, most of these approaches (Fung and McKeown, 1997; Fung and Yee, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002; Dejean et al., 2002; Kaji, 2005; Otero, 2007; Saralegui et al., 2008; Gupta et al., 2013) are specifically focused on extracting word translations from comparable corpora. Most of the strategies follow a standard method based on the context vector similarity measure such as finding the target words that have the most similar distributions with a given source word. In most of the cases, a starting list contains the “seed expressions” and this list is required to build the context vectors of the words in both the languages. A bilingual dictionary can be used as a s"
W14-1009,W10-0734,0,0.048008,"Missing"
W14-1009,W09-0404,0,0.0146889,"T. Textual Entailment has many applications in NLP tasks, such as summarization, information extraction, question answering, Introduction Comparable corpora have recently attracted huge interest in natural language processing research. Comparable corpora are now considered as a rich 48 Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 48–57, c Gothenburg, Sweden, April 27, 2014. 2014 Association for Computational Linguistics information retrieval, machine translation, etc. In machine translation, textual entailment can be applied to MT evaluation (Pado et al., 2009). A number of research works have been carried out on cross-lingual Textual entailment using MT (Mehdad et al.,2010; Negri et al., 2010; Neogi et al., 2012). However, to the best of our knowledge, the work presented here is the first attempt towards employing textual entailment for the purpose of extracting parallel text fragments from comparable corpora which in turn are used to improve MT system. experiments and evaluation results are presented in section 7. Section 8 concludes and presents avenues for future work. 2 Related Work We carried out the task of automatic alignment of parallel fra"
W14-1009,N10-1063,0,0.115956,"Santanu Pal1, Partha Pakray2, Sudip Kumar Naskar3 1 Universität Des Saarlandes, Saarbrücken, Germany 2 Computer & Information Science, Norwegian University of Science and Technology, Trondheim, Norway 3 Department of Computer Science & Engineering, Jadavpur University, Kolkata, India 1 santanu.pal@uni-saarland.de, 2 partha.pakray@idi.ntnu.no, 3 sudip.naskar@cse.jdvu.ac.in resource for acquiring parallel resources such as parallel corpus or parallel text fragments,. Parallel text extracted from comparable corpora can take an important role in improving the quality of machine translation (MT) (Smith et al. 2010). Parallel text extracted from comparable corpora are typically added with the training corpus as additional training material which is expected to facilitate better performance of SMT systems specifically for low density language pairs. Abstract Building parallel resources for corpus based machine translation, especially Statistical Machine Translation (SMT), from comparable corpora has recently received wide attention in the field Machine Translation research. In this paper, we propose an automatic approach for extraction of parallel fragments from comparable corpora. The comparable corpora"
W14-1009,P03-1021,0,0.0310102,"Missing"
W14-1009,2006.amta-papers.25,0,0.107752,"Missing"
W14-1009,2007.mtsummit-papers.26,0,0.181303,"E and a baseline Bengali−English SMT system, and finally (iii) clustering the parallel sentence aligned comparable corpora using textual entailment and then aligning parallel fragments of text by textual entailment and a baseline Bengali−English SMT system. Comparable corpora have been used in many research areas in NLP, especially in machine translation. Several earlier works have studied the use of comparable corpora in machine translation. However, most of these approaches (Fung and McKeown, 1997; Fung and Yee, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002; Dejean et al., 2002; Kaji, 2005; Otero, 2007; Saralegui et al., 2008; Gupta et al., 2013) are specifically focused on extracting word translations from comparable corpora. Most of the strategies follow a standard method based on the context vector similarity measure such as finding the target words that have the most similar distributions with a given source word. In most of the cases, a starting list contains the “seed expressions” and this list is required to build the context vectors of the words in both the languages. A bilingual dictionary can be used as a starting list. The bilingual list can also be prepared form parallel corpus"
W14-1009,W07-1406,0,0.0305496,"Missing"
W14-1009,C98-1066,0,\N,Missing
W14-1009,S12-1103,1,\N,Missing
W14-1009,P07-2045,0,\N,Missing
W14-1009,N03-1017,0,\N,Missing
W14-3323,P07-2045,0,0.00465052,"pipeline. 1 2 2.1 In this paper, we present Saarland University (USAAR) submission to Workshop for Machine Translation 2014 (WMT 2014) using the Manawi MT system. We participated in the generic translation shared task for the English-Hindi (EN-HI) and Hindi-English (HI-EN) language pairs. Our Manawi system showcased the incorporation of NLP tools output within the MT pipeline; a bilingual MWE extractor and a bilingual NE recognizer for English and Hindi were implemented. The output from these NLP tools was appended to the training corpus prior to the SMT model training with the MOSES toolkit (Koehn et al., 2007). The resulting system achieves the lowest Translation Error Rate (TER) among competing systems for the English-Hindi language pair. Multi-word expression And Named-entity Wikipedia titles (Manawi) 2 Lower TER often results in better translation Bilingual MWE in MT Multi-Word Expressions (MWE) are defined as “idiosyncratic interpretations that cross word boundaries” (Sag et al., 2002). MWE can be made up of collocations (e.g. seem ridiculous : behuda dikhai), frozen expressions (e.g. exception handling : apavada sancalaka) or name entities (e.g. Johnny Cash : Johni Kesh). Jackendoff (1997) cla"
W14-3323,2005.mtsummit-papers.11,0,0.0132455,"(2013) improved translation quality by cleaning the Common Crawl corpus during the WMT 2013 shared task. They filtered out documents exceeding 60 words and cleaned the remainder of the corpus by exploiting the number of alignment points in word alignments between sentence pairs. Their hypothesis was that sentence pairs with very few alignment points in the intersection would mostly likely not be parallel. This is based on the fact that when using GIZA++ (Och and Ney, 2003), the intersection of alignments is more sparse than the standard SMT symmetrization heuristics like grow-diag-final-and (Koehn, 2005). Different from Stymne et al., our hypothesis for non-parallelness adheres to sentence level alignment criteria as defined in the Gale-Church algorithm (Gale and Church, 1993). If a sentence pair is parallel, the ratio of the number of characters in the source and target sentence should be coherent to the global ratio of the number of source-target characters in a fully parallel corpus. The GaleChurch algorithm had its parameters tuned to suit European languages and Tan (2013) had demonstrated that sentence-level alignments can be improved by using corpus specific parameters. When 4 Filtering"
W14-3323,D11-1033,0,0.0323736,"Missing"
W14-3323,bojar-etal-2014-hindencorp,0,0.0638834,"Missing"
W14-3323,W13-2224,0,0.0823586,"Missing"
W14-3323,W13-2212,0,0.0260483,"Missing"
W14-3323,W11-0805,0,0.119409,"Missing"
W14-3323,W09-2907,0,0.115243,"Missing"
W14-3323,J93-1004,0,0.0327133,"he remainder of the corpus by exploiting the number of alignment points in word alignments between sentence pairs. Their hypothesis was that sentence pairs with very few alignment points in the intersection would mostly likely not be parallel. This is based on the fact that when using GIZA++ (Och and Ney, 2003), the intersection of alignments is more sparse than the standard SMT symmetrization heuristics like grow-diag-final-and (Koehn, 2005). Different from Stymne et al., our hypothesis for non-parallelness adheres to sentence level alignment criteria as defined in the Gale-Church algorithm (Gale and Church, 1993). If a sentence pair is parallel, the ratio of the number of characters in the source and target sentence should be coherent to the global ratio of the number of source-target characters in a fully parallel corpus. The GaleChurch algorithm had its parameters tuned to suit European languages and Tan (2013) had demonstrated that sentence-level alignments can be improved by using corpus specific parameters. When 4 Filtering Noise in HindEnCorp System Setup Data: To train the baseline translation model, we have used the cleaned subset of the data as described in Section 3. For the Manawi model, we"
W14-3323,W13-2227,0,0.0232851,"Missing"
W14-3323,W10-3707,1,0.933515,"Missing"
W14-3323,W13-2229,0,0.0399133,"Missing"
W14-3323,S13-2030,1,0.780393,"Missing"
W14-3323,W13-2803,0,0.0217028,"Missing"
W14-3323,W06-1204,0,0.0609476,"Missing"
W14-3323,P10-2041,0,\N,Missing
W14-3323,W10-1711,0,\N,Missing
W14-3323,2010.iwslt-evaluation.22,0,\N,Missing
W14-3323,J03-1002,0,\N,Missing
W14-3323,2005.mtsummit-posters.11,0,\N,Missing
W14-5114,W10-3208,1,0.839958,"al. (2004), which significantly outperforms IBM Model 4 and HMM. Fung (1994) presented K-vec, an alternative alignment strategy that starts by estimating the lexicon. Sentiment detection is the task of determining positive or negative sentiment of words, phrases, sentences and documents. The computational approach to sentiment analysis in textual data requires annotated lexicons with polarity tags (Patra et al., 2013). Research has been carried out on building sentiment or emotional corpora in English (Strapparava and Valitutti, 2004; Baccianella et al., 2010; Patra et al., 2013) and Bengali (Das and Bandyopadhyay, 2010; Das and Bandyopadhyay, 2010a). Identifying the sentiment holder is another task closely related to subjectivity detection (Kim and Hovy, 2004). Several methods have been implemented to identify the sentiment holders such as rule based methods (using dependency information) (Kolya et al., 2012) and supervised machine learning methods (Kim and Hovy, 2004; Kolya et al., 2012). To the best of our knowledge, no prior work on improving SMT systems using aligned sentiment expressions, holders and their corresponding objects have been developed yet. There is research on creating sentiment lexica and"
W14-5114,strapparava-valitutti-2004-wordnet,0,0.263172,"Missing"
W14-5114,D08-1014,0,0.0219678,"cy information) (Kolya et al., 2012) and supervised machine learning methods (Kim and Hovy, 2004; Kolya et al., 2012). To the best of our knowledge, no prior work on improving SMT systems using aligned sentiment expressions, holders and their corresponding objects have been developed yet. There is research on creating sentiment lexica and cross-lingual sentiment identification. Automatic translation is a viable alternative for the construction of resources and tools for subjectivity or sentiment analysis in a new resource-constrained language using a resourcerich language as a starting point (Banea et al., 2008). Banea et al., (2008) generated resources for subjectivity annotation in Spanish and Romanian using English corpora. In context of Indian languages, Das et al., 2010 have developed a sentiment lexicon for Bengali Languages using an English to Bengali MT system. Similarly, a Hindi sentiment corpus has been developed using English to Hindi MT system (Balamurali et al., 2010). Hiroshi et al., (2004) developed a high-precision sentiment analysis system with low development cost, by making use of an existing transfer-based MT engine. 3 Dataset In our experiment, an English-Bengali parallel corpus"
W14-5114,P05-1033,0,0.267679,"Missing"
W14-5114,W04-3248,0,0.0173424,"nment template approach for PB-SMT (Och et al., 2004) allows many-tomany relations between words. A model that uses hierarchical phrases based on synchronous grammars is presented in (Chiang et al., 2005). To date there is little research on English-Bengali SMT: PB-SMT systems can be improved (Pal et al., 2011; 2013) by single tokenizing Multiword Expressions (MWEs) on both sides of the parallel corpus. Researches on alignment were mostly developed for MT tasks (Brown, 1991; Gale and 90 Church, 1993). A Maximum Entropy model based approach for English-Chinese NE alignment has been proposed in Feng et al. (2004), which significantly outperforms IBM Model 4 and HMM. Fung (1994) presented K-vec, an alternative alignment strategy that starts by estimating the lexicon. Sentiment detection is the task of determining positive or negative sentiment of words, phrases, sentences and documents. The computational approach to sentiment analysis in textual data requires annotated lexicons with polarity tags (Patra et al., 2013). Research has been carried out on building sentiment or emotional corpora in English (Strapparava and Valitutti, 2004; Baccianella et al., 2010; Patra et al., 2013) and Bengali (Das and Ba"
W14-5114,J04-4002,0,0.224891,"Missing"
W14-5114,C08-1125,0,0.0655339,"Missing"
W14-5114,C04-1071,0,0.0377596,"ation is a viable alternative for the construction of resources and tools for subjectivity or sentiment analysis in a new resource-constrained language using a resourcerich language as a starting point (Banea et al., 2008). Banea et al., (2008) generated resources for subjectivity annotation in Spanish and Romanian using English corpora. In context of Indian languages, Das et al., 2010 have developed a sentiment lexicon for Bengali Languages using an English to Bengali MT system. Similarly, a Hindi sentiment corpus has been developed using English to Hindi MT system (Balamurali et al., 2010). Hiroshi et al., (2004) developed a high-precision sentiment analysis system with low development cost, by making use of an existing transfer-based MT engine. 3 Dataset In our experiment, an English-Bengali parallel corpus containing 23,492 parallel sentences comprising of 488,026 word tokens from the travel and tourism domain has been used. We randomly selected 500 sentences each for the development set and the test set from the initial parallel corpus. The rest of the sentences were used as the training corpus. The training corpus was filtered with the maximum allowable sentence length of 100 words and sentence le"
W14-5114,P02-1040,0,0.107491,"rie Actions) (Grant No. 317471) and the “Development of English to Indian Languages Machine Translation (EILMT) System - Phase II” project funded by Department of Information Technology, Government of India. Our experiments have been carried out in two directions. First we improved the baseline model using the aligned sentiment phrases. Then, we automatically post-edited the translation output by using the sentiment knowledge of the source input test sentence. The evaluation results are reported in Table 1. The evaluation was carried out using well-known automatic MT evaluation metrics: BLEU (Papineni et al., 2002, NIST (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al., 2006). In experiment 2, the extracted parallel sentiment phrase alignments are incorporated with the existing baseline phrase table and the resulting model performs better than the baseline system. Experiment 3 shows how post-editing the output of experiment 2 brings about further improvements. 7 Conclusions and Future Research In this paper, we successfully illustrated how sentiment analysis can improve the translation of an English-Bengali PB-SMT system. We have also shown how sentiment knowledge is useful"
W14-5114,N10-1029,0,0.0575798,"Missing"
W14-5114,C94-2178,0,0.372118,"Missing"
W14-5114,J93-2003,0,0.107473,"Missing"
W14-5114,N03-1017,0,0.107016,"carried out using the positional information of sentiment components. The rest of the paper is organized in the following manner. Section 2 briefly elaborates the related work. Section 3 provides an overview of the dataset used in our experiments. The proposed system is described in Section 4 while Section 5 provides the system setup for the various experiments. Section 6 includes the experiments and results obtained. Finally, Section 7 concludes and provides avenues for further work. 2 Related Work SMT systems have undergone considerable improvements over the years. Moreover, PB-SMT models (Koehn et al., 2003) outperform wordbased models. The alignment template approach for PB-SMT (Och et al., 2004) allows many-tomany relations between words. A model that uses hierarchical phrases based on synchronous grammars is presented in (Chiang et al., 2005). To date there is little research on English-Bengali SMT: PB-SMT systems can be improved (Pal et al., 2011; 2013) by single tokenizing Multiword Expressions (MWEs) on both sides of the parallel corpus. Researches on alignment were mostly developed for MT tasks (Brown, 1991; Gale and 90 Church, 1993). A Maximum Entropy model based approach for English-Chin"
W14-5114,W04-3250,0,0.269403,"Missing"
W14-5114,2013.mtsummit-papers.8,1,0.870543,"Missing"
W14-5114,W05-0909,0,0.0587776,"English to Indian Languages Machine Translation (EILMT) System - Phase II” project funded by Department of Information Technology, Government of India. Our experiments have been carried out in two directions. First we improved the baseline model using the aligned sentiment phrases. Then, we automatically post-edited the translation output by using the sentiment knowledge of the source input test sentence. The evaluation results are reported in Table 1. The evaluation was carried out using well-known automatic MT evaluation metrics: BLEU (Papineni et al., 2002, NIST (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al., 2006). In experiment 2, the extracted parallel sentiment phrase alignments are incorporated with the existing baseline phrase table and the resulting model performs better than the baseline system. Experiment 3 shows how post-editing the output of experiment 2 brings about further improvements. 7 Conclusions and Future Research In this paper, we successfully illustrated how sentiment analysis can improve the translation of an English-Bengali PB-SMT system. We have also shown how sentiment knowledge is useful for automatic post-editing the MT output. In either case, we"
W14-5114,C04-1200,0,0.0836786,"g the lexicon. Sentiment detection is the task of determining positive or negative sentiment of words, phrases, sentences and documents. The computational approach to sentiment analysis in textual data requires annotated lexicons with polarity tags (Patra et al., 2013). Research has been carried out on building sentiment or emotional corpora in English (Strapparava and Valitutti, 2004; Baccianella et al., 2010; Patra et al., 2013) and Bengali (Das and Bandyopadhyay, 2010; Das and Bandyopadhyay, 2010a). Identifying the sentiment holder is another task closely related to subjectivity detection (Kim and Hovy, 2004). Several methods have been implemented to identify the sentiment holders such as rule based methods (using dependency information) (Kolya et al., 2012) and supervised machine learning methods (Kim and Hovy, 2004; Kolya et al., 2012). To the best of our knowledge, no prior work on improving SMT systems using aligned sentiment expressions, holders and their corresponding objects have been developed yet. There is research on creating sentiment lexica and cross-lingual sentiment identification. Automatic translation is a viable alternative for the construction of resources and tools for subjectiv"
W14-5114,W06-0301,0,0.104449,"Missing"
W14-5114,baccianella-etal-2010-sentiwordnet,0,0.071767,"English-Chinese NE alignment has been proposed in Feng et al. (2004), which significantly outperforms IBM Model 4 and HMM. Fung (1994) presented K-vec, an alternative alignment strategy that starts by estimating the lexicon. Sentiment detection is the task of determining positive or negative sentiment of words, phrases, sentences and documents. The computational approach to sentiment analysis in textual data requires annotated lexicons with polarity tags (Patra et al., 2013). Research has been carried out on building sentiment or emotional corpora in English (Strapparava and Valitutti, 2004; Baccianella et al., 2010; Patra et al., 2013) and Bengali (Das and Bandyopadhyay, 2010; Das and Bandyopadhyay, 2010a). Identifying the sentiment holder is another task closely related to subjectivity detection (Kim and Hovy, 2004). Several methods have been implemented to identify the sentiment holders such as rule based methods (using dependency information) (Kolya et al., 2012) and supervised machine learning methods (Kim and Hovy, 2004; Kolya et al., 2012). To the best of our knowledge, no prior work on improving SMT systems using aligned sentiment expressions, holders and their corresponding objects have been dev"
W14-5114,J93-1003,0,0.359133,"Missing"
W14-5114,J93-1004,0,0.625572,"Missing"
W15-3017,W11-2123,0,0.0206342,"lude some NEs that are already there in the parallel NE list, however they might remain untranslated during decoding. Our system post processed the output by replacing each such OOV NE with the corresponding target language NE after looking up the extracted NE list from the parallel corpus (cf. Section 2.1.2). conditioned on both source and target language. The reordering model was built by calculating the probabilities of the phrase pairs being associated with the given orientation such as monotone (m), swap (s) and discontinuous (d). The 5-gram target language model was trained using KENLM (Heafield, 2011). Parameter tuning was carried out using both k-best MIRA (Cherry and Foster, 2012) and Minimum Error Rate Training (MERT) (Och, 2003) on a held-out development set. After the parameters were tuned, decoding was carried out on the held out testset. Note that all the systems described in Section 2 employ the same PB-SMT settings (apart from the feature weights which are obtained via MERT) as the Baseline system. 2.3 System Combination System Combination is a technique, which combines translation hypotheses (outputs) produced by multiple MT systems. We applied a system combination method on the"
W15-3017,W99-0604,0,0.39787,"Missing"
W15-3017,N03-1017,0,0.0361081,"etup • System 4: System 3 with LM2 . 3.1 Baseline Settings • System 5: System 3 with LM3 . The effectiveness of the present work is demonstrated by using the standard log-linear PB-SMT model as our baseline system. For building the baseline system, we used a maximum phrase length of 7 and a 5-gram language model. The other experimental settings were: SymGIZA++ aligner (Junczys-Dowmunt and Szał, 2012), which is a modified version of GIZA++ word alignment models by updating the symmetrizing models between chosen iterations of the original word alignment training algorithms and phraseextraction (Koehn et al., 2003). The reordering model was trained on hier-mslr-bidirectional (i.e. using both forward and backward models) and • System 6: System 3 with LM4 . System 6 provides the individual best system. System combination (System-7 in Table 1) of the 6 best performing individual systems brings considerable improvements over each of the individual component systems. 5 Conclusions and Future Work A hybrid system (System 6) with NE alignment, EBMT phrases, single-tokenized source MWEs, and MIRA-MERT coupled tuning results in the best performing system. However, confusion 155 Systems Baseline System 1 System 2"
W15-3017,J10-4005,0,0.0383815,"s the best performance of each individual system in a multi-engine pipeline. 1 Introduction In this paper, we present Universit¨at des Saarlandes (UdS) submission (named UdS-Sant) to WMT 2015 using a Hybrid MT framework. We participated in the generic translation shared task for the English-German (EN-DE) language pair. Corpus-based MT (CBMT) has delivered progressively improved quality translations since its inception. There are two main approaches to corpus-based MT – Example Based Machine Translation (EBMT) (Carl and Way, 2003) and Statistical Machine Translation (SMT) (Brown et al., 1993; Koehn, 2010). Out of these two, in terms of large-scale evaluations, SMT is the most successful MT paradigm. However, each approach has its own advantages and disadvantages along with its own methods of applying and acquiring translation knowledge from the bilingual parallel training data. EBMT phrases tend to be more linguistically motivated compared to SMT phrases which essentially operate on n-grams. The knowledge extraction as well as representation process, 152 Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 152–157, c Lisboa, Portugal, 17-18 September 2015. 2015 Associati"
W15-3017,N04-1022,0,0.154869,"re tuned, decoding was carried out on the held out testset. Note that all the systems described in Section 2 employ the same PB-SMT settings (apart from the feature weights which are obtained via MERT) as the Baseline system. 2.3 System Combination System Combination is a technique, which combines translation hypotheses (outputs) produced by multiple MT systems. We applied a system combination method on the outputs of the different MT system described earlier. We implement the Minimum Bayes Risk coupled with Confusion Network (MBR-CN) framework described in (Du et al., 2009). The MBR decoder (Kumar and Byrne, 2004) selects the single best hypothesis from amongst the multiple candidate translations by minimising BLEU (Papineni et al., 2002) loss. This single best hypothesis serves as the backbone (also referred to as skeleton) of the confusion network and determines the general word order of the confusion network. A confusion network (Matusov et al., 2006) is built from the backbone while the remaining hypotheses are aligned against the backbone using METEOR (Lavie and Agarwal, 2007) and the TER metric (Snover et al., 2006). The features used to score each arc in the confusion network are word posterior"
W15-3017,E06-1005,0,0.0279832,"iple MT systems. We applied a system combination method on the outputs of the different MT system described earlier. We implement the Minimum Bayes Risk coupled with Confusion Network (MBR-CN) framework described in (Du et al., 2009). The MBR decoder (Kumar and Byrne, 2004) selects the single best hypothesis from amongst the multiple candidate translations by minimising BLEU (Papineni et al., 2002) loss. This single best hypothesis serves as the backbone (also referred to as skeleton) of the confusion network and determines the general word order of the confusion network. A confusion network (Matusov et al., 2006) is built from the backbone while the remaining hypotheses are aligned against the backbone using METEOR (Lavie and Agarwal, 2007) and the TER metric (Snover et al., 2006). The features used to score each arc in the confusion network are word posterior probability, target language model (3-gram, 4-gram), and length penalties. Minimum Error Rate Training (MERT) (Och, 2003) is applied to tune the CN weights (Pal et al., 2014). 3 4 Results and Analysis As described in Section 2.2.1, we developed 16 different systems. Instead of using all these 16 different systems, we apply only the 6 best perfor"
W15-3017,J93-2003,0,0.0424795,"hough, SMT is the most popular MT paradigm, it sometimes fails to deliver sufficient quality in translation output for some languages, since each language has its own difficulties. Multiword Expressions (MWEs) and Named Entities (NEs) offer challenges within a language. MWEs are defined as idiosyncratic interpretations that cross word boundaries (Sag et al., 2002). Named entities on the other hand often consist of more than one word, so that they can be considered as a specific type of MWEs such as noun compounds (Jackendoff, 1997). Traditional approaches to word alignment such as IBM Models (Brown et al., 1993) are unable to tackle NEs and MWEs properly due to their inability to handle many-to-many alignments. In another wellknown word alignment approach, Hidden Markov Model (HMM: (Vogel et al., 1996)), the alignment probabilities depend on the alignment position of the previous word. It does not explicitly consider many-to-many alignment either. We address this alignment problem indirectly. The objective of the present work is threefold. Firstly, we would like to determine how treatment of MWEs as a single unit affects the overall MT quality (Pal et al., 2010; Pal et al., 2011). Secondly, whether a"
W15-3017,P03-1021,0,0.503229,"ssed the output by replacing each such OOV NE with the corresponding target language NE after looking up the extracted NE list from the parallel corpus (cf. Section 2.1.2). conditioned on both source and target language. The reordering model was built by calculating the probabilities of the phrase pairs being associated with the given orientation such as monotone (m), swap (s) and discontinuous (d). The 5-gram target language model was trained using KENLM (Heafield, 2011). Parameter tuning was carried out using both k-best MIRA (Cherry and Foster, 2012) and Minimum Error Rate Training (MERT) (Och, 2003) on a held-out development set. After the parameters were tuned, decoding was carried out on the held out testset. Note that all the systems described in Section 2 employ the same PB-SMT settings (apart from the feature weights which are obtained via MERT) as the Baseline system. 2.3 System Combination System Combination is a technique, which combines translation hypotheses (outputs) produced by multiple MT systems. We applied a system combination method on the outputs of the different MT system described earlier. We implement the Minimum Bayes Risk coupled with Confusion Network (MBR-CN) fram"
W15-3017,N12-1047,0,0.0184546,"might remain untranslated during decoding. Our system post processed the output by replacing each such OOV NE with the corresponding target language NE after looking up the extracted NE list from the parallel corpus (cf. Section 2.1.2). conditioned on both source and target language. The reordering model was built by calculating the probabilities of the phrase pairs being associated with the given orientation such as monotone (m), swap (s) and discontinuous (d). The 5-gram target language model was trained using KENLM (Heafield, 2011). Parameter tuning was carried out using both k-best MIRA (Cherry and Foster, 2012) and Minimum Error Rate Training (MERT) (Och, 2003) on a held-out development set. After the parameters were tuned, decoding was carried out on the held out testset. Note that all the systems described in Section 2 employ the same PB-SMT settings (apart from the feature weights which are obtained via MERT) as the Baseline system. 2.3 System Combination System Combination is a technique, which combines translation hypotheses (outputs) produced by multiple MT systems. We applied a system combination method on the outputs of the different MT system described earlier. We implement the Minimum Baye"
W15-3017,W10-3707,1,0.907834,"o word alignment such as IBM Models (Brown et al., 1993) are unable to tackle NEs and MWEs properly due to their inability to handle many-to-many alignments. In another wellknown word alignment approach, Hidden Markov Model (HMM: (Vogel et al., 1996)), the alignment probabilities depend on the alignment position of the previous word. It does not explicitly consider many-to-many alignment either. We address this alignment problem indirectly. The objective of the present work is threefold. Firstly, we would like to determine how treatment of MWEs as a single unit affects the overall MT quality (Pal et al., 2010; Pal et al., 2011). Secondly, whether a prior automatic NE aligned parallel corpus as well as example based parallel phrases can bring about any further improvement on top of that. And finally, whether system combination can provide any additional advantage in terms of translation quality and performance. The remainder of the paper is organised as follows. Section 2 details the components of our system, in particular named entity extraction, translation memory, and EBMT, followed by description of 3 types of Hybrid systems and the system combination module. In Section 3, we outline the comple"
W15-3017,2011.mtsummit-papers.23,1,0.815387,"uch as IBM Models (Brown et al., 1993) are unable to tackle NEs and MWEs properly due to their inability to handle many-to-many alignments. In another wellknown word alignment approach, Hidden Markov Model (HMM: (Vogel et al., 1996)), the alignment probabilities depend on the alignment position of the previous word. It does not explicitly consider many-to-many alignment either. We address this alignment problem indirectly. The objective of the present work is threefold. Firstly, we would like to determine how treatment of MWEs as a single unit affects the overall MT quality (Pal et al., 2010; Pal et al., 2011). Secondly, whether a prior automatic NE aligned parallel corpus as well as example based parallel phrases can bring about any further improvement on top of that. And finally, whether system combination can provide any additional advantage in terms of translation quality and performance. The remainder of the paper is organised as follows. Section 2 details the components of our system, in particular named entity extraction, translation memory, and EBMT, followed by description of 3 types of Hybrid systems and the system combination module. In Section 3, we outline the complete experimental set"
W15-3017,P02-1040,0,0.0921099,"-SMT settings (apart from the feature weights which are obtained via MERT) as the Baseline system. 2.3 System Combination System Combination is a technique, which combines translation hypotheses (outputs) produced by multiple MT systems. We applied a system combination method on the outputs of the different MT system described earlier. We implement the Minimum Bayes Risk coupled with Confusion Network (MBR-CN) framework described in (Du et al., 2009). The MBR decoder (Kumar and Byrne, 2004) selects the single best hypothesis from amongst the multiple candidate translations by minimising BLEU (Papineni et al., 2002) loss. This single best hypothesis serves as the backbone (also referred to as skeleton) of the confusion network and determines the general word order of the confusion network. A confusion network (Matusov et al., 2006) is built from the backbone while the remaining hypotheses are aligned against the backbone using METEOR (Lavie and Agarwal, 2007) and the TER metric (Snover et al., 2006). The features used to score each arc in the confusion network are word posterior probability, target language model (3-gram, 4-gram), and length penalties. Minimum Error Rate Training (MERT) (Och, 2003) is ap"
W15-3017,2006.amta-papers.25,0,0.0454059,"ion Network (MBR-CN) framework described in (Du et al., 2009). The MBR decoder (Kumar and Byrne, 2004) selects the single best hypothesis from amongst the multiple candidate translations by minimising BLEU (Papineni et al., 2002) loss. This single best hypothesis serves as the backbone (also referred to as skeleton) of the confusion network and determines the general word order of the confusion network. A confusion network (Matusov et al., 2006) is built from the backbone while the remaining hypotheses are aligned against the backbone using METEOR (Lavie and Agarwal, 2007) and the TER metric (Snover et al., 2006). The features used to score each arc in the confusion network are word posterior probability, target language model (3-gram, 4-gram), and length penalties. Minimum Error Rate Training (MERT) (Och, 2003) is applied to tune the CN weights (Pal et al., 2014). 3 4 Results and Analysis As described in Section 2.2.1, we developed 16 different systems. Instead of using all these 16 different systems, we apply only the 6 best performing systems for system combination. Performance is measured on the devset. Table 1 reports the final evaluation results obtained on the test dataset. The best 6 systems a"
W15-3017,W14-3323,1,0.798583,"ve followed Point-wise Mutual InforOur system is designed with three basic components: (i) preprocessing, (ii) hybrid systems and (iii) system combination. 2.1 Preprocessing Data pre-processing plays a very crucial part in any data-driven approach. We carried out preprocessing in two steps: • Cleaning and clustering sentences based on sentence length. • Effective preprocessing of data in the form of explicit alignment of bilingual terminology (viz. NEs and MWEs). The preprocessing has been shown (cf. Section 2.1.2) to improve the output quality of the baseline PB-SMT system (Pal et al., 2013; Tan and Pal, 2014). 2.1.1 Corpus cleaning We utilized all the parallel training data provided by the WMT 2015 shared task organizers for English–German translation. The training data include Europarl, News Commentary and Common Crawl. The provided corpus is noisy and contains some non-German as well as non-English words and sentences. Therefore, we applied a Language Identifier (Shuyo, 2010) on both bilingual English–German parallel data and monolingual German corpora. We discarded those parallel sentences from the bilingual training data which were detected as belonging to some different language by the langua"
W15-3017,C96-2141,0,0.420797,"ressions (MWEs) and Named Entities (NEs) offer challenges within a language. MWEs are defined as idiosyncratic interpretations that cross word boundaries (Sag et al., 2002). Named entities on the other hand often consist of more than one word, so that they can be considered as a specific type of MWEs such as noun compounds (Jackendoff, 1997). Traditional approaches to word alignment such as IBM Models (Brown et al., 1993) are unable to tackle NEs and MWEs properly due to their inability to handle many-to-many alignments. In another wellknown word alignment approach, Hidden Markov Model (HMM: (Vogel et al., 1996)), the alignment probabilities depend on the alignment position of the previous word. It does not explicitly consider many-to-many alignment either. We address this alignment problem indirectly. The objective of the present work is threefold. Firstly, we would like to determine how treatment of MWEs as a single unit affects the overall MT quality (Pal et al., 2010; Pal et al., 2011). Secondly, whether a prior automatic NE aligned parallel corpus as well as example based parallel phrases can bring about any further improvement on top of that. And finally, whether system combination can provide"
W15-3017,W07-0734,0,\N,Missing
W15-3017,W09-0416,0,\N,Missing
W15-3017,W10-1720,1,\N,Missing
W15-3026,W06-1607,0,0.072029,"ning algorithms (described in Section 3) and the phraseextraction (Koehn et al., 2003). The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslrbidirectional) (Galley and Manning, 2008) method and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) optimised with k-best MIRA (Cherry and Foster, 2012) on a held out development set. After the parameters where sk1 = s1 . . . sk denotes a segmentation of the source and target sentences respectively into the sequences of phrases (ˆ ek1 = eˆ1 . . . eˆk ) and (fˆ1k = fˆ1 . . . fˆk ) such that (we set i0 = 0) in equation (6): k−1 11,272 1,000 1,817 EN 238,335 21,617 38,244 Table 1: Statistics. SEN: Sentences, EN: English and ES: Spanish λLM logP (eL 1) ∀1 ≤ k ≤ K, sk = (ik , bk , jk ), eˆk = ei +1 ...ei , fˆk ="
W15-3026,D08-1089,0,0.0720062,"nted with various maximum phrase lengths for the translation model and n–gram settings for the language model. We found that using a maximum phrase length of 7 for the translation model and a 5-gram language model produces the best results in terms of BLEU (Papineni et al., 2002) scores for our SAPE model. The other experimental settings were concerned with hybrid word alignment training algorithms (described in Section 3) and the phraseextraction (Koehn et al., 2003). The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslrbidirectional) (Galley and Manning, 2008) method and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) optimised with k-best MIRA (Cherry and Foster, 2012) on a held out development set. After the parameters where sk1 = s1 . . . sk denot"
W15-3026,W11-2123,0,0.102511,"rase length of 7 for the translation model and a 5-gram language model produces the best results in terms of BLEU (Papineni et al., 2002) scores for our SAPE model. The other experimental settings were concerned with hybrid word alignment training algorithms (described in Section 3) and the phraseextraction (Koehn et al., 2003). The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslrbidirectional) (Galley and Manning, 2008) method and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) optimised with k-best MIRA (Cherry and Foster, 2012) on a held out development set. After the parameters where sk1 = s1 . . . sk denotes a segmentation of the source and target sentences respectively into the sequences of phrases (ˆ ek1 = eˆ1 . . . eˆk ) and (fˆ1k ="
W15-3026,N03-1017,0,0.00755213,"tings The effectiveness of the present work is demonstrated by using the standard log-linear PBSMT model. For building our SAPE system, we experimented with various maximum phrase lengths for the translation model and n–gram settings for the language model. We found that using a maximum phrase length of 7 for the translation model and a 5-gram language model produces the best results in terms of BLEU (Papineni et al., 2002) scores for our SAPE model. The other experimental settings were concerned with hybrid word alignment training algorithms (described in Section 3) and the phraseextraction (Koehn et al., 2003). The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslrbidirectional) (Galley and Manning, 2008) method and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training"
W15-3026,J10-4005,0,0.0634225,"stemmed using the Porter stemmer • WN synonymy: maps if they are considered synonyms in WordNet If multiple alignments exist, METEOR selects the alignment for which the word order in the two strings is most similar (i.e. having fewest crossing alignment links). The final alignment is produced between H and R as the union of all stage alignments (e.g. exact, Porter stemming and WN synonymy). 3.2.3 Hybridization The hybrid word alignment method combines two different kinds of word alignment: the statistical alignment tools such as GIZA++ word alignment with grow-diag-final-and (GDFA) heuristic (Koehn, 2010) and SymGiza++ (JunczysDowmunt and Szał, 2012) and the Berkeley aligner (Liang et al., 2006), as well as edit distance-based aligners (Snover et al., 2006; Lavie and Agarwal, 2007). In order to combine these different word alignment tables (Pal et al., 2013) we used a mathematical union method. For the union method, we hypothesise that all alignments are correct. Duplicate entries are removed. Edit Distance-Based Word Alignment We use two different kind of edit distance based word aligners, where alignment is based on TER (Translation Edit Rate) and the METEOR word aligner. TER (Snover et al.,"
W15-3026,N12-1047,0,0.0310726,"rarchical, monotone, swap, left to right bidirectional (hier-mslrbidirectional) (Galley and Manning, 2008) method and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) optimised with k-best MIRA (Cherry and Foster, 2012) on a held out development set. After the parameters where sk1 = s1 . . . sk denotes a segmentation of the source and target sentences respectively into the sequences of phrases (ˆ ek1 = eˆ1 . . . eˆk ) and (fˆ1k = fˆ1 . . . fˆk ) such that (we set i0 = 0) in equation (6): k−1 11,272 1,000 1,817 EN 238,335 21,617 38,244 Table 1: Statistics. SEN: Sentences, EN: English and ES: Spanish λLM logP (eL 1) ∀1 ≤ k ≤ K, sk = (ik , bk , jk ), eˆk = ei +1 ...ei , fˆk = fb ...fj Data Table 1 presents the statistics of the training, development and test sets released for the English– Spanish SAPE Task orga"
W15-3026,N09-2055,0,0.121014,"Missing"
W15-3026,W07-0734,0,0.742474,"entence aligned training data provided by the organizers of the WMT2015 APE task. The training data consist of 11,272 parallel segments of English to Spanish MT translations as well as the post-edited translations of the MT output. The English source text, 217 the machine translated Spanish output and the corresponding post-edited version contain 238,335, 257,644 and 257,881 tokens respectively. The preprocessing of the training corpus was carried out first by stemming the Spanish MT output and the PE data using Freeling (Padr´o and Stanilovsky, 2012). 3.2 3.2.1 T ER(H, R) = METEOR Alignment (Lavie and Agarwal, 2007) is also an automatic MT evaluation metric which provides an alignment between hypothesis (here the MT output) and reference (here the PE translation). Given a pair of strings such as H and R to be compared, METEOR initially establishes a word alignment between them. The alignment is provided by a mapping method between the words in the hypothesis H an reference R transaltion, which is built incrementally by the following sequence of word-mapping modules: Hybrid Word Alignment Statistical Word Alignment GIZA++ (Och and Ney, 2003) is a statistical word alignment tool which implements maximum li"
W15-3026,N10-1062,0,0.0224964,"ting the MT decoder decide whether the errors should be corrected and about the method of correcting it. Parton et al. (2012) evaluated their approach with human evaluators and found that the adequacy of post-edited MT output improved both for rule-based and feedback APE. In terms of fluency the human evaluation has shown that adequacy increase in feedback APE is related to fluency but not for rule-based APE. Denkowski (2015) has developed a method for integrating in real time post-edited MT output into a translation model, by extracting for each input sentence a grammar. The method, based on Levenberg et al. (2010) and Lopez (2008), allows the indexing of the the source and post-edited MT output, as well as the union of the already existing sentence pairs with the new post-edited data. The system can also remember the rules that are consistent with the post-edited data. This way, rules learned from human corections can be preferred. The experiments Denkowski (2015) ran on from English into and out of Spanish and Arabic data show that the process of translating with an adaptive grammar improves performance on postediting tasks. ing enough to perform the task (Vela and van Genabith, 2015) . The aim of aut"
W15-3026,N07-1064,0,0.424423,"enkowski (2015) ran on from English into and out of Spanish and Arabic data show that the process of translating with an adaptive grammar improves performance on postediting tasks. ing enough to perform the task (Vela and van Genabith, 2015) . The aim of automatic post-editing (APE) is to improve the output of MT by post-processing it. One of the first approaches was the one introduced by Chen and Chen (1997) who proposed a combination of rule-based MT (RBMT) and statistical MT (SMT) systems aiming at merging the positive properties of each system type for a better machine translation output. Simard et al. (2007a) and Simard et al. (2007b) have shown how a PBSMT system can be used for automatic post-editing of an RBMT system for translations from English to French and French to English. Because RBMT systems tend to produce repetitive errors, they train a SMT system to correct errors, with the aim of reducing the postediting effort. The SMT system trains on the output of the RBMT system as the source language and the reference human translations as the target language. The evaluation of their system shows that the post-edited output had a better quality than the output of the RBMT system as well as th"
W15-3026,N06-1014,0,0.353606,"in WordNet If multiple alignments exist, METEOR selects the alignment for which the word order in the two strings is most similar (i.e. having fewest crossing alignment links). The final alignment is produced between H and R as the union of all stage alignments (e.g. exact, Porter stemming and WN synonymy). 3.2.3 Hybridization The hybrid word alignment method combines two different kinds of word alignment: the statistical alignment tools such as GIZA++ word alignment with grow-diag-final-and (GDFA) heuristic (Koehn, 2010) and SymGiza++ (JunczysDowmunt and Szał, 2012) and the Berkeley aligner (Liang et al., 2006), as well as edit distance-based aligners (Snover et al., 2006; Lavie and Agarwal, 2007). In order to combine these different word alignment tables (Pal et al., 2013) we used a mathematical union method. For the union method, we hypothesise that all alignments are correct. Duplicate entries are removed. Edit Distance-Based Word Alignment We use two different kind of edit distance based word aligners, where alignment is based on TER (Translation Edit Rate) and the METEOR word aligner. TER (Snover et al., 2006) was developed for automatic evaluation of MT outputs. TER can align two strings such"
W15-3026,W07-0728,0,0.135807,"enkowski (2015) ran on from English into and out of Spanish and Arabic data show that the process of translating with an adaptive grammar improves performance on postediting tasks. ing enough to perform the task (Vela and van Genabith, 2015) . The aim of automatic post-editing (APE) is to improve the output of MT by post-processing it. One of the first approaches was the one introduced by Chen and Chen (1997) who proposed a combination of rule-based MT (RBMT) and statistical MT (SMT) systems aiming at merging the positive properties of each system type for a better machine translation output. Simard et al. (2007a) and Simard et al. (2007b) have shown how a PBSMT system can be used for automatic post-editing of an RBMT system for translations from English to French and French to English. Because RBMT systems tend to produce repetitive errors, they train a SMT system to correct errors, with the aim of reducing the postediting effort. The SMT system trains on the output of the RBMT system as the source language and the reference human translations as the target language. The evaluation of their system shows that the post-edited output had a better quality than the output of the RBMT system as well as th"
W15-3026,2006.amta-papers.25,0,0.11155,"ignment for which the word order in the two strings is most similar (i.e. having fewest crossing alignment links). The final alignment is produced between H and R as the union of all stage alignments (e.g. exact, Porter stemming and WN synonymy). 3.2.3 Hybridization The hybrid word alignment method combines two different kinds of word alignment: the statistical alignment tools such as GIZA++ word alignment with grow-diag-final-and (GDFA) heuristic (Koehn, 2010) and SymGiza++ (JunczysDowmunt and Szał, 2012) and the Berkeley aligner (Liang et al., 2006), as well as edit distance-based aligners (Snover et al., 2006; Lavie and Agarwal, 2007). In order to combine these different word alignment tables (Pal et al., 2013) we used a mathematical union method. For the union method, we hypothesise that all alignments are correct. Duplicate entries are removed. Edit Distance-Based Word Alignment We use two different kind of edit distance based word aligners, where alignment is based on TER (Translation Edit Rate) and the METEOR word aligner. TER (Snover et al., 2006) was developed for automatic evaluation of MT outputs. TER can align two strings such as the reference (in this case the PE translation) and the hyp"
W15-3026,J03-1002,0,0.0404429,"anilovsky, 2012). 3.2 3.2.1 T ER(H, R) = METEOR Alignment (Lavie and Agarwal, 2007) is also an automatic MT evaluation metric which provides an alignment between hypothesis (here the MT output) and reference (here the PE translation). Given a pair of strings such as H and R to be compared, METEOR initially establishes a word alignment between them. The alignment is provided by a mapping method between the words in the hypothesis H an reference R transaltion, which is built incrementally by the following sequence of word-mapping modules: Hybrid Word Alignment Statistical Word Alignment GIZA++ (Och and Ney, 2003) is a statistical word alignment tool which implements maximum likelihood estimators for all the IBM-1 to IBM-5 models, a HMM alignment model as well as the IBM-6 model covering many to many alignments. GIZA++ facilitates fast development of statistical machine translation (SMT) systems. Like GIZA++, the Berkley Aligner (Liang et al., 2006) is also used to align words across sentence pairs. The Berkeley word aligner uses an extension of Cross Expectation Maximization and is jointly trained with HMM models. We use a third statistical word aligner called SymGiza++ (JunczysDowmunt and Szał, 2012)"
W15-3026,P03-1021,0,0.126312,"ordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslrbidirectional) (Galley and Manning, 2008) method and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) optimised with k-best MIRA (Cherry and Foster, 2012) on a held out development set. After the parameters where sk1 = s1 . . . sk denotes a segmentation of the source and target sentences respectively into the sequences of phrases (ˆ ek1 = eˆ1 . . . eˆk ) and (fˆ1k = fˆ1 . . . fˆk ) such that (we set i0 = 0) in equation (6): k−1 11,272 1,000 1,817 EN 238,335 21,617 38,244 Table 1: Statistics. SEN: Sentences, EN: English and ES: Spanish λLM logP (eL 1) ∀1 ≤ k ≤ K, sk = (ik , bk , jk ), eˆk = ei +1 ...ei , fˆk = fb ...fj Data Table 1 presents the statistics of the training, development and test"
W15-3026,W15-4921,1,0.884399,"Missing"
W15-3026,padro-stanilovsky-2012-freeling,0,0.0343196,"Missing"
W15-3026,W14-0314,1,0.613986,"ection of repetitive errors in the MT output, various automatic or semi-automatic post-processing or automatic PE techniques have been developed. Although MT output needs to be post-edited by humans to produce publishable quality translation (Roturier, 2009; TAUS/CNGL Report, 2010), it is faster and cheaper to post-edit MT output than to perform human translation from scratch. In some cases, recent studies have shown that the quality of MT output plus PE can exceed the quality of human translation (Fiederer and O’Brien, 2009; Koehn, 2009; De Palma and Kelly, 2009) as well as the productivity (Zampieri and Vela, 2014). Aimed at cost-effective and timesaving use of MT, the PE process needs to be further optimised (TAUS/CNGL Report, 2010). Post-editing can be also used as a MT evaluation method, implying at least source and target language skills, different from ranking, that does nor require specific skills, a homogeneous group of evaluators beIntroduction In this paper, we present the submission of Saarland University (USAAR) to the WMT2015 APE task. The system combines a hybrid word alignment system implementation with a monolingual PBSMT for the language pair English-Spanish (EN-ES), translating from Eng"
W15-3026,W13-2814,1,0.716633,"links). The final alignment is produced between H and R as the union of all stage alignments (e.g. exact, Porter stemming and WN synonymy). 3.2.3 Hybridization The hybrid word alignment method combines two different kinds of word alignment: the statistical alignment tools such as GIZA++ word alignment with grow-diag-final-and (GDFA) heuristic (Koehn, 2010) and SymGiza++ (JunczysDowmunt and Szał, 2012) and the Berkeley aligner (Liang et al., 2006), as well as edit distance-based aligners (Snover et al., 2006; Lavie and Agarwal, 2007). In order to combine these different word alignment tables (Pal et al., 2013) we used a mathematical union method. For the union method, we hypothesise that all alignments are correct. Duplicate entries are removed. Edit Distance-Based Word Alignment We use two different kind of edit distance based word aligners, where alignment is based on TER (Translation Edit Rate) and the METEOR word aligner. TER (Snover et al., 2006) was developed for automatic evaluation of MT outputs. TER can align two strings such as the reference (in this case the PE translation) and the hypothesis (MT output). In the our work, the reference string has been chosen to be the confusion network s"
W15-3026,P02-1040,0,0.100602,"single where h phrase-pair. It thus follows (8): M X m=1 λm K X ˆ m (fˆk , eˆk , sk ) = h k=1 ˆ= where h K X k=1 PK k=1 Tokens ES-MT 257,644 23,213 40,925 ES-PE 257,881 23,098 – Experimental Settings The effectiveness of the present work is demonstrated by using the standard log-linear PBSMT model. For building our SAPE system, we experimented with various maximum phrase lengths for the translation model and n–gram settings for the language model. We found that using a maximum phrase length of 7 for the translation model and a 5-gram language model produces the best results in terms of BLEU (Papineni et al., 2002) scores for our SAPE model. The other experimental settings were concerned with hybrid word alignment training algorithms (described in Section 3) and the phraseextraction (Koehn et al., 2003). The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslrbidirectional) (Galley and Manning, 2008) method and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To allevia"
W15-3026,C10-2109,0,0.0179871,"ng raw MT output, before performing human post-editing on it. The objective is to decreases the amount of errors produced by the MT systems, achieving in the end a productivity increase in the translation process. 216 Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 216–221, c Lisboa, Portugal, 17-18 September 2015. 2015 Association for Computational Linguistics. methodologies, a rule-abased APE and a feedback APE. The rule-based APE performs either insertions or replacement to address an identified error. The feedback APE, an approach similar to the one proposed by Parton and McKeown (2010), passes the possible correction to the MT system, letting the MT decoder decide whether the errors should be corrected and about the method of correcting it. Parton et al. (2012) evaluated their approach with human evaluators and found that the adequacy of post-edited MT output improved both for rule-based and feedback APE. In terms of fluency the human evaluation has shown that adequacy increase in feedback APE is related to fluency but not for rule-based APE. Denkowski (2015) has developed a method for integrating in real time post-edited MT output into a translation model, by extracting fo"
W15-3026,2012.eamt-1.34,0,0.114117,"Missing"
W15-3026,W12-3146,0,0.195552,"Missing"
W15-3026,W11-2152,0,\N,Missing
W15-3026,O96-2005,0,\N,Missing
W15-3026,2015.eamt-1.22,1,\N,Missing
W15-5206,2013.mtsummit-wptp.13,0,0.122457,"2011; Gupta and Orăsan, 2014; Gupta et al., 2015), as well as syntax (Clark, 2002; Gotti et al., 2005) in this process. Another recent direction that research in CAT tools is taking is the integration of both TM and machine translation (MT) output (He et al., 2010; Kanavos and Kartsaklis, 2010). With the improvement of state-ofthe-art MT systems, MT output is no longer used just for gisting, it is now being used in real-world translation projects. Taking advantage of these improvements, CAT tools such as MateCat1 , have been integrating MT output along TMs in the list of suitable suggestions (Cettolo et al., 2013). In this paper we are concerned both with retrieval and with the post-editing interface of TMs. We present a new CAT tool called CATaLog2 , which is language pair independent and allows users to upload their own memories in This paper explores a new TM-based CAT tool entitled CATaLog. New features have been integrated into the tool which aim to improve post-editing both in terms of performance and productivity. One of the new features of CATaLog is a color coding scheme that is based on the similarity between a particular input sentence and the segments retrieved from the TM. This color codin"
W15-5206,2012.amta-papers.22,0,0.124202,"presented using English - Bengali data. 2 ments and mismatched portions are translated by an SMT system to ﬁll in the gaps. Even though this paper describes work in progress, our aim is to develop a tool that is as intuitive as possible for end users and this should have direct impact on translators’ performance and productivity. In the recent years, several productive studies were also carried out measuring diﬀerent aspects of the translation process such as cognitive load, eﬀort, time, quality as well as other criteria (Bowker, 2005; O’Brien, 2006; Guerberof, 2009; Plitt and Masselot, 2010; Federico et al., 2012; Guerberof, 2012; Zampieri and Vela, 2014). User studies were taken into account when developing CATaLog as our main motivation is to improve the translation workﬂow. In this paper, however, we do not yet explore the impact of our tool in the translation process, because the functionalities required for this kind of study are currently under development in CATaLog. Future work aims to investigate the impact of the new features we are proposing on the translator’s work. Related Work CAT tools have become very popular in the translation and localization industries in the last two decades. They"
W15-5206,2014.eamt-1.2,0,0.105775,"retrieved segments suggested by the CAT tool or translating new segments from scratch. This process is done iteratively and every new translation increases the size of the translation memory making it both more useful and more helpful to future translations. Although in the ﬁrst place it might sound very simplistic, the process of matching source and target segments, and retrieving translated segments from the TM is far from trivial. To improve the retrieval engines, researchers have been working on diﬀerent ways of incorporating semantic knowledge, such as paraphrasing (Utiyama et al., 2011; Gupta and Orăsan, 2014; Gupta et al., 2015), as well as syntax (Clark, 2002; Gotti et al., 2005) in this process. Another recent direction that research in CAT tools is taking is the integration of both TM and machine translation (MT) output (He et al., 2010; Kanavos and Kartsaklis, 2010). With the improvement of state-ofthe-art MT systems, MT output is no longer used just for gisting, it is now being used in real-world translation projects. Taking advantage of these improvements, CAT tools such as MateCat1 , have been integrating MT output along TMs in the list of suitable suggestions (Cettolo et al., 2013). In th"
W15-5206,2009.mtsummit-papers.14,0,0.0410983,"achines) to decide which output (TM or MT) is most suitable to use for post-editing. Work on integrating MT with TM has also been done to make TM output more suitable for post-editing diminishing translators’ eﬀort (Kanavos and Kartsaklis, 2010). Another study presented a Dynamic Translation Memory which identiﬁes the longest common subsequence in the the closest matching source segment, identiﬁes the corresponding subsequence in its translation, and dynamically adds this source-target phrase pair to the phrase table of a phrasebased ststistical MT (PB-SMT) system (Biçici and Dymetman, 2008). Simard and Isabelle (2009) reported a work on integration of PB-SMT with TM technology in a CAT environment in which the PBSMT system exploits the most similar matches by making use of TM-based feature functions. Koehn and Senellart (2010) reported another MT-TM integration strategy where TM is used to retrieve matching source seg3 System Description We demonstrate the functionalities and features of CATaLog in an English - Bengali translation task. The TM database consists of English sentences taken from BTEC3 (Basic Travel Expression Corpus) corpus and their Bengali translations4 . Unseen input or test segments are p"
W15-5206,W15-4905,1,0.742271,"Missing"
W15-5206,W09-0441,0,0.0370839,"is used to retrieve matching source seg3 System Description We demonstrate the functionalities and features of CATaLog in an English - Bengali translation task. The TM database consists of English sentences taken from BTEC3 (Basic Travel Expression Corpus) corpus and their Bengali translations4 . Unseen input or test segments are provided to the post-editing tool and the tool matches each of the input segments to the most similar segments contained in the TM. TM segments are then ranked according their the similarity to the test sentence using the popular Translation Error Rate (TER) metric (Snover et al., 2009). The top 5 most similar segments are chosen and presented to the translator ordered by their similarity. One very important aspect of computing similarity is alignment. Each test (input) segment in the source language (SL) is aligned with the reference SL sentences in the TM and each SL sentence in the TM is aligned to its respective translation. From these two sets 3 BTEC corpus contains tourism-related sentences similar to those that are usually found in phrase books for tourists going abroad 4 Work in progress. 37 of alignments we apply a method to ﬁnd out which parts of the translation ar"
W15-5206,P10-1064,1,0.924209,"Missing"
W15-5206,2011.eamt-1.12,0,0.0128172,"udy are currently under development in CATaLog. Future work aims to investigate the impact of the new features we are proposing on the translator’s work. Related Work CAT tools have become very popular in the translation and localization industries in the last two decades. They are used by many language service providers, freelance translators to improve translation quality and to increase translator’s productivity (Lagoudaki, 2008). Although the work presented in this paper focuses on TM, it should also be noted that there were many studies on MT post-editing published in the last few years (Specia, 2011; Green et al., 2013; Green, 2014) and as mentioned in the last section, one of the recent trends is the development of hybrid systems that are able to combine MT with TM output. Therefore work on MT post-editing presents signiﬁcant overlap with state-of-the-art CAT tools and to what we propose in this paper. Substantial work have also been carried out on improving translation recommendation systems which recommends post-editors either to use TM output or MT output (He et al., 2010). To achieve good performance with this kind of systems, researchers typically train a binary classiﬁer (e.g., Su"
W15-5206,2010.jec-1.3,0,0.508262,"lthough in the ﬁrst place it might sound very simplistic, the process of matching source and target segments, and retrieving translated segments from the TM is far from trivial. To improve the retrieval engines, researchers have been working on diﬀerent ways of incorporating semantic knowledge, such as paraphrasing (Utiyama et al., 2011; Gupta and Orăsan, 2014; Gupta et al., 2015), as well as syntax (Clark, 2002; Gotti et al., 2005) in this process. Another recent direction that research in CAT tools is taking is the integration of both TM and machine translation (MT) output (He et al., 2010; Kanavos and Kartsaklis, 2010). With the improvement of state-ofthe-art MT systems, MT output is no longer used just for gisting, it is now being used in real-world translation projects. Taking advantage of these improvements, CAT tools such as MateCat1 , have been integrating MT output along TMs in the list of suitable suggestions (Cettolo et al., 2013). In this paper we are concerned both with retrieval and with the post-editing interface of TMs. We present a new CAT tool called CATaLog2 , which is language pair independent and allows users to upload their own memories in This paper explores a new TM-based CAT tool entit"
W15-5206,2011.mtsummit-papers.37,0,0.259019,"editors by correcting retrieved segments suggested by the CAT tool or translating new segments from scratch. This process is done iteratively and every new translation increases the size of the translation memory making it both more useful and more helpful to future translations. Although in the ﬁrst place it might sound very simplistic, the process of matching source and target segments, and retrieving translated segments from the TM is far from trivial. To improve the retrieval engines, researchers have been working on diﬀerent ways of incorporating semantic knowledge, such as paraphrasing (Utiyama et al., 2011; Gupta and Orăsan, 2014; Gupta et al., 2015), as well as syntax (Clark, 2002; Gotti et al., 2005) in this process. Another recent direction that research in CAT tools is taking is the integration of both TM and machine translation (MT) output (He et al., 2010; Kanavos and Kartsaklis, 2010). With the improvement of state-ofthe-art MT systems, MT output is no longer used just for gisting, it is now being used in real-world translation projects. Taking advantage of these improvements, CAT tools such as MateCat1 , have been integrating MT output along TMs in the list of suitable suggestions (Cett"
W15-5206,W14-0314,1,0.778874,"2 ments and mismatched portions are translated by an SMT system to ﬁll in the gaps. Even though this paper describes work in progress, our aim is to develop a tool that is as intuitive as possible for end users and this should have direct impact on translators’ performance and productivity. In the recent years, several productive studies were also carried out measuring diﬀerent aspects of the translation process such as cognitive load, eﬀort, time, quality as well as other criteria (Bowker, 2005; O’Brien, 2006; Guerberof, 2009; Plitt and Masselot, 2010; Federico et al., 2012; Guerberof, 2012; Zampieri and Vela, 2014). User studies were taken into account when developing CATaLog as our main motivation is to improve the translation workﬂow. In this paper, however, we do not yet explore the impact of our tool in the translation process, because the functionalities required for this kind of study are currently under development in CATaLog. Future work aims to investigate the impact of the new features we are proposing on the translator’s work. Related Work CAT tools have become very popular in the translation and localization industries in the last two decades. They are used by many language service providers"
W15-5206,2010.jec-1.4,0,0.0590105,"t (Kanavos and Kartsaklis, 2010). Another study presented a Dynamic Translation Memory which identiﬁes the longest common subsequence in the the closest matching source segment, identiﬁes the corresponding subsequence in its translation, and dynamically adds this source-target phrase pair to the phrase table of a phrasebased ststistical MT (PB-SMT) system (Biçici and Dymetman, 2008). Simard and Isabelle (2009) reported a work on integration of PB-SMT with TM technology in a CAT environment in which the PBSMT system exploits the most similar matches by making use of TM-based feature functions. Koehn and Senellart (2010) reported another MT-TM integration strategy where TM is used to retrieve matching source seg3 System Description We demonstrate the functionalities and features of CATaLog in an English - Bengali translation task. The TM database consists of English sentences taken from BTEC3 (Basic Travel Expression Corpus) corpus and their Bengali translations4 . Unseen input or test segments are provided to the post-editing tool and the tool matches each of the input segments to the most similar segments contained in the TM. TM segments are then ranked according their the similarity to the test sentence us"
W15-5206,2008.amta-srw.4,0,0.397037,"e the translation workﬂow. In this paper, however, we do not yet explore the impact of our tool in the translation process, because the functionalities required for this kind of study are currently under development in CATaLog. Future work aims to investigate the impact of the new features we are proposing on the translator’s work. Related Work CAT tools have become very popular in the translation and localization industries in the last two decades. They are used by many language service providers, freelance translators to improve translation quality and to increase translator’s productivity (Lagoudaki, 2008). Although the work presented in this paper focuses on TM, it should also be noted that there were many studies on MT post-editing published in the last few years (Specia, 2011; Green et al., 2013; Green, 2014) and as mentioned in the last section, one of the recent trends is the development of hybrid systems that are able to combine MT with TM output. Therefore work on MT post-editing presents signiﬁcant overlap with state-of-the-art CAT tools and to what we propose in this paper. Substantial work have also been carried out on improving translation recommendation systems which recommends post"
W15-5206,N06-1014,0,0.0673427,"he top candidates by the TM. Figure 1 presents a snapshot of CATaLog. Color Coding Among the top 5 choices, post-editor selects one reference translation to do the post-editing task. To make that decision process easy, we color code the matched parts and unmatched parts in each reference translation. Green portion implies that they are matched fragments and red portion implies a mismatch. The alignments between the TM source sentences and their corresponding translations are generated using GIZA++ (Och and Ney, 2003) in the present work. However, any other word aligner, e.g., Berkley Aligner (Liang et al., 2006), could be used to produce this alignment. The alignment between the matched source segment and the corresponding translation, together with the TER alignment between the input sentence and the matched source segment, are used to generate the aforementioned color coding between selected source and target sentences. The GIZA++ alignment ﬁle is directly fed into the present TM tool. Given below is an example TM sentence pair along with the corresponding word alignment input to the TM. Input: you gave me wrong number . • English: we want to have a table near the window . Source Matches: 1. you ga"
W15-5206,J03-1002,0,0.00872292,"ssign a higher cost for insertion than deletion, and hence such sentences will not be shown as the top candidates by the TM. Figure 1 presents a snapshot of CATaLog. Color Coding Among the top 5 choices, post-editor selects one reference translation to do the post-editing task. To make that decision process easy, we color code the matched parts and unmatched parts in each reference translation. Green portion implies that they are matched fragments and red portion implies a mismatch. The alignments between the TM source sentences and their corresponding translations are generated using GIZA++ (Och and Ney, 2003) in the present work. However, any other word aligner, e.g., Berkley Aligner (Liang et al., 2006), could be used to produce this alignment. The alignment between the matched source segment and the corresponding translation, together with the TER alignment between the input sentence and the matched source segment, are used to generate the aforementioned color coding between selected source and target sentences. The GIZA++ alignment ﬁle is directly fed into the present TM tool. Given below is an example TM sentence pair along with the corresponding word alignment input to the TM. Input: you gave"
W15-5206,2012.amta-papers.26,0,0.0145925,". | D S S || S | | | we - would like a table by the window . For ﬁnding out the similar and dissimilar parts between the test segment and a matching TM segment, we use TER alignments. TER is an error metric and it gives an edit ratio (often referred to as edit rate or error rate) in terms of how much editing is required to convert a sentence into another with respect to the length of the ﬁrst sentence. Allowable edit operations include insert, delete, substitute and shift. We use the TER metric (using tercom-7.2515 ) to ﬁnd the edit rate between a test sentence and the TM reference sentences. Simard and Fujita (2012) ﬁrst proposed the use of MT evaluation metrics as similarity functions in implementing TM functionality. They experimented with several MT evaluation metrics, viz. BLEU, NIST, Meteor and TER, and studied their behaviors on TM performance. In the TM tool presented here we use TER as the similarity metric as it is very fast and lightweight and it directly mimics the human post-editing eﬀort. Moreover, the tercom-7.251 package also produces the alignments between the sentence pair from which it is very easy to identify which portions in the matching segment match with the input sentence and whic"
W15-5206,2015.eamt-1.6,1,\N,Missing
W16-2333,D11-1033,0,0.150111,", large amount of additional out-domain data may bias the resultant distribution towards the out-domain. In practice, 442 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 442–448, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics 2 3 Related Work System Description 3.1 Data selection Approach Among the different approaches proposed for data selection, the two most popular and successful methodologies are based on monolingual crossentropy difference (Moore and Lewis, 2010) and bilingual cross-entropy difference (Axelrod et al., 2011). The data selection approach taken in the present work is also motivated by the bilingual cross-entropy difference (Axelrod et al., 2011) based data selection. However, instead of using bilingual cross-entropy difference, we applied bilingual cross-perplexity difference to model our data selection process. The difference in crossentropy is computed on two language models (LM); the domain-specific LM is estimated from the entire in-domain corpus (lmin ) and the second LM (lmo ) is estimated from the out-domain corpus. Mathematically, the cross-entropy H(Plm ) of language model probability Plm"
W16-2333,W08-0321,0,0.0258029,"sj − tj ] is calculated based on Equation 2. H(Plm ) = − Koehn et al. (2007) used multiple decoding paths for combining multiple domain-specific translation tables in the state-of-the-art PB-SMT decoder MOSES. Banerjee et al. (2013) combined an in-domain model (translation and reordering model) with an out-of-domain model into MOSES and they derived log-linear features to distinguish between phrases of multiple domains by applying the data-source indicator features and showed modest improvement in translation quality. score = |P Pinsl (sj ) − P Posl (sj )| + |P Pintl (tj ) − P Potl (tj ) |(2) Bach et al. (2008) suggested that sentences may be weighted by how much it matches with the target domain. A comparison among different domain adaptation methods for different subject matters in patent translation was carried out by (Ceaus¸fu et al., 2011) which led to a small gain over the baseline. Subsequently, sentence pairs [s − t] from the out-domain corpus (o) are ranked based on this score. 3.2 Interpolation Approach To combine multiple translation and language models, a common approach is to linearly interpolate them. The language model interpolation weights are automatically learnt by minimizing the p"
W16-2333,2011.mtsummit-papers.32,1,0.872589,"Missing"
W16-2333,N03-1017,0,0.00959327,"performance of the in-domain MT system. The following subsections describe the datasets used for the experiments, detailed experimental settings and systematic evaluation on both the development set and test set. 4.1 4.2 Experimental Settings We used the standard log-linear PB-SMT model for our experiments. All the experiments were carried out using a maximum phrase length of 7 for the translation model and 5-gram language models. The other experimental settings involved word alignment model between EN–DE trained with Berkeley Aligner (Liang et al., 2006). The phraseextraction heuristics of (Koehn et al., 2003) were used to build the phrase-based SMT systems. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslr-bidirectional) (Galley and Manning, 2008) method and conditioned on both the source and target languages. The 5-gram language models were built using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e., 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the Good-Turing smoothing technique (Foster et al., 2006). System tuning w"
W16-2333,2013.mtsummit-papers.13,1,0.874847,"Missing"
W16-2333,E12-1045,0,0.0171699,"the domain-specific LM is estimated from the entire in-domain corpus (lmin ) and the second LM (lmo ) is estimated from the out-domain corpus. Mathematically, the cross-entropy H(Plm ) of language model probability Plm is defined as in Equation 1 considering a k-gram language model. Koehn (2004; Koehn (2005) first proposed domain adaptation in SMT by integrating terminological lexicons in the translation model, as a result of which there was a significant reduction in word error rate (WER). Over the last decade, many researchers (Foster and Kuhn, 2007; Duh et al., 2010; Banerjee et al., 2011; Bisazza and Federico, 2012; Sennrich, 2012; Sennrich et al., 2013; Haddow and Koehn, 2012) investigated the problem of combining multi-domain datasets. To construct a good domain-specific language model, sentences which are similar to the target domain should be included (Sethy et al., 2006) in the monolingual target language corupus on which the language model is trained. L¨u et al. (2007) identified those sentences using the tf/idf method and they increased the count of such sentences. Domain adaptation in MT have been explored in many different directions, ranging from adapating language models and translation model"
W16-2333,W04-3250,0,0.0396345,"otivated by the bilingual cross-entropy difference (Axelrod et al., 2011) based data selection. However, instead of using bilingual cross-entropy difference, we applied bilingual cross-perplexity difference to model our data selection process. The difference in crossentropy is computed on two language models (LM); the domain-specific LM is estimated from the entire in-domain corpus (lmin ) and the second LM (lmo ) is estimated from the out-domain corpus. Mathematically, the cross-entropy H(Plm ) of language model probability Plm is defined as in Equation 1 considering a k-gram language model. Koehn (2004; Koehn (2005) first proposed domain adaptation in SMT by integrating terminological lexicons in the translation model, as a result of which there was a significant reduction in word error rate (WER). Over the last decade, many researchers (Foster and Kuhn, 2007; Duh et al., 2010; Banerjee et al., 2011; Bisazza and Federico, 2012; Sennrich, 2012; Sennrich et al., 2013; Haddow and Koehn, 2012) investigated the problem of combining multi-domain datasets. To construct a good domain-specific language model, sentences which are similar to the target domain should be included (Sethy et al., 2006) in"
W16-2333,2005.mtsummit-papers.11,0,0.0178143,"he bilingual cross-entropy difference (Axelrod et al., 2011) based data selection. However, instead of using bilingual cross-entropy difference, we applied bilingual cross-perplexity difference to model our data selection process. The difference in crossentropy is computed on two language models (LM); the domain-specific LM is estimated from the entire in-domain corpus (lmin ) and the second LM (lmo ) is estimated from the out-domain corpus. Mathematically, the cross-entropy H(Plm ) of language model probability Plm is defined as in Equation 1 considering a k-gram language model. Koehn (2004; Koehn (2005) first proposed domain adaptation in SMT by integrating terminological lexicons in the translation model, as a result of which there was a significant reduction in word error rate (WER). Over the last decade, many researchers (Foster and Kuhn, 2007; Duh et al., 2010; Banerjee et al., 2011; Bisazza and Federico, 2012; Sennrich, 2012; Sennrich et al., 2013; Haddow and Koehn, 2012) investigated the problem of combining multi-domain datasets. To construct a good domain-specific language model, sentences which are similar to the target domain should be included (Sethy et al., 2006) in the monolingu"
W16-2333,2011.eamt-1.5,0,0.0592153,"Missing"
W16-2333,W07-0734,0,0.0408698,"e performed smoothing of the phrase table using the Good-Turing smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) on a held out development set (Batch1 in Table 3) of size 1,000 sentences provided by the WMT-2016 task organizers. After the parameters were tuned, decoding was carried out on the held out development test set (Batch2 in Table 3) as well as test set released by the shared task organizers. We evaluated the systems using three well known automatic MT evaluation metrics: BLEU (Papineni et al., 2002), METEOR (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). The evaluation results of our baseline systems trained on in-domain and out-domain data are reported in Table 3. Datasets In-domain Data: The detailed statistics of indomain data is reported in Table 1. We considered all the data provided by the WMT-2016 organizers for the IT translation task. We combined all data and performed cleaning in two steps: (i) Cleaning1: following the cleaning process described in (Pal et al., 2015), and (ii) Cleaning 2: using the Moses (Koehn et al., 2007) corpus cleaning scripts with minimum and maximum number of tokens set to 1 and"
W16-2333,N06-1014,0,0.0556417,"an them. We also use out of domain data to accelerate the performance of the in-domain MT system. The following subsections describe the datasets used for the experiments, detailed experimental settings and systematic evaluation on both the development set and test set. 4.1 4.2 Experimental Settings We used the standard log-linear PB-SMT model for our experiments. All the experiments were carried out using a maximum phrase length of 7 for the translation model and 5-gram language models. The other experimental settings involved word alignment model between EN–DE trained with Berkeley Aligner (Liang et al., 2006). The phraseextraction heuristics of (Koehn et al., 2003) were used to build the phrase-based SMT systems. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslr-bidirectional) (Galley and Manning, 2008) method and conditioned on both the source and target languages. The 5-gram language models were built using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e., 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the Good-Turing s"
W16-2333,2010.iwslt-papers.5,0,0.0226244,"is computed on two language models (LM); the domain-specific LM is estimated from the entire in-domain corpus (lmin ) and the second LM (lmo ) is estimated from the out-domain corpus. Mathematically, the cross-entropy H(Plm ) of language model probability Plm is defined as in Equation 1 considering a k-gram language model. Koehn (2004; Koehn (2005) first proposed domain adaptation in SMT by integrating terminological lexicons in the translation model, as a result of which there was a significant reduction in word error rate (WER). Over the last decade, many researchers (Foster and Kuhn, 2007; Duh et al., 2010; Banerjee et al., 2011; Bisazza and Federico, 2012; Sennrich, 2012; Sennrich et al., 2013; Haddow and Koehn, 2012) investigated the problem of combining multi-domain datasets. To construct a good domain-specific language model, sentences which are similar to the target domain should be included (Sethy et al., 2006) in the monolingual target language corupus on which the language model is trained. L¨u et al. (2007) identified those sentences using the tf/idf method and they increased the count of such sentences. Domain adaptation in MT have been explored in many different directions, ranging f"
W16-2333,W07-0717,0,0.0383431,"erence in crossentropy is computed on two language models (LM); the domain-specific LM is estimated from the entire in-domain corpus (lmin ) and the second LM (lmo ) is estimated from the out-domain corpus. Mathematically, the cross-entropy H(Plm ) of language model probability Plm is defined as in Equation 1 considering a k-gram language model. Koehn (2004; Koehn (2005) first proposed domain adaptation in SMT by integrating terminological lexicons in the translation model, as a result of which there was a significant reduction in word error rate (WER). Over the last decade, many researchers (Foster and Kuhn, 2007; Duh et al., 2010; Banerjee et al., 2011; Bisazza and Federico, 2012; Sennrich, 2012; Sennrich et al., 2013; Haddow and Koehn, 2012) investigated the problem of combining multi-domain datasets. To construct a good domain-specific language model, sentences which are similar to the target domain should be included (Sethy et al., 2006) in the monolingual target language corupus on which the language model is trained. L¨u et al. (2007) identified those sentences using the tf/idf method and they increased the count of such sentences. Domain adaptation in MT have been explored in many different dir"
W16-2333,D07-1036,0,0.0628601,"Missing"
W16-2333,W06-1607,0,0.20109,"esearch Center for Artificial Intelligence (DFKI), Germany {pahari.koushik,alapan.cse}@gmail.com, sudip.naskar@jdvu.ac.in, sivaji cse ju@yahoo.com {santanu.pal, josef.vangenabith}@uni-saarland.de Abstract it is often difficult to obtain sufficient amount of in-domain parallel data to train a system which can provide good performance in a specific domain. The performance of an in-domain model can be improved by selecting a subset from the out-domain data which is very similar to the indomain data (Matsoukas et al., 2009; Moore and Lewis, 2010), or by re-weighting the probability distributions (Foster et al., 2006; Sennrich et al., 2013) in favor of the in-domain data. This paper presents the JU-USAAR English–German domain adaptive machine translation (MT) system submitted to the IT domain translation task organized in WMT-2016 . Our system brings improvements over the in-domain baseline system by incorporating out-domain knowledge. We applied two methodologies to accelerate the performance of our in-domain MT system: (i) additional training material extraction from out-domain data using data selection method, and (ii) language model and translation model adaptation through interpolation. Our primary s"
W16-2333,D09-1074,0,0.060014,"Missing"
W16-2333,D08-1089,0,0.0115611,"set and test set. 4.1 4.2 Experimental Settings We used the standard log-linear PB-SMT model for our experiments. All the experiments were carried out using a maximum phrase length of 7 for the translation model and 5-gram language models. The other experimental settings involved word alignment model between EN–DE trained with Berkeley Aligner (Liang et al., 2006). The phraseextraction heuristics of (Koehn et al., 2003) were used to build the phrase-based SMT systems. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslr-bidirectional) (Galley and Manning, 2008) method and conditioned on both the source and target languages. The 5-gram language models were built using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e., 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the Good-Turing smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) on a held out development set (Batch1 in Table 3) of size 1,000 sentences provided by the WMT-2016 task organizers. After the paramete"
W16-2333,P10-2041,0,0.539223,"ata, India 3 Universit¨at des Saarlandes, Saarbr¨ucken, Germany 4 German Research Center for Artificial Intelligence (DFKI), Germany {pahari.koushik,alapan.cse}@gmail.com, sudip.naskar@jdvu.ac.in, sivaji cse ju@yahoo.com {santanu.pal, josef.vangenabith}@uni-saarland.de Abstract it is often difficult to obtain sufficient amount of in-domain parallel data to train a system which can provide good performance in a specific domain. The performance of an in-domain model can be improved by selecting a subset from the out-domain data which is very similar to the indomain data (Matsoukas et al., 2009; Moore and Lewis, 2010), or by re-weighting the probability distributions (Foster et al., 2006; Sennrich et al., 2013) in favor of the in-domain data. This paper presents the JU-USAAR English–German domain adaptive machine translation (MT) system submitted to the IT domain translation task organized in WMT-2016 . Our system brings improvements over the in-domain baseline system by incorporating out-domain knowledge. We applied two methodologies to accelerate the performance of our in-domain MT system: (i) additional training material extraction from out-domain data using data selection method, and (ii) language mode"
W16-2333,W12-3154,0,0.0151824,"s (lmin ) and the second LM (lmo ) is estimated from the out-domain corpus. Mathematically, the cross-entropy H(Plm ) of language model probability Plm is defined as in Equation 1 considering a k-gram language model. Koehn (2004; Koehn (2005) first proposed domain adaptation in SMT by integrating terminological lexicons in the translation model, as a result of which there was a significant reduction in word error rate (WER). Over the last decade, many researchers (Foster and Kuhn, 2007; Duh et al., 2010; Banerjee et al., 2011; Bisazza and Federico, 2012; Sennrich, 2012; Sennrich et al., 2013; Haddow and Koehn, 2012) investigated the problem of combining multi-domain datasets. To construct a good domain-specific language model, sentences which are similar to the target domain should be included (Sethy et al., 2006) in the monolingual target language corupus on which the language model is trained. L¨u et al. (2007) identified those sentences using the tf/idf method and they increased the count of such sentences. Domain adaptation in MT have been explored in many different directions, ranging from adapating language models and translation models to alignment adaptation approach to improve domainspecific wor"
W16-2333,P03-1021,0,0.00947555,"rdering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslr-bidirectional) (Galley and Manning, 2008) method and conditioned on both the source and target languages. The 5-gram language models were built using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e., 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the Good-Turing smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) on a held out development set (Batch1 in Table 3) of size 1,000 sentences provided by the WMT-2016 task organizers. After the parameters were tuned, decoding was carried out on the held out development test set (Batch2 in Table 3) as well as test set released by the shared task organizers. We evaluated the systems using three well known automatic MT evaluation metrics: BLEU (Papineni et al., 2002), METEOR (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). The evaluation results of our baseline systems trained on in-domain and out-domain data are reported in Table 3. Datasets In-domain D"
W16-2333,W11-2123,0,0.0263772,"rried out using a maximum phrase length of 7 for the translation model and 5-gram language models. The other experimental settings involved word alignment model between EN–DE trained with Berkeley Aligner (Liang et al., 2006). The phraseextraction heuristics of (Koehn et al., 2003) were used to build the phrase-based SMT systems. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslr-bidirectional) (Galley and Manning, 2008) method and conditioned on both the source and target languages. The 5-gram language models were built using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e., 1). To alleviate this shortcoming, we performed smoothing of the phrase table using the Good-Turing smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) on a held out development set (Batch1 in Table 3) of size 1,000 sentences provided by the WMT-2016 task organizers. After the parameters were tuned, decoding was carried out on the held out development test set (Batch2 in Table 3) as well as test set released by th"
W16-2333,P02-1040,0,0.099321,"To alleviate this shortcoming, we performed smoothing of the phrase table using the Good-Turing smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) on a held out development set (Batch1 in Table 3) of size 1,000 sentences provided by the WMT-2016 task organizers. After the parameters were tuned, decoding was carried out on the held out development test set (Batch2 in Table 3) as well as test set released by the shared task organizers. We evaluated the systems using three well known automatic MT evaluation metrics: BLEU (Papineni et al., 2002), METEOR (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). The evaluation results of our baseline systems trained on in-domain and out-domain data are reported in Table 3. Datasets In-domain Data: The detailed statistics of indomain data is reported in Table 1. We considered all the data provided by the WMT-2016 organizers for the IT translation task. We combined all data and performed cleaning in two steps: (i) Cleaning1: following the cleaning process described in (Pal et al., 2015), and (ii) Cleaning 2: using the Moses (Koehn et al., 2007) corpus cleaning scripts with minimum and max"
W16-2333,P13-1082,0,0.0831355,"tificial Intelligence (DFKI), Germany {pahari.koushik,alapan.cse}@gmail.com, sudip.naskar@jdvu.ac.in, sivaji cse ju@yahoo.com {santanu.pal, josef.vangenabith}@uni-saarland.de Abstract it is often difficult to obtain sufficient amount of in-domain parallel data to train a system which can provide good performance in a specific domain. The performance of an in-domain model can be improved by selecting a subset from the out-domain data which is very similar to the indomain data (Matsoukas et al., 2009; Moore and Lewis, 2010), or by re-weighting the probability distributions (Foster et al., 2006; Sennrich et al., 2013) in favor of the in-domain data. This paper presents the JU-USAAR English–German domain adaptive machine translation (MT) system submitted to the IT domain translation task organized in WMT-2016 . Our system brings improvements over the in-domain baseline system by incorporating out-domain knowledge. We applied two methodologies to accelerate the performance of our in-domain MT system: (i) additional training material extraction from out-domain data using data selection method, and (ii) language model and translation model adaptation through interpolation. Our primary submission obtained a BLE"
W16-2333,E12-1055,0,0.0841094,"timated from the entire in-domain corpus (lmin ) and the second LM (lmo ) is estimated from the out-domain corpus. Mathematically, the cross-entropy H(Plm ) of language model probability Plm is defined as in Equation 1 considering a k-gram language model. Koehn (2004; Koehn (2005) first proposed domain adaptation in SMT by integrating terminological lexicons in the translation model, as a result of which there was a significant reduction in word error rate (WER). Over the last decade, many researchers (Foster and Kuhn, 2007; Duh et al., 2010; Banerjee et al., 2011; Bisazza and Federico, 2012; Sennrich, 2012; Sennrich et al., 2013; Haddow and Koehn, 2012) investigated the problem of combining multi-domain datasets. To construct a good domain-specific language model, sentences which are similar to the target domain should be included (Sethy et al., 2006) in the monolingual target language corupus on which the language model is trained. L¨u et al. (2007) identified those sentences using the tf/idf method and they increased the count of such sentences. Domain adaptation in MT have been explored in many different directions, ranging from adapating language models and translation models to alignment a"
W16-2333,N06-2037,0,0.0324717,"age model. Koehn (2004; Koehn (2005) first proposed domain adaptation in SMT by integrating terminological lexicons in the translation model, as a result of which there was a significant reduction in word error rate (WER). Over the last decade, many researchers (Foster and Kuhn, 2007; Duh et al., 2010; Banerjee et al., 2011; Bisazza and Federico, 2012; Sennrich, 2012; Sennrich et al., 2013; Haddow and Koehn, 2012) investigated the problem of combining multi-domain datasets. To construct a good domain-specific language model, sentences which are similar to the target domain should be included (Sethy et al., 2006) in the monolingual target language corupus on which the language model is trained. L¨u et al. (2007) identified those sentences using the tf/idf method and they increased the count of such sentences. Domain adaptation in MT have been explored in many different directions, ranging from adapating language models and translation models to alignment adaptation approach to improve domainspecific word alignment. N 1 X log Plm (wi |wi−k+1 ...wi−1 ) N i=1 (1) We calculated perplexity (P P = 2H ) of individual sentences of out-domain with respect to indomain LM and out-domain LM for both source (sl) a"
W16-2333,2006.amta-papers.25,0,0.0417351,"e table using the Good-Turing smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) on a held out development set (Batch1 in Table 3) of size 1,000 sentences provided by the WMT-2016 task organizers. After the parameters were tuned, decoding was carried out on the held out development test set (Batch2 in Table 3) as well as test set released by the shared task organizers. We evaluated the systems using three well known automatic MT evaluation metrics: BLEU (Papineni et al., 2002), METEOR (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). The evaluation results of our baseline systems trained on in-domain and out-domain data are reported in Table 3. Datasets In-domain Data: The detailed statistics of indomain data is reported in Table 1. We considered all the data provided by the WMT-2016 organizers for the IT translation task. We combined all data and performed cleaning in two steps: (i) Cleaning1: following the cleaning process described in (Pal et al., 2015), and (ii) Cleaning 2: using the Moses (Koehn et al., 2007) corpus cleaning scripts with minimum and maximum number of tokens set to 1 and 80 respectively. Additionally"
W16-2333,W14-3323,1,0.898642,"Missing"
W16-2333,P07-2045,0,\N,Missing
W16-2333,W15-3017,1,\N,Missing
W16-2373,P91-1022,0,0.876329,"Missing"
W16-2373,1992.tmi-1.7,0,0.866727,"Missing"
W16-2373,P93-1001,0,0.656613,"Missing"
W16-2373,W14-3323,1,0.872891,"Missing"
W16-2373,P91-1023,0,0.580783,"Missing"
W16-2373,E09-1096,0,0.181034,"Missing"
W16-2373,P11-2026,0,0.518386,"Missing"
W16-2373,J93-1006,0,0.824386,"Missing"
W16-2373,P94-1012,0,0.261372,"Missing"
W16-2373,P93-1003,0,0.690047,"Missing"
W16-2373,2012.eamt-1.62,0,0.227133,"Missing"
W16-2373,P93-1004,0,0.628793,"Missing"
W16-2373,W14-1009,1,0.892146,"Missing"
W16-2373,N10-1063,0,\N,Missing
W16-2379,N12-1047,0,0.0301838,"archical, monotone, swap, left to right bidirectional (hiermslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To compensate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) optimized with k-best MIRA (Cherry and Foster, 2012) on a held out development set of size 500 sentences randomly extracted from training data. Therefore, all model has been build on 11,500 parallel T LM T –T LP E sentences. After the parameters were tuned, decoding was carried out on the held out development test set (‘Dev’ in Table 1) as well as test set. Table 1 presents the statistics of the training, development and test sets released for the English–German APE Task organized in WMT2016. These data sets did not require any preprocessing in terms of encoding or alignment. Train Dev Test 12,000 1,000 2,000 EN 201,505 17,827 31,477 Tokens DE-"
W16-2379,P03-1021,0,0.187832,"rdering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hiermslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To compensate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) optimized with k-best MIRA (Cherry and Foster, 2012) on a held out development set of size 500 sentences randomly extracted from training data. Therefore, all model has been build on 11,500 parallel T LM T –T LP E sentences. After the parameters were tuned, decoding was carried out on the held out development test set (‘Dev’ in Table 1) as well as test set. Table 1 presents the statistics of the training, development and test sets released for the English–German APE Task organized in WMT2016. These data sets did not require any preprocessing in terms of encoding or alignment. Train Dev Test 1"
W16-2379,P11-1105,0,0.11743,"Missing"
W16-2379,W15-3026,1,0.834799,"Missing"
W16-2379,J15-2001,0,0.138111,"Missing"
W16-2379,L16-1095,1,0.842747,"Missing"
W16-2379,W06-1607,0,0.0408401,"our PB-SAPE and hierarchical phrase-based statistical (HPB-SAPE) system respectively. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hiermslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To compensate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) optimized with k-best MIRA (Cherry and Foster, 2012) on a held out development set of size 500 sentences randomly extracted from training data. Therefore, all model has been build on 11,500 parallel T LM T –T LP E sentences. After the parameters were tuned, decoding was carried out on the held out development test set (‘Dev’ in Table 1) as well as test set. Table 1 presents the statistics of the training, development and test sets released for the English–German APE Task organized in WMT2016. These data sets d"
W16-2379,P02-1040,0,0.109971,"LM-Toolkit (Stolcke, 2002) 760 3 Experiment SEN The effectiveness of the present work is demonstrated by using the standard log-linear PB-SMT model for our phrase based SAPE (PB-SAPE) model. The MT outputs are provided by WMT2016 APE task (c.f Table 1) are considered as baseline system translation. For building our SAPE system, we experimented with various maximum phrase lengths for the translation model and n–gram settings for the language model. We found that using a maximum phrase length of 10 for the translation model and a 6-gram language model produces the best results in terms of BLEU (Papineni et al., 2002) scores for our SAPE model. The other experimental settings were concerned with word alignment model between T LM T and T LP E are trained on three different aligners: Berkeley Aligner (Liang et al., 2006), METEOR aligner (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). The phraseextraction (Koehn et al., 2003) and hierarchical phrase-extraction (Chiang, 2005) are used to build our PB-SAPE and hierarchical phrase-based statistical (HPB-SAPE) system respectively. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hiermslr-bidirectional)"
W16-2379,D08-1089,0,0.0406055,"for our SAPE model. The other experimental settings were concerned with word alignment model between T LM T and T LP E are trained on three different aligners: Berkeley Aligner (Liang et al., 2006), METEOR aligner (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). The phraseextraction (Koehn et al., 2003) and hierarchical phrase-extraction (Chiang, 2005) are used to build our PB-SAPE and hierarchical phrase-based statistical (HPB-SAPE) system respectively. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hiermslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To compensate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) optimized with k-best MIRA (Cherry and Foster, 2012) on a held out development set of size 500 sentences randomly extracted from training da"
W16-2379,N07-1064,0,0.859858,"diting Santanu Pal1 , Marcos Zampieri1,2 , Josef van Genabith1,2 1 Saarland University, Saarbr¨ucken, Germany 2 German Research Center for Artificial Intelligence (DFKI), Germany {santanu.pal, marcos.zampieri, josef.vangenabith}@uni-saarland.de Abstract tency (Guerberof, 2009; Plitt and Masselot, 2010; Zampieri and Vela, 2014). With this respect the ultimate goal of MT systems is to provide output that can be post-edited with the least effort as possible by human translators. One of the strategies to improve MT output is to apply automatic post-editing (APE) methods (Knight and Chander, 1994; Simard et al., 2007a; Simard et al., 2007b). APE methods work under the assumption that some errors in MT systems are recurrent and they can be corrected automatically in a post-processing stage thus providing output that is more adequate to be post-edited. APE methods are applied before human post-editing increasing translators’ productivity. This paper presents a new approach to APE which was submitted by the USAAR team to the Automatic Post-editing (APE) shared task at WMT-2016. Our system combines two models: monolingual phrase-based and operation sequential model with an edit distance based word alignment b"
W16-2379,W07-0728,0,0.494383,"diting Santanu Pal1 , Marcos Zampieri1,2 , Josef van Genabith1,2 1 Saarland University, Saarbr¨ucken, Germany 2 German Research Center for Artificial Intelligence (DFKI), Germany {santanu.pal, marcos.zampieri, josef.vangenabith}@uni-saarland.de Abstract tency (Guerberof, 2009; Plitt and Masselot, 2010; Zampieri and Vela, 2014). With this respect the ultimate goal of MT systems is to provide output that can be post-edited with the least effort as possible by human translators. One of the strategies to improve MT output is to apply automatic post-editing (APE) methods (Knight and Chander, 1994; Simard et al., 2007a; Simard et al., 2007b). APE methods work under the assumption that some errors in MT systems are recurrent and they can be corrected automatically in a post-processing stage thus providing output that is more adequate to be post-edited. APE methods are applied before human post-editing increasing translators’ productivity. This paper presents a new approach to APE which was submitted by the USAAR team to the Automatic Post-editing (APE) shared task at WMT-2016. Our system combines two models: monolingual phrase-based and operation sequential model with an edit distance based word alignment b"
W16-2379,W11-2123,0,0.0478937,"ree different aligners: Berkeley Aligner (Liang et al., 2006), METEOR aligner (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). The phraseextraction (Koehn et al., 2003) and hierarchical phrase-extraction (Chiang, 2005) are used to build our PB-SAPE and hierarchical phrase-based statistical (HPB-SAPE) system respectively. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hiermslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To compensate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique (Foster et al., 2006). System tuning was carried out using Minimum Error Rate Training (MERT) (Och, 2003) optimized with k-best MIRA (Cherry and Foster, 2012) on a held out development set of size 500 sentences randomly extracted from training data. Therefore, all model has been build on 11,500 parallel T LM T –T LP E sentences. After the parameters were tuned, decoding"
W16-2379,2006.amta-papers.25,0,0.644646,"system translation. For building our SAPE system, we experimented with various maximum phrase lengths for the translation model and n–gram settings for the language model. We found that using a maximum phrase length of 10 for the translation model and a 6-gram language model produces the best results in terms of BLEU (Papineni et al., 2002) scores for our SAPE model. The other experimental settings were concerned with word alignment model between T LM T and T LP E are trained on three different aligners: Berkeley Aligner (Liang et al., 2006), METEOR aligner (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). The phraseextraction (Koehn et al., 2003) and hierarchical phrase-extraction (Chiang, 2005) are used to build our PB-SAPE and hierarchical phrase-based statistical (HPB-SAPE) system respectively. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hiermslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1). To com"
W16-2379,N03-1017,0,0.046298,"es our proposed system, in particular PB-SMT coupled OSM model. In Section 3, we outline the data used for experiments and complete experimental setup. Section 4 presents the results of the automatic evaluation, followed by conclusion and future work in Section 5. 2 p(mt, pe) ≈ I Y i=1 p(oi |oi−m+1 ...oi−1 ) (1) The decoder searches best translation in Equation 2 from the model using language model plm (pe) USAAR APE System Our APE system is based on operational N-gram sequential model which integrates translation and reordering operations into the phrase-based APE system. Traditional PB-SMT (Koehn et al., 2003) provides a powerful translation mechanism which can directly be modelled to a phrase-based SAPE (PB-SAPE) system (Simard et al., 2007a; Simard et al., 2007b; Pal et al., 2015) using target language MT output (T LM T ) and their corresponding post-edited version (T LP E ) as a parallel training corpus. Unlike PB-SMT, PB-SAPE also follows similar kind of drawbacks such as dependency across phrases, handling discontinuous phrases etc. Our OSM-APE system is based on phrase based N-gram APE model, however reordering approach is essentially different, it considers all possible orderings of phrases"
W16-2379,P07-2045,0,0.0304214,"Missing"
W16-2379,W14-0314,1,0.877599,"Missing"
W16-2379,W07-0734,0,0.289413,"able 1) are considered as baseline system translation. For building our SAPE system, we experimented with various maximum phrase lengths for the translation model and n–gram settings for the language model. We found that using a maximum phrase length of 10 for the translation model and a 6-gram language model produces the best results in terms of BLEU (Papineni et al., 2002) scores for our SAPE model. The other experimental settings were concerned with word alignment model between T LM T and T LP E are trained on three different aligners: Berkeley Aligner (Liang et al., 2006), METEOR aligner (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). The phraseextraction (Koehn et al., 2003) and hierarchical phrase-extraction (Chiang, 2005) are used to build our PB-SAPE and hierarchical phrase-based statistical (HPB-SAPE) system respectively. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hiermslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the training data are assigned an unduly high pro"
W16-2379,N06-1014,0,0.596721,"e provided by WMT2016 APE task (c.f Table 1) are considered as baseline system translation. For building our SAPE system, we experimented with various maximum phrase lengths for the translation model and n–gram settings for the language model. We found that using a maximum phrase length of 10 for the translation model and a 6-gram language model produces the best results in terms of BLEU (Papineni et al., 2002) scores for our SAPE model. The other experimental settings were concerned with word alignment model between T LM T and T LP E are trained on three different aligners: Berkeley Aligner (Liang et al., 2006), METEOR aligner (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). The phraseextraction (Koehn et al., 2003) and hierarchical phrase-extraction (Chiang, 2005) are used to build our PB-SAPE and hierarchical phrase-based statistical (HPB-SAPE) system respectively. The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hiermslr-bidirectional) method (Galley and Manning, 2008) and conditioned on both source and target language. The 5-gram target language model was trained using KenLM (Heafield, 2011). Phrase pairs that occur only once in the tra"
W16-2379,W15-5206,1,0.834735,"Missing"
W16-2379,J03-1002,0,0.0182983,"a linear sequence of operations such as lexical generation of post-edited translation and their orderings. The translation and reordering decisions are conditioned on n previous translation and reordering decisions. The model also can able to consistently modelled both local and long-range reorderings. Traditional OSM based MT model consists of three sequence of operations: pe∗ = argmaxpe p(mt, pe) × plm (pe) ppr (pe) (2) QI ppr (pe) ≈ i=1 p(wi |wi−m+1 ...wi−1 ), is the prior probability that marginalize the joint probability p(mt, pe). The model is then represented in a log-linear approach (Och and Ney, 2003) (in Equation 3) that makes it useful to incorporate standard features along with several novel features that improve the accuracy. pe∗ = argmaxpe I X λi hi (mt, pe) (3) i=1 where λi is the weight associated with the feature hi (mt, pe): p(mt, pe), ppr (pe) and plm (pe). Apart from this 8 additional features has been included in the log-linear model: 1. Length penalty: Length of the pe in words 2. Deletion penalty 3. Gap bonus: Total number of gap inserted to produce PE sentence 4. Open gap penalty : Number of open gaps, this penalty controls how quickly gap was closed. • Generates a sequence"
W16-2379,P05-1033,0,\N,Missing
W17-4773,2011.mtsummit-papers.35,0,0.590859,"Missing"
W17-4773,W16-2377,1,0.904407,"Missing"
W17-4773,E17-1050,1,0.854521,"can help to: i) improve MT output by exploiting information unavailable to the decoder, or by performing deeper text analysis that is too expensive at the decoding stage; ii) provide professional translators with improved MT output quality to reduce (human) postediting effort and iii) adapt the output of a generalpurpose MT system to the lexicon/style requested in a specific application domain. Different APE paradigms based on statistical methods (Simard et al., 2007; Dugast et al., 2007; Isabelle et al., 2007; Lagarda et al., 2009; Potet et al., 2012; Rosa et al., 2013; Lagarda et al., 2015; Chatterjee et al., 2017) have been proposed in the past showing the effectiveness of APE systems. In the previous round of the APE shared task (WMT16), neural (Junczys-Dowmunt and Grundkiewicz, 2016), hybrid (Chatterjee et al., 2016), and phrase-based (Pal et al., 2016b) solutions were all able to significantly improve MT output quality in domain-specific settings, with neural system being the best in 2016. Some of the previous approaches, both phrase-based (B´echara et al., 2011; Chatterjee et al., 2015b) and neural (Libovick´y et al., 2016) also suggested the importance of jointly learning both from the source sent"
W17-4773,W15-3025,1,0.947772,", 2007; Isabelle et al., 2007; Lagarda et al., 2009; Potet et al., 2012; Rosa et al., 2013; Lagarda et al., 2015; Chatterjee et al., 2017) have been proposed in the past showing the effectiveness of APE systems. In the previous round of the APE shared task (WMT16), neural (Junczys-Dowmunt and Grundkiewicz, 2016), hybrid (Chatterjee et al., 2016), and phrase-based (Pal et al., 2016b) solutions were all able to significantly improve MT output quality in domain-specific settings, with neural system being the best in 2016. Some of the previous approaches, both phrase-based (B´echara et al., 2011; Chatterjee et al., 2015b) and neural (Libovick´y et al., 2016) also suggested the importance of jointly learning both from the source sentences and from the corresponding translations in order to take advantage of the strict dependency between translation errors and the original source sentences. Learning from these lessons, this year the FBK participation in the APE task is based on a multisource neural sequence-to-sequence architecture. We extend the existing NMT implementation in the Nematus toolkit (Sennrich et al., 2016a) to facilitate multi-source training and decoding. This year we participated in both transl"
W17-4773,N09-2055,0,0.040377,"Missing"
W17-4773,P15-2026,1,0.925704,", 2007; Isabelle et al., 2007; Lagarda et al., 2009; Potet et al., 2012; Rosa et al., 2013; Lagarda et al., 2015; Chatterjee et al., 2017) have been proposed in the past showing the effectiveness of APE systems. In the previous round of the APE shared task (WMT16), neural (Junczys-Dowmunt and Grundkiewicz, 2016), hybrid (Chatterjee et al., 2016), and phrase-based (Pal et al., 2016b) solutions were all able to significantly improve MT output quality in domain-specific settings, with neural system being the best in 2016. Some of the previous approaches, both phrase-based (B´echara et al., 2011; Chatterjee et al., 2015b) and neural (Libovick´y et al., 2016) also suggested the importance of jointly learning both from the source sentences and from the corresponding translations in order to take advantage of the strict dependency between translation errors and the original source sentences. Learning from these lessons, this year the FBK participation in the APE task is based on a multisource neural sequence-to-sequence architecture. We extend the existing NMT implementation in the Nematus toolkit (Sennrich et al., 2016a) to facilitate multi-source training and decoding. This year we participated in both transl"
W17-4773,N12-1047,0,0.0203607,"m achieves significant improvement over the MT baseline (-5.4 TER and 8.7 BLEU points) also on the 2016 test set. Systems MT Baseline APE Baseline Ens8+Re-rank-A Ensemble (Ens8) In order to leverage all the network architectures discussed above, we ensemble the two best models for each of them. Since the networks are very diverse in terms of information learned from the input representation we observed that weighing all the models equally does not improve over the single system. Therefore, we generate 50-best hypothesis from the ensemble system and then tune the model weights with Batch-MIRA (Cherry and Foster, 2012) on the development set to maximize the BLEU score. We observe that, after 3 cycles of decoding and tuning, the performance converges. The weighted ensemble of 8 models further improves the translation quality (-0.8 TER and +1.1 BLEU) over the best single multi-source model (MT+SRC PE). TER 24.76 24.64 19.32† BLEU 62.11 63.47 70.88† Table 3: Performance of the APE systems on the 2016 test set (en-de) (“†” indicates statistically significant differences wrt. MT Baseline with p&lt;0.05). Statistical (Re-rank-AB) This re-ranker is similar to the one used in (Pal et al., 2017). The feature set consis"
W17-4773,W16-2361,0,0.0977145,"Missing"
W17-4773,E17-2056,1,0.881001,"Missing"
W17-4773,W07-0732,0,0.0695889,"more radical internal modifications. As pointed out in (Bojar et al., 2015), from the application point of view an APE system can help to: i) improve MT output by exploiting information unavailable to the decoder, or by performing deeper text analysis that is too expensive at the decoding stage; ii) provide professional translators with improved MT output quality to reduce (human) postediting effort and iii) adapt the output of a generalpurpose MT system to the lexicon/style requested in a specific application domain. Different APE paradigms based on statistical methods (Simard et al., 2007; Dugast et al., 2007; Isabelle et al., 2007; Lagarda et al., 2009; Potet et al., 2012; Rosa et al., 2013; Lagarda et al., 2015; Chatterjee et al., 2017) have been proposed in the past showing the effectiveness of APE systems. In the previous round of the APE shared task (WMT16), neural (Junczys-Dowmunt and Grundkiewicz, 2016), hybrid (Chatterjee et al., 2016), and phrase-based (Pal et al., 2016b) solutions were all able to significantly improve MT output quality in domain-specific settings, with neural system being the best in 2016. Some of the previous approaches, both phrase-based (B´echara et al., 2011; Chatte"
W17-4773,P16-2046,1,0.72219,"Missing"
W17-4773,W16-2379,1,0.873345,"Missing"
W17-4773,P02-1040,0,0.0985144,"n Tables 1 and 2. The performance trends among different networks are similar for both language directions. However, the variation are less visible in the case of de-en given the fact that the room of improvement is much lower due to higher MT quality (15.58 TER and 79.46 BLEU scores). Therefore, we base our discussion for each model below on the results achieved on the development data for the en-de direction, where the performance variations among different networks are much more visible. Evaluation Metric We run case-sensitive evaluation with TER, which is based on edit distance, and BLEU (Papineni et al., 2002), which is based on modified n-gram precision. In addition to the standard evaluation 2 https://github.com/amunmt/amunmt/ wiki/AmuNMT-for-Automatic-Post-Editing 3 http://www.statmt.org/wmt17/ape-task. html 633 SRC PE This system is similar to a NMT system used for bilingual translation from a source language to a target language. The parallel corpus consist of source text and post-edits of MT segments. We notice that the performance of this system is below the MT Baseline indicating that learning only from the source text is not enough to improve the translation quality. Most likely, this syst"
W17-4773,2012.iwslt-papers.19,0,0.035867,"al., 2015), from the application point of view an APE system can help to: i) improve MT output by exploiting information unavailable to the decoder, or by performing deeper text analysis that is too expensive at the decoding stage; ii) provide professional translators with improved MT output quality to reduce (human) postediting effort and iii) adapt the output of a generalpurpose MT system to the lexicon/style requested in a specific application domain. Different APE paradigms based on statistical methods (Simard et al., 2007; Dugast et al., 2007; Isabelle et al., 2007; Lagarda et al., 2009; Potet et al., 2012; Rosa et al., 2013; Lagarda et al., 2015; Chatterjee et al., 2017) have been proposed in the past showing the effectiveness of APE systems. In the previous round of the APE shared task (WMT16), neural (Junczys-Dowmunt and Grundkiewicz, 2016), hybrid (Chatterjee et al., 2016), and phrase-based (Pal et al., 2016b) solutions were all able to significantly improve MT output quality in domain-specific settings, with neural system being the best in 2016. Some of the previous approaches, both phrase-based (B´echara et al., 2011; Chatterjee et al., 2015b) and neural (Libovick´y et al., 2016) also sug"
W17-4773,2007.mtsummit-papers.34,0,0.061602,"l modifications. As pointed out in (Bojar et al., 2015), from the application point of view an APE system can help to: i) improve MT output by exploiting information unavailable to the decoder, or by performing deeper text analysis that is too expensive at the decoding stage; ii) provide professional translators with improved MT output quality to reduce (human) postediting effort and iii) adapt the output of a generalpurpose MT system to the lexicon/style requested in a specific application domain. Different APE paradigms based on statistical methods (Simard et al., 2007; Dugast et al., 2007; Isabelle et al., 2007; Lagarda et al., 2009; Potet et al., 2012; Rosa et al., 2013; Lagarda et al., 2015; Chatterjee et al., 2017) have been proposed in the past showing the effectiveness of APE systems. In the previous round of the APE shared task (WMT16), neural (Junczys-Dowmunt and Grundkiewicz, 2016), hybrid (Chatterjee et al., 2016), and phrase-based (Pal et al., 2016b) solutions were all able to significantly improve MT output quality in domain-specific settings, with neural system being the best in 2016. Some of the previous approaches, both phrase-based (B´echara et al., 2011; Chatterjee et al., 2015b) and"
W17-4773,P13-3025,0,0.0167829,"application point of view an APE system can help to: i) improve MT output by exploiting information unavailable to the decoder, or by performing deeper text analysis that is too expensive at the decoding stage; ii) provide professional translators with improved MT output quality to reduce (human) postediting effort and iii) adapt the output of a generalpurpose MT system to the lexicon/style requested in a specific application domain. Different APE paradigms based on statistical methods (Simard et al., 2007; Dugast et al., 2007; Isabelle et al., 2007; Lagarda et al., 2009; Potet et al., 2012; Rosa et al., 2013; Lagarda et al., 2015; Chatterjee et al., 2017) have been proposed in the past showing the effectiveness of APE systems. In the previous round of the APE shared task (WMT16), neural (Junczys-Dowmunt and Grundkiewicz, 2016), hybrid (Chatterjee et al., 2016), and phrase-based (Pal et al., 2016b) solutions were all able to significantly improve MT output quality in domain-specific settings, with neural system being the best in 2016. Some of the previous approaches, both phrase-based (B´echara et al., 2011; Chatterjee et al., 2015b) and neural (Libovick´y et al., 2016) also suggested the importan"
W17-4773,E17-3017,0,0.0518769,"Missing"
W17-4773,P16-1162,0,0.426112,"e best in 2016. Some of the previous approaches, both phrase-based (B´echara et al., 2011; Chatterjee et al., 2015b) and neural (Libovick´y et al., 2016) also suggested the importance of jointly learning both from the source sentences and from the corresponding translations in order to take advantage of the strict dependency between translation errors and the original source sentences. Learning from these lessons, this year the FBK participation in the APE task is based on a multisource neural sequence-to-sequence architecture. We extend the existing NMT implementation in the Nematus toolkit (Sennrich et al., 2016a) to facilitate multi-source training and decoding. This year we participated in both translation directions Previous phrase-based approaches to Automatic Post-editing (APE) have shown that the dependency of MT errors from the source sentence can be exploited by jointly learning from source and target information. By integrating this notion in a neural approach to the problem, we present the multi-source neural machine translation (NMT) system submitted by FBK to the WMT 2017 APE shared task. Our system implements multi-source NMT in a weighted ensemble of 8 models. The n-best hypotheses prod"
W17-4773,N07-1064,0,0.428785,"for retraining or for more radical internal modifications. As pointed out in (Bojar et al., 2015), from the application point of view an APE system can help to: i) improve MT output by exploiting information unavailable to the decoder, or by performing deeper text analysis that is too expensive at the decoding stage; ii) provide professional translators with improved MT output quality to reduce (human) postediting effort and iii) adapt the output of a generalpurpose MT system to the lexicon/style requested in a specific application domain. Different APE paradigms based on statistical methods (Simard et al., 2007; Dugast et al., 2007; Isabelle et al., 2007; Lagarda et al., 2009; Potet et al., 2012; Rosa et al., 2013; Lagarda et al., 2015; Chatterjee et al., 2017) have been proposed in the past showing the effectiveness of APE systems. In the previous round of the APE shared task (WMT16), neural (Junczys-Dowmunt and Grundkiewicz, 2016), hybrid (Chatterjee et al., 2016), and phrase-based (Pal et al., 2016b) solutions were all able to significantly improve MT output quality in domain-specific settings, with neural system being the best in 2016. Some of the previous approaches, both phrase-based (B´echara"
W17-4773,W15-3001,1,\N,Missing
W17-4773,W16-2378,0,\N,Missing
W17-4773,W16-2323,0,\N,Missing
W17-4773,W16-2301,1,\N,Missing
W18-2411,W14-4012,0,0.134208,"Missing"
W18-2411,W03-1508,0,0.105311,"Missing"
W18-2411,D14-1179,0,0.0409906,"Missing"
W18-2411,W16-2710,0,0.0302942,"nce of character correspondences in many language pairs makes this task complex. So, these types of characters are needed to be tackled in different ways, sometimes these are omitted, and in most of the cases these are approximated and represented in the best possible way keeping the pronunciation intact. Studies have shown that Machine Transliteration have been done mainly with traditional and different statistical methods (Knight and Graehl, 1998; Nguyen et al., 2016; Rama and Gali, 2009). With the advent of deep learning techniques, few research attempts have been made using deep learning (Yan and Nivre, 2016; Rosca and Breuel, 2016; Finch et al., 2016). The deep learning frame-works used are similar to that of the Sequence to Sequence machine translation (Bahdanau et al., 2015; Cho et al., 2014b). In our work, we present a comprehensive study of deep learning techniques for Machine Transliteration. We present some segmentation techniques for Transliteration–Character based and Byte-Pair based. We also present different deep learning architectures for machine transliteration such as In this paper, we propose different architectures for language independent machine transliteration which is extremel"
W18-2411,W16-2711,0,0.0306223,"uage pairs makes this task complex. So, these types of characters are needed to be tackled in different ways, sometimes these are omitted, and in most of the cases these are approximated and represented in the best possible way keeping the pronunciation intact. Studies have shown that Machine Transliteration have been done mainly with traditional and different statistical methods (Knight and Graehl, 1998; Nguyen et al., 2016; Rama and Gali, 2009). With the advent of deep learning techniques, few research attempts have been made using deep learning (Yan and Nivre, 2016; Rosca and Breuel, 2016; Finch et al., 2016). The deep learning frame-works used are similar to that of the Sequence to Sequence machine translation (Bahdanau et al., 2015; Cho et al., 2014b). In our work, we present a comprehensive study of deep learning techniques for Machine Transliteration. We present some segmentation techniques for Transliteration–Character based and Byte-Pair based. We also present different deep learning architectures for machine transliteration such as In this paper, we propose different architectures for language independent machine transliteration which is extremely important for natural language processing ("
W18-2411,P08-1045,0,0.100987,"Missing"
W18-2411,P09-5002,0,0.0245698,"Missing"
W18-2411,W16-2712,0,0.030156,"es between different languages, and different dialects of the same language, thus making the task of transliteration intricate. Moreover, the absence of character correspondences in many language pairs makes this task complex. So, these types of characters are needed to be tackled in different ways, sometimes these are omitted, and in most of the cases these are approximated and represented in the best possible way keeping the pronunciation intact. Studies have shown that Machine Transliteration have been done mainly with traditional and different statistical methods (Knight and Graehl, 1998; Nguyen et al., 2016; Rama and Gali, 2009). With the advent of deep learning techniques, few research attempts have been made using deep learning (Yan and Nivre, 2016; Rosca and Breuel, 2016; Finch et al., 2016). The deep learning frame-works used are similar to that of the Sequence to Sequence machine translation (Bahdanau et al., 2015; Cho et al., 2014b). In our work, we present a comprehensive study of deep learning techniques for Machine Transliteration. We present some segmentation techniques for Transliteration–Character based and Byte-Pair based. We also present different deep learning architectures for ma"
W18-2411,W09-3528,0,0.0363781,"languages, and different dialects of the same language, thus making the task of transliteration intricate. Moreover, the absence of character correspondences in many language pairs makes this task complex. So, these types of characters are needed to be tackled in different ways, sometimes these are omitted, and in most of the cases these are approximated and represented in the best possible way keeping the pronunciation intact. Studies have shown that Machine Transliteration have been done mainly with traditional and different statistical methods (Knight and Graehl, 1998; Nguyen et al., 2016; Rama and Gali, 2009). With the advent of deep learning techniques, few research attempts have been made using deep learning (Yan and Nivre, 2016; Rosca and Breuel, 2016; Finch et al., 2016). The deep learning frame-works used are similar to that of the Sequence to Sequence machine translation (Bahdanau et al., 2015; Cho et al., 2014b). In our work, we present a comprehensive study of deep learning techniques for Machine Transliteration. We present some segmentation techniques for Transliteration–Character based and Byte-Pair based. We also present different deep learning architectures for machine transliteration"
W18-3920,W16-4819,0,0.0223457,"om 2014 (Zampieri et al., 2014) to 2017 (Zampieri et al., 2017b) within the scope of the VarDial workshop series. Four versions of the DSLCC dataset (Tan et al., 2014) have been released containing short excerpts of journalistic texts written in similar languages and language varieties. In the four editions of the DSL shared task a variety of computation methods have been tested. This includes Maximum Entropy (Porta and Sancho, 2014), Prediction by Partial Matching (PPM) (Bobicev, 2015), language model perplexity (Gamallo et al., 2017), SVMs (Purver, 2014), Convolution Neural Networks (CNNs) (Belinkov and Glass, 2016), word-based back-off models (Jauhiainen et al., 2015; Jauhiainen et al., 2016), and classifier ensembles (Malmasi and Dras, 2015), the approach we apply in this paper. Classifier ensembles showed very good performance not only in language identification but also in similar tasks. Therefore, we build on the experience of our previous work and improve the system that we have previously applied to similar tasks, namely author profiling (Ciobanu et al., 2017) and native language identification (Zampieri et al., 2017a). A detailed description of our system is presented in Section 4. 3 Data The dat"
W18-3920,W15-5410,0,0.0278754,"gs are the aforementioned Discriminating between Similar Languages (DSL) shared tasks. The DSL tasks have been organized from 2014 (Zampieri et al., 2014) to 2017 (Zampieri et al., 2017b) within the scope of the VarDial workshop series. Four versions of the DSLCC dataset (Tan et al., 2014) have been released containing short excerpts of journalistic texts written in similar languages and language varieties. In the four editions of the DSL shared task a variety of computation methods have been tested. This includes Maximum Entropy (Porta and Sancho, 2014), Prediction by Partial Matching (PPM) (Bobicev, 2015), language model perplexity (Gamallo et al., 2017), SVMs (Purver, 2014), Convolution Neural Networks (CNNs) (Belinkov and Glass, 2016), word-based back-off models (Jauhiainen et al., 2015; Jauhiainen et al., 2016), and classifier ensembles (Malmasi and Dras, 2015), the approach we apply in this paper. Classifier ensembles showed very good performance not only in language identification but also in similar tasks. Therefore, we build on the experience of our previous work and improve the system that we have previously applied to similar tasks, namely author profiling (Ciobanu et al., 2017) and n"
W18-3920,D14-1069,0,0.0726343,"Missing"
W18-3920,W17-1213,0,0.0135081,"tween Similar Languages (DSL) shared tasks. The DSL tasks have been organized from 2014 (Zampieri et al., 2014) to 2017 (Zampieri et al., 2017b) within the scope of the VarDial workshop series. Four versions of the DSLCC dataset (Tan et al., 2014) have been released containing short excerpts of journalistic texts written in similar languages and language varieties. In the four editions of the DSL shared task a variety of computation methods have been tested. This includes Maximum Entropy (Porta and Sancho, 2014), Prediction by Partial Matching (PPM) (Bobicev, 2015), language model perplexity (Gamallo et al., 2017), SVMs (Purver, 2014), Convolution Neural Networks (CNNs) (Belinkov and Glass, 2016), word-based back-off models (Jauhiainen et al., 2015; Jauhiainen et al., 2016), and classifier ensembles (Malmasi and Dras, 2015), the approach we apply in this paper. Classifier ensembles showed very good performance not only in language identification but also in similar tasks. Therefore, we build on the experience of our previous work and improve the system that we have previously applied to similar tasks, namely author profiling (Ciobanu et al., 2017) and native language identification (Zampieri et al., 20"
W18-3920,L16-1284,1,0.827322,"ombination. With the aid of Hindi speakers, in Section 5.1 we presented a concise error analysis of the misclassified instances of the development set. We observed a few interesting patterns in the misclassified instances, most notably that many of the misclassified sentences were too short, containing only one, two or three words, and that several of them contained only named entities. making it very challenging for classifiers to identify the language of these instances. Another issue discussed in Section 5.1, is that some instances could not be discriminated by native speakers, as noted by Goutte et al. (2016). To cope with these instances one possible direction for future work is to allow a multi-label classification setup in which sentences could be assign to more than one category if annotators labeled them as such. In future work we would like to explore and compare our methods to other high performance methods for this task. In particular, we would like to try an implementation of the token-based back-off method proposed by the SUKI team. As evidenced in Section 5, SUKI’s system achieved substantially higher performance than the other methods in this competition. Acknowledgements We would like"
W18-3920,W15-5408,0,0.088526,"., 2017b) within the scope of the VarDial workshop series. Four versions of the DSLCC dataset (Tan et al., 2014) have been released containing short excerpts of journalistic texts written in similar languages and language varieties. In the four editions of the DSL shared task a variety of computation methods have been tested. This includes Maximum Entropy (Porta and Sancho, 2014), Prediction by Partial Matching (PPM) (Bobicev, 2015), language model perplexity (Gamallo et al., 2017), SVMs (Purver, 2014), Convolution Neural Networks (CNNs) (Belinkov and Glass, 2016), word-based back-off models (Jauhiainen et al., 2015; Jauhiainen et al., 2016), and classifier ensembles (Malmasi and Dras, 2015), the approach we apply in this paper. Classifier ensembles showed very good performance not only in language identification but also in similar tasks. Therefore, we build on the experience of our previous work and improve the system that we have previously applied to similar tasks, namely author profiling (Ciobanu et al., 2017) and native language identification (Zampieri et al., 2017a). A detailed description of our system is presented in Section 4. 3 Data The dataset made available by the organizers of the Indo-Ary"
W18-3920,W16-4820,0,0.0514295,"e of the VarDial workshop series. Four versions of the DSLCC dataset (Tan et al., 2014) have been released containing short excerpts of journalistic texts written in similar languages and language varieties. In the four editions of the DSL shared task a variety of computation methods have been tested. This includes Maximum Entropy (Porta and Sancho, 2014), Prediction by Partial Matching (PPM) (Bobicev, 2015), language model perplexity (Gamallo et al., 2017), SVMs (Purver, 2014), Convolution Neural Networks (CNNs) (Belinkov and Glass, 2016), word-based back-off models (Jauhiainen et al., 2015; Jauhiainen et al., 2016), and classifier ensembles (Malmasi and Dras, 2015), the approach we apply in this paper. Classifier ensembles showed very good performance not only in language identification but also in similar tasks. Therefore, we build on the experience of our previous work and improve the system that we have previously applied to similar tasks, namely author profiling (Ciobanu et al., 2017) and native language identification (Zampieri et al., 2017a). A detailed description of our system is presented in Section 4. 3 Data The dataset made available by the organizers of the Indo-Aryan Language Identification"
W18-3920,W15-5407,1,0.925336,"he DSLCC dataset (Tan et al., 2014) have been released containing short excerpts of journalistic texts written in similar languages and language varieties. In the four editions of the DSL shared task a variety of computation methods have been tested. This includes Maximum Entropy (Porta and Sancho, 2014), Prediction by Partial Matching (PPM) (Bobicev, 2015), language model perplexity (Gamallo et al., 2017), SVMs (Purver, 2014), Convolution Neural Networks (CNNs) (Belinkov and Glass, 2016), word-based back-off models (Jauhiainen et al., 2015; Jauhiainen et al., 2016), and classifier ensembles (Malmasi and Dras, 2015), the approach we apply in this paper. Classifier ensembles showed very good performance not only in language identification but also in similar tasks. Therefore, we build on the experience of our previous work and improve the system that we have previously applied to similar tasks, namely author profiling (Ciobanu et al., 2017) and native language identification (Zampieri et al., 2017a). A detailed description of our system is presented in Section 4. 3 Data The dataset made available by the organizers of the Indo-Aryan Language Identification (ILI) task comprises five similar languages spoken"
W18-3920,W16-4801,1,0.936687,", 2018) and in previous work (Tiedemann and Ljubešić, 2012; Goutte et al., 2016), discriminating between similar languages is one of the main challenges in automatic language identification. State-of-the-art n-gram-based language identification systems are able to discriminate between unrelated languages with very high performance but very often struggle to discriminate between similar languages. This challenge motivated the organization of recent evaluation campaigns such as the TweetLID (Zubiaga et al., 2016) which included languages spoken in the Iberian peninsula and the DSL shared tasks (Malmasi et al., 2016b; Zampieri et al., 2015) which included groups of similar languages such as Malay and Indonesian, Bulgarian and Macedonian, and Bosnian, Croatian, and Serbian as well as groups of language varieties such as Brazilian and European Portuguese. In this paper we revisit the problem of discriminating between similar languages presenting a system to discriminate between five languages of the Indo-Aryan family: Hindi, Braj Bhasha, Awadhi, Bhojpuri, and Magahi. Inspired by systems that performed well in past editions of the DSL shared task such as the one by Malmasi and Dras (2015), we developed a sy"
W18-3920,W14-5314,0,0.0166142,"identification of very similar languages in multilingual settings are the aforementioned Discriminating between Similar Languages (DSL) shared tasks. The DSL tasks have been organized from 2014 (Zampieri et al., 2014) to 2017 (Zampieri et al., 2017b) within the scope of the VarDial workshop series. Four versions of the DSLCC dataset (Tan et al., 2014) have been released containing short excerpts of journalistic texts written in similar languages and language varieties. In the four editions of the DSL shared task a variety of computation methods have been tested. This includes Maximum Entropy (Porta and Sancho, 2014), Prediction by Partial Matching (PPM) (Bobicev, 2015), language model perplexity (Gamallo et al., 2017), SVMs (Purver, 2014), Convolution Neural Networks (CNNs) (Belinkov and Glass, 2016), word-based back-off models (Jauhiainen et al., 2015; Jauhiainen et al., 2016), and classifier ensembles (Malmasi and Dras, 2015), the approach we apply in this paper. Classifier ensembles showed very good performance not only in language identification but also in similar tasks. Therefore, we build on the experience of our previous work and improve the system that we have previously applied to similar tasks"
W18-3920,W14-5318,0,0.017647,"shared tasks. The DSL tasks have been organized from 2014 (Zampieri et al., 2014) to 2017 (Zampieri et al., 2017b) within the scope of the VarDial workshop series. Four versions of the DSLCC dataset (Tan et al., 2014) have been released containing short excerpts of journalistic texts written in similar languages and language varieties. In the four editions of the DSL shared task a variety of computation methods have been tested. This includes Maximum Entropy (Porta and Sancho, 2014), Prediction by Partial Matching (PPM) (Bobicev, 2015), language model perplexity (Gamallo et al., 2017), SVMs (Purver, 2014), Convolution Neural Networks (CNNs) (Belinkov and Glass, 2016), word-based back-off models (Jauhiainen et al., 2015; Jauhiainen et al., 2016), and classifier ensembles (Malmasi and Dras, 2015), the approach we apply in this paper. Classifier ensembles showed very good performance not only in language identification but also in similar tasks. Therefore, we build on the experience of our previous work and improve the system that we have previously applied to similar tasks, namely author profiling (Ciobanu et al., 2017) and native language identification (Zampieri et al., 2017a). A detailed desc"
W18-3920,C12-1160,0,0.0763191,"Missing"
W18-3920,W15-4415,0,0.0311268,"aterial or external resource. 4 Methodology Following our aforementioned previous work (Ciobanu et al., 2017), we built a classification system based on SVM ensembles using the same methodology proposed by Malmasi and Dras (2015). The purpose of using classification ensembles is to improve the overall performance and robustness by combining the results of multiple classifiers. Such systems have proved successful not only in NLI and dialect identification, but also in various text classification tasks, such as complex word identification (Malmasi et al., 2016a) and grammatical error diagnosis (Xiang et al., 2015). The classifiers can differ in a wide range of aspects; for example, algorithms, training data, features or parameters. We implemented our system using the Scikit-learn (Pedregosa et al., 2011) machine learning library, with each classifier in the ensemble using a different type of features. For the individual classifiers, we employed the SVM implementation based on the Liblinear library (Fan et al., 2008), LinearSVC1 , with a linear kernel. This implementation has the advantage of scaling well to large number of samples. For the ensemble, we employed the majority rule VotingClassifier2 , whi"
W18-3920,W14-5307,1,0.895397,", Croatian, Montenegrin, and Serbian (Ljubesic and Kranjcic, 2015). This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http: //creativecommons.org/licenses/by/4.0/ 178 Proceedings of the Fifth Workshop on NLP for Similar Languages, Varieties and Dialects, pages 178–184 Santa Fe, New Mexico, USA, August 20, 2018. A first attempting of benchmarking the identification of very similar languages in multilingual settings are the aforementioned Discriminating between Similar Languages (DSL) shared tasks. The DSL tasks have been organized from 2014 (Zampieri et al., 2014) to 2017 (Zampieri et al., 2017b) within the scope of the VarDial workshop series. Four versions of the DSLCC dataset (Tan et al., 2014) have been released containing short excerpts of journalistic texts written in similar languages and language varieties. In the four editions of the DSL shared task a variety of computation methods have been tested. This includes Maximum Entropy (Porta and Sancho, 2014), Prediction by Partial Matching (PPM) (Bobicev, 2015), language model perplexity (Gamallo et al., 2017), SVMs (Purver, 2014), Convolution Neural Networks (CNNs) (Belinkov and Glass, 2016), word"
W18-3920,W15-5401,1,0.921353,"Missing"
W18-3920,W17-5045,1,0.84077,"bian (Ljubesic and Kranjcic, 2015). This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http: //creativecommons.org/licenses/by/4.0/ 178 Proceedings of the Fifth Workshop on NLP for Similar Languages, Varieties and Dialects, pages 178–184 Santa Fe, New Mexico, USA, August 20, 2018. A first attempting of benchmarking the identification of very similar languages in multilingual settings are the aforementioned Discriminating between Similar Languages (DSL) shared tasks. The DSL tasks have been organized from 2014 (Zampieri et al., 2014) to 2017 (Zampieri et al., 2017b) within the scope of the VarDial workshop series. Four versions of the DSLCC dataset (Tan et al., 2014) have been released containing short excerpts of journalistic texts written in similar languages and language varieties. In the four editions of the DSL shared task a variety of computation methods have been tested. This includes Maximum Entropy (Porta and Sancho, 2014), Prediction by Partial Matching (PPM) (Bobicev, 2015), language model perplexity (Gamallo et al., 2017), SVMs (Purver, 2014), Convolution Neural Networks (CNNs) (Belinkov and Glass, 2016), word-based back-off models (Jauhiai"
W18-3920,W18-3901,1,0.883574,"Missing"
W18-3931,D18-1549,0,0.0246348,"et al., 2016)). Far from being settled, the architecture of NMT systems is constantly evolving. Given the youth of the paradigm and while the main structure of encoder-decoder is still maintained, the implementation of such is done either using recurrent neural networks (RNN) with attention mechanisms (Bahdanau et al., 2015), to convolutional neural networks (CNN) (Gehring et al., 2017) and to only attention mechanisms (Vaswani et al., 2017). For the same reason, research in NMT goes in many directions, including minimal units (Sennrich et al., 2016), unsupervised training and low resources (Artetxe et al., 2018) or transfer learning (Zoph et al., 2016), to name and cite just a few. In this paper we tackle an under-explored problem and apply NMT techniques to translate between language varieties. In previous work (Costa-juss`a, 2017), NMT has been used to translate between Spanish and Catalan, two closely-related Romance languages from the Iberian peninsula, outperforming phrase-based SMT approaches. In this paper we test whether this is also true for national varieties of the same language taking Brazilian and European Portuguese as a case study. To the best of our knowledge the use of NMT to transla"
W18-3931,W14-4012,0,0.102819,"Missing"
W18-3931,P16-2058,1,0.900353,"Missing"
W18-3931,W17-4123,1,0.872714,"Missing"
W18-3931,W17-1207,1,0.793656,"Missing"
W18-3931,2014.eamt-1.34,0,0.696539,"Missing"
W18-3931,L16-1284,1,0.907441,"Missing"
W18-3931,W17-1208,0,0.191108,"ttish Gaelic, (Goyal and Lehal, 2010) on Hindi and Punjabi, a few studies 1 In this paper, when talking about language varieties, we use the verbs adapt, edit, and translate interchangeably. In previous work Marujo et al. (2011) used the word adaptation whereas Fancellu et al. (2014) used the word conversion. We consider it, however, as a full-fledged translation task and approach the task as such. 2 The 1990 orthographic agreement has been recently introduced in both countries diminishing these differences. 276 on Afrikaans and Dutch (Van Huyssteen and Pilon, 2009; Otte and Tyers, 2011), and Hassani (2017) on Kurdish dialects. To the best of our knowledge, however, the use of NMT is under-explored in these tasks and no language variety translation system has been developed using NMT. The most similar study is the one by (Costa-juss`a et al., 2017) who developed a neural-based MT system to translate between Catalan and Spanish. The use of NMT to translate between language varieties is the main contribution of our work. 3 Methods To be able to compare MT approaches, we trained SMT and NMT systems using the same dataset described in Section 3.1. The two systems are described in detail in Section 3"
W18-3931,W17-3204,0,0.0248067,"ystem in comparison to the statistical system. 1 Introduction In the last five years Neural Machine Translation (NMT) has evolved from a new and promising paradigm in Machine Translation (MT) to an established state-of-the-art technology. A few studies pose that performance difference between Statistical Machine Translation (SMT) and NMT is not as a great as one could imagine (Castilho et al., 2017) while others show interesting challenges for NMT (compared to SMT) such as learning with limited amount of data, out-of-domain, long sentences, low frequency words or lack of word alignment model (Koehn and Knowles, 2017). Even so, NMT systems have constantly ranked in the top positions in the competitions held in MT conferences and workshops such as WMT (Bojar et al., 2016) and WAT (Nakazawa et al., 2016). They have also been achieving commercial success (e.g. Google’s GNMT (Wu et al., 2016)). Far from being settled, the architecture of NMT systems is constantly evolving. Given the youth of the paradigm and while the main structure of encoder-decoder is still maintained, the implementation of such is done either using recurrent neural networks (RNN) with attention mechanisms (Bahdanau et al., 2015), to convol"
W18-3931,N03-1017,0,0.0589814,"The use of NMT to translate between language varieties is the main contribution of our work. 3 Methods To be able to compare MT approaches, we trained SMT and NMT systems using the same dataset described in Section 3.1. The two systems are described in detail in Section 3.2. Systems within the SMT category use statistical techniques to compose the final translation. There are a variety of alternatives that are state-of-the art, including: n-gram (Mari˜no et al., 2006), syntax (Yamada and Knight, 2001) or hierarchical to name a few. In this paper, we are using the popular phrase-based system (Koehn et al., 2003). Systems within the NMT category use a machine learning architecture based on neural networks to compose the final translation. As mentioned, there are several architectures which have been proven state-of-the-art, all of them based on an encoder-decoder schema but using either recurrent neural networks (Cho et al., 2014), convolutional neural networks (Gehring et al., 2017) or the transformer architecture based only on attention-based mechanisms (Vaswani et al., 2017). These architectures can be adapted to deal with different input representations either words, subwords (Sennrich et al., 201"
W18-3931,P07-2045,0,0.0103602,"each language for training, with over 33 million tokens for BP and over 34 million tokens for EP. Finally, 2,000 parallel sentences were kept for development and another 2,000 sentences for testing. 3.2 Systems Statistical-based. In a phrase-based system, the main model, which is the translation model, is extracted by statistical co-occurrences from a parallel corpus at the level of sentences. This translation model is combined in the decoder with other models to compose the most probable translation given a source input. We built a standard phrase-based system with Moses open source toolkit (Koehn et al., 2007). The main parameters of our implementation include: grow-diagonal-final-and word alignment symmetrization, lexicalized reordering, relative frequencies (conditional and posterior probabilities) with phrase discounting, lexical weights, phrase bonus, accepting phrases up to length 10, 5-gram language model with Kneser-Ney smoothing, word bonus and MERT (Minimum Error Rate Training) optimisation. These parameters are taken from previous work (Costa-juss`a et al., 2017). 3 4 http://opus.lingfil.uu.se/ The clean version of the corpus is available upon request. 277 Neural-based. Specifically, neur"
W18-3931,Q17-1026,0,0.0341541,"arning architecture based on neural networks to compose the final translation. As mentioned, there are several architectures which have been proven state-of-the-art, all of them based on an encoder-decoder schema but using either recurrent neural networks (Cho et al., 2014), convolutional neural networks (Gehring et al., 2017) or the transformer architecture based only on attention-based mechanisms (Vaswani et al., 2017). These architectures can be adapted to deal with different input representations either words, subwords (Sennrich et al., 2016), characters (Costa-juss`a and Fonollosa, 2016; Lee et al., 2017) or bytes (Costa-juss`a et al., 2017). In this paper, we are using the first option of recurrent neural networks with an added attention-based mechanism (Bahdanau et al., 2015) and bytes as input representations (Costa-juss`a et al., 2017). 3.1 Data Compiling suitable parallel language variety corpora for NLP tasks is not trivial. Popular and freely available data sources (e.g. Wikipedia) used in NLP do not account for regional variation. One possible data source that includes national varieties of the same language are technical user manuals which are often localized between countries. Howeve"
W18-3931,2011.eamt-1.22,0,0.0155857,"ell (2006) on Irish and Scottish Gaelic, (Goyal and Lehal, 2010) on Hindi and Punjabi, a few studies 1 In this paper, when talking about language varieties, we use the verbs adapt, edit, and translate interchangeably. In previous work Marujo et al. (2011) used the word adaptation whereas Fancellu et al. (2014) used the word conversion. We consider it, however, as a full-fledged translation task and approach the task as such. 2 The 1990 orthographic agreement has been recently introduced in both countries diminishing these differences. 276 on Afrikaans and Dutch (Van Huyssteen and Pilon, 2009; Otte and Tyers, 2011), and Hassani (2017) on Kurdish dialects. To the best of our knowledge, however, the use of NMT is under-explored in these tasks and no language variety translation system has been developed using NMT. The most similar study is the one by (Costa-juss`a et al., 2017) who developed a neural-based MT system to translate between Catalan and Spanish. The use of NMT to translate between language varieties is the main contribution of our work. 3 Methods To be able to compare MT approaches, we trained SMT and NMT systems using the same dataset described in Section 3.1. The two systems are described in"
W18-3931,L16-1095,1,0.85961,"Missing"
W18-3931,P02-1040,0,0.100921,"CAT tool developed for translation process research. We ask native speakers of Brazilian Portuguese first to compare segments translated by NMT and SMT, choosing the best output, and subsequently to rate translations taking both fluency and adequacy into account using a 1 to 7 Likert scale. More information and the results of these experiments are presented in Section 4.2. 4 Results 4.1 Automatic Metrics In this section we present the results obtained by the statistical-based system based of phrases and the neural-based system based on seq2seq with attention and bytes in terms of BLEU score (Papineni et al., 2002). Table 1 presents the results obtained by the three systems when translating from EP to BP and Table 2 presents results obtained from BP to EP. The best results for each setting are presented in bold. System BLEU Score Phrase-based SMT Neural MT 47.68 48.58 Table 1: European to Brazilian Portuguese translation results in terms of BLEU score. System BLEU Score Phrase-based SMT Neural MT 47.34 47.54 Table 2: Brazilian to European Portuguese translation results in terms of BLEU score. We observed that in both directions the NMT system outperformed the SMT approach. The neural system obtained the"
W18-3931,P16-1162,0,0.471326,"ve also been achieving commercial success (e.g. Google’s GNMT (Wu et al., 2016)). Far from being settled, the architecture of NMT systems is constantly evolving. Given the youth of the paradigm and while the main structure of encoder-decoder is still maintained, the implementation of such is done either using recurrent neural networks (RNN) with attention mechanisms (Bahdanau et al., 2015), to convolutional neural networks (CNN) (Gehring et al., 2017) and to only attention mechanisms (Vaswani et al., 2017). For the same reason, research in NMT goes in many directions, including minimal units (Sennrich et al., 2016), unsupervised training and low resources (Artetxe et al., 2018) or transfer learning (Zoph et al., 2016), to name and cite just a few. In this paper we tackle an under-explored problem and apply NMT techniques to translate between language varieties. In previous work (Costa-juss`a, 2017), NMT has been used to translate between Spanish and Catalan, two closely-related Romance languages from the Iberian peninsula, outperforming phrase-based SMT approaches. In this paper we test whether this is also true for national varieties of the same language taking Brazilian and European Portuguese as a ca"
W18-3931,tiedemann-2012-parallel,0,0.0209058,"y corpora for NLP tasks is not trivial. Popular and freely available data sources (e.g. Wikipedia) used in NLP do not account for regional variation. One possible data source that includes national varieties of the same language are technical user manuals which are often localized between countries. However, user manuals contain a very specific technical language with short and idiomatic sentences representing commands. We searched for suitable datasets and we acquired an aligned Brazilian - European Portuguese parallel corpus of film subtitle dialogues from Open Subtitles available at Opus3 (Tiedemann, 2012). We removed all XML tags available in the data. The cleaned corpus, which we will be making available for the community as another contribution of our work4 , comprises 4.3 million sentences in each language for training, with over 33 million tokens for BP and over 34 million tokens for EP. Finally, 2,000 parallel sentences were kept for development and another 2,000 sentences for testing. 3.2 Systems Statistical-based. In a phrase-based system, the main model, which is the translation model, is extracted by statistical co-occurrences from a parallel corpus at the level of sentences. This tra"
W18-3931,P01-1067,0,0.307045,"e one by (Costa-juss`a et al., 2017) who developed a neural-based MT system to translate between Catalan and Spanish. The use of NMT to translate between language varieties is the main contribution of our work. 3 Methods To be able to compare MT approaches, we trained SMT and NMT systems using the same dataset described in Section 3.1. The two systems are described in detail in Section 3.2. Systems within the SMT category use statistical techniques to compose the final translation. There are a variety of alternatives that are state-of-the art, including: n-gram (Mari˜no et al., 2006), syntax (Yamada and Knight, 2001) or hierarchical to name a few. In this paper, we are using the popular phrase-based system (Koehn et al., 2003). Systems within the NMT category use a machine learning architecture based on neural networks to compose the final translation. As mentioned, there are several architectures which have been proven state-of-the-art, all of them based on an encoder-decoder schema but using either recurrent neural networks (Cho et al., 2014), convolutional neural networks (Gehring et al., 2017) or the transformer architecture based only on attention-based mechanisms (Vaswani et al., 2017). These archit"
W18-3931,P98-2238,0,0.0882976,"er Zero Hora, and Ted Talks to evaluate their method. Another example of a system developed to translate between Brazilian and European Portuguese is the one by Fancellu et al. (2014) who presented and SMT system trained on a parallel collection from Intel translation memories. The authors report 0.589 BLEU score using a Moses baseline system. Apart from the two aforementioned studies on translating between Portuguese varieties there have been a few studies published on translating between similar languages, language varieties, and dialects of other languages. Examples of such studies include Zhang (1998) on Mandarin and Cantonese Chinese, Scannell (2006) on Irish and Scottish Gaelic, (Goyal and Lehal, 2010) on Hindi and Punjabi, a few studies 1 In this paper, when talking about language varieties, we use the verbs adapt, edit, and translate interchangeably. In previous work Marujo et al. (2011) used the word adaptation whereas Fancellu et al. (2014) used the word conversion. We consider it, however, as a full-fledged translation task and approach the task as such. 2 The 1990 orthographic agreement has been recently introduced in both countries diminishing these differences. 276 on Afrikaans a"
W18-3931,D16-1163,0,0.0335215,"architecture of NMT systems is constantly evolving. Given the youth of the paradigm and while the main structure of encoder-decoder is still maintained, the implementation of such is done either using recurrent neural networks (RNN) with attention mechanisms (Bahdanau et al., 2015), to convolutional neural networks (CNN) (Gehring et al., 2017) and to only attention mechanisms (Vaswani et al., 2017). For the same reason, research in NMT goes in many directions, including minimal units (Sennrich et al., 2016), unsupervised training and low resources (Artetxe et al., 2018) or transfer learning (Zoph et al., 2016), to name and cite just a few. In this paper we tackle an under-explored problem and apply NMT techniques to translate between language varieties. In previous work (Costa-juss`a, 2017), NMT has been used to translate between Spanish and Catalan, two closely-related Romance languages from the Iberian peninsula, outperforming phrase-based SMT approaches. In this paper we test whether this is also true for national varieties of the same language taking Brazilian and European Portuguese as a case study. To the best of our knowledge the use of NMT to translate between national language varieties ha"
W18-3931,C98-2233,0,\N,Missing
W18-6457,C04-1046,0,0.101233,"cument-to-Vector (Doc2Vec) model. In the BoW model, we compute the cosine similarity while in the Doc2Vec model we consider the Doc2Vec similarity. By applying the Kneedle algorithm on the F1mult vs. similarity score plot, we derive the threshold based on which OK/BAD decisions are taken for the MT words. Experimental results revealed that the Doc2Vec model performs better than the BoW model on the word level QE task. 1 Introduction Evaluating and estimating quality of a machine translation (MT) system without referring the actual translation is now one of the key research areas in MT domain (Blatz et al., 2004; Specia et al., 2009). In a machine translated document quality estimation can be performed at various granularities like word level, phrase level or sentence level (Specia et al., 2010, 2013). Scarton et al. (2016) produced their task in WMT16 in document level quality estimation with winning result in two different models (Bojar et al., 2016). One model used discourse features and SVR and another model employed word embedding feature and Gaussian Process for quality estimation. (Bic¸ici, 2017) predicted translation performance with referential translation machines at word level, sentence le"
W18-6457,W17-4759,0,0.191822,"Missing"
W18-6457,W16-2391,0,0.0204848,"ore plot, we derive the threshold based on which OK/BAD decisions are taken for the MT words. Experimental results revealed that the Doc2Vec model performs better than the BoW model on the word level QE task. 1 Introduction Evaluating and estimating quality of a machine translation (MT) system without referring the actual translation is now one of the key research areas in MT domain (Blatz et al., 2004; Specia et al., 2009). In a machine translated document quality estimation can be performed at various granularities like word level, phrase level or sentence level (Specia et al., 2010, 2013). Scarton et al. (2016) produced their task in WMT16 in document level quality estimation with winning result in two different models (Bojar et al., 2016). One model used discourse features and SVR and another model employed word embedding feature and Gaussian Process for quality estimation. (Bic¸ici, 2017) predicted translation performance with referential translation machines at word level, sentence level 759 Proceedings of the Third Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 759–764 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistic"
W18-6457,2006.amta-papers.25,0,0.0789424,"l Si,k ∈ srci do Blist .add(Si,k ) end Bdict [Ti,j ].add(Blist ) end end end return Bdict end tion (QE task-2) on English–German (IT domain) SMT data. The proposed model has been developed in two ways - one using the standard Bagof-Words model and another using the Doc2Vec model. The motivation behind the use of Doc2Vec model is to achieve more accurate semantic similarity compared to the simple cosine similarity on Bag-of-Words model. The Doc2Vec model captures semantic similarity which the Bag-of-Words model can not. Our word level error estimation is mainly based on Translation Error Rate (Snover et al., 2006) between MT and PE. 2 Proposed Approach Our system highlights the retention of a word in MT translation and thus it helps human posteditors to increase their productivity with less effort. Our QE system is built over the Translation Error Rate (TER) (Snover et al., 2006) alignment between MT output and the corresponding PE output in the training data. TER alignment shows whether words from MT data (hypothesis in TER) will be continued, deleted or substituted with respect to the PE data (reference in TER). Based on the TER alignment, we build binary classification models that suggests OK for co"
W18-6457,P13-4014,0,0.0347432,"Missing"
W18-6457,2009.eamt-1.5,0,0.0382457,"c2Vec) model. In the BoW model, we compute the cosine similarity while in the Doc2Vec model we consider the Doc2Vec similarity. By applying the Kneedle algorithm on the F1mult vs. similarity score plot, we derive the threshold based on which OK/BAD decisions are taken for the MT words. Experimental results revealed that the Doc2Vec model performs better than the BoW model on the word level QE task. 1 Introduction Evaluating and estimating quality of a machine translation (MT) system without referring the actual translation is now one of the key research areas in MT domain (Blatz et al., 2004; Specia et al., 2009). In a machine translated document quality estimation can be performed at various granularities like word level, phrase level or sentence level (Specia et al., 2010, 2013). Scarton et al. (2016) produced their task in WMT16 in document level quality estimation with winning result in two different models (Bojar et al., 2016). One model used discourse features and SVR and another model employed word embedding feature and Gaussian Process for quality estimation. (Bic¸ici, 2017) predicted translation performance with referential translation machines at word level, sentence level 759 Proceedings of"
W18-6457,P10-1040,0,0.0542079,"anu.pal@uni-saarland.de, sudip.naskar@jdvu.ac.in Abstract and at phrase level. (Blain et al., 2017) submitted task on bi-lexical word embedding in WMT17 QE shared task, which produced promising results in sentence level Quality Estimation. Some studies (Fiederer and OBrien, 2009; Koehn, 2009; DePalma and Kelly, 2011; Zampieri and Vela, 2014) show that the quality of MT output along with PE can produce better result than human editor in certain situations. In our work we mainly focus on word level quality estimation. The distributional structure of words was first described by (Harris, 1954). (Turian et al., 2010) illustrated representations of words in semi-supervised learning. Bengio et al. (2003) proposed neural probabilistic language model by using a distributed representation of words. Collobert and Weston (2008), described how a convolutional neural network architecture could be used to make different language processing predictions, such as semantically similar words, etc. Mnih and Hinton (2008) proposed a fast hierarchical language model along with a feature based algorithm which automatically builds word trees from data. Mikolov et al. (2013b) proposed vector representation of words with the h"
W18-6457,W14-0314,0,0.0233394,"Prasenjit Basu1 , Santanu Pal2,3 , Sudip Kumar Naskar4 1 Future Institute of Engineering and Management, India 2 Saarland University, Germany, 3 German Research Center for Artificial Intelligence (DFKI), Saarbr¨ucken, Germany 4 Jadavpur University, India basuprasen@gmail.com, santanu.pal@uni-saarland.de, sudip.naskar@jdvu.ac.in Abstract and at phrase level. (Blain et al., 2017) submitted task on bi-lexical word embedding in WMT17 QE shared task, which produced promising results in sentence level Quality Estimation. Some studies (Fiederer and OBrien, 2009; Koehn, 2009; DePalma and Kelly, 2011; Zampieri and Vela, 2014) show that the quality of MT output along with PE can produce better result than human editor in certain situations. In our work we mainly focus on word level quality estimation. The distributional structure of words was first described by (Harris, 1954). (Turian et al., 2010) illustrated representations of words in semi-supervised learning. Bengio et al. (2003) proposed neural probabilistic language model by using a distributed representation of words. Collobert and Weston (2008), described how a convolutional neural network architecture could be used to make different language processing pre"
W18-6468,P15-2026,0,0.164005,". (2015, 2016, 2017). Based on the training process, APE systems can be categorized as either single-source (mt → pe) or multi-source ({src, mt} → pe) approaches. In general, the field of APE covers a wide methodological range, including SMTbased approaches (Simard et al., 2007a,b; Lagarda et al., 2009; Rosa et al., 2012; Pal et al., 2016c; Chatterjee et al., 2017b), and neural APE (Pal et al., 2016b; Junczys-Dowmunt and Grundkiewicz, 2016; Pal et al., 2017) based on neural machine translation (NMT). Some of the stateof-the-art multi-source approaches, both statistical (B´echara et al., 2011; Chatterjee et al., 2015) and recently neural (Libovick´y et al., 2016; Chatterjee et al., 2017a; Junczys-Dowmunt and Grundkiewicz, 2016; Varis and Bojar, 2017), explore learning from {src, mt} → pe (multi-source, MS) This paper presents our English–German Automatic Post-Editing (APE) system submitted to the APE Task organized at WMT 2018 (Chatterjee et al., 2018). The proposed model is an extension of the transformer architecture: two separate self-attention-based encoders encode the machine translation output (mt) and the source (src), followed by a joint encoder that attends over a combination of these two encoded"
W18-6468,2011.mtsummit-papers.35,1,0.854702,"Missing"
W18-6468,P11-2031,0,0.0221022,"those of the submitted overall ensemble model on test18. 3.4 Results and Discussion Table 2 presents the results for the PBSMT APE task (cf. 3.3.1), where two different transformerbased models, one ensemble of these models and the baseline BLEU scores are shown. The baseline here refers to the original MT output evaluated with respect to the corresponding PE translation. All models yield statistically significant results (p &lt; 0.001) over this baseline. M Savg also provides statistically significant improvement over SSavg . For this and all following significance tests we employ the method by Clark et al. (2011)2 . Generally, reasons for the good performance of our transformer-based MS architecture in comparison to the SS approach for PBSMT-based APE could be the positional encoding that injects information about the relative or absolute position of the tokens in the sequence. This might help to handle word order errors in mt for a given src context. Another possible explanation lies in the self-attention mechanism, which handles local word dependencies for src, mt, and pe. After the individual dependencies are learned by the two encoders’ self-attention mechanisms, another level of self-attention is"
W18-6468,W16-2378,0,0.314737,"ta minimally involves MT output (mt) and the human-post-edited (pe) version of mt, but may additionally make use of the source (src). A more detailed motivation on APE can be found in Bojar et al. (2015, 2016, 2017). Based on the training process, APE systems can be categorized as either single-source (mt → pe) or multi-source ({src, mt} → pe) approaches. In general, the field of APE covers a wide methodological range, including SMTbased approaches (Simard et al., 2007a,b; Lagarda et al., 2009; Rosa et al., 2012; Pal et al., 2016c; Chatterjee et al., 2017b), and neural APE (Pal et al., 2016b; Junczys-Dowmunt and Grundkiewicz, 2016; Pal et al., 2017) based on neural machine translation (NMT). Some of the stateof-the-art multi-source approaches, both statistical (B´echara et al., 2011; Chatterjee et al., 2015) and recently neural (Libovick´y et al., 2016; Chatterjee et al., 2017a; Junczys-Dowmunt and Grundkiewicz, 2016; Varis and Bojar, 2017), explore learning from {src, mt} → pe (multi-source, MS) This paper presents our English–German Automatic Post-Editing (APE) system submitted to the APE Task organized at WMT 2018 (Chatterjee et al., 2018). The proposed model is an extension of the transformer architecture: two sepa"
W18-6468,E17-1050,0,0.0501277,"MT output to their corresponding corrections. APE training data minimally involves MT output (mt) and the human-post-edited (pe) version of mt, but may additionally make use of the source (src). A more detailed motivation on APE can be found in Bojar et al. (2015, 2016, 2017). Based on the training process, APE systems can be categorized as either single-source (mt → pe) or multi-source ({src, mt} → pe) approaches. In general, the field of APE covers a wide methodological range, including SMTbased approaches (Simard et al., 2007a,b; Lagarda et al., 2009; Rosa et al., 2012; Pal et al., 2016c; Chatterjee et al., 2017b), and neural APE (Pal et al., 2016b; Junczys-Dowmunt and Grundkiewicz, 2016; Pal et al., 2017) based on neural machine translation (NMT). Some of the stateof-the-art multi-source approaches, both statistical (B´echara et al., 2011; Chatterjee et al., 2015) and recently neural (Libovick´y et al., 2016; Chatterjee et al., 2017a; Junczys-Dowmunt and Grundkiewicz, 2016; Varis and Bojar, 2017), explore learning from {src, mt} → pe (multi-source, MS) This paper presents our English–German Automatic Post-Editing (APE) system submitted to the APE Task organized at WMT 2018 (Chatterjee et al., 2018)."
W18-6468,P07-2045,0,0.00465891,"similar TER statistics; and second, the synthetic ‘eSCAPE’ APE corpus (Negri et al., 2018), consisting of more than 7M triples for both NMT and PBSMT. Table 1 presents the statistics of the released data for the English–German APE Task organized in WMT 2018. These datasets, except for the eSCAPE corpus, do not require any preprocessing in terms of encoding or alignment. For cleaning the noisy eSCAPE dataset containing many unrelated language words (e.g. Chinese), we perform the following two steps: (i) we use the cleaning process described in Pal et al. (2015), and (ii) we execute the Moses (Koehn et al., 2007) corpus cleaning scripts with minimum and maximum number of tokens set to 1 and 80, respectively. After cleaning, we use the Moses tokenizer to tokenize the eSCAPE corpus. To handle outof-vocabulary words, words are preprocessed into subword units (Sennrich et al., 2016) using bytepair encoding (BPE). network are set to 0.2. Each encoder and decoder contains a fully connected feed-forward network having dimensionality dmodel = 256 for the input and output and dimensionality df f = 1024 for the inner layer. This is a similar setting to Vaswani et al. (2017)’s C − model1 . For the scaled dotprod"
W18-6468,W16-2379,1,0.894916,"Missing"
W18-6468,N09-2055,0,0.0773111,"Missing"
W18-6468,2015.mtsummit-wptp.4,0,0.113047,"Missing"
W18-6468,W16-2361,0,0.207937,"Missing"
W18-6468,2015.mtsummit-papers.11,0,0.178999,"Missing"
W18-6468,L18-1004,0,0.201156,"glish– German triplets containing source English text (src) from the IT domain, the corresponding German translations (mt) from a first stage MT system, and the corresponding human-post-edited version (pe), all of them already tokenized. As this released APE dataset is small in size (see Table 1), additional resources are also available: first, the ‘artificial training data’ (Junczys-Dowmunt and Grundkiewicz, 2016) containing 4.5M sentences, 4M of which are weakly similar to the WMT 2016 training data, while 500K show very similar TER statistics; and second, the synthetic ‘eSCAPE’ APE corpus (Negri et al., 2018), consisting of more than 7M triples for both NMT and PBSMT. Table 1 presents the statistics of the released data for the English–German APE Task organized in WMT 2018. These datasets, except for the eSCAPE corpus, do not require any preprocessing in terms of encoding or alignment. For cleaning the noisy eSCAPE dataset containing many unrelated language words (e.g. Chinese), we perform the following two steps: (i) we use the cleaning process described in Pal et al. (2015), and (ii) we execute the Moses (Koehn et al., 2007) corpus cleaning scripts with minimum and maximum number of tokens set t"
W18-6468,W12-3146,0,0.053688,"Missing"
W18-6468,C16-1172,0,0.295776,"Missing"
W18-6468,P16-1162,0,0.061481,"tasets, except for the eSCAPE corpus, do not require any preprocessing in terms of encoding or alignment. For cleaning the noisy eSCAPE dataset containing many unrelated language words (e.g. Chinese), we perform the following two steps: (i) we use the cleaning process described in Pal et al. (2015), and (ii) we execute the Moses (Koehn et al., 2007) corpus cleaning scripts with minimum and maximum number of tokens set to 1 and 80, respectively. After cleaning, we use the Moses tokenizer to tokenize the eSCAPE corpus. To handle outof-vocabulary words, words are preprocessed into subword units (Sennrich et al., 2016) using bytepair encoding (BPE). network are set to 0.2. Each encoder and decoder contains a fully connected feed-forward network having dimensionality dmodel = 256 for the input and output and dimensionality df f = 1024 for the inner layer. This is a similar setting to Vaswani et al. (2017)’s C − model1 . For the scaled dotproduct attention, the input consists of queries and keys of dimension dk , and values of dimension dv . As multi-head attention parameters, we employ h = 8 for parallel attention layers, or heads. For each of these we use a dimensionality of dk = dv = dmodel /h = 32. For op"
W18-6468,W15-3017,1,0.871153,"Missing"
W18-6468,N07-1064,0,0.220716,"efore be viewed as a 2nd -stage MT system, translating predictable error patterns in MT output to their corresponding corrections. APE training data minimally involves MT output (mt) and the human-post-edited (pe) version of mt, but may additionally make use of the source (src). A more detailed motivation on APE can be found in Bojar et al. (2015, 2016, 2017). Based on the training process, APE systems can be categorized as either single-source (mt → pe) or multi-source ({src, mt} → pe) approaches. In general, the field of APE covers a wide methodological range, including SMTbased approaches (Simard et al., 2007a,b; Lagarda et al., 2009; Rosa et al., 2012; Pal et al., 2016c; Chatterjee et al., 2017b), and neural APE (Pal et al., 2016b; Junczys-Dowmunt and Grundkiewicz, 2016; Pal et al., 2017) based on neural machine translation (NMT). Some of the stateof-the-art multi-source approaches, both statistical (B´echara et al., 2011; Chatterjee et al., 2015) and recently neural (Libovick´y et al., 2016; Chatterjee et al., 2017a; Junczys-Dowmunt and Grundkiewicz, 2016; Varis and Bojar, 2017), explore learning from {src, mt} → pe (multi-source, MS) This paper presents our English–German Automatic Post-Editing"
W18-6468,C16-1241,1,0.806247,"Missing"
W18-6468,W07-0728,0,0.0476416,"efore be viewed as a 2nd -stage MT system, translating predictable error patterns in MT output to their corresponding corrections. APE training data minimally involves MT output (mt) and the human-post-edited (pe) version of mt, but may additionally make use of the source (src). A more detailed motivation on APE can be found in Bojar et al. (2015, 2016, 2017). Based on the training process, APE systems can be categorized as either single-source (mt → pe) or multi-source ({src, mt} → pe) approaches. In general, the field of APE covers a wide methodological range, including SMTbased approaches (Simard et al., 2007a,b; Lagarda et al., 2009; Rosa et al., 2012; Pal et al., 2016c; Chatterjee et al., 2017b), and neural APE (Pal et al., 2016b; Junczys-Dowmunt and Grundkiewicz, 2016; Pal et al., 2017) based on neural machine translation (NMT). Some of the stateof-the-art multi-source approaches, both statistical (B´echara et al., 2011; Chatterjee et al., 2015) and recently neural (Libovick´y et al., 2016; Chatterjee et al., 2017a; Junczys-Dowmunt and Grundkiewicz, 2016; Varis and Bojar, 2017), explore learning from {src, mt} → pe (multi-source, MS) This paper presents our English–German Automatic Post-Editing"
W18-6468,P16-2046,1,0.927101,"Missing"
W18-6468,W17-4777,0,0.632079,"rc, mt} → pe) approaches. In general, the field of APE covers a wide methodological range, including SMTbased approaches (Simard et al., 2007a,b; Lagarda et al., 2009; Rosa et al., 2012; Pal et al., 2016c; Chatterjee et al., 2017b), and neural APE (Pal et al., 2016b; Junczys-Dowmunt and Grundkiewicz, 2016; Pal et al., 2017) based on neural machine translation (NMT). Some of the stateof-the-art multi-source approaches, both statistical (B´echara et al., 2011; Chatterjee et al., 2015) and recently neural (Libovick´y et al., 2016; Chatterjee et al., 2017a; Junczys-Dowmunt and Grundkiewicz, 2016; Varis and Bojar, 2017), explore learning from {src, mt} → pe (multi-source, MS) This paper presents our English–German Automatic Post-Editing (APE) system submitted to the APE Task organized at WMT 2018 (Chatterjee et al., 2018). The proposed model is an extension of the transformer architecture: two separate self-attention-based encoders encode the machine translation output (mt) and the source (src), followed by a joint encoder that attends over a combination of these two encoded sequences (encsrc and encmt ) for generating the post-edited sentence. We compare this multi-source architecture (i.e, {src, mt} → pe)"
W18-6468,E17-2056,1,0.885018,"Missing"
W19-5301,W19-5424,1,0.858444,"Missing"
W19-5301,W19-5306,0,0.248769,"al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communications Technology (Dabre et al., 2019; Marie et al., 2019b) National Research Council of Canada (Littell et al., 2019) Bo˘gaziçi University (Biçici, 2019) PROMT LLC (Molchanov, 2019) University of Groningen (Toral et al., 2019) RWTH Aachen (Rosendahl et al., 2019) TALP Research Center, Universitat Politècnica de Catalunya (Casas et al., 2019) University of Tartu (Tättar et al., 2019) Tilde (Pinnis et al., 2019) Universitat d’Alacant (Sánchez-Cartagena et al., 2019) University of Cambridge (Stahlberg et al., 2019) Saarland University, DFKI (España-Bonet and Ruiter, 2019) University of Edinburgh (Bawden et al., 2019a) University of Maryland (Briakou and Carpuat, 2019) (no associated paper) University of Sydney (Ding and Tao, 2019) (no associated"
W19-5301,D18-1549,0,0.116951,"s are available for this system. 2.5.7 BASELINE - RE - RERANK (no associated CUNI-T RANSFORMER -T2T2018 (Popel, 2018) is the exact same system as used last year. paper) BASELINE - RE - RERANK is a standard Transformer, with corpus filtering, pre-processing, postprocessing, averaging and ensembling as well as n-best list reranking. 2.5.8 CUNI-T RANSFORMER -M ARIAN (Popel et al., 2019) is a “reimplementation” of the last year’s system (Popel, 2018) in Marian (JunczysDowmunt et al., 2018). CA I RE (Liu et al., 2019) CUNI-U NSUPERVISED -NER- POST (Kvapilíková et al., 2019) follows the strategy of Artetxe et al. (2018), creating a seed phrase-based system where the phrase table is initialized from cross-lingual embedding mappings trained on monolingual data, followed by a neural machine translation system trained on synthetic parallel corpus. The synthetic corpus is produced by the seed phrase-based MT system or by a such a model refined through iterative back-translation. CUNI-U NSUPERVISED -NER- POST further focuses on the handling of named entities, i.e. the part of vocabulary where the cross-lingual embedding mapping suffer most. CA I RE is a hybrid system that took part only in the unsupervised track."
W19-5301,D18-1332,0,0.0215805,"et al., 2018). For English↔Gujarati, synthetic parallel data from two sources, backtranslation and pivoting through Hindi, is produced using unsupervised and semi-supervised NMT models, pre-trained using a cross-lingual language objective (Lample and Conneau, 2019) For German→English, the impact of vast amounts of back-translated training data on translation quality is studied, and some additional insights are gained over (Edunov et al., 2018). Towards the end of training, for German→English and Chinese↔English, the mini-batch size was increased up to fifty-fold by delaying gradient updates (Bogoychev et al., 2018) as an alternative to learning rate cooldown (Smith, 2018). For Chinese↔English, a comparison of different segmentation strategies showed that character-based decoding was superior to the translation of subwords when translating into Chinese. Pre-processing strategies were also investigated for English→Czech, showing that preprocessing can be simplified without loss to MT quality. UEDIN’s main findings on the Chinese↔English translation task are that character-level model on the Chinese side can be used when translating into Chinese to improve the BLEU score. The same does not hold when transl"
W19-5301,W19-5351,0,0.0505622,"Missing"
W19-5301,W19-5423,0,0.0419015,"Missing"
W19-5301,W18-6412,1,0.856623,"Missing"
W19-5301,W19-5305,0,0.0496912,"Missing"
W19-5301,W12-3102,1,0.474924,"Missing"
W19-5301,W19-5310,0,0.0432396,"Missing"
W19-5301,W19-5425,0,0.0236032,"ys-Dowmunt et al., 2018) and Phrase-based machine translation system (implemented with Moses) and for the Spanish-Portuguese task. The system combination included features formerly presented in (Marie and Fujita, 2018), including scores left-to-right and right-to-left, sentence level translation probabilities and language model scores. Also authors provide contrastive results with an unsupervised phrase-based MT system which achieves quite close results to their primary system. Authors associate high performance of the unsupervised system to the language similarity. Incomslav: Team INCOMSLAV (Chen and Avgustinova, 2019) by Saarlad University participated in the Czech to Polish translation task only. The team’s primary submission builds on a transformer-based NMT baseline with back translation which has been submitted one of their contrastive submission. Incomslav’s primary system is a phoneme-based system re-scored using their NMT baseline. A second contrastive submission builds our phrase-based SMT system combined with a joint BPE model. NITS-CNLP: The NITS-CNLP team (Laskar et al., 2019) by the National Institute of Technology Silchar in India submitted results to the HI-NE translation task in both directi"
W19-5301,W07-0718,1,0.530103,"ojar Charles University Yvette Graham Barry Haddow Dublin City University University of Edinburgh Philipp Koehn JHU / University of Edinburgh Mathias Müller University of Zurich Marta R. Costa-jussà Christian Federmann UPC Microsoft Cloud + AI Shervin Malmasi Harvard Medical School Santanu Pal Saarland University Matt Post JHU Abstract Introduction The Fourth Conference on Machine Translation (WMT) held at ACL 20191 hosts a number of shared tasks on various aspects of machine translation. This conference builds on 13 previous editions of WMT as workshops and conferences (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015, 2016, 2017, 2018). This year we conducted several official tasks. We report in this paper on the news and similar translation tasks. Additional shared tasks are described in separate papers in these proceedings: • biomedical translation (Bawden et al., 2019b) • automatic post-editing (Chatterjee et al., 2019) • metrics (Ma et al., 2019) • quality estimation (Fonseca et al., 2019) • parallel corpus filtering (Koehn et al., 2019) • robustness (Li et al., 2019b) In the news translation task (Section 2), participants were asked to tra"
W19-5301,P16-2058,1,0.819865,"ipated with the Transformer (Vaswani et al., 2017) implemented in the OpenNMT toolkit. They focused on word segmentation methods and compared a cognate-aware segmentation method, Cognate Morfessor (Grönroos et al., 2018), with character segmentation and unsupervised segmentation methods. As primary submission they submitted this Cognate Morfessor that optimizes subword segmentations consistently for cognates. They participated for all translation directions in Spanish-Portuguese and Czech-Polish, and this Cognate Morfessor performed better for Czech-Polish, while characterbased segmentations (Costa-jussà and Fonollosa, 2016), while much more inefficient, were superior for Spanish-Portuguese. UPC-TALP: The UPC-TALP team (Biesialska et al., 2019) by the Universitat Politècnica de Catalunya submitted a Transformer (implemented with Fairseq (Ott et al., 2019)) for the Czechto-Polish task and a Phrase-based system (implemented with Moses (Koehn et al., 2007)) for Spanish-to-Portuguese. They tested adding monolingual data to the NMT system by copying the same data on the source and target sides, with negative results. Also, their system combination based on sentence-level BLEU in back-translation 5.4 Conclusion of Simi"
W19-5301,W08-0309,1,0.659809,"Missing"
W19-5301,W18-3931,1,0.820211,"or they use English as a pivot language to translate between resource-poorer languages. The interest in English is reflected, for example, in the WMT translation tasks (e.g. News, Biomedical) which have always included language pairs in which texts are translated to and/or from English. With the widespread use of MT technology, there is more and more interest in training systems to translate between languages other than English. One evidence of this is the need of directly translating between pairs of similar languages, varieties, and dialects (Zhang, 1998; Marujo et al., 2011; Hassani, 2017; Costa-jussà et al., 2018). The main challenge is to take advantage of the similarity between languages to overcome the limitation given the low amount of available parallel data to produce an accurate output. Given the interest of the community in this topic we organize, for the first time at WMT, a shared task on ""Similar Language Translation"" to evaluate the performance of state-of-the-art translation systems on translating between pairs of languages from the same language family. We provide participants with training and testing data from three language pairs: Spanish - Portuguese (Romance languages), Czech - Polis"
W19-5301,W19-5312,0,0.0773587,"Missing"
W19-5301,W19-5313,0,0.0931699,"University (Marchisio et al., 2019) (no associated paper) University of Saarland (Mondal et al., 2019) Kingsoft AI (Guo et al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communications Technology (Dabre et al., 2019; Marie et al., 2019b) National Research Council of Canada (Littell et al., 2019) Bo˘gaziçi University (Biçici, 2019) PROMT LLC (Molchanov, 2019) University of Groningen (Toral et al., 2019) RWTH Aachen (Rosendahl et al., 2019) TALP Research Center, Universitat Politècnica de Catalunya (Casas et al., 2019) University of Tartu (Tättar et al., 2019) Tilde (Pinnis et al., 2019) Universitat d’Alacant (Sánchez-Cartagena et al., 2019) University of Cambridge (Stahlberg et al., 2019) Saarland University, DFKI (España-Bonet and Ruiter, 2019) University of Edinburgh (Bawden et al., 2019a) University of"
W19-5301,W19-5314,0,0.0200465,"Bo˘gaziçi University (Biçici, 2019) PROMT LLC (Molchanov, 2019) University of Groningen (Toral et al., 2019) RWTH Aachen (Rosendahl et al., 2019) TALP Research Center, Universitat Politècnica de Catalunya (Casas et al., 2019) University of Tartu (Tättar et al., 2019) Tilde (Pinnis et al., 2019) Universitat d’Alacant (Sánchez-Cartagena et al., 2019) University of Cambridge (Stahlberg et al., 2019) Saarland University, DFKI (España-Bonet and Ruiter, 2019) University of Edinburgh (Bawden et al., 2019a) University of Maryland (Briakou and Carpuat, 2019) (no associated paper) University of Sydney (Ding and Tao, 2019) (no associated paper) 8 participated in all language pairs. The translations from the Table 5: Participants in the shared translation task. Not all teams online systems were not submitted by their respective companies but were obtained by us, and are therefore anonymized in a fashion consistent with previous years of the workshop. 2.5.6 BTRANS only the middle sentence was considered for the final translation hypothesis, otherwise shorter context of two sentences or just a single sentence was used. Unfortunately, no details are available for this system. 2.5.7 BASELINE - RE - RERANK (no associ"
W19-5301,D18-1045,0,0.0285693,"xt was morphologically segmented with Apertium. The UEDIN systems are supervised NMT systems based on the transformer architecture and trained using Marian (Junczys-Dowmunt et al., 2018). For English↔Gujarati, synthetic parallel data from two sources, backtranslation and pivoting through Hindi, is produced using unsupervised and semi-supervised NMT models, pre-trained using a cross-lingual language objective (Lample and Conneau, 2019) For German→English, the impact of vast amounts of back-translated training data on translation quality is studied, and some additional insights are gained over (Edunov et al., 2018). Towards the end of training, for German→English and Chinese↔English, the mini-batch size was increased up to fifty-fold by delaying gradient updates (Bogoychev et al., 2018) as an alternative to learning rate cooldown (Smith, 2018). For Chinese↔English, a comparison of different segmentation strategies showed that character-based decoding was superior to the translation of subwords when translating into Chinese. Pre-processing strategies were also investigated for English→Czech, showing that preprocessing can be simplified without loss to MT quality. UEDIN’s main findings on the Chinese↔Engl"
W19-5301,W18-6410,0,0.0193718,"ormance can be found in Hindi-Nepali (both directions), where the best performing system is around 50 BLEU (53 for Hindi-to-Nepali and 49.1 for Nepali-toHindi), and the lowest entry is 1.4 for Hindi-toNepali and 0 for Nepali-to-Hindi. The lowest variance is for Polish-to-Czech and it may be because only two teams participated. UHelsinki: The University of Helsinki team (Scherrer et al., 2019) participated with the Transformer (Vaswani et al., 2017) implemented in the OpenNMT toolkit. They focused on word segmentation methods and compared a cognate-aware segmentation method, Cognate Morfessor (Grönroos et al., 2018), with character segmentation and unsupervised segmentation methods. As primary submission they submitted this Cognate Morfessor that optimizes subword segmentations consistently for cognates. They participated for all translation directions in Spanish-Portuguese and Czech-Polish, and this Cognate Morfessor performed better for Czech-Polish, while characterbased segmentations (Costa-jussà and Fonollosa, 2016), while much more inefficient, were superior for Spanish-Portuguese. UPC-TALP: The UPC-TALP team (Biesialska et al., 2019) by the Universitat Politècnica de Catalunya submitted a Transform"
W19-5301,W19-5317,0,0.114089,"ed paper) (Liu et al., 2019) Charles University (Popel et al., 2019; Kocmi and Bojar, 2019) and (Kvapilíková et al., 2019) Kumamoto University, Telkom University, Indonesian Institute of Sciences (Budiwati et al., 2019) DFKI (Zhang and van Genabith, 2019) eTranslation (Oravecz et al., 2019) Facebook AI Research (Ng et al., 2019) GTCOM (Bei et al., 2019) University of Helsinki (Talman et al., 2019) IIIT Hyderabad (Goyal and Sharma, 2019) IIT Patna (Sen et al., 2019) Johns Hopkins University (Marchisio et al., 2019) (no associated paper) University of Saarland (Mondal et al., 2019) Kingsoft AI (Guo et al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communications Technology (Dabre et al., 2019; Marie et al., 2019b) National Research Council of Canada (Littell et al., 2019) Bo˘gaziçi University (Biçici, 201"
W19-5301,W19-5315,0,0.0266353,"Missing"
W19-5301,W19-5318,0,0.198338,"ance of the systems when translating from French to German seems to heavily depend on the 7 http://data.statmt.org/wmt19/ translation-task/dev.tgz 6 Systems MSRA.MADL eTranslation LIUM MLLP-UPV onlineA TartuNLP onlineB onlineY onlineG onlineX FULL 47.3 45.4 43.7 41.5 40.8 39.2 39.1 39.0 38.5 38.1 source FR 38.3 37.4 37.5 36.4 35.4 34.8 35.3 34.7 34.6 35.6 source DE 50.0 47.8 45.5 43.0 42.3 40.5 40.2 40.2 39.7 38.8 evaluations. In the rest of this sub-section, we provide brief details of the submitted systems, for those in cases where the authors provided such details. 2.5.1 AFRL - SYSCOMB 19 (Gwinnup et al., 2019) is a system combination of a Marian ensemble system, two distinct OpenNMT systems, a Sockeyebased Elastic Weight Consolidation system, and one Moses phrase-based system. Table 3: French→German Meteor scores. Systems MSRA.MADL LinguaCustodia MLLP_UPV Kyoto_University_T2T LIUM onlineY onlineB TartuNLP onlineA onlineX onlineG FULL 52.0 51.3 49.5 48.8 48.3 47.5 46.4 46.3 45.3 42.7 41.7 source FR 51.9 52.5 49.9 49.7 46.5 43.7 43.7 45.0 43.7 41.6 40.9 source DE 52.0 51.0 49.4 48.6 48.7 48.4 47.0 46.7 45.8 42.9 41.9 AFRL- EWC (Gwinnup et al., 2019) is a Sockeye Transformer system trained with the de"
W19-5301,W19-5316,0,0.109691,"boratory (Gwinnup et al., 2019) Apertium (Pirinen, 2019) Apprentice (Li and Specia, 2019) Aylien Ltd. (Hokamp et al., 2019) Baidu (Sun et al., 2019) (no associated paper) (no associated paper) (Liu et al., 2019) Charles University (Popel et al., 2019; Kocmi and Bojar, 2019) and (Kvapilíková et al., 2019) Kumamoto University, Telkom University, Indonesian Institute of Sciences (Budiwati et al., 2019) DFKI (Zhang and van Genabith, 2019) eTranslation (Oravecz et al., 2019) Facebook AI Research (Ng et al., 2019) GTCOM (Bei et al., 2019) University of Helsinki (Talman et al., 2019) IIIT Hyderabad (Goyal and Sharma, 2019) IIT Patna (Sen et al., 2019) Johns Hopkins University (Marchisio et al., 2019) (no associated paper) University of Saarland (Mondal et al., 2019) Kingsoft AI (Guo et al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of"
W19-5301,E14-1047,1,0.904335,"Missing"
W19-5301,W19-5427,0,0.0467733,"Missing"
W19-5301,W19-5322,1,0.807321,"Missing"
W19-5301,W19-5302,1,0.715203,"20191 hosts a number of shared tasks on various aspects of machine translation. This conference builds on 13 previous editions of WMT as workshops and conferences (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015, 2016, 2017, 2018). This year we conducted several official tasks. We report in this paper on the news and similar translation tasks. Additional shared tasks are described in separate papers in these proceedings: • biomedical translation (Bawden et al., 2019b) • automatic post-editing (Chatterjee et al., 2019) • metrics (Ma et al., 2019) • quality estimation (Fonseca et al., 2019) • parallel corpus filtering (Koehn et al., 2019) • robustness (Li et al., 2019b) In the news translation task (Section 2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data (“constrained” condition). We 1 Christof Monz University of Amsterdam Marcos Zampieri University of Wolverhampton held 18 translation tasks this year, between English and each of Chinese, Czech (into Czech only), German, Finnish, Lithuanian, and Russian. New this year were Gujarati↔English and Kazakh↔English. B"
W19-5301,W19-5333,0,0.0923169,"Missing"
W19-5301,W19-5353,0,0.0658382,"Missing"
W19-5301,W19-5430,1,0.873847,"Missing"
W19-5301,W19-5431,0,0.0199622,"Universitat Politècnica de València (UPV) participated with a Transformer (implemented with FairSeq (Ott et al., 2019)) and a finetuning strategy for domain adaptaion in the task of Spanish-Portuguese. Fine-tunning on the development data provide improvements of almost 12 BLEU points, which may explain their clear best performance in the task for this language pair. As a contrastive system authors provided only for the Portuguese-to-Spanish a novel 2D alternating RNN model which did not respond so well when fine-tunning. UBC-NLP: Team UBC-NLP from the University of British Columbia in Canada (Przystupa and Abdul-Mageed, 2019) compared the performance of the LSTM plus attention (Bahdanau et al., 2015) and Transformer (Vaswani et al., 2017) (implemented in OpenNMT toolkit22 ) perform for the three tasks at hand. Authors use backtranslation to introduce monolingual data in their systems. LSTM plus attention outperformed Transformer for Hindi-Nepali, and viceversa for the other two tasks. As reported by the authors, Hindi-Nepali task provides much more shorter sentences than KYOTOUNIVERSITY: Kyoto University’s submission, listed simply as KYOTO in Table 25 for PT → ES task is based on transformer NMT system. They used"
W19-5301,P02-1040,0,0.11337,"ation of the source (CS), and a second encoder to encode sub-word (byte-pair-encoding) information of the source (CS). The results obtained by their system in translating from Czech→Polish and comment on the impact of out-of-domain test data in the performance of their system. UDSDFKI ranked second among ten teams in Czech– Polish translation. 5.3 Results We present results for the three language pairs, each of them in the two possible directions. For this first edition of the Similar Translation Task and differently from News task, evaluation was only performed on automatic basis using BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) measures. Each language direction is reported in one different table which contain information of the team; type of system, either contrastive (C) or primary (P), and the BLEU and TER results. In general, primary systems tend to be better than contrastive systems, as expected, but there are some exceptions. Even if we are presenting 3 pairs of languages each pair belonging to the same family, translation quality in terms of BLEU varies signficantly. While the best systems for Spanish-Portuguese are above 64 BLEU and below 21 TER (see Tables 26 and 27), best syste"
W19-5301,W19-5354,0,0.0611791,"Missing"
W19-5301,W18-6486,0,0.0189853,"the agglutinative nature of Kazakh, (ii) data from an additional language (Russian), given the scarcity of English–Kazakh data and (iii) synthetic data for the source language filtered using language-independent sentence similarity. RUG _ KKEN _ MORFESSOR Tilde developed both constrained and unconstrained NMT systems for English-Lithuanian and Lithuanian-English using the Marian toolkit. All systems feature ensembles of four to five transformer models that were trained using the quasi-hyperbolic Adam optimiser (Ma and Yarats, 2018). Data for the systems were prepared using TildeMT filtering (Pinnis, 2018) and preprocessing (Pinnis et al., 2018) methods. For unconstrained systems, data were additionally filtered using dual conditional cross-entropy filtering (Junczys-Dowmunt, 2018a). All systems were trained using iterative back-translation (Rikters, 2018) and feature synthetic data that allows training NMT systems to support handling of unknown phenomena (Pinnis et al., 2017). During translation, automatic named entity and nontranslatable phrase post-editing were performed. For constrained systems, named entities and nontranslatable phrase lists were extracted from the parallel training data."
W19-5301,W19-5335,0,0.0408704,"Missing"
W19-5301,W19-5344,1,0.904781,"n Institute of Sciences (Budiwati et al., 2019) DFKI (Zhang and van Genabith, 2019) eTranslation (Oravecz et al., 2019) Facebook AI Research (Ng et al., 2019) GTCOM (Bei et al., 2019) University of Helsinki (Talman et al., 2019) IIIT Hyderabad (Goyal and Sharma, 2019) IIT Patna (Sen et al., 2019) Johns Hopkins University (Marchisio et al., 2019) (no associated paper) University of Saarland (Mondal et al., 2019) Kingsoft AI (Guo et al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communications Technology (Dabre et al., 2019; Marie et al., 2019b) National Research Council of Canada (Littell et al., 2019) Bo˘gaziçi University (Biçici, 2019) PROMT LLC (Molchanov, 2019) University of Groningen (Toral et al., 2019) RWTH Aachen (Rosendahl et al., 2019) TALP Research Center, Universitat Politècnica de Catalunya (Casas e"
W19-5301,W19-5346,0,0.197908,"rtium (Pirinen, 2019) Apprentice (Li and Specia, 2019) Aylien Ltd. (Hokamp et al., 2019) Baidu (Sun et al., 2019) (no associated paper) (no associated paper) (Liu et al., 2019) Charles University (Popel et al., 2019; Kocmi and Bojar, 2019) and (Kvapilíková et al., 2019) Kumamoto University, Telkom University, Indonesian Institute of Sciences (Budiwati et al., 2019) DFKI (Zhang and van Genabith, 2019) eTranslation (Oravecz et al., 2019) Facebook AI Research (Ng et al., 2019) GTCOM (Bei et al., 2019) University of Helsinki (Talman et al., 2019) IIIT Hyderabad (Goyal and Sharma, 2019) IIT Patna (Sen et al., 2019) Johns Hopkins University (Marchisio et al., 2019) (no associated paper) University of Saarland (Mondal et al., 2019) Kingsoft AI (Guo et al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communicatio"
W19-5301,W19-5341,0,0.0172601,"A,B,G,X,Y. For presentation of the results, systems are treated as either constrained or unconstrained, depending on whether their models were trained only on the provided data. Since we do not know how they were built, the online systems are treated as unconstrained during the automatic and human AYLIEN _ MULTILINGUAL (Hokamp et al., 2019) The Aylien research team built a Multilingual NMT system which is trained on all WMT2019 language pairs in all directions, then fine-tuned for a small number of iterations on Gujarati-English data only, including some self-backtranslated data. 2.5.5 BAIDU (Sun et al., 2019) Baidu systems are based on the Transformer architecture with several improvements. Data selection, back translation, data augmentation, knowledge distillation, domain adaptation, model ensemble and re-ranking are employed and proven effective in our experiments. 7 Team AFRL A PERTIUM - FIN - ENG A PPRENTICE - C AYLIEN _ MULTILINGUAL BAIDU BTRANS BASELINE - RE - RERANK CA I RE CUNI DBMS-KU DFKI - NMT E T RANSLATION FACEBOOK FAIR GTCOM H ELSINKI NLP IIITH-MT IITP JHU JUMT JU_S AARLAND KSAI K YOTO U NIVERSITY L INGUA C USTODIA LIUM LMU-NMT MLLP-UPV MS T RANSLATOR MSRA N IU T RANS NICT NRC PARFDA"
W19-5301,P16-1162,1,0.310296,"ssible, 2.5.13 E T RANSLATION (Oravecz et al., 2019) E T RANSLATION En-De E T RANSLATION ’s EnDe system is an ensemble of 3 base Transformers and a Transformer-type language model, trained from all available parallel data (cleaned up and filtered with dual conditional cross-entropy filtering) and with additional back-translated data generated 9 2.5.17 from monolingual news. Each Transformer model is fine tuned on previous years’ test sets. H ELSINKI NLP is a Transformer (Vaswani et al., 2017) style model implemented in OpenNMTpy using a variety of corpus filtering techniques, truecasing, BPE (Sennrich et al., 2016), backtranslation, ensembling and fine-tuning for domain adaptation. E T RANSLATION Fr-De The Fr-De system is an ensemble of 2 big Transformers (with size 8192 FFN layers). Back-translation data was selected using topic modelling techniques to tune the model towards the domain defined in the task. 2.5.18 En-Lt The En-Lt system is an ensemble of 2 big Transformers (as for Fr-De) and a Transformer type language model. The training data contains the Rapid corpus and the news domain back-translated data sets 2 times oversampled. E T RANSLATION 2.5.19 FACEBOOK FAIR (Ng et al., 2019) 2.5.20 JHU (Mar"
W19-5301,W19-5339,0,0.0767002,"Missing"
W19-5301,W19-5347,0,0.0328257,"Missing"
W19-5301,W19-5342,1,0.887858,"encia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communications Technology (Dabre et al., 2019; Marie et al., 2019b) National Research Council of Canada (Littell et al., 2019) Bo˘gaziçi University (Biçici, 2019) PROMT LLC (Molchanov, 2019) University of Groningen (Toral et al., 2019) RWTH Aachen (Rosendahl et al., 2019) TALP Research Center, Universitat Politècnica de Catalunya (Casas et al., 2019) University of Tartu (Tättar et al., 2019) Tilde (Pinnis et al., 2019) Universitat d’Alacant (Sánchez-Cartagena et al., 2019) University of Cambridge (Stahlberg et al., 2019) Saarland University, DFKI (España-Bonet and Ruiter, 2019) University of Edinburgh (Bawden et al., 2019a) University of Maryland (Briakou and Carpuat, 2019) (no associated paper) University of Sydney (Ding and Tao, 2019) (no associated paper) 8 participated in all language pairs. The translations from the Table 5: Participants in the shared translation task. Not all teams online systems were not submitted by their respective companies but were obtained by us, and"
W19-5301,W19-5355,1,0.869964,"Missing"
W19-5301,W19-5350,0,0.0441915,"Missing"
W19-5301,P98-2238,0,0.38957,"n trained to translate texts from and to English or they use English as a pivot language to translate between resource-poorer languages. The interest in English is reflected, for example, in the WMT translation tasks (e.g. News, Biomedical) which have always included language pairs in which texts are translated to and/or from English. With the widespread use of MT technology, there is more and more interest in training systems to translate between languages other than English. One evidence of this is the need of directly translating between pairs of similar languages, varieties, and dialects (Zhang, 1998; Marujo et al., 2011; Hassani, 2017; Costa-jussà et al., 2018). The main challenge is to take advantage of the similarity between languages to overcome the limitation given the low amount of available parallel data to produce an accurate output. Given the interest of the community in this topic we organize, for the first time at WMT, a shared task on ""Similar Language Translation"" to evaluate the performance of state-of-the-art translation systems on translating between pairs of languages from the same language family. We provide participants with training and testing data from three language"
W19-5332,D18-1399,0,0.115166,"ta is not enough to train a neural system for such a low resource language pair. Therefore, preparation for large volume of parallel corpus is required which can be produced either by manual translation by professional translators or scraping parallel data from the internet. However, these processes are costly, tedious and sometimes inefficient (in case of scraping from internet). As the released data was insufficient, to generate more training data, we use back-translation. For back-translation we applied two methods, first, using unsupervised statistical machine translation as described in (Artetxe et al., 2018) and second, using Doc translation API1 (The API uses Google translator as of April 2019). We have explained the extraction of sentences and the corresponding results using the above methods in section 4.2. The synthetic dataset which we have generated can be found here.2 192,367 64,346 219,654 1,998 1,016 998 Table 1: Data Statistics of WMT 2019 English– Gujarati translation shared task. Russian. Sennrich et al. (Sennrich et al., 2016a) shown how back-translation of monolingual data can improve the NMT system. Ramesh et al. (Ramesh and Sankaranarayanan, 2018) demonstrated how an existing mode"
W19-5332,1983.tc-1.13,0,0.639264,"Missing"
W19-5332,2000.eamt-1.5,0,0.626376,"Missing"
W19-5332,N18-4016,0,0.0187063,"atistical machine translation as described in (Artetxe et al., 2018) and second, using Doc translation API1 (The API uses Google translator as of April 2019). We have explained the extraction of sentences and the corresponding results using the above methods in section 4.2. The synthetic dataset which we have generated can be found here.2 192,367 64,346 219,654 1,998 1,016 998 Table 1: Data Statistics of WMT 2019 English– Gujarati translation shared task. Russian. Sennrich et al. (Sennrich et al., 2016a) shown how back-translation of monolingual data can improve the NMT system. Ramesh et al. (Ramesh and Sankaranarayanan, 2018) demonstrated how an existing model like bidirectional recurrent neural network can be used to generate parallel sentences for non-English languages like English-Tamil and English-Hindi, which belong to low-resource language pair, to improve the SMT and the NMT systems. Choudhary et al. (Choudhary et al., 2018) has shown how to build NMT system for low resource parallel corpus language pair like English-Tamil using techniques like word embeddings and Byte-PairEncoding (Sennrich et al., 2016b) to handle OutOf-Vocabulary Words. 3 Data Preparation For our experiments we used both parallel and mon"
W19-5332,W18-6459,0,0.0163515,"n be found here.2 192,367 64,346 219,654 1,998 1,016 998 Table 1: Data Statistics of WMT 2019 English– Gujarati translation shared task. Russian. Sennrich et al. (Sennrich et al., 2016a) shown how back-translation of monolingual data can improve the NMT system. Ramesh et al. (Ramesh and Sankaranarayanan, 2018) demonstrated how an existing model like bidirectional recurrent neural network can be used to generate parallel sentences for non-English languages like English-Tamil and English-Hindi, which belong to low-resource language pair, to improve the SMT and the NMT systems. Choudhary et al. (Choudhary et al., 2018) has shown how to build NMT system for low resource parallel corpus language pair like English-Tamil using techniques like word embeddings and Byte-PairEncoding (Sennrich et al., 2016b) to handle OutOf-Vocabulary Words. 3 Data Preparation For our experiments we used both parallel and monolingual corpus released by the WMT 2019 Organizers. We back-translate the monolingual corpus and use it as additional synthetic parallel corpus to train our NMT system. The detailed statistics of the corpus is given in Table 1. We performed our experiments on two datasets, one using the parallel corpus provide"
W19-5332,P16-1009,0,0.200866,"training data, we use back-translation. For back-translation we applied two methods, first, using unsupervised statistical machine translation as described in (Artetxe et al., 2018) and second, using Doc translation API1 (The API uses Google translator as of April 2019). We have explained the extraction of sentences and the corresponding results using the above methods in section 4.2. The synthetic dataset which we have generated can be found here.2 192,367 64,346 219,654 1,998 1,016 998 Table 1: Data Statistics of WMT 2019 English– Gujarati translation shared task. Russian. Sennrich et al. (Sennrich et al., 2016a) shown how back-translation of monolingual data can improve the NMT system. Ramesh et al. (Ramesh and Sankaranarayanan, 2018) demonstrated how an existing model like bidirectional recurrent neural network can be used to generate parallel sentences for non-English languages like English-Tamil and English-Hindi, which belong to low-resource language pair, to improve the SMT and the NMT systems. Choudhary et al. (Choudhary et al., 2018) has shown how to build NMT system for low resource parallel corpus language pair like English-Tamil using techniques like word embeddings and Byte-PairEncoding"
W19-5332,W14-3308,0,0.0232331,"ne translation (MT) that uses artificial neural network to directly model the conditional probability p(y|x) of translating a source sentence (x1 ,x2 ,...,xn ) into a target sentence (y1 ,y2 ,...,ym ). NMT has consistently performed better than the phrase-based statistical MT (PB-SMT) approaches and has provided state-ofthe-art results in the last few years. However, one of the major constraints of using supervised NMT is that it is not suitable for low resource language pairs. Thus, to use supervised NMT, low resource pairs need to resort to other techniques 2 Related Works Dungarwal et al. (Dungarwal et al., 2014) developed a statistical method for machine translation, where phrase based method for Hindi-English and factored based method for English-Hindi SMT system was used. They had shown improvements to the existing SMT systems using pre-procesing and post-processing components that generated morphological inflections correctly. Imankulova et al. (Imankulova et al., 2017) showed how backtranslation and filtering from monolingual data can be used to build an effective translation system for a low-resourse language pair like Japanese∗ These three authors have contributed equally. 308 Proceedings of th"
W19-5332,P16-1162,0,0.189162,"training data, we use back-translation. For back-translation we applied two methods, first, using unsupervised statistical machine translation as described in (Artetxe et al., 2018) and second, using Doc translation API1 (The API uses Google translator as of April 2019). We have explained the extraction of sentences and the corresponding results using the above methods in section 4.2. The synthetic dataset which we have generated can be found here.2 192,367 64,346 219,654 1,998 1,016 998 Table 1: Data Statistics of WMT 2019 English– Gujarati translation shared task. Russian. Sennrich et al. (Sennrich et al., 2016a) shown how back-translation of monolingual data can improve the NMT system. Ramesh et al. (Ramesh and Sankaranarayanan, 2018) demonstrated how an existing model like bidirectional recurrent neural network can be used to generate parallel sentences for non-English languages like English-Tamil and English-Hindi, which belong to low-resource language pair, to improve the SMT and the NMT systems. Choudhary et al. (Choudhary et al., 2018) has shown how to build NMT system for low resource parallel corpus language pair like English-Tamil using techniques like word embeddings and Byte-PairEncoding"
W19-5332,W17-5704,0,0.0159843,"r, one of the major constraints of using supervised NMT is that it is not suitable for low resource language pairs. Thus, to use supervised NMT, low resource pairs need to resort to other techniques 2 Related Works Dungarwal et al. (Dungarwal et al., 2014) developed a statistical method for machine translation, where phrase based method for Hindi-English and factored based method for English-Hindi SMT system was used. They had shown improvements to the existing SMT systems using pre-procesing and post-processing components that generated morphological inflections correctly. Imankulova et al. (Imankulova et al., 2017) showed how backtranslation and filtering from monolingual data can be used to build an effective translation system for a low-resourse language pair like Japanese∗ These three authors have contributed equally. 308 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 2: Shared Task Papers (Day 1) pages 308–313 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics Dataset Parallel Corpora Cleaned Parallel Corpora Back-translated Data Development Data Gujarati Test Data English Test Data Pairs is important in the splitting part too as it is impo"
W19-5332,2006.amta-papers.25,0,0.0451986,"ask for English–Gujarati and Gujarati–English. The released training data set is completely different in-domain compared to the development set and the size is not anywhere close to the sizable amount of training data which is typically required for the success of NMT systems. We use additional synthetic data produced through backtranslation from the monolingual corpus. This provides significant improvements in translation performance for both our English–Gujarati and Gujarati–English NMT systems. Our English– Gujarati system was ranked second in terms of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) in the shared task. In this paper we describe our joint submission (JU-Saarland) from Jadavpur University and Saarland University in the WMT 2019 news translation shared task for English–Gujarati language pair within the translation task subtrack. Our baseline and primary submissions are built using a Recurrent neural network (RNN) based neural machine translation (NMT) system which follows attention mechanism followed by fine-tuning using in-domain data. Given the fact that the two languages belong to different language families and there is not enough parallel data for this language pair, b"
W19-5332,P17-4012,0,0.0223876,"s initially set to 1.0. Table 2 shows the hyper-parameter configurations for our Gujarati–English translation system. We initially trained our model with the cleaned parallel corpus provided by WMT 2019 up to 100K training steps. Thereafter, we fine-tune our generic model on domain specific corpus (containing 219K sentences back-translated using Doc Translator API) changing the learning rate to 0.5 and decay started from 130K training steps with a decay factor of 0.5 and keeping the other hyperparameters same as mentioned in Table 2. Data Postprocessing Postprocessing, such as detokenization (Klein et al., 2017), punctuation normalization4 (Koehn et al., 2007), was performed on our translated data (on the test set) to produce the final translated data. 4 Primary System description Experiment Setup We have explained our experimental setups in the next two sections. The first section contains the setup used for our final submission and the next section describes all the other supporting experimental setups. We use the OpenNMT toolkit (Klein et al., 2017) for our experiments. We performed several experiments where the parallel corpus is sent to the model as space separated character format, space separa"
W19-5332,P07-2045,0,0.00941137,"nslation pairs makes the model prone to overfitting and hence prevents it from recognizing new features. Thus, one of the sentence pair is kept while the other redundant pairs are removed. Some sentence pairs had combinations of both language pairs which were also identified as redundant. These pairs strictly need elimination as the vocabularies of the individual languages consist of alphanumeric characters of the other language which results in inconsistent encoding and decoding during encoderdecoder application steps on the considered language pair. We tokenize the English side using Moses (Koehn et al., 2007) tokenizer and for Gujarati, we use the Indic NLP library tokenization tool3 . Punctuation normalization was also done. 3.2 Value text fp32 2 8 500 256 160,000 50,000 50,000 warm-up+decay* softmax wordpiece LSTM Table 2: Hyper-parameter configurations for Gujarati– English translation using unidirectional RNN (Cho et al., 2014)), *learning-rate was initially set to 1.0. Table 2 shows the hyper-parameter configurations for our Gujarati–English translation system. We initially trained our model with the cleaned parallel corpus provided by WMT 2019 up to 100K training steps. Thereafter, we fine-t"
W19-5332,P02-1040,0,0.104065,"the WMT 2019 news translation task for English–Gujarati and Gujarati–English. The released training data set is completely different in-domain compared to the development set and the size is not anywhere close to the sizable amount of training data which is typically required for the success of NMT systems. We use additional synthetic data produced through backtranslation from the monolingual corpus. This provides significant improvements in translation performance for both our English–Gujarati and Gujarati–English NMT systems. Our English– Gujarati system was ranked second in terms of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) in the shared task. In this paper we describe our joint submission (JU-Saarland) from Jadavpur University and Saarland University in the WMT 2019 news translation shared task for English–Gujarati language pair within the translation task subtrack. Our baseline and primary submissions are built using a Recurrent neural network (RNN) based neural machine translation (NMT) system which follows attention mechanism followed by fine-tuning using in-domain data. Given the fact that the two languages belong to different language families and there is not enough parallel"
W19-5414,D11-1033,0,0.0253945,"split the released data (13.4K) into two sets; we use the first 12K for training and the remaining 1.4K as validation data. The development set (Dev) released by WMT20192 is used as test data for our experiment. We build two models transference4M and transferenceALL using slightly different training procedures. For transference4M, we first train on a training set called eScape4M combined with the first 12k of the provided NMT training data. This eScape4M data is prepared using in-domain (for our case the 12K training data) bilingual cross-entropy difference for data selection as described in Axelrod et al. (2011). The difference in cross-entropy is computed based on two language models (LM): a domain-specific LM is estimated from the indomain (12K) PE corpus (lmi ) and the out-domain LM (lmo ) is estimated from the eScape corpus. We rank the eScape corpus by assigning a score to each of the individual sentences which is the sum of the three cross-entropy (H) differences. For a j th sentence pair srcj –mtj –pej , the score is calculated based on Equation 1. 3.3 Hyper-parameter Setup We follow a similar hyper-parameter setup for all reported systems. All encoders (for {src, mt}tr → pe), and the decoder,"
W19-5414,P11-2031,0,0.0398634,"e EN-DE NMT task. Exp No. Models BLEU ↑ Test TER ↓ Baseline 1 2 3 74.73 Submission transference4M (CONTRASTIVE) 73.97 (-0.76) transferenceALL (PRIMARY) 75.75 (+1.02) raw MT 16.84 17.31 (+0.47) 16.15 (-0.69) Table 3: Evaluation results on the WMT APE 2019 test set for the EN-DE NMT task. 4.1 yield statistically significant results (p < 0.001) over the raw MT baseline. transferenceALL (PRIMARY, our primary submission in WMT2019 APE task) (Exp 7) also provides statistically significant improvement over transference4M (Exp 6). For these and all following significance tests we employ the method by Clark et al. (2011)3 . Table 2 shows that our APE architecture transferenceALL (PRIMARY) (Exp 7) significantly improves over the already very good NMT system by about +0.91 BLEU and -0.56 TER. Table 3 presents the results of our submissions on the Test set in the WMT 2019 ENDE APE task. We submitted transference4M (CONTRASTIVE) system – a weak model having performance close to the baseline, (i) to check whether in-domain data provides any gain in performance on the Test set or not, (ii) to create another baseline trained on in-domain data, by which we could analyze our PRIMARY transference model’s capability of"
W19-5414,W16-2378,0,0.0440917,"nabith1,2 Santanu Pal1,2 , Hongfei Xu1,2 , Nico Herbig2 , Antonio Kruger 1 Department of Language Science and Technology, Saarland University, Germany 2 German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus, Germany {santanu.pal, josef.vangenabith}@uni-saarland.de {hongfei.xu, nico.herbig, krueger, josef.van genabith}@dfki.de Abstract source ({src, mt} → pe) approaches. This integration of source-language information in APE is intuitively useful in conveying context information to improve APE performance. Neural APE was first proposed by Pal et al. (2016b) and Junczys-Dowmunt and Grundkiewicz (2016). A multi-source neural APE system can be configured either by using a single encoder that encodes the concatenation of src and mt (Niehues et al., 2016) or by using two separate encoders for src and mt and passing the concatenation of both encoders’ final states to the decoder (Libovick´y et al., 2016). A small number of multi-source neural APE approaches were proposed in the WMT 2017 APE shared task. The two-encoder architecture (Junczys-Dowmunt and Grundkiewicz, 2017; Chatterjee et al., 2017; Varis and Bojar, 2017) of multi-source models utilizes both the source text (src) and the MT output"
W19-5414,W18-6467,0,0.0567849,"the source (src) has been shown to provide further benefits (Bojar et al., 2015, 2016, 2017). Based on the training process, APE systems can be categorized as either single-source (mt → pe) or multi124 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 3: Shared Task Papers (Day 2) pages 124–131 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics after another multi-head attention between the output of those attention layers helps the decoder to capture common words in mt which should remain in pe. The WMT 2018 winner for the PBSMT task (Junczys-Dowmunt and Grundkiewicz, 2018) also presented transformer-based multisource APE called a dual-source transformer architecture. They use two encoders and stack an additional cross-attention component for src → pe above the previous cross-attention for mt → pe. Comparing Shin and Lee (2018)’s approach with the winner system, there are only two differences in the architecture: (i) the cross-attention order of src → mt and src → pe in the decoder, and (ii) the winner system additionally shares parameters between two encoders. In this work, we present a multi-source neural APE architecture called transference1 . Our model conta"
W19-5414,W17-4773,1,0.922074,"to improve APE performance. Neural APE was first proposed by Pal et al. (2016b) and Junczys-Dowmunt and Grundkiewicz (2016). A multi-source neural APE system can be configured either by using a single encoder that encodes the concatenation of src and mt (Niehues et al., 2016) or by using two separate encoders for src and mt and passing the concatenation of both encoders’ final states to the decoder (Libovick´y et al., 2016). A small number of multi-source neural APE approaches were proposed in the WMT 2017 APE shared task. The two-encoder architecture (Junczys-Dowmunt and Grundkiewicz, 2017; Chatterjee et al., 2017; Varis and Bojar, 2017) of multi-source models utilizes both the source text (src) and the MT output (mt) to predict the postedited output (pe) in a single end-to-end neural architecture. In the WMT 2018 APE shared task, further multi-source APE architectures based on the transformer model (Vaswani et al., 2017) have been presented. The winning team for the NMT task in WMT 2018 Tebbifakhr et al. (2018) employ sequence-level loss functions in order to avoid exposure bias during training and to be consistent with the automatic evaluation metrics. (Pal et al., 2018) proposed an APE model that us"
W19-5414,P02-1040,0,0.10395,"ons for future work. 2 Figure 1: The transference model architecture for APE ({src, mt}tr → pe). layer and an additional cross-attention layer for src → mt. Here, the encsrc encoder and the decpe decoder are equivalent to the original transformer for neural MT (Vaswani et al., 2017). Put differently, our multi-source APE implementation extends Vaswani et al. (2017) by introducing an additional encoding block by which src and mt communicate with the decoder. 3 Experiments We compare our approach against the raw MT output provided by the 1st -stage MT system. We evaluate the systems using BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). 3.1 Data For our experiments, we use the English–German WMT 2019 (Chatterjee et al., 2018) neural APE data. All released APE datasets consist of English–German triplets containing source English text (src) from the IT domain, the corresponding German translations (mt) from a 1st stage NMT system, and the corresponding humanpost-edited version (pe). Table 1 presents the statistics of the released data. As this released APE dataset is small in size (see Table 1), the synthetic eScape APE corpus (Negri et al., 2018), consisting of more than 7M triples, is available"
W19-5414,2015.mtsummit-wptp.4,0,0.021683,"Missing"
W19-5414,W16-2361,0,0.134007,"Missing"
W19-5414,2015.mtsummit-papers.11,0,0.0332464,"Missing"
W19-5414,L18-1004,0,0.125487,"MT system. We evaluate the systems using BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). 3.1 Data For our experiments, we use the English–German WMT 2019 (Chatterjee et al., 2018) neural APE data. All released APE datasets consist of English–German triplets containing source English text (src) from the IT domain, the corresponding German translations (mt) from a 1st stage NMT system, and the corresponding humanpost-edited version (pe). Table 1 presents the statistics of the released data. As this released APE dataset is small in size (see Table 1), the synthetic eScape APE corpus (Negri et al., 2018), consisting of more than 7M triples, is available as an additional resource. All datasets, except for the eScape corpus, do not require any preprocessing in terms of encoding, tokenization or alignment. For cleaning the noisy eScape dataset containing many unrelated language words (e.g. Chinese), we perform the following two steps: (i) we use the cleaning process described in Pal et al. (2015), and (ii) we execute the Moses (Koehn et al., 2007) corpus cleaning scripts with minimum and maximum number of tokens set to 1 and 100, respectively. Transference Model for APE We propose a multi-source"
W19-5414,P16-1162,0,0.0761845,"implementation is available at https:// github.com/santanupal1980/Transference. git 125 Corpus Train Dev Test eScape Sentences Overall Cleaning 13,442 1,000 1,023 7.2M 6.5M Both models are then fine-tuned towards the real data, by training again solely on the first 12k segments of the provided data. For both models, we perform checkpoint averaging using the 8 best checkpoints. We report the results on the development set provided by WMT2019, which we use as a test set. To handle out-of-vocabulary words and to reduce the vocabulary size, instead of considering words, we consider subword units (Sennrich et al., 2016) by using byte-pair encoding (BPE). In the preprocessing step, instead of learning an explicit mapping between BPEs in the src, mt and pe, we define BPE tokens by jointly processing all triplets. Thus, src, mt and pe derive a single BPE vocabulary. Since mt and pe belong to the same language (DE) and src is a close language (EN), they naturally share a good fraction of BPE tokens, which reduces the vocabulary size. Table 1: Statistics of the WMT 2019 English-German APE Shared Task Dataset. (iii) After cleaning, we perform punctuation normalization, and then use the Moses tokenizer to tokenize"
W19-5414,C16-1172,0,0.118961,"Missing"
W19-5414,W18-6470,0,0.398369,"APE architectures based on the transformer model (Vaswani et al., 2017) have been presented. The winning team for the NMT task in WMT 2018 Tebbifakhr et al. (2018) employ sequence-level loss functions in order to avoid exposure bias during training and to be consistent with the automatic evaluation metrics. (Pal et al., 2018) proposed an APE model that uses two separate self-attention-based encoders to encode mt and src, followed by a self-attended joint encoder that attends over a combination of the two encoded sequences and is used by the decoder for generating the post-edited sentence pe. Shin and Lee (2018) propose that each encoder has its own selfattention and feed-forward layer to process each input separately. On the decoder side, they add two additional multi-head attention layers, one for src → mt and another for src → pe. ThereIn this paper we present an English–German Automatic Post-Editing (APE) system called transference, submitted to the APE Task organized at WMT 2019. Our transference model is based on a multi-encoder transformer architecture. Unlike previous approaches, it (i) uses a transformer encoder block for src, (ii) followed by a transformer decoder block, but without masking"
W19-5414,W18-6468,1,0.733685,"Missing"
W19-5414,2006.amta-papers.25,0,0.0291767,"The transference model architecture for APE ({src, mt}tr → pe). layer and an additional cross-attention layer for src → mt. Here, the encsrc encoder and the decpe decoder are equivalent to the original transformer for neural MT (Vaswani et al., 2017). Put differently, our multi-source APE implementation extends Vaswani et al. (2017) by introducing an additional encoding block by which src and mt communicate with the decoder. 3 Experiments We compare our approach against the raw MT output provided by the 1st -stage MT system. We evaluate the systems using BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). 3.1 Data For our experiments, we use the English–German WMT 2019 (Chatterjee et al., 2018) neural APE data. All released APE datasets consist of English–German triplets containing source English text (src) from the IT domain, the corresponding German translations (mt) from a 1st stage NMT system, and the corresponding humanpost-edited version (pe). Table 1 presents the statistics of the released data. As this released APE dataset is small in size (see Table 1), the synthetic eScape APE corpus (Negri et al., 2018), consisting of more than 7M triples, is available as an additional resource. Al"
W19-5414,W15-3017,1,0.900274,"Missing"
W19-5414,W18-6471,0,0.345226,"ibovick´y et al., 2016). A small number of multi-source neural APE approaches were proposed in the WMT 2017 APE shared task. The two-encoder architecture (Junczys-Dowmunt and Grundkiewicz, 2017; Chatterjee et al., 2017; Varis and Bojar, 2017) of multi-source models utilizes both the source text (src) and the MT output (mt) to predict the postedited output (pe) in a single end-to-end neural architecture. In the WMT 2018 APE shared task, further multi-source APE architectures based on the transformer model (Vaswani et al., 2017) have been presented. The winning team for the NMT task in WMT 2018 Tebbifakhr et al. (2018) employ sequence-level loss functions in order to avoid exposure bias during training and to be consistent with the automatic evaluation metrics. (Pal et al., 2018) proposed an APE model that uses two separate self-attention-based encoders to encode mt and src, followed by a self-attended joint encoder that attends over a combination of the two encoded sequences and is used by the decoder for generating the post-edited sentence pe. Shin and Lee (2018) propose that each encoder has its own selfattention and feed-forward layer to process each input separately. On the decoder side, they add two a"
W19-5414,C16-1241,1,0.894741,"Missing"
W19-5414,W17-4777,0,0.133652,"ce. Neural APE was first proposed by Pal et al. (2016b) and Junczys-Dowmunt and Grundkiewicz (2016). A multi-source neural APE system can be configured either by using a single encoder that encodes the concatenation of src and mt (Niehues et al., 2016) or by using two separate encoders for src and mt and passing the concatenation of both encoders’ final states to the decoder (Libovick´y et al., 2016). A small number of multi-source neural APE approaches were proposed in the WMT 2017 APE shared task. The two-encoder architecture (Junczys-Dowmunt and Grundkiewicz, 2017; Chatterjee et al., 2017; Varis and Bojar, 2017) of multi-source models utilizes both the source text (src) and the MT output (mt) to predict the postedited output (pe) in a single end-to-end neural architecture. In the WMT 2018 APE shared task, further multi-source APE architectures based on the transformer model (Vaswani et al., 2017) have been presented. The winning team for the NMT task in WMT 2018 Tebbifakhr et al. (2018) employ sequence-level loss functions in order to avoid exposure bias during training and to be consistent with the automatic evaluation metrics. (Pal et al., 2018) proposed an APE model that uses two separate self-att"
W19-5414,P16-2046,1,0.881439,"Missing"
W19-5430,P07-2045,0,0.0110993,"(or generaldomain) data only and it differs substantially from the released development set which is part of a TED corpus. The parallel data includes Europarl v9, Wiki-titles v1, and JRC-Acquis. We combine all the released data and prepare a large outdomain dataset. 3.1 score = |Hsrc (srcj , lmi ) − Hsrc (srcj , lmo )| + |Htrg (trgj , lmi ) − Htrg (trgj , lmo ) |(1) 4 Pre-processing The out-domain data is noisy for our purposes, so we apply methods for cleaning. We performed the following two steps: (i) we use the cleaning process described in Pal et al. (2015), and (ii) we execute the Moses (Koehn et al., 2007) corpus cleaning scripts with minimum and maximum number of tokens set to 1 and 100, respectively. After cleaning, we perform punctuation normalization, and then we use the Moses tokenizer to tokenize the out-domain corpus with ‘no-escape’ option. Finally, we apply true-casing. The cleaned version of the released data, i.e., the General corpus containing 1,394,319 sentences, is sorted based on the score in Equation 1. Thereafter, We split the entire data (1,394,319) into two sets; we use the first 1,000 for validation and the remaining as training data. The released development set (Dev) is us"
W19-5430,P02-1040,0,0.107429,"verhampton, UK 3 German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus, Germany santanu.pal@uni-saarland.de 1 Abstract ing, development, and testing data from the following language pairs: Spanish - Portuguese (Romance languages), Czech - Polish (Slavic languages), and Hindi - Nepali (Indo-Aryan languages). Participant could submit system outputs to any of the three language pairs in any direction. The shared task attracted a good number of participants and the performance of all entries was evaluated using popular MT automatic evaluation metrics, namely BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). In this paper we describe the UDS-DFKI system to the WMT 2019 Similar Language Translation task. The system achieved competitive performance and ranked second among ten entries in Czech to Polish translation in terms of BLEU score. In this paper we present the UDS-DFKI system submitted to the Similar Language Translation shared task at WMT 2019. The first edition of this shared task featured data from three pairs of similar languages: Czech and Polish, Hindi and Nepali, and Portuguese and Spanish. Participants could choose to participate in any of these three tr"
W19-5430,W15-3017,1,0.860655,"Missing"
W19-5430,D11-1033,0,0.0388467,"h, and two pairs of similar languages Croatian–Serbian 219 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 3: Shared Task Papers (Day 2) pages 219–223 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics et al., 2011), which are very similar to the indomain data (for our case the development set), and (ii) transferenceALL, utilizing all the released out-domain data sorted by Equation 1. The transference500Ktraining set is prepared using in-domain (development set) bilingual cross-entropy difference for data selection as was described in Axelrod et al. (2011). The difference in cross-entropy is computed based on two language models (LM): a domain-specific LM is estimated from the in-domain (containing 2050 sentences) corpus (lmi ) and the out-domain LM (lmo ) is estimated from the eScape corpus. We rank the eScape corpus by assigning a score to each of the individual sentences which is the sum of the three cross-entropy (H) differences. For a j th sentence pair srcj –trg j , the score is calculated based on Equation 1. and Indonesian–Malay. Processing similar languages and language varieties has attracted attention not only in the MT community but"
W19-5430,P16-1162,0,0.0274215,"initially train on the complete out-of-domain dataset (General). The General data is sorted based on their in-domain similarities as described in Equation 1. transferenceALLmodels are then fine-tuned towards the 500K (in-domain-like) data. Finally, we perform checkpoint averaging using the 8 best checkpoints. We report the results on the provided development set, which we use as a test set before the submission. Additionally we also report the official test set result. To handle out-of-vocabulary words and to reduce the vocabulary size, instead of considering words, we consider subword units (Sennrich et al., 2016) by using byte-pair encoding (BPE). In the preprocessing step, instead of learning an explicit mapping between BPEs in the Czech (CS) and Polish (PL), we define BPE tokens by jointly processing all parallel data. Thus, CS and PL derive a single BPE vocabulary. Since CS and PL belong to the similar language, they naturally share a good fraction of BPE tokens, which reduces the vocabulary size. We pass word level information on the first encoder and the BPE information to the second one. On the decoder side of the transference model we pass only BPE text. We evaluate our approach with developmen"
W19-5430,2006.amta-papers.25,0,0.499063,"Center for Artificial Intelligence (DFKI), Saarland Informatics Campus, Germany santanu.pal@uni-saarland.de 1 Abstract ing, development, and testing data from the following language pairs: Spanish - Portuguese (Romance languages), Czech - Polish (Slavic languages), and Hindi - Nepali (Indo-Aryan languages). Participant could submit system outputs to any of the three language pairs in any direction. The shared task attracted a good number of participants and the performance of all entries was evaluated using popular MT automatic evaluation metrics, namely BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). In this paper we describe the UDS-DFKI system to the WMT 2019 Similar Language Translation task. The system achieved competitive performance and ranked second among ten entries in Czech to Polish translation in terms of BLEU score. In this paper we present the UDS-DFKI system submitted to the Similar Language Translation shared task at WMT 2019. The first edition of this shared task featured data from three pairs of similar languages: Czech and Polish, Hindi and Nepali, and Portuguese and Spanish. Participants could choose to participate in any of these three tracks and submit system outputs"
W19-5430,W17-1207,0,0.031028,"Missing"
W19-5430,W18-3931,1,0.847571,"Missing"
W19-5430,2014.eamt-1.34,0,0.0234245,"nterest in training systems to translate between languages other than English (Costa-juss`a, 2017). One reason for this is the growing need of direct translation between pairs of similar languages, and to a lesser extent language varieties, without the use of English as a pivot language. The main challenge is to overcome the limitation of available parallel data taking advantage of the similarity between languages. Studies have been published on translating between similar languages (e.g. Catalan - Spanish (Costa-juss`a, 2017)) and language varieties such as European and Brazilian Portuguese (Fancellu et al., 2014; Costa-juss`a et al., 2018). The study by Lakew et al. (2018) tackles both training MT systems to translate between European–Brazilian Portuguese and European–Canadian French, and two pairs of similar languages Croatian–Serbian 219 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 3: Shared Task Papers (Day 2) pages 219–223 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics et al., 2011), which are very similar to the indomain data (for our case the development set), and (ii) transferenceALL, utilizing all the released out-domain data s"
W19-5430,W18-6316,0,\N,Missing
W19-6702,C14-2028,0,0.137444,", CATaLog Online uses the Nutch2 information retrieval (IR) system. Nutch follows the standard IR model of Lucene3 with document parsing, document Indexing, TF-IDF calculation, query parsing and finally searching/document retrieval and document ranking. In our implementation, each document contains (a) a TM source segment, (b) its corresponding translation and (c) the word alignments. Machine Translation and Automatic Post Editing Along with TM matches, CATaLog Online provides MT output (Pal et al., 2015a) to the translator, an option provided by many state-of-the-art CAT tools (e.g. MateCat (Federico et al., 2014)). Besides the retrieved TM segment and the MT output CATaLog Online provides also a third option to the translator: the output of an automatic post-editing system meant to be post-edited as the MT output. The APE system is based in an OSM model (Pal et al., 2016b) and proved to deliver competitive performance in previous editions of the Automatic Post Editing (APE) shared task at WMT Bojar et al. (2016). 2 3 http://nutch.apache.org/ http://lucene.apache.org/ Proceedings of MT Summit XVII, volume 2 Editing Logs For a given input segment, CATaLog Online provides four different options: TM, MT,"
W19-6702,W15-4905,1,0.909403,"Missing"
W19-6702,W12-3123,0,0.598965,"Missing"
W19-6702,W15-5206,1,0.888157,"Missing"
W19-6702,W15-3017,1,0.90096,"Missing"
W19-6702,W15-3026,1,0.902711,"Missing"
W19-6702,L16-1095,1,0.855593,"Missing"
W19-6702,W16-2379,1,0.892057,"Missing"
W19-6702,2015.tc-1.15,0,0.150837,"Missing"
W19-6702,W14-0314,1,0.712543,"the users preferred using CATaLog Online over existing CAT tools in some respects, especially by selecting the output of the MT system and taking advantage of the color scheme for TM suggestions. 1 Introduction The use of computer software is an important part of the modern translation workflow (Zaretskaya et al., 2015; Schneider et al., 2019). A number of tools are widely used by professional translators, most notably CAT tools and terminology management software. These tools increase translators’ productivity, improve consistency in translation and, in turn, reduce the cost of translation (Zampieri and Vela, 2014). The most important compo© 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CC-BY-ND. Proceedings of MT Summit XVII, volume 2 nent in state-of-the-art CAT tools are translation memories (TM). The translators can either accept, reject or modify the suggestions received from the TM engine. As the process is done iteratively, every new translation increases the size of the translation memory making it more useful for future translations. The idea behind TMs is relatively simple, however, the process of matching and retrieval of so"
W19-6702,2015.eamt-1.6,1,\N,Missing
