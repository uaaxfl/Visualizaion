2021.starsem-1.3,Semantic shift in social networks,2021,-1,-1,3,1,934,bill noble,Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics,0,"Just as the meaning of words is tied to the communities in which they are used, so too is semantic change. But how does lexical semantic change manifest differently across different communities? In this work, we investigate the relationship between community structure and semantic change in 45 communities from the social media website Reddit. We use distributional methods to quantify lexical semantic change and induce a social network on communities, based on interactions between members. We explore the relationship between semantic change and the clustering coefficient of a community{'}s social network graph, as well as community size and stability. While none of these factors are found to be significant on their own, we report a significant effect of their three-way interaction. We also report on significant word-level effects of frequency and change in frequency, which replicate previous findings."
2021.repl4nlp-1.16,Probing Cross-Modal Representations in Multi-Step Relational Reasoning,2021,-1,-1,3,0,2489,iuliia parfenova,Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021),0,"We investigate the representations learned by vision and language models in tasks that require relational reasoning. Focusing on the problem of assessing the relative size of objects in abstract visual contexts, we analyse both one-step and two-step reasoning. For the latter, we construct a new dataset of three-image scenes and define a task that requires reasoning at the level of the individual images and across images in a scene. We probe the learned model representations using diagnostic classifiers. Our experiments show that pretrained multimodal transformer-based architectures can perform higher-level relational reasoning, and are able to learn representations for novel tasks and data that are very different from what was seen in pretraining."
2021.emnlp-main.652,Is Information Density Uniform in Task-Oriented Dialogues?,2021,-1,-1,3,1,9958,mario giulianelli,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"The Uniform Information Density principle states that speakers plan their utterances to reduce fluctuations in the density of the information transmitted. In this paper, we test whether, and within which contextual units this principle holds in task-oriented dialogues. We show that there is evidence supporting the principle in written dialogues where participants play a cooperative reference game as well as in spoken dialogues involving instruction giving and following. Our study underlines the importance of identifying the relevant contextual components, showing that information content increases particularly within topically and referentially related contextual units."
2021.conll-1.50,Analysing Human Strategies of Information Transmission as a Function of Discourse Context,2021,-1,-1,2,1,9958,mario giulianelli,Proceedings of the 25th Conference on Computational Natural Language Learning,0,"Speakers are thought to use rational information transmission strategies for efficient communication (Genzel and Charniak, 2002; Aylett and Turk, 2004; Jaeger and Levy, 2007). Previous work analysing these strategies in sentence production has failed to take into account how the information content of sentences varies as a function of the available discourse context. In this study, we estimate sentence information content within discourse context. We find that speakers transmit information at a stable rate{---}i.e., rationally{---}in English newspaper articles but that this rate decreases in spoken open domain and written task-oriented dialogues. We also observe that speakers{'} choices are not oriented towards local uniformity of information, which is another hypothesised rational strategy. We suggest that a more faithful model of communication should explicitly include production costs and goal-oriented rewards."
2020.emnlp-main.353,"{R}efer, {R}euse, {R}educe: {G}enerating {S}ubsequent {R}eferences in {V}isual and {C}onversational {C}ontexts",2020,-1,-1,5,1,20391,ece takmaz,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Dialogue participants often refer to entities or situations repeatedly within a conversation, which contributes to its cohesiveness. Subsequent references exploit the common ground accumulated by the interlocutors and hence have several interesting properties, namely, they tend to be shorter and reuse expressions that were effective in previous mentions. In this paper, we tackle the generation of first and subsequent references in visually grounded dialogue. We propose a generation model that produces referring utterances grounded in both the visual and the conversational context. To assess the referring effectiveness of its output, we also implement a reference resolution system. Our experiments and analyses show that the model produces better, more effective referring utterances than a model not grounded in the dialogue context, and generates subsequent references that exhibit linguistic patterns akin to humans."
2020.emnlp-main.377,{G}enerating {I}mage {D}escriptions via {S}equential {C}ross-{M}odal {A}lignment {G}uided by {H}uman {G}aze,2020,-1,-1,4,1,20391,ece takmaz,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"When speakers describe an image, they tend to look at objects before mentioning them. In this paper, we investigate such sequential cross-modal alignment by modelling the image description generation process computationally. We take as our starting point a state-of-the-art image captioning system and develop several model variants that exploit information from human gaze patterns recorded during language production. In particular, we propose the first approach to image description generation where visual processing is modelled sequentially. Our experiments and analyses confirm that better descriptions can be obtained by exploiting gaze-driven attention and shed light on human cognitive processes by comparing different ways of aligning the gaze modality with language production. We find that processing gaze data sequentially leads to descriptions that are better aligned to those produced by speakers, more diverse, and more natural{---}particularly when gaze is encoded with a dedicated recurrent component."
2020.coling-main.477,Words are the Window to the Soul: Language-based User Representations for Fake News Detection,2020,-1,-1,2,1,21574,marco tredici,Proceedings of the 28th International Conference on Computational Linguistics,0,"Cognitive and social traits of individuals are reflected in language use. Moreover, individuals who are prone to spread fake news online often share common traits. Building on these ideas, we introduce a model that creates representations of individuals on social media based only on the language they produce, and use them to detect fake news. We show that language-based user representations are beneficial for this task. We also present an extended analysis of the language of fake news spreaders, showing that its main features are mostly domain independent and consistent across two English datasets. Finally, we exploit the relation between language use and connections in the social graph to assess the presence of the Echo Chamber effect in our data."
2020.acl-main.365,Analysing Lexical Semantic Change with Contextualised Word Representations,2020,56,2,3,1,9958,mario giulianelli,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents the first unsupervised approach to lexical semantic change that makes use of contextualised word representations. We propose a novel method that exploits the BERT neural language model to obtain representations of word usages, clusters these representations into usage types, and measures change along time with three proposed metrics. We create a new evaluation dataset and show that the model representations and the detected semantic shifts are positively correlated with human judgements. Our extensive qualitative analysis demonstrates that our method captures a variety of synchronic and diachronic linguistic phenomena. We expect our work to inspire further research in this direction."
W19-0418,Evaluating the Representational Hub of Language and Vision Models,2019,0,0,3,1,6079,ravi shekhar,Proceedings of the 13th International Conference on Computational Semantics - Long Papers,0,"The multimodal models used in the emerging field at the intersection of computational linguistics and computer vision implement the bottom-up processing of the {``}Hub and Spoke{''} architecture proposed in cognitive science to represent how the brain processes and combines multi-sensory inputs. In particular, the Hub is implemented as a neural network encoder. We investigate the effect on this encoder of various vision-and-language tasks proposed in the literature: visual question answering, visual reference resolution, and visually grounded dialogue. To measure the quality of the representations learned by the encoder, we use two kinds of analyses. First, we evaluate the encoder pre-trained on the different vision-and-language tasks on an existing {``}diagnostic task{''} designed to assess multimodal semantic understanding. Second, we carry out a battery of analyses aimed at studying how the encoder merges and exploits the two modalities."
P19-1184,The {P}hoto{B}ook Dataset: Building Common Ground through Visually-Grounded Dialogue,2019,30,1,6,0,6979,janosch haber,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"This paper introduces the PhotoBook dataset, a large-scale collection of visually-grounded, task-oriented dialogues in English designed to investigate shared dialogue history accumulating during conversation. Taking inspiration from seminal work on dialogue analysis, we propose a data-collection task formulated as a collaborative game prompting two online participants to refer to images utilising both their visual context as well as previously established referring expressions. We provide a detailed description of the task setup and a thorough analysis of the 2,500 dialogues collected. To further illustrate the novel features of the dataset, we propose a baseline model for reference resolution which uses a simple method to take into account shared information accumulated in a reference chain. Our results show that this information is particularly important to resolve later descriptions and underline the need to develop more sophisticated models of common ground in dialogue interaction."
P19-1350,Psycholinguistics Meets Continual Learning: Measuring Catastrophic Forgetting in Visual Question Answering,2019,18,0,3,0,14563,claudio greco,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"We study the issue of catastrophic forgetting in the context of neural multimodal approaches to Visual Question Answering (VQA). Motivated by evidence from psycholinguistics, we devise a set of linguistically-informed VQA tasks, which differ by the types of questions involved (Wh-questions and polar questions). We test what impact task difficulty has on continual learning, and whether the order in which a child acquires question types facilitates computational models. Our results show that dramatic forgetting is at play and that task difficulty and order matter. Two well-known current continual learning methods mitigate the problem only to a limiting degree."
N19-1210,Short-Term Meaning Shift: A Distributional Exploration,2019,0,4,2,1,21574,marco tredici,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"We present the first exploration of meaning shift over short periods of time in online communities using distributional representations. We create a small annotated dataset and use it to assess the performance of a standard model for meaning shift detection on short-term meaning shift. We find that the model has problems distinguishing meaning shift from referential phenomena, and propose a measure of contextual variability to remedy this."
N19-1265,"Beyond task success: A closer look at jointly learning to see, ask, and {G}uess{W}hat",2019,0,3,7,1,6079,ravi shekhar,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"We propose a grounded dialogue state encoder which addresses a foundational issue on how to integrate visual grounding with dialogue system components. As a test-bed, we focus on the GuessWhat?! game, a two-player game where the goal is to identify an object in a complex visual scene by asking a sequence of yes/no questions. Our visually-grounded encoder leverages synergies between guessing and asking questions, as it is trained jointly using multi-task learning. We further enrich our model via a cooperative learning regime. We show that the introduction of both the joint architecture and cooperative learning lead to accuracy improvements over the baseline system. We compare our approach to an alternative system which extends the baseline with reinforcement learning. Our in-depth analysis shows that the linguistic skills of the two models differ dramatically, despite approaching comparable performance levels. This points at the importance of analyzing the linguistic output of competing systems beyond numeric comparison solely based on task success."
D19-6403,Big Generalizations with Small Data: Exploring the Role of Training Samples in Learning Adjectives of Size,2019,0,0,2,1,2491,sandro pezzelle,Proceedings of the Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN),0,"In this paper, we experiment with a recently proposed visual reasoning task dealing with quantities {--} modeling the multimodal, contextually-dependent meaning of size adjectives ({`}big{'}, {`}small{'}) {--} and explore the impact of varying the training data on the learning behavior of a state-of-art system. In previous work, models have been shown to fail in generalizing to unseen adjective-noun combinations. Here, we investigate whether, and to what extent, seeing some of these cases during training helps a model understand the rule subtending the task, i.e., that being big implies being not small, and vice versa. We show that relatively few examples are enough to understand this relationship, and that developing a specific, mutually exclusive representation of size adjectives is beneficial to the task."
D19-1285,Is the Red Square Big? {MAL}e{V}i{C}: Modeling Adjectives Leveraging Visual Contexts,2019,48,0,2,1,2491,sandro pezzelle,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"This work aims at modeling how the meaning of gradable adjectives of size ({`}big{'}, {`}small{'}) can be learned from visually-grounded contexts. Inspired by cognitive and linguistic evidence showing that the use of these expressions relies on setting a threshold that is dependent on a specific context, we investigate the ability of multi-modal models in assessing whether an object is {`}big{'} or {`}small{'} in a given visual scene. In contrast with the standard computational approach that simplistically treats gradable adjectives as {`}fixed{'} attributes, we pose the problem as relational: to be successful, a model has to consider the full visual context. By means of four main tasks, we show that state-of-the-art models (but not a relatively strong baseline) can learn the function subtending the meaning of size adjectives, though their performance is found to decrease while moving from simple to more complex tasks. Crucially, models fail in developing abstract representations of gradable adjectives that can be used compositionally."
D19-1477,You Shall Know a User by the Company It Keeps: Dynamic Representations for Social Media Users in {NLP},2019,0,1,4,1,21574,marco tredici,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Information about individuals can help to better understand what they say, particularly in social media where texts are short. Current approaches to modelling social media users pay attention to their social connections, but exploit this information in a static way, treating all connections uniformly. This ignores the fact, well known in sociolinguistics, that an individual may be part of several communities which are not equally relevant in all communicative situations. We present a model based on Graph Attention Networks that captures this observation. It dynamically explores the social graph of a user, computes a user representation given the most relevant connections for a target task, and combines it with linguistic information to make a prediction. We apply our model to three different tasks, evaluate it against alternative models, and analyse the results extensively, showing that it significantly outperforms other current methods."
W18-6524,Automatic Evaluation of Neural Personality-based Chatbots,2018,17,0,2,0,27675,yujie xing,Proceedings of the 11th International Conference on Natural Language Generation,0,"Stylistic variation is critical to render the utterances generated by conversational agents natural and engaging. In this paper, we focus on sequence-to-sequence models for open-domain dialogue response generation and propose a new method to evaluate the extent to which such models are able to generate responses that reflect different personality traits."
W18-5419,Analysing the potential of seq-to-seq models for incremental interpretation in task-oriented dialogue,2018,0,0,3,0,8515,dieuwke hupkes,Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP},0,"We investigate how encoder-decoder models trained on a synthetic dataset of task-oriented dialogues process disfluencies, such as hesitations and self-corrections. We find that, contrary to earlier results, disfluencies have very little impact on the task success of seq-to-seq models with attention. Using visualisations and diagnostic classifiers, we analyse the representations that are incrementally built by the model, and discover that models develop little to no awareness of the structure of disfluencies. However, adding disfluencies to the data appears to help the model create clearer representations overall, as evidenced by the attention patterns the different models exhibit."
C18-1104,Ask No More: Deciding when to guess in referential visual dialogue,2018,29,1,6,1,6079,ravi shekhar,Proceedings of the 27th International Conference on Computational Linguistics,0,"Our goal is to explore how the abilities brought in by a dialogue manager can be included in end-to-end visually grounded conversational agents. We make initial steps towards this general goal by augmenting a task-oriented visual dialogue model with a decision-making component that decides whether to ask a follow-up question to identify a target referent in an image, or to stop the conversation to make a guess. Our analyses show that adding a decision making component produces dialogues that are less repetitive and that include fewer unnecessary questions, thus potentially leading to more efficient and less unnatural interactions."
C18-1135,The Road to Success: Assessing the Fate of Linguistic Innovations in Online Communities,2018,26,3,2,1,21574,marco tredici,Proceedings of the 27th International Conference on Computational Linguistics,0,"We investigate the birth and diffusion of lexical innovations in a large dataset of online social communities. We build on sociolinguistic theories and focus on the relation between the spread of a novel term and the social role of the individuals who use it, uncovering characteristics of innovators and adopters. Finally, we perform a prediction task that allows us to anticipate whether an innovation will successfully spread within a community."
W17-6804,Semantic Variation in Online Communities of Practice,2017,0,6,2,1,21574,marco tredici,{IWCS} 2017 - 12th International Conference on Computational Semantics - Long papers,0,None
W17-5534,Adversarial evaluation for open-domain dialogue generation,2017,15,11,2,0,10786,elia bruni,Proceedings of the 18th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"We investigate the potential of adversarial evaluation methods for open-domain dialogue generation systems, comparing the performance of a discriminative agent to that of humans on the same task. Our results show that the task is hard, both for automated models and humans, but that a discriminative agent can learn patterns that lead to above-chance performance."
S16-2015,Linguistic Style Accommodation in Disagreements,2016,-1,-1,3,0,34181,elise pol,Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics,0,None
P16-1144,The {LAMBADA} dataset: Word prediction requiring a broad discourse context,2016,15,8,9,0,15539,denis paperno,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We introduce LAMBADA, a dataset to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word. To succeed on LAMBADA, computational models cannot simply rely on local context, but must be able to keep track of information in the broader discourse. We show that LAMBADA exemplifies a wide range of linguistic phenomena, and that none of several state-of-the-art language models reaches accuracy above 1% on this novel benchmark. We thus propose LAMBADA as a challenging test set, meant to encourage the development of new models capable of genuine understanding of broad context in natural language text."
N16-1038,Questioning Arbitrariness in Language: a Data-Driven Study of Conventional Iconicity,2016,0,3,2,0,34675,ekaterina abramova,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
N16-1043,Multimodal Semantic Learning from Child-Directed Input,2016,22,7,3,0,20683,angeliki lazaridou,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Children learn the meaning of words by being exposed to perceptually rich situations (linguistic discourse, visual scenes, etc). Current computational learning models typically simulate these rich situations through impoverished symbolic approximations. In this work, we present a distributed word learning model that operates on child-directed speech paired with realistic visual scenes. The model integrates linguistic and extra-linguistic information (visual and social cues), handles referential uncertainty, and correctly learns to associate words with objects, even in cases of limited linguistic exposure."
L16-1019,{P}ento{R}ef: A Corpus of Spoken References in Task-oriented Dialogues,2016,17,9,6,0,1567,sina zarriess,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"PentoRef is a corpus of task-oriented dialogues collected in systematically manipulated settings. The corpus is multilingual, with English and German sections, and overall comprises more than 20000 utterances. The dialogues are fully transcribed and annotated with referring expressions mapped to objects in corresponding visual scenes, which makes the corpus a rich resource for research on spoken referring expressions in generation and resolution. The corpus includes several sub-corpora that correspond to different dialogue situations where parameters related to interactivity, visual access, and verbal channel have been manipulated in systematic ways. The corpus thus lends itself to very targeted studies of reference in spontaneous dialogue."
K16-1011,A Data-driven Investigation of Corrective Feedback on Subject Omission Errors in First Language Acquisition,2016,14,2,2,0,35487,sarah hiller,Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning,0,None
W15-2712,Distributional Semantics in Use,2015,43,3,3,0,1053,raffaella bernardi,"Proceedings of the First Workshop on Linking Computational Models of Lexical, Sentential and Discourse-level Semantics",0,"In this position paper we argue that an adequate semantic model must account for language in use, taking into account how discourse context affects the meaning of words and larger linguistic units. Distributional semantic models are very attractive models of meaning mainly because they capture conceptual aspects and are automatically induced from natural language data. However, they need to be extended in order to account for language use in a discourse or dialogue context. We discuss phenomena that the new generation of distributional semantic models should capture, and propose concrete tasks on which they could be tested."
W15-1104,Centre Stage: How Social Network Position Shapes Linguistic Coordination,2015,-1,-1,2,1,934,bill noble,Proceedings of the 6th Workshop on Cognitive Modeling and Computational Linguistics,0,None
W15-0106,Clarifying Intentions in Dialogue: A Corpus Study,2015,12,0,2,1,37157,julian schloder,Proceedings of the 11th International Conference on Computational Semantics,0,"As part of our ongoing work on grounding in dialogue, we present a corpus-based investigation of intention-level clarification requests. We propose to refine existing theories of grounding by considering two distinct types of intention-related conversational problems: intention recognition and intention adoption. This distinction is backed-up by an annotation experiment conducted on a corpus assembled with a novel method for automatically retrieving potential requests for clarification."
W15-0129,Pragmatic Rejection,2015,17,1,2,1,37157,julian schloder,Proceedings of the 11th International Conference on Computational Semantics,0,None
W14-4321,The Role of Polarity in Inferring Acceptance and Rejection in Dialogue,2014,31,2,2,1,37157,julian schloder,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,We study the role that logical polarity plays in determining the rejection or acceptance function of an utterance in dialogue. We develop a model inspired by recent work on the semantics of negation and polarity particles and test it on annotated data from two spoken dialogue corpora: the Switchboard Corpus and the AMI Meeting Corpus. Our experiments show that taking into account the relative polarity of a proposal under discussion and of its response greatly helps to distinguish rejections from acceptances in both corpora.
S14-1019,Vagueness and Learning: A Type-Theoretic Approach,2014,32,4,1,1,936,raquel fernandez,Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*{SEM} 2014),0,We present a formal account of the meaning of vague scalar adjectives such as xe2x80x98tallxe2x80x99 formulated in Type Theory with Records. Our approach makes precise how perceptual information can be integrated into the meaning representation of these predicates; how an agent evaluates whether an entity counts as tall; and how the proposed semantics can be learned and dynamically updated through experience.
C14-1145,Empirical Analysis of Aggregation Methods for Collective Annotation,2014,22,8,3,0,40288,ciyang qing,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"We investigate methods for aggregating the judgements of multiple individuals in a linguistic annotation task into a collective judgement. We define several aggregators that take the reliability of annotators into account and thus go beyond the commonly used majority vote, and we empirically analyse their performance on new datasets of crowdsourced data. Human annotation of linguistic resources has become indispensable in computational linguistics, especially with regards to semantic and pragmatic information, which is yet beyond the reach of robust automatic labelling. Most annotation campaigns involve a small group of trained annotators who may not always agree on their judgements. The reliability of the annotation is typically assessed by quantifying the level of inter-annotator agreement, while the final annotation to be released is consensuated amongst experts. In recent years, however, crowdsourcing methods such Amazonxe2x80x99s Mechanical Turk (AMT) have shaken up this scenario by making it possible to rapidly recruit large numbers of untrainned annotators at a low cost. This offers great opportunitiesxe2x80x94in particular, if we consider that the community of speakers is the highest authority regarding linguistic knowledgexe2x80x94but also creates several challenges: amongst others, how to obtain good quality annotations from untrainned and unmonitored individuals, and how to combine large numbers of possibly conflicting judgements into a single joint annotation. In this paper we focus on the latter challenge. Our aim is to investigate and empirically test methods for aggregating the judgements of large numbers of individuals in a linguistic annotation task conducted via crowdsourcing into a collective judgement. Most researchers who turn to crowdsourcing to collect data use majority voting to combine the participantsxe2x80x99 responses (Sayeed et al., 2011; Zarcone and Rxc2xa8"
W13-2120,Generation of Quantified Referring Expressions: Evidence from Experimental Data,2013,6,0,3,0,40977,dale barr,Proceedings of the 14th {E}uropean Workshop on Natural Language Generation,0,"We present the results from an elicitation experiment in which human speakers were asked to produced quantified referring expressions (QREs), as in xe2x80x98The crate with 10 applesxe2x80x99, xe2x80x98The crate with many applesxe2x80x99, etc. These results suggest that some subtle contextual factors govern the choice between different types of QREs, and that numerals are highly preferred for subitizable quantities despite the availability of coarser-grained expressions."
P13-1053,Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model,2013,43,14,2,0,40289,ulle endriss,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Crowdsourcing provides new ways of cheaply and quickly gathering large amounts of information contributed by volunteers online. This method has revolutionised the collection of labelled data, in computational linguistics and elsewhere. However, to create annotated linguistic resources from crowdsourced data we face the challenge of having to combine the judgements of a potentially large group of annotators. Here we put forward the idea of using principles of social choice theory to design new methods for aggregating linguistic annotations provided by individuals into a single collective annotation."
S12-1013,Towards a Flexible Semantics: Colour Terms in Collaborative Reference Tasks,2012,10,3,2,0,42595,bert baumgaertner,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"We report ongoing work on the development of agents that can implicitly coordinate with their partners in referential tasks, taking as a case study colour terms. We describe algorithms for generation and resolution of colour descriptions and report results of experiments on how humans use colour terms for reference in production and comprehension."
aloni-etal-2012-building,Building a Corpus of Indefinite Uses Annotated with Fine-grained Semantic Functions,2012,4,1,3,0,42957,maria aloni,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Natural languages possess a wealth of indefinite forms that typically differ in distribution and interpretation. Although formal semanticists have strived to develop precise meaning representations for different indefinite functions, to date there has hardly been any corpus work on the topic. In this paper, we present the results of a small corpus study where English indefinite forms `any' and `some' were labelled with fine-grained semantic functions well-motivated by typological studies. We developed annotation guidelines that could be used by non-expert annotators and calculated inter-annotator agreement amongst several coders. The results show that the annotation task is hard, with agreement scores ranging from 52{\%} to 62{\%} depending on the number of functions considered, but also that each of the independent annotations is in accordance with theoretical predictions regarding the possible distributions of indefinite functions. The resulting annotated corpus is available upon request and can be accessed through a searchable online database."
W09-3944,Cascaded Lexicalised Classifiers for Second-Person Reference Resolution,2009,8,11,2,0,1531,matthew purver,Proceedings of the {SIGDIAL} 2009 Conference,0,"This paper examines the resolution of the second person English pronoun you in multi-party dialogue. Following previous work, we attempt to classify instances as generic or referential, and in the latter case identify the singular or plural addressee. We show that accuracy and robustness can be improved by use of simple lexical features, capturing the intuition that different uses and addressees are associated with different vocabularies; and we show that there is an advantage to treating referentiality and addressee identification as separate (but connected) problems."
E09-1032,Who is {``}You{''}? Combining Linguistic and Gaze Features to Resolve Second-Person References in Dialogue,2009,18,17,2,0,45102,matthew frampton,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"We explore the problem of resolving the second person English pronoun you in multi-party dialogue, using a combination of linguistic and visual features. First, we distinguish generic and referential uses, then we classify the referential uses as either plural or singular, and finally, for the latter cases, we identify the addressee. In our first set of experiments, the linguistic and visual features are derived from manual transcriptions and annotations, but in the second set, they are generated through entirely automatic means. Results show that a multimodal system is often preferable to a unimodal one."
W08-0125,Modelling and Detecting Decisions in Multi-party Dialogue,2008,20,37,1,1,936,raquel fernandez,Proceedings of the 9th {SIG}dial Workshop on Discourse and Dialogue,0,"We describe a process for automatically detecting decision-making sub-dialogues in transcripts of multi-party, human-human meetings. Extending our previous work on action item identification, we propose a structured approach that takes into account the different roles utterances play in the decision-making process. We show that this structured approach outperforms the accuracy achieved by existing decision detection systems based on flat annotations, while enabling the extraction of more fine-grained information that can be used for summarization and reporting."
J07-3005,Classifying Non-Sentential Utterances in Dialogue: A Machine Learning Approach,2007,18,26,1,1,936,raquel fernandez,Computational Linguistics,0,"In this article we use well-known machine learning methods to tackle a novel task, namely the classification of non-sentential utterances (NSUs) in dialogue. We introduce a fine-grained taxonomy of NSU classes based on corpus work, and then report on the results of several machine learning experiments. First, we present a pilot study focused on one of the NSU classes in the taxonomy---bare wh-phrases or xe2x80x9csluicesxe2x80x9d---and explore the task of disambiguating between the different readings that sluices can convey. We then extend the approach to classify the full range of NSU classes, obtaining results of around an 87% weighted F-score. Thus our experiments show that, for the taxonomy adopted, the task of identifying the right NSU class can be successfully learned, and hence provide a very encouraging basis for the more general enterprise of fully processing NSUs."
2007.sigdial-1.9,An Implemented Method for Distributed Collection and Assessment of Speech Data,2007,8,3,3,0,47833,alexander siebert,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"We present an approach to decreasing the cost of collecting speech data by a) distributing experimental setups as a downloadable computer program that records data and sends it back to an experiment server and b) by xe2x80x98re-usingxe2x80x99 subjects for instant quality evaluation of the collected data. As an example of the kind of settings in which this approach can be used, we also shortly describe an experiment we have conducted; evaluation of the collected data showed no negative effect of the xe2x80x98unsupervisedxe2x80x99 collection method."
2007.sigdial-1.10,Beyond Repair {--} Testing the Limits of the Conversational Repair System,2007,5,5,2,0,4242,david schlangen,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"We report on an experiment on the effects of inducing acoustic understanding problems in task-oriented dialogue. We found that despite causing real problems w.r.t. task performance, many instances of induced problems were not explicitly repaired by the dialogue participants. Almost all repairs referred to the immediately preceding utterance, with problems in prior utterances left unacknowledged. Clarification requests of certain forms were in this corpus more likely to trigger reformulations than repetitions, unlike in different settings."
2007.sigdial-1.25,Referring under Restricted Interactivity Conditions,2007,9,13,1,1,936,raquel fernandez,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"We report results on how the collaborative process of referring in task-oriented dialogue is aected by the restrictive interactivity of a turn-taking policy commonly used in dialogue systems, namely push-to-talk. Our findings show that the restriction did not have a negative effect. Instead, the stricter control imposed at the interaction level favoured longer, more eective referring expressions, and induced a stricter and more structured performance at the level of the task."
P05-1029,Scaling up from Dialogue to Multilogue: Some Principles and Benchmarks,2005,13,10,2,0,19278,jonathan ginzburg,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"The paper considers how to scale up dialogue protocols to multilogue, settings with multiple conversationalists. We extract two benchmarks to evaluate scaled up protocols based on the long distance resolution possibilities of non-sentential utterances in dialogue and multilogue in the British National Corpus. In light of these benchmarks, we then consider three possible transformations to dialogue protocols, formulated within an issue-based approach to dialogue management. We show that one such transformation yields protocols for querying and assertion that fulfill these benchmarks."
2005.sigdial-1.9,Using Machine Learning for Non-Sentential Utterance Classification,2005,9,5,1,1,936,raquel fernandez,Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue,0,"In this paper we investigate the use of machine learning techniques to classify a wide range of non-sentential utterance types in dialogue, a necessary first step in the interpretation of such fragments. We train different learners on a set of contextual features that can be extracted from PoS information. Our results achieve an 87% weighted f-scorexe2x80x94a 25% improvement over a simple rule-based algorithm baseline."
C04-1035,Classifying Ellipsis in Dialogue: A Machine Learning Approach,2004,6,18,1,1,936,raquel fernandez,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"This paper presents a machine learning approach to bare sluice disambiguation in dialogue. We extract a set of heuristic principles from a corpus-based sample and formulate them as probabilistic Horn clauses. We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset, and run two different machine learning algorithms: SLIPPER, a rule-based learning algorithm, and TiMBL, a memory-based system. Both learners perform well, yielding similar success rates of approx 90%. The results show that the features in terms of which we formulate our heuristic principles have significant predictive power, and that rules that closely resemble our Horn clauses can be learnt automatically from these features."
E03-3005,A Dynamic Logic Formalisation of the Dialogue Gameboard,2003,12,3,1,1,936,raquel fernandez,Student Research Workshop,0,"This paper explores the possibility of using the paradigm of Dynamic Logic (DL) to formalise information states and update processes on information states. In particular, we present a formalisation of the dialogue gameboard introduced by Jonathan Ginzburg. From a more general point of view, we show that DL is particularly well suited to develop rigorous formal foundations for an approach to dialogue dynamics based on information state updates."
W02-0203,Non-Sentential Utterances in Dialogue: A: Corpus-Based Study,2002,9,13,1,1,936,raquel fernandez,Proceedings of the Third {SIG}dial Workshop on Discourse and Dialogue,0,"Dialogue is full of intuitively complete utterances that are not sentential in their outward form, most prototypically the short answers used to respond to queries. As is well known, processing such non-sentential utterances (NSUs) is a difficult problem on both theoretical and computational grounds. In this paper we present a corpus-based study of NSUs. We propose a comprehensive, theoretically grounded classification of NSUs in dialogue based on a sub-portion of the British National Corpus (BNC). The study suggests that the interpretation of NSUs is amenable to resolution using a relatively intricate grammar combined with an utterance dynamics approach. That is, a strategy that keeps track of a highly structured dialogue record of entities that get introduced into context as a result of utterances. Complex, domain-based reasoning is not, on the whole, very much in evidence."
C02-1135,Non-Sentential Utterances: Grammar and Dialogue Dynamics in Corpus Annotation,2002,9,4,1,1,936,raquel fernandez,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"Dialogue is full of intuitively complete utterances that are not sentential in their outward form, most prototypically the short answers used to respond to queries. As is well known, processing such non-sentential utterances (NSUs) is a difficult problem on both theoretical and computational grounds. In this paper we present a corpus-based study of NSUs. We propose a comprehensive, theoretically grounded classification of NSUs in dialogue based on a sub-portion of the British National Corpus (BNC). The study suggests that the interpretation of NSUs is amenable to resolution using a relatively intricate grammar combined with an utterance dynamics approach. That is, a strategy that keeps track of a highly structured dialogue record of entities that get introduced into context as a result of utterances. Complex, domain-based reasoning is not, on the whole, very much in evidence."
